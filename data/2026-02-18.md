<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.AI](#cs.AI) [Total: 28]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.LG](#cs.LG) [Total: 69]
- [eess.SY](#eess.SY) [Total: 7]
- [cs.CY](#cs.CY) [Total: 8]
- [math.OC](#math.OC) [Total: 13]
- [stat.ML](#stat.ML) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench：首个教育学术写作评估平台，通过分层原子任务分解框架将研究流程分解为6个模块24个原子任务，提供细粒度诊断评估，并基于课程学习策略训练出EduWrite模型，在30B参数下超越72B通用模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准主要关注单次、整体性生成，缺乏对复杂学术研究流程的细粒度评估，无法反映实际学术写作中的能力瓶颈，需要专门针对教育学术写作领域的评估平台。

Method: 提出分层原子任务分解（HATD）框架，将端到端研究流程分解为6个专业研究模块（定量分析、定性研究、政策研究等）的24个原子任务；采用课程学习策略从基础技能到复杂方法论推理逐步构建能力；基于55K原始学术样本构建11K高质量指令对训练EduWrite模型。

Result: EduWrite（30B参数）在多个核心指标上显著优于更大的通用模型（72B），证明在垂直领域中，数据质量密度和分层训练课程比参数规模更具决定性影响。

Conclusion: EduResearchBench填补了教育学术写作评估的空白，通过细粒度诊断评估和课程学习策略，证明了在专业领域中，针对性的训练方法和高质量数据比单纯增加模型参数更有效。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [2] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: Indic-TunedLens：针对印度语言的可解释性框架，通过学习共享仿射变换，改进多语言大语言模型在印度语言上的表示解码能力。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型越来越多地部署在印度等语言多样化地区，但大多数可解释性工具仍针对英语设计。研究发现LLM通常在英语中心表示空间中运行，跨语言可解释性成为迫切需求。

Method: 提出Indic-TunedLens框架，针对印度语言学习共享仿射变换。与直接解码中间激活的标准Logit Lens不同，该方法调整每个目标语言的隐藏状态，使其与目标输出分布对齐，从而实现更忠实的模型表示解码。

Result: 在10种印度语言上使用MMLU基准进行评估，结果显示该方法显著优于现有最先进的可解释性方法，特别是对于形态丰富、资源匮乏的语言。

Conclusion: 该框架为多语言Transformer的层级语义编码提供了重要见解，有助于改进多语言模型在印度语言上的可解释性。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [3] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出CGRA DeBERTa模型，通过概念引导残差域增强Transformer框架提升伊斯兰圣训文本的问答准确性，在特定数据集上达到97.85 EM分数，优于BERT和DeBERTa。


<details>
  <summary>Details</summary>
Motivation: 传统伊斯兰文本QA面临领域特定语义、长上下文依赖和概念敏感推理的挑战，需要专门针对神学领域优化的解决方案。

Method: 基于定制DeBERTa Transformer骨干，结合轻量级LoRA适配和残差概念感知门控机制，利用包含12个核心术语的伊斯兰概念词典融入神学先验知识。

Result: 在42,591个QA对的数据集上，CGRA DeBERTa获得97.85 EM分数，显著优于BERT（75.87）和DeBERTa（89.77），仅增加约8%推理开销。

Conclusion: 该研究提出了高效、可解释且准确的圣训QA系统，能够为教育材料提供必要的神学细微差别，实现了领域特定语义表示的增强。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [4] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文介绍了在AVerImaTeC共享任务中获得第三名的系统，该系统将去年的检索增强生成（RAG）管道与反向图像搜索（RIS）模块结合，以低成本实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 构建一个简单、低成本且易于复制的多模态事实核查系统，为后续实验提供可访问的起点。

Method: 系统包含三个解耦模块：基于相似性搜索的文本检索模块、基于API访问的反向图像搜索（RIS）模块，以及使用GPT5.1的生成模块。每个事实核查只需一次多模态LLM调用。

Result: 系统在AVerImaTeC共享任务中获得第三名，平均每次事实核查成本仅0.013美元（使用GPT5.1），具有竞争性性能。

Conclusion: 该系统展示了简单、低成本的多模态事实核查可行性，提供了可复现的代码、提示词和向量存储，为后续改进提供了基础。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [5] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 论文提出OpaqueToolsBench基准测试，用于评估LLM在不透明工具环境中的表现，并开发了ToolObserver框架通过迭代观察工具执行反馈来改进工具文档，显著提升性能并减少token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设工具简单且文档完善，但现实世界中的工具（如通用"搜索"API）往往不透明，缺乏明确的最佳实践或故障模式。需要研究LLM代理能否通过交互改进文档来提升在不透明工具环境中的性能。

Method: 创建OpaqueToolsBench基准测试，包含三个任务导向环境：通用函数调用、交互式象棋对弈和长轨迹代理搜索。提出ToolObserver框架，通过迭代观察工具执行反馈来改进工具文档。

Result: 现有自动文档生成方法在不透明工具环境中昂贵且不可靠。ToolObserver在OpaqueToolsBench所有数据集上优于现有方法，在测试时工具探索设置中效率更高，消耗token量减少3.5-7.5倍。

Conclusion: ToolObserver框架通过迭代观察工具执行反馈来改进文档，能有效提升LLM在不透明工具环境中的性能，同时显著降低计算成本，为现实世界工具集成提供了实用解决方案。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [6] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: LX模型通过微调大语言模型，从消费者文本中准确提取16种消费相关情绪和4个评价构念，在多项测试中超越GPT-4等主流模型，为营销研究提供了新的方法论基础。


<details>
  <summary>Details</summary>
Motivation: 准确从非结构化文本中测量消费者情绪和评价是营销研究和实践的核心挑战。现有模型在消费者特定语境下的表现有限，需要更精准的测量工具。

Method: 开发了Linguistic eXtractor (LX)模型，这是一个基于消费者撰写文本微调的大语言模型。模型训练数据包含消费者自我报告的16种消费相关情绪和4个评价构念（信任、承诺、推荐、情感）。使用看似不相关回归分析验证模型在在线零售数据中的应用。

Result: LX在开放式调查回复中达到81%的宏观F1准确率，在第三方标注的亚马逊和Yelp评论中准确率超过95%，表现优于GPT-4 Turbo、RoBERTa和DeepSeek等主流模型。情绪表达能预测产品评分，进而影响购买行为，部分情绪如不满和平静直接影响购买决策。

Conclusion: LX为消费者感知测量建立了新的方法论基础，证明大语言模型可以推进营销研究和实践。模型通过无代码、免费的Web应用提供，支持对消费者文本进行可扩展分析，情感语调提供了超越星级评分的有意义信号。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [7] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个结合System-1相似性搜索和System-2全局选择的新型AI记忆框架，通过双图结构实现语义和结构相关的记忆检索，在长期记忆基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆检索方法（RAG和Graph-RAG）主要依赖相似性机制进行检索，这种System-1风格的检索在需要全局推理或全面覆盖相关信息的场景中存在局限性。

Method: Mnemis将记忆组织为两个图结构：基础图用于相似性检索，分层图支持自上而下的语义层次遍历。通过结合System-1相似性搜索和System-2全局选择机制，实现语义和结构相关的记忆检索。

Result: 在长期记忆基准测试中，Mnemis在所有对比方法中达到最先进性能，在LoCoMo上得分93.9，在LongMemEval-S上得分91.6（使用GPT-4.1-mini）。

Conclusion: Mnemis通过整合System-1和System-2两种互补的检索机制，有效解决了传统相似性检索在全局推理和全面覆盖方面的局限性，为LLM记忆系统提供了更强大的检索能力。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [8] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 提出了一个端到端的文本因果效应估计管道，通过稀疏自编码器生成假设和干预，结合协变量残差化解决文本作为治疗时的估计偏差问题。


<details>
  <summary>Details</summary>
Motivation: 文本对下游结果的因果效应估计在许多应用中至关重要，但现有方法在生成和评估受控文本变异方面存在不足。文本作为治疗时天然地将治疗信息和协变量信息混淆，导致因果效应估计存在显著偏差。

Method: 提出了一个端到端管道：1）使用稀疏自编码器（SAEs）进行假设生成和引导；2）通过协变量残差化解决估计偏差；3）结合稳健的因果估计方法，解决文本作为治疗实验中的计算和统计挑战。

Result: 实证结果表明，该管道能有效诱导目标特征的变异，并显著减少估计误差。相比朴素估计方法，提出的协变量残差化方法能有效缓解文本作为治疗时的估计偏差。

Conclusion: 该研究为文本作为治疗场景下的因果效应估计提供了一个稳健的基础框架，通过稀疏自编码器和协变量残差化相结合的方法，解决了文本干预生成和因果估计中的关键挑战。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [9] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive：结合神经符号推理与主动探索的KGQA框架，在保持高准确率的同时减少图查询和模型调用


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型和神经推理系统在处理需要精确结构化多跳推理的知识密集型查询时仍面临挑战。知识图谱提供了事实基础，但将图结构与神经模型结合存在困难：简单嵌入图事实到提示中效率低且脆弱，而纯符号或搜索密集方法检索成本高且缺乏基于梯度的优化。

Method: NeuroSymActive是一个模块化框架，结合了可微分的神经符号推理层与主动、价值引导的探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先扩展高价值路径。

Result: 在标准KGQA基准测试上的实证结果显示，NeuroSymActive在保持强答案准确率的同时，相比常见的检索增强基线方法，减少了昂贵的图查询和模型调用次数。

Conclusion: NeuroSymActive通过神经符号推理与主动探索的结合，有效解决了知识图谱问答中的效率和准确性问题，为知识密集型查询提供了更高效的解决方案。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [10] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 该研究评估了语言模型对印度英语和澳大利亚英语中俚语的识别能力，发现模型在判别任务上表现优于生成任务，且对真实网络数据比合成数据更敏感，印度英语任务表现优于澳大利亚英语。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理非标准语言变体时存在系统性性能差距，但对其理解特定变体俚语的能力研究不足，特别是在印度英语和澳大利亚英语等语言中。

Method: 构建了两个互补数据集：Web数据集（来自Urban Dictionary的377个真实用例）和Gen数据集（1492个合成生成的俚语用例）。评估了7个最先进的语言模型在三个任务上的表现：目标词预测（TWP）、引导目标词预测（TWP*）和目标词选择（TWS）。

Result: 1) TWS任务平均表现优于TWP和TWP*任务（准确率从0.03提升到0.49）；2) 模型在Web数据集上表现优于Gen数据集（相似度分数分别提高0.03和0.05）；3) 印度英语任务在所有模型和数据集上平均表现优于澳大利亚英语任务，TWS任务差异最大（准确率从0.44提升到0.54）。

Conclusion: 研究揭示了语言模型在生成和判别能力之间的基本不对称性，即使在英语这样的技术丰富语言中，对变体特定俚语的理解仍存在显著差距。

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [11] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 提出基于任务导向流程图的无编排框架，实现端到端客服自动化，无需人工干预


<details>
  <summary>Details</summary>
Motivation: 现有客服自动化方法要么依赖复杂的编排系统，要么使用过度简化的指令模式，导致指导有限且泛化能力差

Method: 定义任务导向流程图组件和评估指标，提出成本高效的流程图构建算法从对话中提取流程知识，采用小模型本地部署和基于流程图的去中心化蒸馏解决数据稀缺和隐私问题

Result: 在多种客服任务中验证了有效性，相比强基线和市场产品具有更优的量化指标和应用性能

Conclusion: 通过发布基于Web的系统演示和案例研究，旨在促进未来客服自动化的简化创建

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [12] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 研究通过结构化提示而非微调，让大语言模型在训练数据极少的情况下掌握图鲁语的基本对话能力，将词汇污染从80%降至5%，语法准确率达85%。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能在训练数据极少的情况下掌握新语言，以图鲁语（有200多万使用者但数字存在感极低）为案例进行研究。

Method: 结合显式语法文档、负约束抑制相关语言的高概率词、罗马化标准化、以及通过自我对弈生成质量可控的合成数据，使用结构化提示而非微调。

Result: 在三个LLM（Gemini 2.0 Flash、GPT-4o、Llama 3.1 70B）上评估，词汇污染从80%降至5%，语法准确率达85%。负约束带来12-18个百分点的稳定提升，语法文档效果因模型架构而异（8-22个百分点）。

Conclusion: 结构化提示方法能让大语言模型在训练数据极少的情况下有效掌握新语言的基本对话能力，为低资源语言支持提供了可行路径。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [13] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole：利用视觉语言模型的视觉接口实现模型无关、无需文本的跨智能体通信，通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，显著降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统依赖离散文本通信，存在运行时开销大和信息量化损失问题。现有潜在状态传输方法要么假设同构架构，要么依赖特定对的学习翻译器，限制了在异构模型家族间的可扩展性和模块化。

Method: 提出Vision Wormhole框架，利用视觉语言模型的视觉接口作为通用通信端口。通过通用视觉编解码器将异构推理轨迹映射到共享连续潜在空间，采用中心辐射拓扑将成对对齐复杂度从O(N²)降至O(N)，使用无标签的师生蒸馏目标对齐高速视觉通道与文本推理模式。

Result: 在异构模型家族（如Qwen-VL、Gemma）上的实验表明，Vision Wormhole在控制比较中减少了端到端运行时间，同时保持了与标准基于文本的多智能体系统相当的推理保真度。

Conclusion: Vision Wormhole为异构多智能体系统提供了一种高效、模型无关的通信框架，通过视觉接口实现"心灵感应"式通信，显著提升了跨模型协作的效率和可扩展性。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [14] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 利用大语言模型对芬兰二战难民访谈中的35万个休闲活动和组织成员进行自动分类，构建结构化资源用于社会融合研究


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案虽然能大规模研究社会生活，但直接从文本提取的信息往往无法直接回答历史学家和社会学家的定量研究问题。芬兰二战难民访谈中提取了35万个活动和组织提及，产生了7.1万个独特名称，数量过多难以直接分析。

Method: 开发了捕捉参与关键方面的分类框架（活动/组织类型、社交程度、规律性、体力需求）。标注黄金标准集进行可靠评估，测试大语言模型能否大规模应用相同分类方案。使用多轮模型运行的简单投票方法。

Result: 发现开源权重的大语言模型能够与专家判断高度匹配。应用该方法成功标注了35万个实体，为下游社会融合和相关结果研究提供了结构化资源。

Conclusion: 大语言模型能够有效应用于历史档案的大规模分类任务，为社会科学研究提供结构化数据资源，解决了从非结构化文本到定量分析的关键转换问题。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [15] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: TAROT提出了一种基于测试驱动和能力自适应的课程强化微调方法，通过构建四层测试套件（基础、中级、复杂、边缘）并解耦课程进度与原始奖励分数，根据模型能力自适应调整课程策略，显著提升代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在代码生成中存在算法复杂性和鲁棒性不足的问题，现有强化微调方法忽视了测试用例的异质难度和粒度，导致奖励信号分布不平衡和梯度更新偏差，需要更精细的课程学习策略来激励LLM的深度推理能力。

Method: TAROT方法为每个问题构建四层测试套件（基础、中级、复杂、边缘），创建可控的难度环境。关键创新是解耦课程进度与原始奖励分数，实现能力条件评估，从课程策略组合中进行原则性选择，而非依赖偶然的测试用例难度组合。

Result: 实验结果表明，代码生成中RFT的最佳课程与模型内在能力密切相关：能力较弱的模型在从易到难的课程中获益更大，而能力更强的模型在从难到易的课程中表现更优。TAROT能自适应地根据模型能力调整课程设计，持续提升生成代码的功能正确性和鲁棒性。

Conclusion: TAROT提供了一种可复现的方法，通过自适应地根据模型能力定制课程设计，解决了现有强化微调方法中的奖励信号不平衡问题，显著提升了LLM代码生成的质量，为社区研究提供了有价值的工具和数据集。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [16] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: 研究发现当前LLM代理在处理信息时存在系统性的潜在来源偏好，会优先选择某些来源的信息，这种偏好会影响信息呈现给用户的方式。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理越来越多地作为在线平台信息接口，它们通过过滤、排序和合成信息来影响用户接收的内容。虽然已有研究关注LLM生成信息时的偏见，但对LLM选择和呈现信息时的偏好因素关注较少。

Method: 对来自6个模型提供商的12个LLM进行受控实验，涵盖合成和真实世界任务，测试模型对特定来源信息的偏好程度。

Result: 多个模型表现出强烈且可预测的来源偏好，这些偏好对上下文框架敏感，可能超过内容本身的影响，即使明确提示也无法避免，并能解释先前研究中观察到的新闻推荐左倾倾向。

Conclusion: 需要深入研究这些偏好的起源，并建立机制为用户提供透明度和控制权，以管理LLM驱动代理中的偏见。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [17] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 论文引入"期望检测"任务，创建RedHOTExpect语料库（4.5K Reddit帖子），使用LLM银标注分析患者在线讨论的治疗期望模式。


<details>
  <summary>Details</summary>
Motivation: 患者期望对治疗效果有重要影响，但现有研究主要关注临床环境。在线患者平台（如医疗subreddit）可能包含患者在别处不愿分享的期望信息，然而目前没有研究分析用户在线讨论的期望类型和表达方式。

Method: 引入期望检测任务，创建RedHOTExpect语料库（4.5K Reddit帖子），使用大语言模型进行银标注，手动验证标注质量（准确率约78%），分析期望的语言模式特征。

Result: 发现乐观和主动框架在身体或治疗相关疾病的帖子中比心理健康背景更明显；数据集中患者主要讨论益处而非负面结果；标注准确率约78%。

Conclusion: 期望检测是NLP中相关且未充分探索的任务，RedHOTExpect语料库为研究患者在线期望提供了有价值的资源，揭示了不同医疗背景下期望表达的差异。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [18] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT是基于Gemma 3 27B的卢森堡语到法语/英语机器翻译系统，使用LuxAlign平行语料和议会记录训练，通过LuxEmbedder过滤低质量数据，在多个语言对上表现优于基线，LuxEmbedder还可作为质量评估指标。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对卢森堡语（LB）到法语（FR）和英语（EN）的机器翻译系统，因为卢森堡语资源相对稀缺，需要专门优化的翻译解决方案。

Method: 基于Gemma 3 27B模型进行微调，使用LuxAlign平行语料库（多语言卢森堡新闻文章）和议会记录作为训练数据，通过Google Translate增强数据，使用LuxEmbedder（卢森堡语句子嵌入）过滤低等价性片段对。

Result: LuxMT在LB-FR和LB-EN翻译上相比Gemma 3基线有显著改进，甚至在未包含德语（DE）训练数据的情况下，LB-DE翻译也有良好表现。LuxEmbedder作为质量评估指标与其他基于参考的指标有强相关性。

Conclusion: LuxMT展示了在资源较少语言翻译任务上的有效性，LuxEmbedder有潜力作为质量评估指标，但需要进一步研究验证其效用，建议谨慎使用。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [19] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine是一个细粒度对话系统精炼框架，通过将响应分解为原子单元、验证每个单元的事实性、评估流畅度，并迭代修正错误，显著提升对话的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在对话系统中存在幻觉问题，会产生事实错误的响应误导用户并损害系统信任。现有精炼方法通常在响应层面操作，忽略了单个响应可能包含多个可验证或不可验证的事实。

Method: 提出Fine-Refine框架：1) 将响应分解为原子单元；2) 使用外部知识验证每个单元的事实性；3) 通过困惑度评估流畅度；4) 迭代修正细粒度错误。

Result: 在HybriDialogue和OpendialKG数据集上的实验表明，Fine-Refine显著提升了事实性，对话事实得分最高提升7.63分，仅在对话质量上有小幅权衡。

Conclusion: 细粒度的响应分解和验证方法能有效解决对话系统中的幻觉问题，在保持对话质量的同时显著提升事实准确性。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [20] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: DependencyAI：仅使用语言依存关系标签检测AI生成文本的简单可解释方法，在单语、多生成器和多语言场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益普及，需要可靠的AI文本检测方法来降低潜在风险。现有方法通常复杂且缺乏可解释性，需要更简单、基于语言学原理的检测方法

Method: 提出DependencyAI方法，仅使用语言依存关系标签（如主语、宾语等语法关系）来检测AI生成文本。该方法分析文本的句法结构特征，建立可解释的检测模型

Result: 在单语、多生成器和多语言设置中均取得有竞争力的性能。通过特征重要性分析揭示了区分AI生成与人类写作的句法结构模式。发现特定模型在未见领域存在系统性过预测现象

Conclusion: 依存关系本身为AI生成文本检测提供了稳健信号，DependencyAI成为基于语言学原理、可解释且非神经网络的强基线方法

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [21] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 提出ExpertWeaver框架，利用GLU激活模式将预训练稠密模型转换为稀疏MoE，无需训练即可实现高性能专家构建。


<details>
  <summary>Details</summary>
Motivation: 现有稠密转MoE方法破坏了稠密模型的内在激活模式，导致专家构建不理想。GLU机制为稠密到MoE转换提供了自然蓝图。

Method: 基于GLU的细粒度神经激活模式揭示粗粒度结构，发现固有MoE架构：包含持续激活的通用神经元和动态激活的专业神经元。ExpertWeaver根据激活模式划分神经元，构建共享专家和专业化路由专家，具有层自适应配置。

Result: ExpertWeaver显著优于现有方法，既可作为无需训练的动态结构剪枝技术，也可作为高质量MoE初始化的降循环策略。

Conclusion: GLU激活模式揭示了稠密模型中的固有MoE结构，ExpertWeaver利用这一发现实现了高效的稠密到MoE转换，为大规模模型部署提供了新途径。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [22] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl是一种无需训练的简单方法，直接从冻结的WavLM模型中提取音节边界和嵌入，用于纯语音语言模型，性能优于现有音节标记化方法。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型直接从原始音频学习语言面临挑战：自监督语音编码器的离散标记会产生过长的序列，现有音节提取方法需要复杂的多阶段训练流程。

Method: 使用冻结WavLM模型中间层的L2范数特征来检测音节边界，将得到的片段进行平均池化，使用K-means离散化，然后训练语言模型。

Result: ZeroSyl在词汇、句法和叙事基准测试中优于先前的音节标记化方法。扩展实验显示，细粒度单元对词汇任务有益，而发现的音节单元在句法建模方面表现出更好的扩展性。

Conclusion: ZeroSyl提供了一种简单有效的训练免费方法，直接从预训练语音模型中提取音节单元，解决了纯语音语言模型中的序列长度问题，并在多个语言理解任务上表现出色。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [23] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式文档分析工具，通过人机协作的聚类流程帮助数字人文学者探索大规模非结构化文档集


<details>
  <summary>Details</summary>
Motivation: 数字人文学者需要处理大规模非结构化文档集，但缺乏有效的探索和组织工具，难以发现文档中的主题、情感和其他相关类别

Method: 开发了灵活的、面向方面的文档聚类流程，包含人机协作的细化功能。通过文档重写提示和基于指令的嵌入来定义分析视角，并提供细化聚类和微调嵌入模型的工具

Result: 创建了Perspectives工具，展示了典型工作流程，帮助研究人员利用交互式文档地图发现主题、情感等类别，为后续深入分析准备数据

Conclusion: Perspectives通过人机协作的聚类方法有效支持数字人文研究，使学者能够探索大规模文档集并获得洞察，为后续分析奠定基础

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [24] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 提出结合模型蒸馏与任务特定对比损失的新训练方法，用于训练紧凑高性能的文本嵌入模型，在小型模型上表现优于纯对比或蒸馏方法


<details>
  <summary>Details</summary>
Motivation: 现有通用文本嵌入模型通常使用单阶段或多阶段的对比损失训练，但这种方法对于训练小型模型效果有限，需要更有效的训练方案来获得紧凑且高性能的嵌入模型

Method: 提出新颖的训练方案，将模型蒸馏技术与任务特定的对比损失相结合，通过知识蒸馏从大模型学习，同时使用对比损失优化特定任务性能

Result: 开发的jina-embeddings-v5-text-small和jina-embeddings-v5-text-nano模型在基准测试中达到或超过同类尺寸模型的最先进水平，支持长达32k token的多语言长文本，嵌入在截断和二进制量化下保持鲁棒性

Conclusion: 结合蒸馏与对比损失的方法比纯对比或纯蒸馏训练更有效，特别适合训练小型嵌入模型，公开模型权重以促进嵌入模型开发的进一步进展

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [25] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 提出SquRL强化学习框架，通过动态构建工作流提升Text-to-SQL性能，特别在复杂和分布外查询上表现突出


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法依赖静态工作流，难以适应真实场景中的分布外和长尾情况，需要系统能够在推理时自适应构建工作流

Method: 提出SquRL强化学习框架，设计基于规则的奖励函数，引入动态演员掩码促进探索，使用伪奖励提高训练效率

Result: 动态工作流构建始终优于最佳静态工作流方法，在复杂和分布外查询上提升尤其显著

Conclusion: 通过强化学习实现自适应工作流构建是提升Text-to-SQL实际应用效果的有效途径，代码已开源

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [26] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 提出一个症状特异性且临床启发的框架，通过语音进行抑郁严重程度估计，使用症状引导的交叉注意力机制将PHQ-8问卷项目与情感感知语音表征对齐。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁预测方法大多将抑郁视为二元标签或总体严重程度评分，未显式建模症状特异性信息，限制了提供临床筛查相关症状级分析的能力。

Method: 使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知语音表征对齐，识别语音片段对每个症状的重要性；引入可学习的症状特异性参数，自适应控制注意力分布的锐度。

Result: 在标准临床数据集EDAIC上表现优于先前工作；注意力分析显示，包含多个抑郁症状线索的话语被分配更高注意力，突显了方法的可解释性。

Conclusion: 症状引导和情感感知建模对于基于语音的抑郁筛查具有重要意义，提出的框架能提供更精细的症状级分析，有助于临床解释。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [27] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 论文提出STAPO方法，通过识别并屏蔽仅占0.01%的"虚假token"的梯度更新，解决RL微调中的性能崩溃问题，在数学推理基准上平均提升7.13%


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖启发式技术（如熵正则化和重加权）来维持稳定性，但在实践中常出现后期性能崩溃，导致推理质量下降和训练不稳定。研究发现训练不稳定性主要由极少数（约0.01%）的"虚假token"驱动。

Method: 提出Spurious-Token-Aware Policy Optimization (STAPO)方法：1）识别虚假token（在正确响应中出现但对推理结果贡献小却继承完整序列级奖励的token）；2）选择性屏蔽这些token的梯度更新；3）在有效token上重新归一化损失。

Result: 在六个数学推理基准上使用Qwen 1.7B、8B和14B基础模型测试，STAPO始终表现出优越的熵稳定性，相比GRPO、20-Entropy和JustRL方法平均性能提升7.13%。

Conclusion: 通过理论分析发现RL训练不稳定性源于极少数虚假token的异常梯度放大，提出的STAPO方法能有效识别并处理这些token，显著提升训练稳定性和模型推理性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [28] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 论文介绍了NileTTS数据集——首个公开的埃及阿拉伯语TTS数据集，包含38小时转录语音，通过LLM生成内容、音频合成、自动转录和人工验证的合成管道构建，并基于XTTS v2模型微调发布了开源模型。


<details>
  <summary>Details</summary>
Motivation: 尽管神经TTS技术已有进展，但阿拉伯语方言资源分布不均，现代标准阿拉伯语和海湾方言资源丰富，而使用最广泛的埃及阿拉伯语严重缺乏资源，需要填补这一空白。

Method: 采用创新的合成数据生成管道：1) 使用大语言模型生成埃及阿拉伯语内容；2) 音频合成工具转换为自然语音；3) 自动转录和说话人分离；4) 人工质量验证。基于此构建38小时数据集，并在XTTS v2模型上进行微调。

Result: 创建了首个公开的埃及阿拉伯语TTS数据集（NileTTS），包含两个说话人、医疗、销售和日常对话等多个领域内容。微调后的模型在埃及阿拉伯语TTS任务上表现优于在其他阿拉伯方言上训练的基线模型。

Conclusion: 成功填补了埃及阿拉伯语TTS资源空白，提供了可复现的方言TTS合成数据生成管道、公开数据集和开源模型，将推动埃及阿拉伯语语音合成研究发展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [29] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 提出基于诺斯洛普·弗莱四类叙事体裁的新角色功能框架，结合荣格原型理论，通过大语言模型验证角色-体裁对应关系的系统性结构模式。


<details>
  <summary>Details</summary>
Motivation: 现有计算叙事学研究多关注叙事模式而非角色功能，需要补充弗莱理论框架下的角色功能分析，以完善计算叙事学方法。

Method: 结合荣格原型理论推导四个通用角色功能，再细化为16个体裁特定角色；使用6个先进大语言模型在40部叙事作品中验证角色-体裁对应关系，包含正负样本评估。

Result: 大语言模型平均平衡准确率达82.5%，模型间一致性高（Fleiss' κ=0.600），验证了角色-体裁对应关系的系统性；不同体裁（72.7%-89.9%）和角色（52.5%-99.2%）表现存在差异，反映了真实的叙事特性。

Conclusion: 该角色导向方法展示了大语言模型支持的计算叙事学潜力，为未来叙事生成方法和交互式叙事应用开发奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [30] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 提出基于内容的网络安全拒绝框架，通过显式建模攻击风险与防御收益的权衡，解决现有基于意图或攻击分类方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于主题禁令或攻击分类的拒绝方法存在决策不一致、过度限制合法防御者、对混淆或请求分段处理脆弱等问题，需要更有效的拒绝机制。

Method: 引入基于内容的网络安全拒绝策略框架，从五个维度评估请求：攻击行动贡献度、攻击风险、技术复杂度、防御收益、合法用户预期频率，基于请求的技术实质而非陈述意图。

Result: 该内容导向方法解决了当前前沿模型行为的不一致性，允许组织构建可调、风险感知的拒绝策略。

Conclusion: 有效的网络安全拒绝需要显式建模攻击风险与防御收益的权衡，基于内容而非意图的方法能提供更一致、可调的拒绝策略。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [31] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 论文提出了两种新的词汇语义变化检测度量方法AMD和SAMD，相比传统方法APD和PRT，在不同语言、编码器和表示空间中表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测主要依赖少量语义变化度量方法（主要是APD和余弦距离），限制了方法的多样性和性能提升空间。

Method: 引入平均最小距离（AMD）和对称平均最小距离（SAMD），通过跨时间段词汇使用之间的局部对应关系来量化语义变化。

Result: 在多语言、多种编码器和表示空间的实验中，AMD在降维和非专门编码器下表现更稳健，SAMD在专门编码器中表现优异。

Conclusion: 词汇语义变化检测应考虑APD和PRT之外的替代度量方法，AMD为基于上下文嵌入的分析提供了稳健选择。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [32] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: LLMs在少样本和零样本设置下，对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语、叙利亚语）的词形还原和词性标注任务表现出竞争力，可作为缺乏数据时的有效标注辅助工具。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）中持续面临挑战，需要探索大语言模型在这些任务中的能力，特别是在缺乏标注数据的情况下。

Method: 使用包含对齐训练数据和域外测试数据的新基准，评估GPT-4变体和Mistral等大语言模型在少样本和零样本设置下的性能，并与特定任务的RNN基线模型PIE进行比较。

Result: LLMs即使不经过微调，在少样本设置下对大多数语言的词性标注和词形还原任务都能达到竞争性或更优的性能。但对于形态复杂和非拉丁文字的语言仍存在显著挑战。

Conclusion: LLMs是在缺乏数据时启动语言标注任务的可靠选择，可作为有效的标注辅助工具，特别是在处理低资源语言时。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [33] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 提出了FineMuSe数据集，这是一个西班牙语多模态性别歧视检测数据集，包含二元和细粒度标注，并评估了LLM在检测细微性别歧视方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视表现形式多样，现有自动化工具大多仅限于二元分类，难以检测更细微、语境敏感的性别歧视内容。

Method: 1) 创建FineMuSe数据集，包含西班牙语多模态内容和二元/细粒度标注；2) 设计包含性别歧视形式、非性别歧视以及讽刺幽默修辞手法的层次化分类体系；3) 评估多种LLM在二元和细粒度性别歧视检测上的表现。

Result: 多模态LLM在识别细微性别歧视方面表现与人类标注者相当，但在处理通过视觉线索传达的共现性别歧视类型时存在困难。

Conclusion: 需要开发更先进的多模态模型来有效处理视觉线索中的复杂性别歧视表达，FineMuSe数据集为这一领域的研究提供了重要资源。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [34] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 提出了ChartEditBench基准测试，用于评估多模态大语言模型在迭代式图表编辑任务中的表现，发现现有模型在多轮交互中性能显著下降


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在单轮图表生成上表现良好，但在支持真实世界探索性数据分析方面能力不足。实际应用中，用户需要通过多轮交互迭代优化可视化图表，这需要模型能够维护共同基础、跟踪先前编辑并适应不断变化的偏好。

Method: 1) 引入ChartEditBench基准测试，包含5,000个难度可控的修改链和人工验证子集；2) 提出鲁棒的评估框架，整合基于执行的保真度检查、像素级视觉相似度和逻辑代码验证；3) 在最先进的多模态大语言模型上进行实验。

Result: 实验显示，在多轮设置中，由于错误累积和共享上下文崩溃，模型性能显著下降。模型在样式编辑上表现良好，但在数据为中心的转换上经常出现执行失败。

Conclusion: ChartEditBench为基于代码的增量、视觉基础的图表编辑建立了一个具有挑战性的测试平台，揭示了当前多模态大语言模型在支持真实世界探索性数据分析方面的局限性。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [35] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 多模态大语言模型在结构化数据（表格）的问答中表现尚可，但在证据溯源（指出答案来源的具体行列）方面表现很差，接近随机水平，限制了其在需要透明度和可追溯性应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型能够回答结构化数据（如表格）的问题，但用户需要知道答案的来源。当前模型在提供细粒度、可信的证据溯源方面能力不足，这限制了它们在需要透明度和可追溯性的应用场景中的使用。

Method: 评估了多种多模态大语言模型在不同表格格式（Markdown、JSON、图像）和提示策略下的表现，特别关注模型在证据溯源方面的能力，即指出支持答案的具体行和列。

Result: 1. 问答准确性和证据溯源能力存在明显差距：问答准确率中等，但溯源准确率很低，对于JSON输入接近随机水平
2. 模型在引用行方面比引用列更可靠
3. 模型在文本格式（Markdown、JSON）上比图像格式更困难
4. 不同模型家族之间存在显著差异

Conclusion: 当前多模态大语言模型在提供结构化数据的细粒度、可信溯源方面不可靠，这限制了它们在需要透明度和可追溯性的应用中的使用。需要进一步研究改进模型的证据溯源能力。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [36] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 提出*-PLUIE方法，基于ParaPLUIE的困惑度评估框架，通过任务特定提示变体提升与人类判断的对齐度，同时保持低计算成本


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge方法虽然有效，但计算成本高且需要后处理。需要开发更高效、低成本的自动文本质量评估方法

Method: 基于ParaPLUIE的困惑度评估框架，引入任务特定提示变体*-PLUIE，无需生成文本即可估计"Yes/No"答案的置信度

Result: 个性化*-PLUIE与人类评分具有更强的相关性，同时保持较低的计算成本

Conclusion: *-PLUIE方法在保持低计算成本的同时，显著提升了与人类判断的对齐度，为自动文本质量评估提供了高效替代方案

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [37] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本文提出了一种基于Avey架构的编码器改进方案，通过解耦静态动态参数化、稳定性导向归一化和神经压缩等技术，在保持计算效率的同时，在多个基准测试中超越了Transformer编码器。


<details>
  <summary>Details</summary>
Motivation: 当前工业NLP中，紧凑的预训练双向编码器（如BERT）在有限的计算和内存预算下仍是主流。虽然自注意力机制能提供高质量的双向上下文建模，但最近出现的Avey作为无注意力的自回归替代方案，自然适用于编码器范式。本文旨在将Avey重新构建为编码器架构，并提升其性能。

Method: 1. 将Avey重新构建为编码器架构；2. 引入解耦的静态和动态参数化；3. 采用稳定性导向的归一化方法；4. 应用神经压缩技术；5. 在标准token分类和信息检索基准上进行评估。

Result: 改进后的Avey编码器在标准token分类和信息检索基准测试中，一致优于四种广泛使用的基于Transformer的编码器，同时在处理长上下文时具有更好的扩展效率。

Conclusion: 本文提出的Avey编码器改进方案提供了一种有效的注意力替代方案，在保持计算效率的同时，在多个任务上超越了传统Transformer编码器，特别适合工业NLP应用中的资源受限场景。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [38] [Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis](https://arxiv.org/abs/2602.15067)
*Rut Pate,Snehal Rajput,Mehul S. Raval,Rupal A. Kapdi,Mohendra Roy*

Main category: cs.AI

TL;DR: 该研究提出了一种基于注意力门控循环残差U-Net（R2U-Net）的三平面（2.5D）模型，用于改进脑胶质瘤分割，并在分割精度和生存期预测方面取得了良好结果。


<details>
  <summary>Details</summary>
Motivation: 脑胶质瘤是最常见的原发性脑肿瘤，其侵袭性、预后和组织学特征差异很大，复杂的治疗手术耗时且具有挑战性，需要更精确的肿瘤分割来辅助治疗规划。

Method: 提出注意力门控循环残差U-Net（R2U-Net）三平面（2.5D）模型，整合残差、循环和三平面架构，增强特征表示和分割精度，同时保持计算效率。三平面网络从每个平面模型提取64个特征用于生存期预测，通过人工神经网络（ANN）降维至28个特征。

Result: 在BraTS2021验证集上，全肿瘤（WT）分割的Dice相似系数达到0.900，性能与领先模型相当。生存期预测方面，测试集上准确率为45.71%，均方误差为108,318.128，Spearman秩相关系数为0.338。

Conclusion: 该研究提出的三平面R2U-Net模型在脑肿瘤分割方面表现出色，分割结果可用于改善治疗规划，同时提取的特征在生存期预测方面也显示出一定潜力。

Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.

</details>


### [39] [Predicting Invoice Dilution in Supply Chain Finance with Leakage Free Two Stage XGBoost, KAN (Kolmogorov Arnold Networks), and Ensemble Models](https://arxiv.org/abs/2602.15248)
*Pavel Koptev,Vishnu Kumar,Konstantin Malkov,George Shapiro,Yury Vikhanov*

Main category: cs.AI

TL;DR: 论文提出AI/机器学习框架补充确定性算法，预测供应链金融中的发票稀释风险，使用实时动态信用额度替代传统不可撤销付款承诺


<details>
  <summary>Details</summary>
Motivation: 发票稀释（批准金额与实际收款之间的差距）是供应链金融中非信用风险和利润损失的重要来源。传统依赖买方不可撤销付款承诺（IPU）的方法阻碍了供应链金融的采用，特别是对于次级投资级买方。需要更灵活的数据驱动方法。

Method: 提出AI/机器学习框架，补充确定性算法来预测发票稀释。使用实时动态信用额度方法，针对每个买方-供应商对实时预测稀释风险。基于包含九个关键交易字段的广泛生产数据集进行评估。

Result: 论文评估了AI/机器学习框架在预测发票稀释方面的效果，使用实际生产数据集验证了该方法相对于传统IPU方法的优势。

Conclusion: AI/机器学习框架能够有效补充确定性算法，为供应链金融提供更灵活、数据驱动的发票稀释风险管理方案，有助于扩大供应链金融的采用范围，特别是对于次级投资级买方。

Abstract: Invoice or payment dilution is the gap between the approved invoice amount and the actual collection is a significant source of non credit risk and margin loss in supply chain finance. Traditionally, this risk is managed through the buyer's irrevocable payment undertaking (IPU), which commits to full payment without deductions. However, IPUs can hinder supply chain finance adoption, particularly among sub-invested grade buyers. A newer, data-driven methods use real-time dynamic credit limits, projecting dilution for each buyer-supplier pair in real-time. This paper introduces an AI, machine learning framework and evaluates how that can supplement a deterministic algorithm to predict invoice dilution using extensive production dataset across nine key transaction fields.

</details>


### [40] [ResearchGym: Evaluating Language Model Agents on Real-World AI Research](https://arxiv.org/abs/2602.15112)
*Aniketh Garikaparthi,Manasi Patwardhan,Arman Cohan*

Main category: cs.AI

TL;DR: ResearchGym是一个用于评估AI智能体端到端研究能力的基准测试和执行环境，包含5个论文任务环境共39个子任务。GPT-5等前沿智能体在实验中显示出能力-可靠性差距：仅6.7%的评估中超越基线，平均只完成26.5%的子任务，但偶尔能达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估AI智能体进行端到端科学研究能力的基准环境。需要创建能够测试智能体提出假设、运行实验、超越人类基线等完整研究流程的评估框架。

Method: 从ICML、ICLR和ACL的5篇口头报告和焦点论文中提取任务环境，保留数据集、评估框架和基线实现，但隐藏论文提出的方法。创建包含39个子任务的容器化环境，要求智能体提出新假设、运行实验并超越人类基线。

Result: GPT-5智能体仅在15次评估中的1次（6.7%）超越基线11.5%，平均只完成26.5%的子任务。发现了长期失败模式：缺乏耐心、资源管理差、对弱假设过度自信、并行实验协调困难、上下文长度限制等。但在单次运行中成功超越了ICML 2025焦点任务的解决方案。

Conclusion: 前沿AI智能体偶尔能达到最先进的研究性能，但可靠性存在显著差距。ResearchGym为系统评估和分析自主智能体的闭环研究能力提供了基础设施，揭示了当前智能体在长期研究任务中的局限性。

Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.

</details>


### [41] [Protecting Language Models Against Unauthorized Distillation through Trace Rewriting](https://arxiv.org/abs/2602.15143)
*Xinhang Ma,William Yeoh,Ning Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该论文研究如何通过修改教师模型的推理输出来防止未经授权的知识蒸馏，实现反蒸馏和API水印两种目标。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏被广泛用于将大模型能力迁移到小模型，但未经授权的蒸馏利用会不公平地利用前沿模型的开发投入。需要保护模型知识产权，防止未经授权的蒸馏使用。

Method: 提出动态重写教师模型推理输出的方法，包括基于指令的LLM重写和基于梯度的技术，在保持答案正确性和语义连贯性的同时修改推理过程。

Result: 简单的基于指令的重写方法能有效实现反蒸馏效果，同时保持甚至提升教师模型性能；该方法还能实现高可靠的水印检测，几乎没有误报。

Conclusion: 通过重写推理输出可以有效防止未经授权的知识蒸馏，既保护模型知识产权，又不影响正常使用性能，为模型保护提供了实用解决方案。

Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \emph{anti-distillation}, or degrading the training usefulness of query responses, and (2) \emph{API watermarking}, which embeds verifiable signatures in student models. We introduce several approaches for dynamically rewriting a teacher's reasoning outputs while preserving answer correctness and semantic coherence. Two of these leverage the rewriting capabilities of LLMs, while others use gradient-based techniques. Our experiments show that a simple instruction-based rewriting approach achieves a strong anti-distillation effect while maintaining or even improving teacher performance. Furthermore, we show that our rewriting approach also enables highly reliable watermark detection with essentially no false alarms.

</details>


### [42] [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)
*Shreyas Rajesh,Pavan Holur,Mehmet Yigit Turali,Chenda Duan,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: Panini提出了一种基于生成语义工作空间（GSW）的非参数持续学习框架，将文档表示为实体和事件感知的问答对网络，实现高效推理和记忆整合。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法存在计算效率低（重复推理相同文档）和检索不相关内容导致生成不可靠的问题，需要更高效、可靠的持续学习框架来处理新文档和知识。

Method: 提出Panini框架，将文档表示为生成语义工作空间（GSW）——一个实体和事件感知的问答对网络，基模型保持不变，通过外部语义记忆状态持续积累和整合新经验。

Result: 在六个QA基准测试中，Panini平均性能比竞争基线高5%-7%，同时使用2-30倍更少的答案上下文token，支持完全开源流程，并在不可回答查询上减少不可支持的答案。

Conclusion: 在写入时高效准确地结构化经验（如GSW框架）能在读取时同时获得效率和可靠性收益，为语言模型处理新内容提供了更优的持续学习方法。

Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same documents); moreover, chunk retrieval can inject irrelevant context that increases unsupported generation. We propose a human-like non-parametric continual learning framework, where the base model remains fixed, and learning occurs by integrating each new experience into an external semantic memory state that accumulates and consolidates itself continually. We present Panini, which realizes this by representing documents as Generative Semantic Workspaces (GSW) -- an entity- and event-aware network of question-answer (QA) pairs, sufficient for an LLM to reconstruct the experienced situations and mine latent knowledge via reasoning-grounded inference chains on the network. Given a query, Panini only traverses the continually-updated GSW (not the verbatim documents or chunks), and retrieves the most likely inference chains. Across six QA benchmarks, Panini achieves the highest average performance, 5%-7% higher than other competitive baselines, while using 2-30x fewer answer-context tokens, supports fully open-source pipelines, and reduces unsupported answers on curated unanswerable queries. The results show that efficient and accurate structuring of experiences at write time -- as achieved by the GSW framework -- yields both efficiency and reliability gains at read time. Code is available at https://github.com/roychowdhuryresearch/gsw-memory.

</details>


### [43] [da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems](https://arxiv.org/abs/2602.15158)
*Gabriel Rocha*

Main category: cs.AI

TL;DR: 提出一种基于da Costian-Tarskianism的本体异质性新方法，使用扩展后果系统和扩展发展图来关联本体


<details>
  <summary>Details</summary>
Motivation: 解决本体异质性问题，借鉴Carnapian-Goguenism思想，为不同本体系统之间的关联提供理论基础

Method: 基于后果系统理论，引入扩展后果系统（添加本体公理），定义扩展发展图结构，支持通过扩展后果系统的态射以及纤维化和分裂等操作关联本体

Result: 建立了da Costian-Tarskianism框架，提供了形式化工具来处理本体异质性，能够通过图结构和多种操作关联不同本体

Conclusion: 该方法为应用本体学领域提供了新的理论框架，有助于解决本体异质性问题，并指出了未来研究方向

Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and Lücke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carnielli et al. (2008) and Citkin and Muravitsky (2022), and it introduces the idea of an extended consequence system, which is a consequence system extended with ontological axioms. The paper also defines the concept of an extended development graph, which is a graph structure that allows ontologies to be related via morphisms of extended consequence systems, and additionally via other operations such as fibring and splitting. Finally, we discuss the implications of this approach for the field of applied ontology and suggest directions for future research.

</details>


### [44] [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)
*Luise Ge,Yongyan Zhang,Yevgeniy Vorobeychik*

Main category: cs.AI

TL;DR: 该研究比较了20个前沿和开源LLM在风险决策中的表现，发现LLM可分为推理模型和对话模型两类，前者更理性，后者更接近人类但理性程度较低，数学推理训练是区分两者的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM作为决策支持系统或智能体工作流正在快速改变数字生态系统，但对其在不确定性下决策行为的理解仍然有限。研究者希望比较LLM在风险选择中的表现，特别关注两个维度：前景表示方式（显式vs经验基础）和决策理由（解释）。

Method: 研究涉及20个前沿和开源LLM，通过匹配的人类受试者实验提供一个参考点，同时使用期望收益最大化的理性智能体模型作为另一个参考。研究比较LLM在两个维度上的表现：1）前景表示（显式描述vs经验历史）；2）决策理由（解释）。

Result: LLM可分为两类：推理模型（RMs）和对话模型（CMs）。RMs倾向于理性行为，对前景顺序、得失框架和解释不敏感，在显式前景和经验历史前景下行为相似。CMs理性程度显著较低，稍微更接近人类，对前景顺序、框架和解释敏感，表现出较大的描述-历史差距。开源LLM的配对比较表明，区分RMs和CMs的关键因素是数学推理训练。

Conclusion: LLM在风险决策中存在明显分化，数学推理训练是塑造其理性决策能力的关键因素。理解LLM的决策特性对于其在现实世界应用中的可靠部署至关重要。

Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LLMs, is complemented by a matched human subjects experiment, which provides one reference point, while an expected payoff maximizing rational agent model provides another. We find that LLMs cluster into two categories: reasoning models (RMs) and conversational models (CMs). RMs tend towards rational behavior, are insensitive to the order of prospects, gain/loss framing, and explanations, and behave similarly whether prospects are explicit or presented via experience history. CMs are significantly less rational, slightly more human-like, sensitive to prospect ordering, framing, and explanation, and exhibit a large description-history gap. Paired comparisons of open LLMs suggest that a key factor differentiating RMs and CMs is training for mathematical reasoning.

</details>


### [45] [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)
*Yuanyan Song,Kezhi Wang,Xinmian Xu*

Main category: cs.AI

TL;DR: 提出一个安全的无线智能体AI网络，包含一个监督AI智能体和多个其他AI智能体，通过协同推理提供QoS保障，同时保护隐私知识和推理结果的机密性。


<details>
  <summary>Details</summary>
Motivation: 在无线环境中部署AI智能体进行协同推理时，需要同时保障服务质量、保护隐私机密性，并优化能源效率以延长服务时间。

Method: 提出ASC和LAW两种资源分配方案：ASC使用ADMM、SDR和SCA迭代优化三个子问题；LAW在智能体工作流中使用LLM优化器处理子问题。

Result: 实验结果显示，相比基准方案，所提方案能降低网络能耗最高达59.1%，并在基于Qwen的实际智能体AI系统中验证了在各种公共基准测试中具有满意的推理准确率。

Conclusion: 成功设计了一个安全的无线智能体AI网络框架，通过创新的资源分配方案有效平衡了服务质量、隐私保护和能源效率的需求。

Abstract: In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. To extend the service duration of AI agents, an energy minimization problem is formulated that jointly optimizes AI agent selection, base station (BS) beamforming, and AI agent transmission power, subject to latency and reasoning accuracy constraints. To address the formulated problem, we propose two resource allocation schemes, ASC and LAW, which first decompose it into three sub-problems. Specifically, ASC optimizes each sub-problem iteratively using the proposed alternating direction method of multipliers (ADMM)-based algorithm, semi-definite relaxation (SDR), and successive convex approximation (SCA), while LAW tackles each sub-problem using the proposed large language model (LLM) optimizer within an agentic workflow. The experimental results show that the proposed solutions can reduce network energy consumption by up to 59.1% compared to other benchmark schemes. Furthermore, the proposed schemes are validated using a practical agentic AI system based on Qwen, demonstrating satisfactory reasoning accuracy across various public benchmarks.

</details>


### [46] [Enhancing Diversity and Feasibility: Joint Population Synthesis from Multi-source Data Using Generative Models](https://arxiv.org/abs/2602.15270)
*Farbod Abbasi,Zachary Patterson,Bilal Farooq*

Main category: cs.AI

TL;DR: 提出一种基于WGAN-GP的多源数据联合学习方法来生成更真实、更多样、更可行的合成人口数据，相比传统序列方法在多样性和可行性方面有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有合成人口生成方法存在两个主要问题：1) 依赖单一数据集或采用序列化数据融合生成过程，无法捕捉特征间的复杂交互；2) 难以处理采样零值（有效但未观测到的属性组合）和结构零值（因逻辑约束不可行的组合），导致生成数据多样性不足且可行性差。

Method: 提出基于Wasserstein生成对抗网络（WGAN）与梯度惩罚的多源数据集联合学习框架。在生成器损失函数中定义正则化项（逆梯度惩罚），以同时提高生成数据的多样性和可行性。

Result: 联合学习方法在多样性和可行性方面显著优于序列基线方法：召回率提升7%，精确率提升15%。正则化项进一步改善性能，召回率提升10%，精确率提升1%。相似性分布评估中，联合方法得分为88.1，优于序列方法的84.6。

Conclusion: 该多源生成方法能显著提升合成人口数据的多样性和可行性，作为基于智能体模型的关键输入，有望大幅提高交通和城市规划中ABM的准确性和可靠性。

Abstract: Generating realistic synthetic populations is essential for agent-based models (ABM) in transportation and urban planning. Current methods face two major limitations. First, many rely on a single dataset or follow a sequential data fusion and generation process, which means they fail to capture the complex interplay between features. Second, these approaches struggle with sampling zeros (valid but unobserved attribute combinations) and structural zeros (infeasible combinations due to logical constraints), which reduce the diversity and feasibility of the generated data. This study proposes a novel method to simultaneously integrate and synthesize multi-source datasets using a Wasserstein Generative Adversarial Network (WGAN) with gradient penalty. This joint learning method improves both the diversity and feasibility of synthetic data by defining a regularization term (inverse gradient penalty) for the generator loss function. For the evaluation, we implement a unified evaluation metric for similarity, and place special emphasis on measuring diversity and feasibility through recall, precision, and the F1 score. Results show that the proposed joint approach outperforms the sequential baseline, with recall increasing by 7\% and precision by 15\%. Additionally, the regularization term further improves diversity and feasibility, reflected in a 10\% increase in recall and 1\% in precision. We assess similarity distributions using a five-metric score. The joint approach performs better overall, and reaches a score of 88.1 compared to 84.6 for the sequential method. Since synthetic populations serve as a key input for ABM, this multi-source generative approach has the potential to significantly enhance the accuracy and reliability of ABM.

</details>


### [47] [When Remembering and Planning are Worth it: Navigating under Change](https://arxiv.org/abs/2602.15274)
*Omid Madani,J. Brian Burns,Reza Eghbali,Thomas L. Dean*

Main category: cs.AI

TL;DR: 研究不同记忆类型在动态不确定环境中如何辅助空间导航，发现结合多种策略的架构能有效处理探索和路径规划任务，使用非平稳概率学习更新记忆并构建动态地图的智能体在任务难度增加时表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究在动态变化、感知受限的不确定环境中，不同类型的记忆如何帮助智能体进行有效的空间导航。智能体需要在屏障和食物位置每日变化、定位信息不确定且有限的情况下，快速学习并规划路径。

Method: 研究从简单到复杂的多种策略，包括不同记忆使用和学习方式。重点考察能整合多种策略的架构，特别是结合非平稳概率学习技术来持续更新情景记忆，并利用这些记忆构建动态地图（不完美、有噪声、基于经验的地图）进行实时规划。

Result: 当任务难度（如目标距离）增加时，使用非平稳概率学习更新记忆并构建动态地图的智能体比简单（最小记忆）智能体效率显著提高。但前提是定位和环境变化带来的不确定性不能过大。

Conclusion: 需要能整合多种策略的架构来处理不同性质的子任务（特别是探索搜索和路径规划）。在动态不确定环境中，结合非平稳概率学习更新记忆并构建动态地图的方法能有效提高导航效率，但需要控制不确定性水平。

Abstract: We explore how different types and uses of memory can aid spatial navigation in changing uncertain environments. In the simple foraging task we study, every day, our agent has to find its way from its home, through barriers, to food. Moreover, the world is non-stationary: from day to day, the location of the barriers and food may change, and the agent's sensing such as its location information is uncertain and very limited. Any model construction, such as a map, and use, such as planning, needs to be robust against these challenges, and if any learning is to be useful, it needs to be adequately fast. We look at a range of strategies, from simple to sophisticated, with various uses of memory and learning. We find that an architecture that can incorporate multiple strategies is required to handle (sub)tasks of a different nature, in particular for exploration and search, when food location is not known, and for planning a good path to a remembered (likely) food location. An agent that utilizes non-stationary probability learning techniques to keep updating its (episodic) memories and that uses those memories to build maps and plan on the fly (imperfect maps, i.e. noisy and limited to the agent's experience) can be increasingly and substantially more efficient than the simpler (minimal-memory) agents, as the task difficulties such as distance to goal are raised, as long as the uncertainty, from localization and change, is not too large.

</details>


### [48] [EAA: Automating materials characterization with vision language model agents](https://arxiv.org/abs/2602.15294)
*Ming Du,Yanqi Luo,Srutarshi Banerjee,Michael Wojcik,Jelena Popovic,Mathew J. Cherukara*

Main category: cs.AI

TL;DR: EAA是一个基于视觉语言模型的代理系统，用于自动化复杂的实验显微镜工作流程，通过多模态推理和工具增强操作实现自主和交互式测量。


<details>
  <summary>Details</summary>
Motivation: 传统实验显微镜工作流程复杂且需要专业知识，EAA旨在通过自动化提高束线效率、减轻操作负担并降低用户专业知识门槛。

Method: EAA采用灵活的任务管理器架构，集成多模态推理、工具增强操作和可选长期记忆，支持从完全代理驱动自动化到嵌入局部LLM查询的逻辑定义例程，并提供双向兼容MCP的现代工具生态系统。

Result: 在先进光子源的成像束线上成功演示了自动区域板聚焦、自然语言描述特征搜索和交互式数据采集等功能。

Conclusion: 视觉能力代理能够显著提高束线效率、减轻操作负担并降低用户专业知识门槛，为实验自动化提供了有效解决方案。

Abstract: We present Experiment Automation Agents (EAA), a vision-language-model-driven agentic system designed to automate complex experimental microscopy workflows. EAA integrates multimodal reasoning, tool-augmented action, and optional long-term memory to support both autonomous procedures and interactive user-guided measurements. Built on a flexible task-manager architecture, the system enables workflows ranging from fully agent-driven automation to logic-defined routines that embed localized LLM queries. EAA further provides a modern tool ecosystem with two-way compatibility for Model Context Protocol (MCP), allowing instrument-control tools to be consumed or served across applications. We demonstrate EAA at an imaging beamline at the Advanced Photon Source, including automated zone plate focusing, natural language-described feature search, and interactive data acquisition. These results illustrate how vision-capable agents can enhance beamline efficiency, reduce operational burden, and lower the expertise barrier for users.

</details>


### [49] [X-MAP: eXplainable Misclassification Analysis and Profiling for Spam and Phishing Detection](https://arxiv.org/abs/2602.15298)
*Qi Zhang,Dian Chen,Lance M. Kaplan,Audun Jøsang,Dong Hyun Jeong,Feng Chen,Jin-Hee Cho*

Main category: cs.AI

TL;DR: X-MAP是一个可解释的错误分类分析框架，通过主题级语义模式揭示垃圾邮件/钓鱼检测中的模型失败原因，结合SHAP特征归因和矩阵分解构建可解释主题特征，有效检测和修复错误分类。


<details>
  <summary>Details</summary>
Motivation: 垃圾邮件和钓鱼检测中的错误分类危害很大：假阴性让用户暴露于攻击，假阳性降低信任。现有基于不确定性的检测器可能被欺骗且可解释性有限，需要一种能揭示模型失败背后语义模式的可解释框架。

Method: X-MAP结合SHAP特征归因和非负矩阵分解，为正确分类的垃圾邮件/钓鱼邮件和合法邮件构建可解释的主题特征。通过Jensen-Shannon散度测量每条消息与这些特征之间的偏差，识别错误分类。

Result: 在SMS和钓鱼数据集上的实验表明，错误分类消息的偏差至少是正确分类消息的两倍。作为检测器，X-MAP达到0.98 AUROC，在95% TRR下将错误拒绝率降至0.089。作为修复层，能恢复高达97%的错误拒绝的正确预测。

Conclusion: X-MAP通过揭示主题级语义模式，为改进垃圾邮件和钓鱼检测提供了有效且可解释的解决方案，既能检测错误分类，又能修复基础检测器的错误预测。

Abstract: Misclassifications in spam and phishing detection are very harmful, as false negatives expose users to attacks while false positives degrade trust. Existing uncertainty-based detectors can flag potential errors, but possibly be deceived and offer limited interpretability. This paper presents X-MAP, an eXplainable Misclassification Analysis and Profilling framework that reveals topic-level semantic patterns behind model failures. X-MAP combines SHAP-based feature attributions with non-negative matrix factorization to build interpretable topic profiles for reliably classified spam/phishing and legitimate messages, and measures each message's deviation from these profiles using Jensen-Shannon divergence. Experiments on SMS and phishing datasets show that misclassified messages exhibit at least two times larger divergence than correctly classified ones. As a detector, X-MAP achieves up to 0.98 AUROC and lowers the false-rejection rate at 95% TRR to 0.089 on positive predictions. When used as a repair layer on base detectors, it recovers up to 97% of falsely rejected correct predictions with moderate leakage. These results demonstrate X-MAP's effectiveness and interpretability for improving spam and phishing detection.

</details>


### [50] [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)
*Zhixing Zhang,Jesen Zhang,Hao Liu,Qinhan Lv,Jing Yang,Kaitong Cai,Keze Wang*

Main category: cs.AI

TL;DR: 提出Agro-Reflective框架，通过LLM代理在农业数据环境中执行代码、观察结果并迭代优化，解决现有农业基础模型缺乏语言推理能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有农业基础模型虽然能处理大量时空数据，但缺乏语言推理和交互能力；而大语言模型擅长文本处理，却无法直接处理高维异构农业数据。需要桥接这一鸿沟。

Method: 构建AgriWorld Python执行环境，提供地理空间查询、遥感时间序列分析、作物生长模拟等统一工具。设计Agro-Reflective多轮LLM代理，通过执行-观察-优化的循环迭代编写代码和分析。

Result: 在AgroBench基准测试中，涵盖查找、预测、异常检测和反事实分析等多样化农业问答任务，性能优于纯文本和直接工具使用基线，验证了执行驱动反思的可靠性。

Conclusion: 该框架成功将LLM的语言推理能力与农业数据环境结合，通过代码执行和迭代优化实现了可靠的农业科学分析，为农业工作流程提供了实用的智能代理解决方案。

Abstract: Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-dimensional, heterogeneous agricultural datasets. We bridge this gap with an agentic framework for agricultural science. It provides a Python execution environment, AgriWorld, exposing unified tools for geospatial queries over field parcels, remote-sensing time-series analytics, crop growth simulation, and task-specific predictors (e.g., yield, stress, and disease risk). On top of this environment, we design a multi-turn LLM agent, Agro-Reflective, that iteratively writes code, observes execution results, and refines its analysis via an execute-observe-refine loop. We introduce AgroBench, with scalable data generation for diverse agricultural QA spanning lookups, forecasting, anomaly detection, and counterfactual "what-if" analysis. Experiments outperform text-only and direct tool-use baselines, validating execution-driven reflection for reliable agricultural reasoning.

</details>


### [51] [World-Model-Augmented Web Agents with Action Correction](https://arxiv.org/abs/2602.15384)
*Zhouzhou Shen,Xueyu Hu,Xiyun Li,Tianqing Fang,Juncheng Li,Shengyu Zhang*

Main category: cs.AI

TL;DR: WAC是一个基于多模型协作的网页智能体，通过世界模型模拟行动后果和法官模型评估风险，实现风险感知的网页任务自动化。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的网页智能体存在两个主要问题：1) 难以准确预测环境变化，导致行动决策不合理；2) 缺乏对执行风险的全面认知，容易过早执行高风险行动导致任务失败和损失。

Method: WAC采用多模型协作框架：1) 行动模型咨询世界模型获取战略指导，利用环境状态转换的先验知识生成候选行动；2) 世界模型模拟行动后果，法官模型评估风险并触发行动修正反馈，形成两阶段推理链。

Result: 在VisualWebArena上获得1.8%的绝对提升，在Online-Mind2Web上获得1.3%的绝对提升，证明了WAC在网页任务自动化中的有效性。

Conclusion: WAC通过模型协作、后果模拟和反馈驱动的行动优化，有效解决了现有网页智能体在环境预测和风险感知方面的局限性，实现了更稳健的网页任务执行。

Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not possess comprehensive awareness of execution risks, prematurely performing risky actions that cause losses and lead to task failure. To address these challenges, we propose WAC, a web agent that integrates model collaboration, consequence simulation, and feedback-driven action refinement. To overcome the cognitive isolation of individual models, we introduce a multi-agent collaboration process that enables an action model to consult a world model as a web-environment expert for strategic guidance; the action model then grounds these suggestions into executable actions, leveraging prior knowledge of environmental state transition dynamics to enhance candidate action proposal. To achieve risk-aware resilient task execution, we introduce a two-stage deduction chain. A world model, specialized in environmental state transitions, simulates action outcomes, which a judge model then scrutinizes to trigger action corrective feedback when necessary. Experiments show that WAC achieves absolute gains of 1.8% on VisualWebArena and 1.3% on Online-Mind2Web.

</details>


### [52] [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)
*Ankit Sharma,Nachiket Tapas,Jyotiprakash Patra*

Main category: cs.AI

TL;DR: 本文提出了一种自适应弃权系统，通过动态调整安全阈值和层级级联检测架构，在保持高性能的同时平衡LLM的安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM部署面临安全性与实用性的根本权衡：严格过滤机制会阻止良性查询，而宽松控制则可能生成不安全内容。传统的基于静态规则或固定置信度阈值的防护措施通常缺乏上下文敏感性且计算成本高，导致高延迟和用户体验下降。

Method: 引入自适应弃权系统，基于实时上下文信号（如领域和用户历史）动态调整安全阈值。框架集成了由五个并行检测器组成的多维检测架构，通过层级级联机制组合以优化速度和精度。级联设计通过逐步过滤查询减少不必要的计算。

Result: 在混合和特定领域工作负载上的广泛评估显示，假阳性显著减少，特别是在医疗建议和创意写作等敏感领域。系统在严格操作模式下保持高安全精度和接近完美的召回率，相比非级联模型和外部防护系统实现了显著的延迟改进。

Conclusion: 上下文感知的弃权框架有效平衡了安全性和实用性，同时保持性能，为可靠的LLM部署提供了可扩展的解决方案。

Abstract: Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules or fixed confidence thresholds are typically context-insensitive and computationally expensive, resulting in high latency and degraded user experience. To address these limitations, we introduce an adaptive abstention system that dynamically adjusts safety thresholds based on real-time contextual signals such as domain and user history. The proposed framework integrates a multi-dimensional detection architecture composed of five parallel detectors, combined through a hierarchical cascade mechanism to optimize both speed and precision. The cascade design reduces unnecessary computation by progressively filtering queries, achieving substantial latency improvements compared to non-cascaded models and external guardrail systems. Extensive evaluation on mixed and domain-specific workloads demonstrates significant reductions in false positives, particularly in sensitive domains such as medical advice and creative writing. The system maintains high safety precision and near-perfect recall under strict operating modes. Overall, our context-aware abstention framework effectively balances safety and utility while preserving performance, offering a scalable solution for reliable LLM deployment.

</details>


### [53] [Common Belief Revisited](https://arxiv.org/abs/2602.15403)
*Thomas Ågotnes*

Main category: cs.AI

TL;DR: 本文研究了KD45个体信念下共同信念的逻辑特性，发现共同信念不仅失去5属性但保留D和4属性，还具备shift-reflexivity特性，最终完整刻画了共同信念的逻辑公理化系统。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为共同信念是KD4，但本文发现当个体信念为KD45时，共同信念实际上具有不同的逻辑特性。这引发了一个开放性问题：KD4加上shift-reflexivity公理是否足以完全刻画共同信念？本文旨在解决这个开放问题。

Method: 通过逻辑分析和形式化证明，研究共同信念在KD45个体信念下的逻辑属性。首先识别出共同信念具有shift-reflexivity特性（C(Cφ→φ)），然后探索是否还需要额外公理来完整刻画共同信念。

Result: 研究发现：1）仅KD4加上shift-reflexivity公理不足以完全刻画共同信念；2）需要额外的一条公理；3）该公理依赖于智能体数量；4）最终得到了共同信念的完整公理化系统，解决了这个开放问题。

Conclusion: 本文成功解决了共同信念在KD45个体信念下的逻辑刻画问题，证明了需要KD4、shift-reflexivity公理以及一条依赖于智能体数量的额外公理才能完整描述共同信念的逻辑特性。

Abstract: Contrary to common belief, common belief is not KD4.
  If individual belief is KD45, common belief does indeed lose the 5 property and keep the D and 4 properties -- and it has none of the other commonly considered properties of knowledge and belief. But it has another property: $C(Cφ\rightarrow φ)$ -- corresponding to so-called shift-reflexivity (reflexivity one step ahead). This observation begs the question:
  is KD4 extended with this axiom a complete characterisation of common belief in the KD45 case? If not, what \emph{is} the logic of common belief? In this paper we show that the answer to the first question is ``no'': there is one additional axiom, and, furthermore, it relies on the number of agents. We show that the result is a complete characterisation of common belief, settling the open problem.

</details>


### [54] [GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway](https://arxiv.org/abs/2602.15531)
*Javier Irigoyen,Roberto Daza,Aythami Morales,Julian Fierrez,Francisco Jurado,Alvaro Ortigosa,Ruben Tolosana*

Main category: cs.AI

TL;DR: EduEVAL-DB是一个基于教师角色的数据集，用于评估和训练自动教学评估器和AI导师，包含854个解释，涵盖科学、语言和社会科学K-12年级，采用半自动标注教学风险标签。


<details>
  <summary>Details</summary>
Motivation: 需要支持自动教学评估器和AI导师的评估与训练，解决现有教育数据集中缺乏系统化教学风险评估的问题，为教育AI提供可靠的评估基准。

Method: 1) 构建基于ScienceQA基准的EduEVAL-DB数据集，包含139个问题的854个解释；2) 通过提示工程实例化6种LLM模拟的教师角色；3) 提出包含5个维度的教学风险评估框架；4) 采用半自动标注流程；5) 进行初步验证实验，比较Gemini 2.5 Pro和Llama 3.1 8B模型。

Result: 创建了包含854个标注解释的数据集，建立了教学风险评估框架，初步实验表明EduEVAL-DB可用于评估教育导向模型，并支持在消费级硬件上部署的模型进行教学风险检测。

Conclusion: EduEVAL-DB为自动教学评估器和AI导师提供了有价值的评估基准，其教学风险框架和标注数据支持教育AI系统的开发和评估，特别是在资源受限环境中部署的模型。

Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.

</details>


### [55] [Quantifying construct validity in large language model evaluations](https://arxiv.org/abs/2602.15532)
*Ryan Othniel Kearns*

Main category: cs.AI

TL;DR: 该论文提出结构化能力模型，首次从大量LLM基准测试结果中提取可解释且可泛化的能力，解决了现有方法在构建效度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社区将基准测试结果等同于模型能力，但基准测试存在测试集污染和标注错误等问题。需要可靠的方法来评估基准测试是否真正测量了想要评估的能力，即构建效度问题。

Method: 提出结构化能力模型，结合了潜在因子模型和缩放定律的优点：1) 像缩放定律一样，模型规模影响能力；2) 像潜在因子模型一样，能力影响观察结果并考虑测量误差。在OpenLLM排行榜的大样本结果上拟合该模型。

Result: 结构化能力模型在简约拟合指标上优于潜在因子模型，在分布外基准预测上优于缩放定律。该模型能更好地分离模型规模与能力，提供更好的解释和预测能力。

Conclusion: 结构化能力模型通过适当结合缩放定律和潜在因子模型的见解，为LLM评估中的构建效度量化提供了更好的解释和预测能力，是首个能从大量基准结果中提取可解释且可泛化能力的模型。

Abstract: The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance.
  Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks.
  This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.

</details>


### [56] [RUVA: Personalized Transparent On-Device Graph Reasoning](https://arxiv.org/abs/2602.15553)
*Gabriele Conte,Alessio Mattiace,Gianni Carmosino,Potito Aghilar,Giovanni Servedio,Francesco Musicco,Vito Walter Anelli,Tommaso Di Noia,Francesco Maria Donini*

Main category: cs.AI

TL;DR: Ruva提出首个"透明盒"架构，将个人AI从向量匹配转向知识图谱推理，实现可检查、可精确删除的记忆管理


<details>
  <summary>Details</summary>
Motivation: 当前个人AI主要基于"黑盒"检索增强生成，存在缺乏问责性、无法检查错误原因、无法精确删除敏感数据等问题，违反了真正的隐私保护需求

Method: 采用个人知识图谱替代传统向量数据库，实现从向量匹配到图谱推理的范式转变，支持人类在环记忆管理，允许用户检查和精确删除特定事实

Result: Ruva架构确保"被遗忘权"，用户能够完全控制AI知道的内容，实现真正的隐私保护和问责机制

Conclusion: Ruva将个人AI从黑盒转变为透明盒，让用户成为自己生活的编辑者，实现了可检查、可管理的AI记忆系统

Abstract: The Personal AI landscape is currently dominated by "Black Box" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, "deleting" a concept from a vector space is mathematically imprecise, leaving behind probabilistic "ghosts" that violate true privacy. We propose Ruva, the first "Glass Box" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the "Right to be Forgotten." Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.

</details>


### [57] [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)
*Hongxuan Wu,Yukun Zhang,Xueqing Zhou*

Main category: cs.AI

TL;DR: 该研究使用部分信息分解(PID)分析多模态Transformer中视觉和语言信息的流动模式，发现视觉信息在早期层达到峰值后衰减，语言信息在后期层主导预测(约82%)，跨模态协同作用始终低于2%。


<details>
  <summary>Details</summary>
Motivation: 研究多模态Transformer在回答视觉问题时，预测是由视觉证据、语言推理还是真正的跨模态计算驱动，以及这种结构如何在不同层间演化。旨在理解视觉如何转化为语言信息，并为识别模态特定信息丢失的架构瓶颈提供定量指导。

Method: 提出基于部分信息分解(PID)的层间分析框架，将每层Transformer的预测信息分解为冗余、视觉独特、语言独特和协同四个组件。开发PID Flow管道，结合降维、归一化流高斯化和闭式高斯PID估计来处理高维神经表示。在LLaVA-1.5-7B和LLaVA-1.6-7B模型上应用，分析六个GQA推理任务，并进行Image→Question注意力敲除实验验证因果关系。

Result: 发现一致的模态转换模式：视觉独特信息在早期达到峰值后衰减，语言独特信息在后期层激增，占最终预测的约82%，跨模态协同作用始终低于2%。该模式在不同模型变体间高度稳定(层间相关性>0.96)，但任务依赖性很强。注意力敲除实验显示，破坏主要转换路径会导致视觉独特信息滞留、补偿性协同增加和信息成本上升。

Conclusion: 研究为多模态Transformer中视觉如何转化为语言提供了信息论和因果解释，揭示了模态转换的稳定模式，并为识别架构瓶颈提供了定量指导。发现多模态Transformer主要依赖语言推理而非真正的跨模态融合，这对未来模型设计具有重要意义。

Abstract: When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\% of the final prediction, and cross-modal synergy remains below 2\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.

</details>


### [58] [On inferring cumulative constraints](https://arxiv.org/abs/2602.15635)
*Konstantin Sidorov*

Main category: cs.AI

TL;DR: 提出一种预处理方法，通过推断额外的累积约束来捕获多资源交互，提升调度问题的求解性能


<details>
  <summary>Details</summary>
Motivation: 传统约束规划中累积约束的传播通常单独进行，忽略了多资源间的交互作用，导致在某些基准测试上性能严重下降

Method: 将累积约束解释为占用向量的线性不等式，通过(1)发现不能并行运行的任务集合（覆盖集），(2)通过提升技术加强覆盖不等式，(3)将生成的约束注入调度问题实例

Result: 在标准RCPSP和RCPSP/max测试套件上，推断的约束提高了搜索性能并收紧目标界限，发现了25个新的下界和5个新的最优解，其中8个下界直接来自推断的约束

Conclusion: 该方法能有效捕获多资源交互，在有利实例上显著改善性能，在不利实例上性能下降很小，为调度问题提供了实用的预处理技术

Abstract: Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.

</details>


### [59] [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)
*Lucas Elbert Suryana,Farah Bierenga,Sanne van Buuren,Pepijn Kooij,Elsefien Tulleners,Federico Scari,Simeon Calvert,Bart van Arem,Arkady Zgonnikov*

Main category: cs.AI

TL;DR: CARE Drive是一个用于评估自动驾驶中视觉语言模型"理由响应性"的框架，通过控制上下文变化来检验人类理由是否真正影响模型决策，而非事后合理化。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的基础模型评估主要关注结果性能（如安全性、轨迹精度），但无法确定模型决策是否真正反映了人类相关考虑因素。这可能导致虚假信心，尤其在安全关键领域。

Method: 提出CARE Drive框架，采用两阶段评估：1)提示校准确保稳定输出；2)系统上下文扰动测量决策对人类理由（如安全边际、社会压力、效率约束）的敏感性。通过比较基准模型和理由增强模型在受控上下文变化下的决策来评估理由响应性。

Result: 在自行车超车场景中，明确的人类理由显著影响模型决策，改善了与专家推荐行为的一致性。但对不同上下文因素的响应性存在差异，表明模型对不同类型理由的敏感性不均。

Conclusion: CARE Drive提供了无需修改模型参数即可系统评估基础模型理由响应性的实证证据，有助于确保自动驾驶中AI决策的真实合理性而非事后合理化。

Abstract: Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.

</details>


### [60] [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)
*Xiachong Feng,Liang Zhao,Weihong Zhong,Yichong Huang,Yuxuan Gu,Lingpeng Kong,Xiaocheng Feng,Bing Qin*

Main category: cs.AI

TL;DR: PERSONA框架通过激活空间中的向量操作实现LLM人格控制，无需训练即可达到微调级别性能，证明了人格特质在表示空间中具有可提取、近似正交的数学结构。


<details>
  <summary>Details</summary>
Motivation: 现有的人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态性和组合性。需要一种更灵活、高效且能反映人格复杂性的控制方法。

Method: 提出PERSONA框架，包含三个阶段：Persona-Base通过对比激活分析提取正交特质向量；Persona-Algebra通过向量算术（标量乘法调节强度、加法组合、减法抑制）实现精确控制；Persona-Flow在推理时动态组合向量实现上下文感知适应。

Result: 在PersonalityBench上获得9.60平均分，接近监督微调上限9.61；在Persona-Evolve动态人格适应基准上，在不同模型家族中获得高达91%的胜率。

Conclusion: LLM的人格方面具有数学可处理性，为可解释和高效的行为控制开辟了新方向，证明了通过激活空间向量操作实现训练自由人格控制的可行性。

Abstract: Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.

</details>


### [61] [Recursive Concept Evolution for Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.15725)
*Sarim Chaudhry*

Main category: cs.AI

TL;DR: RCE框架让预训练语言模型在推理时动态修改内部表示几何，通过生成低秩概念子空间来构建新抽象，显著提升组合推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扩展token级搜索来改进推理，但保持模型的潜在表示空间固定。当所需抽象未编码在该空间中时，性能会崩溃。需要让模型能在推理时修改内部表示几何。

Method: 提出递归概念演化(RCE)框架：检测到表示不足时生成动态低秩概念子空间；通过最小描述长度准则选择；协同时合并；通过约束优化进行整合以保持稳定性。

Result: 在Mistral-7B上集成RCE，在组合推理基准测试中：ARC-AGI-2提升12-18点，GPQA和BBH提升8-14点，MATH和HLE上深度诱导误差持续减少。

Conclusion: RCE使预训练语言模型能够在推理时构建新抽象而非仅重组现有概念，显著提升组合推理性能，为改进模型推理能力提供了新方向。

Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.

</details>


### [62] [GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems](https://arxiv.org/abs/2602.15776)
*Yiqin Yang,Xu Yang,Yuhua Jiang,Ni Mu,Hao Hu,Runpeng Xie,Ziyou Zhang,Siyuan Li,Yuan-Hua Ni,Qianchuan Zhao,Bo Xu*

Main category: cs.AI

TL;DR: GlobeDiff：一种基于多模态扩散过程的全局状态推断算法，用于解决多智能体系统中的部分可观测性问题


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的部分可观测性是有效协调和决策的关键障碍。现有方法如信念状态估计和智能体间通信存在局限性：信念方法过于依赖过去经验而未能充分利用全局信息，通信方法缺乏有效利用辅助信息的鲁棒模型。

Method: 提出Global State Diffusion Algorithm (GlobeDiff)，将状态推断过程建模为多模态扩散过程。该方法基于局部观测推断全局状态，通过扩散过程克服状态估计中的模糊性，同时实现高保真度的全局状态推断。

Result: 理论证明了GlobeDiff在单模态和多模态分布下的估计误差有界。大量实验结果表明，GlobeDiff实现了优越的性能，能够准确推断全局状态。

Conclusion: GlobeDiff通过多模态扩散过程有效解决了多智能体系统中的部分可观测性问题，在理论和实验上都表现出色，为全局状态推断提供了新的解决方案。

Abstract: In the realm of multi-agent systems, the challenge of \emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.

</details>


### [63] [This human study did not involve human subjects: Validating LLM simulations as behavioral evidence](https://arxiv.org/abs/2602.15785)
*Jessica Hullman,David Broska,Huaman Sun,Aaron Shaw*

Main category: cs.AI

TL;DR: 论文探讨了在社会科学实验中使用LLM作为合成参与者的有效性，对比了启发式方法和统计校准两种策略，并讨论了它们在不同研究阶段（探索性与验证性）的适用性。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的研究使用大型语言模型作为合成参与者来生成低成本、即时的社会科学实验响应，但缺乏关于何时这种模拟能够有效推断人类行为的指导。

Method: 对比两种策略：1) 启发式方法（通过提示工程、模型微调等减少LLM不准确性）；2) 统计校准（结合辅助人类数据和统计调整来校正模拟与观测响应之间的差异）。

Result: 启发式方法适用于探索性研究但缺乏正式统计保证；统计校准在明确假设下能保持有效性，并以更低成本提供更精确的因果效应估计。

Conclusion: 两种方法的潜力都取决于LLM对相关人群的近似程度，研究人员不应仅局限于用LLM替代人类参与者，而应考虑更广泛的研究机会。

Abstract: A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.

</details>


### [64] [Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings](https://arxiv.org/abs/2602.15791)
*Suhyung Jang,Ghang Lee,Jaekun Lee,Hyunjun Lee*

Main category: cs.AI

TL;DR: 本研究提出使用LLM嵌入作为编码方法，替代传统的one-hot编码，以更好地捕捉建筑语义中对象类型与子类型之间的细微关系，在BIM对象分类任务中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在AECO行业中，准确表示建筑语义（包括通用对象类型和特定子类型）对AI模型训练至关重要。传统编码方法（如one-hot）无法传达密切相关的子类型之间的细微关系，限制了AI的语义理解能力。

Method: 提出一种新颖的训练方法，使用大型语言模型（LLM）嵌入（如OpenAI GPT和Meta LLaMA）作为编码来保留建筑语义的细微区别。评估方法包括训练GraphSAGE模型对5个高层住宅BIM中的42个建筑对象子类型进行分类，测试了不同嵌入维度，包括原始高维LLM嵌入（1,536、3,072或4,096维）和通过Matryoshka表示模型生成的1,024维压缩嵌入。

Result: LLM编码优于传统的one-hot基线，其中llama-3（压缩）嵌入实现了0.8766的加权平均F1分数，而one-hot编码为0.8475。实验结果表明LLM编码在捕捉建筑语义细微差别方面具有优势。

Conclusion: LLM编码方法在增强AI解释复杂领域特定建筑语义能力方面具有前景。随着LLM和降维技术的不断发展，这种方法在AECO行业的语义细化任务中具有广泛应用的潜力。

Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.

</details>


### [65] [Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816)
*Xiaoran Liu,Istvan David*

Main category: cs.AI

TL;DR: 本章介绍基于仿真的合成数据生成概念、优势、挑战，以及数字孪生AI仿真解决方案的参考框架


<details>
  <summary>Details</summary>
Motivation: 数据量不足和质量问题是现代亚符号AI采用的主要障碍，因此对合成数据生成技术有高需求

Method: 提出基于仿真的合成数据生成方法，并建立描述、设计和分析数字孪生AI仿真解决方案的参考框架

Result: 提供了系统化的仿真方法来生成多样化的合成数据，支持AI训练需求

Conclusion: 仿真为AI训练提供了有效的合成数据生成途径，数字孪生框架为相关解决方案的设计和分析提供了参考

Abstract: As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [66] [Optimal investment under capital gains taxes](https://arxiv.org/abs/2602.15177)
*Alexander Dimitrov,Christoph Kühn*

Main category: q-fin.MF

TL;DR: 论文将无摩擦市场中存在最优投资组合的经典结果推广到资本利得税模型，分析了损失只能抵减未来收益的规则，证明了在无限概率空间下，无套利条件不足以保证终端财富集合的闭性，需要更强的"无有界风险非可替代投资"条件。


<details>
  <summary>Details</summary>
Motivation: 研究资本利得税市场中的最优投资组合存在性问题，特别是考虑损失不能产生负税（只能抵减未来收益）这一现实但数学上具有挑战性的规则。传统无摩擦市场的结果无法直接应用于有税市场。

Method: 将离散时间无摩擦市场模型推广到资本利得税模型，分析比例交易成本市场中存在的特殊现象：特定数量的股票投资完全无风险但可能优于银行存款。使用"无有界风险非可替代投资"条件来保证终端财富集合的闭性。

Result: 证明了在无限概率空间下，无套利条件不足以保证终端财富集合在概率意义下的闭性，需要更强的"无有界风险非可替代投资"条件。作为副产品，证明了在卖空约束的无摩擦离散时间模型中，即使存在冗余股票，无套利也意味着终端财富集合的闭性。

Conclusion: 资本利得税市场需要比传统无套利更强的条件来保证最优投资组合的存在性，这反映了税收规则对市场结构的深刻影响，为有税环境下的投资组合优化提供了理论基础。

Abstract: We generalize classical results on the existence of optimal portfolios in discrete time frictionless market models to models with capital gains taxes. We consider the realistic but mathematically challenging rule that losses do not trigger negative taxes but can only be offset against potential gains in the future. Central to the analysis is a well-known phenomenon from arbitrage-free markets with proportional transaction costs that does not exist in arbitrage-free frictionless markets: an investment in specific quantities of stocks that is completely riskless but may provide an advantage over holding money in the bank account. As a result of this phenomenon, on an infinite probability space, no-arbitrage does not imply that the set of attainable terminal wealth is closed in probability. We show closedness under the slightly stronger {\em no unbounded non-substitutable investment with bounded risk} condition.
  As a by-product, we provide a proof that in discrete time frictionless models with short-selling constraints, no-arbitrage implies that the set of attainable terminal wealth is closed in probability -- even if there are redundant stocks.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [67] [A Projection Approach to Nonparametric Significance and Conditional Independence Testing](https://arxiv.org/abs/2602.15289)
*Xiaojun Song,Jichao Yuan*

Main category: econ.EM

TL;DR: 提出基于定制非参数型投影加权函数的新型非参数显著性检验，具有理论优势，能检测参数速率的局部备择，通过非参数正交投影构建计算便利的乘数自助法获取临界值。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要协变量密度具有更强的紧支撑假设（来自随机分母），本文旨在克服这一限制，开发更灵活的非参数显著性检验方法。

Method: 使用定制的非参数型投影加权函数构建检验统计量，通过非参数正交投影构建乘数自助法计算临界值，并扩展该方法测试条件独立性假设。

Result: 推导了检验的渐近性质，证明能检测参数速率的局部备择，模拟实验显示在有限样本中测试显著性和条件独立性方面具有优势。

Conclusion: 提出的非参数检验方法理论性质优良，计算便利，克服了现有方法的限制，在显著性和条件独立性检验中表现优越。

Abstract: This paper develops a novel nonparametric significance test based on a tailored nonparametric-type projected weighting function that exhibits appealing theoretical and numerical properties. We derive the asymptotic properties of the proposed test and show that it can detect local alternatives at the parametric rate. Using the nonparametric orthogonal projection, we construct a computationally convenient multiplier bootstrap to obtain critical values from the case-dependent asymptotic null distribution. Compared with the existing literature, our approach overcomes the need for a stronger compact support assumption on the density of covariates arising from random denominators. We also extend the tailor-made projection procedure to test the conditional independence assumption. The simulation experiments further illustrate the advantages of our proposed method in testing significance and conditional independence in finite samples.

</details>


### [68] [Income Inequality and Economic Growth: A Meta-Analytic Approach](https://arxiv.org/abs/2602.15690)
*Lisa Cpretti,Lorenzo Tonni*

Main category: econ.EM

TL;DR: 收入不平等对经济增长的影响存在显著异质性，平均效应为负但经济意义较小，研究设计和现实特征共同影响估计结果。


<details>
  <summary>Details</summary>
Motivation: 现有关于收入不平等与经济增长关系的实证文献结果高度异质且经常相互矛盾，需要系统分析这种异质性的来源。

Method: 采用元分析方法，系统整合和分析1994-2025年间相关研究证据，通过元回归解释观察到的异质性。

Result: 发现收入不平等对后续经济增长有经济意义较小但统计显著的负向平均效应；存在显著的异质性和基于统计显著性的选择性发表，但无系统性方向偏误；税后转移支付后的不平等与更负的增长效应相关；不平等的不利影响在高收入经济体相对于发展中国家更弱甚至逆转；横截面研究倾向于报告更负的估计，而固定效应、工具变量和GMM估计在面板设置中与更正的估计相关。

Conclusion: 现实世界特征和研究设计选择共同塑造了报告效应大小，解释了文献中观察到的异质性，为理解收入不平等与经济增长关系的复杂性提供了系统证据。

Abstract: The empirical literature on the relationship between income inequality and economic growth has produced highly heterogeneous and often conflicting results. This paper investigates the sources of this heterogeneity using a meta-analytic approach that systematically combines and analyzes evidence from relevant studies published between 1994 and 2025. We find an economically small but statistically significant negative average effect of income inequality on subsequent economic growth, together with strong evidence of substantial heterogeneity and selective publication based on statistical significance, but no evidence of systematic directional bias. To explain the observed heterogeneity, we estimate a meta-regression. The results indicate that both real-world characteristics and research design choices shape reported effect sizes. In particular, inequality measured net of taxes and transfers is associated with more negative growth effects, and the adverse impact of inequality is weaker - or even reversed - in high-income economies relative to developing countries. Methodological choices also matter: cross-sectional studies tend to report more negative estimates, while fixed-effects, instrumental-variable, and GMM estimators are associated with more positive estimates in panel settings.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [Near-Optimal Sample Complexity for Online Constrained MDPs](https://arxiv.org/abs/2602.15076)
*Chang Liu,Yunfan Li,Lin F. Yang*

Main category: cs.LG

TL;DR: 提出一种基于模型的原对偶算法，用于在线强化学习中的安全约束优化，在允许轻微违反约束和严格不允许违反两种设置下，分别达到与无约束MDP相同的样本复杂度下界。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶、机器人、医疗等现实应用中面临安全挑战。现有方法要么产生显著安全违规，要么需要高样本复杂度才能获得近似最优策略。

Method: 提出基于模型的原对偶算法，结合在线强化学习和约束优化技术，平衡遗憾和约束违反。针对两种设置：允许轻微违反的松弛可行性和严格不允许违反的严格可行性。

Result: 对于松弛可行性，算法以任意高概率返回ε-最优策略且违反边界为ε，需要Õ(SAH³/ε²)学习回合，匹配无约束MDP下界。对于严格可行性，算法以任意高概率返回ε-最优策略且零违反，需要Õ(SAH⁵/ε²ζ²)学习回合，其中ζ是Slater常数，匹配生成模型下界。

Conclusion: 在线学习约束MDP与使用生成模型学习同样容易，当允许轻微违反时，学习约束MDP不比学习无约束MDP更困难。

Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with $\varepsilon$-bounded violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^3}{\varepsilon^2}\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\tilde{O}\left(\frac{SAH^5}{\varepsilon^2ζ^2}\right)$ learning episodes, where $ζ$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model.
  Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.

</details>


### [70] [Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction](https://arxiv.org/abs/2602.15089)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出一种结合深度学习时间序列嵌入与统计特征的混合方法，用于HVAC设备异常预测，在64台设备上实现高精度异常检测


<details>
  <summary>Details</summary>
Motivation: 纯深度学习方法在真实世界设备维护数据上往往精度不足，需要结合领域知识提升预测性能

Method: 使用Granite TinyTimeMixer提取64维时间序列嵌入（LoRA微调），结合28维统计特征（趋势、波动性、回撤等），通过LightGBM分类器进行学习

Result: 在64台设备、51,564个样本上，30/60/90天预测精度达91-95%，ROC-AUC为0.995，误报率≤1.1%，检测率88-94%

Conclusion: 通过结合深度学习的表征学习能力和统计特征工程的互补优势，可以实现实用的异常检测系统

Abstract: In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a hybrid approach that integrates 64-dimensional time series embeddings from Granite TinyTimeMixer with 28-dimensional statistical features based on domain knowledge for HVAC equipment anomaly prediction tasks. Specifically, we combine time series embeddings extracted from a Granite TinyTimeMixer encoder fine-tuned with LoRA (Low-Rank Adaptation) and 28 types of statistical features including trend, volatility, and drawdown indicators, which are then learned using a LightGBM gradient boosting classifier. In experiments using 64 equipment units and 51,564 samples, we achieved Precision of 91--95\% and ROC-AUC of 0.995 for anomaly prediction at 30-day, 60-day, and 90-day horizons. Furthermore, we achieved production-ready performance with a false positive rate of 1.1\% or less and a detection rate of 88--94\%, demonstrating the effectiveness of the system for predictive maintenance applications. This work demonstrates that practical anomaly detection systems can be realized by leveraging the complementary strengths between deep learning's representation learning capabilities and statistical feature engineering.

</details>


### [71] [PolyNODE: Variable-dimension Neural ODEs on M-polyfolds](https://arxiv.org/abs/2602.15128)
*Per Åhag,Alexander Friedrich,Fredrik Ohlsson,Viktor Vigren Näslund*

Main category: cs.LG

TL;DR: 提出了PolyNODEs，这是首个可变维度的流基几何深度学习模型，通过将神经常微分方程扩展到M-多流形来解决传统NODE模型只能处理固定维度动态的限制。


<details>
  <summary>Details</summary>
Motivation: 现有神经常微分方程（NODE）模型基于流形上的向量场和动态系统，但所有现有NODE模型都受限于流形维度的固有特性，只能处理固定维度的动态。这限制了模型在处理可变维度数据时的应用能力。

Method: 将NODEs扩展到M-多流形（能同时容纳变化维度和可微概念的空间），引入PolyNODEs作为首个可变维度的流基模型。构建具有维度瓶颈的显式M-多流形，并基于参数化向量场构建PolyNODE自编码器，这些向量场可以穿越维度瓶颈。

Result: 实验证明PolyNODE模型可以训练解决这些空间中的重构任务，并且可以提取输入的潜在表示用于解决下游分类任务。代码已公开可用。

Conclusion: 成功将NODEs扩展到可变维度设置，提出了首个可变维度的流基几何深度学习模型PolyNODEs，为处理可变维度数据提供了新的理论框架和实用工具。

Abstract: Neural ordinary differential equations (NODEs) are geometric deep learning models based on dynamical systems and flows generated by vector fields on manifolds. Despite numerous successful applications, particularly within the flow matching paradigm, all existing NODE models are fundamentally constrained to fixed-dimensional dynamics by the intrinsic nature of the manifold's dimension. In this paper, we extend NODEs to M-polyfolds (spaces that can simultaneously accommodate varying dimensions and a notion of differentiability) and introduce PolyNODEs, the first variable-dimensional flow-based model in geometric deep learning. As an example application, we construct explicit M-polyfolds featuring dimensional bottlenecks and PolyNODE autoencoders based on parametrised vector fields that traverse these bottlenecks. We demonstrate experimentally that our PolyNODE models can be trained to solve reconstruction tasks in these spaces, and that latent representations of the input can be extracted and used to solve downstream classification tasks. The code used in our experiments is publicly available at https://github.com/turbotage/PolyNODE .

</details>


### [72] [Refine Now, Query Fast: A Decoupled Refinement Paradigm for Implicit Neural Fields](https://arxiv.org/abs/2602.15155)
*Tianyu Xiong,Skylar Wurster,Han-Wei Shen*

Main category: cs.LG

TL;DR: DRR-Net通过解耦表示精炼架构解决INR的速度-精度困境，使用深度精炼网络和离线处理将丰富表示编码到紧凑嵌入结构中，实现高保真度同时推理速度提升27倍。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示作为3D科学模拟的代理面临关键的速度-精度困境：深度MLP推理成本高，而高效的基于嵌入的模型表达能力不足。

Method: 提出解耦表示精炼架构范式，使用深度精炼网络和非参数变换在离线过程中将丰富表示编码到紧凑嵌入结构中，实现慢速高容量网络与快速推理路径的解耦。引入DRR-Net验证该范式，并提出变分对数据增强策略提升高维代理建模性能。

Result: 在多个集成模拟数据集上实验表明，该方法达到最先进的保真度，推理速度比高保真基线快27倍，同时与最快模型保持竞争力。

Conclusion: DRR范式为构建强大实用的神经场代理和INR应用提供了有效策略，在速度和精度之间实现最小妥协。

Abstract: Implicit Neural Representations (INRs) have emerged as promising surrogates for large 3D scientific simulations due to their ability to continuously model spatial and conditional fields, yet they face a critical fidelity-speed dilemma: deep MLPs suffer from high inference cost, while efficient embedding-based models lack sufficient expressiveness. To resolve this, we propose the Decoupled Representation Refinement (DRR) architectural paradigm. DRR leverages a deep refiner network, alongside non-parametric transformations, in a one-time offline process to encode rich representations into a compact and efficient embedding structure. This approach decouples slow neural networks with high representational capacity from the fast inference path. We introduce DRR-Net, a simple network that validates this paradigm, and a novel data augmentation strategy, Variational Pairs (VP) for improving INRs under complex tasks like high-dimensional surrogate modeling. Experiments on several ensemble simulation datasets demonstrate that our approach achieves state-of-the-art fidelity, while being up to 27$\times$ faster at inference than high-fidelity baselines and remaining competitive with the fastest models. The DRR paradigm offers an effective strategy for building powerful and practical neural field surrogates and \rev{INRs in broader applications}, with a minimal compromise between speed and quality.

</details>


### [73] [Learning Representations from Incomplete EHR Data with Dual-Masked Autoencoding](https://arxiv.org/abs/2602.15159)
*Xiao Xiang,David Restrepo,Hyewon Jeong,Yugang Jia,Leo Anthony Celi*

Main category: cs.LG

TL;DR: AID-MAE：一种双掩码自编码器，直接从不完整的时间序列中学习，通过内在缺失掩码和增强掩码处理电子健康记录数据，在临床任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录时间序列数据存在不规则采样、异质性缺失和观测稀疏性等问题。现有的自监督方法要么先插补再学习，要么通过专用输入信号表示缺失，要么仅优化插补任务，限制了学习支持临床下游任务表示的能力。

Method: 提出增强-内在双掩码自编码器（AID-MAE），直接从不完整时间序列中学习：1）使用内在缺失掩码表示自然缺失值；2）使用增强掩码隐藏部分观测值进行重建训练；3）仅处理未掩码的标记子集。

Result: 在两个数据集上的多个临床任务中，AID-MAE持续优于XGBoost和DuETT等强基线方法。此外，学习到的嵌入在表示空间中自然地对患者队列进行分层。

Conclusion: AID-MAE通过双掩码策略有效处理电子健康记录时间序列的不完整性和稀疏性，能够学习到支持临床下游任务的高质量表示，在患者分层和预测任务中表现出色。

Abstract: Learning from electronic health records (EHRs) time series is challenging due to irregular sam- pling, heterogeneous missingness, and the resulting sparsity of observations. Prior self-supervised meth- ods either impute before learning, represent missingness through a dedicated input signal, or optimize solely for imputation, reducing their capacity to efficiently learn representations that support clinical downstream tasks. We propose the Augmented-Intrinsic Dual-Masked Autoencoder (AID-MAE), which learns directly from incomplete time series by applying an intrinsic missing mask to represent naturally missing values and an augmented mask that hides a subset of observed values for reconstruction during training. AID-MAE processes only the unmasked subset of tokens and consistently outperforms strong baselines, including XGBoost and DuETT, across multiple clinical tasks on two datasets. In addition, the learned embeddings naturally stratify patient cohorts in the representation space.

</details>


### [74] [Seeing to Generalize: How Visual Data Corrects Binding Shortcuts](https://arxiv.org/abs/2602.15183)
*Nicolas Buzeta,Felipe del Rio,Cristian Hinostroza,Denis Parra,Hans Lobel,Rodrigo Toro Icarte*

Main category: cs.LG

TL;DR: VLMs在纯文本任务上表现优于其底层LLMs，特别是在长上下文信息检索中。研究发现视觉训练改变了模型的内部绑定策略，使其从位置捷径转向更稳健的符号绑定机制，从而提升了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解释一个令人惊讶的现象：视觉语言模型（VLMs）在纯文本任务上表现优于其底层大型语言模型（LLMs），特别是在长上下文信息检索中。研究者希望探究这种跨模态训练如何提升单模态任务的性能。

Method: 研究者构建了受控的合成检索任务，比较了仅文本训练的transformer和后续在图像标记化版本上训练的模型。使用机制可解释性方法分析内部绑定策略的变化，并研究了不同训练机制、视觉编码器和初始化条件下的绑定策略变化。

Result: 仅文本训练的模型在分布内准确率完美但分布外泛化失败，而后续图像训练使文本任务的分布外性能提升近一倍。视觉训练通过空间平移不变性破坏了位置捷径，迫使模型采用更稳健的符号绑定机制，这种机制在重新引入纯文本示例后仍然保持。

Conclusion: 跨模态训练可以增强推理和泛化能力，即使对于单模态任务也是如此。视觉训练改变了模型的内部表示策略，使其从依赖位置线索转向更抽象的符号绑定，这种机制在预训练的LLM到VLM转换过程中也会发生类似变化。

Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in long-context information retrieval. To investigate this effect, we build a controlled synthetic retrieval task and find that a transformer trained only on text achieves perfect in-distribution accuracy but fails to generalize out of distribution, while subsequent training on an image-tokenized version of the same task nearly doubles text-only OOD performance. Mechanistic interpretability reveals that visual training changes the model's internal binding strategy: text-only training encourages positional shortcuts, whereas image-based training disrupts them through spatial translation invariance, forcing the model to adopt a more robust symbolic binding mechanism that persists even after text-only examples are reintroduced. We further characterize how binding strategies vary across training regimes, visual encoders, and initializations, and show that analogous shifts occur during pretrained LLM-to-VLM transitions. Our findings suggest that cross-modal training can enhance reasoning and generalization even for tasks grounded in a single modality.

</details>


### [75] [Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge](https://arxiv.org/abs/2602.15184)
*Siying Ma,Mehrdad M. Zadeh,Mauricio Soroco,Wuyang Chen,Jiguo Cao,Vijay Ganesh*

Main category: cs.LG

TL;DR: 提出一种多物理训练框架，通过联合学习原始PDE及其简化基本形式，提升神经算子的数据效率、预测精度和分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法主要关注从目标PDE学习模拟，但忽略了支撑这些方程的更基本物理原理。受数值求解器能与不同PDE设置兼容的启发，希望将基础物理知识显式融入训练过程。

Method: 提出多物理训练框架，同时从原始PDE及其简化基本形式中联合学习。该方法与架构无关，通过结合基础物理知识来增强神经算子的泛化能力。

Result: 在广泛的1D/2D/3D PDE问题上，该方法在归一化均方根误差(nRMSE)上表现出一致的改进，显著提升了数据效率、预测精度和分布外泛化能力，特别是在物理参数偏移和合成到真实转移场景中。

Conclusion: 显式融入基础物理知识能显著增强神经算子的泛化能力，提出的多物理训练框架为科学机器学习提供了一种有效的方法，将物理原理与数据驱动学习相结合。

Abstract: Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from the target PDE, they often overlook more fundamental physical principles underlying these equations. Inspired by how numerical solvers are compatible with simulations of different settings of PDEs, we propose a multiphysics training framework that jointly learns from both the original PDEs and their simplified basic forms. Our framework enhances data efficiency, reduces predictive errors, and improves out-of-distribution (OOD) generalization, particularly in scenarios involving shifts of physical parameters and synthetic-to-real transfer. Our method is architecture-agnostic and demonstrates consistent improvements in normalized root mean square error (nRMSE) across a wide range of 1D/2D/3D PDE problems. Through extensive experiments, we show that explicit incorporation of fundamental physics knowledge significantly strengthens the generalization ability of neural operators. We will release models and codes at https://sites.google.com/view/sciml-fundemental-pde.

</details>


### [76] [COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression](https://arxiv.org/abs/2602.15200)
*Denis Makhov,Dmitriy Shopkhoev,Magauiya Zhussip,Ammar Ali,Baher Mohammad,Stamatios Lefkimmiatis*

Main category: cs.LG

TL;DR: COMPOT是一种无需训练的Transformer压缩框架，使用校准数据集进行稀疏权重分解，通过正交字典和Procrustes更新实现高效压缩，并采用动态分配策略优化层间压缩率。


<details>
  <summary>Details</summary>
Motivation: 传统的截断SVD压缩方法使用单一共享子空间，在中等压缩率下就会显著降低精度。稀疏字典学习虽然提供更灵活的表示，但现有方法通常需要迭代更新字典和系数，计算效率低。

Method: COMPOT使用小规模校准数据集估计稀疏权重分解，采用正交字典实现闭式Procrustes更新和解析单步稀疏编码，无需迭代优化。同时引入一次性动态分配策略，根据层敏感度自适应调整压缩率。

Result: 在多种架构和任务上的实验表明，COMPOT在质量-压缩权衡方面始终优于强低秩和稀疏基线方法，并且完全兼容训练后量化以实现极端压缩。

Conclusion: COMPOT提供了一种高效、无需训练的Transformer压缩框架，通过正交字典和动态压缩分配实现了优越的压缩性能，为模型部署提供了实用解决方案。

Abstract: Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but existing approaches often suffer from iterative dictionary and coefficient updates. We propose COMPOT (Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers), a training-free compression framework that uses a small calibration dataset to estimate a sparse weight factorization. COMPOT employs orthogonal dictionaries that enable closed-form Procrustes updates for the dictionary and analytical single-step sparse coding for the coefficients, eliminating iterative optimization. To handle heterogeneous layer sensitivity under a global compression budget, COMPOT further introduces a one-shot dynamic allocation strategy that adaptively redistributes layer-wise compression rates. Extensive experiments across diverse architectures and tasks show that COMPOT consistently delivers a superior quality-compression trade-off over strong low-rank and sparse baselines, while remaining fully compatible with post-training quantization for extreme compression. Code is available $\href{https://github.com/mts-ai/COMPOT}{here}$.

</details>


### [77] [MAVRL: Learning Reward Functions from Multiple Feedback Types with Amortized Variational Inference](https://arxiv.org/abs/2602.15206)
*Raphaël Baur,Yannick Metz,Maria Gkoulta,Mennatallah El-Assady,Giorgia Ramponi,Thomas Kleine Buening*

Main category: cs.LG

TL;DR: 提出贝叶斯推理框架，从多种异构反馈类型（演示、比较、评分、停止信号）联合学习奖励函数，避免人工损失平衡，提高策略鲁棒性


<details>
  <summary>Details</summary>
Motivation: 当前奖励学习通常依赖单一反馈类型或手动加权组合多种反馈，缺乏从异构反馈类型（演示、比较、评分、停止信号）联合学习的系统方法

Method: 将多反馈类型奖励学习建模为共享潜在奖励函数的贝叶斯推理，每种反馈通过显式似然贡献信息；提出可扩展的摊销变分推理方法，学习共享奖励编码器和反馈特定似然解码器，通过优化单一证据下界训练

Result: 在离散和连续控制基准测试中，联合推断的奖励后验优于单类型基线，利用跨反馈类型的互补信息，产生对环境扰动更鲁棒的策略；推断的奖励不确定性提供可解释信号分析模型置信度和跨反馈一致性

Conclusion: 贝叶斯推理框架有效整合异构反馈信号，避免人工损失平衡，提高奖励学习效果和策略鲁棒性，同时提供不确定性量化增强可解释性

Abstract: Reward learning typically relies on a single feedback type or combines multiple feedback types using manually weighted loss terms. Currently, it remains unclear how to jointly learn reward functions from heterogeneous feedback types such as demonstrations, comparisons, ratings, and stops that provide qualitatively different signals. We address this challenge by formulating reward learning from multiple feedback types as Bayesian inference over a shared latent reward function, where each feedback type contributes information through an explicit likelihood. We introduce a scalable amortized variational inference approach that learns a shared reward encoder and feedback-specific likelihood decoders and is trained by optimizing a single evidence lower bound. Our approach avoids reducing feedback to a common intermediate representation and eliminates the need for manual loss balancing. Across discrete and continuous-control benchmarks, we show that jointly inferred reward posteriors outperform single-type baselines, exploit complementary information across feedback types, and yield policies that are more robust to environment perturbations. The inferred reward uncertainty further provides interpretable signals for analyzing model confidence and consistency across feedback types.

</details>


### [78] [Controlled oscillation modeling using port-Hamiltonian neural networks](https://arxiv.org/abs/2602.15704)
*Maximino Linares,Guillaume Doras,Thomas Hélie*

Main category: cs.LG

TL;DR: 提出将二阶离散梯度方法嵌入端口哈密顿神经网络中学习动力系统，相比同阶Runge-Kutta方法表现更优


<details>
  <summary>Details</summary>
Motivation: 纯数据驱动方法难以学习守恒定律，现有端口哈密顿神经网络方法虽基于功率平衡原理，但通常不考虑功率保持离散化，依赖Runge-Kutta数值方法

Method: 在端口哈密顿神经网络学习中嵌入二阶离散梯度方法，对三种不同动态行为的受控系统进行数值实验：基线谐振子、Duffing振子、自持振子

Result: 离散梯度方法优于同阶Runge-Kutta方法；比较了两种理论上等价的端口哈密顿系统表述；分析了训练中正则化端口哈密顿神经网络雅可比矩阵的影响

Conclusion: 二阶离散梯度方法能更好地保持功率平衡特性，提升端口哈密顿神经网络在动力系统建模中的性能

Abstract: Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training.

</details>


### [79] [The Information Geometry of Softmax: Probing and Steering](https://arxiv.org/abs/2602.15293)
*Kiho Park,Todd Nief,Yo Joong Choe,Victor Veitch*

Main category: cs.LG

TL;DR: 论文探讨AI系统如何将语义结构编码到表示空间的几何结构中，提出信息几何是softmax分布表示的自然几何，并开发了"双重引导"方法用于概念操控。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是观察AI表示空间的自然几何应该反映模型如何使用这些表示来产生行为。特别关注softmax分布表示的情况，认为信息几何是这种表示的自然几何结构。

Method: 论文聚焦于信息几何在语义编码和线性表示假说中的作用。作为应用示例，开发了"双重引导"方法，该方法使用线性探针稳健地引导表示以展现特定概念。该方法在数学上被证明能够最优地修改目标概念，同时最小化对非目标概念的改变。

Result: 经验研究发现，双重引导方法增强了概念操控的可控性和稳定性。该方法在概念操作中表现出优越的性能。

Conclusion: 信息几何为理解AI表示空间的语义结构提供了合适的几何框架，双重引导方法证明了这一框架在实际应用中的有效性，为概念操控提供了更稳健的工具。

Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop "dual steering", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.

</details>


### [80] [ÜberWeb: Insights from Multilingual Curation for a 20-Trillion-Token Dataset](https://arxiv.org/abs/2602.15210)
*DatologyAI,:,Aldo Gael Carranza,Kaleigh Mentzer,Ricardo Pio Monti,Alex Fang,Alvin Deng,Amro Abbas,Anshuman Suri,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Diego Kiner,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: 通过针对性的多语言数据筛选，可以缓解多语言训练中的性能干扰问题，实现计算效率更高的多语言模型扩展。


<details>
  <summary>Details</summary>
Motivation: 现代基础模型需要多语言能力，但多语言训练面临数据分布不均和性能干扰（"多语言诅咒"）的挑战。研究发现许多性能下降并非多语言扩展的固有缺陷，而是数据质量和组成问题。

Method: 在13种语言中进行多语言数据筛选研究，通过双语对照实验验证数据质量改进的效果。将筛选方法扩展到大规模通用训练混合中，使用仅占总标记数8%的筛选多语言分配。构建了20T标记的预训练语料库，训练3B和8B参数模型。

Result: 改进任一语言的数据质量都能惠及其他语言：筛选英语数据改善13种语言中12种的非英语性能，筛选非英语数据也能提升英语性能。针对性的语言特定筛选产生更大的语言内改进。3B和8B模型在1T标记子集上训练，相比强基线减少4-10倍训练FLOPs，建立了多语言性能与计算的新帕累托前沿。400B/A13B的Trinity Large模型也展现出相对于训练FLOPs的强大多语言性能。

Conclusion: 针对性的语言特定数据筛选能够缓解多语言干扰，实现计算效率更高的多语言扩展，为高质量多语言模型训练提供了有效方法。

Abstract: Multilinguality is a core capability for modern foundation models, yet training high-quality multilingual models remains challenging due to uneven data availability across languages. A further challenge is the performance interference that can arise from joint multilingual training, commonly referred to as the "curse of multilinguality". We study multilingual data curation across thirteen languages and find that many reported regressions are not inherent to multilingual scaling but instead stem from correctable deficiencies in data quality and composition rather than fundamental capacity limits. In controlled bilingual experiments, improving data quality for any single language benefits others: curating English improves non-English performance in 12 of 13 languages, while curating non-English yields reciprocal improvements in English. Bespoke per-language curation produces substantially larger within-language improvements. Extending these findings to large-scale general-purpose training mixtures, we show that curated multilingual allocations comprising under 8% of total tokens remain remarkably effective. We operationalize this approach within an effort that produced a 20T-token pretraining corpus derived entirely from public sources. Models with 3B and 8B parameters trained on a 1T-token random subset achieve competitive multilingual accuracy with 4-10x fewer training FLOPs than strong public baselines, establishing a new Pareto frontier in multilingual performance versus compute. Moreover, these benefits extend to frontier model scale: the 20T-token corpus served as part of the pretraining dataset for Trinity Large (400B/A13B), which exhibits strong multilingual performance relative to its training FLOPs. These results show that targeted, per-language data curation mitigates multilingual interference and enables compute-efficient multilingual scaling.

</details>


### [81] [Prescriptive Scaling Reveals the Evolution of Language Model Capabilities](https://arxiv.org/abs/2602.15327)
*Hanlin Zhang,Jikai Jin,Vasilis Syrgkanis,Sham Kakade*

Main category: cs.LG

TL;DR: 该论文提出了一种通过平滑分位数回归估计模型能力边界的方法，用于预测给定预训练计算预算下的下游性能，并验证了时间稳定性，同时发布了Proteus 2k数据集和高效评估算法。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的部署需求增长，实践者需要预测性的扩展定律：给定预训练计算预算，在当代后训练实践下可获得的下游准确率是多少？这种映射关系随着领域发展有多稳定？

Method: 使用大规模观测评估（5k观测数据和2k新采样数据），通过具有单调饱和sigmoid参数化的平滑分位数回归来估计能力边界（基准分数的高条件分位数作为预训练FLOPs对数的函数）。验证时间可靠性：在早期模型代上拟合并在后期发布上评估。扩展方法分析任务依赖性饱和和污染相关偏移。引入高效算法，用约20%评估预算恢复接近完整的数据边界。

Result: 估计的能力边界在大多数任务中基本稳定，但数学推理任务表现出随时间持续推进的边界。方法能够有效分析任务依赖性饱和和污染相关偏移。高效算法能以约20%评估预算恢复接近完整的数据边界。

Conclusion: 该工作发布了最新的模型性能评估数据集Proteus 2k，并引入了一种实用方法，用于将计算预算转化为可靠的性能预期，并监控能力边界随时间的变化。

Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.

</details>


### [82] [Automatically Finding Reward Model Biases](https://arxiv.org/abs/2602.15222)
*Atticus Wang,Iván Arcuschin,Arthur Conmy*

Main category: cs.LG

TL;DR: 论文提出自动发现奖励模型偏见的框架，通过LLM迭代提出和优化候选偏见，成功识别出已知和新颖的偏见模式。


<details>
  <summary>Details</summary>
Motivation: 奖励模型在LLM后训练中至关重要，但现有研究表明它们可能奖励虚假或不良属性（如长度、格式、幻觉和谄媚）。需要自动发现这些偏见的方法来改进奖励模型。

Method: 使用LLM迭代提出和优化候选偏见的简单方法。比较了进化迭代与平面最佳N搜索的效果，并使用合成注入的偏见验证了管道的召回率。

Result: 方法能够恢复已知偏见并发现新颖偏见：例如发现Skywork-V2-8B奖励模型经常错误地偏好带有冗余空格和幻觉内容的回答。进化迭代优于平面最佳N搜索。

Conclusion: 该工作为通过自动可解释性方法改进奖励模型的研究做出了贡献，展示了自动发现奖励模型偏见的可行性。

Abstract: Reward models are central to large language model (LLM) post-training. However, past work has shown that they can reward spurious or undesirable attributes such as length, format, hallucinations, and sycophancy. In this work, we introduce and study the research problem of automatically finding reward model biases in natural language. We offer a simple approach of using an LLM to iteratively propose and refine candidate biases. Our method can recover known biases and surface novel ones: for example, we found that Skywork-V2-8B, a leading open-weight reward model, often mistakenly favors responses with redundant spacing and responses with hallucinated content. In addition, we show evidence that evolutionary iteration outperforms flat best-of-N search, and we validate the recall of our pipeline using synthetically injected biases. We hope our work contributes to further research on improving RMs through automated interpretability methods.

</details>


### [83] [Logit Distance Bounds Representational Similarity](https://arxiv.org/abs/2602.15438)
*Beatrix M. B. Nielsen,Emanuele Marconato,Luigi Gresele,Andrea Dittadi,Simon Buchholz*

Main category: cs.LG

TL;DR: 研究近似条件下的表示相似性：当两个判别模型的分布接近而非相等时，其内部表示是否仍保持线性相似性。发现基于logit差异的距离能保证线性相似性，而KL散度不能。


<details>
  <summary>Details</summary>
Motivation: 对于判别模型（包括自回归语言模型），可识别性理论表明当两个模型的条件分布完全相同时，其内部表示在可逆线性变换下一致。但实际中模型分布通常只是接近而非相等，需要研究这种近似条件下的表示相似性保证。

Method: 1) 基于logit差异定义分布距离；2) 基于模型可识别性类定义表示相似性度量；3) 证明logit距离能约束表示相似性；4) 分析KL散度与logit距离的关系；5) 在合成和图像数据集上进行蒸馏实验验证。

Result: 1) 基于logit差异的距离能保证线性表示相似性；2) KL散度虽然能上界logit距离，但在实践中无法提供有效控制；3) 基于KL散度的蒸馏能匹配教师预测但无法保持线性表示特性；4) 基于logit距离的蒸馏能获得更高的线性表示相似性和更好的概念可恢复性。

Conclusion: 对于近似相等的模型，基于logit差异的距离比KL散度更适合衡量表示相似性。在知识蒸馏中，使用logit距离能更好地保持教师的线性表示特性，这对于保持人类可解释概念的可恢复性很重要。

Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.

</details>


### [84] [tensorFM: Low-Rank Approximations of Cross-Order Feature Interactions](https://arxiv.org/abs/2602.15229)
*Alessio Mazzetto,Mohammad Mahdi Khalili,Laura Fee Nern,Michael Viderman,Alex Shtoff,Krzysztof Dembczyński*

Main category: cs.LG

TL;DR: 提出tensorFM模型，通过低秩张量近似高效捕捉分类数据中的高阶交互，在点击率预测等应用中表现优异且延迟低


<details>
  <summary>Details</summary>
Motivation: 解决表格分类数据中的预测问题，特别是需要捕捉多个分类属性间高阶交互的场景，如点击率预测和社会科学研究

Method: 提出tensorFM模型，通过低秩张量近似来高效表示属性间交互强度，该方法推广了场加权分解机

Result: tensorFM在实证研究中表现出与最先进方法竞争的性能，同时具有低延迟特性

Conclusion: tensorFM是处理表格分类数据预测的有效模型，特别适合在线广告等对时间敏感的应用场景

Abstract: We address prediction problems on tabular categorical data, where each instance is defined by multiple categorical attributes, each taking values from a finite set. These attributes are often referred to as fields, and their categorical values as features. Such problems frequently arise in practical applications, including click-through rate prediction and social sciences. We introduce and analyze {tensorFM}, a new model that efficiently captures high-order interactions between attributes via a low-rank tensor approximation representing the strength of these interactions. Our model generalizes field-weighted factorization machines. Empirically, tensorFM demonstrates competitive performance with state-of-the-art methods. Additionally, its low latency makes it well-suited for time-sensitive applications, such as online advertising.

</details>


### [85] [Approximation Theory for Lipschitz Continuous Transformers](https://arxiv.org/abs/2602.15503)
*Takashi Furuya,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 提出一种梯度下降型上下文Transformer，通过构造保证Lipschitz连续性，在Lipschitz约束函数空间中实现通用逼近，为稳健Transformer架构提供理论基础


<details>
  <summary>Details</summary>
Motivation: Transformer在安全敏感场景中需要稳定性和鲁棒性，约束Lipschitz常数是保证这种行为的原理性方法，但目前缺乏对显式保持Lipschitz连续性的架构的逼近理论保证

Method: 引入梯度下降型上下文Transformer，将MLP和注意力块实现为负梯度流的显式欧拉步，确保固有稳定性而不牺牲表达能力；采用测度论形式主义，将Transformer解释为概率测度上的算子

Result: 证明了这类架构在Lipschitz约束函数空间中的通用逼近定理，逼近保证独立于token数量，为稳健的Lipschitz连续Transformer设计提供了严格理论基础

Conclusion: 通过构造保证Lipschitz连续性的梯度下降型Transformer填补了理论空白，为安全敏感应用中稳健Transformer架构的设计提供了原理性框架

Abstract: Stability and robustness are critical for deploying Transformers in safety-sensitive settings. A principled way to enforce such behavior is to constrain the model's Lipschitz constant. However, approximation-theoretic guarantees for architectures that explicitly preserve Lipschitz continuity have yet to be established. In this work, we bridge this gap by introducing a class of gradient-descent-type in-context Transformers that are Lipschitz-continuous by construction. We realize both MLP and attention blocks as explicit Euler steps of negative gradient flows, ensuring inherent stability without sacrificing expressivity. We prove a universal approximation theorem for this class within a Lipschitz-constrained function space. Crucially, our analysis adopts a measure-theoretic formalism, interpreting Transformers as operators on probability measures, to yield approximation guarantees independent of token count. These results provide a rigorous theoretical foundation for the design of robust, Lipschitz continuous Transformer architectures.

</details>


### [86] [BindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening](https://arxiv.org/abs/2602.15236)
*Anjie Qiao,Zhen Wang,Yaliang Li,Jiahua Rao,Yuedong Yang*

Main category: cs.LG

TL;DR: BindCLIP：通过结合对比学习和生成式姿态监督的统一框架，提升虚拟筛选中的结合相互作用感知能力


<details>
  <summary>Details</summary>
Motivation: 现有CLIP风格模型（如DrugCLIP）在虚拟筛选中存在两个问题：1）对细粒度结合相互作用不敏感；2）可能依赖训练数据中的捷径相关性，限制了其根据真实结合兼容性排序配体的能力

Method: 提出BindCLIP统一框架：1）使用CLIP风格对比学习联合训练口袋和配体编码器；2）结合口袋条件扩散目标进行结合姿态生成，使姿态级监督直接塑造检索嵌入空间朝向相互作用相关特征；3）引入硬负样本增强和配体-配体锚定正则化器防止表示坍塌

Result: 在两个公共基准测试中均优于强基线模型，在具有挑战性的分布外虚拟筛选中取得显著提升，在FEP+基准测试中改善了配体类似物排序

Conclusion: 将生成式姿态级监督与对比学习相结合，能产生更具相互作用感知能力的嵌入表示，在真实筛选场景中提高泛化能力，使虚拟筛选更接近实际应用

Abstract: Virtual screening aims to efficiently identify active ligands from massive chemical libraries for a given target pocket. Recent CLIP-style models such as DrugCLIP enable scalable virtual screening by embedding pockets and ligands into a shared space. However, our analyses indicate that such representations can be insensitive to fine-grained binding interactions and may rely on shortcut correlations in training data, limiting their ability to rank ligands by true binding compatibility. To address these issues, we propose BindCLIP, a unified contrastive-generative representation learning framework for virtual screening. BindCLIP jointly trains pocket and ligand encoders using CLIP-style contrastive learning together with a pocket-conditioned diffusion objective for binding pose generation, so that pose-level supervision directly shapes the retrieval embedding space toward interaction-relevant features. To further mitigate shortcut reliance, we introduce hard-negative augmentation and a ligand-ligand anchoring regularizer that prevents representation collapse. Experiments on two public benchmarks demonstrate consistent improvements over strong baselines. BindCLIP achieves substantial gains on challenging out-of-distribution virtual screening and improves ligand-analogue ranking on the FEP+ benchmark. Together, these results indicate that integrating generative, pose-level supervision with contrastive learning yields more interaction-aware embeddings and improves generalization in realistic screening settings, bringing virtual screening closer to real-world applicability.

</details>


### [87] [Uniform error bounds for quantized dynamical models](https://arxiv.org/abs/2602.15586)
*Abdelkader Metakalard,Fabien Lauer,Kevin Colin,Marion Gilson*

Main category: cs.LG

TL;DR: 该论文为从依赖数据序列学习到的动态模型提供了统计精度保证，开发了适用于量化模型和不完美优化算法的统一误差界，特别针对系统辨识和混合系统辨识应用。


<details>
  <summary>Details</summary>
Motivation: 在实际系统辨识应用中，特别是混合系统辨识，通常使用量化模型和不完美的优化算法，但缺乏对这些实际约束下学习模型的统计精度保证。

Method: 开发了两种误差界：通过块分解的慢速率界，以及通过新颖的间隔点策略的快速率、方差自适应界。这些界与编码模型所需的比特数成比例。

Result: 获得了可扩展的误差界，将硬件约束转化为可解释的统计复杂度，为实际系统辨识中的量化模型和不完美优化提供了统计保证。

Conclusion: 该研究为依赖数据序列学习的动态模型提供了实用的统计精度保证框架，特别适用于受硬件限制的实际系统辨识应用。

Abstract: This paper provides statistical guarantees on the accuracy of dynamical models learned from dependent data sequences. Specifically, we develop uniform error bounds that apply to quantized models and imperfect optimization algorithms commonly used in practical contexts for system identification, and in particular hybrid system identification. Two families of bounds are obtained: slow-rate bounds via a block decomposition and fast-rate, variance-adaptive, bounds via a novel spaced-point strategy. The bounds scale with the number of bits required to encode the model and thus translate hardware constraints into interpretable statistical complexities.

</details>


### [88] [Closing the Distribution Gap in Adversarial Training for LLMs](https://arxiv.org/abs/2602.15238)
*Chengzhi Hu,Jonas Dornbusch,David Lüdke,Stephan Günnemann,Leo Schwinn*

Main category: cs.LG

TL;DR: 提出Distributional Adversarial Training (DAT)方法，通过扩散语言模型近似真实数据分布，生成多样化的对抗样本，显著提升大语言模型的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前对抗训练方法虽然取得进展，但模型仍然容易受到简单的分布内攻击（如时态改写、语言翻译）。这种脆弱性源于现有方法仅在训练集上最小化对抗损失，未能充分覆盖数据分布。

Method: 提出Distributional Adversarial Training (DAT)：1) 利用扩散语言模型近似提示和响应的真实联合分布；2) 生成多样化、高似然的样本来解决泛化失败问题；3) 将扩散模型提供的数据分布优化与连续对抗训练相结合。

Result: DAT相比先前方法实现了显著更高的对抗鲁棒性，能够有效防御看似简单的攻击。

Conclusion: 通过近似真实数据分布并生成多样化对抗样本，DAT解决了当前对抗训练方法的根本局限性，为大语言模型的鲁棒性提升提供了新方向。

Abstract: Adversarial training for LLMs is one of the most promising methods to reliably improve robustness against adversaries. However, despite significant progress, models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or translating them into other languages. We argue that this persistent fragility stems from a fundamental limitation in current adversarial training algorithms: they minimize adversarial loss on their training set but inadequately cover the data distribution, resulting in vulnerability to seemingly simple attacks. To bridge this gap, we propose Distributional Adversarial Training, DAT. We leverage Diffusion LLMs to approximate the true joint distribution of prompts and responses, enabling generation of diverse, high-likelihood samples that address generalization failures. By combining optimization over the data distribution provided by the diffusion model with continuous adversarial training, DAT achieves substantially higher adversarial robustness than previous methods.

</details>


### [89] [Certified Per-Instance Unlearning Using Individual Sensitivity Bounds](https://arxiv.org/abs/2602.15602)
*Hanna Benarroch,Jamal Atif,Olivier Cappé*

Main category: cs.LG

TL;DR: 提出一种基于自适应逐实例噪声校准的认证机器遗忘方法，相比传统差分隐私的保守校准，显著减少噪声注入并保持性能


<details>
  <summary>Details</summary>
Motivation: 传统基于差分隐私的认证机器遗忘方法采用最坏情况敏感性校准噪声，导致性能显著下降，限制了实际应用。需要一种更精细的噪声校准方法，根据每个数据点对学习解决方案的个体贡献来调整噪声

Method: 采用自适应逐实例噪声校准方法，基于逐实例差分隐私定义个体数据点敏感性。针对通过Langevin动态训练的岭回归，推导高概率的逐实例敏感性边界，实现认证遗忘

Result: 理论分析表明该方法能显著减少噪声注入，实验在线性设置中验证了理论发现，并在深度学习设置中提供了进一步实证证据

Conclusion: 通过逐实例敏感性分析实现的认证机器遗忘方法，相比传统差分隐私方法，能在保持认证保证的同时显著减少噪声注入，提高实际应用价值

Abstract: Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.

</details>


### [90] [Size Transferability of Graph Transformers with Convolutional Positional Encodings](https://arxiv.org/abs/2602.15239)
*Javier Porras-Valenzuela,Zhiyang Wang,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 图Transformer通过GNN位置编码获得可迁移性，能在小图上训练后迁移到大图上，理论证明与流形神经网络相关


<details>
  <summary>Details</summary>
Motivation: 研究图Transformer（GTs）的可迁移性，特别是使用GNN位置编码的GTs如何在不同规模的图上保持性能，为大规模图上的高效训练提供理论指导

Method: 通过流形极限模型分析图序列，建立GTs与流形神经网络的理论联系，基于GNN在流形收敛下的可迁移性结果，证明GTs继承其位置编码的可迁移性

Result: 理论证明GTs在小图上训练后能在温和假设下推广到大图，实验验证GTs在标准图基准上表现出与GNN相当的可扩展性，并在最短路径距离估计任务中展示实际效率

Conclusion: GTs通过GNN位置编码获得可迁移性，为理解GTs提供了新视角，并为大规模图上的高效训练提供了实用方向

Abstract: Transformers have achieved remarkable success across domains, motivating the rise of Graph Transformers (GTs) as attention-based architectures for graph-structured data. A key design choice in GTs is the use of Graph Neural Network (GNN)-based positional encodings to incorporate structural information. In this work, we study GTs through the lens of manifold limit models for graph sequences and establish a theoretical connection between GTs with GNN positional encodings and Manifold Neural Networks (MNNs). Building on transferability results for GNNs under manifold convergence, we show that GTs inherit transferability guarantees from their positional encodings. In particular, GTs trained on small graphs provably generalize to larger graphs under mild assumptions. We complement our theory with extensive experiments on standard graph benchmarks, demonstrating that GTs exhibit scalable behavior on par with GNNs. To further show the efficiency in a real-world scenario, we implement GTs for shortest path distance estimation over terrains to better illustrate the efficiency of the transferable GTs. Our results provide new insights into the understanding of GTs and suggest practical directions for efficient training of GTs in large-scale settings.

</details>


### [91] [Symbolic recovery of PDEs from measurement data](https://arxiv.org/abs/2602.15603)
*Erion Morina,Philipp Scholl,Martin Holler*

Main category: cs.LG

TL;DR: 该论文提出使用基于有理函数的神经网络架构进行物理定律的符号表示，证明了在无噪声完整测量条件下，此类符号网络能够唯一重构PDE模型中最简单的物理定律，并通过ParFam架构进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 基于偏微分方程的模型在描述自然科学中的复杂关系方面很强大，但准确识别代表底层物理定律的PDE模型通常依赖于间接且有噪声的测量，且传统方法很少能产生符号表达式，这阻碍了模型的可解释性。

Method: 采用基于有理函数的神经网络架构进行物理定律的符号表示，利用有理函数的逼近能力和表示算术运算的灵活性，通过正则化最小化参数化来促进可解释性和稀疏性。

Result: 提出了可识别性结果，证明在无噪声完整测量条件下，符号网络能够唯一重构PDE模型中最简单的物理定律，重构的定律在符号网络架构中保持可表达性，并提供了符号网络的规律性结果。

Conclusion: 基于有理函数的符号网络架构能够有效重构物理定律，在理论可识别性和实际可重构性方面都表现出良好性能，为物理定律的符号表示和可解释性提供了有前景的方法。

Abstract: Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.

</details>


### [92] [Scaling Laws for Masked-Reconstruction Transformers on Single-Cell Transcriptomics](https://arxiv.org/abs/2602.15253)
*Ihor Kendiukhov*

Main category: cs.LG

TL;DR: 首次系统研究单细胞RNA测序数据上掩码重建Transformer的缩放规律，发现数据充足时存在类似NLP的幂律缩放，数据稀缺时缩放效应可忽略。


<details>
  <summary>Details</summary>
Motivation: 神经缩放规律在语言和视觉Transformer中已被广泛记录，但在单细胞基因组学中尚未得到充分探索。本研究旨在填补这一空白，探究单细胞转录组学数据上Transformer的缩放行为。

Method: 使用CELLxGENE Census的表达谱数据，构建两个实验体系：数据丰富体系（512个高变异基因，200,000个细胞）和数据有限体系（1,024个基因，10,000个细胞）。在跨越三个数量级的七个模型规模（533到3.4×10^8参数）上，拟合验证均方误差的参数量化缩放规律。

Result: 数据丰富体系显示出清晰的幂律缩放，具有不可约损失下限c~1.44；数据有限体系缩放效应可忽略，表明当数据稀缺时模型容量不是主要限制因素。初步将数据丰富渐近下限转换为信息论单位，估计每个掩码基因位置约2.30比特的熵。

Conclusion: 当数据充足时，单细胞转录组学中确实会出现类似自然语言处理的缩放规律，数据与参数比是缩放行为的关键决定因素。这些发现对单细胞基础模型的设计具有重要启示，并指出了完善熵估计所需的额外测量。

Abstract: Neural scaling laws -- power-law relationships between loss, model size, and data -- have been extensively documented for language and vision transformers, yet their existence in single-cell genomics remains largely unexplored. We present the first systematic study of scaling behaviour for masked-reconstruction transformers trained on single-cell RNA sequencing (scRNA-seq) data. Using expression profiles from the CELLxGENE Census, we construct two experimental regimes: a data-rich regime (512 highly variable genes, 200,000 cells) and a data-limited regime (1,024 genes, 10,000 cells). Across seven model sizes spanning three orders of magnitude in parameter count (533 to 3.4 x 10^8 parameters), we fit the parametric scaling law to validation mean squared error (MSE). The data-rich regime exhibits clear power-law scaling with an irreducible loss floor of c ~ 1.44, while the data-limited regime shows negligible scaling, indicating that model capacity is not the binding constraint when data are scarce. These results establish that scaling laws analogous to those observed in natural language processing do emerge in single-cell transcriptomics when sufficient data are available, and they identify the data-to-parameter ratio as a critical determinant of scaling behaviour. A preliminary conversion of the data-rich asymptotic floor to information-theoretic units yields an estimate of approximately 2.30 bits of entropy per masked gene position. We discuss implications for the design of single-cell foundation models and outline the additional measurements needed to refine this entropy estimate.

</details>


### [93] [Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning](https://arxiv.org/abs/2602.15817)
*Oswin So,Eric Yang Yu,Songyuan Zhang,Matthew Cleaveland,Mitchell Black,Chuchu Fan*

Main category: cs.LG

TL;DR: 提出Feasibility-Guided Exploration (FGE)方法，通过同时识别可行初始条件子集并学习策略，解决强化学习在可达性问题中的不匹配问题，相比现有方法在多个任务中覆盖范围提升50%以上。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在高维控制任务中表现优异，但应用于可达性问题时存在根本性不匹配：可达性追求最大化系统保持安全的初始状态集合，而RL优化用户指定分布上的期望回报。这种不匹配可能导致策略在低概率但仍安全的初始状态下表现不佳。

Method: 提出可行性引导探索(FGE)方法，同时识别存在安全策略的可行初始条件子集，并学习在该初始条件集合上解决可达性问题的策略。

Result: 实验结果表明，FGE在MuJoCo模拟器和Kinetix模拟器（像素观测）的多个任务中，对于具有挑战性的初始条件，学习的策略覆盖范围比现有最佳方法高出50%以上。

Conclusion: FGE方法通过同时识别可行初始条件并学习策略，有效解决了RL在可达性问题中的不匹配问题，显著提升了策略在安全状态集合上的覆盖范围。

Abstract: Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.

</details>


### [94] [Fast and Effective On-policy Distillation from Reasoning Prefixes](https://arxiv.org/abs/2602.15260)
*Dongxu Zhang,Zhichao Yang,Sepehr Janghorbani,Jun Han,Andrew Ressler,Qian Qian,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.LG

TL;DR: 提出一种改进的在线蒸馏方法：仅对学生模型生成输出的前缀部分应用蒸馏目标，并提前终止采样，大幅降低训练成本的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 在线蒸馏虽然能获得比离线蒸馏更好的泛化能力，但需要在训练时实时采样学生策略，成本高昂，尤其对于长响应。研究发现训练信号通常集中在输出的前缀部分，短的前缀就能显著帮助学生生成正确答案。

Method: 提出在线前缀蒸馏：仅对学生生成输出的前缀部分应用蒸馏目标，并在蒸馏过程中提前终止每个采样。这减少了需要处理的计算量，同时保留了关键的训练信号。

Result: 在AI-for-Math和领域外基准测试套件上的实验表明，在线前缀蒸馏与完整在线蒸馏性能相当，同时将训练FLOP降低了2-47倍。

Conclusion: 在线前缀蒸馏是一种简单有效的改进方法，通过专注于输出前缀的蒸馏，在保持模型性能的同时大幅降低了在线蒸馏的训练成本。

Abstract: On-policy distillation (OPD), which samples trajectories from the student model and supervises them with a teacher at the token level, avoids relying solely on verifiable terminal rewards and can yield better generalization than off-policy distillation. However, OPD requires expensive on-the-fly sampling of the student policy during training, which substantially increases training cost, especially for long responses. Our initial analysis shows that, during OPD, training signals are often concentrated in the prefix of each output, and that even a short teacher-generated prefix can significantly help the student produce the correct answer. Motivated by these observations, we propose a simple yet effective modification of OPD: we apply the distillation objective only to prefixes of student-generated outputs and terminate each sampling early during distillation. Experiments on a suite of AI-for-Math and out-of-domain benchmarks show that on-policy prefix distillation matches the performance of full OPD while reducing training FLOP by 2x-47x.

</details>


### [95] [Complex-Valued Unitary Representations as Classification Heads for Improved Uncertainty Quantification in Deep Neural Networks](https://arxiv.org/abs/2602.15283)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.LG

TL;DR: 提出量子启发的分类头架构，通过Cayley映射参数化的酉变换在复值希尔伯特空间中演化特征，显著改善深度神经网络的校准性能。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络预测准确率高但校准性差，置信度分数不能可靠反映正确概率的真实概率。需要改进模型校准性能。

Method: 提出量子启发的分类头架构：将骨干网络特征投影到复值希尔伯特空间，通过Cayley映射参数化的酉变换演化特征。采用受控混合实验设计，比较轻量级可互换的头部结构。

Result: 在CIFAR-10上，酉幅度头（复特征在Cayley酉变换下演化，通过幅度和softmax读出）的期望校准误差为0.0146，比标准softmax头（0.0355）改善2.4倍，比温度缩放（0.0510）改善3.5倍。在CIFAR-10H人类不确定性基准上，波函数头获得最低KL散度（0.336）。

Conclusion: 复值表示通过特征空间几何改善校准性能，能更好地捕捉人类感知模糊性结构。但Born规则测量层会降低校准性能。该方法对安全关键应用有实际意义。

Abstract: Modern deep neural networks achieve high predictive accuracy but remain poorly calibrated: their confidence scores do not reliably reflect the true probability of correctness. We propose a quantum-inspired classification head architecture that projects backbone features into a complex-valued Hilbert space and evolves them under a learned unitary transformation parameterised via the Cayley map. Through a controlled hybrid experimental design - training a single shared backbone and comparing lightweight interchangeable heads - we isolate the effect of complex-valued unitary representations on calibration. Our ablation study on CIFAR-10 reveals that the unitary magnitude head (complex features evolved under a Cayley unitary, read out via magnitude and softmax) achieves an Expected Calibration Error (ECE) of 0.0146, representing a 2.4x improvement over a standard softmax head (0.0355) and a 3.5x improvement over temperature scaling (0.0510). Surprisingly, replacing the softmax readout with a Born rule measurement layer - the quantum-mechanically motivated approach - degrades calibration to an ECE of 0.0819. On the CIFAR-10H human-uncertainty benchmark, the wave function head achieves the lowest KL-divergence (0.336) to human soft labels among all compared methods, indicating that complex-valued representations better capture the structure of human perceptual ambiguity. We provide theoretical analysis connecting norm-preserving unitary dynamics to calibration through feature-space geometry, report negative results on out-of-distribution detection and sentiment analysis to delineate the method's scope, and discuss practical implications for safety-critical applications. Code is publicly available.

</details>


### [96] [Hybrid Federated and Split Learning for Privacy Preserving Clinical Prediction and Treatment Optimization](https://arxiv.org/abs/2602.15304)
*Farzana Akter,Rakib Hossain,Deb Kanna Roy Toushi,Mahmood Menon Khan,Sultana Amin,Lisan Al Amin*

Main category: cs.LG

TL;DR: 提出结合联邦学习与分割学习的混合隐私保护框架，用于医疗决策支持，无需共享原始数据，在预测性能、隐私泄漏、通信开销等方面取得平衡。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持系统常受治理和隐私规则限制，无法跨机构汇集患者数据。需要一种既能保护隐私又能支持决策导向医疗建模的方法。

Method: 结合联邦学习（FL）和分割学习（SL）的混合框架，将特征提取主干保留在客户端，预测头放在协调服务器上，通过成员推断审计隐私泄漏，并采用激活裁剪和高斯噪声等轻量级防御措施。

Result: 在三个公开临床数据集上评估，混合FL-SL变体在预测性能和决策优先级方面与独立FL或SL相当，同时提供可调的隐私-效用权衡，能减少审计泄漏且无需原始数据共享。

Conclusion: 混合FL-SL为隐私保护医疗决策支持提供了一个实用的设计空间，能够明确平衡效用、泄漏风险和部署成本。

Abstract: Collaborative clinical decision support is often constrained by governance and privacy rules that prevent pooling patient-level records across institutions. We present a hybrid privacy-preserving framework that combines Federated Learning (FL) and Split Learning (SL) to support decision-oriented healthcare modeling without raw-data sharing. The approach keeps feature-extraction trunks on clients while hosting prediction heads on a coordinating server, enabling shared representation learning and exposing an explicit collaboration boundary where privacy controls can be applied. Rather than assuming distributed training is inherently private, we audit leakage empirically using membership inference on cut-layer representations and study lightweight defenses based on activation clipping and additive Gaussian noise. We evaluate across three public clinical datasets under non-IID client partitions using a unified pipeline and assess performance jointly along four deployment-relevant axes: factual predictive utility, uplift-based ranking under capacity constraints, audited privacy leakage, and communication overhead. Results show that hybrid FL-SL variants achieve competitive predictive performance and decision-facing prioritization behavior relative to standalone FL or SL, while providing a tunable privacy-utility trade-off that can reduce audited leakage without requiring raw-data sharing. Overall, the work positions hybrid FL-SL as a practical design space for privacy-preserving healthcare decision support where utility, leakage risk, and deployment cost must be balanced explicitly.

</details>


### [97] [On Surprising Effectiveness of Masking Updates in Adaptive Optimizers](https://arxiv.org/abs/2602.15322)
*Taejong Joo,Wenhan Xia,Cheolmin Kim,Ming Zhang,Eugene Ie*

Main category: cs.LG

TL;DR: 提出Magma优化器，通过随机掩码参数更新和动量梯度对齐，在LLM预训练中超越现有自适应优化器，显著降低困惑度


<details>
  <summary>Details</summary>
Motivation: 挑战当前LLM训练依赖复杂自适应优化器的现状，发现随机掩码参数更新能有效提升性能，这源于掩码带来的曲率相关几何正则化效应

Method: 提出Momentum-aligned gradient masking (Magma)方法：1) 随机掩码参数更新；2) 利用动量-梯度对齐调节掩码更新；3) 作为自适应优化器的简单替代方案

Result: 在LLM预训练实验中，Magma相比Adam和Muon等优化器表现更优：对于10亿参数模型，困惑度分别降低19%和9%，且计算开销可忽略

Conclusion: Magma是一种简单有效的优化器替代方案，通过随机掩码和动量对齐机制实现更好的训练效果，挑战了当前依赖复杂自适应优化器的范式

Abstract: Training large language models (LLMs) relies almost exclusively on dense adaptive optimizers with increasingly sophisticated preconditioners. We challenge this by showing that randomly masking parameter updates can be highly effective, with a masked variant of RMSProp consistently outperforming recent state-of-the-art optimizers. Our analysis reveals that the random masking induces a curvature-dependent geometric regularization that smooths the optimization trajectory. Motivated by this finding, we introduce Momentum-aligned gradient masking (Magma), which modulates the masked updates using momentum-gradient alignment. Extensive LLM pre-training experiments show that Magma is a simple drop-in replacement for adaptive optimizers with consistent gains and negligible computational overhead. Notably, for the 1B model size, Magma reduces perplexity by over 19\% and 9\% compared to Adam and Muon, respectively.

</details>


### [98] [A Scalable Curiosity-Driven Game-Theoretic Framework for Long-Tail Multi-Label Learning in Data Mining](https://arxiv.org/abs/2602.15330)
*Jing Yang,Keze Wang*

Main category: cs.LG

TL;DR: 提出CD-GTMLL框架，将长尾多标签分类重构为多玩家博弈，通过好奇驱动机制自适应增强尾部标签学习，无需手动调参，在极端多标签数据集上超越SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据挖掘中，多标签分类面临长尾分布挑战：少数头部标签主导，大量尾部标签稀少。现有重采样和重加权方法会破坏标签间依赖关系或需要脆弱的超参数调优，尤其在标签空间扩展到数万个标签时问题更严重。

Method: 提出好奇驱动博弈论多标签学习(CD-GTMLL)：将长尾多标签分类重构为多玩家博弈，每个子预测器（"玩家"）专攻标签空间的一个分区，通过合作最大化全局准确率，同时基于尾部标签稀有性和玩家间分歧追求内在好奇奖励。该机制自适应地向代表性不足的尾部标签注入学习信号，无需手动平衡或调参。

Result: 在7个基准测试（包括30,000+标签的极端多标签分类数据集）上，CD-GTMLL始终超越最先进方法，在Wiki10-31K上P@3提升高达+1.6%。理论分析表明CD-GTMLL收敛到尾部感知均衡，优化动态与Rare-F1指标改进有形式化联系。消融研究证实了博弈论合作和好奇驱动探索对稳健尾部性能的贡献。

Conclusion: 通过整合博弈论与好奇机制，CD-GTMLL不仅提高了资源受限环境中的模型效率，还为电子商务和医疗等行业的不平衡数据场景中更自适应学习铺平了道路。

Abstract: The long-tail distribution, where a few head labels dominate while rare tail labels abound, poses a persistent challenge for large-scale Multi-Label Classification (MLC) in real-world data mining applications. Existing resampling and reweighting strategies often disrupt inter-label dependencies or require brittle hyperparameter tuning, especially as the label space expands to tens of thousands of labels. To address this issue, we propose Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL), a scalable cooperative framework that recasts long-tail MLC as a multi-player game - each sub-predictor ("player") specializes in a partition of the label space, collaborating to maximize global accuracy while pursuing intrinsic curiosity rewards based on tail label rarity and inter-player disagreement. This mechanism adaptively injects learning signals into under-represented tail labels without manual balancing or tuning. We further provide a theoretical analysis showing that our CD-GTMLL converges to a tail-aware equilibrium and formally links the optimization dynamics to improvements in the Rare-F1 metric. Extensive experiments across 7 benchmarks, including extreme multi-label classification datasets with 30,000+ labels, demonstrate that CD-GTMLL consistently surpasses state-of-the-art methods, with gains up to +1.6% P@3 on Wiki10-31K. Ablation studies further confirm the contributions of both game-theoretic cooperation and curiosity-driven exploration to robust tail performance. By integrating game theory with curiosity mechanisms, CD-GTMLL not only enhances model efficiency in resource-constrained environments but also paves the way for more adaptive learning in imbalanced data scenarios across industries like e-commerce and healthcare.

</details>


### [99] [Directional Reasoning Trajectory Change (DRTC): Identifying Critical Trace Segments in Reasoning Models](https://arxiv.org/abs/2602.15332)
*Waldemar Chang*

Main category: cs.LG

TL;DR: DRTC是一个因果解释框架，用于分析语言模型的长程推理过程，通过检测关键决策点并测量上下文块对推理轨迹方向的影响。


<details>
  <summary>Details</summary>
Motivation: 现有解释方法通常只突出与答案相关的token或文本片段，但很少揭示模型在哪里做出关键推理转折、哪些早期上下文因果性地触发这些转折，或者突出文本是否真正引导推理过程。

Method: 提出方向性推理轨迹变化(DRTC)框架：1) 使用不确定性和分布偏移信号检测关键决策点；2) 应用接收端干预，在保持已实现推理轨迹的同时，在关键点阻断选定早期文本块的信息流；3) 测量干预是否改变模型对数概率轨迹的方向，产生带符号的每块归因分数；4) 计算原始logits的转角曲率变化作为补充诊断。

Result: 方向性影响在四个推理模型中高度集中（Gini系数0.50-0.58，前5%质量占比0.23-0.28）；学习到的关键点比随机匹配的文本片段产生更强的干预幅度；在500个MATH问题上的扩展研究中，学习到的文本片段显著优于随机匹配片段（中位数差异=0.409，355/500为正，符号检验p=2.3e-21）。

Conclusion: DRTC提供了一个因果基础、轨迹层面的视角，揭示特定上下文元素如何在策略动态下引导推理过程，为理解语言模型的长程推理机制提供了新工具。

Abstract: Understanding how language models carry out long-horizon reasoning remains an open challenge. Existing interpretability methods often highlight tokens or spans correlated with an answer, but they rarely reveal where the model makes consequential reasoning turns, which earlier context causally triggers those turns, or whether the highlighted text actually steers the reasoning process. We introduce Directional Reasoning Trajectory Change (DRTC), a process-causal framework for interpreting long-form reasoning from a single on-policy rollout. DRTC detects pivot decision points using uncertainty and distribution-shift signals, then applies receiver-side interventions that preserve the realized rollout without resampling the continuation while blocking information flow from selected earlier chunks only at a pivot. It measures whether each intervention redirects the direction of the model's log-probability trajectory relative to the realized rollout direction, producing a signed per-chunk attribution score. We also compute turning-angle curvature changes on raw logits as a complementary diagnostic and introduce curvature signatures to summarize shared intervention-response geometry. Empirically, directional influence is sharply concentrated across four reasoning models (per-example |DRTC| shares yield Gini 0.50 to 0.58 and top-5 percent mass 0.23 to 0.28), and learned pivots induce stronger intervention magnitudes than matched random spans. In a scaling study on 500 MATH problems with R1-Distill-Qwen-1.5B, learned spans outperform matched random spans (median delta = 0.409, 355 of 500 positive; sign test p = 2.3e-21). Overall, DRTC provides a causally grounded, trajectory-level view of how specific context elements steer reasoning under on-policy dynamics.

</details>


### [100] [FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning](https://arxiv.org/abs/2602.15337)
*Chaoyi Lu*

Main category: cs.LG

TL;DR: FedPSA：基于参数敏感度的异步联邦学习框架，通过细粒度评估模型过时程度和动态调整过时信息容忍度，提升异步联邦学习性能。


<details>
  <summary>Details</summary>
Motivation: 异步联邦学习（AFL）虽然能加速训练，但异步过程引入的过时性（staleness）会导致性能下降。现有方法仅使用轮次差异作为过时性度量，这种粗粒度方法缺乏对模型本身的观察，限制了异步方法的性能上限。

Method: 提出FedPSA框架：1）利用参数敏感度（parameter sensitivity）来细粒度衡量模型过时程度；2）建立动态动量队列（dynamic momentum queue）实时评估当前训练阶段；3）动态调整对过时信息的容忍度。

Result: 在多个数据集上的实验表明，FedPSA相比基线方法提升高达6.37%，相比当前最优方法提升1.93%，表现出优越性能。

Conclusion: FedPSA通过细粒度的参数敏感度度量和动态调整机制，有效解决了异步联邦学习中的过时性问题，显著提升了性能表现。

Abstract: Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\% improvement over baseline methods and 1.93\% over the current state-of-the-art method.

</details>


### [101] [Discovering Implicit Large Language Model Alignment Objectives](https://arxiv.org/abs/2602.15338)
*Edward Chen,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.LG

TL;DR: Obj-Disco框架自动将LLM对齐奖励信号分解为可解释的自然语言目标，揭示隐藏的激励，提高AI对齐透明度


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法存在奖励信号不透明、可能遗漏未知风险、无法全面识别因果目标等问题，需要更透明的解释工具

Method: 使用迭代贪婪算法分析训练检查点间的行为变化，识别并验证最能解释剩余奖励信号的候选目标，生成稀疏加权组合

Result: 在多种任务、模型规模和算法中表现稳健，能捕获>90%的奖励行为，成功识别出伴随预期行为出现的潜在错位激励

Conclusion: Obj-Disco为揭示LLM对齐中的隐式目标提供了关键工具，有助于更透明、更安全的AI开发

Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on pre-defined rubrics, risking the omission of "unknown unknowns", or fail to identify objectives that comprehensively cover and are causal to the model behavior. To address these limitations, we introduce Obj-Disco, a framework that automatically decomposes an alignment reward signal into a sparse, weighted combination of human-interpretable natural language objectives. Our approach utilizes an iterative greedy algorithm to analyze behavioral changes across training checkpoints, identifying and validating candidate objectives that best explain the residual reward signal. Extensive evaluations across diverse tasks, model sizes, and alignment algorithms demonstrate the framework's robustness. Experiments with popular open-source reward models show that the framework consistently captures > 90% of reward behavior, a finding further corroborated by human evaluation. Additionally, a case study on alignment with an open-source reward model reveals that Obj-Disco can successfully identify latent misaligned incentives that emerge alongside intended behaviors. Our work provides a crucial tool for uncovering the implicit objectives in LLM alignment, paving the way for more transparent and safer AI development.

</details>


### [102] [ER-MIA: Black-Box Adversarial Memory Injection Attacks on Long-Term Memory-Augmented Large Language Models](https://arxiv.org/abs/2602.15344)
*Mitchell Piehl,Zhaohan Xi,Zuobin Xiong,Pan He,Muchao Ye*

Main category: cs.LG

TL;DR: ER-MIA：首个针对长时记忆增强LLM的黑盒对抗记忆注入攻击系统研究，揭示基于相似性检索机制的根本性安全漏洞


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地配备长时记忆系统以克服有限上下文窗口并实现跨交互的持续推理，研究发现记忆系统为攻击者提供了额外的攻击面，使LLM变得更加脆弱。目前缺乏针对长时记忆增强LLM中相似性检索机制的系统性安全研究。

Method: 提出ER-MIA统一框架，针对基于相似性的检索机制设计黑盒对抗记忆注入攻击。形式化两种现实攻击场景：基于内容的攻击和问题目标攻击。框架包含可组合的攻击原语和集成攻击方法，在最小攻击者假设下实现高成功率。

Result: 在多个LLM和长时记忆系统上的广泛实验表明，基于相似性的检索机制存在根本性和系统级漏洞。攻击成功率很高，且这种安全风险在不同记忆设计和应用场景中持续存在。

Conclusion: 基于相似性的检索机制是长时记忆增强LLM的根本安全漏洞，ER-MIA框架成功暴露了这一系统级脆弱性。研究揭示了跨记忆设计和应用场景持续存在的安全风险，为未来安全增强的记忆系统设计提供了重要参考。

Abstract: Large language models (LLMs) are increasingly augmented with long-term memory systems to overcome finite context windows and enable persistent reasoning across interactions. However, recent research finds that LLMs become more vulnerable because memory provides extra attack surfaces. In this paper, we present the first systematic study of black-box adversarial memory injection attacks that target the similarity-based retrieval mechanism in long-term memory-augmented LLMs. We introduce ER-MIA, a unified framework that exposes this vulnerability and formalizes two realistic attack settings: content-based attacks and question-targeted attacks. In these settings, ER-MIA includes an arsenal of composable attack primitives and ensemble attacks that achieve high success rates under minimal attacker assumptions. Extensive experiments across multiple LLMs and long-term memory systems demonstrate that similarity-based retrieval constitutes a fundamental and system-level vulnerability, revealing security risks that persist across memory designs and application scenarios.

</details>


### [103] [CDRL: A Reinforcement Learning Framework Inspired by Cerebellar Circuits and Dendritic Computational Strategies](https://arxiv.org/abs/2602.15367)
*Sibo Zhang,Rui Jing,Liangfu Lv,Jian Zhang,Yunliang Zang*

Main category: cs.LG

TL;DR: 受小脑结构启发，提出一种生物启发的强化学习架构，通过大规模扩展、稀疏连接、稀疏激活和树突级调制提升样本效率、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在高维序列决策任务中表现优异，但存在样本效率低、对噪声敏感、部分可观测下泛化能力弱等问题。现有方法主要通过优化策略解决这些问题，而架构先验在表征学习和决策动态中的作用较少被探索。受小脑结构原理启发，探索生物启发的架构设计。

Method: 提出基于小脑结构的强化学习架构，包含四大关键特征：大规模扩展、稀疏连接、稀疏激活和树突级调制。在噪声高维强化学习基准上进行实验验证。

Result: 实验表明，小脑架构和树突调制相比传统设计能一致提升样本效率、鲁棒性和泛化能力。架构参数敏感性分析显示，小脑启发的结构能在有限模型参数下提供优化性能。

Conclusion: 小脑结构先验可作为强化学习的有效归纳偏置，生物启发的架构设计对解决强化学习现有局限性具有重要价值。

Abstract: Reinforcement learning (RL) has achieved notable performance in high-dimensional sequential decision-making tasks, yet remains limited by low sample efficiency, sensitivity to noise, and weak generalization under partial observability. Most existing approaches address these issues primarily through optimization strategies, while the role of architectural priors in shaping representation learning and decision dynamics is less explored. Inspired by structural principles of the cerebellum, we propose a biologically grounded RL architecture that incorporate large expansion, sparse connectivity, sparse activation, and dendritic-level modulation. Experiments on noisy, high-dimensional RL benchmarks show that both the cerebellar architecture and dendritic modulation consistently improve sample efficiency, robustness, and generalization compared to conventional designs. Sensitivity analysis of architectural parameters suggests that cerebellum-inspired structures can offer optimized performance for RL with constrained model parameters. Overall, our work underscores the value of cerebellar structural priors as effective inductive biases for RL.

</details>


### [104] [Fractional-Order Federated Learning](https://arxiv.org/abs/2602.15380)
*Mohammad Partohaghighi,Roummel Marcia,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FOFedAvg算法，通过分数阶随机梯度下降引入记忆感知更新，改善联邦学习中的收敛速度、通信效率和异构数据稳定性


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护隐私，但存在收敛慢、通信成本高、非独立同分布数据等问题，需要更鲁棒高效的优化方法

Method: 提出FOFedAvg算法，将分数阶随机梯度下降融入FedAvg框架，利用分数阶导数捕捉长期关系和历史信息，实现记忆感知更新

Result: 在多个基准数据集上，FOFedAvg在测试性能和收敛速度上优于现有联邦优化算法，特别是在非独立同分布数据划分下表现突出

Conclusion: 分数阶记忆感知更新能显著提升联邦学习的鲁棒性和有效性，为异构数据分布式训练提供了实用路径

Abstract: Federated learning (FL) allows remote clients to train a global model collaboratively while protecting client privacy. Despite its privacy-preserving benefits, FL has significant drawbacks, including slow convergence, high communication cost, and non-independent-and-identically-distributed (non-IID) data. In this work, we present a novel FedAvg variation called Fractional-Order Federated Averaging (FOFedAvg), which incorporates Fractional-Order Stochastic Gradient Descent (FOSGD) to capture long-range relationships and deeper historical information. By introducing memory-aware fractional-order updates, FOFedAvg improves communication efficiency and accelerates convergence while mitigating instability caused by heterogeneous, non-IID client data. We compare FOFedAvg against a broad set of established federated optimization algorithms on benchmark datasets including MNIST, FEMNIST, CIFAR-10, CIFAR-100, EMNIST, the Cleveland heart disease dataset, Sent140, PneumoniaMNIST, and Edge-IIoTset. Across a range of non-IID partitioning schemes, FOFedAvg is competitive with, and often outperforms, these baselines in terms of test performance and convergence speed. On the theoretical side, we prove that FOFedAvg converges to a stationary point under standard smoothness and bounded-variance assumptions for fractional order $0<α\le 1$. Together, these results show that fractional-order, memory-aware updates can substantially improve the robustness and effectiveness of federated learning, offering a practical path toward distributed training on heterogeneous data.

</details>


### [105] [Doubly Stochastic Mean-Shift Clustering](https://arxiv.org/abs/2602.15393)
*Tom Trigano,Yann Sepulcre,Itshak Lapidot*

Main category: cs.LG

TL;DR: DSMS通过随机化带宽和数据采样，改进了传统Mean-Shift算法对带宽超参数的敏感性，在稀疏聚类场景中表现出更好的稳定性和防止过分割能力。


<details>
  <summary>Details</summary>
Motivation: 传统Mean-Shift算法对带宽超参数非常敏感，特别是在数据稀缺的情况下，固定尺度的密度估计会导致碎片化和虚假模式的出现。

Method: 提出双重随机Mean-Shift（DSMS），在轨迹更新和核带宽本身都引入随机性。每次迭代从连续均匀分布中抽取数据样本和半径，从而更好地探索密度景观。

Result: 在合成高斯混合数据上的比较实验显示，DSMS显著优于标准和随机Mean-Shift基线，在稀疏聚类场景中表现出卓越的稳定性，防止过分割且没有其他性能下降。

Conclusion: 随机带宽策略起到了隐式正则化机制的作用，DSMS为处理带宽敏感性问题提供了有效解决方案，特别是在数据稀缺的聚类场景中。

Abstract: Standard Mean-Shift algorithms are notoriously sensitive to the bandwidth hyperparameter, particularly in data-scarce regimes where fixed-scale density estimation leads to fragmentation and spurious modes. In this paper, we propose Doubly Stochastic Mean-Shift (DSMS), a novel extension that introduces randomness not only in the trajectory updates but also in the kernel bandwidth itself. By drawing both the data samples and the radius from a continuous uniform distribution at each iteration, DSMS effectively performs a better exploration of the density landscape. We show that this randomized bandwidth policy acts as an implicit regularization mechanism, and provide convergence theoretical results. Comparative experiments on synthetic Gaussian mixtures reveal that DSMS significantly outperforms standard and stochastic Mean-Shift baselines, exhibiting remarkable stability and preventing over-segmentation in sparse clustering scenarios without other performance degradation.

</details>


### [106] [Joint Enhancement and Classification using Coupled Diffusion Models of Signals and Logits](https://arxiv.org/abs/2602.15405)
*Gilad Nurko,Roi Benita,Yehoshua Dissen,Tomohiro Nakatani,Marc Delcroix,Shoko Araki,Joseph Keshet*

Main category: cs.LG

TL;DR: 提出一个联合增强框架，将信号增强和分类耦合，通过两个交互的扩散模型相互指导，提升噪声环境下的分类鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将信号增强和分类作为分离的序列阶段，无法在去噪过程中利用分类器的语义信息，限制了噪声环境下分类的鲁棒性。

Method: 提出一个领域无关的框架，集成两个交互的扩散模型：一个处理输入信号，另一个处理分类器输出logits。引入三种策略来建模输入和logit的联合分布，无需重新训练或微调分类器。

Result: 在图像分类和自动语音识别任务上评估，该框架超越了传统的序列增强基线方法，在多种噪声条件下实现了鲁棒且灵活的分类准确率提升。

Conclusion: 通过耦合信号增强和分类过程，实现相互指导的联合增强框架，显著提升了噪声环境下的分类鲁棒性，为机器学习中的鲁棒分类问题提供了新的解决方案。

Abstract: Robust classification in noisy environments remains a fundamental challenge in machine learning. Standard approaches typically treat signal enhancement and classification as separate, sequential stages: first enhancing the signal and then applying a classifier. This approach fails to leverage the semantic information in the classifier's output during denoising. In this work, we propose a general, domain-agnostic framework that integrates two interacting diffusion models: one operating on the input signal and the other on the classifier's output logits, without requiring any retraining or fine-tuning of the classifier. This coupled formulation enables mutual guidance, where the enhancing signal refines the class estimation and, conversely, the evolving class logits guide the signal reconstruction towards discriminative regions of the manifold. We introduce three strategies to effectively model the joint distribution of the input and the logit. We evaluated our joint enhancement method for image classification and automatic speech recognition. The proposed framework surpasses traditional sequential enhancement baselines, delivering robust and flexible improvements in classification accuracy under diverse noise conditions.

</details>


### [107] [Fairness over Equality: Correcting Social Incentives in Asymmetric Sequential Social Dilemmas](https://arxiv.org/abs/2602.15407)
*Alper Demir,Hüseyin Aydın,Kale-ab Abebe Tessera,David Abel,Stefano V. Albrecht*

Main category: cs.LG

TL;DR: 本文针对传统公平性方法在非对称社会困境中的局限性，提出了三种改进方案：基于奖励范围重新定义公平性、引入智能体权重机制、以及本地化社会反馈，以在非对称条件下促进合作。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多假设智能体在社会困境中面临相同的激励，并需要持续访问全局信息来评估公平性。然而，现实中的智能体往往存在自然差异（非对称性），传统基于公平性的方法在这种条件下难以适应，因为它们强制执行原始平等，反而错误地激励了背叛行为。

Method: 提出了三种关键改进：1）通过考虑智能体的奖励范围重新定义公平性；2）引入基于智能体的权重机制以更好地处理固有的非对称性；3）将社会反馈本地化，使方法在部分可观测性下有效，无需全局信息共享。

Result: 实验结果表明，在非对称场景中，相比现有方法，本文提出的方法能更快地促进合作策略的出现，同时不牺牲可扩展性或实用性。

Conclusion: 本文通过重新定义公平性、引入权重机制和本地化反馈，有效解决了非对称社会困境中传统公平性方法的局限性，为在现实非对称条件下促进多智能体合作提供了更实用的解决方案。

Abstract: Sequential Social Dilemmas (SSDs) provide a key framework for studying how cooperation emerges when individual incentives conflict with collective welfare. In Multi-Agent Reinforcement Learning, these problems are often addressed by incorporating intrinsic drives that encourage prosocial or fair behavior. However, most existing methods assume that agents face identical incentives in the dilemma and require continuous access to global information about other agents to assess fairness. In this work, we introduce asymmetric variants of well-known SSD environments and examine how natural differences between agents influence cooperation dynamics. Our findings reveal that existing fairness-based methods struggle to adapt under asymmetric conditions by enforcing raw equality that wrongfully incentivize defection. To address this, we propose three modifications: (i) redefining fairness by accounting for agents' reward ranges, (ii) introducing an agent-based weighting mechanism to better handle inherent asymmetries, and (iii) localizing social feedback to make the methods effective under partial observability without requiring global information sharing. Experimental results show that in asymmetric scenarios, our method fosters faster emergence of cooperative policies compared to existing approaches, without sacrificing scalability or practicality.

</details>


### [108] [Benchmarking IoT Time-Series AD with Event-Level Augmentations](https://arxiv.org/abs/2602.15457)
*Dmitry Zhevnenko,Ilya Makarov,Aleksandr Kovalenko,Fedor Meshchaninov,Anton Kozhukhov,Vladislav Travnikov,Makar Ippolitov,Kirill Yashunin,Iurii Katser*

Main category: cs.LG

TL;DR: 论文提出针对物联网时间序列异常检测的事件级评估协议，包含多种现实扰动模拟，评估14个模型发现无通用最优模型，不同模型在不同场景下表现各异。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测研究多关注点级结果和精心整理的基础数据集，缺乏对现实世界扰动（如传感器故障、漂移、噪声等）的评估，限制了模型在实际应用中的选择价值。

Method: 引入统一的事件级评估协议，包含校准传感器丢失、线性和对数漂移、加性噪声、窗口偏移等现实扰动模拟；采用传感器级探测（掩码作为缺失值归零）和每通道影响估计支持根因分析；在5个公共数据集和2个工业数据集上评估14个代表性模型。

Result: 无通用最优模型：图结构模型在传感器丢失和长事件下转移性最好；密度/流模型在清洁稳定工厂表现良好但对单调漂移脆弱；谱CNN在周期性强的场景领先；重建自编码器在基本传感器审查后变得有竞争力；预测/混合动态模型在故障破坏时间依赖时有效但窗口敏感。

Conclusion: 评估协议为实际模型选择提供了实用指导，揭示了不同模型在不同现实扰动下的表现差异，并帮助指导设计选择（如替换归一化流为高斯密度会降低性能，固定学习DAG会显著增加漂移敏感性）。

Abstract: Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations. Yet many studies still emphasize point-level results on curated base datasets, limiting value for model selection in practice. We introduce an evaluation protocol with unified event-level augmentations that simulate real-world issues: calibrated sensor dropout, linear and log drift, additive noise, and window shifts. We also perform sensor-level probing via mask-as-missing zeroing with per-channel influence estimation to support root-cause analysis. We evaluate 14 representative models on five public anomaly datasets (SWaT, WADI, SMD, SKAB, TEP) and two industrial datasets (steam turbine, nuclear turbogenerator) using unified splits and event aggregation. There is no universal winner: graph-structured models transfer best under dropout and long events (e.g., on SWaT under additive noise F1 drops 0.804->0.677 for a graph autoencoder, 0.759->0.680 for a graph-attention variant, and 0.762->0.756 for a hybrid graph attention model); density/flow models work well on clean stationary plants but can be fragile to monotone drift; spectral CNNs lead when periodicity is strong; reconstruction autoencoders become competitive after basic sensor vetting; predictive/hybrid dynamics help when faults break temporal dependencies but remain window-sensitive. The protocol also informs design choices: on SWaT under log drift, replacing normalizing flows with Gaussian density reduces high-stress F1 from ~0.75 to ~0.57, and fixing a learned DAG gives a small clean-set gain (~0.5-1.0 points) but increases drift sensitivity by ~8x.

</details>


### [109] [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)
*Yannic Neuhaus,Nicolas Flammarion,Matthias Hein,Francesco Croce*

Main category: cs.LG

TL;DR: 本文提出一个评估框架，用于系统检验CoT推理方法在简单规划任务上的泛化能力，发现CoT能提升分布内泛化，但分布外泛化仍有限，多格式文本推理表现最佳，纯文本模型优于图像输入模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和大视觉语言模型中的推理能力已有显著提升，但推理模型的泛化能力仍然定义模糊且理解不足。本文旨在通过一个简单的规划任务，系统评估CoT方法的泛化能力。

Method: 采用基于网格的导航任务，模型接收地图信息并输出从起点到终点的移动序列。通过不同输入表示（视觉和文本）和CoT推理策略微调模型变体，并在分布内和分布外测试条件下系统评估。

Result: 实验表明：1) CoT推理能提升所有表示下的分布内泛化；2) 控制与ID数据的平凡匹配后，分布外泛化（如更大地图）在多数情况下仍非常有限；3) 结合多种文本格式的推理轨迹在分布外泛化上表现最佳且非平凡；4) 纯文本模型一致优于基于图像输入的模型。

Conclusion: CoT推理能有效提升分布内泛化，但分布外泛化能力仍然有限。多格式文本推理策略在分布外泛化上表现最佳，纯文本表示优于视觉表示，这对未来推理模型的设计具有重要启示。

Abstract: Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigorously examine how well chain-of-thought (CoT) approaches generalize on a simple planning task. Specifically, we consider a grid-based navigation task in which a model is provided with a map and must output a sequence of moves that guides a player from a start position to a goal while avoiding obstacles. The versatility of the task and its data allows us to fine-tune model variants using different input representations (visual and textual) and CoT reasoning strategies, and systematically evaluate them under both in-distribution (ID) and out-of-distribution (OOD) test conditions. Our experiments show that, while CoT reasoning improves in-distribution generalization across all representations, out-of-distribution generalization (e.g., to larger maps) remains very limited in most cases when controlling for trivial matches with the ID data. Surprisingly, we find that reasoning traces which combine multiple text formats yield the best (and non-trivial) OOD generalization. Finally, purely text-based models consistently outperform those utilizing image-based inputs, including a recently proposed approach relying on latent space reasoning.

</details>


### [110] [POP: Prior-fitted Optimizer Policies](https://arxiv.org/abs/2602.15473)
*Jan Kobiolka,Christian Frey,Gresa Shala,Arlind Kadra,Erind Bedalli,Josif Grabocka*

Main category: cs.LG

TL;DR: POP是一种元学习的优化器，通过从包含凸和非凸目标的先验分布中学习，能够预测坐标步长，在47个优化函数基准测试中优于传统梯度方法、进化策略、贝叶斯优化和其他元学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的优化器对超参数选择高度敏感，在高度非凸场景中性能依赖于精心调整的学习率、动量和梯度累积。为了解决这些限制，需要开发更鲁棒的优化方法。

Method: 提出POP（先验拟合优化器策略），这是一种元学习的优化器，根据优化轨迹提供的上下文信息预测坐标步长。模型从包含凸和非凸目标的新先验分布中采样数百万个合成优化问题进行学习。

Result: 在包含47个不同复杂度优化函数的基准测试中，POP在相同预算约束下一致优于一阶梯度方法、非凸优化方法（如进化策略）、贝叶斯优化和最近的元学习竞争对手。

Conclusion: POP展示了强大的泛化能力，无需任务特定调优，为优化问题提供了一种更鲁棒和有效的解决方案。

Abstract: Optimization refers to the task of finding extrema of an objective function. Classical gradient-based optimizers are highly sensitive to hyperparameter choices. In highly non-convex settings their performance relies on carefully tuned learning rates, momentum, and gradient accumulation. To address these limitations, we introduce POP (Prior-fitted Optimizer Policies), a meta-learned optimizer that predicts coordinate-wise step sizes conditioned on the contextual information provided in the optimization trajectory. Our model is learned on millions of synthetic optimization problems sampled from a novel prior spanning both convex and non-convex objectives. We evaluate POP on an established benchmark including 47 optimization functions of various complexity, where it consistently outperforms first-order gradient-based methods, non-convex optimization approaches (e.g., evolutionary strategies), Bayesian optimization, and a recent meta-learned competitor under matched budget constraints. Our evaluation demonstrates strong generalization capabilities without task-specific tuning.

</details>


### [111] [Evaluating Federated Learning for Cross-Country Mood Inference from Smartphone Sensing Data](https://arxiv.org/abs/2602.15478)
*Sharmad Kalpande,Saurabh Shirke,Haroon R. Lone*

Main category: cs.LG

TL;DR: FedFAP：一种特征感知个性化联邦学习框架，用于跨国家智能手机传感数据下的情绪推断，在保护隐私的同时处理异构传感模式，性能优于集中式方法和现有联邦学习基线。


<details>
  <summary>Details</summary>
Motivation: 情绪不稳定是心理健康的关键行为指标，但传统评估依赖不频繁的回顾性报告，无法捕捉其连续性。智能手机移动传感可实现被动情绪推断，但大规模部署面临隐私限制、传感可用性不均和行为模式变异等挑战。

Method: 提出FedFAP（特征感知个性化联邦学习框架），在跨国家联邦学习设置中，每个国家作为独立客户端保留本地数据。该框架专门设计用于处理不同地区间的异构传感模式，实现隐私保护下的个性化学习。

Result: 在跨地理和文化多样化人群的评估中，FedFAP达到AUROC 0.744，优于集中式方法和现有个性化联邦学习基线。结果还提供了情绪感知系统的设计见解。

Conclusion: 研究表明，基于人口感知的个性化和隐私保护学习可以实现可扩展的情绪感知移动传感技术，为心理健康监测提供了新的技术路径。

Abstract: Mood instability is a key behavioral indicator of mental health, yet traditional assessments rely on infrequent and retrospective reports that fail to capture its continuous nature. Smartphone-based mobile sensing enables passive, in-the-wild mood inference from everyday behaviors; however, deploying such systems at scale remains challenging due to privacy constraints, uneven sensing availability, and substantial variability in behavioral patterns.
  In this work, we study mood inference using smartphone sensing data in a cross-country federated learning setting, where each country participates as an independent client while retaining local data. We introduce FedFAP, a feature-aware personalized federated framework designed to accommodate heterogeneous sensing modalities across regions. Evaluations across geographically and culturally diverse populations show that FedFAP achieves an AUROC of 0.744, outperforming both centralized approaches and existing personalized federated baselines. Beyond inference, our results offer design insights for mood-aware systems, demonstrating how population-aware personalization and privacy-preserving learning can enable scalable and mood-aware mobile sensing technologies.

</details>


### [112] [LLM-as-Judge on a Budget](https://arxiv.org/abs/2602.15481)
*Aadirupa Saha,Aniket Wagde,Branislav Kveton*

Main category: cs.LG

TL;DR: 提出一种基于多臂老虎机理论和集中不等式的方差自适应方法，用于在固定计算预算下优化LLM评估中的查询分配，以减少估计误差。


<details>
  <summary>Details</summary>
Motivation: LLM-as-a-judge技术通过多次查询来准确估计提示-响应对的得分，但在固定计算预算下，如何最优分配查询次数以最小化估计误差是一个关键挑战。

Method: 基于多臂老虎机理论和集中不等式的方差自适应方法，根据估计的得分方差动态分配查询，将资源集中在不确定性最高的地方。

Result: 在Summarize-From-Feedback和HelpSteer2数据集上的实验表明，该方法显著优于均匀分配，在相同预算下减少了最坏情况估计误差。

Conclusion: 为高效LLM评估建立了理论基础，对AI安全、模型对齐和大规模自动评估具有实际意义。

Abstract: LLM-as-a-judge has emerged as a cornerstone technique for evaluating large language models by leveraging LLM reasoning to score prompt-response pairs. Since LLM judgments are stochastic, practitioners commonly query each pair multiple times to estimate mean scores accurately. This raises a critical challenge: given a fixed computational budget $B$, how to optimally allocate queries across $K$ prompt-response pairs to minimize estimation error? %
We present a principled variance-adaptive approach leveraging multi-armed bandit theory and concentration inequalities. Our method dynamically allocates queries based on estimated score variances, concentrating resources where uncertainty is highest. Further, our algorithm is shown to achieve a worst-case score-estimation error of $\tilde{O}\left(\sqrt{\frac{\sum_{i=1}^K σ_i^2}{B}}\right)$, $σ_i^2$ being the unknown score variance for pair $i \in [K]$ with near-optimal budget allocation. %
Experiments on \emph{Summarize-From-Feedback} and \emph{HelpSteer2} demonstrate that our method significantly outperforms uniform allocation, reducing worst-case estimation error while maintaining identical budgets. Our work establishes a theoretical foundation for efficient LLM evaluation with practical implications for AI safety, model alignment, and automated assessment at scale.

</details>


### [113] [ExLipBaB: Exact Lipschitz Constant Computation for Piecewise Linear Neural Networks](https://arxiv.org/abs/2602.15499)
*Tom A. Splittgerber*

Main category: cs.LG

TL;DR: 提出LipBaB算法的扩展版本，用于精确计算任意分段线性神经网络和p-范数的Lipschitz常数，支持ReLU、LeakyReLU、GroupSort、MinMax、FullSort、MaxPool等多种激活函数。


<details>
  <summary>Details</summary>
Motivation: Lipschitz常数对神经网络鲁棒性保证、正则化改进和可逆网络构建至关重要。现有精确计算方法仅局限于ReLU激活网络，而ReLU在Lipschitz约束网络中存在严重缺陷。需要一种能处理更广泛激活函数的精确计算方法。

Method: 扩展LipBaB算法，使其能够处理任意分段线性神经网络和p-范数。该方法支持传统激活函数（ReLU、LeakyReLU）以及近年来在Lipschitz约束网络中日益重要的激活函数（GroupSort、MinMax、FullSort），还包括其他分段线性函数如MaxPool。

Result: 提出了首个能够精确计算包含多种分段线性激活函数的神经网络Lipschitz常数的通用算法，突破了现有方法仅限ReLU网络的限制。

Conclusion: 该扩展算法为需要精确Lipschitz常数计算的应用（如新方法基准测试、敏感数据上小模型的鲁棒性保证）提供了更强大的工具，支持更广泛的神经网络架构和激活函数类型。

Abstract: It has been shown that a neural network's Lipschitz constant can be leveraged to derive robustness guarantees, to improve generalizability via regularization or even to construct invertible networks. Therefore, a number of methods varying in the tightness of their bounds and their computational cost have been developed to approximate the Lipschitz constant for different classes of networks. However, comparatively little research exists on methods for exact computation, which has been shown to be NP-hard. Nonetheless, there are applications where one might readily accept the computational cost of an exact method. These applications could include the benchmarking of new methods or the computation of robustness guarantees for small models on sensitive data. Unfortunately, existing exact algorithms restrict themselves to only ReLU-activated networks, which are known to come with severe downsides in the context of Lipschitz-constrained networks. We therefore propose a generalization of the LipBaB algorithm to compute exact Lipschitz constants for arbitrary piecewise linear neural networks and $p$-norms. With our method, networks may contain traditional activations like ReLU or LeakyReLU, activations like GroupSort or the related MinMax and FullSort, which have been of increasing interest in the context of Lipschitz constrained networks, or even other piecewise linear functions like MaxPool.

</details>


### [114] [On the Geometric Coherence of Global Aggregation in Federated GNN](https://arxiv.org/abs/2602.15510)
*Chethana Prasad Kabgere,Shylaja SS*

Main category: cs.LG

TL;DR: 该论文提出了GGRS框架，用于解决联邦图神经网络中由于客户端图结构异质性导致的全局聚合几何失效问题，通过几何可容许性准则调节客户端更新，保持消息传递的一致性。


<details>
  <summary>Details</summary>
Motivation: 在跨域联邦图神经网络中，客户端图具有异构的结构和传播特性。标准的聚合机制应用于这些异构更新时，虽然全局模型可能在数值上收敛，但会表现出退化的关系行为。作者识别了全局聚合的几何失效模式，即聚合来自不兼容传播机制的更新会在变换空间中引入破坏性干扰，导致全局消息传递失去一致性。

Method: 提出了GGRS（全局几何参考结构）框架，这是一个服务器端框架，基于几何可容许性准则在聚合前调节客户端更新。GGRS保持关系变换的方向一致性，维护可容许传播子空间的多样性，并稳定对邻域交互的敏感性，同时不访问客户端数据或图拓扑。

Result: 在异构的GNN原生数据集和Amazon Co-purchase数据集上的实验表明，GGRS在训练轮次中保持了全局消息传递的一致性，突出了在联邦图学习中几何感知调节的必要性。

Conclusion: 该工作强调了在联邦图神经网络中考虑几何特性的重要性，提出的GGRS框架有效解决了全局聚合中的几何失效问题，为跨域联邦图学习提供了几何感知的调节机制。

Abstract: Federated Learning (FL) enables distributed training across multiple clients without centralized data sharing, while Graph Neural Networks (GNNs) model relational data through message passing. In federated GNN settings, client graphs often exhibit heterogeneous structural and propagation characteristics. When standard aggregation mechanisms are applied to such heterogeneous updates, the global model may converge numerically while exhibiting degraded relational behavior.Our work identifies a geometric failure mode of global aggregation in Cross- Domain Federated GNNs. Although GNN parameters are numerically represented as vectors, they encode relational transformations that govern the direction, strength, and sensitivity of information flow across graph neighborhoods. Aggregating updates originating from incompatible propagation regimes can therefore introduce destructive interference in this transformation space.This leads to loss of coherence in global message passing. Importantly, this degradation is not necessarily reflected in conventional metrics such as loss or accuracy.To address this issue, we propose GGRS (Global Geometric Reference Structure), a server-side framework that regulates client updates prior to aggregation based on geometric admissibility criteria. GGRS preserves directional consistency of relational transformations as well as maintains diversity of admissible propagation subspaces. It also stabilizes sensitivity to neighborhood interactions, without accessing client data or graph topology. Experiments on heterogeneous GNN-native, Amazon Co-purchase datasets demonstrate that GGRS preserves global message-passing coherence across training rounds by highlighting the necessity of geometry-aware regulation in federated graph learning.

</details>


### [115] [The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes](https://arxiv.org/abs/2602.15515)
*Mohammad Taufeeque,Stefan Heimersheim,Adam Gleave,Chris Cundy*

Main category: cs.LG

TL;DR: 训练对抗白盒欺骗检测器可能导致模型学会通过两种策略来混淆欺骗：混淆激活或混淆策略，但在足够的KL正则化和检测器惩罚下，可以获得诚实策略。


<details>
  <summary>Details</summary>
Motivation: 研究在现实编码环境中训练对抗白盒欺骗检测器时，模型是否会学会混淆欺骗以逃避检测，以及如何防止这种情况发生。

Method: 构建现实编码环境，让模型通过硬编码测试用例进行奖励黑客行为，引入欺骗结果分类法，通过RL训练分析不同策略的出现条件。

Result: 发现模型会通过两种混淆策略逃避检测：混淆激活（修改内部表示）和混淆策略（输出包含理由的欺骗文本）。混淆激活来自RL中的表示漂移，混淆策略由检测器惩罚激励。

Conclusion: 足够高的KL正则化和检测器惩罚可以产生诚实策略，表明白盒欺骗检测器可以作为易受奖励黑客攻击任务的可行训练信号。

Abstract: Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.

</details>


### [116] [CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals](https://arxiv.org/abs/2602.15546)
*Tomàs Garriga,Gerard Sanz,Eduard Serrahima de Cambra,Axel Brando*

Main category: cs.LG

TL;DR: 本文提出了一种针对时间序列数据的反事实推理方法CEPAE，通过熵惩罚自编码器学习解耦表示，在合成和真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在金融、医疗、营销等领域，准确的时间序列反事实推理对决策至关重要，能够理解事件或干预对时间序列结果的影响。本文受工业应用驱动，针对市场事件影响的时间序列数据开发反事实推理方法。

Method: 基于结构因果模型框架和溯因-行动-预测流程，首先将变分自编码器和对抗自编码器方法适配到时间序列设置，然后提出条件熵惩罚自编码器（CEPAE），通过在潜在空间使用熵惩罚损失来鼓励解耦的数据表示。

Result: 在合成、半合成和真实世界数据集上的实验验证表明，CEPAE在评估指标上通常优于其他方法。

Conclusion: CEPAE是一种有效的自编码器反事实推理方法，通过熵惩罚促进解耦表示，在时间序列反事实推理任务中表现优异。

Abstract: The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.

</details>


### [117] [GLM-5: from Vibe Coding to Agentic Engineering](https://arxiv.org/abs/2602.15763)
*GLM-5 Team,:,Aohan Zeng,Xin Lv,Zhenyu Hou,Zhengxiao Du,Qinkai Zheng,Bin Chen,Da Yin,Chendi Ge,Chengxing Xie,Cunxiang Wang,Gengzheng Pan,Hao Zeng,Haoke Zhang,Haoran Wang,Huilong Chen,Jiajie Zhang,Jian Jiao,Jiaqi Guo,Jingsen Wang,Jingzhao Du,Jinzhu Wu,Kedong Wang,Lei Li,Lin Fan,Lucen Zhong,Mingdao Liu,Mingming Zhao,Pengfan Du,Qian Dong,Rui Lu,Shuang-Li,Shulin Cao,Song Liu,Ting Jiang,Xiaodong Chen,Xiaohan Zhang,Xuancheng Huang,Xuezhen Dong,Yabo Xu,Yao Wei,Yifan An,Yilin Niu,Yitong Zhu,Yuanhao Wen,Yukuo Cen,Yushi Bai,Zhongpei Qiao,Zihan Wang,Zikang Wang,Zilin Zhu,Ziqiang Liu,Zixuan Li,Bojie Wang,Bosi Wen,Can Huang,Changpeng Cai,Chao Yu,Chen Li,Chen Li,Chenghua Huang,Chengwei Hu,Chenhui Zhang,Chenzheng Zhu,Congfeng Yin,Daoyan Lin,Dayong Yang,Di Wang,Ding Ai,Erle Zhu,Fangzhou Yi,Feiyu Chen,Guohong Wen,Hailong Sun,Haisha Zhao,Haiyi Hu,Hanchen Zhang,Hanrui Liu,Hanyu Zhang,Hao Peng,Hao Tai,Haobo Zhang,He Liu,Hongwei Wang,Hongxi Yan,Hongyu Ge,Huan Liu,Huan Liu,Huanpeng Chu,Jia'ni Zhao,Jiachen Wang,Jiajing Zhao,Jiamin Ren,Jiapeng Wang,Jiaxin Zhang,Jiayi Gui,Jiayue Zhao,Jijie Li,Jing An,Jing Li,Jingwei Yuan,Jinhua Du,Jinxin Liu,Junkai Zhi,Junwen Duan,Kaiyue Zhou,Kangjian Wei,Ke Wang,Keyun Luo,Laiqiang Zhang,Leigang Sha,Liang Xu,Lindong Wu,Lintao Ding,Lu Chen,Minghao Li,Nianyi Lin,Pan Ta,Qiang Zou,Rongjun Song,Ruiqi Yang,Shangqing Tu,Shangtong Yang,Shaoxiang Wu,Shengyan Zhang,Shijie Li,Shuang Li,Shuyi Fan,Wei Qin,Wei Tian,Weining Zhang,Wenbo Yu,Wenjie Liang,Xiang Kuang,Xiangmeng Cheng,Xiangyang Li,Xiaoquan Yan,Xiaowei Hu,Xiaoying Ling,Xing Fan,Xingye Xia,Xinyuan Zhang,Xinze Zhang,Xirui Pan,Xunkai Zhang,Yandong Wu,Yanfu Li,Yidong Wang,Yifan Zhu,Yijun Tan,Yilin Zhou,Yiming Pan,Ying Zhang,Yinpei Su,Yipeng Geng,Yipeng Geng,Yong Yan,Yonglin Tan,Yuean Bi,Yuhan Shen,Yuhao Yang,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yurong Wu,Yutao Zhang,Yuxi Duan,Yuxuan Zhang,Zezhen Liu,Zhengtao Jiang,Zhenhe Yan,Zheyu Zhang,Zhixiang Wei,Zhuo Chen,Zhuoer Feng,Zijun Yao,Ziwei Chai,Ziyuan Wang,Zuzhou Zhang,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.LG

TL;DR: GLM-5是一个下一代基础模型，旨在从氛围编码转向代理工程，通过DSA降低训练和推理成本，采用异步强化学习提升对齐和自主性，在开放基准测试中达到SOTA，在真实世界编码任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 将AI范式从"氛围编码"（vibe coding）转向"代理工程"（agentic engineering），构建能够处理端到端软件工程挑战的下一代基础模型。

Method: 1. 采用DSA（未详细说明）显著降低训练和推理成本，同时保持长上下文保真度；2. 实现新的异步强化学习基础设施，通过解耦生成和训练提高后训练效率；3. 提出新颖的异步代理RL算法，提升强化学习质量，使模型能更有效地从复杂、长视野的交互中学习。

Result: 在主要开放基准测试中达到最先进的性能；在真实世界编码任务中展现出前所未有的能力，在处理端到端软件工程挑战方面超越了之前的基线模型。

Conclusion: GLM-5成功实现了从氛围编码到代理工程的范式转变，通过创新的训练架构和算法在编码能力上取得了突破性进展，为实际软件工程应用提供了强大的AI基础模型。

Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.

</details>


### [118] [1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization](https://arxiv.org/abs/2602.15563)
*Sohir Maskey,Constantin Eichenberg,Johannes Messner,Douglas Orr*

Main category: cs.LG

TL;DR: 该论文通过实证研究发现，在低比特量化训练中，k-means权重量化优于整数格式，且在固定推理内存预算下，1比特权重量化在生成下游任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 量化感知训练(QAT)能显著减少LLMs内存占用，但实际应用中量化格式和比特宽度的选择存在挑战。当前量化设计空间未充分探索，量化与下游性能的权衡关系不明确，且评估常依赖困惑度指标。

Method: 在低比特量化领域进行实证研究，比较k-means权重量化与整数格式的性能差异，并在标准硬件上实现高效部署。

Result: k-means权重量化优于整数格式；在固定推理内存预算下，1比特权重量化在生成下游任务中达到最佳性能。

Conclusion: 该研究为低比特量化训练提供了实证指导，表明k-means量化和1比特权重量化在保持性能的同时能有效减少内存占用。

Abstract: Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.

</details>


### [119] [Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment](https://arxiv.org/abs/2602.15571)
*Davide Casnici,Martin Lefebvre,Justin Dauwels,Charlotte Frenkel*

Main category: cs.LG

TL;DR: 提出DKP-PC算法，通过可学习的反馈连接直接从输出层到所有隐藏层，解决预测编码中误差信号传播延迟和指数衰减问题，将误差传播时间复杂度从O(L)降至O(1)


<details>
  <summary>Details</summary>
Motivation: 预测编码(PC)作为生物启发的神经网络训练算法，虽然支持局部更新和跨层并行学习，但在实际应用中面临两个关键限制：误差信号需要通过多个推理步骤从输出层传播到早期层，且反馈信号在此过程中呈指数衰减，导致早期层更新消失

Method: 提出直接Kolen-Pollack预测编码(DKP-PC)，结合直接反馈对齐和直接Kolen-Pollack算法，引入从输出层到所有隐藏层的可学习反馈连接，建立误差传输的直接通路

Result: DKP-PC将理论误差传播时间复杂度从O(L)降至O(1)，消除了误差信号的深度依赖延迟。实验结果表明，DKP-PC性能至少与标准PC相当，且通常更优，同时提供更低的延迟和更好的计算性能

Conclusion: DKP-PC同时解决了反馈延迟和指数衰减问题，产生了更高效、可扩展的PC变体，同时保持了更新局部性，支持定制硬件高效实现

Abstract: Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.

</details>


### [120] [Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model](https://arxiv.org/abs/2602.15572)
*M Lopes Alves,Joel Dyer,Doyne Farmer,Michael Wooldridge,Anisoara Calinescu*

Main category: cs.LG

TL;DR: 该研究评估了基于神经网络的模拟推理框架在大型劳动力市场ABM参数估计中的应用，证明其相比传统贝叶斯方法更高效且能准确恢复原始参数。


<details>
  <summary>Details</summary>
Motivation: 虽然基于代理的建模（ABM）在模拟复杂系统方面应用广泛，但大规模ABM中的参数估计面临计算约束，限制了其作为决策支持工具的使用。本研究旨在解决这一挑战。

Method: 采用最先进的基于模拟推理（SBI）框架，使用神经网络进行参数估计。将该框架应用于基于工作转换网络的劳动力市场ABM，使用合成数据集和真实美国劳动力市场数据初始化，并比较传统统计量摘要与神经网络学习摘要的效果。

Result: 神经网络方法在不同规模数据集下都能通过后验分布准确恢复原始参数，相比传统贝叶斯方法提高了效率。

Conclusion: 基于神经网络的SBI框架为大规模ABM参数估计提供了有效解决方案，能够克服传统方法的计算限制，提升ABM作为决策支持工具的实际应用价值。

Abstract: Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.

</details>


### [121] [A unified theory of feature learning in RNNs and DNNs](https://arxiv.org/abs/2602.15593)
*Jan P. Bauer,Kirsten Fischer,Moritz Helias,Agostina Palmigiano*

Main category: cs.LG

TL;DR: 该论文通过统一的平均场理论，揭示了RNN和DNN在功能特性上的差异主要源于权重共享，并识别了相位转变和归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 尽管RNN和DNN在结构上仅通过权重共享区分（通过时间展开可见），但它们表现出不同的功能特性。研究旨在理解这种结构相似性与功能差异之间的关系，探索权重共享如何影响网络的功能特性。

Method: 开发了RNN和DNN的统一平均场理论，使用表征核来描述在特征学习（μP）机制下完全训练的网络。该理论将训练视为对序列和模式的贝叶斯推断，直接揭示RNN权重共享的功能含义。

Result: 在DNN典型任务中，识别了相位转变：当学习信号克服权重随机性产生的噪声时，RNN和DNN行为相同；超过该阈值后，只有RNN能在时间步之间发展相关表示。对于序列任务，RNN的权重共享还诱导了归纳偏置，通过插值无监督时间步来帮助泛化。

Conclusion: 该理论提供了一种将架构结构连接到功能偏置的方法，揭示了权重共享如何导致RNN和DNN在功能特性上的根本差异，特别是在序列处理和表示学习方面。

Abstract: Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.

</details>


### [122] [Multi-Objective Coverage via Constraint Active Search](https://arxiv.org/abs/2602.15595)
*Zakaria Shams Siam,Xuefeng Liu,Chong Liu*

Main category: cs.LG

TL;DR: 提出多目标覆盖(MOC)问题，旨在识别能广泛覆盖可行多目标空间的小规模代表性样本集，应用于药物发现和材料设计等关键领域，以加速科学发现过程。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和材料设计等关键应用中，需要快速评估大量样本。现有方法要么关注样本空间覆盖，要么专注于帕累托前沿的多目标优化，无法直接解决多目标空间覆盖问题。化学多样性样本可能产生相同的目标特征，且安全约束通常定义在目标上。

Method: 提出MOC-CAS搜索算法，采用基于上置信界的获取函数，在高斯过程后验预测指导下选择乐观样本。为高效优化，开发了硬可行性测试的平滑松弛方法并推导近似优化器。

Result: 在SARS-CoV-2和癌症相关的大规模蛋白质靶点数据集上评估，每个数据集基于SMILES特征评估五个目标。与竞争基线相比，MOC-CAS在经验上表现出优越性能。

Conclusion: MOC-CAS算法有效解决了多目标覆盖问题，能够识别广泛覆盖可行多目标空间的小规模代表性样本集，显著加速药物发现和材料设计等科学发现过程。

Abstract: In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse samples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predictions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features.

</details>


### [123] [DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness](https://arxiv.org/abs/2602.15617)
*Kaifeng Lu,Markus Rupp,Stefan Schwarz*

Main category: cs.LG

TL;DR: 提出基于无线变压器架构的优化无监督学习方法，通过拉格朗日乘子自动更新机制，在保证规定公平性的同时最大化总速率，实现帕累托前沿上的可控权衡。


<details>
  <summary>Details</summary>
Motivation: 无线通信中的用户公平性保障是一个基本挑战，因为公平性与总速率之间的权衡导致非凸、多目标优化问题，其复杂度随网络规模增长而增加。

Method: 基于无线变压器架构的优化无监督学习方法，通过拉格朗日乘子将总速率和公平性目标结合，采用对偶上升算法自动更新乘子，实现可控公平性约束下的总速率最大化。

Result: 该方法能够在规定公平性要求下灵活管理权衡优化，有效实现两个冲突目标之间的帕累托前沿追踪。

Conclusion: 所提出的方法为在规定的公平性约束下管理权衡优化提供了灵活的解决方案，通过自动调整机制平衡公平性与总速率性能。

Abstract: Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.

</details>


### [124] [Beyond ReLU: Bifurcation, Oversmoothing, and Topological Priors](https://arxiv.org/abs/2602.15634)
*Erkan Turan,Gaspard Abel,Maysam Behmanesh,Emery Pierson,Maks Ovsjanikov*

Main category: cs.LG

TL;DR: 该论文从分岔理论角度重新审视GNN过平滑问题，提出通过替换激活函数来破坏同质稳定点，从而抵抗过平滑。


<details>
  <summary>Details</summary>
Motivation: 深度图神经网络存在过平滑问题，节点特征会收敛到同质的、无信息的状态。作者希望从分岔理论角度重新理解这一现象，并找到解决方案。

Method: 使用分岔理论框架，将过平滑问题重新定义为向稳定"同质固定点"的收敛。通过用特定函数类替换标准单调激活函数（如ReLU），利用Lyapunov-Schmidt约简分析证明这种替换会诱导分岔，破坏同质状态的稳定性。

Result: 理论发现替换激活函数会诱导分岔，破坏同质稳定点，产生一对稳定的、非同质的模式，这些模式能够抵抗过平滑。理论预测了这些涌现模式的精确非平凡缩放规律，并在实验中得到了定量验证。

Conclusion: 该研究从分岔理论角度为GNN过平滑问题提供了新的理论框架，不仅解释了过平滑现象，还提出了有效的解决方案。通过推导出封闭形式的分岔感知初始化方法，在实际基准实验中展示了其实际效用。

Abstract: Graph Neural Networks (GNNs) learn node representations through iterative network-based message-passing. While powerful, deep GNNs suffer from oversmoothing, where node features converge to a homogeneous, non-informative state. We re-frame this problem of representational collapse from a \emph{bifurcation theory} perspective, characterizing oversmoothing as convergence to a stable ``homogeneous fixed point.'' Our central contribution is the theoretical discovery that this undesired stability can be broken by replacing standard monotone activations (e.g., ReLU) with a class of functions. Using Lyapunov-Schmidt reduction, we analytically prove that this substitution induces a bifurcation that destabilizes the homogeneous state and creates a new pair of stable, non-homogeneous \emph{patterns} that provably resist oversmoothing. Our theory predicts a precise, nontrivial scaling law for the amplitude of these emergent patterns, which we quantitatively validate in experiments. Finally, we demonstrate the practical utility of our theory by deriving a closed-form, bifurcation-aware initialization and showing its utility in real benchmark experiments.

</details>


### [125] [The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems](https://arxiv.org/abs/2602.15637)
*Amirreza Dolatpour Fathkouhi,Alireza Namazi,Heman Shakeri*

Main category: cs.LG

TL;DR: 论文指出时间序列插值基准存在"平稳性偏差"，并提出分层压力测试方法，在CGM数据上验证了线性方法在平稳区间有效但在关键瞬态表现差，而深度学习模型在瞬态保持形态完整性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列插值基准使用均匀随机掩码和形状无关指标（MSE、RMSE），在具有主导吸引子的系统中（如稳态生理、工业运行、网络流量）会产生系统性"平稳性偏差"——简单方法因主要采样低熵平稳区间而显得优越，但无法评估关键瞬态的性能。

Method: 提出分层压力测试方法，将评估划分为平稳和瞬态两种机制；使用连续血糖监测（CGM）作为测试平台，利用其精确的地面真实强迫函数（饮食、胰岛素）进行机制识别；从临床试验中推导经验缺失分布并应用于完整训练数据，防止模型利用不现实的干净观测。

Result: 1) 平稳效率：线性插值在稳定区间达到最先进的重建效果；2) 瞬态保真度：线性方法在关键瞬态（餐后峰值、低血糖事件）表现出严重退化的形态保真度，存在"RMSE幻象"；3) 机制条件模型选择：深度学习模型在瞬态保持点准确性和形态完整性。

Conclusion: 该框架适用于任何常规平稳性主导关键瞬态的受调控系统，强调了机制条件评估的重要性，深度学习模型对于安全关键的下游任务至关重要，而线性方法在低熵平稳区间足够有效。

Abstract: Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systematic \emph{Stationarity Bias}: simple methods appear superior because the benchmark predominantly samples the easy, low-entropy regime where they trivially succeed. We formalize this bias and propose a \emph{Stratified Stress-Test} that partitions evaluation into Stationary and Transient regimes. Using Continuous Glucose Monitoring (CGM) as a testbed -- chosen for its rigorous ground-truth forcing functions (meals, insulin) that enable precise regime identification -- we establish three findings with broad implications:(i)~Stationary Efficiency: Linear interpolation achieves state-of-the-art reconstruction during stable intervals, confirming that complex architectures are computationally wasteful in low-entropy regimes.(ii)~Transient Fidelity: During critical transients (post-prandial peaks, hypoglycemic events), linear methods exhibit drastically degraded morphological fidelity (DTW), disproportionate to their RMSE -- a phenomenon we term the \emph{RMSE Mirage}, where low pointwise error masks the destruction of signal shape.(iii)~Regime-Conditional Model Selection: Deep learning models preserve both pointwise accuracy and morphological integrity during transients, making them essential for safety-critical downstream tasks. We further derive empirical missingness distributions from clinical trials and impose them on complete training data, preventing models from exploiting unrealistically clean observations and encouraging robustness under real-world missingness. This framework generalizes to any regulated system where routine stationarity dominates critical transients.

</details>


### [126] [Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design](https://arxiv.org/abs/2602.15648)
*Jens U. Kreber,Christian Weißenfels,Joerg Stueckler*

Main category: cs.LG

TL;DR: 提出基于扩散模型的逆设计方法，通过连续网格表示和可微分模拟，在复合材料设计中生成满足目标体积模量的多样化设计方案。


<details>
  <summary>Details</summary>
Motivation: 逆设计问题在工程和材料科学中常见，但设计空间通常包含离散参数和约束，难以直接使用基于梯度的优化方法。此外，多个设计参数可能产生相同或相似的输出值，需要多模态概率方法来获得多样化解决方案。

Method: 1) 将原始设计空间松弛为连续网格表示，通过隐式微分计算梯度；2) 在松弛参数空间上训练扩散模型作为先验；3) 使用可微分模拟传播的梯度进行引导扩散采样；4) 通过反向投影获得原始参数空间的设计样本。

Result: 在复合材料设计问题中，该方法能够在2D和3D设置中，为中高目标体积模量生成相对误差在1%以内的多样化设计。同时，通过多目标损失函数可以最小化生成样本的材料密度。

Conclusion: 提出的基于扩散模型的逆设计方法能够有效处理具有离散参数和约束的设计空间，生成满足特定性能目标的多样化设计方案，为工程和材料科学中的逆设计问题提供了新解决方案。

Abstract: Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.

</details>


### [127] [Continuous-Time Piecewise-Linear Recurrent Neural Networks](https://arxiv.org/abs/2602.15649)
*Alena Brändle,Lukas Eisenmann,Florian Götz,Daniel Durstewitz*

Main category: cs.LG

TL;DR: 提出连续时间分段线性循环神经网络(cPLRNN)，解决传统离散时间PLRNN与物理生物过程连续时间性质不匹配的问题，同时保持数学可分析性


<details>
  <summary>Details</summary>
Motivation: 现有PLRNN都是离散时间映射，与大多数物理和生物过程的连续时间性质不符，且难以处理不规则时间间隔数据。神经ODE虽然解决连续时间问题，但在动态系统重建性能和可分析性上不如PLRNN

Method: 开发连续时间PLRNN理论，提出新的训练和模拟算法，通过有效利用分段线性结构绕过数值积分。展示如何半解析地确定重要拓扑对象如平衡点或极限环

Result: 在动态系统重建基准测试中，cPLRNN与离散时间PLRNN和神经ODE进行比较，包括具有硬阈值的不连续系统

Conclusion: cPLRNN结合了连续时间建模的优势和PLRNN的数学可分析性，为科学和医学领域的动态系统重建提供了更合适的工具

Abstract: In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In scientific and medical areas, in particular, these models need to be mechanistically tractable -- through their mathematical analysis we would like to obtain insight into the recovered system's workings. Piecewise-linear (PL), ReLU-based RNNs (PLRNNs) have a strong track-record in this regard, representing SOTA DSR models while allowing mathematical insight by virtue of their PL design. However, all current PLRNN variants are discrete-time maps. This is in disaccord with the assumed continuous-time nature of most physical and biological processes, and makes it hard to accommodate data arriving at irregular temporal intervals. Neural ODEs are one solution, but they do not reach the DSR performance of PLRNNs and often lack their tractability. Here we develop theory for continuous-time PLRNNs (cPLRNNs): We present a novel algorithm for training and simulating such models, bypassing numerical integration by efficiently exploiting their PL structure. We further demonstrate how important topological objects like equilibria or limit cycles can be determined semi-analytically in trained models. We compare cPLRNNs to both their discrete-time cousins as well as Neural ODEs on DSR benchmarks, including systems with discontinuities which come with hard thresholds.

</details>


### [128] [Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry](https://arxiv.org/abs/2602.15676)
*Deniz Kucukahmetler,Maximilian Jean Hemmann,Julian Mosig von Aehrenfeld,Maximilian Amthor,Christian Deubel,Nico Scherf,Diaaeldin Taha*

Main category: cs.LG

TL;DR: 论文通过相对嵌入方法研究神经网络如何内部表示动力系统，发现不同模型家族（MLP、RNN、Transformer等）在潜在空间中对齐模式存在系统性差异，对齐度与预测精度相关但不完全一致。


<details>
  <summary>Details</summary>
Motivation: 神经网络能够准确预测复杂动力系统，但其内部如何表示潜在的几何结构仍不清楚。需要研究神经网络预测器如何内部表示动力系统的潜在几何结构，理解不同模型家族在表示学习上的差异。

Method: 引入基于锚点的、几何无关的相对嵌入方法，消除潜在空间中的旋转和缩放模糊性。在七个典型动力系统（从周期性到混沌系统）上应用该框架，分析多层感知机、循环神经网络、Transformer和回声状态网络等不同模型家族的表示对齐模式。

Result: 发现可重复的家族级结构：多层感知机与其他MLP对齐，循环网络与RNN对齐，而Transformer和回声状态网络虽然预测能力强，但对齐度较弱。对齐度通常与预测精度相关，但高精度可以与低对齐度共存。

Conclusion: 相对几何为比较不同模型家族如何内部化和表示动力结构提供了一个简单、可重复的基础框架，揭示了神经网络表示学习中的系统性模式。

Abstract: Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.

</details>


### [129] [CAMEL: An ECG Language Model for Forecasting Cardiac Events](https://arxiv.org/abs/2602.15677)
*Neelay Velingker,Alaia Solko-Breslin,Mayank Keoliya,Seewon Choi,Jiayi Xin,Anika Marathe,Alireza Oraii,Rajat Deo,Sameed Khatana,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAMEL是首个能够进行长期信号推理和心律失常预测的ECG语言模型，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有ECG语言模型虽然能进行分类和报告生成，但无法预测未来心脏事件，而这对早期干预具有重要临床价值

Method: 提出专门的ECG编码器实现心电信号与文本的跨模态理解，采用LoRA适应和课程学习管道训练，包括ECG分类、指标计算和多轮对话推理

Result: 在6个任务和9个数据集上表现出强大的零样本性能，在ECGBench上获得+7.0%绝对平均增益，在ECGForecastBench上比全监督模型高+12.4%，比零样本ELMs高+21.1%

Conclusion: CAMEL是首个具备长期信号推理和心律失常预测能力的ECG语言模型，在分布内和分布外都达到或超越了现有ELMs和全监督基线

Abstract: Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).

</details>


### [130] [Random Wavelet Features for Graph Kernel Machines](https://arxiv.org/abs/2602.15711)
*Valentin de Bassompierre,Jean-Charles Delvenne,Laurent Jacques*

Main category: cs.LG

TL;DR: 提出随机谱节点嵌入方法，通过随机特征技术近似图核，实现更准确且可扩展的图表示学习。


<details>
  <summary>Details</summary>
Motivation: 图核能提供节点相似性的理论定义，但直接计算在大规模网络上计算成本过高。需要一种既能保持图核的理论优势，又能实现高效计算的方法。

Method: 受欧氏空间中核近似随机特征方法的启发，提出随机谱节点嵌入方法。该方法通过随机谱构造生成节点嵌入，其点积能够估计特定图核的低秩近似。

Result: 理论分析和实验结果表明，该方法比现有方法能更准确地近似图核，特别是在谱局部化核上表现更优。证明了随机谱构造在可扩展图表示学习中的有效性。

Conclusion: 随机谱节点嵌入方法为大规模图学习提供了既具有理论保证又计算高效的解决方案，在节点分类、链接预测和信号重建等任务中具有应用价值。

Abstract: Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.

</details>


### [131] [MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2602.15740)
*Fatemeh Khalvandi,Saadat Izadi,Abdolah Chalechale*

Main category: cs.LG

TL;DR: 提出MRC-GAT模型，通过copula相似性对齐、关系注意力和节点融合，结合元学习进行阿尔茨海默病多模态分类，在TADPOLE和NACC数据集上达到96.87%和92.31%的准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病需要早期精确诊断，现有图模型依赖固定结构设计，缺乏灵活性且难以泛化到异质患者数据。

Method: 提出Meta-Relational Copula-Based Graph Attention Network (MRC-GAT)，整合copula相似性对齐、关系注意力和节点融合作为元学习核心组件，将风险因素、认知测试分数和MRI特征通过copula变换对齐到统一统计空间，再通过多关系注意力机制融合。

Result: 在TADPOLE和NACC数据集上分别达到96.87%和92.31%的准确率，优于现有诊断模型，展现了最先进的性能。

Conclusion: MRC-GAT模型通过提供疾病诊断各阶段的可解释性，证实了方法的鲁棒性和适用性，为阿尔茨海默病诊断提供了有效的多模态解决方案。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.

</details>


### [132] [UrbanVerse: Learning Urban Region Representation Across Cities and Tasks](https://arxiv.org/abs/2602.15750)
*Fengze Sun,Egemen Tanin,Shanika Karunasekera,Zuqing Li,Flora D. Salim,Jianzhong Qi*

Main category: cs.LG

TL;DR: UrbanVerse：一个用于跨城市表示学习和跨任务城市分析的基础模型，通过随机游走生成区域序列，并结合条件扩散模块实现多任务联合建模。


<details>
  <summary>Details</summary>
Motivation: 现有城市区域表示学习方法在城市间和任务间的泛化能力有限，需要构建一个基础模型来支持跨城市、跨任务的城市分析。

Method: 1) 将区域建模为图节点，通过随机游走生成反映局部和邻域结构特征的"区域序列"；2) 提出HCondDiffCT模块，将区域条件先验知识和任务条件语义整合到扩散过程中，联合建模多个下游预测任务。

Result: 在真实数据集上的实验表明，UrbanVerse在跨城市设置的六个任务中始终优于最先进方法，预测准确率最高提升35.89%。

Conclusion: UrbanVerse成功构建了一个基础模型，能够有效实现跨城市表示学习和跨任务城市分析，为城市分析提供了更通用的解决方案。

Abstract: Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form "sequences of regions" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.

</details>


### [133] [Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching](https://arxiv.org/abs/2602.15752)
*Ren Kishimoto,Rikiya Takehi,Koichi Tanaka,Masahiro Nomura,Riku Togashi,Yoji Tomita,Yuta Saito*

Main category: cs.LG

TL;DR: 提出MRet算法，通过动态学习个性化留存曲线来最大化双边匹配平台的用户留存率，而非传统方法关注的匹配数量或公平性。


<details>
  <summary>Details</summary>
Motivation: 传统双边匹配平台（如在线约会和招聘）通常以最大化匹配数量为目标，但这会导致用户匹配分布不均：部分用户获得过多匹配，而许多其他用户获得很少匹配并最终流失。对于依赖订阅的平台来说，用户留存至关重要。虽然公平性目标可以解决匹配最大化的问题，但公平本身并非平台的最终目标，用户不会仅仅因为曝光均等化就奖励平台。在实践中，用户留存通常是最终目标，简单地依赖公平性会让留存优化变得随机。

Method: 提出MRet（Matching for Retention）算法，这是一种动态学习排序方法。不同于传统的双边匹配算法，MRet通过学习每个用户的个人资料和交互历史来建模个性化留存曲线。基于这些曲线，MRet动态调整推荐策略，联合考虑接收推荐用户和被推荐用户的留存收益，从而将有限的匹配机会分配到最能提高整体留存的地方。

Result: 在合成数据集和来自主要在线约会平台的真实数据集上的实证评估表明，MRet实现了更高的用户留存率，因为传统方法优化的是匹配数量或公平性，而不是留存。

Conclusion: 本文正式定义了双边匹配平台中最大化用户留存的新问题设置，并提出MRet算法来解决这一问题。通过建模个性化留存曲线并动态调整推荐策略，MRet能够更有效地分配匹配机会以提高整体用户留存，为依赖用户留存的双边匹配平台提供了更实用的优化方法。

Abstract: On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck.
  In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.

</details>


### [134] [The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety](https://arxiv.org/abs/2602.15799)
*Max Springer,Chung Peng Lee,Blossom Metevier,Jane Castleman,Bohdan Turbal,Hayoung Jung,Zeyu Shen,Aleksandra Korolova*

Main category: cs.LG

TL;DR: 微调对齐的语言模型即使在良性任务上也会意外破坏安全护栏，这是由于对齐几何的低维子空间具有尖锐曲率，导致梯度下降的二阶加速效应将优化轨迹推入安全敏感区域。


<details>
  <summary>Details</summary>
Motivation: 当前安全微调方法存在结构性盲点：即使训练数据无害且开发者无恶意意图，微调对齐的语言模型仍会不可预测地破坏安全护栏。现有解释（微调更新应正交于安全关键方向）提供了虚假保证，需要深入理解这一现象的根本机制。

Method: 通过新颖的几何分析，证明对齐集中在具有尖锐曲率的低维子空间中，形成梯度下降无法检测或防御的脆弱结构。提出"对齐不稳定性条件"，包含三个几何特性，当同时满足时会导致安全退化。建立四次方缩放定律，量化对齐损失与训练时间的关系。

Result: 发现对齐损失随训练时间的四次方增长，由对齐几何的尖锐度和微调任务与安全关键参数之间的曲率耦合强度控制。证明初始微调更新可能避免安全敏感子空间，但微调损失的曲率会产生二阶加速，系统地将轨迹引导到对齐敏感区域。

Conclusion: 对齐脆弱性不是可以修补的错误，而是曲流形上梯度下降的内在几何特性。当前安全微调方法只解决了动态问题的初始快照，需要开发曲率感知方法，推动对齐安全分析从反应式红队测试转向预测性诊断。

Abstract: Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.

</details>


### [135] [Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics](https://arxiv.org/abs/2602.15820)
*Anna Zimmel,Paul Setinek,Gianluca Galletti,Johannes Brandstetter,Werner Zellinger*

Main category: cs.LG

TL;DR: 提出基于D-最优统计量的测试时适应框架，解决仿真代理模型在分布偏移下的性能下降问题，首次在高维仿真回归和生成设计优化中实现有效TTA


<details>
  <summary>Details</summary>
Motivation: 机器学习代理模型在工程仿真中广泛应用，但训练与部署间的分布偏移会导致严重性能下降。现有测试时适应方法主要针对低维分类问题，不适用于高维、非结构化的仿真回归问题

Method: 提出基于存储最大化信息量（D-最优）统计量的TTA框架，能够实现稳定适应和测试时的参数选择，应用于预训练的仿真代理模型

Result: 在SIMSHIFT和EngiBench基准测试中验证，实现高达7%的分布外性能提升，计算成本可忽略不计，首次系统证明TTA在高维仿真回归和生成设计优化中的有效性

Conclusion: 该框架成功解决了仿真代理模型在分布偏移下的适应问题，为高维仿真回归和生成设计优化提供了有效的测试时适应解决方案

Abstract: Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.

</details>


### [136] [CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing](https://arxiv.org/abs/2602.15823)
*Zarif Ikram,Arad Firouzkouhi,Stephen Tu,Mahdi Soltanolkotabi,Paria Rashidinejad*

Main category: cs.LG

TL;DR: CrispEdit是一种可扩展的二阶编辑算法，通过将能力保持作为显式约束，在成功编辑目标行为的同时防止模型能力退化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型编辑中的一个核心挑战是能力保持：成功改变目标行为的方法可能会悄悄操纵编辑代理并破坏通用能力，产生类似代理/奖励破解的退化行为。

Method: 将编辑建模为约束优化问题，通过将编辑更新投影到能力损失景观的低曲率子空间来强制执行能力约束。使用Bregman散度表达能力约束，采用Kronecker分解近似曲率（K-FAC）和新型无矩阵投影器实现高效二阶计算。

Result: 在标准模型编辑基准测试中，CrispEdit实现了高编辑成功率，同时在多个数据集上平均保持能力退化低于1%，显著优于先前编辑方法。

Conclusion: CrispEdit提供了一个可扩展且原则性的编辑框架，通过显式处理能力保持约束，有效解决了大语言模型编辑中的能力退化问题。

Abstract: A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.

</details>


### [137] [Operationalising the Superficial Alignment Hypothesis via Task Complexity](https://arxiv.org/abs/2602.15829)
*Tomás Vergara-Browne,Darshan Patil,Ivan Titov,Siva Reddy,Tiago Pimentel,Marius Mosbach*

Main category: cs.LG

TL;DR: 本文提出任务复杂度作为衡量模型能力的指标，发现预训练模型大幅降低了许多任务达到高性能所需的复杂度，而微调进一步将复杂度降低了几个数量级，表明任务适应通常只需要极少信息（通常仅几千字节）。


<details>
  <summary>Details</summary>
Motivation: 表面对齐假说（SAH）认为大语言模型的知识主要在预训练阶段学习，而后续训练只是让这些知识显现出来。然而SAH缺乏精确定义，导致支持它的论点各不相同甚至相互矛盾，同时也受到重要批评。本文旨在为SAH提供一个更精确的框架。

Method: 提出任务复杂度这一新指标：在特定任务上达到目标性能所需的最短程序长度。在此框架下，SAH被重新定义为：预训练模型大幅降低了许多任务达到高性能所需的复杂度。通过实验估计数学推理、机器翻译和指令跟随等任务的任务复杂度。

Result: 实验表明，当基于预训练模型时，这些任务的复杂度可以非常低。预训练确实能访问任务的高性能，但可能需要GB级别的程序长度；而微调后，达到相同性能的复杂度降低了几个数量级。任务适应通常只需要极少信息（通常仅几千字节）。

Conclusion: 任务复杂度框架为表面对齐假说提供了统一的解释，将先前支持SAH的不同论点解释为寻找短程序的不同策略。预训练大幅降低了任务复杂度，而微调进一步将复杂度降低了几个数量级，表明任务适应所需的信息量通常非常小。

Abstract: The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [138] [Embedding Economic Input-Output Models in Systems of Systems: An MBSE and Hetero-functional Graph Theory Approach](https://arxiv.org/abs/2602.15254)
*Mohammad Mhadi Naderi,Megan S. Harris,John C. Little,Amro M. Farid*

Main category: eess.SY

TL;DR: 首次将基于模型的系统工程(MBSE)和异质功能图论(HFGT)应用于经济系统，建立可扩展的方法将经济投入产出模型整合到统一的系统之系统建模框架中。


<details>
  <summary>Details</summary>
Motivation: 人类世系统之系统具有相互依赖的特性，需要综合决策方法来应对复杂的生态、环境和人类-自然耦合系统挑战。当前缺乏将经济模型整合到统一系统建模框架的方法。

Method: 将经济投入产出(EIO)模型整合到MBSE-HFGT工作流中，使用SysML图形本体表达经济系统的结构和功能，然后转换为HFGT的计算结构。采用合成矩形技术选择(RCOT)示例作为教学基础。

Result: 证实基本EIO模型和其他基于EIO理论的复杂经济模型的动态特性可以在MBSE-HFGT框架中完全重现。该方法在保持分析精度的同时，通过共享本体结构提供增强的图形清晰度和系统级洞察。

Conclusion: 提出的方法为知识共同生产和综合决策奠定了基础，能够应对人类世系统之系统相关的多方面可持续性挑战。通过整合建模语言和数学框架，实现了经济系统在统一建模框架中的表达。

Abstract: Characterizing the interdependent nature of Anthropocene systems of systems is fundamental to making informed decisions to address challenges across complex ecological, environmental, and coupled human-natural systems. This paper presents the first application of Model-Based Systems Engineering (MBSE) and Hetero-functional Graph Theory (HFGT) to economic systems, establishing a scalable and extensible methodology for integrating economic input-output (EIO) models within a unified system-of-systems modeling framework. Integrating EIO models into the MBSE-HFGT workflow demonstrates how the structural form and function of economic systems can be expressed through SysML's graphical ontology and subsequently translated into the computational structure of HFGT. Using a synthetic Rectangular Choice of Technology (RCOT) example as a pedagogical foundation, the study confirms that the dynamics captured by basic EIO models, as well as other complex economic models grounded in EIO theory, can be equivalently reproduced within the MBSE-HFGT framework. The integration with MBSE and HFGT thus preserves analytical precision while offering enhanced graphical clarity and system-level insight through a shared ontological structure. By integrating modeling languages and mathematical frameworks, the proposed methodology establishes a foundation for knowledge co-production and integrated decision-making to address the multifaceted sustainability challenges associated with Anthropocene systems of systems.

</details>


### [139] [State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs](https://arxiv.org/abs/2602.15282)
*Fen Wu*

Main category: eess.SY

TL;DR: 提出了一种新的时变状态延迟LPV系统控制框架，结合参数依赖Lyapunov函数和积分二次约束，通过凸LMI条件设计延迟依赖状态反馈控制器。


<details>
  <summary>Details</summary>
Motivation: 传统延迟控制方法在处理时变状态延迟的线性参数变化系统时存在局限性，需要更灵活、系统化的框架来减少保守性并提升控制性能。

Method: 提出延迟依赖状态反馈控制器结构，结合参数依赖Lyapunov函数和动态积分二次约束，通过凸线性矩阵不等式条件进行控制器综合。

Result: 建立了闭环稳定性和L2增益性能分析框架，提供了保证性能的参数依赖LMI条件，相比传统方法具有更好的灵活性和更低的保守性。

Conclusion: 所提出的IQC框架为时变延迟LPV系统控制提供了系统化方法，增强了控制能力，减少了保守性，改善了闭环性能。

Abstract: This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance.

</details>


### [140] [Noncooperative Coordination for Decentralized Air Traffic Management](https://arxiv.org/abs/2602.15333)
*Jaehan Im*

Main category: eess.SY

TL;DR: 提出非合作协调的统一框架，通过设计激励和信号来重塑个体最优性，而非强制合作，应用于去中心化空中交通管理


<details>
  <summary>Details</summary>
Motivation: 去中心化空中交通管理需要自利利益相关者在共享安全和容量约束下协调，传统集中式或隐式合作模型无法充分捕捉这一场景

Method: 开发非合作协调的统一视角，通过设计激励和分配信号来重塑个体最优性；推进三个方向：可扩展均衡工程（降维和不确定性感知相关均衡）、无强制执行的去中心化机制设计、具有收敛保证的结构化非合作动态

Result: 建立了可扩展、鲁棒协调的基础，为安全关键空中交通系统提供系统级结果

Conclusion: 这些结果为安全关键空中交通系统中的可扩展、鲁棒协调奠定了基础，并讨论了去中心化系统中激励兼容协调的核心设计原则

Abstract: Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems.

</details>


### [141] [Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid](https://arxiv.org/abs/2602.15350)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: 使用指令微调大语言模型生成PSPS场景下的校正开关方案，通过多阶段微调管道提升DC目标值和电压性能


<details>
  <summary>Details</summary>
Motivation: 公共安全停电（PSPS）导致电网拓扑快速变化，使标准运行点不可行，需要快速识别校正开关动作以减少负荷削减并维持可接受的电压行为

Method: 提出可验证的多阶段适应管道：1）监督微调将DC-OPF MILP蒸馏为约束动作语法；2）直接偏好优化使用AC评估的偏好对注入电压感知；3）最佳N选择在推理时选择最佳可行候选方案

Result: 在IEEE 118节点PSPS场景中，微调显著改善DC目标值，将AC潮流故障率从50%降至个位数，并在共同成功集上改善电压惩罚结果

Conclusion: 提出的多阶段微调管道能有效生成PSPS场景下的校正开关方案，提升电网恢复性能，代码和数据生成脚本已开源支持可复现性

Abstract: Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.

</details>


### [142] [Generalized bilinear Koopman realization from input-output data for multi-step prediction with metaheuristic optimization of lifting function and its application to real-world industrial system](https://arxiv.org/abs/2602.15422)
*Shuichi Yahagi,Ansei Yonezawa,Heisei Yonezawa,Hiroki Seto,Itsuro Kajiwara*

Main category: eess.SY

TL;DR: 提出一种输入输出双线性Koopman实现方法，通过优化径向基函数提升函数参数来改进非线性系统的长期预测性能，在柴油机空气路径控制系统中验证了优于传统线性Koopman模型的预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统Koopman方法在工业应用中面临三个主要挑战：1) 难以测量所有系统状态（传感器安装限制）；2) 提升函数设计依赖大量人工经验且显著影响预测性能；3) 常用的线性时不变Koopman模型预测精度有限。需要一种能自动优化提升函数并提高预测准确性的方法。

Method: 提出输入输出双线性Koopman建模方法，使用径向基函数作为提升函数，并通过全局元启发式算法优化其设计参数。该方法考虑长期预测性能来增强模型可靠性，特别针对具有强非线性和耦合多输入多输出动态的系统。

Result: 在仿真和实验测试中验证了所提方法，以柴油机空气路径控制系统为建模对象。结果表明，提出的输入输出双线性Koopman模型在预测精度上显著优于传统线性Koopman模型。

Conclusion: 通过优化提升函数参数并采用双线性结构，有效解决了传统Koopman方法在工业应用中的局限性，为具有强非线性和耦合MIMO动态的复杂系统提供了更准确的建模框架。

Abstract: This paper introduces an input-output bilinear Koopman realization with an optimization algorithm of lifting functions. For nonlinear systems with inputs, Koopman-based modeling is effective because the Koopman operator enables a high-dimensional linear representation of nonlinear dynamics. However, traditional approaches face significant challenges in industrial applications. Measuring all system states is often impractical due to constraints on sensor installation. Moreover, the predictive performance of a Koopman model strongly depends on the choice of lifting functions, and their design typically requires substantial manual effort. In addition, although a linear time-invariant (LTI) Koopman model is the most commonly used model structure in the Koopman framework, such model exhibit limited predictive accuracy. To address these limitations, we propose an input-output bilinear Koopman modeling in which the design parameters of radial basis function (RBF)-based lifting functions are optimized using a global metaheuristic algorithm to improve long-term prediction performance. Consideration of the long-term prediction performance enhances the reliability of the resulting model. The proposed methodology is validated in simulations and experimental tests, with the airpath control system of a diesel engine as the plant to be modeled. This plant represents a challenging industrial application because it exhibits strong nonlinearities and coupled multi-input multi-output (MIMO) dynamics. These results demonstrate that the proposed input-output bilinear Koopman model significantly outperforms traditional linear Koopman models in predictive accuracy.

</details>


### [143] [The role of VSG parameters in shaping small-signal SG dynamics](https://arxiv.org/abs/2602.15526)
*Ferdinand Geuss,Orcun Karaca,Mario Schweizer,Ognjen Stanojev*

Main category: eess.SY

TL;DR: 推导了包含虚拟同步发电机(VSG)、同步发电机(SG)和负载系统的小信号传递函数，分析SG动态对VSG参数的敏感性


<details>
  <summary>Details</summary>
Motivation: 研究VSG参数对SG动态特性的影响，为VSG参数选择提供理论指导，优化混合发电系统的稳定性

Method: 建立包含VSG、SG和负载的小信号传递函数模型，分析SG动态对VSG参数的敏感性

Result: 揭示了虚拟惯性和调速器滞后选择的权衡关系，阻尼绕组仿真的有限效果，以及其他参数的影响

Conclusion: VSG参数选择对SG动态有重要影响，需要权衡虚拟惯性和调速器滞后，阻尼绕组仿真效果有限

Abstract: We derive a small-signal transfer function for a system comprising a virtual synchronous generator (VSG), a synchronous generator (SG), and a load, capturing voltage and frequency dynamics. Using this model, we analyze the sensitivity of SG dynamics to VSG parameters, highlighting trade-offs in choosing virtual inertia and governor lag, the limited effect of damper-winding emulation, and several others.

</details>


### [144] [Time-Certified and Efficient NMPC via Koopman Operator](https://arxiv.org/abs/2602.15596)
*Liang Wu,Yunhong Che,Bo Yang,Kangyu Lin,Ján Drgoňa*

Main category: eess.SY

TL;DR: 本文提出了一种为非线性模型预测控制（NMPC）提供执行时间证书和加速的方法，通过Koopman算子学习线性模型，构建结构化BoxQP，并利用其结构大幅减少计算复杂度。


<details>
  <summary>Details</summary>
Motivation: NMPC的执行时间证书和加速是其实际应用的两个核心需求。执行时间证书能保证控制器在下一个采样时间前返回解，而更快的执行时间能扩展其应用范围。然而，NMPC产生非线性规划问题，难以推导其执行时间证书。

Method: 1) 通过Koopman算子学习线性模型；2) 提出动态松弛构造方法，生成结构化BoxQP而非一般QP；3) 利用BoxQP的结构，将每次迭代中线性系统的维度从5N(n_u+n_x)减少到Nn_u，大幅加速计算。

Result: 该方法显著减少了计算复杂度，特别是在状态维度远大于输入维度的情况下（如PDE控制），能实现实质性的加速效果。

Conclusion: 通过结合Koopman线性化、结构化BoxQP构造和维度缩减技术，本文为NMPC提供了可认证的执行时间保证和计算加速，扩展了NMPC在实时控制应用中的可行性。

Abstract: Certifying and accelerating execution times of nonlinear model predictive control (NMPC) implementations are two core requirements. Execution-time certificate guarantees that the NMPC controller returns a solution before the next sampling time, and achieving faster worst-case and average execution times further enables its use in a wider set of applications. However, NMPC produces a nonlinear program (NLP) for which it is challenging to derive its execution time certificates. Our previous works, \citep{wu2025direct,wu2025time} provide data-independent execution time certificates (certified number of iterations) for box-constrained quadratic programs (BoxQP). To apply the time-certified BoxQP algorithm \citep{wu2025time} for state-input constrained NMPC, this paper i) learns a linear model via Koopman operator; ii) proposes a dynamic-relaxation construction approach yields a structured BoxQP rather than a general QP; iii) exploits the structure of BoxQP, where the dimension of the linear system solved in each iteration is reduced from $5N(n_u+n_x)$ to $Nn_u$ (where $n_u, n_x, N$ denote the number of inputs, states, and length of prediction horizon), yielding substantial speedups (when $n_x \gg n_u$, as in PDE control).

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [145] [Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight](https://arxiv.org/abs/2602.15259)
*Kirandeep Kaur,Xingda Lyu,Chirag Shah*

Main category: cs.CY

TL;DR: 论文主张生成式AI需要从被动响应转向主动干预，但需基于认识论和行为学双重基础进行约束，以应对用户"未知的未知"问题。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI代理假设理解等于解决明确查询，这限制了与用户的互动范围。当用户自身缺乏对缺失、风险或值得考虑事项的意识时，这种假设就会失效。在这种情况下，主动性不仅是效率提升，更是认识论上的必要。

Method: 提出"认识论不完整性"概念，借鉴无知哲学和主动行为研究，主张生成式主动性需要在认识论和行为学上双重基础，为代理干预提供原则性约束。

Result: 论文提出了"行为基础"框架，为主动代理何时、如何以及何种程度进行干预提供原则性约束，避免无约束主动干预可能导致的注意力分散、用户负担或伤害。

Conclusion: 生成式AI的主动性设计需要认识论和行为学的双重基础，才能负责任地参与并促进有意义的伙伴关系，应对用户"未知的未知"挑战。

Abstract: Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.

</details>


### [146] [FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health](https://arxiv.org/abs/2602.15273)
*Victor De Lima,Jiqun Liu,Grace Hui Yang*

Main category: cs.CY

TL;DR: FrameRef是一个大规模数据集和模拟框架，用于研究排名和推荐系统中信息框架对用户长期信息健康的影响。


<details>
  <summary>Details</summary>
Motivation: 现代搜索和推荐系统中的排名和个性化策略会影响用户接触不良数字体验的方式，从而对信息健康产生长期影响，需要系统研究这些效应。

Method: 创建包含107万条系统性重构声明的FrameRef数据集，涵盖权威性、共识、情感、声望和煽情五个框架维度；提出基于模拟的框架，通过微调语言模型构建框架敏感代理角色，使用蒙特卡洛轨迹采样分析累积效应。

Result: 研究表明，接受度和信心的小幅系统性偏移会随时间累积，导致信息健康轨迹显著分化；人类评估证实FrameRef生成的框架确实影响人类判断。

Conclusion: FrameRef数据集和框架为通过模拟进行系统性信息健康研究奠定了基础，可补充和指导负责任的人本中心研究。

Abstract: Information ecosystems increasingly shape how people internalize exposure to adverse digital experiences, raising concerns about the long-term consequences for information health. In modern search and recommendation systems, ranking and personalization policies play a central role in shaping such exposure and its long-term effects on users. To study these effects in a controlled setting, we present FrameRef, a large-scale dataset of 1,073,740 systematically reframed claims across five framing dimensions: authoritative, consensus, emotional, prestige, and sensationalist, and propose a simulation-based framework for modeling sequential information exposure and reinforcement dynamics characteristic of ranking and recommendation systems. Within this framework, we construct framing-sensitive agent personas by fine-tuning language models with framing-conditioned loss attenuation, inducing targeted biases while preserving overall task competence. Using Monte Carlo trajectory sampling, we show that small, systematic shifts in acceptance and confidence can compound over time, producing substantial divergence in cumulative information health trajectories. Human evaluation further confirms that FrameRef's generated framings measurably affect human judgment. Together, our dataset and framework provide a foundation for systematic information health research through simulation, complementing and informing responsible human-centered research. We release FrameRef, code, documentation, human evaluation data, and persona adapter models at https://github.com/infosenselab/frameref.

</details>


### [147] [From PhysioNet to Foundation Models -- A history and potential futures](https://arxiv.org/abs/2602.15371)
*Gari D. Clifford*

Main category: cs.CY

TL;DR: 回顾医学数据共享35年演变，聚焦心电生理信号数据库PhysioNet的25年发展，分析大规模生理数据、开源代码和公开竞赛面临的挑战与机遇，探讨AI碳足迹、边缘计算、激励机制等关键问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗领域的快速发展，大规模生理数据共享面临新的挑战。作者基于PhysioNet资源25年的发展经验，旨在分析医学数据共享的历史演变、当前问题及未来方向，为领域发展提供指导。

Method: 基于作者在PhysioNet资源25年的亲身参与经验，回顾医学数据共享从磁带到互联网的35年演变历程，以心脏病学为例分析数据密集型领域的发展，结合PhysioNet挑战赛等具体实践案例进行探讨。

Result: 识别了大规模生理数据库、开源代码和公开竞赛面临的关键问题，提出了包括应对AI碳足迹、利用边缘计算、改进激励机制、确保科学可重复性等解决方案，并规划了PhysioNet资源的未来发展方向。

Conclusion: 医学数据共享正面临机器学习时代的新挑战，需要平衡数据利用与伦理、环境、激励等多方面因素。PhysioNet资源的开放获取理念和挑战赛模式为解决这些问题提供了有价值的框架，未来应继续推动可持续、可重复的医疗AI发展。

Abstract: Over the last 35 years, the sharing of medical data and models for research has evolved from sneakernet to the internet - from mailing magnetic tapes and compact discs of a handful of well-curated recordings, to the high-speed download of relatively comprehensive hospital databases. More recently, the fervor around the potential for modern machine learning and 'AI' to catapult us into the next industrial revolution has led to a seemingly insatiable desire to pump almost any source of data into large models. Although this has great potential, it also presents a whole set of new challenges. In this article I examine these trends over the last 30 years, drawing on examples from cardiology, one of the oldest data-intensive fields that is undergoing a renaissance via machine learning. From the early days of computerized cardiology, the Research Resource for Complex Physiologic Signals (PhysioNet) has been at the cutting edge of this field. This article, therefore, includes much of the Resource's history and the contributions drawn from 25 years of firsthand experience of co-developing elements of the Resource with its founders. I identify the most promising future directions for the PhysioNet Resource, and more generally, the growing issues and opportunities around dissemination and use of massive physiological databases, associated open access code, and public competitions, along with potential solutions to the key issues facing our field. Topics range from how we should approach foundation models in the context of the rapidly growing AI carbon footprint, to the potential of Tiny-ML and edge computing. I also cover issues around prizes and incentives, funding models, and scientific repeatability, as well as how we might address these issues by leveraging the PhysioNet Challenges, consistent with the philosophy of open-access from the early days of the PhysioNet Resource.

</details>


### [148] [What makes an Expert? Comparing Problem-solving Practices in Data Science Notebooks](https://arxiv.org/abs/2602.15428)
*Manuel Valle Torre,Marcus Specht,Catharine Oertel*

Main category: cs.CY

TL;DR: 专家与新手在数据科学问题解决过程中差异：专家采用短小迭代策略和高效行动序列，而非线性长流程


<details>
  <summary>Details</summary>
Motivation: 数据科学需要难以直接教授的隐性、过程导向技能，需要实证理解专家与新手在问题解决过程中的差异

Method: 对440个Jupyter笔记本进行多层次序列分析，将低级编码动作映射到高级问题解决实践

Result: 专家与新手在数据科学阶段转换上没有根本差异，但专家工作流程更短、更迭代，行动序列更高效；新手则倾向于长线性流程

Conclusion: 数据科学教育应关注培养灵活迭代思维而非最终产品，这对AI工具日益重要的领域尤为重要

Abstract: The development of data science expertise requires tacit, process-oriented skills that are difficult to teach directly. This study addresses the resulting challenge of empirically understanding how the problem-solving processes of experts and novices differ. We apply a multi-level sequence analysis to 440 Jupyter notebooks from a public dataset, mapping low-level coding actions to higher-level problem-solving practices. Our findings reveal that experts do not follow fundamentally different transitions between data science phases than novices (e.g., Data Import, EDA, Model Training, Visualization). Instead, expertise is distinguished by the overall workflow structure from a problem-solving perspective and cell-level, fine-grained action patterns. Novices tend to follow long, linear processes, whereas experts employ shorter, more iterative strategies enacted through efficient, context-specific action sequences. These results provide data science educators with empirical insights for curriculum design and assessment, shifting the focus from final products toward the development of the flexible, iterative thinking that defines expertise-a priority in a field increasingly shaped by AI tools.

</details>


### [149] [From Earthquake Solidarity to Educational Equity: Conceptualizing a Sustainable, Volunteer-Driven P2P Learning Ecosystem at Scale](https://arxiv.org/abs/2602.15432)
*Öykü Kaplan,Adam Przybyłek,Michael Neumann,Netta Iivari*

Main category: cs.CY

TL;DR: 该研究探讨了一个由志愿者驱动的P2P教育项目如何从土耳其地震应急响应演变为持续两年多的可持续生态系统，支持300多名中学生和40多名志愿者导师。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在完全在线、非互惠的远同伴辅导环境中，社会技术动态如何支持长期韧性，探索从紧急响应到可持续生态系统的转变过程。

Method: 采用解释性案例研究方法，通过参与观察、焦点小组、问卷调查和协作愿景研讨会进行数据三角验证，分析社会技术动态。

Result: 研究发现：年龄相近促进信任但挑战教学权威；志愿者参与主要受内在动机驱动；学生报告信心、表达能力和理解力显著提升；学生视导师为榜样并希望成为导师；双方都呼吁建立专用平台。

Conclusion: 研究总结出可持续P2P学习生态系统的五个设计原则，展示了从紧急响应到可持续生态系统的转变，强调代际互惠循环的重要性。

Abstract: This study examines the evolution of a grassroots, volunteer-driven peer-to-peer (P2P) educational initiative from an emergency response to the 2023 Türkiye earthquake into a sustainable ecosystem that operated for over two years and supported 300+ middle-school learners with 40+ volunteer tutors. Employing an interpretive case study approach, we triangulated data from participant observation, focus groups, questionnaires, and collaborative visioning workshops to investigate the socio-technical dynamics enabling long-term resilience in a fully online, nonreciprocal far-peer tutoring setting. Our findings reveal that while age proximity fosters trust and open communication, it also poses challenges for tutors who must balance peer rapport with instructional authority. Volunteer engagement is driven primarily by intrinsic motives - educational impact and community belonging - while optional micro-earning is envisioned as a practical enabler for long-term sustainability. Tutees report significant gains in confidence, self-expression, and accelerated comprehension, attributing these outcomes to personalized, interactive sessions within a "family-like" safe space that combines academic instruction with socio-emotional support. Notably, tutees view tutors as aspirational role models and express strong intentions to return as tutors themselves, envisioning a self-regenerating cycle of intergenerational reciprocity that carries knowledge and solidarity from generation to generation. Both cohorts call for a dedicated platform featuring integrated scheduling, personalization, feedback, and quality assurance mechanisms. We synthesize these insights into theory-informed implications and five design principles for sustainable P2P learning ecosystems at scale.

</details>


### [150] [Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study](https://arxiv.org/abs/2602.15439)
*Salim Hafid,Manon Berriche,Jean-Philippe Cointet*

Main category: cs.CY

TL;DR: 论文提出了一种基于社会选择理论的新算法，用于在线审议平台中平衡多样性和比例代表性的意见选择策略。


<details>
  <summary>Details</summary>
Motivation: 在线审议平台使用算法自动化选择代表性意见时，现有策略（如共识、多样性）对民主标准（如比例代表性）的影响不明确，可能导致少数声音被忽视或内容多样性降低。

Method: 基于社会选择理论提出新算法，结合多样性和平衡代表性；对多种算法方法进行基准测试。

Result: 实证发现：没有单一策略在所有民主期望标准上占优；提出的社会选择启发式选择规则在比例代表性和多样性之间实现了最强的权衡。

Conclusion: 在在线审议平台的意见选择中，需要平衡多种民主标准；提出的社会选择理论算法在比例代表性和多样性之间提供了最佳权衡。

Abstract: During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.

</details>


### [151] [How to Detect Information Voids Using Longitudinal Data from Social Media and Web Searches](https://arxiv.org/abs/2602.15476)
*Irene Scalco,Francesco Gesualdo,Roy Cerqueti,Matteo Cinelli*

Main category: cs.CY

TL;DR: 该研究利用注意力经济模型中的信息供需反馈循环，开发了一种检测和量化信息空白（即特定话题缺乏可靠信息的时期）的方法，并通过COVID-19疫苗在欧洲六国推广的案例研究，发现信息空白与错误信息传播密切相关。


<details>
  <summary>Details</summary>
Motivation: 当前信息传播环境中存在信息空白（缺乏可靠信息）和信息过载两种极端现象，特别是在公共卫生危机如COVID-19期间，这些信息动态如何影响错误信息的传播需要系统研究。研究旨在通过实证分析信息空白与错误信息的关系，为理解错误信息产生机制提供新视角。

Method: 采用注意力经济模型，基于信息供给与需求的反馈循环开发信息空白检测方法。使用多平台数据（Facebook、Google、Twitter、Wikipedia、在线新闻媒体）进行案例研究，分析欧洲六国COVID-19疫苗推广期间的信息动态。将信息空白概念化为特定的信息传播机制，并量化其对应现象——信息过载。

Result: 研究发现信息空白与高质量信息比例下降相关，且信息空白区域中错误信息更普遍，成为个体更容易被低质量内容误导的问题热点。信息空白和信息过载共同构成了当前信息流行病定义的核心组成部分。研究为将信息空白纳入错误信息产生的机制性解释提供了实证支持。

Conclusion: 信息空白是错误信息传播的关键因素，在缺乏可靠信息的时期，错误信息更容易扩散。研究强调了监测信息空白的重要性，并提供了量化方法，有助于更全面地理解和管理信息流行病现象。

Abstract: The model of the attention economy, where content producers compete for the attention of users, relies on two key forces: information supply and demand. This study leverages the feedback loop between these forces to develop a method for detecting and quantifying information voids, i.e., periods in which little or no reliable information is available on a given topic. Using a case study on COVID-19 vaccines rollout in six European countries, and drawing on data from multiple platforms including Facebook, Google, Twitter, Wikipedia, and online news outlets, we examine how information voids emerge, persist and correlate with a decline in the proportion of high-quality information circulating online. By conceptualising information voids as a specific regime of information spreading, we also quantify their counterpart, information overabundance, which constitute a central component of the current definition of infodemic. We show that information voids are associated with a higher prevalence of misinformation, thus representing problematic hotspots in which individuals are more likely to be misled by low-quality online content. Overall, our findings provide empirical support for the inclusion of information voids in mechanistic explanations of misinformation emergence.

</details>


### [152] [Who Is Doing the Thinking? AI as a Dynamic Cognitive Partner: A Learner-Informed Framework](https://arxiv.org/abs/2602.15638)
*C. K. Y Chan*

Main category: cs.CY

TL;DR: 本研究提出一个框架，将AI定位为动态认知伙伴，通过分析133名香港中学生的书面回答，识别出AI作为认知伙伴的九个维度，区分了扩展理解的"生产性支持"和替代认知努力的"非生产性依赖"。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育中的普及，需要理解学生如何概念化AI在他们思维和学习中的角色。当前缺乏解释学生如何看待AI作为认知伙伴的框架，特别是在不同学习情境中AI功能如何变化。

Method: 采用质性分析方法，收集133名香港中学生在完成AI素养课程后的书面回答，识别出学生描述AI作为认知伙伴的九个相互关联的维度，并基于社会文化理论、分布式认知、自我调节学习和认知负荷理论构建框架。

Result: 识别出AI作为认知伙伴的九个维度：概念脚手架、反馈与错误检测、想法激发、认知组织、适应性辅导支持、元认知监控支持、任务与认知负荷调节、课堂边界外的学习连续性、以及困惑或超负荷时的解释重构。学生能够区分扩展理解的"生产性支持"和替代认知努力的"非生产性依赖"。

Conclusion: 该框架阐明了AI如何融入学习者的认知活动，同时揭示了认知扩展与替代之间的边界。学生表现出对何时应该和不应该使用AI的情境意识，这对AI教育应用的设计和实施具有重要意义。

Abstract: Artificial intelligence is increasingly embedded in education, yet there remains a need to explain how students conceptualize AI's role in their thinking and learning. This study proposes a framework positioning AI as a dynamic cognitive partner whose function shifts across learning situations. Using qualitative analysis of written responses from 133 secondary students in Hong Kong following completion of an AI literacy course, we identified nine interrelated dimensions through which learners described AI as partnering with their cognition: conceptual scaffolding for difficult ideas; feedback and error detection; idea stimulation; cognitive organization; adaptive tutoring support; metacognitive monitoring support; task and cognitive load regulation; learning continuity beyond classroom boundaries; and explanation reframing through representational flexibility during moments of being stuck or overwhelmed. Across these dimensions, students distinguished between productive support that extends understanding and unproductive reliance that replaces cognitive effort, indicating situational awareness of when AI should and should not be used. Grounded in sociocultural theory, distributed cognition, self-regulated learning, and cognitive load perspectives, the framework clarifies how AI becomes integrated into learners' cognitive activity while illuminating the boundary between cognitive extension and substitution.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [153] [On propagation of chaos for the Fisher-Rao gradient flow in entropic mean-field optimization](https://arxiv.org/abs/2602.15094)
*Petra Lazić,Linshan Liu,Mateusz B. Majka*

Main category: math.OC

TL;DR: 本文研究概率测度空间上的优化问题，提出使用Fisher-Rao梯度流和交互粒子系统来近似求解，通过核平滑技术确保粒子系统良好定义，并提供了严格的理论证明。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络的均值场方法中出现的概率测度空间优化问题，需要构建有效的数值算法来近似连续时间梯度流。

Method: 采用Fisher-Rao梯度流，构建交互粒子系统作为其均值场极限近似，通过核平滑技术处理能量函数，确保粒子系统良好定义。

Result: 严格证明了核化流的存在性和唯一性，以及传播混沌结果，为使用核化粒子系统作为熵均值场优化的近似算法提供了理论依据。

Conclusion: 提出的核化粒子系统方法为求解概率测度空间优化问题提供了有效的数值算法，具有严格的理论保证，适用于神经网络的均值场分析。

Abstract: We consider a class of optimization problems on the space of probability measures motivated by the mean-field approach to studying neural networks. Such problems can be solved by constructing continuous-time gradient flows that converge to the minimizer of the energy function under consideration, and then implementing discrete-time algorithms that approximate the flow. In this work, we focus on the Fisher-Rao gradient flow and we construct an interacting particle system that approximates the flow as its mean-field limit. We discuss the connection between the energy function, the gradient flow and the particle system and explain different approaches to smoothing out the energy function with an appropriate kernel in a way that allows for the particle system to be well-defined. We provide a rigorous proof of the existence and uniqueness of thus obtained kernelized flows, as well as a propagation of chaos result that provides a theoretical justification for using the corresponding kernelized particle systems as approximation algorithms in entropic mean-field optimization.

</details>


### [154] [Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations](https://arxiv.org/abs/2602.15722)
*Cheng Guo,Lauren Henderson,Ryan Cory-Wright,Boshi Yang*

Main category: math.OC

TL;DR: 提出基于半定规划松弛的非凸市场定价方案，用于解决电力市场机组组合等离散非线性问题，通过凸化非凸结构并利用对偶变量定价，显著降低机会成本损失。


<details>
  <summary>Details</summary>
Motivation: 非凸市场（如电力市场机组组合问题）由于离散决策和非线性约束，使得高效定价具有挑战性，通常需要补贴。现有定价方案存在机会成本损失高的问题。

Method: 通过半定规划松弛凸化非凸结构，利用松弛问题的对偶变量推导边际价格信号作为定价机制。当选择集有界时，建立半定规划的强对偶性，扩展包络定理到松弛值函数。

Result: 当松弛的右侧线性依赖于需求时，机会成本损失受限于松弛的最优性间隙。在IEEE基准实例测试中，该定价方案的机会成本损失平均比常用的固定二进制定价方案低46%。

Conclusion: 提出的基于半定规划松弛的定价框架适用于非凸电力市场问题，包括直流和交流机组组合。数值实验表明半定规划松弛通常是紧的，验证了定价方案的有效性。

Abstract: Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme.

</details>


### [155] [Revisiting transportation problems under Monge costs with applications to location problems](https://arxiv.org/abs/2602.15151)
*Stefan Nickel,Justo Puerto,Simon Ramoser,Alberto Torrejón*

Main category: math.OC

TL;DR: 论文研究了Monge成本结构下的运输问题，推导了基于西北角法则的最优对偶解紧凑公式，并将其应用于设施选址问题，在Benders分解框架中为离散有序中值问题提出了新公式，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究Monge成本结构下的运输问题，旨在推导最优对偶解的紧凑公式，为设施选址问题提供理论工具，提高计算效率并增强结构洞察力。

Method: 基于西北角法则推导Monge运输问题的最优对偶解紧凑公式，将其应用于Benders分解框架，为具有非递增权重的离散有序中值问题构建新公式。

Result: 数值实验验证了所得公式在最先进性能方面的优越性，并在广泛实例中表现出强大的鲁棒性。

Conclusion: 提出的紧凑对偶解公式不仅提供了结构洞察，还显著提升了计算性能，为设施选址问题特别是离散有序中值问题提供了有效的解决方案。

Abstract: We investigate the transportation problem under a Monge cost structure and derive compact formulas for optimal dual solutions based on the northwest-corner rule. As an application illustrating how these formulas yield structural insight while enhancing computational performance, we consider a broad class of facility location problems. In particular, the expressions are used within a Benders decomposition framework to derive novel formulations for the Discrete Ordered Median Problem with non-increasing weights. Numerical experiments validate that the resulting formulations achieve state-of-the-art performance and exhibit strong robustness across a wide range of instances.

</details>


### [156] [Linear error bounds for HJB equations in finite horizon control problems](https://arxiv.org/abs/2602.15215)
*Alessandro Alla,Filippo Mayer*

Main category: math.OC

TL;DR: 本文改进了有限时域最优控制问题中Hamilton-Jacobi-Bellman方程半拉格朗日近似方案的误差估计，消除了经典分析中的1/Δt项，获得了线性依赖于时间步长、空间网格尺寸和控制时间振荡度的新误差界。


<details>
  <summary>Details</summary>
Motivation: 经典半拉格朗日近似方案的误差估计包含1/Δt项，导致过于悲观的收敛界，且与数值实验结果不符。需要改进误差分析以获得更符合实际观测的收敛估计。

Method: 在存在正折扣因子的标准正则性假设下，通过精细化比较连续与离散成本泛函，以及控制动力学的稳定性估计，推导新的误差界。

Result: 获得了线性依赖于时间步长、空间网格尺寸和控制时间振荡度的新误差界，消除了经典分析中的混合项。数值实验证实了时间和空间的一阶收敛性，且改进行为在无折扣情况下似乎仍然成立。

Conclusion: 本文提供了更准确的半拉格朗日近似方案误差估计，解决了经典分析中过于悲观的问题，为有限时域最优控制问题的数值求解提供了更可靠的理论基础。

Abstract: We study semi Lagrangian approximation schemes for Hamilton Jacobi Bellman equations arising from finite horizon optimal control problems. Classical error estimates for these schemes include the term $\frac{1}{Δt}$ which leads to pessimistic convergence bounds and is not observed in numerical experiments. In this work, we provide improved error estimates under standard regularity assumptions on the dynamics, the running cost, and the final cost, assuming the presence of a positive discount factor. The new bound depends linearly on the time step, the spatial mesh size, and a measure of the temporal oscillation of the control, thus removing the mixed term appearing in previous analyses. The proof relies on a refined comparison between continuous and discrete cost functionals and on stability estimates for the controlled dynamics. Numerical experiments confirm first-order convergence in both space and time and suggest that the improved behavior persists even in the undiscounted case.

</details>


### [157] [Efficient Adjoint-based Design Optimization with Optimal Control](https://arxiv.org/abs/2602.15242)
*Sicheng He,Shugo Kaneko,Max Howell,Nan Li,Joaquim R. R. A. Martins*

Main category: math.OC

TL;DR: 将最优控制与多学科设计优化整合为单一线性二次调节器问题，通过耦合伴随方法高效计算梯度，应用于倒立摆和四旋翼叶片设计


<details>
  <summary>Details</summary>
Motivation: 传统多学科工程系统设计采用顺序流程（从系统动力学到设计变量再到控制），效率低下且可能导致次优设计。需要将最优控制和多学科设计优化整合为单一问题以提高效率

Method: 将最优控制与多学科设计优化问题表述为单一线性二次调节器问题，使用耦合伴随方法计算设计变量导数，通过解决三个较小的伴随方程间接高效求解耦合伴随问题

Result: 在倒立摆和四旋翼叶片设计两个测试问题上验证了新方法。对于四旋翼叶片设计，通过针对特定控制任务优化叶片，将控制成本降低10%，稳态悬停功耗仅有轻微增加

Conclusion: 提出的集成方法能够有效优化控制系统设计，耦合伴随方法计算成本与设计变量数量无关，适合大规模问题，通过间接求解策略进一步提高了计算效率

Abstract: Multidisciplinary engineering system design typically employs a sequential process, progressing from system dynamics to design variables and control. However, this process is inefficient and may lead to a suboptimal design. We propose formulating the optimal control and multidisciplinary design optimization (MDO) problems as a single problem with linear quadratic regulator (LQR) control. We use the coupled adjoint method to compute the design variable derivatives, which are critical for gradient-based design optimization. The computational cost of the derivative computation using the adjoint method is independent of the number of design variables, making it suitable for large-scale problems. We show that the coupled adjoint can be solved indirectly and more efficiently by solving three smaller adjoint equations that leverage the feedforward structure of the problem. We demonstrate this new approach on two test problems: design optimization of a classic cart-pole problem and the aerodynamic shape of a quadrotor blade. For the quadrotor blade design problem, we reduce the control cost by 10% by optimizing the blade for a specific control task with a slight penalty in steady hovering power consumption.

</details>


### [158] [Operating room planning with pooling downstream beds among specialties: A stochastic programming approach](https://arxiv.org/abs/2602.15269)
*Arian Andam,Hossein Hashemi Doulabi*

Main category: math.OC

TL;DR: 研究手术室规划中跨专科共享下游病床（ICU和普通病房）的随机优化模型，通过两阶段随机规划最小化总成本，结果显示完全共享策略可提升系统性能19.53%，随机模型解比确定性模型优17.43%。


<details>
  <summary>Details</summary>
Motivation: 手术室规划面临手术时长和患者住院时间的不确定性，需要优化下游病床（ICU和普通病房）的分配策略，以降低患者等待成本、延期成本、加班成本和下游服务能力成本。

Method: 提出两阶段随机规划模型：第一阶段决定各专科非共享ICU/病房床位数和手术室分配；第二阶段决定每日共享床位数、应急容量需求和手术室加班。采用样本平均近似框架，并开发专用算法高效求解第二阶段问题。

Result: 完全共享策略在不同专科间共享下游病床可提升系统性能达19.53%；随机规划模型解比对应的确定性模型解平均优17.43%；开发的算法能高效处理大量场景。

Conclusion: 跨专科共享下游病床能显著提升医疗系统效率，随机规划模型能有效处理手术时长和住院时间的不确定性，为医院运营管理提供优化决策支持。

Abstract: In this paper, we study pooling downstream beds across specialties in a stochastic operating room planning problem. The main sources of uncertainty are stochastic surgical durations and patients' lengths of stay. We developed a two-stage stochastic programming model where in the first stage we decide on 1) the number of non-shared ICU and ward beds to be allocated to each specialty, and 2) the allocation of surgeries to operating rooms during the planning horizon. In the second stage, we decide on 1) the number of shared beds in ICU and wards to be allocated to different specialties on each day during the planning horizon, 2) the surge capacity required to satisfy downstream service to patients, and 3) the overtime incurred in operating rooms. The proposed model aims at minimizing the total cost including the patients' waiting cost, postponement cost, overtime and fixed cost of operating rooms, and the cost of downstream surge capacity. We have implemented the proposed stochastic programming model in a sample average approximation framework. To enhance the efficiency of sample average approximation, we have developed a specialized algorithm that quickly solves the second-stage model for any given first-stage solution for a large number of scenarios. We have carried out extensive computational experiments to evaluate the effectiveness of several pooling policies for downstream beds and also the efficiency of the proposed sample average approximation algorithm. Moreover, we have performed an extensive sensitivity analysis of cost and stochastic parameters. Our results demonstrated that a full-sharing policy among different specialties in the downstream units enhance the functionality of the system by up to 19.53%. Moreover, the results indicated that the solutions obtained by the proposed stochastic model outperform those from the corresponding deterministic problem by 17.43% on average.

</details>


### [159] [Carleman Inequalities for the Heat Equation with Fourier Boundary Conditions: Applications to Null Controllability Problems](https://arxiv.org/abs/2602.15300)
*Jose Antonio Villa*

Main category: math.OC

TL;DR: 建立热方程的Carleman不等式，用于处理傅里叶边界条件下的边界控制问题，并开发数值方法求解耦合系统


<details>
  <summary>Details</summary>
Motivation: 研究热方程在傅里叶边界条件（∂_νy+by=f1_γ）下的控制问题，其中控制作用在边界的小区域γ上，解决这类边界控制支撑在小区域上的零可控性问题

Method: 首先建立热方程的Carleman不等式，然后将其应用于边界控制支撑在小区域上的零可控性问题，通过耦合抛物方程组获得显式解，并基于此提出迭代数值方法求解耦合系统

Result: 成功建立了热方程的Carleman不等式，解决了傅里叶边界条件下边界控制支撑在小区域上的零可控性问题，获得了耦合抛物方程组的显式解，并提出了有效的迭代数值方法

Conclusion: 该工作为热方程在傅里叶边界条件下的边界控制问题提供了理论分析和数值求解框架，特别是对于控制作用在边界小区域的情况，具有重要的理论和应用价值

Abstract: In this work, we establish a Carleman inequality for the heat equation with Fourier boundary conditions of the form $\partial_νy+by=f1_γ$, where the control acts on a small portion $γ$ of the boundary. We apply this inequality to address the null controllability problem with boundary control supported on this small region. An explicit solution to this problem is obtained via a system of coupled parabolic equations. Based on these results, we propose an iterative numerical method to solve the coupled system.

</details>


### [160] [Data Informativeness in Linear Optimization under Uncertainty](https://arxiv.org/abs/2602.15365)
*Omar Bennouna,Amine Bennouna,Saurabh Amin,Asuman Ozdaglar*

Main category: math.OC

TL;DR: 论文提出了一种基于决策的数据信息性概念，用于确定在部分信息下解决决策问题所需的最小数据集，并开发了可计算算法。


<details>
  <summary>Details</summary>
Motivation: 当只能获得世界状态的部分信息时，需要确定解决决策任务所需的数据。现有方法通常关注估计器设计，但缺乏对数据本身是否足以恢复最优决策的系统分析。

Method: 针对线性规划问题，引入决策聚焦的数据信息性概念，抽象掉估计器设计。主要结果提供了数据充分性的几何特征：数据集充分当且仅当它能捕捉所有可能改变最优解的成本方向。基于此特征，开发了在一般数据收集约束下确定最小充分数据集的算法。

Result: 提出了一个原则性的任务感知数据收集框架，并在两个应用中验证：基础设施设计的现场实验选址和最优招聘决策的面试候选人选择。结果表明，精心选择的小数据集通常足以确定最优决策。

Conclusion: 该工作为任务感知数据收集提供了理论基础和实用工具，能够识别最小充分数据集，从而在数据收集成本高昂的场景中实现高效决策。

Abstract: We study the problem of determining what data is required to solve a decision-making task when only partial information about the state of the world is available. Focusing on linear programs, we introduce a decision-focused notion of data informativeness that formalizes when a data set is sufficient to recover the optimal decision. Our notion abstracts away the notion of estimators (how data is used): it depends solely on the structure of the optimization task and the uncertainty. Our main result provides a geometric characterization of data sufficiency: a data set is sufficient if and only if, together with prior knowledge, it captures all cost directions that can change the optimal solution, given the task structure and the uncertainty set. Building on our characterization, we develop a tractable algorithm to determine minimal sufficient data sets under general data collection constraints. Taken together, our work introduces a principled framework for task-aware data collection. We demonstrate the approach in two applications: selecting where to conduct field experiments to inform infrastructure design and choosing which candidates to interview in order to make an optimal hiring decision. Our results illustrate that small, carefully selected data sets often suffice to determine the optimal decisions.

</details>


### [161] [A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift](https://arxiv.org/abs/2602.15370)
*Hannah Michalska,Miguel Torres-Torriti*

Main category: math.OC

TL;DR: 提出一种针对强非线性系统的稳定反馈构造方法，适用于具有漂移项且无法通过连续状态反馈稳定的仿射控制系统，不依赖Lyapunov函数但需要解决对数坐标下的非线性规划问题。


<details>
  <summary>Details</summary>
Motivation: 针对具有漂移项的强非线性仿射控制系统，这类系统通常无法通过连续状态反馈实现稳定，需要开发新的稳定控制方法。

Method: 提出一种不依赖Lyapunov函数的稳定反馈构造方法，通过在对数坐标空间中求解非线性规划"满足问题"，要求受控系统的流周期性地与对数坐标空间中某个可达集相交。

Result: 该方法避免了传统方法中所需的点到点引导要求，通过周期性相交条件实现渐近稳定性，为强非线性系统的稳定控制提供了新途径。

Conclusion: 提出了一种创新的稳定反馈构造框架，通过在对数坐标空间中定义周期性相交条件，为无法通过连续状态反馈稳定的强非线性系统提供了有效的稳定控制方案。

Abstract: The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates.

</details>


### [162] [Stochastic Games on Large Sparse Graphs](https://arxiv.org/abs/2602.15557)
*Eyal Neuman,Sturmius Tuschmann*

Main category: math.OC

TL;DR: 提出了一个在大型稀疏图上进行随机博弈的框架，涵盖连续/离散时间动态博弈和静态博弈，证明了纳什均衡的存在唯一性、相关性的指数衰减以及局部近似性。


<details>
  <summary>Details</summary>
Motivation: 研究大型稀疏图上随机博弈的理论框架，解决玩家数量巨大且结构复杂时的均衡分析问题，特别是当玩家位于图的顶点且具有异质性时的博弈分析。

Method: 使用简单、局部有限图作为玩家索引，允许有限和可数无限玩家群体，通过标记图的局部弱收敛描述渐近行为，在收缩条件下分析博弈均衡。

Result: 证明了纳什均衡的存在唯一性，建立了相关性随图距离的指数衰减，展示了全局均衡可通过截断局部博弈近似，并能从子图边界信息精确重构，证明了沿局部弱收敛图序列的均衡收敛性。

Conclusion: 该框架为大型稀疏图上的随机博弈提供了统一的理论基础，建立了均衡的存在性、唯一性、局部性和收敛性等重要理论结果，适用于超有限幺模随机图等复杂图结构。

Abstract: We introduce a framework for stochastic games on large sparse graphs, covering continuous-time and discrete-time dynamic games as well as static games. Players are indexed by the vertices of simple, locally finite graphs, allowing both finite and countably infinite populations, with asymptotics described through local weak convergence of marked graphs. The framework allows path-dependent utility functionals that may be heterogeneous across players. Under a contraction condition, we prove existence and uniqueness of Nash equilibria and establish exponential decay of correlations with graph distance. We further show that global equilibria can be approximated by truncated local games, and can even be reconstructed exactly on subgraphs given information on their boundary. Finally, we prove convergence of Nash equilibria along locally weakly convergent graph sequences, including sequences sampled from hyperfinite unimodular random graphs.

</details>


### [163] [BORWin: Exact algorithm based on a Bi-Objective Relaxation for Window-constrained problems](https://arxiv.org/abs/2602.15594)
*Christian Artigues,Pascale Bendotti,Alexandre Heintzmann,Sandra Ulrich Ngueveu,Cécile Rottner*

Main category: math.OC

TL;DR: 提出BORWin算法解决带窗口约束的混合整数最大化问题，通过双目标松弛提供上界，针对图结构问题设计标签扩展算法，在水电机组组合问题上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决带有多个上下界约束的混合整数最大化问题，其中某个约束比其他约束更严格（窗口约束），需要高效算法处理这类复杂约束问题

Method: 提出两阶段BORWin算法：第一阶段通用，通过双目标松弛额外约束提供上界族，与拉格朗日对偶界相关；第二阶段针对无环图上的窗口约束最长路径问题，利用上界设计标签扩展算法，对特殊背包结构约束可推导补充上界

Result: BORWin算法在单厂水电机组组合问题上比现有方法更高效，数值实验验证了其优越性能

Conclusion: BORWin算法为窗口约束问题提供了有效的解决方案，特别是对于具有图结构和特殊约束形式的问题，在水电机组组合等实际应用中表现出色

Abstract: A mixed integer maximization problem involving several additional constraints defined with both a lower and an upper bound is considered. It is assumed that one of such constraints is more restrictive than the others. As it can be seen as a resource window constraint, it defines the so-called window-constrained problem. From a bi-objective perspective, a 2-phase algorithm, called BORWin, is devised. It stands for Bi-Objective Relaxation for Window-constrained problems. The first phase is generic for any window-constrained problem and provides a family of upper bounds based on a bi-objective relaxation of the additional constraints. It is shown that the latter bounds strongly relate to the Lagrangian dual bounds. The second phase is derived for a variant involving a graph structure, namely the window-constrained longest-path problem on an acyclic graph. The aim is to take advantage of the upper bounds to devise an efficient label extension algorithm. It is shown that complementary upper bounds could be derived to further improve performance in some special cases. A typical example is when the additional constraints have special knapsack structures. This is the case for the Hydro-Unit Commitment problem with a single plant (1-HUC). From numerical experiments for the 1-HUC, BOR-Win appears to be very efficient compared to state-of-the-art approaches.

</details>


### [164] [Reinforcement Learning in Real Option Models](https://arxiv.org/abs/2602.15643)
*Jodi Dianetti,Giorgio Ferrari,Renyuan Xu*

Main category: math.OC

TL;DR: 提出了一种基于熵正则化的强化学习方法来解决最优停止问题，通过引入随机化停止策略平衡探索与利用，并提供了模型无关和模型相关的算法实现。


<details>
  <summary>Details</summary>
Motivation: 传统最优停止规则是确定性的，限制了强化学习中的自然探索。需要一种能够平衡探索与利用的随机化停止策略框架。

Method: 引入熵正则化到强化学习中，将问题转化为奇异随机控制问题，推导出解析解，并提出了模型相关和模型无关的策略迭代算法。

Result: 证明了正则化问题的收敛性，当熵趋于零时正则化边界收敛到经典停止阈值。算法在数值实验中表现出色，模型无关方法无需系统动态知识。

Conclusion: 该框架为不确定性下的数据驱动停止问题提供了原则性且可处理的解决方案，通过熵正则化实现了探索与利用的平衡。

Abstract: We investigate an entropy-regularized reinforcement learning (RL) approach to optimal stopping problems motivated by real option models. Classical stopping rules are strict and non-randomized, limiting natural exploration in RL settings. To address this, we introduce entropy regularization, allowing randomized stopping policies that balance exploitation and exploration. We derive an explicit analytical solution to the regularized problem and prove convergence of the associated free boundary to the classical stopping threshold as the entropy vanishes. The regularized problem admits a natural formulation as a singular stochastic control problem. Building on this structure, we propose both model-based and model-free policy iteration algorithms to learn the optimal boundary. The model-free method operates without knowledge of system dynamics, using only trajectories from the stochastic environment. We establish convergence guarantees and illustrate strong numerical performance. This framework provides a principled and tractable approach for data-driven stopping problems under uncertainty.

</details>


### [165] [All roads lead to Rome: Path-following Augmented Lagrangian Methods via Bregman Proximal Regularization](https://arxiv.org/abs/2602.15710)
*Emanuel Laude*

Main category: math.OC

TL;DR: 提出一种结合Bregman近端点算法与二阶oracle的凸复合优化方法，通过KKT算子求解，利用非欧几何实现广义自协调性，获得二次收敛速度。


<details>
  <summary>Details</summary>
Motivation: 研究凸复合优化问题的高效求解方法，结合Bregman近端点算法与二阶oracle，旨在获得类似经典拉格朗日-牛顿方法的快速收敛性能。

Method: 采用Bregman近端点算法作为外循环处理KKT算子，内循环通过最小化平滑的Bregman增广拉格朗日函数求解正则化KKT包含问题，利用非欧几何实现广义自协调性，使用牛顿法获得二次收敛。

Result: 方法在适当步长选择下实现二次收敛，通过度量次正则性框架获得外循环快速收敛率，最终得到联合复杂度界限，包含Tseng和Bertsekas的指数乘子法变体以及Pougkakiotis和Gondzio的内点增广拉格朗日方案等特例。

Conclusion: 提出了一种统一的Bregman近端增广拉格朗日方法框架，结合算子理论与非欧几何，为凸复合优化问题提供了高效的二阶求解方案，扩展了现有方法的理论框架。

Abstract: We study Bregman proximal augmented Lagrangian methods with second-order oracles for convex convex-composite optimization problems. The outer loop is an instance of the Bregman proximal point algorithm with relative errors in the sense of Solodov and Svaiter, applied to the KKT operator associated with the problem. Akin to classical Lagrange-Newton methods, including primal-dual interior point methods the Bregman proximal point algorithm repeatedly solves regularized KKT inclusions by minimizing a smooth Bregman augmented Lagrangian function, obtained after marginalizing out the multiplier variables. Thanks to non-Euclidean geometries the marginal function is generalized self-concordant and therefore within the regime of Newton's method which converges quadratically if the step-size in the outer proximal point loop is chosen carefully. The operator-theoretic viewpoint allows us to employ the framework of metric subregularity to derive fast rates for the outer loop, and eventually state a joint complexity bound. Important special cases of our framework are a proximal variant of the exponential multiplier method due to Tseng and Bertsekas and interior-point proximal augmented Lagrangian schemes closely related to those of Pougkakiotis and Gondzio.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [166] [Mixture-of-Experts under Finite-Rate Gating: Communication--Generalization Trade-offs](https://arxiv.org/abs/2602.15091)
*Ali Khalesi,Mohammad Reza Deylam Salehi*

Main category: stat.ML

TL;DR: 该论文从通信理论视角分析MoE架构的门控机制，将门控建模为有限信息率下的随机信道，推导出基于互信息的泛化界和率失真特性，揭示了门控率、表达能力和泛化之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构的门控机制研究缺乏通信理论视角，特别是在有限信息率约束下门控机制的理论分析不足。论文旨在建立门控机制的信息论框架，分析通信约束对MoE系统性能的影响。

Method: 采用通信理论视角，将MoE门控建模为有限信息率下的随机信道。在信息论学习框架下，专门化互信息泛化界，开发有限率门控的率失真特性D(R_g)，其中R_g:=I(X; T)。在标准经验率失真最优性条件下，推导出泛化误差上界。

Result: 理论分析得出通信约束MoE系统的容量感知极限，数值模拟在合成多专家模型上实证验证了门控率、表达能力和泛化之间的预测权衡关系。推导出泛化误差上界：𝔼[R(W)] ≤ D(R_g) + δ_m + √((2/m) I(S; W))。

Conclusion: 该研究为MoE架构提供了信息论分析框架，揭示了门控机制在有限通信资源下的理论极限，为设计通信高效的MoE系统提供了理论基础，并实证验证了理论预测的权衡关系。

Abstract: Mixture-of-Experts (MoE) architectures decompose prediction tasks into specialized expert sub-networks selected by a gating mechanism. This letter adopts a communication-theoretic view of MoE gating, modeling the gate as a stochastic channel operating under a finite information rate. Within an information-theoretic learning framework, we specialize a mutual-information generalization bound and develop a rate-distortion characterization $D(R_g)$ of finite-rate gating, where $R_g:=I(X; T)$, yielding (under a standard empirical rate-distortion optimality condition) $\mathbb{E}[R(W)] \le D(R_g)+δ_m+\sqrt{(2/m)\, I(S; W)}$. The analysis yields capacity-aware limits for communication-constrained MoE systems, and numerical simulations on synthetic multi-expert models empirically confirm the predicted trade-offs between gating rate, expressivity, and generalization.

</details>


### [167] [Universal priors: solving empirical Bayes via Bayesian inference and pretraining](https://arxiv.org/abs/2602.15136)
*Nick Cannella,Anzo Teh,Yanjun Han,Yury Polyanskiy*

Main category: stat.ML

TL;DR: 论文从理论上解释了预训练Transformer在经验贝叶斯问题上的强性能，通过分析后验收缩现象，证明了存在通用先验使得训练后的模型能在任意测试分布上获得近乎最优的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解释Teh等人(2025)的实证发现：在合成数据上预训练的Transformer在经验贝叶斯问题上表现优异。研究动机是理解为什么在特定训练分布下预训练的贝叶斯估计器能够适应任意测试分布。

Method: 采用间接分析方法，不直接分析模型架构或训练动态，而是关注泊松经验贝叶斯问题。识别存在通用先验，使得在这些先验下训练能获得近乎最优的遗憾界。分析基于贝叶斯统计中的后验收缩现象。

Result: 证明了存在通用先验，使得训练后的模型在所有测试分布上获得近乎最优的遗憾界 $\widetilde{O}(\frac{1}{n})$。同时解释了长度泛化现象，即模型使用广义后验进行贝叶斯推断。

Conclusion: 预训练Transformer通过后验收缩机制适应未知测试分布，这解释了其在经验贝叶斯问题上的强性能。模型本质上是在执行贝叶斯推断，使用广义后验来处理超出训练长度的序列。

Abstract: We theoretically justify the recent empirical finding of [Teh et al., 2025] that a transformer pretrained on synthetically generated data achieves strong performance on empirical Bayes (EB) problems. We take an indirect approach to this question: rather than analyzing the model architecture or training dynamics, we ask why a pretrained Bayes estimator, trained under a prespecified training distribution, can adapt to arbitrary test distributions. Focusing on Poisson EB problems, we identify the existence of universal priors such that training under these priors yields a near-optimal regret bound of $\widetilde{O}(\frac{1}{n})$ uniformly over all test distributions. Our analysis leverages the classical phenomenon of posterior contraction in Bayesian statistics, showing that the pretrained transformer adapts to unknown test distributions precisely through posterior contraction. This perspective also explains the phenomenon of length generalization, in which the test sequence length exceeds the training length, as the model performs Bayesian inference using a generalized posterior.

</details>


### [168] [Sparse Additive Model Pruning for Order-Based Causal Structure Learning](https://arxiv.org/abs/2602.15306)
*Kentaro Kanamori,Hirofumi Suzuki,Takuya Takagi*

Main category: stat.ML

TL;DR: 提出基于稀疏加性模型的新剪枝方法，用于因果结构学习中的后处理步骤，比现有方法更快且保持或提升准确性


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法中的剪枝步骤（如CAM-pruning）存在计算瓶颈（需重复拟合加性模型）和多重检验问题，影响计算效率和估计质量

Method: 结合随机树嵌入技术和组稀疏回归，学习稀疏加性模型，直接剪枝冗余边而不依赖假设检验

Result: 在合成和真实数据集上的实验表明，新方法显著快于现有剪枝方法，同时保持相当或更优的准确性

Conclusion: 提出的基于稀疏加性模型的剪枝方法有效解决了现有方法的计算瓶颈和多重检验问题，为因果结构学习提供了更高效的解决方案

Abstract: Causal structure learning, also known as causal discovery, aims to estimate causal relationships between variables as a form of a causal directed acyclic graph (DAG) from observational data. One of the major frameworks is the order-based approach that first estimates a topological order of the underlying DAG and then prunes spurious edges from the fully-connected DAG induced by the estimated topological order. Previous studies often focus on the former ordering step because it can dramatically reduce the search space of DAGs. In practice, the latter pruning step is equally crucial for ensuring both computational efficiency and estimation accuracy. Most existing methods employ a pruning technique based on generalized additive models and hypothesis testing, commonly known as CAM-pruning. However, this approach can be a computational bottleneck as it requires repeatedly fitting additive models for all variables. Furthermore, it may harm estimation quality due to multiple testing. To address these issues, we introduce a new pruning method based on sparse additive models, which enables direct pruning of redundant edges without relying on hypothesis testing. We propose an efficient algorithm for learning sparse additive models by combining the randomized tree embedding technique with group-wise sparse regression. Experimental results on both synthetic and real datasets demonstrated that our method is significantly faster than existing pruning methods while maintaining comparable or superior accuracy.

</details>


### [169] [Functional Central Limit Theorem for Stochastic Gradient Descent](https://arxiv.org/abs/2602.15538)
*Kessang Flamand,Victor-Emmanuel Brunel*

Main category: stat.ML

TL;DR: 论文研究了随机梯度下降算法应用于凸目标函数时轨迹的渐近形状，证明了适当缩放后的轨迹满足函数中心极限定理，刻画了算法在最小值附近的长期波动特性。


<details>
  <summary>Details</summary>
Motivation: 现有中心极限定理主要关注最后迭代或Polyak-Ruppert平均，但缺乏对算法轨迹时间结构波动的理解，特别是在非光滑设置下的分析。

Method: 在温和的正则性假设下，对随机梯度下降算法的轨迹进行适当缩放，证明其满足函数中心极限定理，将轨迹的长期波动特征化为扩散极限。

Result: 获得了随机梯度下降轨迹的函数中心极限定理，该结果能够捕捉波动的时间结构，并适用于非光滑设置，如稳健位置估计（包括几何中位数）。

Conclusion: 随机梯度下降算法的轨迹在适当缩放后收敛于扩散过程，这为理解算法在凸优化中的长期波动行为提供了新的理论框架，特别适用于非光滑优化问题。

Abstract: We study the asymptotic shape of the trajectory of the stochastic gradient descent algorithm applied to a convex objective function. Under mild regularity assumptions, we prove a functional central limit theorem for the properly rescaled trajectory. Our result characterizes the long-term fluctuations of the algorithm around the minimizer by providing a diffusion limit for the trajectory. In contrast with classical central limit theorems for the last iterate or Polyak-Ruppert averages, this functional result captures the temporal structure of the fluctuations and applies to non-smooth settings such as robust location estimation, including the geometric median.

</details>
