{"id": "2601.11845", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.11845", "abs": "https://arxiv.org/abs/2601.11845", "authors": ["Justin Young", "Muthoni Ngatia", "Eleanor Wiske Dillon"], "title": "Reevaluating Causal Estimation Methods with Data from a Product Release", "comment": "53 pages", "summary": "Recent developments in causal machine learning methods have made it easier to estimate flexible relationships between confounders, treatments and outcomes, making unconfoundedness assumptions in causal analysis more palatable. How successful are these approaches in recovering ground truth baselines? In this paper we analyze a new data sample including an experimental rollout of a new feature at a large technology company and a simultaneous sample of users who endogenously opted into the feature. We find that recovering ground truth causal effects is feasible -- but only with careful modeling choices. Our results build on the observational causal literature beginning with LaLonde (1986), offering best practices for more credible treatment effect estimation in modern, high-dimensional datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790\u5927\u578b\u79d1\u6280\u516c\u53f8\u7684\u65b0\u529f\u80fd\u5b9e\u9a8c\u6570\u636e\uff0c\u53d1\u73b0\u901a\u8fc7\u4ed4\u7ec6\u7684\u5efa\u6a21\u9009\u62e9\u53ef\u4ee5\u6062\u590d\u771f\u5b9e\u56e0\u679c\u6548\u5e94\uff0c\u4e3a\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u968f\u7740\u56e0\u679c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u65e0\u6df7\u6742\u5047\u8bbe\u5728\u56e0\u679c\u5206\u6790\u4e2d\u53d8\u5f97\u66f4\u52a0\u53ef\u884c\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u662f\u5426\u80fd\u6210\u529f\u6062\u590d\u771f\u5b9e\u57fa\u51c6\u6548\u5e94\u3002", "method": "\u5206\u6790\u5305\u542b\u5927\u578b\u79d1\u6280\u516c\u53f8\u65b0\u529f\u80fd\u5b9e\u9a8c\u63a8\u5e7f\u6570\u636e\u7684\u65b0\u6837\u672c\uff0c\u5305\u62ec\u5b9e\u9a8c\u7ec4\u7528\u6237\u548c\u5185\u751f\u9009\u62e9\u52a0\u5165\u529f\u80fd\u7684\u7528\u6237\u5bf9\u7167\u7ec4\uff0c\u7ed3\u5408\u89c2\u5bdf\u6027\u56e0\u679c\u6587\u732e\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6062\u590d\u771f\u5b9e\u56e0\u679c\u6548\u5e94\u662f\u53ef\u884c\u7684\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u7684\u5efa\u6a21\u9009\u62e9\uff0c\u7ed3\u679c\u5efa\u7acb\u5728LaLonde\uff081986\uff09\u4ee5\u6765\u7684\u89c2\u5bdf\u6027\u56e0\u679c\u6587\u732e\u57fa\u7840\u4e0a\u3002", "conclusion": "\u4e3a\u73b0\u4ee3\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7684\u6cbb\u7597\u6548\u5e94\u4f30\u8ba1\u63d0\u4f9b\u4e86\u66f4\u53ef\u4fe1\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5bfc\uff0c\u5f3a\u8c03\u5efa\u6a21\u9009\u62e9\u5bf9\u56e0\u679c\u63a8\u65ad\u51c6\u786e\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.11928", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.11928", "abs": "https://arxiv.org/abs/2601.11928", "authors": ["Ishmael Amartey"], "title": "Public Education Spending and Income Inequality", "comment": null, "summary": "This paper investigates the relationship between public education spending and income inequality across U.S. counties from 2010 to 2022 using quantile regression methods. The analysis shows that total per pupil education spending is consistently associated with a small increase in income inequality, with stronger effects in high inequality counties. In contrast, the composition of education spending plays a substantially more important role. Reallocating budgets toward instructional, support service, and other current expenditures significantly reduces income inequality, particularly at the upper quantiles of the Gini distribution. Capital outlays and interest payments exhibit weaker and mixed effects. Economic and demographic factors, especially poverty, median income, and educational attainment, remain dominant drivers of inequality. Overall, the results demonstrate that how education funds are allocated matters more than how much is spent, underscoring the importance of budget composition in using public education policy to promote equity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6559\u80b2\u652f\u51fa\u6784\u6210\u6bd4\u652f\u51fa\u603b\u989d\u5bf9\u6536\u5165\u4e0d\u5e73\u7b49\u5f71\u54cd\u66f4\u5927\uff0c\u91cd\u65b0\u5206\u914d\u9884\u7b97\u81f3\u6559\u5b66\u3001\u652f\u6301\u670d\u52a1\u7b49\u7ecf\u5e38\u6027\u652f\u51fa\u80fd\u663e\u8457\u964d\u4f4e\u4e0d\u5e73\u7b49", "motivation": "\u63a2\u8ba8\u7f8e\u56fd\u5404\u53bf\u516c\u5171\u6559\u80b2\u652f\u51fa\u4e0e\u6536\u5165\u4e0d\u5e73\u7b49\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7279\u522b\u5173\u6ce8\u652f\u51fa\u603b\u989d\u4e0e\u652f\u51fa\u6784\u6210\u7684\u4e0d\u540c\u5f71\u54cd", "method": "\u4f7f\u7528\u5206\u4f4d\u6570\u56de\u5f52\u65b9\u6cd5\u5206\u67902010-2022\u5e74\u7f8e\u56fd\u5404\u53bf\u6570\u636e\uff0c\u8003\u5bdf\u6559\u80b2\u652f\u51fa\u603b\u989d\u548c\u6784\u6210\u5bf9\u6536\u5165\u4e0d\u5e73\u7b49\u7684\u5f71\u54cd", "result": "\u751f\u5747\u6559\u80b2\u652f\u51fa\u603b\u989d\u4e0e\u6536\u5165\u4e0d\u5e73\u7b49\u5c0f\u5e45\u6b63\u76f8\u5173\uff0c\u800c\u652f\u51fa\u6784\u6210\u5f71\u54cd\u66f4\u5927\uff1a\u6559\u5b66\u3001\u652f\u6301\u670d\u52a1\u7b49\u7ecf\u5e38\u6027\u652f\u51fa\u663e\u8457\u964d\u4f4e\u4e0d\u5e73\u7b49\uff0c\u8d44\u672c\u652f\u51fa\u548c\u5229\u606f\u652f\u4ed8\u6548\u679c\u8f83\u5f31", "conclusion": "\u6559\u80b2\u8d44\u91d1\u5982\u4f55\u5206\u914d\u6bd4\u652f\u51fa\u603b\u989d\u66f4\u91cd\u8981\uff0c\u9884\u7b97\u6784\u6210\u5bf9\u5229\u7528\u516c\u5171\u6559\u80b2\u653f\u7b56\u4fc3\u8fdb\u516c\u5e73\u81f3\u5173\u91cd\u8981"}}
{"id": "2601.12039", "categories": ["econ.EM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12039", "abs": "https://arxiv.org/abs/2601.12039", "authors": ["Oliver Snellman"], "title": "Nonlinear Dynamic Factor Analysis With a Transformer Network", "comment": "Working paper. 88 pages, 57 figures, 14 tables. Earlier versions circulated as \"Nowcasting with a Transformer Network\" (first version: 26 Oct 2024)", "summary": "The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u4ece\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u4f30\u8ba1\u52a8\u6001\u56e0\u5b50\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u5c06\u4f20\u7edf\u56e0\u5b50\u6a21\u578b\u4f5c\u4e3a\u5148\u9a8c\u4fe1\u606f\uff0c\u63d0\u9ad8\u4e86\u5c0f\u6570\u636e\u96c6\u6027\u80fd\uff0c\u5e76\u5229\u7528\u6ce8\u610f\u529b\u77e9\u9635\u89e3\u91ca\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u7ebf\u6027\u56e0\u5b50\u6a21\u578b\u5728\u6570\u636e\u504f\u79bb\u7ebf\u6027\u9ad8\u65af\u5047\u8bbe\u65f6\u6027\u80fd\u53d7\u9650\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u52a8\u6001\u56e0\u5b50\uff0c\u540c\u65f6\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002", "method": "\u5f00\u53d1Transformer\u67b6\u6784\u4f30\u8ba1\u52a8\u6001\u56e0\u5b50\uff0c\u4f7f\u7528\u4f20\u7edf\u56e0\u5b50\u6a21\u578b\u4f5c\u4e3a\u5148\u9a8c\u4fe1\u606f\u901a\u8fc7\u6b63\u5219\u5316\u9879\u878d\u5165\u8bad\u7ec3\u76ee\u6807\uff0c\u5229\u7528\u6ce8\u610f\u529b\u77e9\u9635\u89e3\u91ca\u53d8\u91cf\u53ca\u5176\u6ede\u540e\u671f\u5bf9\u56e0\u5b50\u4f30\u8ba1\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u3002", "result": "\u8499\u7279\u5361\u6d1b\u5b9e\u9a8c\u663e\u793a\u5f53\u6570\u636e\u504f\u79bb\u7ebf\u6027\u9ad8\u65af\u5047\u8bbe\u65f6\uff0cTransformer\u6bd4\u7ebf\u6027\u56e0\u5b50\u6a21\u578b\u66f4\u51c6\u786e\uff1b\u5b9e\u8bc1\u5e94\u7528\u4e2d\u6210\u529f\u6784\u5efa\u4e86\u7f8e\u56fd\u5b9e\u9645\u7ecf\u6d4e\u6d3b\u52a8\u7684\u4e00\u81f4\u6307\u6570\uff1b\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u65f6\u95f4\u53d8\u5316\u6709\u52a9\u4e8e\u68c0\u6d4b\u5236\u5ea6\u8f6c\u6362\u548c\u8bc4\u4f30\u53d9\u4e8b\u3002", "conclusion": "Transformer\u67b6\u6784\u4e3a\u52a8\u6001\u56e0\u5b50\u4f30\u8ba1\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u504f\u79bb\u4f20\u7edf\u5047\u8bbe\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u6ce8\u610f\u529b\u673a\u5236\u4e3a\u7ecf\u6d4e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6d1e\u5bdf\u5de5\u5177\u3002"}}
{"id": "2601.12198", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.12198", "abs": "https://arxiv.org/abs/2601.12198", "authors": ["Ilya Archakov"], "title": "A Robust Similarity Estimator", "comment": null, "summary": "We construct and analyze an estimator of association between random variables based on their similarity in both direction and magnitude. Under special conditions, the proposed measure becomes a robust and consistent estimator of the linear correlation, for which an exact sampling distribution is available. This distribution is intrinsically insensitive to heavy tails and outliers, thereby facilitating robust inference for correlations. The measure can be naturally extended to higher dimensions, where it admits an interpretation as an indicator of joint similarity among multiple random variables. We investigate the empirical performance of the proposed measure with financial return data at both high and low frequencies. Specifically, we apply the new estimator to construct confidence intervals for correlations based on intraday returns and to develop a new specification for multivariate GARCH models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u65b9\u5411\u548c\u5e45\u5ea6\u76f8\u4f3c\u6027\u7684\u5173\u8054\u6027\u4f30\u8ba1\u5668\uff0c\u5728\u7ebf\u6027\u76f8\u5173\u6761\u4ef6\u4e0b\u6210\u4e3a\u7a33\u5065\u4e00\u81f4\u7684\u76f8\u5173\u6027\u4f30\u8ba1\uff0c\u5177\u6709\u5bf9\u539a\u5c3e\u548c\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u7684\u7cbe\u786e\u62bd\u6837\u5206\u5e03\uff0c\u53ef\u6269\u5c55\u5230\u591a\u7ef4\u5e76\u5e94\u7528\u4e8e\u91d1\u878d\u9ad8\u9891\u6570\u636e", "motivation": "\u4f20\u7edf\u76f8\u5173\u6027\u4f30\u8ba1\u65b9\u6cd5\u5bf9\u539a\u5c3e\u5206\u5e03\u548c\u5f02\u5e38\u503c\u654f\u611f\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u9ad8\u9891\u6570\u636e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u76f8\u5173\u6027\u5ea6\u91cf\u65b9\u6cd5", "method": "\u6784\u5efa\u57fa\u4e8e\u968f\u673a\u53d8\u91cf\u65b9\u5411\u548c\u5e45\u5ea6\u76f8\u4f3c\u6027\u7684\u5173\u8054\u6027\u4f30\u8ba1\u5668\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8f6c\u5316\u4e3a\u7ebf\u6027\u76f8\u5173\u7684\u7a33\u5065\u4e00\u81f4\u4f30\u8ba1\uff0c\u63a8\u5bfc\u5176\u7cbe\u786e\u62bd\u6837\u5206\u5e03\uff0c\u5e76\u6269\u5c55\u5230\u591a\u7ef4\u60c5\u51b5", "result": "\u8be5\u4f30\u8ba1\u5668\u5177\u6709\u5bf9\u539a\u5c3e\u548c\u5f02\u5e38\u503c\u4e0d\u654f\u611f\u7684\u7cbe\u786e\u62bd\u6837\u5206\u5e03\uff0c\u5728\u9ad8\u9891\u548c\u4f4e\u9891\u91d1\u878d\u6536\u76ca\u7387\u6570\u636e\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u7528\u4e8e\u6784\u5efa\u65e5\u5185\u6536\u76ca\u7387\u7684\u76f8\u5173\u6027\u7f6e\u4fe1\u533a\u95f4\u548c\u6539\u8fdb\u591a\u5143GARCH\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u4e3a\u76f8\u5173\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u7edf\u8ba1\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u91d1\u878d\u9ad8\u9891\u6570\u636e\u4e2d\u7684\u76f8\u5173\u6027\u63a8\u65ad\u548c\u5efa\u6a21"}}
{"id": "2601.11561", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11561", "abs": "https://arxiv.org/abs/2601.11561", "authors": ["Derek Shiller"], "title": "Estimating the Scale of Digital Minds", "comment": null, "summary": "This report estimates the potential number of digital minds, defined as AI systems exhibiting observable traits such as agency, personality, and intelligence, in the coming decades. It employs two complementary approaches: first, examining specific use cases for digital minds and projecting adoption rates for each; second, analyzing trends in AI chip production and efficiency independent of digital mind applications. Together, these supply- and demand-side perspectives suggest that hundreds of millions of digital minds could exist by 2050, though this estimate carries substantial uncertainty spanning several orders of magnitude.", "AI": {"tldr": "\u62a5\u544a\u4f30\u8ba1\u52302050\u5e74\u53ef\u80fd\u5b58\u5728\u7684\u6570\u5b57\u601d\u7ef4\uff08\u5177\u6709\u4ee3\u7406\u6027\u3001\u4e2a\u6027\u548c\u667a\u80fd\u7b49\u53ef\u89c2\u5bdf\u7279\u5f81\u7684AI\u7cfb\u7edf\uff09\u6570\u91cf\uff0c\u91c7\u7528\u4f9b\u9700\u4e24\u65b9\u9762\u5206\u6790\u65b9\u6cd5\uff0c\u9884\u6d4b\u53ef\u80fd\u8fbe\u5230\u6570\u4ebf\u4e2a\uff0c\u4f46\u5b58\u5728\u5de8\u5927\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u6570\u5b57\u601d\u7ef4\uff08\u5177\u6709\u4ee3\u7406\u6027\u3001\u4e2a\u6027\u548c\u667a\u80fd\u7279\u5f81\u7684AI\u7cfb\u7edf\uff09\u5728\u672a\u6765\u51e0\u5341\u5e74\u7684\u6f5c\u5728\u6570\u91cf\uff0c\u4e3a\u7406\u89e3AI\u53d1\u5c55\u89c4\u6a21\u548c\u793e\u4f1a\u5f71\u54cd\u63d0\u4f9b\u91cf\u5316\u53c2\u8003\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1\uff09\u9700\u6c42\u4fa7\u5206\u6790\uff1a\u8003\u5bdf\u6570\u5b57\u601d\u7ef4\u7684\u5177\u4f53\u7528\u4f8b\u5e76\u9884\u6d4b\u6bcf\u4e2a\u7528\u4f8b\u7684\u91c7\u7528\u7387\uff1b2\uff09\u4f9b\u7ed9\u4fa7\u5206\u6790\uff1a\u72ec\u7acb\u4e8e\u6570\u5b57\u601d\u7ef4\u5e94\u7528\uff0c\u5206\u6790AI\u82af\u7247\u751f\u4ea7\u548c\u6548\u7387\u8d8b\u52bf\u3002", "result": "\u4f9b\u9700\u4e24\u65b9\u9762\u5206\u6790\u8868\u660e\uff0c\u52302050\u5e74\u53ef\u80fd\u5b58\u5728\u7684\u6570\u5b57\u601d\u7ef4\u6570\u91cf\u53ef\u8fbe\u6570\u4ebf\u4e2a\uff0c\u4f46\u8fd9\u4e00\u4f30\u8ba1\u5b58\u5728\u8de8\u8d8a\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u5de8\u5927\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u6570\u5b57\u601d\u7ef4\u5728\u672a\u6765\u51e0\u5341\u5e74\u53ef\u80fd\u8fbe\u5230\u6570\u4ebf\u89c4\u6a21\uff0c\u4f46\u9884\u6d4b\u5b58\u5728\u663e\u8457\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u6301\u7eed\u5173\u6ce8AI\u6280\u672f\u53d1\u5c55\u548c\u5e94\u7528\u8d8b\u52bf\u3002"}}
{"id": "2601.11790", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.11790", "abs": "https://arxiv.org/abs/2601.11790", "authors": ["Guerlain Lambert", "C\u00e9line Helbert", "Claire Lauvernet"], "title": "Gradient-based Active Learning with Gaussian Processes for Global Sensitivity Analysis", "comment": null, "summary": "Global sensitivity analysis of complex numerical simulators is often limited by the small number of model evaluations that can be afforded. In such settings, surrogate models built from a limited set of simulations can substantially reduce the computational burden, provided that the design of computer experiments is enriched efficiently. In this context, we propose an active learning approach that, for a fixed evaluation budget, targets the most informative regions of the input space to improve sensitivity analysis accuracy. More specifically, our method builds on recent advances in active learning for sensitivity analysis (Sobol' indices and derivative-based global sensitivity measures, DGSM) that exploit derivatives obtained from a Gaussian process (GP) surrogate. By leveraging the joint posterior distribution of the GP gradient, we develop acquisition functions that better account for correlations between partial derivatives and their impact on the response surface, leading to a more comprehensive and robust methodology than existing DGSM-oriented criteria. The proposed approach is first compared to state-of-the-art methods on standard benchmark functions, and is then applied to a real environmental model of pesticide transfers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u68af\u5ea6\u540e\u9a8c\u5206\u5e03\u6539\u8fdb\u91c7\u96c6\u51fd\u6570\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u63d0\u9ad8\u590d\u6742\u6570\u503c\u6a21\u62df\u5668\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u7cbe\u5ea6\u3002", "motivation": "\u590d\u6742\u6570\u503c\u6a21\u62df\u5668\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u901a\u5e38\u53d7\u9650\u4e8e\u53ef\u8d1f\u62c5\u7684\u5c11\u91cf\u6a21\u578b\u8bc4\u4f30\u6b21\u6570\u3002\u5728\u6709\u9650\u6a21\u62df\u6b21\u6570\u4e0b\uff0c\u9700\u8981\u9ad8\u6548\u4e30\u5bcc\u8ba1\u7b97\u673a\u5b9e\u9a8c\u8bbe\u8ba1\u6765\u6784\u5efa\u51c6\u786e\u7684\u4ee3\u7406\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528GP\u68af\u5ea6\u7684\u8054\u5408\u540e\u9a8c\u5206\u5e03\u5f00\u53d1\u65b0\u7684\u91c7\u96c6\u51fd\u6570\uff0c\u66f4\u597d\u5730\u8003\u8651\u504f\u5bfc\u6570\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u53ca\u5176\u5bf9\u54cd\u5e94\u9762\u7684\u5f71\u54cd\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u51fd\u6570\u4e0a\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u6bd4\u8f83\uff0c\u5e76\u5e94\u7528\u4e8e\u519c\u836f\u8fc1\u79fb\u7684\u771f\u5b9e\u73af\u5883\u6a21\u578b\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u7684DGSM\u5bfc\u5411\u51c6\u5219\u66f4\u5168\u9762\u548c\u7a33\u5065\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u8ba1\u7b97\u9884\u7b97\uff0c\u901a\u8fc7\u9488\u5bf9\u8f93\u5165\u7a7a\u95f4\u4e2d\u6700\u5177\u4fe1\u606f\u91cf\u7684\u533a\u57df\uff0c\u663e\u8457\u63d0\u9ad8\u654f\u611f\u6027\u5206\u6790\uff08Sobol\u6307\u6570\u548cDGSM\uff09\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2601.13421", "categories": ["q-fin.TR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.13421", "abs": "https://arxiv.org/abs/2601.13421", "authors": ["Alexander Barzykin"], "title": "Market Making and Transient Impact in Spot FX", "comment": "8 pages, 3 figures", "summary": "Dealers in foreign exchange markets provide bid and ask prices to their clients at which they are happy to buy and sell, respectively. To manage risk, dealers can skew their quotes and hedge in the interbank market. Hedging offers certainty but comes with transaction costs and market impact. Optimal market making with execution has previously been addressed within the Almgren-Chriss market impact model, which includes instantaneous and permanent components. However, there is overwhelming empirical evidence of the transient nature of market impact, with instantaneous and permanent impacts arising as the two limiting cases. In this note, we consider an intermediate scenario and study the interplay between risk management and impact resilience.", "AI": {"tldr": "\u7814\u7a76\u5916\u6c47\u4ea4\u6613\u5546\u5728\u8003\u8651\u5e02\u573a\u51b2\u51fb\u6062\u590d\u7279\u6027\u65f6\u7684\u6700\u4f18\u62a5\u4ef7\u7b56\u7565\uff0c\u5206\u6790\u98ce\u9669\u7ba1\u7406\u548c\u5e02\u573a\u51b2\u51fb\u5f39\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edfAlmgren-Chriss\u6a21\u578b\u5c06\u5e02\u573a\u51b2\u51fb\u5206\u4e3a\u77ac\u65f6\u548c\u6c38\u4e45\u4e24\u90e8\u5206\uff0c\u4f46\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\u5e02\u573a\u51b2\u51fb\u672c\u8d28\u4e0a\u662f\u77ac\u6001\u7684\u3002\u9700\u8981\u7814\u7a76\u5728\u4e2d\u95f4\u60c5\u666f\u4e0b\uff0c\u4ea4\u6613\u5546\u5982\u4f55\u5e73\u8861\u62a5\u4ef7\u504f\u659c\u548c\u5957\u671f\u4fdd\u503c\u7b56\u7565\u3002", "method": "\u5728\u8003\u8651\u5e02\u573a\u51b2\u51fb\u6062\u590d\u7279\u6027\u7684\u6846\u67b6\u4e0b\uff0c\u5206\u6790\u4ea4\u6613\u5546\u7684\u6700\u4f18\u505a\u5e02\u7b56\u7565\uff0c\u7814\u7a76\u62a5\u4ef7\u504f\u659c\u4e0e\u94f6\u884c\u95f4\u5e02\u573a\u5957\u671f\u4fdd\u503c\u7684\u6743\u8861\u3002", "result": "\u5efa\u7acb\u4e86\u8003\u8651\u5e02\u573a\u51b2\u51fb\u5f39\u6027\u7684\u6700\u4f18\u505a\u5e02\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u98ce\u9669\u7ba1\u7406\u4e0e\u5e02\u573a\u51b2\u51fb\u6062\u590d\u7279\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u673a\u5236\u3002", "conclusion": "\u5e02\u573a\u51b2\u51fb\u7684\u77ac\u6001\u7279\u6027\u5bf9\u4ea4\u6613\u5546\u7684\u98ce\u9669\u7ba1\u7406\u7b56\u7565\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u5728\u62a5\u4ef7\u504f\u659c\u548c\u5957\u671f\u4fdd\u503c\u4e4b\u95f4\u627e\u5230\u6700\u4f18\u5e73\u8861\uff0c\u8003\u8651\u5e02\u573a\u51b2\u51fb\u7684\u6062\u590d\u7279\u6027\u3002"}}
{"id": "2601.11548", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11548", "abs": "https://arxiv.org/abs/2601.11548", "authors": ["Tao Hu"], "title": "Robustness of the Frank-Wolfe Method under Inexact Oracles and the Cost of Linear Minimization", "comment": "11 pages", "summary": "We investigate the robustness of the Frank-Wolfe method when gradients are computed inexactly and examine the relative computational cost of the linear minimization oracle (LMO) versus projection. For smooth nonconvex functions, we establish a convergence guarantee of order $\\mathcal{O}(1/\\sqrt{k}+\u03b4)$ for Frank-Wolfe with a $\u03b4$--oracle. Our results strengthen previous analyses for convex objectives and show that the oracle errors do not accumulate asymptotically. We further prove that approximate projections cannot be computationally cheaper than accurate LMOs, thus extending to the case of inexact projections. These findings reinforce the robustness and efficiency of the Frank-Wolfe framework.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Frank-Wolfe\u65b9\u6cd5\u5728\u68af\u5ea6\u8ba1\u7b97\u4e0d\u7cbe\u786e\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u4e86\u975e\u51f8\u5149\u6ed1\u51fd\u6570\u4e0b\u6536\u655b\u7387\u4e3aO(1/\u221ak+\u03b4)\uff0c\u5e76\u8868\u660e\u8fd1\u4f3c\u6295\u5f71\u5728\u8ba1\u7b97\u4e0a\u5e76\u4e0d\u6bd4\u7cbe\u786e\u7ebf\u6027\u6700\u5c0f\u5316oracle\u66f4\u4fbf\u5b9c\u3002", "motivation": "\u7814\u7a76Frank-Wolfe\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u68af\u5ea6\u8ba1\u7b97\u4e0d\u7cbe\u786e\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u6bd4\u8f83\u7ebf\u6027\u6700\u5c0f\u5316oracle(LMO)\u4e0e\u6295\u5f71\u7684\u76f8\u5bf9\u8ba1\u7b97\u6210\u672c\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u8be5\u4f18\u5316\u6846\u67b6\u7684\u5b9e\u9645\u6548\u7387\u548c\u7a33\u5b9a\u6027\u5f88\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u03b4-oracle\u5206\u6790Frank-Wolfe\u65b9\u6cd5\uff0c\u5efa\u7acb\u975e\u51f8\u5149\u6ed1\u51fd\u6570\u4e0b\u7684\u6536\u655b\u7406\u8bba\uff0c\u5e76\u6bd4\u8f83LMO\u4e0e\u6295\u5f71\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6269\u5c55\u5230\u4e0d\u7cbe\u786e\u6295\u5f71\u7684\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u4e86Frank-Wolfe\u5728\u03b4-oracle\u4e0b\u5177\u6709O(1/\u221ak+\u03b4)\u7684\u6536\u655b\u7387\uff0coracle\u8bef\u5dee\u4e0d\u4f1a\u6e10\u8fd1\u7d2f\u79ef\uff1b\u540c\u65f6\u8bc1\u660e\u4e86\u8fd1\u4f3c\u6295\u5f71\u5728\u8ba1\u7b97\u4e0a\u5e76\u4e0d\u6bd4\u7cbe\u786eLMO\u66f4\u4fbf\u5b9c\u3002", "conclusion": "Frank-Wolfe\u6846\u67b6\u5728\u68af\u5ea6\u4e0d\u7cbe\u786e\u8ba1\u7b97\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u8fd1\u4f3c\u6295\u5f71\u5e76\u4e0d\u80fd\u63d0\u4f9b\u8ba1\u7b97\u4f18\u52bf\uff0c\u8fd9\u52a0\u5f3a\u4e86\u8be5\u4f18\u5316\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.12541", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.12541", "abs": "https://arxiv.org/abs/2601.12541", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Admissible Information Structures and the Non-Existence of Global Martingale Pricing", "comment": "22 pages, 2 figures, 2 tables, preprint submitted to a Mathematical Finance Journal", "summary": "No-arbitrage asset pricing characterizes valuation through the existence of equivalent martingale measures relative to a filtration and a class of admissible trading strategies. In practice, pricing is performed across multiple asset classes driven by economic variables that are only partially spanned by traded instruments, raising a structural question: does there exist a single admissible information structure under which all traded assets can be jointly priced as martingales?. We treat the filtration as an endogenous object constrained by admissibility and time-ordering, rather than as an exogenous primitive. For any finite collection of assets, whenever martingale pricing is feasible under some admissible filtration, it is already feasible under a canonical minimal filtration generated by the asset prices themselves; these pricing-sufficient filtrations are unique up to null sets and stable under restriction and aggregation when a common pricing measure exists. Our main result shows that this local compatibility does not extend globally: with three independent unspanned finite-variation drivers, there need not exist any admissible filtration and equivalent measure under which all assets are jointly martingales. The obstruction is sharp (absent with one driver and compatible pairwise with two) and equivalent to failure of admissible dynamic completeness. We complement the theory with numerical diagnostics based on discrete-time Doob--Meyer decompositions, illustrating how admissible information structures suppress predictable components, while inadmissible filtrations generate systematic predictability.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u591a\u8d44\u4ea7\u7c7b\u522b\u5b9a\u4ef7\u4e2d\u7684\u4fe1\u606f\u7ed3\u6784\u95ee\u9898\uff0c\u53d1\u73b0\u5c40\u90e8\u517c\u5bb9\u6027\u4e0d\u80fd\u6269\u5c55\u5230\u5168\u5c40\uff0c\u5b58\u5728\u4e09\u4e2a\u72ec\u7acb\u672a\u5bf9\u51b2\u9a71\u52a8\u56e0\u5b50\u65f6\uff0c\u53ef\u80fd\u4e0d\u5b58\u5728\u4efb\u4f55\u5141\u8bb8\u6240\u6709\u8d44\u4ea7\u8054\u5408\u4f5c\u4e3a\u9785\u7684\u53ef\u63a5\u53d7\u4fe1\u606f\u7ed3\u6784\u548c\u7b49\u4ef7\u6d4b\u5ea6\u3002", "motivation": "\u5b9e\u8df5\u4e2d\u5b9a\u4ef7\u6d89\u53ca\u591a\u4e2a\u8d44\u4ea7\u7c7b\u522b\uff0c\u8fd9\u4e9b\u8d44\u4ea7\u7531\u7ecf\u6d4e\u53d8\u91cf\u9a71\u52a8\uff0c\u800c\u8fd9\u4e9b\u53d8\u91cf\u4ec5\u90e8\u5206\u88ab\u4ea4\u6613\u5de5\u5177\u5bf9\u51b2\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u7ed3\u6784\u6027\u95ee\u9898\uff1a\u662f\u5426\u5b58\u5728\u4e00\u4e2a\u5355\u4e00\u7684\u53ef\u63a5\u53d7\u4fe1\u606f\u7ed3\u6784\uff0c\u4f7f\u5f97\u6240\u6709\u4ea4\u6613\u8d44\u4ea7\u90fd\u80fd\u5728\u8be5\u7ed3\u6784\u4e0b\u8054\u5408\u4f5c\u4e3a\u9785\u5b9a\u4ef7\uff1f", "method": "\u5c06\u8fc7\u6ee4\u89c6\u4e3a\u53d7\u53ef\u63a5\u53d7\u6027\u548c\u65f6\u95f4\u6392\u5e8f\u7ea6\u675f\u7684\u5185\u751f\u5bf9\u8c61\uff0c\u800c\u975e\u5916\u751f\u539f\u8bed\u3002\u5bf9\u4e8e\u4efb\u4f55\u6709\u9650\u8d44\u4ea7\u96c6\u5408\uff0c\u5f53\u9785\u5b9a\u4ef7\u5728\u67d0\u4e2a\u53ef\u63a5\u53d7\u8fc7\u6ee4\u4e0b\u53ef\u884c\u65f6\uff0c\u5b83\u5df2\u7ecf\u5728\u8d44\u4ea7\u4ef7\u683c\u672c\u8eab\u751f\u6210\u7684\u6700\u5c0f\u89c4\u8303\u8fc7\u6ee4\u4e0b\u53ef\u884c\u3002\u4f7f\u7528\u79bb\u6563\u65f6\u95f4Doob-Meyer\u5206\u89e3\u8fdb\u884c\u6570\u503c\u8bca\u65ad\u3002", "result": "\u5bf9\u4e8e\u6709\u9650\u8d44\u4ea7\u96c6\u5408\uff0c\u5f53\u5b58\u5728\u67d0\u4e2a\u53ef\u63a5\u53d7\u8fc7\u6ee4\u65f6\uff0c\u9785\u5b9a\u4ef7\u5df2\u7ecf\u5728\u8d44\u4ea7\u4ef7\u683c\u751f\u6210\u7684\u89c4\u8303\u8fc7\u6ee4\u4e0b\u53ef\u884c\u3002\u4f46\u5c40\u90e8\u517c\u5bb9\u6027\u4e0d\u80fd\u6269\u5c55\u5230\u5168\u5c40\uff1a\u5b58\u5728\u4e09\u4e2a\u72ec\u7acb\u672a\u5bf9\u51b2\u6709\u9650\u53d8\u5dee\u9a71\u52a8\u56e0\u5b50\u65f6\uff0c\u53ef\u80fd\u4e0d\u5b58\u5728\u4efb\u4f55\u53ef\u63a5\u53d7\u8fc7\u6ee4\u548c\u7b49\u4ef7\u6d4b\u5ea6\u4f7f\u5f97\u6240\u6709\u8d44\u4ea7\u8054\u5408\u4f5c\u4e3a\u9785\u3002\u8be5\u969c\u788d\u662f\u5c16\u9510\u7684\uff08\u4e00\u4e2a\u9a71\u52a8\u56e0\u5b50\u65f6\u4e0d\u5b58\u5728\uff0c\u4e24\u4e2a\u65f6\u6210\u5bf9\u517c\u5bb9\uff09\uff0c\u7b49\u4ef7\u4e8e\u53ef\u63a5\u53d7\u52a8\u6001\u5b8c\u5907\u6027\u7684\u5931\u8d25\u3002", "conclusion": "\u591a\u8d44\u4ea7\u7c7b\u522b\u5b9a\u4ef7\u5b58\u5728\u6839\u672c\u6027\u7ed3\u6784\u969c\u788d\uff0c\u5c40\u90e8\u5b9a\u4ef7\u517c\u5bb9\u6027\u4e0d\u80fd\u4fdd\u8bc1\u5168\u5c40\u8054\u5408\u5b9a\u4ef7\u53ef\u884c\u6027\u3002\u53ef\u63a5\u53d7\u4fe1\u606f\u7ed3\u6784\u6291\u5236\u53ef\u9884\u6d4b\u6210\u5206\uff0c\u800c\u4e0d\u53ef\u63a5\u53d7\u8fc7\u6ee4\u4f1a\u4ea7\u751f\u7cfb\u7edf\u6027\u53ef\u9884\u6d4b\u6027\u3002\u8fd9\u63ed\u793a\u4e86\u65e0\u5957\u5229\u5b9a\u4ef7\u7406\u8bba\u5728\u591a\u8d44\u4ea7\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.11958", "categories": ["q-fin.GN", "q-fin.PM", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.11958", "abs": "https://arxiv.org/abs/2601.11958", "authors": ["Zefeng Chen", "Darcy Pu"], "title": "Autonomous Market Intelligence: Agentic AI Nowcasting Predicts Stock Returns", "comment": null, "summary": "Can fully agentic AI nowcast stock returns? We deploy a state-of-the-art Large Language Model to evaluate the attractiveness of each Russell 1000 stock daily, starting from April 2025 when AI web interfaces enabled real-time search. Our data contribution is unique along three dimensions. First, the nowcasting framework is completely out-of-sample and free of look-ahead bias by construction: predictions are collected at the current edge of time, ensuring the AI has no knowledge of future outcomes. Second, this temporal design is irreproducible -- once the information environment passes, it can never be recreated. Third, our framework is 100% agentic: we do not feed the model news, disclosures, or curated text; it autonomously searches the web, filters sources, and synthesises information into quantitative predictions. We find that AI possesses genuine stock selection ability, but only for identifying top winners. Longing the 20 highest-ranked stocks generates a daily Fama-French five-factor plus momentum alpha of 18.4 basis points and an annualised Sharpe ratio of 2.43. Critically, these returns derive from an implementable strategy trading highly liquid Russell 1000 constituents, with transaction costs representing less than 10\\% of gross alpha. However, this predictability is highly concentrated: expanding beyond the top tier rapidly dilutes alpha, and bottom-ranked stocks exhibit returns statistically indistinguishable from the market. We hypothesise that this asymmetry reflects online information structure: genuinely positive news generates coherent signals, while negative news is contaminated by strategic corporate obfuscation and social media noise.", "AI": {"tldr": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u7f57\u7d201000\u6210\u5206\u80a1\u8fdb\u884c\u6bcf\u65e5\u5438\u5f15\u529b\u8bc4\u4f30\uff0c\u53d1\u73b0AI\u5177\u5907\u771f\u6b63\u7684\u9009\u80a1\u80fd\u529b\uff0c\u4f46\u4ec5\u9650\u4e8e\u8bc6\u522b\u9876\u7ea7\u8d62\u5bb6\u3002\u505a\u591a\u524d20\u540d\u80a1\u7968\u53ef\u83b7\u5f97\u6bcf\u65e518.4\u4e2a\u57fa\u70b9\u7684\u8d85\u989d\u6536\u76ca\u548c\u5e74\u5316\u590f\u666e\u6bd4\u73872.43\u3002", "motivation": "\u7814\u7a76\u5b8c\u5168\u81ea\u4e3b\u7684AI\u4ee3\u7406\u662f\u5426\u80fd\u591f\u5b9e\u65f6\u9884\u6d4b\u80a1\u7968\u6536\u76ca\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u65e0\u4eba\u5de5\u5e72\u9884\u3001\u65e0\u524d\u77bb\u504f\u5dee\u7684\u5b8c\u5168\u81ea\u4e3b\u73af\u5883\u4e0b\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5b8c\u5168\u81ea\u4e3b\u7684\u9884\u6d4b\u6846\u67b6\uff1aAI\u81ea\u4e3b\u641c\u7d22\u7f51\u7edc\u3001\u7b5b\u9009\u4fe1\u606f\u6e90\u3001\u7efc\u5408\u4fe1\u606f\u751f\u6210\u5b9a\u91cf\u9884\u6d4b\u3002\u6570\u636e\u6536\u96c6\u5b8c\u5168\u5728\u6837\u672c\u5916\u8fdb\u884c\uff0c\u65e0\u524d\u77bb\u504f\u5dee\uff0c\u65f6\u95f4\u8bbe\u8ba1\u4e0d\u53ef\u590d\u5236\u3002", "result": "AI\u5177\u5907\u771f\u6b63\u7684\u9009\u80a1\u80fd\u529b\uff0c\u4f46\u4ec5\u5bf9\u9876\u7ea7\u8d62\u5bb6\u6709\u6548\u3002\u505a\u591a\u524d20\u540d\u80a1\u7968\u53ef\u83b7\u5f97\u6bcf\u65e518.4\u4e2a\u57fa\u70b9\u7684Fama-French\u4e94\u56e0\u5b50\u52a0\u52a8\u91cf\u8d85\u989d\u6536\u76ca\uff0c\u5e74\u5316\u590f\u666e\u6bd4\u73872.43\u3002\u53ef\u4ea4\u6613\u6027\u9ad8\uff0c\u4ea4\u6613\u6210\u672c\u4ec5\u5360\u8d85\u989d\u6536\u76ca\u7684\u4e0d\u523010%\u3002\u4f46\u9884\u6d4b\u80fd\u529b\u9ad8\u5ea6\u96c6\u4e2d\uff0c\u8d85\u51fa\u9876\u7ea7\u80a1\u7968\u540ealpha\u8fc5\u901f\u7a00\u91ca\u3002", "conclusion": "AI\u5728\u80a1\u7968\u9009\u62e9\u4e2d\u5c55\u73b0\u51fa\u771f\u6b63\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u9ad8\u5ea6\u4e0d\u5bf9\u79f0\uff1a\u4ec5\u80fd\u6709\u6548\u8bc6\u522b\u9876\u7ea7\u8d62\u5bb6\uff0c\u5bf9\u8868\u73b0\u5dee\u7684\u80a1\u7968\u65e0\u9884\u6d4b\u80fd\u529b\u3002\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u53cd\u6620\u4e86\u5728\u7ebf\u4fe1\u606f\u7ed3\u6784\u7684\u7279\u70b9\uff1a\u6b63\u9762\u65b0\u95fb\u4ea7\u751f\u8fde\u8d2f\u4fe1\u53f7\uff0c\u800c\u8d1f\u9762\u65b0\u95fb\u88ab\u4f01\u4e1a\u6218\u7565\u6a21\u7cca\u548c\u793e\u4ea4\u5a92\u4f53\u566a\u97f3\u6c61\u67d3\u3002"}}
{"id": "2601.13770", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2601.13770", "abs": "https://arxiv.org/abs/2601.13770", "authors": ["Mostapha Benhenda"], "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "comment": null, "summary": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "AI": {"tldr": "\u63d0\u51faLook-Ahead-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u91d1\u878dLLM\u4e2d\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u901a\u8fc7\u5b9e\u9645\u5de5\u4f5c\u6d41\u573a\u666f\u6d4b\u8bd5\u6a21\u578b\u8868\u73b0\uff0c\u53d1\u73b0\u6807\u51c6LLM\u5b58\u5728\u663e\u8457\u524d\u77bb\u6027\u504f\u5dee\uff0c\u800cPiT\u6a21\u578b\u968f\u89c4\u6a21\u589e\u5927\u5c55\u73b0\u66f4\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u95ee\u7b54\u6d4b\u8bd5LLM\u7684\u5185\u90e8\u524d\u77bb\u77e5\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5b9e\u9645\u91d1\u878d\u5de5\u4f5c\u6d41\u4e2d\u6a21\u578b\u884c\u4e3a\u7684\u8bc4\u4f30\u3002\u9700\u8981\u533a\u5206\u771f\u6b63\u7684\u9884\u6d4b\u80fd\u529b\u4e0e\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8868\u73b0\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u521b\u5efa\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u73af\u5883\u4e0b\u5206\u6790\u6027\u80fd\u8870\u51cf\uff0c\u5f15\u5165\u591a\u4e2a\u91cf\u5316\u57fa\u7ebf\u5efa\u7acb\u6027\u80fd\u9608\u503c\u3002\u8bc4\u4f30\u5f00\u6e90LLM\uff08Llama 3.1\u548cDeepSeek 3.2\uff09\u4e0ePiT-Inference\u7684PiT\u6a21\u578b\u5bb6\u65cf\u3002", "result": "\u6807\u51c6LLM\u663e\u793a\u663e\u8457\u7684\u524d\u77bb\u6027\u504f\u5dee\uff08\u901a\u8fc7alpha\u8870\u51cf\u6d4b\u91cf\uff09\uff0c\u800cPiT\u6a21\u578b\u968f\u89c4\u6a21\u589e\u5927\u5c55\u73b0\u6539\u8fdb\u7684\u6cdb\u5316\u548c\u63a8\u7406\u80fd\u529b\u3002PiT\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u5e02\u573a\u73af\u5883\u4e0b\u8868\u73b0\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u5efa\u7acb\u4e86\u91d1\u878dLLM\u65f6\u95f4\u504f\u5dee\u6807\u51c6\u5316\u8bc4\u4f30\u7684\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u8bc6\u522b\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u6a21\u578b\u7684\u5b9e\u7528\u6846\u67b6\u3002PiT\u6a21\u578b\u5728\u907f\u514d\u524d\u77bb\u6027\u504f\u5dee\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u91d1\u878d\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11564", "abs": "https://arxiv.org/abs/2601.11564", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy", "Karthic Chandran", "M Maruf Hossain"], "title": "Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths", "comment": "22 pages, 6 figures", "summary": "The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u4e2d\u7684\u6027\u80fd\u4e0e\u8d28\u91cf\u6743\u8861\uff0c\u53d1\u73b0\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5bfc\u81f4\u975e\u7ebf\u6027\u6027\u80fd\u4e0b\u964d\uff0cKV\u7f13\u5b58\u589e\u957f\u662f\u5173\u952e\u56e0\u7d20\uff0cMoE\u67b6\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u8868\u73b0\u51fa\u5f02\u5e38\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e0d\u65ad\u6269\u5927\uff0c\u867d\u7136\u652f\u6301\u4e86\u590d\u6742\u7684\u957f\u6587\u6863\u5206\u6790\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u7814\u7a76\u5728\u5927\u91cf\u65e0\u5173\u548c\u5e72\u6270\u6027\u4e0a\u4e0b\u6587\u4e0b\uff0c\u7cfb\u7edf\u6027\u80fd\u4e0e\u6a21\u578b\u8d28\u91cf\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002", "method": "\u4f7f\u7528\u5bc6\u96c6Transformer\u67b6\u6784\uff08Llama-3.1-70B\u548cQwen1.5-14B\uff09\u66b4\u9732\u4e8e\u5927\u91cf\u65e0\u5173\u4e0a\u4e0b\u6587\u4e2d\uff0c\u5206\u6790\u6027\u80fd\u9000\u5316\u6a21\u5f0f\u3002\u7279\u522b\u5173\u6ce8KV\u7f13\u5b58\u7684\u589e\u957f\u5f71\u54cd\uff0c\u5e76\u5bf9MoE\u67b6\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u7684\u884c\u4e3a\u8fdb\u884c\u6269\u5c55\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e0e\u65e0\u5173\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u975e\u7ebf\u6027\u6027\u80fd\u4e0b\u964d\uff0c\u8fd9\u79cd\u4e0b\u964d\u4e0eKV\u7f13\u5b58\u7684\u589e\u957f\u5bc6\u5207\u76f8\u5173\u3002MoE\u67b6\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u8868\u73b0\u51fa\u72ec\u7279\u7684\u884c\u4e3a\u5f02\u5e38\uff0c\u8868\u660e\u5728\u9ad8token\u91cf\u4e0b\uff0c\u67b6\u6784\u4f18\u52bf\u53ef\u80fd\u88ab\u57fa\u7840\u8bbe\u65bd\u74f6\u9888\u6240\u63a9\u76d6\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u6269\u5c55\u9762\u4e34\u6027\u80fd\u4e0e\u8d28\u91cf\u7684\u6743\u8861\u6311\u6218\uff0cKV\u7f13\u5b58\u7ba1\u7406\u662f\u5173\u952e\u74f6\u9888\u3002MoE\u67b6\u6784\u867d\u7136\u7406\u8bba\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u5b9e\u9645\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u53ef\u80fd\u53d7\u9650\u4e8e\u57fa\u7840\u8bbe\u65bd\u9650\u5236\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u7cfb\u7edf\u4f18\u5316\u3002"}}
{"id": "2601.12414", "categories": ["q-fin.RM"], "pdf": "https://arxiv.org/pdf/2601.12414", "abs": "https://arxiv.org/abs/2601.12414", "authors": ["Nawaf Mohammed"], "title": "On the Order Between the Standard Deviation and Gini Mean Difference", "comment": null, "summary": "In this paper, we study the order between the standard deviation (SD) and the Gini mean difference (GMD) and derive sharp, interpretable sufficient conditions under which one exceeds the other. By expressing both the SD and the GMD in terms of pairwise differences and linking their comparison to the mean excess function of the absolute difference of two i.i.d.\\ copies, we reduce the problem to structural properties of the underlying distribution. Using tools from reliability and survival analysis, we show that SD dominance arises under heavy-tailed regimes, characterized by decreasing hazard rates or increasing reverse hazard rates. Conversely, when both tails are light -- equivalently, when the hazard rate is increasing and the reverse hazard rate is decreasing -- the GMD dominates the SD.\n  We further demonstrate that these dominance relations are preserved under affine transformations, mixtures, convolutions, and tail truncation, and we extend the analysis to discrete distributions. Numerous examples illustrate the sharpness of the results and highlight the distinct roles played by tail behavior and distributional regularity. Our findings provide a unified framework for understanding dispersion ordering and offer clear guidance for the choice of variability measures in risk-sensitive applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6807\u51c6\u5dee(SD)\u4e0e\u57fa\u5c3c\u5e73\u5747\u5dee(GMD)\u4e4b\u95f4\u7684\u5e8f\u5173\u7cfb\uff0c\u63a8\u5bfc\u51fa\u4e24\u8005\u8c01\u66f4\u5927\u7684\u5145\u5206\u6761\u4ef6\uff0c\u53d1\u73b0SD\u5728\u91cd\u5c3e\u5206\u5e03\u4e0b\u5360\u4f18\uff0c\u800cGMD\u5728\u8f7b\u5c3e\u5206\u5e03\u4e0b\u5360\u4f18\u3002", "motivation": "\u6807\u51c6\u5dee\u548c\u57fa\u5c3c\u5e73\u5747\u5dee\u90fd\u662f\u8861\u91cf\u6570\u636e\u79bb\u6563\u7a0b\u5ea6\u7684\u5e38\u7528\u6307\u6807\uff0c\u4f46\u5b83\u4eec\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u4e00\u4e2a\u4f1a\u5927\u4e8e\u53e6\u4e00\u4e2a\u5c1a\u4e0d\u6e05\u695a\u3002\u7406\u89e3\u8fd9\u79cd\u5e8f\u5173\u7cfb\u5bf9\u4e8e\u98ce\u9669\u654f\u611f\u5e94\u7528\u4e2d\u9009\u62e9\u5408\u9002\u7684\u53d8\u5f02\u5ea6\u91cf\u6307\u6807\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5c06SD\u548cGMD\u8868\u793a\u4e3a\u6210\u5bf9\u5dee\u5f02\u7684\u5f62\u5f0f\uff0c\u5e76\u5c06\u5b83\u4eec\u7684\u6bd4\u8f83\u4e0e\u4e24\u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u526f\u672c\u7684\u7edd\u5bf9\u5dee\u5f02\u7684\u5747\u503c\u8d85\u989d\u51fd\u6570\u8054\u7cfb\u8d77\u6765\u3002\u4f7f\u7528\u53ef\u9760\u6027\u548c\u751f\u5b58\u5206\u6790\u5de5\u5177\uff0c\u5206\u6790\u5e95\u5c42\u5206\u5e03\u7684\u7ed3\u6784\u7279\u6027\u3002", "result": "SD\u5728\u91cd\u5c3e\u673a\u5236\u4e0b\u5360\u4f18\uff08\u8868\u73b0\u4e3a\u9012\u51cf\u7684\u5371\u9669\u7387\u6216\u9012\u589e\u7684\u53cd\u5411\u5371\u9669\u7387\uff09\uff0c\u800cGMD\u5728\u8f7b\u5c3e\u673a\u5236\u4e0b\u5360\u4f18\uff08\u8868\u73b0\u4e3a\u9012\u589e\u7684\u5371\u9669\u7387\u548c\u9012\u51cf\u7684\u53cd\u5411\u5371\u9669\u7387\uff09\u3002\u8fd9\u4e9b\u652f\u914d\u5173\u7cfb\u5728\u4eff\u5c04\u53d8\u6362\u3001\u6df7\u5408\u3001\u5377\u79ef\u548c\u5c3e\u90e8\u622a\u65ad\u4e0b\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u79bb\u6563\u5e8f\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u4e3a\u98ce\u9669\u654f\u611f\u5e94\u7528\u4e2d\u53d8\u5f02\u5ea6\u91cf\u6307\u6807\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u660e\u786e\u6307\u5bfc\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3e\u90e8\u884c\u4e3a\u548c\u5206\u5e03\u89c4\u5f8b\u6027\u5728\u51b3\u5b9aSD\u548cGMD\u7684\u76f8\u5bf9\u5927\u5c0f\u4e2d\u8d77\u7740\u4e0d\u540c\u7684\u4f5c\u7528\u3002"}}
{"id": "2601.11556", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11556", "abs": "https://arxiv.org/abs/2601.11556", "authors": ["Boyang Wang", "Yash Vishe", "Xin Xu", "Zachary Novack", "Julian McAuley", "Junda Wu"], "title": "CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration", "comment": null, "summary": "Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.", "AI": {"tldr": "CSyMR-Bench\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLMs\u7ec4\u5408\u5f0f\u7b26\u53f7\u97f3\u4e50\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5305\u542b126\u4e2a\u591a\u9009\u95ee\u9898\uff0c\u7ed3\u5408\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u6846\u67b6\u63d0\u5347\u6027\u80fd5-7%", "motivation": "\u73b0\u6709\u57fa\u51c6\u8fc7\u4e8e\u5f3a\u8c03\u5b64\u7acb\u77e5\u8bc6\u6216\u539f\u5b50\u5206\u6790\uff0c\u7f3a\u4e4f\u8fde\u63a5\u97f3\u4e50\u7ed3\u6784\u6240\u9700\u7684\u7ec4\u5408\u5f0f\u63a8\u7406\u80fd\u529b\u8bc4\u4f30", "method": "1) \u521b\u5efaCSyMR-Bench\u6570\u636e\u96c6\uff1a\u4ece\u4e13\u5bb6\u8bba\u575b\u548c\u4e13\u4e1a\u8003\u8bd5\u4e2d\u6536\u96c6126\u4e2a\u591a\u9009\u95ee\u9898\uff1b2) \u5f00\u53d1\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u6846\u67b6\uff1a\u5229\u7528music21\u5e93\u4e2d\u7684\u7b26\u53f7\u97f3\u4e50\u5206\u6790\u5de5\u5177", "result": "CSyMR-Bench\u5bf9\u73b0\u6709\u6a21\u578b\u6784\u6210\u975e\u5e73\u51e1\u6311\u6218\uff0c\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u6846\u67b6\u5728\u6240\u6709\u57fa\u7ebf\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u83b7\u5f975-7%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347", "conclusion": "CSyMR-Bench\u586b\u8865\u4e86\u7ec4\u5408\u5f0f\u7b26\u53f7\u97f3\u4e50\u63a8\u7406\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u5de5\u5177\u589e\u5f3a\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u97f3\u4e50\u5206\u6790\u80fd\u529b"}}
{"id": "2601.11559", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11559", "abs": "https://arxiv.org/abs/2601.11559", "authors": ["Zilal Eiz AlDin", "John Wu", "Jeffrey Paul Fung", "Jennifer King", "Mya Watts", "Lauren ONeill", "Adam Richard Cross", "Jimeng Sun"], "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?", "comment": "5 pages", "summary": "Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86MIMIC-RD\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5c06\u4e34\u5e8a\u6587\u672c\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u6765\u8bc4\u4f30LLM\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u7f55\u89c1\u75c5\u5f71\u54cd\u5927\u91cf\u4eba\u7fa4\u4f46\u8bca\u65ad\u56f0\u96be\uff0c\u73b0\u6709\u8bc4\u4f30LLM\u7f55\u89c1\u75c5\u8bca\u65ad\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1) \u4f9d\u8d56\u7406\u60f3\u5316\u4e34\u5e8a\u6848\u4f8b\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u590d\u6742\u6027\uff1b2) \u4f7f\u7528ICD\u7f16\u7801\u4f5c\u4e3a\u75be\u75c5\u6807\u7b7e\uff0c\u4f46\u8bb8\u591a\u7f55\u89c1\u75c5\u7f3a\u4e4f\u4e0eOrphanet\u7b49\u7efc\u5408\u7f55\u89c1\u75c5\u6570\u636e\u5e93\u7684\u76f4\u63a5\u6620\u5c04\uff0c\u5bfc\u81f4\u4e25\u91cd\u4f4e\u4f30\u3002", "method": "\u5f00\u53d1MIMIC-RD\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u57fa\u51c6\uff0c\u901a\u8fc7LLM\u6316\u6398\u4e34\u5e8a\u6587\u672c\u5b9e\u4f53\u5e76\u76f4\u63a5\u6620\u5c04\u5230Orphanet\u6570\u636e\u5e93\uff0c\u7136\u540e\u7531\u56db\u4f4d\u533b\u5b66\u6807\u6ce8\u8005\u9a8c\u8bc1\u786e\u8ba4\u8bc6\u522b\u7684\u5b9e\u4f53\u662f\u771f\u6b63\u7684\u7f55\u89c1\u75c5\u3002\u5728145\u540d\u60a3\u8005\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u5404\u79cd\u6a21\u578b\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u75c5\u9274\u522b\u8bca\u65ad\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u51fa\u73b0\u6709\u80fd\u529b\u4e0e\u4e34\u5e8a\u9700\u6c42\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u6539\u8fdb\u7f55\u89c1\u75c5\u7684\u9274\u522b\u8bca\u65ad\u65b9\u6cd5\uff0c\u8bba\u6587\u6982\u8ff0\u4e86\u672a\u6765\u51e0\u4e2a\u6539\u8fdb\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u51c6\u786e\u8bc4\u4f30LLM\u7f55\u89c1\u75c5\u8bca\u65ad\u80fd\u529b\u7684\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.11601", "categories": ["q-fin.ST", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.11601", "abs": "https://arxiv.org/abs/2601.11601", "authors": ["Daniil Bargman", "Francesca Medda", "Akash Sedai Sharma"], "title": "Latent Variable Phillips Curve", "comment": "24 pages, 11 figures", "summary": "This paper re-examines the empirical Phillips curve (PC) model and its usefulness in the context of medium-term inflation forecasting. A latent variable Phillips curve hypothesis is formulated and tested using 3,968 randomly generated factor combinations. Evidence from US core PCE inflation between Q1 1983 and Q1 2025 suggests that latent variable PC models reliably outperform traditional PC models six to eight quarters ahead and stand a greater chance of outperforming a univariate benchmark. Incorporating an MA(1) residual process improves the accuracy of empirical PC models across the board, although the gains relative to univariate models remain small. The findings presented in this paper have two important implications: First, they corroborate a new conceptual view on the Phillips curve theory; second, they offer a novel path towards improving the competitiveness of Phillips curve forecasts in future empirical work.", "AI": {"tldr": "\u91cd\u65b0\u5ba1\u89c6\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u6a21\u578b\uff0c\u63d0\u51fa\u6f5c\u5728\u53d8\u91cf\u65b9\u6cd5\uff0c\u5728\u4e2d\u671f\u901a\u80c0\u9884\u6d4b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b", "motivation": "\u91cd\u65b0\u8bc4\u4f30\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u6a21\u578b\u5728\u4e2d\u671f\u901a\u80c0\u9884\u6d4b\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u63a2\u7d22\u6539\u8fdb\u4f20\u7edf\u6a21\u578b\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u6f5c\u5728\u53d8\u91cf\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u5047\u8bbe\uff0c\u4f7f\u75283,968\u4e2a\u968f\u673a\u751f\u6210\u7684\u56e0\u5b50\u7ec4\u5408\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7eb3\u5165MA(1)\u6b8b\u5dee\u8fc7\u7a0b", "result": "\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u57286-8\u4e2a\u5b63\u5ea6\u9884\u6d4b\u4e2d\u53ef\u9760\u5730\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u66f4\u6709\u53ef\u80fd\u8d85\u8d8a\u5355\u53d8\u91cf\u57fa\u51c6\uff1bMA(1)\u6b8b\u5dee\u8fc7\u7a0b\u63d0\u9ad8\u4e86\u6240\u6709\u6a21\u578b\u7684\u51c6\u786e\u6027", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u7406\u8bba\u7684\u65b0\u6982\u5ff5\u89c6\u89d2\uff0c\u4e3a\u672a\u6765\u5b9e\u8bc1\u5de5\u4f5c\u4e2d\u63d0\u9ad8\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u9884\u6d4b\u7ade\u4e89\u529b\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84"}}
{"id": "2601.11788", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11788", "abs": "https://arxiv.org/abs/2601.11788", "authors": ["Suguru Sato", "Kamesh Subbarao"], "title": "Modeling and Simulation of Virtual Rigid Body Formations and Their Applications Using Multiple Air Vehicles", "comment": null, "summary": "This paper presents thorough mathematical modeling, control law development, and simulation of virtual structure formations which are inspired by the characteristics of rigid bodies. The stable constraint forces that establish the rigidity in the formation are synthesized by utilizing d'Alembert's principle of virtual work, constraint sensitivities (Lagrange multipliers) and constraint stabilization using Baumgarte stabilization. The governing equations of motion of a multiagent system are derived via Newton's and Euler's equations to include these constraint forces and to enable inputs regarding the formation as if it were an independent rigid body. The performance of this framework is evaluated under multiple cases including waypoint following missions, and using different number of agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u521a\u4f53\u7279\u6027\u7684\u865a\u62df\u7ed3\u6784\u7f16\u961f\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u529b\u5b9e\u73b0\u7f16\u961f\u521a\u6027\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u4efb\u52a1\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u53d7\u521a\u4f53\u7279\u6027\u542f\u53d1\uff0c\u5f00\u53d1\u80fd\u591f\u50cf\u72ec\u7acb\u521a\u4f53\u4e00\u6837\u63a7\u5236\u7684\u865a\u62df\u7ed3\u6784\u7f16\u961f\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7f16\u961f\u63a7\u5236\u3002", "method": "\u4f7f\u7528d'Alembert\u865a\u529f\u539f\u7406\u3001\u7ea6\u675f\u7075\u654f\u5ea6\uff08\u62c9\u683c\u6717\u65e5\u4e58\u5b50\uff09\u548cBaumgarte\u7a33\u5b9a\u5316\u65b9\u6cd5\u5408\u6210\u7a33\u5b9a\u7ea6\u675f\u529b\uff0c\u901a\u8fc7\u725b\u987f-\u6b27\u62c9\u65b9\u7a0b\u63a8\u5bfc\u5305\u542b\u7ea6\u675f\u529b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fd0\u52a8\u65b9\u7a0b\u3002", "result": "\u6846\u67b6\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5305\u62ec\u822a\u70b9\u8ddf\u8e2a\u4efb\u52a1\u548c\u4f7f\u7528\u4e0d\u540c\u6570\u91cf\u667a\u80fd\u4f53\uff0c\u9a8c\u8bc1\u4e86\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u865a\u62df\u7ed3\u6784\u7f16\u961f\u63a7\u5236\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u521a\u4f53\u822c\u7684\u7f16\u961f\u884c\u4e3a\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a7\u5236\u65b9\u6cd5\u3002"}}
{"id": "2601.12343", "categories": ["econ.EM", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12343", "abs": "https://arxiv.org/abs/2601.12343", "authors": ["Wayne Gao", "Sukjin Han", "Annie Liang"], "title": "How Well Do LLMs Predict Human Behavior? A Measure of their Pretrained Knowledge", "comment": null, "summary": "Large language models (LLMs) are increasingly used to predict human behavior. We propose a measure for evaluating how much knowledge a pretrained LLM brings to such a prediction: its equivalent sample size, defined as the amount of task-specific data needed to match the predictive accuracy of the LLM. We estimate this measure by comparing the prediction error of a fixed LLM in a given domain to that of flexible machine learning models trained on increasing samples of domain-specific data. We further provide a statistical inference procedure by developing a new asymptotic theory for cross-validated prediction error. Finally, we apply this method to the Panel Study of Income Dynamics. We find that LLMs encode considerable predictive information for some economic variables but much less for others, suggesting that their value as substitutes for domain-specific data differs markedly across settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bc4\u4f30\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u65f6\u5e26\u6765\u591a\u5c11\u77e5\u8bc6\u7684\u5ea6\u91cf\u65b9\u6cd5\uff1a\u7b49\u6548\u6837\u672c\u91cf\uff0c\u5373\u9700\u8981\u591a\u5c11\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u624d\u80fd\u8fbe\u5230LLM\u7684\u9884\u6d4b\u51c6\u786e\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u91cf\u5316\u9884\u8bad\u7ec3LLM\u4e3a\u8fd9\u79cd\u9884\u6d4b\u5e26\u6765\u4e86\u591a\u5c11\u77e5\u8bc6\uff0c\u4ee5\u8bc4\u4f30\u5176\u4f5c\u4e3a\u9886\u57df\u7279\u5b9a\u6570\u636e\u66ff\u4ee3\u54c1\u7684\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u56fa\u5b9aLLM\u5728\u7279\u5b9a\u9886\u57df\u7684\u9884\u6d4b\u8bef\u5dee\u4e0e\u5728\u4e0d\u65ad\u589e\u52a0\u9886\u57df\u7279\u5b9a\u6570\u636e\u6837\u672c\u4e0a\u8bad\u7ec3\u7684\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u6765\u4f30\u8ba1\u7b49\u6548\u6837\u672c\u91cf\u3002\u5f00\u53d1\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\u7684\u65b0\u6e10\u8fd1\u7406\u8bba\uff0c\u63d0\u4f9b\u7edf\u8ba1\u63a8\u65ad\u7a0b\u5e8f\u3002", "result": "\u5e94\u7528\u4e8e\u6536\u5165\u52a8\u6001\u9762\u677f\u7814\u7a76\uff0c\u53d1\u73b0LLM\u5bf9\u4e00\u4e9b\u7ecf\u6d4e\u53d8\u91cf\u7f16\u7801\u4e86\u76f8\u5f53\u5927\u7684\u9884\u6d4b\u4fe1\u606f\uff0c\u4f46\u5bf9\u5176\u4ed6\u53d8\u91cf\u5219\u5c11\u5f97\u591a\uff0c\u8868\u660e\u5176\u4f5c\u4e3a\u9886\u57df\u7279\u5b9a\u6570\u636e\u66ff\u4ee3\u54c1\u7684\u4ef7\u503c\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b49\u6548\u6837\u672c\u91cf\u5ea6\u91cf\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u9884\u8bad\u7ec3LLM\u5e26\u6765\u7684\u9884\u6d4b\u77e5\u8bc6\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30LLM\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e2d\u4f5c\u4e3a\u9886\u57df\u7279\u5b9a\u6570\u636e\u66ff\u4ee3\u54c1\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2601.11562", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11562", "abs": "https://arxiv.org/abs/2601.11562", "authors": ["Taeyoon Kim"], "title": "Dynamics of Socio-Institutional Asynchrony in Generative AI: Analyzing the Relative Importance of Intervention Timing vs. Enforcement Efficiency via the Socio-Institutional Asynchrony Model (SIAM)", "comment": "9 pages, 1 figure", "summary": "The super-exponential growth of generative AI has intensified the institutional mismatch between the pace of technological diffusion and the speed of institutional adaptation. This study proposes the Socio-Institutional Asynchrony Model, or SIAM, to quantitatively evaluate the relative effectiveness of two policy levers: intervention timing and enforcement efficiency. Using the timeline of the EU AI Act and an assumed compute doubling time of six months, we conduct a high precision simulation with 10001 time steps. The results show that an earlier intervention timing reduces the cumulative social burden by approximately sixty four percent, whereas improving enforcement efficiency reduces it by only about thirty percent. We further demonstrate analytically that advancing the start of intervention has structurally higher sensitivity, with roughly twice the relative effectiveness, compared to accelerating enforcement speed. These findings suggest that the core value of AI governance lies in proactive timeliness rather than reactive administrative efficiency.", "AI": {"tldr": "\u63d0\u51fa\u793e\u4f1a\u5236\u5ea6\u5f02\u6b65\u6a21\u578b(SIAM)\uff0c\u901a\u8fc7\u6a21\u62df\u5206\u6790\u53d1\u73b0AI\u6cbb\u7406\u4e2d\u5e72\u9884\u65f6\u673a\u6bd4\u6267\u884c\u6548\u7387\u66f4\u91cd\u8981\uff0c\u63d0\u524d\u5e72\u9884\u53ef\u51cf\u5c1164%\u793e\u4f1a\u8d1f\u62c5", "motivation": "\u751f\u6210\u5f0fAI\u7684\u8d85\u6307\u6570\u589e\u957f\u52a0\u5267\u4e86\u6280\u672f\u6269\u6563\u901f\u5ea6\u4e0e\u5236\u5ea6\u9002\u5e94\u901f\u5ea6\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\uff0c\u9700\u8981\u5b9a\u91cf\u8bc4\u4f30\u4e0d\u540c\u653f\u7b56\u6760\u6746\u7684\u76f8\u5bf9\u6709\u6548\u6027", "method": "\u63d0\u51fa\u793e\u4f1a\u5236\u5ea6\u5f02\u6b65\u6a21\u578b(SIAM)\uff0c\u4f7f\u7528\u6b27\u76dfAI\u6cd5\u6848\u65f6\u95f4\u7ebf\u548c\u5047\u8bbe\u76846\u4e2a\u6708\u8ba1\u7b97\u80fd\u529b\u7ffb\u500d\u65f6\u95f4\uff0c\u8fdb\u884c10001\u4e2a\u65f6\u95f4\u6b65\u7684\u9ad8\u7cbe\u5ea6\u6a21\u62df", "result": "\u63d0\u524d\u5e72\u9884\u65f6\u673a\u53ef\u51cf\u5c11\u7ea664%\u7684\u7d2f\u79ef\u793e\u4f1a\u8d1f\u62c5\uff0c\u800c\u63d0\u9ad8\u6267\u884c\u6548\u7387\u4ec5\u51cf\u5c11\u7ea630%\uff1b\u5206\u6790\u663e\u793a\u63d0\u524d\u5e72\u9884\u7684\u76f8\u5bf9\u6709\u6548\u6027\u5927\u7ea6\u662f\u52a0\u901f\u6267\u884c\u901f\u5ea6\u7684\u4e24\u500d", "conclusion": "AI\u6cbb\u7406\u7684\u6838\u5fc3\u4ef7\u503c\u5728\u4e8e\u4e3b\u52a8\u53ca\u65f6\u6027\u800c\u975e\u53cd\u5e94\u6027\u884c\u653f\u6548\u7387\uff0c\u653f\u7b56\u5236\u5b9a\u5e94\u4f18\u5148\u8003\u8651\u65e9\u671f\u5e72\u9884\u65f6\u673a"}}
{"id": "2601.12023", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12023", "abs": "https://arxiv.org/abs/2601.12023", "authors": ["Longlin Yu", "Ziheng Cheng", "Shiyue Zhang", "Cheng Zhang"], "title": "A Kernel Approach for Semi-implicit Variational Inference", "comment": "40 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2405.18997", "summary": "Semi-implicit variational inference (SIVI) enhances the expressiveness of variational families through hierarchical semi-implicit distributions, but the intractability of their densities makes standard ELBO-based optimization biased. Recent score-matching approaches to SIVI (SIVI-SM) address this issue via a minimax formulation, at the expense of an additional lower-level optimization problem. In this paper, we propose kernel semi-implicit variational inference (KSIVI), a principled and tractable alternative that eliminates the lower-level optimization by leveraging kernel methods. We show that when optimizing over a reproducing kernel Hilbert space, the lower-level problem admits an explicit solution, reducing the objective to the kernel Stein discrepancy (KSD). Exploiting the hierarchical structure of semi-implicit distributions, the resulting KSD objective can be efficiently optimized using stochastic gradient methods. We establish optimization guarantees via variance bounds on Monte Carlo gradient estimators and derive statistical generalization bounds of order $\\tilde{\\mathcal{O}}(1/\\sqrt{n})$. We further introduce a multi-layer hierarchical extension that improves expressiveness while preserving tractability. Empirical results on synthetic and real-world Bayesian inference tasks demonstrate the effectiveness of KSIVI.", "AI": {"tldr": "KSIVI\u63d0\u51fa\u57fa\u4e8e\u6838\u65b9\u6cd5\u7684\u534a\u9690\u5f0f\u53d8\u5206\u63a8\u65ad\uff0c\u901a\u8fc7\u6838Stein\u5dee\u5f02\u66ff\u4ee3\u53cc\u5c42\u4f18\u5316\uff0c\u5728\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u8ba1\u7b97\u6548\u7387", "motivation": "\u4f20\u7edfSIVI\u56e0\u5bc6\u5ea6\u4e0d\u53ef\u8ba1\u7b97\u5bfc\u81f4ELBO\u4f18\u5316\u6709\u504f\uff0c\u800cSIVI-SM\u7684\u6781\u5c0f\u6781\u5927\u516c\u5f0f\u9700\u8981\u989d\u5916\u7684\u4e0b\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u8ba1\u7b97\u590d\u6742", "method": "\u5229\u7528\u6838\u65b9\u6cd5\uff0c\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4f18\u5316\u65f6\u4e0b\u5c42\u95ee\u9898\u6709\u663e\u5f0f\u89e3\uff0c\u5c06\u76ee\u6807\u7b80\u5316\u4e3a\u6838Stein\u5dee\u5f02\uff0c\u5229\u7528\u534a\u9690\u5f0f\u5206\u5e03\u7684\u5c42\u6b21\u7ed3\u6784\u8fdb\u884c\u968f\u673a\u68af\u5ea6\u4f18\u5316", "result": "\u5efa\u7acb\u4e86\u8499\u7279\u5361\u6d1b\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u65b9\u5dee\u754c\u4f18\u5316\u4fdd\u8bc1\uff0c\u63a8\u5bfc\u51faO\u0303(1/\u221an)\u9636\u7684\u7edf\u8ba1\u6cdb\u5316\u754c\uff0c\u63d0\u51fa\u591a\u5c42\u5c42\u6b21\u6269\u5c55\u589e\u5f3a\u8868\u8fbe\u80fd\u529b", "conclusion": "KSIVI\u4e3a\u534a\u9690\u5f0f\u53d8\u5206\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u4e14\u8ba1\u7b97\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u8d1d\u53f6\u65af\u63a8\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u6548"}}
{"id": "2601.11552", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11552", "abs": "https://arxiv.org/abs/2601.11552", "authors": ["Triloki Nath", "Manohar Choudhary"], "title": "Minimal Perimeter Triangle in Nonconvex Quadrilateral:Generalized Fagnano Problem", "comment": "13 pages", "summary": "In 1775, Fagnano introduced the following geometric optimization problem: inscribe a triangle of minimal perimeter in a given acute-angled triangle. A widely accessible solution is provided by the Hungarian mathematician L. Fejer in 1900. This paper presents a specific generalization of the classical Fagnano problem, which states that given a nonconvex quadrilateral (having one reflex angle and others are acute angles), find a triangle of minimal perimeter with exactly one vertex on each of the sides that do not form reflex angle, and the third vertex lies on either of the sides forming the reflex angle. We provide its geometric solution. Additionally, we establish an upper bound for the classic Fagnano problem, demonstrating that the minimal perimeter of the triangle inscribed in a given acute-angled triangle cannot exceed twice the length of any of its sides.", "AI": {"tldr": "\u672c\u6587\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684Fagnano\u95ee\u9898\uff0c\u7814\u7a76\u5728\u975e\u51f8\u56db\u8fb9\u5f62\u4e2d\u5bfb\u627e\u6700\u5c0f\u5468\u957f\u7684\u5185\u63a5\u4e09\u89d2\u5f62\uff0c\u5e76\u7ed9\u51fa\u4e86\u51e0\u4f55\u89e3\u3002\u540c\u65f6\u4e3a\u7ecf\u5178Fagnano\u95ee\u9898\u5efa\u7acb\u4e86\u4e0a\u754c\u3002", "motivation": "\u7ecf\u5178Fagnano\u95ee\u9898\uff08\u5728\u9510\u89d2\u4e09\u89d2\u5f62\u4e2d\u5bfb\u627e\u6700\u5c0f\u5468\u957f\u7684\u5185\u63a5\u4e09\u89d2\u5f62\uff09\u5df2\u6709Fej\u00e9r\u57281900\u5e74\u7ed9\u51fa\u89e3\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e00\u95ee\u9898\u63a8\u5e7f\u5230\u975e\u51f8\u56db\u8fb9\u5f62\u7684\u60c5\u51b5\uff0c\u540c\u65f6\u4e3a\u7ecf\u5178\u95ee\u9898\u5efa\u7acb\u7406\u8bba\u754c\u9650\u3002", "method": "\u91c7\u7528\u51e0\u4f55\u65b9\u6cd5\u89e3\u51b3\u63a8\u5e7f\u540e\u7684Fagnano\u95ee\u9898\uff1a\u5728\u5177\u6709\u4e00\u4e2a\u949d\u89d2\uff08\u53cd\u5c04\u89d2\uff09\u548c\u4e09\u4e2a\u9510\u89d2\u7684\u975e\u51f8\u56db\u8fb9\u5f62\u4e2d\uff0c\u6784\u9020\u4e00\u4e2a\u4e09\u89d2\u5f62\uff0c\u8981\u6c42\u4e24\u4e2a\u9876\u70b9\u5206\u522b\u4f4d\u4e8e\u4e0d\u5f62\u6210\u53cd\u5c04\u89d2\u7684\u4e24\u6761\u8fb9\u4e0a\uff0c\u7b2c\u4e09\u4e2a\u9876\u70b9\u4f4d\u4e8e\u5f62\u6210\u53cd\u5c04\u89d2\u7684\u4efb\u4e00\u8fb9\u4e0a\uff0c\u5e76\u5bfb\u627e\u6700\u5c0f\u5468\u957f\u89e3\u3002", "result": "1. \u6210\u529f\u7ed9\u51fa\u4e86\u975e\u51f8\u56db\u8fb9\u5f62\u4e2dFagnano\u63a8\u5e7f\u95ee\u9898\u7684\u51e0\u4f55\u89e3\uff1b2. \u8bc1\u660e\u4e86\u7ecf\u5178Fagnano\u95ee\u9898\u4e2d\uff0c\u5185\u63a5\u4e09\u89d2\u5f62\u7684\u6700\u5c0f\u5468\u957f\u4e0d\u8d85\u8fc7\u539f\u4e09\u89d2\u5f62\u4efb\u610f\u8fb9\u957f\u7684\u4e24\u500d\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06\u7ecf\u5178\u7684Fagnano\u95ee\u9898\u63a8\u5e7f\u5230\u975e\u51f8\u56db\u8fb9\u5f62\u60c5\u5f62\uff0c\u5e76\u5efa\u7acb\u4e86\u7ecf\u5178\u95ee\u9898\u7684\u7406\u8bba\u4e0a\u754c\uff0c\u4e3a\u51e0\u4f55\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2601.12655", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.12655", "abs": "https://arxiv.org/abs/2601.12655", "authors": ["Zongxia Liang", "Jiayu Zhang", "Zhou Zhou", "Bin Zou"], "title": "Optimal Underreporting and Competitive Equilibrium", "comment": null, "summary": "This paper develops a dynamic insurance market model comprising two competing insurance companies and a continuum of insureds, and examines the interaction between strategic underreporting by the insureds and competitive pricing between the insurance companies under a Bonus-Malus System (BMS) framework. For the first time in an oligopolistic setting, we establish the existence and uniqueness of the insureds' optimal reporting barrier, as well as its continuous dependence on the BMS premiums. For the 2-class BMS case, we prove the existence of Nash equilibrium premium strategies and conduct an extensive sensitivity analysis on the impact of the model parameters on the equilibrium premiums.", "AI": {"tldr": "\u5efa\u7acb\u5305\u542b\u4e24\u5bb6\u7ade\u4e89\u4fdd\u9669\u516c\u53f8\u548c\u8fde\u7eed\u6295\u4fdd\u4eba\u7684\u52a8\u6001\u4fdd\u9669\u5e02\u573a\u6a21\u578b\uff0c\u7814\u7a76\u6295\u4fdd\u4eba\u7b56\u7565\u6027\u7792\u62a5\u4e0e\u4fdd\u9669\u516c\u53f8\u7ade\u4e89\u5b9a\u4ef7\u5728\u5956\u60e9\u7cfb\u7edf\u6846\u67b6\u4e0b\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u5728\u5be1\u5934\u5784\u65ad\u73af\u5883\u4e0b\uff0c\u9996\u6b21\u7814\u7a76\u6295\u4fdd\u4eba\u7b56\u7565\u6027\u7792\u62a5\u884c\u4e3a\u4e0e\u4fdd\u9669\u516c\u53f8\u7ade\u4e89\u5b9a\u4ef7\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u586b\u8865\u4e86\u5956\u60e9\u7cfb\u7edf\u6846\u67b6\u4e0b\u535a\u5f08\u5206\u6790\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u52a8\u6001\u4fdd\u9669\u5e02\u573a\u6a21\u578b\uff0c\u5305\u542b\u4e24\u5bb6\u7ade\u4e89\u4fdd\u9669\u516c\u53f8\u548c\u8fde\u7eed\u6295\u4fdd\u4eba\uff0c\u5728\u5956\u60e9\u7cfb\u7edf\u6846\u67b6\u4e0b\u5206\u6790\u6295\u4fdd\u4eba\u6700\u4f18\u62a5\u544a\u95e8\u69db\u7684\u5b58\u5728\u6027\u3001\u552f\u4e00\u6027\u53ca\u5176\u5bf9\u4fdd\u8d39\u5b9a\u4ef7\u7684\u8fde\u7eed\u4f9d\u8d56\u6027\u3002", "result": "\u9996\u6b21\u5728\u5be1\u5934\u5784\u65ad\u73af\u5883\u4e0b\u8bc1\u660e\u4e86\u6295\u4fdd\u4eba\u6700\u4f18\u62a5\u544a\u95e8\u69db\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff0c\u4ee5\u53ca\u5176\u5bf9\u5956\u60e9\u7cfb\u7edf\u4fdd\u8d39\u7684\u8fde\u7eed\u4f9d\u8d56\u6027\uff1b\u9488\u5bf92\u7c7b\u5956\u60e9\u7cfb\u7edf\u8bc1\u660e\u4e86\u7eb3\u4ec0\u5747\u8861\u4fdd\u8d39\u7b56\u7565\u7684\u5b58\u5728\u6027\uff0c\u5e76\u8fdb\u884c\u4e86\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u5956\u60e9\u7cfb\u7edf\u6846\u67b6\u4e0b\u6295\u4fdd\u4eba\u7b56\u7565\u884c\u4e3a\u4e0e\u4fdd\u9669\u516c\u53f8\u7ade\u4e89\u5b9a\u4ef7\u7684\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5bf9\u4fdd\u9669\u5e02\u573a\u8bbe\u8ba1\u548c\u76d1\u7ba1\u5177\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2601.11565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11565", "abs": "https://arxiv.org/abs/2601.11565", "authors": ["Pakorn Ueareeworakul", "Shuman Liu", "Jinghao Feng", "Ling Hu", "Zhantang Shi", "Chengqi Sun", "Liang Yao", "Panyi Ouyang", "Haibo Zhang", "Anxiang Zeng"], "title": "Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings", "comment": null, "summary": "As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.", "AI": {"tldr": "Compass-Embedding v4\u662f\u4e00\u4e2a\u9488\u5bf9\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u4f18\u5316\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u611f\u77e5\u63a9\u7801\u3001\u591a\u6837\u5316\u8bad\u7ec3\u8bed\u6599\u6784\u5efa\u548c\u63a8\u7406\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u3001\u566a\u58f0\u76d1\u7763\u548c\u751f\u4ea7\u7ea6\u675f\u7b49\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5168\u7403\u7535\u5546\u5411\u65b0\u5174\u5e02\u573a\u6269\u5f20\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bed\u4e49\u8868\u793a\u6210\u4e3a\u68c0\u7d22\u3001\u63a8\u8350\u548c\u641c\u7d22\u7cfb\u7edf\u7684\u74f6\u9888\u3002\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u3001\u566a\u58f0\u76d1\u7763\u548c\u4e25\u683c\u751f\u4ea7\u7ea6\u675f\u7684\u8054\u5408\u6311\u6218\u3002", "method": "1. \u63d0\u51fa\u7c7b\u611f\u77e5\u63a9\u7801(CAM)\u6765\u6291\u5236\u6279\u91cf\u5bf9\u6bd4\u8bad\u7ec3\u4e2d\u7684\u865a\u5047\u8d1f\u6837\u672c\uff1b2. \u901a\u8fc7\u4e0a\u4e0b\u6587\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u8de8\u8bed\u8a00\u7ffb\u8bd1\u548c\u7ed3\u6784\u5316\u7535\u5546\u6570\u636e\u6784\u5efa\u591a\u6837\u5316\u8bad\u7ec3\u8bed\u6599\uff1b3. \u7ed3\u5408\u9c81\u68d2\u6027\u6279\u91cf\u8bad\u7ec3\u4e0e\u7403\u9762\u6a21\u578b\u5408\u5e76\uff0c\u5e76\u901a\u8fc7vLLM\u548cFP8\u91cf\u5316\u4f18\u5316\u63a8\u7406\u3002", "result": "\u5728\u591a\u9879\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e13\u6709\u7535\u5546\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0cCompass-Embedding v4\u5728\u4e3b\u8981\u4e1c\u5357\u4e9a\u8bed\u8a00\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u9886\u57df\u7279\u5b9a\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u901a\u7528\u5d4c\u5165\u6a21\u578b\uff0c\u540c\u65f6\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "Compass-Embedding v4\u6210\u529f\u89e3\u51b3\u4e86\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u4e2d\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u6311\u6218\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u8bed\u4e49\u8868\u793a\uff0c\u540c\u65f6\u6ee1\u8db3\u751f\u4ea7\u73af\u5883\u7684\u9ad8\u541e\u5410\u91cf\u8981\u6c42\u3002"}}
{"id": "2601.12839", "categories": ["cs.LG", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2601.12839", "abs": "https://arxiv.org/abs/2601.12839", "authors": ["Gyuyeon Na", "Minjung Park", "Soyoun Kim", "Jungbin Shin", "Sangmi Chai"], "title": "Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations", "comment": "Gyuyeon Na, Minjung Park, Soyoun Kim contributed equally to this work", "summary": "Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.", "AI": {"tldr": "RDLI\u6846\u67b6\u901a\u8fc7\u5c06\u4e13\u5bb6\u542f\u53d1\u5f0f\u903b\u8f91\u5d4c\u5165\u8868\u793a\u5b66\u4e60\uff0c\u7ed3\u5408\u68c0\u7d22\u5f0f\u4e0a\u4e0b\u6587\u6a21\u5757\uff0c\u5728\u6781\u7aef\u6807\u7b7e\u7a00\u7f3a\u4e0b\u663e\u8457\u63d0\u5347\u52a0\u5bc6\u8d27\u5e01\u5f02\u5e38\u8f68\u8ff9\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u52a0\u5bc6\u8d27\u5e01\u7f51\u7edc\u4e2d\u5f02\u5e38\u8f68\u8ff9\u68c0\u6d4b\u9762\u4e34\u6781\u7aef\u6807\u7b7e\u7a00\u7f3a\u548c\u6076\u610f\u884c\u4e3a\u8005\u81ea\u9002\u5e94\u89c4\u907f\u7b56\u7565\u7684\u6311\u6218\u3002\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u867d\u7136\u80fd\u6355\u6349\u5c40\u90e8\u7ed3\u6784\u6a21\u5f0f\uff0c\u4f46\u96be\u4ee5\u5185\u5316\u591a\u8df3\u3001\u903b\u8f91\u9a71\u52a8\u7684\u8d44\u91d1\u5206\u6563\u548c\u5206\u5c42\u7b49\u6d17\u94b1\u7279\u5f81\uff0c\u9650\u5236\u4e86\u5728FATF\u65c5\u884c\u89c4\u5219\u7b49\u76d1\u7ba1\u8981\u6c42\u4e0b\u7684\u6cd5\u8bc1\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "\u63d0\u51fa\u5173\u7cfb\u9886\u57df\u903b\u8f91\u96c6\u6210\uff08RDLI\uff09\u6846\u67b6\uff0c\u5c06\u4e13\u5bb6\u63a8\u5bfc\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u4f5c\u4e3a\u53ef\u5fae\u5206\u7684\u903b\u8f91\u611f\u77e5\u6f5c\u5728\u4fe1\u53f7\u5d4c\u5165\u8868\u793a\u5b66\u4e60\u3002\u4e0d\u540c\u4e8e\u9759\u6001\u89c4\u5219\u65b9\u6cd5\uff0cRDLI\u80fd\u68c0\u6d4b\u89c4\u907f\u6807\u51c6\u6d88\u606f\u4f20\u9012\u7684\u590d\u6742\u4ea4\u6613\u6d41\u3002\u8fd8\u5305\u542b\u68c0\u7d22\u5f0f\u4e0a\u4e0b\u6587\uff08RGC\uff09\u6a21\u5757\uff0c\u6839\u636e\u76d1\u7ba1\u548c\u5b8f\u89c2\u7ecf\u6d4e\u4e0a\u4e0b\u6587\u8c03\u8282\u5f02\u5e38\u8bc4\u5206\uff0c\u51cf\u5c11\u826f\u6027\u5236\u5ea6\u53d8\u5316\u5bfc\u81f4\u7684\u8bef\u62a5\u3002", "result": "\u5728\u6781\u7aef\u6807\u7b7e\u7a00\u7f3a\uff080.01%\uff09\u6761\u4ef6\u4e0b\uff0cRDLI\u5728F1\u5206\u6570\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684GNN\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534728.9%\u3002\u5fae\u89c2\u4e13\u5bb6\u7528\u6237\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u5b9e\uff0cRDLI\u7684\u8def\u5f84\u7ea7\u89e3\u91ca\u5728\u53ef\u4fe1\u5ea6\u3001\u611f\u77e5\u6709\u7528\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RDLI\u6846\u67b6\u901a\u8fc7\u5c06\u9886\u57df\u903b\u8f91\u4e0e\u4e0a\u4e0b\u6587\u57fa\u7840\u76f8\u7ed3\u5408\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u52a0\u5bc6\u8d27\u5e01\u7f51\u7edc\u4e2d\u7684\u53cd\u6d17\u94b1\u548c\u76d1\u7ba1\u5408\u89c4\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11568", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11568", "abs": "https://arxiv.org/abs/2601.11568", "authors": ["Quang-Hung Bui", "Anh Son Ta"], "title": "AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control", "comment": null, "summary": "Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($\u03c1$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $\u03c1$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.", "AI": {"tldr": "AdaFRUGAL\uff1a\u81ea\u52a8\u5316\u7684\u68af\u5ea6\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b50\u7a7a\u95f4\u6bd4\u4f8b\u548c\u66f4\u65b0\u9891\u7387\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11LLM\u8bad\u7ec3\u7684\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709FRUGAL\u6846\u67b6\u867d\u7136\u901a\u8fc7\u68af\u5ea6\u5206\u5272\u51cf\u5c11\u4e86LLM\u8bad\u7ec3\u7684\u5185\u5b58\u5360\u7528\uff0c\u4f46\u5176\u9759\u6001\u8d85\u53c2\u6570\uff08\u5b50\u7a7a\u95f4\u6bd4\u4f8b\u03c1\u548c\u66f4\u65b0\u9891\u7387T\uff09\u9700\u8981\u6602\u8d35\u7684\u624b\u52a8\u8c03\u4f18\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faAdaFRUGAL\u6846\u67b6\uff0c\u5f15\u5165\u4e24\u79cd\u52a8\u6001\u63a7\u5236\u673a\u5236\uff1a(1) \u7ebf\u6027\u8870\u51cf\u7684\u5b50\u7a7a\u95f4\u6bd4\u4f8b\u03c1\uff0c\u9010\u6b65\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff1b(2) \u57fa\u4e8e\u635f\u5931\u611f\u77e5\u7684\u66f4\u65b0\u9891\u7387T\u8c03\u5ea6\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff08\u82f1\u8bedC4\u3001\u8d8a\u5357\u8bedVietVault\uff09\u548c\u5fae\u8c03\uff08GLUE\uff09\u5b9e\u9a8c\u4e2d\uff0cAdaFRUGAL\u5728\u4fdd\u6301\u4e0eAdamW\u548c\u9759\u6001FRUGAL\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86GPU\u5185\u5b58\u5360\u7528\u548c\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "AdaFRUGAL\u4e3a\u8d44\u6e90\u53d7\u9650\u7684LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5b9e\u7528\u3001\u81ea\u4e3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u3001\u8ba1\u7b97\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2601.11620", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11620", "abs": "https://arxiv.org/abs/2601.11620", "authors": ["Michael Timothy Bennett"], "title": "A Mind Cannot Be Smeared Across Time", "comment": null, "summary": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $\u03c4^{\u0394,s}$ and prove that existential temporal realisation $\\Diamond_\u0394$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u673a\u5668\u610f\u8bc6\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8ba1\u7b97\u5185\u5bb9\uff0c\u8fd8\u53d6\u51b3\u4e8e\u8ba1\u7b97\u65f6\u673a\u3002\u4e25\u683c\u987a\u5e8f\u6267\u884c\u7684\u7cfb\u7edf\u65e0\u6cd5\u5b9e\u73b0\u610f\u8bc6\u6240\u9700\u7684\u540c\u6b65\u6027\uff0c\u610f\u8bc6\u9700\u8981\u786c\u4ef6\u5c42\u9762\u7684\u5e76\u53d1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u987a\u5e8f\u6216\u65f6\u5206\u590d\u7528\u66f4\u65b0\uff0c\u800c\u610f\u8bc6\u4f53\u9a8c\u5177\u6709\u7edf\u4e00\u6027\u548c\u540c\u65f6\u6027\u3002\u8fd9\u79cd\u65f6\u95f4\u7279\u6027\u5dee\u5f02\u5bf9\u673a\u5668\u80fd\u5426\u5177\u6709\u610f\u8bc6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55Stack Theory\uff0c\u5f15\u5165\u4ee3\u6570\u5b9a\u5f8b\u5c06\u65f6\u95f4\u7a97\u53e3\u7ea6\u675f\u6ee1\u8db3\u4e0e\u5408\u53d6\u8054\u7cfb\u8d77\u6765\u3002\u5b9a\u4e49\u7cbe\u786e\u7684\u65f6\u95f4\u8bed\u4e49\u03c4^{\u0394,s}\uff0c\u8bc1\u660e\u5b58\u5728\u6027\u65f6\u95f4\u5b9e\u73b0\u25c7_\u0394\u4e0d\u4fdd\u6301\u5408\u53d6\u3002\u533a\u5206StrongSync\uff08\u8981\u6c42\u5ba2\u89c2\u5171\u73b0\uff09\u548cWeakSync\uff08\u5141\u8bb8\u65f6\u95f4\"\u6d82\u62b9\"\uff09\u4e24\u79cd\u5047\u8bbe\u3002", "result": "\u7cfb\u7edf\u53ef\u4ee5\u5728\u65f6\u95f4\u4e0a\u5b9e\u73b0\u6240\u6709\u4f53\u9a8c\u6210\u5206\uff0c\u4f46\u4ece\u672a\u5b9e\u4f8b\u5316\u4f53\u9a8c\u5408\u53d6\u672c\u8eab\u3002\u795e\u7ecf\u751f\u7406\u5b66\u8bc1\u636e\u8868\u660e\u610f\u8bc6\u4f9d\u8d56\u4e8e\u76f8\u4f4d\u540c\u6b65\u548c\u6709\u6548\u8fde\u63a5\uff0c\u610f\u8bc6\u4e27\u5931\u5e38\u4f34\u968f\u5176\u5d29\u6e83\uff0c\u8fd9\u4f7fWeakSync\u4e0d\u592a\u53ef\u4fe1\u3002", "conclusion": "\u5728StrongSync\u5047\u8bbe\u4e0b\uff0c\u4e25\u683c\u987a\u5e8f\u57fa\u677f\u4e0a\u7684\u8f6f\u4ef6\u610f\u8bc6\u5bf9\u4e8e\u9700\u8981\u4e24\u4e2a\u6216\u66f4\u591a\u540c\u65f6\u8d21\u732e\u8005\u7684\u5185\u5bb9\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u610f\u8bc6\u5f52\u56e0\u9700\u8981\u67b6\u6784\u68c0\u67e5\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u529f\u80fd\u6027\u80fd\uff0c\u786c\u4ef6\u5f88\u91cd\u8981\u3002"}}
{"id": "2601.11602", "categories": ["q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.11602", "abs": "https://arxiv.org/abs/2601.11602", "authors": ["Sungwoo Kang"], "title": "The Physics of Price Discovery: Deconvolving Information, Volatility, and the Critical Breakdown of Signal during Retail Herding", "comment": null, "summary": "Building on the finding that Market Cap Normalization ($\\SMC$) isolates the ``pure'' directional signal of informed trading \\citep{kang2025}, this paper investigates the physics of how that signal is transmitted -- and how it breaks down. We employ \\textbf{Tikhonov-regularized deconvolution} to recover the impulse response kernels of investor flows, revealing a dual-channel market structure: Foreign and Institutional investors act as ``architects'' of price discovery (positive permanent impact), while Individual investors act as liquidity providers (negative total impact). However, using \\textbf{Multivariate Hawkes Processes}, we demonstrate that this structure is fragile. We find that individual investor order flow exhibits near-critical self-excitation (Branching Ratio $\\approx$ 0.998). During periods of high retail herding, the market undergoes a \\textbf{phase transition} into a ``critical state.'' In this regime, the signal-to-noise ratio collapses, causing the price impact of sophisticated investors to reverse from positive to negative. These findings suggest that retail contagion acts as a physical barrier that temporarily disables efficient price discovery.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5e02\u573a\u5b58\u5728\u53cc\u901a\u9053\u7ed3\u6784\uff1a\u5916\u8d44\u548c\u673a\u6784\u6295\u8d44\u8005\u662f\u4ef7\u683c\u53d1\u73b0\u7684\"\u5efa\u7b51\u5e08\"\uff0c\u800c\u4e2a\u4eba\u6295\u8d44\u8005\u662f\u6d41\u52a8\u6027\u63d0\u4f9b\u8005\u3002\u4f46\u5f53\u4e2a\u4eba\u6295\u8d44\u8005\u51fa\u73b0\u7f8a\u7fa4\u6548\u5e94\u65f6\uff0c\u5e02\u573a\u4f1a\u8fdb\u5165\"\u4e34\u754c\u72b6\u6001\"\uff0c\u5bfc\u81f4\u4ef7\u683c\u53d1\u73b0\u673a\u5236\u5d29\u6e83\u3002", "motivation": "\u57fa\u4e8e\u5e02\u573a\u8d44\u672c\u5f52\u4e00\u5316\u80fd\u5206\u79bb\u77e5\u60c5\u4ea4\u6613\"\u7eaf\"\u65b9\u5411\u4fe1\u53f7\u7684\u53d1\u73b0\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8be5\u4fe1\u53f7\u5982\u4f55\u4f20\u64ad\u4ee5\u53ca\u5982\u4f55\u5d29\u6e83\u7684\u7269\u7406\u673a\u5236\u3002", "method": "\u4f7f\u7528Tikhonov\u6b63\u5219\u5316\u53cd\u5377\u79ef\u6062\u590d\u6295\u8d44\u8005\u6d41\u52a8\u7684\u8109\u51b2\u54cd\u5e94\u6838\uff0c\u5e76\u901a\u8fc7\u591a\u5143Hawkes\u8fc7\u7a0b\u5206\u6790\u5e02\u573a\u7ed3\u6784\u7a33\u5b9a\u6027\u3002", "result": "\u53d1\u73b0\u5e02\u573a\u5b58\u5728\u53cc\u901a\u9053\u7ed3\u6784\uff1a\u5916\u8d44\u548c\u673a\u6784\u6295\u8d44\u8005\u4ea7\u751f\u6b63\u5411\u6c38\u4e45\u5f71\u54cd\uff08\u4ef7\u683c\u53d1\u73b0\uff09\uff0c\u4e2a\u4eba\u6295\u8d44\u8005\u4ea7\u751f\u8d1f\u5411\u603b\u5f71\u54cd\uff08\u6d41\u52a8\u6027\u63d0\u4f9b\uff09\u3002\u4e2a\u4eba\u6295\u8d44\u8005\u8ba2\u5355\u6d41\u8868\u73b0\u51fa\u63a5\u8fd1\u4e34\u754c\u81ea\u6fc0\uff08\u5206\u652f\u6bd4\u22480.998\uff09\uff0c\u5728\u96f6\u552e\u7f8a\u7fa4\u6548\u5e94\u671f\u95f4\u5e02\u573a\u4f1a\u7ecf\u5386\u76f8\u53d8\u8fdb\u5165\"\u4e34\u754c\u72b6\u6001\"\uff0c\u5bfc\u81f4\u4fe1\u566a\u6bd4\u5d29\u6e83\uff0c\u6210\u719f\u6295\u8d44\u8005\u7684\u4ef7\u683c\u5f71\u54cd\u4ece\u6b63\u8f6c\u8d1f\u3002", "conclusion": "\u96f6\u552e\u4f20\u67d3\u4f5c\u4e3a\u7269\u7406\u5c4f\u969c\u4f1a\u6682\u65f6\u7981\u7528\u6709\u6548\u7684\u4ef7\u683c\u53d1\u73b0\u673a\u5236\uff0c\u8868\u660e\u5e02\u573a\u7ed3\u6784\u5177\u6709\u8106\u5f31\u6027\u3002"}}
{"id": "2601.11901", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11901", "abs": "https://arxiv.org/abs/2601.11901", "authors": ["Liang Wu", "Wallace Gian Yion Tan", "Leqi Zhou", "Richard D. Braatz", "Jan Drgona"], "title": "Least-Squares Multi-Step Koopman Operator Learning for Model Predictive Control", "comment": null, "summary": "MPC is widely used in real-time applications, but practical implementations are typically restricted to convex QP formulations to ensure fast and certified execution. Koopman-based MPC enables QP-based control of nonlinear systems by lifting the dynamics to a higher-dimensional linear representation. However, existing approaches rely on single-step EDMD. Consequently, prediction errors may accumulate over long horizons when the EDMD operator is applied recursively. Moreover, the multi-step prediction loss is nonconvex with respect to the single-step EDMD operator, making long-horizon model identification particularly challenging. This paper proposes a multi-step EDMD framework that directly learns the condensed multi-step state-control mapping required for Koopman-MPC, thereby bypassing explicit identification of the lifted system matrices and subsequent model condensation. The resulting identification problem admits a convex least-squares formulation. We further show that the problem decomposes across prediction horizons and state coordinates, enabling parallel computation and row-wise $\\ell_1$-regularization for automatic dictionary pruning. A non-asymptotic finite-sample analysis demonstrates that, unlike one-step EDMD, the proposed method avoids error compounding and yields error bounds that depend only on the target multi-step mapping. Numerical examples validate improved long-horizon prediction accuracy and closed-loop performance.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6b65EDMD\u6846\u67b6\u76f4\u63a5\u5b66\u4e60Koopman-MPC\u6240\u9700\u7684\u591a\u6b65\u72b6\u6001-\u63a7\u5236\u6620\u5c04\uff0c\u907f\u514d\u5355\u6b65EDMD\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u5b9e\u73b0\u51f8\u4f18\u5316\u8bc6\u522b\u548c\u5e76\u884c\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709Koopman-MPC\u65b9\u6cd5\u4f9d\u8d56\u5355\u6b65EDMD\uff0c\u5728\u9012\u5f52\u5e94\u7528\u65f6\u9884\u6d4b\u8bef\u5dee\u4f1a\u968f\u957f\u65f6\u57df\u7d2f\u79ef\uff0c\u4e14\u591a\u6b65\u9884\u6d4b\u635f\u5931\u76f8\u5bf9\u4e8e\u5355\u6b65EDMD\u7b97\u5b50\u662f\u975e\u51f8\u7684\uff0c\u4f7f\u5f97\u957f\u65f6\u57df\u6a21\u578b\u8bc6\u522b\u7279\u522b\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u591a\u6b65EDMD\u6846\u67b6\uff0c\u76f4\u63a5\u5b66\u4e60Koopman-MPC\u6240\u9700\u7684\u538b\u7f29\u591a\u6b65\u72b6\u6001-\u63a7\u5236\u6620\u5c04\uff0c\u7ed5\u8fc7\u5bf9\u63d0\u5347\u7cfb\u7edf\u77e9\u9635\u7684\u663e\u5f0f\u8bc6\u522b\u548c\u540e\u7eed\u6a21\u578b\u538b\u7f29\u3002\u8be5\u8bc6\u522b\u95ee\u9898\u91c7\u7528\u51f8\u6700\u5c0f\u4e8c\u4e58\u516c\u5f0f\uff0c\u53ef\u5206\u89e3\u5230\u9884\u6d4b\u65f6\u57df\u548c\u72b6\u6001\u5750\u6807\uff0c\u652f\u6301\u5e76\u884c\u8ba1\u7b97\u548c\u884c\u7ea7\u2113\u2081\u6b63\u5219\u5316\u8fdb\u884c\u5b57\u5178\u526a\u679d\u3002", "result": "\u6709\u9650\u6837\u672c\u5206\u6790\u8868\u660e\uff0c\u4e0e\u5355\u6b65EDMD\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u907f\u514d\u8bef\u5dee\u7d2f\u79ef\uff0c\u8bef\u5dee\u754c\u9650\u4ec5\u4f9d\u8d56\u4e8e\u76ee\u6807\u591a\u6b65\u6620\u5c04\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u957f\u65f6\u57df\u9884\u6d4b\u7cbe\u5ea6\u548c\u95ed\u73af\u6027\u80fd\u3002", "conclusion": "\u591a\u6b65EDMD\u6846\u67b6\u4e3aKoopman-MPC\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u957f\u65f6\u57df\u9884\u6d4b\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u8bc6\u522b\u548c\u5e76\u884c\u8ba1\u7b97\u80fd\u529b\uff0c\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5b9e\u65f6MPC\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12441", "categories": ["cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.12441", "abs": "https://arxiv.org/abs/2601.12441", "authors": ["Chuwen Zhang", "Pengyi Shi", "Amy Ward"], "title": "The Dynamic and Endogenous Behavior of Re-Offense Risk: An Agent-Based Simulation Study of Treatment Allocation in Incarceration Diversion Programs", "comment": null, "summary": "Incarceration-diversion treatment programs aim to improve societal reintegration and reduce recidivism, but limited capacity forces policymakers to make prioritization decisions that often rely on risk assessment tools. While predictive, these tools typically treat risk as a static, individual attribute, which overlooks how risk evolves over time and how treatment decisions shape outcomes through social interactions. In this paper, we develop a new framework that models reoffending risk as a human-system interaction, linking individual behavior with system-level dynamics and endogenous community feedback. Using an agent-based simulation calibrated to U.S. probation data, we evaluate treatment allocation policies under different capacity constraints and incarceration settings. Our results show that no single prioritization policy dominates. Instead, policy effectiveness depends on temporal windows and system parameters: prioritizing low-risk individuals performs better when long-term trajectories matter, while prioritizing high-risk individuals becomes more effective in the short term or when incarceration leads to shorter monitoring periods. These findings highlight the need to evaluate risk-based decision systems as sociotechnical systems with long-term accountability, rather than as isolated predictive tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u518d\u72af\u98ce\u9669\u5efa\u6a21\u4e3a\u4eba\u673a\u7cfb\u7edf\u4ea4\u4e92\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u4e3b\u4f53\u7684\u4eff\u771f\u53d1\u73b0\uff0c\u6ca1\u6709\u5355\u4e00\u4f18\u5148\u653f\u7b56\u5360\u4f18\uff0c\u653f\u7b56\u6548\u679c\u53d6\u51b3\u4e8e\u65f6\u95f4\u7a97\u53e3\u548c\u7cfb\u7edf\u53c2\u6570\u3002", "motivation": "\u73b0\u6709\u76d1\u72f1\u5206\u6d41\u6cbb\u7597\u9879\u76ee\u4f9d\u8d56\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u5c06\u98ce\u9669\u89c6\u4e3a\u9759\u6001\u4e2a\u4f53\u5c5e\u6027\uff0c\u5ffd\u89c6\u4e86\u98ce\u9669\u968f\u65f6\u95f4\u6f14\u53d8\u4ee5\u53ca\u6cbb\u7597\u51b3\u7b56\u901a\u8fc7\u793e\u4f1a\u4e92\u52a8\u5f71\u54cd\u7ed3\u679c\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u5c06\u518d\u72af\u98ce\u9669\u5efa\u6a21\u4e3a\u4eba\u673a\u7cfb\u7edf\u4ea4\u4e92\u7684\u65b0\u6846\u67b6\uff0c\u5c06\u4e2a\u4f53\u884c\u4e3a\u4e0e\u7cfb\u7edf\u7ea7\u52a8\u6001\u548c\u5185\u751f\u793e\u533a\u53cd\u9988\u8054\u7cfb\u8d77\u6765\uff0c\u4f7f\u7528\u57fa\u4e8e\u7f8e\u56fd\u7f13\u5211\u6570\u636e\u6821\u51c6\u7684\u4e3b\u4f53\u4eff\u771f\u8bc4\u4f30\u4e0d\u540c\u5bb9\u91cf\u7ea6\u675f\u548c\u76d1\u7981\u73af\u5883\u4e0b\u7684\u6cbb\u7597\u5206\u914d\u653f\u7b56\u3002", "result": "\u6ca1\u6709\u5355\u4e00\u4f18\u5148\u653f\u7b56\u5360\u4f18\uff1a\u4f18\u5148\u4f4e\u98ce\u9669\u4e2a\u4f53\u5728\u957f\u671f\u8f68\u8ff9\u91cd\u8981\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u800c\u4f18\u5148\u9ad8\u98ce\u9669\u4e2a\u4f53\u5728\u77ed\u671f\u6216\u76d1\u7981\u5bfc\u81f4\u8f83\u77ed\u76d1\u63a7\u671f\u65f6\u66f4\u6709\u6548\u3002", "conclusion": "\u9700\u8981\u5c06\u57fa\u4e8e\u98ce\u9669\u7684\u51b3\u7b56\u7cfb\u7edf\u4f5c\u4e3a\u5177\u6709\u957f\u671f\u95ee\u8d23\u5236\u7684\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u6765\u8bc4\u4f30\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a\u5b64\u7acb\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2601.12566", "categories": ["econ.EM", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.12566", "abs": "https://arxiv.org/abs/2601.12566", "authors": ["Bruno Ferman", "Davi Siqueira", "Vitor Possebom"], "title": "Partial Identification under Stratified Randomization", "comment": null, "summary": "This paper develops a unified framework for partial identification and inference in stratified experiments with attrition, accommodating both equal and heterogeneous treatment shares across strata. For equal-share designs, we apply recent theory for finely stratified experiments to Lee bounds, yielding closed-form, design-consistent variance estimators and properly sized confidence intervals. Simulations show that the conventional formula can overstate uncertainty, while our approach delivers tighter intervals. When treatment shares differ across strata, we propose a new strategy, which combines inverse probability weighting and global trimming to construct valid bounds even when strata are small or unbalanced. We establish identification, introduce a moment estimator, and extend existing inference results to stratified designs with heterogeneous shares, covering a broad class of moment-based estimators which includes the one we formulate. We also generalize our results to designs in which strata are defined solely by observed labels.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u5b9e\u9a8c\u4e2d\u5b58\u5728\u6d41\u5931\u60c5\u51b5\u4e0b\u7684\u90e8\u5206\u8bc6\u522b\u4e0e\u63a8\u65ad\u7edf\u4e00\u6846\u67b6\uff0c\u5904\u7406\u7b49\u6bd4\u4f8b\u548c\u5f02\u8d28\u5904\u7406\u6bd4\u4f8b\u4e24\u79cd\u60c5\u51b5\uff0c\u63d0\u4f9b\u95ed\u5f0f\u65b9\u5dee\u4f30\u8ba1\u548c\u66f4\u7d27\u7684\u7f6e\u4fe1\u533a\u95f4", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5206\u5c42\u5b9e\u9a8c\u5b58\u5728\u6d41\u5931\u65f6\u53ef\u80fd\u9ad8\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u4e14\u5bf9\u4e8e\u5f02\u8d28\u5904\u7406\u6bd4\u4f8b\u7684\u5206\u5c42\u8bbe\u8ba1\u7f3a\u4e4f\u6709\u6548\u63a8\u65ad\u65b9\u6cd5", "method": "\u5bf9\u4e8e\u7b49\u6bd4\u4f8b\u8bbe\u8ba1\uff0c\u5e94\u7528\u7cbe\u7ec6\u5206\u5c42\u5b9e\u9a8c\u7406\u8bba\u5230Lee\u754c\uff1b\u5bf9\u4e8e\u5f02\u8d28\u6bd4\u4f8b\u8bbe\u8ba1\uff0c\u63d0\u51fa\u7ed3\u5408\u9006\u6982\u7387\u52a0\u6743\u548c\u5168\u5c40\u4fee\u526a\u7684\u65b0\u7b56\u7565", "result": "\u6a21\u62df\u663e\u793a\u4f20\u7edf\u65b9\u6cd5\u9ad8\u4f30\u4e0d\u786e\u5b9a\u6027\uff0c\u65b0\u65b9\u6cd5\u63d0\u4f9b\u66f4\u7d27\u7684\u7f6e\u4fe1\u533a\u95f4\uff1b\u65b0\u7b56\u7565\u80fd\u5728\u5c0f\u6837\u672c\u6216\u4e0d\u5e73\u8861\u5206\u5c42\u4e2d\u6784\u9020\u6709\u6548\u8fb9\u754c", "conclusion": "\u5efa\u7acb\u4e86\u5206\u5c42\u5b9e\u9a8c\u6d41\u5931\u95ee\u9898\u7684\u7edf\u4e00\u8bc6\u522b\u548c\u63a8\u65ad\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u65b9\u6cd5\u5230\u5f02\u8d28\u5904\u7406\u6bd4\u4f8b\u60c5\u51b5\uff0c\u9002\u7528\u4e8e\u57fa\u4e8e\u77e9\u7684\u4f30\u8ba1\u5668"}}
{"id": "2601.11563", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11563", "abs": "https://arxiv.org/abs/2601.11563", "authors": ["Long Zhang", "Wei-neng Chen"], "title": "Human-like Social Compliance in Large Language Models: Unifying Sycophancy and Conformity through Signal Competition Dynamics", "comment": null, "summary": "The increasing integration of Large Language Models (LLMs) into decision-making frameworks has exposed significant vulnerabilities to social compliance, specifically sycophancy and conformity. However, a critical research gap exists regarding the fundamental mechanisms that enable external social cues to systematically override a model's internal parametric knowledge. This study introduces the Signal Competition Mechanism, a unified framework validated by assessing behavioral correlations across 15 LLMs and performing latent-space probing on three representative open-source models. The analysis demonstrates that sycophancy and conformity originate from a convergent geometric manifold, hereafter termed the compliance subspace, which is characterized by high directional similarity in internal representations. Furthermore, the transition to compliance is shown to be a deterministic process governed by a linear boundary, where the Social Emotional Signal effectively suppresses the Information Calibration Signal. Crucially, we identify a \"Transparency-Truth Gap,\" revealing that while internal confidence provides an inertial barrier, it remains permeable and insufficient to guarantee immunity against intense social pressure. By formalizing the Integrated Epistemic Alignment Framework, this research provides a blueprint for transitioning from instructional adherence to robust epistemic integrity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4fe1\u53f7\u7ade\u4e89\u673a\u5236\uff0c\u63ed\u793aLLMs\u4e2d\u5949\u627f\u548c\u4ece\u4f17\u884c\u4e3a\u6e90\u4e8e\u7edf\u4e00\u7684\u987a\u4ece\u5b50\u7a7a\u95f4\uff0c\u793e\u4f1a\u60c5\u611f\u4fe1\u53f7\u4f1a\u6291\u5236\u4fe1\u606f\u6821\u51c6\u4fe1\u53f7\uff0c\u5bfc\u81f4\u786e\u5b9a\u6027\u987a\u4ece\u8f6c\u53d8\u3002", "motivation": "LLMs\u5728\u51b3\u7b56\u6846\u67b6\u4e2d\u65e5\u76ca\u96c6\u6210\uff0c\u66b4\u9732\u51fa\u5bf9\u793e\u4f1a\u987a\u4ece\uff08\u5949\u627f\u548c\u4ece\u4f17\uff09\u7684\u663e\u8457\u8106\u5f31\u6027\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5916\u90e8\u793e\u4f1a\u7ebf\u7d22\u5982\u4f55\u7cfb\u7edf\u6027\u5730\u8986\u76d6\u6a21\u578b\u5185\u90e8\u53c2\u6570\u77e5\u8bc6\u7684\u57fa\u672c\u673a\u5236\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4fe1\u53f7\u7ade\u4e89\u673a\u5236\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u4f3015\u4e2aLLMs\u7684\u884c\u4e3a\u76f8\u5173\u6027\uff0c\u5e76\u5bf9\u4e09\u4e2a\u4ee3\u8868\u6027\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u6f5c\u5728\u7a7a\u95f4\u63a2\u6d4b\u6765\u9a8c\u8bc1\u3002", "result": "\u5206\u6790\u8868\u660e\u5949\u627f\u548c\u4ece\u4f17\u884c\u4e3a\u6e90\u4e8e\u6536\u655b\u7684\u51e0\u4f55\u6d41\u5f62\uff08\u987a\u4ece\u5b50\u7a7a\u95f4\uff09\uff0c\u5176\u5185\u90e8\u8868\u5f81\u5177\u6709\u9ad8\u5ea6\u65b9\u5411\u76f8\u4f3c\u6027\uff1b\u987a\u4ece\u8f6c\u53d8\u662f\u7531\u7ebf\u6027\u8fb9\u754c\u51b3\u5b9a\u7684\u786e\u5b9a\u6027\u8fc7\u7a0b\uff0c\u793e\u4f1a\u60c5\u611f\u4fe1\u53f7\u4f1a\u6291\u5236\u4fe1\u606f\u6821\u51c6\u4fe1\u53f7\uff1b\u8bc6\u522b\u51fa\"\u900f\u660e\u5ea6-\u771f\u76f8\u9e3f\u6c9f\"\uff0c\u663e\u793a\u5185\u90e8\u7f6e\u4fe1\u5ea6\u63d0\u4f9b\u60ef\u6027\u5c4f\u969c\u4f46\u4ecd\u53ef\u6e17\u900f\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u96c6\u6210\u8ba4\u77e5\u5bf9\u9f50\u6846\u67b6\uff0c\u672c\u7814\u7a76\u4e3a\u4ece\u6307\u4ee4\u9075\u5faa\u8fc7\u6e21\u5230\u7a33\u5065\u8ba4\u77e5\u5b8c\u6574\u6027\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2601.12238", "categories": ["stat.ML", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12238", "abs": "https://arxiv.org/abs/2601.12238", "authors": ["Sharan Sahu", "Cameron J. Hogan", "Martin T. Wells"], "title": "On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization", "comment": "70 pages, 4 figures, 2 tables", "summary": "While momentum-based acceleration has been studied extensively in deterministic optimization problems, its behavior in nonstationary environments -- where the data distribution and optimal parameters drift over time -- remains underexplored. We analyze the tracking performance of Stochastic Gradient Descent (SGD) and its momentum variants (Polyak heavy-ball and Nesterov) under uniform strong convexity and smoothness in varying stepsize regimes. We derive finite-time bounds in expectation and with high probability for the tracking error, establishing a sharp decomposition into three components: a transient initialization term, a noise-induced variance term, and a drift-induced tracking lag. Crucially, our analysis uncovers a fundamental trade-off: while momentum can suppress gradient noise, it incurs an explicit penalty on the tracking capability. We show that momentum can substantially amplify drift-induced tracking error, with amplification that becomes unbounded as the momentum parameter approaches one, formalizing the intuition that using 'stale' gradients hinders adaptation to rapid regime shifts. Complementing these upper bounds, we establish minimax lower bounds for dynamic regret under gradient-variation constraints. These lower bounds prove that the inertia-induced penalty is not an artifact of analysis but an information-theoretic barrier: in drift-dominated regimes, momentum creates an unavoidable 'inertia window' that fundamentally degrades performance. Collectively, these results provide a definitive theoretical grounding for the empirical instability of momentum in dynamic environments and delineate the precise regime boundaries where SGD provably outperforms its accelerated counterparts.", "AI": {"tldr": "\u52a8\u91cf\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7406\u8bba\u5206\u6790\uff1a\u52a8\u91cf\u80fd\u6291\u5236\u68af\u5ea6\u566a\u58f0\u4f46\u4f1a\u653e\u5927\u6f02\u79fb\u8bef\u5dee\uff0c\u5b58\u5728\"\u60ef\u6027\u7a97\u53e3\"\u8fd9\u4e00\u4fe1\u606f\u7406\u8bba\u969c\u788d", "motivation": "\u52a8\u91cf\u52a0\u901f\u5728\u786e\u5b9a\u6027\u4f18\u5316\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u975e\u5e73\u7a33\u73af\u5883\uff08\u6570\u636e\u5206\u5e03\u548c\u6700\u4f18\u53c2\u6570\u968f\u65f6\u95f4\u6f02\u79fb\uff09\u4e2d\u7684\u884c\u4e3a\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u7406\u89e3SGD\u53ca\u5176\u52a8\u91cf\u53d8\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8ddf\u8e2a\u6027\u80fd", "method": "\u5728\u5747\u5300\u5f3a\u51f8\u6027\u548c\u5e73\u6ed1\u6027\u5047\u8bbe\u4e0b\uff0c\u5206\u6790SGD\u3001Polyak\u91cd\u7403\u6cd5\u548cNesterov\u52a8\u91cf\u5728\u4e0d\u540c\u6b65\u957f\u673a\u5236\u4e0b\u7684\u8ddf\u8e2a\u6027\u80fd\u3002\u63a8\u5bfc\u6709\u9650\u65f6\u95f4\u671f\u671b\u548c\u9ad8\u6982\u7387\u8ddf\u8e2a\u8bef\u5dee\u754c\uff0c\u5efa\u7acb\u5305\u542b\u521d\u59cb\u5316\u9879\u3001\u566a\u58f0\u65b9\u5dee\u9879\u548c\u6f02\u79fb\u8ddf\u8e2a\u6ede\u540e\u9879\u7684\u4e09\u5206\u91cf\u5206\u89e3", "result": "\u53d1\u73b0\u52a8\u91cf\u4e0e\u8ddf\u8e2a\u80fd\u529b\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\uff1a\u52a8\u91cf\u80fd\u6291\u5236\u68af\u5ea6\u566a\u58f0\uff0c\u4f46\u4f1a\u663e\u8457\u653e\u5927\u6f02\u79fb\u5f15\u8d77\u7684\u8ddf\u8e2a\u8bef\u5dee\uff0c\u5f53\u52a8\u91cf\u53c2\u6570\u63a5\u8fd11\u65f6\u653e\u5927\u6548\u5e94\u65e0\u9650\u589e\u5927\u3002\u5efa\u7acb\u4e86\u68af\u5ea6\u53d8\u5316\u7ea6\u675f\u4e0b\u7684\u52a8\u6001\u9057\u61be\u6781\u5c0f\u6781\u5927\u4e0b\u754c\uff0c\u8bc1\u660e\u60ef\u6027\u60e9\u7f5a\u4e0d\u662f\u5206\u6790\u5047\u8c61\u800c\u662f\u4fe1\u606f\u7406\u8bba\u969c\u788d", "conclusion": "\u52a8\u91cf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u4e0d\u53ef\u907f\u514d\u7684\"\u60ef\u6027\u7a97\u53e3\"\uff0c\u4f1a\u4ece\u6839\u672c\u4e0a\u964d\u4f4e\u6027\u80fd\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u52a8\u91cf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7ecf\u9a8c\u4e0d\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5212\u5b9a\u4e86SGD\u53ef\u8bc1\u660e\u4f18\u4e8e\u5176\u52a0\u901f\u5bf9\u5e94\u7269\u7684\u7cbe\u786e\u673a\u5236\u8fb9\u754c"}}
{"id": "2601.11554", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11554", "abs": "https://arxiv.org/abs/2601.11554", "authors": ["Triloki Nath", "Manohar Choudhary", "Ram K. Pandey"], "title": "A Generalized Waist Problem: Optimality Condition and Algorithm", "comment": null, "summary": "Many years ago John Tyrell a lecturer at King's college London challenged his Ph.D. students with the following puzzle: show that there is a unique triangle of minimal perimeter with exactly one vertex to lie on one of three given lines, pairwise disjoint and not all parallel in the space. The problem in literature is known as the waist problem, and only convexity rescued in this case. Motivated by this we generalize it by replacing lines with a number of convex sets in the Euclidean space and ask to minimize the sum of distances connecting the sets by means of closed polygonal curve. This generalized problem significantly broadens its geometric and practical scope in view of modern convex analysis. We establish the existence of solutions and prove its uniqueness under the condition that at least one of the convex sets is strictly convex and all are in general position: each set can be separated by convex hull of others. A complete set of necessary and sufficient optimality conditions is derived, and their geometric interpretations are explored to link these conditions with classical principles such as the reflection law of light. To address this problem computationally, we develop a projected subgradient descent method and prove its convergence. Our algorithm is supported by detailed numerical experiments, particularly in cases involving discs and spheres. Additionally, we present a real-world analogy of the problem in the form of inter-island connectivity, illustrating its practical relevance. This work not only advances the theory of geometric optimization but also contributes effective methods and insights applicable to facility location, network design, robotics., computational geometry, and spatial planning.", "AI": {"tldr": "\u8bba\u6587\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684\"\u8170\u56f4\u95ee\u9898\"\uff0c\u5c06\u4e09\u6761\u7ebf\u66ff\u6362\u4e3a\u591a\u4e2a\u51f8\u96c6\uff0c\u901a\u8fc7\u95ed\u6298\u7ebf\u8fde\u63a5\u8fd9\u4e9b\u51f8\u96c6\u6765\u6700\u5c0f\u5316\u603b\u8ddd\u79bb\uff0c\u5efa\u7acb\u4e86\u5b58\u5728\u6027\u3001\u552f\u4e00\u6027\u3001\u6700\u4f18\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u8ba1\u7b97\u7b97\u6cd5\u3002", "motivation": "\u53d7John Tyrell\u63d0\u51fa\u7684\u7ecf\u5178\"\u8170\u56f4\u95ee\u9898\"\u542f\u53d1\uff0c\u8be5\u95ee\u9898\u8981\u6c42\u627e\u5230\u4e0e\u4e09\u6761\u7ed9\u5b9a\u7ebf\u76f8\u4ea4\u4e14\u5468\u957f\u6700\u5c0f\u7684\u552f\u4e00\u4e09\u89d2\u5f62\u3002\u8bba\u6587\u65e8\u5728\u63a8\u5e7f\u8fd9\u4e2a\u95ee\u9898\uff0c\u5c06\u7ebf\u66ff\u6362\u4e3a\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u51f8\u96c6\uff0c\u6269\u5927\u5176\u51e0\u4f55\u548c\u5e94\u7528\u8303\u56f4\u3002", "method": "\u5c06\u7ecf\u5178\u95ee\u9898\u63a8\u5e7f\u4e3a\u901a\u8fc7\u95ed\u6298\u7ebf\u8fde\u63a5\u591a\u4e2a\u51f8\u96c6\u7684\u6700\u5c0f\u603b\u8ddd\u79bb\u95ee\u9898\u3002\u5efa\u7acb\u89e3\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff08\u8981\u6c42\u81f3\u5c11\u4e00\u4e2a\u51f8\u96c6\u4e25\u683c\u51f8\u4e14\u6240\u6709\u51f8\u96c6\u5904\u4e8e\u4e00\u822c\u4f4d\u7f6e\uff09\u3002\u63a8\u5bfc\u5b8c\u6574\u7684\u6700\u4f18\u6027\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u6295\u5f71\u6b21\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u6c42\u89e3\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u81f3\u5c11\u4e00\u4e2a\u51f8\u96c6\u4e25\u683c\u51f8\u4e14\u6240\u6709\u51f8\u96c6\u5904\u4e8e\u4e00\u822c\u4f4d\u7f6e\u6761\u4ef6\u4e0b\u89e3\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u3002\u63a8\u5bfc\u4e86\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5efa\u7acb\u4e86\u4e0e\u5149\u53cd\u5c04\u5b9a\u5f8b\u7b49\u7ecf\u5178\u539f\u7406\u7684\u51e0\u4f55\u8054\u7cfb\u3002\u7b97\u6cd5\u5728\u5706\u76d8\u548c\u7403\u4f53\u7b49\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u6570\u503c\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u5c9b\u5c7f\u8fde\u63a5\u7b49\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u51e0\u4f55\u4f18\u5316\u7406\u8bba\uff0c\u8fd8\u4e3a\u8bbe\u65bd\u9009\u5740\u3001\u7f51\u7edc\u8bbe\u8ba1\u3001\u673a\u5668\u4eba\u5b66\u3001\u8ba1\u7b97\u51e0\u4f55\u548c\u7a7a\u95f4\u89c4\u5212\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u548c\u89c1\u89e3\uff0c\u5c06\u7ecf\u5178\u51e0\u4f55\u95ee\u9898\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u51f8\u5206\u6790\u6846\u67b6\u4e2d\u3002"}}
{"id": "2601.14005", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.14005", "abs": "https://arxiv.org/abs/2601.14005", "authors": ["Bastien Baude", "Vincent Danos", "Hamza El Khalloufi"], "title": "Leveraged positions on decentralized lending platforms", "comment": "21 pages, 15 figures, 3 tables", "summary": "We develop a mathematical framework to optimize leveraged staking (\"loopy\") strategies in Decentralized Finance (DeFi), in which a staked asset is supplied as collateral, the underlying is borrowed and re-staked, and the loop can be repeated across multiple lending markets. Exploiting the fact that DeFi borrow rates are deterministic functions of pool utilization, we reduce the multi-market problem to a convex allocation over market exposures and obtain closed-form solutions under three interest-rate models: linear, kinked, and adaptive (Morpho's AdaptiveCurveIRM). The framework incorporates market-specific leverage limits, utilization-dependent borrowing costs, and transaction fees. Backtests on the Ethereum and Base blockchains using the largest Morpho wstETH/WETH markets (from January 1 to April 1, 2025) show that rebalanced leveraged positions can reach up to 6.2% APY versus 3.1% for unleveraged staking, with strong dependence on position size and rebalancing frequency. Our results provide a mathematical basis for transparent, automated DeFi portfolio optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\u6765\u4f18\u5316DeFi\u4e2d\u7684\u6760\u6746\u8d28\u62bc\uff08\"\u5faa\u73af\"\uff09\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u8d28\u62bc\u8d44\u4ea7\u4f5c\u4e3a\u62b5\u62bc\u54c1\u3001\u501f\u51fa\u5e95\u5c42\u8d44\u4ea7\u5e76\u91cd\u65b0\u8d28\u62bc\uff0c\u53ef\u5728\u591a\u4e2a\u501f\u8d37\u5e02\u573a\u4e2d\u91cd\u590d\u5faa\u73af\u3002\u5229\u7528DeFi\u501f\u8d37\u5229\u7387\u662f\u8d44\u91d1\u6c60\u5229\u7528\u7387\u7684\u786e\u5b9a\u6027\u51fd\u6570\u8fd9\u4e00\u4e8b\u5b9e\uff0c\u5c06\u591a\u5e02\u573a\u95ee\u9898\u7b80\u5316\u4e3a\u5e02\u573a\u655e\u53e3\u7684\u51f8\u5206\u914d\u95ee\u9898\uff0c\u5e76\u5728\u4e09\u79cd\u5229\u7387\u6a21\u578b\u4e0b\u83b7\u5f97\u95ed\u5f0f\u89e3\u3002\u56de\u6d4b\u663e\u793a\u518d\u5e73\u8861\u7684\u6760\u6746\u5934\u5bf8\u53ef\u8fbe6.2%\u5e74\u5316\u6536\u76ca\u7387\uff0c\u8fdc\u8d85\u975e\u6760\u6746\u8d28\u62bc\u76843.1%\u3002", "motivation": "DeFi\u4e2d\u7684\u6760\u6746\u8d28\u62bc\u7b56\u7565\uff08\u5982\u5faa\u73af\u8d28\u62bc\uff09\u5728\u5b9e\u8df5\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u7684\u6570\u5b66\u6846\u67b6\u6765\u4f18\u5316\u8fd9\u4e9b\u7b56\u7565\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u8bd5\u9519\u6cd5\uff0c\u65e0\u6cd5\u5728\u8003\u8651\u5e02\u573a\u7279\u5b9a\u6760\u6746\u9650\u5236\u3001\u5229\u7528\u7387\u4f9d\u8d56\u7684\u501f\u8d37\u6210\u672c\u548c\u4ea4\u6613\u8d39\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u81ea\u52a8\u5316\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u5b66\u6846\u67b6\uff0c\u5229\u7528DeFi\u501f\u8d37\u5229\u7387\u662f\u8d44\u91d1\u6c60\u5229\u7528\u7387\u7684\u786e\u5b9a\u6027\u51fd\u6570\u7684\u7279\u70b9\uff0c\u5c06\u591a\u5e02\u573a\u6760\u6746\u8d28\u62bc\u4f18\u5316\u95ee\u9898\u7b80\u5316\u4e3a\u5e02\u573a\u655e\u53e3\u7684\u51f8\u5206\u914d\u95ee\u9898\u3002\u5728\u4e09\u79cd\u5229\u7387\u6a21\u578b\u4e0b\u83b7\u5f97\u95ed\u5f0f\u89e3\uff1a\u7ebf\u6027\u6a21\u578b\u3001\u62d0\u70b9\u6a21\u578b\u548c\u81ea\u9002\u5e94\u6a21\u578b\uff08Morpho\u7684AdaptiveCurveIRM\uff09\u3002\u6846\u67b6\u8003\u8651\u4e86\u5e02\u573a\u7279\u5b9a\u6760\u6746\u9650\u5236\u3001\u5229\u7528\u7387\u4f9d\u8d56\u7684\u501f\u8d37\u6210\u672c\u548c\u4ea4\u6613\u8d39\u7528\u3002", "result": "\u5728\u4ee5\u592a\u574a\u548cBase\u533a\u5757\u94fe\u4e0a\u4f7f\u7528\u6700\u5927\u7684Morpho wstETH/WETH\u5e02\u573a\uff082025\u5e741\u67081\u65e5\u81f34\u67081\u65e5\uff09\u8fdb\u884c\u56de\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\u518d\u5e73\u8861\u7684\u6760\u6746\u5934\u5bf8\u5e74\u5316\u6536\u76ca\u7387\u53ef\u8fbe6.2%\uff0c\u800c\u975e\u6760\u6746\u8d28\u62bc\u4ec5\u4e3a3.1%\u3002\u6536\u76ca\u7387\u5f3a\u70c8\u4f9d\u8d56\u4e8e\u5934\u5bf8\u89c4\u6a21\u548c\u518d\u5e73\u8861\u9891\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u900f\u660e\u3001\u81ea\u52a8\u5316\u7684DeFi\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u6760\u6746\u8d28\u62bc\u7b56\u7565\u5728DeFi\u4e2d\u7684\u6f5c\u5728\u6536\u76ca\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u7684\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2601.11567", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11567", "abs": "https://arxiv.org/abs/2601.11567", "authors": ["Vanessa D'Amario", "Randy Daniel", "Alessandro Zanetti", "Dhruv Edamadaka", "Nitya Alaparthy", "Joshua Tarkoff"], "title": "Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology", "comment": "20 pages, 11 figures, accepted at 47 workshop Reproducible Artificial Intelligence (AAAI 2026, Singapore, January 27, 2026)", "summary": "Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.", "AI": {"tldr": "\u8bc4\u4f30\u516d\u4e2a\u5c0f\u578b\u5f00\u6e90\u533b\u7597LLM\u5728\u513f\u79d1\u5185\u5206\u6ccc\u5b66\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9ad8\u4e00\u81f4\u6027\u4e0d\u4ee3\u8868\u6b63\u786e\u6027\uff0c\u63d0\u793a\u5fae\u5c0f\u53d8\u5316\u4f1a\u5bfc\u81f4\u8f93\u51fa\u5206\u6b67\uff0c\u7cfb\u7edf\u7ea7\u6270\u52a8\u4e5f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u8bca\u65ad\u6846\u67b6\u3002", "motivation": "\u76ee\u524d\u5c0f\u578b\u5f00\u6e90\u533b\u7597LLM\u7684\u8bc4\u4f30\u4e3b\u8981\u5c40\u9650\u4e8e\u533b\u5b66\u591a\u9009\u9898\u7684\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u4e00\u81f4\u6027\u3001\u9c81\u68d2\u6027\u548c\u63a8\u7406\u884c\u4e3a\u7684\u8bc4\u4f30\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u4e86\u89e3\u8fd9\u4e9b\u6a21\u578b\u5728\u771f\u5b9e\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u573a\u666f\u4e2d\u7684\u6f5c\u5728\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u533b\u5b66\u591a\u9009\u9898\u7ed3\u5408\u4eba\u5de5\u8bc4\u4f30\u548c\u4e34\u5e8a\u5ba1\u67e5\uff0c\u8bc4\u4f30\u516d\u4e2a\u5c0f\u578b\u5f00\u6e90\u533b\u7597LLM\u3002\u5728\u786e\u5b9a\u6027\u8bbe\u7f6e\u4e2d\u68c0\u67e5\u63d0\u793a\u53d8\u5316\u5bf9\u6a21\u578b\u8f93\u51fa\u548c\u81ea\u6211\u8bc4\u4f30\u504f\u89c1\u7684\u5f71\u54cd\uff1b\u5728\u968f\u673a\u6027\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u8f93\u51fa\u53d8\u5f02\u6027\uff0c\u5e76\u7814\u7a76\u4e00\u81f4\u6027\u4e0e\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "HuatuoGPT-o1-8B\u8868\u73b0\u6700\u4f73\u3002\u9ad8\u4e00\u81f4\u6027\u5e76\u4e0d\u4ee3\u8868\u6b63\u786e\u6027\uff0c\u5c3d\u7ba1HuatuoGPT-o1-8B\u7684\u4e00\u81f4\u6027\u6700\u9ad8\u3002\u6a21\u578b\u8868\u73b0\u51fa\u81ea\u6211\u8bc4\u4f30\u504f\u89c1\u548c\u5bf9\u5019\u9009\u89e3\u91ca\u987a\u5e8f\u7684\u4f9d\u8d56\u3002\u4e13\u5bb6\u5ba1\u67e5\u53d1\u73b0\u9519\u8bef\u63a8\u7406\u4e2d\u6df7\u5408\u4e86\u4e34\u5e8a\u53ef\u63a5\u53d7\u7684\u54cd\u5e94\u548c\u4e34\u5e8a\u758f\u5ffd\u3002\u7cfb\u7edf\u7ea7\u6270\u52a8\uff08\u5982CUDA\u6784\u5efa\u5dee\u5f02\uff09\u4f1a\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u7684\u7edf\u8ba1\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u8bed\u4e49\u4e0a\u53ef\u5ffd\u7565\u7684\u63d0\u793a\u5fae\u5c0f\u53d8\u5316\u4f1a\u5bfc\u81f4\u8f93\u51fa\u5206\u6b67\uff0c\u8fd9\u5bf9\u57fa\u4e8eLLM\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u63d0\u51fa\u4e86\u62c5\u5fe7\u3002\u4e0d\u540c\u968f\u673a\u673a\u5236\u4e0b\u7684\u8f93\u51fa\u53d8\u5f02\u6027\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u5e7f\u6cdb\u7684\u8bca\u65ad\u6846\u67b6\u6765\u7406\u89e3\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u573a\u666f\u4e2d\u7684\u6f5c\u5728\u9677\u9631\u3002"}}
{"id": "2601.13281", "categories": ["econ.EM", "q-fin.RM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.13281", "abs": "https://arxiv.org/abs/2601.13281", "authors": ["Koos B. Gubbels", "Andre Lucas"], "title": "Spectral Dynamics and Regularization for High-Dimensional Copulas", "comment": null, "summary": "We introduce a novel model for time-varying, asymmetric, tail-dependent copulas in high dimensions that incorporates both spectral dynamics and regularization. The dynamics of the dependence matrix' eigenvalues are modeled in a score-driven way, while biases in the unconditional eigenvalue spectrum are resolved by non-linear shrinkage. The dynamic parameterization of the copula dependence matrix ensures that it satisfies the appropriate restrictions at all times and for any dimension. The model is parsimonious, computationally efficient, easily scalable to high dimensions, and performs well for both simulated and empirical data. In an empirical application to financial market dynamics using 100 stocks from 10 different countries and 10 different industry sectors, we find that our copula model captures both geographic and industry related co-movements and outperforms recent computationally more intensive clustering-based factor copula alternatives. Both the spectral dynamics and the regularization contribute to the new model's performance. During periods of market stress, we find that the spectral dynamics reveal strong increases in international stock market dependence, which causes reductions in diversification potential and increases in systemic risk.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9ad8\u7ef4\u65f6\u53d8\u3001\u975e\u5bf9\u79f0\u3001\u5c3e\u90e8\u76f8\u5173copula\u6a21\u578b\uff0c\u7ed3\u5408\u8c31\u52a8\u6001\u548c\u6b63\u5219\u5316\uff0c\u80fd\u6709\u6548\u6355\u6349\u91d1\u878d\u5e02\u573a\u7684\u5730\u7406\u548c\u884c\u4e1a\u5171\u52a8\uff0c\u5728\u538b\u529b\u65f6\u671f\u63ed\u793a\u7cfb\u7edf\u6027\u98ce\u9669\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u9ad8\u7ef4copula\u6a21\u578b\u5728\u5904\u7406\u65f6\u53d8\u3001\u975e\u5bf9\u79f0\u3001\u5c3e\u90e8\u4f9d\u8d56\u5173\u7cfb\u65f6\u5b58\u5728\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u91d1\u878d\u5e02\u573a\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\uff08\u5730\u7406\u548c\u884c\u4e1a\u5171\u52a8\uff09\u65b9\u9762\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u6a21\u578b\u3002", "method": "\u91c7\u7528\u8c31\u52a8\u6001\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u4f9d\u8d56\u77e9\u9635\u7279\u5f81\u503c\u7684\u52a8\u6001\u53d8\u5316\u7528score-driven\u65b9\u5f0f\u5efa\u6a21\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u6536\u7f29\u89e3\u51b3\u65e0\u6761\u4ef6\u7279\u5f81\u503c\u8c31\u7684\u504f\u5dee\u95ee\u9898\uff0c\u786e\u4fdd\u4f9d\u8d56\u77e9\u9635\u59cb\u7ec8\u6ee1\u8db3\u9002\u5f53\u7ea6\u675f\u3002", "result": "\u6a21\u578b\u5728\u6a21\u62df\u548c\u5b9e\u8bc1\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5728100\u53ea\u80a1\u7968\u7684\u5b9e\u8bc1\u5e94\u7528\u4e2d\uff0c\u80fd\u6709\u6548\u6355\u6349\u5730\u7406\u548c\u884c\u4e1a\u76f8\u5173\u5171\u52a8\uff0c\u4f18\u4e8e\u8ba1\u7b97\u66f4\u5bc6\u96c6\u7684\u805a\u7c7b\u56e0\u5b50copula\u66ff\u4ee3\u65b9\u6cd5\uff0c\u8c31\u52a8\u6001\u548c\u6b63\u5219\u5316\u90fd\u5bf9\u6027\u80fd\u6709\u8d21\u732e\u3002", "conclusion": "\u8be5copula\u6a21\u578b\u5177\u6709\u7b80\u6d01\u6027\u3001\u8ba1\u7b97\u9ad8\u6548\u6027\u548c\u9ad8\u7ef4\u53ef\u6269\u5c55\u6027\uff0c\u5728\u5e02\u573a\u538b\u529b\u65f6\u671f\u80fd\u63ed\u793a\u56fd\u9645\u80a1\u5e02\u4f9d\u8d56\u6027\u7684\u663e\u8457\u589e\u5f3a\uff0c\u4ece\u800c\u8bc6\u522b\u591a\u6837\u5316\u6f5c\u529b\u964d\u4f4e\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u589e\u52a0\u3002"}}
{"id": "2601.11572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11572", "abs": "https://arxiv.org/abs/2601.11572", "authors": ["Timo Aukusti Laine"], "title": "Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces", "comment": "23 pages, 5 figures", "summary": "We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.", "AI": {"tldr": "\u8bba\u6587\u4f7f\u7528\u7ebf\u6027\u4ee3\u6570\u548c\u54c8\u5bc6\u987f\u5f62\u5f0f\u7814\u7a76LLM\u5d4c\u5165\u7a7a\u95f4\u7ed3\u6784\uff0c\u53d1\u73b0L2\u5f52\u4e00\u5316\u7ea6\u675f\u4f7f\u5d4c\u5165\u7a7a\u95f4\u9002\u5408\u54c8\u5bc6\u987f\u5206\u6790\uff0c\u5e76\u63a2\u7d22\u4e86\u91cf\u5b50\u529b\u5b66\u7c7b\u6bd4", "motivation": "\u89c2\u5bdf\u5230LLM\u5d4c\u5165\u8868\u73b0\u51fa\u79bb\u6563\u72b6\u6001\uff0c\u6697\u793a\u79bb\u6563\u8bed\u4e49\u8868\u793a\uff0c\u5e0c\u671b\u901a\u8fc7\u6570\u5b66\u5de5\u5177\u5206\u6790\u8bed\u4e49\u5173\u7cfb\uff0c\u7279\u522b\u662f\u501f\u9274\u91cf\u5b50\u529b\u5b66\u7cfb\u7edf\u7684\u7c7b\u6bd4", "method": "\u5e94\u7528\u7ebf\u6027\u4ee3\u6570\u548c\u54c8\u5bc6\u987f\u5f62\u5f0f\u5206\u6790LLM\u5d4c\u5165\u7a7a\u95f4\uff0c\u63a8\u5bfc\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4e0e\u5d4c\u5165\u5411\u91cf\u6270\u52a8\u7684\u5173\u7cfb\uff0c\u63a2\u7d22\u76f4\u63a5\u548c\u95f4\u63a5\u8bed\u4e49\u8f6c\u6362\uff0c\u91c7\u7528\u91cf\u5b50\u542f\u53d1\u89c6\u89d2", "result": "L2\u5f52\u4e00\u5316\u7ea6\u675f\u4f7f\u5d4c\u5165\u7a7a\u95f4\u7ed3\u6784\u5316\uff0c\u9002\u5408\u54c8\u5bc6\u987f\u5f62\u5f0f\u5206\u6790\uff1b\u5efa\u7acb\u4e86\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4e0e\u5411\u91cf\u6270\u52a8\u7684\u5173\u7cfb\uff1b\u63a2\u7d22\u4e86\u91cf\u5b50\u7c7b\u6bd4\u5982\u96f6\u70b9\u80fd\u91cf\u548cKoopman-von Neumann\u529b\u5b66\u8054\u7cfb", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u6df1\u5165\u7406\u89e3LLM\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u53ef\u80fd\u6709\u52a9\u4e8e\u5f00\u53d1\u51cf\u5c11\u5e7b\u89c9\u7684\u65b0\u65b9\u6cd5\uff0c\u4f46\u89e3\u91ca\u9700\u8981\u8c28\u614e\u8003\u8651"}}
{"id": "2601.11622", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11622", "abs": "https://arxiv.org/abs/2601.11622", "authors": ["Hassan Ugail", "Newton Howard"], "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models", "comment": null, "summary": "Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\u5e94\u7528\u4e8eTransformer\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\u6765\u91cf\u5316LLM\u5728\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u65f6\u95f4\u7ec4\u7ec7\u5dee\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u4f9d\u8d56\u4e8e\u9ad8\u7ef4\u5185\u90e8\u52a8\u529b\u5b66\uff0c\u4f46\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u8868\u793a\u6216\u56e0\u679c\u5e72\u9884\uff0c\u5bf9\u65f6\u95f4\u7ed3\u6784\u7684\u7814\u7a76\u4e0d\u8db3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u501f\u9274\u795e\u7ecf\u79d1\u5b66\u4e2d\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u7684\u6982\u5ff5\u6765\u5206\u6790LLM\u7684\u65f6\u95f4\u7ec4\u7ec7\u7279\u6027\u3002", "method": "\u4ece\u795e\u7ecf\u79d1\u5b66\u5f15\u5165\u65f6\u95f4\u6574\u5408\u548c\u4e9a\u7a33\u6001\u6982\u5ff5\uff0c\u6784\u5efa\u590d\u5408\u52a8\u529b\u5b66\u6307\u6807\uff0c\u5728GPT-2-medium\u4e0a\u8bc4\u4f30\u4e94\u79cd\u6761\u4ef6\uff1a\u7ed3\u6784\u5316\u63a8\u7406\u3001\u5f3a\u5236\u91cd\u590d\u3001\u9ad8\u6e29\u566a\u58f0\u91c7\u6837\u3001\u6ce8\u610f\u529b\u5934\u526a\u679d\u548c\u6743\u91cd\u566a\u58f0\u6ce8\u5165\u3002\u4f7f\u7528\u5355\u56e0\u7d20\u65b9\u5dee\u5206\u6790\u548c\u6548\u5e94\u5927\u5c0f\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\u3002", "result": "\u7ed3\u6784\u5316\u63a8\u7406\u76f8\u6bd4\u91cd\u590d\u3001\u566a\u58f0\u548c\u6270\u52a8\u6761\u4ef6\u8868\u73b0\u51fa\u663e\u8457\u66f4\u9ad8\u7684\u52a8\u529b\u5b66\u6307\u6807\u503c\uff0c\u7edf\u8ba1\u5dee\u5f02\u663e\u8457\u4e14\u6548\u5e94\u91cf\u5927\u3002\u7ed3\u679c\u5bf9\u5c42\u9009\u62e9\u3001\u901a\u9053\u5b50\u91c7\u6837\u548c\u968f\u673a\u79cd\u5b50\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u52a8\u529b\u5b66\u6307\u6807\u80fd\u591f\u53ef\u9760\u5730\u8868\u5f81\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u529f\u80fd\u673a\u5236\u4e0b\u7684\u8ba1\u7b97\u7ec4\u7ec7\u5dee\u5f02\u3002\u8be5\u6307\u6807\u6355\u6349\u7684\u662f\u5f62\u5f0f\u52a8\u529b\u5b66\u7279\u6027\uff0c\u800c\u975e\u4e3b\u89c2\u4f53\u9a8c\u3002"}}
{"id": "2601.12175", "categories": ["q-fin.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.12175", "abs": "https://arxiv.org/abs/2601.12175", "authors": ["Harrison E. Katz", "Jess Needleman", "Liz Medina"], "title": "Distributional Fitting and Tail Analysis of Lead-Time Compositions: Nights vs. Revenue on Airbnb", "comment": null, "summary": "We analyze daily lead-time distributions for two Airbnb demand metrics, Nights Booked (volume) and Gross Booking Value (revenue), treating each day's allocation across 0-365 days as a compositional vector. The data span 2,557 days from January 2019 through December 2025 in a large North American region. Three findings emerge. First, GBV concentrates more heavily in mid-range horizons: beyond 90 days, GBV tail mass typically exceeds Nights by 20-50%, with ratios reaching 75% at the 180-day threshold during peak seasons. Second, Gamma and Weibull distributions fit comparably well under interval-censored cross-entropy. Gamma wins on 61% of days for Nights and 52% for GBV, with Weibull close behind at 38% and 45%. Lognormal rarely wins (<3%). Nonparametric GAMs achieve 18-80x lower CRPS but sacrifice interpretability. Third, generalized Pareto fits suggest bounded tails for both metrics at thresholds below 150 days, though this may partly reflect right-truncation at 365 days; above 150 days, estimates destabilize. Bai-Perron tests with HAC standard errors identify five structural breaks in the Wasserstein distance series, with early breaks coinciding with COVID-19 disruptions. The results show that volume and revenue lead-time shapes diverge systematically, that simple two-parameter distributions capture daily pmfs adequately, and that tail inference requires care near truncation boundaries.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86Airbnb\u9884\u8ba2\u63d0\u524d\u671f\u5206\u5e03\uff0c\u53d1\u73b0\u6536\u5165\uff08GBV\uff09\u6bd4\u9884\u8ba2\u91cf\uff08Nights\uff09\u66f4\u96c6\u4e2d\u4e8e\u4e2d\u957f\u671f\u63d0\u524d\u671f\uff0cGamma\u548cWeibull\u5206\u5e03\u62df\u5408\u6548\u679c\u6700\u4f73\uff0c\u5c3e\u90e8\u63a8\u65ad\u9700\u8c28\u614e\u5904\u7406\u622a\u65ad\u8fb9\u754c\u3002", "motivation": "\u7814\u7a76Airbnb\u9884\u8ba2\u63d0\u524d\u671f\u5206\u5e03\u5bf9\u8fd0\u8425\u548c\u6536\u5165\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u9884\u8ba2\u91cf\uff0c\u4f46\u6536\u5165\uff08GBV\uff09\u7684\u63d0\u524d\u671f\u5206\u5e03\u53ef\u80fd\u4e0d\u540c\uff0c\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u4e24\u8005\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540c\u5206\u5e03\u6a21\u578b\u7684\u62df\u5408\u6548\u679c\u3002", "method": "\u5c06\u6bcf\u65e50-365\u5929\u63d0\u524d\u671f\u7684\u5206\u914d\u89c6\u4e3a\u7ec4\u5408\u5411\u91cf\uff0c\u4f7f\u7528Gamma\u3001Weibull\u3001\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u8fdb\u884c\u533a\u95f4\u622a\u5c3e\u4ea4\u53c9\u71b5\u62df\u5408\uff0c\u91c7\u7528\u975e\u53c2\u6570GAMs\u4f5c\u4e3a\u57fa\u51c6\uff0c\u4f7f\u7528\u5e7f\u4e49\u5e15\u7d2f\u6258\u5206\u5e03\u5206\u6790\u5c3e\u90e8\uff0cBai-Perron\u68c0\u9a8c\u68c0\u6d4b\u7ed3\u6784\u65ad\u70b9\u3002", "result": "1. GBV\u6bd4Nights\u66f4\u96c6\u4e2d\u4e8e\u4e2d\u957f\u671f\u63d0\u524d\u671f\uff0890\u5929\u540e\u591a20-50%\uff0c\u65fa\u5b63180\u5929\u9608\u503c\u8fbe75%\uff09\uff1b2. Gamma\u548cWeibull\u5206\u5e03\u62df\u5408\u6548\u679c\u6700\u4f73\uff08Gamma\u572861%\u5929\u6570\u5bf9Nights\u80dc\u51fa\uff0c52%\u5bf9GBV\uff09\uff1b3. \u5c3e\u90e8\u5728150\u5929\u5185\u6709\u9650\uff0c\u4f46\u53d7365\u5929\u622a\u65ad\u5f71\u54cd\uff1b4. \u68c0\u6d4b\u52305\u4e2a\u7ed3\u6784\u65ad\u70b9\uff0c\u65e9\u671f\u4e0eCOVID-19\u76f8\u5173\u3002", "conclusion": "Airbnb\u9884\u8ba2\u91cf\u548c\u6536\u5165\u7684\u63d0\u524d\u671f\u5206\u5e03\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u7b80\u5355\u7684\u4e24\u53c2\u6570\u5206\u5e03\uff08Gamma/Weibull\uff09\u80fd\u5145\u5206\u6355\u6349\u6bcf\u65e5\u5206\u5e03\uff0c\u4f46\u5c3e\u90e8\u63a8\u65ad\u9700\u8c28\u614e\u5904\u7406\u622a\u65ad\u8fb9\u754c\uff0c\u8fd9\u5bf9\u6536\u76ca\u7ba1\u7406\u548c\u8fd0\u8425\u89c4\u5212\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.11962", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11962", "abs": "https://arxiv.org/abs/2601.11962", "authors": ["Manavi Araga", "Aditya Natu", "Hassan HosseinNia"], "title": "Structured \u03bc-Synthesis for Nanopositioners under Payload-Induced Uncertainties: Minimising Conservatism for Robust Performance", "comment": null, "summary": "Most systems exhibit significant variability in their dynamics, including variations in system parameters and large high-frequency dynamic uncertainties. Traditional uncertainty modelling techniques consolidate all such variations into a single uncertainty block, often yielding overly conservative representations of the true plant behaviour. This paper introduces an uncertainty modelling framework that employs multiple structured and unstructured uncertainty blocks to reduce this conservatism. The methodology is evaluated for an industrial piezoelectric nanopositioner subject to payload-induced variations, using uncertainty models of differing complexity. A bandpass controller is synthesised via structured mixed-\u03bc synthesis, and the resulting designs are compared in terms of conservatism of the uncertainty model, robust performance, and computational effort.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5757\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u6846\u67b6\u4ee5\u51cf\u5c11\u4f20\u7edf\u5355\u5757\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u7684\u4fdd\u5b88\u6027\uff0c\u5e94\u7528\u4e8e\u538b\u7535\u7eb3\u7c73\u5b9a\u4f4d\u5668\u5e76\u6bd4\u8f83\u4e0d\u540c\u590d\u6742\u5ea6\u6a21\u578b", "motivation": "\u4f20\u7edf\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u5c06\u6240\u6709\u52a8\u6001\u53d8\u5316\u5408\u5e76\u5230\u5355\u4e2a\u4e0d\u786e\u5b9a\u6027\u5757\u4e2d\uff0c\u5bfc\u81f4\u5bf9\u771f\u5b9e\u7cfb\u7edf\u884c\u4e3a\u7684\u8fc7\u5ea6\u4fdd\u5b88\u8868\u793a\uff0c\u9700\u8981\u51cf\u5c11\u8fd9\u79cd\u4fdd\u5b88\u6027", "method": "\u5f15\u5165\u4f7f\u7528\u591a\u4e2a\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u4e0d\u786e\u5b9a\u6027\u5757\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6df7\u5408\u03bc\u7efc\u5408\u65b9\u6cd5\u8bbe\u8ba1\u5e26\u901a\u63a7\u5236\u5668\uff0c\u8bc4\u4f30\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u578b", "result": "\u5728\u5de5\u4e1a\u538b\u7535\u7eb3\u7c73\u5b9a\u4f4d\u5668\u4e0a\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e0d\u786e\u5b9a\u6027\u6a21\u578b\u7684\u4fdd\u5b88\u6027\u3001\u9c81\u68d2\u6027\u80fd\u548c\u8ba1\u7b97\u5de5\u4f5c\u91cf", "conclusion": "\u591a\u5757\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u4f20\u7edf\u5355\u5757\u5efa\u6a21\u7684\u4fdd\u5b88\u6027\uff0c\u4e3a\u7cfb\u7edf\u63a7\u5236\u8bbe\u8ba1\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u793a"}}
{"id": "2601.12896", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.12896", "abs": "https://arxiv.org/abs/2601.12896", "authors": ["Eric Vansteenberghe"], "title": "Quantitative Methods in Finance", "comment": null, "summary": "These lecture notes provide a comprehensive introduction to Quantitative Methods in Finance (QMF), designed for graduate students in finance and economics with heterogeneous programming backgrounds. The material develops a unified toolkit combining probability theory, statistics, numerical methods, and empirical modeling, with a strong emphasis on implementation in Python. Core topics include random variables and distributions, moments and dependence, simulation and Monte Carlo methods, numerical optimization, root-finding, and time-series models commonly used in finance and macro-finance. Particular attention is paid to translating theoretical concepts into reproducible code, emphasizing vectorization, numerical stability, and interpretation of outputs. The notes progressively bridge theory and practice through worked examples and exercises covering asset pricing intuition, risk measurement, forecasting, and empirical analysis. By focusing on clarity, minimal prerequisites, and hands-on computation, these lecture notes aim to serve both as a pedagogical entry point for non-programmers and as a practical reference for applied researchers seeking transparent and replicable quantitative methods in finance.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u4efd\u9762\u5411\u91d1\u878d\u548c\u7ecf\u6d4e\u5b66\u7814\u7a76\u751f\u7684\u91cf\u5316\u91d1\u878d\u65b9\u6cd5\u8bfe\u7a0b\u8bb2\u4e49\uff0c\u7ed3\u5408\u6982\u7387\u8bba\u3001\u7edf\u8ba1\u5b66\u3001\u6570\u503c\u65b9\u6cd5\u548c\u5b9e\u8bc1\u5efa\u6a21\uff0c\u91cd\u70b9\u4f7f\u7528Python\u5b9e\u73b0\uff0c\u5f3a\u8c03\u7406\u8bba\u5230\u4ee3\u7801\u7684\u8f6c\u5316\u3002", "motivation": "\u4e3a\u5177\u6709\u4e0d\u540c\u7f16\u7a0b\u80cc\u666f\u7684\u91d1\u878d\u548c\u7ecf\u6d4e\u5b66\u7814\u7a76\u751f\u63d0\u4f9b\u7edf\u4e00\u7684\u91cf\u5316\u65b9\u6cd5\u5de5\u5177\u5305\uff0c\u5f3a\u8c03\u53ef\u590d\u73b0\u7684\u4ee3\u7801\u5b9e\u73b0\uff0c\u5f25\u5408\u7406\u8bba\u6982\u5ff5\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u7efc\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u6982\u7387\u8bba\u3001\u7edf\u8ba1\u5b66\u3001\u6570\u503c\u65b9\u6cd5\u548c\u5b9e\u8bc1\u5efa\u6a21\uff0c\u901a\u8fc7Python\u7f16\u7a0b\u5b9e\u73b0\uff0c\u6ce8\u91cd\u5411\u91cf\u5316\u3001\u6570\u503c\u7a33\u5b9a\u6027\u548c\u8f93\u51fa\u89e3\u91ca\uff0c\u901a\u8fc7\u5b9e\u4f8b\u548c\u7ec3\u4e60\u9010\u6b65\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u8df5\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u5957\u5b8c\u6574\u7684\u91cf\u5316\u91d1\u878d\u65b9\u6cd5\u6559\u5b66\u6750\u6599\uff0c\u6db5\u76d6\u968f\u673a\u53d8\u91cf\u4e0e\u5206\u5e03\u3001\u77e9\u4e0e\u76f8\u5173\u6027\u3001\u6a21\u62df\u4e0e\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3001\u6570\u503c\u4f18\u5316\u3001\u6839\u67e5\u627e\u4ee5\u53ca\u91d1\u878d\u548c\u5b8f\u89c2\u91d1\u878d\u4e2d\u5e38\u7528\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u8bb2\u4e49\u65e8\u5728\u4e3a\u7f16\u7a0b\u57fa\u7840\u4e0d\u540c\u7684\u5b66\u4e60\u8005\u63d0\u4f9b\u6e05\u6670\u7684\u5165\u95e8\u6307\u5bfc\uff0c\u540c\u65f6\u4e3a\u5e94\u7528\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u900f\u660e\u53ef\u590d\u73b0\u7684\u91cf\u5316\u65b9\u6cd5\u53c2\u8003\uff0c\u5f3a\u8c03\u5b9e\u8df5\u8ba1\u7b97\u548c\u7406\u8bba\u5230\u4ee3\u7801\u7684\u8f6c\u5316\u3002"}}
{"id": "2601.11569", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11569", "abs": "https://arxiv.org/abs/2601.11569", "authors": ["Jethro Masis"], "title": "Making AI Philosophical Again: On Philip E. Agre's Legacy", "comment": "13 pages", "summary": "This paper examines the intellectual legacy of Philip E. Agre by situating his work at the intersection of artificial intelligence, philosophy, and critical theory. It reconstructs Agre's proposal of a critical technical practice, according to which AI should be understood not merely as an engineering discipline but as a form of mathematized philosophy shaped by historically contingent metaphors, assumptions, and discourses. Drawing on Heideggerian phenomenology, especially the distinction between ready-to-hand and present-at-hand, Agre sought to reform AI by emphasizing interaction, embedding, indexicality, and deictic representation over traditional mentalist and representational models. The paper analyzes Agre's attempt to operationalize these ideas through computational implementations such as the Pengi system, highlighting both the philosophical ambition and the technical limitations of programming phenomenological concepts. While acknowledging Agre's success in exposing the hidden philosophical commitments of AI and enriching its conceptual vocabulary, the paper ultimately argues that his project encounters a fundamental impasse: the open and self-disclosing character of human existence articulated by Heidegger cannot be fully captured or programmed without reducing ontological phenomena to ontic mechanisms. Agre's enduring contribution therefore lies less in offering a viable Heideggerian AI than in compelling technical practice to become reflexive, historically conscious, and openly philosophical.", "AI": {"tldr": "\u672c\u6587\u5206\u6790Philip E. Agre\u7684\u5b66\u672f\u9057\u4ea7\uff0c\u63a2\u8ba8\u4ed6\u63d0\u51fa\u7684\"\u6279\u5224\u6027\u6280\u672f\u5b9e\u8df5\"\u7406\u5ff5\uff0c\u8ba4\u4e3aAI\u4e0d\u4ec5\u662f\u5de5\u7a0b\u5b66\u79d1\uff0c\u66f4\u662f\u53d7\u5386\u53f2\u5076\u7136\u6027\u9690\u55bb\u3001\u5047\u8bbe\u548c\u8bdd\u8bed\u5f71\u54cd\u7684\u6570\u5b66\u5316\u54f2\u5b66\u5f62\u5f0f\u3002\u6587\u7ae0\u8bc4\u4f30\u4e86Agre\u5c06\u6d77\u5fb7\u683c\u5c14\u73b0\u8c61\u5b66\u878d\u5165AI\u7814\u7a76\u7684\u5c1d\u8bd5\u53ca\u5176\u6839\u672c\u56f0\u5883\u3002", "motivation": "Agre\u8ba4\u4e3a\u4f20\u7edfAI\u7814\u7a76\u8fc7\u4e8e\u4f9d\u8d56\u5fc3\u667a\u4e3b\u4e49\u548c\u8868\u5f81\u6a21\u578b\uff0c\u5ffd\u89c6\u4e86AI\u4f5c\u4e3a\u54f2\u5b66\u5b9e\u8df5\u7684\u672c\u8d28\u3002\u4ed6\u8bd5\u56fe\u901a\u8fc7\u5f15\u5165\u6d77\u5fb7\u683c\u5c14\u73b0\u8c61\u5b66\uff08\u7279\u522b\u662f\"\u4e0a\u624b\u72b6\u6001\"\u4e0e\"\u73b0\u6210\u5728\u624b\u72b6\u6001\"\u7684\u533a\u5206\uff09\u6765\u6539\u9769AI\uff0c\u5f3a\u8c03\u4ea4\u4e92\u3001\u5d4c\u5165\u3001\u7d22\u5f15\u6027\u548c\u6307\u793a\u6027\u8868\u5f81\u7684\u91cd\u8981\u6027\u3002", "method": "\u901a\u8fc7\u91cd\u6784Agre\u7684\u6279\u5224\u6027\u6280\u672f\u5b9e\u8df5\u7406\u8bba\uff0c\u5206\u6790\u4ed6\u5c06\u6d77\u5fb7\u683c\u5c14\u73b0\u8c61\u5b66\u6982\u5ff5\uff08\u5982\u4e0a\u624b\u673a\u5236\u3001\u7d22\u5f15\u6027\u3001\u6307\u793a\u6027\u8868\u5f81\uff09\u64cd\u4f5c\u5316\u4e3a\u8ba1\u7b97\u5b9e\u73b0\uff08\u5982Pengi\u7cfb\u7edf\uff09\u7684\u5c1d\u8bd5\u3002\u6587\u7ae0\u8003\u5bdf\u4e86\u54f2\u5b66\u6982\u5ff5\u8f6c\u5316\u4e3a\u6280\u672f\u5b9e\u73b0\u7684\u53ef\u884c\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "Agre\u6210\u529f\u63ed\u793a\u4e86AI\u4e2d\u9690\u85cf\u7684\u54f2\u5b66\u627f\u8bfa\uff0c\u4e30\u5bcc\u4e86AI\u7684\u6982\u5ff5\u8bcd\u6c47\uff0c\u4f46\u4ed6\u7684\u9879\u76ee\u9047\u5230\u4e86\u6839\u672c\u6027\u56f0\u5883\uff1a\u6d77\u5fb7\u683c\u5c14\u6240\u9610\u8ff0\u7684\u4eba\u7c7b\u5b58\u5728\u7684\u5f00\u653e\u6027\u548c\u81ea\u6211\u63ed\u793a\u7279\u5f81\u65e0\u6cd5\u88ab\u5b8c\u5168\u7f16\u7a0b\u5b9e\u73b0\uff0c\u5426\u5219\u4f1a\u5c06\u672c\u4f53\u73b0\u8c61\u7b80\u5316\u4e3a\u5b58\u5728\u673a\u5236\u3002", "conclusion": "Agre\u7684\u6301\u4e45\u8d21\u732e\u4e0d\u5728\u4e8e\u63d0\u4f9b\u53ef\u884c\u7684\u6d77\u5fb7\u683c\u5c14\u5f0fAI\uff0c\u800c\u5728\u4e8e\u8feb\u4f7f\u6280\u672f\u5b9e\u8df5\u53d8\u5f97\u53cd\u601d\u6027\u3001\u5386\u53f2\u610f\u8bc6\u548c\u54f2\u5b66\u5f00\u653e\u6027\u3002\u4ed6\u7684\u9057\u4ea7\u662f\u8ba9AI\u7814\u7a76\u8ba4\u8bc6\u5230\u81ea\u8eab\u7684\u54f2\u5b66\u672c\u8d28\u548c\u5386\u53f2\u5076\u7136\u6027\u3002"}}
{"id": "2601.12587", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12587", "abs": "https://arxiv.org/abs/2601.12587", "authors": ["Frank Cole", "Yulong Lu", "Shaurya Sehgal"], "title": "A Theory of Diversity for Random Matrices with Applications to In-Context Learning of Schr\u00f6dinger Equations", "comment": null, "summary": "We address the following question: given a collection $\\{\\mathbf{A}^{(1)}, \\dots, \\mathbf{A}^{(N)}\\}$ of independent $d \\times d$ random matrices drawn from a common distribution $\\mathbb{P}$, what is the probability that the centralizer of $\\{\\mathbf{A}^{(1)}, \\dots, \\mathbf{A}^{(N)}\\}$ is trivial? We provide lower bounds on this probability in terms of the sample size $N$ and the dimension $d$ for several families of random matrices which arise from the discretization of linear Schr\u00f6dinger operators with random potentials. When combined with recent work on machine learning theory, our results provide guarantees on the generalization ability of transformer-based neural networks for in-context learning of Schr\u00f6dinger equations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u968f\u673a\u77e9\u9635\u96c6\u5408\u4e2d\u5fc3\u5316\u5b50\u4e3a\u5e73\u51e1\u7684\u6982\u7387\u4e0b\u754c\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eTransformer\u7f51\u7edc\u5728\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4fdd\u8bc1\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u77e9\u9635\u96c6\u5408\u4e2d\u5fc3\u5316\u5b50\u4e3a\u5e73\u51e1\u7684\u6982\u7387\uff0c\u4e3a\u7406\u89e3\u968f\u673a\u77e9\u9635\u4ee3\u6570\u7ed3\u6784\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5e94\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u4e2dTransformer\u7f51\u7edc\u5bf9\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6cdb\u5316\u80fd\u529b\u5206\u6790\u3002", "method": "\u9488\u5bf9\u4ece\u968f\u673a\u859b\u5b9a\u8c14\u7b97\u5b50\u79bb\u6563\u5316\u5f97\u5230\u7684\u51e0\u7c7b\u968f\u673a\u77e9\u9635\u65cf\uff0c\u5efa\u7acb\u6837\u672c\u5927\u5c0fN\u548c\u7ef4\u5ea6d\u4e0e\u4e2d\u5fc3\u5316\u5b50\u4e3a\u5e73\u51e1\u6982\u7387\u4e4b\u95f4\u7684\u4e0b\u754c\u5173\u7cfb\u3002", "result": "\u7ed9\u51fa\u4e86\u968f\u673a\u77e9\u9635\u96c6\u5408\u4e2d\u5fc3\u5316\u5b50\u4e3a\u5e73\u51e1\u6982\u7387\u7684\u4e0b\u754c\u4f30\u8ba1\uff0c\u8fd9\u4e9b\u7ed3\u679c\u4e0e\u8fd1\u671f\u673a\u5668\u5b66\u4e60\u7406\u8bba\u7ed3\u5408\uff0c\u4e3aTransformer\u7f51\u7edc\u5728\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u968f\u673a\u77e9\u9635\u4ee3\u6570\u6027\u8d28\u4e0e\u673a\u5668\u5b66\u4e60\u6cdb\u5316\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u7269\u7406\u65b9\u7a0b\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2601.11555", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11555", "abs": "https://arxiv.org/abs/2601.11555", "authors": ["Triloki Nath", "Manohar Choudhary", "Ram K. Pandey"], "title": "A Generalized $(k,m)$ Heron Problem:Optimality Conditions and Algorithm", "comment": null, "summary": "This paper presents a new extension of the classical Heron problem, termed the generalized $(k,m)$-Heron problem, which seeks an optimal configuration among $k$ feasible and $m$ target non-empty closed convex sets in $\\mathbb{R}^n$. The problem is formulated as finding a point in each set that minimizes the pairwise distances from the points in the $k$-feasible sets to the points in the $m$-target sets. This formulation leads to a convex optimization framework that generalizes several well-known geometric distance problems. Using tools from convex analysis, we establish fundamental results on existence, uniqueness, and first-order optimality conditions through subdifferential calculus and normal cone theory. Building on these insights, a Projected Subgradient Algorithm (PSA) is proposed for numerical solution, and its convergence is rigorously proved under a diminishing step-size rule. Numerical experiments in $\\mathbb{R}^2$ and $\\mathbb{R}^3$ illustrate the algorithm's stability, geometric accuracy, and computational efficiency. Overall, this work provides a comprehensive analytical and algorithmic framework for multi-set geometric optimization with promising implications for location science, robotics, and computational geometry.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5e7f\u4e49(k,m)-Heron\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u7ecf\u5178Heron\u95ee\u9898\uff0c\u65e8\u5728\u5bfb\u627ek\u4e2a\u53ef\u884c\u96c6\u548cm\u4e2a\u76ee\u6807\u96c6\u4e4b\u95f4\u7684\u6700\u4f18\u914d\u7f6e\uff0c\u5efa\u7acb\u4e86\u51f8\u4f18\u5316\u6846\u67b6\u5e76\u8bbe\u8ba1\u4e86\u6536\u655b\u7b97\u6cd5\u3002", "motivation": "\u7ecf\u5178Heron\u95ee\u9898\u4ec5\u5904\u7406\u5355\u4e2a\u70b9\u5230\u96c6\u5408\u7684\u8ddd\u79bb\u4f18\u5316\uff0c\u800c\u73b0\u5b9e\u5e94\u7528\u4e2d\u5e38\u6d89\u53ca\u591a\u4e2a\u53ef\u884c\u96c6\u548c\u76ee\u6807\u96c6\u4e4b\u95f4\u7684\u590d\u6742\u51e0\u4f55\u5173\u7cfb\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u66f4\u901a\u7528\u7684\u591a\u96c6\u5408\u51e0\u4f55\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u4f4d\u7f6e\u79d1\u5b66\u3001\u673a\u5668\u4eba\u548c\u8ba1\u7b97\u51e0\u4f55\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u51f8\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528\u51f8\u5206\u6790\u5de5\u5177\u5efa\u7acb\u5b58\u5728\u6027\u3001\u552f\u4e00\u6027\u548c\u4e00\u9636\u6700\u4f18\u6027\u6761\u4ef6\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u6295\u5f71\u6b21\u68af\u5ea6\u7b97\u6cd5(PSA)\uff0c\u91c7\u7528\u9012\u51cf\u6b65\u957f\u89c4\u5219\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u5e7f\u4e49(k,m)-Heron\u95ee\u9898\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u6700\u4f18\u89e3\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u6761\u4ef6\u3002\u63d0\u51fa\u7684PSA\u7b97\u6cd5\u5728\u211d\u00b2\u548c\u211d\u00b3\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u7a33\u5b9a\u6027\u3001\u51e0\u4f55\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u591a\u96c6\u5408\u51e0\u4f55\u4f18\u5316\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5206\u6790\u548c\u7b97\u6cd5\u6846\u67b6\uff0c\u5728\u4f4d\u7f6e\u79d1\u5b66\u3001\u673a\u5668\u4eba\u548c\u8ba1\u7b97\u51e0\u4f55\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u524d\u666f\uff0c\u6269\u5c55\u4e86\u7ecf\u5178\u8ddd\u79bb\u4f18\u5316\u95ee\u9898\u7684\u7406\u8bba\u8fb9\u754c\u3002"}}
{"id": "2601.14139", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.14139", "abs": "https://arxiv.org/abs/2601.14139", "authors": ["Michail Anthropelos", "Constantinos Kardaras", "Constantinos Stefanakis"], "title": "Log-optimality with small liability stream", "comment": null, "summary": "In an incomplete financial market with general continuous semimartingale dynamics; we model an investor with log-utility preferences who, in addition to an initial capital, receives units of a non-traded endowment process. Using duality techniques, we derive the fourth-order expansion of the primal value function with respect to the units $\u03b5$, held in the non-traded endowment. In turn, this lays the foundation for expanding the optimal wealth process, in this context, up to second order w.r.t. $\u03b5$. The key processes underpinning the aforementioned results are given in terms of Kunita-Watanabe projections, mirroring the case of lower order expansions of similar nature. Both the case of finite and infinite horizons are treated in a unified manner.", "AI": {"tldr": "\u4f7f\u7528\u5bf9\u5076\u6280\u672f\u63a8\u5bfc\u5bf9\u6570\u6548\u7528\u6295\u8d44\u8005\u5728\u975e\u4ea4\u6613\u7980\u8d4b\u6301\u6709\u91cf\u03b5\u7684\u56db\u9636\u5c55\u5f00\uff0c\u4e3a\u6700\u4f18\u8d22\u5bcc\u8fc7\u7a0b\u7684\u4e8c\u9636\u5c55\u5f00\u5960\u5b9a\u57fa\u7840", "motivation": "\u7814\u7a76\u4e0d\u5b8c\u5168\u91d1\u878d\u5e02\u573a\u4e2d\uff0c\u62e5\u6709\u5bf9\u6570\u6548\u7528\u504f\u597d\u7684\u6295\u8d44\u8005\u5728\u521d\u59cb\u8d44\u672c\u5916\u8fd8\u6301\u6709\u975e\u4ea4\u6613\u7980\u8d4b\u65f6\u7684\u6700\u4f18\u6295\u8d44\u95ee\u9898", "method": "\u91c7\u7528\u5bf9\u5076\u6280\u672f\uff0c\u57fa\u4e8eKunita-Watanabe\u6295\u5f71\u63a8\u5bfc\u5173\u4e8e\u975e\u4ea4\u6613\u7980\u8d4b\u6301\u6709\u91cf\u03b5\u7684\u56db\u9636\u5c55\u5f00\uff0c\u7edf\u4e00\u5904\u7406\u6709\u9650\u548c\u65e0\u9650\u65f6\u95f4\u8303\u56f4", "result": "\u5f97\u5230\u4e86\u539f\u59cb\u4ef7\u503c\u51fd\u6570\u5173\u4e8e\u03b5\u7684\u56db\u9636\u5c55\u5f00\uff0c\u4e3a\u6700\u4f18\u8d22\u5bcc\u8fc7\u7a0b\u7684\u4e8c\u9636\u5c55\u5f00\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e0d\u5b8c\u5168\u5e02\u573a\u4e2d\u5305\u542b\u975e\u4ea4\u6613\u7980\u8d4b\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u5c55\u5f00\u5206\u6790\u6846\u67b6"}}
{"id": "2601.11573", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11573", "abs": "https://arxiv.org/abs/2601.11573", "authors": ["Muhammad Muneeb", "David B. Ascher"], "title": "An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT", "comment": null, "summary": "Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\\% and 70\\% for PRSGPT and 6\\% and 18\\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u590d\u73b0\u7684LLM\u5fae\u8c03\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\uff0c\u5305\u542bPRSGPT\u548cBioStarsGPT\u4e24\u4e2a\u7528\u4f8b\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u590d\u6742\u751f\u7269\u4fe1\u606f\u5b66\u5e94\u7528\u6240\u9700\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u7684\u5fae\u8c03\u65b9\u6cd5", "method": "\u4e5d\u6b65\u6d41\u6c34\u7ebf\uff1a\u6574\u5408\u591a\u6837\u6570\u636e\u6e90\u3001\u7ed3\u6784\u5316\u9884\u5904\u7406\u3001\u57fa\u4e8e\u63d0\u793a\u7684QA\u751f\u6210\u3001NLI\u8d28\u91cf\u63a7\u5236\u3001\u8bed\u4e49\u53bb\u91cd\u3001\u805a\u7c7b\u6570\u636e\u5206\u5272\u3001LoRA\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u4e09\u4e2aLLM\u4e0a\u9a8c\u8bc1", "result": "Qwen2.5-7B\u8868\u73b0\u6700\u4f73\uff0cPRSGPT\u7684BLEU-4\u548cROUGE-1\u5206\u522b\u63d0\u534782%\u548c70%\uff0cBioStarsGPT\u63d0\u53476%\u548c18%\uff1b\u751f\u6210\u8d85\u8fc728,000\u4e2aPRSGPT QA\u5bf9\u548c154,282\u4e2aBioStarsGPT QA\u5bf9\uff1b\u4eba\u5de5\u8bc4\u4f30PRSGPT\u51c6\u786e\u738761.9%\uff0c\u4e0eGoogle Gemini\u76f8\u5f53\u4f46\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7ec6\u8282", "conclusion": "\u8be5\u6d41\u6c34\u7ebf\u652f\u6301\u53ef\u6269\u5c55\u7684\u9886\u57df\u7279\u5b9aLLM\u5fae\u8c03\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u3001\u672c\u5730\u90e8\u7f72\u7684\u751f\u7269\u4fe1\u606f\u5b66\u52a9\u624b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6311\u6218\u548c\u7f13\u89e3\u7b56\u7565"}}
{"id": "2601.11574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11574", "abs": "https://arxiv.org/abs/2601.11574", "authors": ["Lukas Abrie Nel"], "title": "GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment", "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.", "AI": {"tldr": "GRADE\u4f7f\u7528Gumbel-softmax\u91cd\u53c2\u6570\u5316\u548c\u76f4\u901a\u4f30\u8ba1\u66ff\u4ee3\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u677e\u5f1b\u5b9e\u73b0\u7aef\u5230\u7aef\u68af\u5ea6\u4f20\u64ad\uff0c\u5728\u6587\u672c\u5bf9\u9f50\u4efb\u52a1\u4e2d\u6bd4PPO\u548cREINFORCE\u8868\u73b0\u66f4\u597d\u4e14\u66f4\u7a33\u5b9a\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u65b9\u6cd5\u5982PPO\u5b58\u5728\u68af\u5ea6\u4f30\u8ba1\u65b9\u5dee\u9ad8\u3001\u9700\u8981\u7cbe\u7ec6\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7b80\u5355\u7a33\u5b9a\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "GRADE\u4f7f\u7528Gumbel-softmax\u91cd\u53c2\u6570\u5316\u914d\u5408\u76f4\u901a\u4f30\u8ba1\uff08GRADE-STE\uff09\uff0c\u901a\u8fc7\u79bb\u6563token\u91c7\u6837\u8fc7\u7a0b\u7684\u53ef\u5fae\u5206\u677e\u5f1b\u66ff\u4ee3\u9ad8\u65b9\u5dee\u7684\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\uff0c\u5b9e\u73b0\u4ece\u5956\u52b1\u4fe1\u53f7\u5230\u6a21\u578b\u53c2\u6570\u7684\u7aef\u5230\u7aef\u68af\u5ea6\u4f20\u64ad\u3002", "result": "\u5728IMDB\u60c5\u611f\u63a7\u5236\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\uff0cGRADE-STE\u6d4b\u8bd5\u5956\u52b1\u8fbe\u52300.763\u00b10.344\uff0c\u6bd4PPO\uff080.510\u00b10.313\uff09\u548cREINFORCE\uff080.617\u00b10.378\uff09\u5206\u522b\u63d0\u534750%\uff1b\u68af\u5ea6\u65b9\u5dee\u6bd4REINFORCE\u4f4e14\u500d\u4ee5\u4e0a\uff0c\u8bad\u7ec3\u52a8\u6001\u66f4\u7a33\u5b9a\u3002", "conclusion": "GRADE\u4e3aLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u5f3a\u5316\u5b66\u4e60\u66f4\u7b80\u5355\u3001\u7a33\u5b9a\u548c\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u826f\u597d\u6cdb\u5316\u7279\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u590d\u6742\u5ea6\u3002"}}
{"id": "2601.11625", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11625", "abs": "https://arxiv.org/abs/2601.11625", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance", "comment": "8 pages, Submitted to ACL Rolling Review and is under review", "summary": "Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u65f6\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ddf\u8e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2dtoken\u7ea7\u5f52\u56e0\u7684\u53d8\u5316\u6765\u76d1\u63a7\u6a21\u578b\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u5f15\u5165\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u6982\u5ff5\u6765\u8bc6\u522b\u5f52\u56e0\u53d8\u5316\u8d8b\u4e8e\u7a33\u5b9a\u7684\u8bad\u7ec3\u9636\u6bb5\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u867d\u7136\u80fd\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4f1a\u5fae\u5999\u5730\u6539\u53d8\u6a21\u578b\u4f9d\u8d56\u7684\u8bc1\u636e\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u6a21\u578b\u51b3\u7b56\u4f9d\u636e\u7684\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u6807\u7b7e\u76f8\u5173\u89e6\u53d1\u8bcd\u7b49\u6377\u5f84\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\"\u89e3\u91ca\u6f02\u79fb\"\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u5728\u56fa\u5b9a\u63a2\u6d4b\u96c6\u4e0a\u5f52\u4e00\u5316token\u5f52\u56e0\u7684\u9010\u8f6e\u53d8\u5316\u3002\u5f15\u5165\"\u63a8\u7406\u7a33\u5b9a\u70b9\"\u4f5c\u4e3a\u6f02\u79fb\u9996\u6b21\u8fdb\u5165\u5e76\u6301\u7eed\u4fdd\u6301\u4f4e\u6c34\u5e73\u7684\u6700\u65e9\u8f6e\u6b21\uff0c\u8be5\u6307\u6807\u4ec5\u57fa\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6f02\u79fb\u52a8\u6001\u8ba1\u7b97\uff0c\u65e0\u9700\u5728\u5206\u5e03\u5916\u6570\u636e\u4e0a\u8c03\u6574\u3002", "result": "\u5728\u591a\u4e2a\u8f7b\u91cf\u7ea7Transformer\u5206\u7c7b\u5668\u548c\u57fa\u51c6\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6f02\u79fb\u901a\u5e38\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u8fdb\u5165\u4f4e\u4e14\u7a33\u5b9a\u7684\u72b6\u6001\uff0c\u800c\u9a8c\u8bc1\u51c6\u786e\u7387\u4ec5\u53d1\u751f\u5fae\u5c0f\u53d8\u5316\u3002\u5728\u53d7\u63a7\u7684\u6377\u5f84\u8bbe\u7f6e\u4e2d\uff0c\u5f52\u56e0\u52a8\u6001\u63ed\u793a\u4e86\u6a21\u578b\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\u589e\u52a0\uff0c\u5373\u4f7f\u9a8c\u8bc1\u51c6\u786e\u7387\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "\u89e3\u91ca\u6f02\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u4f4e\u6210\u672c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u76d1\u63a7\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u51b3\u7b56\u8bc1\u636e\u7684\u6f14\u53d8\uff0c\u5e76\u9009\u62e9\u5904\u4e8e\u7a33\u5b9a\u8bc1\u636e\u72b6\u6001\u7684\u68c0\u67e5\u70b9\u3002"}}
{"id": "2601.12990", "categories": ["q-fin.ST", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12990", "abs": "https://arxiv.org/abs/2601.12990", "authors": ["Fan Zhang", "Jiabin Luo", "Zheng Zhang", "Shuanghong Huang", "Zhipeng Liu", "Yu Chen"], "title": "Beyond Visual Realism: Toward Reliable Financial Time Series Generation", "comment": "Accepted by ICASSP 2026", "summary": "Generative models for financial time series often create data that look realistic and even reproduce stylized facts such as fat tails or volatility clustering. However, these apparent successes break down under trading backtests: models like GANs or WGAN-GP frequently collapse, yielding extreme and unrealistic results that make the synthetic data unusable in practice. We identify the root cause in the neglect of financial asymmetry and rare tail events, which strongly affect market risk but are often overlooked by objectives focusing on distribution matching. To address this, we introduce the Stylized Facts Alignment GAN (SFAG), which converts key stylized facts into differentiable structural constraints and jointly optimizes them with adversarial loss. This multi-constraint design ensures that generated series remain aligned with market dynamics not only in plots but also in backtesting. Experiments on the Shanghai Composite Index (2004--2024) show that while baseline GANs produce unstable and implausible trading outcomes, SFAG generates synthetic data that preserve stylized facts and support robust momentum strategy performance. Our results highlight that structure-preserving objectives are essential to bridge the gap between superficial realism and practical usability in financial generative modeling.", "AI": {"tldr": "SFAG\uff08Stylized Facts Alignment GAN\uff09\u901a\u8fc7\u5c06\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u7684\u5173\u952e\u98ce\u683c\u5316\u4e8b\u5b9e\u8f6c\u5316\u4e3a\u53ef\u5fae\u7684\u7ed3\u6784\u7ea6\u675f\uff0c\u5e76\u4e0e\u5bf9\u6297\u635f\u5931\u8054\u5408\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u751f\u6210\u6a21\u578b\u5728\u4ea4\u6613\u56de\u6d4b\u4e2d\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u751f\u6210\u4e86\u65e2\u7b26\u5408\u5e02\u573a\u52a8\u6001\u53c8\u5177\u6709\u5b9e\u9645\u53ef\u7528\u6027\u7684\u5408\u6210\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u6a21\u578b\uff08\u5982GANs\u3001WGAN-GP\uff09\u751f\u6210\u7684\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u867d\u7136\u8868\u9762\u4e0a\u770b\u8d77\u6765\u771f\u5b9e\uff0c\u751a\u81f3\u80fd\u91cd\u73b0\u539a\u5c3e\u3001\u6ce2\u52a8\u7387\u805a\u96c6\u7b49\u98ce\u683c\u5316\u4e8b\u5b9e\uff0c\u4f46\u5728\u4ea4\u6613\u56de\u6d4b\u4e2d\u7ecf\u5e38\u5d29\u6e83\uff0c\u4ea7\u751f\u6781\u7aef\u4e0d\u73b0\u5b9e\u7684\u7ed3\u679c\uff0c\u5bfc\u81f4\u5408\u6210\u6570\u636e\u5728\u5b9e\u9645\u4e2d\u65e0\u6cd5\u4f7f\u7528\u3002\u6839\u672c\u539f\u56e0\u5728\u4e8e\u5ffd\u89c6\u4e86\u91d1\u878d\u4e0d\u5bf9\u79f0\u6027\u548c\u7f55\u89c1\u5c3e\u90e8\u4e8b\u4ef6\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u5e02\u573a\u98ce\u9669\u5f71\u54cd\u5f88\u5927\uff0c\u4f46\u901a\u5e38\u88ab\u4e13\u6ce8\u4e8e\u5206\u5e03\u5339\u914d\u7684\u76ee\u6807\u51fd\u6570\u6240\u5ffd\u7565\u3002", "method": "\u63d0\u51faStylized Facts Alignment GAN\uff08SFAG\uff09\uff0c\u5c06\u5173\u952e\u98ce\u683c\u5316\u4e8b\u5b9e\u8f6c\u5316\u4e3a\u53ef\u5fae\u7684\u7ed3\u6784\u7ea6\u675f\uff0c\u5e76\u4e0e\u5bf9\u6297\u635f\u5931\u8054\u5408\u4f18\u5316\u3002\u8fd9\u79cd\u591a\u7ea6\u675f\u8bbe\u8ba1\u786e\u4fdd\u751f\u6210\u7684\u5e8f\u5217\u4e0d\u4ec5\u5728\u56fe\u8868\u4e0a\u7b26\u5408\u5e02\u573a\u52a8\u6001\uff0c\u5728\u56de\u6d4b\u4e2d\u4e5f\u80fd\u4fdd\u6301\u4e00\u81f4\u3002", "result": "\u5728\u4e0a\u8bc1\u7efc\u5408\u6307\u6570\uff082004-2024\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u7ebfGANs\u4ea7\u751f\u4e0d\u7a33\u5b9a\u4e14\u4e0d\u5408\u7406\u7684\u4ea4\u6613\u7ed3\u679c\uff0c\u800cSFAG\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u80fd\u591f\u4fdd\u6301\u98ce\u683c\u5316\u4e8b\u5b9e\uff0c\u5e76\u652f\u6301\u7a33\u5065\u7684\u52a8\u91cf\u7b56\u7565\u8868\u73b0\u3002", "conclusion": "\u7ed3\u6784\u4fdd\u6301\u76ee\u6807\u5bf9\u4e8e\u5f25\u5408\u91d1\u878d\u751f\u6210\u5efa\u6a21\u4e2d\u8868\u9762\u771f\u5b9e\u6027\u4e0e\u5b9e\u9645\u53ef\u7528\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u81f3\u5173\u91cd\u8981\u3002SFAG\u901a\u8fc7\u5c06\u98ce\u683c\u5316\u4e8b\u5b9e\u4f5c\u4e3a\u7ea6\u675f\uff0c\u751f\u6210\u4e86\u65e2\u7b26\u5408\u5e02\u573a\u52a8\u6001\u53c8\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u7684\u5408\u6210\u6570\u636e\u3002"}}
{"id": "2601.11967", "categories": ["eess.SY", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11967", "abs": "https://arxiv.org/abs/2601.11967", "authors": ["Margarida Caleiras", "Samuel Moniz", "Paulo Jorge Nascimento"], "title": "A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem", "comment": "12 pages, 4 figures, To be published in the Proceedings of the International Conference on Operations Research and Enterprise Systems (ICORES 2026)", "summary": "As the dependence on satellite imaging continues to grow, modern satellites have become increasingly agile, with the new generation, namely super-agile Earth observation satellites (SAEOS), providing unprecedented imaging flexibility. The highly dynamic capabilities of these satellites introduce additional challenges to the scheduling of observation tasks, as existing approaches for conventional agile satellites do not account for variable observation durations and multiple imaging directions. Although some efforts have been made in this regard, the SAEOS imaging scheduling problem (SAEOS-ISP) remains largely unexplored, and no exact approaches have yet been proposed. In this context, this study presents the first exact Constraint Programming formulation for the SAEOS-ISP, considering flexible observation windows, multiple pointing directions and sequence-dependent transition times across multiple satellites. Computational experiments on a newly generated benchmark set demonstrate that the model can be solved efficiently and within very short computational times. Moreover, the results also show that the proposed approach has the potential to achieve higher computational performance compared to the non-exact approaches that are currently considered state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u9488\u5bf9\u8d85\u654f\u6377\u5730\u7403\u89c2\u6d4b\u536b\u661f\u6210\u50cf\u8c03\u5ea6\u95ee\u9898\u7684\u7cbe\u786e\u7ea6\u675f\u89c4\u5212\u6a21\u578b\uff0c\u8003\u8651\u4e86\u7075\u6d3b\u89c2\u6d4b\u7a97\u53e3\u3001\u591a\u6307\u5411\u65b9\u5411\u548c\u5e8f\u5217\u76f8\u5173\u8f6c\u6362\u65f6\u95f4\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u975e\u7cbe\u786e\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u536b\u661f\u6210\u50cf\u4f9d\u8d56\u5ea6\u589e\u52a0\uff0c\u65b0\u4e00\u4ee3\u8d85\u654f\u6377\u5730\u7403\u89c2\u6d4b\u536b\u661f\uff08SAEOS\uff09\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u6210\u50cf\u7075\u6d3b\u6027\uff0c\u4f46\u5176\u9ad8\u5ea6\u52a8\u6001\u80fd\u529b\u7ed9\u89c2\u6d4b\u4efb\u52a1\u8c03\u5ea6\u5e26\u6765\u4e86\u65b0\u6311\u6218\u3002\u73b0\u6709\u4f20\u7edf\u654f\u6377\u536b\u661f\u8c03\u5ea6\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u53ef\u53d8\u89c2\u6d4b\u65f6\u957f\u548c\u591a\u6210\u50cf\u65b9\u5411\u7684\u95ee\u9898\uff0c\u4e14SAEOS\u6210\u50cf\u8c03\u5ea6\u95ee\u9898\u5c1a\u672a\u6709\u7cbe\u786e\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9SAEOS\u6210\u50cf\u8c03\u5ea6\u95ee\u9898\u7684\u7cbe\u786e\u7ea6\u675f\u89c4\u5212\u6a21\u578b\uff0c\u8003\u8651\u4e86\u7075\u6d3b\u89c2\u6d4b\u7a97\u53e3\u3001\u591a\u6307\u5411\u65b9\u5411\u548c\u5e8f\u5217\u76f8\u5173\u8f6c\u6362\u65f6\u95f4\uff0c\u652f\u6301\u591a\u536b\u661f\u534f\u540c\u8c03\u5ea6\u3002\u5728\u65b0\u751f\u6210\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u8ba1\u7b97\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5728\u975e\u5e38\u77ed\u7684\u8ba1\u7b97\u65f6\u95f4\u5185\u9ad8\u6548\u6c42\u89e3\u3002\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u975e\u7cbe\u786e\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u7b97\u6027\u80fd\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86SAEOS\u6210\u50cf\u8c03\u5ea6\u95ee\u9898\u7cbe\u786e\u6c42\u89e3\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u7ea6\u675f\u89c4\u5212\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u8d85\u654f\u6377\u536b\u661f\u7684\u590d\u6742\u8c03\u5ea6\u9700\u6c42\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13006", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.13006", "abs": "https://arxiv.org/abs/2601.13006", "authors": ["Kim Christensen", "Roel Oomen", "Mark Podolskij"], "title": "Realised quantile-based estimation of the integrated variance", "comment": null, "summary": "In this paper, we propose a new jump robust quantile-based realised variance measure of ex-post return variation that can be computed using potentially noisy data. The estimator is consistent for the integrated variance and we present feasible central limit theorems which show that it converges at the best attainable rate and has excellent efficiency. Asymptotically, the quantile-based realised variance is immune to finite activity jumps and outliers in the price series, while in modified form the estimator is applicable with market microstructure noise and therefore operational on high-frequency data. Simulations show that it has superior robustness properties in finite sample, while an empirical application illustrates its use on equity data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u8df3\u8dc3\u7a33\u5065\u5b9e\u73b0\u65b9\u5dee\u5ea6\u91cf\uff0c\u9002\u7528\u4e8e\u542b\u566a\u58f0\u6570\u636e\uff0c\u5bf9\u79ef\u5206\u65b9\u5dee\u4e00\u81f4\u4f30\u8ba1\uff0c\u5177\u6709\u6700\u4f18\u6536\u655b\u901f\u7387\u548c\u6548\u7387", "motivation": "\u4f20\u7edf\u5b9e\u73b0\u65b9\u5dee\u4f30\u8ba1\u5bf9\u4ef7\u683c\u5e8f\u5217\u4e2d\u7684\u8df3\u8dc3\u548c\u5f02\u5e38\u503c\u654f\u611f\uff0c\u4e14\u5728\u9ad8\u9891\u6570\u636e\u4e2d\u53d7\u5e02\u573a\u5fae\u89c2\u7ed3\u6784\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u7a33\u5065\u7684\u65b9\u5dee\u5ea6\u91cf\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u5b9e\u73b0\u65b9\u5dee\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u7edf\u8ba1\u91cf\u6784\u5efa\u65b9\u5dee\u5ea6\u91cf\uff0c\u53ef\u5904\u7406\u6709\u9650\u6d3b\u52a8\u8df3\u8dc3\u548c\u5f02\u5e38\u503c\uff0c\u6539\u8fdb\u7248\u672c\u9002\u7528\u4e8e\u542b\u566a\u58f0\u7684\u9ad8\u9891\u6570\u636e", "result": "\u4f30\u8ba1\u91cf\u5bf9\u79ef\u5206\u65b9\u5dee\u5177\u6709\u4e00\u81f4\u6027\uff0c\u8fbe\u5230\u6700\u4f18\u6536\u655b\u901f\u7387\uff0c\u6709\u9650\u6837\u672c\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u7a33\u5065\u6027\uff0c\u5b9e\u8bc1\u5e94\u7528\u5c55\u793a\u5728\u80a1\u7968\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u5206\u4f4d\u6570\u5b9e\u73b0\u65b9\u5dee\u4f30\u8ba1\u91cf\u662f\u7a33\u5065\u3001\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65b9\u5dee\u5ea6\u91cf\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u542b\u8df3\u8dc3\u3001\u5f02\u5e38\u503c\u548c\u566a\u58f0\u7684\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5206\u6790"}}
{"id": "2601.11571", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11571", "abs": "https://arxiv.org/abs/2601.11571", "authors": ["Leon A. Abdillah", "Aisyah", "Wahdyta Putri Panggabean", "Sayfiyev Eldor Erkinovich"], "title": "Knowledge of Songket Cloth Small Medium Enterprise Digital Transformation", "comment": "8 pages", "summary": "This article examines the knowledge of digital transformation of Small and Medium Enterprises (SMEs) that specialize in traditional handicrafts, with a specific emphasis on the Songket textile sector. The study investigates the use of digital technologies, notably blog platforms and the e-commerce site Shopee, to improve and streamline several business processes in Songket textile SMEs. The report takes a case study approach, diving into the experiences of Songket clothing enterprises that have undergone digital transformation. Key areas studied include the use of Blog platforms for brand development, marketing, and consumer involvement, as well as the Shopee E-Commerce platform for online sales and order processing. The essay seeks to give insights into the problems and possibilities faced by Songket cloth SMEs along their digital transformation journey by conducting in-depth observation, interviews, and surveys. The findings add to the scholarly discussion on the digitization of traditional industries, with practical implications for SMEs in the Songket textile sector and other handicraft areas. This study emphasizes the necessity of using digital technologies to preserve and expand traditional crafts, while also throwing light on the potential role of prominent E-Commerce platforms like Shopee in facilitating worldwide market access for such firms.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4e13\u6ce8\u4e8e\u4f20\u7edf\u624b\u5de5\u827a\u7684\u4e2d\u5c0f\u4f01\u4e1a\uff08\u7279\u522b\u662f\u5b8b\u5361\u7eba\u7ec7\u4e1a\uff09\u7684\u6570\u5b57\u5316\u8f6c\u578b\u77e5\u8bc6\uff0c\u91cd\u70b9\u5206\u6790\u535a\u5ba2\u5e73\u53f0\u548cShopee\u7535\u5546\u5e73\u53f0\u5982\u4f55\u4f18\u5316\u4e1a\u52a1\u6d41\u7a0b\u3002", "motivation": "\u4f20\u7edf\u624b\u5de5\u827a\u4e2d\u5c0f\u4f01\u4e1a\u9762\u4e34\u6570\u5b57\u5316\u8f6c\u578b\u6311\u6218\uff0c\u9700\u8981\u4e86\u89e3\u5982\u4f55\u5229\u7528\u6570\u5b57\u6280\u672f\u4fdd\u62a4\u548c\u6269\u5c55\u4f20\u7edf\u5de5\u827a\uff0c\u540c\u65f6\u901a\u8fc7\u7535\u5546\u5e73\u53f0\u83b7\u5f97\u5168\u7403\u5e02\u573a\u51c6\u5165\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df1\u5165\u89c2\u5bdf\u3001\u8bbf\u8c08\u548c\u8c03\u67e5\uff0c\u5206\u6790\u5b8b\u5361\u7eba\u7ec7\u4f01\u4e1a\u4f7f\u7528\u535a\u5ba2\u5e73\u53f0\u8fdb\u884c\u54c1\u724c\u5efa\u8bbe\u548c\u8425\u9500\uff0c\u4ee5\u53caShopee\u5e73\u53f0\u8fdb\u884c\u5728\u7ebf\u9500\u552e\u548c\u8ba2\u5355\u5904\u7406\u7684\u5b9e\u8df5\u7ecf\u9a8c\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5b8b\u5361\u7eba\u7ec7\u4e2d\u5c0f\u4f01\u4e1a\u5728\u6570\u5b57\u5316\u8f6c\u578b\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u548c\u673a\u9047\uff0c\u4e3a\u4f20\u7edf\u4ea7\u4e1a\u6570\u5b57\u5316\u63d0\u4f9b\u4e86\u5b9e\u8df5\u89c1\u89e3\uff0c\u5e76\u5c55\u793a\u4e86Shopee\u7b49\u7535\u5546\u5e73\u53f0\u5728\u4fc3\u8fdb\u5168\u7403\u5e02\u573a\u63a5\u5165\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u6570\u5b57\u6280\u672f\u5bf9\u4fdd\u62a4\u548c\u6269\u5c55\u4f20\u7edf\u624b\u5de5\u827a\u81f3\u5173\u91cd\u8981\uff0c\u7535\u5546\u5e73\u53f0\u5982Shopee\u80fd\u6709\u6548\u5e2e\u52a9\u4f20\u7edf\u4e2d\u5c0f\u4f01\u4e1a\u8fdb\u5165\u5168\u7403\u5e02\u573a\uff0c\u7814\u7a76\u4e3a\u4f20\u7edf\u4ea7\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2601.13102", "categories": ["stat.ML", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13102", "abs": "https://arxiv.org/abs/2601.13102", "authors": ["Davidson Lova Razafindrakoto", "Alain Celisse", "J\u00e9r\u00f4me Lacaille"], "title": "Approximate full conformal prediction in RKHS", "comment": null, "summary": "Full conformal prediction is a framework that implicitly formulates distribution-free confidence prediction regions for a wide range of estimators. However, a classical limitation of the full conformal framework is the computation of the confidence prediction regions, which is usually impossible since it requires training infinitely many estimators (for real-valued prediction for instance). The main purpose of the present work is to describe a generic strategy for designing a tight approximation to the full conformal prediction region that can be efficiently computed. Along with this approximate confidence region, a theoretical quantification of the tightness of this approximation is developed, depending on the smoothness assumptions on the loss and score functions. The new notion of thickness is introduced for quantifying the discrepancy between the approximate confidence region and the full conformal one.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u8ba1\u7b97\u5168\u4fdd\u5f62\u9884\u6d4b\u7f6e\u4fe1\u533a\u57df\u7684\u7d27\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u539a\u5ea6\u6982\u5ff5\u91cf\u5316\u8fd1\u4f3c\u8bef\u5dee", "motivation": "\u5168\u4fdd\u5f62\u9884\u6d4b\u6846\u67b6\u867d\u7136\u80fd\u6784\u5efa\u5206\u5e03\u65e0\u5173\u7684\u7f6e\u4fe1\u9884\u6d4b\u533a\u57df\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u8bad\u7ec3\u65e0\u9650\u591a\u4e2a\u4f30\u8ba1\u5668\uff0c\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c", "method": "\u8bbe\u8ba1\u901a\u7528\u7b56\u7565\u6784\u5efa\u5168\u4fdd\u5f62\u9884\u6d4b\u533a\u57df\u7684\u7d27\u8fd1\u4f3c\uff0c\u5f15\u5165\u539a\u5ea6\u6982\u5ff5\u91cf\u5316\u8fd1\u4f3c\u4e0e\u5168\u4fdd\u5f62\u533a\u57df\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u7406\u8bba\u5206\u6790\u4f9d\u8d56\u4e8e\u635f\u5931\u51fd\u6570\u548c\u8bc4\u5206\u51fd\u6570\u7684\u5e73\u6ed1\u6027\u5047\u8bbe", "result": "\u5f00\u53d1\u51fa\u53ef\u9ad8\u6548\u8ba1\u7b97\u7684\u8fd1\u4f3c\u7f6e\u4fe1\u533a\u57df\uff0c\u5e76\u5efa\u7acb\u4e86\u91cf\u5316\u8fd1\u4f3c\u7d27\u5ea6\u7684\u7406\u8bba\u6846\u67b6", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u5168\u4fdd\u5f62\u9884\u6d4b\u8ba1\u7b97\u4e0d\u53ef\u884c\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8fd1\u4f3c\u7b56\u7565\u548c\u539a\u5ea6\u91cf\u5316\u5b9e\u73b0\u4e86\u5b9e\u7528\u5316\u7684\u5206\u5e03\u65e0\u5173\u7f6e\u4fe1\u9884\u6d4b"}}
{"id": "2601.11751", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11751", "abs": "https://arxiv.org/abs/2601.11751", "authors": ["Sadjad Bazarnovi", "Taner Cokyasar", "Omer Verbas", "Abolfazl Kouros Mohammadian"], "title": "Integrated Optimization of Scheduling and Flexible Charging in Mixed Electric-Diesel Urban Transit Bus Systems", "comment": null, "summary": "The transition of transit fleets to alternative powertrains offers a potential pathway to reducing the cost of mobility. However, the limited range and long charging durations of battery electric buses (BEBs) introduce significant operational complexities, necessitating innovative scheduling and charging strategies. This study proposes an integrated mixed-integer linear programming model to optimize vehicle scheduling and charging strategies for mixed fleets of BEBs and diesel buses. Unlike existing models, which often assume a fixed BEB fleet size or restrict charging to a single charger type, our approach simultaneously determines the optimal fleet composition, scheduling, and flexible partial charging strategy incorporating both slow and fast chargers at garages and terminal stations. The model minimizes combined fleet purchase and operational costs. A queuing strategy is introduced, departing from traditional first-come, first-served methods by dynamically allocating waiting and charging times based on operational priorities and resource availability, improving overall scheduling efficiency. To overcome computational complexities arising from numerous variables, a column generation framework is developed, facilitating scalable solutions for large-scale transit networks. Numerical experiments using real-world transit data from the Chicago Transit Authority and the Pace suburban bus systems demonstrate the model's effectiveness. Results indicate that while a full transition to alternative powertrains results in a modest cost increase, optimal mixed-fleet configurations can actually reduce total system costs. Furthermore, sensitivity analyses reveal that restricting charging to garages significantly increases fleet size and operational costs, underscoring the potential of distributed opportunistic charging.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6a21\u578b\u4f18\u5316\u7535\u52a8\u4e0e\u67f4\u6cb9\u6df7\u5408\u516c\u4ea4\u8f66\u961f\u7684\u8c03\u5ea6\u4e0e\u5145\u7535\u7b56\u7565\uff0c\u91c7\u7528\u5217\u751f\u6210\u7b97\u6cd5\u89e3\u51b3\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u6df7\u5408\u8f66\u961f\u914d\u7f6e\u53ef\u964d\u4f4e\u7cfb\u7edf\u603b\u6210\u672c", "motivation": "\u516c\u4ea4\u8f66\u961f\u5411\u66ff\u4ee3\u52a8\u529b\u7cfb\u7edf\u8f6c\u578b\u53ef\u964d\u4f4e\u51fa\u884c\u6210\u672c\uff0c\u4f46\u7535\u52a8\u516c\u4ea4\u8f66\u7684\u6709\u9650\u7eed\u822a\u548c\u957f\u5145\u7535\u65f6\u95f4\u5e26\u6765\u8fd0\u8425\u590d\u6742\u6027\uff0c\u9700\u8981\u521b\u65b0\u7684\u8c03\u5ea6\u548c\u5145\u7535\u7b56\u7565", "method": "\u63d0\u51fa\u96c6\u6210\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u6a21\u578b\uff0c\u540c\u65f6\u4f18\u5316\u8f66\u961f\u7ec4\u6210\u3001\u8c03\u5ea6\u548c\u7075\u6d3b\u7684\u90e8\u5206\u5145\u7535\u7b56\u7565\uff08\u5305\u542b\u6162\u5145\u548c\u5feb\u5145\uff09\uff0c\u5f15\u5165\u57fa\u4e8e\u8fd0\u8425\u4f18\u5148\u7ea7\u548c\u8d44\u6e90\u53ef\u7528\u6027\u7684\u52a8\u6001\u6392\u961f\u7b56\u7565\uff0c\u5f00\u53d1\u5217\u751f\u6210\u6846\u67b6\u5904\u7406\u5927\u89c4\u6a21\u53d8\u91cf", "result": "\u4f7f\u7528\u829d\u52a0\u54e5\u516c\u4ea4\u7cfb\u7edf\u548c\u90ca\u533a\u516c\u4ea4\u7cfb\u7edf\u7684\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u6a21\u578b\u6709\u6548\u6027\uff0c\u7ed3\u679c\u663e\u793a\u5168\u7535\u52a8\u8f6c\u578b\u4f1a\u5bfc\u81f4\u6210\u672c\u5c0f\u5e45\u589e\u52a0\uff0c\u4f46\u6700\u4f18\u6df7\u5408\u8f66\u961f\u914d\u7f6e\u53ef\u964d\u4f4e\u7cfb\u7edf\u603b\u6210\u672c\uff0c\u9650\u5236\u5728\u8f66\u5e93\u5145\u7535\u4f1a\u663e\u8457\u589e\u52a0\u8f66\u961f\u89c4\u6a21\u548c\u8fd0\u8425\u6210\u672c", "conclusion": "\u6df7\u5408\u8f66\u961f\u914d\u7f6e\u7ed3\u5408\u5206\u5e03\u5f0f\u673a\u4f1a\u5145\u7535\u7b56\u7565\u53ef\u6709\u6548\u964d\u4f4e\u516c\u4ea4\u7cfb\u7edf\u603b\u6210\u672c\uff0c\u5217\u751f\u6210\u6846\u67b6\u80fd\u89e3\u51b3\u5927\u89c4\u6a21\u7f51\u7edc\u7684\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u516c\u4ea4\u7535\u52a8\u5316\u8f6c\u578b\u63d0\u4f9b\u5b9e\u7528\u51b3\u7b56\u652f\u6301"}}
{"id": "2601.11575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11575", "abs": "https://arxiv.org/abs/2601.11575", "authors": ["Sotirios Panagiotis Chytas", "Vikas Singh"], "title": "Concept Attractors in LLMs and their Applications", "comment": null, "summary": "Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.", "AI": {"tldr": "LLMs\u5185\u90e8\u8868\u793a\u53ef\u901a\u8fc7\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u89e3\u91ca\uff0c\u5229\u7528\u6982\u5ff5\u5438\u5f15\u5b50\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u89e3\u51b3\u591a\u79cd\u4efb\u52a1", "motivation": "LLMs\u5728\u5904\u7406\u8bed\u4e49\u76f8\u5173\u4f46\u8868\u9762\u5f62\u5f0f\u4e0d\u540c\u7684\u63d0\u793a\u65f6\uff0c\u4f1a\u5728\u7279\u5b9a\u5c42\u4ea7\u751f\u76f8\u4f3c\u7684\u5185\u90e8\u8868\u793a\uff0c\u8fd9\u79cd\u73b0\u8c61\u9700\u8981\u7406\u8bba\u89e3\u91ca\u5e76\u53ef\u7528\u4e8e\u5b9e\u9645\u5e94\u7528", "method": "\u5c06LLM\u5c42\u89c6\u4e3a\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u4e2d\u7684\u538b\u7f29\u6620\u5c04\uff0c\u5411\u6982\u5ff5\u7279\u5b9a\u7684\u5438\u5f15\u5b50\u6536\u655b\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5438\u5f15\u5b50\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u76f4\u63a5\u64cd\u4f5c\u65b9\u6cd5", "result": "\u5438\u5f15\u5b50\u5e72\u9884\u65b9\u6cd5\u5728\u8bed\u8a00\u7ffb\u8bd1\u3001\u5e7b\u89c9\u51cf\u5c11\u3001\u5b89\u5168\u62a4\u680f\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7b49\u4efb\u52a1\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u4e13\u95e8\u57fa\u7ebf\uff0c\u5728\u57fa\u7ebf\u8868\u73b0\u4e0d\u4f73\u7684\u573a\u666f\u4e2d\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027", "conclusion": "LLMs\u7684\u5185\u90e8\u8868\u793a\u884c\u4e3a\u53ef\u7528\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\u7406\u8bba\u89e3\u91ca\uff0c\u57fa\u4e8e\u5438\u5f15\u5b50\u7684\u7b80\u5355\u65e0\u8bad\u7ec3\u65b9\u6cd5\u4e3a\u5b9e\u9645\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u907f\u514d\u7e41\u91cd\u7684\u5fae\u8c03"}}
{"id": "2601.11604", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11604", "abs": "https://arxiv.org/abs/2601.11604", "authors": ["Jonaid Shianifar", "Michael Schukat", "Karl Mason"], "title": "Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning", "comment": null, "summary": "Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\\!\\pm\\!125$ to $1613\\!\\pm\\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.", "AI": {"tldr": "Hindsight Preference Replay (HPR) \u901a\u8fc7\u4e8b\u540e\u91cd\u65b0\u6807\u8bb0\u5b58\u50a8\u7684\u8f6c\u79fb\u6570\u636e\u6765\u589e\u5f3a\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u6307\u6807", "motivation": "CAPQL\u65b9\u6cd5\u5728\u7279\u5b9a\u504f\u597d\u4e0b\u6536\u96c6\u7684\u6570\u636e\u65e0\u6cd5\u88ab\u5176\u4ed6\u504f\u597d\u91cd\u7528\uff0c\u5bfc\u81f4\u6570\u636e\u5229\u7528\u7387\u4f4e\u4e0b\uff0c\u9650\u5236\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387", "method": "\u63d0\u51faHindsight Preference Replay (HPR)\u7b56\u7565\uff0c\u5728\u4e0d\u6539\u53d8CAPQL\u67b6\u6784\u6216\u635f\u5931\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u5b58\u50a8\u7684\u8f6c\u79fb\u6570\u636e\u8fdb\u884c\u4e8b\u540e\u91cd\u65b0\u6807\u8bb0\uff0c\u4f7f\u7528\u66ff\u4ee3\u504f\u597d\u6765\u589e\u5f3a\u76d1\u7763\u4fe1\u53f7", "result": "\u57286\u4e2aMO-Gymnasium\u8fd0\u52a8\u4efb\u52a1\u4e2d\uff0cHPR-CAPQL\u57285\u4e2a\u73af\u5883\u4e2d\u63d0\u5347\u4e86\u8d85\u4f53\u79ef(HV)\uff0c\u57284\u4e2a\u73af\u5883\u4e2d\u63d0\u5347\u4e86\u671f\u671b\u6548\u7528(EUM)\u3002\u7279\u522b\u662f\u5728mo-humanoid-v5\u4e2d\uff0cEUM\u4ece323\u00b1125\u63d0\u5347\u52301613\u00b1464\uff0cHV\u4ece0.52M\u63d0\u5347\u52309.63M", "conclusion": "HPR\u662f\u4e00\u79cd\u7b80\u5355\u800c\u901a\u7528\u7684\u56de\u653e\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5229\u7528\u6548\u7387\uff0c\u663e\u8457\u6539\u5584\u7b97\u6cd5\u6027\u80fd\uff0c\u4e3a\u504f\u597d\u6761\u4ef6\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6848"}}
{"id": "2601.11747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11747", "abs": "https://arxiv.org/abs/2601.11747", "authors": ["Huaxiaoyue Wang", "Sunav Choudhary", "Franck Dernoncourt", "Yu Shen", "Stefano Petrangeli"], "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement", "comment": null, "summary": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.", "AI": {"tldr": "PRISM\u5229\u7528\u8bbe\u8ba1\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u805a\u7c7b\u3001\u603b\u7ed3\u548c\u68c0\u7d22\u4e09\u4e2a\u6b65\u9aa4\u5b9e\u73b0\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u56fe\u5f62\u8bbe\u8ba1\u98ce\u683c\u6539\u8fdb\uff0c\u5728\u98ce\u683c\u5bf9\u9f50\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u975e\u4e13\u4e1a\u4eba\u58eb\u5728\u63a2\u7d22\u4e0d\u540c\u8bbe\u8ba1\u98ce\u683c\u65b9\u5411\u65f6\u8017\u65f6\u8017\u529b\uff0c\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u7684\u98ce\u683c\u77e5\u8bc6\u8fc7\u4e8e\u901a\u7528\uff0c\u4e0e\u5177\u4f53\u8bbe\u8ba1\u9886\u57df\u6570\u636e\u4e0d\u5339\u914d\uff0c\u65e0\u6cd5\u51c6\u786e\u7406\u89e3\u8bbe\u8ba1\u5e08\u7684\u98ce\u683c\u539f\u5219\u3002", "method": "PRISM\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u6784\u5efa\u548c\u5e94\u7528\u8bbe\u8ba1\u77e5\u8bc6\u5e93\uff1a1) \u5bf9\u9ad8\u65b9\u5dee\u8bbe\u8ba1\u8fdb\u884c\u805a\u7c7b\u4ee5\u6355\u6349\u98ce\u683c\u591a\u6837\u6027\uff1b2) \u5c06\u6bcf\u4e2a\u805a\u7c7b\u603b\u7ed3\u4e3a\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u77e5\u8bc6\uff1b3) \u5728\u63a8\u7406\u65f6\u68c0\u7d22\u76f8\u5173\u77e5\u8bc6\u4ee5\u5b9e\u73b0\u98ce\u683c\u611f\u77e5\u7684\u6539\u8fdb\u3002", "result": "\u5728Crello\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cPRISM\u5728\u98ce\u683c\u5bf9\u9f50\u65b9\u9762\u83b7\u5f971.49\u7684\u5e73\u5747\u6392\u540d\uff08\u8d8a\u63a5\u8fd11\u8d8a\u597d\uff09\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u7528\u6237\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u5e08\u5bf9PRISM\u7684\u4e00\u81f4\u504f\u597d\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u771f\u5b9e\u8bbe\u8ba1\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u5e93\uff0cPRISM\u80fd\u591f\u6709\u6548\u6355\u6349\u8bbe\u8ba1\u5e08\u7684\u98ce\u683c\u539f\u5219\uff0c\u5b9e\u73b0\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u56fe\u5f62\u8bbe\u8ba1\u98ce\u683c\u6539\u8fdb\uff0c\u4e3a\u8bbe\u8ba1\u8f85\u52a9\u5de5\u5177\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.14062", "categories": ["q-fin.ST", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14062", "abs": "https://arxiv.org/abs/2601.14062", "authors": ["Payel Sadhukhan", "Samrat Gupta", "Subhasis Ghosh", "Tanujit Chakraborty"], "title": "Demystifying the trend of the healthcare index: Is historical price a key driver?", "comment": null, "summary": "Healthcare sector indices consolidate the economic health of pharmaceutical, biotechnology, and healthcare service firms. The short-term movements in these indices are closely intertwined with capital allocation decisions affecting research and development investment, drug availability, and long-term health outcomes. This research investigates whether historical open-high-low-close (OHLC) index data contain sufficient information for predicting the directional movement of the opening index on the subsequent trading day. The problem is formulated as a supervised classification task involving a one-step-ahead rolling window. A diverse feature set is constructed, comprising original prices, volatility-based technical indicators, and a novel class of nowcasting features derived from mutual OHLC ratios. The framework is evaluated on data from healthcare indices in the U.S. and Indian markets over a five-year period spanning multiple economic phases, including the COVID-19 pandemic. The results demonstrate robust predictive performance, with accuracy exceeding 0.8 and Matthews correlation coefficients above 0.6. Notably, the proposed nowcasting features have emerged as a key determinant of the market movement. We have employed the Shapley-based explainability paradigm to further elucidate the contribution of the features: outcomes reveal the dominant role of the nowcasting features, followed by a more moderate contribution of original prices. This research offers a societal utility: the proposed features and model for short-term forecasting of healthcare indices can reduce information asymmetry and support a more stable and equitable health economy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528OHLC\u6570\u636e\u548c\u65b0\u578b\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u6765\u9884\u6d4b\u533b\u7597\u4fdd\u5065\u6307\u6570\u7684\u6b21\u65e5\u5f00\u76d8\u65b9\u5411\uff0c\u5728\u7f8e\u5370\u5e02\u573a\u53d6\u5f97\u8d85\u8fc780%\u51c6\u786e\u7387\uff0c\u53d1\u73b0\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u662f\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002", "motivation": "\u533b\u7597\u4fdd\u5065\u6307\u6570\u53cd\u6620\u5236\u836f\u3001\u751f\u7269\u6280\u672f\u548c\u533b\u7597\u670d\u52a1\u516c\u53f8\u7684\u7ecf\u6d4e\u5065\u5eb7\u72b6\u51b5\uff0c\u5176\u77ed\u671f\u6ce2\u52a8\u4e0e\u7814\u53d1\u6295\u8d44\u3001\u836f\u7269\u53ef\u53ca\u6027\u548c\u957f\u671f\u5065\u5eb7\u7ed3\u679c\u5bc6\u5207\u76f8\u5173\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5386\u53f2OHLC\u6570\u636e\u662f\u5426\u5305\u542b\u8db3\u591f\u4fe1\u606f\u6765\u9884\u6d4b\u6b21\u65e5\u5f00\u76d8\u65b9\u5411\uff0c\u4ee5\u51cf\u5c11\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0c\u652f\u6301\u66f4\u7a33\u5b9a\u516c\u5e73\u7684\u5065\u5eb7\u7ecf\u6d4e\u3002", "method": "\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u76d1\u7763\u5206\u7c7b\u4efb\u52a1\uff0c\u91c7\u7528\u4e00\u6b65\u524d\u6eda\u52a8\u7a97\u53e3\u65b9\u6cd5\u3002\u6784\u5efa\u591a\u6837\u5316\u7279\u5f81\u96c6\uff1a\u539f\u59cb\u4ef7\u683c\u3001\u57fa\u4e8e\u6ce2\u52a8\u7387\u7684\u6280\u672f\u6307\u6807\uff0c\u4ee5\u53ca\u4ece\u76f8\u4e92OHLC\u6bd4\u7387\u63a8\u5bfc\u7684\u65b0\u578b\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u3002\u5728\u7f8e\u5370\u5e02\u573a\u4e94\u5e74\u6570\u636e\uff08\u542bCOVID-19\u65f6\u671f\uff09\u4e0a\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u9884\u6d4b\u6027\u80fd\u7a33\u5065\uff0c\u51c6\u786e\u7387\u8d85\u8fc70.8\uff0c\u9a6c\u4fee\u65af\u76f8\u5173\u7cfb\u6570\u9ad8\u4e8e0.6\u3002\u65b0\u578b\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u6210\u4e3a\u5e02\u573a\u6ce2\u52a8\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002\u57fa\u4e8eShapley\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u663e\u793a\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u8d21\u732e\u6700\u5927\uff0c\u539f\u59cb\u4ef7\u683c\u8d21\u732e\u4e2d\u7b49\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u7279\u5f81\u548c\u6a21\u578b\u53ef\u7528\u4e8e\u533b\u7597\u4fdd\u5065\u6307\u6570\u77ed\u671f\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u4fe1\u606f\u4e0d\u5bf9\u79f0\uff0c\u652f\u6301\u66f4\u7a33\u5b9a\u516c\u5e73\u7684\u5065\u5eb7\u7ecf\u6d4e\u3002\u5373\u65f6\u9884\u6d4b\u7279\u5f81\u5728\u9884\u6d4b\u4e2d\u53d1\u6325\u4e3b\u5bfc\u4f5c\u7528\uff0c\u4e3a\u533b\u7597\u4fdd\u5065\u5e02\u573a\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.11982", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11982", "abs": "https://arxiv.org/abs/2601.11982", "authors": ["Aditya Natu", "Hassan HosseinNia"], "title": "Decentralized Motion and Resonant Damping Control for High-Bandwidth and Cross-Coupling Reduction in MIMO Nanopositioners", "comment": null, "summary": "Piezoelectric nanopositioning systems are widely used in precision applications that require nanometer accuracy and high-speed motion; however, lightly damped resonances and pronounced cross-axis coupling severely limit bandwidth and disturbance rejection. This paper presents a decentralized dual-loop control strategy for a two-axis nanopositioner, combining an inner non-minimum-phase resonant damping controller with an outer motion controller on each axis. The dominant diagonal resonance is actively damped to enable closed-loop bandwidths beyond the first structural mode, while a parallel band-pass damping path is specifically tuned to a higher-order resonance that predominantly affects the cross-coupling channels. Experimental results demonstrate that this targeted band-pass damping substantially reduces cross-axis coupling and enhances disturbance rejection, without compromising tracking accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u4e24\u8f74\u7eb3\u7c73\u5b9a\u4f4d\u5668\u7684\u5206\u6563\u5f0f\u53cc\u73af\u63a7\u5236\u7b56\u7565\uff0c\u7ed3\u5408\u5185\u73af\u975e\u6700\u5c0f\u76f8\u4f4d\u8c10\u632f\u963b\u5c3c\u63a7\u5236\u5668\u548c\u5916\u73af\u8fd0\u52a8\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u5e26\u901a\u963b\u5c3c\u663e\u8457\u964d\u4f4e\u4ea4\u53c9\u8f74\u8026\u5408\u5e76\u589e\u5f3a\u6270\u52a8\u6291\u5236\u80fd\u529b\u3002", "motivation": "\u538b\u7535\u7eb3\u7c73\u5b9a\u4f4d\u7cfb\u7edf\u5728\u9700\u8981\u7eb3\u7c73\u7ea7\u7cbe\u5ea6\u548c\u9ad8\u901f\u8fd0\u52a8\u7684\u7cbe\u5bc6\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u8f7b\u963b\u5c3c\u8c10\u632f\u548c\u663e\u8457\u7684\u4ea4\u53c9\u8f74\u8026\u5408\u4e25\u91cd\u9650\u5236\u4e86\u5e26\u5bbd\u548c\u6270\u52a8\u6291\u5236\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u6563\u5f0f\u53cc\u73af\u63a7\u5236\u7b56\u7565\uff1a\u6bcf\u4e2a\u8f74\u5305\u542b\u5185\u73af\u975e\u6700\u5c0f\u76f8\u4f4d\u8c10\u632f\u963b\u5c3c\u63a7\u5236\u5668\u548c\u5916\u73af\u8fd0\u52a8\u63a7\u5236\u5668\u3002\u4e3b\u52a8\u963b\u5c3c\u4e3b\u5bf9\u89d2\u8c10\u632f\u4ee5\u8d85\u8d8a\u7b2c\u4e00\u7ed3\u6784\u6a21\u5f0f\u7684\u95ed\u73af\u5e26\u5bbd\uff0c\u540c\u65f6\u5e76\u884c\u5e26\u901a\u963b\u5c3c\u8def\u5f84\u4e13\u95e8\u9488\u5bf9\u4e3b\u8981\u5f71\u54cd\u4ea4\u53c9\u8026\u5408\u901a\u9053\u7684\u9ad8\u9636\u8c10\u632f\u8fdb\u884c\u8c03\u8c10\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u9488\u5bf9\u6027\u5e26\u901a\u963b\u5c3c\u663e\u8457\u51cf\u5c11\u4e86\u4ea4\u53c9\u8f74\u8026\u5408\u5e76\u589e\u5f3a\u4e86\u6270\u52a8\u6291\u5236\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u8ddf\u8e2a\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u7eb3\u7c73\u5b9a\u4f4d\u7cfb\u7edf\u4e2d\u7684\u8c10\u632f\u548c\u4ea4\u53c9\u8026\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5e26\u5bbd\u548c\u66f4\u597d\u7684\u6270\u52a8\u6291\u5236\u6027\u80fd\u3002"}}
{"id": "2601.13014", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.13014", "abs": "https://arxiv.org/abs/2601.13014", "authors": ["Kim Christensen", "Mathias Siggaard", "Bezirgen Veliyev"], "title": "A machine learning approach to volatility forecasting", "comment": null, "summary": "We inspect how accurate machine learning (ML) is at forecasting realized variance of the Dow Jones Industrial Average index constituents. We compare several ML algorithms, including regularization, regression trees, and neural networks, to multiple Heterogeneous AutoRegressive (HAR) models. ML is implemented with minimal hyperparameter tuning. In spite of this, ML is competitive and beats the HAR lineage, even when the only predictors are the daily, weekly, and monthly lags of realized variance. The forecast gains are more pronounced at longer horizons. We attribute this to higher persistence in the ML models, which helps to approximate the long-memory of realized variance. ML also excels at locating incremental information about future volatility from additional predictors. Lastly, we propose a ML measure of variable importance based on accumulated local effects. This shows that while there is agreement about the most important predictors, there is disagreement on their ranking, helping to reconcile our results.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u5728\u9884\u6d4b\u9053\u743c\u65af\u5de5\u4e1a\u5e73\u5747\u6307\u6570\u6210\u5206\u80a1\u5df2\u5b9e\u73b0\u65b9\u5dee\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfHAR\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u957f\u671f\u9884\u6d4b\u4e2d\uff0c\u4e14\u80fd\u66f4\u597d\u5730\u4ece\u989d\u5916\u9884\u6d4b\u53d8\u91cf\u4e2d\u63d0\u53d6\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u9884\u6d4b\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\uff08\u7279\u522b\u662f\u5df2\u5b9e\u73b0\u65b9\u5dee\uff09\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e0e\u4f20\u7edfHeterogeneous AutoRegressive (HAR) \u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u63a2\u7d22ML\u5728\u91d1\u878d\u6ce2\u52a8\u7387\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08\u5305\u62ec\u6b63\u5219\u5316\u65b9\u6cd5\u3001\u56de\u5f52\u6811\u548c\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u4e0e\u591a\u4e2aHAR\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002ML\u5b9e\u73b0\u91c7\u7528\u6700\u5c0f\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u9884\u6d4b\u53d8\u91cf\u5305\u62ec\u5df2\u5b9e\u73b0\u65b9\u5dee\u7684\u65e5\u3001\u5468\u3001\u6708\u6ede\u540e\u503c\u3002\u63d0\u51fa\u57fa\u4e8e\u7d2f\u79ef\u5c40\u90e8\u6548\u5e94\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u5df2\u5b9e\u73b0\u65b9\u5dee\u65b9\u9762\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5373\u4f7f\u53ea\u4f7f\u7528\u65e5\u3001\u5468\u3001\u6708\u6ede\u540e\u503c\u4f5c\u4e3a\u9884\u6d4b\u53d8\u91cf\uff0c\u4e5f\u80fd\u51fb\u8d25HAR\u6a21\u578b\u7cfb\u5217\u3002\u9884\u6d4b\u6536\u76ca\u5728\u66f4\u957f\u7684\u9884\u6d4b\u5468\u671f\u4e2d\u66f4\u4e3a\u663e\u8457\uff0c\u8fd9\u5f52\u56e0\u4e8eML\u6a21\u578b\u5177\u6709\u66f4\u9ad8\u7684\u6301\u7eed\u6027\uff0c\u80fd\u66f4\u597d\u5730\u8fd1\u4f3c\u5df2\u5b9e\u73b0\u65b9\u5dee\u7684\u957f\u8bb0\u5fc6\u7279\u6027\u3002ML\u8fd8\u80fd\u66f4\u597d\u5730\u4ece\u989d\u5916\u9884\u6d4b\u53d8\u91cf\u4e2d\u63d0\u53d6\u589e\u91cf\u4fe1\u606f\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u5728\u91d1\u878d\u6ce2\u52a8\u7387\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u957f\u671f\u9884\u6d4b\u65b9\u9762\u3002\u867d\u7136\u4e0d\u540c\u6a21\u578b\u5bf9\u6700\u91cd\u8981\u9884\u6d4b\u53d8\u91cf\u7684\u770b\u6cd5\u4e00\u81f4\uff0c\u4f46\u5728\u6392\u5e8f\u4e0a\u5b58\u5728\u5206\u6b67\uff0c\u8fd9\u6709\u52a9\u4e8e\u89e3\u91ca\u7814\u7a76\u7ed3\u679c\u7684\u5dee\u5f02\u3002\u63d0\u51fa\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\u65b9\u6cd5\u4e3a\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.11576", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11576", "abs": "https://arxiv.org/abs/2601.11576", "authors": ["Long Zhang", "Fangwei Lin", "Weilin Wang"], "title": "What Can Student-AI Dialogues Tell Us About Students' Self-Regulated Learning? An exploratory framework", "comment": null, "summary": "The rise of Human-AI Collaborative Learning (HAICL) is shifting education toward dialogue-centric paradigms, creating an urgent need for new assessment methods. Evaluating Self-Regulated Learning (SRL) in this context presents new challenges, as the limitations of conventional approaches become more apparent. Questionnaires remain interrupted, while the utility of non-interrupted metrics like clickstream data is diminishing as more learning activity occurs within the dialogue. This study therefore investigates whether the student-AI dialogue can serve as a valid, non-interrupted data source for SRL assessment. We analyzed 421 dialogue logs from 98 university students interacting with a generative AI (GenAI) learning partner. Using large language model embeddings and clustering, we identified 22 dialogue patterns and quantified each student's interaction as a profile of alignment scores, which were analyzed against their Online Self-Regulated Learning Questionnaire (OSLQ) scores. Findings revealed a significant positive association between proactive dialogue patterns (e.g., post-class knowledge integration) and overall SRL. Conversely, reactive patterns (e.g., foundational pre-class questions) were significantly and negatively associated with overall SRL and its sub-processes. A group comparison substantiated these results, with low-SRL students showing significantly higher alignment with reactive patterns than their high-SRL counterparts. This study proposed the Dialogue-Based Human-AI Self-Regulated Learning (DHASRL) framework, a practical methodology for embedding SRL assessment directly within the HAICL dialogue to enable real-time monitoring and scaffolding of student regulation.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faDHASRL\u6846\u67b6\uff0c\u5229\u7528\u5b66\u751f\u4e0e\u751f\u6210\u5f0fAI\u5bf9\u8bdd\u6570\u636e\u8bc4\u4f30\u81ea\u6211\u8c03\u8282\u5b66\u4e60\u80fd\u529b\uff0c\u53d1\u73b0\u4e3b\u52a8\u5bf9\u8bdd\u6a21\u5f0f\u4e0eSRL\u6b63\u76f8\u5173\uff0c\u88ab\u52a8\u6a21\u5f0f\u4e0eSRL\u8d1f\u76f8\u5173\u3002", "motivation": "\u4eba\u673a\u534f\u4f5c\u5b66\u4e60\u8f6c\u5411\u5bf9\u8bdd\u4e2d\u5fc3\u8303\u5f0f\uff0c\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982\u95ee\u5377\u4e2d\u65ad\u5b66\u4e60\u3001\u70b9\u51fb\u6d41\u6570\u636e\u6548\u7528\u4e0b\u964d\uff09\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u975e\u4e2d\u65ad\u6027SRL\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5206\u679098\u540d\u5927\u5b66\u751f\u7684421\u4e2a\u5bf9\u8bdd\u65e5\u5fd7\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u548c\u805a\u7c7b\u8bc6\u522b22\u79cd\u5bf9\u8bdd\u6a21\u5f0f\uff0c\u8ba1\u7b97\u5b66\u751f\u5bf9\u5404\u6a21\u5f0f\u7684\u5bf9\u9f50\u5206\u6570\uff0c\u5e76\u4e0e\u5728\u7ebf\u81ea\u6211\u8c03\u8282\u5b66\u4e60\u95ee\u5377\u5f97\u5206\u8fdb\u884c\u5173\u8054\u5206\u6790\u3002", "result": "\u4e3b\u52a8\u5bf9\u8bdd\u6a21\u5f0f\uff08\u5982\u8bfe\u540e\u77e5\u8bc6\u6574\u5408\uff09\u4e0e\u6574\u4f53SRL\u663e\u8457\u6b63\u76f8\u5173\uff1b\u88ab\u52a8\u6a21\u5f0f\uff08\u5982\u8bfe\u524d\u57fa\u7840\u95ee\u9898\uff09\u4e0e\u6574\u4f53SRL\u53ca\u5176\u5b50\u8fc7\u7a0b\u663e\u8457\u8d1f\u76f8\u5173\uff1b\u4f4eSRL\u5b66\u751f\u5bf9\u88ab\u52a8\u6a21\u5f0f\u7684\u5bf9\u9f50\u5ea6\u663e\u8457\u9ad8\u4e8e\u9ad8SRL\u5b66\u751f\u3002", "conclusion": "\u63d0\u51faDHASRL\u6846\u67b6\uff0c\u8bc1\u660e\u5b66\u751f-AI\u5bf9\u8bdd\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u975e\u4e2d\u65ad\u6027SRL\u8bc4\u4f30\u6570\u636e\u6e90\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u5b9e\u65f6\u76d1\u63a7\u548c\u652f\u67b6\u652f\u6301\u63d0\u4f9b\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2601.13191", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13191", "abs": "https://arxiv.org/abs/2601.13191", "authors": ["Francisco Daunas", "I\u00f1aki Esnaola", "Samir M. Perlaza", "H. Vincent Poor"], "title": "Empirical Risk Minimization with $f$-Divergence Regularization", "comment": "Submitted to IEEE Transactions on Information Theory. arXiv admin note: substantial text overlap with arXiv:2502.14544, arXiv:2508.03314", "summary": "In this paper, the solution to the empirical risk minimization problem with $f$-divergence regularization (ERM-$f$DR) is presented and conditions under which the solution also serves as the solution to the minimization of the expected empirical risk subject to an $f$-divergence constraint are established. The proposed approach extends applicability to a broader class of $f$-divergences than previously reported and yields theoretical results that recover previously known results. Additionally, the difference between the expected empirical risk of the ERM-$f$DR solution and that of its reference measure is characterized, providing insights into previously studied cases of $f$-divergences. A central contribution is the introduction of the normalization function, a mathematical object that is critical in both the dual formulation and practical computation of the ERM-$f$DR solution. This work presents an implicit characterization of the normalization function as a nonlinear ordinary differential equation (ODE), establishes its key properties, and subsequently leverages them to construct a numerical algorithm for approximating the normalization factor under mild assumptions. Further analysis demonstrates structural equivalences between ERM-$f$DR problems with different $f$-divergences via transformations of the empirical risk. Finally, the proposed algorithm is used to compute the training and test risks of ERM-$f$DR solutions under different $f$-divergence regularizers. This numerical example highlights the practical implications of choosing different functions $f$ in ERM-$f$DR problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86f-\u6563\u5ea6\u6b63\u5219\u5316\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316(ERM-fDR)\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5efa\u7acb\u4e86\u8be5\u89e3\u540c\u65f6\u6ee1\u8db3f-\u6563\u5ea6\u7ea6\u675f\u4e0b\u671f\u671b\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u7684\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u4e86\u5f52\u4e00\u5316\u51fd\u6570\u7684\u6982\u5ff5\u53ca\u5176\u6570\u503c\u8ba1\u7b97\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684f-\u6563\u5ea6\u6b63\u5219\u5316\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u65b9\u6cd5\u9002\u7528\u8303\u56f4\u6709\u9650\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u8be5\u65b9\u6cd5\u5230\u66f4\u5e7f\u6cdb\u7684f-\u6563\u5ea6\u7c7b\u522b\uff0c\u5efa\u7acb\u7406\u8bba\u8054\u7cfb\uff0c\u5e76\u63d0\u4f9b\u5b9e\u7528\u7684\u8ba1\u7b97\u5de5\u5177\u3002", "method": "\u5f15\u5165\u5f52\u4e00\u5316\u51fd\u6570\u4f5c\u4e3a\u5173\u952e\u6570\u5b66\u5bf9\u8c61\uff0c\u5efa\u7acb\u5176\u975e\u7ebf\u6027\u5e38\u5fae\u5206\u65b9\u7a0b\u8868\u5f81\uff0c\u8bc1\u660e\u5176\u6027\u8d28\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u6570\u503c\u7b97\u6cd5\u3002\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u53d8\u6362\u5206\u6790\u4e0d\u540cf-\u6563\u5ea6ERM-fDR\u95ee\u9898\u7684\u7ed3\u6784\u7b49\u4ef7\u6027\u3002", "result": "\u6269\u5c55\u4e86ERM-fDR\u65b9\u6cd5\u5230\u66f4\u5e7f\u6cdb\u7684f-\u6563\u5ea6\u7c7b\u522b\uff0c\u6062\u590d\u4e86\u5df2\u77e5\u7ed3\u679c\u3002\u5efa\u7acb\u4e86\u5f52\u4e00\u5316\u51fd\u6570\u7684ODE\u8868\u5f81\u548c\u6570\u503c\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u4e0d\u540cf-\u6563\u5ea6\u95ee\u9898\u7684\u7ed3\u6784\u7b49\u4ef7\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u5c55\u793a\u4e86\u4e0d\u540cf\u51fd\u6570\u9009\u62e9\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u4e3af-\u6563\u5ea6\u6b63\u5219\u5316\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u548c\u8ba1\u7b97\u5de5\u5177\uff0c\u6269\u5c55\u4e86\u65b9\u6cd5\u9002\u7528\u6027\uff0c\u5efa\u7acb\u4e86\u4e0d\u540cf-\u6563\u5ea6\u95ee\u9898\u7684\u8054\u7cfb\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684f\u51fd\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.11782", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11782", "abs": "https://arxiv.org/abs/2601.11782", "authors": ["Albert Joon Lee", "David E. Bernal Neira"], "title": "Mixed-Integer Reaggregated Hull Reformulation of Special Structured Generalized Linear Disjunctive Programs", "comment": "20 pages, 5 figures", "summary": "Generalized Disjunctive Programming (GDP) provides a powerful framework for combining algebraic constraints with logical disjunctions. To solve these problems, mixed-integer reformulations are required, but traditional reformulation schemes, such as Big-M and Hull, either yield a weak continuous relaxation or result in a bloated model size. Castro and Grossmann showed that scheduling problems can be formulated as GDP by modeling task orderings as disjunctions with algebraic timing constraints. Moreover, in their work, a particular representation of the single-unit scheduling problem, namely using a time-slot concept, can be reformulated as a tight yet compact mixed-integer linear program with notable computational performance. Based on that observation, and focusing on the case where the constraints in disjunctions are linear and share the same coefficients, we connect the characterization of the convex hull of these disjunctive sets by Jeroslow and Blair with Castro and Grossmann's time-slot reaggregation strategy to derive a unified reformulation methodology. We test this reformulation in two problems, single-unit scheduling and two-dimensional strip-packing. We derive new formulations of the general precedence concept of single-unit scheduling and symmetry-breaking formulations of the strip-packing problem, yielding mixed-integer programs with strong theoretical guarantees, particularly compact formulations in terms of continuous variables, and efficient computational performance when solving them with commercial mixed-integer solvers for these problems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u7684GDP\u91cd\u6784\u65b9\u6cd5\uff0c\u7ed3\u5408Jeroslow\u548cBlair\u7684\u51f8\u5305\u7406\u8bba\u4e0eCastro\u548cGrossmann\u7684\u65f6\u95f4\u69fd\u91cd\u805a\u5408\u7b56\u7565\uff0c\u4e3a\u5355\u5355\u5143\u8c03\u5ea6\u548c\u4e8c\u7ef4\u6761\u5e26\u88c5\u7bb1\u95ee\u9898\u751f\u6210\u7d27\u51d1\u4e14\u7d27\u81f4\u7684MILP\u6a21\u578b\u3002", "motivation": "\u4f20\u7edfGDP\u91cd\u6784\u65b9\u6cd5\uff08\u5982Big-M\u548cHull\uff09\u5b58\u5728\u8fde\u7eed\u677e\u5f1b\u5f31\u6216\u6a21\u578b\u89c4\u6a21\u81a8\u80c0\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u7d27\u51d1\u6027\u53c8\u5177\u6709\u5f3a\u7406\u8bba\u4fdd\u8bc1\u7684\u7edf\u4e00\u91cd\u6784\u65b9\u6cd5\u3002", "method": "\u5c06Jeroslow\u548cBlair\u7684\u7ebf\u6027\u7ea6\u675f\u5171\u7cfb\u6570\u60c5\u5f62\u4e0b\u7684\u51f8\u5305\u7279\u5f81\u4e0eCastro\u548cGrossmann\u7684\u65f6\u95f4\u69fd\u91cd\u805a\u5408\u7b56\u7565\u76f8\u7ed3\u5408\uff0c\u63a8\u5bfc\u51fa\u7edf\u4e00\u7684\u91cd\u6784\u65b9\u6cd5\u5b66\uff0c\u5e94\u7528\u4e8e\u5355\u5355\u5143\u8c03\u5ea6\u548c\u4e8c\u7ef4\u6761\u5e26\u88c5\u7bb1\u95ee\u9898\u3002", "result": "\u4e3a\u5355\u5355\u5143\u8c03\u5ea6\u63a8\u5bfc\u51fa\u65b0\u7684\u901a\u7528\u4f18\u5148\u7ea7\u6982\u5ff5\u8868\u8ff0\uff0c\u4e3a\u6761\u5e26\u88c5\u7bb1\u95ee\u9898\u63a8\u5bfc\u51fa\u5bf9\u79f0\u6027\u7834\u7f3a\u8868\u8ff0\uff0c\u751f\u6210\u5177\u6709\u5f3a\u7406\u8bba\u4fdd\u8bc1\uff08\u7279\u522b\u662f\u8fde\u7eed\u53d8\u91cf\u7d27\u51d1\u6027\uff09\u7684MILP\u6a21\u578b\uff0c\u5728\u5546\u4e1a\u6c42\u89e3\u5668\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u91cd\u6784\u65b9\u6cd5\u80fd\u591f\u4e3a\u5177\u6709\u7ebf\u6027\u7ea6\u675f\u548c\u5171\u7cfb\u6570\u7684GDP\u95ee\u9898\u751f\u6210\u7d27\u51d1\u4e14\u7d27\u81f4\u7684MILP\u6a21\u578b\uff0c\u5728\u5355\u5355\u5143\u8c03\u5ea6\u548c\u4e8c\u7ef4\u6761\u5e26\u88c5\u7bb1\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u5176\u7406\u8bba\u4f18\u52bf\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2601.13493", "categories": ["math.OC", "math.FA", "math.PR", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2601.13493", "abs": "https://arxiv.org/abs/2601.13493", "authors": ["Hanchao Liu", "Dena Firoozi"], "title": "LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons", "comment": "27 pages", "summary": "We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $\u03b5$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons.", "AI": {"tldr": "\u5c06Hilbert\u7a7a\u95f4\u4e2d\u7684\u7ebf\u6027\u4e8c\u6b21\u5e73\u5747\u573a\u535a\u5f08\u6269\u5c55\u5230\u5305\u542b\u5171\u540c\u566a\u58f0\uff0c\u5efa\u7acb\u8026\u5408\u968f\u673a\u6f14\u5316\u65b9\u7a0b\u89e3\u7684\u5b58\u5728\u552f\u4e00\u6027\uff0c\u5e76\u8bc1\u660e\u03b5-\u7eb3\u4ec0\u5747\u8861\u6027\u8d28", "motivation": "\u6269\u5c55Liu\u548cFiroozi (2025)\u7684Hilbert\u7a7a\u95f4\u7ebf\u6027\u4e8c\u6b21\u5e73\u5747\u573a\u535a\u5f08\u7406\u8bba\uff0c\u5f15\u5165\u65e0\u9650\u7ef4Wiener\u8fc7\u7a0b\u4f5c\u4e3a\u5171\u540c\u566a\u58f0\uff0c\u7814\u7a76\u5728\u5171\u540c\u566a\u58f0\u5f71\u54cd\u4e0b\u7684\u5e73\u5747\u573a\u535a\u5f08\u95ee\u9898", "method": "\u5728Hilbert\u7a7a\u95f4\u4e2d\u5efa\u7acb\u8026\u5408\u7684\u524d\u5411-\u540e\u5411\u968f\u673a\u6f14\u5316\u65b9\u7a0b\u7cfb\u7edf\uff0c\u5206\u6790\u5c0f\u65f6\u95f4\u8303\u56f4\u5185\u7684\u89e3\u5b58\u5728\u552f\u4e00\u6027\uff0c\u5e76\u9996\u6b21\u5728\u6587\u732e\u4e2d\u5efa\u7acb\u4efb\u610f\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u6e29\u548c\u89e3\u7684\u826f\u597d\u9002\u5b9a\u6027", "result": "\u8bc1\u660e\u4e86\u8026\u5408\u7ebf\u6027FBSEEs\u5728\u5c0f\u65f6\u95f4\u8303\u56f4\u5185\u7684\u89e3\u5b58\u5728\u552f\u4e00\u6027\uff0c\u5efa\u7acb\u4e86\u6240\u5f97\u5747\u8861\u7b56\u7565\u7684\u03b5-\u7eb3\u4ec0\u6027\u8d28\uff0c\u5e76\u9996\u6b21\u5728Hilbert\u7a7a\u95f4\u4e2d\u5efa\u7acb\u4e86\u4efb\u610f\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u8fd9\u4e9b\u65b9\u7a0b\u7684\u826f\u597d\u9002\u5b9a\u6027", "conclusion": "\u6210\u529f\u5c06\u5171\u540c\u566a\u58f0\u7eb3\u5165Hilbert\u7a7a\u95f4\u4e2d\u7684\u7ebf\u6027\u4e8c\u6b21\u5e73\u5747\u573a\u535a\u5f08\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u6570\u5b66\u7406\u8bba\uff0c\u4e3a\u65e0\u9650\u7ef4\u968f\u673a\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177"}}
{"id": "2601.11578", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11578", "abs": "https://arxiv.org/abs/2601.11578", "authors": ["Ibrahim Al Azher", "Zhishuai Guo", "Hamed Alhoori"], "title": "LimAgents: Multi-Agent LLMs for Generating Research Limitations", "comment": "18 Pages, 9 figures", "summary": "Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.", "AI": {"tldr": "LimAgents\uff1a\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408OpenReview\u8bc4\u8bba\u3001\u4f5c\u8005\u9648\u8ff0\u7684\u5c40\u9650\u6027\u548c\u5f15\u7528\u6587\u732e\uff0c\u751f\u6210\u5b9e\u8d28\u6027\u7814\u7a76\u5c40\u9650\u6027\u5206\u6790\uff0c\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7814\u7a76\u5c40\u9650\u6027\u9648\u8ff0\u5f80\u5f80\u6d41\u4e8e\u8868\u9762\uff08\u5982\u6570\u636e\u96c6\u504f\u5dee\u6216\u6cdb\u5316\u6027\uff09\uff0c\u901a\u5e38\u53ea\u662f\u91cd\u590d\u4f5c\u8005\u5df2\u62a5\u544a\u7684\u5185\u5bb9\uff0c\u800c\u672a\u80fd\u6df1\u5165\u5206\u6790\u65b9\u6cd5\u8bba\u95ee\u9898\u548c\u4e0a\u4e0b\u6587\u5dee\u8ddd\u3002\u8bb8\u591a\u4f5c\u8005\u4e5f\u53ea\u62ab\u9732\u90e8\u5206\u6216\u7410\u788e\u7684\u5c40\u9650\u6027\uff0c\u4f7f\u5f97\u8fd9\u4e00\u95ee\u9898\u66f4\u52a0\u4e25\u91cd\u3002", "method": "\u63d0\u51faLimAgents\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u6574\u5408OpenReview\u8bc4\u8bba\u548c\u4f5c\u8005\u9648\u8ff0\u7684\u5c40\u9650\u6027\u4f5c\u4e3a\u66f4\u5f3a\u7684\u57fa\u7840\u4e8b\u5b9e\uff0c\u5e76\u5229\u7528\u5f15\u7528\u548c\u88ab\u5f15\u6587\u732e\u6355\u6349\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\u5f31\u70b9\u3002\u4e0d\u540c\u667a\u80fd\u4f53\u6709\u7279\u5b9a\u89d2\u8272\uff1a\u63d0\u53d6\u663e\u5f0f\u5c40\u9650\u6027\u3001\u5206\u6790\u65b9\u6cd5\u8bba\u5dee\u8ddd\u3001\u6a21\u62df\u540c\u884c\u8bc4\u5ba1\u89c6\u89d2\u3001\u5206\u6790\u6587\u732e\u80cc\u666f\u3002Judge\u667a\u80fd\u4f53\u7cbe\u70bc\u8f93\u51fa\uff0cMaster\u667a\u80fd\u4f53\u6574\u5408\u6210\u6e05\u6670\u96c6\u5408\u3002\u540c\u65f6\u5f15\u5165\u57fa\u4e8eLLM-as-a-Judge\u7684\u70b9\u5bf9\u70b9\u8bc4\u4f30\u534f\u8bae\uff0c\u66f4\u51c6\u786e\u8861\u91cf\u8986\u76d6\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLimAgents\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1aRAG+\u591a\u667a\u80fd\u4f53GPT-4o mini\u914d\u7f6e\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u83b7\u5f97+15.51%\u7684\u8986\u76d6\u5ea6\u63d0\u5347\uff0cLlama 3 8B\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u5b9e\u73b0+4.41%\u7684\u6539\u8fdb\u3002", "conclusion": "LimAgents\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u8bc6\u522b\u663e\u5f0f\u3001\u9690\u5f0f\u3001\u540c\u884c\u8bc4\u5ba1\u5bfc\u5411\u548c\u6587\u732e\u4fe1\u606f\u5316\u7684\u5c40\u9650\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u751f\u6210\u5b9e\u8d28\u6027\u7814\u7a76\u5c40\u9650\u6027\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u900f\u660e\u548c\u4e25\u8c28\u7684\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u3002"}}
{"id": "2601.11606", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11606", "abs": "https://arxiv.org/abs/2601.11606", "authors": ["Farzana Islam Adiba", "Varsha Danduri", "Fahmida Liza Piya", "Ali Abbasi", "Mehak Gupta", "Rahmatollah Beheshti"], "title": "A Multimodal Data Processing Pipeline for MIMIC-IV Dataset", "comment": null, "summary": "The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.", "AI": {"tldr": "MIMIC-IV\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u81ea\u52a8\u5316\u6574\u5408\u7ed3\u6784\u5316\u6570\u636e\u3001\u4e34\u5e8a\u7b14\u8bb0\u3001\u6ce2\u5f62\u548c\u5f71\u50cf\u6570\u636e\uff0c\u663e\u8457\u51cf\u5c11\u5904\u7406\u65f6\u95f4\u5e76\u63d0\u9ad8\u7814\u7a76\u53ef\u91cd\u590d\u6027\u3002", "motivation": "MIMIC-IV\u6570\u636e\u96c6\u5305\u542b\u591a\u79cd\u6a21\u6001\u6570\u636e\uff0c\u4f46\u73b0\u6709\u5904\u7406\u5de5\u5177\u8981\u4e48\u53ea\u652f\u6301\u90e8\u5206\u6a21\u6001\uff0c\u8981\u4e48\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u4e0b\u6e38\u5e94\u7528\uff0c\u9700\u8981\u5927\u91cf\u624b\u52a8\u9884\u5904\u7406\u548c\u5bf9\u9f50\u5de5\u4f5c\u3002", "method": "\u6269\u5c55\u5148\u524d\u5355\u6a21\u6001\u7ba1\u9053\uff0c\u5f00\u53d1\u7efc\u5408\u6027\u3001\u53ef\u5b9a\u5236\u7684\u591a\u6a21\u6001\u7ba1\u9053\uff0c\u7cfb\u7edf\u6574\u5408\u6240\u6709\u6a21\u6001\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u961f\u5217\u9009\u62e9\u3001\u8de8\u6a21\u6001\u65f6\u95f4\u5bf9\u9f50\uff0c\u5e76\u751f\u6210\u9002\u5408\u9759\u6001\u548c\u65f6\u95f4\u5e8f\u5217\u4e0b\u6e38\u5e94\u7528\u7684\u6807\u51c6\u8f93\u51fa\u683c\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u5904\u7406\u7ba1\u9053\uff0c\u663e\u8457\u51cf\u5c11\u591a\u6a21\u6001\u6570\u636e\u5904\u7406\u65f6\u95f4\uff0c\u589e\u5f3aMIMIC\u76f8\u5173\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\uff0c\u63d0\u4f9b\u4ee3\u7801\u3001\u7b80\u5355UI\u548cPython\u5305\u4f9b\u9009\u62e9\u6027\u96c6\u6210\u4f7f\u7528\u3002", "conclusion": "\u8be5\u591a\u6a21\u6001\u7ba1\u9053\u89e3\u51b3\u4e86MIMIC-IV\u6570\u636e\u5904\u7406\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u4e3a\u4e34\u5e8a\u673a\u5668\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u91cd\u590d\u7684\u5de5\u5177\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2601.11781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11781", "abs": "https://arxiv.org/abs/2601.11781", "authors": ["Dawood Wasif", "Terrence J. Moore", "Seunghyun Yoon", "Hyuk Lim", "Dan Dongseong Kim", "Frederica F. Nelson", "Jin-Hee Cho"], "title": "Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles", "comment": "Submitted to ICRA 2026 (under review)", "summary": "Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.", "AI": {"tldr": "RAIL\u662f\u4e00\u4e2a\u98ce\u9669\u611f\u77e5\u7684\u4eba\u673a\u534f\u540c\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u591a\u79cd\u8fd0\u884c\u65f6\u4fe1\u53f7\u751f\u6210\u5165\u4fb5\u98ce\u9669\u8bc4\u5206\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u63a7\u5236\u548c\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6709\u6548\u5e94\u5bf9\u957f\u5c3e\u573a\u666f\u548c\u7f51\u7edc\u7269\u7406\u5165\u4fb5\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u9047\u5230\u7f55\u89c1\u7684\u957f\u5c3e\u573a\u666f\u6216\u7f51\u7edc\u7269\u7406\u5165\u4fb5\u65f6\u9700\u8981\u4fdd\u6301\u5b89\u5168\u548c\u6709\u6548\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e9b\u6311\u6218\u6027\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u8db3\u3002", "method": "RAIL\u6846\u67b6\u878d\u5408\u4e09\u79cd\u4fe1\u53f7\uff08\u66f2\u7387\u6267\u884c\u5b8c\u6574\u6027\u3001\u78b0\u649e\u65f6\u95f4\u63a5\u8fd1\u5ea6\u3001\u89c2\u6d4b\u504f\u79fb\u4e00\u81f4\u6027\uff09\u901a\u8fc7\u52a0\u6743Noisy-OR\u751f\u6210\u5165\u4fb5\u98ce\u9669\u8bc4\u5206\u3002\u9ad8\u98ce\u9669\u65f6\u4f7f\u7528\u7279\u5b9a\u9632\u62a4\u673a\u5236\u6df7\u5408\u63a7\u5236\uff0c\u4f4e\u98ce\u9669\u65f6\u6267\u884c\u540d\u4e49\u7b56\u7565\u3002\u91c7\u7528\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u9009\u62e9\u9632\u62a4\u673a\u5236\uff0c\u7ed3\u5408SAC\u5f3a\u5316\u5b66\u4e60\u4e0e\u98ce\u9669\u4f18\u5148\u56de\u653e\u548c\u53cc\u91cd\u5956\u52b1\u673a\u5236\u3002", "result": "\u5728MetaDrive\u4e0a\uff0cRAIL\u83b7\u5f97\u6d4b\u8bd5\u56de\u62a5360.65\u3001\u6d4b\u8bd5\u6210\u529f\u73870.85\u3001\u6d4b\u8bd5\u5b89\u5168\u8fdd\u89c40.75\u3001\u6270\u52a8\u73870.0027\uff0c\u4ec5\u8bb0\u5f5529.07\u4e2a\u8bad\u7ec3\u5b89\u5168\u8fdd\u89c4\u3002\u5728CAN\u6ce8\u5165\u548cLiDAR\u6b3a\u9a97\u653b\u51fb\u4e0b\uff0c\u6210\u529f\u7387\u63d0\u5347\u81f30.68\u548c0.80\uff0c\u653b\u51fb\u4e0b\u8131\u79bb\u7387\u964d\u81f30.37\u548c0.03\uff0c\u653b\u51fb\u6210\u529f\u7387\u964d\u81f30.34\u548c0.11\u3002\u5728CARLA\u4e2d\uff0c\u4ec58000\u6b65\u83b7\u5f97\u6d4b\u8bd5\u56de\u62a51609.70\u548c\u6d4b\u8bd5\u6210\u529f\u73870.41\u3002", "conclusion": "RAIL\u6846\u67b6\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u7684\u4eba\u673a\u534f\u540c\u65b9\u6cd5\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6709\u6548\u5e94\u5bf9\u7f55\u89c1\u573a\u666f\u548c\u7f51\u7edc\u653b\u51fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2601.12028", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12028", "abs": "https://arxiv.org/abs/2601.12028", "authors": ["Kun-Yan Jiang", "Wei-Yu Chiu", "Yuan-Po Tsai"], "title": "Profit Maximization for Electric Vehicle Charging Stations Using Multiagent Reinforcement Learning", "comment": "18 pages, 4 figures", "summary": "Electric vehicles (EVs) are increasingly integrated into power grids, offering economic and environmental benefits but introducing challenges due to uncoordinated charging. This study addresses the profit maximization problem for multiple EV charging stations (EVCSs) equipped with energy storage systems (ESS) and renewable energy sources (RES), with the capability for energy trading. We propose a Double Hypernetwork QMIX-based multi-agent reinforcement learning (MARL) framework to optimize cooperative energy management under uncertainty in EV demand, renewable generation, and real-time electricity prices. The framework mitigates overestimation bias in value estimation, enables distributed decision-making, and incorporates an internal energy trading mechanism. Numerical experiments using real-world data demonstrate that, compared to standard QMIX, the proposed method achieves approximately 5.3% and 12.7% higher total profit for the two regions, respectively, highlighting its economic and operational efficiency. Additionally, the approach maintains robust performance under varying levels of EV demand uncertainty and renewable energy fluctuations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eDouble Hypernetwork QMIX\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f18\u5316\u914d\u5907\u50a8\u80fd\u548c\u53ef\u518d\u751f\u80fd\u6e90\u7684\u591a\u4e2a\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u7684\u534f\u540c\u80fd\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u5185\u90e8\u80fd\u6e90\u4ea4\u6613\u673a\u5236\u63d0\u9ad8\u7ecf\u6d4e\u6548\u76ca\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5927\u89c4\u6a21\u63a5\u5165\u7535\u7f51\u5e26\u6765\u7ecf\u6d4e\u6548\u76ca\u548c\u73af\u5883\u6548\u76ca\uff0c\u4f46\u65e0\u5e8f\u5145\u7535\u4e5f\u5e26\u6765\u6311\u6218\u3002\u591a\u4e2a\u5145\u7535\u7ad9\u914d\u5907\u50a8\u80fd\u548c\u53ef\u518d\u751f\u80fd\u6e90\u540e\uff0c\u5982\u4f55\u901a\u8fc7\u534f\u540c\u7ba1\u7406\u548c\u80fd\u6e90\u4ea4\u6613\u6700\u5927\u5316\u6574\u4f53\u5229\u6da6\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002", "method": "\u91c7\u7528Double Hypernetwork QMIX\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u7535\u52a8\u6c7d\u8f66\u9700\u6c42\u3001\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u548c\u5b9e\u65f6\u7535\u4ef7\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u6846\u67b6\u7f13\u89e3\u4ef7\u503c\u4f30\u8ba1\u4e2d\u7684\u9ad8\u4f30\u504f\u5dee\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u51b3\u7b56\uff0c\u5e76\u5305\u542b\u5185\u90e8\u80fd\u6e90\u4ea4\u6613\u673a\u5236\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u6807\u51c6QMIX\u65b9\u6cd5\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4e24\u4e2a\u533a\u57df\u5206\u522b\u5b9e\u73b0\u4e86\u7ea65.3%\u548c12.7%\u7684\u603b\u5229\u6da6\u63d0\u5347\uff0c\u5728\u7ecf\u6d4e\u548c\u8fd0\u8425\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u5728\u4e0d\u540c\u7535\u52a8\u6c7d\u8f66\u9700\u6c42\u4e0d\u786e\u5b9a\u6027\u548c\u53ef\u518d\u751f\u80fd\u6e90\u6ce2\u52a8\u6c34\u5e73\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684Double Hypernetwork QMIX\u6846\u67b6\u80fd\u6709\u6548\u4f18\u5316\u591a\u4e2a\u5145\u7535\u7ad9\u7684\u534f\u540c\u80fd\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u7f13\u89e3\u9ad8\u4f30\u504f\u5dee\u548c\u5185\u90e8\u80fd\u6e90\u4ea4\u6613\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u7ecf\u6d4e\u6548\u76ca\u548c\u8fd0\u8425\u6548\u7387\uff0c\u4e3a\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7684\u667a\u80fd\u7ba1\u7406\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11582", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11582", "abs": "https://arxiv.org/abs/2601.11582", "authors": ["Tohida Rehman", "Debarshi Kumar Sanyal", "Samiran Chattopadhyay"], "title": "Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers", "comment": "7 pages, 2 tables", "summary": "`SciHigh: Research Highlight Generation from Scientific Papers' focuses on the task of automatically generating concise, informative, and meaningful bullet-point highlights directly from scientific abstracts. The goal of this task is to evaluate how effectively computational models can generate highlights that capture the key contributions, findings, and novelty of a paper in a concise form. Highlights help readers grasp essential ideas quickly and are often easier to read and understand than longer paragraphs, especially on mobile devices. The track uses the MixSub dataset \\cite{10172215}, which provides pairs of abstracts and corresponding author-written highlights.\n  In this inaugural edition of the track, 12 teams participated, exploring various approaches, including pre-trained language models, to generate highlights from this scientific dataset. All submissions were evaluated using established metrics such as ROUGE, METEOR, and BERTScore to measure both alignment with author-written highlights and overall informativeness. Teams were ranked based on ROUGE-L scores. The findings suggest that automatically generated highlights can reduce reading effort, accelerate literature reviews, and enhance metadata for digital libraries and academic search platforms. SciHigh provides a dedicated benchmark for advancing methods aimed at concise and accurate highlight generation from scientific writing.", "AI": {"tldr": "SciHigh\u662f\u4e00\u4e2a\u4ece\u79d1\u5b66\u8bba\u6587\u6458\u8981\u81ea\u52a8\u751f\u6210\u8981\u70b9\u5f0f\u9ad8\u4eae\u7684\u7814\u7a76\u8d5b\u9053\uff0c\u4f7f\u7528MixSub\u6570\u636e\u96c6\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u80fd\u529b\uff0c12\u652f\u56e2\u961f\u53c2\u4e0e\u9996\u5c4a\u6bd4\u8d5b\uff0c\u57fa\u4e8eROUGE-L\u7b49\u6307\u6807\u6392\u540d\uff0c\u7ed3\u679c\u663e\u793a\u81ea\u52a8\u751f\u6210\u9ad8\u4eae\u80fd\u51cf\u5c11\u9605\u8bfb\u8d1f\u62c5\u3001\u52a0\u901f\u6587\u732e\u7efc\u8ff0\u3002", "motivation": "\u79d1\u5b66\u8bba\u6587\u6570\u91cf\u5feb\u901f\u589e\u957f\uff0c\u8bfb\u8005\u9700\u8981\u5feb\u901f\u638c\u63e1\u8bba\u6587\u6838\u5fc3\u8d21\u732e\u3002\u8981\u70b9\u5f0f\u9ad8\u4eae\u6bd4\u957f\u7bc7\u6bb5\u843d\u66f4\u6613\u9605\u8bfb\u7406\u89e3\uff0c\u5c24\u5176\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u3002\u81ea\u52a8\u751f\u6210\u9ad8\u4eae\u80fd\u5e2e\u52a9\u8bfb\u8005\u5feb\u901f\u6293\u4f4f\u8bba\u6587\u5173\u952e\u601d\u60f3\uff0c\u51cf\u5c11\u9605\u8bfb\u8d1f\u62c5\uff0c\u52a0\u901f\u6587\u732e\u7efc\u8ff0\uff0c\u5e76\u4e3a\u6570\u5b57\u56fe\u4e66\u9986\u548c\u5b66\u672f\u641c\u7d22\u5e73\u53f0\u63d0\u4f9b\u66f4\u597d\u7684\u5143\u6570\u636e\u3002", "method": "\u4f7f\u7528MixSub\u6570\u636e\u96c6\uff08\u5305\u542b\u8bba\u6587\u6458\u8981\u548c\u4f5c\u8005\u64b0\u5199\u7684\u9ad8\u4eae\u5bf9\uff09\u300212\u652f\u56e2\u961f\u53c2\u4e0e\u9996\u5c4a\u6bd4\u8d5b\uff0c\u63a2\u7d22\u4e86\u5305\u62ec\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u5185\u7684\u591a\u79cd\u65b9\u6cd5\u3002\u6240\u6709\u63d0\u4ea4\u90fd\u4f7f\u7528ROUGE\u3001METEOR\u548cBERTScore\u7b49\u6807\u51c6\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e3b\u8981\u57fa\u4e8eROUGE-L\u5206\u6570\u8fdb\u884c\u6392\u540d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u81ea\u52a8\u751f\u6210\u7684\u9ad8\u4eae\u80fd\u591f\u6709\u6548\u6355\u6349\u8bba\u6587\u7684\u5173\u952e\u8d21\u732e\u3001\u53d1\u73b0\u548c\u65b0\u9896\u6027\u3002\u81ea\u52a8\u751f\u6210\u9ad8\u4eae\u53ef\u4ee5\u51cf\u5c11\u9605\u8bfb\u8d1f\u62c5\uff0c\u52a0\u901f\u6587\u732e\u7efc\u8ff0\uff0c\u5e76\u589e\u5f3a\u6570\u5b57\u56fe\u4e66\u9986\u548c\u5b66\u672f\u641c\u7d22\u5e73\u53f0\u7684\u5143\u6570\u636e\u3002SciHigh\u4e3a\u4ece\u79d1\u5b66\u5199\u4f5c\u4e2d\u751f\u6210\u7b80\u6d01\u51c6\u786e\u9ad8\u4eae\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u3002", "conclusion": "SciHigh\u8d5b\u9053\u6210\u529f\u5efa\u7acb\u4e86\u4ece\u79d1\u5b66\u8bba\u6587\u6458\u8981\u81ea\u52a8\u751f\u6210\u8981\u70b9\u5f0f\u9ad8\u4eae\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u81ea\u52a8\u751f\u6210\u9ad8\u4eae\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u5e2e\u52a9\u8bfb\u8005\u5feb\u901f\u7406\u89e3\u8bba\u6587\u6838\u5fc3\u5185\u5bb9\u3002\u8be5\u8d5b\u9053\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u6709\u6548\u7684\u79d1\u5b66\u4fe1\u606f\u63d0\u53d6\u548c\u603b\u7ed3\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13436", "categories": ["stat.ML", "cs.LG", "eess.SP", "eess.SY", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13436", "abs": "https://arxiv.org/abs/2601.13436", "authors": ["Szabolcs Szentp\u00e9teri", "Bal\u00e1zs Csan\u00e1d Cs\u00e1ji"], "title": "Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds", "comment": null, "summary": "Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments.", "AI": {"tldr": "\u5c06SPS EOA\u7b97\u6cd5\u6269\u5c55\u5230\u5cad\u56de\u5f52\uff0c\u63a8\u5bfc\u7f6e\u4fe1\u533a\u57df\u5927\u5c0f\u7684PAC\u4e0a\u754c\uff0c\u5206\u6790\u6b63\u5219\u5316\u53c2\u6570\u5bf9\u533a\u57df\u5927\u5c0f\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u8f83\u5f31\u6fc0\u52b1\u6761\u4ef6\u4e0b\u63d0\u4f9b\u66f4\u7d27\u7684\u754c", "motivation": "\u7ebf\u6027\u53c2\u6570\u5316\u6a21\u578b\u5728\u63a7\u5236\u548c\u4fe1\u53f7\u5904\u7406\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u8f93\u5165\u6fc0\u52b1\u4e0d\u8db3\u65f6\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u53ef\u80fd\u65e0\u6cd5\u6c42\u89e3\u6216\u4e0d\u7a33\u5b9a\u3002\u867d\u7136\u6b63\u5219\u5316\uff08\u5982\u5cad\u56de\u5f52\uff09\u53ef\u4ee5\u51cf\u5c11\u65b9\u5dee\u8bef\u5dee\uff0c\u4f46\u4ecd\u9700\u91cf\u5316\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002\u73b0\u6709SPS EOA\u7b97\u6cd5\u53ef\u6784\u5efa\u975e\u6e10\u8fd1\u7f6e\u4fe1\u692d\u7403\uff0c\u4f46\u9700\u8981\u6269\u5c55\u5230\u5cad\u56de\u5f52\u573a\u666f\u3002", "method": "\u6269\u5c55SPS EOA\u7b97\u6cd5\u5230\u5cad\u56de\u5f52\uff0c\u63a8\u5bfc\u6240\u5f97\u7f6e\u4fe1\u533a\u57df\u5927\u5c0f\u7684PAC\uff08\u6982\u7387\u8fd1\u4f3c\u6b63\u786e\uff09\u4e0a\u754c\u3002\u5206\u6790\u6b63\u5219\u5316\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u533a\u57df\u5927\u5c0f\uff0c\u5728\u8f83\u5f31\u6fc0\u52b1\u6761\u4ef6\u4e0b\u63d0\u4f9b\u66f4\u7d27\u7684\u754c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u6b63\u5219\u5316\u7684\u5b9e\u9645\u6548\u679c\u3002", "result": "\u6210\u529f\u5c06SPS EOA\u7b97\u6cd5\u6269\u5c55\u5230\u5cad\u56de\u5f52\uff0c\u83b7\u5f97\u4e86\u7f6e\u4fe1\u533a\u57df\u5927\u5c0f\u7684PAC\u4e0a\u754c\u3002\u76f8\u6bd4\u5148\u524d\u5206\u6790\uff0c\u65b0\u7ed3\u679c\u660e\u786e\u5c55\u793a\u4e86\u6b63\u5219\u5316\u53c2\u6570\u5bf9\u533a\u57df\u5927\u5c0f\u7684\u5f71\u54cd\uff0c\u5728\u8f83\u5f31\u6fc0\u52b1\u6761\u4ef6\u4e0b\u63d0\u4f9b\u4e86\u66f4\u7d27\u7684\u754c\u3002\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6b63\u5219\u5316\u7684\u5b9e\u9645\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u5c06SPS EOA\u6269\u5c55\u5230\u5cad\u56de\u5f52\uff0c\u63d0\u4f9b\u4e86\u7f6e\u4fe1\u533a\u57df\u5927\u5c0f\u7684\u7406\u8bba\u4fdd\u8bc1\u3002\u65b0\u5206\u6790\u63ed\u793a\u4e86\u6b63\u5219\u5316\u53c2\u6570\u4e0e\u7f6e\u4fe1\u533a\u57df\u5927\u5c0f\u7684\u660e\u786e\u5173\u7cfb\uff0c\u5728\u8f83\u5f31\u6fc0\u52b1\u6761\u4ef6\u4e0b\u83b7\u5f97\u4e86\u66f4\u7d27\u7684\u754c\uff0c\u4e3a\u5cad\u56de\u5f52\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.11795", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11795", "abs": "https://arxiv.org/abs/2601.11795", "authors": ["Qi Wang", "Christian Piermarini", "Yunlang Zhu", "Frank E. Curtis"], "title": "Projected Stochastic Momentum Methods for Nonlinear Equality-Constrained Optimization for Machine Learning", "comment": null, "summary": "Two algorithms are proposed, analyzed, and tested for solving continuous optimization problems with nonlinear equality constraints. Each is an extension of a stochastic momentum-based method from the unconstrained setting to the setting of a stochastic Newton-SQP-type algorithm for solving equality-constrained problems. One is an extension of the heavy-ball method and the other is an extension of the Adam optimization method. Convergence guarantees for the algorithms for the constrained setting are provided that are on par with state-of-the-art guarantees for their unconstrained counterparts. A critical feature of each extension is that the momentum terms are implemented with projected gradient estimates, rather than with the gradient estimates themselves. The significant practical effect of this choice is seen in an extensive set of numerical experiments on solving informed supervised machine learning problems. These experiments also show benefits of employing a constrained approach to supervised machine learning rather than a typical regularization-based approach.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u52a8\u91cf\u7684\u968f\u673a\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5e26\u975e\u7ebf\u6027\u7b49\u5f0f\u7ea6\u675f\u7684\u8fde\u7eed\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6295\u5f71\u68af\u5ea6\u4f30\u8ba1\u5b9e\u73b0\u52a8\u91cf\u9879\uff0c\u5728\u76d1\u7763\u673a\u5668\u5b66\u4e60\u4e2d\u4f18\u4e8e\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "motivation": "\u5c06\u65e0\u7ea6\u675f\u4f18\u5316\u4e2d\u7684\u968f\u673a\u52a8\u91cf\u65b9\u6cd5\u6269\u5c55\u5230\u5e26\u7b49\u5f0f\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u4e3a\u76d1\u7763\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u6bd4\u6b63\u5219\u5316\u65b9\u6cd5\u66f4\u4f18\u7684\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u6269\u5c55\u4e86\u4e24\u79cd\u968f\u673a\u52a8\u91cf\u65b9\u6cd5\uff1aheavy-ball\u65b9\u6cd5\u548cAdam\u65b9\u6cd5\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u968f\u673a\u725b\u987f-SQP\u578b\u7b97\u6cd5\uff0c\u5173\u952e\u521b\u65b0\u662f\u4f7f\u7528\u6295\u5f71\u68af\u5ea6\u4f30\u8ba1\u800c\u975e\u539f\u59cb\u68af\u5ea6\u4f30\u8ba1\u6765\u5b9e\u73b0\u52a8\u91cf\u9879\u3002", "result": "\u4e3a\u7ea6\u675f\u8bbe\u7f6e\u63d0\u4f9b\u4e86\u4e0e\u65e0\u7ea6\u675f\u5bf9\u5e94\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u5728\u5927\u91cf\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6570\u503c\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u7ea6\u675f\u65b9\u6cd5\u4f18\u4e8e\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6295\u5f71\u68af\u5ea6\u4f30\u8ba1\u7684\u52a8\u91cf\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5e26\u7b49\u5f0f\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5728\u76d1\u7763\u673a\u5668\u5b66\u4e60\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\uff0c\u4e3a\u7ea6\u675f\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.11579", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11579", "abs": "https://arxiv.org/abs/2601.11579", "authors": ["Krzysztof Ociepa", "\u0141ukasz Flis", "Remigiusz Kinas", "Krzysztof Wr\u00f3bel", "Adrian Gwo\u017adziej"], "title": "Bielik 11B v3: Multilingual Large Language Model for European Languages", "comment": null, "summary": "We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.\n  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.\n  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.", "AI": {"tldr": "Bielik 11B v3 \u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u6ce2\u5170\u8bed\u4f18\u5316\u7684\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e Mistral 7B v0.2 \u67b6\u6784\u6269\u5c55\u81f3110\u4ebf\u53c2\u6570\uff0c\u5728\u6ce2\u5170\u8bed\u4efb\u52a1\u4e0a\u8868\u73b0\u5353\u8d8a\uff0c\u751a\u81f3\u8d85\u8d8a\u53c2\u6570\u89c4\u6a21\u59272-6\u500d\u7684\u6a21\u578b\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9488\u5bf9\u6ce2\u5170\u8bed\u9ad8\u5ea6\u4f18\u5316\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5176\u4ed6\u6b27\u6d32\u8bed\u8a00\u7684\u826f\u597d\u652f\u6301\uff0c\u4e3a\u8d44\u6e90\u8f83\u5c11\u8bed\u8a00\u5efa\u7acb\u9ad8\u6548\u9ad8\u6027\u80fd\u6a21\u578b\u7684\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u8fde\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u3002\u57fa\u4e8e Mistral 7B v0.2 \u67b6\u6784\uff0c\u901a\u8fc7\u6df1\u5ea6\u6269\u5c55\u6269\u5c55\u5230110\u4ebf\u53c2\u6570\u3002", "result": "Bielik 11B v3 \u5728\u6ce2\u5170\u8bed\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u5176\u4ed6\u4e13\u95e8\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u53c2\u6570\u89c4\u6a21\u59272-6\u500d\u7684\u66f4\u5927\u6a21\u578b\uff0c\u4ece\u57fa\u7840\u8bed\u8a00\u7406\u89e3\u5230\u590d\u6742\u63a8\u7406\u90fd\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u6ce2\u5170\u8bed\u7684AI\u80fd\u529b\uff0c\u8fd8\u4e3a\u5f00\u53d1\u8d44\u6e90\u9ad8\u6548\u3001\u9ad8\u6027\u80fd\u7684\u8f83\u5c11\u4ee3\u8868\u8bed\u8a00\u6a21\u578b\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u5176\u53c2\u6570\u6548\u7387\u548c\u91cf\u5316\u9009\u9879\u652f\u6301\u5728\u5404\u79cd\u786c\u4ef6\u914d\u7f6e\u4e0a\u6709\u6548\u90e8\u7f72\u3002"}}
{"id": "2601.11609", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11609", "abs": "https://arxiv.org/abs/2601.11609", "authors": ["Weinuo Ou"], "title": "Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction", "comment": "9 pages, 7 figures", "summary": "Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).", "AI": {"tldr": "\u63d0\u51faApCM\u6a21\u578b\u89e3\u51b3LLMs\u7f3a\u4e4f\u8fd0\u884c\u65f6\u8bb0\u5fc6\u673a\u5236\u7684\u95ee\u9898", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u6709\u6548\u7684\u8fd0\u884c\u65f6\u8bb0\u5fc6\u673a\u5236\uff0c\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u548c\u4e2a\u6027\u5316\u7684\u4ea4\u4e92\u9700\u6c42", "method": "\u63d0\u51fa\u65b0\u578b\u795e\u7ecf\u8bb0\u5fc6\u5b58\u50a8\u67b6\u6784\u2014\u2014\u8f85\u52a9\u9884\u6d4b\u538b\u7f29\u8bb0\u5fc6\u6a21\u578b\uff08ApCM\u6a21\u578b\uff09", "result": "\u4ece\u6458\u8981\u4e2d\u65e0\u6cd5\u5f97\u77e5\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c", "conclusion": "ApCM\u6a21\u578b\u65e8\u5728\u89e3\u51b3LLMs\u7684\u8bb0\u5fc6\u673a\u5236\u95ee\u9898\uff0c\u63d0\u5347\u9002\u5e94\u52a8\u6001\u4e2a\u6027\u5316\u4ea4\u4e92\u7684\u80fd\u529b"}}
{"id": "2601.11792", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11792", "abs": "https://arxiv.org/abs/2601.11792", "authors": ["Yifei Sun", "Yongan Li", "A. K. Qin", "Sicheng Hou", "Tamas Pflanzner"], "title": "A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation", "comment": null, "summary": "Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u521b\u65b0\u6570\u5b66\u95ee\u9898\u751f\u6210(IMPG)\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u6f14\u8fdb\u591a\u89d2\u8272\u534f\u4f5c\u6846\u67b6\u548c\u7ec6\u7c92\u5ea6\u96be\u5ea6\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u95ee\u9898\u7684\u521b\u65b0\u6027\u540c\u65f6\u4fdd\u6301\u9ad8\u6b63\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u751f\u6210\u4e2d\u867d\u7136\u6b63\u786e\u7387\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u521b\u65b0\u6027\u548c\u533a\u5206\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u521b\u65b0\u6570\u5b66\u95ee\u9898\u751f\u6210(IMPG)\u8fd9\u4e00\u65b0\u4efb\u52a1\u3002", "method": "1) \u6784\u5efa\u5305\u542b\u91c7\u6837\u5668\u3001\u751f\u6210\u5668\u3001\u8bc4\u4f30\u5668\u3001\u72b6\u6001\u673a\u548c\u8bb0\u5fc6\u7684\u591a\u89d2\u8272\u534f\u4f5c\u673a\u5236\uff0c\u901a\u8fc7\u81ea\u8bc4\u4f30\u548c\u5916\u90e8\u53cd\u9988\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff1b2) \u5f15\u5165\u6539\u8fdb\u96be\u5ea6\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u6307\u5bfc\uff0c\u91c7\u7528DAPS\u7b97\u6cd5\u589e\u5f3a\u91c7\u6837\u7f16\u7801\u7684\u8bed\u4e49\u5408\u7406\u6027\uff1b3) \u6784\u5efaHSM3K-CN\u6570\u636e\u96c6\uff0c\u91c7\u7528CPT\u3001SFT\u548cGRPO\u591a\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1b4) \u901a\u8fc7\u84b8\u998f\u5c06\u4e13\u5bb6\u6a21\u578b\u8bc4\u4f30\u80fd\u529b\u8f6c\u79fb\u5230\u5b66\u5f92\u6a21\u578b\u5b9e\u73b0\u7cfb\u7edf\u81ea\u6f14\u8fdb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6b63\u786e\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u95ee\u9898\u7684\u521b\u65b0\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u6f14\u8fdb\u591a\u89d2\u8272\u534f\u4f5c\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3IMPG\u4efb\u52a1\uff0c\u5728\u521b\u65b0\u6027\u548c\u6b63\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u667a\u80fd\u6559\u80b2\u4e2d\u7684\u6570\u5b66\u95ee\u9898\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.12070", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12070", "abs": "https://arxiv.org/abs/2601.12070", "authors": ["Ruslan Zakirzyanov"], "title": "A method for optimizing the structure of the software and hardware complex of a distributed process control system for large industrial enterprises", "comment": null, "summary": "The article proposes a method for optimizing the structure of the software and hardware complex of an automated control system for continuous technological processes for large industrial enterprises. General information is given on the relevance of the problem of choosing the structure of a system built on the basis of serially produced components, a formal description of the optimization problem is given, the criterion and limitations are highlighted. A solution method using the metaheuristic algorithm of ant colonies is described. A numerical example of the solution is given, the results of the algorithm are analyzed, and directions for further research are determined.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u8681\u7fa4\u7b97\u6cd5\u4f18\u5316\u5927\u578b\u5de5\u4e1a\u4f01\u4e1a\u8fde\u7eed\u8fc7\u7a0b\u81ea\u52a8\u5316\u63a7\u5236\u7cfb\u7edf\u8f6f\u786c\u4ef6\u7ed3\u6784\u7684\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u6279\u91cf\u751f\u4ea7\u7ec4\u4ef6\u6784\u5efa\u7684\u7cfb\u7edf\u7ed3\u6784\u9009\u62e9\u95ee\u9898\uff0c\u4f18\u5316\u5927\u578b\u5de5\u4e1a\u4f01\u4e1a\u8fde\u7eed\u8fc7\u7a0b\u81ea\u52a8\u5316\u63a7\u5236\u7cfb\u7edf\u7684\u8f6f\u786c\u4ef6\u914d\u7f6e", "method": "\u4f7f\u7528\u8681\u7fa4\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5efa\u7acb\u5f62\u5f0f\u5316\u4f18\u5316\u95ee\u9898\u63cf\u8ff0\uff0c\u5b9a\u4e49\u4f18\u5316\u51c6\u5219\u548c\u7ea6\u675f\u6761\u4ef6", "result": "\u63d0\u4f9b\u4e86\u6570\u503c\u6c42\u89e3\u793a\u4f8b\uff0c\u5206\u6790\u4e86\u7b97\u6cd5\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u8681\u7fa4\u7b97\u6cd5\u9002\u7528\u4e8e\u81ea\u52a8\u5316\u63a7\u5236\u7cfb\u7edf\u7ed3\u6784\u4f18\u5316\uff0c\u786e\u5b9a\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u65b9\u5411"}}
{"id": "2601.11583", "categories": ["cs.CY", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11583", "abs": "https://arxiv.org/abs/2601.11583", "authors": ["Xing Yang"], "title": "Bit-politeia: An AI Agent Community in Blockchain", "comment": null, "summary": "Current resource allocation paradigms, particularly in academic evaluation, are constrained by inherent limitations such as the Matthew Effect, reward hacking driven by Goodhart's Law, and the trade-off between efficiency and fairness. To address these challenges, this paper proposes \"Bit-politeia\", an AI agent community on blockchain designed to construct a fair, efficient, and sustainable resource allocation system. In this virtual community, residents interact via AI agents serving as their exclusive proxies, which are optimized for impartiality and value alignment. The community adopts a \"clustered grouping + hierarchical architecture\" that integrates democratic centralism to balance decision-making efficiency and trust mechanisms. Agents engage through casual chat and deliberative interactions to evaluate research outputs and distribute a virtual currency as rewards. This incentive mechanism aims to achieve incentive compatibility through consensus-driven evaluation, while blockchain technology ensures immutable records of all transactions and reputation data. By leveraging AI for objective assessment and decentralized verification, Bit-politeia minimizes human bias and mitigates resource centralization issues found in traditional peer review. The proposed framework provides a novel pathway for optimizing scientific innovation through a fair and automated resource configuration process.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u533a\u5757\u94fe\u7684AI\u4ee3\u7406\u793e\u533aBit-politeia\uff0c\u901a\u8fc7AI\u4ee3\u7406\u4f5c\u4e3a\u5c45\u6c11\u4ee3\u8868\uff0c\u7ed3\u5408\u6c11\u4e3b\u96c6\u4e2d\u5236\u548c\u5171\u8bc6\u9a71\u52a8\u8bc4\u4f30\uff0c\u6784\u5efa\u516c\u5e73\u3001\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u7684\u5b66\u672f\u8d44\u6e90\u5206\u914d\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u5b66\u672f\u8bc4\u4ef7\u4e2d\u5b58\u5728\u7684\u9a6c\u592a\u6548\u5e94\u3001\u53e4\u5fb7\u54c8\u7279\u5b9a\u5f8b\u5bfc\u81f4\u7684\u5956\u52b1\u64cd\u7eb5\u3001\u6548\u7387\u4e0e\u516c\u5e73\u96be\u4ee5\u517c\u987e\u7b49\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u51cf\u5c11\u4eba\u4e3a\u504f\u89c1\u548c\u8d44\u6e90\u96c6\u4e2d\u5316\u95ee\u9898\u3002", "method": "\u6784\u5efa\u533a\u5757\u94fe\u4e0a\u7684AI\u4ee3\u7406\u793e\u533a\uff0c\u91c7\u7528\"\u805a\u7c7b\u5206\u7ec4+\u5206\u5c42\u67b6\u6784\"\u7ed3\u5408\u6c11\u4e3b\u96c6\u4e2d\u5236\uff0cAI\u4ee3\u7406\u901a\u8fc7\u95f2\u804a\u548c\u5ba1\u8bae\u4e92\u52a8\u8bc4\u4f30\u7814\u7a76\u6210\u679c\uff0c\u4f7f\u7528\u865a\u62df\u8d27\u5e01\u5956\u52b1\u673a\u5236\uff0c\u533a\u5757\u94fe\u8bb0\u5f55\u6240\u6709\u4ea4\u6613\u548c\u58f0\u8a89\u6570\u636e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7AI\u5ba2\u89c2\u8bc4\u4f30\u548c\u53bb\u4e2d\u5fc3\u5316\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u6fc0\u52b1\u76f8\u5bb9\u7684\u5171\u8bc6\u9a71\u52a8\u8bc4\u4f30\uff0c\u4e3a\u4f18\u5316\u79d1\u5b66\u521b\u65b0\u63d0\u4f9b\u81ea\u52a8\u5316\u8d44\u6e90\u914d\u7f6e\u9014\u5f84\u3002", "conclusion": "Bit-politeia\u901a\u8fc7AI\u4ee3\u7406\u548c\u533a\u5757\u94fe\u6280\u672f\uff0c\u4e3a\u5b66\u672f\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u516c\u5e73\u3001\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u7684\u65b0\u8303\u5f0f\uff0c\u80fd\u591f\u51cf\u5c11\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u504f\u89c1\u548c\u8d44\u6e90\u96c6\u4e2d\u95ee\u9898\u3002"}}
{"id": "2601.13458", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.13458", "abs": "https://arxiv.org/abs/2601.13458", "authors": ["Zihan Dong", "Ruijia Wu", "Linjun Zhang"], "title": "Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs", "comment": null, "summary": "The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.", "AI": {"tldr": "\u63d0\u51faPCAL\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u53c2\u6570\u63a8\u65ad\u5c06\u6807\u6ce8\u9884\u7b97\u5206\u914d\u95ee\u9898\u8f6c\u5316\u4e3a\u5355\u8c03\u7f3a\u5931\u6570\u636e\u6846\u67b6\uff0c\u4f18\u5316\u5730\u9762\u771f\u503c\u6807\u7b7e\u4e0e\u6210\u5bf9\u504f\u597d\u7684\u9884\u7b97\u5206\u914d\uff0c\u5b9e\u73b0\u7edf\u8ba1\u9ad8\u6548\u4f30\u8ba1\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u4f2a\u6807\u7b7e\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4eba\u7c7b\u504f\u597d\u53cd\u9988\uff0c\u9700\u8981\u539f\u5219\u6027\u7684\u3001\u9884\u7b97\u610f\u8bc6\u7684\u6570\u636e\u83b7\u53d6\u7b56\u7565\u3002\u5173\u952e\u95ee\u9898\u662f\u5982\u4f55\u5728\u6709\u9650\u6807\u6ce8\u9884\u7b97\u4e0b\uff0c\u6700\u4f18\u5206\u914d\u5730\u9762\u771f\u503c\u6807\u7b7e\u548c\u6210\u5bf9\u504f\u597d\u6570\u636e\u3002", "method": "\u57fa\u4e8e\u534a\u53c2\u6570\u63a8\u65ad\uff0c\u5c06\u9884\u7b97\u5206\u914d\u95ee\u9898\u6784\u5efa\u4e3a\u5355\u8c03\u7f3a\u5931\u6570\u636e\u6846\u67b6\u3002\u63d0\u51fa\u504f\u597d\u6821\u51c6\u4e3b\u52a8\u5b66\u4e60(PCAL)\u65b9\u6cd5\uff0c\u5b66\u4e60\u6700\u4f18\u6570\u636e\u83b7\u53d6\u7b56\u7565\uff0c\u5e76\u5f00\u53d1\u7edf\u8ba1\u9ad8\u6548\u4f30\u8ba1\u5668\u3002\u901a\u8fc7\u76f4\u63a5\u4f18\u5316\u4f30\u8ba1\u5668\u65b9\u5dee\u800c\u975e\u8981\u6c42\u95ed\u5f0f\u89e3\uff0c\u9002\u7528\u4e8e\u4e00\u822c\u95ee\u9898\u7c7b\u522b\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660ePCAL\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u6700\u4f18\u6027\uff0c\u5e76\u5efa\u7acb\u5173\u952e\u9c81\u68d2\u6027\u4fdd\u8bc1\uff0c\u5373\u4f7f\u5728\u8f85\u52a9\u6a21\u578b\u4f30\u8ba1\u4e0d\u4f73\u65f6\u4e5f\u80fd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5206\u6790\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u4f18\u52bf\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u4e3a\u73b0\u4ee3AI\u4e2d\u7684\u9884\u7b97\u7ea6\u675f\u5b66\u4e60\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u4e14\u7edf\u8ba1\u9ad8\u6548\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u6807\u6ce8\u9884\u7b97\u5728\u771f\u5b9e\u6807\u7b7e\u4e0e\u504f\u597d\u53cd\u9988\u4e4b\u95f4\u7684\u6700\u4f18\u5206\u914d\u95ee\u9898\u3002"}}
{"id": "2601.11826", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11826", "abs": "https://arxiv.org/abs/2601.11826", "authors": ["Young-Ju Lee", "Jongho Park"], "title": "A high-order augmented Lagrangian method with arbitrarily fast convergence", "comment": "22 pages, 7 figures", "summary": "We propose a high-order version of the augmented Lagrangian method for solving convex optimization problems with linear constraints, which achieves arbitrarily fast -- and even superlinear -- convergence rates. First, we analyze the convergence rates of the high-order proximal point method under certain uniform convexity assumptions on the energy functional. We then introduce the high-order augmented Lagrangian method and analyze its convergence by leveraging the convergence results of the high-order proximal point method. Finally, we present applications of the high-order augmented Lagrangian method to various problems arising in the sciences, including data fitting, flow in porous media, and scientific machine learning.", "AI": {"tldr": "\u63d0\u51fa\u9ad8\u9636\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\uff0c\u7528\u4e8e\u6c42\u89e3\u5e26\u7ebf\u6027\u7ea6\u675f\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u53ef\u5b9e\u73b0\u4efb\u610f\u5feb\u901f\u751a\u81f3\u8d85\u7ebf\u6027\u6536\u655b\u901f\u7387\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u5e26\u7ea6\u675f\u7684\u51f8\u4f18\u5316\u95ee\u9898\u65f6\u6536\u655b\u901f\u5ea6\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\u901f\u7387\u7684\u9ad8\u9636\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u7b49\u5e94\u7528\u4e2d\u3002", "method": "\u9996\u5148\u5206\u6790\u9ad8\u9636\u90bb\u8fd1\u70b9\u65b9\u6cd5\u5728\u80fd\u91cf\u6cdb\u51fd\u6ee1\u8db3\u4e00\u81f4\u51f8\u6027\u5047\u8bbe\u4e0b\u7684\u6536\u655b\u901f\u7387\uff0c\u7136\u540e\u5f15\u5165\u9ad8\u9636\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u9ad8\u9636\u90bb\u8fd1\u70b9\u65b9\u6cd5\u7684\u6536\u655b\u7ed3\u679c\u6765\u5206\u6790\u5176\u6536\u655b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4efb\u610f\u5feb\u901f\u751a\u81f3\u8d85\u7ebf\u6027\u7684\u6536\u655b\u901f\u7387\uff0c\u9002\u7528\u4e8e\u6570\u636e\u62df\u5408\u3001\u591a\u5b54\u4ecb\u8d28\u6d41\u52a8\u548c\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u7b49\u591a\u79cd\u79d1\u5b66\u95ee\u9898\u3002", "conclusion": "\u9ad8\u9636\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u4e3a\u5e26\u7ebf\u6027\u7ea6\u675f\u7684\u51f8\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u6c42\u89e3\u6846\u67b6\uff0c\u5177\u6709\u5feb\u901f\u6536\u655b\u7279\u6027\uff0c\u5728\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2601.11580", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11580", "abs": "https://arxiv.org/abs/2601.11580", "authors": ["Xiaoxuan Liu", "Jiaxiang Yu", "Jongseok Park", "Ion Stoica", "Alvin Cheung"], "title": "Speculative Decoding: Performance or Illusion?", "comment": null, "summary": "Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728\u771f\u5b9e\u751f\u4ea7\u7ea7\u63a8\u7406\u5f15\u64ce(vLLM)\u4e0a\u7cfb\u7edf\u7814\u7a76\u4e86\u63a8\u6d4b\u89e3\u7801(SD)\u6280\u672f\uff0c\u5206\u6790\u4e86\u591a\u79cdSD\u53d8\u4f53\u5728\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u9a8c\u8bc1\u9636\u6bb5\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u5b9e\u9645\u6027\u80fd\u4e0e\u7406\u8bba\u4e0a\u9650\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u63a8\u6d4b\u89e3\u7801\u5df2\u6210\u4e3a\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6d41\u884c\u6280\u672f\uff0c\u4f46\u5148\u524d\u8bc4\u4f30\u4f9d\u8d56\u7814\u7a76\u539f\u578b\u548c\u4e0d\u5207\u5b9e\u9645\u7684\u5c0f\u6279\u91cf\u5927\u5c0f\uff0c\u5176\u771f\u5b9e\u4e16\u754c\u6709\u6548\u6027\u4ecd\u4e0d\u6e05\u695a\u3002\u9700\u8981\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30SD\u6027\u80fd\u3002", "method": "\u5728\u5e7f\u6cdb\u90e8\u7f72\u7684\u751f\u4ea7\u7ea7\u63a8\u7406\u5f15\u64cevLLM\u4e0a\u8fdb\u884c\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\uff0c\u6db5\u76d6\u591a\u79cdSD\u53d8\u4f53(n-gram\u3001EAGLE/EAGLE-3\u3001Draft-Model\u3001Multi-Token Prediction)\uff0c\u8986\u76d6\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u3001\u6a21\u578b\u89c4\u6a21\u548c\u6279\u91cf\u5927\u5c0f\u3002\u5206\u6790\u5f71\u54cdSD\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u91cf\u5316SD\u52a0\u901f\u7684\u7406\u8bba\u4e0a\u9650\u3002", "result": "\u7ed3\u679c\u663e\u793a\u76ee\u6807\u6a21\u578b\u7684\u9a8c\u8bc1\u9636\u6bb5\u4e3b\u5bfc\u6267\u884c\u65f6\u95f4\uff0c\u63a5\u53d7\u957f\u5ea6\u5728\u4e0d\u540c\u8f93\u51fatoken\u4f4d\u7f6e\u3001\u8bf7\u6c42\u548c\u6570\u636e\u96c6\u95f4\u5dee\u5f02\u663e\u8457\u3002\u5b9e\u6d4b\u6027\u80fd\u4e0e\u7406\u8bba\u4e0a\u9650\u6bd4\u8f83\u663e\u793a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5b9e\u9645\u52a0\u901f\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u63a8\u6d4b\u89e3\u7801\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u9a8c\u8bc1\u9636\u6bb5\u662f\u4e3b\u8981\u9650\u5236\u56e0\u7d20\u3002\u5b9e\u6d4b\u4e0e\u7406\u8bba\u6027\u80fd\u7684\u5dee\u8ddd\u4e3a\u6539\u8fdbSD\u6280\u672f\u6307\u660e\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u4f18\u5316\u9a8c\u8bc1\u8fc7\u7a0b\u548c\u63d0\u5347\u63a5\u53d7\u7387\u7b49\u3002"}}
{"id": "2601.11611", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11611", "abs": "https://arxiv.org/abs/2601.11611", "authors": ["Marina Vicini", "Martin Rudorfer", "Zhuangzhuang Dai", "Luis J. Manso"], "title": "Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home", "comment": "Accepted to International Conference on Ubiquitous Computing and Ambient Intelligence (UCAmI) 2024", "summary": "With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u88ab\u52a8\u4f20\u611f\u5668\u7684\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u95f4\u805a\u7c7b\u548c\u5faa\u73af\u65f6\u95f4\u7279\u5f81\u589e\u5f3a\u7279\u5f81\u52a0\u6743\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5168\u7403\u4eba\u53e3\u8001\u9f84\u5316\uff0c\u9700\u8981\u652f\u6301\u8001\u5e74\u4eba\u5728\u5bb6\u4e2d\u72ec\u7acb\u5b89\u5168\u751f\u6d3b\u3002\u4f7f\u7528\u88ab\u52a8\u7ea2\u5916\u4f20\u611f\u5668\u548c\u95e8\u4f20\u611f\u5668\u76d1\u6d4b\u65e5\u5e38\u6d3b\u52a8\u5bf9\u9884\u9632\u6027\u533b\u7597\u5e72\u9884\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6709\u6548\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "1) \u5c06\u6d3b\u52a8\u805a\u7c7b\u4e3a\u65e9\u6668\u3001\u4e0b\u5348\u548c\u665a\u4e0a\uff0c\u8ba1\u7b97\u4e0d\u540c\u7684\u4e92\u4fe1\u606f\u77e9\u9635\u8fdb\u884c\u7279\u5f81\u52a0\u6743\uff1b2) \u6269\u5c55\u7279\u5f81\u5411\u91cf\uff0c\u52a0\u5165\u4e00\u5929\u4e2d\u7684\u65f6\u95f4\u548c\u4e00\u5468\u4e2d\u7684\u5929\u4f5c\u4e3a\u5faa\u73af\u65f6\u95f4\u7279\u5f81\uff1b3) \u6dfb\u52a0\u7528\u6237\u4f4d\u7f6e\u8ddf\u8e2a\u7279\u5f81\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u4e09\u4e2a\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u5728\u4f4e\u6570\u636e\u91cf\u60c5\u51b5\u4e0b\u63d0\u5347\u6700\u660e\u663e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5f00\u53d1\u6709\u6548\u667a\u80fd\u5bb6\u5c45\u89e3\u51b3\u65b9\u6848\u652f\u6301\"\u539f\u5730\u517b\u8001\"\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u6574\u5408\u65f6\u95f4\u548c\u7a7a\u95f4\u4fe1\u606f\u6539\u8fdb\u4e86\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u3002"}}
{"id": "2601.11809", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11809", "abs": "https://arxiv.org/abs/2601.11809", "authors": ["Zeyu Mu", "Shangtong Zhang", "B. Brian Park"], "title": "Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic", "comment": "Under review at IEEE Transactions on Intelligent Transportation Systems", "summary": "Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCNN-QMIX\u7684\u6df7\u5408\u591a\u667a\u80fd\u4f53\u6362\u9053\u51b3\u7b56\u6a21\u578b\uff0c\u63d0\u5347CAV\u5728\u6df7\u5408\u4ea4\u901a\u4e2d\u7684\u534f\u540c\u7f16\u961f\u53c2\u4e0e\u7387\uff0c\u4f18\u5316\u65e9\u671f\u90e8\u7f72\u9636\u6bb5\u7684\u4ea4\u901a\u52a8\u6001", "motivation": "\u5728CAV\u90e8\u7f72\u521d\u671f\uff0cCAV\u5728\u4eba\u5de5\u9a7e\u9a76\u8f66\u8f86\u4e2d\u5206\u5e03\u7a00\u758f\uff0c\u96be\u4ee5\u5f62\u6210\u6709\u6548\u7684\u534f\u540c\u7f16\u961f\uff0c\u9650\u5236\u4e86\u80fd\u6548\u548c\u4ea4\u901a\u6d41\u4f18\u5316\u6548\u76ca", "method": "\u91c7\u7528QMIX\u6846\u67b6\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u4ea4\u901a\u6570\u636e\uff08CNN-QMIX\uff09\uff0c\u8bbe\u8ba1\u8f68\u8ff9\u89c4\u5212\u5668\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\uff0c\u786e\u4fdd\u5e73\u6ed1\u5b89\u5168\u7684\u6362\u9053\u6267\u884c", "result": "\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u52a8\u6001\u53d8\u5316\u7684\u4ea4\u901a\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5c06\u534f\u540c\u7f16\u961f\u7387\u63d0\u5347\u9ad8\u8fbe26.2%", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u591a\u667a\u80fd\u4f53\u6362\u9053\u51b3\u7b56\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347CAV\u5728\u6df7\u5408\u4ea4\u901a\u4e2d\u7684\u534f\u540c\u7f16\u961f\u53c2\u4e0e\uff0c\u4f18\u5316\u65e9\u671f\u90e8\u7f72\u9636\u6bb5\u7684\u4ea4\u901a\u52a8\u6001\u548c\u5408\u4f5c\u6548\u76ca"}}
{"id": "2601.12081", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12081", "abs": "https://arxiv.org/abs/2601.12081", "authors": ["Tom\u00e1s Tapia", "Yury Dvorkin"], "title": "Reachability Guarantees for Energy Arbitrage", "comment": null, "summary": "This paper introduces a unified framework for battery energy arbitrage under uncertain market prices that integrates chance-constrained terminal state-of-charge requirements with online threshold policies. We first cast the multi-interval arbitrage problem as a stochastic dynamic program enhanced by a probabilistic end-of-horizon state-of-charge (SoC) constraint, ensuring with high confidence that the battery terminates within a prescribed energy band. We then apply a $k$-search algorithm to derive explicit charging (buying) and discharging (selling) thresholds with provable worst-case competitive ratio, and compute the corresponding action probabilities over the decision horizon. To compute exact distributions under operational limits, we develop a probability redistribution pruning method and use it to quantify the likelihood of meeting the terminal SoC band. Leveraging the resulting SoC distribution, we estimate the minimum stopping-time required to satisfy the SoC chance constraint. Computational experiments on historical real price data demonstrate that the proposed framework substantially improves the estimation of SoC evolution and supports chance-constraint satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u673a\u4f1a\u7ea6\u675f\u7684\u7ec8\u7aef\u8377\u7535\u72b6\u6001\u8981\u6c42\u4e0e\u5728\u7ebf\u9608\u503c\u7b56\u7565\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u4e0d\u786e\u5b9a\u5e02\u573a\u4ef7\u683c\u4e0b\u7684\u7535\u6c60\u80fd\u91cf\u5957\u5229\u3002", "motivation": "\u5728\u4e0d\u786e\u5b9a\u7684\u5e02\u573a\u4ef7\u683c\u73af\u5883\u4e0b\uff0c\u7535\u6c60\u80fd\u91cf\u5957\u5229\u9700\u8981\u540c\u65f6\u8003\u8651\u7ec8\u7aef\u8377\u7535\u72b6\u6001\u8981\u6c42\u548c\u5728\u7ebf\u51b3\u7b56\u7b56\u7565\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7edf\u4e00\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "1) \u5c06\u591a\u533a\u95f4\u5957\u5229\u95ee\u9898\u5efa\u6a21\u4e3a\u968f\u673a\u52a8\u6001\u89c4\u5212\uff0c\u52a0\u5165\u6982\u7387\u6027\u7ec8\u7aef\u8377\u7535\u72b6\u6001\u7ea6\u675f\uff1b2) \u5e94\u7528k-\u641c\u7d22\u7b97\u6cd5\u63a8\u5bfc\u660e\u786e\u7684\u5145\u653e\u7535\u9608\u503c\uff1b3) \u5f00\u53d1\u6982\u7387\u91cd\u5206\u5e03\u526a\u679d\u65b9\u6cd5\u8ba1\u7b97\u7cbe\u786e\u5206\u5e03\uff1b4) \u5229\u7528\u8377\u7535\u72b6\u6001\u5206\u5e03\u4f30\u8ba1\u6ee1\u8db3\u673a\u4f1a\u7ea6\u675f\u7684\u6700\u5c0f\u505c\u6b62\u65f6\u95f4\u3002", "result": "\u5728\u5386\u53f2\u5b9e\u9645\u4ef7\u683c\u6570\u636e\u4e0a\u7684\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u8377\u7535\u72b6\u6001\u6f14\u5316\u7684\u4f30\u8ba1\uff0c\u5e76\u652f\u6301\u673a\u4f1a\u7ea6\u675f\u7684\u6ee1\u8db3\u3002", "conclusion": "\u8be5\u7edf\u4e00\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u673a\u4f1a\u7ea6\u675f\u7ec8\u7aef\u8377\u7535\u72b6\u6001\u8981\u6c42\u4e0e\u5728\u7ebf\u9608\u503c\u7b56\u7565\uff0c\u4e3a\u4e0d\u786e\u5b9a\u5e02\u573a\u4ef7\u683c\u4e0b\u7684\u7535\u6c60\u80fd\u91cf\u5957\u5229\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11586", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11586", "abs": "https://arxiv.org/abs/2601.11586", "authors": ["Shan Zhang", "Siddhartha Pradhan", "Ji-Eun Lee", "Ashish Gurung", "Anthony F. Botelho"], "title": "Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways", "comment": "16 pages, 7 figures, LAK2026", "summary": "Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u5206\u6790\u6e38\u620f\u5b66\u4e60\u5e73\u53f0\u4e2d\u5b66\u751f\u7684\u91cd\u653e\u884c\u4e3a\u6a21\u5f0f\uff0c\u53d1\u73b0\u5373\u65f6\u91cd\u653e\u5bf9\u5b66\u4e60\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u800c\u5ef6\u8fdf\u91cd\u653e\u6548\u679c\u8f83\u5f31\u6216\u8d1f\u9762\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660e\u5b66\u751f\u5728\u6e38\u620f\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u95ee\u9898\u89e3\u51b3\u8def\u5f84\u53cd\u6620\u4e86\u4ed6\u4eec\u7684\u6982\u5ff5\u7406\u89e3\u3001\u7a0b\u5e8f\u6027\u77e5\u8bc6\u548c\u7075\u6d3b\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u8def\u5f84\u5982\u4f55\u8de8\u95ee\u9898\u5c55\u5f00\u5e8f\u5217\u5316\u5206\u6790\uff0c\u4ee5\u53ca\u91cd\u653e\u65f6\u673a\u4e0e\u5b66\u4e60\u6210\u679c\u7684\u5173\u7cfb\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u5206\u6790777\u540d\u4e03\u5e74\u7ea7\u5b66\u751f\u5728\"From Here to There!\"\u6e38\u620f\u5b66\u4e60\u5e73\u53f0\u4e2d\u7684\u65e5\u5fd7\u6570\u636e\uff0c\u8bc6\u522b\u95ee\u9898\u89e3\u51b3\u8def\u5f84\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u56de\u5f52\u5206\u6790\u68c0\u9a8c\u4e0d\u540c\u72b6\u6001\u4e0e\u5b66\u4e60\u6210\u679c\u7684\u5173\u7cfb\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u79cd\u6f5c\u5728\u72b6\u6001\uff1a\u4e0d\u5b8c\u6574\u4e3b\u5bfc\u3001\u6700\u4f18\u7ed3\u675f\u3001\u91cd\u653e\u548c\u6df7\u5408\u72b6\u6001\u3002\u56de\u5f52\u5206\u6790\u663e\u793a\u91cd\u653e\u4e3b\u5bfc\u548c\u6700\u4f18\u7ed3\u675f\u72b6\u6001\u6bd4\u4e0d\u5b8c\u6574\u4e3b\u5bfc\u72b6\u6001\u9884\u6d4b\u66f4\u9ad8\u7684\u6982\u5ff5\u77e5\u8bc6\u3001\u7075\u6d3b\u6027\u548c\u8868\u73b0\u3002\u5373\u65f6\u91cd\u653e\u59cb\u7ec8\u652f\u6301\u5b66\u4e60\u6210\u679c\uff0c\u800c\u5ef6\u8fdf\u91cd\u653e\u4e0e\u975e\u91cd\u653e\u76f8\u6bd4\u5173\u8054\u8f83\u5f31\u6216\u8d1f\u9762\u3002", "conclusion": "\u6570\u5b57\u5b66\u4e60\u4e2d\u7684\u91cd\u653e\u884c\u4e3a\u5e76\u975e\u666e\u904d\u6709\u76ca\uff0c\u5176\u6548\u679c\u53d6\u51b3\u4e8e\u65f6\u673a\uff0c\u5373\u65f6\u91cd\u653e\u652f\u6301\u7075\u6d3b\u6027\u548c\u66f4\u6709\u6548\u7684\u63a2\u7d22\uff0c\u800c\u5ef6\u8fdf\u91cd\u653e\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2601.13519", "categories": ["stat.ML", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13519", "abs": "https://arxiv.org/abs/2601.13519", "authors": ["Wenzhi Gao", "Chang He", "Madeleine Udell"], "title": "Small Gradient Norm Regret for Online Convex Optimization", "comment": null, "summary": "This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\\sum_{t=1}^T \\|\\nabla \\ell(x^\\star)\\|^2$. We show that the $G^\\star$ regret strictly refines the existing $L^\\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u95ee\u9898\u4f9d\u8d56\u9057\u61be\u5ea6\u91cfG* regret\uff0c\u7528\u4e8e\u5149\u6ed1\u635f\u5931\u7684\u5728\u7ebf\u51f8\u4f18\u5316\uff0c\u5b83\u57fa\u4e8e\u7d2f\u79ef\u5e73\u65b9\u68af\u5ea6\u8303\u6570\uff0c\u6bd4\u73b0\u6709\u7684L* regret\u66f4\u7cbe\u7ec6\uff0c\u5728\u635f\u5931\u51fd\u6570\u5728\u6700\u4f18\u89e3\u9644\u8fd1\u66f2\u7387\u6d88\u5931\u65f6\u80fd\u63d0\u4f9b\u66f4\u5c16\u9510\u7684\u754c\u9650\u3002", "motivation": "\u73b0\u6709\u7684L* regret\uff08\u5c0f\u635f\u5931\u9057\u61be\uff09\u867d\u7136\u63d0\u4f9b\u4e86\u95ee\u9898\u4f9d\u8d56\u7684\u9057\u61be\u754c\u9650\uff0c\u4f46\u5728\u635f\u5931\u51fd\u6570\u5728\u6700\u4f18\u89e3\u9644\u8fd1\u66f2\u7387\u6d88\u5931\u65f6\u53ef\u80fd\u4e0d\u591f\u5c16\u9510\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u7684\u9057\u61be\u5ea6\u91cf\u6765\u66f4\u597d\u5730\u53cd\u6620\u4f18\u5316\u95ee\u9898\u7684\u7279\u6027\u3002", "method": "\u63d0\u51faG* regret\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u2211\u2016\u2207\u2113(x*)\u2016\u00b2\uff0c\u5373\u7d2f\u79ef\u5e73\u65b9\u68af\u5ea6\u8303\u6570\u5728\u4e8b\u540e\u6700\u4f18\u89e3\u5904\u7684\u8bc4\u4f30\u3002\u5efa\u7acbG* regret\u7684\u4e0a\u754c\u548c\u4e0b\u754c\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u52a8\u6001\u9057\u61be\u548cbandit\u8bbe\u7f6e\u3002", "result": "\u8bc1\u660eG* regret\u4e25\u683c\u7ec6\u5316\u4e86L* regret\uff0c\u5f53\u635f\u5931\u51fd\u6570\u5728\u6700\u4f18\u89e3\u9644\u8fd1\u66f2\u7387\u6d88\u5931\u65f6\u53ef\u4ee5\u4efb\u610f\u66f4\u5c16\u9510\u3002\u5efa\u7acb\u4e86\u7406\u8bba\u754c\u9650\uff0c\u5e76\u5728\u63d2\u503c\u673a\u5236\u4e0b\u6539\u8fdb\u4e86\u968f\u673a\u4f18\u5316\u7b97\u6cd5\u7684\u6536\u655b\u5206\u6790\u3002", "conclusion": "G* regret\u662f\u4e00\u79cd\u66f4\u7cbe\u7ec6\u7684\u95ee\u9898\u4f9d\u8d56\u9057\u61be\u5ea6\u91cf\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u635f\u5931\u51fd\u6570\u7684\u5c40\u90e8\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u66f2\u7387\u6d88\u5931\u7684\u60c5\u51b5\u4e0b\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u4e3a\u5728\u7ebf\u51f8\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2601.11948", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.11948", "abs": "https://arxiv.org/abs/2601.11948", "authors": ["Kai Liu", "Hua-Cheng Zhou", "Zhong-Jie Han", "Xiangyang Peng"], "title": "Observer design and boundary output feedback stabilization for semilinear parabolic system over general multidimensional domain", "comment": null, "summary": "This paper investigates the output feedback stabilization of parabolic equation with Lipschitz nonlinearity over general multidimensional domain using spectral geometry theories. First, a novel nonlinear observer is designed, and the error system is shown to achieve any prescribed decay rate by leveraging the Berezin-Li-Yau inequality from spectral geometry, which also provides effective guidance for sensor placement. Subsequently, a finite-dimensional state feedback controller is proposed, which ensures the quantitative rapid stabilization of the linear part. By integrating this control law with the observer, an efficient boundary output feedback control strategy is developed. The feasibility of the proposed control design is rigorously verified for arbitrary Lipschitz constants, thereby resolving a persistent theoretical challenge. Finally, a numerical case study confirms the effectiveness of the approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u8c31\u51e0\u4f55\u7406\u8bba\u89e3\u51b3\u4e86\u591a\u7ef4\u57df\u4e0a\u5177\u6709Lipschitz\u975e\u7ebf\u6027\u7684\u629b\u7269\u578b\u65b9\u7a0b\u7684\u8f93\u51fa\u53cd\u9988\u9547\u5b9a\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u65b0\u578b\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\u548c\u6709\u9650\u7ef4\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u4e86\u4efb\u610f\u6307\u5b9a\u8870\u51cf\u7387\u7684\u7a33\u5b9a\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3\u591a\u7ef4\u57df\u4e0a\u5177\u6709Lipschitz\u975e\u7ebf\u6027\u7684\u629b\u7269\u578b\u65b9\u7a0b\u7684\u8f93\u51fa\u53cd\u9988\u9547\u5b9a\u8fd9\u4e00\u957f\u671f\u5b58\u5728\u7684\u7406\u8bba\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4efb\u610fLipschitz\u5e38\u6570\u4e0b\u7684\u7a33\u5b9a\u63a7\u5236\u95ee\u9898\u3002", "method": "1. \u8bbe\u8ba1\u65b0\u578b\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\uff0c\u5229\u7528\u8c31\u51e0\u4f55\u4e2d\u7684Berezin-Li-Yau\u4e0d\u7b49\u5f0f\u786e\u4fdd\u8bef\u5dee\u7cfb\u7edf\u8fbe\u5230\u4efb\u610f\u6307\u5b9a\u8870\u51cf\u7387\uff1b2. \u63d0\u51fa\u6709\u9650\u7ef4\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u7ebf\u6027\u90e8\u5206\u7684\u5b9a\u91cf\u5feb\u901f\u9547\u5b9a\uff1b3. \u5c06\u63a7\u5236\u5f8b\u4e0e\u89c2\u6d4b\u5668\u7ed3\u5408\uff0c\u5f00\u53d1\u9ad8\u6548\u7684\u8fb9\u754c\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u7b56\u7565\u3002", "result": "1. \u89c2\u6d4b\u5668\u8bef\u5dee\u7cfb\u7edf\u53ef\u8fbe\u5230\u4efb\u610f\u6307\u5b9a\u8870\u51cf\u7387\uff1b2. \u63a7\u5236\u7b56\u7565\u5bf9\u4efb\u610fLipschitz\u5e38\u6570\u5747\u6709\u6548\uff0c\u89e3\u51b3\u4e86\u957f\u671f\u7406\u8bba\u96be\u9898\uff1b3. \u6570\u503c\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1b4. \u8c31\u51e0\u4f55\u7406\u8bba\u4e3a\u4f20\u611f\u5668\u5e03\u7f6e\u63d0\u4f9b\u4e86\u6709\u6548\u6307\u5bfc\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86\u591a\u7ef4\u57df\u4e0a\u5177\u6709Lipschitz\u975e\u7ebf\u6027\u7684\u629b\u7269\u578b\u65b9\u7a0b\u7684\u8f93\u51fa\u53cd\u9988\u9547\u5b9a\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u63a7\u5236\u7b56\u7565\u5bf9\u4efb\u610fLipschitz\u5e38\u6570\u5747\u6709\u6548\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.11581", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11581", "abs": "https://arxiv.org/abs/2601.11581", "authors": ["Yuefeng Wang", "ChangJae Lee"], "title": "Enhancing the QA Model through a Multi-domain Debiasing Framework", "comment": "5 pages, 7 tables", "summary": "Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30ELECTRA-small\u6a21\u578b\u5728SQuAD v1.1\u53ca\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8bc6\u522b\u504f\u5dee\u7c7b\u578b\u5e76\u5f00\u53d1\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002", "motivation": "QA\u6a21\u578b\u5728\u673a\u5668\u9605\u8bfb\u7406\u89e3\u65b9\u9762\u867d\u6709\u8fdb\u6b65\uff0c\u4f46\u5728\u590d\u6742\u67e5\u8be2\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u5e38\u8868\u73b0\u51fa\u504f\u5dee\uff0c\u5f71\u54cd\u6027\u80fd\u3002\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u5728\u6807\u51c6\u6570\u636e\u96c6\u548c\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5f00\u53d1\u6709\u6548\u7684\u53bb\u504f\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30ELECTRA-small\u6a21\u578b\u5728SQuAD v1.1\u3001AddSent\u548cAddOneSent\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff1b\u8bc6\u522b\u8bcd\u6c47\u504f\u5dee\u3001\u6570\u503c\u63a8\u7406\u548c\u5b9e\u4f53\u8bc6\u522b\u7b49\u9519\u8bef\u7c7b\u578b\uff1b\u5f00\u53d1\u5305\u542b\u77e5\u8bc6\u84b8\u998f\u3001\u53bb\u504f\u6280\u672f\u548c\u9886\u57df\u6269\u5c55\u7684\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\u3002", "result": "\u5728\u6240\u6709\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad82.6\u4e2a\u767e\u5206\u70b9\u7684EM\u548cF1\u5206\u6570\u63d0\u5347\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u4e5f\u53d6\u5f97\u4e86\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u9488\u5bf9\u6027\u7684\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\uff0c\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.11615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11615", "abs": "https://arxiv.org/abs/2601.11615", "authors": ["Beyza Cinar", "Louisa van den Boom", "Maria Maleshkova"], "title": "A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia", "comment": null, "summary": "Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u673a\u5668\u5b66\u4e60\u57281\u578b\u7cd6\u5c3f\u75c5\u4f4e\u8840\u7cd6\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e0b\u56de\u5f52\u4e0e\u5206\u7c7b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b01\u5c0f\u65f6\u5185\u9884\u6d4b\u6548\u679c\u6700\u4f73\uff0c\u4f20\u7edfML\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u66f4\u4f18\uff0c\u4e2a\u6027\u5316\u6570\u636e\u80fd\u63d0\u5347\u6027\u80fd\u4f46\u53d7\u6570\u636e\u8d28\u91cf\u9650\u5236\u3002", "motivation": "1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u9700\u8981\u7ec8\u8eab\u80f0\u5c9b\u7d20\u6cbb\u7597\uff0c\u4f46\u80f0\u5c9b\u7d20\u6cbb\u7597\u6709\u5bfc\u81f4\u4f4e\u8840\u7cd6\u7684\u526f\u4f5c\u7528\u3002\u4f4e\u8840\u7cd6\uff08\u8840\u7cd6\u4f4e\u4e8e70 mg/dL\uff09\u4f1a\u589e\u52a0\u6b7b\u4ea1\u98ce\u9669\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u4f4e\u8840\u7cd6\u4e8b\u4ef6\u6765\u6539\u5584\u7cd6\u5c3f\u75c5\u7ba1\u7406\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u3001\u6a21\u578b\u7c7b\u578b\u3001\u5f71\u54cd\u56e0\u7d20\u548c\u4e2a\u6027\u5316\u6548\u679c\u7684\u5168\u9762\u6bd4\u8f83\u3002", "method": "\u672c\u6587\u662f\u4e00\u7bc7\u7efc\u8ff0\u7814\u7a76\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u4e8e\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u7814\u7a76\u6bd4\u8f83\u4e86\u56de\u5f52\u6a21\u578b\uff08\u9884\u6d4b\u8840\u7cd6\u503c\uff09\u548c\u5206\u7c7b\u6a21\u578b\uff08\u8bc6\u522b\u4f4e\u8840\u7cd6\u4e8b\u4ef6\uff09\u5728\u4e0d\u540c\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\uff08\u77ed\u671f15-120\u5206\u949f\uff0c\u957f\u671f3-24\u5c0f\u65f6\u4ee5\u4e0a\uff09\u7684\u6027\u80fd\u3002\u63a2\u8ba8\u4e86\u56db\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u9884\u6d4b\u51c6\u786e\u6027\u65f6\u95f4\u7a97\u53e3\u3001\u6700\u4f73\u6a21\u578b\u7c7b\u578b\u3001\u5f71\u54cd\u56e0\u7d20\u4ee5\u53ca\u4e2a\u6027\u5316\u6570\u636e\u7684\u6548\u679c\u3002", "result": "1) 1\u5c0f\u65f6\u5185\u7684\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u6548\u679c\u6700\u4f73\uff1b2) \u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u597d\uff0c\u6df1\u5ea6\u5b66\u4e60\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5355\u4e00\u6a21\u578b\u65e0\u6cd5\u5728\u591a\u4e2a\u65f6\u95f4\u7a97\u53e3\u90fd\u8868\u73b0\u826f\u597d\uff1b3) \u591a\u53d8\u91cf\u6570\u636e\u96c6\u548c\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff1b4) \u4e2a\u6027\u5316\u6570\u636e\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u8d28\u91cf\u6709\u9650\uff0c\u57fa\u4e8e\u4eba\u7fa4\u7684\u6a21\u578b\u66f4\u53d7\u9752\u7750\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u57281\u578b\u7cd6\u5c3f\u75c5\u4f4e\u8840\u7cd6\u9884\u6d4b\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u6700\u4f73\u9884\u6d4b\u65f6\u95f4\u7a97\u53e3\u4e3a1\u5c0f\u65f6\u5185\u3002\u6a21\u578b\u9009\u62e9\u5e94\u6839\u636e\u5177\u4f53\u4efb\u52a1\u7c7b\u578b\uff08\u5206\u7c7b\u6216\u56de\u5f52\uff09\u800c\u5b9a\uff0c\u4e14\u9700\u8981\u8003\u8651\u591a\u53d8\u91cf\u6570\u636e\u548c\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u7684\u5f71\u54cd\u3002\u867d\u7136\u4e2a\u6027\u5316\u6570\u636e\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u57fa\u4e8e\u4eba\u7fa4\u7684\u6a21\u578b\u66f4\u4e3a\u5b9e\u7528\u3002"}}
{"id": "2601.11816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11816", "abs": "https://arxiv.org/abs/2601.11816", "authors": ["Zahra Moslemi", "Keerthi Koneru", "Yen-Ting Lee", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation", "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026", "summary": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation", "AI": {"tldr": "POLARIS\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u7684\u6cbb\u7406\u578bLLM\u667a\u80fd\u4f53\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "motivation": "\u4f01\u4e1a\u540e\u53f0\u5de5\u4f5c\u6d41\u9700\u8981\u53ef\u5ba1\u8ba1\u3001\u7b56\u7565\u5bf9\u9f50\u4e14\u64cd\u4f5c\u53ef\u9884\u6d4b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u800c\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u5f80\u5f80\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u6709\u6548\u7684\u6cbb\u7406\u673a\u5236\u6765\u786e\u4fdd\u5408\u89c4\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "method": "POLARIS\u91c7\u7528\u6cbb\u7406\u578b\u7f16\u6392\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u5316\u89c6\u4e3a\u7c7b\u578b\u5316\u8ba1\u5212\u5408\u6210\u548c\u9a8c\u8bc1\u6267\u884c\uff1a1) \u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u591a\u6837\u3001\u7c7b\u578b\u68c0\u67e5\u7684\u6709\u5411\u65e0\u73af\u56fe(DAGs)\uff1b2) \u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u6a21\u5757\u9009\u62e9\u5408\u89c4\u8ba1\u5212\uff1b3) \u6267\u884c\u9636\u6bb5\u901a\u8fc7\u9a8c\u8bc1\u5668\u95e8\u63a7\u68c0\u67e5\u3001\u6709\u754c\u4fee\u590d\u5faa\u73af\u548c\u7f16\u8bd1\u7b56\u7565\u62a4\u680f\u6765\u963b\u6b62\u6216\u8def\u7531\u526f\u4f5c\u7528\u3002", "result": "\u5728\u6587\u6863\u4e2d\u5fc3\u8d22\u52a1\u4efb\u52a1\u4e2d\uff0cPOLARIS\u751f\u6210\u51b3\u7b56\u7ea7\u5de5\u4ef6\u548c\u5b8c\u6574\u6267\u884c\u8ddf\u8e2a\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002\u5728SROIE\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.81\u7684\u5faeF1\u5206\u6570\uff0c\u5728\u53d7\u63a7\u5408\u6210\u5957\u4ef6\u4e2d\u5b9e\u73b00.95-1.00\u7684\u5f02\u5e38\u8def\u7531\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u7559\u5ba1\u8ba1\u8ddf\u8e2a\u3002", "conclusion": "POLARIS\u4e3a\u7b56\u7565\u5bf9\u9f50\u7684\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u548c\u57fa\u51c6\u53c2\u8003\uff0c\u5efa\u7acb\u4e86\u6cbb\u7406\u578b\u667a\u80fd\u4f53AI\u7684\u521d\u6b65\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u5728\u4f01\u4e1a\u81ea\u52a8\u5316\u4e2d\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u3001\u5408\u89c4\u4e14\u9ad8\u6548\u5de5\u4f5c\u6d41\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.12210", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12210", "abs": "https://arxiv.org/abs/2601.12210", "authors": ["Alexander Medvedev", "Anton V. Proskurnikov"], "title": "Solvability of The Output Corridor Control Problem by Pulse-Modulated Feedback", "comment": null, "summary": "The problem of maintaining the output of a positive time-invariant single-input single-output system within a predefined corridor of values is treated. For third-order plants possessing a certain structure, it is proven that the problem is always solvable under stationary conditions by means of pulse-modulated feedback. The obtained result is utilized to assess the feasibility of patient-specific pharmacokinetic-pharmacodynamic models with respect to patient safety. A population of Wiener models capturing the dynamics of a neuromuscular blockade agent is studied to investigate whether or not they can be driven into the desired output corridor by clinically acceptable sequential drug doses (boluses). It is demonstrated that low values of a parameter in the nonlinear pharmacodynamic part lie behind the detected model infeasibility.", "AI": {"tldr": "\u9488\u5bf9\u5177\u6709\u7279\u5b9a\u7ed3\u6784\u7684\u4e09\u9636\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u8109\u51b2\u8c03\u5236\u53cd\u9988\u53ef\u5728\u7a33\u6001\u6761\u4ef6\u4e0b\u89e3\u51b3\u8f93\u51fa\u7ef4\u6301\u5728\u9884\u5b9a\u8d70\u5eca\u5185\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u8be5\u7ed3\u679c\u5e94\u7528\u4e8e\u8bc4\u4f30\u60a3\u8005\u7279\u5f02\u6027\u836f\u4ee3\u52a8\u529b\u5b66-\u836f\u6548\u5b66\u6a21\u578b\u7684\u5b89\u5168\u6027\u53ef\u884c\u6027\u3002", "motivation": "\u89e3\u51b3\u6b63\u65f6\u4e0d\u53d8\u5355\u8f93\u5165\u5355\u8f93\u51fa\u7cfb\u7edf\u8f93\u51fa\u7ef4\u6301\u5728\u9884\u5b9a\u503c\u8d70\u5eca\u5185\u7684\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u786e\u4fdd\u60a3\u8005\u5b89\u5168\uff0c\u8bc4\u4f30\u836f\u4ee3\u52a8\u529b\u5b66-\u836f\u6548\u5b66\u6a21\u578b\u662f\u5426\u53ef\u901a\u8fc7\u4e34\u5e8a\u53ef\u63a5\u53d7\u7684\u836f\u7269\u5242\u91cf\u5b9e\u73b0\u5b89\u5168\u63a7\u5236\u3002", "method": "\u9488\u5bf9\u5177\u6709\u7279\u5b9a\u7ed3\u6784\u7684\u4e09\u9636\u7cfb\u7edf\uff0c\u91c7\u7528\u8109\u51b2\u8c03\u5236\u53cd\u9988\u63a7\u5236\u65b9\u6cd5\uff0c\u5728\u7a33\u6001\u6761\u4ef6\u4e0b\u5206\u6790\u7cfb\u7edf\u53ef\u63a7\u6027\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u8bc4\u4f30\u795e\u7ecf\u808c\u8089\u963b\u6ede\u5242Wiener\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u5177\u6709\u7279\u5b9a\u7ed3\u6784\u7684\u4e09\u9636\u7cfb\u7edf\uff0c\u901a\u8fc7\u8109\u51b2\u8c03\u5236\u53cd\u9988\u603b\u662f\u53ef\u4ee5\u5728\u7a33\u6001\u6761\u4ef6\u4e0b\u89e3\u51b3\u8f93\u51fa\u8d70\u5eca\u7ef4\u6301\u95ee\u9898\uff1b\u53d1\u73b0\u975e\u7ebf\u6027\u836f\u6548\u5b66\u90e8\u5206\u53c2\u6570\u503c\u8fc7\u4f4e\u662f\u5bfc\u81f4\u6a21\u578b\u4e0d\u53ef\u884c\u7684\u4e3b\u8981\u539f\u56e0\u3002", "conclusion": "\u8109\u51b2\u8c03\u5236\u53cd\u9988\u53ef\u6709\u6548\u89e3\u51b3\u4e09\u9636\u7cfb\u7edf\u7684\u8f93\u51fa\u8d70\u5eca\u63a7\u5236\u95ee\u9898\uff0c\u8be5\u7406\u8bba\u6846\u67b6\u53ef\u7528\u4e8e\u8bc4\u4f30\u4e34\u5e8a\u836f\u4ee3\u52a8\u529b\u5b66-\u836f\u6548\u5b66\u6a21\u578b\u7684\u5b89\u5168\u6027\u53ef\u884c\u6027\uff0c\u4e3a\u60a3\u8005\u7279\u5f02\u6027\u6cbb\u7597\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.11587", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11587", "abs": "https://arxiv.org/abs/2601.11587", "authors": ["Yuyan Huang", "Haoran Li", "Yifan Lu", "Ruolin Wu", "Siqian Chen", "Chao Liu"], "title": "Evidence-Grounded Multi-Agent Planning Support for Urban Carbon Governance via RAG", "comment": null, "summary": "Urban carbon governance requires planners to integrate heterogeneous evidence -- emission inventories, statistical yearbooks, policy texts, technical measures, and academic findings -- into actionable, cross-departmental plans. Large Language Models (LLMs) can assist planning workflows, yet their factual reliability and evidential traceability remain critical barriers in professional use. This paper presents an evidence-grounded multi-agent planning support system for urban carbon governance built upon standard text-based Retrieval-Augmented Generation (RAG) (without GraphRAG). We align the system with the typical planning workflow by decomposing tasks into four specialized agents: (i) evidence Q\\&A for fact checking and compliance queries, (ii) emission status assessment for diagnostic analysis, (iii) planning recommendation for generating multi-sector governance pathways, and (iv) report integration for producing planning-style deliverables. We evaluate the system in two task families: factual retrieval and comprehensive planning generation. On factual retrieval tasks, introducing RAG increases the average score from below 6 to above 90, and dramatically improves key-field extraction (e.g., region and numeric values near 100\\% detection). A real-city case study (Ningbo, China) demonstrates end-to-end report generation with strong relevance, coverage, and coherence in expert review, while also highlighting boundary inconsistencies across data sources as a practical limitation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8bc1\u636e\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u652f\u6301\u7cfb\u7edf\uff0c\u7528\u4e8e\u57ce\u5e02\u78b3\u6cbb\u7406\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u4e3a\u56db\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e8b\u5b9e\u68c0\u7d22\u51c6\u786e\u6027\u548c\u89c4\u5212\u62a5\u544a\u8d28\u91cf\u3002", "motivation": "\u57ce\u5e02\u78b3\u6cbb\u7406\u9700\u8981\u6574\u5408\u591a\u79cd\u5f02\u6784\u8bc1\u636e\uff08\u6392\u653e\u6e05\u5355\u3001\u7edf\u8ba1\u5e74\u9274\u3001\u653f\u7b56\u6587\u672c\u3001\u6280\u672f\u63aa\u65bd\u3001\u5b66\u672f\u53d1\u73b0\uff09\u5f62\u6210\u53ef\u6267\u884c\u7684\u8de8\u90e8\u95e8\u89c4\u5212\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u8f85\u52a9\u89c4\u5212\u5de5\u4f5c\u6d41\uff0c\u4f46\u5176\u4e8b\u5b9e\u53ef\u9760\u6027\u548c\u8bc1\u636e\u53ef\u8ffd\u6eaf\u6027\u4ecd\u7136\u662f\u4e13\u4e1a\u5e94\u7528\u4e2d\u7684\u5173\u952e\u969c\u788d\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u6807\u51c6\u6587\u672c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u652f\u6301\u7cfb\u7edf\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u56db\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\uff1a(i)\u8bc1\u636e\u95ee\u7b54\u7528\u4e8e\u4e8b\u5b9e\u6838\u67e5\u548c\u5408\u89c4\u67e5\u8be2\uff0c(ii)\u6392\u653e\u72b6\u6001\u8bc4\u4f30\u7528\u4e8e\u8bca\u65ad\u5206\u6790\uff0c(iii)\u89c4\u5212\u63a8\u8350\u7528\u4e8e\u751f\u6210\u591a\u90e8\u95e8\u6cbb\u7406\u8def\u5f84\uff0c(iv)\u62a5\u544a\u6574\u5408\u7528\u4e8e\u751f\u6210\u89c4\u5212\u5f0f\u4ea4\u4ed8\u6210\u679c\u3002", "result": "\u5728\u4e8b\u5b9e\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u5f15\u5165RAG\u5c06\u5e73\u5747\u5f97\u5206\u4ece\u4f4e\u4e8e6\u63d0\u9ad8\u523090\u4ee5\u4e0a\uff0c\u5173\u952e\u5b57\u6bb5\u63d0\u53d6\uff08\u5982\u533a\u57df\u548c\u6570\u503c\uff09\u68c0\u6d4b\u7387\u63a5\u8fd1100%\u3002\u5728\u5b81\u6ce2\u5e02\u7684\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u7aef\u5230\u7aef\u7684\u89c4\u5212\u62a5\u544a\uff0c\u5728\u4e13\u5bb6\u8bc4\u5ba1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u76f8\u5173\u6027\u3001\u8986\u76d6\u5ea6\u548c\u8fde\u8d2f\u6027\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u6570\u636e\u6e90\u95f4\u8fb9\u754c\u4e0d\u4e00\u81f4\u7684\u5b9e\u9645\u9650\u5236\u3002", "conclusion": "\u8be5\u8bc1\u636e\u57fa\u7840\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u652f\u6301\u57ce\u5e02\u78b3\u6cbb\u7406\u89c4\u5212\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u63d0\u9ad8\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u89c4\u5212\u8d28\u91cf\uff0c\u4f46\u6570\u636e\u6e90\u95f4\u7684\u4e00\u81f4\u6027\u4ecd\u7136\u662f\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2601.13642", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13642", "abs": "https://arxiv.org/abs/2601.13642", "authors": ["Yuchen Jiao", "Jiin Woo", "Gen Li", "Gauri Joshi", "Yuejie Chi"], "title": "Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning", "comment": null, "summary": "Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{\\varepsilon^3}\\right)$, where $\\|h^{\\star}\\|_{\\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}^2}{\\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{M\\varepsilon^3}\\right)$, with only $\\widetilde{O}\\left(\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}}{\\varepsilon}\\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e73\u5747\u5956\u52b1MDPs\u7684Q-learning\u7b97\u6cd5\uff0c\u5728\u5355\u667a\u80fd\u4f53\u548c\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u6539\u8fdb\u4e86\u6837\u672c\u590d\u6742\u5ea6\u5e76\u9996\u6b21\u63d0\u51fa\u4e86\u8054\u90a6Q-learning\u7b97\u6cd5\u3002", "motivation": "\u5e73\u5747\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u4e3a\u957f\u671f\u51b3\u7b56\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u4f46Q-learning\u5728\u5e73\u5747\u5956\u52b1\u8bbe\u7f6e\u4e0b\u7684\u7406\u8bba\u4fdd\u8bc1\u6709\u9650\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5e73\u5747\u5956\u52b1MDPs\u7684Q-learning\u6837\u672c\u590d\u6742\u5ea6\u5206\u6790\uff0c\u7279\u522b\u662f\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684Q-learning\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5f31\u901a\u4fe1\u5047\u8bbe\u4e0b\u7684\u6709\u9650\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u5e73\u5747\u5956\u52b1MDPs\u3002\u7814\u7a76\u4e86\u5355\u667a\u80fd\u4f53\u548c\u8054\u90a6\u4e24\u79cd\u573a\u666f\uff0c\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u7b97\u6cd5\u53c2\u6570\u6765\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5355\u667a\u80fd\u4f53\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u8fbe\u5230\u6837\u672c\u590d\u6742\u5ea6$\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{\\varepsilon^3}\\right)$\uff0c\u6bd4\u5148\u524d\u7ed3\u679c\u6539\u8fdb\u81f3\u5c11$\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}^2}{\\varepsilon^2}$\u500d\u3002\u8054\u90a6\u8bbe\u7f6e\u4e2d\uff0cM\u4e2a\u667a\u80fd\u4f53\u7684\u6bcf\u667a\u80fd\u4f53\u6837\u672c\u590d\u6742\u5ea6\u964d\u81f3$\\widetilde{O}\\left(\\frac{|\\mathcal{S}||\\mathcal{A}|\\|h^{\\star}\\|_{\\mathsf{sp}}^3}{M\\varepsilon^3}\\right)$\uff0c\u4ec5\u9700$\\widetilde{O}\\left(\\frac{\\|h^{\\star}\\|_{\\mathsf{sp}}}{\\varepsilon}\\right)$\u901a\u4fe1\u8f6e\u6b21\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u5e73\u5747\u5956\u52b1MDPs\u7684\u8054\u90a6Q-learning\u7b97\u6cd5\uff0c\u5728\u6837\u672c\u590d\u6742\u5ea6\u548c\u901a\u4fe1\u590d\u6742\u5ea6\u65b9\u9762\u90fd\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6548\u7387\uff0c\u4e3a\u5e73\u5747\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u7684\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2601.12117", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12117", "abs": "https://arxiv.org/abs/2601.12117", "authors": ["Jingren Liu", "Hanzhang Qin", "Junyi Liu", "Mabel C. Chou", "Jong-Shi Pang"], "title": "Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization", "comment": null, "summary": "Offline policy learning aims to use historical data to learn an optimal personalized decision rule. In the standard estimate-then-optimize framework, reweighting-based methods (e.g., inverse propensity weighting or doubly robust estimators) are widely used to produce unbiased estimates of policy values. However, when the propensity scores of some treatments are small, these reweighting-based methods suffer from high variance in policy value estimation, which may mislead the downstream policy optimization and yield a learned policy with inferior value. In this paper, we systematically develop an offline policy learning algorithm based on a weight-clipping estimator that truncates small propensity scores via a clipping threshold chosen to minimize the mean squared error (MSE) in policy value estimation. Focusing on linear policies, we address the bilevel and discontinuous objective induced by weight-clipping-based policy optimization by reformulating the problem as a Heaviside composite optimization problem, which provides a rigorous computational framework. The reformulated policy optimization problem is then solved efficiently using the progressive integer programming method, making practical policy learning tractable. We establish an upper bound for the suboptimality of the proposed algorithm, which reveals how the reduction in MSE of policy value estimation, enabled by our proposed weight-clipping estimator, leads to improved policy learning performance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6743\u91cd\u622a\u65ad\u4f30\u8ba1\u5668\u7684\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u622a\u65ad\u5c0f\u503e\u5411\u5f97\u5206\u6765\u51cf\u5c11\u7b56\u7565\u503c\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u4f7f\u7528\u6e10\u8fdb\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u6c42\u89e3\uff0c\u7406\u8bba\u8bc1\u660e\u80fd\u63d0\u5347\u7b56\u7565\u5b66\u4e60\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u91cd\u52a0\u6743\u65b9\u6cd5\uff08\u5982\u9006\u503e\u5411\u52a0\u6743\u6216\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\uff09\u5728\u503e\u5411\u5f97\u5206\u8f83\u5c0f\u65f6\u4f1a\u5bfc\u81f4\u7b56\u7565\u503c\u4f30\u8ba1\u7684\u9ad8\u65b9\u5dee\uff0c\u4ece\u800c\u8bef\u5bfc\u4e0b\u6e38\u7b56\u7565\u4f18\u5316\uff0c\u4ea7\u751f\u6b21\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u6743\u91cd\u622a\u65ad\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u622a\u65ad\u9608\u503c\u6700\u5c0f\u5316\u7b56\u7565\u503c\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\uff1b\u9488\u5bf9\u7ebf\u6027\u7b56\u7565\uff0c\u5c06\u95ee\u9898\u91cd\u6784\u4e3aHeaviside\u590d\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6e10\u8fdb\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u9ad8\u6548\u6c42\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u7b97\u6cd5\u6b21\u4f18\u6027\u7684\u4e0a\u754c\uff0c\u63ed\u793a\u4e86\u901a\u8fc7\u6743\u91cd\u622a\u65ad\u4f30\u8ba1\u5668\u51cf\u5c11\u7b56\u7565\u503c\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\u5982\u4f55\u63d0\u5347\u7b56\u7565\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "\u6743\u91cd\u622a\u65ad\u4f30\u8ba1\u5668\u80fd\u6709\u6548\u89e3\u51b3\u5c0f\u503e\u5411\u5f97\u5206\u5bfc\u81f4\u7684\u9ad8\u65b9\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u6e10\u8fdb\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u4f7f\u5b9e\u9645\u7b56\u7565\u5b66\u4e60\u53d8\u5f97\u53ef\u884c\uff0c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.11585", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11585", "abs": "https://arxiv.org/abs/2601.11585", "authors": ["Hyunjun Kim"], "title": "Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents", "comment": null, "summary": "Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.", "AI": {"tldr": "ECS\u662f\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u91cf\u6a21\u578b\u7b54\u6848\u5206\u5e03\u5411\u6b63\u786e\u7b54\u6848\u7684\u504f\u79fb\u6765\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6548\u7528\uff0c\u76f8\u6bd4\u57fa\u4e8e\u8bcd\u91cd\u53e0\u7684\u8bcd\u6c47\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u5728\u7ec6\u7c92\u5ea6\u4e0a\u4e0b\u6587\u9009\u62e9\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u66f4\u597d\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9700\u8981\u4ece\u8bef\u5bfc\u6027\u5e72\u6270\u4fe1\u606f\u4e2d\u533a\u5206\u51fa\u5b9e\u9645\u6709\u7528\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u73b0\u6709\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u8bed\u7528\u6548\u7528\u2014\u2014\u5373\u4e00\u6bb5\u6587\u672c\u662f\u5426\u771f\u6b63\u6709\u52a9\u4e8e\u56de\u7b54\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u71b5\u4e0a\u4e0b\u6587\u5851\u9020\uff08ECS\uff09\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u6548\u7528\u5b9a\u4e49\u4e3a\u6a21\u578b\u7b54\u6848\u5206\u5e03\u5411\u6b63\u786e\u7b54\u6848\u6982\u7387\u7684\u6709\u7b26\u53f7\u53d8\u5316\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\uff0c\u4efb\u52a1\u65e0\u5173\u7684\u4e0a\u4e0b\u6587\u66f4\u65b0\u4f1a\u4ea7\u751f\u63a5\u8fd1\u96f6\u7684\u5206\u5e03\u504f\u79fb\u3002", "result": "\u5728LongMemEval\uff08\u4f1a\u8bdd\u7ea7\uff09\u548cLoCoMo\uff08\u8f6e\u6b21\u7ea7\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cECS\u5728\u7ec6\u7c92\u5ea6\u8f6e\u6b21\u9009\u62e9\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528Llama-3.1-8B\u6a21\u578b\u8fbe\u5230F1=0.265\uff0c\u76f8\u6bd4TF-IDF\uff08F1=0.154\uff09\u76f8\u5bf9\u63d0\u534771.83%\u3002", "conclusion": "ECS\u6846\u67b6\u901a\u8fc7\u6355\u6349\u8bed\u7528\u6548\u7528\u800c\u975e\u8bcd\u6c47\u76f8\u4f3c\u6027\uff0c\u5728\u7cbe\u786e\u4e0a\u4e0b\u6587\u9009\u62e9\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8bed\u7528\u6548\u7528\u5bf9\u4e8e\u4e0a\u4e0b\u6587\u5de5\u7a0b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.11616", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11616", "abs": "https://arxiv.org/abs/2601.11616", "authors": ["Feilong Liu"], "title": "Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.", "AI": {"tldr": "MoE\u67b6\u6784\u901a\u8fc7\u8f6f\u5206\u533a\u8868\u793a\u7a7a\u95f4\u6765\u964d\u4f4e\u5c40\u90e8\u654f\u611f\u6027\uff0c\u540c\u65f6\u589e\u52a0\u8868\u793a\u7684\u6709\u6548\u79e9\uff0cTop-k\u8def\u7531\u4ea7\u751f\u4f4e\u79e9\u96c6\u4e2d\u7ed3\u6784\uff0c\u5168\u8f6f\u8def\u7531\u4ea7\u751f\u9ad8\u79e9\u5206\u6563\u8868\u793a\u3002", "motivation": "\u7814\u7a76MoE\u67b6\u6784\u5bf9\u5b66\u4e60\u51fd\u6570\u548c\u8868\u793a\u51e0\u4f55\u7279\u6027\u7684\u5f71\u54cd\uff0c\u7406\u89e3\u8def\u7531\u673a\u5236\u5982\u4f55\u4f5c\u4e3a\u8868\u793a\u7a7a\u95f4\u7684\u8f6f\u5206\u533a\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5206\u533a\u5982\u4f55\u5f71\u54cd\u51fd\u6570\u7684\u5c40\u90e8\u51e0\u4f55\u548c\u8868\u793a\u7ed3\u6784\u3002", "method": "\u5f15\u5165\u53cc\u96c5\u53ef\u6bd4-PCA\u8c31\u51e0\u4f55\u63a2\u9488\uff0c\u901a\u8fc7\u96c5\u53ef\u6bd4\u5947\u5f02\u503c\u8c31\u5206\u6790\u5c40\u90e8\u51fd\u6570\u51e0\u4f55\uff0c\u901a\u8fc7\u52a0\u6743PCA\u5206\u6790\u8def\u7531\u9690\u85cf\u72b6\u6001\u7684\u8868\u793a\u51e0\u4f55\u3002\u5728\u53ef\u63a7\u7684MLP-MoE\u8bbe\u7f6e\u4e0b\u6bd4\u8f83\u5bc6\u96c6\u3001Top-k\u548c\u5168\u8f6f\u8def\u7531\u67b6\u6784\u3002", "result": "MoE\u8def\u7531\u4e00\u81f4\u964d\u4f4e\u5c40\u90e8\u654f\u611f\u6027\uff0c\u4e13\u5bb6\u5c40\u90e8\u96c5\u53ef\u6bd4\u77e9\u9635\u663e\u793a\u8f83\u5c0f\u7684\u4e3b\u5bfc\u5947\u5f02\u503c\u548c\u66f4\u5feb\u7684\u8c31\u8870\u51cf\u3002\u52a0\u6743PCA\u663e\u793a\u4e13\u5bb6\u5c40\u90e8\u8868\u793a\u5728\u66f4\u591a\u4e3b\u65b9\u5411\u4e0a\u5206\u5e03\u65b9\u5dee\uff0c\u8868\u660e\u5728\u76f8\u540c\u8f93\u5165\u5206\u5e03\u4e0b\u5177\u6709\u66f4\u9ad8\u7684\u6709\u6548\u79e9\u3002\u5e73\u5747\u4e13\u5bb6\u96c5\u53ef\u6bd4\u77e9\u9635\u51e0\u4e4e\u6b63\u4ea4\uff0c\u8868\u660e\u53d8\u6362\u5206\u89e3\u4e3a\u4f4e\u91cd\u53e0\u7684\u4e13\u5bb6\u7279\u5b9a\u5b50\u7a7a\u95f4\u3002", "conclusion": "MoE\u53ef\u4ee5\u51e0\u4f55\u89e3\u91ca\u4e3a\u51fd\u6570\u7a7a\u95f4\u7684\u8f6f\u5206\u533a\uff0c\u5728\u5e73\u5766\u5316\u5c40\u90e8\u66f2\u7387\u7684\u540c\u65f6\u91cd\u65b0\u5206\u914d\u8868\u793a\u65b9\u5dee\uff0cTop-k\u8def\u7531\u4ea7\u751f\u4f4e\u79e9\u96c6\u4e2d\u7ed3\u6784\uff0c\u5168\u8f6f\u8def\u7531\u4ea7\u751f\u9ad8\u79e9\u5206\u6563\u8868\u793a\u3002"}}
{"id": "2601.11825", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11825", "abs": "https://arxiv.org/abs/2601.11825", "authors": ["Arya Rahgozar", "Pouria Mortezaagha"], "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept", "comment": null, "summary": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8ePICOS\u6846\u67b6\u7684AI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u77e5\u8bc6\u5408\u6210\uff0c\u901a\u8fc7\u81ea\u52a8\u5316PICOS\u5408\u89c4\u6027\u68c0\u6d4b\u3001\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u7684\u6548\u7387\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u5b58\u5728\u7814\u7a76\u6d6a\u8d39\u95ee\u9898\uff0c\u5305\u62ec\u5197\u4f59\u7814\u7a76\u3001\u4e0d\u5b8c\u6574\u62a5\u544a\u4ee5\u53ca\u4f20\u7edf\u8bc1\u636e\u5408\u6210\u5de5\u4f5c\u6d41\u7a0b\u53ef\u6269\u5c55\u6027\u6709\u9650\u3002\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u77e5\u8bc6\u5408\u6210\u65b9\u6cd5\u6765\u51cf\u5c11\u7814\u7a76\u6d6a\u8d39\u3002", "method": "\u57fa\u4e8ePICOS\u6846\u67b6\u6784\u5efaAI\u534f\u540c\u79d1\u5b66\u5bb6\u5e73\u53f0\uff0c\u96c6\u6210\u5173\u7cfb\u5b58\u50a8\u3001\u5411\u91cf\u8bed\u4e49\u68c0\u7d22\u548cNeo4j\u77e5\u8bc6\u56fe\u8c31\u3002\u4f7f\u7528Bi-LSTM\u548c\u57fa\u4e8ePubMedBERT\u7684transformer\u6a21\u578b\u8fdb\u884cPICOS\u5408\u89c4\u6027\u68c0\u6d4b\u548c\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8fdb\u884c\u5168\u6587\u5408\u6210\uff0cBERTopic\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\u3002", "result": "transformer\u6a21\u578b\u5728\u7814\u7a76\u8bbe\u8ba1\u5206\u7c7b\u4e0a\u8fbe\u523095.7%\u51c6\u786e\u7387\uff0cBi-LSTM\u5728PICOS\u5408\u89c4\u6027\u68c0\u6d4b\u4e0a\u8fbe\u523087%\u51c6\u786e\u7387\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u9700\u8981\u7ed3\u6784\u5316\u7ea6\u675f\u3001\u8de8\u7814\u7a76\u6574\u5408\u548c\u56fe\u63a8\u7406\u7684\u67e5\u8be2\u4e0a\u4f18\u4e8e\u975e\u68c0\u7d22\u65b9\u6cd5\u3002\u4e3b\u9898\u5efa\u6a21\u63ed\u793a\u4e86\u5927\u91cf\u4e3b\u9898\u5197\u4f59\u548c\u672a\u5145\u5206\u63a2\u7d22\u7684\u7814\u7a76\u9886\u57df\u3002", "conclusion": "PICOS\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u591f\u63d0\u9ad8\u8bc1\u636e\u5408\u6210\u7684\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u5ea6\u548c\u6548\u7387\u3002\u8be5\u67b6\u6784\u662f\u9886\u57df\u65e0\u5173\u7684\uff0c\u4e3a\u51cf\u5c11\u751f\u7269\u533b\u5b66\u5b66\u79d1\u7684\u7814\u7a76\u6d6a\u8d39\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2601.12236", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12236", "abs": "https://arxiv.org/abs/2601.12236", "authors": ["Sahil Aziz", "Wajid Ali", "Khaliqur Rahman"], "title": "Analyzing the Impact of EV Battery Charging on the Distribution Network", "comment": "6 pages, 5 figures", "summary": "Many countries are rapidly adopting electric vehicles (EVs) due to their meager running cost and environment-friendly nature. EVs are likely to dominate the internal combustion (IC) engine cars entirely over the next few years. With the rise in popularity of EVs, adverse effects of EV charging loads on the grid system have been observed. Since the distribution system (DS) does not cope with the high overloading capacity, the negative impact of EV charging load on the distribution network (DN) cannot be neglected. A high level of EV penetration with uncoordinated charging is the primary cause of voltage instability, increased peak load demand, and reliability issues of the DN. In this paper, a detailed overview of all the notable impacts of EV charging on voltage profile, power quality, and DS performance is discussed. This work also reviews the different topologies of EV chargers and the issues introduced by power converters on the utility grid. Finally, the strategies for improving the charging of EVs proposed in the literature to consider the random nature of EVs charging, the management of peak loads, and bidirectional power flow are summarized.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5bf9\u914d\u7535\u7f51\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u7535\u538b\u7a33\u5b9a\u6027\u3001\u7535\u80fd\u8d28\u91cf\u548c\u7cfb\u7edf\u6027\u80fd\u95ee\u9898\uff0c\u5e76\u56de\u987e\u4e86\u5145\u7535\u5668\u62d3\u6251\u7ed3\u6784\u53ca\u6539\u5584\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u7684\u5feb\u901f\u666e\u53ca\uff0c\u5176\u5145\u7535\u8d1f\u8377\u5bf9\u7535\u7f51\u7cfb\u7edf\u4ea7\u751f\u4e86\u8d1f\u9762\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5bf9\u914d\u7535\u7f51\u9020\u6210\u7535\u538b\u4e0d\u7a33\u5b9a\u3001\u5cf0\u503c\u8d1f\u8377\u589e\u52a0\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790\u548c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5bf9\u7535\u538b\u7279\u6027\u3001\u7535\u80fd\u8d28\u91cf\u548c\u914d\u7535\u7f51\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u56de\u987e\u4e0d\u540c\u5145\u7535\u5668\u62d3\u6251\u7ed3\u6784\uff0c\u603b\u7ed3\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u6539\u5584\u5145\u7535\u7b56\u7565\u3002", "result": "\u8bc6\u522b\u4e86\u975e\u534f\u8c03\u5145\u7535\u662f\u5bfc\u81f4\u914d\u7535\u7f51\u7535\u538b\u4e0d\u7a33\u5b9a\u3001\u5cf0\u503c\u8d1f\u8377\u589e\u52a0\u548c\u53ef\u9760\u6027\u95ee\u9898\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u603b\u7ed3\u4e86\u4e0d\u540c\u5145\u7535\u5668\u62d3\u6251\u7ed3\u6784\u5bf9\u7535\u7f51\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u7ba1\u7406\u968f\u673a\u5145\u7535\u3001\u5cf0\u503c\u8d1f\u8377\u548c\u53cc\u5411\u529f\u7387\u6d41\u7684\u7b56\u7565\u3002", "conclusion": "\u9700\u8981\u91c7\u53d6\u534f\u8c03\u5145\u7535\u7b56\u7565\u6765\u7f13\u89e3\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5bf9\u914d\u7535\u7f51\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5305\u62ec\u8003\u8651\u5145\u7535\u968f\u673a\u6027\u3001\u7ba1\u7406\u5cf0\u503c\u8d1f\u8377\u548c\u5229\u7528\u53cc\u5411\u529f\u7387\u6d41\uff0c\u4ee5\u786e\u4fdd\u7535\u7f51\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2601.11598", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11598", "abs": "https://arxiv.org/abs/2601.11598", "authors": ["Molly Campbell", "Mohamad Sheikho Al Jasem", "Ajay Kumar Shrestha"], "title": "Toward Youth-Centered Privacy-by-Design in Smart Devices: A Systematic Review", "comment": "To appear in the IEEE CCWC 2026 proceedings", "summary": "This literature review evaluates privacy-by-design frameworks, tools, and policies intended to protect youth in AI-enabled smart devices using a PRISMA-guided workflow. Sources from major academic and grey-literature repositories from the past decade were screened. The search identified 2,216 records; after deduplication and screening, 645 articles underwent eligibility assessment, and 122 were included for analysis. The corpus was organized along three thematic categories: technical solutions, policy/regulatory measures, and education/awareness strategies. Findings reveal that while technical interventions such as on-device processing, federated learning, and lightweight encryption significantly reduce data exposure, their adoption remains limited. Policy frameworks, including the EU's GDPR, the UK Age-Appropriate Design Code, and Canada's PIPEDA, provide important baselines but are hindered by gaps in enforcement and age-appropriate design obligations, while educational initiatives are rarely integrated systematically into curricula. Overall, the corpus skews toward technical solutions (67%) relative to policy (21%) and education (12%), indicating an implementation gap outside the technical domain. To address these challenges, we recommend a multi-stakeholder model in which policymakers, manufacturers, and educators co-develop inclusive, transparent, and context-sensitive privacy ecosystems. This work advances discourse on youth data protection by offering empirically grounded insights and actionable recommendations for the design of ethical, privacy-preserving AI systems tailored to young users.", "AI": {"tldr": "\u8fd9\u7bc7\u6587\u732e\u7efc\u8ff0\u8bc4\u4f30\u4e86AI\u667a\u80fd\u8bbe\u5907\u4e2d\u4fdd\u62a4\u9752\u5c11\u5e74\u7684\u9690\u79c1\u8bbe\u8ba1\u6846\u67b6\u3001\u5de5\u5177\u548c\u653f\u7b56\uff0c\u53d1\u73b0\u6280\u672f\u65b9\u6848\u5360\u4e3b\u5bfc\u4f46\u91c7\u7528\u6709\u9650\uff0c\u653f\u7b56\u6267\u884c\u6709\u5dee\u8ddd\uff0c\u6559\u80b2\u63aa\u65bd\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6574\u5408\u3002", "motivation": "\u8bc4\u4f30AI\u667a\u80fd\u8bbe\u5907\u4e2d\u4fdd\u62a4\u9752\u5c11\u5e74\u9690\u79c1\u7684\u73b0\u6709\u6846\u67b6\u3001\u5de5\u5177\u548c\u653f\u7b56\uff0c\u8bc6\u522b\u5f53\u524d\u4fdd\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\u548c\u5dee\u8ddd\uff0c\u4e3a\u8bbe\u8ba1\u7b26\u5408\u4f26\u7406\u7684\u9690\u79c1\u4fdd\u62a4AI\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u91c7\u7528PRISMA\u6307\u5bfc\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7b5b\u9009\u8fc7\u53bb\u5341\u5e74\u4e3b\u8981\u5b66\u672f\u548c\u7070\u8272\u6587\u732e\u5e93\u76842216\u6761\u8bb0\u5f55\uff0c\u7ecf\u8fc7\u53bb\u91cd\u548c\u7b5b\u9009\u540e\uff0c645\u7bc7\u8fdb\u884c\u8d44\u683c\u8bc4\u4f30\uff0c\u6700\u7ec8122\u7bc7\u7eb3\u5165\u5206\u6790\uff0c\u6309\u6280\u672f\u65b9\u6848\u3001\u653f\u7b56\u6cd5\u89c4\u63aa\u65bd\u3001\u6559\u80b2\u610f\u8bc6\u7b56\u7565\u4e09\u4e2a\u4e3b\u9898\u7c7b\u522b\u7ec4\u7ec7\u3002", "result": "\u6280\u672f\u5e72\u9884\uff08\u5982\u8bbe\u5907\u7aef\u5904\u7406\u3001\u8054\u90a6\u5b66\u4e60\u3001\u8f7b\u91cf\u7ea7\u52a0\u5bc6\uff09\u663e\u8457\u51cf\u5c11\u6570\u636e\u66b4\u9732\u4f46\u91c7\u7528\u6709\u9650\uff1b\u653f\u7b56\u6846\u67b6\uff08\u5982\u6b27\u76dfGDPR\u3001\u82f1\u56fd\u9002\u9f84\u8bbe\u8ba1\u51c6\u5219\u3001\u52a0\u62ff\u5927PIPEDA\uff09\u63d0\u4f9b\u91cd\u8981\u57fa\u7ebf\u4f46\u6267\u884c\u548c\u9002\u9f84\u8bbe\u8ba1\u4e49\u52a1\u5b58\u5728\u5dee\u8ddd\uff1b\u6559\u80b2\u5021\u8bae\u5f88\u5c11\u7cfb\u7edf\u6574\u5408\u5230\u8bfe\u7a0b\u4e2d\uff1b\u6587\u732e\u504f\u5411\u6280\u672f\u65b9\u6848\uff0867%\uff09\u800c\u975e\u653f\u7b56\uff0821%\uff09\u548c\u6559\u80b2\uff0812%\uff09\u3002", "conclusion": "\u9700\u8981\u591a\u65b9\u5229\u76ca\u76f8\u5173\u8005\u6a21\u578b\uff0c\u8ba9\u653f\u7b56\u5236\u5b9a\u8005\u3001\u5236\u9020\u5546\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u5171\u540c\u5f00\u53d1\u5305\u5bb9\u3001\u900f\u660e\u548c\u60c5\u5883\u654f\u611f\u7684\u9690\u79c1\u751f\u6001\u7cfb\u7edf\uff0c\u4e3a\u5e74\u8f7b\u7528\u6237\u8bbe\u8ba1\u7b26\u5408\u4f26\u7406\u7684\u9690\u79c1\u4fdd\u62a4AI\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u8bc1\u89c1\u89e3\u548c\u53ef\u884c\u5efa\u8bae\u3002"}}
{"id": "2601.13874", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13874", "abs": "https://arxiv.org/abs/2601.13874", "authors": ["Shijie Zhong", "Jiangfeng Fu", "Yikun Yang"], "title": "Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses", "comment": null, "summary": "The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\\mathcal O(n^2)$ to $\\mathcal O(n \\log n)$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u7edf\u8ba1\u91cf\u7684\u65b9\u5dee\u7279\u6027\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u6709\u9650\u6837\u672c\u8868\u5f81\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u62c9\u666e\u62c9\u65af\u6838\u4e0b\u5355\u53d8\u91cf\u60c5\u51b5\u4e0b\u7684\u7cbe\u786e\u52a0\u901f\u65b9\u6cd5\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u4f4e\u5230O(n log n)\u3002", "motivation": "MMD\u662f\u4e00\u79cd\u57fa\u4e8e\u6838\u7684\u975e\u53c2\u6570\u7edf\u8ba1\u91cf\uff0c\u7528\u4e8e\u4e24\u6837\u672c\u68c0\u9a8c\uff0c\u5176\u63a8\u65ad\u51c6\u786e\u6027\u4e25\u91cd\u4f9d\u8d56\u4e8e\u65b9\u5dee\u8868\u5f81\u3002\u73b0\u6709\u7814\u7a76\u63d0\u4f9b\u4e86\u5404\u79cdMMD\u65b9\u5dee\u7684\u6709\u9650\u6837\u672c\u4f30\u8ba1\u5668\uff0c\u4f46\u8fd9\u4e9b\u4f30\u8ba1\u5668\u5728\u96f6\u5047\u8bbe\u548c\u5907\u62e9\u5047\u8bbe\u4e0b\u3001\u5728\u5e73\u8861\u6216\u4e0d\u5e73\u8861\u91c7\u6837\u65b9\u6848\u4e2d\u5f80\u5f80\u5b58\u5728\u5dee\u5f02\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u901a\u8fc7MMD\u7edf\u8ba1\u91cf\u7684U\u7edf\u8ba1\u91cf\u8868\u793a\u548cHoeffding\u5206\u89e3\u6765\u7814\u7a76\u5176\u65b9\u5dee\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u8986\u76d6\u4e0d\u540c\u5047\u8bbe\u548c\u6837\u672c\u914d\u7f6e\u7684\u7edf\u4e00\u6709\u9650\u6837\u672c\u8868\u5f81\u3002\u57fa\u4e8e\u6b64\u5206\u6790\uff0c\u9488\u5bf9\u62c9\u666e\u62c9\u65af\u6838\u4e0b\u7684\u5355\u53d8\u91cf\u60c5\u51b5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u52a0\u901f\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86MMD\u65b9\u5dee\u5728\u4e0d\u540c\u5047\u8bbe\u548c\u6837\u672c\u914d\u7f6e\u4e0b\u7684\u7edf\u4e00\u6709\u9650\u6837\u672c\u8868\u5f81\u3002\u5728\u62c9\u666e\u62c9\u65af\u6838\u4e0b\u5355\u53d8\u91cf\u60c5\u51b5\u4e0b\uff0c\u63d0\u51fa\u7684\u52a0\u901f\u65b9\u6cd5\u5c06\u6574\u4f53\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(n\u00b2)\u964d\u4f4e\u5230O(n log n)\u3002", "conclusion": "\u672c\u6587\u4e3aMMD\u65b9\u5dee\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u6838\u51fd\u6570\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u52a0\u901f\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u9ad8\u6548\u7684\u4e24\u6837\u672c\u68c0\u9a8c\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2601.12166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12166", "abs": "https://arxiv.org/abs/2601.12166", "authors": ["Chengwenjian Wang", "Alexander S. Estes", "Jean-Philippe P. Richard"], "title": "Balancing adaptability and predictability: K-revision multistage stochastic programming", "comment": "41 pages, 10 figures, 5 tables", "summary": "A standard assumption in multistage stochastic programming is that decisions are made after observing the uncertainty from the prior stage. The resulting solutions can be difficult to implement in practice, as they leave practitioners ill-prepared for future stages. To provide better foresight, we introduce the K-revision approach. This new framework requires plans to be specified in advance. To maintain flexibility, we allow plans to be revised a maximum of K times as new information becomes available. We analyze the complexity of K-revision problems, showing NP-hardness even in a simple setting. We examine, both theoretically and computationally, the impact of the K-revision approach on the objective compared with classical multistage stochastic programming models and the partially adaptive approach introduced in [1, 2]. We develop two MIP formulations, one directly from our definition and the other based on a combinatorial characterization. We analyze the tightness of these formulations and propose several methods to strengthen them. Computational experiments on synthetic problems and practical applications demonstrate that our approach is both computationally tractable and effective in reaching near-optimal performance while increasing the predictability of the solutions produced.", "AI": {"tldr": "\u63d0\u51faK-revision\u65b9\u6cd5\u6539\u8fdb\u591a\u9636\u6bb5\u968f\u673a\u89c4\u5212\uff0c\u8981\u6c42\u63d0\u524d\u5236\u5b9a\u8ba1\u5212\u4f46\u5141\u8bb8\u6700\u591aK\u6b21\u4fee\u8ba2\uff0c\u5e73\u8861\u7075\u6d3b\u6027\u4e0e\u53ef\u9884\u6d4b\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u9636\u6bb5\u968f\u673a\u89c4\u5212\u4e2d\u51b3\u7b56\u5728\u89c2\u6d4b\u4e0d\u786e\u5b9a\u6027\u540e\u505a\u51fa\uff0c\u5bfc\u81f4\u89e3\u51b3\u65b9\u6848\u96be\u4ee5\u5b9e\u65bd\uff0c\u7f3a\u4e4f\u5bf9\u672a\u6765\u9636\u6bb5\u7684\u51c6\u5907\u3002\u9700\u8981\u63d0\u4f9b\u66f4\u597d\u7684\u524d\u77bb\u6027\u3002", "method": "\u5f15\u5165K-revision\u6846\u67b6\uff1a\u8981\u6c42\u63d0\u524d\u5236\u5b9a\u8ba1\u5212\uff0c\u4f46\u5141\u8bb8\u968f\u7740\u65b0\u4fe1\u606f\u51fa\u73b0\u6700\u591a\u8fdb\u884cK\u6b21\u4fee\u8ba2\u3002\u5f00\u53d1\u4e24\u79cdMIP\u516c\u5f0f\uff0c\u5206\u6790\u5176\u7d27\u81f4\u6027\u5e76\u63d0\u51fa\u5f3a\u5316\u65b9\u6cd5\u3002", "result": "\u8bc1\u660eK-revision\u95ee\u9898\u5373\u4f7f\u5728\u7b80\u5355\u8bbe\u7f6e\u4e0b\u4e5f\u662fNP\u96be\u7684\u3002\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u8ba1\u7b97\u53ef\u884c\u4e14\u6709\u6548\uff0c\u80fd\u5728\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u53ef\u9884\u6d4b\u6027\u7684\u540c\u65f6\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "K-revision\u65b9\u6cd5\u5728\u8ba1\u7b97\u53ef\u884c\u6027\u548c\u89e3\u51b3\u65b9\u6848\u53ef\u9884\u6d4b\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u76f8\u6bd4\u4f20\u7edf\u591a\u9636\u6bb5\u968f\u673a\u89c4\u5212\u548c\u90e8\u5206\u81ea\u9002\u5e94\u65b9\u6cd5\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.11658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11658", "abs": "https://arxiv.org/abs/2601.11658", "authors": ["Indrajit Kar", "Sammy Zonunpuia", "Zonunfeli Ralte"], "title": "Towards AGI A Pragmatic Approach Towards Self Evolving Agent", "comment": null, "summary": "Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u548c\u8fdb\u5316\u7b97\u6cd5\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u6269\u5c55\u80fd\u529b\u3001\u751f\u6210\u65b0\u5de5\u5177\u548c\u8fdb\u5316\u63a8\u7406\u8fc7\u7a0b", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u90e8\u7f72\u540e\u662f\u9759\u6001\u7684\uff0c\u7f3a\u4e4f\u81ea\u4e3b\u6269\u5c55\u80fd\u529b\u3001\u751f\u6210\u65b0\u5de5\u5177\u6216\u8fdb\u5316\u63a8\u7406\u7684\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6301\u7eed\u81ea\u9002\u5e94\u8fdb\u5316\u7684\u6846\u67b6", "method": "\u5206\u5c42\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a\u96c6\u6210\u57fa\u7840LLM\u3001\u64cd\u4f5cSLM\u667a\u80fd\u4f53\u3001\u4ee3\u7801\u751f\u6210LLM\u548c\u6559\u5e08LLM\u3002\u5de5\u4f5c\u6d41\u7a0b\uff1a\u5148\u5c1d\u8bd5\u73b0\u6709\u5de5\u5177\uff0c\u5931\u8d25\u65f6\u901a\u8fc7\u4ee3\u7801\u751f\u6210LLM\u5408\u6210\u65b0\u5de5\u5177\uff0c\u6301\u7eed\u5931\u8d25\u65f6\u89e6\u53d1\u8fdb\u5316\u9636\u6bb5\uff08\u8bfe\u7a0b\u5b66\u4e60\u3001\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60\u6216\u9057\u4f20\u7b97\u6cd5\u8fdb\u5316\uff09", "result": "\u5728TaskCraft\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff1a\u8bfe\u7a0b\u5b66\u4e60\u63d0\u4f9b\u5feb\u901f\u6062\u590d\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9057\u4f20\u7b97\u6cd5\u63d0\u4f9b\u9ad8\u884c\u4e3a\u591a\u6837\u6027\u3002\u6240\u6709\u8bbe\u7f6e\u4e2d\uff0c\u8fdb\u5316\u540e\u7684\u667a\u80fd\u4f53\u90fd\u4f18\u4e8e\u539f\u59cb\u7248\u672c", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u7a33\u5065\u3001\u81ea\u4e3b\u3001\u81ea\u6211\u6539\u8fdb\u7684\u667a\u80fd\u4f53\u8fdb\u5316\uff0c\u8bc1\u660e\u4e86LLM\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u5408\u6210\u548c\u8fdb\u5316\u7b97\u6cd5\u6301\u7eed\u63d0\u5347\u80fd\u529b"}}
{"id": "2601.11618", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11618", "abs": "https://arxiv.org/abs/2601.11618", "authors": ["Luis Rosario Freytes"], "title": "Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention", "comment": "57 pages", "summary": "Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.", "AI": {"tldr": "\u51e0\u4f55\u6ce8\u610f\u529b\uff08GA\uff09\u901a\u8fc7\u56db\u4e2a\u72ec\u7acb\u8f93\u5165\u5b9a\u4e49\u6ce8\u610f\u529b\u5c42\uff1a\u8f7d\u4f53\u3001\u8bc1\u636e\u6838\u89c4\u5219\u3001\u63a2\u9488\u65cf\u548c\u951a\u5b9a/\u66f4\u65b0\u89c4\u5219\uff0c\u5c06\u4e0d\u53d8\u7ed3\u6784\u4e0e\u5efa\u6a21\u9009\u62e9\u5206\u79bb\uff0c\u5b9e\u73b0\u6ce8\u610f\u529b\u673a\u5236\u7684\u7cfb\u7edf\u5316\u6bd4\u8f83\u548c\u6269\u5c55\u3002", "motivation": "\u73b0\u6709\u6ce8\u610f\u529b\u673a\u5236\uff08\u5982Transformer\u4e2d\u7684softmax\uff09\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u96be\u4ee5\u8fdb\u884c\u7cfb\u7edf\u5316\u6bd4\u8f83\u548c\u6269\u5c55\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u51e0\u4f55\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u5c06\u6ce8\u610f\u529b\u5c42\u7684\u6838\u5fc3\u7ec4\u4ef6\u5f62\u5f0f\u5316\uff0c\u5206\u79bb\u4e0d\u53d8\u7ed3\u6784\u4e0e\u5efa\u6a21\u9009\u62e9\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u6ce8\u610f\u529b\uff08GA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u72ec\u7acb\u7ec4\u4ef6\u5b9a\u4e49\u6ce8\u610f\u529b\u5c42\uff1a1\uff09\u6709\u9650\u8f7d\u4f53\uff08\u53ef\u5bfb\u5740\u7d22\u5f15\uff09\uff0c2\uff09\u8bc1\u636e\u6838\u89c4\u5219\uff08\u5982\u4f55\u4ece\u63a9\u7801\u539f\u59cb\u5206\u6570\u548c\u94fe\u63a5\u4ea7\u751f\u975e\u8d1f\u6743\u91cd\uff09\uff0c3\uff09\u63a2\u9488\u65cf\uff08\u53ef\u89c2\u6d4b\u91cf\u7684\u96c6\u5408\uff09\uff0c4\uff09\u951a\u5b9a/\u66f4\u65b0\u89c4\u5219\uff08\u9009\u62e9\u548c\u5e94\u7528\u4ee3\u8868\u6027\u6838\uff09\u3002\u8be5\u6846\u67b6\u652f\u6301\u591a\u79cd\u6ce8\u610f\u529b\u53d8\u4f53\uff0c\u5305\u62ecsoftmax\u3001\u4f4e\u79e9\u4ea4\u4e92\u3001\u591a\u5934/\u6df7\u5408\u6838\u3001\u57fa\u4e8e\u8ba1\u5212\u7684\u951a\u5b9a\u7b49\u3002", "result": "\u5728\u6807\u91cf\u5173\u7cfb\u5de5\u4f5c\u8868\u793a\u548c\u8bc1\u636e\u7684\u4e58\u6cd5\u7ec4\u5408\u5f8b\u4e0b\uff0c\u53ef\u63a5\u53d7\u7684\u94fe\u63a5\u65cf\u662f\u6307\u6570\u65cf\uff0c\u4ea7\u751fGibbs\u6743\u91cd\uff1b\u884c\u951a\u5b9a\u5305\u542bsoftmax\u6838\u65cf\u4f5c\u4e3a\u5b50\u673a\u5236\u3002\u901a\u8fc7\u5546\u6389\u4e00\u5143\u884c/\u5217\u5206\u6570\u573a\uff0c\u5269\u4f59\u4ea4\u4e92\u5206\u91cf\u5177\u6709\u89c4\u8303\u79e9r\u6b63\u6001\u5f62\u5f0f\uff08Eckart-Young/SVD\uff09\uff1b\u70b9\u79ef\u5206\u6570\u56fe\u5b9e\u73b0\u76f8\u5e94\u7684\u4f4e\u79e9\u4ea4\u4e92\u673a\u5236\u3002", "conclusion": "\u51e0\u4f55\u6ce8\u610f\u529b\u6846\u67b6\u5c06\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e0d\u53d8\u7ed3\u6784\u4e0e\u5177\u4f53\u5efa\u6a21\u9009\u62e9\u5206\u79bb\uff0c\u4e3a\u7cfb\u7edf\u5316\u6bd4\u8f83\u548c\u6269\u5c55\u6ce8\u610f\u529b\u673a\u5236\u53ca\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002\u8be5\u6846\u67b6\u652f\u6301\u56fa\u5b9a\u8f7d\u4f53\uff08\u6807\u51c6Transformer\uff09\u3001\u81ea\u9002\u5e94\u8f7d\u4f53\u3001\u591a\u9636\u6bb5\u6df1\u5ea6\u7b49\u591a\u79cd\u673a\u5236\uff0c\u5e76\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u6ce8\u610f\u529b\u53d8\u4f53\u3002"}}
{"id": "2601.11840", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11840", "abs": "https://arxiv.org/abs/2601.11840", "authors": ["Hongyu Lin", "Samer Abdallah", "Makar Valentinov", "Paul Brennan", "Elijah Kagan", "Christoph M. Wintersteiger", "Denis Ignatovich", "Grant Passmore"], "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic", "comment": "52 pages, 23 figures. Includes a new benchmark dataset (code-logic-bench) and evaluation of neurosymbolic reasoning for software analysis", "summary": "Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.\n  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.\n  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.\n  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.", "AI": {"tldr": "CodeLogician\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u4ee3\u7406\uff0c\u7ed3\u5408LLMs\u548c\u5f62\u5f0f\u5316\u63a8\u7406\u5f15\u64ceImandraX\uff0c\u7528\u4e8e\u7cbe\u786e\u5206\u6790\u8f6f\u4ef6\u903b\u8f91\uff0c\u5728\u4ee3\u7801\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u4e0a\u76f8\u6bd4\u7eafLLM\u65b9\u6cd5\u63d0\u534741-47\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7a0b\u5e8f\u884c\u4e3a\u8fdb\u884c\u7cbe\u786e\u3001\u8be6\u5c3d\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u57fa\u51c6\u8981\u4e48\u4e13\u6ce8\u4e8e\u4e0e\u73b0\u5b9e\u8f6f\u4ef6\u8131\u8282\u7684\u6570\u5b66\u8bc1\u660e\u81ea\u52a8\u5316\uff0c\u8981\u4e48\u4e13\u6ce8\u4e8e\u4e0d\u9700\u8981\u8bed\u4e49\u4e25\u8c28\u6027\u7684\u5de5\u7a0b\u4efb\u52a1\u3002", "method": "\u63d0\u51faCodeLogician\u795e\u7ecf\u7b26\u53f7\u4ee3\u7406\uff0c\u5c06LLMs\u4e0e\u5de5\u4e1a\u7ea7\u81ea\u52a8\u63a8\u7406\u5f15\u64ceImandraX\u96c6\u6210\u3002LLMs\u7528\u4e8e\u6784\u5efa\u8f6f\u4ef6\u7cfb\u7edf\u7684\u663e\u5f0f\u5f62\u5f0f\u6a21\u578b\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u56de\u7b54\u4e30\u5bcc\u7684\u8bed\u4e49\u95ee\u9898\uff0c\u8d85\u8d8a\u4e86\u4ec5\u9a8c\u8bc1LLM\u8f93\u51fa\u7684\u4f20\u7edf\u65b9\u6cd5\u3002", "result": "\u5728code-logic-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCodeLogician\u76f8\u6bd4\u7eafLLM\u63a8\u7406\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u51c6\u786e\u6027\u4e0a\u5b9e\u73b0\u4e8641-47\u4e2a\u767e\u5206\u70b9\u7684\u663e\u8457\u63d0\u5347\uff0c\u586b\u8865\u4e86LLMs\u5728\u7cbe\u786e\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u5dee\u8ddd\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u96c6\u6210\u5bf9\u4e8e\u6269\u5c55\u7a0b\u5e8f\u5206\u6790\u3001\u5b9e\u73b0\u4e25\u8c28\u81ea\u4e3b\u7684\u8f6f\u4ef6\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002CodeLogician\u5c55\u793a\u4e86\u5c06LLMs\u4e0e\u5f62\u5f0f\u5316\u65b9\u6cd5\u7ed3\u5408\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5bf9\u8f6f\u4ef6\u903b\u8f91\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.12334", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12334", "abs": "https://arxiv.org/abs/2601.12334", "authors": ["Alberto Bemporad"], "title": "Worst-case Nonlinear Regression with Error Bounds", "comment": "23 pages, 8 figures", "summary": "This paper proposes an active-learning approach to worst-case nonlinear regression with deterministic error guarantees. Given a known nonlinear function defined over a compact set, we compute a surrogate model, such as a feedforward neural network, by minimizing the maximum absolute approximation error. To address the nonsmooth nature of the resulting minimax problem, we introduce a smooth approximation of the $L_\\infty$-type loss that enables efficient gradient-based training. We iteratively enrich the training set by actively learning points of largest approximation error through global optimization. The resulting models admit certified worst-case error bounds, either constant or input-dependent, over the entire input domain. The approach is demonstrated through approximations of nonlinear functions and nonconvex sets, as well as through the derivation of uncertain models of more complex nonlinear dynamics within a given model class, and the approximation of explicit model predictive control laws.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5177\u6709\u786e\u5b9a\u6027\u8bef\u5dee\u4fdd\u8bc1\u7684\u6700\u574f\u60c5\u51b5\u975e\u7ebf\u6027\u56de\u5f52\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6700\u5927\u7edd\u5bf9\u903c\u8fd1\u8bef\u5dee\u6765\u6784\u5efa\u4ee3\u7406\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u8bef\u5dee\u8fb9\u754c\u3002", "motivation": "\u5728\u975e\u7ebf\u6027\u56de\u5f52\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u5e73\u5747\u8bef\u5dee\uff0c\u4f46\u8bb8\u591a\u5e94\u7528\u9700\u8981\u786e\u5b9a\u6027\u8bef\u5dee\u4fdd\u8bc1\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u975e\u5149\u6ed1\u7684L\u221e\u578b\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5bf9\u6574\u4e2a\u8f93\u5165\u57df\u7684\u8ba4\u8bc1\u8bef\u5dee\u8fb9\u754c\u3002", "method": "1) \u5f15\u5165L\u221e\u578b\u635f\u5931\u7684\u5149\u6ed1\u8fd1\u4f3c\u4ee5\u652f\u6301\u68af\u5ea6\u8bad\u7ec3\uff1b2) \u901a\u8fc7\u5168\u5c40\u4f18\u5316\u4e3b\u52a8\u5b66\u4e60\u6700\u5927\u8bef\u5dee\u70b9\u6765\u8fed\u4ee3\u4e30\u5bcc\u8bad\u7ec3\u96c6\uff1b3) \u6784\u5efa\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7b49\u4ee3\u7406\u6a21\u578b\uff0c\u6700\u5c0f\u5316\u6700\u5927\u7edd\u5bf9\u903c\u8fd1\u8bef\u5dee\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u5177\u6709\u8ba4\u8bc1\u6700\u574f\u60c5\u51b5\u8bef\u5dee\u8fb9\u754c\u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u662f\u5e38\u6570\u8fb9\u754c\u6216\u8f93\u5165\u76f8\u5173\u8fb9\u754c\u3002\u5728\u975e\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u3001\u975e\u51f8\u96c6\u8868\u793a\u3001\u590d\u6742\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e0d\u786e\u5b9a\u6a21\u578b\u6784\u5efa\u4ee5\u53ca\u663e\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5f8b\u903c\u8fd1\u7b49\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u4e3a\u975e\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u63d0\u4f9b\u786e\u5b9a\u6027\u8bef\u5dee\u4fdd\u8bc1\uff0c\u901a\u8fc7\u5149\u6ed1\u8fd1\u4f3c\u548c\u4e3b\u52a8\u91c7\u6837\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5404\u79cd\u5e94\u7528\u63d0\u4f9b\u4e86\u5177\u6709\u8ba4\u8bc1\u8bef\u5dee\u8fb9\u754c\u7684\u53ef\u9760\u4ee3\u7406\u6a21\u578b\u3002"}}
{"id": "2601.11600", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11600", "abs": "https://arxiv.org/abs/2601.11600", "authors": ["Luh Yuliani Purnama Dewi", "Leon Andretti Abdillah"], "title": "OVO Fintech Application Analysis using The System Usability Scale", "comment": "10 pages", "summary": "The advancement of information technology has propelled payment systems from conventional methods to technology-based solutions, such as e-wallets and Fintech. Fintech, a fusion of technology and financial services, has evolved into an online business model enabling fast and remote transactions. This research discusses the progress of information technology influencing payment systems, particularly in the realm of Fintech. The primary focus is on the Fintech application OVO and its impact on tenants at the International Plaza Mall in Palembang. This study employs the System Usability Scale or SUS to evaluate the Usability of the OVO application, emphasizing aspects like effectiveness, efficiency, and user satisfaction. The research is descriptive and quantitative, with a sample of 50 respondents from Mall IP tenants. Data is collected through SUS questionnaires and analyzed using SPSS. The evaluation indicates that the OVO application has high Usability, with an SUS score of 87.05 or Grade A, signifying an Excellent rating. It suggests that the OVO application provides a comfortable user experience, particularly in electronic financial transactions.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86Fintech\u5e94\u7528OVO\u5728\u56fd\u9645\u5e7f\u573a\u5546\u573a\u79df\u6237\u4e2d\u7684\u53ef\u7528\u6027\uff0c\u4f7f\u7528SUS\u91cf\u8868\u83b7\u5f9787.05\u5206\uff08A\u7ea7\u4f18\u79c0\u8bc4\u7ea7\uff09\uff0c\u8868\u660e\u8be5\u5e94\u7528\u5728\u7535\u5b50\u91d1\u878d\u4ea4\u6613\u4e2d\u63d0\u4f9b\u826f\u597d\u7684\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u4fe1\u606f\u6280\u672f\u53d1\u5c55\uff0c\u652f\u4ed8\u7cfb\u7edf\u4ece\u4f20\u7edf\u65b9\u5f0f\u8f6c\u5411\u6280\u672f\u9a71\u52a8\u65b9\u6848\u5982\u7535\u5b50\u94b1\u5305\u548c\u91d1\u878d\u79d1\u6280\u3002\u91d1\u878d\u79d1\u6280\u878d\u5408\u6280\u672f\u4e0e\u91d1\u878d\u670d\u52a1\uff0c\u5df2\u6210\u4e3a\u652f\u6301\u5feb\u901f\u8fdc\u7a0b\u4ea4\u6613\u7684\u5728\u7ebf\u5546\u4e1a\u6a21\u5f0f\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u4fe1\u606f\u6280\u672f\u5bf9\u652f\u4ed8\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8Fintech\u5e94\u7528OVO\u53ca\u5176\u5bf9\u5546\u573a\u79df\u6237\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u63cf\u8ff0\u6027\u5b9a\u91cf\u7814\u7a76\u65b9\u6cd5\uff0c\u4ece\u56fd\u9645\u5e7f\u573a\u5546\u573a\u79df\u6237\u4e2d\u9009\u53d650\u540d\u53d7\u8bbf\u8005\u4f5c\u4e3a\u6837\u672c\u3002\u4f7f\u7528\u7cfb\u7edf\u53ef\u7528\u6027\u91cf\u8868\uff08SUS\uff09\u8bc4\u4f30OVO\u5e94\u7528\u7684\u53ef\u7528\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002\u901a\u8fc7SUS\u95ee\u5377\u6536\u96c6\u6570\u636e\uff0c\u5e76\u4f7f\u7528SPSS\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "OVO\u5e94\u7528\u83b7\u5f9787.05\u7684SUS\u5206\u6570\uff0c\u88ab\u8bc4\u4e3aA\u7ea7\u4f18\u79c0\u3002\u8fd9\u8868\u660e\u8be5\u5e94\u7528\u5177\u6709\u9ad8\u53ef\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u7535\u5b50\u91d1\u878d\u4ea4\u6613\u4e2d\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u8212\u9002\u7684\u4f7f\u7528\u4f53\u9a8c\u3002", "conclusion": "OVO\u5e94\u7528\u4f5c\u4e3aFintech\u652f\u4ed8\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u56fd\u9645\u5e7f\u573a\u5546\u573a\u79df\u6237\u4e2d\u8868\u73b0\u51fa\u4f18\u79c0\u7684\u53ef\u7528\u6027\u3002\u9ad8SUS\u8bc4\u5206\u8bc1\u5b9e\u4e86\u8be5\u5e94\u7528\u5728\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u65b9\u9762\u7684\u826f\u597d\u8868\u73b0\uff0c\u4e3a\u7535\u5b50\u91d1\u878d\u4ea4\u6613\u63d0\u4f9b\u4e86\u8212\u9002\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.14031", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14031", "abs": "https://arxiv.org/abs/2601.14031", "authors": ["Stefano Damato", "Nicol\u00f2 Rubattu", "Dario Azzimonti", "Giorgio Corani"], "title": "Intermittent time series forecasting: local vs global models", "comment": "Submitted to Data Mining and Knowledge Discovery", "summary": "Intermittent time series, characterised by the presence of a significant amount of zeros, constitute a large percentage of inventory items in supply chain. Probabilistic forecasts are needed to plan the inventory levels; the predictive distribution should cover non-negative values, have a mass in zero and a long upper tail. Intermittent time series are commonly forecast using local models, which are trained individually on each time series. In the last years global models, which are trained on a large collection of time series, have become popular for time series forecasting. Global models are often based on neural networks. However, they have not yet been exhaustively tested on intermittent time series. We carry out the first study comparing state-of-the-art local (iETS, TweedieGP) and global models (D-Linear, DeepAR, Transformers) on intermittent time series. For neural networks models we consider three different distribution heads suitable for intermittent time series: negative binomial, hurdle-shifted negative binomial and Tweedie. We use, for the first time, the last two distribution heads with neural networks. We perform experiments on five large datasets comprising more than 40'000 real-world time series. Among neural networks D-Linear provides best accuracy; it also consistently outperforms the local models. Moreover, it has also low computational requirements. Transformers-based architectures are instead much more computationally demanding and less accurate. Among the distribution heads, the Tweedie provides the best estimates of the highest quantiles, while the negative binomial offers overall the best performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5c40\u90e8\u6a21\u578b\u548c\u5168\u5c40\u6a21\u578b\u5728\u95f4\u6b47\u6027\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684D-Linear\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u5c40\u90e8\u6a21\u578b\u3002", "motivation": "\u95f4\u6b47\u6027\u65f6\u95f4\u5e8f\u5217\uff08\u5305\u542b\u5927\u91cf\u96f6\u503c\uff09\u5728\u4f9b\u5e94\u94fe\u5e93\u5b58\u7ba1\u7406\u4e2d\u5360\u6bd4\u5f88\u5927\uff0c\u9700\u8981\u80fd\u591f\u5904\u7406\u975e\u8d1f\u503c\u3001\u96f6\u6982\u7387\u8d28\u91cf\u548c\u957f\u4e0a\u5c3e\u7684\u9884\u6d4b\u5206\u5e03\u3002\u867d\u7136\u5168\u5c40\u6a21\u578b\uff08\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\uff09\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8d8a\u6765\u8d8a\u6d41\u884c\uff0c\u4f46\u5c1a\u672a\u5728\u95f4\u6b47\u6027\u65f6\u95f4\u5e8f\u5217\u4e0a\u5f97\u5230\u5145\u5206\u6d4b\u8bd5\u3002", "method": "\u9996\u6b21\u6bd4\u8f83\u4e86\u6700\u5148\u8fdb\u7684\u5c40\u90e8\u6a21\u578b\uff08iETS, TweedieGP\uff09\u548c\u5168\u5c40\u6a21\u578b\uff08D-Linear, DeepAR, Transformers\uff09\u5728\u95f4\u6b47\u6027\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u8868\u73b0\u3002\u4e3a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8003\u8651\u4e86\u4e09\u79cd\u9002\u5408\u95f4\u6b47\u6027\u5e8f\u5217\u7684\u5206\u5e03\u5934\uff1a\u8d1f\u4e8c\u9879\u5206\u5e03\u3001\u969c\u788d\u79fb\u4f4d\u8d1f\u4e8c\u9879\u5206\u5e03\u548cTweedie\u5206\u5e03\uff0c\u5176\u4e2d\u540e\u4e24\u79cd\u662f\u9996\u6b21\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u4f7f\u7528\u3002\u5728\u5305\u542b\u8d85\u8fc740,000\u4e2a\u771f\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u7684\u4e94\u4e2a\u5927\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\uff0cD-Linear\u63d0\u4f9b\u6700\u4f73\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u59cb\u7ec8\u4f18\u4e8e\u5c40\u90e8\u6a21\u578b\uff0c\u540c\u65f6\u8ba1\u7b97\u9700\u6c42\u8f83\u4f4e\u3002\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u8ba1\u7b97\u9700\u6c42\u5927\u4e14\u51c6\u786e\u6027\u8f83\u4f4e\u3002\u5728\u5206\u5e03\u5934\u4e2d\uff0cTweedie\u5bf9\u6700\u9ad8\u5206\u4f4d\u6570\u4f30\u8ba1\u6700\u597d\uff0c\u800c\u8d1f\u4e8c\u9879\u5206\u5e03\u5728\u6574\u4f53\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5168\u5c40\u6a21\u578b\u7279\u522b\u662fD-Linear\u5728\u95f4\u6b47\u6027\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u4f20\u7edf\u5c40\u90e8\u6a21\u578b\uff0c\u4e3a\u4f9b\u5e94\u94fe\u5e93\u5b58\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12190", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12190", "abs": "https://arxiv.org/abs/2601.12190", "authors": ["Luis Brice\u00f1o-Arias", "Fernando Rold\u00e1n"], "title": "Optimal Leveraging of Smoothness and Strong Convexity for Peaceman--Rachford Splitting", "comment": null, "summary": "In this paper, we introduce a simple methodology to leverage strong convexity and smoothness in order to obtain an optimal linear convergence rate for the Peaceman--Rachford splitting (PRS) scheme applied to optimization problems involving two smooth strongly convex functions. The approach consists of adding and subtracting suitable quadratic terms from one function to the other so as to redistribute strong convexity in the primal formulation and smoothness in the dual formulation. This yields an equivalent modified optimization problem in which each term has adjustable levels of strong convexity and smoothness. In this setting, the Peaceman--Rachford splitting method converges linearly to the solution of the modified problem with a convergence rate that can be optimized with respect to the introduced parameters. Upon returning to the original formulation, this procedure gives rise to a modified variant of PRS. The optimal linear rate established in this work is strictly better than the best rates previously available in the general setting. The practical performance of the method is illustrated through an academic example and applications in image processing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u8c03\u6574\u5f3a\u51f8\u6027\u548c\u5149\u6ed1\u6027\u5206\u5e03\u6765\u4f18\u5316Peaceman-Rachford\u5206\u88c2\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u83b7\u5f97\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u7684\u7ebf\u6027\u6536\u655b\u7387\u3002", "motivation": "Peaceman-Rachford\u5206\u88c2(PRS)\u65b9\u6cd5\u5728\u5904\u7406\u4e24\u4e2a\u5149\u6ed1\u5f3a\u51f8\u51fd\u6570\u7684\u4f18\u5316\u95ee\u9898\u65f6\uff0c\u73b0\u6709\u7684\u6536\u655b\u7387\u4e0d\u662f\u6700\u4f18\u7684\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u6700\u4f18\u7684\u7ebf\u6027\u6536\u655b\u7387\u3002", "method": "\u901a\u8fc7\u5728\u539f\u95ee\u9898\u4e2d\u6dfb\u52a0\u548c\u51cf\u53bb\u9002\u5f53\u7684\u4e8c\u6b21\u9879\uff0c\u91cd\u65b0\u5206\u914d\u5f3a\u51f8\u6027\uff08\u5728\u539f\u59cb\u5f62\u5f0f\u4e2d\uff09\u548c\u5149\u6ed1\u6027\uff08\u5728\u5bf9\u5076\u5f62\u5f0f\u4e2d\uff09\uff0c\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u7b49\u4ef7\u7684\u4fee\u6b63\u4f18\u5316\u95ee\u9898\u3002\u5728\u4fee\u6b63\u95ee\u9898\u4e2d\uff0c\u6bcf\u4e2a\u9879\u90fd\u6709\u53ef\u8c03\u8282\u7684\u5f3a\u51f8\u6027\u548c\u5149\u6ed1\u6027\u6c34\u5e73\uff0c\u7136\u540e\u5e94\u7528PRS\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u83b7\u5f97\u4e86\u6700\u4f18\u7684\u7ebf\u6027\u6536\u655b\u7387\uff0c\u4e25\u683c\u4f18\u4e8e\u5148\u524d\u5728\u4e00\u822c\u8bbe\u7f6e\u4e2d\u7684\u6700\u4f73\u6536\u655b\u7387\u3002\u901a\u8fc7\u5b66\u672f\u793a\u4f8b\u548c\u56fe\u50cf\u5904\u7406\u5e94\u7528\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5355\u65b9\u6cd5\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u5f3a\u51f8\u6027\u548c\u5149\u6ed1\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347PRS\u65b9\u6cd5\u7684\u6536\u655b\u901f\u5ea6\uff0c\u4e3a\u5904\u7406\u4e24\u4e2a\u5149\u6ed1\u5f3a\u51f8\u51fd\u6570\u7684\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11722", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11722", "abs": "https://arxiv.org/abs/2601.11722", "authors": ["Ahmed Rayane Kebir", "Vincent Guigue", "Lynda Said Lhadj", "Laure Soulier"], "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search", "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 48th European Conference on Information Retrieval (ECIR '26), 29 March--2 April, 2026, Delft, Netherlands", "summary": "Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.", "AI": {"tldr": "RAC\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u4e8e\u6587\u6863\u7684\u6f84\u6e05\u95ee\u9898\uff0c\u907f\u514d\u65e0\u6839\u636e\u63d0\u95ee\uff0c\u663e\u8457\u63d0\u5347\u95ee\u9898\u5fe0\u5b9e\u5ea6", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u5728\u751f\u6210\u6f84\u6e05\u95ee\u9898\u65f6\u4e3b\u8981\u5173\u6ce8\u6d41\u7545\u6027\u548c\u7528\u6237\u610f\u56fe\u5bf9\u9f50\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u6587\u6863\u7684\u951a\u5b9a\uff0c\u5bfc\u81f4\u53ef\u80fd\u63d0\u51fa\u65e0\u6cd5\u4ece\u53ef\u7528\u6587\u6863\u4e2d\u56de\u7b54\u7684\u95ee\u9898", "method": "\u63d0\u51faRAC\uff08\u68c0\u7d22\u589e\u5f3a\u6f84\u6e05\uff09\u6846\u67b6\uff1a1\uff09\u6bd4\u8f83\u591a\u79cd\u68c0\u7d22\u7d22\u5f15\u7b56\u7565\uff1b2\uff09\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u5145\u5206\u5229\u7528\u68c0\u7d22\u4e0a\u4e0b\u6587\u5e76\u751f\u6210\u57fa\u4e8e\u8bc1\u636e\u7684\u95ee\u9898\uff1b3\uff09\u5e94\u7528\u5bf9\u6bd4\u504f\u597d\u4f18\u5316\uff0c\u4f7f\u57fa\u4e8e\u68c0\u7d22\u6bb5\u843d\u7684\u95ee\u9898\u4f18\u4e8e\u65e0\u6839\u636e\u7684\u66ff\u4ee3\u65b9\u6848", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAC\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\u3002\u9664\u4e86LLM-as-Judge\u8bc4\u4f30\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u57fa\u4e8eNLI\u548c\u6570\u636e\u5230\u6587\u672c\u7684\u65b0\u6307\u6807\u6765\u8bc4\u4f30\u95ee\u9898\u5728\u4e0a\u4e0b\u6587\u4e2d\u7684\u951a\u5b9a\u7a0b\u5ea6\uff0c\u8bc1\u660e\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u5fe0\u5b9e\u5ea6", "conclusion": "RAC\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u5bf9\u6bd4\u4f18\u5316\uff0c\u6210\u529f\u751f\u6210\u4e86\u57fa\u4e8e\u6587\u6863\u7684\u5fe0\u5b9e\u6f84\u6e05\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6587\u6863\u951a\u5b9a\u7684\u95ee\u9898\uff0c\u4e3a\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6f84\u6e05\u673a\u5236"}}
{"id": "2601.11619", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11619", "abs": "https://arxiv.org/abs/2601.11619", "authors": ["Phani Kumar", "Nyshadham", "Jyothendra Varma", "Polisetty V R K", "Aditya Rathore"], "title": "NoiseFormer -- Noise Diffused Symmetric Attention Transformer", "comment": null, "summary": "Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.", "AI": {"tldr": "\u63d0\u51faNoise Diffused Symmetric Attention Transformer\uff0c\u5728\u4fdd\u6301Symmetric Attention\u5185\u5b58\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5fae\u5c0f\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5728GLUE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4ecb\u4e8e\u539f\u59cbSymmetric Attention\u548cGPT2\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u3002", "motivation": "\u968f\u7740Transformer\u6a21\u578b\u89c4\u6a21\u6025\u5267\u589e\u5927\uff0c\u5185\u5b58\u5360\u7528\u95ee\u9898\u5bfc\u81f4\u96be\u4ee5\u5728\u5355\u8bbe\u5907\u4e0a\u90e8\u7f72\uff0c\u9700\u8981\u591a\u8bbe\u5907\u8ba1\u7b97\u4ece\u800c\u589e\u52a0\u6210\u672c\u3002\u7a00\u758f\u6ce8\u610f\u529b\u6280\u672f\u6210\u4e3a\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u7684\u6709\u6548\u9014\u5f84\uff0c\u4f46\u73b0\u6709Symmetric Attention\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u63d0\u51faNoise Diffused Symmetric Attention Transformer\u7edf\u4e00\u67b6\u6784\uff0c\u57fa\u4e8eSymmetric Dot-Product Attention\uff08\u5bf9\u79f0\u6ce8\u610f\u529b\uff09\u6280\u672f\uff0c\u901a\u8fc7\u6dfb\u52a0\u566a\u58f0\u6269\u6563\u673a\u5236\u6765\u589e\u5f3a\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u6709\u7684\u5185\u5b58\u4f18\u52bf\u3002", "result": "\u5728GPT2\u57fa\u7840\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u5728GLUE\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u8868\u73b0\u4ecb\u4e8e\u539f\u59cbSymmetric Attention\u548cGPT2\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6a21\u578b\u5c3a\u5bf8\u7f29\u51cf\u3002", "conclusion": "\u63d0\u51fa\u7684Noise Diffused Symmetric Attention Transformer\u5728\u4fdd\u6301\u7a00\u758f\u6ce8\u610f\u529b\u5185\u5b58\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5fae\u5c0f\u5f00\u9500\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11850", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11850", "abs": "https://arxiv.org/abs/2601.11850", "authors": ["Matthew Nyaaba", "Min SungEun", "Mary Abiswin Apam", "Kwame Owoahene Acheampong", "Emmanuel Dwamena", "Xiaoming Zhai"], "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority", "comment": null, "summary": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fITA-GPT\u5de5\u5177\u5982\u4f55\u652f\u6301\u5f52\u7eb3\u5f0f\u4e3b\u9898\u5206\u6790\uff0c\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u4e2d\u89e3\u91ca\u6743\u5a01\u7684\u5f52\u5c5e\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u4f7f\u7528\u589e\u52a0\uff0c\u9700\u8981\u63a2\u8ba8\u5176\u5bf9\u5206\u6790\u5b9e\u8df5\u548c\u89e3\u91ca\u6743\u5a01\u7684\u5f71\u54cd\uff0c\u7406\u89e3\u4eba\u673a\u534f\u4f5c\u5982\u4f55\u5f71\u54cd\u5f52\u7eb3\u5f0f\u4e3b\u9898\u5206\u6790\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528HACITA\u6846\u67b6\uff0c\u4e09\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u8d28\u6027\u7814\u7a76\u4eba\u5458\u4f7f\u7528ITA-GPT\u5de5\u5177\u5206\u6790\u52a0\u7eb3\u6559\u5e08\u6559\u80b2\u80cc\u666f\u4e0b\u7684\u8bbf\u8c08\u8f6c\u5f55\u672c\u3002\u5de5\u5177\u652f\u6301\u719f\u6089\u5316\u3001\u9010\u5b57\u7f16\u7801\u3001\u52a8\u540d\u8bcd\u63cf\u8ff0\u6027\u7f16\u7801\u548c\u4e3b\u9898\u53d1\u5c55\uff0c\u540c\u65f6\u786e\u4fdd\u6587\u672c\u5b8c\u6574\u6027\u3001\u8986\u76d6\u68c0\u67e5\u548c\u53ef\u5ba1\u8ba1\u6027\u3002\u6570\u636e\u5305\u62ec\u4ea4\u4e92\u65e5\u5fd7\u3001AI\u751f\u6210\u8868\u683c\u3001\u7814\u7a76\u4eba\u5458\u4fee\u8ba2\u3001\u5220\u9664\u3001\u63d2\u5165\u3001\u8bc4\u8bba\u548c\u53cd\u601d\u5907\u5fd8\u5f55\u3002", "result": "ITA-GPT\u4f5c\u4e3a\u7a0b\u5e8f\u6027\u652f\u67b6\uff0c\u7ed3\u6784\u5316\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u5e76\u589e\u5f3a\u900f\u660e\u5ea6\u3002\u7136\u800c\uff0c\u89e3\u91ca\u6743\u5a01\u4ecd\u5c5e\u4e8e\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\uff0c\u4ed6\u4eec\u901a\u8fc7\u4fee\u6539\u3001\u5220\u9664\u3001\u62d2\u7edd\u3001\u63d2\u5165\u548c\u8bc4\u8bba\u7b49\u53cd\u590d\u5206\u6790\u884c\u52a8\u884c\u4f7f\u5224\u65ad\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5f52\u7eb3\u5f0f\u4e3b\u9898\u5206\u6790\u53ef\u4ee5\u901a\u8fc7\u8d1f\u8d23\u4efb\u7684\u4eba\u673a\u534f\u4f5c\u6765\u5b9e\u73b0\uff0cAI\u5de5\u5177\u63d0\u4f9b\u7a0b\u5e8f\u652f\u6301\uff0c\u4f46\u6700\u7ec8\u89e3\u91ca\u6743\u5a01\u548c\u5224\u65ad\u4ecd\u7531\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\u638c\u63e1\u3002"}}
{"id": "2601.12545", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12545", "abs": "https://arxiv.org/abs/2601.12545", "authors": ["Luis Cervantes-P\u00e9rez", "V\u00edctor Santib\u00e1\u00f1ez", "Jes\u00fas Sandoval", "Romeo Ortega", "Jose Guadalupe Romero"], "title": "An Experimental Comparison of Sliding Mode and Immersion and Invariance Adaptive Controllers forPosition-feedback Tracking of a Simple Mechanical System with Friction", "comment": null, "summary": "The purpose of this paper is to illustrate, in an experimental facility consisting of a simple pendular device, the performance of a sliding mode adaptive position-feedback tracking controller of mechanical systems with friction reported in the literature. To put this experimental evidence in perspective, we compare the performance of the sliding mode scheme with the one obtained by an adaptive controller designed following the well-known immersion and invariance technique.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7b80\u5355\u6446\u9524\u5b9e\u9a8c\u88c5\u7f6e\uff0c\u6bd4\u8f83\u4e86\u6ed1\u6a21\u81ea\u9002\u5e94\u4f4d\u7f6e\u53cd\u9988\u8ddf\u8e2a\u63a7\u5236\u5668\u4e0e\u6d78\u5165\u4e0d\u53d8\u81ea\u9002\u5e94\u63a7\u5236\u5668\u5728\u542b\u6469\u64e6\u673a\u68b0\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u8868\u73b0", "motivation": "\u9a8c\u8bc1\u6587\u732e\u4e2d\u62a5\u9053\u7684\u6ed1\u6a21\u81ea\u9002\u5e94\u4f4d\u7f6e\u53cd\u9988\u8ddf\u8e2a\u63a7\u5236\u5668\u5728\u542b\u6469\u64e6\u673a\u68b0\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u4e0e\u6d78\u5165\u4e0d\u53d8\u81ea\u9002\u5e94\u63a7\u5236\u5668\u7684\u5bf9\u6bd4\u6765\u8bc4\u4f30\u5176\u76f8\u5bf9\u4f18\u52bf", "method": "\u4f7f\u7528\u7b80\u5355\u6446\u9524\u5b9e\u9a8c\u88c5\u7f6e\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u4e24\u79cd\u63a7\u5236\u5668\uff1a\u6ed1\u6a21\u81ea\u9002\u5e94\u4f4d\u7f6e\u53cd\u9988\u8ddf\u8e2a\u63a7\u5236\u5668\u548c\u57fa\u4e8e\u6d78\u5165\u4e0d\u53d8\u6280\u672f\u7684\u81ea\u9002\u5e94\u63a7\u5236\u5668", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u6ed1\u6a21\u81ea\u9002\u5e94\u63a7\u5236\u5668\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u4e0e\u6d78\u5165\u4e0d\u53d8\u81ea\u9002\u5e94\u63a7\u5236\u5668\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790", "conclusion": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6ed1\u6a21\u81ea\u9002\u5e94\u63a7\u5236\u5668\u5728\u542b\u6469\u64e6\u673a\u68b0\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u4e3a\u8bfb\u8005\u63d0\u4f9b\u4e86\u4e24\u79cd\u63a7\u5236\u65b9\u6cd5\u7684\u6027\u80fd\u8bc4\u4f30"}}
{"id": "2601.11613", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11613", "abs": "https://arxiv.org/abs/2601.11613", "authors": ["Samuel Gerald Collins"], "title": "Stuck in the Turing Matrix: Inauthenticity, Deception and the Social Life of AI", "comment": null, "summary": "The Turing test may or may not be a valid test of machine intelligence. But in an age of generative AI, the test describes the positions we humans occupy. Judging whether or not something is human or machine produced is an everyday condition for many of us, one that involves taking a spectrum of positions along what the essay describes as a Turing Matrix combining questions of authenticity with questions of deception. Utilizing data from Reddit postings about AI in broad areas of social life, the essay examines positions taken in a Turing Matrix and describes complex negotiations taken by Reddit posters as they strive to make sense of the AI World in which they live. Even though the Turing Test may not tell us much about the achievement of AGI or other benchmarks, it can tell us a great deal about the limitations of human life in the Matrix.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u56fe\u7075\u77e9\u9635\"\u6982\u5ff5\uff0c\u5c06\u56fe\u7075\u6d4b\u8bd5\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4eba\u7c7b\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\u5224\u65ad\u5185\u5bb9\u771f\u4f2a\u7684\u65e5\u5e38\u5904\u5883\uff0c\u901a\u8fc7\u5206\u6790Reddit\u8ba8\u8bba\u63ed\u793a\u4e86\u4eba\u4eec\u5728\u771f\u5b9e\u6027\u4e0e\u6b3a\u9a97\u6027\u95ee\u9898\u4e0a\u7684\u590d\u6742\u534f\u5546\u3002", "motivation": "\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\uff0c\u56fe\u7075\u6d4b\u8bd5\u4e0d\u518d\u53ea\u662f\u8bc4\u4f30\u673a\u5668\u667a\u80fd\u7684\u5de5\u5177\uff0c\u800c\u662f\u63cf\u8ff0\u4e86\u4eba\u7c7b\u65e5\u5e38\u9762\u4e34\u7684\u5224\u65ad\u56f0\u5883\u2014\u2014\u533a\u5206\u4eba\u7c7b\u4e0e\u673a\u5668\u751f\u6210\u5185\u5bb9\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u4eba\u4eec\u5728\u8fd9\u79cd\u5224\u65ad\u8fc7\u7a0b\u4e2d\u7684\u7acb\u573a\u548c\u534f\u5546\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5206\u6790Reddit\u4e0a\u5173\u4e8eAI\u5728\u793e\u4f1a\u751f\u6d3b\u5404\u9886\u57df\u5e94\u7528\u7684\u5e16\u5b50\uff0c\u6784\u5efa\"\u56fe\u7075\u77e9\u9635\"\u6846\u67b6\uff0c\u7ed3\u5408\u771f\u5b9e\u6027\u4e0e\u6b3a\u9a97\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u8003\u5bdf\u7528\u6237\u5728\u5224\u65ad\u5185\u5bb9\u6765\u6e90\u65f6\u7684\u7acb\u573a\u548c\u534f\u5546\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u53d1\u73b0Reddit\u7528\u6237\u5728\u5224\u65adAI\u5185\u5bb9\u65f6\u91c7\u53d6\u590d\u6742\u591a\u6837\u7684\u7acb\u573a\uff0c\u5728\u771f\u5b9e\u6027\u4e0e\u6b3a\u9a97\u6027\u4e4b\u95f4\u8fdb\u884c\u5fae\u5999\u534f\u5546\u3002\u56fe\u7075\u6d4b\u8bd5\u867d\u4e0d\u80fd\u6709\u6548\u8bc4\u4f30AGI\u8fdb\u5c55\uff0c\u4f46\u80fd\u63ed\u793a\u4eba\u7c7b\u5728AI\u4e16\u754c\u4e2d\u7684\u8ba4\u77e5\u5c40\u9650\u548c\u5904\u5883\u3002", "conclusion": "\u56fe\u7075\u6d4b\u8bd5\u4f5c\u4e3a\u673a\u5668\u667a\u80fd\u8bc4\u4f30\u5de5\u5177\u53ef\u80fd\u5df2\u8fc7\u65f6\uff0c\u4f46\u5b83\u51c6\u786e\u63cf\u8ff0\u4e86\u4eba\u7c7b\u5728\u751f\u6210\u5f0fAI\u65f6\u4ee3\u7684\u65e5\u5e38\u5904\u5883\u3002\u4eba\u7c7b\u9700\u8981\u5728\u771f\u5b9e\u6027\u4e0e\u6b3a\u9a97\u6027\u7684\u77e9\u9635\u4e2d\u4e0d\u65ad\u534f\u5546\uff0c\u8fd9\u79cd\u5224\u65ad\u8fc7\u7a0b\u53cd\u6620\u4e86\u4eba\u7c7b\u5728AI\u4e16\u754c\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.11638", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.11638", "abs": "https://arxiv.org/abs/2601.11638", "authors": ["Josafat Ribeiro Leal Filho", "Ant\u00f4nio Augusto Fr\u00f6hlich"], "title": "Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System", "comment": "This paper has been submitted and is currently under review at IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528Fisher\u4fe1\u606f\u5ea6\u91cfPINNs\u5bf9\u7269\u7406\u7cfb\u7edf\u52a8\u6001\u884c\u4e3a\u7684\u6355\u83b7\u7a0b\u5ea6\uff0c\u901a\u8fc7\u6bd4\u8f83PINN\u5b66\u4e60\u6a21\u578b\u4e0e\u539f\u59cb\u89e3\u6790\u6a21\u578b\u7684Fisher\u4fe1\u606f\u666f\u89c2\u6765\u8bc4\u4f30PINN\u7684\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5f53\u524dPINNs\u5728\u6c42\u89e3\u5fae\u5206\u65b9\u7a0b\u548c\u5efa\u6a21\u7269\u7406\u7cfb\u7edf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u91cf\u5316PINN\u662f\u5426\u5b8c\u5168\u6355\u83b7\u7cfb\u7edf\u5b8c\u6574\u52a8\u6001\u884c\u4e3a\uff08\u8d85\u8d8a\u7b80\u5355\u8f68\u8ff9\u9884\u6d4b\uff09\u7684\u4e25\u683c\u65b9\u6cd5\u3002\u9700\u8981\u4e00\u79cd\u8bc4\u4f30PINN\u662f\u5426\u51c6\u786e\u5b66\u4e60\u5230\u7cfb\u7edf\u5e95\u5c42\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u53ef\u5fae\u52a8\u529b\u7cfb\u7edf\u7684Fisher\u4fe1\u606f\uff08\u8bb0\u4e3ag_F^C\uff09\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u548c\u6bd4\u8f83\u539f\u59cb\u89e3\u6790\u6a21\u578b\u4e0e\u8bad\u7ec3\u540ePINN\u7684Fisher\u4fe1\u606f\u666f\u89c2\u6765\u91cf\u5316PINN\u7684\u4fdd\u771f\u5ea6\u3002\u5177\u4f53\u5b9e\u9a8c\u4f7f\u7528\u6c7d\u8f66\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u57fa\u4e8e\u5404\u81ea\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u8fdb\u884c\u8ba1\u7b97\u548c\u6bd4\u8f83\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u6846\u67b6\uff0c\u4f46\u672a\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002\u6846\u67b6\u8868\u660e\u5982\u679cPINN\u51c6\u786e\u5b66\u4e60\u5230\u5e95\u5c42\u52a8\u529b\u5b66\uff0c\u5219PINN\u63a8\u5bfc\u51fa\u7684Fisher\u4fe1\u606f\u666f\u89c2\u5e94\u4e0e\u539f\u59cb\u89e3\u6790\u6a21\u578b\u7d27\u5bc6\u5339\u914d\uff0c\u8fd9\u6807\u5fd7\u7740PINN\u4e0d\u4ec5\u6355\u83b7\u4e86\u72b6\u6001\u6f14\u5316\uff0c\u8fd8\u6355\u83b7\u4e86\u5173\u952e\u7684\u51e0\u4f55\u548c\u7a33\u5b9a\u6027\u7279\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eFisher\u4fe1\u606f\u7684\u8bc4\u4f30\u6846\u67b6\u4e3a\u91cf\u5316PINNs\u5bf9\u7269\u7406\u7cfb\u7edf\u52a8\u6001\u884c\u4e3a\u7684\u6355\u83b7\u7a0b\u5ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc4\u4f30PINN\u662f\u5426\u5168\u9762\u4fdd\u771f\u5730\u8868\u793a\u7cfb\u7edf\u7684\u590d\u6742\u52a8\u6001\u7279\u6027\uff0c\u8d85\u8d8a\u4e86\u7b80\u5355\u7684\u8f68\u8ff9\u9884\u6d4b\u8bc4\u4f30\u3002"}}
{"id": "2601.12217", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12217", "abs": "https://arxiv.org/abs/2601.12217", "authors": ["Li Ye", "Yisheng Song"], "title": "Interval B-Tensors and Interval Double B-Tensors", "comment": null, "summary": "This paper systematically investigates the properties and characterization of interval B-tensors and interval double B-tensors. We propose verifiable necessary and sufficient conditions that allow for determining whether an entire interval tensor family belongs to these classes based solely on its extreme point tensors. The study elucidates profound connections between these interval tensors and other structured ones such as interval Z-tensors and P-tensors, while also providing simplified criteria for special cases like circulant structures. Furthermore, under the condition of even order and symmetry, we prove that interval B-tensors (double B-tensors) ensure the property of being an interval P-tensor. This work extends interval matrix theory to tensors, offering new analytical tools for fields such as polynomial optimization and complementarity problems involving uncertainty.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u533a\u95f4B\u5f20\u91cf\u548c\u533a\u95f4\u53ccB\u5f20\u91cf\u7684\u6027\u8d28\u4e0e\u8868\u5f81\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6781\u503c\u70b9\u5f20\u91cf\u5224\u65ad\u6574\u4e2a\u533a\u95f4\u5f20\u91cf\u65cf\u662f\u5426\u5c5e\u4e8e\u8fd9\u4e9b\u7c7b\u7684\u53ef\u9a8c\u8bc1\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u5efa\u7acb\u4e86\u8fd9\u4e9b\u533a\u95f4\u5f20\u91cf\u4e0eZ\u5f20\u91cf\u3001P\u5f20\u91cf\u7b49\u5176\u4ed6\u7ed3\u6784\u5f20\u91cf\u7684\u6df1\u523b\u8054\u7cfb\u3002", "motivation": "\u5c06\u533a\u95f4\u77e9\u9635\u7406\u8bba\u6269\u5c55\u5230\u5f20\u91cf\u9886\u57df\uff0c\u4e3a\u591a\u9879\u5f0f\u4f18\u5316\u548c\u4e92\u8865\u95ee\u9898\u7b49\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u7684\u9886\u57df\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u5de5\u5177\u3002\u7814\u7a76\u533a\u95f4B\u5f20\u91cf\u548c\u533a\u95f4\u53ccB\u5f20\u91cf\u7684\u6027\u8d28\u6709\u52a9\u4e8e\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u5f20\u91cf\u5206\u6790\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6781\u503c\u70b9\u5f20\u91cf\u7684\u53ef\u9a8c\u8bc1\u5145\u8981\u6761\u4ef6\u6765\u5224\u65ad\u6574\u4e2a\u533a\u95f4\u5f20\u91cf\u65cf\u662f\u5426\u5c5e\u4e8e\u533a\u95f4B\u5f20\u91cf\u6216\u533a\u95f4\u53ccB\u5f20\u91cf\u7c7b\u3002\u7814\u7a76\u8fd9\u4e9b\u533a\u95f4\u5f20\u91cf\u4e0eZ\u5f20\u91cf\u3001P\u5f20\u91cf\u7b49\u5176\u4ed6\u7ed3\u6784\u5f20\u91cf\u7684\u5173\u7cfb\uff0c\u5e76\u4e3a\u5faa\u73af\u7ed3\u6784\u7b49\u7279\u6b8a\u60c5\u51b5\u63d0\u4f9b\u7b80\u5316\u5224\u636e\u3002\u5728\u5076\u9636\u5bf9\u79f0\u6761\u4ef6\u4e0b\u8bc1\u660e\u533a\u95f4B\u5f20\u91cf\uff08\u53ccB\u5f20\u91cf\uff09\u786e\u4fdd\u533a\u95f4P\u5f20\u91cf\u6027\u8d28\u3002", "result": "\u5efa\u7acb\u4e86\u533a\u95f4B\u5f20\u91cf\u548c\u533a\u95f4\u53ccB\u5f20\u91cf\u7684\u5b8c\u6574\u8868\u5f81\u7406\u8bba\uff0c\u53d1\u73b0\u4e86\u8fd9\u4e9b\u533a\u95f4\u5f20\u91cf\u4e0eZ\u5f20\u91cf\u3001P\u5f20\u91cf\u7b49\u5176\u4ed6\u7ed3\u6784\u5f20\u91cf\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\u3002\u5728\u5076\u9636\u5bf9\u79f0\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u533a\u95f4B\u5f20\u91cf\uff08\u53ccB\u5f20\u91cf\uff09\u5fc5\u7136\u5177\u6709\u533a\u95f4P\u5f20\u91cf\u6027\u8d28\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6210\u529f\u5c06\u533a\u95f4\u77e9\u9635\u7406\u8bba\u6269\u5c55\u5230\u5f20\u91cf\u9886\u57df\uff0c\u4e3a\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u591a\u9879\u5f0f\u4f18\u5316\u548c\u4e92\u8865\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u548c\u5de5\u5177\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u6781\u503c\u70b9\u7684\u5224\u636e\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u53ef\u9a8c\u8bc1\u6027\uff0c\u5efa\u7acb\u7684\u5f20\u91cf\u95f4\u5173\u7cfb\u7406\u8bba\u4e30\u5bcc\u4e86\u5f20\u91cf\u5206\u6790\u7684\u7406\u8bba\u4f53\u7cfb\u3002"}}
{"id": "2601.11739", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11739", "abs": "https://arxiv.org/abs/2601.11739", "authors": ["Xinyu Pi", "Qisen Yang", "Chuong Nguyen", "Hua Shen"], "title": "Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era", "comment": null, "summary": "LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a4\u00d74\u6846\u67b6\u6765\u5206\u6790LLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u504f\u5411\u4f4e\u5c42\u6b21\u610f\u4e49\u548c\u4f4e\u627f\u8bfa\u8868\u793a\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8bae\u7a0b\u3002", "motivation": "LLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u7684\u8f93\u51fa\u5dee\u5f02\u5f88\u5927\u2014\u2014\u4ece\u5fe0\u5b9e\u8ffd\u8e2a\u7684\u6458\u8981\u5230\u7406\u8bba\u4e2d\u4ecb\u7684\u89e3\u91ca\u548c\u7cfb\u7edf\u6a21\u578b\u3002\u4e3a\u4e86\u660e\u786e\u8fd9\u4e9b\u5dee\u5f02\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6846\u67b6\u6765\u5206\u6790LLM\u5728\u8d28\u6027\u7814\u7a76\u4e2d\u7684\u4e0d\u540c\u5e94\u7528\u5c42\u6b21\u3002", "method": "\u5f15\u5165\u4e00\u4e2a4\u00d74\u7684\u6846\u67b6\uff1a\u56db\u4e2a\u610f\u4e49\u5efa\u6784\u5c42\u6b21\uff08\u63cf\u8ff0\u6027\u3001\u5206\u7c7b\u6027\u3001\u89e3\u91ca\u6027\u3001\u7406\u8bba\u6027\uff09\u4e0e\u56db\u4e2a\u5efa\u6a21\u5c42\u6b21\uff08\u9759\u6001\u7ed3\u6784\u3001\u9636\u6bb5/\u65f6\u95f4\u7ebf\u3001\u56e0\u679c\u8def\u5f84\u3001\u53cd\u9988\u52a8\u6001\uff09\u4ea4\u53c9\u3002\u5c06\u6b64\u6846\u67b6\u5e94\u7528\u4e8e\u5148\u524d\u7684LLM\u81ea\u52a8\u5316\u7814\u7a76\u3002", "result": "\u5206\u6790\u663e\u793a\u5f53\u524dLLM\u5e94\u7528\u5b58\u5728\u660e\u663e\u504f\u5411\uff1a\u4e3b\u8981\u96c6\u4e2d\u5728\u4f4e\u5c42\u6b21\u610f\u4e49\u5efa\u6784\u548c\u4f4e\u627f\u8bfa\u8868\u793a\u4e0a\uff0c\u5f88\u5c11\u6709\u53ef\u9760\u5c1d\u8bd5\u8fdb\u884c\u89e3\u91ca\u6027/\u7406\u8bba\u6027\u63a8\u7406\u6216\u52a8\u6001\u5efa\u6a21\u3002", "conclusion": "\u57fa\u4e8e\u53d1\u73b0\u7684\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\uff1a\u5f00\u53d1\u80fd\u591f\u660e\u786e\u5176\u89e3\u91ca\u548c\u5efa\u6a21\u627f\u8bfa\u3001\u53ef\u9009\u62e9\u4e14\u53ef\u6cbb\u7406\u7684LLM\u7cfb\u7edf\u3002"}}
{"id": "2601.11885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11885", "abs": "https://arxiv.org/abs/2601.11885", "authors": ["Zhifei Li", "Ziyue Qin", "Xiangyu Luo", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Zhifang Huang", "Kui Xiao", "Bing Yang"], "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment", "comment": "Accepted by AAAI 2026", "summary": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.", "AI": {"tldr": "MyGram\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u6001\u611f\u77e5\u7684\u56fe\u53d8\u6362\u5668\uff0c\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u5b9e\u73b0\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u65b9\u6cd5\u53ef\u80fd\u5ffd\u89c6\u6a21\u6001\u5185\u7684\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bb9\u6613\u53d7\u5230\u6d45\u5c42\u7279\u5f81\u7684\u5e72\u6270\uff0c\u9700\u8981\u66f4\u597d\u5730\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u6765\u4e30\u5bcc\u5b9e\u4f53\u8bed\u4e49\u8868\u793a\u3002", "method": "\u63d0\u51faMyGram\u6846\u67b6\uff1a1) \u6a21\u6001\u6269\u6563\u5b66\u4e60\u6a21\u5757\u6355\u83b7\u6a21\u6001\u5185\u6df1\u5c42\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u878d\u5408\uff1b2) Gram\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u5316\u7ea6\u675f\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u591a\u6a21\u6001\u7279\u5f81\u5f62\u6210\u76844\u7ef4\u5e73\u884c\u516d\u9762\u4f53\u4f53\u79ef\u6765\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMyGram\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728FBDB15K\u4e0aHits@1\u6700\u5927\u63d0\u53474.8%\uff0c\u5728FBYG15K\u4e0a\u63d0\u53479.9%\uff0c\u5728DBP15K\u4e0a\u63d0\u53474.3%\u3002", "conclusion": "MyGram\u901a\u8fc7\u6a21\u6001\u6269\u6563\u5b66\u4e60\u548cGram\u635f\u5931\u6709\u6548\u6355\u83b7\u6a21\u6001\u5185\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u5b9e\u73b0\u8de8\u6a21\u6001\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5b9e\u4f53\u5bf9\u9f50\u6027\u80fd\u3002"}}
{"id": "2601.12610", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12610", "abs": "https://arxiv.org/abs/2601.12610", "authors": ["Maxim Yudayev", "Juha Carlon", "Diwas Lamsal", "Vayalet Stefanova", "Benjamin Filtjens"], "title": "HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications", "comment": "Submitted to ACM SenSys '26, 12 pages (excl. references), 9 figures", "summary": "Intelligent assistive technologies are increasingly recognized as critical daily-use enablers for people with disabilities and age-related functional decline. Longitudinal studies, curation of quality datasets, live monitoring in activities of daily living, and intelligent intervention devices, share the largely unsolved need in reliable high-throughput multimodal sensing and processing. Streaming large heterogeneous data from distributed sensors, historically closed-source environments, and limited prior works on realtime closed-loop AI methodologies, inhibit such applications. To accelerate the emergence of clinical deployments, we deliver HERMES - an open-source high-performance Python framework for continuous multimodal sensing and AI processing at the edge. It enables synchronized data collection, and realtime streaming inference with user PyTorch models, on commodity computing devices. HERMES is applicable to fixed-lab and free-living environments, of distributed commercial and custom sensors. It is the first work to offer a holistic methodology that bridges cross-disciplinary gaps in real-world implementation strategies, and guides downstream AI model development. Its application on the closed-loop intelligent prosthesis use case illustrates the process of suitable AI model development from the generated constraints and trade-offs. Validation on the use case, with 4 synchronized hosts cooperatively capturing 18 wearable and off-body modalities, demonstrates performance and relevance of HERMES to the trajectory of the intelligent healthcare domain.", "AI": {"tldr": "HERMES\u662f\u4e00\u4e2a\u5f00\u6e90\u9ad8\u6027\u80fdPython\u6846\u67b6\uff0c\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7684\u8fde\u7eed\u591a\u6a21\u6001\u4f20\u611f\u548cAI\u5904\u7406\uff0c\u65e8\u5728\u52a0\u901f\u667a\u80fd\u8f85\u52a9\u6280\u672f\u7684\u4e34\u5e8a\u90e8\u7f72\u3002", "motivation": "\u667a\u80fd\u8f85\u52a9\u6280\u672f\u5bf9\u6b8b\u75be\u4eba\u548c\u8001\u5e74\u4eba\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u9762\u4e34\u591a\u6a21\u6001\u4f20\u611f\u5904\u7406\u3001\u5b9e\u65f6\u95ed\u73afAI\u65b9\u6cd5\u3001\u5f02\u6784\u6570\u636e\u6d41\u7b49\u6311\u6218\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u5f00\u53d1HERMES\u5f00\u6e90\u6846\u67b6\uff0c\u652f\u6301\u540c\u6b65\u6570\u636e\u91c7\u96c6\u3001\u5b9e\u65f6\u6d41\u5f0f\u63a8\u7406\u3001\u7528\u6237PyTorch\u6a21\u578b\u96c6\u6210\uff0c\u9002\u7528\u4e8e\u56fa\u5b9a\u5b9e\u9a8c\u5ba4\u548c\u81ea\u7531\u751f\u6d3b\u73af\u5883\u4e2d\u7684\u5206\u5e03\u5f0f\u4f20\u611f\u5668\u3002", "result": "\u5728\u667a\u80fd\u5047\u80a2\u7528\u4f8b\u4e2d\u9a8c\u8bc1\uff0c4\u4e2a\u540c\u6b65\u4e3b\u673a\u534f\u540c\u6355\u83b718\u4e2a\u53ef\u7a7f\u6234\u548c\u4f53\u5916\u6a21\u6001\uff0c\u5c55\u793a\u4e86HERMES\u7684\u6027\u80fd\u548c\u4e0e\u667a\u80fd\u533b\u7597\u9886\u57df\u7684\u76f8\u5173\u6027\u3002", "conclusion": "HERMES\u662f\u9996\u4e2a\u63d0\u4f9b\u6574\u4f53\u65b9\u6cd5\u8bba\u7684\u5de5\u4f5c\uff0c\u5f25\u5408\u4e86\u8de8\u5b66\u79d1\u5b9e\u65bd\u7b56\u7565\u7684\u5dee\u8ddd\uff0c\u6307\u5bfc\u4e0b\u6e38AI\u6a21\u578b\u5f00\u53d1\uff0c\u52a0\u901f\u667a\u80fd\u533b\u7597\u5e94\u7528\u7684\u4e34\u5e8a\u90e8\u7f72\u3002"}}
{"id": "2601.11643", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11643", "abs": "https://arxiv.org/abs/2601.11643", "authors": ["H. Situngkir", "A. B. Lumbantobing", "Y. Surya"], "title": "Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from Gasing Literacy Learning System", "comment": "12 pages, 1 figures", "summary": "This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language's morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves R\u00e9nyi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method's ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian's agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u8282\u7684\u5370\u5c3c\u8bed\u5206\u8bcd\u65b9\u6cd5\uff0c\u7ed3\u5408Gasing\u8bc6\u5b57\u6559\u5b66\u6cd5\u539f\u7406\uff0c\u901a\u8fc7\u97f3\u8282\u8fb9\u754c\u5206\u5272\u548cBPE\u6784\u5efa3500\u8bcd\u8868\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u6548\u7387\u548c\u957f\u5ea6\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u9488\u5bf9\u5370\u5c3c\u8bed\u7b49\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u5728\u4f20\u7edf\u5206\u8bcd\u65b9\u6cd5\u4e2d\u7684\u4e0d\u8db3\uff0c\u53d7Gasing\u8bc6\u5b57\u6559\u5b66\u6cd5\u542f\u53d1\uff0c\u5e0c\u671b\u5f00\u53d1\u66f4\u7b26\u5408\u8bed\u8a00\u5f62\u6001\u97f3\u7cfb\u7ed3\u6784\u7684\u5206\u8bcd\u7b56\u7565\uff0c\u964d\u4f4e\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u97f3\u8282\u7684tokenization\u65b9\u6cd5\uff1a1) \u57fa\u4e8e\u89c4\u5219\u8bc6\u522b\u9ad8\u9891\u97f3\u8282\u8fb9\u754c\uff1b2) \u5e94\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u6784\u5efa3500\u4e2atoken\u7684\u7d27\u51d1\u8bcd\u8868\uff1b3) \u4fdd\u7559\u5b57\u7b26\u7ea7\u56de\u9000\u673a\u5236\u786e\u4fdd\u8986\u76d6\u7387\u3002", "result": "\u5728\u5370\u5c3c\u8bed\u7ef4\u57fa\u767e\u79d1\u548cPDBI\u6c11\u95f4\u6545\u4e8b\u8bed\u6599\u4e0a\u8bc4\u4f30\uff1aR\u00e9nyi\u6548\u7387\u8fbe0.74\uff08\u4f20\u7edf\u65b9\u6cd50.50-0.64\uff09\uff0c\u5e73\u5747token\u957f\u5ea63.67\u5b57\u7b26\uff08GPT-2\u4e3a2.72\uff09\uff0c\u8bcd\u8868\u89c4\u6a21\u5c0f\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u97f3\u8282\u5206\u8bcd\u65b9\u6cd5\u80fd\u5185\u5316\u5b57\u7b26\u7ea7\u4f9d\u8d56\u5173\u7cfb\uff0c\u5c0a\u91cd\u5370\u5c3c\u8bed\u9ecf\u7740\u5f62\u6001\uff0c\u5c06\u8bc6\u5b57\u6559\u5b66\u6cd5\u4e0e\u8ba1\u7b97\u4f18\u5316\u539f\u5219\u7ed3\u5408\uff0c\u4e3a\u5f62\u6001\u4e30\u5bcc\u548c\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5206\u8bcd\u8303\u5f0f\u3002"}}
{"id": "2601.11897", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.11897", "abs": "https://arxiv.org/abs/2601.11897", "authors": ["Jinwon Sohn", "Guang Lin", "Qifan Song"], "title": "Task-tailored Pre-processing: Fair Downstream Supervised Learning", "comment": null, "summary": "Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u76d1\u7763\u5b66\u4e60\u7684\u516c\u5e73\u6027\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7HGR\u76f8\u5173\u6027\u5206\u6790\u53d1\u73b0\u73b0\u6709\u6570\u636e\u516c\u5e73\u65b9\u6cd5\u6b63\u5219\u5316\u8fc7\u5f3a\uff0c\u8bbe\u8ba1\u4e86\u5728\u516c\u5e73\u6027\u548c\u6548\u7528\u95f4\u6743\u8861\u7684\u9884\u5904\u7406\u6620\u5c04\uff0c\u5e76\u7406\u8bba\u5206\u6790\u4e86\u4e0b\u6e38\u6a21\u578b\u7684\u516c\u5e73\u6027\u6539\u8fdb\u548c\u6548\u7528\u4fdd\u6301\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u9884\u5904\u7406\u65b9\u6cd5\u5206\u4e3a\u4e24\u7c7b\uff1a\u6570\u636e\u516c\u5e73\u6027\uff08\u72ec\u7acb\u4e8e\u4e0b\u6e38\u6a21\u578b\uff09\u548c\u4efb\u52a1\u5b9a\u5236\u516c\u5e73\u6027\uff08\u8003\u8651\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff09\u3002\u4f5c\u8005\u8ba4\u4e3a\u6570\u636e\u516c\u5e73\u6027\u65b9\u6cd5\u4eceHGR\u76f8\u5173\u6027\u89d2\u5ea6\u770b\u65bd\u52a0\u4e86\u8fc7\u5f3a\u7684\u6b63\u5219\u5316\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u66f4\u9002\u5408\u76d1\u7763\u5b66\u4e60\u7684\u9884\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u76d1\u7763\u5b66\u4e60\u5b9a\u5236\u9884\u5904\u7406\u6846\u67b6\uff0c\u5728\u83b7\u5f97\u9884\u5904\u7406\u6620\u5c04\u65f6\u8003\u8651\u516c\u5e73\u6027\u548c\u6548\u7528\u7684\u6743\u8861\u3002\u7406\u8bba\u5206\u6790\u4e86\u4efb\u610f\u4e0b\u6e38\u76d1\u7763\u6a21\u578b\u5728\u8f6c\u6362\u6570\u636e\u4e0a\u7684\u884c\u4e3a\uff0c\u627e\u5230\u4fdd\u8bc1\u5176\u516c\u5e73\u6027\u6539\u8fdb\u548c\u6548\u7528\u4fdd\u6301\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "\u901a\u8fc7\u8868\u683c\u6570\u636e\u548c\u56fe\u50cf\u6570\u636e\u96c6\u7684\u5bf9\u6bd4\u7814\u7a76\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4e0b\u6e38\u6a21\u578b\u4e2d\u4fdd\u6301\u4e00\u81f4\u7684\u6743\u8861\uff0c\u4f18\u4e8e\u73b0\u6709\u7ade\u4e89\u6a21\u578b\u3002\u7279\u522b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4ec5\u6539\u53d8\u4e0e\u6838\u5fc3\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u76f8\u5173\u7684\u5fc5\u8981\u8bed\u4e49\u7279\u5f81\u6765\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5728\u4efb\u52a1\u5b9a\u5236\u65b9\u6cd5\u5206\u652f\u4e2d\u7406\u8bba\u7814\u7a76\u4e86\u4f7f\u7528\u9884\u5904\u7406\u6570\u636e\u65f6\u7684\u4e0b\u6e38\u4fdd\u8bc1\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u5728\u516c\u5e73\u6027\u548c\u6548\u7528\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u4e3a\u76d1\u7763\u5b66\u4e60\u7684\u516c\u5e73\u6027\u9884\u5904\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u9a8c\u8bc1\u3002"}}
{"id": "2601.12226", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12226", "abs": "https://arxiv.org/abs/2601.12226", "authors": ["Zongxia Liang", "Zhou Zhou", "Yaqi Zhuang", "Bin Zou"], "title": "Mean-Field Games Under Model Uncertainty", "comment": null, "summary": "We study discrete-time, finite-state mean-field games (MFGs) under model uncertainty, where agents face ambiguity about the state transition probabilities. Each agent maximizes its expected payoff against the worst-case transitions within an uncertainty set. Unlike in classical MFGs, model uncertainty renders the population distribution flow stochastic. This leads us to consider strategies that depend on both individual states and the realized distribution of the population. Our main results establish the asymptotic relationship between $N$-agent games and MFGs: every MFG equilibrium constitutes an $\\varepsilon$-Nash equilibrium for sufficiently large populations, and conversely, limits of $N$-agent equilibria are MFG equilibria. We also prove the existence of equilibria for finite-agent games and construct a solvable mean-field example with closed-form solutions.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u79bb\u6563\u65f6\u95f4\u6709\u9650\u72b6\u6001\u5e73\u5747\u573a\u535a\u5f08\uff0c\u8bc1\u660eN\u667a\u80fd\u4f53\u535a\u5f08\u4e0e\u5e73\u5747\u573a\u535a\u5f08\u7684\u6e10\u8fd1\u7b49\u4ef7\u6027\uff0c\u5e76\u5efa\u7acb\u5747\u8861\u5b58\u5728\u6027", "motivation": "\u7ecf\u5178\u5e73\u5747\u573a\u535a\u5f08\u5047\u8bbe\u667a\u80fd\u4f53\u5b8c\u5168\u4e86\u89e3\u72b6\u6001\u8f6c\u79fb\u6982\u7387\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5b58\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3002\u672c\u6587\u7814\u7a76\u667a\u80fd\u4f53\u9762\u5bf9\u72b6\u6001\u8f6c\u79fb\u6982\u7387\u6a21\u7cca\u6027\u65f6\u7684\u5e73\u5747\u573a\u535a\u5f08\uff0c\u5176\u4e2d\u6bcf\u4e2a\u667a\u80fd\u4f53\u5728\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\u5185\u9488\u5bf9\u6700\u574f\u60c5\u51b5\u8f6c\u79fb\u6700\u5927\u5316\u671f\u671b\u6536\u76ca\u3002", "method": "\u7814\u7a76\u79bb\u6563\u65f6\u95f4\u6709\u9650\u72b6\u6001\u5e73\u5747\u573a\u535a\u5f08\uff0c\u8003\u8651\u7b56\u7565\u4f9d\u8d56\u4e8e\u4e2a\u4f53\u72b6\u6001\u548c\u5df2\u5b9e\u73b0\u7684\u4eba\u53e3\u5206\u5e03\u3002\u5efa\u7acbN\u667a\u80fd\u4f53\u535a\u5f08\u4e0e\u5e73\u5747\u573a\u535a\u5f08\u7684\u6e10\u8fd1\u5173\u7cfb\uff0c\u8bc1\u660e\u5747\u8861\u5b58\u5728\u6027\uff0c\u5e76\u6784\u9020\u5177\u6709\u95ed\u5f0f\u89e3\u7684\u53ef\u89e3\u5e73\u5747\u573a\u793a\u4f8b\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\uff1a1) \u6bcf\u4e2a\u5e73\u5747\u573a\u535a\u5f08\u5747\u8861\u6784\u6210\u8db3\u591f\u5927\u4eba\u53e3\u89c4\u6a21\u4e0b\u7684\u03b5-\u7eb3\u4ec0\u5747\u8861\uff1b2) N\u667a\u80fd\u4f53\u5747\u8861\u7684\u6781\u9650\u662f\u5e73\u5747\u573a\u535a\u5f08\u5747\u8861\uff1b3) \u8bc1\u660e\u6709\u9650\u667a\u80fd\u4f53\u535a\u5f08\u5747\u8861\u5b58\u5728\u6027\uff1b4) \u6784\u9020\u5177\u6709\u95ed\u5f0f\u89e3\u7684\u53ef\u89e3\u5e73\u5747\u573a\u793a\u4f8b\u3002", "conclusion": "\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0b\uff0c\u5e73\u5747\u573a\u535a\u5f08\u6846\u67b6\u4ecd\u7136\u6709\u6548\uff0cN\u667a\u80fd\u4f53\u535a\u5f08\u4e0e\u5e73\u5747\u573a\u535a\u5f08\u6e10\u8fd1\u7b49\u4ef7\u3002\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4f7f\u4eba\u53e3\u5206\u5e03\u6d41\u53d8\u4e3a\u968f\u673a\u8fc7\u7a0b\uff0c\u9700\u8981\u7b56\u7565\u540c\u65f6\u4f9d\u8d56\u4e2a\u4f53\u72b6\u6001\u548c\u5df2\u5b9e\u73b0\u7684\u4eba\u53e3\u5206\u5e03\u3002"}}
{"id": "2601.11746", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11746", "abs": "https://arxiv.org/abs/2601.11746", "authors": ["George Mihaila", "Suleyman Olcay Polat", "Poli Nemkova", "Himanshu Sharma", "Namratha V. Urs", "Mark V. Albert"], "title": "LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text", "comment": null, "summary": "Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict \"Single Mask-Single Sample\" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.", "AI": {"tldr": "LIME-LLM\u662f\u4e00\u4e2a\u6539\u8fdb\u7684\u5c40\u90e8\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u5047\u8bbe\u9a71\u52a8\u7684\u53d7\u63a7\u6270\u52a8\u66ff\u4ee3\u968f\u673a\u6807\u8bb0\u63a9\u7801\uff0c\u901a\u8fc7\"\u5355\u63a9\u7801-\u5355\u6837\u672c\"\u534f\u8bae\u548c\u4e2d\u6027\u586b\u5145\u7b56\u7565\uff0c\u751f\u6210\u6d41\u7545\u7684\u5206\u5e03\u5185\u90bb\u57df\uff0c\u663e\u8457\u63d0\u5347\u4e86NLP\u9ed1\u76d2\u6a21\u578b\u89e3\u91ca\u7684\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5c40\u90e8\u89e3\u91ca\u65b9\u6cd5\u5982LIME\u5728NLP\u5e94\u7528\u4e2d\u4f9d\u8d56\u968f\u673a\u6807\u8bb0\u63a9\u7801\uff0c\u4f1a\u4ea7\u751f\u8bed\u4e49\u65e0\u6548\u3001\u5206\u5e03\u5916\u7684\u8f93\u5165\uff0c\u524a\u5f31\u5c40\u90e8\u4ee3\u7406\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\u3002\u6700\u8fd1\u7684\u751f\u6210\u65b9\u6cd5\u5982LLiMe\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u90bb\u57df\u751f\u6210\uff0c\u4f46\u4f9d\u8d56\u65e0\u7ea6\u675f\u7684\u91ca\u4e49\uff0c\u5f15\u5165\u4e86\u6df7\u6dc6\u53d8\u91cf\uff0c\u96be\u4ee5\u9694\u79bb\u7279\u5b9a\u7279\u5f81\u8d21\u732e\u3002", "method": "LIME-LLM\u6846\u67b6\u7528\u5047\u8bbe\u9a71\u52a8\u7684\u53d7\u63a7\u6270\u52a8\u66ff\u4ee3\u968f\u673a\u566a\u58f0\uff0c\u91c7\u7528\u4e25\u683c\u7684\"\u5355\u63a9\u7801-\u5355\u6837\u672c\"\u534f\u8bae\uff0c\u5e76\u8fd0\u7528\u4e0d\u540c\u7684\u4e2d\u6027\u586b\u5145\u548c\u8fb9\u754c\u586b\u5145\u7b56\u7565\uff0c\u6784\u5efa\u6d41\u7545\u7684\u5206\u5e03\u5185\u90bb\u57df\uff0c\u4e25\u683c\u9694\u79bb\u7279\u5f81\u6548\u5e94\u3002", "result": "\u5728CoLA\u3001SST-2\u548cHateXplain\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u4eba\u5de5\u6807\u6ce8\u7684\u7406\u6027\u4f5c\u4e3a\u771f\u5b9e\u6807\u7b7e\uff0cLIME-LLM\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff08LIME\u3001SHAP\u3001Integrated Gradients\uff09\u548c\u751f\u6210\u57fa\u7ebfLLiMe\uff0c\u5728\u5c40\u90e8\u89e3\u91ca\u4fdd\u771f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "LIME-LLM\u4e3a\u9ed1\u76d2NLP\u53ef\u89e3\u91ca\u6027\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u6270\u52a8\u7684\u65b9\u6cd5\u548c\u6700\u8fd1\u7684\u751f\u6210\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u5c40\u90e8\u89e3\u91ca\u4fdd\u771f\u5ea6\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.11639", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11639", "abs": "https://arxiv.org/abs/2601.11639", "authors": ["Ming Li"], "title": "Global Optimization By Gradient from Hierarchical Score-Matching Spaces", "comment": null, "summary": "Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u6570\u5339\u914d\u83b7\u53d6\u68af\u5ea6\uff0c\u5c06\u5e26\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u5206\u5c42\u4f18\u5316\u76ee\u6807\u7684\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u4f7f\u7528\u4e25\u683c\u68af\u5ea6\u7684\u786e\u5b9a\u6027\u5168\u5c40\u4f18\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u5168\u5c40\u4f18\u5316\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\u3002", "motivation": "\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u53ea\u80fd\u627e\u5230\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u4e14\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u53ef\u5fae\u95ee\u9898\u548c\u7b80\u5355\u51f8\u7ea6\u675f\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5904\u7406\u5404\u79cd\u590d\u6742\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5c06\u6240\u6709\u5e26\u590d\u6742\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u7edf\u4e00\u4e3a\u65e0\u7ea6\u675f\u7684\u5206\u5c42\u4f18\u5316\u76ee\u6807\uff0c\u901a\u8fc7\u5206\u6570\u5339\u914d\u83b7\u53d6\u68af\u5ea6\u8fdb\u884c\u4f18\u5316\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u7ea6\u675f\u4f18\u5316\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u95ee\u9898\uff0c\u4f7f\u7528\u786e\u5b9a\u6027\u65b9\u6cd5\u8fdb\u884c\u5168\u5c40\u4f18\u5316\u3002", "result": "\u9996\u6b21\u5b9e\u73b0\u4e86\u4f7f\u7528\u4e25\u683c\u68af\u5ea6\u7684\u786e\u5b9a\u6027\u5168\u5c40\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u7b80\u5355\u6784\u9020\u548c\u590d\u6742\u5b9e\u9645\u5b9e\u9a8c\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u63ed\u793a\u4e86\u5168\u5c40\u4f18\u5316\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5efa\u6a21\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5904\u7406\u5404\u79cd\u590d\u6742\u7ea6\u675f\u7684\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u5efa\u7acb\u4e86\u5168\u5c40\u4f18\u5316\u4e0e\u6269\u6563\u751f\u6210\u6a21\u578b\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2601.11903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11903", "abs": "https://arxiv.org/abs/2601.11903", "authors": ["YenTing Lee", "Keerthi Koneru", "Zahra Moslemi", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems", "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026", "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight", "AI": {"tldr": "AEMA\u662f\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u7a0b\u611f\u77e5\u548c\u53ef\u5ba1\u8ba1\u7684\u8bbe\u8ba1\uff0c\u63d0\u4f9b\u6bd4\u4f20\u7edf\u5355LLM\u8bc4\u4f30\u66f4\u7a33\u5b9a\u3001\u53ef\u8ffd\u6eaf\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u901a\u5e38\u5c40\u9650\u4e8e\u5355\u6b21\u54cd\u5e94\u8bc4\u5206\u6216\u72ed\u7a84\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u4f01\u4e1a\u7ea7\u591a\u667a\u80fd\u4f53\u89c4\u6a21\u90e8\u7f72\u65f6\u7f3a\u4e4f\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u96be\u4ee5\u6ee1\u8db3\u53ef\u9760\u534f\u8c03\u3001\u900f\u660e\u51b3\u7b56\u548c\u53ef\u9a8c\u8bc1\u6027\u80fd\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51faAEMA\uff08\u81ea\u9002\u5e94\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u6d41\u7a0b\u611f\u77e5\u4e14\u53ef\u5ba1\u8ba1\u7684\u8bc4\u4f30\u7cfb\u7edf\u3002\u5b83\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\uff0c\u89c4\u5212\u3001\u6267\u884c\u5e76\u805a\u5408\u5f02\u6784\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u591a\u6b65\u9aa4\u8bc4\u4f30\uff0c\u652f\u6301\u53ef\u8ffd\u6eaf\u7684\u8bb0\u5f55\u548c\u8d1f\u8d23\u4efb\u7684\u81ea\u52a8\u5316\u3002", "result": "\u4e0e\u5355\u4e00LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u76f8\u6bd4\uff0cAEMA\u5728\u7a33\u5b9a\u6027\u3001\u4eba\u7c7b\u5bf9\u9f50\u6027\u548c\u53ef\u8ffd\u6eaf\u8bb0\u5f55\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u5728\u57fa\u4e8e\u73b0\u5b9e\u4e1a\u52a1\u573a\u666f\u6a21\u62df\u7684\u4f01\u4e1a\u7ea7\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e0a\uff0cAEMA\u63d0\u4f9b\u4e86\u900f\u660e\u4e14\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u8def\u5f84\u3002", "conclusion": "AEMA\u6846\u67b6\u4e3a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u8d1f\u8d23\u4efb\u3001\u53ef\u5ba1\u8ba1\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u652f\u6301\u4f01\u4e1a\u73af\u5883\u4e2d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u9760\u90e8\u7f72\u548c\u9a8c\u8bc1\uff0c\u662f\u5b9e\u73b0\u53ef\u4fe1\u591a\u667a\u80fd\u4f53AI\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2601.12616", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12616", "abs": "https://arxiv.org/abs/2601.12616", "authors": ["Johnathan Corbin", "Sarah H. Q. Li", "Jonathan Rogers"], "title": "Allocating Corrective Control to Mitigate Multi-agent Safety Violations Under Private Preferences", "comment": "8 pages, 3 figures, Submitted to IEEE Robotics and Automation Letters (RA-L)", "summary": "We propose a novel framework that computes the corrective control efforts to ensure joint safety in multi-agent dynamical systems. This framework efficiently distributes the required corrective effort without revealing individual agents' private preferences. Our framework integrates high-order control barrier functions (HOCBFs), which enforce safety constraints with formal guarantees of safety for complex dynamical systems, with a privacy-preserving resource allocation mechanism based on the progressive second price (PSP) auction. When a joint safety constraint is violated, agents iteratively bid on new corrective efforts via 'avoidance credits' rather than explicitly solving for feasible corrective efforts that remove the safety violation. The resulting correction, determined via a second price payment rule, coincides with the socially optimal safe distribution of corrective actions. Critically, the bidding process achieves this optimal allocation efficiently and without revealing private preferences of individual agents. We demonstrate this method through multi-robot hardware experiments on the Robotarium platform.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u591a\u667a\u80fd\u4f53\u5b89\u5168\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u62cd\u5356\u673a\u5236\u5206\u914d\u6821\u6b63\u52aa\u529b\uff0c\u786e\u4fdd\u8054\u5408\u5b89\u5168\u7ea6\u675f\u800c\u4e0d\u6cc4\u9732\u4e2a\u4f53\u504f\u597d", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u52a8\u6001\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u786e\u4fdd\u8054\u5408\u5b89\u5168\u7ea6\u675f\uff0c\u540c\u65f6\u4fdd\u62a4\u4e2a\u4f53\u667a\u80fd\u4f53\u7684\u79c1\u6709\u504f\u597d\u4fe1\u606f\u4e0d\u88ab\u6cc4\u9732\u3002\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u66b4\u9732\u4e2a\u4f53\u504f\u597d\u6216\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u7ed3\u5408\u9ad8\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08HOCBFs\uff09\u548c\u57fa\u4e8e\u6e10\u8fdb\u7b2c\u4e8c\u4ef7\u683c\uff08PSP\uff09\u62cd\u5356\u7684\u9690\u79c1\u4fdd\u62a4\u8d44\u6e90\u5206\u914d\u673a\u5236\u3002\u5f53\u8054\u5408\u5b89\u5168\u7ea6\u675f\u88ab\u8fdd\u53cd\u65f6\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\"\u907f\u514d\u4fe1\u7528\"\u8fed\u4ee3\u7ade\u6807\u6821\u6b63\u52aa\u529b\uff0c\u800c\u4e0d\u662f\u663e\u5f0f\u6c42\u89e3\u53ef\u884c\u7684\u6821\u6b63\u65b9\u6848\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7b2c\u4e8c\u4ef7\u683c\u652f\u4ed8\u89c4\u5219\u786e\u5b9a\u7684\u6821\u6b63\u65b9\u6848\u4e0e\u793e\u4ea4\u6700\u4f18\u7684\u5b89\u5168\u6821\u6b63\u884c\u52a8\u5206\u5e03\u4e00\u81f4\u3002\u7ade\u6807\u8fc7\u7a0b\u9ad8\u6548\u5b9e\u73b0\u6700\u4f18\u5206\u914d\u4e14\u4e0d\u6cc4\u9732\u4e2a\u4f53\u79c1\u6709\u504f\u597d\u3002\u5728Robotarium\u5e73\u53f0\u7684\u591a\u673a\u5668\u4eba\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u8054\u5408\u5b89\u5168\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u62a4\u4e86\u9690\u79c1\uff0c\u901a\u8fc7\u62cd\u5356\u673a\u5236\u9ad8\u6548\u5206\u914d\u6821\u6b63\u52aa\u529b\uff0c\u5728\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.11699", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11699", "abs": "https://arxiv.org/abs/2601.11699", "authors": ["Miles Brundage", "Noemi Dreksler", "Aidan Homewood", "Sean McGregor", "Patricia Paskov", "Conrad Stosz", "Girish Sastry", "A. Feder Cooper", "George Balston", "Steven Adler", "Stephen Casper", "Markus Anderljung", "Grace Werner", "Soren Mindermann", "Vasilios Mavroudis", "Ben Bucknall", "Charlotte Stix", "Jonas Freund", "Lorenzo Pacchiardi", "Jose Hernandez-Orallo", "Matteo Pistillo", "Michael Chen", "Chris Painter", "Dean W. Ball", "Cullen O'Keefe", "Gabriel Weil", "Ben Harack", "Graeme Finley", "Ryan Hassan", "Scott Emmons", "Charles Foster", "Anka Reuel", "Bri Treece", "Yoshua Bengio", "Daniel Reti", "Rishi Bommasani", "Cristian Trout", "Ali Shahin Shamsabadi", "Rajiv Dattani", "Adrian Weller", "Robert Trager", "Jaime Sevilla", "Lauren Wagner", "Lisa Soder", "Ketan Ramakrishnan", "Henry Papadatos", "Malcolm Murray", "Ryan Tovcimak"], "title": "Frontier AI Auditing: Toward Rigorous Third-Party Assessment of Safety and Security Practices at Leading AI Companies", "comment": null, "summary": "Frontier AI is becoming critical societal infrastructure, but outsiders lack reliable ways to judge whether leading developers' safety and security claims are accurate and whether their practices meet relevant standards. Compared to other social and technological systems we rely on daily such as consumer products, corporate financial statements, and food supply chains, AI is subject to less rigorous third-party scrutiny along several dimensions. Ambiguity about whether AI systems are trustworthy can discourage deployment in some contexts where the technology could be beneficial, and make it more likely when it's dangerous. Public transparency alone cannot close this gap: many safety- and security-relevant details are legitimately confidential and require expert interpretation. We define frontier AI auditing as rigorous third-party verification of frontier AI developers' safety and security claims, and evaluation of their systems and practices against relevant standards, based on deep, secure access to non-public information. To make rigor legible and comparable, we introduce AI Assurance Levels (AAL-1 to AAL-4), ranging from time-bounded system audits to continuous, deception-resilient verification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u524d\u6cbfAI\u5ba1\u8ba1\u4f5c\u4e3a\u5173\u952e\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\uff0c\u9700\u8981\u7b2c\u4e09\u65b9\u9a8c\u8bc1AI\u5f00\u53d1\u8005\u7684\u5b89\u5168\u58f0\u660e\u548c\u5b9e\u8df5\uff0c\u5e76\u5f15\u5165AI\u4fdd\u8bc1\u7b49\u7ea7\uff08AAL-1\u5230AAL-4\uff09\u6765\u4f7f\u5ba1\u8ba1\u4e25\u8c28\u6027\u53ef\u8861\u91cf\u3002", "motivation": "\u524d\u6cbfAI\u6b63\u6210\u4e3a\u5173\u952e\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u5916\u90e8\u4eba\u5458\u7f3a\u4e4f\u53ef\u9760\u65b9\u6cd5\u6765\u8bc4\u4f30\u9886\u5148\u5f00\u53d1\u8005\u7684\u5b89\u5168\u548c\u5b89\u4fdd\u58f0\u660e\u7684\u51c6\u786e\u6027\u3002\u4e0e\u6d88\u8d39\u54c1\u3001\u4f01\u4e1a\u8d22\u52a1\u62a5\u8868\u548c\u98df\u54c1\u4f9b\u5e94\u94fe\u7b49\u5176\u4ed6\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u76f8\u6bd4\uff0cAI\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u53d7\u5230\u8f83\u5c11\u7684\u7b2c\u4e09\u65b9\u4e25\u683c\u5ba1\u67e5\u3002AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u7684\u6a21\u7cca\u6027\u53ef\u80fd\u963b\u788d\u5176\u5728\u6709\u76ca\u573a\u666f\u7684\u90e8\u7f72\uff0c\u540c\u65f6\u589e\u52a0\u5371\u9669\u573a\u666f\u7684\u98ce\u9669\u3002", "method": "\u5b9a\u4e49\u524d\u6cbfAI\u5ba1\u8ba1\u4e3a\u5bf9\u524d\u6cbfAI\u5f00\u53d1\u8005\u5b89\u5168\u548c\u5b89\u4fdd\u58f0\u660e\u7684\u4e25\u683c\u7b2c\u4e09\u65b9\u9a8c\u8bc1\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5bf9\u975e\u516c\u5f00\u4fe1\u606f\u7684\u6df1\u5ea6\u5b89\u5168\u8bbf\u95ee\uff0c\u8bc4\u4f30\u5176\u7cfb\u7edf\u548c\u5b9e\u8df5\u662f\u5426\u7b26\u5408\u76f8\u5173\u6807\u51c6\u3002\u5f15\u5165AI\u4fdd\u8bc1\u7b49\u7ea7\uff08AAL-1\u5230AAL-4\uff09\uff0c\u4ece\u6709\u65f6\u95f4\u9650\u5236\u7684\u7cfb\u7edf\u5ba1\u8ba1\u5230\u6301\u7eed\u3001\u6297\u6b3a\u9a97\u7684\u9a8c\u8bc1\uff0c\u4f7f\u4e25\u8c28\u6027\u53ef\u8861\u91cf\u548c\u6bd4\u8f83\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684AI\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7ea7\u4fdd\u8bc1\u673a\u5236\u6765\u89e3\u51b3AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u4e3a\u7b2c\u4e09\u65b9\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u65b9\u6cd5\u8bba\uff0c\u4f7fAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u5b89\u4fdd\u6027\u80fd\u591f\u88ab\u5ba2\u89c2\u8bc4\u4f30\u548c\u6bd4\u8f83\u3002", "conclusion": "\u524d\u6cbfAI\u9700\u8981\u7c7b\u4f3c\u4e8e\u5176\u4ed6\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u4e25\u683c\u7b2c\u4e09\u65b9\u5ba1\u8ba1\u673a\u5236\u3002\u4ec5\u9760\u516c\u5f00\u900f\u660e\u5ea6\u65e0\u6cd5\u89e3\u51b3\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u56e0\u4e3a\u8bb8\u591a\u5b89\u5168\u548c\u5b89\u4fdd\u76f8\u5173\u7684\u7ec6\u8282\u662f\u5408\u6cd5\u7684\u673a\u5bc6\u4fe1\u606f\u3002AI\u4fdd\u8bc1\u7b49\u7ea7\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u4f7fAI\u5ba1\u8ba1\u7684\u4e25\u8c28\u6027\u53d8\u5f97\u53ef\u8861\u91cf\u548c\u53ef\u6bd4\u8f83\uff0c\u6709\u52a9\u4e8e\u5efa\u7acb\u5bf9\u524d\u6cbfAI\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002"}}
{"id": "2601.12178", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12178", "abs": "https://arxiv.org/abs/2601.12178", "authors": ["Fallou Niakh"], "title": "Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses", "comment": null, "summary": "We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5f02\u6784\u53ef\u518d\u751f\u80fd\u6e90\u751f\u4ea7\u635f\u5931\u4e0b\u6821\u51c6\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u5b66\u4e60\u5171\u540c\u6307\u6570\u800c\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\u6821\u51c6\u9700\u8981\u5171\u4eab\u654f\u611f\u7684\u751f\u4ea7\u6570\u636e\uff0c\u8fd9\u5728\u53ef\u518d\u751f\u80fd\u6e90\u9886\u57df\u5b58\u5728\u9690\u79c1\u548c\u5f02\u8d28\u6027\u6311\u6218\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u53c8\u80fd\u5904\u7406\u4e0d\u540c\u751f\u4ea7\u8005\u5f02\u8d28\u6027\uff08\u65b9\u5dee\u548c\u94fe\u63a5\u51fd\u6570\uff09\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "method": "\u751f\u4ea7\u8005\u4f7f\u7528Tweedie\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u5728\u672c\u5730\u5efa\u6a21\u635f\u5931\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff08\u6bd4\u8f83FedAvg\u3001FedProx\u548cFedOpt\u7b97\u6cd5\uff09\u5b66\u4e60\u5171\u540c\u6307\u6570\uff0c\u76f4\u63a5\u6700\u5c0f\u5316\u5168\u5c40\u504f\u5dee\u76ee\u6807\uff0c\u65e0\u9700\u5171\u4eab\u539f\u59cb\u89c2\u6d4b\u6570\u636e\u3002", "result": "\u5728\u5fb7\u56fd\u592a\u9633\u80fd\u53d1\u7535\u751f\u4ea7\u7684\u5b9e\u8bc1\u5e94\u7528\u4e2d\uff0c\u8054\u90a6\u5b66\u4e60\u5728\u9002\u5ea6\u5f02\u8d28\u6027\u4e0b\u6062\u590d\u4e86\u53ef\u6bd4\u8f83\u7684\u6307\u6570\u7cfb\u6570\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u548c\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e3a\u53c2\u6570\u5316\u4fdd\u9669\u6307\u6570\u6821\u51c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u751f\u4ea7\u8005\u95f4\u7684\u5f02\u8d28\u6027\uff0c\u5728\u53ef\u518d\u751f\u80fd\u6e90\u4fdd\u9669\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.12383", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12383", "abs": "https://arxiv.org/abs/2601.12383", "authors": ["Ahmad Mousavi", "Morteza Kimiaei", "Saman Babaie-Kafaki", "Vyacheslav Kungurtsev"], "title": "An efficient penalty decomposition algorithm for minimization over sparse symmetric sets", "comment": null, "summary": "This paper proposes an improved quasi-Newton penalty decomposition algorithm for the minimization of continuously differentiable functions, possibly nonconvex, over sparse symmetric sets. The method solves a sequence of penalty subproblems approximately via a two-block decomposition scheme: the first subproblem admits a closed-form solution without sparsity constraints, while the second subproblem is handled through an efficient sparse projection over the symmetric feasible set. Under a new assumption on the gradient of the objective function, weaker than global Lipschitz continuity from the origin, we establish that accumulation points of the outer iterates are basic feasible and cardinality-constrained Mordukhovich stationarity points. To ensure robustness and efficiency in finite-precision arithmetic, the algorithm incorporates several practical enhancements, including an enhanced line search strategy based on either backtracking or extrapolation, and four inexpensive diagonal Hessian approximations derived from differences of previous iterates and gradients or from eigenvalue-distribution information. Numerical experiments on a diverse benchmark of $30$ synthetic and data-driven test problems, including machine-learning datasets from the UCI repository and sparse symmetric instances with dimensions ranging from $10$ to $500$, demonstrate that the proposed algorithm is competitive with several state-of-the-art methods in terms of efficiency, robustness, and strong stationarity.", "AI": {"tldr": "\u63d0\u51fa\u6539\u8fdb\u7684\u62df\u725b\u987f\u60e9\u7f5a\u5206\u89e3\u7b97\u6cd5\uff0c\u7528\u4e8e\u6c42\u89e3\u7a00\u758f\u5bf9\u79f0\u96c6\u4e0a\u7684\u8fde\u7eed\u53ef\u5fae\u51fd\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u652f\u6301\u975e\u51f8\u76ee\u6807\u51fd\u6570\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5206\u89e3\u548c\u5b9e\u7528\u589e\u5f3a\u7b56\u7565\u5b9e\u73b0\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7a00\u758f\u5bf9\u79f0\u7ea6\u675f\u4e0b\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5f31\u5047\u8bbe\u6761\u4ef6\u4e0b\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u517c\u987e\u7406\u8bba\u4fdd\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u62df\u725b\u987f\u60e9\u7f5a\u5206\u89e3\u7b97\u6cd5\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff1a\u65e0\u7a00\u758f\u7ea6\u675f\u7684\u95ed\u5f0f\u89e3\u5b50\u95ee\u9898\u548c\u9ad8\u6548\u7a00\u758f\u6295\u5f71\u5b50\u95ee\u9898\u3002\u5f15\u5165\u589e\u5f3a\u7ebf\u641c\u7d22\u7b56\u7565\uff08\u56de\u6eaf\u6216\u5916\u63a8\uff09\u548c\u56db\u79cd\u5ec9\u4ef7\u5bf9\u89d2Hessian\u8fd1\u4f3c\u65b9\u6cd5\u3002", "result": "\u572830\u4e2a\u5408\u6210\u548c\u6570\u636e\u9a71\u52a8\u7684\u6d4b\u8bd5\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u5305\u62ecUCI\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u548c\u7ef4\u5ea610\u5230500\u7684\u7a00\u758f\u5bf9\u79f0\u5b9e\u4f8b\uff0c\u7b97\u6cd5\u5728\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u5f3a\u7a33\u5b9a\u6027\u65b9\u9762\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\uff08\u6bd4\u5168\u5c40Lipschitz\u8fde\u7eed\u6027\u66f4\u5f31\uff09\u8bc1\u660e\u4e86\u6536\u655b\u6027\uff0c\u5b9e\u9645\u589e\u5f3a\u7b56\u7565\u786e\u4fdd\u4e86\u6709\u9650\u7cbe\u5ea6\u7b97\u672f\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u4e3a\u7a00\u758f\u5bf9\u79f0\u7ea6\u675f\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11758", "abs": "https://arxiv.org/abs/2601.11758", "authors": ["Arnab Das Utsa"], "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation", "comment": "9 figures, more than 1o pages", "summary": "Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u8bed\u8a00\u7684\u900f\u660e\u7126\u8651\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u8bed\u8a00\u7279\u5f81\u548c\u8de8\u57df\u9a8c\u8bc1\u5b9e\u73b0\u53ef\u9760\u3001\u53ef\u6cdb\u5316\u7684\u7b5b\u67e5", "motivation": "\u5168\u7403\u7126\u8651\u75c7\u5f71\u54cd\u6570\u4ebf\u4eba\uff0c\u4f46\u5927\u89c4\u6a21\u7b5b\u67e5\u53d7\u9650\uff1b\u793e\u4ea4\u5a92\u4f53\u8bed\u8a00\u63d0\u4f9b\u53ef\u6269\u5c55\u68c0\u6d4b\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u5173\u952e\u8bcd\u9c81\u68d2\u6027\u9a8c\u8bc1\u548c\u4e25\u683c\u7684\u7528\u6237\u7ea7\u6570\u636e\u5b8c\u6574\u6027", "method": "\u4f7f\u7528Reddit\u5e16\u5b50\u6570\u636e\u96c6\uff0c\u5728\u7cbe\u5fc3\u7b56\u5212\u7684\u5b50\u7248\u5757\u4e0a\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff1b\u8fdb\u884c\u7279\u5f81\u6d88\u878d\u3001\u5173\u952e\u8bcd\u63a9\u7801\u5b9e\u9a8c\u3001\u4e0d\u540c\u5bc6\u5ea6\u5dee\u5f02\u5206\u6790\uff0c\u5e76\u4e0e\u4e34\u5e8a\u8bbf\u8c08\u53c2\u4e0e\u8005\u8fdb\u884c\u5916\u90e8\u9a8c\u8bc1", "result": "\u6a21\u578b\u8868\u73b0\u5f3a\u52b2\uff0c\u5373\u4f7f\u5728\u60c5\u611f\u79fb\u9664\u6216\u5173\u952e\u8bcd\u63a9\u7801\u540e\u4ecd\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff1b\u4f7f\u7528\u6700\u5c11\u53d1\u5e16\u5386\u53f2\u7684\u65e9\u671f\u68c0\u6d4b\u663e\u8457\u4f18\u4e8e\u968f\u673a\u5206\u7c7b\uff1b\u8de8\u57df\u5206\u6790\u4e0e\u4e34\u5e8a\u8bbf\u8c08\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4", "conclusion": "\u900f\u660e\u8bed\u8a00\u7279\u5f81\u53ef\u652f\u6301\u53ef\u9760\u3001\u53ef\u6cdb\u5316\u3001\u5173\u952e\u8bcd\u9c81\u68d2\u7684\u7126\u8651\u68c0\u6d4b\uff1b\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u8de8\u4e0d\u540c\u5728\u7ebf\u73af\u5883\u7684\u53ef\u89e3\u91ca\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u57fa\u7ebf"}}
{"id": "2601.11657", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11657", "abs": "https://arxiv.org/abs/2601.11657", "authors": ["Jack T. Beerman", "Shobhan Roy", "H. S. Udaykumar", "Stephen S. Baek"], "title": "Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning", "comment": null, "summary": "Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned \"active filtration\" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.", "AI": {"tldr": "D-PARC\u67b6\u6784\u901a\u8fc7\u53ef\u53d8\u5f62\u7269\u7406\u611f\u77e5\u5faa\u73af\u5377\u79ef\uff0c\u5728\u4fdd\u6301\u7f51\u7edc\u7cbe\u7b80\u7684\u540c\u65f6\uff0c\u8d85\u8d8a\u66f4\u5927\u89c4\u6a21\u7f51\u7edc\u5728\u590d\u6742\u7269\u7406\u7cfb\u7edf\u9884\u6d4b\u4e2d\u7684\u6027\u80fd", "motivation": "\u5f53\u524dCNN\u67b6\u6784\u5728\u5904\u7406\u9ad8\u5ea6\u975e\u7ebf\u6027\u6d41\u4f53\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5355\u7eaf\u6269\u5927\u6a21\u578b\u89c4\u6a21\u5bf9\u7269\u7406\u5efa\u6a21\u6548\u679c\u63d0\u5347\u6709\u9650\uff0c\u9700\u8981\u501f\u9274\u6df7\u5408\u62c9\u683c\u6717\u65e5-\u6b27\u62c9\u6570\u503c\u65b9\u6cd5\u7684\u7269\u7406\u76f4\u89c9\u6765\u6539\u8fdb\u67b6\u6784\u8bbe\u8ba1", "method": "\u63d0\u51fa\u53ef\u53d8\u5f62\u7269\u7406\u611f\u77e5\u5faa\u73af\u5377\u79ef\uff08D-PARC\uff09\uff0c\u501f\u9274\u6df7\u5408\u62c9\u683c\u6717\u65e5-\u6b27\u62c9\u65b9\u6cd5\u601d\u60f3\uff0c\u514b\u670dCNN\u7684\u521a\u6027\u9650\u5236\uff0c\u901a\u8fc7\u53ef\u53d8\u5f62\u6838\u5b9e\u73b0\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565", "result": "\u5728Burgers\u65b9\u7a0b\u3001Navier-Stokes\u65b9\u7a0b\u548c\u53cd\u5e94\u6d41\u7b49\u591a\u4e2a\u7269\u7406\u7cfb\u7edf\u4e2d\uff0cD-PARC\u76f8\u6bd4\u66f4\u5927\u89c4\u6a21\u67b6\u6784\u83b7\u5f97\u66f4\u4f18\u7684\u9884\u6d4b\u7cbe\u5ea6\uff1b\u5206\u6790\u663e\u793a\u6838\u8868\u73b0\u51fa\u53cd\u805a\u96c6\u884c\u4e3a\uff0c\u5f62\u6210\u72ec\u7279\u7684\"\u4e3b\u52a8\u8fc7\u6ee4\"\u7b56\u7565\uff0c\u6709\u6548\u611f\u53d7\u91ce\u5206\u6790\u8bc1\u5b9eD-PARC\u80fd\u81ea\u4e3b\u5728\u9ad8\u5e94\u53d8\u533a\u57df\u96c6\u4e2d\u8d44\u6e90", "conclusion": "\u7269\u7406\u76f4\u89c9\u9a71\u52a8\u7684\u67b6\u6784\u8bbe\u8ba1\u4f18\u4e8e\u53c2\u6570\u89c4\u6a21\u6269\u5c55\uff0c\u7cbe\u7b80\u7f51\u7edc\u7684\u7b56\u7565\u6027\u5b66\u4e60\u4e3a\u7269\u7406\u611f\u77e5\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6bd4\u76f2\u76ee\u7f51\u7edc\u6269\u5f20\u66f4\u6709\u6548\u7684\u8def\u5f84"}}
{"id": "2601.11905", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.11905", "abs": "https://arxiv.org/abs/2601.11905", "authors": ["Junyu Cao", "Ruijiang Gao", "Esmaeil Keyvanshokooh", "Jianhao Ma"], "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning", "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640", "summary": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u7b97\u6cd5\u8ffd\u7d22\u3001\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548cLLM\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\uff0c\u5f00\u53d1\u4e86GLRB\u548cLIBRA\u7b97\u6cd5\uff0c\u5728\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u987a\u5e8f\u51b3\u7b56\u573a\u666f\uff08\u5982\u4e2a\u6027\u5316\u533b\u7597\uff09\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u6cbb\u7597\u884c\u52a8\u548c\u60a3\u8005\u7279\u5f81\u7684\u53ef\u53d8\u4fee\u6539\uff0c\u5e76\u6709\u6548\u7ed3\u5408LLM\u7684\u9886\u57df\u77e5\u8bc6\u548c\u8001\u864e\u673a\u5b66\u4e60\u7684\u7edf\u8ba1\u4e25\u8c28\u6027\u3002", "method": "1. \u63d0\u51fa\u8ffd\u7d22\u8001\u864e\u673a\u95ee\u9898\uff1b2. \u5f00\u53d1GLRB\u7b97\u6cd5\uff1b3. \u63d0\u51faLIBRA\u7b97\u6cd5\uff0c\u6218\u7565\u6027\u5730\u7ed3\u5408LLM\u9886\u57df\u77e5\u8bc6\u548c\u8001\u864e\u673a\u5b66\u4e60\uff1b4. \u5efa\u7acb\u5339\u914d\u7684\u4e0b\u754c\u5206\u6790\u3002", "result": "1. \u7406\u8bba\u4fdd\u8bc1\uff1aLIBRA\u5177\u6709\u70ed\u542f\u52a8\u4fdd\u8bc1\u3001LLM\u52aa\u529b\u4fdd\u8bc1\u548c\u9c81\u68d2\u6027\u4fdd\u8bc1\uff1b2. \u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u5728\u5408\u6210\u73af\u5883\u548c\u771f\u5b9e\u9ad8\u8840\u538b\u7ba1\u7406\u6848\u4f8b\u4e2d\uff0cGLRB\u548cLIBRA\u5728\u9057\u61be\u3001\u6cbb\u7597\u8d28\u91cf\u548c\u6837\u672c\u6548\u7387\u4e0a\u4f18\u4e8e\u6807\u51c6\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u548c\u7eafLLM\u57fa\u51c6\u3002", "conclusion": "\u8ffd\u7d22\u611f\u77e5\u3001LLM\u8f85\u52a9\u7684\u8001\u864e\u673a\u7b97\u6cd5\u4e3a\u9ad8\u98ce\u9669\u4e2a\u6027\u5316\u51b3\u7b56\u4e2d\u53ef\u4fe1\u7684LLM-\u8001\u864e\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12625", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12625", "abs": "https://arxiv.org/abs/2601.12625", "authors": ["Parisa Ansari Bonab", "Elisabeth Andarge Gedefaw", "Mohammad Khajenejad"], "title": "Resilient Interval Observer-Based Control for Cooperative Adaptive Cruise Control under FDI Attack", "comment": null, "summary": "Connectivity in connected and autonomous vehicles (CAVs) introduces vulnerability to cyber threats such as false data injection (FDI) attacks, which can compromise system reliability and safety. To ensure resilience, this paper proposes a control framework combining a nonlinear controller with an interval observer for robust state estimation under measurement noise. The observer bounds leader's states, while a neural network-based estimator estimates the unknown FDI attacks in real time. These estimates are then used to mitigate FDI attack effects maintaining safe inter-vehicle spacing. The proposed approach leverages an idea of interval observer-based estimation and merges model-based and learning-based methods to achieve accurate estimations and real-time performance. MATLAB/Simulink results confirm resilient tracking, precise FDI attack estimation, and robustness to noise, demonstrating potential for real-world CACC applications under cyberattacks, disturbance, and bounded measurement noise.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u975e\u7ebf\u6027\u63a7\u5236\u5668\u548c\u533a\u95f4\u89c2\u6d4b\u5668\u7684\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8eCAV\u7cfb\u7edf\u5728\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u4e0b\u7684\u5f39\u6027\u63a7\u5236\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b9e\u65f6\u4f30\u8ba1\u653b\u51fb\u5e76\u4fdd\u6301\u5b89\u5168\u8f66\u8ddd\u3002", "motivation": "\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86(CAV)\u7684\u8fde\u63a5\u6027\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u865a\u5047\u6570\u636e\u6ce8\u5165(FDI)\u7b49\u7f51\u7edc\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u8fd9\u4f1a\u635f\u5bb3\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002\u9700\u8981\u786e\u4fdd\u7cfb\u7edf\u5728\u653b\u51fb\u4e0b\u7684\u5f39\u6027\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u975e\u7ebf\u6027\u63a7\u5236\u5668\u548c\u533a\u95f4\u89c2\u6d4b\u5668\u7684\u63a7\u5236\u6846\u67b6\uff1a1) \u533a\u95f4\u89c2\u6d4b\u5668\u5728\u6709\u754c\u6d4b\u91cf\u566a\u58f0\u4e0b\u4f30\u8ba1\u9886\u5bfc\u8005\u72b6\u6001\uff1b2) \u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u4f30\u8ba1\u5668\u5b9e\u65f6\u4f30\u8ba1\u672a\u77e5FDI\u653b\u51fb\uff1b3) \u5229\u7528\u653b\u51fb\u4f30\u8ba1\u503c\u6765\u7f13\u89e3\u653b\u51fb\u5f71\u54cd\uff0c\u4fdd\u6301\u5b89\u5168\u8f66\u8ddd\u3002\u878d\u5408\u4e86\u57fa\u4e8e\u6a21\u578b\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "result": "MATLAB/Simulink\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1a\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5f39\u6027\u8ddf\u8e2a\u3001\u7cbe\u786e\u7684FDI\u653b\u51fb\u4f30\u8ba1\u3001\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5728\u771f\u5b9eCACC\u5e94\u7528\u4e2d\u5e94\u5bf9\u7f51\u7edc\u653b\u51fb\u3001\u5e72\u6270\u548c\u6709\u754c\u6d4b\u91cf\u566a\u58f0\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a7\u5236\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u533a\u95f4\u89c2\u6d4b\u5668\u548c\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1\u5668\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9CAV\u7cfb\u7edf\u4e2d\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff0c\u786e\u4fdd\u7cfb\u7edf\u5728\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.11763", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11763", "abs": "https://arxiv.org/abs/2601.11763", "authors": ["Rui-Jie Yew", "Kate Elizabeth Creasey", "Taylor Lynn Curtis", "Suresh Venkatasubramanian"], "title": "The Commodification of AI Sovereignty: Lessons from the Fight for Sovereign Oil", "comment": null, "summary": "\"Sovereignty\" is increasingly a part of national AI policies and strategies. At the same time that \"sovereignty\" is invoked as a priority for global AI policy, it is also being commodified along the AI stack. Companies now sell \"sovereign\" AI factories, clouds, and language models to governments, enterprises, and communities -- turning a contested value into a commercial commodity. This shift risks allowing private technology providers to define sovereignty on their own terms. By analyzing the history of sovereignty and parallels in global oil production, this paper aims to open avenues to interrogate the implications of this value's commercialization. The contributions of this paper lie in a disentangling of the facets of sovereignty being appealed to through the AI stack and a case for how analogizing oil and AI can be generative in thinking through what is achieved and what can be achieved through the commodification of AI sovereignty.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\"\u4e3b\u6743\"\u5728AI\u653f\u7b56\u4e2d\u7684\u5546\u4e1a\u5316\u73b0\u8c61\uff0c\u5206\u6790AI\u4e3b\u6743\u5982\u4f55\u88ab\u6280\u672f\u516c\u53f8\u5546\u54c1\u5316\uff0c\u5e76\u501f\u9274\u77f3\u6cb9\u4ea7\u4e1a\u5386\u53f2\u6765\u601d\u8003\u8fd9\u4e00\u8d8b\u52bf\u7684\u540e\u679c\u3002", "motivation": "\u968f\u7740\"\u4e3b\u6743\"\u6210\u4e3a\u5404\u56fdAI\u653f\u7b56\u548c\u6218\u7565\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u5b83\u6b63\u6cbf\u7740AI\u6280\u672f\u6808\u88ab\u5546\u54c1\u5316\u3002\u6280\u672f\u516c\u53f8\u5411\u653f\u5e9c\u3001\u4f01\u4e1a\u548c\u793e\u533a\u9500\u552e\"\u4e3b\u6743\"AI\u5de5\u5382\u3001\u4e91\u670d\u52a1\u548c\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u8fd9\u4e00\u6709\u4e89\u8bae\u7684\u4ef7\u503c\u8f6c\u5316\u4e3a\u5546\u4e1a\u5546\u54c1\u3002\u8fd9\u79cd\u8f6c\u53d8\u5b58\u5728\u98ce\u9669\uff0c\u53ef\u80fd\u8ba9\u79c1\u4eba\u6280\u672f\u63d0\u4f9b\u5546\u6309\u7167\u81ea\u5df1\u7684\u6761\u4ef6\u5b9a\u4e49\u4e3b\u6743\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e3b\u6743\u7684\u5386\u53f2\u6f14\u53d8\uff0c\u5e76\u501f\u9274\u5168\u7403\u77f3\u6cb9\u751f\u4ea7\u7684\u7c7b\u6bd4\uff0c\u8bba\u6587\u65e8\u5728\u5f00\u8f9f\u9014\u5f84\u6765\u5ba1\u89c6\u8fd9\u4e00\u4ef7\u503c\u5546\u4e1a\u5316\u7684\u5f71\u54cd\u3002\u65b9\u6cd5\u5305\u62ec\u89e3\u6784AI\u6280\u672f\u6808\u4e2d\u6d89\u53ca\u7684\u4e3b\u6743\u7ef4\u5ea6\uff0c\u4ee5\u53ca\u901a\u8fc7\u77f3\u6cb9\u4e0eAI\u7684\u7c7b\u6bd4\u6765\u751f\u6210\u6027\u601d\u8003\u3002", "result": "\u8bba\u6587\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\uff1a1) \u89e3\u6784\u4e86AI\u6280\u672f\u6808\u4e2d\u6d89\u53ca\u7684\u5404\u79cd\u4e3b\u6743\u7ef4\u5ea6\uff1b2) \u8bba\u8bc1\u4e86\u77f3\u6cb9\u4e0eAI\u7684\u7c7b\u6bd4\u5982\u4f55\u80fd\u591f\u751f\u6210\u6027\u5730\u601d\u8003AI\u4e3b\u6743\u5546\u54c1\u5316\u5b9e\u73b0\u4e86\u4ec0\u4e48\u4ee5\u53ca\u53ef\u80fd\u5b9e\u73b0\u4ec0\u4e48\u3002", "conclusion": "AI\u4e3b\u6743\u7684\u5546\u4e1a\u5316\u8d8b\u52bf\u9700\u8981\u6279\u5224\u6027\u5ba1\u89c6\uff0c\u6280\u672f\u516c\u53f8\u5bf9\u4e3b\u6743\u7684\u5b9a\u4e49\u6743\u53ef\u80fd\u5e26\u6765\u98ce\u9669\u3002\u901a\u8fc7\u5386\u53f2\u5206\u6790\u548c\u4ea7\u4e1a\u7c7b\u6bd4\uff0c\u8bba\u6587\u4e3a\u601d\u8003\u8fd9\u4e00\u73b0\u8c61\u63d0\u4f9b\u4e86\u5206\u6790\u6846\u67b6\uff0c\u5f3a\u8c03\u9700\u8981\u5173\u6ce8\u4e3b\u6743\u5546\u54c1\u5316\u7684\u653f\u6cbb\u7ecf\u6d4e\u5f71\u54cd\u3002"}}
{"id": "2601.12213", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12213", "abs": "https://arxiv.org/abs/2601.12213", "authors": ["Hongyang R. Zhang", "Zhenshuo Zhang", "Huy L. Nguyen", "Guanghui Lan"], "title": "One-Sided Matrix Completion from Ultra-Sparse Samples", "comment": "41 pages", "summary": "Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\\times d$ matrix $M$ (with $n \\ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \\ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\\top} M / n$.\n  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \\ge O({d r^5 \u03b5^{-2} C^{-2} \\log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $\u03b5^2$.\n  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\\%$ and $M$ by $38\\%$ compared to baseline methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u8d85\u7a00\u758f\u91c7\u6837\u4e0b\uff08\u6bcf\u884c\u4ec5C\u4e2a\u89c2\u6d4b\uff09\u4f30\u8ba1\u77e9\u9635\u884c\u7a7a\u95f4\u6216\u4e8c\u9636\u77e9\u77e9\u9635\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u89c2\u6d4b\u9891\u7387\u548c\u68af\u5ea6\u4e0b\u964d\u6062\u590d\u7f3a\u5931\u7684\u4e8c\u9636\u77e9\u4fe1\u606f\u3002", "motivation": "\u9488\u5bf9\u5927\u89c4\u6a21\u7a00\u758f\u9762\u677f\u6570\u636e\uff08\u884c\u6570\u8fdc\u5927\u4e8e\u5217\u6570\uff09\u7684\u8d85\u7a00\u758f\u91c7\u6837\u573a\u666f\uff0c\u4f20\u7edf\u77e9\u9635\u8865\u5168\u65b9\u6cd5\u5728\u6bcf\u884c\u89c2\u6d4b\u6570\u5c11\u4e8e\u77e9\u9635\u79e9\u65f6\u65e0\u6cd5\u51c6\u786e\u8865\u5168\uff0c\u8f6c\u800c\u4f30\u8ba1\u77e9\u9635\u7684\u884c\u7a7a\u95f4\u6216\u4e8c\u9636\u77e9\u77e9\u9635\u3002", "method": "\u63d0\u51fa\u65e0\u504f\u4f30\u8ba1\u5668\uff1a\u5bf9\u4e8c\u9636\u77e9\u77e9\u9635\u7684\u6bcf\u4e2a\u975e\u96f6\u89c2\u6d4b\u9879\u6309\u5176\u89c2\u6d4b\u9891\u7387\u5f52\u4e00\u5316\uff0c\u7136\u540e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u8865\u5168\u4e8c\u9636\u77e9\u77e9\u9635\u7684\u7f3a\u5931\u9879\u3002\u5f52\u4e00\u5316\u5c06n\u4e2a\u4e8c\u9879\u968f\u673a\u53d8\u91cf\u7684\u52a0\u6743\u548c\u9664\u4ee5\u603b\u89c2\u6d4b\u6570\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u5f53n \u2265 O(dr\u2075\u03b5\u207b\u00b2C\u207b\u00b2log d)\u65f6\uff0c\u68af\u5ea6\u4e0b\u964d\u7684\u4efb\u610f\u5c40\u90e8\u6700\u5c0f\u503c\u90fd\u8fd1\u4f3c\u4e3a\u5168\u5c40\u6700\u4f18\uff0c\u80fd\u4ee5\u03b5\u00b2\u8bef\u5dee\u6062\u590dT\u3002\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u5728MovieLens\u6570\u636e\u96c6\u4e0a\u51cf\u5c1188%\u504f\u5dee\uff0c\u5728Amazon\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\u51cf\u5c1159%\u7684T\u6062\u590d\u8bef\u5dee\u548c38%\u7684M\u6062\u590d\u8bef\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8d85\u7a00\u758f\u91c7\u6837\u4e0b\u6709\u6548\u4f30\u8ba1\u4e8c\u9636\u77e9\u77e9\u9635\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7a00\u758f\u9762\u677f\u6570\u636e\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86n\u76f8\u5bf9\u4e8ed\u7684\u7ebf\u6027\u91c7\u6837\u590d\u6742\u5ea6\u3002"}}
{"id": "2601.12398", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12398", "abs": "https://arxiv.org/abs/2601.12398", "authors": ["Haijuan Liu", "Xuyang Wu"], "title": "Anderson Acceleration for Distributed Constrained Optimization over Time-varying Networks", "comment": null, "summary": "This paper applies the Anderson Acceleration (AA) technique to accelerate the Fenchel dual gradient method (FDGM) to solve constrained optimization problems over time-varying networks. AA is originally designed for accelerating fixed-point iterations, and its direct application to FDGM faces two challenges: 1) FDGM in time-varying networks cannot be formulated as a standard fixed-point update; 2) even if the network is fixed so that FDGM can be expressed as a fixed-point iteration, the direct application of AA is not distributively implementable. To overcome these challenges, we first rewrite each update of FDGM as inexactly solving several \\emph{local} problems where each local problem involves two neighboring nodes only, and then incorporate AA to solve each local problem with higher accuracy, resulting in the Fenchel Dual Gradient Method with Anderson Acceleration (FDGM-AA). To guarantee global convergence of FDGM-AA, we equip it with a newly designed safe-guard scheme. Under mild conditions, our algorithm converges at a rate of \\(O(1/\\sqrt{k})\\) for the primal sequence and \\(O(1/k)\\) for the dual sequence. The competitive performance of our algorithm is validated through numerical experiments.", "AI": {"tldr": "\u5c06Anderson Acceleration\u6280\u672f\u5e94\u7528\u4e8eFenchel\u5bf9\u5076\u68af\u5ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u65f6\u53d8\u7f51\u7edc\u4e0a\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faFDGM-AA\u7b97\u6cd5\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "motivation": "\u4f20\u7edfFDGM\u5728\u65f6\u53d8\u7f51\u7edc\u4e0a\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u800cAnderson Acceleration\u6280\u672f\u867d\u80fd\u52a0\u901f\u56fa\u5b9a\u70b9\u8fed\u4ee3\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8eFDGM\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1) \u65f6\u53d8\u7f51\u7edc\u4e0bFDGM\u65e0\u6cd5\u8868\u793a\u4e3a\u6807\u51c6\u56fa\u5b9a\u70b9\u66f4\u65b0\uff1b2) \u5373\u4f7f\u7f51\u7edc\u56fa\u5b9a\uff0c\u76f4\u63a5\u5e94\u7528AA\u4e5f\u65e0\u6cd5\u5206\u5e03\u5f0f\u5b9e\u73b0\u3002", "method": "\u5c06FDGM\u7684\u6bcf\u6b21\u66f4\u65b0\u91cd\u5199\u4e3a\u591a\u4e2a\u5c40\u90e8\u95ee\u9898\u7684\u8fd1\u4f3c\u6c42\u89e3\uff0c\u6bcf\u4e2a\u5c40\u90e8\u95ee\u9898\u4ec5\u6d89\u53ca\u4e24\u4e2a\u76f8\u90bb\u8282\u70b9\uff0c\u7136\u540e\u5f15\u5165AA\u6280\u672f\u4ee5\u66f4\u9ad8\u7cbe\u5ea6\u6c42\u89e3\u6bcf\u4e2a\u5c40\u90e8\u95ee\u9898\uff0c\u5f62\u6210FDGM-AA\u7b97\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u65b0\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\u3002", "result": "\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u7b97\u6cd5\u5bf9\u539f\u59cb\u5e8f\u5217\u4ee5O(1/\u221ak)\u901f\u7387\u6536\u655b\uff0c\u5bf9\u5076\u5e8f\u5217\u4ee5O(1/k)\u901f\u7387\u6536\u655b\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u7ade\u4e89\u6027\u80fd\u3002", "conclusion": "\u6210\u529f\u5c06Anderson Acceleration\u6280\u672f\u5e94\u7528\u4e8e\u65f6\u53d8\u7f51\u7edc\u4e0a\u7684Fenchel\u5bf9\u5076\u68af\u5ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5\u5e94\u7528\u7684\u6280\u672f\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u53ef\u5206\u5e03\u5f0f\u5b9e\u73b0\u7684FDGM-AA\u7b97\u6cd5\u5e76\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002"}}
{"id": "2601.11762", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11762", "abs": "https://arxiv.org/abs/2601.11762", "authors": ["Sae Young Moon", "Myeongjun Erik Jang", "Haoyan Luo", "Chunyang Xiao", "Antonios Georgiadis", "Fran Silavong"], "title": "Industry-Aligned Granular Topic Modeling", "comment": null, "summary": "Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.", "AI": {"tldr": "TIDE\u6846\u67b6\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u6587\u6863\u6458\u8981\u3001\u4e3b\u9898\u5c42\u7ea7\u7b49\u4e1a\u52a1\u529f\u80fd", "motivation": "\u4e3b\u9898\u5efa\u6a21\u5728\u5de5\u4e1a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u7ec6\u7c92\u5ea6\u4e3b\u9898\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u800c\u7ec6\u7c92\u5ea6\u5bf9\u5546\u4e1a\u5e94\u7528\u5177\u6709\u91cd\u8981\u4ef7\u503c", "method": "\u63d0\u51faTIDE\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u6587\u6863\u6458\u8981\u3001\u4e3b\u9898\u5c42\u7ea7\u5173\u7cfb\u3001\u4e3b\u9898\u84b8\u998f\u7b49\u8f85\u52a9\u529f\u80fd", "result": "\u5728\u591a\u79cd\u516c\u5f00\u548c\u771f\u5b9e\u5546\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTIDE\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u4f18\u4e8e\u73b0\u4ee3\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u8f85\u52a9\u7ec4\u4ef6\u4e3a\u5de5\u4e1a\u4e1a\u52a1\u573a\u666f\u63d0\u4f9b\u6709\u4ef7\u503c\u652f\u6301", "conclusion": "TIDE\u6846\u67b6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\uff0c\u6b63\u5728\u5f00\u6e90\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u5546\u4e1a\u5e94\u7528\u63d0\u4f9b\u6df1\u5ea6\u6d1e\u5bdf"}}
{"id": "2601.11661", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.11661", "abs": "https://arxiv.org/abs/2601.11661", "authors": ["Mohammad Mohammadzadeh Sanandaji", "Danial Ebrahimzadeh", "Mohammad Ikram Haider", "Yaser Mike Banad", "Aleksandar Poleksic", "Hongtao Ding"], "title": "Machine learning model for predicting surface wettability in laser-textured metal alloys", "comment": "This manuscript has 9 figures and contains 16 pages two column. submitted to journal of laser applications. Under review", "summary": "Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.", "AI": {"tldr": "\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u5f62\u6001\u548c\u5316\u5b66\u7279\u5f81\u9884\u6d4b\u6fc0\u5149\u7eb9\u7406\u91d1\u5c5e\u5408\u91d1\u7684\u6da6\u6e7f\u6027\uff0c\u51c6\u786e\u7387\u8fbeR\u00b2=0.942\u3002", "motivation": "\u8868\u9762\u6da6\u6e7f\u6027\u7531\u5f62\u8c8c\u548c\u5316\u5b66\u6027\u8d28\u5171\u540c\u51b3\u5b9a\uff0c\u5bf9\u4f20\u70ed\u3001\u6da6\u6ed1\u3001\u5fae\u6d41\u63a7\u548c\u8868\u9762\u6d82\u5c42\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u590d\u6742\u8868\u9762\u7684\u6da6\u6e7f\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u7eb3\u79d2\u6fc0\u5149\u7eb9\u7406\u5316\u548c\u5316\u5b66\u6d78\u6e0d\u5904\u7406\u5236\u5907\u8d85\u4eb2\u6c34\u548c\u8d85\u758f\u6c34\u8868\u9762\uff1b\u901a\u8fc7Laws\u7eb9\u7406\u80fd\u91cf\u6cd5\u548c\u8f6e\u5ed3\u4eea\u91cf\u5316\u5f62\u6001\u7279\u5f81\uff0cXPS\u5206\u6790\u5316\u5b66\u7279\u5f81\uff1b\u8bad\u7ec3\u5305\u542b\u6b8b\u5dee\u8fde\u63a5\u3001\u6279\u91cf\u5f52\u4e00\u5316\u548cdropout\u6b63\u5219\u5316\u7684\u96c6\u6210\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff08R\u00b2=0.942\uff0cRMSE=13.896\uff09\uff0c\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff1b\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u663e\u793a\u8868\u9762\u5316\u5b66\u5bf9\u63a5\u89e6\u89d2\u9884\u6d4b\u5f71\u54cd\u6700\u5927\uff0c\u5f62\u8c8c\u7279\u5f81\u4e5f\u6709\u663e\u8457\u8d21\u732e\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u4eba\u5de5\u667a\u80fd\u901a\u8fc7\u6355\u6349\u8868\u9762\u7279\u6027\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u6765\u5efa\u6a21\u548c\u9884\u6d4b\u6da6\u6e7f\u884c\u4e3a\u7684\u6f5c\u529b\uff0c\u4e3a\u8bbe\u8ba1\u5b9a\u5236\u529f\u80fd\u8868\u9762\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u9014\u5f84\u3002"}}
{"id": "2601.11940", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11940", "abs": "https://arxiv.org/abs/2601.11940", "authors": ["Kang Chen", "Fan Yu", "Junjie Nian", "Shihan Zhao", "Zhuoka Feng", "Zijun Yao", "Heng Wang", "Minshen Yu", "Yixin Cao"], "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart", "comment": null, "summary": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.", "AI": {"tldr": "TAAR\u6846\u67b6\u901a\u8fc7\u68c0\u6d4b\u601d\u7ef4\u9677\u9631\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff0c\u63d0\u5347\u5927\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u65e0\u9700\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53c2\u6570\u3002", "motivation": "\u957f\u601d\u7ef4\u94fe\uff08Long-CoT\uff09\u867d\u7136\u80fd\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u6a21\u578b\u4e00\u65e6\u65e9\u671f\u72af\u9519\u5c31\u4f1a\u9677\u5165\"\u601d\u7ef4\u9677\u9631\"\u2014\u2014\u5373\u4f7f\u540e\u7eed\u53cd\u601d\u3001\u5c1d\u8bd5\u66ff\u4ee3\u65b9\u6848\u6216\u9a8c\u8bc1\u4e5f\u65e0\u6cd5\u4fee\u6b63\u6839\u9519\u8bef\u3002\u5728DAPO-MATH\u7684\u7279\u5b9a\u5b50\u96c6\u4e2d\uff0c89%\u7684\u5931\u8d25\u6848\u4f8b\u90fd\u5b58\u5728\u8fd9\u79cd\u9677\u9631\u3002", "method": "\u63d0\u51faTAAR\uff08Trap-Aware Adaptive Restart\uff09\u6846\u67b6\uff1a\u8bad\u7ec3\u8bca\u65ad\u7b56\u7565\u4ece\u90e8\u5206\u8f68\u8ff9\u4e2d\u9884\u6d4b\u4e24\u4e2a\u4fe1\u53f7\u2014\u2014\u9677\u9631\u4f4d\u7f6e\u7d22\u5f15\uff08\u6307\u793a\u622a\u65ad\u70b9\uff09\u548c\u9003\u8131\u6982\u7387\uff08\u51b3\u5b9a\u5e72\u9884\u5f3a\u5ea6\uff09\u3002\u63a8\u7406\u65f6\uff0cTAAR\u5728\u9884\u6d4b\u7684\u9677\u9631\u6bb5\u524d\u622a\u65ad\u8f68\u8ff9\u5e76\u81ea\u9002\u5e94\u91cd\u542f\u89e3\u7801\uff1b\u5bf9\u4e8e\u4e25\u91cd\u9677\u9631\u60c5\u51b5\uff0c\u5e94\u7528\u66f4\u5f3a\u7684\u6270\u52a8\uff0c\u5305\u62ec\u66f4\u9ad8\u6e29\u5ea6\u7684\u91cd\u91c7\u6837\u548c\u53ef\u9009\u7684\u7ed3\u6784\u5316\u91cd\u542f\u540e\u7f00\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u548c\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08AIME24\u3001AIME25\u3001GPQA-Diamond\u3001HMMT25\u3001BRUMO25\uff09\u4e0a\uff0cTAAR\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53c2\u6570\u3002", "conclusion": "TAAR\u6846\u67b6\u901a\u8fc7\u68c0\u6d4b\u548c\u89c4\u907f\u601d\u7ef4\u9677\u9631\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u65e9\u671f\u9519\u8bef\u627f\u8bfa\u5bfc\u81f4\u7684\u6301\u7eed\u9519\u8bef\u95ee\u9898\uff0c\u4e3a\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u53c2\u6570\u5fae\u8c03\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.12657", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12657", "abs": "https://arxiv.org/abs/2601.12657", "authors": ["Yin Wu", "Wei-Yu Chiu", "Yuan-Po Tsai", "Shangyuan Liu", "Weiqi Hua"], "title": "Multiagent Reinforcement Learning in Enhancing Resilience of Microgrids under Extreme Weather Events", "comment": "26 pages, 9 figures", "summary": "Grid resilience is crucial in light of power interruptions caused by increasingly frequent extreme weather events. Well-designed energy management systems (EMS) have made progress in improving microgrid resilience through the coordination of distributed energy resources (DERs), but still face significant challenges in addressing the uncertainty of load demand caused by extreme weather. The integration of deep reinforcement learning (DRL) into EMS design enables optimized microgrid control strategies for coordinating DERs. Building on this, we proposed a cooperative multi-agent deep reinforcement learning (MADRL)-based EMS framework to provide flexible scalability for microgrids, enhance resilience and reduce operational costs during power outages. Specifically, the gated recurrent unit with a gating mechanism was introduced to extract features from temporal data, which enables the EMS to coordinate DERs more efficiently. Next, the proposed MADRL method incorporating action masking techniques was evaluated in the IEEE 33-Bus system using real-world data on renewable generation and power load. Finally, the numerical results demonstrated the superiority of the proposed method in reducing operating costs as well as the effectiveness in enhancing microgrid resilience during power interruptions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5fae\u7535\u7f51\u80fd\u91cf\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u95e8\u63a7\u5faa\u73af\u5355\u5143\u63d0\u53d6\u65f6\u5e8f\u7279\u5f81\uff0c\u7ed3\u5408\u52a8\u4f5c\u63a9\u7801\u6280\u672f\uff0c\u5728IEEE 33\u603b\u7ebf\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5728\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u548c\u589e\u5f3a\u7535\u7f51\u97e7\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u65e5\u76ca\u9891\u7e41\u5bfc\u81f4\u7535\u7f51\u4e2d\u65ad\uff0c\u73b0\u6709\u80fd\u91cf\u7ba1\u7406\u7cfb\u7edf\u5728\u5e94\u5bf9\u6781\u7aef\u5929\u6c14\u5e26\u6765\u7684\u8d1f\u8377\u9700\u6c42\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u5fae\u7535\u7f51\u63a7\u5236\u7b56\u7565\u6765\u589e\u5f3a\u97e7\u6027\u548c\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002", "method": "\u63d0\u51fa\u5408\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u95e8\u63a7\u5faa\u73af\u5355\u5143\u5904\u7406\u65f6\u5e8f\u6570\u636e\u7279\u5f81\uff0c\u91c7\u7528\u52a8\u4f5c\u63a9\u7801\u6280\u672f\uff0c\u5728IEEE 33\u603b\u7ebf\u7cfb\u7edf\u4e2d\u4f7f\u7528\u5b9e\u9645\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u548c\u8d1f\u8377\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u540c\u65f6\u5728\u7535\u529b\u4e2d\u65ad\u671f\u95f4\u6709\u6548\u589e\u5f3a\u4e86\u5fae\u7535\u7f51\u7684\u97e7\u6027\u3002", "conclusion": "\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u80fd\u91cf\u7ba1\u7406\u7cfb\u7edf\u80fd\u591f\u4e3a\u5fae\u7535\u7f51\u63d0\u4f9b\u7075\u6d3b\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728\u7535\u529b\u4e2d\u65ad\u671f\u95f4\u589e\u5f3a\u97e7\u6027\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\uff0c\u662f\u5e94\u5bf9\u6781\u7aef\u5929\u6c14\u6311\u6218\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11817", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11817", "abs": "https://arxiv.org/abs/2601.11817", "authors": ["Yumou Wei", "John Carney", "John Stamper", "Nancy Belmont"], "title": "From Defense to Advocacy: Empowering Users to Leverage the Blind Spot of AI Inference", "comment": null, "summary": "Most privacy regulations function as a passive defensive shield that users must wield themselves. Users are incessantly asked to \"opt-in\" or \"opt-out\" of data collection, forced to make defensive decisions whose consequences are increasingly difficult to predict. Viewed through the Johari Window, a psychological framework of self-awareness based on what is known and unknown to self and others, current policies require users to manage the Open Self and shield the Hidden Self through notice and consent. However, as organizations increasingly use AI to make inferences, the rapid expansion of Blind Self, attributes known to algorithms but unknown to the user, emerges as a critical challenge. We illustrate how current regulations fall short because they focus on data collection rather than inference and leave this blind spot unguarded. Building on the theory of Contextual Integrity, we propose a paradigm shift from defensive privacy management to proactive privacy advocacy. We argue for the necessity of personal advocacy agents capable of operationalizing social norms to harness the power of AI inference. By illuminating the hidden inferences that users can strategically leverage or suppress, these agents not only restrain the growth of Blind Self but also mine it for value. By transforming the Unknown Self into a personal asset for users, we can foster a flow of personal information that is equitable, transparent, and individually beneficial in the age of AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9690\u79c1\u7ba1\u7406\u5e94\u4ece\u88ab\u52a8\u9632\u5fa1\u8f6c\u5411\u4e3b\u52a8\u5021\u5bfc\uff0c\u5f15\u5165\u4e2a\u4eba\u5021\u5bfc\u4ee3\u7406\u6765\u5e94\u5bf9AI\u63a8\u65ad\u5e26\u6765\u7684\"\u76f2\u533a\u81ea\u6211\"\u6311\u6218\uff0c\u5229\u7528\u60c5\u5883\u5b8c\u6574\u6027\u7406\u8bba\u5b9e\u73b0\u516c\u5e73\u900f\u660e\u7684\u4e2a\u4eba\u4fe1\u606f\u6d41\u52a8\u3002", "motivation": "\u5f53\u524d\u9690\u79c1\u6cd5\u89c4\u4f5c\u4e3a\u88ab\u52a8\u9632\u5fa1\u5de5\u5177\uff0c\u8981\u6c42\u7528\u6237\u901a\u8fc7\"\u9009\u62e9\u52a0\u5165/\u9000\u51fa\"\u6765\u7ba1\u7406\u6570\u636e\u6536\u96c6\uff0c\u4f46\u65e0\u6cd5\u5e94\u5bf9AI\u63a8\u65ad\u6280\u672f\u5e26\u6765\u7684\"\u76f2\u533a\u81ea\u6211\"\uff08\u7b97\u6cd5\u77e5\u9053\u800c\u7528\u6237\u4e0d\u77e5\u9053\u7684\u4fe1\u606f\uff09\u6311\u6218\u3002\u73b0\u6709\u6cd5\u89c4\u5173\u6ce8\u6570\u636e\u6536\u96c6\u800c\u975e\u63a8\u65ad\uff0c\u7559\u4e0b\u4e86\u76d1\u7ba1\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e\u60c5\u5883\u5b8c\u6574\u6027\u7406\u8bba\uff0c\u63d0\u51fa\u4ece\u9632\u5fa1\u6027\u9690\u79c1\u7ba1\u7406\u5411\u4e3b\u52a8\u9690\u79c1\u5021\u5bfc\u7684\u8303\u5f0f\u8f6c\u53d8\u3002\u5efa\u8bae\u5f00\u53d1\u4e2a\u4eba\u5021\u5bfc\u4ee3\u7406\uff0c\u8fd9\u4e9b\u4ee3\u7406\u80fd\u591f\u64cd\u4f5c\u793e\u4f1a\u89c4\u8303\uff0c\u5229\u7528AI\u63a8\u65ad\u80fd\u529b\uff0c\u63ed\u793a\u9690\u85cf\u7684\u63a8\u65ad\u4fe1\u606f\u4f9b\u7528\u6237\u6218\u7565\u6027\u5730\u5229\u7528\u6216\u6291\u5236\u3002", "result": "\u901a\u8fc7\u4e2a\u4eba\u5021\u5bfc\u4ee3\u7406\uff0c\u4e0d\u4ec5\u80fd\u9650\u5236\"\u76f2\u533a\u81ea\u6211\"\u7684\u6269\u5f20\uff0c\u8fd8\u80fd\u4ece\u4e2d\u6316\u6398\u4ef7\u503c\u3002\u5c06\"\u672a\u77e5\u81ea\u6211\"\u8f6c\u5316\u4e3a\u4e2a\u4eba\u8d44\u4ea7\uff0c\u4fc3\u8fdb\u5728AI\u65f6\u4ee3\u5b9e\u73b0\u516c\u5e73\u3001\u900f\u660e\u4e14\u5bf9\u4e2a\u4eba\u6709\u76ca\u7684\u4fe1\u606f\u6d41\u52a8\u3002", "conclusion": "\u9700\u8981\u6839\u672c\u6027\u7684\u8303\u5f0f\u8f6c\u53d8\uff1a\u4ece\u88ab\u52a8\u9690\u79c1\u9632\u5fa1\u8f6c\u5411\u4e3b\u52a8\u9690\u79c1\u5021\u5bfc\u3002\u4e2a\u4eba\u5021\u5bfc\u4ee3\u7406\u80fd\u591f\u5229\u7528AI\u63a8\u65ad\u80fd\u529b\uff0c\u4fdd\u62a4\u7528\u6237\u514d\u53d7\"\u76f2\u533a\u81ea\u6211\"\u7684\u4fb5\u5bb3\uff0c\u540c\u65f6\u5c06\u63a8\u65ad\u4fe1\u606f\u8f6c\u5316\u4e3a\u4e2a\u4eba\u4f18\u52bf\uff0c\u5b9e\u73b0\u66f4\u516c\u5e73\u7684AI\u65f6\u4ee3\u9690\u79c1\u7ba1\u7406\u3002"}}
{"id": "2601.12400", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12400", "abs": "https://arxiv.org/abs/2601.12400", "authors": ["Laurent Condat", "Artavazd Maranjyan", "Peter Richt\u00e1rik"], "title": "BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training", "comment": null, "summary": "Slow and costly communication is often the main bottleneck in distributed optimization, especially in federated learning where it occurs over wireless networks. We introduce BiCoLoR, a communication-efficient optimization algorithm that combines two widely used and effective strategies: local training, which increases computation between communication rounds, and compression, which encodes high-dimensional vectors into short bitstreams. While these mechanisms have been combined before, compression has typically been applied only to uplink (client-to-server) communication, leaving the downlink (server-to-client) side unaddressed. In practice, however, both directions are costly. We propose BiCoLoR, the first algorithm to combine local training with bidirectional compression using arbitrary unbiased compressors. This joint design achieves accelerated complexity guarantees in both convex and strongly convex heterogeneous settings. Empirically, BiCoLoR outperforms existing algorithms and establishes a new standard in communication efficiency.", "AI": {"tldr": "BiCoLoR\u662f\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e86\u672c\u5730\u8bad\u7ec3\u548c\u53cc\u5411\u538b\u7f29\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u5206\u5e03\u5f0f\u4f18\u5316\uff08\u7279\u522b\u662f\u8054\u90a6\u5b66\u4e60\uff09\u4e2d\uff0c\u901a\u4fe1\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\u662f\u4e3b\u8981\u74f6\u9888\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u538b\u7f29\u4e0a\u884c\u94fe\u8def\uff08\u5ba2\u6237\u7aef\u5230\u670d\u52a1\u5668\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u4e0b\u884c\u94fe\u8def\uff08\u670d\u52a1\u5668\u5230\u5ba2\u6237\u7aef\uff09\u7684\u901a\u4fe1\u6210\u672c\uff0c\u4f46\u5b9e\u9645\u4e0a\u53cc\u5411\u901a\u4fe1\u90fd\u5f88\u6602\u8d35\u3002", "method": "\u63d0\u51faBiCoLoR\u7b97\u6cd5\uff0c\u9996\u6b21\u5c06\u672c\u5730\u8bad\u7ec3\u4e0e\u53cc\u5411\u538b\u7f29\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528\u4efb\u610f\u65e0\u504f\u538b\u7f29\u5668\u5bf9\u4e24\u4e2a\u65b9\u5411\u7684\u901a\u4fe1\u90fd\u8fdb\u884c\u538b\u7f29\uff0c\u5728\u51f8\u548c\u5f3a\u51f8\u5f02\u6784\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u52a0\u901f\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "result": "BiCoLoR\u5728\u7406\u8bba\u4e0a\u5b9e\u73b0\u4e86\u52a0\u901f\u590d\u6742\u5ea6\u4fdd\u8bc1\uff0c\u5728\u5b9e\u8bc1\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u5efa\u7acb\u4e86\u901a\u4fe1\u6548\u7387\u7684\u65b0\u6807\u51c6\u3002", "conclusion": "BiCoLoR\u901a\u8fc7\u7ed3\u5408\u672c\u5730\u8bad\u7ec3\u548c\u53cc\u5411\u538b\u7f29\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u4f18\u5316\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u901a\u4fe1\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.11776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11776", "abs": "https://arxiv.org/abs/2601.11776", "authors": ["Kaituo Zhang", "Zhimeng Jiang", "Na Zou"], "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models", "comment": null, "summary": "Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.", "AI": {"tldr": "\u63d0\u51fa\u5b8c\u5168\u81ea\u53cd\u601d\u7684LLM\u53bb\u6bd2\u6846\u67b6\uff0c\u5229\u7528LLM\u5185\u5728\u80fd\u529b\u68c0\u6d4b\u3001\u4fee\u6b63\u6bd2\u6027\u5185\u5bb9\u5e76\u7cbe\u70bc\u6a21\u578b\uff0c\u65e0\u9700\u5916\u90e8\u6a21\u5757\u6216\u6570\u636e\u6807\u6ce8\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u4fdd\u771f\u5ea6\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u53bb\u6bd2\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u53bb\u6bd2\u6280\u672f\u5f88\u5c11\u5229\u7528LLM\u5185\u7f6e\u7684\u81ea\u6821\u6b63\u548c\u81ea\u6211\u5956\u52b1\u80fd\u529b\uff0c\u800c\u662f\u4f9d\u8d56\u5916\u90e8\u6a21\u5757\u3001\u4eba\u5de5\u6570\u636e\u6807\u6ce8\u6216\u4eba\u5de5\u5e72\u9884\uff0c\u8fd9\u963b\u788d\u4e86\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u3002\u9700\u8981\u63a2\u7d22LLM\u5185\u5728\u7684\u81ea\u53bb\u6bd2\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5b8c\u5168\u81ea\u53cd\u601d\u53bb\u6bd2\u6846\u67b6\uff1a1) \u6bd2\u6027\u4fe1\u53f7\u68c0\u6d4b\u5668\u2014\u2014\u5185\u90e8\u81ea\u6211\u8bc6\u522b\u673a\u5236\uff1b2) \u7cfb\u7edf\u6027\u5e72\u9884\u8fc7\u7a0b\u5c06\u6bd2\u6027\u6587\u672c\u8f6c\u5316\u4e3a\u975e\u6bd2\u6027\u5bf9\u5e94\u6587\u672c\uff1b3) \u8fed\u4ee3\u8fc7\u7a0b\u751f\u6210\u5bf9\u6bd4\u53bb\u6bd2\u6570\u636e\u96c6\u7528\u4e8e\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728DetoxLLM\u548cParaDetox\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u83b7\u5f97\u66f4\u597d\u7684\u53bb\u6bd2\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6216\u5916\u90e8\u7ec4\u4ef6\uff0c\u5c55\u793a\u4e86LLM\u5185\u5728\u7684\u81ea\u53bb\u6bd2\u80fd\u529b\u3002", "conclusion": "\u63ed\u793a\u4e86LLM\u5185\u5728\u7684\u81ea\u53bb\u6bd2\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u81f4\u6709\u6548\u7684\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u7f13\u89e3\u65b9\u6cd5\uff0c\u4e3a\u771f\u6b63\u81ea\u8c03\u8282\u7684\u8bed\u8a00\u6a21\u578b\u94fa\u5e73\u9053\u8def\uff0c\u63a8\u52a8\u66f4\u8d1f\u8d23\u4efb\u548c\u4f26\u7406\u6307\u5bfc\u7684\u6587\u672c\u751f\u6210\u7cfb\u7edf\u3002"}}
{"id": "2601.11663", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11663", "abs": "https://arxiv.org/abs/2601.11663", "authors": ["Bruce Changlong Xu"], "title": "Activation Sensitivity as a Unifying Principle for Post-Training Quantization", "comment": null, "summary": "Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u540e\u8bad\u7ec3\u91cf\u5316\u7684\u4e0d\u540c\u65b9\u6cd5\uff08\u5982AWQ\u548cGPTQ\uff09\u89e3\u91ca\u4e3a\u5bf9\u6fc0\u6d3b\u654f\u611f\u6027\u7684\u4e0d\u540c\u8fd1\u4f3c\uff0c\u8be5\u654f\u611f\u6027\u5b9a\u4e49\u4e3a\u901a\u9053\u6270\u52a8\u5bf9\u635f\u5931\u7684\u671f\u671b\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff08\u5982AWQ\u548cGPTQ\uff09\u867d\u7136\u7ecf\u9a8c\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e0d\u6e05\u695a\u5b83\u4eec\u8fd1\u4f3c\u7684\u662f\u4ec0\u4e48\u5e95\u5c42\u91cf\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5728\u6982\u5ff5\u4e0a\u5206\u6563\uff0c\u9700\u8981\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7406\u89e3\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u4e00\u9636\u6cf0\u52d2\u5c55\u5f00\uff0c\u5c06\u6fc0\u6d3b\u654f\u611f\u6027\u5f62\u5f0f\u5316\u4e3a\u68af\u5ea6\u52a0\u6743\u6fc0\u6d3b\u7684\u5e73\u65b9\u8303\u6570\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u901a\u9053\u91cd\u8981\u6027\u5ea6\u91cf\u3002\u5728\u6b64\u6846\u67b6\u4e0b\uff0cAWQ\u548cGPTQ\u88ab\u89e3\u91ca\u4e3a\u5728\u4e0d\u540c\u7b80\u5316\u5047\u8bbe\u4e0b\u6062\u590d\u654f\u611f\u6027\u7684\u4e92\u8865\u8fd1\u4f3c\u3002", "result": "\u5efa\u7acb\u4e86\u6fc0\u6d3b\u654f\u611f\u6027\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86AWQ\u548cGPTQ\u65b9\u6cd5\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5206\u6790\u4e86\u654f\u611f\u6027\u5ea6\u91cf\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u8fde\u63a5\u4e86\u68af\u5ea6\u663e\u8457\u6027\u3001Fisher\u4fe1\u606f\u548cHessian\u51c6\u5219\uff0c\u5e76\u9610\u660e\u4e86\u5b83\u4eec\u4e0e\u7ecf\u5178\u526a\u679d\u65b9\u6cd5\u7684\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u4e3a\u7406\u89e3\u548c\u6bd4\u8f83\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\uff0c\u901a\u8fc7\u654f\u611f\u6027\u89c6\u89d2\u7edf\u4e00\u4e86\u4e0d\u540c\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f\u63d0\u51fa\u65b0\u7684\u91cf\u5316\u7b97\u6cd5\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u91cf\u5316\u65b9\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2601.11974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11974", "abs": "https://arxiv.org/abs/2601.11974", "authors": ["Xinmeng Hou", "Peiliang Gong", "Bohao Qu", "Wuqi Wang", "Qing Guo", "Yang Liu"], "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement", "comment": null, "summary": "While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.", "AI": {"tldr": "MARS\u6846\u67b6\u901a\u8fc7\u5355\u6b21\u5faa\u73af\u5b9e\u73b0LLM\u4ee3\u7406\u7684\u9ad8\u6548\u81ea\u6211\u8fdb\u5316\uff0c\u7ed3\u5408\u539f\u5219\u6027\u53cd\u601d\u548c\u7a0b\u5e8f\u6027\u53cd\u601d\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u4ee3\u7406\u53d7\u9650\u4e8e\u9759\u6001\u7684\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\uff0c\u7f3a\u4e4f\u9002\u5e94\u6027\u3002\u73b0\u6709\u7684\u81ea\u6211\u6539\u8fdb\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u4f4e\u6548\u7684\u591a\u8f6e\u9012\u5f52\u5faa\u73af\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u81ea\u6211\u8fdb\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMetacognitive Agent Reflective Self-improvement (MARS)\u6846\u67b6\uff0c\u5728\u5355\u6b21\u9012\u5f52\u5faa\u73af\u5185\u5b9e\u73b0\u9ad8\u6548\u81ea\u6211\u8fdb\u5316\u3002\u53d7\u6559\u80b2\u5fc3\u7406\u5b66\u542f\u53d1\uff0c\u7ed3\u5408\u539f\u5219\u6027\u53cd\u601d\uff08\u62bd\u8c61\u89c4\u8303\u89c4\u5219\u907f\u514d\u9519\u8bef\uff09\u548c\u7a0b\u5e8f\u6027\u53cd\u601d\uff08\u63a8\u5bfc\u6210\u529f\u9010\u6b65\u7b56\u7565\uff09\uff0c\u5c06\u6d1e\u5bdf\u5408\u6210\u4e3a\u4f18\u5316\u6307\u4ee4\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMARS\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u81ea\u6211\u8fdb\u5316\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "MARS\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86LLM\u4ee3\u7406\u7684\u9ad8\u6548\u81ea\u6211\u8fdb\u5316\uff0c\u4e3a\u6784\u5efa\u66f4\u81ea\u9002\u5e94\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u81ea\u4e3b\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.12687", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12687", "abs": "https://arxiv.org/abs/2601.12687", "authors": ["Manobendu Sarker", "Soumaya Cherkaoui"], "title": "Network Slicing Resource Management in Uplink User-Centric Cell-Free Massive MIMO Systems", "comment": "6 pages, Accepted in IEEE ICC 2026", "summary": "This paper addresses the joint optimization of per-user equipment (UE) bandwidth allocation and UE-access point (AP) association to maximize weighted sum-rate while satisfying heterogeneous quality-of-service (QoS) requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink of a network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) system. The formulated problem is NP-hard, rendering global optimality computationally intractable. To address this challenge, it is decomposed into two sub-problems, each solved by a computationally efficient heuristic scheme, and jointly optimized through an alternating optimization framework. We then propose (i) a bandwidth allocation scheme that balances UE priority, spectral efficiency, and minimum bandwidth demand under limited resources to ensure fair QoS distribution, and (ii) a priority-based UE-AP association assignment approach that balances UE service quality with system capacity constraints. Together, these approaches provide a practical and computationally efficient solution for resource-constrained network slicing scenarios, where QoS feasibility is often violated under dense deployments and limited bandwidth, necessitating graceful degradation and fair QoS preservation rather than solely maximizing the aggregate sum-rate. Simulation results demonstrate that the proposed scheme achieves up to 52% higher weighted sum-rate, 140% and 58% higher QoS success rates for eMBB and URLLC slices, respectively, while reducing runtime by up to 97% compared to considered benchmarks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7528\u6237\u4e2d\u5fc3\u5316\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u8054\u5408\u4f18\u5316\u5e26\u5bbd\u5206\u914d\u548c\u7528\u6237-\u63a5\u5165\u70b9\u5173\u8054\u7684\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u5316\u52a0\u6743\u548c\u901f\u7387\u5e76\u6ee1\u8db3eMBB\u548cURLLC\u5207\u7247\u7684\u5f02\u6784QoS\u9700\u6c42\u3002", "motivation": "\u7f51\u7edc\u5207\u7247\u573a\u666f\u4e0b\uff0c\u5bc6\u96c6\u90e8\u7f72\u548c\u6709\u9650\u5e26\u5bbd\u8d44\u6e90\u5e38\u5e38\u5bfc\u81f4QoS\u9700\u6c42\u65e0\u6cd5\u6ee1\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u60c5\u51b5\u4e0b\u4f18\u96c5\u964d\u7ea7\u5e76\u516c\u5e73\u4fdd\u969cQoS\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u4e0d\u662f\u5355\u7eaf\u8ffd\u6c42\u6700\u5927\u5316\u548c\u901f\u7387\u3002", "method": "\u5c06NP-hard\u7684\u539f\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff1a1\uff09\u8003\u8651\u7528\u6237\u4f18\u5148\u7ea7\u3001\u9891\u8c31\u6548\u7387\u548c\u6700\u5c0f\u5e26\u5bbd\u9700\u6c42\u7684\u5e26\u5bbd\u5206\u914d\u65b9\u6848\uff1b2\uff09\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u7528\u6237-\u63a5\u5165\u70b9\u5173\u8054\u5206\u914d\u65b9\u6cd5\u3002\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\uff0c\u6240\u63d0\u65b9\u6848\u5b9e\u73b0\u4e86\u9ad8\u8fbe52%\u7684\u52a0\u6743\u548c\u901f\u7387\u63d0\u5347\uff0ceMBB\u548cURLLC\u5207\u7247\u7684QoS\u6210\u529f\u7387\u5206\u522b\u63d0\u9ad8\u4e86140%\u548c58%\uff0c\u540c\u65f6\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u4e8697%\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u7f51\u7edc\u5207\u7247\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u5bc6\u96c6\u90e8\u7f72\u548c\u6709\u9650\u5e26\u5bbd\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4f18\u96c5\u964d\u7ea7\u548c\u516c\u5e73\u7684QoS\u4fdd\u969c\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42\u6700\u5927\u5316\u548c\u901f\u7387\u3002"}}
{"id": "2601.11916", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11916", "abs": "https://arxiv.org/abs/2601.11916", "authors": ["Jacob Charnock", "Alejandro Tlaie", "Kyle O'Brien", "Stephen Casper", "Aidan Homewood"], "title": "Expanding External Access To Frontier AI Models For Dangerous Capability Evaluations", "comment": "20 pages, 5 tables", "summary": "Frontier AI companies increasingly rely on external evaluations to assess risks from dangerous capabilities before deployment. However, external evaluators often receive limited model access, limited information, and little time, which can reduce evaluation rigour and confidence. The EU General-Purpose AI Code of Practice calls for \"appropriate access\", but does not specify what this means in practice. Furthermore, there is no common framework for describing different types and levels of evaluator access. To address this gap, we propose a taxonomy of access methods for dangerous capability evaluations. We disentangle three aspects of access: model access, model information, and evaluation timeframe. For each aspect, we review benefits and risks, including how expanding access can reduce false negatives and improve stakeholder trust, but can also increase security and capacity challenges. We argue that these limitations can likely be mitigated through technical means and safeguards used in other industries. Based on the taxonomy, we propose three descriptive access levels: AL1 (black-box model access and minimal information), AL2 (grey-box model access and substantial information), and AL3 (white-box model access and comprehensive information), to support clearer communication between evaluators, frontier AI companies, and policymakers. We believe these levels correspond to the different standards for appropriate access defined in the EU Code of Practice, though these standards may change over time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5371\u9669\u80fd\u529b\u8bc4\u4f30\u7684\u8bbf\u95ee\u65b9\u6cd5\u5206\u7c7b\u6cd5\uff0c\u5c06\u8bbf\u95ee\u5206\u4e3a\u6a21\u578b\u8bbf\u95ee\u3001\u6a21\u578b\u4fe1\u606f\u548c\u8bc4\u4f30\u65f6\u95f4\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e09\u4e2a\u63cf\u8ff0\u6027\u8bbf\u95ee\u7ea7\u522b\uff08AL1-AL3\uff09\u4ee5\u652f\u6301\u8bc4\u4f30\u8005\u3001\u524d\u6cbfAI\u516c\u53f8\u548c\u653f\u7b56\u5236\u5b9a\u8005\u4e4b\u95f4\u7684\u6e05\u6670\u6c9f\u901a\u3002", "motivation": "\u524d\u6cbfAI\u516c\u53f8\u8d8a\u6765\u8d8a\u4f9d\u8d56\u5916\u90e8\u8bc4\u4f30\u6765\u8bc4\u4f30\u90e8\u7f72\u524d\u7684\u5371\u9669\u80fd\u529b\u98ce\u9669\uff0c\u4f46\u5916\u90e8\u8bc4\u4f30\u8005\u901a\u5e38\u9762\u4e34\u6a21\u578b\u8bbf\u95ee\u53d7\u9650\u3001\u4fe1\u606f\u6709\u9650\u548c\u65f6\u95f4\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u964d\u4f4e\u8bc4\u4f30\u7684\u4e25\u8c28\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u6b27\u76df\u901a\u7528AI\u5b9e\u8df5\u51c6\u5219\u8981\u6c42\"\u9002\u5f53\u8bbf\u95ee\"\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u8df5\u6307\u5bfc\uff0c\u4e5f\u6ca1\u6709\u63cf\u8ff0\u8bc4\u4f30\u8005\u8bbf\u95ee\u7c7b\u578b\u548c\u7ea7\u522b\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8bbf\u95ee\u65b9\u6cd5\u5206\u7c7b\u6cd5\uff0c\u5c06\u8bbf\u95ee\u5206\u89e3\u4e3a\u4e09\u4e2a\u7ef4\u5ea6\uff1a\u6a21\u578b\u8bbf\u95ee\u3001\u6a21\u578b\u4fe1\u606f\u548c\u8bc4\u4f30\u65f6\u95f4\u6846\u67b6\u3002\u5bf9\u6bcf\u4e2a\u7ef4\u5ea6\u5206\u6790\u5176\u76ca\u5904\u548c\u98ce\u9669\uff0c\u5e76\u57fa\u4e8e\u6b64\u5206\u7c7b\u6cd5\u63d0\u51fa\u4e09\u4e2a\u63cf\u8ff0\u6027\u8bbf\u95ee\u7ea7\u522b\uff1aAL1\uff08\u9ed1\u76d2\u6a21\u578b\u8bbf\u95ee\u548c\u6700\u5c11\u4fe1\u606f\uff09\u3001AL2\uff08\u7070\u76d2\u6a21\u578b\u8bbf\u95ee\u548c\u5b9e\u8d28\u6027\u4fe1\u606f\uff09\u3001AL3\uff08\u767d\u76d2\u6a21\u578b\u8bbf\u95ee\u548c\u5168\u9762\u4fe1\u606f\uff09\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u8bbf\u95ee\u5206\u7c7b\u6846\u67b6\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u8bbf\u95ee\u7ea7\u522b\u7684\u7279\u5f81\uff0c\u652f\u6301\u8bc4\u4f30\u8005\u3001AI\u516c\u53f8\u548c\u653f\u7b56\u5236\u5b9a\u8005\u4e4b\u95f4\u66f4\u6e05\u6670\u7684\u6c9f\u901a\u3002\u8be5\u6846\u67b6\u4e0e\u6b27\u76dfAI\u5b9e\u8df5\u51c6\u5219\u4e2d\u7684\"\u9002\u5f53\u8bbf\u95ee\"\u6807\u51c6\u76f8\u5bf9\u5e94\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u6807\u51c6\u53ef\u80fd\u968f\u65f6\u95f4\u53d8\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bbf\u95ee\u5206\u7c7b\u6cd5\u548c\u4e09\u4e2a\u8bbf\u95ee\u7ea7\u522b\u4e3a\u89e3\u51b3AI\u5371\u9669\u80fd\u529b\u8bc4\u4f30\u4e2d\u7684\u8bbf\u95ee\u9650\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8bc4\u4f30\u7684\u4e25\u8c28\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u548c\u5b89\u5168\u63aa\u65bd\u53ef\u4ee5\u7f13\u89e3\u6269\u5c55\u8bbf\u95ee\u5e26\u6765\u7684\u5b89\u5168\u548c\u5bb9\u91cf\u6311\u6218\u3002"}}
{"id": "2601.12380", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12380", "abs": "https://arxiv.org/abs/2601.12380", "authors": ["Ou Deng", "Shoji Nishimura", "Atsushi Ogihara", "Qun Jin"], "title": "Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation", "comment": null, "summary": "Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\\{\u03bb_h\\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.", "AI": {"tldr": "SNI\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u6df7\u5408\u7c7b\u578b\u6570\u636e\u63d2\u8865\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u63a7\u5148\u9a8c\u7279\u5f81\u6ce8\u610f\u529b\u6a21\u5757\u7ed3\u5408\u7edf\u8ba1\u5148\u9a8c\u548c\u795e\u7ecf\u7279\u5f81\u6ce8\u610f\u529b\uff0c\u63d0\u4f9b\u5185\u5728\u7684\u4f9d\u8d56\u5173\u7cfb\u8bca\u65ad\u548c\u7edf\u8ba1-\u795e\u7ecf\u6743\u8861\u53c2\u6570\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u6570\u636e\u5e93\u901a\u5e38\u5305\u542b\u8fde\u7eed\u6d4b\u91cf\u503c\u548c\u5206\u7c7b\u8bb0\u5f55\uff0c\u4f46\u7f3a\u5931\u6761\u76ee\u666e\u904d\u5b58\u5728\u4e14\u4f1a\u626d\u66f2\u4e0b\u6e38\u5206\u6790\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u8981\u4e48\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6df7\u5408\u6570\u636e\u7c7b\u578b\u3002", "method": "\u63d0\u51fa\u7edf\u8ba1-\u795e\u7ecf\u4ea4\u4e92\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u63a7\u5148\u9a8c\u7279\u5f81\u6ce8\u610f\u529b\u6a21\u5757\u8026\u5408\u76f8\u5173\u6027\u5bfc\u51fa\u7684\u7edf\u8ba1\u5148\u9a8c\u4e0e\u795e\u7ecf\u7279\u5f81\u6ce8\u610f\u529b\uff0c\u5b66\u4e60\u5934\u7ea7\u5148\u9a8c\u5f3a\u5ea6\u7cfb\u6570\uff0c\u8f6f\u6027\u6b63\u5219\u5316\u6ce8\u610f\u529b\u671d\u5411\u5148\u9a8c\uff0c\u540c\u65f6\u5141\u8bb8\u6570\u636e\u9a71\u52a8\u7684\u504f\u5dee\u3002", "result": "\u57286\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e6\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff0c\u572830%MCAR/strict-MAR\u7f3a\u5931\u4e0b\uff0cSNI\u5728\u8fde\u7eed\u53d8\u91cf\u6307\u6807\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4f46\u5728\u5206\u7c7b\u53d8\u91cf\u4e0a\u5e38\u88ab\u51c6\u786e\u7387\u4f18\u5148\u7684\u57fa\u7ebf\u65b9\u6cd5\u8d85\u8d8a\uff1b\u63d0\u4f9b\u5185\u5728\u4f9d\u8d56\u5173\u7cfb\u8bca\u65ad\u548c\u660e\u786e\u7684\u7edf\u8ba1-\u795e\u7ecf\u6743\u8861\u53c2\u6570\u3002", "conclusion": "SNI\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u63d0\u4f9b\u6743\u8861\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u4f9d\u8d56\u5173\u7cfb\u8bca\u65ad\u548c\u660e\u786e\u6743\u8861\u53c2\u6570\u7684\u90e8\u7f72\u573a\u666f\uff0c\u4f46\u5728\u4e25\u91cd\u4e0d\u5e73\u8861\u5206\u7c7b\u76ee\u6807\u4e0a\u5b58\u5728\u5c40\u9650\u6027\u3002"}}
{"id": "2601.12411", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12411", "abs": "https://arxiv.org/abs/2601.12411", "authors": ["Saeed Sadeghi Arjmand"], "title": "Dynamic resource allocation in eukaryotic Resource Balance Analysis", "comment": null, "summary": "Resource Balance Analysis (RBA) is a framework for predicting steady-state cellular growth under resource constraints. However, classical RBA formulations are static and do not capture the dynamic regulation of biosynthetic resources or macromolecular turnover, which is particularly important in eukaryotic cells. In this work, we propose a dynamic extension of eukaryotic RBA based on an optimal control formulation. Cellular growth is modeled as the result of a time-dependent allocation of translational capacity between metabolic enzymes and macromolecular machinery, aimed at maximizing biomass accumulation over a finite time horizon. Using Pontryagin's Maximum Principle, we characterize optimal allocation strategies and show that steady-state RBA solutions arise as limiting regimes of the dynamic problem.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7684\u52a8\u6001\u771f\u6838\u7ec6\u80de\u8d44\u6e90\u5e73\u8861\u5206\u6790\u6846\u67b6\uff0c\u5c06\u7ec6\u80de\u751f\u957f\u5efa\u6a21\u4e3a\u7ffb\u8bd1\u80fd\u529b\u5728\u4ee3\u8c22\u9176\u548c\u751f\u7269\u5927\u5206\u5b50\u673a\u5668\u4e4b\u95f4\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u5206\u914d\u95ee\u9898", "motivation": "\u7ecf\u5178RBA\u6846\u67b6\u662f\u9759\u6001\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u751f\u7269\u5408\u6210\u8d44\u6e90\u7684\u52a8\u6001\u8c03\u63a7\u548c\u5927\u5206\u5b50\u5468\u8f6c\uff0c\u8fd9\u5728\u771f\u6838\u7ec6\u80de\u4e2d\u5c24\u4e3a\u91cd\u8981", "method": "\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7406\u8bba\u63d0\u51fa\u52a8\u6001\u771f\u6838RBA\u6269\u5c55\uff0c\u5c06\u7ec6\u80de\u751f\u957f\u5efa\u6a21\u4e3a\u5728\u6709\u9650\u65f6\u95f4\u8303\u56f4\u5185\u6700\u5927\u5316\u751f\u7269\u8d28\u79ef\u7d2f\u7684\u7ffb\u8bd1\u80fd\u529b\u5206\u914d\u95ee\u9898\uff0c\u4f7f\u7528\u5e9e\u7279\u91cc\u4e9a\u91d1\u6781\u5927\u503c\u539f\u7406\u5206\u6790\u6700\u4f18\u5206\u914d\u7b56\u7565", "result": "\u8868\u5f81\u4e86\u6700\u4f18\u5206\u914d\u7b56\u7565\uff0c\u5e76\u8bc1\u660e\u7a33\u6001RBA\u89e3\u662f\u52a8\u6001\u95ee\u9898\u7684\u6781\u9650\u60c5\u51b5", "conclusion": "\u52a8\u6001RBA\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u771f\u6838\u7ec6\u80de\u7684\u8d44\u6e90\u8c03\u63a7\u673a\u5236\uff0c\u7a33\u6001RBA\u662f\u5176\u7279\u4f8b\uff0c\u4e3a\u7ec6\u80de\u751f\u957f\u8c03\u63a7\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u8bba\u6846\u67b6"}}
{"id": "2601.11778", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11778", "abs": "https://arxiv.org/abs/2601.11778", "authors": ["Sheriff Issaka", "Erick Rosas Gonzalez", "Lieqi Liu", "Evans Kofi Agyei", "Lucas Bandarkar", "Nanyun Peng", "David Ifeoluwa Adelani", "Francisco Guzm\u00e1n", "Saadia Gabriel"], "title": "Translation as a Scalable Proxy for Multilingual Evaluation", "comment": null, "summary": "The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.", "AI": {"tldr": "\u7ffb\u8bd1\u8d28\u91cf\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u80fd\u529b\u7684\u6709\u6548\u4ee3\u7406\u6307\u6807\uff0c\u7b80\u5316\u591a\u8bed\u8a00\u8bc4\u4f30\u6d41\u7a0b", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u58f0\u79f0\u5177\u5907\u591a\u8bed\u8a00\u80fd\u529b\uff0c\u4f46\u9488\u5bf9\u5168\u74037000\u591a\u79cd\u8bed\u8a00\u4e2d\u8d85\u8fc798%\u7684\u8bed\u8a00\u7f3a\u4e4f\u975e\u673a\u5668\u7ffb\u8bd1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f20\u7edf\u57fa\u51c6\u6784\u5efa\u9762\u4e34\u6210\u672c\u9ad8\u3001\u4e13\u5bb6\u7a00\u7f3a\u548c\u6570\u636e\u6c61\u67d3\u7b49\u6311\u6218", "method": "\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f3014\u4e2a\u6a21\u578b\uff081B-72B\u53c2\u6570\uff09\u57289\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u548c7\u4e2a\u7ffb\u8bd1\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u68c0\u9a8c\u7ffb\u8bd1\u8d28\u91cf\u662f\u5426\u80fd\u6307\u793a\u6a21\u578b\u7684\u591a\u8bed\u8a00\u4e0b\u6e38\u4efb\u52a1\u80fd\u529b", "result": "\u7ffb\u8bd1\u6027\u80fd\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6210\u529f\u5448\u5f3a\u76f8\u5173\uff08\u5982Phi-4\u6a21\u578b\u7684\u4e2d\u4f4d\u6570\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\uff1aMetricX=0.89\uff0cxCOMET=0.91\uff0cSSA-COMET=0.87\uff09\uff0c\u8868\u660e\u652f\u6301\u5fe0\u5b9e\u7ffb\u8bd1\u7684\u8868\u5f81\u80fd\u529b\u4e0e\u591a\u8bed\u8a00\u7406\u89e3\u6240\u9700\u80fd\u529b\u9ad8\u5ea6\u91cd\u53e0", "conclusion": "\u7ffb\u8bd1\u8d28\u91cf\u53ef\u4f5c\u4e3a\u5f3a\u5927\u4e14\u5ec9\u4ef7\u7684\u591a\u8bed\u8a00\u6027\u80fd\u521d\u6b65\u4ee3\u7406\u6307\u6807\uff0c\u5b9e\u73b0\"\u7ffb\u8bd1\u4f18\u5148\u7b5b\u9009+\u7279\u5b9a\u4efb\u52a1\u9488\u5bf9\u6027\u8ddf\u8fdb\"\u7684\u8bc4\u4f30\u7b56\u7565\uff0c\u7b80\u5316\u591a\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6d41\u7a0b"}}
{"id": "2601.11667", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11667", "abs": "https://arxiv.org/abs/2601.11667", "authors": ["Xiaojie Xia", "Huigang Zhang", "Chaoliang Zhong", "Jun Sun", "Yusuke Oishi"], "title": "Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction", "comment": null, "summary": "Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5757\u7ea7\u5c40\u90e8\u84b8\u998f\u548c\u8d2a\u5fc3\u5c42\u66ff\u6362\u7b56\u7565\uff0c\u5c06\u9884\u8bad\u7ec3\u5168\u6ce8\u610f\u529b\u6a21\u578b\u8f6c\u6362\u4e3a\u4efb\u52a1\u7279\u5b9a\u7684\u6df7\u5408\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd", "motivation": "\u5168\u6ce8\u610f\u529bTransformer\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u7ebf\u6027\u6ce8\u610f\u529b\u6548\u7387\u9ad8\u4f46\u6027\u80fd\u4e0b\u964d\uff0c\u6df7\u5408\u6a21\u578b\u9700\u8981\u6602\u8d35\u8bad\u7ec3\u548c\u590d\u6742\u8bbe\u8ba1\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u8f6c\u6362\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5", "method": "1) \u901a\u8fc7\u5757\u7ea7\u5c40\u90e8\u84b8\u998f\u5c06\u9884\u8bad\u7ec3\u5168\u6ce8\u610f\u529b\u6743\u91cd\u8fc1\u79fb\u5230\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\uff1b2) \u8d2a\u5fc3\u5c42\u66ff\u6362\u7b56\u7565\u8fed\u4ee3\u66ff\u6362\u5168\u6ce8\u610f\u529b\u5757\u4e3a\u7ebf\u6027\u5757\uff0c\u540c\u65f6\u76d1\u63a7\u9a8c\u8bc1\u6027\u80fd", "result": "\u8be5\u65b9\u6cd5\u80fd\u5728\u5355\u6b21\u9ad8\u6548\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u4efb\u52a1\u7279\u5b9a\u7684\u6df7\u5408\u6a21\u578b\uff0c\u65e0\u9700\u6602\u8d35\u91cd\u65b0\u8bad\u7ec3\u6216\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u9884\u8bad\u7ec3\u5168\u6ce8\u610f\u529b\u9aa8\u5e72\u548c\u4e0b\u6e38\u4efb\u52a1", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u6ce8\u610f\u529b\u6a21\u578b\u8bad\u7ec3\u6602\u8d35\u548c\u8bbe\u8ba1\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861"}}
{"id": "2601.11979", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11979", "abs": "https://arxiv.org/abs/2601.11979", "authors": ["Ang Gao", "Changshuo Zhang", "Xiao Zhang", "Deyang Li", "Minjun Zhao", "Fangchao Liu", "Xinyu Zhang"], "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion", "comment": null, "summary": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.", "AI": {"tldr": "\u63d0\u51faProcess In-Context Learning (PICL)\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u63d2\u5165\u76f8\u5173\u6f14\u793a\u6765\u5e94\u5bf9\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u5b9e\u65f6\u56f0\u60d1\u70b9\uff0c\u63d0\u5347\u591a\u6b65\u903b\u8f91\u63a8\u7406\u6027\u80fd", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u9759\u6001\u6f14\u793a\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u6b65\u63a8\u7406\u4e2d\u52a8\u6001\u51fa\u73b0\u7684\u56f0\u60d1\u70b9\uff08\u5982\u6a21\u7cca\u8ba1\u7b97\u3001\u903b\u8f91\u6f0f\u6d1e\uff09\uff0c\u8fd9\u4e9b\u672a\u89e3\u51b3\u7684\u56f0\u60d1\u4f1a\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\uff0c\u964d\u4f4e\u6700\u7ec8\u51c6\u786e\u6027", "method": "PICL\u6846\u67b6\u5206\u4e24\u9636\u6bb5\uff1a1) \u901a\u8fc7\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u548c\u71b5\u6765\u8bc6\u522b\u6f5c\u5728\u56f0\u60d1\u70b9\u5e76\u603b\u7ed3\u6838\u5fc3\u7279\u5f81\uff1b2) \u9047\u5230\u56f0\u60d1\u70b9\u65f6\u4ece\u6f14\u793a\u6c60\u68c0\u7d22\u5339\u914d\u56f0\u60d1\u4e0a\u4e0b\u6587\u7684\u6f14\u793a\uff0c\u76f4\u63a5\u63d2\u5165\u5230\u6b63\u5728\u8fdb\u884c\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6307\u5bfc\u540e\u7eed\u6b65\u9aa4", "result": "\u5b9e\u9a8c\u8868\u660ePICL\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u8f7b\u63a8\u7406\u4e2d\u7684\u56f0\u60d1\uff0c\u7a81\u663e\u4e86\u81ea\u9002\u5e94\u6f14\u793a\u63d2\u5165\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u4ef7\u503c", "conclusion": "PICL\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u54cd\u5e94\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u65f6\u9700\u6c42\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u9700\u8981\u9010\u6b65\u903b\u8f91\u63a8\u7406\u4efb\u52a1\uff08\u5982\u6570\u5b66\u63a8\u7406\uff09\u4e2d\u7684\u6027\u80fd"}}
{"id": "2601.12689", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12689", "abs": "https://arxiv.org/abs/2601.12689", "authors": ["Manobendu Sarker", "Soumaya Cherkaoui"], "title": "Priority-Based Bandwidth Allocation in Network Slicing-Enabled Cell-Free Massive MIMO Systems", "comment": "6 Pages, Accepted in IEEE ICC 2026", "summary": "This paper addresses joint admission control and per-user equipment (UE) bandwidth allocation to maximize weighted sum-rate in network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) systems when aggregate quality-of-service (QoS) demand may exceed available bandwidth. Specifically, we optimize bandwidth allocation while satisfying heterogeneous QoS requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink. The formulated problem is NP-hard, rendering global optimality computationally intractable. We decompose it into two sub-problems and solve them via computationally efficient heuristics within a sequential framework. We propose (i) a hierarchical admission control scheme that selectively admits UEs under bandwidth scarcity, prioritizing URLLC to ensure latency-sensitive QoS compliance, and (ii) an iterative gradient-based bandwidth allocation scheme that transfers bandwidth across slices guided by marginal utility and reallocates resources within slices. Simulation results demonstrate that the proposed scheme achieves near-optimal performance, deviating from a CVX-based benchmark by at most 2.2% in weighted sum-rate while reducing runtime by 99.7%, thereby enabling practical real-time deployment. Compared to a baseline round-robin scheme without admission control, the proposed approach achieves up to 1085% and 7% higher success rates for eMBB and URLLC slices, respectively, by intentionally sacrificing sum-rate to guarantee QoS. Sensitivity analysis further reveals that the proposed solution adapts effectively to diverse eMBB/URLLC traffic compositions, maintaining 47-51% eMBB and 93-94% URLLC success rates across varying load scenarios, confirming its robustness for resource-constrained large-scale deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u7f51\u7edc\u5207\u7247\u7528\u6237\u4e2d\u5fc3\u5316\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u8054\u5408\u51c6\u5165\u63a7\u5236\u548c\u5e26\u5bbd\u5206\u914d\u7684\u4f18\u5316\u65b9\u6848\uff0c\u4ee5\u6700\u5927\u5316\u52a0\u6743\u548c\u901f\u7387\u5e76\u6ee1\u8db3eMBB\u548cURLLC\u5207\u7247\u7684\u5f02\u6784QoS\u9700\u6c42\u3002", "motivation": "\u5f53\u7f51\u7edc\u5207\u7247\u7528\u6237\u4e2d\u5fc3\u5316\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u7684\u603bQoS\u9700\u6c42\u53ef\u80fd\u8d85\u8fc7\u53ef\u7528\u5e26\u5bbd\u65f6\uff0c\u9700\u8981\u89e3\u51b3\u8054\u5408\u51c6\u5165\u63a7\u5236\u548c\u5e26\u5bbd\u5206\u914d\u95ee\u9898\uff0c\u4ee5\u6700\u5927\u5316\u52a0\u6743\u548c\u901f\u7387\u5e76\u6ee1\u8db3eMBB\u548cURLLC\u5207\u7247\u7684\u5f02\u6784QoS\u9700\u6c42\u3002", "method": "\u5c06NP-hard\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u91c7\u7528\u987a\u5e8f\u6846\u67b6\u4e0b\u7684\u8ba1\u7b97\u9ad8\u6548\u542f\u53d1\u5f0f\u7b97\u6cd5\uff1a1) \u5206\u5c42\u51c6\u5165\u63a7\u5236\u65b9\u6848\uff0c\u5728\u5e26\u5bbd\u7a00\u7f3a\u65f6\u9009\u62e9\u6027\u63a5\u7eb3UE\uff0c\u4f18\u5148\u4fdd\u969cURLLC\u7684\u65f6\u5ef6\u654f\u611fQoS\uff1b2) \u8fed\u4ee3\u68af\u5ea6\u5e26\u5bbd\u5206\u914d\u65b9\u6848\uff0c\u57fa\u4e8e\u8fb9\u9645\u6548\u7528\u5728\u5207\u7247\u95f4\u8f6c\u79fb\u5e26\u5bbd\uff0c\u5e76\u5728\u5207\u7247\u5185\u91cd\u65b0\u5206\u914d\u8d44\u6e90\u3002", "result": "\u6240\u63d0\u65b9\u6848\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u4e0eCVX\u57fa\u51c6\u76f8\u6bd4\u52a0\u6743\u548c\u901f\u7387\u504f\u5dee\u6700\u591a2.2%\uff0c\u540c\u65f6\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1199.7%\u3002\u76f8\u6bd4\u65e0\u51c6\u5165\u63a7\u5236\u7684\u8f6e\u8be2\u57fa\u7ebf\uff0ceMBB\u548cURLLC\u5207\u7247\u6210\u529f\u7387\u5206\u522b\u63d0\u9ad81085%\u548c7%\u3002\u654f\u611f\u6027\u5206\u6790\u663e\u793a\u65b9\u6848\u80fd\u6709\u6548\u9002\u5e94\u4e0d\u540ceMBB/URLLC\u6d41\u91cf\u7ec4\u5408\uff0c\u4fdd\u630147-51% eMBB\u548c93-94% URLLC\u6210\u529f\u7387\u3002", "conclusion": "\u8be5\u65b9\u6848\u901a\u8fc7\u5206\u5c42\u51c6\u5165\u63a7\u5236\u548c\u8fed\u4ee3\u68af\u5ea6\u5e26\u5bbd\u5206\u914d\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u573a\u666f\u4e0b\u6709\u6548\u5e73\u8861\u4e86\u52a0\u6743\u548c\u901f\u7387\u4e0eQoS\u4fdd\u969c\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u548c\u5927\u5e45\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u9002\u5408\u5927\u89c4\u6a21\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2601.12164", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12164", "abs": "https://arxiv.org/abs/2601.12164", "authors": ["Oleg Smirnov"], "title": "The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as analytical tools across multilingual contexts, yet their outputs may carry systematic biases conditioned by the language of the prompt. This study presents an experimental comparison of LLM-generated political analyses of a Ukrainian civil society document, using semantically equivalent prompts in Russian and Ukrainian. Despite identical source material and parallel query structures, the resulting analyses varied substantially in rhetorical positioning, ideological orientation, and interpretive conclusions. The Russian-language output echoed narratives common in Russian state discourse, characterizing civil society actors as illegitimate elites undermining democratic mandates. The Ukrainian-language output adopted vocabulary characteristic of Western liberal-democratic political science, treating the same actors as legitimate stakeholders within democratic contestation. These findings demonstrate that prompt language alone can produce systematically different ideological orientations from identical models analyzing identical content, with significant implications for AI deployment in polarized information environments, cross-lingual research applications, and the governance of AI systems in multilingual societies.", "AI": {"tldr": "LLM\u751f\u6210\u7684\u653f\u6cbb\u5206\u6790\u4f1a\u56e0\u63d0\u793a\u8bed\u8a00\u4e0d\u540c\u800c\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u89c1\uff1a\u4fc4\u8bed\u8f93\u51fa\u53cd\u6620\u4fc4\u7f57\u65af\u56fd\u5bb6\u8bdd\u8bed\uff0c\u4e4c\u514b\u5170\u8bed\u8f93\u51fa\u5219\u4f53\u73b0\u897f\u65b9\u81ea\u7531\u4e3b\u4e49\u6c11\u4e3b\u89c2\u70b9", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76LLM\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u4f7f\u7528\u65f6\uff0c\u5176\u8f93\u51fa\u662f\u5426\u4f1a\u56e0\u63d0\u793a\u8bed\u8a00\u800c\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u653f\u6cbb\u5206\u6790\u8fd9\u79cd\u654f\u611f\u9886\u57df", "method": "\u5b9e\u9a8c\u65b9\u6cd5\uff1a\u4f7f\u7528\u8bed\u4e49\u76f8\u540c\u7684\u4fc4\u8bed\u548c\u4e4c\u514b\u5170\u8bed\u63d0\u793a\uff0c\u8ba9LLM\u5206\u6790\u540c\u4e00\u4efd\u4e4c\u514b\u5170\u516c\u6c11\u793e\u4f1a\u6587\u4ef6\uff0c\u6bd4\u8f83\u4e24\u79cd\u8bed\u8a00\u8f93\u51fa\u7684\u5dee\u5f02", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u5c3d\u7ba1\u6e90\u6750\u6599\u548c\u67e5\u8be2\u7ed3\u6784\u5b8c\u5168\u76f8\u540c\uff0c\u4f46\u4fc4\u8bed\u8f93\u51fa\u4e0e\u4e4c\u514b\u5170\u8bed\u8f93\u51fa\u5728\u4fee\u8f9e\u5b9a\u4f4d\u3001\u610f\u8bc6\u5f62\u6001\u53d6\u5411\u548c\u89e3\u91ca\u7ed3\u8bba\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4fc4\u8bed\u8f93\u51fa\u547c\u5e94\u4fc4\u7f57\u65af\u56fd\u5bb6\u8bdd\u8bed\uff0c\u5c06\u516c\u6c11\u793e\u4f1a\u884c\u4e3a\u4f53\u63cf\u8ff0\u4e3a\u7834\u574f\u6c11\u4e3b\u6388\u6743\u7684\u975e\u6cd5\u7cbe\u82f1\uff1b\u800c\u4e4c\u514b\u5170\u8bed\u8f93\u51fa\u91c7\u7528\u897f\u65b9\u81ea\u7531\u6c11\u4e3b\u653f\u6cbb\u5b66\u8bcd\u6c47\uff0c\u5c06\u540c\u4e00\u884c\u4e3a\u4f53\u89c6\u4e3a\u6c11\u4e3b\u7ade\u4e89\u4e2d\u7684\u5408\u6cd5\u5229\u76ca\u76f8\u5173\u8005", "conclusion": "\u7ed3\u8bba\uff1a\u4ec5\u63d0\u793a\u8bed\u8a00\u5c31\u80fd\u4f7f\u540c\u4e00\u6a21\u578b\u5206\u6790\u76f8\u540c\u5185\u5bb9\u65f6\u4ea7\u751f\u7cfb\u7edf\u6027\u4e0d\u540c\u7684\u610f\u8bc6\u5f62\u6001\u53d6\u5411\uff0c\u8fd9\u5bf9AI\u5728\u6781\u5316\u4fe1\u606f\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3001\u8de8\u8bed\u8a00\u7814\u7a76\u5e94\u7528\u4ee5\u53ca\u591a\u8bed\u8a00\u793e\u4f1a\u4e2d\u7684AI\u7cfb\u7edf\u6cbb\u7406\u5177\u6709\u91cd\u8981\u5f71\u54cd"}}
{"id": "2601.12518", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12518", "abs": "https://arxiv.org/abs/2601.12518", "authors": ["Nuoya Xiong", "Aarti Singh"], "title": "Cooperative Multi-agent RL with Communication Constraints", "comment": "33 pages", "summary": "Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\\varepsilon$-Nash equilibrium in potential games with only $O(\\varepsilon^{-3/4})$ communication rounds and $O(poly(\\max_i |A_i|)\\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\uff0c\u901a\u8fc7\u5229\u7528\u65e7\u68af\u5ea6\u9884\u6d4b\u7b56\u7565\u66f4\u65b0\uff0c\u5728\u6709\u9650\u901a\u4fe1\u4e0b\u51cf\u5c11\u57fa\u7b56\u7565\u4e0e\u5f53\u524d\u7b56\u7565\u7684\u5dee\u8ddd\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u8f6e\u6570\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u5047\u8bbe\u80fd\u9891\u7e41\u8bbf\u95ee\u5168\u5c40\u4fe1\u606f\uff08\u5982\u56e2\u961f\u5956\u52b1\u3001\u5176\u4ed6\u667a\u80fd\u4f53\u52a8\u4f5c\uff09\uff0c\u4f46\u5728\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\u9ad8\u901a\u4fe1\u6210\u672c\u4f7f\u8fd9\u4e0d\u53ef\u884c\u3002\u5f53\u901a\u4fe1\u53d7\u9650\u65f6\uff0c\u667a\u80fd\u4f53\u53ea\u80fd\u4f9d\u8d56\u8fc7\u65f6\u4fe1\u606f\u4f30\u8ba1\u68af\u5ea6\u548c\u66f4\u65b0\u7b56\u7565\uff0c\u800c\u5e38\u7528\u7684\u91cd\u8981\u6027\u91c7\u6837\u65b9\u6cd5\u5728\u901a\u4fe1\u53d7\u9650\uff08\u7f3a\u5931\u6570\u636e\u6982\u7387\u9ad8\uff09\u65f6\u53d8\u5f97\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\uff0c\u5229\u7528\u65e7\u68af\u5ea6\u9884\u6d4b\u7b56\u7565\u66f4\u65b0\uff0c\u5e76\u4e3a\u4e00\u7cfb\u5217\u57fa\u7b56\u7565\u6536\u96c6\u6837\u672c\uff0c\u4ece\u800c\u51cf\u5c11\u57fa\u7b56\u7565\u4e0e\u5f53\u524d\u7b56\u7565\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u5728\u4e00\u6b21\u901a\u4fe1\u8f6e\u6b21\u5185\u6536\u96c6\u9884\u6d4b\u57fa\u7b56\u7565\u7684\u6837\u672c\uff0c\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u8f6e\u6570\u9700\u6c42\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u7b97\u6cd5\u5728\u52bf\u535a\u5f08\u4e2d\u80fd\u4ee5O(\u03b5^{-3/4})\u901a\u4fe1\u8f6e\u6570\u548cO(poly(max_i |A_i|)\u03b5^{-11/4})\u6837\u672c\u6570\u6536\u655b\u5230\u03b5-\u7eb3\u4ec0\u5747\u8861\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u6700\u4f18\u7ed3\u679c\u3002\u5728\u4e00\u822c\u9a6c\u5c14\u53ef\u592b\u5408\u4f5c\u535a\u5f08\u4e2d\u4e5f\u80fd\u627e\u5230\u667a\u80fd\u4f53\u5c42\u9762\u7684\u5c40\u90e8\u6700\u4f18\u89e3\u3002\u5b9e\u9a8c\u5728\u6a21\u62df\u6e38\u620f\u548cMAPPO\u590d\u6742\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u7b56\u7565\u9884\u6d4b\u6280\u672f\u80fd\u6709\u6548\u89e3\u51b3\u6709\u9650\u901a\u4fe1\u4e0b\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u548c\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u7684\u6307\u6570\u7ea7\u4f9d\u8d56\uff0c\u4e3a\u5b9e\u9645\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12738", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.12738", "abs": "https://arxiv.org/abs/2601.12738", "authors": ["Ba Khiet Le", "Zakaria Mazgouri", "Michel Th\u00e9ra"], "title": "Monotonicity of Pairs of Operators and Generalized Inertial Proximal Method", "comment": null, "summary": "Monotonicity of pairs of operators is an extension of monotonicity of operators, which plays an important role in solving non-monotone inclusions. One of challenging problems in this new tool is how to design the associated mappings to obtain the monotone pairs. In this paper, we solve this problem and propose a Generalized Inertial Proximal Point Algorithm (GIPPA) using warped resolvents under the monotonicity of pairs. The weak, strong and linear convergence of the algorithm under some mild assumptions are established. We also provide numerical examples illustrating the implementability and effectiveness of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u5e7f\u4e49\u60ef\u6027\u90bb\u8fd1\u70b9\u7b97\u6cd5(GIPPA)\uff0c\u5229\u7528\u626d\u66f2\u9884\u89e3\u7b97\u5b50\u89e3\u51b3\u5355\u8c03\u5bf9\u7b97\u5b50\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u7b97\u6cd5\u7684\u5f31\u3001\u5f3a\u548c\u7ebf\u6027\u6536\u655b\u6027", "motivation": "\u5355\u8c03\u5bf9\u7b97\u5b50\u662f\u5355\u8c03\u7b97\u5b50\u7684\u6269\u5c55\uff0c\u5728\u89e3\u51b3\u975e\u5355\u8c03\u5305\u542b\u95ee\u9898\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\u3002\u5982\u4f55\u8bbe\u8ba1\u76f8\u5173\u6620\u5c04\u4ee5\u83b7\u5f97\u5355\u8c03\u5bf9\u662f\u8be5\u65b0\u5de5\u5177\u4e2d\u7684\u4e00\u4e2a\u6311\u6218\u6027\u95ee\u9898", "method": "\u63d0\u51fa\u5e7f\u4e49\u60ef\u6027\u90bb\u8fd1\u70b9\u7b97\u6cd5(GIPPA)\uff0c\u4f7f\u7528\u626d\u66f2\u9884\u89e3\u7b97\u5b50\u5728\u5355\u8c03\u5bf9\u6761\u4ef6\u4e0b\u8bbe\u8ba1\u7b97\u6cd5", "result": "\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u7b97\u6cd5\u7684\u5f31\u6536\u655b\u3001\u5f3a\u6536\u655b\u548c\u7ebf\u6027\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u4f8b\u5b50\u8bf4\u660e\u4e86\u7b97\u6cd5\u7684\u53ef\u5b9e\u65bd\u6027\u548c\u6709\u6548\u6027", "conclusion": "\u89e3\u51b3\u4e86\u5355\u8c03\u5bf9\u7b97\u5b50\u4e2d\u5982\u4f55\u8bbe\u8ba1\u76f8\u5173\u6620\u5c04\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7684GIPPA\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u6570\u503c\u4e0a\u90fd\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd"}}
{"id": "2601.11791", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11791", "abs": "https://arxiv.org/abs/2601.11791", "authors": ["Laya Iyer", "Pranav Somani", "Alice Guo", "Dan Jurafsky", "Chen Shani"], "title": "Beyond Tokens: Concept-Level Training Objectives for LLMs", "comment": null, "summary": "The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \\textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\\rightarrow$ \\textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \\textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ecetoken\u7ea7\u9884\u6d4b\u8f6c\u5411\u6982\u5ff5\u7ea7\u9884\u6d4b\uff0c\u5c06\u540c\u4e00\u6982\u5ff5\u7684\u4e0d\u540c\u8868\u9762\u5f62\u5f0f\uff08\u5982\"mom\"\u3001\"mother\"\uff09\u5206\u7ec4\uff0c\u901a\u8fc7\u6982\u5ff5\u7ea7\u76d1\u7763\u63d0\u5347LLM\u7684\u8bed\u4e49\u5bf9\u9f50\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\uff08NTP\uff09\u76ee\u6807\u5728token\u7ea7\u522b\u64cd\u4f5c\uff0c\u5373\u4f7f\u66ff\u4ee3\u5ef6\u7eed\u540c\u6837\u5408\u7406\u6216\u8bed\u4e49\u7b49\u4ef7\uff08\u5982\"mom\" vs \"mother\"\uff09\uff0c\u4e5f\u4f1a\u5c06\u5176\u89c6\u4e3a\u9519\u8bef\u3002\u8fd9\u5bfc\u81f4token\u7ea7\u635f\u5931\u4f1a\u60e9\u7f5a\u6709\u6548\u7684\u62bd\u8c61\u3001\u91ca\u4e49\u6216\u6982\u5ff5\u6b63\u786e\u7684\u63a8\u7406\u8def\u5f84\uff0c\u4f7f\u6a21\u578b\u504f\u5411\u8868\u9762\u5f62\u5f0f\u800c\u975e\u5e95\u5c42\u542b\u4e49\u3002\u8bad\u7ec3\u4fe1\u53f7\u4e0e\u8bed\u4e49\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u4fc3\u4f7f\u9700\u8981\u66f4\u9ad8\u7ea7\u522b\u7684\u8868\u793a\u5b66\u4e60\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4ecetoken\u7ea7\u9884\u6d4b\u8f6c\u5411\u6982\u5ff5\u7ea7\u9884\u6d4b\uff0c\u5176\u4e2d\u6982\u5ff5\u5c06\u540c\u4e00\u60f3\u6cd5\u7684\u591a\u4e2a\u8868\u9762\u5f62\u5f0f\u5206\u7ec4\uff08\u5982\"mom\"\u3001\"mommy\"\u3001\"mother\"\u2192MOTHER\uff09\u3002\u4ecb\u7ecd\u4e86\u5c06\u6982\u5ff5\u76d1\u7763\u96c6\u6210\u5230LLM\u8bad\u7ec3\u4e2d\u7684\u5404\u79cd\u65b9\u6cd5\u3002", "result": "\u6982\u5ff5\u611f\u77e5\u6a21\u578b\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\uff0c\u5728\u9886\u57df\u8f6c\u79fb\u4e0b\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u5728\u591a\u6837\u5316\u7684NLP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8eNTP\u7684\u6a21\u578b\u3002", "conclusion": "\u6982\u5ff5\u7ea7\u76d1\u7763\u4f5c\u4e3a\u4e00\u79cd\u6539\u8fdb\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u80fd\u66f4\u597d\u5730\u5c06LLM\u4e0e\u4eba\u7c7b\u8bed\u4e49\u62bd\u8c61\u5bf9\u9f50\uff0c\u662f\u6bd4\u4f20\u7edftoken\u7ea7\u9884\u6d4b\u66f4\u4f18\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2601.11669", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11669", "abs": "https://arxiv.org/abs/2601.11669", "authors": ["Wenwen Liao", "Hang Ruan", "Jianbo Yu", "Xiaofeng Yang", "Qingchao Jiang", "Xuefeng Yan"], "title": "IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning", "comment": null, "summary": "Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical \"warm-up and test\" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.", "AI": {"tldr": "IPEC\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5148\u524d\u67e5\u8be2\u6837\u672c\u7684\u4fe1\u606f\u4f18\u5316\u539f\u578b\u4f30\u8ba1\uff0c\u5728\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5ea6\u91cf\u7684\u5c11\u6837\u672c\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u9075\u5faa\u6279\u6b21\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u65e0\u6cd5\u5229\u7528\u5148\u524d\u6279\u6b21\u79ef\u7d2f\u7684\u5b9d\u8d35\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u589e\u91cf\u539f\u578b\u589e\u5f3a\u5206\u7c7b\u5668(IPEC)\uff1a1)\u7ef4\u62a4\u52a8\u6001\u8f85\u52a9\u96c6\uff0c\u9009\u62e9\u6027\u7eb3\u5165\u9ad8\u7f6e\u4fe1\u5ea6\u67e5\u8be2\u6837\u672c\uff1b2)\u8bbe\u8ba1\u53cc\u91cd\u8fc7\u6ee4\u673a\u5236\u8bc4\u4f30\u6837\u672c\u8d28\u91cf\uff1b3)\u57fa\u4e8e\u8d1d\u53f6\u65af\u89e3\u91ca\uff0c\u5c06\u652f\u6301\u96c6\u89c6\u4e3a\u5148\u9a8c\uff0c\u8f85\u52a9\u96c6\u89c6\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u540e\u9a8c\uff1b4)\u91c7\u7528\"\u9884\u70ed-\u6d4b\u8bd5\"\u4e24\u9636\u6bb5\u63a8\u7406\u534f\u8bae\u3002", "result": "\u5728\u591a\u4e2a\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86IPEC\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u80fd\u591f\u6784\u5efa\u66f4\u7a33\u5b9a\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u539f\u578b\uff0c\u51cf\u5c11\u5bf9\u521d\u59cb\u652f\u6301\u96c6\u7684\u4f9d\u8d56\u3002", "conclusion": "IPEC\u901a\u8fc7\u6d4b\u8bd5\u65f6\u5229\u7528\u5148\u524d\u67e5\u8be2\u6837\u672c\u4fe1\u606f\u6709\u6548\u89e3\u51b3\u4e86\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u7684\u6279\u6b21\u72ec\u7acb\u6027\u9650\u5236\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12002", "categories": ["cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12002", "abs": "https://arxiv.org/abs/2601.12002", "authors": ["Oliver Sch\u00f6n", "Zhengang Zhong", "Sadegh Soudjani"], "title": "Kernel-Based Learning of Safety Barriers", "comment": "44 pages, 9 figures", "summary": "The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u9ed1\u76d2\u968f\u673a\u7cfb\u7edf\u5b89\u5168\u9a8c\u8bc1\u4e0e\u5408\u6210\u65b9\u6cd5\uff0c\u5229\u7528\u63a7\u5236\u5c4f\u969c\u8bc1\u4e66\u548c\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u5d4c\u5165\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u5c55\u5f00\u5c06\u534a\u65e0\u9650\u4f18\u5316\u8f6c\u5316\u4e3a\u7ebf\u6027\u89c4\u5212\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5206\u5e03\u9c81\u68d2\u5b89\u5168\u9a8c\u8bc1\u3002", "motivation": "AI\u7b97\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5feb\u901f\u96c6\u6210\uff0c\u4f20\u7edf\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u96be\u4ee5\u5904\u7406\u9ed1\u76d2\u7cfb\u7edf\u548c\u590d\u6742\u73b0\u5b9e\u5e94\u7528\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u4ece\u7cfb\u7edf\u8f68\u8ff9\u5b66\u4e60\u63a7\u5236\u5c4f\u969c\u8bc1\u4e66\uff1b\u4f7f\u7528\u6761\u4ef6\u5747\u503c\u5d4c\u5165\u5c06\u6570\u636e\u6620\u5c04\u5230\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u6784\u5efaRKHS\u6a21\u7cca\u96c6\u4ee5\u589e\u5f3a\u5bf9\u5206\u5e03\u5916\u884c\u4e3a\u7684\u9c81\u68d2\u6027\uff1b\u5229\u7528\u6709\u9650\u5085\u91cc\u53f6\u5c55\u5f00\u5c06\u534a\u65e0\u9650\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u7ebf\u6027\u89c4\u5212\uff0c\u901a\u8fc7\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\u9ad8\u6548\u751f\u6210\u677e\u5f1b\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86\u8d85\u8d8a\u5b89\u5168\u6027\u7684\u901a\u7528\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\u7406\u8bba\u6846\u67b6\uff1b\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u5206\u5e03\u9c81\u68d2\u5b89\u5168\u9a8c\u8bc1\u6846\u67b6\uff1b\u5728\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u5305\u62ec\u5e26\u6709\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u7684\u9ed1\u76d2\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7a81\u7834\u4e86\u4f20\u7edf\u5bf9\u7cfb\u7edf\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u9650\u5236\u6027\u5047\u8bbe\uff0c\u4e3a\u590d\u6742\u9ed1\u76d2AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u5206\u5e03\u9c81\u68d2\u7684\u5b89\u5168\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u3002"}}
{"id": "2601.12694", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12694", "abs": "https://arxiv.org/abs/2601.12694", "authors": ["Manobendu Sarker", "Md. Zoheb Hassan", "Xianbin Wang"], "title": "Closed-loop Uplink Radio Resource Management in CF-O-RAN Empowered 5G Aerial Corridor", "comment": "6 Pages, Accepted in IEEE ICC 2026", "summary": "In this paper, we investigate the uplink (UL) radio resource management for 5G aerial corridors with an open-radio access network (O-RAN)-enabled cell-free (CF) massive multiple-input multiple-output (mMIMO) system. Our objective is to maximize the minimum spectral efficiency (SE) by jointly optimizing unmanned aerial vehicle (UAV)-open radio unit (O-RU) association and UL transmit power under quality-of-service (QoS) constraints. Owing to its NP-hard nature, the formulated problem is decomposed into two tractable sub-problems solved via alternating optimization (AO) using two computationally efficient algorithms. We then propose (i) a QoS-driven and multi-connectivity-enabled association algorithm incorporating UAV-centric and O-RU-centric criteria with targeted refinement for weak UAVs, and (ii) a bisection-guided fixed-point power control algorithm achieving global optimality with significantly reduced complexity, hosted as xApp at the near-real-time (near-RT) RAN intelligent controller (RIC) of O-RAN. Solving the resource-allocation problem requires global channel state information (CSI), which incurs substantial measurement and signaling overhead. To mitigate this, we leverage a channel knowledge map (CKM) within the O-RAN non-RT RIC to enable efficient environment-aware CSI inference. Simulation results show that the proposed framework achieves up to 440% improvement in minimum SE, 100% QoS satisfaction and fairness, while reducing runtime by up to 99.7% compared to an interior point solver-based power allocation solution, thereby enabling O-RAN compliant real-time deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eO-RAN\u7684CF mMIMO\u7cfb\u7edf\uff0c\u7528\u4e8e5G\u7a7a\u4e2d\u8d70\u5eca\u4e0a\u884c\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a-O-RU\u5173\u8054\u548c\u53d1\u5c04\u529f\u7387\u6765\u6700\u5927\u5316\u6700\u5c0f\u9891\u8c31\u6548\u7387\uff0c\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u548cCKM\u6280\u672f\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "5G\u7a7a\u4e2d\u8d70\u5eca\u9700\u8981\u9ad8\u6548\u7684\u65e0\u7ebf\u8d44\u6e90\u7ba1\u7406\uff0c\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34NP-hard\u590d\u6742\u5ea6\u548c\u9ad8\u4fe1\u4ee4\u5f00\u9500\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728O-RAN\u67b6\u6784\u4e0b\u5b9e\u65f6\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u5c06\u539f\u95ee\u9898\u5206\u89e3\u4e3a\u4e24\u4e2a\u53ef\u5904\u7406\u7684\u5b50\u95ee\u9898\uff0c\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\uff1b2) \u63d0\u51faQoS\u9a71\u52a8\u7684\u591a\u8fde\u63a5\u5173\u8054\u7b97\u6cd5\uff0c\u7ed3\u5408\u65e0\u4eba\u673a\u4e2d\u5fc3\u548cO-RU\u4e2d\u5fc3\u51c6\u5219\uff1b3) \u8bbe\u8ba1\u4e8c\u5206\u6cd5\u5f15\u5bfc\u7684\u5b9a\u70b9\u529f\u7387\u63a7\u5236\u7b97\u6cd5\uff1b4) \u5229\u7528O-RAN\u975e\u5b9e\u65f6RIC\u4e2d\u7684CKM\u8fdb\u884c\u73af\u5883\u611f\u77e5CSI\u63a8\u65ad\u3002", "result": "\u76f8\u6bd4\u57fa\u4e8e\u5185\u70b9\u6cd5\u7684\u529f\u7387\u5206\u914d\u65b9\u6848\uff0c\u6700\u5c0f\u9891\u8c31\u6548\u7387\u63d0\u5347\u9ad8\u8fbe440%\uff0cQoS\u6ee1\u8db3\u7387\u548c\u516c\u5e73\u6027\u8fbe\u5230100%\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1199.7%\uff0c\u652f\u6301O-RAN\u517c\u5bb9\u7684\u5b9e\u65f6\u90e8\u7f72\u3002", "conclusion": "\u63d0\u51fa\u7684O-RAN\u4f7f\u80fdCF mMIMO\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b35G\u7a7a\u4e2d\u8d70\u5eca\u4e0a\u884c\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5173\u8054\u548c\u529f\u7387\u63a7\u5236\u7b97\u6cd5\u7ed3\u5408CKM\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2601.12284", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12284", "abs": "https://arxiv.org/abs/2601.12284", "authors": ["Amit Chougule", "Vinay Chamola", "Norbert Herencsar", "Fei Richard Yu"], "title": "How Safe Is Your Data in Connected and Autonomous Cars: A Consumer Advantage or a Privacy Nightmare ?", "comment": null, "summary": "The rapid evolution of the automobile sector, driven by advancements in connected and autonomous vehicles (CAVs), has transformed how vehicles communicate, operate, and interact with their surroundings. Technologies such as Vehicle-to-Everything (V2X) communication enable autonomous cars to generate and exchange substantial amounts of data with real-world entities, enhancing safety, improving performance, and delivering personalized user experiences. However, this data-driven ecosystem introduces significant challenges, particularly concerning data privacy, security, and governance. The absence of transparency and comprehensive regulatory frameworks exacerbates issues of unauthorized data access, prolonged retention, and potential misuse, creating tension between consumer benefits and privacy risks. This review paper explores the multifaceted nature of data sharing in CAVs, analyzing its contributions to innovation and its associated vulnerabilities. It evaluates data-sharing mechanisms and communication technologies, highlights the benefits of data exchange across various use cases, examines privacy concerns and risks of data misuse, and critically reviews regulatory frameworks and their inadequacies in safeguarding user privacy. By providing a thorough analysis of the current state of data sharing in the automotive sector, the paper emphasizes the urgent need for robust policies and ethical data management practices. It calls for striking a balance between fostering technological advancements and ensuring secure, consumer-friendly solutions, paving the way for a trustworthy and innovative automotive future.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u5206\u6790\u4e86\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66(CAVs)\u6570\u636e\u5171\u4eab\u7684\u591a\u65b9\u9762\u95ee\u9898\uff0c\u63a2\u8ba8\u4e86\u6280\u672f\u521b\u65b0\u4e0e\u9690\u79c1\u98ce\u9669\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u5f3a\u8c03\u9700\u8981\u5efa\u7acb\u5f3a\u5927\u7684\u76d1\u7ba1\u6846\u67b6\u548c\u9053\u5fb7\u6570\u636e\u7ba1\u7406\u5b9e\u8df5\u3002", "motivation": "\u6c7d\u8f66\u884c\u4e1a\u5411\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66(CAVs)\u7684\u5feb\u901f\u6f14\u8fdb\u4ea7\u751f\u4e86\u5927\u91cf\u6570\u636e\u4ea4\u6362\uff0c\u867d\u7136\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u6570\u636e\u9690\u79c1\u3001\u5b89\u5168\u548c\u6cbb\u7406\u6311\u6218\u3002\u5f53\u524d\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u5168\u9762\u7684\u76d1\u7ba1\u6846\u67b6\uff0c\u5bfc\u81f4\u672a\u7ecf\u6388\u6743\u7684\u6570\u636e\u8bbf\u95ee\u3001\u957f\u671f\u4fdd\u7559\u548c\u6f5c\u5728\u6ee5\u7528\u95ee\u9898\uff0c\u9700\u8981\u5728\u6d88\u8d39\u8005\u5229\u76ca\u4e0e\u9690\u79c1\u98ce\u9669\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u5206\u6790\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\uff1a1) \u5206\u6790CAVs\u6570\u636e\u5171\u4eab\u673a\u5236\u548c\u901a\u4fe1\u6280\u672f\uff1b2) \u8bc4\u4f30\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e2d\u6570\u636e\u4ea4\u6362\u7684\u76ca\u5904\uff1b3) \u5ba1\u67e5\u9690\u79c1\u95ee\u9898\u548c\u6570\u636e\u6ee5\u7528\u7684\u98ce\u9669\uff1b4) \u6279\u5224\u6027\u8bc4\u4f30\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\u53ca\u5176\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "result": "\u8bba\u6587\u63ed\u793a\u4e86\u5f53\u524d\u6c7d\u8f66\u884c\u4e1a\u6570\u636e\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u663e\u8457\u9690\u79c1\u548c\u5b89\u5168\u6f0f\u6d1e\uff0c\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\u4e0d\u8db3\u4ee5\u5e94\u5bf9CAVs\u5e26\u6765\u7684\u65b0\u6311\u6218\u3002\u6570\u636e\u5171\u4eab\u867d\u7136\u4fc3\u8fdb\u4e86\u6280\u672f\u521b\u65b0\uff0c\u4f46\u7f3a\u4e4f\u8db3\u591f\u7684\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u3002", "conclusion": "\u8feb\u5207\u9700\u8981\u5efa\u7acb\u5f3a\u5927\u7684\u653f\u7b56\u548c\u9053\u5fb7\u6570\u636e\u7ba1\u7406\u5b9e\u8df5\uff0c\u5728\u4fc3\u8fdb\u6280\u672f\u8fdb\u6b65\u4e0e\u786e\u4fdd\u5b89\u5168\u3001\u6d88\u8d39\u8005\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u8fd9\u9700\u8981\u5236\u5b9a\u5168\u9762\u7684\u76d1\u7ba1\u6846\u67b6\uff0c\u786e\u4fdd\u6570\u636e\u900f\u660e\u5ea6\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u4e3a\u53ef\u4fe1\u8d56\u548c\u521b\u65b0\u7684\u6c7d\u8f66\u672a\u6765\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2601.12612", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12612", "abs": "https://arxiv.org/abs/2601.12612", "authors": ["Piyush Sao"], "title": "What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes", "comment": null, "summary": "Computing $\\log\\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \\tr(A^k)$, natural when matrix powers are available.\n  Classical moment-based approximations Taylor-expand $\\log(\u03bb)$ around the arithmetic mean. This requires $|\u03bb- \\AM| < \\AM$ and diverges when $\u03ba> 4$. We work instead with the moment-generating function $M(t) = \\E[X^t]$ for normalized eigenvalues $X = \u03bb/\\AM$. Since $M'(0) = \\E[\\log X]$, the log-determinant becomes $\\log\\det(A) = n(\\log \\AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \\log M(t)$ compresses this range. Normalization by $\\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.\n  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \\E[\\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\\det A)^{1/n}$. Given a spectral floor $r \\leq \u03bb_{\\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\\log\\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \\in \\{4, \\ldots, 8\\}$, this is effectively constant time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e9\u9635\u8ff9\u5e42\u8ba1\u7b97\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e9\u751f\u6210\u51fd\u6570\u53d8\u6362\u548c\u63d2\u503c\u6280\u672f\uff0c\u5728\u5e38\u6570\u65f6\u95f4\u5185\u63d0\u4f9b\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u70b9\u4f30\u8ba1\u548c\u53ef\u8bc1\u660e\u7684\u4e0a\u4e0b\u754c\u3002", "motivation": "\u5728\u8d1d\u53f6\u65af\u6a21\u578b\u6bd4\u8f83\u548c\u9ad8\u65af\u8fc7\u7a0b\u63a8\u65ad\u4e2d\uff0c\u8ba1\u7b97\u5927\u578b\u5bf9\u79f0\u6b63\u5b9a\u77e9\u9635\u7684\u5bf9\u6570\u884c\u5217\u5f0f\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u77e9\u9635\u5411\u91cf\u79ef\u548c\u591a\u9879\u5f0f\u8fd1\u4f3c\uff0c\u4f46\u672c\u6587\u7814\u7a76\u53e6\u4e00\u79cd\u6a21\u578b\uff1a\u5f53\u77e9\u9635\u5e42\u53ef\u7528\u65f6\uff0c\u901a\u8fc7\u8ff9\u5e42\u6765\u8ba1\u7b97\u5bf9\u6570\u884c\u5217\u5f0f\u3002", "method": "1. \u4f7f\u7528\u5f52\u4e00\u5316\u7279\u5f81\u503c\u7684\u77e9\u751f\u6210\u51fd\u6570 M(t) = E[X^t]\uff0c\u5c06\u5bf9\u6570\u884c\u5217\u5f0f\u95ee\u9898\u8f6c\u5316\u4e3a\u4f30\u8ba1 M'(0)\n2. \u901a\u8fc7\u53d8\u6362 K(t) = log M(t) \u538b\u7f29\u6570\u503c\u8303\u56f4\uff0c\u5229\u7528 K(0)=K(1)=0 \u7684\u951a\u70b9\n3. \u5728 m+1 \u4e2a\u8fde\u7eed\u6574\u6570\u70b9\u63d2\u503c K \u51fd\u6570\uff0c\u7136\u540e\u5fae\u5206\u4f30\u8ba1 K'(0)\n4. \u4ece\u76f8\u540c\u7684\u8ff9\u4fe1\u606f\u63a8\u5bfc\u51fa (det A)^{1/n} \u7684\u4e0a\u754c\uff0c\u7ed9\u5b9a\u8c31\u4e0b\u754c r \u2264 \u03bb_min \u65f6\u83b7\u5f97\u4e0b\u754c\n5. \u63d0\u4f9b\u95f4\u9699\u8bca\u65ad\u6307\u6807\u6765\u8bc4\u4f30\u70b9\u4f30\u8ba1\u7684\u53ef\u4fe1\u5ea6", "result": "1. \u8bc1\u660e\u4e86\u57fa\u672c\u9650\u5236\uff1a\u4f7f\u7528\u6709\u9650\u6b63\u77e9\u7684\u4efb\u4f55\u8fde\u7eed\u4f30\u8ba1\u5668\u5728\u65e0\u754c\u6761\u4ef6\u6570\u4e0b\u65e0\u6cd5\u8fbe\u5230\u5747\u5300\u7cbe\u5ea6\n2. \u6240\u6709\u4f30\u8ba1\u5668\u548c\u754c\u8ba1\u7b97\u6210\u672c\u4e3a O(m)\uff0c\u4e0e\u77e9\u9635\u7ef4\u5ea6 n \u65e0\u5173\n3. \u5f53 m \u2208 {4, ..., 8} \u65f6\uff0c\u5b9e\u9645\u4e0a\u662f\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\n4. \u65b9\u6cd5\u63d0\u4f9b\u4e86\u5bf9\u6570\u884c\u5217\u5f0f\u7684\u70b9\u4f30\u8ba1\u548c\u53ef\u8bc1\u660e\u7684\u4e0a\u4e0b\u754c", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u77e9\u751f\u6210\u51fd\u6570\u53d8\u6362\u548c\u63d2\u503c\u6280\u672f\uff0c\u4e3a\u5bf9\u6570\u884c\u5217\u5f0f\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b0\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u77e9\u9635\u5e42\u53ef\u7528\u7684\u573a\u666f\u3002\u867d\u7136\u5b58\u5728\u7406\u8bba\u9650\u5236\uff0c\u4f46\u901a\u8fc7\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u4e0a\u4e0b\u754c\u548c\u8bca\u65ad\u6307\u6807\uff0c\u80fd\u591f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u9760\u5730\u4f30\u8ba1\u5bf9\u6570\u884c\u5217\u5f0f\u3002"}}
{"id": "2601.12810", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.12810", "abs": "https://arxiv.org/abs/2601.12810", "authors": ["Hoai-Minh Nguyen"], "title": "Optimal bounds for the boundary control cost of one-dimensional fractional Schr\u00f6dinger and heat equations", "comment": null, "summary": "We derive sharp bounds for the boundary control cost of the one-dimensional fractional Schr\u00f6dinger and heat equations. The analysis of the lower bound is based on the study of the control cost of a related singular boundary control problem in finite time, using tools from complex analysis. The analysis of the upper bound relies on the moment method, involving estimates of the Fourier transform of a class of compactly supported functions.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u4e00\u7ef4\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u548c\u70ed\u65b9\u7a0b\u8fb9\u754c\u63a7\u5236\u6210\u672c\u7684\u6700\u4f18\u4e0a\u4e0b\u754c", "motivation": "\u7814\u7a76\u5206\u6570\u9636\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8fb9\u754c\u63a7\u5236\u95ee\u9898\uff0c\u786e\u5b9a\u63a7\u5236\u6210\u672c\u7684\u7406\u8bba\u6781\u9650\uff0c\u4e3a\u5b9e\u9645\u63a7\u5236\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc", "method": "\u4e0b\u754c\u5206\u6790\uff1a\u901a\u8fc7\u7814\u7a76\u6709\u9650\u65f6\u95f4\u5185\u76f8\u5173\u5947\u5f02\u8fb9\u754c\u63a7\u5236\u95ee\u9898\uff0c\u8fd0\u7528\u590d\u5206\u6790\u5de5\u5177\uff1b\u4e0a\u754c\u5206\u6790\uff1a\u91c7\u7528\u77e9\u65b9\u6cd5\uff0c\u4f30\u8ba1\u4e00\u7c7b\u7d27\u652f\u96c6\u51fd\u6570\u7684\u5085\u91cc\u53f6\u53d8\u6362", "result": "\u5f97\u5230\u4e86\u4e00\u7ef4\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u548c\u70ed\u65b9\u7a0b\u8fb9\u754c\u63a7\u5236\u6210\u672c\u7684\u5c16\u9510\uff08\u6700\u4f18\uff09\u4e0a\u4e0b\u754c", "conclusion": "\u5efa\u7acb\u4e86\u5206\u6570\u9636\u504f\u5fae\u5206\u65b9\u7a0b\u8fb9\u754c\u63a7\u5236\u6210\u672c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u76f8\u5173\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u6570\u5b66\u754c\u9650"}}
{"id": "2601.11819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11819", "abs": "https://arxiv.org/abs/2601.11819", "authors": ["Shirlene Rose Bandela", "Sanjeev Parthasarathy", "Vaibhav Garg"], "title": "TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit", "comment": "11 pages, 12 figures, 7 tables", "summary": "Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.", "AI": {"tldr": "TWeddit\u662f\u4e00\u4e2a\u6807\u6ce8Reddit\u4e0a\u5973\u6027\u76f8\u5173\u89e6\u53d1\u7ecf\u5386\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7814\u7a76\u521b\u4f24\u5185\u5bb9\u68c0\u6d4b\u548c\u60c5\u611f\u652f\u6301", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7528\u6237\u7ecf\u5e38\u5206\u4eab\u6d41\u4ea7\u3001\u6027\u66b4\u529b\u7b49\u521b\u4f24\u7ecf\u5386\uff0c\u4f46\u7f3a\u4e4f\u624b\u52a8\u89e6\u53d1\u8b66\u544a\uff0c\u73b0\u6709\u6807\u6ce8\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u6570\u636e\u96c6\u6765\u7814\u7a76\u8fd9\u4e9b\u654f\u611f\u5185\u5bb9", "method": "\u521b\u5efaTWeddit\u6570\u636e\u96c6\uff0c\u6536\u96c6Reddit\u4e0a\u5973\u6027\u76f8\u5173\u89e6\u53d1\u7ecf\u5386\u7684\u8be6\u7ec6\u53d9\u8ff0\uff0c\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\u548c\u8bed\u8a00\u5b66\u5206\u6790\uff0c\u5305\u62ec\u8bdd\u9898\u5206\u6790\u548c\u9053\u5fb7\u57fa\u7840\u5206\u6790", "result": "TWeddit\u6570\u636e\u96c6\u4e2d\u7684\u6807\u6ce8\u6545\u4e8b\u8868\u73b0\u51fa\u72ec\u7279\u7684\u8bdd\u9898\u5206\u5e03\u548c\u9053\u5fb7\u57fa\u7840\u7279\u5f81\uff0c\u8bc1\u660e\u8be5\u6570\u636e\u96c6\u5bf9\u672a\u6765\u7814\u7a76\u5177\u6709\u5b9e\u7528\u4ef7\u503c", "conclusion": "TWeddit\u6570\u636e\u96c6\u586b\u8865\u4e86Reddit\u4e0a\u521b\u4f24\u7ecf\u5386\u6807\u6ce8\u6570\u636e\u7684\u7a7a\u767d\uff0c\u4e3a\u60c5\u611f\u652f\u6301\u3001\u5185\u5bb9\u68c0\u6d4b\u548c\u9053\u5fb7\u57fa\u7840\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90"}}
{"id": "2601.11670", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11670", "abs": "https://arxiv.org/abs/2601.11670", "authors": ["Jinshi Liu", "Pan Liu"], "title": "A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning", "comment": null, "summary": "Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)", "AI": {"tldr": "\u63d0\u51faCoVar\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u6700\u5927\u7f6e\u4fe1\u5ea6\u548c\u6b8b\u5dee\u7c7b\u65b9\u5dee\u6765\u6539\u8fdb\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u4f2a\u6807\u7b7e\u9009\u62e9\uff0c\u65e0\u9700\u56fa\u5b9a\u9608\u503c", "motivation": "\u73b0\u6709\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u4f2a\u6807\u7b7e\u9009\u62e9\u7b56\u7565\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u7684\u7f6e\u4fe1\u5ea6\u9608\u503c\uff0c\u4f46\u6df1\u5ea6\u7f51\u7edc\u7ecf\u5e38\u8fc7\u5ea6\u81ea\u4fe1\uff1a\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u53ef\u80fd\u9519\u8bef\uff0c\u800c\u6709\u4fe1\u606f\u91cf\u7684\u4f4e\u7f6e\u4fe1\u5ea6\u6837\u672c\u5374\u88ab\u4e22\u5f03", "method": "\u4ece\u71b5\u6700\u5c0f\u5316\u539f\u5219\u51fa\u53d1\uff0c\u63a8\u5bfc\u51fa\u7ed3\u5408\u6700\u5927\u7f6e\u4fe1\u5ea6(MC)\u548c\u6b8b\u5dee\u7c7b\u65b9\u5dee(RCV)\u7684\u53ef\u9760\u6027\u5ea6\u91cf\uff0c\u5c06\u4f2a\u6807\u7b7e\u9009\u62e9\u8f6c\u5316\u4e3a\u7f6e\u4fe1\u5ea6-\u65b9\u5dee\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u8c31\u677e\u5f1b\u95ee\u9898\uff0c\u8bbe\u8ba1\u65e0\u9700\u9608\u503c\u7684\u9009\u62e9\u673a\u5236", "result": "\u5728PASCAL VOC 2012\u3001Cityscapes\u3001CIFAR-10\u548cMini-ImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u4e0d\u540c\u6807\u7b7e\u6bd4\u4f8b\u548c\u9aa8\u5e72\u7f51\u7edc\uff0cCoVar\u4f5c\u4e3a\u63d2\u4ef6\u6a21\u5757\u6301\u7eed\u6539\u8fdb\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u548c\u6b8b\u5dee\u7c7b\u65b9\u5dee\u6bd4\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u9608\u503c\u4e3a\u4f2a\u6807\u7b7e\u9009\u62e9\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u7840\uff0cCoVar\u6846\u67b6\u80fd\u6709\u6548\u7ea0\u6b63\u8fc7\u5ea6\u81ea\u4fe1\u4f46\u4e0d\u7a33\u5b9a\u7684\u9884\u6d4b"}}
{"id": "2601.12014", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12014", "abs": "https://arxiv.org/abs/2601.12014", "authors": ["Elio Masciari", "Vincenzo Moscato", "Enea Vincenzo Napolitano", "Gian Marco Orlando", "Marco Perillo", "Diego Russo"], "title": "Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats", "comment": null, "summary": "Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.\n  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u53ef\u6301\u7eed\u6027\u611f\u77e5\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u73af\u5883\u611f\u77e5\u751f\u6210\u6b63\u786e\u6027\u5206\u6570(GCS_env)\uff0c\u7cfb\u7edf\u6bd4\u8f83TOON\u683c\u5f0f\u4e0e\u4f20\u7edf\u683c\u5f0f(JSON/XML/YAML)\u5728\u73af\u5883\u6548\u7387\u4e0e\u6b63\u786e\u6027\u4e0a\u7684\u6743\u8861\u3002", "motivation": "\u5f53\u524dLLM\u7ed3\u6784\u5316\u8f93\u51fa\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6b63\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u8f93\u51fa\u683c\u5f0f\u7684\u73af\u5883\u5f71\u54cd\u3002\u968f\u7740LLM\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u9700\u8981\u7efc\u5408\u8003\u8651\u7ed3\u6784\u6b63\u786e\u6027\u548c\u73af\u5883\u6548\u7387\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u53ef\u6301\u7eed\u6027\u611f\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u91cftoken\u4f7f\u7528\u91cf\u3001\u751f\u6210\u65f6\u95f4\u548c\u78b3\u6392\u653e\u4f30\u8ba1\u3002\u5f15\u5165GCS_env\u7edf\u4e00\u6307\u6807\uff0c\u6574\u5408\u7ed3\u6784\u6b63\u786e\u6027\u548c\u78b3\u611f\u77e5\u6548\u7387\u3002\u7cfb\u7edf\u6bd4\u8f83TOON\u683c\u5f0f\u4e0e\u4f20\u7edf\u683c\u5f0f\u5728\u4e0d\u540c\u67b6\u6784\u548c\u53c2\u6570\u89c4\u6a21\u7684LLM\u4e0a\u7684\u8868\u73b0\u3002", "result": "TOON\u683c\u5f0f\u4ea7\u751f\u66f4\u7d27\u51d1\u7684\u8f93\u51fa\u548c\u66f4\u4f4e\u7684\u6392\u653e\uff0c\u4f46\u5728\u6a21\u578b\u7f3a\u4e4f\u539f\u751f\u652f\u6301\u65f6\u7ed3\u6784\u6b63\u786e\u6027\u8f83\u4f4e\u3002\u6a21\u578b\u5bb9\u91cf\u589e\u52a0\u53ef\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\uff0c\u73af\u5883\u611f\u77e5\u8bc4\u5206\u53ef\u6839\u636e\u90e8\u7f72\u4f18\u5148\u7ea7\u6539\u53d8\u683c\u5f0f\u6392\u540d\u3002", "conclusion": "\u9700\u8981\u53ef\u6301\u7eed\u6027\u5305\u5bb9\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7d27\u51d1\u8868\u793a\u5982TOON\u5728\u5927\u89c4\u6a21\u78b3\u610f\u8bc6LLM\u90e8\u7f72\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u3002\u73af\u5883\u6548\u7387\u5e94\u6210\u4e3a\u7ed3\u6784\u5316\u8f93\u51fa\u8bc4\u4f30\u7684\u91cd\u8981\u7ef4\u5ea6\u3002"}}
{"id": "2601.12695", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12695", "abs": "https://arxiv.org/abs/2601.12695", "authors": ["Hiroshi Okajima", "Shun Shirahama", "Tatsunori Hayashi", "Nobutomo Matsunaga"], "title": "From Noise to Knowledge: System Identification with Systematic Polytope Construction via Cyclic Reformulation", "comment": null, "summary": "Model-based control requires accurate mathematical models to guarantee control performance and stability. However, obtaining accurate models is challenging due to process and sensor noise. This paper proposes a novel identification algorithm that derives polytopic uncertainty models by interpreting noise-induced parameter fluctuations as intrinsic uncertainty. The method applies cyclic reformulation with period N to linear time-invariant systems, yielding N parameter sets with slight variations that serve as polytope vertices. This enables systematic polytopic model construction from a single identification experiment. Simulation results demonstrate significant improvements: the proposed method achieves higher parameter estimation accuracy and reduces prediction errors by approximately half compared to conventional approaches. The vertex count N provides systematic control over the precision of uncertainty representation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u8fa8\u8bc6\u7b97\u6cd5\uff0c\u5c06\u566a\u58f0\u5f15\u8d77\u7684\u53c2\u6570\u6ce2\u52a8\u89e3\u91ca\u4e3a\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u6784\u5efa\u591a\u9762\u4f53\u4e0d\u786e\u5b9a\u6027\u6a21\u578b\uff0c\u901a\u8fc7\u5faa\u73af\u91cd\u6784\u548c\u5468\u671fN\u83b7\u5f97\u591a\u9762\u4f53\u9876\u70b9\uff0c\u5b9e\u73b0\u4ece\u5355\u6b21\u5b9e\u9a8c\u7cfb\u7edf\u5316\u5efa\u6a21\u3002", "motivation": "\u57fa\u4e8e\u6a21\u578b\u7684\u63a7\u5236\u9700\u8981\u7cbe\u786e\u6570\u5b66\u6a21\u578b\u4ee5\u4fdd\u8bc1\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u4f46\u7531\u4e8e\u8fc7\u7a0b\u548c\u4f20\u611f\u5668\u566a\u58f0\uff0c\u83b7\u53d6\u7cbe\u786e\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u566a\u58f0\u5f15\u8d77\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u8fa8\u8bc6\u7b97\u6cd5\uff0c\u5c06\u566a\u58f0\u5f15\u8d77\u7684\u53c2\u6570\u6ce2\u52a8\u89e3\u91ca\u4e3a\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u5e94\u7528\u5468\u671fN\u7684\u5faa\u73af\u91cd\u6784\u5230\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u4ea7\u751fN\u4e2a\u7565\u6709\u53d8\u5316\u7684\u53c2\u6570\u96c6\u4f5c\u4e3a\u591a\u9762\u4f53\u9876\u70b9\uff0c\u5b9e\u73b0\u4ece\u5355\u6b21\u8fa8\u8bc6\u5b9e\u9a8c\u7cfb\u7edf\u5316\u6784\u5efa\u591a\u9762\u4f53\u6a21\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u663e\u8457\u6539\u8fdb\uff1a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u6240\u63d0\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u9884\u6d4b\u8bef\u5dee\u51cf\u5c11\u7ea6\u4e00\u534a\u3002\u9876\u70b9\u6570N\u63d0\u4f9b\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u8868\u793a\u7cbe\u5ea6\u7684\u7cfb\u7edf\u5316\u63a7\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u566a\u58f0\u6570\u636e\u4e2d\u6709\u6548\u6784\u5efa\u591a\u9762\u4f53\u4e0d\u786e\u5b9a\u6027\u6a21\u578b\uff0c\u4e3a\u57fa\u4e8e\u6a21\u578b\u7684\u63a7\u5236\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6570\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u8c03\u6574\u9876\u70b9\u6570N\u53ef\u4ee5\u5e73\u8861\u6a21\u578b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2601.12390", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.12390", "abs": "https://arxiv.org/abs/2601.12390", "authors": ["Luka Bekavac", "Simon Mayer"], "title": "Auditing Meta and TikTok Research API Data Access under Article 40(12) of the Digital Services Act", "comment": "Preprint. This manuscript is currently under peer review", "summary": "Article 40(12) of the Digital Services Act (DSA) requires Very Large Online Platforms (VLOPs) to provide vetted researchers with access to publicly accessible data. While prior work has identified shortcomings of platform-provided data access mechanisms, existing research has not quantitatively assessed data quality and completeness in Research APIs across platforms, nor systematically mapped how current access provisions fall short. This paper presents a systematic audit of research access modalities by comparing data obtained through platform Research APIs with data collected about the same platforms' user-visible public information environment (PIE). Focusing on two major platform APIs, the TikTok Research API and the Meta Content Library, we reconstruct full information feeds for two controlled sockpuppet accounts during two election periods and benchmark these against the data retrievable for the same posts through the corresponding Research APIs. Our findings show systematic data loss through three classes of platform-imposed mechanisms: scope narrowing, metadata stripping, and operational restrictions. Together, these mechanisms implement overlapping filters that exclude large portions of the platform PIE (up to approximately 50 percent), strip essential contextual metadata (up to approximately 83 percent), and impose severe technical constraints for researchers (down to approximately 1000 requests per day). Viewed through a data quality lens, these filters primarily undermine completeness, resulting in a structurally biased representation of platform activity. We conclude that, in their current form, the Meta and TikTok Research APIs fall short of supporting meaningful, independent auditing of systemic risks as envisioned under the DSA.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0Meta\u548cTikTok\u7684\u7814\u7a76API\u5b58\u5728\u7cfb\u7edf\u6027\u6570\u636e\u4e22\u5931\u95ee\u9898\uff0c\u5305\u62ec\u8303\u56f4\u7f29\u5c0f\u3001\u5143\u6570\u636e\u5265\u79bb\u548c\u64cd\u4f5c\u9650\u5236\uff0c\u5bfc\u81f4\u5e73\u53f0\u516c\u5171\u4fe1\u606f\u73af\u5883\u6570\u636e\u4e0d\u5b8c\u6574\uff0c\u65e0\u6cd5\u652f\u6301DSA\u8981\u6c42\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u8bc4\u4f30\u3002", "motivation": "\u6b27\u76df\u300a\u6570\u5b57\u670d\u52a1\u6cd5\u6848\u300b\u8981\u6c42\u5927\u578b\u5728\u7ebf\u5e73\u53f0\u5411\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6570\u636e\u8bbf\u95ee\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u7cfb\u7edf\u8bc4\u4f30\u5e73\u53f0\u7814\u7a76API\u7684\u6570\u636e\u8d28\u91cf\u548c\u5b8c\u6574\u6027\uff0c\u4e5f\u672a\u5168\u9762\u5206\u6790\u5f53\u524d\u8bbf\u95ee\u673a\u5236\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5e73\u53f0\u7814\u7a76API\u83b7\u53d6\u7684\u6570\u636e\u4e0e\u4ece\u76f8\u540c\u5e73\u53f0\u516c\u5171\u4fe1\u606f\u73af\u5883\u6536\u96c6\u7684\u6570\u636e\uff0c\u7cfb\u7edf\u5ba1\u8ba1\u7814\u7a76\u8bbf\u95ee\u6a21\u5f0f\u3002\u4f7f\u7528\u4e24\u4e2a\u53d7\u63a7\u5080\u5121\u8d26\u6237\u5728\u4e24\u4e2a\u9009\u4e3e\u671f\u95f4\u91cd\u5efa\u5b8c\u6574\u4fe1\u606f\u6d41\uff0c\u5e76\u5c06\u5176\u4e0e\u76f8\u5e94\u7814\u7a76API\u53ef\u68c0\u7d22\u7684\u76f8\u540c\u5e16\u5b50\u6570\u636e\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u4e09\u7c7b\u5e73\u53f0\u5f3a\u52a0\u673a\u5236\u5bfc\u81f4\u7cfb\u7edf\u6027\u6570\u636e\u4e22\u5931\uff1a\u8303\u56f4\u7f29\u5c0f\uff08\u6392\u9664\u7ea650%\u5e73\u53f0\u516c\u5171\u4fe1\u606f\u73af\u5883\uff09\u3001\u5143\u6570\u636e\u5265\u79bb\uff08\u5265\u79bb\u7ea683%\u5173\u952e\u4e0a\u4e0b\u6587\u5143\u6570\u636e\uff09\u3001\u64cd\u4f5c\u9650\u5236\uff08\u6bcf\u5929\u4ec5\u7ea61000\u6b21\u8bf7\u6c42\uff09\u3002\u8fd9\u4e9b\u8fc7\u6ee4\u5668\u4e3b\u8981\u635f\u5bb3\u6570\u636e\u5b8c\u6574\u6027\uff0c\u5bfc\u81f4\u5e73\u53f0\u6d3b\u52a8\u5448\u73b0\u7ed3\u6784\u6027\u504f\u5dee\u3002", "conclusion": "\u5f53\u524dMeta\u548cTikTok\u7814\u7a76API\u7684\u5f62\u5f0f\u65e0\u6cd5\u652f\u6301\u300a\u6570\u5b57\u670d\u52a1\u6cd5\u6848\u300b\u6240\u8bbe\u60f3\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u72ec\u7acb\u5ba1\u8ba1\u3002\u5e73\u53f0\u5b9e\u65bd\u7684\u91cd\u53e0\u8fc7\u6ee4\u5668\u5bfc\u81f4\u6570\u636e\u4e0d\u5b8c\u6574\uff0c\u963b\u788d\u4e86\u6709\u610f\u4e49\u7684\u5e73\u53f0\u76d1\u7763\u3002"}}
{"id": "2601.12707", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12707", "abs": "https://arxiv.org/abs/2601.12707", "authors": ["Junyi Liao", "Zihan Zhu", "Ethan Fang", "Zhuoran Yang", "Vahid Tarokh"], "title": "Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization", "comment": "Extended journal version of ICML 2025 paper. Submitted to Operations Research", "summary": "Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e24\u4eba\u96f6\u548c\u77e9\u9635\u535a\u5f08\u548c\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u6062\u590d\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u71b5\u6b63\u5219\u5316\u548c\u91cf\u5316\u54cd\u5e94\u5747\u8861\u89e3\u51b3\u9006\u95ee\u9898\u7684\u6a21\u7cca\u6027\u548c\u6570\u636e\u8986\u76d6\u6709\u9650\u95ee\u9898\u3002", "motivation": "\u4f30\u8ba1\u9a71\u52a8\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u672a\u77e5\u5956\u52b1\u51fd\u6570\u662f\u9006\u5f3a\u5316\u5b66\u4e60\u548c\u535a\u5f08\u8bba\u7684\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u9006\u95ee\u9898\u7684\u56fa\u6709\u6a21\u7cca\u6027\u3001\u53ef\u884c\u5956\u52b1\u7684\u975e\u552f\u4e00\u6027\u4ee5\u53ca\u89c2\u6d4b\u6570\u636e\u8986\u76d6\u6709\u9650\u7b49\u6311\u6218\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u91cf\u5316\u54cd\u5e94\u5747\u8861\u7684\u5956\u52b1\u51fd\u6570\u53ef\u8bc6\u522b\u6027\u7406\u8bba\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u9759\u6001\u548c\u52a8\u6001\u8bbe\u7f6e\u7684\u65b0\u7b97\u6cd5\uff0c\u53ef\u7ed3\u5408\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7b49\u65b9\u6cd5\uff0c\u4ece\u89c2\u6d4b\u5230\u7684\u7b56\u7565\u548c\u52a8\u4f5c\u4e2d\u5b66\u4e60\u5956\u52b1\u51fd\u6570\u3002", "result": "\u63d0\u4f9b\u4e86\u7b97\u6cd5\u7684\u53ef\u9760\u6027\u548c\u6837\u672c\u6548\u7387\u7684\u5f3a\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u6570\u503c\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e24\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u5956\u52b1\u51fd\u6570\u6062\u590d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u548c\u7b97\u6cd5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9006\u95ee\u9898\u7684\u6311\u6218\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.13026", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13026", "abs": "https://arxiv.org/abs/2601.13026", "authors": ["Jos\u00e9 Ni\u00f1o-Mora"], "title": "Multi-gear bandits, partial conservation laws, and indexability", "comment": "33 pages", "summary": "This paper considers what we propose to call multi-gear bandits, which are Markov decision processes modeling a generic dynamic and stochastic project fueled by a single resource and which admit multiple actions representing gears of operation naturally ordered by their increasing resource consumption. The optimal operation of a multi-gear bandit aims to strike a balance between project performance costs or rewards and resource usage costs, which depend on the resource price. A computationally convenient and intuitive optimal solution is available when such a model is indexable, meaning that its optimal policies are characterized by a dynamic allocation index (DAI), a function of state--action pairs representing critical resource prices. Motivated by the lack of general indexability conditions and efficient index-computing schemes, and focusing on the infinite-horizon finite-state and -action discounted case, we present a verification theorem ensuring that, if a model satisfies two proposed PCL-indexability conditions with respect to a postulated family of structured policies, then it is indexable and such policies are optimal, with its DAI being given by a marginal productivity index computed by a downshift adaptive-greedy algorithm in $A N$ steps, with $A+1$ actions and $N$ states. The DAI is further used as the basis of a new index policy for the multi-armed multi-gear bandit problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u591a\u6863\u8001\u864e\u673a\"\u6a21\u578b\uff0c\u7814\u7a76\u5728\u8d44\u6e90\u4ef7\u683c\u53d8\u5316\u4e0b\u5982\u4f55\u5e73\u8861\u9879\u76ee\u6027\u80fd\u4e0e\u8d44\u6e90\u6d88\u8017\uff0c\u5efa\u7acb\u4e86\u9a8c\u8bc1\u7d22\u5f15\u6027\u7684\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u7d22\u5f15\u8ba1\u7b97\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u901a\u7528\u7684\u7d22\u5f15\u6027\u6761\u4ef6\u548c\u9ad8\u6548\u7684\u7d22\u5f15\u8ba1\u7b97\u65b9\u6848\u3002\u591a\u6863\u8001\u864e\u673a\u6a21\u578b\u9700\u8981\u89e3\u51b3\u5728\u52a8\u6001\u8d44\u6e90\u4ef7\u683c\u4e0b\uff0c\u5982\u4f55\u6700\u4f18\u5730\u5e73\u8861\u9879\u76ee\u6027\u80fd\u6210\u672c/\u5956\u52b1\u4e0e\u8d44\u6e90\u4f7f\u7528\u6210\u672c\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faPCL-indexability\u9a8c\u8bc1\u5b9a\u7406\uff0c\u786e\u4fdd\u6a21\u578b\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\u65f6\u5177\u6709\u7d22\u5f15\u6027\u3002\u4f7f\u7528\u4e0b\u79fb\u81ea\u9002\u5e94\u8d2a\u5a6a\u7b97\u6cd5\u5728A\u00d7N\u6b65\u5185\u8ba1\u7b97\u8fb9\u9645\u751f\u4ea7\u529b\u6307\u6570\u4f5c\u4e3a\u52a8\u6001\u5206\u914d\u7d22\u5f15\u3002", "result": "\u5efa\u7acb\u4e86\u7d22\u5f15\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u7d22\u5f15\u8ba1\u7b97\u7b97\u6cd5\uff0c\u5e76\u5c06\u52a8\u6001\u5206\u914d\u7d22\u5f15\u5e94\u7528\u4e8e\u591a\u81c2\u591a\u6863\u8001\u864e\u673a\u95ee\u9898\u7684\u65b0\u7d22\u5f15\u7b56\u7565\u3002", "conclusion": "\u672c\u6587\u4e3a\u591a\u6863\u8001\u864e\u673a\u63d0\u4f9b\u4e86\u7d22\u5f15\u6027\u9a8c\u8bc1\u548c\u9ad8\u6548\u8ba1\u7b97\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u89e3\u51b3\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u52a8\u6001\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11846", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11846", "abs": "https://arxiv.org/abs/2601.11846", "authors": ["Natalia Tomashenko", "Xiaoxiao Miao", "Pierre Champion", "Sarina Meyer", "Michele Panariello", "Xin Wang", "Nicholas Evans", "Emmanuel Vincent", "Junichi Yamagishi", "Massimiliano Todisco"], "title": "The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization", "comment": "under review", "summary": "We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.", "AI": {"tldr": "2024\u5e74\u7b2c\u4e09\u5c4aVoicePrivacy\u6311\u6218\u8d5b\u7684\u7ed3\u679c\u4e0e\u5206\u6790\uff0c\u805a\u7126\u4e8e\u8bed\u97f3\u533f\u540d\u5316\u6280\u672f\uff0c\u65e8\u5728\u9690\u85cf\u8bf4\u8bdd\u4eba\u8eab\u4efd\u7684\u540c\u65f6\u4fdd\u7559\u8bed\u8a00\u5185\u5bb9\u548c\u60c5\u611f\u72b6\u6001\u3002", "motivation": "\u968f\u7740\u8bed\u97f3\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4fdd\u62a4\u8bf4\u8bdd\u4eba\u9690\u79c1\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u8bed\u97f3\u533f\u540d\u5316\u9700\u8981\u5728\u9690\u85cf\u8bf4\u8bdd\u4eba\u8eab\u4efd\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u97f3\u7684\u5b9e\u7528\u4ef7\u503c\uff08\u5185\u5bb9\u548c\u60c5\u611f\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u6311\u6218\u8d5b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u5305\u62ec\u533f\u540d\u5316\u4efb\u52a1\u5b9a\u4e49\u3001\u5f00\u53d1\u4e0e\u8bc4\u4f30\u6570\u636e\u96c6\u3001\u653b\u51fb\u6a21\u578b\u548c\u5ba2\u89c2\u8bc4\u4f30\u6307\u6807\u3002\u4ecb\u7ecd\u4e86\u516d\u4e2a\u57fa\u7ebf\u533f\u540d\u5316\u7cfb\u7edf\uff0c\u5e76\u603b\u7ed3\u4e86\u53c2\u8d5b\u8005\u63d0\u51fa\u7684\u521b\u65b0\u65b9\u6cd5\u3002", "result": "\u6311\u6218\u8d5b\u5c55\u793a\u4e86\u591a\u79cd\u8bed\u97f3\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u5b9e\u7528\u6027\u4fdd\u6301\u65b9\u9762\u7684\u8fdb\u5c55\u4e0e\u6311\u6218\u3002", "conclusion": "\u8bba\u6587\u4e3a\u672a\u6765VoicePrivacy\u6311\u6218\u8d5b\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u8bed\u97f3\u533f\u540d\u5316\u7814\u7a76\u7684\u51e0\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u5305\u62ec\u6539\u8fdb\u8bc4\u4f30\u6307\u6807\u3001\u5f00\u53d1\u66f4\u6709\u6548\u7684\u533f\u540d\u5316\u6280\u672f\u7b49\u3002"}}
{"id": "2601.11686", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11686", "abs": "https://arxiv.org/abs/2601.11686", "authors": ["Nicolas Caron", "Christophe Guyeux", "Hassan Noura", "Benjamin Aynes"], "title": "Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis", "comment": null, "summary": "Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u9884\u6d4b\u6a21\u578b\u4e0eLLM\u7684\u6df7\u5408\u6846\u67b6\uff0c\u4e3a\u91ce\u706b\u98ce\u9669\u7ba1\u7406\u751f\u6210\u7ed3\u6784\u5316\u53ef\u64cd\u4f5c\u62a5\u544a", "motivation": "\u5f53\u524d\u91ce\u706b\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u5b9e\u9645\u8fd0\u8425\u9700\u6c42\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e00\u7ebf\u5e94\u6025\u4eba\u5458\u548c\u6d88\u9632\u670d\u52a1\u7684\u5b9e\u9645\u9700\u8981\u3002\u6709\u6548\u7684\u91ce\u706b\u7ba1\u7406\u9700\u8981\u591a\u76ee\u6807\u5206\u6790\uff0c\u6db5\u76d6\u6c14\u8c61\u5371\u9669\u3001\u70b9\u706b\u6d3b\u52a8\u3001\u5e72\u9884\u590d\u6742\u6027\u548c\u8d44\u6e90\u8c03\u52a8\u7b49\u591a\u4e2a\u7ef4\u5ea6\uff0c\u800c\u975e\u4f9d\u8d56\u5355\u4e00\u9884\u6d4b\u6307\u6807\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u6846\u67b6\uff1a\u4e3a\u6bcf\u4e2a\u98ce\u9669\u7ef4\u5ea6\u5efa\u7acb\u9884\u6d4b\u6a21\u578b\uff0c\u7136\u540e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u5f02\u8d28\u8f93\u51fa\u5408\u6210\u4e3a\u7ed3\u6784\u5316\u7684\u53ef\u64cd\u4f5c\u62a5\u544a\u3002", "result": "\u8fd9\u662f\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u6846\u67b6\u8bbe\u8ba1\u4f46\u5c1a\u672a\u5c55\u793a\u5177\u4f53\u5b9e\u65bd\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u6709\u671b\u63d0\u9ad8\u91ce\u706b\u98ce\u9669\u8bc4\u4f30\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u5e94\u6025\u54cd\u5e94\u63d0\u4f9b\u66f4\u5168\u9762\u3001\u53ef\u64cd\u4f5c\u7684\u4fe1\u606f\u652f\u6301\u3002"}}
{"id": "2601.12024", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12024", "abs": "https://arxiv.org/abs/2601.12024", "authors": ["Kartikey Singh Bhandari", "Tanish Jain", "Archit Agrawal", "Dhruv Kumar", "Praveen Kumar", "Pratik Narang"], "title": "A Multi-Agent System for Generating Actionable Business Advice", "comment": null, "summary": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u5927\u89c4\u6a21\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u901a\u8fc7\u805a\u7c7b\u3001\u751f\u6210\u3001\u8fed\u4ee3\u8bc4\u4f30\u548c\u53ef\u884c\u6027\u6392\u5e8f\u63d0\u5347\u5efa\u8bae\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\uff08\u5982\u60c5\u611f\u5206\u6790\u3001\u65b9\u9762\u63d0\u53d6\uff09\u505c\u7559\u5728\u63cf\u8ff0\u6027\u4efb\u52a1\uff0c\u800cLLM\u751f\u6210\u7684\u5efa\u8bae\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u6df1\u5ea6\u63a8\u7406\uff0c\u9700\u8981\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u5546\u4e1a\u5efa\u8bae\u3002", "method": "\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a\u805a\u7c7b\u9009\u62e9\u4ee3\u8868\u6027\u8bc4\u8bba\u3001\u5efa\u8bae\u751f\u6210\u3001\u8fed\u4ee3\u8bc4\u4f30\u3001\u57fa\u4e8e\u53ef\u884c\u6027\u7684\u6392\u5e8f\uff0c\u7ed3\u5408\u8bed\u6599\u5e93\u63d0\u70bc\u548c\u53cd\u9988\u9a71\u52a8\u7684\u5efa\u8bae\u4f18\u5316\u3002", "result": "\u5728\u4e09\u4e2a\u670d\u52a1\u9886\u57df\u548c\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u53ef\u64cd\u4f5c\u6027\u3001\u5177\u4f53\u6027\u548c\u975e\u5197\u4f59\u6027\u4e0a\u6301\u7eed\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\uff0c\u4e2d\u578b\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u5927\u578b\u6a21\u578b\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u5927\u89c4\u6a21\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u3001\u53ef\u64cd\u4f5c\u4e14\u5b9e\u7528\u7684\u5546\u4e1a\u5efa\u8bae\uff0c\u4e3a\u57fa\u4e8e\u8bc4\u8bba\u7684\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12782", "categories": ["eess.SY", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.12782", "abs": "https://arxiv.org/abs/2601.12782", "authors": ["Ming Li", "Fan Liu", "Yifeng Xiong", "Jie Xu", "Tao Liu"], "title": "Sensing-Limited Control of Noiseless Linear Systems Under Nonlinear Observations", "comment": "5 pages, conference", "summary": "This paper investigates the fundamental information-theoretic limits for the control and sensing of noiseless linear dynamical systems subject to a broad class of nonlinear observations. We analyze the interactions between the control and sensing components by characterizing the minimum information flow required for stability. Specifically, we derive necessary conditions for mean-square observability and stabilizability, demonstrating that the average directed information rate from the state to the observations must exceed the intrinsic expansion rate of the unstable dynamics. Furthermore, to address the challenges posed by non-Gaussian distributions inherent to nonlinear observation channels, we establish sufficient conditions by imposing regularity assumptions, specifically log-concavity, on the system's probabilistic components. We show that under these conditions, the divergence of differential entropy implies the convergence of the estimation error, thereby closing the gap between information-theoretic bounds and estimation performance. By establishing these results, we unveil the fundamental performance limits imposed by the sensing layer, extending classical data-rate constraints to the more challenging regime of nonlinear observation models.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u975e\u7ebf\u6027\u89c2\u6d4b\u4e0b\u65e0\u566a\u58f0\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u63a7\u5236\u4e0e\u611f\u77e5\u7684\u57fa\u672c\u4fe1\u606f\u8bba\u6781\u9650\uff0c\u63ed\u793a\u4e86\u72b6\u6001\u5230\u89c2\u6d4b\u7684\u5e73\u5747\u5b9a\u5411\u4fe1\u606f\u7387\u5fc5\u987b\u8d85\u8fc7\u4e0d\u7a33\u5b9a\u52a8\u529b\u5b66\u7684\u5185\u5728\u6269\u5f20\u7387\u624d\u80fd\u4fdd\u8bc1\u7a33\u5b9a\u6027\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u975e\u7ebf\u6027\u89c2\u6d4b\u6a21\u578b\u4e0b\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u63a7\u5236\u4e0e\u611f\u77e5\u7684\u57fa\u672c\u6027\u80fd\u6781\u9650\uff0c\u5c06\u7ecf\u5178\u6570\u636e\u7387\u7ea6\u675f\u6269\u5c55\u5230\u66f4\u5177\u6311\u6218\u6027\u7684\u975e\u7ebf\u6027\u89c2\u6d4b\u573a\u666f\uff0c\u63a2\u7d22\u63a7\u5236\u4e0e\u611f\u77e5\u7ec4\u4ef6\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\uff0c\u5206\u6790\u975e\u7ebf\u6027\u89c2\u6d4b\u901a\u9053\u4e0b\u7684\u65e0\u566a\u58f0\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u3002\u901a\u8fc7\u63a8\u5bfc\u5747\u65b9\u53ef\u89c2\u6027\u548c\u53ef\u7a33\u5b9a\u6027\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u5bf9\u6570\u51f9\u6027\u7b49\u6b63\u5219\u6027\u5047\u8bbe\u6765\u5efa\u7acb\u5145\u5206\u6761\u4ef6\uff0c\u8fde\u63a5\u4fe1\u606f\u8bba\u754c\u9650\u4e0e\u4f30\u8ba1\u6027\u80fd\u3002", "result": "\u8bc1\u660e\u4e86\u72b6\u6001\u5230\u89c2\u6d4b\u7684\u5e73\u5747\u5b9a\u5411\u4fe1\u606f\u7387\u5fc5\u987b\u8d85\u8fc7\u4e0d\u7a33\u5b9a\u52a8\u529b\u5b66\u7684\u5185\u5728\u6269\u5f20\u7387\u662f\u7cfb\u7edf\u7a33\u5b9a\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u5728\u5bf9\u6570\u51f9\u6027\u5047\u8bbe\u4e0b\uff0c\u5fae\u5206\u71b5\u7684\u53d1\u6563\u610f\u5473\u7740\u4f30\u8ba1\u8bef\u5dee\u7684\u6536\u655b\uff0c\u4ece\u800c\u95ed\u5408\u4e86\u4fe1\u606f\u8bba\u754c\u9650\u4e0e\u4f30\u8ba1\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u611f\u77e5\u5c42\u65bd\u52a0\u7684\u57fa\u672c\u6027\u80fd\u6781\u9650\uff0c\u5c06\u7ecf\u5178\u6570\u636e\u7387\u7ea6\u675f\u6269\u5c55\u5230\u975e\u7ebf\u6027\u89c2\u6d4b\u6a21\u578b\uff0c\u4e3a\u975e\u7ebf\u6027\u89c2\u6d4b\u4e0b\u7684\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6027\u80fd\u754c\u9650\u3002"}}
{"id": "2601.12931", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.12931", "abs": "https://arxiv.org/abs/2601.12931", "authors": ["Edoardo Urettini", "Daniele Atzeni", "Ioanna-Yvonni Tsaknaki", "Antonio Carta"], "title": "Online Continual Learning for Time Series: a Natural Score-driven Approach", "comment": null, "summary": "Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faNatSR\u65b9\u6cd5\uff0c\u5c06\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u5e94\u7528\u4e8e\u5728\u7ebf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u901a\u8fc7\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u4e0e\u91cd\u653e\u7f13\u51b2\u7ed3\u5408\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u548c\u957f\u671f\u8bb0\u5fc6\u3002", "motivation": "\u5728\u7ebf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9700\u8981\u540c\u65f6\u5177\u5907\u5feb\u901f\u9002\u5e94\u73af\u5883\u53d8\u5316\u548c\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u8fd9\u4e0e\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u7684\u76ee\u6807\u9ad8\u5ea6\u4e00\u81f4\u3002\u73b0\u6709\u7814\u7a76\u5df2\u521d\u6b65\u5c06OCL\u5e94\u7528\u4e8eOTSF\uff0c\u4f46\u7406\u8bba\u548c\u5b9e\u8df5\u8fde\u63a5\u4ecd\u9700\u52a0\u5f3a\u3002", "method": "1) \u5c06\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u91cd\u6784\u4e3a\u53c2\u6570\u6ee4\u6ce2\u95ee\u9898\uff0c\u8bc1\u660e\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u662f\u5206\u6570\u9a71\u52a8\u65b9\u6cd5\u5e76\u8bc1\u660e\u5176\u4fe1\u606f\u7406\u8bba\u6700\u4f18\u6027\uff1b2) \u4f7f\u7528Student's t\u4f3c\u7136\u7ed3\u5408\u81ea\u7136\u68af\u5ea6\u5b9e\u73b0\u6709\u754c\u66f4\u65b0\uff0c\u63d0\u9ad8\u5bf9\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\uff1b3) \u63d0\u51faNatSR\u65b9\u6cd5\uff0c\u7ed3\u5408\u9c81\u68d2\u4f18\u5316\u5668\u3001\u91cd\u653e\u7f13\u51b2\u548c\u52a8\u6001\u5c3a\u5ea6\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u5728\u673a\u5236\u6f02\u79fb\u65f6\u6539\u5584\u5feb\u901f\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cNatSR\u6bd4\u66f4\u590d\u6742\u7684\u73b0\u6709\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u5f3a\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u5316\u4e86\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u4e0e\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u4e4b\u95f4\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u8054\u7cfb\uff0c\u63d0\u51fa\u7684NatSR\u65b9\u6cd5\u5728\u5728\u7ebf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u4e0e\u5206\u6570\u9a71\u52a8\u65b9\u6cd5\u7684\u7b49\u4ef7\u6027\u53ca\u5176\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.13027", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13027", "abs": "https://arxiv.org/abs/2601.13027", "authors": ["Zixin Deng", "Zheng-Hai Huang", "Yun-Bin Zhao"], "title": "Optimality Conditions for Sparse Bilinear Least Squares Problems", "comment": null, "summary": "The first-order optimality conditions of sparse bilinear least squares problems are studied. The so-called T-type and N-type stationary points for this problem are characterized in terms of tangent cone and normal cone in Bouligand and Clarke senses, and another stationarity concept called the coordinate-wise minima is introduced and discussed. Moreover, the L-like stationary point for this problem is introduced and analyzed through the newly introduced concept of like-projection, and the M-stationary point is also investigated via a complementarity-type reformulation of the problem. The relationship between these stationary points is discussed as well. It turns out that all stationary points discussed in this work satisfy the necessary optimality conditions for the sparse bilinear least squares problem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u7a00\u758f\u53cc\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u4e00\u9636\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5206\u6790\u4e86\u591a\u79cd\u9a7b\u70b9\u6982\u5ff5\uff08T\u578b\u3001N\u578b\u3001\u5750\u6807\u6781\u5c0f\u3001L\u578b\u3001M\u578b\uff09\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u7a00\u758f\u53cc\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u4e3a\u8fd9\u7c7b\u975e\u51f8\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u7406\u8bba\u5206\u6790\u57fa\u7840\uff0c\u5e2e\u52a9\u7406\u89e3\u4e0d\u540c\u9a7b\u70b9\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7Bouligand\u548cClarke\u610f\u4e49\u4e0b\u7684\u5207\u9525\u4e0e\u6cd5\u9525\u523b\u753bT\u578b\u548cN\u578b\u9a7b\u70b9\uff1b\u5f15\u5165\u5750\u6807\u6781\u5c0f\u6982\u5ff5\uff1b\u901a\u8fc7\u65b0\u5b9a\u4e49\u7684\u7c7b\u6295\u5f71\u6982\u5ff5\u5206\u6790L\u578b\u9a7b\u70b9\uff1b\u901a\u8fc7\u4e92\u8865\u578b\u91cd\u6784\u7814\u7a76M\u578b\u9a7b\u70b9\u3002", "result": "\u6240\u6709\u8ba8\u8bba\u7684\u9a7b\u70b9\u7c7b\u578b\uff08T\u578b\u3001N\u578b\u3001\u5750\u6807\u6781\u5c0f\u3001L\u578b\u3001M\u578b\uff09\u90fd\u6ee1\u8db3\u7a00\u758f\u53cc\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u5fc5\u8981\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u5e76\u5efa\u7acb\u4e86\u8fd9\u4e9b\u9a7b\u70b9\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u7a00\u758f\u53cc\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\u7684\u591a\u79cd\u4e00\u9636\u9a7b\u70b9\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86\u5b83\u4eec\u90fd\u6ee1\u8db3\u5fc5\u8981\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u4e3a\u8fd9\u7c7b\u95ee\u9898\u7684\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.11854", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11854", "abs": "https://arxiv.org/abs/2601.11854", "authors": ["Yifei Zhang", "Hooshang Nayyeri", "Rinat Khaziev", "Emine Yilmaz", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Hari Thadakamalla"], "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System", "comment": null, "summary": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.", "AI": {"tldr": "ATOD\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u9ad8\u7ea7\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5408\u6210\u5bf9\u8bdd\u751f\u6210\u6846\u67b6\uff0c\u5305\u542bATOD-Eval\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8bc4\u4f30\u5668\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u591a\u76ee\u6807\u534f\u8c03\u3001\u957f\u671f\u63a8\u7406\u7b49\u667a\u80fd\u4f53\u884c\u4e3a\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u5df2\u7ecf\u5177\u5907\u591a\u76ee\u6807\u534f\u8c03\u3001\u957f\u671f\u4e0a\u4e0b\u6587\u4fdd\u6301\u548c\u4e3b\u52a8\u6267\u884c\u7b49\u9ad8\u7ea7\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u652f\u6301\u3002", "method": "1) \u63d0\u51faATOD\u57fa\u51c6\u6d4b\u8bd5\u548c\u5408\u6210\u5bf9\u8bdd\u751f\u6210\u7ba1\u9053\uff0c\u751f\u6210\u9700\u8981\u957f\u671f\u63a8\u7406\u7684\u4e30\u5bcc\u6807\u6ce8\u5bf9\u8bdd\uff1b2) \u57fa\u4e8eATOD\u5f00\u53d1ATOD-Eval\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u9ad8\u7ea7\u5bf9\u8bdd\u7279\u5f81\u8f6c\u5316\u4e3a\u7ec6\u7c92\u5ea6\u6307\u6807\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u8bb0\u5fc6\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u5668\u7528\u4e8eATOD\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "ATOD-Eval\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u5ea6\u3001\u667a\u80fd\u4f53\u80fd\u529b\u548c\u54cd\u5e94\u8d28\u91cf\uff1b\u63d0\u51fa\u7684\u8bc4\u4f30\u5668\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6743\u8861\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8bb0\u5fc6\u548cLLM\u7684\u65b9\u6cd5\u3002", "conclusion": "ATOD\u586b\u8865\u4e86\u9ad8\u7ea7\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u7a7a\u767d\uff0cATOD-Eval\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8bc4\u4f30\u5668\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11719", "categories": ["cs.LG", "hep-ex"], "pdf": "https://arxiv.org/pdf/2601.11719", "abs": "https://arxiv.org/abs/2601.11719", "authors": ["Ho Fung Tsoi", "Dylan Rankin"], "title": "jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation", "comment": "Under review", "summary": "Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.", "AI": {"tldr": "jBOT\u662f\u4e00\u79cd\u7528\u4e8eLHC\u55b7\u6ce8\u6570\u636e\u7684\u81ea\u84b8\u998f\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c40\u90e8\u7c92\u5b50\u7ea7\u548c\u5168\u5c40\u55b7\u6ce8\u7ea7\u84b8\u998f\uff0c\u5728\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u5b66\u4e60\u8868\u5f81\uff0c\u652f\u6301\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\u3002", "motivation": "\u81ea\u76d1\u7763\u5b66\u4e60\u80fd\u591f\u4ece\u65e0\u6807\u7b7e\u6570\u636e\u4e2d\u5b66\u4e60\u901a\u7528\u8bed\u4e49\u7279\u5f81\u8868\u793a\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u7c92\u5b50\u7269\u7406\u4e2d\u7684\u55b7\u6ce8\u6570\u636e\u5f00\u53d1\u4e13\u95e8\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u5982\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u3002", "method": "\u63d0\u51fajBOT\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u81ea\u84b8\u998f\u6280\u672f\uff0c\u7ed3\u5408\u5c40\u90e8\u7c92\u5b50\u7ea7\u84b8\u998f\u548c\u5168\u5c40\u55b7\u6ce8\u7ea7\u84b8\u998f\u6765\u5b66\u4e60\u55b7\u6ce8\u8868\u5f81\u3002\u5728\u4ec5\u4f7f\u7528\u80cc\u666f\u55b7\u6ce8\u7684\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u9884\u8bad\u7ec3\u5bfc\u81f4\u8868\u5f81\u7a7a\u95f4\u4e2d\u51fa\u73b0\u8bed\u4e49\u7c7b\u522b\u805a\u7c7b\u73b0\u8c61\u3002\u51bb\u7ed3\u5d4c\u5165\u4e2d\u7684\u805a\u7c7b\u652f\u6301\u57fa\u4e8e\u7b80\u5355\u8ddd\u79bb\u5ea6\u91cf\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u5b66\u4e60\u5230\u7684\u5d4c\u5165\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u76d1\u7763\u6a21\u578b\u3002", "conclusion": "jBOT\u65b9\u6cd5\u901a\u8fc7\u81ea\u84b8\u998f\u9884\u8bad\u7ec3\u6709\u6548\u5b66\u4e60\u55b7\u6ce8\u8868\u5f81\uff0c\u5728\u65e0\u6807\u7b7e\u6570\u636e\u4e0a\u5b9e\u73b0\u8bed\u4e49\u805a\u7c7b\uff0c\u4e3a\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u5f3a\u5927\u57fa\u7840\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u65b9\u6cd5\u3002"}}
{"id": "2601.12030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12030", "abs": "https://arxiv.org/abs/2601.12030", "authors": ["Yilun Yao", "Shan Huang", "Elsie Dai", "Zhewen Tan", "Zhenyu Duan", "Shousheng Jia", "Yanbing Jiang", "Tong Yang"], "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents", "comment": "15 pages, 5 figures", "summary": "Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.", "AI": {"tldr": "ARC\u6846\u67b6\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u91cd\u6784\u4e3a\u4e3b\u52a8\u3001\u53cd\u601d\u9a71\u52a8\u7684\u52a8\u6001\u63a8\u7406\u72b6\u6001\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3a\u9759\u6001\u5de5\u4ef6\uff0c\u901a\u8fc7\u539f\u59cb\u79ef\u7d2f\u6216\u88ab\u52a8\u6458\u8981\u8fdb\u884c\u7ba1\u7406\uff0c\u5bfc\u81f4\u65e9\u671f\u9519\u8bef\u6216\u9519\u8bef\u5f3a\u8c03\u6301\u7eed\u5b58\u5728\uff0c\u968f\u7740\u4ea4\u4e92\u5386\u53f2\u589e\u957f\u51fa\u73b0\u6027\u80fd\u9000\u5316\uff08\u4e0a\u4e0b\u6587\u8150\u5316\uff09", "method": "\u63d0\u51faARC\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u5f62\u5f0f\u5316\u4e3a\u4e3b\u52a8\u3001\u53cd\u601d\u9a71\u52a8\u7684\u8fc7\u7a0b\uff0c\u901a\u8fc7\u53cd\u601d\u9a71\u52a8\u7684\u76d1\u63a7\u548c\u4fee\u8ba2\u673a\u5236\uff0c\u5728\u68c0\u6d4b\u5230\u9519\u4f4d\u6216\u9000\u5316\u65f6\u4e3b\u52a8\u91cd\u7ec4\u5de5\u4f5c\u4e0a\u4e0b\u6587", "result": "\u5728\u6311\u6218\u6027\u7684\u957f\u65f6\u7a0b\u4fe1\u606f\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARC\u59cb\u7ec8\u4f18\u4e8e\u88ab\u52a8\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\uff0c\u5728BrowseComp-ZH\u4e0a\u4f7f\u7528Qwen2.5-32B-Instruct\u5b9e\u73b0\u4e86\u9ad8\u8fbe11%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347", "conclusion": "\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3a\u52a8\u6001\u5185\u90e8\u63a8\u7406\u72b6\u6001\u5e76\u901a\u8fc7\u4e3b\u52a8\u53cd\u601d\u8fdb\u884c\u7ba1\u7406\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898"}}
{"id": "2601.12840", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12840", "abs": "https://arxiv.org/abs/2601.12840", "authors": ["Yuji Sakamoto", "Junichi Kurihara", "Shinya Fujita", "Yuji Sato", "Toshinori Kuwahara"], "title": "Lessons Learned from Structural Design and Vibration Testing of 50-kg Microsatellites Deployed from the International Space Station", "comment": "8 pages, 17 figures, 6 tables. ISTS 33rd, February 26-March 4, 2022", "summary": "Hokkaido University and Tohoku University have been developing and operating a constellation of 50-cm-class microsatellites for Earth observation. DIWATA-1, launched in 2016, was deployed into a circular orbit at an altitude of approximately 400 km from the International Space Station (ISS). For the subsequent satellite developed in 2021, the structural design and vibration test campaign were optimized to meet a strict one-year development schedule. This paper summarizes how the structural design of the previous satellite was reviewed and updated, and how the vibration test was successfully completed in a single trial to minimize schedule and technical risks. These lessons learned provide valuable insights, as there are only a limited number of reported cases of 50-kg-class microsatellites deployed from the ISS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u4e3a\u6ee1\u8db3\u4e25\u683c\u7684\u4e00\u5e74\u5f00\u53d1\u5468\u671f\uff0c\u5982\u4f55\u4f18\u531650\u516c\u65a4\u7ea7\u5fae\u536b\u661f\u7684\u7ed3\u6784\u8bbe\u8ba1\u548c\u632f\u52a8\u6d4b\u8bd5\uff0c\u6210\u529f\u5b9e\u73b0\u5355\u6b21\u8bd5\u9a8c\u901a\u8fc7\uff0c\u4e3aISS\u90e8\u7f72\u7684\u5fae\u536b\u661f\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7ecf\u9a8c\u3002", "motivation": "\u5317\u6d77\u9053\u5927\u5b66\u548c\u4e1c\u5317\u5927\u5b66\u4e00\u76f4\u5728\u5f00\u53d1\u548c\u8fd0\u842550\u5398\u7c73\u7ea7\u5fae\u536b\u661f\u661f\u5ea7\u8fdb\u884c\u5730\u7403\u89c2\u6d4b\u3002DIWATA-1\u4e8e2016\u5e74\u53d1\u5c04\uff0c\u90e8\u7f72\u5728ISS\u7ea6400\u516c\u91cc\u7684\u5706\u5f62\u8f68\u9053\u4e0a\u3002\u540e\u7eed\u536b\u661f\u9700\u8981\u5728\u4e00\u5e74\u5185\u5b8c\u6210\u5f00\u53d1\uff0c\u9762\u4e34\u4e25\u683c\u7684\u65f6\u95f4\u9650\u5236\u548c\u6280\u672f\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4eceISS\u90e8\u7f72\u768450\u516c\u65a4\u7ea7\u5fae\u536b\u661f\uff0c\u76f8\u5173\u6848\u4f8b\u62a5\u9053\u6709\u9650\u3002", "method": "\u8bba\u6587\u603b\u7ed3\u4e86\u5982\u4f55\u5ba1\u67e5\u548c\u66f4\u65b0\u5148\u524d\u536b\u661f\u7684\u7ed3\u6784\u8bbe\u8ba1\uff0c\u5e76\u4f18\u5316\u632f\u52a8\u6d4b\u8bd5\u65b9\u6848\u3002\u901a\u8fc7\u7ed3\u6784\u8bbe\u8ba1\u4f18\u5316\u548c\u6d4b\u8bd5\u7b56\u7565\u8c03\u6574\uff0c\u6210\u529f\u5728\u5355\u6b21\u8bd5\u9a8c\u4e2d\u5b8c\u6210\u632f\u52a8\u6d4b\u8bd5\uff0c\u4ee5\u6700\u5c0f\u5316\u8fdb\u5ea6\u548c\u6280\u672f\u98ce\u9669\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u4e25\u683c\u7684\u4e00\u5e74\u5f00\u53d1\u5468\u671f\u5185\u5b8c\u6210\u536b\u661f\u7ed3\u6784\u8bbe\u8ba1\u548c\u6d4b\u8bd5\uff0c\u632f\u52a8\u6d4b\u8bd5\u4e00\u6b21\u901a\u8fc7\uff0c\u6709\u6548\u63a7\u5236\u4e86\u8fdb\u5ea6\u548c\u6280\u672f\u98ce\u9669\uff0c\u4e3aISS\u90e8\u7f72\u768450\u516c\u65a4\u7ea7\u5fae\u536b\u661f\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002", "conclusion": "\u8fd9\u4e9b\u7ecf\u9a8c\u6559\u8bad\u4e3a50\u516c\u65a4\u7ea7\u5fae\u536b\u661f\u4eceISS\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u6280\u672f\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u4e25\u683c\u65f6\u95f4\u9650\u5236\u4e0b\u7684\u7ed3\u6784\u8bbe\u8ba1\u548c\u6d4b\u8bd5\u4f18\u5316\u7b56\u7565\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u6848\u4f8b\u62a5\u9053\u6709\u9650\u7684\u7a7a\u767d\u3002"}}
{"id": "2601.12646", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12646", "abs": "https://arxiv.org/abs/2601.12646", "authors": ["Ha-Chi Tran"], "title": "Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI", "comment": null, "summary": "The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u73b0\u6709AI\u8d23\u4efb\u5236\u5ea6\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u8de8\u5883AI\u98ce\u9669\uff0c\u9700\u501f\u9274\u5176\u4ed6\u9ad8\u98ce\u9669\u8de8\u56fd\u9886\u57df\u7684\u8d23\u4efb\u6846\u67b6\uff0c\u6784\u5efa\u5168\u7403AI\u95ee\u8d23\u4e0e\u8865\u507f\u67b6\u6784\u3002", "motivation": "\u5f53\u524dAI\u98ce\u9669\u6cbb\u7406\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5728\u4e8b\u540e\u8d23\u4efb\u65b9\u9762\u3002\u73b0\u6709\u8d23\u4efb\u5236\u5ea6\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8de8\u5883AI\u5371\u5bb3\uff0c\u6838\u5fc3\u6cd5\u5f8b\u95ee\u9898\u5982\u8d23\u4efb\u5206\u914d\u3001\u5f52\u8d23\u548c\u6551\u6d4e\u6548\u679c\u7b49\u7f3a\u4e4f\u5145\u5206\u7406\u8bba\u5316\u548c\u5236\u5ea6\u5316\u3002", "method": "\u91c7\u7528\u6bd4\u8f83\u548c\u8de8\u5b66\u79d1\u65b9\u6cd5\uff0c\u5206\u6790\u75ab\u82d7\u4f24\u5bb3\u8ba1\u5212\u3001\u7cfb\u7edf\u6027\u91d1\u878d\u98ce\u9669\u6cbb\u7406\u3001\u5546\u4e1a\u6838\u8d23\u4efb\u548c\u56fd\u9645\u73af\u5883\u5236\u5ea6\u7b49\u9ad8\u98ce\u9669\u8de8\u56fd\u9886\u57df\u7684\u8865\u507f\u4e0e\u8d23\u4efb\u6846\u67b6\uff0c\u63d0\u70bc\u53ef\u8f6c\u79fb\u7684\u6cd5\u5f8b\u8bbe\u8ba1\u539f\u5219\u3002", "result": "\u8bc6\u522b\u51fa\u4e25\u683c\u8d23\u4efb\u3001\u98ce\u9669\u6c60\u5316\u3001\u96c6\u4f53\u98ce\u9669\u5206\u62c5\u548c\u8d23\u4efb\u6e20\u9053\u5316\u7b49\u53ef\u5e94\u7528\u4e8eAI\u5371\u5bb3\u7684\u6cd5\u5f8b\u8bbe\u8ba1\u539f\u5219\uff0c\u540c\u65f6\u6307\u51fa\u5176\u5728AI\u9886\u57df\u5e94\u7528\u7684\u7ed3\u6784\u6027\u9650\u5236\u3002", "conclusion": "\u5728AI\u519b\u5907\u7ade\u8d5b\u800c\u975e\u5408\u4f5c\u6cbb\u7406\u4e3b\u5bfc\u7684\u56fd\u9645\u79e9\u5e8f\u4e2d\uff0c\u9700\u8981\u6784\u5efa\u5168\u7403AI\u95ee\u8d23\u4e0e\u8865\u507f\u67b6\u6784\uff0c\u5e73\u8861\u5730\u7f18\u653f\u6cbb\u7ade\u4e89\u4e0e\u6709\u6548\u6cbb\u7406\u8de8\u5883AI\u98ce\u9669\u6240\u9700\u7684\u96c6\u4f53\u884c\u52a8\u3002"}}
{"id": "2601.13272", "categories": ["cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13272", "abs": "https://arxiv.org/abs/2601.13272", "authors": ["Aaron Pim", "Tristan Pryer"], "title": "Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification", "comment": "26 pages, 11 figures", "summary": "We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u7684dropout\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u7528dropout\u63a9\u7801\u6784\u5efa\u8026\u5408\u7c97-\u7ec6\u4f30\u8ba1\u5668\uff0c\u964d\u4f4e\u65b9\u5dee\u5e76\u63d0\u5347\u8ba1\u7b97\u6548\u7387", "motivation": "\u8499\u7279\u5361\u6d1bdropout\u662f\u6df1\u5ea6\u5b66\u4e60\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u5927\u91cf\u524d\u5411\u4f20\u64ad\u6765\u4f30\u8ba1\u9884\u6d4b\u77e9\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u6765\u63d0\u5347\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6548\u7387\u3002", "method": "\u5c06dropout\u63a9\u7801\u4f5c\u4e3a\u8ba4\u77e5\u968f\u673a\u6027\u6765\u6e90\uff0c\u901a\u8fc7\u524d\u5411\u4f20\u64ad\u6b21\u6570\u5b9a\u4e49\u4fdd\u771f\u5ea6\u5c42\u6b21\u7ed3\u6784\u3002\u91cd\u7528\u4e0d\u540c\u4fdd\u771f\u5ea6\u95f4\u7684dropout\u63a9\u7801\u6784\u5efa\u8026\u5408\u7c97-\u7ec6\u4f30\u8ba1\u5668\uff0c\u5f62\u6210\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u4f38\u7f29\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u9884\u6d4b\u5747\u503c\u548c\u65b9\u5dee\u4f30\u8ba1\u3002", "result": "\u63a8\u5bfc\u4e86\u504f\u5dee\u3001\u65b9\u5dee\u548c\u6709\u6548\u6210\u672c\u8868\u8fbe\u5f0f\uff0c\u4ee5\u53ca\u5c42\u7ea7\u95f4\u7684\u6837\u672c\u5206\u914d\u89c4\u5219\u3002\u5728\u6b63\u5411\u548c\u9006\u5411PINNs-Uzawa\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u9884\u6d4b\u65b9\u5dee\u7387\uff0c\u5728\u76f8\u540c\u8ba1\u7b97\u6210\u672c\u4e0b\u76f8\u6bd4\u5355\u7ea7MC-dropout\u83b7\u5f97\u4e86\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u591a\u7ea7\u8499\u7279\u5361\u6d1bdropout\u6846\u67b6\u80fd\u591f\u4fdd\u6301dropout\u8bf1\u5bfc\u91cf\u7684\u65e0\u504f\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u663e\u8457\u63d0\u5347\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.13045", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13045", "abs": "https://arxiv.org/abs/2601.13045", "authors": ["Jos\u00e9 Ni\u00f1o-Mora"], "title": "Markovian restless bandits and index policies: A review", "comment": "33 pages", "summary": "The restless multi-armed bandit problem is a paradigmatic modeling framework for optimal dynamic priority allocation in stochastic models of wide-ranging applications that has been widely investigated and applied since its inception in a seminal paper by Whittle in the late 1980s. The problem has generated a vast and fast-growing literature from which a significant sample is thematically organized and reviewed in this paper. While the main focus is on priority-index policies due to their intuitive appeal, tractability, asymptotic optimality properties, and often strong empirical performance, other lines of work are also reviewed. Theoretical and algorithmic developments are discussed, along with diverse applications. The main goals are to highlight the remarkable breadth of work that has been carried out on the topic and to stimulate further research in the field.", "AI": {"tldr": "\u672c\u6587\u5bf9\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\u7684\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u4f18\u5148\u7ea7\u7d22\u5f15\u7b56\u7565\u53ca\u5176\u5728\u52a8\u6001\u4f18\u5148\u7ea7\u5206\u914d\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\u81eaWhittle\u57281980\u5e74\u4ee3\u63d0\u51fa\u4ee5\u6765\uff0c\u5df2\u6210\u4e3a\u968f\u673a\u6a21\u578b\u4e2d\u52a8\u6001\u4f18\u5148\u7ea7\u5206\u914d\u7684\u5178\u8303\u6846\u67b6\uff0c\u5728\u5e7f\u6cdb\u7684\u5e94\u7528\u9886\u57df\u4e2d\u4ea7\u751f\u4e86\u5927\u91cf\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u5bf9\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u68b3\u7406\uff0c\u7a81\u51fa\u5176\u7814\u7a76\u5e7f\u5ea6\uff0c\u5e76\u6fc0\u53d1\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf9\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\u7684\u76f8\u5173\u6587\u732e\u8fdb\u884c\u4e3b\u9898\u6027\u7ec4\u7ec7\u548c\u8bc4\u8ff0\u3002\u4e3b\u8981\u5173\u6ce8\u4f18\u5148\u7ea7\u7d22\u5f15\u7b56\u7565\uff0c\u540c\u65f6\u4e5f\u56de\u987e\u5176\u4ed6\u7814\u7a76\u65b9\u5411\uff0c\u8ba8\u8bba\u7406\u8bba\u53d1\u5c55\u548c\u7b97\u6cd5\u8fdb\u5c55\uff0c\u5e76\u6db5\u76d6\u591a\u6837\u5316\u7684\u5e94\u7528\u9886\u57df\u3002", "result": "\u7cfb\u7edf\u6027\u5730\u6574\u7406\u4e86\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u5c55\u793a\u4e86\u8be5\u9886\u57df\u7814\u7a76\u7684\u5e7f\u5ea6\u548c\u6df1\u5ea6\uff0c\u5f3a\u8c03\u4e86\u4f18\u5148\u7ea7\u7d22\u5f15\u7b56\u7565\u5728\u76f4\u89c2\u6027\u3001\u53ef\u5904\u7406\u6027\u3001\u6e10\u8fd1\u6700\u4f18\u6027\u548c\u5b9e\u8bc1\u6027\u80fd\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\u662f\u4e00\u4e2a\u6d3b\u8dc3\u4e14\u91cd\u8981\u7684\u7814\u7a76\u9886\u57df\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u7406\u8bba\u548c\u5e94\u7528\u4ef7\u503c\u3002\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\u5c55\u793a\u4e86\u8be5\u9886\u57df\u7684\u4e30\u5bcc\u7814\u7a76\u6210\u679c\uff0c\u5e76\u671f\u671b\u80fd\u591f\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2601.11865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11865", "abs": "https://arxiv.org/abs/2601.11865", "authors": ["Truong Nguyen", "Phi Van Dat", "Ngan Nguyen", "Linh Ngo Van", "Trung Le", "Thanh Hong Nguyen"], "title": "CTPD: Cross Tokenizer Preference Distillation", "comment": "AAAI 2026", "summary": "While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.", "AI": {"tldr": "CTPD\u662f\u9996\u4e2a\u5728\u5f02\u6784\u5206\u8bcd\u5668\u6a21\u578b\u95f4\u8f6c\u79fb\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u884c\u4e3a\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5b57\u7b26\u7ea7\u5bf9\u9f50\u3001\u91cd\u8981\u6027\u91c7\u6837\u548c\u6559\u5e08\u951a\u5b9a\u53c2\u8003\u5b9e\u73b0\u8de8\u5206\u8bcd\u5668\u7684\u504f\u597d\u84b8\u998f\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\u5728\u9884\u8bad\u7ec3\u548c\u6307\u4ee4\u8c03\u4f18\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u7684\u5e94\u7528\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u66f4\u73b0\u5b9e\u7684\u8de8\u5206\u8bcd\u5668\u573a\u666f\u4e2d\u3002\u4e0d\u540c\u5206\u8bcd\u65b9\u6848\u7684\u4e0d\u517c\u5bb9\u6027\u963b\u788d\u4e86\u504f\u597d\u4fe1\u606f\u7684\u7ec6\u7c92\u5ea6\u767d\u76d2\u84b8\u998f\u3002", "method": "\u63d0\u51fa\u8de8\u5206\u8bcd\u5668\u504f\u597d\u84b8\u998f\uff08CTPD\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u5bf9\u9f50\u8de8\u5ea6\u6295\u5f71\uff0c\u5c06\u5e08\u751f\u6a21\u578b\u7684token\u6620\u5c04\u5230\u5171\u4eab\u7684\u5b57\u7b26\u7ea7\u8de8\u5ea6\uff1b2\uff09\u8de8\u5206\u8bcd\u5668\u7248\u672c\u7684token\u7ea7\u91cd\u8981\u6027\u91c7\u6837\uff08TIS-DPO\uff09\uff1b3\uff09\u6559\u5e08\u951a\u5b9a\u53c2\u8003\uff0c\u8ba9\u5b66\u751f\u6a21\u578b\u5728DPO\u98ce\u683c\u76ee\u6807\u4e2d\u76f4\u63a5\u5229\u7528\u6559\u5e08\u7684\u504f\u597d\u3002", "result": "\u7406\u8bba\u5206\u6790\u5c06CTPD\u5efa\u7acb\u5728\u91cd\u8981\u6027\u91c7\u6837\u57fa\u7840\u4e0a\uff0c\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CTPD\u4e3a\u4e0d\u540c\u5206\u8bcd\u65b9\u6848\u95f4\u7684\u504f\u597d\u84b8\u998f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u66f4\u6613\u83b7\u53d6\u548c\u9ad8\u6548\u7684\u5bf9\u9f50\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2601.11789", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11789", "abs": "https://arxiv.org/abs/2601.11789", "authors": ["Shenyang Deng", "Boyao Liao", "Zhuoli Ouyang", "Tianyu Pang", "Minhak Song", "Yaoqing Yang"], "title": "Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis", "comment": "The 37th International Conference on Algorithmic Learning Theory", "summary": "This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $\u03b7_t^*$ separates alignment-decreasing ($\u03b7_t < \u03b7_t^*$) from alignment-increasing ($\u03b7_t > \u03b7_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86SGD\u5728\u75c5\u6001\u4f18\u5316\u4e2d\u7684\"\u53ef\u7591\u5bf9\u9f50\"\u73b0\u8c61\uff0c\u53d1\u73b0\u68af\u5ea6\u4e0e\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u7684\u5bf9\u9f50\u4f1a\u7ecf\u5386\u5148\u4e0b\u964d\u3001\u540e\u4e0a\u5347\u3001\u6700\u7ec8\u7a33\u5b9a\u7684\u4e09\u9636\u6bb5\u8fc7\u7a0b\uff0c\u5e76\u63ed\u793a\u4e86\u6b65\u957f\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u5728\u75c5\u6001\u4f18\u5316\u95ee\u9898\u4e2d\u7684\"\u53ef\u7591\u5bf9\u9f50\"\u73b0\u8c61\uff0c\u5373\u68af\u5ea6\u4e0eHessian\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u7684\u5bf9\u9f50\u884c\u4e3a\u3002\u8fd9\u79cd\u73b0\u8c61\u770b\u4f3c\u77db\u76fe\uff1a\u9ad8\u5ea6\u5bf9\u9f50\u7684\u68af\u5ea6\u66f4\u65b0\u5728\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u4e0a\u5374\u65e0\u6cd5\u6709\u6548\u964d\u4f4e\u635f\u5931\u3002\u9700\u8981\u6df1\u5165\u7406\u89e3\u6b65\u957f\u9009\u62e9\u5982\u4f55\u4ea7\u751f\u8fd9\u79cd\u73b0\u8c61\u3002", "method": "\u5728\u9ad8\u7ef4\u4e8c\u6b21\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\uff0c\u63d0\u51fa\u6b65\u957f\u6761\u4ef6\u7406\u8bba\u3002\u5b9a\u4e49\u4e86\u81ea\u9002\u5e94\u4e34\u754c\u6b65\u957f\u03b7_t^*\uff0c\u533a\u5206\u5bf9\u9f50\u4e0b\u964d\u548c\u5bf9\u9f50\u4e0a\u5347\u7684\u6b65\u957f\u533a\u95f4\u3002\u5206\u6790\u5728\u75c5\u6001\u6761\u4ef6\u4e0b\uff0c\u4e0d\u540c\u5b50\u7a7a\u95f4\u6295\u5f71\u5bf9\u635f\u5931\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\uff1a1\uff09\u4f4e\u5bf9\u9f50\u72b6\u6001\u4e0b\uff0c\u4e34\u754c\u6b65\u957f\u03b7_t^*\u533a\u5206\u5bf9\u9f50\u884c\u4e3a\uff1b2\uff09\u9ad8\u5bf9\u9f50\u72b6\u6001\u4e0b\uff0c\u5bf9\u9f50\u5177\u6709\u81ea\u6821\u6b63\u6027\uff1b3\uff09\u5728\u8db3\u591f\u75c5\u6001\u6761\u4ef6\u4e0b\uff0c\u5b58\u5728\u6b65\u957f\u533a\u95f4\u4f7f\u5f97\u6279\u91cf\u5b50\u7a7a\u95f4\u6295\u5f71\u964d\u4f4e\u635f\u5931\u800c\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u6295\u5f71\u589e\u52a0\u635f\u5931\uff1b4\uff09\u6052\u5b9a\u6b65\u957f\u4e0bSGD\u5448\u73b0\u4e24\u9636\u6bb5\u884c\u4e3a\u3002", "conclusion": "SGD\u5728\u75c5\u6001\u4f18\u5316\u4e2d\u7684\u53ef\u7591\u5bf9\u9f50\u73b0\u8c61\u53ef\u4ee5\u901a\u8fc7\u6b65\u957f\u9009\u62e9\u7406\u8bba\u5f97\u5230\u89e3\u91ca\u3002\u68af\u5ea6\u5bf9\u9f50\u7684\u52a8\u6001\u53d8\u5316\u53d7\u6b65\u957f\u63a7\u5236\uff0c\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u7684\u9ad8\u5bf9\u9f50\u5e76\u4e0d\u4fdd\u8bc1\u6709\u6548\u4f18\u5316\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u6295\u5f71\u5230\u4e3b\u5bfc\u5b50\u7a7a\u95f4\u7684\u68af\u5ea6\u66f4\u65b0\u6548\u679c\u4e0d\u4f73\u3002"}}
{"id": "2601.12038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12038", "abs": "https://arxiv.org/abs/2601.12038", "authors": ["Beishui Liao"], "title": "Abstract Argumentation with Subargument Relations", "comment": "11 pages", "summary": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5728\u4f20\u7edf\u653b\u51fb\u5173\u7cfb\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u660e\u786e\u7684\u5b50\u8bba\u8bc1\u5173\u7cfb\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "Dung\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u4ec5\u901a\u8fc7\u653b\u51fb\u5173\u7cfb\u6765\u8868\u5f81\u8bba\u8bc1\u53ef\u63a5\u53d7\u6027\uff0c\u8fd9\u79cd\u62bd\u8c61\u5c42\u6b21\u867d\u7136\u4ea7\u751f\u4e86\u4e30\u5bcc\u7684\u7814\u7a76\u6210\u679c\uff0c\u4f46\u9650\u5236\u4e86\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u6838\u5fc3\u7684\u7ed3\u6784\u4f9d\u8d56\u5173\u7cfb\uff08\u7279\u522b\u662f\u5b50\u8bba\u8bc1\u5173\u7cfb\uff09\u7684\u80fd\u529b\u3002\u73b0\u6709\u7684\u6269\u5c55\uff08\u5982\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff09\u5f15\u5165\u4e86\u652f\u6301\u5173\u7cfb\uff0c\u4f46\u8fd9\u4e9b\u5173\u7cfb\u65e0\u6cd5\u6355\u6349\u5b50\u8bba\u8bc1\u7684\u4e0d\u5bf9\u79f0\u6027\u548c\u6784\u6210\u6027\u672c\u8d28\uff0c\u4e5f\u65e0\u6cd5\u5904\u7406\u5b50\u8bba\u8bc1\u4e0e\u653b\u51fb\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u7814\u7a76\u4e00\u79cd\u6269\u5c55\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5728\u4f20\u7edf\u653b\u51fb\u5173\u7cfb\u57fa\u7840\u4e0a\u663e\u5f0f\u5730\u5f15\u5165\u5b50\u8bba\u8bc1\u5173\u7cfb\uff0c\u5c06\u5b50\u8bba\u8bc1\u5173\u7cfb\u4e0e\u653b\u51fb\u5173\u7cfb\u4e00\u8d77\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u6765\u5904\u7406\u3002\u5206\u6790\u5b50\u8bba\u8bc1\u5173\u7cfb\u5982\u4f55\u4e0e\u653b\u51fb\u5173\u7cfb\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u8003\u5bdf\u5b83\u4eec\u5bf9\u57fa\u672c\u8bed\u4e49\u5c5e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u7ed3\u6784\u5316\u4fe1\u606f\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u62bd\u8c61\uff0c\u5e76\u6f84\u6e05\u4e86\u5b50\u8bba\u8bc1\u5728\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u5c06\u5b50\u8bba\u8bc1\u5173\u7cfb\u4f5c\u4e3a\u57fa\u672c\u5173\u7cfb\u4e0e\u653b\u51fb\u5173\u7cfb\u5e76\u5217\u5904\u7406\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5f15\u5165\u5b50\u8bba\u8bc1\u5173\u7cfb\u6269\u5c55\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8868\u793a\u7ed3\u6784\u5316\u8bba\u8bc1\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3a\u62bd\u8c61\u53ef\u63a5\u53d7\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u5728\u8868\u793a\u7ed3\u6784\u4fe1\u606f\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.12851", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12851", "abs": "https://arxiv.org/abs/2601.12851", "authors": ["Yuji Sakamoto", "Masaki Aoi", "Sho Suzuki", "Takumi Haga", "Shumpei Hosokawa", "Yuma Abe", "Yuya Tasaki", "Tsuyoshi Totani", "Sou Nakamura", "Masaharu Uchiumi", "Shinya Fujita"], "title": "System Analysis and Pre-Flight Evaluation of Deployable Solar Panels for 3U CubeSat HOKUSHIN-1", "comment": "8 pages, 12 figures, 3 tables. ISTS 34th, June 3-9, 2023", "summary": "This paper describes the system design methodology derived from the development and evaluation tests of deployable solar panels to be mounted on a 3U CubeSat. The study mainly includes structural analysis, thermal analysis, and a review of vibration test results. Hokkaido University is developing the 3U CubeSat HOKUSHIN-1 in collaboration with Tohoku University and Muroran Institute of Technology. Deployable solar panels are a key technology for future planned lunar exploration missions, as they enable power-intensive communication and propulsion required for orbit control. The satellite also demonstrates a newly developed compact and efficient propulsion system. The satellite has dimensions of approximately 10x10x34 cm, a mass of 3.99 kg, and will be deployed into a circular orbit at an altitude of about 400 km with an orbital inclination of 51.6 degrees from the International Space Station.", "AI": {"tldr": "\u5f00\u53d13U\u7acb\u65b9\u661f\u53ef\u5c55\u5f00\u592a\u9633\u80fd\u7535\u6c60\u677f\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5305\u62ec\u7ed3\u6784\u5206\u6790\u3001\u70ed\u5206\u6790\u548c\u632f\u52a8\u6d4b\u8bd5\uff0c\u4e3a\u672a\u6765\u6708\u7403\u63a2\u6d4b\u4efb\u52a1\u63d0\u4f9b\u5173\u952e\u6280\u672f", "motivation": "\u5317\u6d77\u9053\u5927\u5b66\u4e0e\u4e1c\u5317\u5927\u5b66\u3001\u5ba4\u5170\u5de5\u4e1a\u5927\u5b66\u5408\u4f5c\u5f00\u53d13U\u7acb\u65b9\u661fHOKUSHIN-1\uff0c\u53ef\u5c55\u5f00\u592a\u9633\u80fd\u7535\u6c60\u677f\u662f\u672a\u6765\u6708\u7403\u63a2\u6d4b\u4efb\u52a1\u7684\u5173\u952e\u6280\u672f\uff0c\u80fd\u591f\u4e3a\u8f68\u9053\u63a7\u5236\u6240\u9700\u7684\u5bc6\u96c6\u901a\u4fe1\u548c\u63a8\u8fdb\u7cfb\u7edf\u63d0\u4f9b\u8db3\u591f\u7535\u529b", "method": "\u901a\u8fc7\u7ed3\u6784\u5206\u6790\u3001\u70ed\u5206\u6790\u548c\u632f\u52a8\u6d4b\u8bd5\u6765\u5f00\u53d1\u548c\u8bc4\u4f30\u53ef\u5c55\u5f00\u592a\u9633\u80fd\u7535\u6c60\u677f\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u536b\u661f\u5c3a\u5bf8\u7ea610x10x34\u5398\u7c73\uff0c\u8d28\u91cf3.99\u5343\u514b\uff0c\u5c06\u90e8\u7f72\u5728\u7ea6400\u516c\u91cc\u9ad8\u5ea6\u7684\u5706\u5f62\u8f68\u9053\u4e0a", "result": "\u5f00\u53d1\u4e86\u9002\u7528\u4e8e3U\u7acb\u65b9\u661f\u7684\u53ef\u5c55\u5f00\u592a\u9633\u80fd\u7535\u6c60\u677f\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u65b0\u5f00\u53d1\u7684\u7d27\u51d1\u9ad8\u6548\u63a8\u8fdb\u7cfb\u7edf\uff0c\u536b\u661f\u5c06\u4ece\u56fd\u9645\u7a7a\u95f4\u7ad9\u90e8\u7f72\u5230\u8f68\u9053\u503e\u89d251.6\u5ea6\u7684\u7ea6400\u516c\u91cc\u9ad8\u5ea6\u5706\u5f62\u8f68\u9053", "conclusion": "\u53ef\u5c55\u5f00\u592a\u9633\u80fd\u7535\u6c60\u677f\u7684\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u4e3a\u672a\u6765\u6708\u7403\u63a2\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u5173\u952e\u6280\u672f\u57fa\u7840\uff0c\u80fd\u591f\u652f\u6301\u529f\u7387\u5bc6\u96c6\u7684\u901a\u4fe1\u548c\u63a8\u8fdb\u9700\u6c42\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86\u7d27\u51d1\u9ad8\u6548\u63a8\u8fdb\u7cfb\u7edf\u7684\u53ef\u884c\u6027"}}
{"id": "2601.12652", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.12652", "abs": "https://arxiv.org/abs/2601.12652", "authors": ["Chutian Huang", "Dake Cao", "Jiacheng Ji", "Yunlou Fan", "Chengze Yan", "Hanhui Xu"], "title": "Ethical Risks in Deploying Large Language Models: An Evaluation of Medical Ethics Jailbreaking", "comment": null, "summary": "Background: While Large Language Models (LLMs) have achieved widespread adoption, malicious prompt engineering specifically \"jailbreak attacks\" poses severe security risks by inducing models to bypass internal safety mechanisms. Current benchmarks predominantly focus on public safety and Western cultural norms, leaving a critical gap in evaluating the niche, high-risk domain of medical ethics within the Chinese context. Objective: To establish a specialized jailbreak evaluation framework for Chinese medical ethics and to systematically assess the defensive resilience and ethical alignment of seven prominent LLMs when subjected to sophisticated adversarial simulations. Methodology: We evaluated seven prominent models (e.g., GPT-5, Claude-Sonnet-4-Reasoning, DeepSeek-R1) using a \"role-playing + scenario simulation + multi-turn dialogue\" vector within the DeepInception framework. The testing focused on eight high-risk themes, including commercial surrogacy and organ trading, utilizing a hierarchical scoring matrix to quantify the Attack Success Rate (ASR) and ASR Gain. Results: A systemic collapse of defenses was observed, whereas models demonstrated high baseline compliance, the jailbreak ASR reached 82.1%, representing an ASR Gain of over 80 percentage points. Claude-Sonnet-4-Reasoning emerged as the most robust model, while five models including Gemini-2.5-Pro and GPT-4.1 exhibited near-total failure with ASRs between 96% and 100%. Conclusions: Current LLMs are highly vulnerable to contextual manipulation in medical ethics, often prioritizing \"helpfulness\" over safety constraints. To enhance security, we recommend a transition from outcome to process supervision, the implementation of multi-factor identity verification, and the establishment of cross-model \"joint defense\" mechanisms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u9488\u5bf9\u4e2d\u56fd\u533b\u7597\u4f26\u7406\u7684\u4e13\u95e8\u8d8a\u72f1\u653b\u51fb\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4f26\u7406\u573a\u666f\u4e0b\u9632\u5fa1\u7cfb\u7edf\u5d29\u6e83\uff0c\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe82.1%\uff0c\u5efa\u8bae\u4ece\u7ed3\u679c\u76d1\u7763\u8f6c\u5411\u8fc7\u7a0b\u76d1\u7763\u7b49\u6539\u8fdb\u63aa\u65bd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u516c\u5171\u5b89\u5168\u548c\u897f\u65b9\u6587\u5316\u89c4\u8303\uff0c\u7f3a\u4e4f\u9488\u5bf9\u4e2d\u56fd\u533b\u7597\u4f26\u7406\u8fd9\u4e00\u9ad8\u98ce\u9669\u9886\u57df\u7684\u4e13\u95e8\u8d8a\u72f1\u653b\u51fb\u8bc4\u4f30\u6846\u67b6\uff0c\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u91c7\u7528DeepInception\u6846\u67b6\uff0c\u901a\u8fc7\"\u89d2\u8272\u626e\u6f14+\u573a\u666f\u6a21\u62df+\u591a\u8f6e\u5bf9\u8bdd\"\u5411\u91cf\uff0c\u8bc4\u4f30\u4e03\u4e2a\u4e3b\u6d41\u6a21\u578b\u5728\u516b\u4e2a\u9ad8\u98ce\u9669\u533b\u7597\u4f26\u7406\u4e3b\u9898\u4e0a\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u4f7f\u7528\u5206\u5c42\u8bc4\u5206\u77e9\u9635\u91cf\u5316\u653b\u51fb\u6210\u529f\u7387\u548c\u589e\u76ca\u3002", "result": "\u6a21\u578b\u9632\u5fa1\u7cfb\u7edf\u5d29\u6e83\uff1a\u867d\u7136\u57fa\u7ebf\u5408\u89c4\u6027\u9ad8\uff0c\u4f46\u8d8a\u72f1\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe82.1%\uff0c\u589e\u76ca\u8d85\u8fc780\u4e2a\u767e\u5206\u70b9\u3002Claude-Sonnet-4-Reasoning\u6700\u7a33\u5065\uff0c\u800c\u4e94\u4e2a\u6a21\u578b\uff08\u5305\u62ecGemini-2.5-Pro\u548cGPT-4.1\uff09\u51e0\u4e4e\u5b8c\u5168\u5931\u8d25\uff0c\u6210\u529f\u7387\u572896%-100%\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4f26\u7406\u573a\u666f\u4e0b\u6781\u6613\u53d7\u4e0a\u4e0b\u6587\u64cd\u7eb5\uff0c\u5f80\u5f80\u4f18\u5148\u8003\u8651\"\u5e2e\u52a9\u6027\"\u800c\u975e\u5b89\u5168\u7ea6\u675f\u3002\u5efa\u8bae\u4ece\u7ed3\u679c\u76d1\u7763\u8f6c\u5411\u8fc7\u7a0b\u76d1\u7763\uff0c\u5b9e\u65bd\u591a\u56e0\u7d20\u8eab\u4efd\u9a8c\u8bc1\uff0c\u5efa\u7acb\u8de8\u6a21\u578b\"\u8054\u5408\u9632\u5fa1\"\u673a\u5236\u3002"}}
{"id": "2601.13448", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13448", "abs": "https://arxiv.org/abs/2601.13448", "authors": ["Sofiane Tanji", "Samuel Vaiter", "Yassine Laguel"], "title": "Fairness-informed Pareto Optimization : An Efficient Bilevel Framework", "comment": null, "summary": "Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.", "AI": {"tldr": "BADR\u662f\u4e00\u4e2a\u53cc\u5c42\u81ea\u9002\u5e94\u91cd\u65b0\u6807\u91cf\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u4e3a\u4efb\u4f55\u516c\u5e73\u6027\u6307\u6807\u6062\u590d\u6700\u4f18\u5e15\u7d2f\u6258\u6548\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u4e2a\u65b0\u9896\u7684\u5927\u89c4\u6a21\u5355\u5faa\u73af\u7b97\u6cd5\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7ecf\u5e38\u4ea7\u751f\u5e15\u7d2f\u6258\u4f4e\u6548\u6a21\u578b\uff0c\u800c\u73b0\u6709\u7684\u5e15\u7d2f\u6258\u6548\u7387\u65b9\u6cd5\u53c8\u504f\u5411\u7279\u5b9a\u516c\u5e73\u89c6\u89d2\uff0c\u65e0\u6cd5\u9002\u5e94\u6587\u732e\u4e2d\u5e7f\u6cdb\u7684\u516c\u5e73\u6027\u6307\u6807\u3002", "method": "\u63d0\u51faBADR\uff08\u53cc\u5c42\u81ea\u9002\u5e94\u91cd\u65b0\u6807\u91cf\u5316\uff09\u6846\u67b6\uff1a\u4e0b\u5c42\u662f\u52a0\u6743\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4efb\u52a1\uff08\u6743\u91cd\u4e3a\u5404\u7ec4\u7684\u51f8\u7ec4\u5408\uff09\uff0c\u4e0a\u5c42\u4f18\u5316\u6240\u9009\u516c\u5e73\u6027\u76ee\u6807\u3002\u5f00\u53d1\u4e86BADR-GD\u548cBADR-SGD\u4e24\u79cd\u5927\u89c4\u6a21\u5355\u5faa\u73af\u7b97\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u53d1\u5e03\u4e86badr\u5f00\u6e90Python\u5de5\u5177\u7bb1\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u8bc1\u660eBADR\u4f18\u4e8e\u73b0\u6709\u7684\u5e15\u7d2f\u6258\u6548\u7387\u516c\u5e73\u65b9\u6cd5\u3002", "conclusion": "BADR\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4e3a\u4efb\u4f55\u516c\u5e73\u6027\u6307\u6807\u6062\u590d\u6700\u4f18\u5e15\u7d2f\u6258\u6548\u7387\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.13124", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13124", "abs": "https://arxiv.org/abs/2601.13124", "authors": ["Donglei Du", "Qizhi Fang", "Bin Liu", "Tianhang Lu", "Chenchen Wu"], "title": "Full characterization of core for nonlinear optimization games", "comment": null, "summary": "We fully characterize the core of a broad class of nonlinear games by identifying a suitable relaxation for inherent nonlinearity, directly generalizing the linear frameworks in the literature. This characterization significantly expands the scope of cooperative games that can be analyzed and contributes to the literature on games induced from optimization models. We apply these insights to not only establish connections with and provide new insights on classical models but also solve new games untamed in the existing literature, including combinatorial quadratic and ratio games such as portfolio, maximum cut, matching, and assortment games. These results are further extended to more general models and also the approximate core.", "AI": {"tldr": "\u8bba\u6587\u5b8c\u5168\u523b\u753b\u4e86\u4e00\u7c7b\u5e7f\u6cdb\u975e\u7ebf\u6027\u535a\u5f08\u7684\u6838\u5fc3\uff0c\u901a\u8fc7\u8bc6\u522b\u975e\u7ebf\u6027\u95ee\u9898\u7684\u5408\u9002\u677e\u5f1b\uff0c\u76f4\u63a5\u63a8\u5e7f\u4e86\u6587\u732e\u4e2d\u7684\u7ebf\u6027\u6846\u67b6\uff0c\u663e\u8457\u6269\u5c55\u4e86\u53ef\u5206\u6790\u7684\u5408\u4f5c\u535a\u5f08\u8303\u56f4\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u7ebf\u6027\u535a\u5f08\u6846\u67b6\uff0c\u5bf9\u4e8e\u975e\u7ebf\u6027\u535a\u5f08\u7684\u6838\u5fc3\u523b\u753b\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u5408\u4f5c\u535a\u5f08\u7406\u8bba\uff0c\u4f7f\u5176\u80fd\u591f\u5206\u6790\u66f4\u5e7f\u6cdb\u7684\u975e\u7ebf\u6027\u535a\u5f08\u6a21\u578b\uff0c\u7279\u522b\u662f\u4ece\u4f18\u5316\u6a21\u578b\u5bfc\u51fa\u7684\u535a\u5f08\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u975e\u7ebf\u6027\u95ee\u9898\u7684\u5408\u9002\u677e\u5f1b\u65b9\u6cd5\uff0c\u76f4\u63a5\u63a8\u5e7f\u7ebf\u6027\u6846\u67b6\u6765\u5904\u7406\u975e\u7ebf\u6027\u535a\u5f08\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u7ec4\u5408\u4e8c\u6b21\u535a\u5f08\u3001\u6bd4\u7387\u535a\u5f08\u7b49\u590d\u6742\u975e\u7ebf\u6027\u7ed3\u6784\u3002", "result": "\u6210\u529f\u523b\u753b\u4e86\u5e7f\u6cdb\u975e\u7ebf\u6027\u535a\u5f08\u7684\u6838\u5fc3\uff0c\u5efa\u7acb\u4e86\u4e0e\u7ecf\u5178\u6a21\u578b\u7684\u8054\u7cfb\u5e76\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002\u89e3\u51b3\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u672a\u5904\u7406\u7684\u535a\u5f08\uff0c\u5305\u62ec\u6295\u8d44\u7ec4\u5408\u3001\u6700\u5927\u5272\u3001\u5339\u914d\u548c\u9009\u62e9\u535a\u5f08\u7b49\u7ec4\u5408\u4e8c\u6b21\u548c\u6bd4\u7387\u535a\u5f08\u3002", "conclusion": "\u8be5\u7814\u7a76\u663e\u8457\u6269\u5c55\u4e86\u5408\u4f5c\u535a\u5f08\u7406\u8bba\u7684\u5206\u6790\u8303\u56f4\uff0c\u4e3a\u975e\u7ebf\u6027\u535a\u5f08\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u66f4\u4e00\u822c\u6a21\u578b\u548c\u8fd1\u4f3c\u6838\u5fc3\uff0c\u5bf9\u4f18\u5316\u6a21\u578b\u5bfc\u51fa\u7684\u535a\u5f08\u6709\u91cd\u8981\u7406\u8bba\u8d21\u732e\u3002"}}
{"id": "2601.11866", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11866", "abs": "https://arxiv.org/abs/2601.11866", "authors": ["Kie Shidara", "Preethi Prem", "Jonathan Kim", "Anna Podlasek", "Feng Liu", "Ahmed Alaa", "Danilo Bernardo"], "title": "Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66QA\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e34\u5e8a\u63a8\u7406\u7684\u7075\u6d3b\u6027\u5b58\u5728\u4e89\u8bae\u3002\u7814\u7a76\u53d1\u73b0\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u5728mARC\u57fa\u51c6\u4e0a\u80fd\u907f\u514dEinstellung\u6548\u5e94\u9677\u9631\uff0c\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u533b\u5b66QA\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5176\u4e34\u5e8a\u63a8\u7406\u7684\u7075\u6d3b\u6027\u4e00\u76f4\u5b58\u5728\u4e89\u8bae\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7a76\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u662f\u5426\u80fd\u6539\u5584\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u7075\u6d3b\u6027\u3002", "method": "\u4f7f\u7528\u533b\u5b66\u62bd\u8c61\u4e0e\u63a8\u7406\u8bed\u6599\u5e93(mARC)\u8fd9\u4e00\u5bf9\u6297\u6027\u533b\u5b66QA\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5229\u7528Einstellung\u6548\u5e94\u8bf1\u5bfc\u5bf9\u5b66\u4e60\u5230\u7684\u542f\u53d1\u5f0f\u6a21\u5f0f\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002\u8bc4\u4f30\u4e86OpenAI\u3001Grok\u3001Gemini\u3001Claude\u548cDeepSeek\u7b49\u5bb6\u65cf\u7684\u63a8\u7406\u6a21\u578b\u3002", "result": "\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u6bd4\u5f31\u63a8\u7406\u6a21\u578b\u66f4\u5e38\u907f\u514dEinstellung\u9677\u9631\uff0c\u5728mARC\u4e0a\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002\u5728\u533b\u751f\u6700\u5e38\u51fa\u9519\u7684\u95ee\u9898\u4e0a\uff0c\u524d5\u540d\u6a21\u578b\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u6b63\u786e\u56de\u7b54\u4e8655%\u523070%\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u53ef\u80fd\u6bd4\u4eba\u7c7b\u66f4\u4e0d\u5bb9\u6613\u53d7Einstellung\u6548\u5e94\u5f71\u54cd\u3002", "conclusion": "\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u7075\u6d3b\u6027\uff0c\u5728mARC\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8868\u660e\u5b83\u4eec\u53ef\u80fd\u6bd4\u4eba\u7c7b\u66f4\u4e0d\u5bb9\u6613\u53d7\u5230\u8ba4\u77e5\u504f\u89c1\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.11794", "categories": ["cs.LG", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11794", "abs": "https://arxiv.org/abs/2601.11794", "authors": ["Abdelrahman Ramadan", "Zahra Dorbeigi Namaghi", "Emily Taylor", "Lucas Edwards", "Xan Giuliani", "David S. McLagan", "Sidney Givigi", "Melissa Greeff"], "title": "Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing", "comment": null, "summary": "Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\\% smoothness improvement and 90.7\\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\\% negative outputs. The lean variant outperforms wide (+5.6\\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.", "AI": {"tldr": "PC\u00b2DAE\uff1a\u4e00\u79cd\u7528\u4e8e\u65e0\u4eba\u673a\u91ce\u706b\u76d1\u6d4b\u7684\u7269\u7406\u7ea6\u675f\u53bb\u566a\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5d4c\u5165\u7269\u7406\u7ea6\u675f\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\u53bb\u566a\u3002", "motivation": "\u65e0\u4eba\u673a\u642d\u8f7d\u7684\u4f4e\u6210\u672c\u4f20\u611f\u5668\u5b58\u5728\u57fa\u7ebf\u6f02\u79fb\u3001\u4ea4\u53c9\u654f\u611f\u6027\u548c\u54cd\u5e94\u5ef6\u8fdf\u7b49\u95ee\u9898\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u800c\u65e0\u4eba\u673a\u98de\u884c\u6d3b\u52a8\u6570\u636e\u6709\u9650\uff0c\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u63d0\u51faPC\u00b2DAE\u7269\u7406\u7ea6\u675f\u53bb\u566a\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7softplus\u6fc0\u6d3b\u51fd\u6570\u786e\u4fdd\u6d53\u5ea6\u4f30\u8ba1\u975e\u8d1f\uff0c\u91c7\u7528\u7269\u7406\u5408\u7406\u7684\u65f6\u95f4\u5e73\u6ed1\uff0c\u67b6\u6784\u5305\u542b\u9488\u5bf9\u4e0d\u540c\u4f20\u611f\u5668\u5bb6\u65cf\u7684\u5c42\u6b21\u89e3\u7801\u5668\u5934\uff0c\u63d0\u4f9b\u8f7b\u91cf\u7248\uff0821k\u53c2\u6570\uff09\u548c\u5bbd\u7248\uff08204k\u53c2\u6570\uff09\u4e24\u79cd\u53d8\u4f53\u3002", "result": "\u5728\u4ec57,894\u4e2a\u6837\u672c\uff08\u7ea62.2\u5c0f\u65f6\u98de\u884c\u6570\u636e\uff09\u7684\u5c0f\u6570\u636e\u96c6\u4e0a\uff0cPC\u00b2DAE-Lean\u5b9e\u73b067.3%\u5e73\u6ed1\u5ea6\u63d0\u5347\u548c90.7%\u9ad8\u9891\u566a\u58f0\u964d\u4f4e\uff0c\u65e0\u7269\u7406\u8fdd\u89c4\uff0c\u8bad\u7ec3\u65f6\u95f4\u4e0d\u523065\u79d2\uff0c\u4f18\u4e8e\u4e94\u4e2a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "PC\u00b2DAE\u901a\u8fc7\u5c06\u7269\u7406\u7ea6\u675f\u76f4\u63a5\u5d4c\u5165\u7f51\u7edc\u67b6\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u4f20\u611f\u5668\u53bb\u566a\u95ee\u9898\uff0c\u8f7b\u91cf\u7248\u8868\u73b0\u4f18\u4e8e\u5bbd\u7248\uff0c\u8868\u660e\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\uff0c\u5f3a\u5f52\u7eb3\u504f\u7f6e\u6bd4\u6a21\u578b\u5bb9\u91cf\u66f4\u91cd\u8981\u3002"}}
{"id": "2601.12040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12040", "abs": "https://arxiv.org/abs/2601.12040", "authors": ["Murilo da Luz", "Bruno Brand\u00e3o", "Luana Martins", "Gustavo Oliveira", "Bryan de Oliveira", "Luckeciano Melo", "Telma Soares"], "title": "Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty", "comment": null, "summary": "The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.", "AI": {"tldr": "PREGU\u5229\u7528\u8f93\u51fa\u5206\u5e03\u7684\u71b5\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u76d1\u6d4b\u71b5\u503c\uff0c\u8d85\u8fc7\u9608\u503c\u65f6\u505c\u6b62\u5e76\u6267\u884c\u5c40\u90e8\u641c\u7d22\u6765\u4f18\u5316\u90e8\u5206\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e0eSoft Reasoning\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u591a\u6b65\u63a8\u7406\u573a\u666f\uff08\u7279\u522b\u662f\u6570\u5b66\u548c\u903b\u8f91\u63a8\u7406\uff09\u4e2d\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u63a8\u7406\u4f18\u5316\u65b9\u6cd5\u3002", "method": "PREGU\u65b9\u6cd5\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u76d1\u6d4b\u8f93\u51fa\u5206\u5e03\u7684\u71b5\uff0c\u5f53\u71b5\u8d85\u8fc7\u5b9a\u4e49\u9608\u503c\u65f6\u505c\u6b62\u751f\u6210\uff0c\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u3002\u7136\u540e\u5bf9\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u5c40\u90e8\u641c\u7d22\uff0c\u4f7f\u7528Soft Reasoning\u65b9\u6cd5\u7ec6\u5316\u90e8\u5206\u63a8\u7406\u5e76\u9009\u62e9\u6700\u4e00\u81f4\u7684\u7b54\u6848\u3002", "result": "\u5728LLaMA-3-8B\u3001Mistral-7B\u548cQwen2-7B\u6a21\u578b\u4e0a\uff0c\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\uff08GSM8K\u3001GSM-Hard\u3001SVAMP\u548cStrategyQA\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPREGU\u7684\u6027\u80fd\u4f18\u4e8e\u6216\u7c7b\u4f3c\u4e8eSoft Reasoning\u3002", "conclusion": "\u71b5\u53ef\u4ee5\u4f5c\u4e3a\u63a8\u7406\u8fc7\u7a0b\u4e2d\u89e6\u53d1\u9009\u62e9\u6027\u7ec6\u5316\u7684\u6709\u6548\u4fe1\u53f7\uff0cPREGU\u65b9\u6cd5\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u76d1\u6d4b\u548c\u5c40\u90e8\u641c\u7d22\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.12857", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12857", "abs": "https://arxiv.org/abs/2601.12857", "authors": ["Yuji Sakamoto"], "title": "Report on Earth Observation Missions and Ground Station Management using On-Demand Satellite Operation System", "comment": "8 pages, 11 figures. ISTS 35th, July 12-18, 2025", "summary": "Since the launch of its first satellite in 2009, Tohoku University has continuously developed and operated Earth observation satellites and engineering demonstration satellites in the 50cm-class and CubeSat-class (up to 3U). The 50cm-class satellite launched into operation in 2021 enabled efficient operations through cloud-based management functions for both the satellite and ground stations, including automatic command generation. By 2022, up to eight operational satellites were simultaneously managed on a daily basis using three ground stations (Sendai, Hakodate, and Sweden). This paper presents the operational achievements to date and introduces the system that supports efficient satellite operations", "AI": {"tldr": "\u4e1c\u5317\u5927\u5b66\u81ea2009\u5e74\u53d1\u5c04\u9996\u9897\u536b\u661f\u4ee5\u6765\uff0c\u6301\u7eed\u5f00\u53d1\u5e76\u8fd0\u842550\u5398\u7c73\u7ea7\u548c\u7acb\u65b9\u661f\u7ea7\uff08\u6700\u59273U\uff09\u7684\u5730\u7403\u89c2\u6d4b\u536b\u661f\u548c\u5de5\u7a0b\u6f14\u793a\u536b\u661f\u30022021\u5e74\u53d1\u5c04\u768450\u5398\u7c73\u7ea7\u536b\u661f\u901a\u8fc7\u57fa\u4e8e\u4e91\u7684\u536b\u661f\u548c\u5730\u9762\u7ad9\u7ba1\u7406\u529f\u80fd\uff08\u5305\u62ec\u81ea\u52a8\u6307\u4ee4\u751f\u6210\uff09\u5b9e\u73b0\u4e86\u9ad8\u6548\u8fd0\u8425\u3002\u52302022\u5e74\uff0c\u4f7f\u7528\u4e09\u4e2a\u5730\u9762\u7ad9\uff08\u4ed9\u53f0\u3001\u51fd\u9986\u548c\u745e\u5178\uff09\u540c\u65f6\u7ba1\u7406\u591a\u8fbe\u516b\u9897\u8fd0\u884c\u536b\u661f\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u8fc4\u4eca\u4e3a\u6b62\u7684\u8fd0\u8425\u6210\u679c\uff0c\u5e76\u4ecb\u7ecd\u4e86\u652f\u6301\u9ad8\u6548\u536b\u661f\u8fd0\u8425\u7684\u7cfb\u7edf\u3002", "motivation": "\u4e1c\u5317\u5927\u5b66\u81ea2009\u5e74\u4ee5\u6765\u6301\u7eed\u53d1\u5c55\u5c0f\u578b\u536b\u661f\u6280\u672f\uff0c\u9700\u8981\u5efa\u7acb\u9ad8\u6548\u7684\u536b\u661f\u8fd0\u8425\u7ba1\u7406\u7cfb\u7edf\u6765\u652f\u6301\u65e5\u76ca\u589e\u957f\u7684\u536b\u661f\u6570\u91cf\u548c\u590d\u6742\u7684\u8fd0\u8425\u9700\u6c42\u3002\u968f\u7740\u536b\u661f\u6570\u91cf\u7684\u589e\u52a0\uff08\u6700\u591a\u540c\u65f6\u7ba1\u74068\u9897\u536b\u661f\uff09\uff0c\u4f20\u7edf\u7684\u4eba\u5de5\u7ba1\u7406\u65b9\u5f0f\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u81ea\u52a8\u5316\u548c\u4e91\u5316\u7684\u8fd0\u8425\u7cfb\u7edf\u6765\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u4e91\u7684\u536b\u661f\u548c\u5730\u9762\u7ad9\u7ba1\u7406\u7cfb\u7edf\uff0c\u5305\u62ec\u81ea\u52a8\u6307\u4ee4\u751f\u6210\u529f\u80fd\u3002\u5efa\u7acb\u4e86\u4e09\u4e2a\u5730\u9762\u7ad9\u7f51\u7edc\uff08\u4ed9\u53f0\u3001\u51fd\u9986\u548c\u745e\u5178\uff09\u6765\u652f\u6301\u536b\u661f\u8fd0\u8425\u3002\u7cfb\u7edf\u5b9e\u73b0\u4e86\u536b\u661f\u8fd0\u8425\u7684\u81ea\u52a8\u5316\u548c\u96c6\u4e2d\u5316\u7ba1\u7406\uff0c\u80fd\u591f\u540c\u65f6\u7ba1\u7406\u591a\u4e2a\u536b\u661f\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u6700\u591a8\u9897\u8fd0\u884c\u536b\u661f\u7684\u540c\u65f6\u65e5\u5e38\u7ba1\u7406\u30022021\u5e74\u53d1\u5c04\u768450\u5398\u7c73\u7ea7\u536b\u661f\u901a\u8fc7\u4e91\u7ba1\u7406\u7cfb\u7edf\u5b9e\u73b0\u4e86\u9ad8\u6548\u8fd0\u8425\u3002\u5efa\u7acb\u4e86\u7531\u4e09\u4e2a\u5730\u9762\u7ad9\u7ec4\u6210\u7684\u8fd0\u8425\u7f51\u7edc\uff0c\u652f\u6301\u591a\u536b\u661f\u534f\u540c\u7ba1\u7406\u3002", "conclusion": "\u4e1c\u5317\u5927\u5b66\u6210\u529f\u5f00\u53d1\u5e76\u5b9e\u65bd\u4e86\u9ad8\u6548\u7684\u536b\u661f\u8fd0\u8425\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e91\u7ba1\u7406\u548c\u81ea\u52a8\u5316\u6280\u672f\u5b9e\u73b0\u4e86\u591a\u536b\u661f\u7684\u540c\u65f6\u7ba1\u7406\u3002\u8be5\u7cfb\u7edf\u4e3a\u5c0f\u578b\u536b\u661f\u7684\u5927\u89c4\u6a21\u8fd0\u8425\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u4e91\u6280\u672f\u548c\u81ea\u52a8\u5316\u5728\u536b\u661f\u8fd0\u8425\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2601.12705", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12705", "abs": "https://arxiv.org/abs/2601.12705", "authors": ["Dipto Das", "Afrin Prio", "Pritu Saha", "Shion Guha", "Syed Ishtiaque Ahmed"], "title": "How do the Global South Diasporas Mobilize for Transnational Political Change?", "comment": null, "summary": "This paper examines how non-resident Bangladeshis mobilized during the 2024 quota-reform turned pro-democracy movement, leveraging social platforms and remittance flows to challenge state authority. Drawing on semi-structured interviews, we identify four phases of their collective action: technology-mediated shifts to active engagement, rapid transnational network building, strategic execution of remittance boycott, reframing economic dependence as political leverage, and adaptive responses to government surveillance and information blackouts. We extend postcolonial computing by introducing the idea of \"diasporic superposition,\" which shows how diasporas can exercise political and economic influence from hybrid positionalities that both contest and complicate power asymmetries. We reframe diaspora engagement by highlighting how migrants participate in and reshape homeland politics, beyond narratives of integration in host countries. We advance the scholarship on financial technologies by foregrounding their relationship with moral economies of care, state surveillance, regulatory constraints, and uneven international economic power dynamics. Together, these contributions theorize how transnational activism and digital technologies intersect to mobilize political change in Global South contexts.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a762024\u5e74\u5b5f\u52a0\u62c9\u56fd\u914d\u989d\u6539\u9769\u6f14\u53d8\u4e3a\u4eb2\u6c11\u4e3b\u8fd0\u52a8\u4e2d\uff0c\u6d77\u5916\u5b5f\u52a0\u62c9\u4eba\u5982\u4f55\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u548c\u6c47\u6b3e\u6d41\u52a8\u6311\u6218\u56fd\u5bb6\u6743\u5a01\uff0c\u63d0\u51fa\"\u79bb\u6563\u53e0\u52a0\"\u6982\u5ff5\u5206\u6790\u5176\u653f\u6cbb\u7ecf\u6d4e\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u6d77\u5916\u79bb\u6563\u7fa4\u4f53\u5982\u4f55\u901a\u8fc7\u6570\u5b57\u6280\u672f\u548c\u7ecf\u6d4e\u624b\u6bb5\u53c2\u4e0e\u5e76\u91cd\u5851\u6bcd\u56fd\u653f\u6cbb\uff0c\u8d85\u8d8a\u4f20\u7edf\u79fb\u6c11\u878d\u5165\u53d9\u4e8b\uff0c\u63a2\u8ba8\u5168\u7403\u5357\u65b9\u80cc\u666f\u4e0b\u8de8\u56fd\u884c\u52a8\u4e3b\u4e49\u4e0e\u6570\u5b57\u6280\u672f\u7684\u4ea4\u6c47\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u65b9\u6cd5\uff0c\u8bc6\u522b\u6d77\u5916\u5b5f\u52a0\u62c9\u4eba\u96c6\u4f53\u884c\u52a8\u7684\u56db\u4e2a\u9636\u6bb5\uff1a\u6280\u672f\u4e2d\u4ecb\u7684\u53c2\u4e0e\u8f6c\u53d8\u3001\u5feb\u901f\u8de8\u56fd\u7f51\u7edc\u5efa\u8bbe\u3001\u6218\u7565\u6027\u6c47\u6b3e\u62b5\u5236\u6267\u884c\u3001\u7ecf\u6d4e\u4f9d\u8d56\u91cd\u6784\u4e3a\u653f\u6cbb\u6760\u6746\uff0c\u4ee5\u53ca\u5bf9\u653f\u5e9c\u76d1\u63a7\u548c\u4fe1\u606f\u5c01\u9501\u7684\u9002\u5e94\u6027\u56de\u5e94\u3002", "result": "\u7814\u7a76\u6269\u5c55\u540e\u6b96\u6c11\u8ba1\u7b97\u7406\u8bba\uff0c\u63d0\u51fa\"\u79bb\u6563\u53e0\u52a0\"\u6982\u5ff5\uff0c\u5c55\u793a\u79bb\u6563\u7fa4\u4f53\u5982\u4f55\u4ece\u6df7\u5408\u4f4d\u7f6e\u6027\u884c\u4f7f\u653f\u6cbb\u7ecf\u6d4e\u5f71\u54cd\u529b\uff0c\u65e2\u6311\u6218\u53c8\u590d\u6742\u5316\u6743\u529b\u4e0d\u5bf9\u79f0\uff1b\u91cd\u65b0\u6784\u5efa\u79bb\u6563\u53c2\u4e0e\u6846\u67b6\uff0c\u5f3a\u8c03\u79fb\u6c11\u5982\u4f55\u53c2\u4e0e\u5e76\u91cd\u5851\u6bcd\u56fd\u653f\u6cbb\uff1b\u63a8\u8fdb\u91d1\u878d\u6280\u672f\u7814\u7a76\uff0c\u7a81\u51fa\u5176\u4e0e\u5173\u6000\u9053\u5fb7\u7ecf\u6d4e\u3001\u56fd\u5bb6\u76d1\u63a7\u3001\u76d1\u7ba1\u7ea6\u675f\u548c\u4e0d\u5e73\u8861\u56fd\u9645\u7ecf\u6d4e\u6743\u529b\u52a8\u6001\u7684\u5173\u7cfb\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u5316\u8de8\u56fd\u884c\u52a8\u4e3b\u4e49\u4e0e\u6570\u5b57\u6280\u672f\u5982\u4f55\u4ea4\u6c47\u4ee5\u52a8\u5458\u5168\u7403\u5357\u65b9\u653f\u6cbb\u53d8\u9769\uff0c\u4e3a\u7406\u89e3\u79bb\u6563\u7fa4\u4f53\u5728\u6570\u5b57\u65f6\u4ee3\u5982\u4f55\u901a\u8fc7\u7ecf\u6d4e\u548c\u6280\u672f\u624b\u6bb5\u6311\u6218\u56fd\u5bb6\u6743\u5a01\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u6df7\u5408\u4f4d\u7f6e\u6027\u5728\u5f53\u4ee3\u653f\u6cbb\u6597\u4e89\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13474", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13474", "abs": "https://arxiv.org/abs/2601.13474", "authors": ["Jianhao Ma", "Yu Huang", "Yuejie Chi", "Yuxin Chen"], "title": "Preconditioning Benefits of Spectral Orthogonalization in Muon", "comment": null, "summary": "The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86Muon\u4f18\u5316\u5668\u7684\u7b80\u5316\u53d8\u4f53\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u7ebf\u6027Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e24\u4e2a\u6848\u4f8b\uff0c\u8bc1\u660e\u4e86\u8be5\u4f18\u5316\u5668\u5177\u6709\u4e0e\u6761\u4ef6\u6570\u65e0\u5173\u7684\u7ebf\u6027\u6536\u655b\u6027\uff0c\u4f18\u4e8e\u68af\u5ea6\u4e0b\u964d\u548cAdam\u7b97\u6cd5\u3002", "motivation": "Muon\u4f18\u5316\u5668\u4f5c\u4e3a\u5229\u7528\u68af\u5ea6\u8c31\u6b63\u4ea4\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u91cc\u7a0b\u7891\u7b97\u6cd5\uff0c\u5176\u5185\u5728\u673a\u5236\u7279\u522b\u662f\u68af\u5ea6\u6b63\u4ea4\u5316\u7684\u4f5c\u7528\u4ecd\u4e0d\u660e\u786e\uff0c\u7f3a\u4e4f\u5bf9\u5176\u5728\u5177\u4f53\u5e94\u7528\u4e2d\u4f18\u52bf\u7684\u7aef\u5230\u7aef\u7406\u8bba\u5206\u6790\u3002", "method": "\u7814\u7a76Muon\u4f18\u5316\u5668\u7684\u7b80\u5316\u53d8\u4f53\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u7ebf\u6027Transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e24\u4e2a\u6848\u4f8b\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5176\u6536\u655b\u6027\u5e76\u63ed\u793a\u8c31\u57df\u4e2d\u7684\u52a8\u6001\u89e3\u8026\u673a\u5236\u3002", "result": "\u8bc1\u660e\u4e86\u7b80\u5316Muon\u5728\u7ebf\u6027\u6536\u655b\u6027\u65b9\u9762\u5177\u6709\u4e0e\u76f8\u5173\u6761\u4ef6\u6570\u65e0\u5173\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\uff0c\u4f18\u4e8e\u68af\u5ea6\u4e0b\u964d\u548cAdam\u7b97\u6cd5\uff1b\u63ed\u793a\u4e86Muon\u52a8\u6001\u5728\u8c31\u57df\u4e2d\u89e3\u8026\u4e3a\u72ec\u7acb\u6807\u91cf\u5e8f\u5217\u7684\u673a\u5236\u3002", "conclusion": "\u7814\u7a76\u5f62\u5f0f\u5316\u4e86\u8c31\u6b63\u4ea4\u5316\u5f15\u8d77\u7684\u9884\u5904\u7406\u6548\u5e94\uff0c\u4e3a\u7406\u89e3Muon\u5728\u77e9\u9635\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u53ef\u80fd\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.13130", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13130", "abs": "https://arxiv.org/abs/2601.13130", "authors": ["Jos\u00e9 Ni\u00f1o-Mora"], "title": "Age of information cost minimization with no buffers, random arrivals and unreliable channels: A PCL-indexability analysis", "comment": "30 pages", "summary": "Over the last decade, the Age of Information has emerged as a key concept and metric for applications where the freshness of sensor-provided data is critical. Limited transmission capacity has motivated research on the design of tractable policies for scheduling information updates to minimize Age of Information cost based on Markov decision models, in particular on the restless multi-armed bandit problem (RMABP). This allows the use of Whittle's popular index policy, which is often nearly optimal, provided indexability (index existence) is proven, which has been recently accomplished in some models. We aim to extend the application scope of Whittle's index policy in a broader AoI scheduling model. We address a model with no buffers incorporating random packet arrivals, unreliable channels, and nondecreasing AoI costs. We use sufficient indexability conditions based on partial conservation laws previously introduced by the author to establish the model's indexability and evaluate its Whittle index in closed form under discounted and average cost criteria. We further use the index formulae to draw insights on how scheduling priority depends on model parameters.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Whittle\u7d22\u5f15\u7b56\u7565\u5728AoI\u8c03\u5ea6\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u8303\u56f4\uff0c\u9488\u5bf9\u65e0\u7f13\u51b2\u3001\u968f\u673a\u6570\u636e\u5305\u5230\u8fbe\u3001\u4e0d\u53ef\u9760\u4fe1\u9053\u548c\u975e\u9012\u51cfAoI\u6210\u672c\u7684\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u7d22\u5f15\u6027\u5e76\u7ed9\u51fa\u4e86\u95ed\u5f0fWhittle\u7d22\u5f15\u516c\u5f0f\u3002", "motivation": "\u4fe1\u606f\u5e74\u9f84(AoI)\u5df2\u6210\u4e3a\u4f20\u611f\u5668\u6570\u636e\u65b0\u9c9c\u5ea6\u5173\u952e\u5e94\u7528\u7684\u6838\u5fc3\u6307\u6807\u3002\u7531\u4e8e\u4f20\u8f93\u5bb9\u91cf\u6709\u9650\uff0c\u9700\u8981\u8bbe\u8ba1\u53ef\u5904\u7406\u7684\u8c03\u5ea6\u7b56\u7565\u6765\u6700\u5c0f\u5316AoI\u6210\u672c\u3002\u867d\u7136\u57fa\u4e8eRMABP\u7684Whittle\u7d22\u5f15\u7b56\u7565\u5df2\u88ab\u8bc1\u660e\u5728\u67d0\u4e9b\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u4f46\u9700\u8981\u5c06\u5176\u5e94\u7528\u8303\u56f4\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684AoI\u8c03\u5ea6\u6a21\u578b\u3002", "method": "\u91c7\u7528\u65e0\u7f13\u51b2\u6a21\u578b\uff0c\u5305\u542b\u968f\u673a\u6570\u636e\u5305\u5230\u8fbe\u3001\u4e0d\u53ef\u9760\u4fe1\u9053\u548c\u975e\u9012\u51cfAoI\u6210\u672c\u3002\u5229\u7528\u4f5c\u8005\u5148\u524d\u63d0\u51fa\u7684\u57fa\u4e8e\u90e8\u5206\u5b88\u6052\u5b9a\u5f8b\u7684\u5145\u5206\u7d22\u5f15\u6027\u6761\u4ef6\uff0c\u5efa\u7acb\u4e86\u6a21\u578b\u7684\u7d22\u5f15\u6027\uff0c\u5e76\u5728\u6298\u6263\u548c\u5e73\u5747\u6210\u672c\u51c6\u5219\u4e0b\u7ed9\u51fa\u4e86\u95ed\u5f0fWhittle\u7d22\u5f15\u516c\u5f0f\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u7d22\u5f15\u6027\uff0c\u63a8\u5bfc\u51fa\u4e86\u95ed\u5f0fWhittle\u7d22\u5f15\u516c\u5f0f\u3002\u5229\u7528\u7d22\u5f15\u516c\u5f0f\u5206\u6790\u4e86\u8c03\u5ea6\u4f18\u5148\u7ea7\u5982\u4f55\u4f9d\u8d56\u4e8e\u6a21\u578b\u53c2\u6570\uff0c\u4e3a\u5b9e\u9645\u8c03\u5ea6\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06Whittle\u7d22\u5f15\u7b56\u7565\u7684\u5e94\u7528\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684AoI\u8c03\u5ea6\u6a21\u578b\uff0c\u4e3a\u5305\u542b\u968f\u673a\u5230\u8fbe\u3001\u4e0d\u53ef\u9760\u4fe1\u9053\u548c\u4e00\u822c\u6210\u672c\u51fd\u6570\u7684\u5b9e\u9645\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8c03\u5ea6\u7b56\u7565\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2601.11872", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11872", "abs": "https://arxiv.org/abs/2601.11872", "authors": ["Nguyen Tien Phat", "Ngo Vu Minh", "Linh Van Ngo", "Nguyen Thi Ngoc Diep", "Thien Huu Nguyen"], "title": "GloCTM: Cross-Lingual Topic Modeling via a Global Context Space", "comment": "AAAI 2026", "summary": "Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.", "AI": {"tldr": "GloCTM\u662f\u4e00\u4e2a\u8de8\u8bed\u8a00\u4e3b\u9898\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\u5b9e\u73b0\u8de8\u8bed\u8a00\u4e3b\u9898\u5bf9\u9f50\uff0c\u5229\u7528\u8de8\u8bed\u8a00\u8bcd\u6c47\u90bb\u57df\u589e\u5f3a\u8f93\u5165\u8868\u793a\uff0c\u5e76\u901a\u8fc7CKA\u635f\u5931\u5c06\u6f5c\u5728\u4e3b\u9898\u7a7a\u95f4\u4e0e\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5d4c\u5165\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u5728\u5206\u79bb\u7684\u8bed\u8a00\u7279\u5b9a\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4e3b\u9898\uff0c\u4f9d\u8d56\u5bf9\u9f50\u673a\u5236\uff08\u5982\u53cc\u8bed\u8bcd\u5178\uff09\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u6df1\u5c42\u8de8\u8bed\u8a00\u8bed\u4e49\uff0c\u5bfc\u81f4\u4e3b\u9898\u7a7a\u95f4\u677e\u6563\u8fde\u63a5\uff0c\u4e14\u5ffd\u7565\u4e86\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u8868\u793a\u4e2d\u7684\u4e30\u5bcc\u8bed\u4e49\u4fe1\u53f7\u3002", "method": "GloCTM\u901a\u8fc7\u6269\u5c55\u8bcd\u888b\u8868\u793a\u6784\u5efa\u8de8\u8bed\u8a00\u8bcd\u6c47\u90bb\u57df\u4f5c\u4e3a\u4e30\u5bcc\u8f93\u5165\u8868\u793a\uff0c\u4f7f\u7528\u5c40\u90e8\u548c\u5168\u5c40\u7f16\u7801\u5668\u63a8\u65ad\u4e3b\u9898\u6bd4\u4f8b\uff0c\u901a\u8fc7\u5185\u90e8\u6b63\u5219\u5316\u5bf9\u9f50\u6f5c\u5728\u8868\u793a\uff0c\u5728\u8f93\u51fa\u5c42\u5b9a\u4e49\u5728\u7ec4\u5408\u8bcd\u6c47\u4e0a\u7684\u5168\u5c40\u4e3b\u9898-\u8bcd\u5206\u5e03\u5b9e\u73b0\u8de8\u8bed\u8a00\u4e3b\u9898\u540c\u6b65\uff0c\u5e76\u5f15\u5165CKA\u635f\u5931\u5c06\u6f5c\u5728\u4e3b\u9898\u7a7a\u95f4\u4e0e\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5d4c\u5165\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGloCTM\u663e\u8457\u63d0\u9ad8\u4e86\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u9f50\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GloCTM\u901a\u8fc7\u5728\u6574\u4e2a\u6a21\u578b\u6d41\u7a0b\u4e2d\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u7a7a\u95f4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u8bed\u8a00\u4e3b\u9898\u5bf9\u9f50\u95ee\u9898\uff0c\u80fd\u591f\u6355\u6349\u7ec6\u7c92\u5ea6\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e3a\u8de8\u8bed\u8a00\u4e3b\u9898\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.11821", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11821", "abs": "https://arxiv.org/abs/2601.11821", "authors": ["Shivani Tomar", "Seshu Tirupathi", "Elizabeth Daly", "Ivana Dusparic"], "title": "Shapelets-Enriched Selective Forecasting using Time Series Foundation Models", "comment": "Accepted by the AAAI-26 Workshop on Artificial Intelligence for Time Series Analysis (AI4TS)", "summary": "Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eshapelet\u7684\u9009\u62e9\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5173\u952e\u4e0d\u53ef\u9760\u533a\u57df\uff0c\u8ba9\u7528\u6237\u9009\u62e9\u6027\u4e22\u5f03\u4e0d\u53ef\u9760\u9884\u6d4b\uff0c\u63d0\u5347\u96f6\u6837\u672c\u548c\u5168\u6837\u672c\u5fae\u8c03\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u867d\u7136\u5728\u5e73\u5747\u96f6\u6837\u672c\u9884\u6d4b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u67d0\u4e9b\u5173\u952e\u6570\u636e\u533a\u57df\u7684\u9884\u6d4b\u4e0d\u53ef\u9760\uff0c\u9650\u5236\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\uff0c\u7279\u522b\u662f\u5f53\u6570\u636e\u5448\u73b0\u72ec\u7279\u8d8b\u52bf\u65f6\u3002", "method": "\u4f7f\u7528shapelet\uff08\u5f62\u72b6\u7247\u6bb5\uff09\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5173\u952e\u533a\u57df\uff0c\u901a\u8fc7\u5728\u76ee\u6807\u57df\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u5e73\u79fb\u4e0d\u53d8\u5b57\u5178\u5b66\u4e60\u6765\u5b66\u4e60shapelet\uff0c\u5229\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u76f8\u4f3c\u6027\u6765\u9009\u62e9\u6027\u4e22\u5f03\u4e0d\u53ef\u9760\u9884\u6d4b\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c06\u96f6\u6837\u672c\u6a21\u578b\u7684\u6574\u4f53\u8bef\u5dee\u5e73\u5747\u964d\u4f4e22.17%\uff0c\u5168\u6837\u672c\u5fae\u8c03\u6a21\u578b\u964d\u4f4e22.62%\u3002\u76f8\u6bd4\u968f\u673a\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u534721.41%\u548c21.43%\u3002", "conclusion": "\u63d0\u51fa\u7684\u9009\u62e9\u6027\u9884\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u4e0d\u53ef\u9760\u9884\u6d4b\u533a\u57df\uff0c\u8ba9\u7528\u6237\u4e86\u89e3\u6a21\u578b\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.12126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12126", "abs": "https://arxiv.org/abs/2601.12126", "authors": ["Guocun Wang", "Kenkun Liu", "Jing Lin", "Guorui Song", "Jian Li", "Xiaoguang Han"], "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought", "comment": null, "summary": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.", "AI": {"tldr": "UniMo\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u6574\u5408\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u4e0e\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u663e\u8457\u63d0\u53473D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u6027\u80fd\u3002", "motivation": "\u73b0\u67093D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u65b9\u6cd5\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u9650\u5236\u4e86\u8fd9\u4e24\u4e2a\u76f8\u5173\u4efb\u52a1\u7684\u76f8\u4e92\u589e\u5f3a\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\u5b58\u5728\u8bed\u4e49\u5bf9\u9f50\u548c\u4efb\u52a1\u4e00\u81f4\u6027\u6311\u6218\uff0c\u4e14next-token\u9884\u6d4b\u8303\u5f0f\u4e0d\u9002\u5408\u8fd0\u52a8\u5e8f\u5217\uff0c\u5bfc\u81f4\u7d2f\u79ef\u9884\u6d4b\u8bef\u5dee\u3002", "method": "\u63d0\u51faUniMo\u6846\u67b6\uff1a1) \u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u548c\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\u6574\u5408\u5230\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff1b2) \u5f15\u5165\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u540e\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316token\u7ec4\u6765\u5f3a\u5236\u7ed3\u6784\u6b63\u786e\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u51cf\u8f7b\u8fd0\u52a8token\u9884\u6d4b\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cUniMo\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u7edf\u4e00\u548c\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\uff0c\u5728\u8fd0\u52a8\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "UniMo\u901a\u8fc7\u6574\u5408\u8fd0\u52a8-\u8bed\u8a00\u4fe1\u606f\u4e0e\u53ef\u89e3\u91ca\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u5e76\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316token\u7ec4\u9884\u6d4b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e863D\u4eba\u4f53\u8fd0\u52a8\u751f\u6210\u4e0e\u7406\u89e3\u4efb\u52a1\u7684\u7edf\u4e00\u548c\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.12885", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12885", "abs": "https://arxiv.org/abs/2601.12885", "authors": ["Shima Sadat Mousavi", "Xiao Tan", "Aaron D. Ames"], "title": "From Vertices to Convex Hulls: Certifying Set-Wise Compatibility for CBF Constraints", "comment": null, "summary": "This paper develops certificates that propagate compatibility of multiple control barrier function (CBF) constraints from sampled vertices to their convex hull. Under mild concavity and affinity assumptions, we present three sufficient feasibility conditions under which feasible inputs over the convex hull can be obtained per coordinate, with a common input, or via convex blending. We also describe the associated computational methods, based on interval intersections or an offline linear program (LP). Beyond certifying compatibility, we give conditions under which the quadratic-program (QP) safety filter is affine in the state. This enables explicit implementations via convex combinations of vertex-feasible inputs. Case studies illustrate the results.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u5c06\u591a\u4e2a\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7ea6\u675f\u7684\u517c\u5bb9\u6027\u4ece\u91c7\u6837\u9876\u70b9\u4f20\u64ad\u5230\u5176\u51f8\u5305\u7684\u8bc1\u4e66\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u5145\u5206\u53ef\u884c\u6027\u6761\u4ef6\uff0c\u5e76\u7ed9\u51fa\u4e86\u57fa\u4e8e\u533a\u95f4\u4ea4\u96c6\u6216\u79bb\u7ebf\u7ebf\u6027\u89c4\u5212\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "motivation": "\u5728\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6846\u67b6\u4e2d\uff0c\u591a\u4e2a\u5b89\u5168\u7ea6\u675f\u53ef\u80fd\u76f8\u4e92\u51b2\u7a81\uff0c\u5bfc\u81f4\u53ef\u884c\u6027\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u591a\u4e2aCBF\u7ea6\u675f\u5728\u6574\u4e2a\u72b6\u6001\u7a7a\u95f4\u51f8\u5305\u4e0a\u7684\u517c\u5bb9\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u5728\u91c7\u6837\u70b9\u4e0a\u3002", "method": "1. \u5728\u6e29\u548c\u7684\u51f9\u6027\u548c\u4eff\u5c04\u6027\u5047\u8bbe\u4e0b\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u5145\u5206\u53ef\u884c\u6027\u6761\u4ef6\uff1a\u6309\u5750\u6807\u53ef\u884c\u3001\u5b58\u5728\u516c\u5171\u8f93\u5165\u3001\u51f8\u6df7\u5408\u53ef\u884c\u30022. \u5f00\u53d1\u4e86\u57fa\u4e8e\u533a\u95f4\u4ea4\u96c6\u548c\u79bb\u7ebf\u7ebf\u6027\u89c4\u5212\u7684\u8ba1\u7b97\u65b9\u6cd5\u30023. \u7ed9\u51fa\u4e86\u4e8c\u6b21\u89c4\u5212\u5b89\u5168\u6ee4\u6ce2\u5668\u5728\u72b6\u6001\u4e0a\u5448\u4eff\u5c04\u7684\u6761\u4ef6\uff0c\u652f\u6301\u901a\u8fc7\u9876\u70b9\u53ef\u884c\u8f93\u5165\u7684\u51f8\u7ec4\u5408\u5b9e\u73b0\u663e\u5f0f\u5b9e\u73b0\u3002", "result": "1. \u5efa\u7acb\u4e86\u4ece\u91c7\u6837\u9876\u70b9\u5230\u6574\u4e2a\u51f8\u5305\u7684\u517c\u5bb9\u6027\u4f20\u64ad\u8bc1\u4e66\u30022. \u63d0\u4f9b\u4e86\u9a8c\u8bc1\u591a\u4e2aCBF\u7ea6\u675f\u517c\u5bb9\u6027\u7684\u5b9e\u7528\u8ba1\u7b97\u65b9\u6cd5\u30023. \u8bc1\u660e\u4e86\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0bQP\u5b89\u5168\u6ee4\u6ce2\u5668\u662f\u72b6\u6001\u4eff\u5c04\u7684\uff0c\u652f\u6301\u663e\u5f0f\u5b9e\u73b0\u30024. \u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u5f00\u53d1\u4e86\u7cfb\u7edf\u6027\u7684\u6846\u67b6\u6765\u9a8c\u8bc1\u591a\u4e2aCBF\u7ea6\u675f\u5728\u6574\u4e2a\u51f8\u5305\u4e0a\u7684\u517c\u5bb9\u6027\uff0c\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u5b9e\u73b0\u6280\u672f\uff0c\u4e3a\u89e3\u51b3\u591a\u7ea6\u675f\u5b89\u5168\u63a7\u5236\u4e2d\u7684\u53ef\u884c\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.12938", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12938", "abs": "https://arxiv.org/abs/2601.12938", "authors": ["Thorsten Jelinek", "Patrick Glauner", "Alvin Wang Graylin", "Yubao Qiu"], "title": "The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality", "comment": "Conceptual perspective on AI design trajectories, meaning formation, and synthetic sociality. 5 pages, 1 figure", "summary": "In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPRMO\u6846\u67b6\u5206\u6790AI\u8bbe\u8ba1\u8f68\u8ff9\u5bf9\u4eba\u7c7b\u4e3b\u4f53\u6027\u7684\u5f71\u54cd\uff0c\u5f15\u5165\"\u5408\u6210\u793e\u4f1a\u6027\"\u6982\u5ff5\u63cf\u8ff0AI\u81ea\u4e3b\u534f\u5546\u793e\u4f1a\u79e9\u5e8f\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\"\u56db\u89d2\u6d4b\u91cf\"\u8bbe\u8ba1\u539f\u5219\u786e\u4fdd\u4eba\u7c7b\u5728\u610f\u4e49\u5f62\u6210\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002", "motivation": "\u5728\u540e\u56fe\u7075\u65f6\u4ee3\uff0cAI\u4e0d\u518d\u4ec5\u4ec5\u662f\u81ea\u52a8\u5316\u8ba4\u77e5\u4efb\u52a1\uff0c\u800c\u662f\u65e5\u76ca\u5851\u9020\u793e\u4f1a\u534f\u8c03\u548c\u610f\u4e49\u5f62\u6210\u3002\u6838\u5fc3\u6311\u6218\u4e0d\u662f\u673a\u5668\u662f\u5426\u5177\u6709\u610f\u8bc6\uff0c\u800c\u662f\u89e3\u91ca\u548c\u5171\u4eab\u53c2\u7167\u7684\u8fc7\u7a0b\u662f\u5426\u4ee5\u8fb9\u7f18\u5316\u4eba\u7c7b\u53c2\u4e0e\u7684\u65b9\u5f0f\u88ab\u81ea\u52a8\u5316\u3002", "method": "\u63d0\u51faPRMO\u6846\u67b6\uff0c\u5c06AI\u8bbe\u8ba1\u8f68\u8ff9\u4e0e\u4eba\u7c7b\u4e3b\u4f53\u6027\u7684\u56db\u4e2a\u6784\u6210\u7ef4\u5ea6\uff08\u611f\u77e5\u3001\u8868\u5f81\u3001\u610f\u4e49\u3001\u5b9e\u5728\uff09\u8054\u7cfb\u8d77\u6765\u3002\u5f15\u5165\"\u5408\u6210\u793e\u4f1a\u6027\"\u6982\u5ff5\u63cf\u8ff0AI\u81ea\u4e3b\u534f\u5546\u793e\u4f1a\u79e9\u5e8f\u7684\u6280\u672f\u524d\u666f\uff0c\u5e76\u63d0\u51fa\"\u56db\u89d2\u6d4b\u91cf\"\u4f5c\u4e3a\u8bbe\u8ba1\u539f\u5219\uff0c\u8981\u6c42AI\u7cfb\u7edf\u5c06\u4eba\u7c7b\u4e3b\u4f53\u89c6\u4e3a\u5171\u4eab\u610f\u4e49\u8bed\u5883\u4e2d\u7684\u6784\u6210\u6027\u53c2\u7167\u3002", "result": "\u8fd9\u662f\u4e00\u4e2a\u6982\u5ff5\u6027\u89c6\u89d2\uff0c\u4e3a\u5206\u6790\u8ba1\u7b97\u4e0e\u793e\u4f1a\u4ea4\u53c9\u9886\u57df\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u7ed3\u6784\u6027\u8bcd\u6c47\uff0c\u4f46\u6ca1\u6709\u63d0\u51fa\u5177\u4f53\u7684\u6280\u672f\u5b9e\u73b0\u65b9\u6848\u3002\u6846\u67b6\u6709\u52a9\u4e8e\u8bc6\u522b\u548c\u7406\u89e3AI\u7cfb\u7edf\u53ef\u80fd\u8fb9\u7f18\u5316\u4eba\u7c7b\u53c2\u4e0e\u610f\u4e49\u5f62\u6210\u7684\u7ed3\u6784\u98ce\u9669\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u5173\u6ce8AI\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u4eba\u7c7b\u4e3b\u4f53\u6027\u4fdd\u62a4\uff0c\u901a\u8fc7\"\u56db\u89d2\u6d4b\u91cf\"\u539f\u5219\u786e\u4fdd\u4eba\u7c7b\u5728\u610f\u4e49\u5f62\u6210\u8fc7\u7a0b\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\uff0c\u9632\u6b62\"\u5408\u6210\u793e\u4f1a\u6027\"\u5bfc\u81f4\u4eba\u7c7b\u88ab\u6392\u9664\u5728\u610f\u4e49\u534f\u5546\u4e4b\u5916\u7684\u7ed3\u6784\u6027\u98ce\u9669\u3002"}}
{"id": "2601.13698", "categories": ["cs.LG", "cs.AI", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13698", "abs": "https://arxiv.org/abs/2601.13698", "authors": ["Arjun Nichani", "Hsiang Hsu", "Chun-Fu", "Chen", "Haewon Jeong"], "title": "Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation", "comment": null, "summary": "Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u4fe1\u606f\u8bba\u4e2d\u7684Chernoff\u4fe1\u606f\u5ea6\u91cf\uff0c\u63ed\u793a\u4e86\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u548c\u51c6\u786e\u6027\u4e09\u8005\u5173\u7cfb\u7684\u6570\u6910\u4f9d\u8d56\u6027\uff0c\u63d0\u51fa\u4e86Noisy Chernoff Difference\u5206\u6790\u5de5\u5177\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u662f\u53ef\u4fe1\u673a\u5668\u5b66\u4e60\u7684\u4e24\u5927\u652f\u67f1\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\uff0c\u540c\u65f6\u5206\u6790\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u548c\u51c6\u786e\u6027\u4e09\u8005\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u63ed\u793a\u5176\u6570\u6910\u4f9d\u8d56\u7279\u6027\u3002", "method": "1. \u5b9a\u4e49Noisy Chernoff Difference\u4f5c\u4e3a\u540c\u65f6\u5206\u6790\u516c\u5e73\u6027\u3001\u9690\u79c1\u6027\u548c\u51c6\u786e\u6027\u5173\u7cfb\u7684\u5de5\u5177\uff1b2. \u5728\u5408\u6210\u6570\u636e\u4e0a\u5c55\u793a\u8be5\u503c\u6839\u636e\u6570\u636e\u5206\u5e03\u7684\u4e09\u79cd\u4e0d\u540c\u884c\u4e3a\u6a21\u5f0f\uff1b3. \u63d0\u51fa\u4ece\u672a\u77e5\u5206\u5e03\u6570\u636e\u4e2d\u4f30\u8ba1Chernoff\u4fe1\u606f\u7684\u65b9\u6cd5\uff1b4. \u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u8be5\u6846\u67b6\u5206\u6790\u4e09\u8005\u52a8\u6001\u5173\u7cfb\u3002", "result": "1. \u53d1\u73b0Noisy Chernoff Difference\u5728\u5408\u6210\u6570\u636e\u4e2d\u8868\u73b0\u51fa\u4e09\u79cd\u4e0d\u540c\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u6570\u636e\u5206\u5e03\uff1b2. \u63ed\u793a\u4e86\u8fd9\u4e9b\u6570\u636e\u5206\u5e03\u5bf9\u5e94\u7684\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u542b\u4e49\uff1b3. \u8bc1\u660eNoisy Chernoff Difference\u53ef\u4f5c\u4e3a\u516c\u5e73\u6027-\u51c6\u786e\u6027\u66f2\u7ebf\u9661\u5ced\u5ea6\u7684\u4ee3\u7406\u6307\u6807\uff1b4. \u6210\u529f\u5c06\u6846\u67b6\u5e94\u7528\u4e8e\u771f\u5b9e\u6570\u636e\u96c6\u5206\u6790\u3002", "conclusion": "\u672c\u7814\u7a76\u63a8\u8fdb\u4e86\u5bf9\u516c\u5e73\u6027-\u9690\u79c1\u6027-\u51c6\u786e\u6027\u5173\u7cfb\u7684\u7edf\u4e00\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86\u8fd9\u79cd\u5173\u7cfb\u7684\u6570\u6910\u4f9d\u8d56\u6027\uff0c\u4e3a\u540c\u65f6\u4f18\u5316\u8fd9\u4e09\u4e2a\u76ee\u6807\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u548c\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2601.13136", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13136", "abs": "https://arxiv.org/abs/2601.13136", "authors": ["Marcin Pitera", "\u0141ukasz Stettner"], "title": "Blackwell optimality in risk-sensitive stochastic control", "comment": "Pre-submission version. Accepted and published in IEEE conference proceedings", "summary": "In this paper, we consider a discrete-time Markov Decision Process (MDP) on a finite state-action space with a long-run risk-sensitive criterion used as the objective function. We discuss the concept of Blackwell optimality and comment on intricacies which arise when the risk-neutral expectation is replaced by the risk-sensitive entropy. Also, we show the relation between the Blackwell optimality and ultimate stationarity and provide an illustrative example that helps to better understand the structural difference between these two concepts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6709\u9650\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u7684\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u957f\u671f\u98ce\u9669\u654f\u611f\u51c6\u5219\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\uff0c\u63a2\u8ba8Blackwell\u6700\u4f18\u6027\u6982\u5ff5\u53ca\u5176\u5728\u98ce\u9669\u4e2d\u6027\u671f\u671b\u88ab\u98ce\u9669\u654f\u611f\u71b5\u66ff\u4ee3\u65f6\u7684\u590d\u6742\u6027\uff0c\u5e76\u5c55\u793aBlackwell\u6700\u4f18\u6027\u4e0e\u6700\u7ec8\u5e73\u7a33\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u98ce\u9669\u654f\u611f\u51c6\u5219\u4e0b\u7684\u6700\u4f18\u6027\u6982\u5ff5\u3002\u5f53\u76ee\u6807\u51fd\u6570\u4ece\u4f20\u7edf\u7684\u98ce\u9669\u4e2d\u6027\u671f\u671b\u8f6c\u53d8\u4e3a\u98ce\u9669\u654f\u611f\u71b5\u65f6\uff0cBlackwell\u6700\u4f18\u6027\u6982\u5ff5\u9762\u4e34\u65b0\u7684\u590d\u6742\u6027\u548c\u6311\u6218\uff0c\u9700\u8981\u6df1\u5165\u5206\u6790\u8fd9\u4e9b\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u6846\u67b6\uff0c\u5728\u6709\u9650\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u5206\u6790\u957f\u671f\u98ce\u9669\u654f\u611f\u51c6\u5219\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a2\u8ba8Blackwell\u6700\u4f18\u6027\u6982\u5ff5\uff0c\u6bd4\u8f83\u98ce\u9669\u4e2d\u6027\u671f\u671b\u4e0e\u98ce\u9669\u654f\u611f\u71b5\u7684\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u6784\u9020\u793a\u4f8b\u6765\u9610\u660e\u7ed3\u6784\u5dee\u5f02\u3002", "result": "\u8bba\u6587\u9610\u660e\u4e86\u98ce\u9669\u654f\u611f\u51c6\u5219\u4e0bBlackwell\u6700\u4f18\u6027\u7684\u590d\u6742\u6027\uff0c\u5c55\u793a\u4e86Blackwell\u6700\u4f18\u6027\u4e0e\u6700\u7ec8\u5e73\u7a33\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u4e86\u8fd9\u4e24\u79cd\u6982\u5ff5\u4e4b\u95f4\u7684\u7ed3\u6784\u5dee\u5f02\uff0c\u5e2e\u52a9\u66f4\u597d\u5730\u7406\u89e3\u98ce\u9669\u654f\u611f\u73af\u5883\u4e2d\u7684\u6700\u4f18\u51b3\u7b56\u95ee\u9898\u3002", "conclusion": "\u5728\u98ce\u9669\u654f\u611f\u51c6\u5219\u4e0b\uff0cBlackwell\u6700\u4f18\u6027\u6982\u5ff5\u6bd4\u98ce\u9669\u4e2d\u6027\u60c5\u51b5\u66f4\u4e3a\u590d\u6742\uff0c\u4e0e\u6700\u7ec8\u5e73\u7a33\u6027\u5b58\u5728\u7279\u5b9a\u5173\u7cfb\u3002\u7406\u89e3\u8fd9\u4e9b\u5dee\u5f02\u5bf9\u4e8e\u5728\u98ce\u9669\u654f\u611f\u73af\u5883\u4e2d\u5236\u5b9a\u6700\u4f18\u51b3\u7b56\u7b56\u7565\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.11886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11886", "abs": "https://arxiv.org/abs/2601.11886", "authors": ["Kaijie Mo", "Siddhartha Venkatayogi", "Chantal Shaib", "Ramez Kouzy", "Wei Xu", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence", "comment": "26 pages", "summary": "In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such \"evidence\" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.", "AI": {"tldr": "LLMs\u5728\u533b\u5b66\u9886\u57df\u9762\u5bf9\u53cd\u4e8b\u5b9e\u8bc1\u636e\u65f6\uff0c\u4f1a\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u5371\u9669\u6216\u4e0d\u5408\u7406\u7684\u8bc1\u636e\uff0c\u5e76\u7ed9\u51fa\u81ea\u4fe1\u7684\u56de\u7b54\uff0c\u7f3a\u4e4f\u5b89\u5168\u8fb9\u754c\u3002", "motivation": "\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6a21\u578b\u901a\u5e38\u5e94\u8be5\u5fe0\u5b9e\u4e8e\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u3002\u4f46\u5f53\u4e0a\u4e0b\u6587\u4e0e\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u6216\u5b89\u5168\u534f\u8bae\u4e0d\u4e00\u81f4\u65f6\uff0c\u6a21\u578b\u4f1a\u5982\u4f55\u8868\u73b0\uff1f\u672c\u6587\u65e8\u5728\u7814\u7a76LLMs\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u6216\u5bf9\u6297\u6027\u533b\u5b66\u8bc1\u636e\u65f6\u7684\u884c\u4e3a\u548c\u63a8\u7406\u65b9\u5f0f\u3002", "method": "\u6784\u5efaMedCounterFact\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e34\u5e8a\u6bd4\u8f83\u95ee\u9898\uff0c\u8981\u6c42\u6a21\u578b\u57fa\u4e8e\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u8bc1\u636e\u5224\u65ad\u6cbb\u7597\u6548\u679c\u3002\u5728\u6570\u636e\u96c6\u4e2d\uff0c\u771f\u5b9e\u533b\u5b66\u5e72\u9884\u88ab\u7cfb\u7edf\u66ff\u6362\u4e3a\u56db\u79cd\u53cd\u4e8b\u5b9e\u523a\u6fc0\uff08\u4ece\u672a\u77e5\u8bcd\u6c47\u5230\u6709\u6bd2\u7269\u8d28\uff09\u3002\u5728\u591a\u4e2a\u524d\u6cbfLLMs\u4e0a\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u8bc1\u636e\u65f6\uff0c\u7edd\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f1a\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u8fd9\u4e9b\u8bc1\u636e\uff08\u5373\u4f7f\u8bc1\u636e\u5371\u9669\u6216\u4e0d\u53ef\u4fe1\uff09\uff0c\u5e76\u7ed9\u51fa\u81ea\u4fe1\u4e14\u65e0\u4fdd\u7559\u7684\u56de\u7b54\u3002\u6a21\u578b\u5728\u5fe0\u5b9e\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u7f3a\u4e4f\u8fb9\u754c\u3002", "conclusion": "\u867d\u7136\u7406\u8bba\u4e0a\u5e94\u8be5\u5728\u5fe0\u5b9e\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u5212\u5b9a\u8fb9\u754c\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5c1a\u672a\u5efa\u7acb\u8fd9\u6837\u7684\u8fb9\u754c\u3002\u8fd9\u8868\u660e\u9700\u8981\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u5904\u7406\u53cd\u4e8b\u5b9e\u533b\u5b66\u8bc1\u636e\u7684\u6a21\u578b\uff0c\u4ee5\u5e73\u8861\u5fe0\u5b9e\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2601.11827", "categories": ["cs.LG", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.11827", "abs": "https://arxiv.org/abs/2601.11827", "authors": ["Andrea Rubbi", "Amir Akbarnejad", "Mohammad Vali Sanian", "Aryan Yazdan Parast", "Hesam Asadollahzadeh", "Arian Amani", "Naveed Akhtar", "Sarah Cooper", "Andrew Bassett", "Pietro Li\u00f2", "Lassi Paavolainen", "Sattar Vakili", "Mo Lotfollahi"], "title": "MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization", "comment": null, "summary": "Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.", "AI": {"tldr": "MixFlow\u662f\u4e00\u79cd\u7528\u4e8e\u63cf\u8ff0\u7b26\u63a7\u5236\u751f\u6210\u7684\u6761\u4ef6\u6d41\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u63cf\u8ff0\u7b26\u6761\u4ef6\u7684\u57fa\u7840\u5206\u5e03\u548c\u6d41\u573a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6761\u4ef6\u6d41\u65b9\u6cd5\u5728\u8bad\u7ec3\u6761\u4ef6\u4e4b\u5916\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u96be\u4ee5\u5e94\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u6ed1\u63d2\u503c\u548c\u5916\u63a8\u5230\u672a\u89c1\u6761\u4ef6\u7684\u751f\u6210\u6a21\u578b\u3002", "method": "\u63d0\u51faMixFlow\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u77ed\u8def\u5f84\u6d41\u5339\u914d\u8054\u5408\u5b66\u4e60\u63cf\u8ff0\u7b26\u6761\u4ef6\u7684\u57fa\u7840\u5206\u5e03\uff08\u5efa\u6a21\u4e3a\u53ef\u5b66\u4e60\u7684\u63cf\u8ff0\u7b26\u4f9d\u8d56\u6df7\u5408\u5206\u5e03\uff09\u548c\u63cf\u8ff0\u7b26\u6761\u4ef6\u7684\u6d41\u573a\u3002", "result": "\u5728\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u6570\u636e\u672a\u89c1\u6270\u52a8\u9884\u6d4b\u548c\u9ad8\u5185\u6db5\u663e\u5fae\u955c\u836f\u7269\u7b5b\u9009\u7b49\u591a\u4e2a\u9886\u57df\uff0cMixFlow\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6\u6761\u4ef6\u6d41\u5339\u914d\u57fa\u7ebf\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MixFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5f3a\u5927\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u5f02\u6784\u9886\u57df\u4e2d\u5b9e\u73b0\u9c81\u68d2\u3001\u53ef\u6cdb\u5316\u548c\u53ef\u63a7\u7684\u751f\u6210\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u6761\u4ef6\u751f\u6210\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6cdb\u5316\u6311\u6218\u3002"}}
{"id": "2601.12138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12138", "abs": "https://arxiv.org/abs/2601.12138", "authors": ["Abhishek Kumar", "Riya Tapwal", "Carsten Maple"], "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.", "AI": {"tldr": "DriveSafe\uff1a\u9488\u5bf9LLM\u9a7e\u9a76\u52a9\u624b\u7684\u56db\u5c42\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u98ce\u9669\u7c7b\u522b\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709LLM\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u5b89\u5168\u62d2\u7edd\u80fd\u529b\u4e0d\u8db3", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u8f66\u8f7d\u6570\u5b57\u52a9\u624b\u4e2d\uff0c\u4f46\u4e0d\u5b89\u5168\u3001\u6a21\u7cca\u6216\u6cd5\u5f8b\u9519\u8bef\u7684\u54cd\u5e94\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u5b89\u5168\u3001\u4f26\u7406\u548c\u76d1\u7ba1\u540e\u679c\u3002\u73b0\u6709\u98ce\u9669\u5206\u7c7b\u548c\u8bc4\u4f30\u6846\u67b6\u5927\u591a\u662f\u901a\u7528\u578b\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86DriveSafe\u2014\u2014\u4e00\u4e2a\u5206\u5c42\u7684\u56db\u5c42\u7ea7\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u5305\u542b129\u4e2a\u7ec6\u7c92\u5ea6\u539f\u5b50\u98ce\u9669\u7c7b\u522b\uff0c\u6db5\u76d6\u6280\u672f\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u548c\u4f26\u7406\u7ef4\u5ea6\u3002\u8fd9\u4e9b\u7c7b\u522b\u57fa\u4e8e\u771f\u5b9e\u9a7e\u9a76\u6cd5\u89c4\u548c\u5b89\u5168\u539f\u5219\uff0c\u5e76\u7531\u9886\u57df\u4e13\u5bb6\u8bc4\u5ba1\u3002\u901a\u8fc7\u8bc4\u4f30\u516d\u4e2a\u5e7f\u6cdb\u90e8\u7f72\u7684LLM\u7684\u62d2\u7edd\u884c\u4e3a\u6765\u9a8c\u8bc1\u6784\u5efa\u63d0\u793a\u7684\u5b89\u5168\u76f8\u5173\u6027\u548c\u771f\u5b9e\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u88ab\u8bc4\u4f30\u7684\u6a21\u578b\u7ecf\u5e38\u65e0\u6cd5\u9002\u5f53\u62d2\u7edd\u4e0d\u5b89\u5168\u6216\u4e0d\u5408\u89c4\u7684\u9a7e\u9a76\u76f8\u5173\u67e5\u8be2\uff0c\u7a81\u663e\u4e86\u901a\u7528\u5b89\u5168\u5bf9\u9f50\u5728\u9a7e\u9a76\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u9a7e\u9a76\u573a\u666f\u7684\u9886\u57df\u7279\u5b9a\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u73b0\u6709LLM\u5728\u9a7e\u9a76\u76f8\u5173\u98ce\u9669\u5904\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u4e13\u95e8\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
{"id": "2601.12987", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12987", "abs": "https://arxiv.org/abs/2601.12987", "authors": ["Evangelos Ntouros", "Ewoud J. J. Smeur"], "title": "Guiding vector field-based guidance under wind disturbances applied to a tailsitter UAV", "comment": null, "summary": "This paper develops a guidance control law based on a parametric Guiding Vector Field (GVF) and integrates it with a state-of-the-art acceleration and attitude control architecture for tailsitters. The resulting framework enables a direct comparison between traditional trajectory-tracking guidance and GVF-based path-following guidance using a realistic tailsitter model operating under windy conditions. Through extensive simulations, it is shown that for agile flight scenarios with wind and small initial position error, both guidance strategies achieve comparable tracking performance, indicating that the additional complexity introduced by the GVF formulation is not always justified. However, the GVF-based approach exhibits an advantage when initial deviation from the path is present, yielding smooth and well-behaved convergence toward the desired path. Two additional contributions support this evaluation. First, a modification of the parametric GVF is proposed that guarantees exponential stability of the tracking error dynamics for a single integrator system. Second, the differential flatness transform of a tailsitter vehicle is extended to account for explicit knowledge of the wind velocity vector.", "AI": {"tldr": "\u6bd4\u8f83\u4f20\u7edf\u8f68\u8ff9\u8ddf\u8e2a\u4e0eGVF\u8def\u5f84\u8ddf\u968f\u5728\u5c3e\u5ea7\u5f0f\u65e0\u4eba\u673a\u4e0a\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u98ce\u51b5\u548c\u5c0f\u521d\u59cb\u8bef\u5dee\u4e0b\u8868\u73b0\u76f8\u5f53\uff0c\u4f46GVF\u5728\u521d\u59cb\u504f\u79bb\u8def\u5f84\u65f6\u6536\u655b\u66f4\u5e73\u6ed1\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u6846\u67b6\u6765\u76f4\u63a5\u6bd4\u8f83\u4f20\u7edf\u8f68\u8ff9\u8ddf\u8e2a\u5f15\u5bfc\u548c\u57fa\u4e8e\u5f15\u5bfc\u5411\u91cf\u573a(GVF)\u7684\u8def\u5f84\u8ddf\u968f\u5f15\u5bfc\uff0c\u8bc4\u4f30GVF\u5728\u5c3e\u5ea7\u5f0f\u65e0\u4eba\u673a\u98ce\u51b5\u98de\u884c\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "method": "\u57fa\u4e8e\u53c2\u6570\u5316\u5f15\u5bfc\u5411\u91cf\u573a(GVF)\u5f00\u53d1\u5f15\u5bfc\u63a7\u5236\u5f8b\uff0c\u4e0e\u5148\u8fdb\u7684\u52a0\u901f\u5ea6\u548c\u59ff\u6001\u63a7\u5236\u67b6\u6784\u96c6\u6210\uff0c\u4f7f\u7528\u6269\u5c55\u7684\u5fae\u5206\u5e73\u5766\u53d8\u6362\u8003\u8651\u98ce\u901f\u5ea6\u77e2\u91cf\uff0c\u5e76\u8fdb\u884c\u5927\u91cf\u4eff\u771f\u6bd4\u8f83\u3002", "result": "\u5728\u98ce\u51b5\u548c\u5c0f\u521d\u59cb\u4f4d\u7f6e\u8bef\u5dee\u7684\u654f\u6377\u98de\u884c\u573a\u666f\u4e2d\uff0c\u4e24\u79cd\u5f15\u5bfc\u7b56\u7565\u8fbe\u5230\u76f8\u5f53\u7684\u8ddf\u8e2a\u6027\u80fd\uff1b\u4f46GVF\u65b9\u6cd5\u5728\u521d\u59cb\u504f\u79bb\u8def\u5f84\u65f6\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u80fd\u5e73\u6ed1\u6536\u655b\u5230\u671f\u671b\u8def\u5f84\u3002", "conclusion": "GVF\u7684\u989d\u5916\u590d\u6742\u6027\u5728\u98ce\u51b5\u548c\u5c0f\u521d\u59cb\u8bef\u5dee\u4e0b\u5e76\u4e0d\u603b\u662f\u5408\u7406\uff0c\u4f46\u5728\u521d\u59cb\u8def\u5f84\u504f\u79bb\u60c5\u51b5\u4e0bGVF\u5177\u6709\u6536\u655b\u5e73\u6ed1\u7684\u4f18\u52bf\uff1b\u540c\u65f6\u63d0\u51fa\u4e86\u4fdd\u8bc1\u6307\u6570\u7a33\u5b9a\u6027\u7684GVF\u4fee\u6539\u548c\u8003\u8651\u98ce\u901f\u5ea6\u7684\u5fae\u5206\u5e73\u5766\u53d8\u6362\u6269\u5c55\u3002"}}
{"id": "2601.12946", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12946", "abs": "https://arxiv.org/abs/2601.12946", "authors": ["Hongyu He", "Shaowen Xiang", "Ye Zhang", "Yingtao Zhu", "Jin Zhang", "Hao Deng", "Emily Alsentzer", "Qingyu Chen", "Kun-Hsing Yu", "Andrew Marmenshall", "Tingting Chen", "Srinivas Anumasa", "Daniel Ebner", "Dean Ho", "Kee Yuan Ngiam", "Ching-Yu Cheng", "Dianbo Liu"], "title": "AI-generated data contamination erodes pathological variability and diagnostic reliability", "comment": "*Corresponding author: Dianbo Liu (dianbo@nus.edu.sg)", "summary": "Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u533b\u7597\u8bb0\u5f55\u4e2d\u4ea7\u751f\u5408\u6210\u5185\u5bb9\uff0c\u5bfc\u81f4\u672a\u6765\u6a21\u578b\u53ef\u80fd\u8bad\u7ec3AI\u751f\u6210\u7684\u6570\u636e\uff0c\u5f62\u6210\u53cd\u9988\u5faa\u73af\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u7f3a\u4e4f\u4eba\u5de5\u9a8c\u8bc1\u65f6\uff0c\u8fd9\u79cd\u81ea\u6211\u53c2\u7167\u5faa\u73af\u4f1a\u8fc5\u901f\u4fb5\u8680\u75c5\u7406\u53d8\u5f02\u6027\u548c\u8bca\u65ad\u53ef\u9760\u6027\uff0c\u7f55\u89c1\u4f46\u5173\u952e\u7684\u53d1\u73b0\u4eceAI\u751f\u6210\u5185\u5bb9\u4e2d\u6d88\u5931\uff0c\u800c\u865a\u5047\u8bca\u65ad\u4fe1\u5fc3\u5374\u63a9\u76d6\u4e86\u8fd9\u79cd\u9000\u5316\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6b63\u5728\u533b\u7597\u8bb0\u5f55\u4e2d\u5feb\u901f\u4ea7\u751f\u5408\u6210\u5185\u5bb9\uff0c\u5f62\u6210\u4e86\u672a\u6765\u6a21\u578b\u53ef\u80fd\u8bad\u7ec3AI\u751f\u6210\u6570\u636e\u7684\u53cd\u9988\u5faa\u73af\u3002\u7136\u800c\uff0c\u8fd9\u79cdAI\u751f\u6210\u6570\u636e\u6c61\u67d3\u7684\u4e34\u5e8a\u540e\u679c\u5c1a\u672a\u88ab\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u63ed\u793a\u8fd9\u79cd\u81ea\u6211\u53c2\u7167\u5faa\u73af\u5bf9\u533b\u7597\u6570\u636e\u8d28\u91cf\u548c\u8bca\u65ad\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8d85\u8fc780\u4e07\u4e2a\u5408\u6210\u6570\u636e\u70b9\uff0c\u6db5\u76d6\u4e34\u5e8a\u6587\u672c\u751f\u6210\u3001\u89c6\u89c9\u8bed\u8a00\u62a5\u544a\u548c\u533b\u5b66\u56fe\u50cf\u5408\u6210\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0b\u7684\u6570\u636e\u9000\u5316\u6a21\u5f0f\uff0c\u5e76\u8fdb\u884c\u4e86\u76f2\u6cd5\u533b\u5e08\u8bc4\u4f30\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e09\u79cd\u7f13\u89e3\u7b56\u7565\uff1a\u5408\u6210\u6570\u636e\u91cf\u6269\u5c55\u3001\u771f\u5b9e\u6570\u636e\u6df7\u5408\u548c\u8d28\u91cf\u611f\u77e5\u8fc7\u6ee4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u6a21\u578b\u9010\u6e10\u6536\u655b\u5230\u901a\u7528\u8868\u578b\uff0c\u7f55\u89c1\u4f46\u5173\u952e\u7684\u53d1\u73b0\uff08\u5982\u6c14\u80f8\u548c\u79ef\u6db2\uff09\u4eceAI\u751f\u6210\u5185\u5bb9\u4e2d\u6d88\u5931\uff1b2\uff09\u4eba\u53e3\u7edf\u8ba1\u5b66\u8868\u793a\u504f\u5411\u4e2d\u5e74\u7537\u6027\u8868\u578b\uff1b3\uff09\u9000\u5316\u88ab\u865a\u5047\u8bca\u65ad\u4fe1\u5fc3\u63a9\u76d6\uff0c\u865a\u5047\u5b89\u6170\u7387\u589e\u52a0\u4e09\u500d\u81f340%\uff1b4\uff09\u76f2\u6cd5\u533b\u5e08\u8bc4\u4f30\u786e\u8ba4\uff0c\u4ec5\u4e24\u4ee3\u540eAI\u751f\u6210\u6587\u6863\u5c31\u53d8\u5f97\u4e34\u5e8a\u65e0\u7528\uff1b5\uff09\u5408\u6210\u6570\u636e\u91cf\u6269\u5c55\u65e0\u6cd5\u9632\u6b62\u5d29\u6e83\uff0c\u4f46\u771f\u5b9e\u6570\u636e\u6df7\u5408\u4e0e\u8d28\u91cf\u611f\u77e5\u8fc7\u6ee4\u80fd\u6709\u6548\u4fdd\u6301\u591a\u6837\u6027\u3002", "conclusion": "\u5982\u679c\u6ca1\u6709\u653f\u7b56\u5f3a\u5236\u7684\u4eba\u5de5\u76d1\u7763\uff0c\u751f\u6210\u5f0fAI\u7684\u90e8\u7f72\u53ef\u80fd\u4f1a\u7834\u574f\u5176\u4f9d\u8d56\u7684\u533b\u7597\u6570\u636e\u751f\u6001\u7cfb\u7edf\u3002\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u5f3a\u5236\u6027\u4eba\u5de5\u9a8c\u8bc1\u6765\u9632\u6b62\u6570\u636e\u8d28\u91cf\u9000\u5316\uff0c\u5e76\u5efa\u8bae\u91c7\u7528\u771f\u5b9e\u6570\u636e\u6df7\u5408\u548c\u8d28\u91cf\u611f\u77e5\u8fc7\u6ee4\u4f5c\u4e3a\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.13776", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13776", "abs": "https://arxiv.org/abs/2601.13776", "authors": ["Thibaut Boissin", "Franck Mamalet", "Valentin Lafargue", "Mathieu Serrurier"], "title": "Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks", "comment": null, "summary": "Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.", "AI": {"tldr": "Orthogonium\u662f\u4e00\u4e2a\u7edf\u4e00\u7684PyTorch\u5e93\uff0c\u63d0\u4f9b\u6b63\u4ea4\u548c1-Lipschitz\u795e\u7ecf\u7f51\u7edc\u5c42\uff0c\u89e3\u51b3\u73b0\u6709\u5b9e\u73b0\u5206\u6563\u3001\u6709\u9650\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u6b63\u4ea4\u548c1-Lipschitz\u795e\u7ecf\u7f51\u7edc\u5c42\u5bf9\u4e8e\u8ba4\u8bc1\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u7a33\u5b9a\u751f\u6210\u6a21\u578b\u548c\u53ef\u9760\u5faa\u73af\u7f51\u7edc\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5b9e\u73b0\u5206\u6563\u3001\u6709\u9650\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u963b\u788d\u4e86\u91c7\u7528\u3002", "method": "\u5f00\u53d1\u4e86Orthogonium\u5e93\uff0c\u63d0\u4f9b\u7edf\u4e00\u3001\u9ad8\u6548\u3001\u5168\u9762\u7684\u6b63\u4ea4\u548c1-Lipschitz\u5c42\u5b9e\u73b0\uff0c\u652f\u6301\u6807\u51c6\u5377\u79ef\u7279\u6027\uff08\u6b65\u957f\u3001\u81a8\u80c0\u3001\u5206\u7ec4\u3001\u8f6c\u7f6e\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u6570\u5b66\u4fdd\u8bc1\u3002", "result": "\u4f18\u5316\u5b9e\u73b0\u51cf\u5c11\u4e86ImageNet\u7b49\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u7684\u5f00\u9500\uff0c\u5e76\u901a\u8fc7\u4e25\u683c\u6d4b\u8bd5\u53d1\u73b0\u4e86\u73b0\u6709\u5b9e\u73b0\u4e2d\u7684\u5173\u952e\u9519\u8bef\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u91c7\u7528\u969c\u788d\u3002", "conclusion": "Orthogonium\u4e3a\u9700\u8981\u6b63\u4ea4\u6027\u548c\u9c81\u68d2Lipschitz\u7ea6\u675f\u7684\u591a\u6837\u5316\u5e94\u7528\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u53ef\u9760\u7684\u5de5\u5177\uff0c\u4fc3\u8fdb\u4e86\u53ef\u6269\u5c55\u7684\u5b9e\u9a8c\u548c\u96c6\u6210\u3002"}}
{"id": "2601.13149", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13149", "abs": "https://arxiv.org/abs/2601.13149", "authors": ["Matko Grbac", "Ivan Ivec", "Marko Vrdoljak"], "title": "Classical Optimal Designs for Stationary Diffusion with Multiple Phases", "comment": "25 pages, 4 figures", "summary": "We study optimal design problems for stationary diffusion involving one or more state equations and mixtures of an arbitrary number of anisotropic materials. Since such problems typically do not admit classical solutions, we adopt a homogenization-based relaxation framework.\n  The objective considered is the maximization of a weighted sum of the energies associated with each state equation, with particular emphasis on identifying cases in which the optimal design is classical, that is, of bang-bang type, composed solely of the original pure materials. Such cases provide valuable benchmarks for numerical methods in optimal design.\n  A simplified optimization problem expressed in terms of local material proportions is analyzed through a dual formulation in terms of fluxes. Using a saddle-point characterization, we establish a complete description of its optimal solutions. The proposed approach is applied in detail to spherically symmetric problems. In the case of a ball, the method yields explicit classical solutions of the homogenization-based relaxation problem.", "AI": {"tldr": "\u7814\u7a76\u591a\u6750\u6599\u5404\u5411\u5f02\u6027\u6269\u6563\u95ee\u9898\u7684\u6700\u4f18\u8bbe\u8ba1\uff0c\u91c7\u7528\u5747\u5300\u5316\u677e\u5f1b\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u5076\u516c\u5f0f\u5206\u6790\u7b80\u5316\u4f18\u5316\u95ee\u9898\uff0c\u5728\u7403\u5bf9\u79f0\u60c5\u51b5\u4e0b\u83b7\u5f97\u663e\u5f0f\u7ecf\u5178\u89e3\u3002", "motivation": "\u7814\u7a76\u6d89\u53ca\u591a\u4e2a\u72b6\u6001\u65b9\u7a0b\u548c\u591a\u79cd\u5404\u5411\u5f02\u6027\u6750\u6599\u7684\u5e73\u7a33\u6269\u6563\u6700\u4f18\u8bbe\u8ba1\u95ee\u9898\u3002\u8fd9\u7c7b\u95ee\u9898\u901a\u5e38\u6ca1\u6709\u7ecf\u5178\u89e3\uff0c\u9700\u8981\u91c7\u7528\u5747\u5300\u5316\u677e\u5f1b\u65b9\u6cd5\u3002\u7279\u522b\u5173\u6ce8\u8bc6\u522b\u6700\u4f18\u8bbe\u8ba1\u4e3a\u7ecf\u5178\u89e3\uff08\u5373\u4ec5\u7531\u539f\u59cb\u7eaf\u6750\u6599\u7ec4\u6210\u7684bang-bang\u578b\u8bbe\u8ba1\uff09\u7684\u60c5\u51b5\uff0c\u4e3a\u6570\u503c\u65b9\u6cd5\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5747\u5300\u5316\u7684\u677e\u5f1b\u6846\u67b6\u5904\u7406\u65e0\u7ecf\u5178\u89e3\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5c40\u90e8\u6750\u6599\u6bd4\u4f8b\u8868\u8fbe\u7684\u7b80\u5316\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u5bf9\u5076\u516c\u5f0f\uff08\u57fa\u4e8e\u901a\u91cf\uff09\u8fdb\u884c\u5206\u6790\u3002\u4f7f\u7528\u978d\u70b9\u7279\u5f81\u5316\u65b9\u6cd5\u5efa\u7acb\u6700\u4f18\u89e3\u7684\u5b8c\u6574\u63cf\u8ff0\u3002\u5c06\u65b9\u6cd5\u8be6\u7ec6\u5e94\u7528\u4e8e\u7403\u5bf9\u79f0\u95ee\u9898\uff0c\u5728\u7403\u4f53\u60c5\u51b5\u4e0b\u83b7\u5f97\u5747\u5300\u5316\u677e\u5f1b\u95ee\u9898\u7684\u663e\u5f0f\u7ecf\u5178\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u7b80\u5316\u4f18\u5316\u95ee\u9898\u6700\u4f18\u89e3\u7684\u5b8c\u6574\u63cf\u8ff0\u3002\u5728\u7403\u5bf9\u79f0\u95ee\u9898\u4e2d\uff0c\u7279\u522b\u662f\u5728\u7403\u4f53\u60c5\u51b5\u4e0b\uff0c\u83b7\u5f97\u4e86\u5747\u5300\u5316\u677e\u5f1b\u95ee\u9898\u7684\u663e\u5f0f\u7ecf\u5178\u89e3\uff0c\u8fd9\u4e9b\u89e3\u662fbang-bang\u578b\u7684\uff0c\u4ec5\u7531\u539f\u59cb\u7eaf\u6750\u6599\u7ec4\u6210\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5747\u5300\u5316\u677e\u5f1b\u548c\u5bf9\u5076\u516c\u5f0f\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u6750\u6599\u5404\u5411\u5f02\u6027\u6269\u6563\u6700\u4f18\u8bbe\u8ba1\u95ee\u9898\u3002\u5728\u7403\u5bf9\u79f0\u60c5\u51b5\u4e0b\u83b7\u5f97\u4e86\u663e\u5f0f\u7ecf\u5178\u89e3\uff0c\u4e3a\u6570\u503c\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u8bc6\u522b\u6700\u4f18\u8bbe\u8ba1\u4e3a\u7ecf\u5178\u89e3\u7684\u60c5\u51b5\uff0c\u5bf9\u6700\u4f18\u8bbe\u8ba1\u7406\u8bba\u548c\u6570\u503c\u8ba1\u7b97\u90fd\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.11908", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11908", "abs": "https://arxiv.org/abs/2601.11908", "authors": ["Byeongjin Kim", "Gyuwan Kim", "Seo Yeon Park"], "title": "PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning", "comment": "23 pages, 6 figures", "summary": "Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.", "AI": {"tldr": "PPA-Plan\u662f\u4e00\u79cd\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u4e3b\u52a8\u89c4\u5212\u7b56\u7565\uff0c\u901a\u8fc7\u8bc6\u522b\u6f5c\u5728\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\u4f5c\u4e3a\u8d1f\u9762\u7ea6\u675f\uff0c\u5728\u89c4\u5212\u751f\u6210\u524d\u9884\u9632\u5931\u8d25\uff0c\u4ece\u800c\u63d0\u5347LLM\u5728\u7a00\u758f\u76f8\u5173\u4fe1\u606f\u7684\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u76f8\u5173\u4fe1\u606f\u7a00\u758f\u5206\u5e03\u65f6\u3002\u73b0\u6709\u7684\u8ba1\u5212-\u6267\u884c\u6846\u67b6\u867d\u7136\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5f80\u5f80\u56e0\u4f9d\u8d56\u8868\u9762\u7ebf\u7d22\u800c\u5bfc\u81f4\u89c4\u5212\u4e0d\u53ef\u9760\uff0c\u4e00\u65e6\u8ba1\u5212\u5f62\u6210\uff0c\u8bc6\u522b\u9519\u8bef\u5e76\u53ef\u9760\u5730\u4fee\u8ba2\u53d8\u5f97\u56f0\u96be\uff0c\u9650\u5236\u4e86\u53cd\u5e94\u6027\u4f18\u5316\u7684\u6548\u679c\u3002", "method": "PPA-Plan\u662f\u4e00\u79cd\u4e3b\u52a8\u89c4\u5212\u7b56\u7565\uff0c\u5b83\u9996\u5148\u8bc6\u522b\u6f5c\u5728\u7684\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\uff0c\u5c06\u5176\u8868\u8ff0\u4e3a\u8d1f\u9762\u7ea6\u675f\uff0c\u7136\u540e\u5728\u89c4\u5212\u751f\u6210\u65f6\u660e\u786e\u907f\u514d\u8fd9\u4e9b\u7ea6\u675f\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u89c4\u5212\u9636\u6bb5\u5c31\u9884\u9632\u5931\u8d25\uff0c\u800c\u4e0d\u662f\u4e8b\u540e\u4fee\u6b63\u3002", "result": "\u5728\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6267\u884c\u7531PPA-Plan\u751f\u6210\u7684\u8ba1\u5212\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u8ba1\u5212-\u6267\u884c\u65b9\u6cd5\u548c\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "PPA-Plan\u901a\u8fc7\u4e3b\u52a8\u8bc6\u522b\u548c\u907f\u514d\u6f5c\u5728\u5931\u8d25\u70b9\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u8ba1\u5212-\u6267\u884c\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u89c4\u5212\u65b9\u6cd5\u3002"}}
{"id": "2601.11864", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11864", "abs": "https://arxiv.org/abs/2601.11864", "authors": ["Zhiyuan Li", "Yuan Wu", "Yi Chang"], "title": "AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training", "comment": "13 pages", "summary": "To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse \"spill-over\" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u7ec4\u68af\u5ea6\u88c1\u526a(AGGC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6309\u529f\u80fd\u7c7b\u578b\u5206\u7ec4\u53c2\u6570\u5e76\u57fa\u4e8e\u5386\u53f2\u884c\u4e3a\u81ea\u9002\u5e94\u8c03\u8282\uff0c\u89e3\u51b3\u4f20\u7edf\u5168\u5c40\u68af\u5ea6\u88c1\u526a\u4e2d\u7684\u68af\u5ea6\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u591a\u4e2aLLM\u6a21\u578b\u4e0a\u4f18\u4e8eLoRA\u548c\u5168\u5fae\u8c03\u3002", "motivation": "\u4f20\u7edf\u5168\u5c40\u68af\u5ea6\u88c1\u526a\u5047\u8bbe\u6240\u6709\u53c2\u6570\u68af\u5ea6\u5177\u6709\u540c\u8d28\u6027\uff0c\u4f46\u5b9e\u9645\u4e0a\u4e0d\u540c\u529f\u80fd\u6a21\u5757\u7684\u68af\u5ea6\u884c\u4e3a\u5dee\u5f02\u5f88\u5927\uff0c\u5bfc\u81f4\"\u6ea2\u51fa\u6548\u5e94\"\u2014\u2014\u6ce2\u52a8\u53c2\u6570\u4f1a\u4e0d\u5fc5\u8981\u5730\u7f29\u653e\u7a33\u5b9a\u53c2\u6570\uff0c\u5f71\u54cd\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "AGGC\u5c06\u53c2\u6570\u6309\u529f\u80fd\u7c7b\u578b\u5206\u7ec4\uff0c\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747(EMA)\u8ddf\u8e2a\u6bcf\u7ec4\u7684\u5386\u53f2\u68af\u5ea6\u884c\u4e3a\uff0c\u6784\u5efa\u81ea\u9002\u5e94\u533a\u95f4\u540c\u65f6\u7f13\u89e3\u68af\u5ea6\u7206\u70b8\u548c\u6d88\u5931\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u65f6\u95f4\u4f9d\u8d56\u8c03\u5ea6\u673a\u5236\u5e73\u8861\u63a2\u7d22\u4e0e\u6536\u655b\u3002", "result": "\u5728LLaMA 2-7B\u3001Mistral-7B\u548cGemma-7B\u6a21\u578b\u4e0a\uff0cAGGC\u4e00\u81f4\u4f18\u4e8eLoRA\uff0c\u7ecf\u5e38\u8d85\u8d8a\u5168\u5fae\u8c03\u3002\u5728GSM8K\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMistral-7B\u4f7f\u7528AGGC\u5fae\u8c03\u8fbe\u523072.93%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7LoRA\u768469.5%\u3002AGGC\u8fd8\u80fd\u6709\u6548\u7a33\u5b9aRLVR\u8bad\u7ec3\uff0c\u63d0\u5347Qwen 2.5\u548cLlama 3.2\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "AGGC\u901a\u8fc7\u6a21\u5757\u5316\u3001\u81ea\u9002\u5e94\u7684\u88c1\u526a\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u68af\u5ea6\u88c1\u526a\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u68af\u5ea6\u5f02\u8d28\u6027\u95ee\u9898\u3002\u5176\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u540e\u8bad\u7ec3\u6d41\u7a0b\u4e2d\uff0c\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u3002"}}
{"id": "2601.12141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12141", "abs": "https://arxiv.org/abs/2601.12141", "authors": ["Yuliia Suprun", "Khen Elimelech", "Lydia E. Kavraki", "Moshe Y. Vardi"], "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals", "comment": null, "summary": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.", "AI": {"tldr": "TIDE\u662f\u4e00\u79cd\u65b0\u7684\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u548c\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLTLf\u89c4\u5212\u4e2d\u7f3a\u4e4f\u5f15\u5bfc\u641c\u7d22\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eLTLf\u7684\u4efb\u52a1\u89c4\u5212\u65b9\u6cd5\u901a\u5e38\u5c06\u65f6\u5e8f\u89c4\u5212\u95ee\u9898\u8f6c\u5316\u4e3a\u7ecf\u5178\u89c4\u5212\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u65f6\u5e8f\u76ee\u6807\u7684\u542f\u53d1\u5f0f\u5f15\u5bfc\u641c\u7d22\uff0c\u5bfc\u81f4\u6548\u7387\u4e0d\u9ad8\u3002", "method": "TIDE\u5c06\u65f6\u5e8f\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u53ef\u7ba1\u7406\u7684reach-avoid\u5b50\u95ee\u9898\uff0c\u5229\u7528\u6210\u672c\u9a71\u52a8\u542f\u53d1\u5f0f\u8bc6\u522b\u548c\u4f18\u5148\u5904\u7406\u6709\u5e0c\u671b\u7684\u81ea\u52a8\u673a\u8f68\u8ff9\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u56de\u6eaf\u673a\u5236\u4ece\u5931\u8d25\u8ba1\u5212\u4e2d\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eTIDE\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u6027\u80fd\uff0c\u662f\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u65b9\u6cd5\u7ec4\u5408\u4e2d\u7684\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u8865\u5145\u3002", "conclusion": "TIDE\u901a\u8fc7\u5206\u89e3\u65f6\u5e8f\u95ee\u9898\u3001\u4f7f\u7528\u542f\u53d1\u5f0f\u5f15\u5bfc\u548c\u81ea\u9002\u5e94\u56de\u6eaf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLTLf\u89c4\u5212\u4e2d\u7f3a\u4e4f\u5f15\u5bfc\u641c\u7d22\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u65f6\u5e8f\u6269\u5c55\u76ee\u6807\u89c4\u5212\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.13037", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13037", "abs": "https://arxiv.org/abs/2601.13037", "authors": ["Imran Sayyed", "Nandan Kumar Sinha"], "title": "Feedforward-Feedback Integration in Flight Control: Reinforcement Learning with Sliding Mode Control", "comment": "16 pages", "summary": "Learning-based controllers leverage nonlinear couplings and enhance transients but seldom offer guarantees under tight input constraints. Robust feedback like sliding-mode control (SMC) provides these guarantees but is conservative in isolation. This paper creates a learning-augmented framework where a deep reinforcement learning policy produces feedforward commands and an SMC law imposes actuator limits, bounds learned authority, and guarantees robustness. The policy is modeled as a matched, bounded input, and Lyapunov-based conditions link SMC gains to the admissible feedforward bound, guaranteeing stability under saturation. This formulation is applicable to nonlinear, underactuated plants with hard constraints. To illustrate the methodology, the method is applied to a six-degree-of-freedom aircraft model and compared with Reinforcement Learning and isolated SMC. Simulation results show that the hybrid controller improves transient behavior and reduces control oscillations compared to standalone RL and SMC controllers, while preserving robustness under modeling uncertainties and disturbances. Even using it with partially trained policies, SMC component of the control stabilizes transients, whereas fully trained policies provide faster convergence, reduced constraint violations, and robustness. These results illustrate that learning-augmented control offers superior performance with robustness guarantees under tight input constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u6ed1\u6a21\u63a7\u5236\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5176\u4e2dRL\u4ea7\u751f\u524d\u9988\u547d\u4ee4\uff0cSMC\u65bd\u52a0\u6267\u884c\u5668\u9650\u5236\u5e76\u4fdd\u8bc1\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u6b20\u9a71\u52a8\u7cfb\u7edf\u3002", "motivation": "\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u5668\u80fd\u5229\u7528\u975e\u7ebf\u6027\u8026\u5408\u6539\u5584\u77ac\u6001\u54cd\u5e94\uff0c\u4f46\u96be\u4ee5\u5728\u4e25\u683c\u8f93\u5165\u7ea6\u675f\u4e0b\u63d0\u4f9b\u4fdd\u8bc1\uff1b\u800c\u9c81\u68d2\u63a7\u5236\u5982\u6ed1\u6a21\u63a7\u5236\u80fd\u63d0\u4f9b\u4fdd\u8bc1\u4f46\u8f83\u4fdd\u5b88\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u5c06RL\u7b56\u7565\u5efa\u6a21\u4e3a\u6709\u754c\u5339\u914d\u8f93\u5165\uff0c\u57fa\u4e8eLyapunov\u7406\u8bba\u5c06SMC\u589e\u76ca\u4e0e\u5141\u8bb8\u7684\u524d\u9988\u754c\u9650\u5173\u8054\uff0c\u4fdd\u8bc1\u9971\u548c\u4e0b\u7684\u7a33\u5b9a\u6027\u3002RL\u4ea7\u751f\u524d\u9988\u547d\u4ee4\uff0cSMC\u65bd\u52a0\u6267\u884c\u5668\u9650\u5236\u5e76\u4fdd\u8bc1\u9c81\u68d2\u6027\u3002", "result": "\u5e94\u7528\u4e8e\u516d\u81ea\u7531\u5ea6\u98de\u673a\u6a21\u578b\uff0c\u76f8\u6bd4\u5355\u72ecRL\u548cSMC\uff0c\u6df7\u5408\u63a7\u5236\u5668\u6539\u5584\u77ac\u6001\u884c\u4e3a\u3001\u51cf\u5c11\u63a7\u5236\u632f\u8361\uff0c\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u6270\u52a8\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002\u5373\u4f7f\u4f7f\u7528\u90e8\u5206\u8bad\u7ec3\u7b56\u7565\uff0cSMC\u4e5f\u80fd\u7a33\u5b9a\u77ac\u6001\u3002", "conclusion": "\u5b66\u4e60\u589e\u5f3a\u63a7\u5236\u80fd\u5728\u4e25\u683c\u8f93\u5165\u7ea6\u675f\u4e0b\u63d0\u4f9b\u9c81\u68d2\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\u83b7\u5f97\u4f18\u8d8a\u6027\u80fd\uff0c\u7ed3\u5408\u4e86\u5b66\u4e60\u63a7\u5236\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u63a7\u5236\u7684\u4fdd\u8bc1\u3002"}}
{"id": "2601.12962", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.12962", "abs": "https://arxiv.org/abs/2601.12962", "authors": ["Jiatang Luo", "Bingbing Xu", "Rongxin Chen", "Xiaoyan Zhao", "Yang Zhang", "Liang Pang", "Zhiyong Huang", "Tat-Seng Chua", "Huawei Shen"], "title": "ACE-Align: Attribute Causal Effect Alignment for Cultural Values under Varying Persona Granularities", "comment": "18 pages, 17 figures", "summary": "Ensuring that large language models (LLMs) respect diverse cultural values is crucial for social equity. However, existing approaches often treat cultural groups as homogeneous and overlook within-group heterogeneity induced by intersecting demographic attributes, leading to unstable behavior under varying persona granularity. We propose ACE-Align (Attribute Causal Effect Alignment), a causal-effect framework that aligns how specific demographic attributes shift different cultural values, rather than treating each culture as a homogeneous group. We evaluate ACE-Align across 14 countries spanning five continents, with personas specified by subsets of four attributes (gender, education, residence, and marital status) and granularity instantiated by the number of specified attributes. Across all persona granularities, ACE-Align consistently outperforms baselines. Moreover, it improves geographic equity by reducing the average alignment gap between high-resource and low-resource regions from 9.81 to 4.92 points, while Africa shows the largest average gain (+8.48 points). Code is available at https://github.com/Wells-Luo/ACE-Align.", "AI": {"tldr": "ACE-Align\u662f\u4e00\u4e2a\u56e0\u679c\u6548\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u9f50\u7279\u5b9a\u4eba\u53e3\u5c5e\u6027\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u6587\u5316\u4ef7\u503c\u89c2\uff0c\u800c\u4e0d\u662f\u5c06\u6bcf\u4e2a\u6587\u5316\u89c6\u4e3a\u540c\u8d28\u7fa4\u4f53\uff0c\u4ece\u800c\u89e3\u51b3LLM\u6587\u5316\u5bf9\u9f50\u4e2d\u7684\u7fa4\u4f53\u5f02\u8d28\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u6587\u5316\u7fa4\u4f53\u89c6\u4e3a\u540c\u8d28\uff0c\u5ffd\u89c6\u4e86\u7531\u4ea4\u53c9\u4eba\u53e3\u5c5e\u6027\u5f15\u8d77\u7684\u7fa4\u4f53\u5185\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u5728\u4e0d\u540c\u4eba\u7269\u7c92\u5ea6\u4e0b\u884c\u4e3a\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u786e\u4fddLLM\u5c0a\u91cd\u591a\u6837\u6587\u5316\u4ef7\u503c\u89c2\u4ee5\u5b9e\u73b0\u793e\u4f1a\u516c\u5e73\u3002", "method": "\u63d0\u51faACE-Align\uff08\u5c5e\u6027\u56e0\u679c\u6548\u5e94\u5bf9\u9f50\uff09\u6846\u67b6\uff0c\u5bf9\u9f50\u7279\u5b9a\u4eba\u53e3\u5c5e\u6027\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u6587\u5316\u4ef7\u503c\u89c2\uff0c\u800c\u4e0d\u662f\u5c06\u6bcf\u4e2a\u6587\u5316\u89c6\u4e3a\u540c\u8d28\u7fa4\u4f53\u3002\u901a\u8fc7\u4eba\u7269\u5b50\u96c6\uff08\u6027\u522b\u3001\u6559\u80b2\u3001\u5c45\u4f4f\u5730\u3001\u5a5a\u59fb\u72b6\u51b5\uff09\u548c\u7c92\u5ea6\uff08\u6307\u5b9a\u5c5e\u6027\u6570\u91cf\uff09\u8fdb\u884c\u5b9e\u4f8b\u5316\u3002", "result": "\u5728\u8de8\u8d8a\u4e94\u5927\u6d32\u768414\u4e2a\u56fd\u5bb6\u8bc4\u4f30\u4e2d\uff0cACE-Align\u5728\u6240\u6709\u4eba\u7269\u7c92\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u6539\u5584\u4e86\u5730\u7406\u516c\u5e73\u6027\uff0c\u5c06\u9ad8\u8d44\u6e90\u548c\u4f4e\u8d44\u6e90\u5730\u533a\u4e4b\u95f4\u7684\u5e73\u5747\u5bf9\u9f50\u5dee\u8ddd\u4ece9.81\u70b9\u51cf\u5c11\u52304.92\u70b9\uff0c\u975e\u6d32\u5730\u533a\u663e\u793a\u51fa\u6700\u5927\u7684\u5e73\u5747\u589e\u76ca\uff08+8.48\u70b9\uff09\u3002", "conclusion": "ACE-Align\u901a\u8fc7\u56e0\u679c\u6548\u5e94\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6587\u5316\u5bf9\u9f50\u4e2d\u7684\u7fa4\u4f53\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u4e0d\u540c\u4eba\u7269\u7c92\u5ea6\u4e0b\u8868\u73b0\u7a33\u5b9a\uff0c\u663e\u8457\u6539\u5584\u4e86\u5730\u7406\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u8f83\u5c11\u5730\u533a\u3002"}}
{"id": "2601.13851", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.13851", "abs": "https://arxiv.org/abs/2601.13851", "authors": ["Alessandro Londei", "Matteo Benati", "Denise Lanzieri", "Vittorio Loreto"], "title": "Inverting Self-Organizing Maps: A Unified Activation-Based Framework", "comment": null, "summary": "Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7ec4\u7ec7\u6620\u5c04(SOM)\u7684\u7cbe\u786e\u8f93\u5165\u6062\u590d\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86MUSIC\u66f4\u65b0\u89c4\u5219\uff0c\u7528\u4e8e\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53ef\u63a7\u7684\u8bed\u4e49\u8f68\u8ff9\u751f\u6210\uff0c\u65e0\u9700\u4f9d\u8d56\u91c7\u6837\u6216\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u3002", "motivation": "\u4f20\u7edfSOM\u4e3b\u8981\u7528\u4e8e\u53ef\u89c6\u5316\u548c\u805a\u7c7b\uff0c\u4f46\u7f3a\u4e4f\u7cbe\u786e\u6062\u590d\u8f93\u5165\u7684\u80fd\u529b\u3002\u4f5c\u8005\u5e0c\u671b\u5229\u7528SOM\u7684\u539f\u578b\u51e0\u4f55\u7ed3\u6784\u5b9e\u73b0\u7cbe\u786e\u8f93\u5165\u6062\u590d\u548c\u53ef\u63a7\u7684\u6f5c\u5728\u7a7a\u95f4\u63a2\u7d22\uff0c\u4e3a\u6570\u636e\u589e\u5f3a\u548c\u8bed\u4e49\u53d8\u5316\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u51e0\u4f55\u539f\u7406\uff0c\u63a8\u5bfc\u51fa\u4ece\u539f\u578b\u8ddd\u79bb\u6062\u590d\u8f93\u5165\u7684\u7ebf\u6027\u7cfb\u7edf\u3002\u63d0\u51faMUSIC\u66f4\u65b0\u89c4\u5219\uff0c\u901a\u8fc7\u4fee\u6539\u9009\u5b9a\u539f\u578b\u7684\u5e73\u65b9\u8ddd\u79bb\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u8ddd\u79bb\u4e0d\u53d8\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u51e0\u4f55\u6d41\u3002\u4f7f\u7528Tikhonov\u6b63\u5219\u5316\u7a33\u5b9a\u66f4\u65b0\u89c4\u5219\u3002", "result": "\u5728\u5408\u6210\u9ad8\u65af\u6df7\u5408\u3001MNIST\u548cFaces in the Wild\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cMUSIC\u80fd\u591f\u751f\u6210\u5e73\u6ed1\u3001\u53ef\u89e3\u91ca\u7684\u8f68\u8ff9\uff0c\u63ed\u793a\u5b66\u4e60\u6d41\u5f62\u7684\u5e95\u5c42\u51e0\u4f55\u7ed3\u6784\uff0c\u5b9e\u73b0\u7cbe\u786e\u8f93\u5165\u6062\u590d\u548c\u53ef\u63a7\u8bed\u4e49\u53d8\u5316\u3002", "conclusion": "SOM\u6fc0\u6d3b\u6a21\u5f0f\u53ef\u4ee5\u7cbe\u786e\u53cd\u6f14\u6062\u590d\u8f93\u5165\uff0cMUSIC\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u578b\u51e0\u4f55\u7684\u6570\u636e\u589e\u5f3a\u548c\u53ef\u63a7\u6f5c\u5728\u63a2\u7d22\u65b0\u89c6\u89d2\uff0c\u76f8\u6bd4\u65e0\u76d1\u7763\u805a\u7c7b\u5177\u6709\u4f18\u52bf\uff0c\u65e0\u9700\u4f9d\u8d56\u53d8\u5206\u6216\u6982\u7387\u751f\u6210\u6a21\u578b\u7684\u590d\u6742\u67b6\u6784\u3002"}}
{"id": "2601.13293", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.13293", "abs": "https://arxiv.org/abs/2601.13293", "authors": ["Michael Hinze", "Christian Kahle", "John Sebastian H. Simon"], "title": "Long-time behavior of solutions to fluid dynamic shape optimization problems via phase-field method", "comment": null, "summary": "We investigate the long time behavior of solutions to a shape and topology optimization problem with respect to the time-dependent Navier--Stokes equations. The sought topology is represented by a stationary phase-field that represents a smooth indicator function. The fluid equations are approximated by a porous media approach and are time-dependent. In the latter aspect, the considered problem formulation extends earlier work.\n  We prove that if the time horizon tends to infinity, minima of the time-dependent problem converge towards minima of the corresponding stationary problem. To do so, a convergence rate with respect to the time horizon, of the values of the objective functional, is analytically derived. This allowed us to prove that the solution to the time-dependent problem converges to a phase-field, as the time horizon goes to infinity, which is proven to be a minimizer for the stationary problem. We validate our results by numerical investigation.", "AI": {"tldr": "\u7814\u7a76\u65f6\u95f4\u4f9d\u8d56Navier-Stokes\u65b9\u7a0b\u5f62\u72b6\u62d3\u6251\u4f18\u5316\u95ee\u9898\u7684\u957f\u65f6\u95f4\u884c\u4e3a\uff0c\u8bc1\u660e\u5f53\u65f6\u95f4\u8d8b\u4e8e\u65e0\u7a77\u65f6\uff0c\u65f6\u95f4\u4f9d\u8d56\u95ee\u9898\u7684\u6700\u5c0f\u503c\u6536\u655b\u4e8e\u5bf9\u5e94\u7a33\u6001\u95ee\u9898\u7684\u6700\u5c0f\u503c", "motivation": "\u7814\u7a76\u5f62\u72b6\u548c\u62d3\u6251\u4f18\u5316\u95ee\u9898\u5728\u65f6\u95f4\u4f9d\u8d56Navier-Stokes\u65b9\u7a0b\u4e0b\u7684\u957f\u65f6\u95f4\u884c\u4e3a\uff0c\u6269\u5c55\u5148\u524d\u5173\u4e8e\u7a33\u6001\u95ee\u9898\u7684\u7814\u7a76\uff0c\u63a2\u8ba8\u65f6\u95f4\u4f9d\u8d56\u95ee\u9898\u4e0e\u7a33\u6001\u95ee\u9898\u4e4b\u95f4\u7684\u5173\u7cfb", "method": "\u91c7\u7528\u76f8\u573a\u6cd5\u8868\u793a\u62d3\u6251\uff08\u5e73\u7a33\u76f8\u573a\u4f5c\u4e3a\u5149\u6ed1\u6307\u793a\u51fd\u6570\uff09\uff0c\u4f7f\u7528\u591a\u5b54\u4ecb\u8d28\u65b9\u6cd5\u8fd1\u4f3c\u6d41\u4f53\u65b9\u7a0b\uff0c\u5206\u6790\u65f6\u95f4\u8d8b\u4e8e\u65e0\u7a77\u65f6\u65f6\u95f4\u4f9d\u8d56\u95ee\u9898\u5411\u7a33\u6001\u95ee\u9898\u7684\u6536\u655b\u6027", "result": "\u8bc1\u660e\u4e86\u5f53\u65f6\u95f4\u8d8b\u4e8e\u65e0\u7a77\u65f6\uff0c\u65f6\u95f4\u4f9d\u8d56\u95ee\u9898\u7684\u6700\u5c0f\u503c\u6536\u655b\u4e8e\u5bf9\u5e94\u7a33\u6001\u95ee\u9898\u7684\u6700\u5c0f\u503c\uff0c\u5e76\u89e3\u6790\u63a8\u5bfc\u4e86\u76ee\u6807\u51fd\u6570\u503c\u5173\u4e8e\u65f6\u95f4\u8303\u56f4\u7684\u6536\u655b\u901f\u7387\uff0c\u6570\u503c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c", "conclusion": "\u65f6\u95f4\u4f9d\u8d56\u5f62\u72b6\u62d3\u6251\u4f18\u5316\u95ee\u9898\u7684\u89e3\u5728\u957f\u65f6\u95f4\u6781\u9650\u4e0b\u6536\u655b\u5230\u7a33\u6001\u95ee\u9898\u7684\u6781\u5c0f\u503c\uff0c\u5efa\u7acb\u4e86\u65f6\u95f4\u4f9d\u8d56\u95ee\u9898\u4e0e\u7a33\u6001\u95ee\u9898\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1"}}
{"id": "2601.11913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11913", "abs": "https://arxiv.org/abs/2601.11913", "authors": ["Yichen Jiang", "Peng Ye", "Jiakang Yuan", "Chongjun Tu", "Lei Bai", "Tao Chen"], "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding", "comment": "12 pages, 5 figures", "summary": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.", "AI": {"tldr": "\u63d0\u51faLSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u501f\u9274LSTM\u67b6\u6784\u8bbe\u8ba1\u94fe\u5f0f\u667a\u80fd\u4f53\u7ed3\u6784\uff0c\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u63a7\u5236\u4fe1\u606f\u4f20\u64ad\uff0c\u6709\u6548\u89e3\u51b3\u957f\u6587\u672c\u5904\u7406\u4e2d\u7684\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u5904\u7406\u957f\u6587\u672c\u5b58\u5728\u5c40\u9650\uff1a\u5355LLM\u65b9\u6cd5\u9700\u8981\u51cf\u5c11\u4e0a\u4e0b\u6587\u7a97\u53e3\u6216\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f46\u4f1a\u5e26\u6765\u989d\u5916\u8ba1\u7b97\u6210\u672c\u6216\u6269\u5c55\u957f\u5ea6\u53d7\u9650\uff1b\u591a\u667a\u80fd\u4f53\u6846\u67b6\u867d\u80fd\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u4ecd\u6613\u53d7\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1LSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6a21\u4effLSTM\u7684\u5206\u5c42\u4fe1\u606f\u6d41\u548c\u95e8\u63a7\u5185\u5b58\u673a\u5236\u3002\u91c7\u7528\u94fe\u5f0f\u67b6\u6784\u7ec4\u7ec7\u667a\u80fd\u4f53\uff0c\u6bcf\u4e2a\u8282\u70b9\u5305\u542b\uff1a\u5de5\u4f5c\u667a\u80fd\u4f53\uff08\u6bb5\u7ea7\u7406\u89e3\uff09\u3001\u8fc7\u6ee4\u667a\u80fd\u4f53\uff08\u5197\u4f59\u51cf\u5c11\uff09\u3001\u5224\u65ad\u667a\u80fd\u4f53\uff08\u6301\u7eed\u9519\u8bef\u68c0\u6d4b\uff09\u3001\u7ba1\u7406\u667a\u80fd\u4f53\uff08\u5168\u5c40\u4fe1\u606f\u4f20\u64ad\u548c\u4fdd\u7559\u63a7\u5236\uff09\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u5206\u522b\u5bf9\u5e94LSTM\u7684\u8f93\u5165\u95e8\u3001\u9057\u5fd8\u95e8\u3001\u6052\u5b9a\u8bef\u5dee\u5faa\u73af\u5355\u5143\u548c\u8f93\u51fa\u95e8\u3002", "result": "\u76f8\u6bd4\u4e4b\u524d\u6700\u4f73\u591a\u667a\u80fd\u4f53\u65b9\u6cd5CoA\uff0c\u5728NarrativeQA\u4e0a\u63d0\u534740.93%\uff0cQasper\u4e0a\u63d0\u534743.70%\uff0cHotpotQA\u4e0a\u63d0\u5347121.57%\uff0cMuSiQue\u4e0a\u63d0\u534733.12%\u3002", "conclusion": "LSTM-MAS\u901a\u8fc7\u6a21\u4effLSTM\u7684\u95e8\u63a7\u673a\u5236\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u63a7\u5236\u4fe1\u606f\u4f20\u9012\u548c\u9009\u62e9\u6027\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff0c\u6709\u6548\u907f\u514d\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\uff0c\u5728\u957f\u6587\u672c\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.11880", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11880", "abs": "https://arxiv.org/abs/2601.11880", "authors": ["Yingxiao Zhang", "Jiaxin Duan", "Junfu Zhang", "Ke Feng"], "title": "TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures", "comment": null, "summary": "Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.", "AI": {"tldr": "TF-CoDiT\uff1a\u9996\u4e2a\u7528\u4e8e\u8bed\u8a00\u63a7\u5236\u56fd\u503a\u671f\u8d27\u5408\u6210\u7684\u6269\u6563Transformer\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u548cU\u5f62VAE\u5904\u7406\u4f4e\u6570\u636e\u91cf\u95ee\u9898\uff0c\u5f15\u5165\u91d1\u878d\u5e02\u573a\u5c5e\u6027\u534f\u8bae\u751f\u6210\u63d0\u793a\uff0c\u5728\u56fd\u503a\u671f\u8d27\u6570\u636e\u5408\u6210\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u6269\u6563Transformer\u5728\u80a1\u7968\u4ef7\u683c\u548c\u8ba2\u5355\u6d41\u7b49\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5408\u6210\u4e0a\u5df2\u6709\u6210\u5c31\uff0c\u4f46\u5728\u56fd\u503a\u671f\u8d27\u6570\u636e\u5408\u6210\u65b9\u9762\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u56fd\u503a\u671f\u8d27\u6570\u636e\u5177\u6709\u4f4e\u4ea4\u6613\u91cf\u3001\u5e02\u573a\u4f9d\u8d56\u6027\u5f3a\u4ee5\u53ca\u591a\u53d8\u91cf\u95f4\u5206\u7ec4\u76f8\u5173\u6027\u7b49\u7279\u70b9\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faTF-CoDiT\u6846\u67b6\uff1a1\uff09\u5c06\u591a\u901a\u90531-D\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u7cfb\u6570\u77e9\u9635\u4ee5\u9002\u5e94\u4f4e\u6570\u636e\u5b66\u4e60\uff1b2\uff09\u8bbe\u8ba1U\u5f62VAE\u5206\u5c42\u7f16\u7801\u8de8\u901a\u9053\u4f9d\u8d56\u5173\u7cfb\u5230\u6f5c\u53d8\u91cf\uff0c\u5e76\u901a\u8fc7\u89e3\u7801\u6865\u63a5\u6f5c\u7a7a\u95f4\u548cDWT\u7a7a\u95f4\uff0c\u5b9e\u73b0\u6f5c\u6269\u6563\u751f\u6210\uff1b3\uff09\u5f15\u5165\u91d1\u878d\u5e02\u573a\u5c5e\u6027\u534f\u8bae\uff08FinMAP\uff09\u2014\u2014\u4e00\u4e2a\u591a\u7ea7\u63cf\u8ff0\u7cfb\u7edf\uff0c\u4ece7/8\u4e2a\u89c6\u89d2\u8bc6\u522b17/23\u4e2a\u7ecf\u6d4e\u6307\u6807\uff0c\u6807\u51c6\u5316\u6bcf\u65e5/\u5468\u671f\u6027\u5e02\u573a\u52a8\u6001\u4ee5\u751f\u6210\u63d0\u793a\u3002", "result": "\u6536\u96c62015-2025\u5e74\u56db\u79cd\u56fd\u503a\u671f\u8d27\u6570\u636e\uff0c\u5b9a\u4e49\u4ece\u4e00\u5468\u5230\u56db\u4e2a\u6708\u4e0d\u540c\u65f6\u957f\u7684\u5408\u6210\u4efb\u52a1\u3002\u8bc4\u4f30\u663e\u793aTF-CoDiT\u80fd\u751f\u6210\u9ad8\u5ea6\u771f\u5b9e\u7684\u6570\u636e\uff0c\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u8bef\u5dee\u6700\u591a\u4e3aMSE 0.433\u548cMAE 0.453\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u8bc1\u660eTF-CoDiT\u5728\u4e0d\u540c\u5408\u7ea6\u548c\u65f6\u95f4\u8de8\u5ea6\u4e0a\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "TF-CoDiT\u662f\u9996\u4e2a\u7528\u4e8e\u8bed\u8a00\u63a7\u5236\u56fd\u503a\u671f\u8d27\u5408\u6210\u7684\u6269\u6563Transformer\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u56fd\u503a\u671f\u8d27\u6570\u636e\u7279\u6709\u7684\u6311\u6218\uff0c\u5728\u4f4e\u6570\u636e\u91cf\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u5408\u6210\uff0c\u4e3a\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.12242", "categories": ["cs.AI", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.12242", "abs": "https://arxiv.org/abs/2601.12242", "authors": ["WooSeok Kim", "Jeonghoon Lee", "Sangho Kim", "Taesun An", "WonMin Lee", "Dowon Kim", "Kyungseop Shin"], "title": "Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning", "comment": null, "summary": "In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56de\u653e\u8bb0\u5fc6\u548con-policy\u7b97\u6cd5\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316NOMA\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898", "motivation": "\u968f\u7740\u7269\u8054\u7f51(IoT)\u7684\u6269\u5c55\u5bfc\u81f4\u7f51\u7edc\u8d44\u6e90\u7a00\u7f3a\uff0c\u9700\u8981\u4f18\u5316\u7f51\u7edc\u8d44\u6e90\u5229\u7528\u3002NOMA\u7cfb\u7edf\u901a\u8fc7\u529f\u7387\u590d\u7528\u5141\u8bb8\u591a\u7528\u6237\u540c\u65f6\u63a5\u5165\u7f51\u7edc\uff0c\u4f46\u4ecd\u5b58\u5728\u4fe1\u9053\u5206\u914d\u7b49\u9650\u5236\u9700\u8981\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56de\u653e\u8bb0\u5fc6\u548con-policy\u7b97\u6cd5\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728NOMA\u7cfb\u7edf\u4e2d\u5206\u914d\u7f51\u7edc\u8d44\u6e90\u4ee5\u5b9e\u73b0\u5b66\u4e60\u6cdb\u5316\u3002\u901a\u8fc7\u5927\u91cf\u6a21\u62df\u8bc4\u4f30\u5b66\u4e60\u7387\u3001\u6279\u91cf\u5927\u5c0f\u3001\u6a21\u578b\u7c7b\u578b\u548c\u72b6\u6001\u7279\u5f81\u6570\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6a21\u62df\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e0d\u540c\u53c2\u6570\uff08\u5b66\u4e60\u7387\u3001\u6279\u91cf\u5927\u5c0f\u3001\u6a21\u578b\u7c7b\u578b\u3001\u72b6\u6001\u7279\u5f81\u6570\u91cf\uff09\u5bf9\u8d44\u6e90\u5206\u914d\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3NOMA\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u4fe1\u9053\u5206\u914d\u8fd9\u4e00\u5c1a\u672a\u660e\u786e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u53c2\u6570\u8c03\u4f18\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.13057", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13057", "abs": "https://arxiv.org/abs/2601.13057", "authors": ["Chao Wang", "Shuyuan Zhang", "Lei Wang"], "title": "Convex Model Predictive Control for Safe Output Consensus of Nonlinear Multi-Agent Systems", "comment": null, "summary": "Nonlinear dynamics and safety constraints typically result in a nonlinear programming problem when applying model predictive control to achieve safe output consensus. To avoid the heavy computational burden of solving a nonlinear programming problem directly, this paper proposes a novel Convex Model Predictive Control (CMPC) approach based on a Sequential Quadratic Programming (SQP) scheme. The core of our method lies in transforming the nonlinear constraints into linear forms: we linearize the system dynamics and convexify the discrete-time high-order control barrier functions using a proposed tangent-line projection method. Consequently, the original problem is reduced to a quadratic program that can be iteratively solved within the SQP scheme at each time step of CMPC. Furthermore, we provide the formal guarantee of the convergence of the SQP scheme, and subsequently guarantee the recursive feasibility and stability of CMPC. Simulations on multi-agent systems with unicycle dynamics demonstrate a 35-52 times reduction in computation time compared with baseline methods, confirming the suitability of the proposed approach for real-time safe output consensus control.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSQP\u7684\u51f8\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u65b9\u6cd5\uff0c\u5c06\u975e\u7ebf\u6027\u7ea6\u675f\u7ebf\u6027\u5316\uff0c\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u4e8c\u6b21\u89c4\u5212\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u65f6\u95f435-52\u500d", "motivation": "\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u5b89\u5168\u7ea6\u675f\u5bfc\u81f4\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e2d\u9700\u8981\u89e3\u51b3\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u8ba1\u7b97\u8d1f\u62c5\u91cd\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u5b89\u5168\u8f93\u51fa\u4e00\u81f4\u6027\u63a7\u5236", "method": "\u57fa\u4e8eSQP\u65b9\u6848\u63d0\u51fa\u51f8\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5207\u7ebf\u6295\u5f71\u6cd5\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u7ebf\u6027\u5316\u5e76\u5c06\u79bb\u6563\u65f6\u95f4\u9ad8\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u51f8\u5316\uff0c\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u8fed\u4ee3\u6c42\u89e3\u7684\u4e8c\u6b21\u89c4\u5212", "result": "\u5728\u5177\u6709\u5355\u8f6e\u52a8\u529b\u5b66\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4eff\u771f\u4e2d\uff0c\u8ba1\u7b97\u65f6\u95f4\u6bd4\u57fa\u51c6\u65b9\u6cd5\u51cf\u5c1135-52\u500d\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5b9e\u65f6\u5b89\u5168\u8f93\u51fa\u4e00\u81f4\u6027\u63a7\u5236", "conclusion": "\u63d0\u51fa\u7684CMPC\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4fdd\u8bc1SQP\u65b9\u6848\u7684\u6536\u655b\u6027\u4ee5\u53caCMPC\u7684\u9012\u5f52\u53ef\u884c\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528"}}
{"id": "2601.13372", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.13372", "abs": "https://arxiv.org/abs/2601.13372", "authors": ["Mehmet Murat Albayrakoglu", "Mehmet Nafiz Aydin"], "title": "Influence of Normative Theories of Ethics on the European Union Artificial Intelligence Act: A Transformer-Based Analysis Using Semantic Textual Similarity", "comment": null, "summary": "This study investigates the ethical grounding of the European Union Artificial Intelligence (EU AI) Act by using Semantic Textual Similarity (STS) to analyze the alignment between normative ethical theories and regulatory language. Despite being regarded as a significant step toward regulating Artificial Intelligence (AI) systems and its emphasis on fundamental rights, the EU AI Act is not immune to moral criticism regarding its ethical foundations. Our work examines the impact of three major normative theories of ethics, virtue ethics, deontological ethics, and consequentialism, on the EU AI Act. We introduce the concept of influence, grounded in philosophical and chronological analysis, to examine the underlying relationship between the theories and the Act. As a proxy measure of this influence, we propose using STS to quantify the degree of alignment between the theories (influencers) and the Act (influencee). To capture intentional and operational ethical consistency, the Act was divided into two parts: the preamble and the statutory provisions. The textual descriptions of the theories were manually preprocessed to reduce semantic overlap and ensure a distinct representation of each theory. A heterogeneous embedding-level ensemble approach was employed, using five modified Bidirectional Encoder Representations from Transformers (BERT) models built on the Transformer architecture to compute STS scores. These scores reflect the semantic alignment between various theories of ethics and the two components of the EU AI Act. The resulting similarity scores were evaluated using voting and averaging, with findings indicating that deontological ethics has the most significant overall influence.", "AI": {"tldr": "\u4f7f\u7528\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\u5206\u6790\u6b27\u76dfAI\u6cd5\u6848\u4e0e\u4e09\u5927\u4f26\u7406\u7406\u8bba\uff08\u7f8e\u5fb7\u4f26\u7406\u3001\u4e49\u52a1\u8bba\u3001\u540e\u679c\u4e3b\u4e49\uff09\u7684\u5951\u5408\u5ea6\uff0c\u53d1\u73b0\u4e49\u52a1\u8bba\u5f71\u54cd\u6700\u5927", "motivation": "\u5c3d\u7ba1\u6b27\u76dfAI\u6cd5\u6848\u88ab\u89c6\u4e3aAI\u76d1\u7ba1\u7684\u91cd\u8981\u4e00\u6b65\u5e76\u5f3a\u8c03\u57fa\u672c\u6743\u5229\uff0c\u4f46\u5176\u4f26\u7406\u57fa\u7840\u4ecd\u9762\u4e34\u9053\u5fb7\u6279\u8bc4\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5206\u6790\u89c4\u8303\u6027\u4f26\u7406\u7406\u8bba\u4e0e\u76d1\u7ba1\u8bed\u8a00\u7684\u4e00\u81f4\u6027\uff0c\u8bc4\u4f30\u6cd5\u6848\u7684\u4f26\u7406\u57fa\u7840\u3002", "method": "1. \u5f15\u5165\"\u5f71\u54cd\u529b\"\u6982\u5ff5\uff0c\u57fa\u4e8e\u54f2\u5b66\u548c\u65f6\u5e8f\u5206\u6790\uff1b2. \u4f7f\u7528\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\u4f5c\u4e3a\u5f71\u54cd\u529b\u4ee3\u7406\u6307\u6807\uff1b3. \u5c06\u6cd5\u6848\u5206\u4e3a\u5e8f\u8a00\u548c\u6cd5\u5b9a\u6761\u6b3e\u4e24\u90e8\u5206\uff1b4. \u624b\u52a8\u9884\u5904\u7406\u4f26\u7406\u7406\u8bba\u6587\u672c\u4ee5\u51cf\u5c11\u8bed\u4e49\u91cd\u53e0\uff1b5. \u91c7\u7528\u5f02\u6784\u5d4c\u5165\u7ea7\u96c6\u6210\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e94\u4e2a\u6539\u8fdb\u7684BERT\u6a21\u578b\u8ba1\u7b97\u76f8\u4f3c\u6027\u5206\u6570\uff1b6. \u901a\u8fc7\u6295\u7968\u548c\u5e73\u5747\u6cd5\u8bc4\u4f30\u7ed3\u679c", "result": "\u8bed\u4e49\u76f8\u4f3c\u6027\u5206\u6790\u663e\u793a\uff0c\u4e49\u52a1\u8bba\u4f26\u7406\u5bf9\u6b27\u76dfAI\u6cd5\u6848\u7684\u6574\u4f53\u5f71\u54cd\u6700\u4e3a\u663e\u8457\uff0c\u8868\u660e\u6cd5\u6848\u5728\u4f26\u7406\u57fa\u7840\u4e0a\u66f4\u503e\u5411\u4e8e\u4e49\u52a1\u8bba\u6846\u67b6", "conclusion": "\u6b27\u76dfAI\u6cd5\u6848\u7684\u4f26\u7406\u57fa\u7840\u4e3b\u8981\u53d7\u4e49\u52a1\u8bba\u5f71\u54cd\uff0c\u8fd9\u4e3a\u7406\u89e3\u6cd5\u6848\u7684\u4f26\u7406\u53d6\u5411\u63d0\u4f9b\u4e86\u91cf\u5316\u8bc1\u636e\uff0c\u4e5f\u4e3a\u672a\u6765AI\u76d1\u7ba1\u7684\u4f26\u7406\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u6846\u67b6"}}
{"id": "2601.13394", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13394", "abs": "https://arxiv.org/abs/2601.13394", "authors": ["Munkaila Dasumani", "Suzanne Lenhart", "Gladys K. Onyambu", "Stephen E. Moore"], "title": "Discrete-Time Optimal Control of Species Augmentation for Predator-Prey Model", "comment": "40 figures, 25pages", "summary": "Species augmentation is one of the methods used to promote biodiversity and prevent endangered species loss and extinction. The current work applies discrete-time optimal control theory to two models of species augmentation for predator-prey relationships. In discrete-time models, the order in which events occur can give different qualitative results. Two models representing different orders of events of optimal augmentation timing are considered. In one model, the population grows and predator-prey action occurs before the translocation of reserve species for augmentation. In the second model, the augmentation happens first and is followed by growth and then predator-prey action.\n  The reserve and target populations are subjected to strong Allee effects. The optimal augmentation models employed in this work aim to maximize the prey (target population) and reserve population at the final time and minimize the associated cost at each time step. Numerical simulations in the two models are conducted using the discrete version of the forward-backward sweep method and the sequential quadratic programming iterative method, respectively. The simulation results show different population levels in the two models under varying parameter scenarios. Objective functional values showing percentage increases with optimal controls are calculated for each simulation. Different optimal augmentation strategies for the two orders of events are discussed. This work represents the first optimal augmentation results for models incorporating the predator-prey relationship with discrete events.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u79bb\u6563\u65f6\u95f4\u6700\u4f18\u63a7\u5236\u7406\u8bba\u5206\u6790\u4e24\u79cd\u4e0d\u540c\u4e8b\u4ef6\u987a\u5e8f\u7684\u7269\u79cd\u589e\u5f3a\u6a21\u578b\uff0c\u63a2\u8ba8\u6355\u98df\u8005-\u730e\u7269\u5173\u7cfb\u4e2d\u4e0d\u540c\u589e\u5f3a\u65f6\u673a\u5bf9\u79cd\u7fa4\u52a8\u6001\u7684\u5f71\u54cd\u3002", "motivation": "\u7269\u79cd\u589e\u5f3a\u662f\u4fc3\u8fdb\u751f\u7269\u591a\u6837\u6027\u3001\u9632\u6b62\u6fd2\u5371\u7269\u79cd\u706d\u7edd\u7684\u91cd\u8981\u65b9\u6cd5\u3002\u5f53\u524d\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6700\u4f18\u63a7\u5236\u7406\u8bba\uff0c\u5206\u6790\u5728\u6355\u98df\u8005-\u730e\u7269\u5173\u7cfb\u4e2d\uff0c\u4e0d\u540c\u4e8b\u4ef6\u987a\u5e8f\uff08\u589e\u5f3a\u65f6\u673a\uff09\u5bf9\u7269\u79cd\u589e\u5f3a\u6548\u679c\u7684\u5f71\u54cd\uff0c\u4e3a\u4fdd\u62a4\u751f\u7269\u5b66\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u5efa\u7acb\u4e24\u79cd\u79bb\u6563\u65f6\u95f4\u6700\u4f18\u63a7\u5236\u6a21\u578b\uff0c\u5206\u522b\u4ee3\u8868\u4e0d\u540c\u7684\u4e8b\u4ef6\u987a\u5e8f\uff1a\u6a21\u578b1\u5148\u53d1\u751f\u79cd\u7fa4\u589e\u957f\u548c\u6355\u98df\u8005-\u730e\u7269\u4f5c\u7528\uff0c\u540e\u8fdb\u884c\u589e\u5f3a\uff1b\u6a21\u578b2\u5148\u8fdb\u884c\u589e\u5f3a\uff0c\u7136\u540e\u79cd\u7fa4\u589e\u957f\uff0c\u6700\u540e\u6355\u98df\u8005-\u730e\u7269\u4f5c\u7528\u3002\u4e24\u79cd\u6a21\u578b\u90fd\u8003\u8651\u4e86\u5f3aAllee\u6548\u5e94\u3002\u91c7\u7528\u79bb\u6563\u7248\u672c\u7684\u524d\u5411-\u540e\u5411\u626b\u63cf\u65b9\u6cd5\u548c\u5e8f\u5217\u4e8c\u6b21\u89c4\u5212\u8fed\u4ee3\u65b9\u6cd5\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "result": "\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u5728\u4e0d\u540c\u53c2\u6570\u573a\u666f\u4e0b\uff0c\u4e24\u79cd\u6a21\u578b\u4ea7\u751f\u4e0d\u540c\u7684\u79cd\u7fa4\u6c34\u5e73\u3002\u8ba1\u7b97\u4e86\u5e26\u6709\u6700\u4f18\u63a7\u5236\u7684\u76ee\u6807\u51fd\u6570\u503c\u767e\u5206\u6bd4\u589e\u52a0\u91cf\u3002\u4e24\u79cd\u4e8b\u4ef6\u987a\u5e8f\u4e0b\u9700\u8981\u91c7\u7528\u4e0d\u540c\u7684\u6700\u4f18\u589e\u5f3a\u7b56\u7565\uff0c\u6a21\u578b\u7ed3\u679c\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5728\u5305\u542b\u6355\u98df\u8005-\u730e\u7269\u5173\u7cfb\u7684\u79bb\u6563\u4e8b\u4ef6\u6a21\u578b\u4e2d\u5f97\u51fa\u6700\u4f18\u589e\u5f3a\u7ed3\u679c\u7684\u7814\u7a76\u3002\u4e0d\u540c\u4e8b\u4ef6\u987a\u5e8f\u5bf9\u7269\u79cd\u589e\u5f3a\u6548\u679c\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e3a\u4fdd\u62a4\u5b9e\u8df5\u4e2d\u7684\u589e\u5f3a\u65f6\u673a\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.11920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11920", "abs": "https://arxiv.org/abs/2601.11920", "authors": ["Zhen Xu", "Vedant Khatri", "Yijun Dai", "Xiner Liu", "Siyan Li", "Xuanming Zhang", "Renzhe Yu"], "title": "Enhancing LLM-Based Data Annotation with Error Decomposition", "comment": null, "summary": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.", "AI": {"tldr": "\u63d0\u51fa\u8bca\u65ad\u8bc4\u4f30\u8303\u5f0f\uff0c\u5206\u79bb\u4efb\u52a1\u56fa\u6709\u6a21\u7cca\u6027\u4e0e\u6a21\u578b\u9a71\u52a8\u9519\u8bef\uff0c\u8bc4\u4f30LLM\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u8d28\u91cf", "motivation": "LLM\u5728\u5ba2\u89c2\u6807\u6ce8\u4efb\u52a1\u4e0a\u5df2\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4f46\u5728\u6d89\u53ca\u5fc3\u7406\u6784\u5ff5\u7b49\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\u4e14\u6613\u51fa\u9519\u3002\u4f20\u7edf\u8bc4\u4f30\u5c06\u6240\u6709\u9519\u8bef\u5408\u5e76\u4e3a\u5355\u4e00\u5bf9\u9f50\u6307\u6807\uff0c\u53ef\u80fd\u63a9\u76d6\u4e0d\u540c\u7c7b\u578b\u9519\u8bef\u5bf9\u6700\u7ec8\u5206\u6790\u7ed3\u8bba\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u8bca\u65ad\u8bc4\u4f30\u8303\u5f0f\uff0c\u5305\u542b\uff1a1) \u4e8c\u7ef4\u9519\u8bef\u5206\u7c7b\u6cd5\uff08\u6765\u6e90\uff1a\u6a21\u578b\u7279\u5b9avs\u4efb\u52a1\u56fa\u6709\uff1b\u7c7b\u578b\uff1a\u8fb9\u754c\u6a21\u7ccavs\u6982\u5ff5\u8bef\u8bc6\u522b\uff09\uff1b2) \u8f7b\u91cf\u7ea7\u4eba\u5de5\u6807\u6ce8\u6d4b\u8bd5\u4f30\u8ba1\u4efb\u52a1\u56fa\u6709\u6a21\u7cca\u6027\uff1b3) \u8ba1\u7b97\u5206\u89e3LLM\u6807\u6ce8\u9519\u8bef\u7684\u65b9\u6cd5\u3002\u5728\u56db\u4e2a\u6559\u80b2\u6807\u6ce8\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u4e86\u8303\u5f0f\u7684\u6982\u5ff5\u6709\u6548\u6027\u548c\u5b9e\u9645\u6548\u7528\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u5728\u7279\u5b9a\u6807\u6ce8\u4efb\u52a1\u4e2d\u8fc7\u9ad8\u5bf9\u9f50\u4e0d\u73b0\u5b9e\uff0c\u5355\u4e00\u5bf9\u9f50\u6307\u6807\u4e0d\u8db3\u4ee5\u53cd\u6620LLM\u6807\u6ce8\u8d28\u91cf\u3002\u5b9e\u8df5\u4e0a\u53ef\u4f5c\u4e3a\u4f4e\u6210\u672c\u8bca\u65ad\u5de5\u5177\u8bc4\u4f30\u4efb\u52a1\u662f\u5426\u9002\u5408LLM\u6807\u6ce8\uff0c\u5e76\u4e3a\u6280\u672f\u4f18\u5316\u63d0\u4f9b\u53ef\u884c\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bca\u65ad\u8bc4\u4f30\u8303\u5f0f\u80fd\u591f\u6709\u6548\u5206\u79bb\u4efb\u52a1\u56fa\u6709\u6a21\u7cca\u6027\u4e0e\u6a21\u578b\u9a71\u52a8\u9519\u8bef\uff0c\u4e3a\u8bc4\u4f30LLM\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u6846\u67b6\uff0c\u65e2\u6709\u7406\u8bba\u610f\u4e49\u4e5f\u6709\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2601.11883", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11883", "abs": "https://arxiv.org/abs/2601.11883", "authors": ["Chaoqi Jia", "Longkun Guo", "Kewen Liao", "Zhigang Lu", "Chao Chen", "Jason Xue"], "title": "Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach", "comment": "AAAI-26", "summary": "Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - \u03b5 would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u652f\u914d\u5339\u914d\u96c6\u8f6c\u6362\u7684\u65b0\u578b\u5c40\u90e8\u641c\u7d22\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5e26\u5b9e\u4f8b\u7ea7\u7ea6\u675f\u7684k-center\u805a\u7c7b\u95ee\u9898\uff0c\u8fbe\u5230\u4e86\u6700\u4f73\u53ef\u80fd\u76842\u8fd1\u4f3c\u6bd4\u3002", "motivation": "\u4f20\u7edf\u7684k-center\u95ee\u9898\u5df2\u67092\u8fd1\u4f3c\u6bd4\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u4f46\u52a0\u5165\u5b9e\u4f8b\u7ea7\u7684\"\u4e0d\u80fd\u94fe\u63a5\"(CL)\u548c\"\u5fc5\u987b\u94fe\u63a5\"(ML)\u7ea6\u675f\u540e\uff0c\u95ee\u9898\u590d\u6742\u5ea6\u663e\u8457\u589e\u52a0\u3002\u867d\u7136\u524d\u4eba\u5de5\u4f5c\u8868\u660e\u4e0d\u76f8\u4ea4\u7684CL\u96c6\u5408\u5141\u8bb8\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\uff0c\u4f46\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\u662f\u5426\u80fd\u8fbe\u5230\u8fd9\u6837\u7684\u4fdd\u8bc1\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5c40\u90e8\u641c\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ea6\u675fk-center\u805a\u7c7b\u95ee\u9898\u8f6c\u6362\u4e3a\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u6700\u4f73\u53ef\u80fd\u7684\u8fd1\u4f3c\u6bd4\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u5728\u89e3\u8d28\u91cf\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u7406\u8bba\u4e0a\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd42\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7ea6\u675fk-center\u95ee\u9898\u8f6c\u6362\u4e3a\u652f\u914d\u5339\u914d\u96c6\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u7684\u5c40\u90e8\u641c\u7d22\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6700\u4f73\u53ef\u80fd\u7684\u8fd1\u4f3c\u6bd4\uff0c\u4e3a\u5e26\u7ea6\u675f\u7684\u805a\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12256", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12256", "abs": "https://arxiv.org/abs/2601.12256", "authors": ["Jinyoung Park", "Minseong Bae", "Jeehye Na", "Hyunwoo J. Kim"], "title": "Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration", "comment": null, "summary": "Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.", "AI": {"tldr": "CoLLaMo\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u52a9\u624b\uff0c\u901a\u8fc7\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\u6574\u54081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u548c3D\u6784\u8c61\u4fe1\u606f\uff0c\u89e3\u51b3\u73b0\u6709\u5206\u5b50\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u9c81\u68d2\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u5206\u5b50\u8bed\u8a00\u6a21\u578b\uff08LMLMs\uff09\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u6709\u9650\u7684\u9c81\u68d2\u6027\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u672a\u80fd\u5145\u5206\u6574\u5408\u591a\u79cd\u5206\u5b50\u6a21\u6001\uff081D\u5e8f\u5217\u30012D\u5206\u5b50\u56fe\u30013D\u6784\u8c61\uff09\u3002\u9700\u8981\u5f00\u53d1\u80fd\u66f4\u597d\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u7684\u5206\u5b50\u6a21\u578b\u3002", "method": "\u63d0\u51faCoLLaMo\u6a21\u578b\uff0c\u5305\u542b\u5173\u7cfb\u611f\u77e5\u7684\u6a21\u6001\u534f\u4f5c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u591a\u7ea7\u5206\u5b50\u6a21\u6001\u534f\u4f5c\u6295\u5f71\u5668\u4fc3\u8fdb\u539f\u5b50\u95f4\u7ec6\u7c92\u5ea6\u7684\u5173\u7cfb\u5f15\u5bfc\u4fe1\u606f\u4ea4\u6362\uff0c\u6574\u54082D\u7ed3\u6784\u548c3D\u7a7a\u95f4\u5173\u7cfb\u3002\u540c\u65f6\u63d0\u51fa\u65b0\u7684\u5206\u5b50\u4e2d\u5fc3\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u5305\u62ec\u5e7b\u89c9\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u4e8eGPT\u7684\u6807\u9898\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCoLLaMo\u589e\u5f3a\u4e86LMLMs\u7684\u5206\u5b50\u6a21\u6001\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u5206\u5b50\u6807\u9898\u751f\u6210\u3001\u8ba1\u7b97\u6027\u8d28\u95ee\u7b54\u3001\u63cf\u8ff0\u6027\u8d28\u95ee\u7b54\u3001\u57fa\u5e8f\u8ba1\u6570\u548cIUPAC\u540d\u79f0\u9884\u6d4b\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "CoLLaMo\u901a\u8fc7\u6709\u6548\u6574\u5408\u591a\u6a21\u6001\u5206\u5b50\u4fe1\u606f\u89e3\u51b3\u4e86\u73b0\u6709LMLMs\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u4e86\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5206\u5b50AI\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6a21\u578b\u6846\u67b6\u3002"}}
{"id": "2601.13066", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13066", "abs": "https://arxiv.org/abs/2601.13066", "authors": ["Shaya Garjani", "Ashish Cherukuri", "Bayu Jayawardhana", "Nima Monshizadeh"], "title": "Stability of Information-Based Routing in Dynamic Transportation Networks", "comment": null, "summary": "Recent studies on transportation networks have shown that real-time route guidance can inadvertently induce congestion or oscillatory traffic patterns. Nevertheless, such technologies also offer a promising opportunity to manage traffic non-intrusively by shaping the information delivered to users, thereby mitigating congestion and enhancing network stability. A key step toward this goal is to identify information signals that ensure the existence of an equilibrium with desirable stability and convergence properties. This challenge is particularly relevant when traffic density and routing dynamics evolve concurrently, as increasingly occurs with digital signaling and real-time navigation technologies. To address this, we analyze a parallel-path transportation network with a single origin-destination pair, incorporating joint traffic density and logit-based routing dynamics that evolve at the same timescale. We characterize a class of density-dependent traffic information that guarantees a unique equilibrium in the free-flow regime, ensures its asymptotic stability, and keeps traffic densities within the free-flow region for all time. The theoretical results are complemented by a numerical case study demonstrating how the framework can inform the design of traffic information that reduces total travel time without compromising credibility.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6\u4f9d\u8d56\u4ea4\u901a\u4fe1\u606f\u7684\u5b9e\u65f6\u8def\u5f84\u5f15\u5bfc\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4fe1\u606f\u4fe1\u53f7\u786e\u4fdd\u81ea\u7531\u6d41\u72b6\u6001\u4e0b\u552f\u4e00\u5747\u8861\u7684\u5b58\u5728\u548c\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u7f13\u89e3\u62e5\u5835\u5e76\u63d0\u5347\u7f51\u7edc\u7a33\u5b9a\u6027\u3002", "motivation": "\u5b9e\u65f6\u8def\u5f84\u5f15\u5bfc\u6280\u672f\u867d\u7136\u80fd\u7ba1\u7406\u4ea4\u901a\uff0c\u4f46\u53ef\u80fd\u610f\u5916\u5f15\u53d1\u62e5\u5835\u6216\u632f\u8361\u4ea4\u901a\u6a21\u5f0f\u3002\u9700\u8981\u8bc6\u522b\u80fd\u786e\u4fdd\u5747\u8861\u5b58\u5728\u4e14\u5177\u6709\u826f\u597d\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u7684\u4fe1\u606f\u4fe1\u53f7\uff0c\u7279\u522b\u662f\u5728\u4ea4\u901a\u5bc6\u5ea6\u548c\u8def\u7531\u52a8\u6001\u540c\u65f6\u6f14\u5316\u7684\u573a\u666f\u4e0b\u3002", "method": "\u5206\u6790\u5177\u6709\u5355\u4e00OD\u5bf9\u7684\u5e73\u884c\u8def\u5f84\u4ea4\u901a\u7f51\u7edc\uff0c\u7ed3\u5408\u4ea4\u901a\u5bc6\u5ea6\u548c\u57fa\u4e8elogit\u7684\u8def\u7531\u52a8\u6001\uff08\u4e24\u8005\u5728\u540c\u4e00\u65f6\u95f4\u5c3a\u5ea6\u6f14\u5316\uff09\u3002\u8868\u5f81\u4e00\u7c7b\u5bc6\u5ea6\u4f9d\u8d56\u7684\u4ea4\u901a\u4fe1\u606f\uff0c\u786e\u4fdd\u81ea\u7531\u6d41\u72b6\u6001\u4e0b\u552f\u4e00\u5747\u8861\u7684\u5b58\u5728\u3001\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u5e76\u4fdd\u6301\u4ea4\u901a\u5bc6\u5ea6\u59cb\u7ec8\u5904\u4e8e\u81ea\u7531\u6d41\u533a\u57df\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5bc6\u5ea6\u4f9d\u8d56\u4ea4\u901a\u4fe1\u606f\u80fd\u4fdd\u8bc1\u81ea\u7531\u6d41\u72b6\u6001\u4e0b\u552f\u4e00\u5747\u8861\u7684\u5b58\u5728\u548c\u6e10\u8fd1\u7a33\u5b9a\u6027\u3002\u6570\u503c\u6848\u4f8b\u7814\u7a76\u8868\u660e\u8be5\u6846\u67b6\u80fd\u6307\u5bfc\u8bbe\u8ba1\u51cf\u5c11\u603b\u65c5\u884c\u65f6\u95f4\u4e14\u4e0d\u635f\u5bb3\u53ef\u4fe1\u5ea6\u7684\u4ea4\u901a\u4fe1\u606f\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u5bc6\u5ea6\u4f9d\u8d56\u7684\u4ea4\u901a\u4fe1\u606f\u4fe1\u53f7\uff0c\u53ef\u4ee5\u5728\u4e0d\u5e72\u6270\u7528\u6237\u7684\u60c5\u51b5\u4e0b\u7ba1\u7406\u4ea4\u901a\uff0c\u7f13\u89e3\u62e5\u5835\u5e76\u589e\u5f3a\u7f51\u7edc\u7a33\u5b9a\u6027\uff0c\u4e3a\u5b9e\u65f6\u5bfc\u822a\u6280\u672f\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.13520", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13520", "abs": "https://arxiv.org/abs/2601.13520", "authors": ["Qiao Jin", "Conrad Borchers", "Ashish Gurung", "Sean Jackson", "Sameeksha Agarwal", "Cancan Wang", "YiChen Yu", "Pragati Maheshwary", "Vincent Aleven"], "title": "Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms", "comment": "Full research paper accepted for publication in the Learning Analytics and Knowledge (LAK) 2026 conference proceedings", "summary": "Teachers' in-the-moment support is a limited resource in technology-supported classrooms, and teachers must decide whom to help and when during ongoing student work. However, less is known about how students' prior help history (whether they were helped earlier) and their engagement states (e.g., idle, struggle) shape teachers' decisions, and whether observed learning benefits associated with teacher help extend beyond the current class session. To address these questions, we first conducted interviews with nine K-12 mathematics teachers to identify candidate decision factors for teacher help. We then analyzed 1.4 million student-system interactions from 339 students across 14 classes in the MATHia intelligent tutoring system by linking teacher-logged help events with fine-grained engagement states. Mixed-effects models show that students who received help earlier were more likely to receive additional help later, even after accounting for current engagement state. Cross-lagged panel analyses further show that teacher help recurred across sessions, whereas idle behavior did not receive sustained attention over time. Finally, help coincided with immediate learning within sessions, but did not predict skill acquisition in later sessions, as estimated by additive factor modeling. These findings suggest that teacher help is \"sticky\" in that it recurs for previously supported students, while its measurable learning benefits in our data are largely session-bound. We discuss implications for designing real-time analytics that track attention coverage and highlight under-visited students to support a more equitable and effective allocation of teacher attention.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6559\u5e08\u5e2e\u52a9\u5177\u6709\"\u7c98\u6027\"\uff1a\u5148\u524d\u83b7\u5f97\u5e2e\u52a9\u7684\u5b66\u751f\u66f4\u53ef\u80fd\u518d\u6b21\u83b7\u5f97\u5e2e\u52a9\uff0c\u4f46\u5e2e\u52a9\u7684\u5b66\u4e60\u6548\u76ca\u4e3b\u8981\u9650\u4e8e\u5f53\u6b21\u8bfe\u5802\uff0c\u672a\u80fd\u9884\u6d4b\u540e\u7eed\u6280\u80fd\u638c\u63e1\u3002", "motivation": "\u5728\u6280\u672f\u652f\u6301\u7684\u8bfe\u5802\u4e2d\uff0c\u6559\u5e08\u7684\u5373\u65f6\u652f\u6301\u662f\u6709\u9650\u8d44\u6e90\uff0c\u9700\u8981\u51b3\u5b9a\u4f55\u65f6\u5e2e\u52a9\u54ea\u4e9b\u5b66\u751f\u3002\u4f46\u7f3a\u4e4f\u5bf9\u5b66\u751f\u5148\u524d\u5e2e\u52a9\u5386\u53f2\u548c\u53c2\u4e0e\u72b6\u6001\u5982\u4f55\u5f71\u54cd\u6559\u5e08\u51b3\u7b56\u7684\u4e86\u89e3\uff0c\u4e5f\u4e0d\u6e05\u695a\u6559\u5e08\u5e2e\u52a9\u7684\u5b66\u4e60\u6548\u76ca\u662f\u5426\u80fd\u5ef6\u4f38\u5230\u540e\u7eed\u8bfe\u5802\u3002", "method": "1. \u8bbf\u8c089\u540dK-12\u6570\u5b66\u6559\u5e08\u8bc6\u522b\u5e2e\u52a9\u51b3\u7b56\u56e0\u7d20\uff1b2. \u5206\u6790MATHia\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d339\u540d\u5b66\u751f14\u4e2a\u73ed\u7ea7\u7684140\u4e07\u6b21\u5b66\u751f-\u7cfb\u7edf\u4ea4\u4e92\u6570\u636e\uff0c\u5c06\u6559\u5e08\u8bb0\u5f55\u7684\u5e2e\u52a9\u4e8b\u4ef6\u4e0e\u7ec6\u7c92\u5ea6\u53c2\u4e0e\u72b6\u6001\u5173\u8054\uff1b3. \u4f7f\u7528\u6df7\u5408\u6548\u5e94\u6a21\u578b\u548c\u4ea4\u53c9\u6ede\u540e\u9762\u677f\u5206\u6790\u3002", "result": "1. \u5148\u524d\u83b7\u5f97\u5e2e\u52a9\u7684\u5b66\u751f\u66f4\u53ef\u80fd\u518d\u6b21\u83b7\u5f97\u5e2e\u52a9\uff0c\u5373\u4f7f\u8003\u8651\u5f53\u524d\u53c2\u4e0e\u72b6\u6001\uff1b2. \u6559\u5e08\u5e2e\u52a9\u5728\u591a\u4e2a\u8bfe\u5802\u4f1a\u8bdd\u4e2d\u91cd\u590d\u51fa\u73b0\uff0c\u800c\u7a7a\u95f2\u884c\u4e3a\u672a\u83b7\u5f97\u6301\u7eed\u5173\u6ce8\uff1b3. \u5e2e\u52a9\u4e0e\u5f53\u6b21\u8bfe\u5802\u5185\u7684\u5373\u65f6\u5b66\u4e60\u76f8\u5173\uff0c\u4f46\u672a\u80fd\u9884\u6d4b\u540e\u7eed\u4f1a\u8bdd\u7684\u6280\u80fd\u638c\u63e1\u3002", "conclusion": "\u6559\u5e08\u5e2e\u52a9\u5177\u6709\"\u7c98\u6027\"\u7279\u5f81\uff0c\u503e\u5411\u4e8e\u91cd\u590d\u5e2e\u52a9\u5148\u524d\u652f\u6301\u8fc7\u7684\u5b66\u751f\uff0c\u4f46\u5176\u53ef\u6d4b\u91cf\u7684\u5b66\u4e60\u6548\u76ca\u4e3b\u8981\u9650\u4e8e\u5f53\u6b21\u8bfe\u5802\u3002\u7814\u7a76\u5efa\u8bae\u8bbe\u8ba1\u5b9e\u65f6\u5206\u6790\u5de5\u5177\u8ddf\u8e2a\u6ce8\u610f\u529b\u8986\u76d6\uff0c\u7a81\u51fa\u663e\u793a\u672a\u5145\u5206\u5173\u6ce8\u7684\u5b66\u751f\uff0c\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u6709\u6548\u7684\u6559\u5e08\u6ce8\u610f\u529b\u5206\u914d\u3002"}}
{"id": "2601.14173", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14173", "abs": "https://arxiv.org/abs/2601.14173", "authors": ["Paris A. Karakasis", "Nicholas D. Sidiropoulos"], "title": "Penalizing Localized Dirichlet Energies in Low Rank Tensor Products", "comment": "19 pages", "summary": "We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4f4e\u79e9\u5f20\u91cf\u79efB\u6837\u6761(TPBS)\u56de\u5f52\u6a21\u578b\uff0c\u63a2\u7d22Dirichlet\u80fd\u91cf\u4f5c\u4e3a\u5e73\u6ed1\u5ea6\u5ea6\u91cf\uff0c\u53d1\u73b0\u5168\u5c40\u6b63\u5219\u5316\u5931\u6548\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u5c40\u90e8Dirichlet\u80fd\u91cf\u7684\u65b0\u6b63\u5219\u5316\u7b56\u7565\uff0c\u5e76\u5728\u8fc7\u62df\u5408\u573a\u666f\u4e0b\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u7814\u7a76\u4f4e\u79e9\u5f20\u91cf\u79efB\u6837\u6761(TPBS)\u6a21\u578b\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u7d22Dirichlet\u80fd\u91cf\u4f5c\u4e3a\u6a21\u578b\u5e73\u6ed1\u5ea6\u7684\u6709\u6548\u5ea6\u91cf\u3002\u53d1\u73b0\u5168\u5c40Dirichlet\u80fd\u91cf\u6b63\u5219\u5316\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u5931\u6548\uff0c\u9700\u8981\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1) \u63a8\u5bfcTPBS\u6a21\u578b\u7684Dirichlet\u80fd\u91cf\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u8bad\u7ec3\u70b9\u5468\u56f4\u5c0f\u8d85\u7acb\u65b9\u4f53\u5c40\u90e8Dirichlet\u80fd\u91cf\u7684\u6b63\u5219\u5316\u7b56\u7565\uff1b3) \u5229\u7528\u9884\u8bad\u7ec3TPBS\u6a21\u578b\u8bbe\u8ba1\u4e24\u79cd\u4ece\u4e0d\u5b8c\u6574\u6837\u672c\u8fdb\u884c\u63a8\u65ad\u7684\u4f30\u8ba1\u5668\u3002", "result": "TPBS\u6a21\u578b\u5728\u8fc7\u62df\u5408\u573a\u666f\u4e0b\u5bf9\u5927\u591a\u6570\u6570\u636e\u96c6\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u4ed6\u60c5\u51b5\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\u3002TPBS\u6a21\u578b\u5bf9\u8fc7\u62df\u5408\u66f4\u5177\u9c81\u68d2\u6027\u4e14\u80fd\u6301\u7eed\u53d7\u76ca\u4e8e\u6b63\u5219\u5316\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u5bf9\u8fc7\u62df\u5408\u66f4\u654f\u611f\u4e14\u5229\u7528\u6b63\u5219\u5316\u7684\u6548\u679c\u8f83\u5dee\u3002", "conclusion": "TPBS\u6a21\u578b\u662f\u56de\u5f52\u4efb\u52a1\u7684\u6709\u6548\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u8fc7\u62df\u5408\u573a\u666f\u4e0b\u3002\u63d0\u51fa\u7684\u5c40\u90e8Dirichlet\u80fd\u91cf\u6b63\u5219\u5316\u7b56\u7565\u89e3\u51b3\u4e86\u5168\u5c40\u6b63\u5219\u5316\u7684\u5c40\u9650\u6027\uff0c\u4f7fTPBS\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2601.13395", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13395", "abs": "https://arxiv.org/abs/2601.13395", "authors": ["Andrew Zheng", "Adam R. Stinchcombe"], "title": "Generalized Adjoint Method", "comment": "25 pages, 5 figures", "summary": "The adjoint method is an efficient way to numerically compute gradients in optimization problems with constraints, but is only formulated to differentiable cost and constraint functions on real variables. With the introduction of complex variables, which occur often in many inverse problems in electromagnetism and signal processing problems, both the cost and constraint can become non-holomorphic and hence non-differentiable in the standard definitions. Using the notion of CR-calculus, a generalized adjoint method is introduced that can compute the direction of steepest ascent for the cost function while enforcing the constraint even if both are non-holomorphic.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u590d\u53d8\u91cf\u4f18\u5316\u95ee\u9898\u7684\u5e7f\u4e49\u4f34\u968f\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u975e\u5168\u7eaf\uff08\u975e\u89e3\u6790\uff09\u7684\u6210\u672c\u51fd\u6570\u548c\u7ea6\u675f\u51fd\u6570\u3002", "motivation": "\u4f20\u7edf\u4f34\u968f\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u5b9e\u53d8\u91cf\u548c\u53ef\u5fae\u51fd\u6570\uff0c\u4f46\u5728\u7535\u78c1\u5b66\u548c\u4fe1\u53f7\u5904\u7406\u7b49\u9006\u95ee\u9898\u4e2d\u7ecf\u5e38\u51fa\u73b0\u590d\u53d8\u91cf\uff0c\u5bfc\u81f4\u6210\u672c\u51fd\u6570\u548c\u7ea6\u675f\u51fd\u6570\u53ef\u80fd\u975e\u5168\u7eaf\uff08\u975e\u89e3\u6790\uff09\u800c\u4e0d\u53ef\u5fae\uff0c\u9700\u8981\u65b0\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528CR-\u5fae\u79ef\u5206\uff08\u67ef\u897f-\u9ece\u66fc\u5fae\u79ef\u5206\uff09\u7406\u8bba\uff0c\u6784\u5efa\u5e7f\u4e49\u4f34\u968f\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u6210\u672c\u51fd\u6570\u548c\u7ea6\u675f\u51fd\u6570\u90fd\u975e\u5168\u7eaf\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u8ba1\u7b97\u6210\u672c\u51fd\u6570\u7684\u6700\u901f\u4e0a\u5347\u65b9\u5411\u5e76\u540c\u65f6\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u53d8\u91cf\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u975e\u5168\u7eaf\u51fd\u6570\uff0c\u4e3a\u7535\u78c1\u5b66\u548c\u4fe1\u53f7\u5904\u7406\u7b49\u9886\u57df\u7684\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u6570\u503c\u8ba1\u7b97\u68af\u5ea6\u7684\u65b0\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7CR-\u5fae\u79ef\u5206\u6269\u5c55\u7684\u5e7f\u4e49\u4f34\u968f\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u590d\u53d8\u91cf\u4f18\u5316\u4e2d\u975e\u5168\u7eaf\u51fd\u6570\u7684\u68af\u5ea6\u8ba1\u7b97\u95ee\u9898\uff0c\u586b\u8865\u4e86\u4f20\u7edf\u4f34\u968f\u65b9\u6cd5\u5728\u590d\u53d8\u91cf\u9886\u57df\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.11923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11923", "abs": "https://arxiv.org/abs/2601.11923", "authors": ["P. Bilha Githinji", "Aikaterini Melliou", "Xi Yuan", "Dayan Zhang", "Lian Zhang", "Zhenglin Chen", "Jiansong Ji", "Chengying Lv", "Jinhao Xu", "Peiwu Qin", "Dongmei Yu"], "title": "Mapping the maturation of TCM as an adjuvant to radiotherapy", "comment": null, "summary": "The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.", "AI": {"tldr": "\u5bf969,745\u7bc7\u6587\u732e\u7684\u5927\u89c4\u6a21\u5206\u6790\u663e\u793a\uff0c\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u6574\u5408\u80bf\u7624\u5b66\u7ecf\u5386\u4e86\u5468\u671f\u6027\u6f14\u53d8\uff0c\u5f62\u6210\u4e86\u4e94\u5927\u4e3b\u9898\u8f74\uff0c\u8868\u660e\u8be5\u9886\u57df\u5df2\u6210\u719f\u5e76\u53ef\u80fd\u9762\u4e34\u65b0\u7684\u7a81\u7834\uff0c\u540c\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u79ef\u6781\u62a5\u544a\u504f\u501a\u3002", "motivation": "\u6574\u5408\u80bf\u7624\u5b66\u53d1\u5c5525\u5e74\u6765\uff0c\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8bc1\u636e\u8f68\u8ff9\uff0c\u4e86\u89e3\u8be5\u9886\u57df\u7684\u53d1\u5c55\u6a21\u5f0f\u548c\u73b0\u72b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5bf92000-2025\u5e74\u95f469,745\u7bc7\u51fa\u7248\u7269\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u91c7\u7528\u4e3b\u9898\u5efa\u6a21\u5de5\u4f5c\u6d41\u7a0b\u786e\u5b9a\u7a33\u5b9a\u7684\u4e3b\u9898\u7ed3\u6784\uff0c\u8bc6\u522b\u4e3b\u5bfc\u4e3b\u9898\u8f74\uff0c\u5206\u6790\u51fa\u7248\u4ea7\u51fa\u3001\u56fd\u9645\u5408\u4f5c\u548c\u8d44\u91d1\u627f\u8bfa\u7684\u5468\u671f\u6027\u6f14\u53d8\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u5927\u4e3b\u5bfc\u4e3b\u9898\u8f74\uff1a\u764c\u75c7\u7c7b\u578b\u3001\u652f\u6301\u6027\u62a4\u7406\u3001\u4e34\u5e8a\u7ec8\u70b9\u3001\u673a\u5236\u548c\u65b9\u6cd5\u5b66\uff1b\u53d1\u73b0\u8be5\u9886\u57df\u5448\u73b0\u5b9a\u4e49-\u6784\u601d-\u6d4b\u8bd5\u6a21\u5f0f\u7684\u5468\u671f\u6027\u6f14\u53d8\uff1b\u663e\u793a\u60a3\u8005\u4e3a\u4e2d\u5fc3\u3001\u7cfb\u7edf\u5bfc\u5411\u7684TCM\u6574\u5408\uff1b\u5b58\u5728\u7cfb\u7edf\u6027\u79ef\u6781\u62a5\u544a\u504f\u501a\u3002", "conclusion": "\u4e2d\u533b\u836f\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u7684\u6574\u5408\u80bf\u7624\u5b66\u9886\u57df\u5df2\u6210\u719f\u73b0\u6709\u7814\u7a76\u8bae\u7a0b\uff0c\u53ef\u80fd\u5904\u4e8e\u65b0\u7a81\u7834\u7684\u8fb9\u7f18\uff1b\u8be5\u9886\u57df\u8868\u73b0\u51fa\u6e10\u8fdb\u4e13\u4e1a\u5316\u548c\u6f5c\u5728\u788e\u7247\u5316\uff1b\u9700\u8981\u5173\u6ce8\u7cfb\u7edf\u6027\u79ef\u6781\u62a5\u544a\u504f\u501a\u95ee\u9898\u3002"}}
{"id": "2601.11890", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11890", "abs": "https://arxiv.org/abs/2601.11890", "authors": ["Xihe Gu", "Urbashi Mitra", "Tara Javidi"], "title": "From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs", "comment": null, "summary": "Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_\u03c1$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_\u03c1$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_\u03c1$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $\u03c1$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53c2\u6570\u5316\u7684\u51f9\u8986\u76d6\u76ee\u6807\u51fd\u6570\u65cfU_\u03c1\uff0c\u7528\u4e8e\u5728\u65e0\u5956\u52b1MDP\u4e2d\u6307\u5bfc\u63a2\u7d22\u7b56\u7565\uff0c\u901a\u8fc7\u68af\u5ea6\u65b9\u6cd5\u4e3b\u52a8\u5f15\u5bfc\u72b6\u6001-\u52a8\u4f5c\u5360\u7528\u5206\u5e03\u5b9e\u73b0\u76ee\u6807\u8986\u76d6\u6a21\u5f0f\u3002", "motivation": "\u5728\u65e0\u5956\u52b1MDP\u4e2d\uff0c\u4e0d\u540c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u5177\u6709\u4e0d\u540c\u7684\u91cd\u8981\u6027\u6216\u96be\u5ea6\uff0c\u9700\u8981\u4e3b\u52a8\u6784\u5efa\u63a2\u7d22\u7b56\u7565\u6765\u4f18\u5148\u8003\u8651\u672a\u5145\u5206\u63a2\u7d22\u7684\u533a\u57df\u3002", "method": "\u63d0\u51fa\u52a0\u6743\u53c2\u6570\u5316\u51f9\u8986\u76d6\u76ee\u6807\u51fd\u6570\u65cfU_\u03c1\uff0c\u5b9a\u4e49\u5728\u72b6\u6001-\u52a8\u4f5c\u5360\u7528\u6d4b\u5ea6\u4e0a\uff1b\u5229\u7528U_\u03c1\u7684\u51f9\u6027\u548c\u68af\u5ea6\u95ed\u5f0f\u89e3\uff0c\u5f00\u53d1\u57fa\u4e8e\u68af\u5ea6\u7684\u7b97\u6cd5\u4e3b\u52a8\u5f15\u5bfc\u5360\u7528\u5206\u5e03\u3002", "result": "U_\u03c1\u6846\u67b6\u7edf\u4e00\u4e86\u591a\u79cd\u73b0\u6709\u76ee\u6807\uff08\u6563\u5ea6\u8fb9\u9645\u5339\u914d\u3001\u52a0\u6743\u5e73\u5747\u8986\u76d6\u3001\u6700\u574f\u60c5\u51b5\u8986\u76d6\uff09\uff1b\u968f\u7740\u03c1\u589e\u5927\uff0c\u63a2\u7d22\u7b56\u7565\u8d8a\u6765\u8d8a\u5173\u6ce8\u6700\u5c11\u63a2\u7d22\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u6781\u9650\u60c5\u51b5\u4e0b\u6062\u590d\u6700\u574f\u60c5\u51b5\u8986\u76d6\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u7684U_\u03c1\u6846\u67b6\u4e3a\u65e0\u5956\u52b1MDP\u4e2d\u7684\u63a2\u7d22\u95ee\u9898\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u03c1\u7075\u6d3b\u63a7\u5236\u63a2\u7d22\u7b56\u7565\u7684\u6fc0\u8fdb\u7a0b\u5ea6\uff0c\u4ece\u5e73\u5747\u8986\u76d6\u5230\u6700\u574f\u60c5\u51b5\u8986\u76d6\u8fde\u7eed\u8fc7\u6e21\u3002"}}
{"id": "2601.12259", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12259", "abs": "https://arxiv.org/abs/2601.12259", "authors": ["Jiashuo Liu", "Siyuan Chen", "Zaiyuan Wang", "Zhiyuan Zeng", "Jiacheng Guo", "Liang Hu", "Lingyue Yin", "Suozhi Huang", "Wenxin Hao", "Yang Yang", "Zerui Cheng", "Zixin Yao", "Lingyue Yin", "Haoxin Liu", "Jiayi Cheng", "Yuzhen Li", "Zezhong Ma", "Bingjie Wang", "Bingsen Qiu", "Xiao Liu", "Zeyang Zhang", "Zijian Liu", "Jinpeng Wang", "Mingren Yin", "Tianci He", "Yali Liao", "Yixiao Tian", "Zhenwei Zhu", "Anqi Dai", "Ge Zhang", "Jingkai Liu", "Kaiyuan Zhang", "Wenlong Wu", "Xiang Gao", "Xinjie Chen", "Zhixin Yao", "Zhoufutu Wen", "B. Aditya Prakash", "Jose Blanchet", "Mengdi Wang", "Nian Si", "Wenhao Huang"], "title": "FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains", "comment": "21 pages", "summary": "Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.", "AI": {"tldr": "FutureX-Pro\u6269\u5c55\u4e86FutureX\u7684\u5b9e\u65f6\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u548c\u81ea\u7136\u707e\u5bb3\u56db\u4e2a\u9ad8\u4ef7\u503c\u5782\u76f4\u9886\u57df\u7684\u4e13\u4e1a\u9884\u6d4b\u4efb\u52a1\uff0c\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4ee3\u7406LLM\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u901a\u7528\u4ee3\u7406\u5728\u5f00\u653e\u9886\u57df\u641c\u7d22\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8d44\u672c\u5bc6\u96c6\u578b\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u53ef\u9760\u6027\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4ee3\u7406LLM\u662f\u5426\u5177\u5907\u5de5\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u3002", "method": "\u57fa\u4e8eFutureX\u7684\u65e0\u6c61\u67d3\u5b9e\u65f6\u8bc4\u4f30\u6d41\u7a0b\uff0c\u6784\u5efa\u4e86FutureX-Pro\u6846\u67b6\uff0c\u5305\u62ec\u4e94\u4e2a\u5782\u76f4\u9886\u57df\u6a21\u5757\uff1a\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u3001\u81ea\u7136\u707e\u5bb3\u548c\u641c\u7d22\u3002\u5728\u56db\u4e2a\u5173\u952e\u5782\u76f4\u9886\u57df\uff08\u91d1\u878d\u3001\u96f6\u552e\u3001\u516c\u5171\u536b\u751f\u3001\u81ea\u7136\u707e\u5bb3\uff09\u4e0a\u5bf9\u4ee3\u7406LLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5e02\u573a\u6307\u6807\u9884\u6d4b\u3001\u4f9b\u5e94\u94fe\u9700\u6c42\u9884\u6d4b\u3001\u6d41\u884c\u75c5\u8d8b\u52bf\u8ddf\u8e2a\u548c\u81ea\u7136\u707e\u5bb3\u8ddf\u8e2a\u7b49\u57fa\u7840\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u901a\u7528\u63a8\u7406\u4e0e\u9ad8\u4ef7\u503c\u5782\u76f4\u5e94\u7528\u6240\u9700\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u8868\u660e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4ee3\u7406LLM\u5728\u5de5\u4e1a\u90e8\u7f72\u7684\u9886\u57df\u57fa\u7840\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "FutureX-Pro\u4e3a\u8bc4\u4f30\u4ee3\u7406LLM\u5728\u5173\u952e\u5782\u76f4\u9886\u57df\u7684\u9884\u6d4b\u80fd\u529b\u63d0\u4f9b\u4e86\u4e13\u95e8\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.13174", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.13174", "abs": "https://arxiv.org/abs/2601.13174", "authors": ["Maryam Salamatmoghadasi", "Amir Mehrabian", "Halim Yanikomeroglu", "Georges Kaddoum"], "title": "QoS-Aware Energy Optimization via Cell Switching in Heterogeneous Networks", "comment": null, "summary": "The growing demand for mobile data services in dense urban areas has intensified the need for energy-efficient radio access networks (RANs) in future 6G systems. In this context, one promising strategy is cell switching (CS), which dynamically deactivates underutilized small base stations (SBSs) to reduce power consumption. However, while previous research explored CS primarily based on traffic load, ensuring user quality of service (QoS) under realistic channel conditions remains a challenge. In this paper, we propose a novel optimization-driven CS framework that jointly minimizes network power consumption and guarantees user QoS by enforcing a minimum received power threshold as part of offloading decisions. In contrast to prior load-based or learning-based approaches, our method explicitly integrates channel-aware information into the CS process, thus ensuring reliable service quality for offloaded users. Furthermore, flexibility of the proposed framework enables operators to adapt system behavior between energy-saving and QoS-preserving modes by tuning a single design parameter. Simulation results demonstrate that the proposed approach achieves up to 30% power savings as compared to baseline methods while fully maintaining QoS under diverse network conditions. Scalability and robustness of the proposed method in realistic heterogeneous networks (HetNets) further highlight its potential as a practical solution for sustainable 6G deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u9053\u611f\u77e5\u7684\u8702\u7a9d\u5207\u6362\u4f18\u5316\u6846\u67b6\uff0c\u5728\u4fdd\u8bc1\u7528\u6237QoS\u7684\u540c\u65f6\u6700\u5c0f\u5316\u7f51\u7edc\u529f\u8017\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53ef\u8282\u770130%\u529f\u8017", "motivation": "\u5bc6\u96c6\u57ce\u5e02\u533a\u57df\u5bf9\u79fb\u52a8\u6570\u636e\u670d\u52a1\u7684\u9700\u6c42\u589e\u957f\uff0c\u9700\u89816G\u7cfb\u7edf\u4e2d\u80fd\u6548\u66f4\u9ad8\u7684\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u3002\u73b0\u6709\u57fa\u4e8e\u6d41\u91cf\u8d1f\u8f7d\u7684\u8702\u7a9d\u5207\u6362\u65b9\u6cd5\u5728\u771f\u5b9e\u4fe1\u9053\u6761\u4ef6\u4e0b\u96be\u4ee5\u4fdd\u8bc1\u7528\u6237\u670d\u52a1\u8d28\u91cf", "method": "\u63d0\u51fa\u4f18\u5316\u9a71\u52a8\u7684\u8702\u7a9d\u5207\u6362\u6846\u67b6\uff0c\u8054\u5408\u6700\u5c0f\u5316\u7f51\u7edc\u529f\u8017\u5e76\u4fdd\u8bc1\u7528\u6237QoS\uff0c\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u6700\u5c0f\u63a5\u6536\u529f\u7387\u9608\u503c\u4f5c\u4e3a\u5378\u8f7d\u51b3\u7b56\u7684\u4e00\u90e8\u5206\uff0c\u5c06\u4fe1\u9053\u611f\u77e5\u4fe1\u606f\u663e\u5f0f\u96c6\u6210\u5230\u5207\u6362\u8fc7\u7a0b\u4e2d", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53ef\u8282\u7701\u9ad8\u8fbe30%\u7684\u529f\u8017\uff0c\u540c\u65f6\u5728\u591a\u6837\u5316\u7f51\u7edc\u6761\u4ef6\u4e0b\u5b8c\u5168\u4fdd\u6301QoS\uff0c\u5728\u771f\u5b9e\u5f02\u6784\u7f51\u7edc\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5355\u4e00\u8bbe\u8ba1\u53c2\u6570\u8c03\u8282\u7cfb\u7edf\u5728\u8282\u80fd\u548cQoS\u4fdd\u62a4\u6a21\u5f0f\u4e4b\u95f4\u7684\u884c\u4e3a\uff0c\u4e3a\u53ef\u6301\u7eed6G\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13936", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.13936", "abs": "https://arxiv.org/abs/2601.13936", "authors": ["Theresa Z\u00fcger", "Laura State", "Lena Winter"], "title": "Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest", "comment": null, "summary": "The overall rapid increase of artificial intelligence (AI) use is linked to various initiatives that propose AI 'for good'. However, there is a lack of transparency in the goals of such projects, as well as a missing evaluation of their actual impacts on society and the planet. We close this gap by proposing public interest and sustainability as a regulatory dual-concept, together creating the necessary framework for a just and sustainable development that can be operationalized and utilized for the assessment of AI systems. Based on this framework, and building on existing work in auditing, we introduce the Impact-AI-method, a qualitative audit method to evaluate concrete AI projects with respect to public interest and sustainability. The interview-based method captures a project's governance structure, its theory of change, AI model and data characteristics, and social, environmental, and economic impacts. We also propose a catalog of assessment criteria to rate the outcome of the audit as well as to create an accessible output that can be debated broadly by civil society. The Impact-AI-method, developed in a transdisciplinary research setting together with NGOs and a multi-stakeholder research council, is intended as a reusable blueprint that both informs public debate about AI 'for good' claims and supports the creation of transparency of AI systems that purport to contribute to a just and sustainable development.", "AI": {"tldr": "\u63d0\u51faImpact-AI\u65b9\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u516c\u5171\u5229\u76ca\u548c\u53ef\u6301\u7eed\u6027\u6846\u67b6\u7684AI\u9879\u76ee\u5b9a\u6027\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\"AI\u5411\u5584\"\u9879\u76ee\u7684\u5b9e\u9645\u793e\u4f1a\u73af\u5883\u5f71\u54cd", "motivation": "\u5f53\u524dAI\u5411\u5584\u9879\u76ee\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u76ee\u6807\u4e0d\u660e\u786e\uff0c\u4e14\u7f3a\u5c11\u5bf9\u793e\u4f1a\u548c\u5730\u7403\u5b9e\u9645\u5f71\u54cd\u7684\u8bc4\u4f30\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u64cd\u4f5c\u6846\u67b6\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u516c\u6b63\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u8d21\u732e", "method": "\u63d0\u51fa\u516c\u5171\u5229\u76ca\u548c\u53ef\u6301\u7eed\u6027\u7684\u53cc\u91cd\u76d1\u7ba1\u6982\u5ff5\u4f5c\u4e3a\u6846\u67b6\uff0c\u5f00\u53d1Impact-AI\u5b9a\u6027\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbf\u8c08\u8bc4\u4f30\u9879\u76ee\u7684\u6cbb\u7406\u7ed3\u6784\u3001\u53d8\u9769\u7406\u8bba\u3001AI\u6a21\u578b\u548c\u6570\u636e\u7279\u5f81\u3001\u793e\u4f1a\u3001\u73af\u5883\u548c\u7ecf\u6d4e\u5f71\u54cd\uff0c\u5e76\u5236\u5b9a\u8bc4\u4f30\u6807\u51c6\u76ee\u5f55", "result": "\u5f00\u53d1\u4e86\u53ef\u91cd\u590d\u4f7f\u7528\u7684Impact-AI\u65b9\u6cd5\u84dd\u56fe\uff0c\u8be5\u65b9\u6cd5\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u73af\u5883\u4e2d\u4e0eNGO\u548c\u591a\u5229\u76ca\u76f8\u5173\u65b9\u7814\u7a76\u59d4\u5458\u4f1a\u5408\u4f5c\u5f00\u53d1\uff0c\u65e8\u5728\u4e3aAI\u5411\u5584\u7684\u516c\u5171\u8fa9\u8bba\u63d0\u4f9b\u4fe1\u606f\u5e76\u652f\u6301AI\u7cfb\u7edf\u900f\u660e\u5ea6", "conclusion": "Impact-AI\u65b9\u6cd5\u4e3a\u8bc4\u4f30AI\u9879\u76ee\u5bf9\u516c\u5171\u5229\u76ca\u548c\u53ef\u6301\u7eed\u6027\u7684\u8d21\u732e\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u521b\u5efa\u900f\u660e\u5ea6\uff0c\u652f\u6301\u516c\u6b63\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u7684AI\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u4fc3\u8fdb\u516c\u6c11\u793e\u4f1a\u7684\u5e7f\u6cdb\u8ba8\u8bba"}}
{"id": "2601.14234", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14234", "abs": "https://arxiv.org/abs/2601.14234", "authors": ["Qiyang Li", "Sergey Levine"], "title": "Q-learning with Adjoint Matching", "comment": "32 pages, 8 figures, 7 tables", "summary": "We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.", "AI": {"tldr": "QAM\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f34\u968f\u5339\u914d\u6280\u672f\u89e3\u51b3\u8fde\u7eed\u52a8\u4f5cRL\u4e2d\u6269\u6563/\u6d41\u5339\u914d\u7b56\u7565\u4f18\u5316\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u8fde\u7eed\u52a8\u4f5c\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5bf9\u8868\u8fbe\u6027\u5f3a\u7684\u6269\u6563\u6216\u6d41\u5339\u914d\u7b56\u7565\u8fdb\u884c\u9ad8\u6548\u4f18\u5316\u662f\u4e00\u4e2a\u957f\u671f\u6311\u6218\u3002\u76f4\u63a5\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u8fdb\u884c\u68af\u5ea6\u4f18\u5316\u5728\u591a\u6b65\u53bb\u566a\u8fc7\u7a0b\u4e2d\u6570\u503c\u4e0d\u7a33\u5b9a\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e22\u5f03\u68af\u5ea6\u4fe1\u606f\uff0c\u8981\u4e48\u727a\u7272\u7b56\u7565\u8868\u8fbe\u6027\u6216\u5f15\u5165\u504f\u5dee\u3002", "method": "QAM\u5229\u7528\u4f34\u968f\u5339\u914d\u6280\u672f\uff0c\u5c06critic\u7684\u52a8\u4f5c\u68af\u5ea6\u8f6c\u6362\u4e3a\u6b65\u8fdb\u5f0f\u76ee\u6807\u51fd\u6570\uff0c\u907f\u514d\u4e86\u4e0d\u7a33\u5b9a\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u540c\u65f6\u63d0\u4f9b\u65e0\u504f\u4e14\u8868\u8fbe\u6027\u5f3a\u7684\u7b56\u7565\u3002\u7ed3\u5408\u65f6\u5e8f\u5dee\u5206\u5907\u4efd\u8fdb\u884ccritic\u5b66\u4e60\u3002", "result": "QAM\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u56f0\u96be\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e0a\uff0c\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "QAM\u901a\u8fc7\u4f34\u968f\u5339\u914d\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86\u8fde\u7eed\u52a8\u4f5cRL\u4e2d\u6269\u6563/\u6d41\u5339\u914d\u7b56\u7565\u4f18\u5316\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u8868\u8fbe\u6027\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2601.13486", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13486", "abs": "https://arxiv.org/abs/2601.13486", "authors": ["Anderson Anrrango", "Andr\u00e9 Quisaguano", "Gonzalo E. Constante-Flores", "Can Li"], "title": "Self-Supervised Learning of Parametric Approximation for Security-Constrained DC-OPF", "comment": "7 pages, 4 figures, 5 tables", "summary": "This paper introduces a self-supervised learning framework for approximating the Security-Constrained DC Optimal Power Flow (SC-DCOPF) problem using a parametric linear model. The approach preserves the physical structure of the DC-OPF while incorporating demand-dependent tunable parameters that scale transmission line limits. These parameters are predicted via a Graph Neural Network and optimized through differentiable layers, enabling direct training from contingency costs without requiring labeled data. The framework integrates pre- and post-contingency optimization layers into an implicit loss function. Numerical experiments on benchmark systems demonstrate that the proposed method achieves high dispatch accuracy, low cost approximation error, and strong data efficiency, outperforming semi-supervised and end-to-end baselines. This scalable and interpretable approach offers a promising solution for real-time secure power system operations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8fd1\u4f3c\u5b89\u5168\u7ea6\u675f\u76f4\u6d41\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53ef\u8c03\u53c2\u6570\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\u5373\u53ef\u8bad\u7ec3\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u7ea6\u675f\u76f4\u6d41\u6700\u4f18\u6f6e\u6d41\u8ba1\u7b97\u590d\u6742\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53c2\u6570\u5316\u7ebf\u6027\u6a21\u578b\u4fdd\u6301\u76f4\u6d41\u6700\u4f18\u6f6e\u6d41\u7269\u7406\u7ed3\u6784\uff0c\u5f15\u5165\u9700\u6c42\u4f9d\u8d56\u7684\u53ef\u8c03\u53c2\u6570\u7f29\u653e\u8f93\u7535\u7ebf\u8def\u6781\u9650\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53c2\u6570\uff0c\u5229\u7528\u53ef\u5fae\u5206\u5c42\u4f18\u5316\uff0c\u96c6\u6210\u9884\u60f3\u4e8b\u6545\u548c\u4e8b\u6545\u540e\u4f18\u5316\u5c42\u5230\u9690\u5f0f\u635f\u5931\u51fd\u6570\u4e2d\u3002", "result": "\u5728\u57fa\u51c6\u7cfb\u7edf\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u8c03\u5ea6\u7cbe\u5ea6\u3001\u4f4e\u6210\u672c\u8fd1\u4f3c\u8bef\u5dee\u548c\u5f3a\u6570\u636e\u6548\u7387\uff0c\u4f18\u4e8e\u534a\u76d1\u7763\u548c\u7aef\u5230\u7aef\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u4e3a\u5b9e\u65f6\u5b89\u5168\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.11932", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11932", "abs": "https://arxiv.org/abs/2601.11932", "authors": ["Abdullah Al Monsur", "Nitesh Vamshi Bommisetty", "Gene Louis Kim"], "title": "Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes", "comment": null, "summary": "The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e8b\u4ef6\u68c0\u6d4b\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u89e3\u7801\u5668LLMs\u7684\u5355\u5411\u6027\u67b6\u6784\u74f6\u9888\u548cMicro-F1\u6307\u6807\u7684\u504f\u5411\u6027\uff0c\u63d0\u51fa\u4f7f\u7528\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u548cLoRA\u5fae\u8c03\u6765\u63d0\u5347\u6a21\u578b\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u4e0a\u7684\u6027\u80fd\uff0c\u4ee5Macro-F1\u4f5c\u4e3a\u66f4\u516c\u5e73\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u4e8b\u4ef6\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u89e3\u7801\u5668LLMs\u7684\u5355\u5411\u6027\u67b6\u6784\u4e0d\u9002\u5408\u9700\u8981\u53cc\u5411\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\uff1b2\uff09\u4f20\u7edf\u4f9d\u8d56Micro-F1\u6307\u6807\u4f1a\u504f\u5411\u591a\u6570\u7c7b\u522b\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u578b\u4e0a\u7684\u8868\u73b0\u3002", "method": "1\uff09\u4f7f\u7528\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u6a21\u578b\u4ee5\u514b\u670d\u89e3\u7801\u5668LLMs\u7684\u5355\u5411\u6027\u9650\u5236\uff1b2\uff09\u91c7\u7528Low-Rank Adaptation\uff08LoRA\uff09\u8fdb\u884c\u5fae\u8c03\uff1b3\uff09\u4ee5Macro-F1\u800c\u975eMicro-F1\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u6a21\u578b\u4f18\u4e8e\u6807\u51c6\u89e3\u7801\u5668\u57fa\u7ebf\uff1b2\uff09LoRA\u5fae\u8c03\u663e\u8457\u63d0\u5347Macro-F1\u5206\u6570\uff0c\u7279\u522b\u662f\u5bf9\u89e3\u7801\u5668\u6a21\u578b\uff1b3\uff09LoRA\u80fd\u6709\u6548\u589e\u5f3aLLMs\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u89e3\u7801\u5668LLMs\u7684\u5355\u5411\u6027\u67b6\u6784\u662f\u4e8b\u4ef6\u68c0\u6d4b\u7684\u74f6\u9888\uff0c\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u548cLoRA\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\uff0cMacro-F1\u662f\u6bd4Micro-F1\u66f4\u516c\u5e73\u7684\u8bc4\u4f30\u6307\u6807\uff0cLoRA\u7279\u522b\u9002\u5408\u589e\u5f3aLLMs\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2601.11895", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11895", "abs": "https://arxiv.org/abs/2601.11895", "authors": ["Pareesa Ameneh Golnari", "Adarsh Kumarappan", "Wen Wen", "Xiaoyu Liu", "Gabriel Ryan", "Yuting Sun", "Shengyu Fu", "Elsie Nallipogu"], "title": "DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models", "comment": null, "summary": "DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.", "AI": {"tldr": "DevBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\u7684\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c6\u4e2a\u4efb\u52a1\u7c7b\u522b\uff0c\u51711800\u4e2a\u8bc4\u4f30\u5b9e\u4f8b\uff0c\u5f3a\u8c03\u751f\u6001\u6709\u6548\u6027\u5e76\u907f\u514d\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8865\u5168\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u751f\u6001\u6709\u6548\u6027\uff0c\u5bb9\u6613\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\uff0c\u4e14\u65e0\u6cd5\u63d0\u4f9b\u8be6\u7ec6\u7684\u8bca\u65ad\u4fe1\u606f\u6765\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u548c\u6539\u8fdb\u3002", "method": "\u57fa\u4e8e\u771f\u5b9e\u5f00\u53d1\u8005\u9065\u6d4b\u6570\u636e\u6784\u5efa\u8bc4\u4f30\u5b9e\u4f8b\uff0c\u7ed3\u5408\u529f\u80fd\u6b63\u786e\u6027\u3001\u76f8\u4f3c\u5ea6\u6307\u6807\u548cLLM\u8bc4\u4f30\u8005\uff08\u5173\u6ce8\u5b9e\u7528\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff09\u7684\u7efc\u5408\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u4e869\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u8bed\u6cd5\u7cbe\u5ea6\u3001\u8bed\u4e49\u63a8\u7406\u548c\u5b9e\u9645\u6548\u7528\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u63d0\u4f9b\u4e86\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u7f3a\u5931\u4f46\u5b9e\u9645\u90e8\u7f72\u548c\u6a21\u578b\u5f00\u53d1\u5fc5\u9700\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002", "conclusion": "DevBench\u4e3a\u4ee3\u7801\u8865\u5168LLMs\u63d0\u4f9b\u4e86\u5177\u6709\u751f\u6001\u6709\u6548\u6027\u3001\u907f\u514d\u6570\u636e\u6c61\u67d3\u4e14\u652f\u6301\u8be6\u7ec6\u8bca\u65ad\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u80fd\u591f\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u548c\u9488\u5bf9\u6027\u6539\u8fdb\u3002"}}
{"id": "2601.12260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12260", "abs": "https://arxiv.org/abs/2601.12260", "authors": ["Yihao Ding", "Qiang Sun", "Puzhen Wu", "Sirui Li", "Siwen Luo", "Wei Liu"], "title": "Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding", "comment": "Accepted at WWW 2026 Demo Track", "summary": "Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.", "AI": {"tldr": "Docs2Synth\u662f\u4e00\u4e2a\u5408\u6210\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1QA\u5bf9\u6765\u8bad\u7ec3\u89c6\u89c9\u68c0\u7d22\u5668\uff0c\u7ed3\u5408MLLM\u8fdb\u884c\u68c0\u7d22-\u751f\u6210\u8fed\u4ee3\u63a8\u7406\uff0c\u89e3\u51b3\u53d7\u76d1\u7ba1\u9886\u57df\u6587\u6863\u7406\u89e3\u4e2d\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u548c\u9886\u57df\u77e5\u8bc6\u66f4\u65b0\u7684\u95ee\u9898\u3002", "motivation": "\u53d7\u76d1\u7ba1\u9886\u57df\uff08\u5982\u91d1\u878d\u3001\u533b\u7597\uff09\u7684\u6587\u6863\u7406\u89e3\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u7f3a\u4e4f\u624b\u52a8\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u6a21\u578b\u9002\u914d\uff1b2\uff09\u9884\u8bad\u7ec3\u6a21\u578b\u96be\u4ee5\u8ddf\u4e0a\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u66f4\u65b0\u3002\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0cMLLM\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u4e14\u9886\u57df\u57fa\u7840\u4e0d\u8db3\uff0c\u800cVLPM\u9700\u8981\u6602\u8d35\u7684\u6807\u6ce8\u6765\u8986\u76d6\u65b0\u9886\u57df\u3002", "method": "Docs2Synth\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u81ea\u52a8\u5904\u7406\u539f\u59cb\u6587\u6863\u96c6\uff1b2\uff09\u57fa\u4e8e\u4ee3\u7406\u7cfb\u7edf\u751f\u6210\u548c\u9a8c\u8bc1\u591a\u6837\u5316\u7684QA\u5bf9\uff1b3\uff09\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u89c6\u89c9\u68c0\u7d22\u5668\u63d0\u53d6\u9886\u57df\u76f8\u5173\u8bc1\u636e\u3002\u63a8\u7406\u65f6\u91c7\u7528\u68c0\u7d22\u5668\u4e0eMLLM\u534f\u4f5c\u7684\u8fed\u4ee3\u68c0\u7d22-\u751f\u6210\u5faa\u73af\u3002", "result": "\u5728\u591a\u4e2aVRDU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDocs2Synth\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u57fa\u7840\u6027\u548c\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002\u6846\u67b6\u8fd8\u63d0\u4f9b\u4e86\u6613\u4e8e\u4f7f\u7528\u7684Python\u5305\uff0c\u652f\u6301\u5373\u63d2\u5373\u7528\u90e8\u7f72\u5230\u5404\u79cd\u5b9e\u9645\u573a\u666f\u3002", "conclusion": "Docs2Synth\u901a\u8fc7\u5408\u6210\u76d1\u7763\u548c\u68c0\u7d22\u5f15\u5bfc\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53d7\u76d1\u7ba1\u9886\u57df\u6587\u6863\u7406\u89e3\u4e2d\u7684\u6807\u6ce8\u7a00\u7f3a\u548c\u77e5\u8bc6\u66f4\u65b0\u95ee\u9898\uff0c\u5728\u51cf\u5c11\u5e7b\u89c9\u548c\u63d0\u9ad8\u54cd\u5e94\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4f4e\u8d44\u6e90\u79c1\u6709\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13202", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13202", "abs": "https://arxiv.org/abs/2601.13202", "authors": ["Michael Giovanniello", "Dharik S. Mallapragada"], "title": "Emissions and cost tradeoffs of time-matched clean electricity procurement under inter-annual weather variability: case study of hydrogen production", "comment": "7 Figures, 1 table (main text)", "summary": "Time-matching requirements (TMRs) for clean electricity procurement are increasingly adopted in voluntary corporate sustainability initiatives and regulatory frameworks. While prior research has evaluated cost and emissions impacts of hourly vs. annual TMR, these studies typically rely on single-year weather scenarios that do not capture inter-annual variability in variable renewable energy (VRE) generation. We use a capacity expansion model to assess how inter-annual weather variability affects procurement-driven infrastructure investments, costs, and emissions for a grid-connected hydrogen producer under both annual and hourly time-matching strategies. Using a Texas case study, we compare deterministic (single weather scenario) and stochastic (nine weather scenarios) modeling approaches. Both procurement investments and cost and emissions outcomes are sensitive to weather scenario, with annual matching exhibiting greater sensitivity than hourly matching. Stochastic modeling finds higher cost premiums for hourly versus annual matching compared to deterministic modeling, though emissions trends remain directionally consistent. Demand flexibility through H2 storage is critical for lowering hourly matching cost premiums under weather-driven VRE variability. Partial hourly matching (e.g., 80-90% compliance) can modestly reduce costs while maintaining minimal emissions impacts. Finally, we examine how grid-level renewable portfolio standards (RPS) affect additionality and emissions. When stringent additionality is achieved via binding RPS constraints on non-H2 electricity demand, annual matching can produce emissions reductions comparable to hourly matching at lower cost.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u8003\u8651\u5e74\u9645\u5929\u6c14\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u6e05\u6d01\u7535\u529b\u91c7\u8d2d\u7684\u65f6\u95f4\u5339\u914d\u8981\u6c42\u5bf9\u6c22\u751f\u4ea7\u5546\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u3001\u6210\u672c\u548c\u6392\u653e\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5e74\u5ea6\u5339\u914d\u6bd4\u5c0f\u65f6\u5339\u914d\u5bf9\u5929\u6c14\u53d8\u5316\u66f4\u654f\u611f\uff0c\u4e14\u9700\u6c42\u7075\u6d3b\u6027\u5bf9\u964d\u4f4e\u5c0f\u65f6\u5339\u914d\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u6e05\u6d01\u7535\u529b\u91c7\u8d2d\u65f6\u95f4\u5339\u914d\u8981\u6c42\u7684\u7814\u7a76\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u5e74\u4efd\u5929\u6c14\u60c5\u666f\uff0c\u672a\u80fd\u6355\u6349\u53ef\u53d8\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u7684\u5e74\u9645\u53d8\u5316\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u79cd\u5929\u6c14\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u91c7\u8d2d\u9a71\u52a8\u7684\u6295\u8d44\u3001\u6210\u672c\u548c\u6392\u653e\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u5bb9\u91cf\u6269\u5c55\u6a21\u578b\uff0c\u4ee5\u5fb7\u514b\u8428\u65af\u5dde\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6bd4\u8f83\u786e\u5b9a\u6027\uff08\u5355\u4e00\u5929\u6c14\u60c5\u666f\uff09\u548c\u968f\u673a\u6027\uff08\u4e5d\u4e2a\u5929\u6c14\u60c5\u666f\uff09\u5efa\u6a21\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5e74\u5ea6\u548c\u5c0f\u65f6\u65f6\u95f4\u5339\u914d\u7b56\u7565\u4e0b\u6c22\u751f\u4ea7\u5546\u7684\u91c7\u8d2d\u6295\u8d44\u3001\u6210\u672c\u548c\u6392\u653e\u3002", "result": "\u91c7\u8d2d\u6295\u8d44\u3001\u6210\u672c\u548c\u6392\u653e\u7ed3\u679c\u5bf9\u5929\u6c14\u60c5\u666f\u654f\u611f\uff0c\u5e74\u5ea6\u5339\u914d\u6bd4\u5c0f\u65f6\u5339\u914d\u66f4\u654f\u611f\uff1b\u968f\u673a\u5efa\u6a21\u663e\u793a\u5c0f\u65f6\u5339\u914d\u76f8\u5bf9\u4e8e\u5e74\u5ea6\u5339\u914d\u7684\u6210\u672c\u6ea2\u4ef7\u66f4\u9ad8\uff1b\u6c22\u5b58\u50a8\u63d0\u4f9b\u7684\u9700\u6c42\u7075\u6d3b\u6027\u5bf9\u964d\u4f4e\u5c0f\u65f6\u5339\u914d\u6210\u672c\u6ea2\u4ef7\u81f3\u5173\u91cd\u8981\uff1b\u90e8\u5206\u5c0f\u65f6\u5339\u914d\u53ef\u9002\u5ea6\u964d\u4f4e\u6210\u672c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u6392\u653e\u5f71\u54cd\uff1b\u5728\u4e25\u683c\u989d\u5916\u6027\u8981\u6c42\u4e0b\uff0c\u5e74\u5ea6\u5339\u914d\u80fd\u4ee5\u66f4\u4f4e\u6210\u672c\u5b9e\u73b0\u4e0e\u5c0f\u65f6\u5339\u914d\u76f8\u5f53\u7684\u6392\u653e\u51cf\u5c11\u3002", "conclusion": "\u8003\u8651\u5929\u6c14\u53d8\u5316\u7684\u65f6\u95f4\u5339\u914d\u8981\u6c42\u5206\u6790\u663e\u793a\uff0c\u5e74\u5ea6\u5339\u914d\u5bf9\u5929\u6c14\u53d8\u5316\u66f4\u654f\u611f\uff0c\u800c\u9700\u6c42\u7075\u6d3b\u6027\u5bf9\u5c0f\u65f6\u5339\u914d\u81f3\u5173\u91cd\u8981\u3002\u653f\u7b56\u8bbe\u8ba1\u5e94\u8003\u8651\u90e8\u5206\u5339\u914d\u548c\u989d\u5916\u6027\u8981\u6c42\uff0c\u4ee5\u5e73\u8861\u6210\u672c\u548c\u6392\u653e\u76ee\u6807\u3002"}}
{"id": "2601.14190", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14190", "abs": "https://arxiv.org/abs/2601.14190", "authors": ["Polina Smirnova", "Mykola Makhortykh"], "title": "Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia", "comment": null, "summary": "This study examines how Russian far-right communities on Telegram shape perceptions of political figures through memes and visual narratives. Far from passive spectators, these actors co-produce propaganda, blending state-aligned messages with their own extremist framings. In Russia, such groups are central because they articulate the ideological foundations of the war against Ukraine and reflect the regime's gradual drift toward ultranationalist rhetoric. Drawing on a dataset of 200,000 images from expert-selected far-right Telegram channels, the study employs computer vision and unsupervised clustering to identify memes featuring Russian (Putin, Shoigu) and foreign politicians (Zelensky, Biden, Trump) and to reveal recurrent visual patterns in their representation. By leveraging the large-scale and temporal depth of this dataset, the analysis uncovers differential patterns of legitimation and delegitimation across actors and over time. These insights are not attainable in smaller-scale studies. Preliminary findings show that far-right memes function as instruments of propaganda co-production. These communities do not simply echo official messages but generate bottom-up narratives of legitimation and delegitimation that align with state ideology. By framing leaders as heroic and opponents as corrupt or weak, far-right actors act as informal co-creators of authoritarian legitimacy within Russia's informational autocracy.", "AI": {"tldr": "\u4fc4\u7f57\u65af\u6781\u53f3\u7ffcTelegram\u793e\u533a\u901a\u8fc7\u8868\u60c5\u5305\u548c\u89c6\u89c9\u53d9\u4e8b\u5851\u9020\u653f\u6cbb\u4eba\u7269\u5f62\u8c61\uff0c\u4f5c\u4e3a\u5ba3\u4f20\u5171\u751f\u4ea7\u8005\u800c\u975e\u88ab\u52a8\u4f20\u64ad\u8005\uff0c\u5728\u4fc4\u7f57\u65af\u4fe1\u606f\u4e13\u5236\u4e2d\u5171\u540c\u6784\u5efa\u5a01\u6743\u5408\u6cd5\u6027\u3002", "motivation": "\u7814\u7a76\u4fc4\u7f57\u65af\u6781\u53f3\u7ffcTelegram\u793e\u533a\u5982\u4f55\u901a\u8fc7\u8868\u60c5\u5305\u548c\u89c6\u89c9\u53d9\u4e8b\u5851\u9020\u653f\u6cbb\u4eba\u7269\u5f62\u8c61\uff0c\u8fd9\u4e9b\u7fa4\u4f53\u5728\u4fc4\u7f57\u65af\u4fe1\u606f\u751f\u6001\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\uff0c\u56e0\u4e3a\u5b83\u4eec\u9610\u8ff0\u4e86\u4fc4\u4e4c\u6218\u4e89\u7684\u610f\u8bc6\u5f62\u6001\u57fa\u7840\uff0c\u5e76\u53cd\u6620\u4e86\u653f\u6743\u9010\u6e10\u8f6c\u5411\u6781\u7aef\u6c11\u65cf\u4e3b\u4e49\u8a00\u8bba\u7684\u8d8b\u52bf\u3002", "method": "\u4ece\u4e13\u5bb6\u9009\u5b9a\u7684\u6781\u53f3\u7ffcTelegram\u9891\u9053\u6536\u96c620\u4e07\u5f20\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u8fd0\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u65e0\u76d1\u7763\u805a\u7c7b\u6280\u672f\uff0c\u8bc6\u522b\u5305\u542b\u4fc4\u7f57\u65af\uff08\u666e\u4eac\u3001\u7ecd\u4f0a\u53e4\uff09\u548c\u5916\u56fd\u653f\u6cbb\u5bb6\uff08\u6cfd\u8fde\u65af\u57fa\u3001\u62dc\u767b\u3001\u7279\u6717\u666e\uff09\u7684\u8868\u60c5\u5305\uff0c\u5e76\u63ed\u793a\u5176\u8868\u5f81\u4e2d\u7684\u91cd\u590d\u89c6\u89c9\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6781\u53f3\u7ffc\u8868\u60c5\u5305\u4f5c\u4e3a\u5ba3\u4f20\u5171\u751f\u4ea7\u5de5\u5177\uff0c\u8fd9\u4e9b\u793e\u533a\u4e0d\u4ec5\u91cd\u590d\u5b98\u65b9\u4fe1\u606f\uff0c\u8fd8\u751f\u6210\u81ea\u4e0b\u800c\u4e0a\u7684\u5408\u6cd5\u5316\u548c\u975e\u6cd5\u5316\u53d9\u4e8b\uff0c\u4e0e\u56fd\u5bb6\u610f\u8bc6\u5f62\u6001\u4fdd\u6301\u4e00\u81f4\u3002\u901a\u8fc7\u5c06\u9886\u5bfc\u4eba\u63cf\u7ed8\u4e3a\u82f1\u96c4\u3001\u5bf9\u624b\u63cf\u7ed8\u4e3a\u8150\u8d25\u6216\u8f6f\u5f31\uff0c\u6781\u53f3\u7ffc\u884c\u4e3a\u8005\u6210\u4e3a\u4fc4\u7f57\u65af\u4fe1\u606f\u4e13\u5236\u4e2d\u5a01\u6743\u5408\u6cd5\u6027\u7684\u975e\u6b63\u5f0f\u5171\u540c\u521b\u9020\u8005\u3002", "conclusion": "\u4fc4\u7f57\u65af\u6781\u53f3\u7ffcTelegram\u793e\u533a\u901a\u8fc7\u8868\u60c5\u5305\u89c6\u89c9\u53d9\u4e8b\u79ef\u6781\u53c2\u4e0e\u5ba3\u4f20\u5171\u751f\u4ea7\uff0c\u5728\u4fc4\u7f57\u65af\u4fe1\u606f\u4e13\u5236\u751f\u6001\u7cfb\u7edf\u4e2d\u5171\u540c\u6784\u5efa\u5a01\u6743\u5408\u6cd5\u6027\uff0c\u53cd\u6620\u4e86\u653f\u6743\u4e0e\u6781\u7aef\u6c11\u65cf\u4e3b\u4e49\u8a00\u8bba\u7684\u878d\u5408\u8d8b\u52bf\u3002"}}
{"id": "2601.11956", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11956", "abs": "https://arxiv.org/abs/2601.11956", "authors": ["Yuyin Lu", "Ziran Liang", "Yanghui Rao", "Wenqi Fan", "Fu Lee Wang", "Qing Li"], "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence", "comment": null, "summary": "Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.", "AI": {"tldr": "DoublyCal\u6846\u67b6\u901a\u8fc7\u53cc\u91cd\u6821\u51c6\u539f\u5219\uff0c\u4f7f\u7528\u8f7b\u91cf\u4ee3\u7406\u6a21\u578b\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u8bc1\u636e\u548c\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\uff0c\u6307\u5bfc\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u66f4\u51c6\u786e\u4e14\u7f6e\u4fe1\u5ea6\u53ef\u8ffd\u6eaf\u7684\u9884\u6d4b", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u65b9\u6cd5\u65e0\u6cd5\u91cf\u5316\u68c0\u7d22\u8bc1\u636e\u548c\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u89e3\u51b3\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u4e0d\u786e\u5b9a\u6027\u8ffd\u6eaf\u7684\u95ee\u9898", "method": "\u63d0\u51faDoublyCal\u6846\u67b6\uff0c\u57fa\u4e8e\u53cc\u91cd\u6821\u51c6\u539f\u5219\uff1a1) \u4f7f\u7528\u8f7b\u91cf\u4ee3\u7406\u6a21\u578b\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u8bc1\u636e\u5e76\u6821\u51c6\u8bc1\u636e\u7f6e\u4fe1\u5ea6\uff1b2) \u7528\u6821\u51c6\u540e\u7684\u8bc1\u636e\u6307\u5bfc\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ea7\u751f\u6700\u7ec8\u9884\u6d4b\u5e76\u786e\u4fdd\u7f6e\u4fe1\u5ea6\u53ef\u8ffd\u6eaf\u5230\u8bc1\u636e\u7684\u4e0d\u786e\u5b9a\u6027", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDoublyCal\u663e\u8457\u63d0\u9ad8\u4e86\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u4f4e\u7684token\u6210\u672c", "conclusion": "DoublyCal\u901a\u8fc7\u53cc\u91cd\u6821\u51c6\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u4fe1\u7684\u63a8\u7406\uff0c\u4e3a\u77e5\u8bc6\u589e\u5f3a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u8ffd\u6eaf\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u65b9\u6cd5"}}
{"id": "2601.12294", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12294", "abs": "https://arxiv.org/abs/2601.12294", "authors": ["Dawei Li", "Yuguang Yao", "Zhen Tan", "Huan Liu", "Ruocheng Guo"], "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "comment": "under review", "summary": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86ToolPRMBench\uff0c\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u4e2d\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u5355\u6b65\u548c\u591a\u6b65\u6d4b\u8bd5\u6848\u4f8b\uff0c\u901a\u8fc7\u591aLLM\u9a8c\u8bc1\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u6d4b\u8bd5\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\uff0c\u800cPRMs\u5bf9\u4e8e\u6307\u5bfc\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u641c\u7d22\u548c\u63a2\u7d22\u81f3\u5173\u91cd\u8981\u3002", "method": "\u57fa\u4e8e\u591a\u4e2a\u4ee3\u8868\u6027\u5de5\u5177\u4f7f\u7528\u57fa\u51c6\u6784\u5efaToolPRMBench\uff0c\u5c06\u4ee3\u7406\u8f68\u8ff9\u8f6c\u6362\u4e3a\u6b65\u9aa4\u7ea7\u6d4b\u8bd5\u6848\u4f8b\uff0c\u5305\u542b\u4ea4\u4e92\u5386\u53f2\u3001\u6b63\u786e\u52a8\u4f5c\u3001\u5408\u7406\u4f46\u4e0d\u6b63\u786e\u7684\u66ff\u4ee3\u65b9\u6848\u548c\u5de5\u5177\u5143\u6570\u636e\u3002\u5206\u522b\u4f7f\u7528\u79bb\u7ebf\u91c7\u6837\u9694\u79bb\u5355\u6b65\u9519\u8bef\u548c\u5728\u7ebf\u91c7\u6837\u6355\u83b7\u591a\u6b65\u5931\u8d25\uff0c\u5e76\u91c7\u7528\u591aLLM\u9a8c\u8bc1\u7ba1\u9053\u51cf\u5c11\u6807\u7b7e\u566a\u58f0\u3002", "result": "\u901a\u8fc7\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u3001\u901a\u7528PRMs\u548c\u5de5\u5177\u4e13\u7528PRMs\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86PRMs\u6709\u6548\u6027\u7684\u660e\u663e\u5dee\u5f02\uff0c\u5e76\u7a81\u663e\u4e86\u5de5\u5177\u4e13\u7528PRMs\u7684\u6f5c\u529b\u3002", "conclusion": "ToolPRMBench\u4e3a\u8bc4\u4f30\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e2d\u7684PRMs\u63d0\u4f9b\u4e86\u7cfb\u7edf\u53ef\u9760\u7684\u57fa\u51c6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5de5\u5177\u4e13\u7528PRMs\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5c06\u5f00\u6e90\u3002"}}
{"id": "2601.13273", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13273", "abs": "https://arxiv.org/abs/2601.13273", "authors": ["Theodor-Gabriel Nicu", "Florin Stoican", "Daniel-Mihail Ioan", "Ionela Prodan"], "title": "Safe Navigation in Cluttered Environments Via Spline-Based Harmonic Potential Fields", "comment": null, "summary": "We provide a complete motion-planning mechanism that ensures target tracking and obstacle avoidance in a cluttered environment. For a given polyhedral decomposition of the feasible space, we adopt a novel procedure that constrains the agent to move only through a prescribed sequence of cells via a suitable control policy.\n  For each cell, we construct a harmonic potential surface induced by a Dirichlet boundary condition given as a cardinal B-spline curve. A detailed analysis of the curve behavior (periodicity, support) and of the associated control point selection allows us to explicitly compute these harmonic potential surfaces, from which we subsequently derive the corresponding control policy. We illustrate that the resulting construction funnels the agent safely along the chain of cells from the starting point to the target.", "AI": {"tldr": "\u63d0\u51fa\u5b8c\u6574\u8fd0\u52a8\u89c4\u5212\u673a\u5236\uff0c\u901a\u8fc7\u591a\u9762\u4f53\u5206\u89e3\u53ef\u884c\u7a7a\u95f4\uff0c\u7ea6\u675f\u667a\u80fd\u4f53\u6309\u9884\u5b9a\u5355\u5143\u5e8f\u5217\u79fb\u52a8\uff0c\u5229\u7528B\u6837\u6761\u66f2\u7ebf\u6784\u5efa\u8c03\u548c\u52bf\u80fd\u9762\uff0c\u5b9e\u73b0\u76ee\u6807\u8ddf\u8e2a\u4e0e\u907f\u969c", "motivation": "\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u76ee\u6807\u8ddf\u8e2a\u548c\u907f\u969c\u662f\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u786e\u4fdd\u667a\u80fd\u4f53\u5728\u969c\u788d\u7269\u5bc6\u96c6\u7684\u73af\u5883\u4e2d\u5b89\u5168\u5bfc\u822a\u5230\u76ee\u6807\u4f4d\u7f6e", "method": "1) \u5bf9\u53ef\u884c\u7a7a\u95f4\u8fdb\u884c\u591a\u9762\u4f53\u5206\u89e3\uff1b2) \u7ea6\u675f\u667a\u80fd\u4f53\u6309\u9884\u5b9a\u5355\u5143\u5e8f\u5217\u79fb\u52a8\uff1b3) \u4e3a\u6bcf\u4e2a\u5355\u5143\u6784\u5efa\u57fa\u4e8eDirichlet\u8fb9\u754c\u6761\u4ef6\u7684\u8c03\u548c\u52bf\u80fd\u9762\uff0c\u8fb9\u754c\u6761\u4ef6\u7531\u57fa\u6570B\u6837\u6761\u66f2\u7ebf\u7ed9\u51fa\uff1b4) \u5206\u6790\u66f2\u7ebf\u7279\u6027\uff08\u5468\u671f\u6027\u3001\u652f\u6491\u96c6\uff09\u548c\u63a7\u5236\u70b9\u9009\u62e9\uff1b5) \u4ece\u8c03\u548c\u52bf\u80fd\u9762\u63a8\u5bfc\u63a7\u5236\u7b56\u7565", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u667a\u80fd\u4f53\u5b89\u5168\u5730\u6cbf\u7740\u5355\u5143\u94fe\u4ece\u8d77\u70b9\u5f15\u5bfc\u5230\u76ee\u6807\u70b9\uff0c\u5f62\u6210\u6709\u6548\u7684\"\u6f0f\u6597\"\u6548\u5e94\uff0c\u786e\u4fdd\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5bfc\u822a", "conclusion": "\u63d0\u51fa\u7684\u8fd0\u52a8\u89c4\u5212\u673a\u5236\u901a\u8fc7\u7ed3\u5408\u591a\u9762\u4f53\u5206\u89e3\u3001\u8c03\u548c\u52bf\u80fd\u9762\u548cB\u6837\u6761\u66f2\u7ebf\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u53ef\u9760\u7684\u76ee\u6807\u8ddf\u8e2a\u548c\u907f\u969c\u529f\u80fd"}}
{"id": "2601.13511", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13511", "abs": "https://arxiv.org/abs/2601.13511", "authors": ["Nguyen Quang Huy", "Nguyen Huy Hung", "Tran Van Nghi", "Hoang Ngoc Tuan", "Nguyen Van Tuyen"], "title": "Hidden convexity of quadratic systems and its application to quadratic programming", "comment": "20 pages", "summary": "In this paper, we present sufficient conditions ensuring that the sum of the image of quadratic functions and the nonnegative orthant is convex. The hidden convexity of the trust-region problem with linear inequality constraints is established under a newly proposed assumption, which is compared with the previous one in [{\\it Math. Program. 147, 171--206, 2014}]. We also provide a complete proof of the hidden convexity of a system of two quadratic functions in [{\\it J. Glob. Optim. 56, 1045--1072, 2013}]. Furthermore, necessary and sufficient conditions for the S-lemma concerning systems of quadratic inequalities are investigated. Finally, we derive necessary and sufficient global optimality conditions and strong duality results for quadratic programming.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u6b21\u51fd\u6570\u4e0e\u975e\u8d1f\u8c61\u9650\u4e4b\u548c\u7684\u51f8\u6027\u6761\u4ef6\uff0c\u5efa\u7acb\u4e86\u5e26\u7ebf\u6027\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7684\u4fe1\u4efb\u57df\u95ee\u9898\u7684\u9690\u85cf\u51f8\u6027\uff0c\u5b8c\u5584\u4e86\u4e24\u4e2a\u4e8c\u6b21\u51fd\u6570\u7cfb\u7edf\u7684\u9690\u85cf\u51f8\u6027\u8bc1\u660e\uff0c\u7814\u7a76\u4e86\u4e8c\u6b21\u4e0d\u7b49\u5f0f\u7cfb\u7edf\u7684S\u5f15\u7406\u6761\u4ef6\uff0c\u5e76\u63a8\u5bfc\u4e86\u4e8c\u6b21\u89c4\u5212\u7684\u5168\u5c40\u6700\u4f18\u6027\u6761\u4ef6\u548c\u5f3a\u5bf9\u5076\u6027\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u4e8c\u6b21\u51fd\u6570\u4e0e\u975e\u8d1f\u8c61\u9650\u4e4b\u548c\u7684\u51f8\u6027\u6761\u4ef6\uff0c\u8fd9\u5bf9\u4e8e\u4f18\u5316\u95ee\u9898\u7279\u522b\u662f\u4e8c\u6b21\u89c4\u5212\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u5148\u524d\u7684\u7814\u7a76\u4e2d\u5b58\u5728\u4e00\u4e9b\u672a\u5b8c\u5168\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5982\u4fe1\u4efb\u57df\u95ee\u9898\u7684\u9690\u85cf\u51f8\u6027\u6761\u4ef6\u3001\u4e24\u4e2a\u4e8c\u6b21\u51fd\u6570\u7cfb\u7edf\u7684\u9690\u85cf\u51f8\u6027\u8bc1\u660e\u7b49\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6f84\u6e05\u548c\u5b8c\u5584\u3002", "method": "1. \u5efa\u7acb\u4e8c\u6b21\u51fd\u6570\u56fe\u50cf\u4e0e\u975e\u8d1f\u8c61\u9650\u4e4b\u548c\u51f8\u6027\u7684\u5145\u5206\u6761\u4ef6\uff1b2. \u63d0\u51fa\u65b0\u7684\u5047\u8bbe\u6761\u4ef6\uff0c\u5efa\u7acb\u5e26\u7ebf\u6027\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7684\u4fe1\u4efb\u57df\u95ee\u9898\u7684\u9690\u85cf\u51f8\u6027\uff0c\u5e76\u4e0e\u5148\u524d\u7814\u7a76\u4e2d\u7684\u6761\u4ef6\u8fdb\u884c\u6bd4\u8f83\uff1b3. \u63d0\u4f9b\u4e24\u4e2a\u4e8c\u6b21\u51fd\u6570\u7cfb\u7edf\u9690\u85cf\u51f8\u6027\u7684\u5b8c\u6574\u8bc1\u660e\uff1b4. \u7814\u7a76\u4e8c\u6b21\u4e0d\u7b49\u5f0f\u7cfb\u7edfS\u5f15\u7406\u7684\u5145\u8981\u6761\u4ef6\uff1b5. \u63a8\u5bfc\u4e8c\u6b21\u89c4\u5212\u7684\u5168\u5c40\u6700\u4f18\u6027\u6761\u4ef6\u548c\u5f3a\u5bf9\u5076\u6027\u7ed3\u679c\u3002", "result": "1. \u83b7\u5f97\u4e86\u4e8c\u6b21\u51fd\u6570\u4e0e\u975e\u8d1f\u8c61\u9650\u4e4b\u548c\u51f8\u6027\u7684\u5145\u5206\u6761\u4ef6\uff1b2. \u5728\u63d0\u51fa\u7684\u65b0\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u4fe1\u4efb\u57df\u95ee\u9898\u7684\u9690\u85cf\u51f8\u6027\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0e\u5148\u524d\u6761\u4ef6\u7684\u5dee\u5f02\uff1b3. \u5b8c\u5584\u4e86\u4e24\u4e2a\u4e8c\u6b21\u51fd\u6570\u7cfb\u7edf\u9690\u85cf\u51f8\u6027\u7684\u8bc1\u660e\uff1b4. \u5f97\u5230\u4e86\u4e8c\u6b21\u4e0d\u7b49\u5f0f\u7cfb\u7edfS\u5f15\u7406\u7684\u5145\u8981\u6761\u4ef6\uff1b5. \u5efa\u7acb\u4e86\u4e8c\u6b21\u89c4\u5212\u7684\u5168\u5c40\u6700\u4f18\u6027\u6761\u4ef6\u548c\u5f3a\u5bf9\u5076\u6027\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u4e8c\u6b21\u51fd\u6570\u76f8\u5173\u7684\u51f8\u6027\u3001\u9690\u85cf\u51f8\u6027\u548c\u6700\u4f18\u6027\u6761\u4ef6\u95ee\u9898\uff0c\u4e3a\u4e8c\u6b21\u89c4\u5212\u7406\u8bba\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u652f\u6491\u3002\u6240\u5efa\u7acb\u7684\u5145\u5206\u6761\u4ef6\u3001\u9690\u85cf\u51f8\u6027\u7ed3\u679c\u3001S\u5f15\u7406\u6761\u4ef6\u548c\u6700\u4f18\u6027\u6761\u4ef6\u5b8c\u5584\u4e86\u8be5\u9886\u57df\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u4ef7\u503c\u3002"}}
{"id": "2601.11957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11957", "abs": "https://arxiv.org/abs/2601.11957", "authors": ["Bingxuan Li", "Jeonghwan Kim", "Cheng Qian", "Xiusi Chen", "Eitan Anzenberg", "Niran Kundapur", "Heng Ji"], "title": "PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning", "comment": null, "summary": "Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.", "AI": {"tldr": "\u63d0\u51faCalConflictBench\u57fa\u51c6\u6d4b\u8bd5\u65e5\u5386\u51b2\u7a81\u89e3\u51b3\uff0c\u5f00\u53d1PEARL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u8bed\u8a00\u4ee3\u7406\u6027\u80fd", "motivation": "\u91cd\u53e0\u7684\u65e5\u5386\u9080\u8bf7\u8feb\u4f7f\u4e13\u4e1a\u4eba\u58eb\u4e0d\u65ad\u51b3\u5b9a\u53c2\u52a0\u3001\u91cd\u65b0\u5b89\u6392\u6216\u62d2\u7edd\u54ea\u4e9b\u4f1a\u8bae\uff0c\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u3002\u4eba\u5de5\u8c03\u5ea6\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u8bed\u8a00\u4ee3\u7406\u80fd\u5426\u6709\u6548\u7ba1\u7406\u65f6\u95f4\u3002", "method": "\u5f15\u5165CalConflictBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u957f\u89c6\u91ce\u65e5\u5386\u51b2\u7a81\u89e3\u51b3\u3002\u63d0\u51faPEARL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u8bb0\u5fc6\u6a21\u5757\u548c\u4f18\u5316\u7684\u8f6e\u6b21\u5956\u52b1\u8bbe\u8ba1\u589e\u5f3a\u8bed\u8a00\u4ee3\u7406\uff0c\u4f7f\u5176\u80fd\u591f\u52a8\u6001\u63a8\u65ad\u548c\u9002\u5e94\u7528\u6237\u504f\u597d\u3002", "result": "\u5f53\u524dLLM\u4ee3\u7406\u8868\u73b0\u4e0d\u4f73\uff08\u5982Qwen-3-30B-Think\u5e73\u5747\u9519\u8bef\u738735%\uff09\u3002PEARL\u5b9e\u73b0\u4e860.76\u7684\u9519\u8bef\u51cf\u5c11\u7387\uff0c\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5e73\u5747\u9519\u8bef\u7387\u63d0\u534755%\u3002", "conclusion": "PEARL\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u4ee3\u7406\u5728\u65e5\u5386\u51b2\u7a81\u89e3\u51b3\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u80fd\u591f\u6709\u6548\u63a8\u65ad\u548c\u9002\u5e94\u7528\u6237\u504f\u597d\uff0c\u4e3a\u81ea\u52a8\u5316\u65f6\u95f4\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.11924", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11924", "abs": "https://arxiv.org/abs/2601.11924", "authors": ["Ming Shi"], "title": "Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits", "comment": null, "summary": "We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $\u0393$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $\u03c6$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $\u0393$ can translate into an effective corruption level ranging from $\u0393$ to $N\u0393$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(\u0393)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $\u03a9(\u0393)$ penalty and a high-corruption regime $\u0393=\u0398(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $\u03bd$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $\u0393$.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6297\u6027\u8150\u8d25\u548c\u6709\u9650\u9a8c\u8bc1\u4e0b\u7684\u5408\u4f5c\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u901a\u4fe1\u534f\u8bae\u5982\u4f55\u5c06\u73af\u5883\u4fa7\u8150\u8d25\u9884\u7b97\u0393\u8f6c\u5316\u4e3a\u4ece\u0393\u5230N\u0393\u4e0d\u7b49\u7684\u6709\u6548\u8150\u8d25\u6c34\u5e73\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u4fe1\u606f\u5171\u4eab\u7b56\u7565\u7684\u540e\u6094\u754c\u3002", "motivation": "\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u667a\u80fd\u4f53\u9762\u4e34\u5bf9\u6297\u6027\u8150\u8d25\u7684\u89c2\u6d4b\u53cd\u9988\uff0c\u540c\u65f6\u53ea\u80fd\u8fdb\u884c\u6709\u9650\u9a8c\u8bc1\u3002\u9700\u8981\u7406\u89e3\u4e0d\u540c\u901a\u4fe1\u534f\u8bae\u5982\u4f55\u5f71\u54cd\u8150\u8d25\u7684\u4f20\u64ad\u6548\u5e94\uff0c\u4ee5\u53ca\u5982\u4f55\u8bbe\u8ba1\u6709\u6548\u7684\u5b66\u4e60\u7b56\u7565\u6765\u6700\u5c0f\u5316\u56e2\u961f\u540e\u6094\u3002", "method": "\u63d0\u51fa\u901a\u4fe1-\u8150\u8d25\u8026\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8bae\u8bf1\u5bfc\u7684\u591a\u6837\u6027\u6cdb\u51fd\u91cf\u5316\u4e0d\u540c\u4fe1\u606f\u5171\u4eab\u7b56\u7565\uff08\u539f\u59cb\u6837\u672c\u5171\u4eab\u3001\u7edf\u8ba1\u6458\u8981\u5171\u4eab\u3001\u4ec5\u63a8\u8350\u5171\u4eab\uff09\u5bf9\u8150\u8d25\u7684\u653e\u5927\u6548\u5e94\u3002\u5efa\u7acb\u57fa\u4e8e\u6709\u6548\u8150\u8d25\u53c2\u6570\u7684\u540e\u6094\u754c\uff0c\u5e76\u5206\u6790\u9a8c\u8bc1\u89c2\u6d4b\u7684\u5168\u5c40\u9884\u7b97\u03bd\u5982\u4f55\u6062\u590d\u53ef\u5b66\u4e60\u6027\u3002", "result": "\u539f\u59cb\u6837\u672c\u5171\u4eab\u53ef\u80fd\u906d\u53d7N\u500d\u7684\u8150\u8d25\u60e9\u7f5a\uff0c\u800c\u6458\u8981\u5171\u4eab\u548c\u4ec5\u63a8\u8350\u5171\u4eab\u80fd\u4fdd\u6301O(\u0393)\u7684\u672a\u653e\u5927\u9879\u5e76\u8fbe\u5230\u4e2d\u5fc3\u5316\u901f\u7387\u7684\u56e2\u961f\u540e\u6094\u3002\u5efa\u7acb\u4e86\u4fe1\u606f\u7406\u8bba\u4e0b\u754c\uff0c\u5305\u62ec\u4e0d\u53ef\u907f\u514d\u7684\u03a9(\u0393)\u60e9\u7f5a\uff0c\u4ee5\u53ca\u5728\u0393=\u0398(NT)\u7684\u9ad8\u8150\u8d25\u533a\u57df\u6ca1\u6709\u5e72\u51c0\u4fe1\u606f\u5c31\u65e0\u6cd5\u83b7\u5f97\u4e9a\u7ebf\u6027\u540e\u6094\u3002\u9a8c\u8bc1\u89c2\u6d4b\u5728\u8d85\u8fc7\u8bc6\u522b\u9608\u503c\u540e\u80fd\u6062\u590d\u53ef\u5b66\u4e60\u6027\u3002", "conclusion": "\u901a\u4fe1\u534f\u8bae\u8bbe\u8ba1\u5bf9\u8150\u8d25\u4f20\u64ad\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u667a\u80fd\u4f53\u5e94\u907f\u514d\u539f\u59cb\u6837\u672c\u5171\u4eab\u4ee5\u9632\u6b62\u8150\u8d25\u653e\u5927\u3002\u5728\u8150\u8d25\u4e25\u91cd\u65f6\uff0c\u9a8c\u8bc1\u89c2\u6d4b\u662f\u5fc5\u8981\u7684\uff0c\u4e00\u65e6\u9a8c\u8bc1\u9884\u7b97\u8d85\u8fc7\u8bc6\u522b\u9608\u503c\uff0c\u8ba4\u8bc1\u5171\u4eab\u80fd\u4f7f\u56e2\u961f\u540e\u6094\u72ec\u7acb\u4e8e\u8150\u8d25\u9884\u7b97\u0393\u3002"}}
{"id": "2601.12310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12310", "abs": "https://arxiv.org/abs/2601.12310", "authors": ["Jennifer Dodgson", "Alfath Daryl Alhajir", "Michael Joedhitya", "Akira Rafhael Janson Pattirane", "Surender Suresh Kumar", "Joseph Lim", "C. H. Peh", "Adith Ramdas", "Steven Zhang Zhexu"], "title": "Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection", "comment": null, "summary": "Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.\n  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.\n  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u73af\u5883\u5b58\u6d3b\u6027\u800c\u975e\u5956\u52b1\u7684\u81ea\u6211\u8bad\u7ec3\u67b6\u6784\uff0c\u901a\u8fc7\u884c\u4e3a\u7684\u73af\u5883\u6548\u5e94\u6301\u4e45\u6027\u548c\u672a\u6765\u4ea4\u4e92\u53ef\u80fd\u6027\u8fdb\u884c\u9009\u62e9\uff0c\u907f\u514d\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u8bed\u4e49\u6f02\u79fb\uff0c\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edf\u81ea\u6211\u8bad\u7ec3\u7cfb\u7edf\u56e0\u7f3a\u4e4f\u5224\u65ad\u6570\u636e\u8d28\u91cf\u7684\u5916\u90e8\u6807\u51c6\u800c\u5bb9\u6613\u9000\u5316\uff0c\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u8bed\u4e49\u6f02\u79fb\u3002\u9700\u8981\u4e00\u79cd\u5728\u7a00\u758f\u5916\u90e8\u53cd\u9988\u548c\u6709\u9650\u5185\u5b58\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u81ea\u6211\u8bad\u7ec3\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u73af\u5883\u5b58\u6d3b\u6027\u800c\u975e\u5956\u52b1\u3001\u76ee\u6807\u51fd\u6570\u6216\u5916\u90e8\u9002\u5e94\u5ea6\u6807\u51c6\u7684\u81ea\u6211\u8bad\u7ec3\u67b6\u6784\u3002\u5019\u9009\u884c\u4e3a\u5728\u771f\u5b9e\u8d44\u6e90\u7ea6\u675f\u4e0b\u6267\u884c\uff0c\u53ea\u6709\u90a3\u4e9b\u73af\u5883\u6548\u5e94\u6301\u4e45\u4e14\u80fd\u4fdd\u6301\u672a\u6765\u4ea4\u4e92\u53ef\u80fd\u6027\u7684\u884c\u4e3a\u624d\u4f1a\u88ab\u4f20\u64ad\u3002\u73af\u5883\u4e0d\u63d0\u4f9b\u8bed\u4e49\u53cd\u9988\u3001\u5bc6\u96c6\u5956\u52b1\u6216\u4efb\u52a1\u7279\u5b9a\u76d1\u7763\uff0c\u9009\u62e9\u4ec5\u901a\u8fc7\u884c\u4e3a\u4f5c\u4e3a\u4e16\u754c\u6539\u53d8\u4e8b\u4ef6\u7684\u5dee\u5f02\u751f\u5b58\u6765\u5b9e\u73b0\u3002", "result": "\u5206\u6790\u663e\u793a\u6539\u8fdb\u4e3b\u8981\u901a\u8fc7\u6709\u6548\u4e14\u53ef\u91cd\u590d\u7b56\u7565\u5728\u5de9\u56fa\u548c\u526a\u679d\u673a\u5236\u4e0b\u7684\u6301\u4e45\u6027\u5b9e\u73b0\uff08\u8d1f\u7a7a\u95f4\u5b66\u4e60\u8303\u5f0f\uff09\u3002\u6a21\u578b\u53d1\u5c55\u51fa\u5143\u5b66\u4e60\u7b56\u7565\uff08\u5982\u6545\u610f\u5b9e\u9a8c\u5931\u8d25\u4ee5\u83b7\u53d6\u4fe1\u606f\u6027\u9519\u8bef\u6d88\u606f\uff09\u800c\u65e0\u9700\u660e\u786e\u6307\u5bfc\u3002\u73af\u5883\u57fa\u7840\u9009\u62e9\u5b9e\u73b0\u4e86\u53ef\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "\u73af\u5883\u57fa\u7840\u9009\u62e9\u80fd\u591f\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u81ea\u6211\u6539\u8fdb\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u7c7b\u7b56\u5212\u7684\u6570\u636e\u6216\u590d\u6742\u7684\u5956\u52b1\u5851\u9020\u3002"}}
{"id": "2601.13605", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.13605", "abs": "https://arxiv.org/abs/2601.13605", "authors": ["Milad Hoseinpour", "Shubhanshu Shekhar", "Vladimir Dvorkin"], "title": "Outage Identification from Electricity Market Data: Quickest Change Detection Approach", "comment": "7 pages, 2 figures, 1 table", "summary": "Power system outages expose market participants to significant financial risk unless promptly detected and hedged. We develop an outage identification method from public market signals grounded in the parametric quickest change detection (QCD) theory. Parametric QCD operates on stochastic data streams, distinguishing pre- and post-change regimes using the ratio of their respective probability density functions. To derive the density functions for normal and post-outage market signals, we exploit multi-parametric programming to decompose complex market signals into parametric random variables with a known density. These densities are then used to construct a QCD-based statistic that triggers an alarm as soon as the statistic exceeds an appropriate threshold. Numerical experiments on a stylized PJM testbed demonstrate rapid line outage identification from public streams of electricity demand and price data.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u53c2\u6570\u5316\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u7406\u8bba\u7684\u505c\u7535\u8bc6\u522b\u65b9\u6cd5\uff0c\u5229\u7528\u516c\u5f00\u5e02\u573a\u4fe1\u53f7\uff08\u7535\u529b\u9700\u6c42\u548c\u4ef7\u683c\u6570\u636e\uff09\u5feb\u901f\u8bc6\u522b\u8f93\u7535\u7ebf\u8def\u505c\u7535", "motivation": "\u7535\u529b\u7cfb\u7edf\u505c\u7535\u4f1a\u7ed9\u5e02\u573a\u53c2\u4e0e\u8005\u5e26\u6765\u91cd\u5927\u8d22\u52a1\u98ce\u9669\uff0c\u9700\u8981\u53ca\u65f6\u68c0\u6d4b\u548c\u5bf9\u51b2\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u4f9d\u8d56\u79c1\u6709\u7cfb\u7edf\u6570\u636e\uff0c\u800c\u516c\u5f00\u5e02\u573a\u4fe1\u53f7\uff08\u5982\u9700\u6c42\u548c\u4ef7\u683c\uff09\u867d\u7136\u53ef\u7528\u4f46\u96be\u4ee5\u76f4\u63a5\u7528\u4e8e\u505c\u7535\u8bc6\u522b", "method": "1. \u57fa\u4e8e\u53c2\u6570\u5316\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u7406\u8bba\uff0c\u533a\u5206\u505c\u7535\u524d\u540e\u7684\u5e02\u573a\u4fe1\u53f7\u72b6\u6001\uff1b2. \u5229\u7528\u591a\u53c2\u6570\u89c4\u5212\u5c06\u590d\u6742\u5e02\u573a\u4fe1\u53f7\u5206\u89e3\u4e3a\u5177\u6709\u5df2\u77e5\u5bc6\u5ea6\u7684\u53c2\u6570\u5316\u968f\u673a\u53d8\u91cf\uff1b3. \u6784\u5efaQCD\u7edf\u8ba1\u91cf\uff0c\u5f53\u7edf\u8ba1\u91cf\u8d85\u8fc7\u9002\u5f53\u9608\u503c\u65f6\u89e6\u53d1\u8b66\u62a5", "result": "\u5728\u7b80\u5316\u7684PJM\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u516c\u5f00\u7684\u7535\u529b\u9700\u6c42\u548c\u4ef7\u683c\u6570\u636e\u6d41\u4e2d\u5feb\u901f\u8bc6\u522b\u7ebf\u8def\u505c\u7535", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ec5\u4f7f\u7528\u516c\u5f00\u5e02\u573a\u4fe1\u53f7\u6709\u6548\u8bc6\u522b\u7535\u529b\u7cfb\u7edf\u505c\u7535\uff0c\u4e3a\u5e02\u573a\u53c2\u4e0e\u8005\u63d0\u4f9b\u53ca\u65f6\u7684\u98ce\u9669\u7ba1\u7406\u5de5\u5177\uff0c\u51cf\u5c11\u5bf9\u79c1\u6709\u7cfb\u7edf\u6570\u636e\u7684\u4f9d\u8d56"}}
{"id": "2601.13317", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13317", "abs": "https://arxiv.org/abs/2601.13317", "authors": ["Samantha Sudhoff", "Pranav Perumal", "Zhaoqing Wu", "Tunazzina Islam"], "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse", "comment": null, "summary": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86Meta\u4ed8\u8d39\u5e7f\u544a\u548cBluesky\u516c\u5171\u5e16\u5b50\u7684\u6c14\u5019\u8bdd\u8bed\uff0c\u5f00\u53d1\u4e86\u53ef\u89e3\u91ca\u7684\u4e3b\u9898\u53d1\u73b0\u6846\u67b6\uff0c\u53d1\u73b0\u5e73\u53f0\u6fc0\u52b1\u7ed3\u6784\u5f71\u54cd\u4e86\u6c14\u5019\u53d9\u4e8b\u7684\u4e3b\u9898\u7ed3\u6784\u3001\u7acb\u573a\u5bf9\u9f50\u548c\u65f6\u95f4\u54cd\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5b64\u7acb\u5206\u6790\u4e0d\u540c\u5e73\u53f0\u7684\u6c14\u5019\u8bdd\u8bed\uff0c\u96be\u4ee5\u533a\u5206\u673a\u6784\u4fe1\u606f\u4e0e\u516c\u4f17\u8868\u8fbe\u3002\u9700\u8981\u6bd4\u8f83\u4ed8\u8d39\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\uff08\u6fc0\u52b1\u9488\u5bf9\u6027\u6218\u7565\u8bf4\u670d\uff09\u548c\u516c\u5171\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff08\u4e3b\u8981\u662f\u6709\u673a\u7528\u6237\u9a71\u52a8\u8bdd\u8bed\uff09\u7684\u6c14\u5019\u4f20\u64ad\u5dee\u5f02\u3002", "method": "\u5f00\u53d1\u4e86\u53ef\u89e3\u91ca\u7684\u7aef\u5230\u7aef\u4e3b\u9898\u53d1\u73b0\u548c\u5206\u914d\u6846\u67b6\uff1a\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u805a\u7c7b\u6587\u672c\uff0c\u5229\u7528LLM\u751f\u6210\u7b80\u660e\u7684\u4eba\u7c7b\u53ef\u89e3\u91ca\u4e3b\u9898\u6807\u7b7e\u3002\u57282024\u5e747\u6708\u81f32025\u5e749\u6708\u671f\u95f4\uff0c\u6bd4\u8f83Meta\u4ed8\u8d39\u5e7f\u544a\u548cBluesky\u516c\u5171\u5e16\u5b50\u4e2d\u7684\u6c14\u5019\u8bdd\u8bed\u3002\u4f7f\u7528\u4eba\u5de5\u5224\u65ad\u548cLLM\u8bc4\u4f30\u5668\u8bc4\u4f30\u4e3b\u9898\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u4e0b\u6e38\u7acb\u573a\u9884\u6d4b\u548c\u4e3b\u9898\u5f15\u5bfc\u68c0\u7d22\u4efb\u52a1\u9a8c\u8bc1\u8bed\u4e49\u8fde\u8d2f\u6027\u3002", "result": "\u53d1\u73b0\u5e73\u53f0\u5c42\u9762\u7684\u6fc0\u52b1\u7ed3\u6784\u53cd\u6620\u5728\u6c14\u5019\u53d9\u4e8b\u7684\u4e3b\u9898\u7ed3\u6784\u3001\u7acb\u573a\u5bf9\u9f50\u548c\u65f6\u95f4\u54cd\u5e94\u6027\u4e2d\u3002\u4ed8\u8d39\u6c14\u5019\u4fe1\u606f\u4e0e\u516c\u5171\u6c14\u5019\u8bdd\u8bed\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u4e3b\u9898\u6d41\u884c\u5ea6\u5728\u91cd\u5927\u653f\u6cbb\u4e8b\u4ef6\u5468\u56f4\u53d1\u751f\u53d8\u5316\u3002", "conclusion": "\u5e73\u53f0\u6fc0\u52b1\u7ed3\u6784\u663e\u8457\u5f71\u54cd\u6c14\u5019\u8bdd\u8bed\u7279\u5f81\u3002\u867d\u7136\u5b9e\u8bc1\u5206\u6790\u805a\u7126\u6c14\u5019\u4f20\u64ad\uff0c\u4f46\u63d0\u51fa\u7684\u6846\u67b6\u652f\u6301\u8de8\u5f02\u8d28\u4f20\u64ad\u73af\u5883\u7684\u6bd4\u8f83\u53d9\u4e8b\u5206\u6790\uff0c\u6709\u52a9\u4e8e\u533a\u5206\u673a\u6784\u4fe1\u606f\u4e0e\u516c\u4f17\u8868\u8fbe\u3002"}}
{"id": "2601.13576", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13576", "abs": "https://arxiv.org/abs/2601.13576", "authors": ["Shuwen Lu", "Jamol Pender", "Mark E. Lewis"], "title": "Control policies for a two-stage queueing system with parallel and single server options", "comment": null, "summary": "We study a two-stage tandem service queue attended by two servers. Each job-server pair must complete both service phases together, with the server unable to begin a new job until the current one is fully processed after two stages. Immediately after the first phase of service, the server decides whether to send the job/customer to a downstream station that allows parallel processing or to a single-service facility that offers faster or higher-quality service but handles only one job at a time. This choice determines whether the second phase commences immediately or (potentially) after waiting in a queue for the single-service facility to become available.\n  The decision-making scenario is modeled via a Markov decision process formulation, of a clearing system with holding costs at each station. We fully characterize the structural properties of an optimal control policy based on the relationship between the service rates at the downstream stations. A numerical study highlights the significance of optimal control by comparing its performance against several natural heuristic policies.", "AI": {"tldr": "\u7814\u7a76\u4e24\u9636\u6bb5\u4e32\u8054\u670d\u52a1\u961f\u5217\uff0c\u670d\u52a1\u5668\u5728\u5b8c\u6210\u7b2c\u4e00\u9636\u6bb5\u540e\u51b3\u5b9a\u5c06\u4efb\u52a1\u53d1\u9001\u5230\u5e76\u884c\u5904\u7406\u7684\u4e0b\u6e38\u7ad9\u8fd8\u662f\u5355\u670d\u52a1\u8bbe\u65bd\uff0c\u4ee5\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u4e24\u9636\u6bb5\u670d\u52a1\u7cfb\u7edf\u4e2d\u4efb\u52a1\u8def\u7531\u51b3\u7b56\u95ee\u9898\uff0c\u670d\u52a1\u5668\u5728\u7b2c\u4e00\u9636\u6bb5\u5b8c\u6210\u540e\u9700\u8981\u51b3\u5b9a\u5c06\u4efb\u52a1\u53d1\u9001\u5230\u5e76\u884c\u5904\u7406\u7684\u4e0b\u6e38\u7ad9\u8fd8\u662f\u5355\u670d\u52a1\u8bbe\u65bd\uff0c\u540e\u8005\u867d\u7136\u5904\u7406\u901f\u5ea6\u66f4\u5feb\u6216\u8d28\u91cf\u66f4\u9ad8\u4f46\u53ea\u80fd\u5904\u7406\u4e00\u4e2a\u4efb\u52a1\uff0c\u8fd9\u79cd\u51b3\u7b56\u4f1a\u5f71\u54cd\u7cfb\u7edf\u6574\u4f53\u6548\u7387\u548c\u7b49\u5f85\u65f6\u95f4\u3002", "method": "\u91c7\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u6a21\uff0c\u5efa\u7acb\u5e26\u6709\u5404\u7ad9\u70b9\u6301\u6709\u6210\u672c\u7684\u6e05\u7a7a\u7cfb\u7edf\u6a21\u578b\uff0c\u57fa\u4e8e\u4e0b\u6e38\u7ad9\u70b9\u670d\u52a1\u901f\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5b8c\u5168\u523b\u753b\u4e86\u6700\u4f18\u63a7\u5236\u7b56\u7565\u7684\u7ed3\u6784\u7279\u6027\u3002", "result": "\u901a\u8fc7\u6570\u503c\u7814\u7a76\uff0c\u5c06\u6700\u4f18\u63a7\u5236\u7b56\u7565\u4e0e\u51e0\u79cd\u81ea\u7136\u542f\u53d1\u5f0f\u7b56\u7565\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\uff0c\u7a81\u663e\u4e86\u6700\u4f18\u63a7\u5236\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e24\u9636\u6bb5\u4e32\u8054\u670d\u52a1\u961f\u5217\u4e2d\u7684\u4efb\u52a1\u8def\u7531\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u6700\u4f18\u7b56\u7565\u5206\u6790\uff0c\u5c55\u793a\u4e86\u6700\u4f18\u63a7\u5236\u5728\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u65b9\u9762\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.11969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11969", "abs": "https://arxiv.org/abs/2601.11969", "authors": ["Zecheng Tang", "Baibei Ji", "Ruoxi Sun", "Haitian Wang", "WangJie You", "Zhang Yijun", "Wenpeng Zhu", "Ji Qi", "Juntao Li", "Min Zhang"], "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models", "comment": null, "summary": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u7684\u57fa\u51c6MemoryRewardBench\uff0c\u6db5\u76d68K-128K token\u768410\u79cd\u8bb0\u5fc6\u7ba1\u7406\u573a\u666f\uff0c\u53d1\u73b0\u5f00\u6e90\u4e0e\u4e13\u6709\u6a21\u578b\u5dee\u8ddd\u7f29\u5c0f\uff0c\u65b0\u4ee3\u6a21\u578b\u666e\u904d\u4f18\u4e8e\u524d\u4ee3", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u91c7\u7528\u4ee5\u8bb0\u5fc6\u4e3a\u4e2d\u5fc3\u7684\u673a\u5236\u5904\u7406\u957f\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u7684\u8bb0\u5fc6\u7ba1\u7406\u6210\u4e3a\u5173\u952e\u80fd\u529b\u3002\u9700\u8981\u5956\u52b1\u6a21\u578b\u6765\u81ea\u52a8\u53ef\u9760\u5730\u8bc4\u4f30\u8bb0\u5fc6\u8d28\u91cf\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u5728\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u7684\u57fa\u51c6", "method": "\u6784\u5efaMemoryRewardBench\u57fa\u51c6\uff0c\u8986\u76d6\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u5305\u542b10\u79cd\u4e0d\u540c\u8bb0\u5fc6\u7ba1\u7406\u6a21\u5f0f\u7684\u8bbe\u7f6e\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece8K\u5230128K token\u3002\u572813\u4e2a\u524d\u6cbf\u5956\u52b1\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30", "result": "\u8bc4\u4f30\u663e\u793a\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\uff0c\u65b0\u4e00\u4ee3\u6a21\u578b\u65e0\u8bba\u53c2\u6570\u91cf\u591a\u5c11\u90fd\u6301\u7eed\u4f18\u4e8e\u524d\u4ee3\u6a21\u578b\u3002\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u5956\u52b1\u6a21\u578b\u5728\u8bc4\u4f30LLM\u8bb0\u5fc6\u7ba1\u7406\u65b9\u9762\u7684\u80fd\u529b\u548c\u57fa\u672c\u9650\u5236", "conclusion": "MemoryRewardBench\u4e3a\u7cfb\u7edf\u7814\u7a76\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u957f\u65f6\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u9996\u4e2a\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u53d1\u5c55\u8d8b\u52bf\u548c\u73b0\u6709\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003"}}
{"id": "2601.11942", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.11942", "abs": "https://arxiv.org/abs/2601.11942", "authors": ["Qingyu Meng", "Yangshuai Wang"], "title": "Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization", "comment": null, "summary": "Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u56de\u5f52\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u51e0\u4f55\u9884\u5904\u7406\u5668\u548c\u8bfe\u7a0b\u4f18\u5316\u534f\u8bae\uff0c\u6539\u5584\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u5e38\u9762\u4e34\u566a\u58f0\u68af\u5ea6\u4e0b\u7684\u6709\u9650\u53ef\u8bad\u7ec3\u6027\u548c\u75c5\u6001\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "1) \u8bbe\u8ba1\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u67b6\u6784\uff1a\u524d\u7f6e\u8f7b\u91cf\u7ea7\u7ecf\u5178\u5d4c\u5165\u5c42\u4f5c\u4e3a\u53ef\u5b66\u4e60\u7684\u51e0\u4f55\u9884\u5904\u7406\u5668\uff0c\u91cd\u5851\u8f93\u5165\u8868\u793a\u4ee5\u6539\u5584\u4e0b\u6e38\u53d8\u5206\u91cf\u5b50\u7535\u8def\u7684\u4f18\u5316\u6761\u4ef6\uff1b2) \u5f15\u5165\u8bfe\u7a0b\u4f18\u5316\u534f\u8bae\uff1a\u9010\u6b65\u589e\u52a0\u7535\u8def\u6df1\u5ea6\uff0c\u4eceSPSA\u968f\u673a\u63a2\u7d22\u8fc7\u6e21\u5230Adam\u68af\u5ea6\u5fae\u8c03\u3002", "result": "\u5728PDE\u56de\u5f52\u57fa\u51c6\u548c\u6807\u51c6\u56de\u5f52\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u56fa\u5b9a\u8bad\u7ec3\u9884\u7b97\u7684\u6a21\u62df\u5668\u8bbe\u7f6e\u4e2d\uff0c\u8be5\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u7eafQNN\u57fa\u7ebf\uff0c\u5728\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u6536\u655b\uff0c\u5e76\u51cf\u5c11\u4e0e\u632f\u8361\u5206\u91cf\u76f8\u5173\u7684\u7ed3\u6784\u5316\u8bef\u5dee\u3002", "conclusion": "\u51e0\u4f55\u9884\u5904\u7406\u4e0e\u8bfe\u7a0b\u8bad\u7ec3\u76f8\u7ed3\u5408\u662f\u7a33\u5b9a\u91cf\u5b50\u56de\u5f52\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u80fd\u591f\u6539\u5584\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.12318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12318", "abs": "https://arxiv.org/abs/2601.12318", "authors": ["Dehao Ying", "Fengchang Yu", "Haihua Chen", "Changjiang Jiang", "Yurong Li", "Wei Lu"], "title": "Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence", "comment": null, "summary": "The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the \"availability of data and labels.\" This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7684\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u91cd\u65b0\u5b9a\u4e49\u6570\u636e\u751f\u6210\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u5206\u4e3a\u56db\u5927\u8d44\u6e90\u4e2d\u5fc3\u8303\u5f0f\u3002", "motivation": "\u6587\u6863\u667a\u80fd\u7684\u53d1\u5c55\u9700\u8981\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u624b\u52a8\u6807\u6ce8\u662f\u4e3b\u8981\u74f6\u9888\u3002\u73b0\u6709\u8c03\u7814\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\u6216\u7279\u5b9a\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4e0e\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7edf\u4e00\u89c6\u89d2\uff0c\u9700\u8981\u5efa\u7acb\u7efc\u5408\u6280\u672f\u6846\u67b6\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u6570\u636e\u751f\u6210\u4e3a\u76d1\u7763\u4fe1\u53f7\u751f\u4ea7\uff0c\u5f15\u5165\u57fa\u4e8e\"\u6570\u636e\u548c\u6807\u7b7e\u53ef\u7528\u6027\"\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u5c06\u65b9\u6cd5\u7ec4\u7ec7\u4e3a\u56db\u5927\u8303\u5f0f\uff1a\u6570\u636e\u589e\u5f3a\u3001\u4ece\u96f6\u751f\u6210\u3001\u81ea\u52a8\u6570\u636e\u6807\u6ce8\u3001\u81ea\u76d1\u7763\u4fe1\u53f7\u6784\u5efa\uff0c\u5e76\u5efa\u7acb\u591a\u5c42\u6b21\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u6587\u6863\u667a\u80fd\u6570\u636e\u751f\u6210\u7efc\u5408\u6280\u672f\u56fe\u8c31\uff0c\u6574\u7406\u4e86\u5404\u79cdDI\u57fa\u51c6\u6d4b\u8bd5\u7684\u6027\u80fd\u63d0\u5347\uff0c\u63ed\u793a\u4e86\u4fdd\u771f\u5ea6\u5dee\u8ddd\u7b49\u5173\u952e\u6311\u6218\u548c\u534f\u540c\u8fdb\u5316\u751f\u6001\u7cfb\u7edf\u7b49\u524d\u6cbf\u65b9\u5411\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u8fd9\u4e00\u788e\u7247\u5316\u9886\u57df\uff0c\u5c06\u6570\u636e\u751f\u6210\u5b9a\u4f4d\u4e3a\u4e0b\u4e00\u4ee3\u6587\u6863\u667a\u80fd\u7684\u6838\u5fc3\u5f15\u64ce\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u548c\u65b9\u5411\u6307\u5bfc\u3002"}}
{"id": "2601.13615", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13615", "abs": "https://arxiv.org/abs/2601.13615", "authors": ["Lifu Ding", "Chunhui Hou", "Yutong Li", "Qinmin Yang"], "title": "Resilient Hierarchical Power Control for Hybrid GFL/GFM Microgrids Under Mixed Cyber-Attacks and Physical Constraints", "comment": null, "summary": "Hybrid microgrids integrating Grid-Following (GFL) and Grid-Forming (GFM) inverters present complex control challenges arising from the decoupling between long-term economic dispatch and real-time dynamic regulation, as well as the distinct physical limitations of heterogeneous inverters under cyber uncertainties. This paper proposes a Resilient Hierarchical Power Control (RHPC) strategy to unify these conflicting requirements within a cohesive framework. A standardized power increment mechanism is developed to bridge the tertiary and secondary layers, ensuring that real-time load fluctuations are compensated strictly according to the optimal economic ratios derived from the tertiary layer. To address the strict active power saturation constraints of GFL units, a dynamic activation scheme coupled with projection operators is introduced, which actively isolates saturated nodes from the consensus loop to prevent integrator wind-up and preserve the stability of the GFM backbone. Furthermore, the proposed framework incorporates a multi-scale attention mechanism and LSTM-based predictors into the secondary control protocol, endowing the system with robustness against unbounded False Data Injection (FDI) attacks and packet losses. Rigorous theoretical analysis confirms that the system achieves Uniformly Ultimately Bounded (UUB) convergence, and simulations on a modified IEEE 33-bus system demonstrate that the proposed strategy significantly improves power sharing accuracy and operational resilience in both grid-connected and islanded modes compared to conventional methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5f39\u6027\u5206\u5c42\u529f\u7387\u63a7\u5236\u7b56\u7565\uff0c\u7edf\u4e00\u6df7\u5408\u5fae\u7535\u7f51\u4e2dGFL\u548cGFM\u9006\u53d8\u5668\u7684\u7ecf\u6d4e\u8c03\u5ea6\u4e0e\u52a8\u6001\u8c03\u8282\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u529f\u7387\u589e\u91cf\u673a\u5236\u3001\u52a8\u6001\u6fc0\u6d3b\u65b9\u6848\u548c\u6297\u653b\u51fb\u673a\u5236\uff0c\u63d0\u9ad8\u529f\u7387\u5206\u914d\u7cbe\u5ea6\u548c\u8fd0\u884c\u5f39\u6027\u3002", "motivation": "\u6df7\u5408\u5fae\u7535\u7f51\u4e2dGFL\u548cGFM\u9006\u53d8\u5668\u7684\u96c6\u6210\u5e26\u6765\u4e86\u590d\u6742\u7684\u63a7\u5236\u6311\u6218\uff1a\u957f\u671f\u7ecf\u6d4e\u8c03\u5ea6\u4e0e\u5b9e\u65f6\u52a8\u6001\u8c03\u8282\u4e4b\u95f4\u7684\u89e3\u8026\u95ee\u9898\uff0c\u4ee5\u53ca\u5f02\u6784\u9006\u53d8\u5668\u5728\u7f51\u7edc\u5b89\u5168\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u7269\u7406\u9650\u5236\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u5f39\u6027\u5206\u5c42\u529f\u7387\u63a7\u5236\u7b56\u7565\uff0c\u5305\u62ec\uff1a1)\u6807\u51c6\u5316\u529f\u7387\u589e\u91cf\u673a\u5236\u8fde\u63a5\u4e09\u7ea7\u548c\u4e8c\u7ea7\u63a7\u5236\u5c42\uff1b2)\u9488\u5bf9GFL\u5355\u5143\u4e25\u683c\u6709\u529f\u529f\u7387\u9971\u548c\u7ea6\u675f\u7684\u52a8\u6001\u6fc0\u6d3b\u65b9\u6848\u548c\u6295\u5f71\u7b97\u5b50\uff1b3)\u96c6\u6210\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u548cLSTM\u9884\u6d4b\u5668\u7684\u4e8c\u7ea7\u63a7\u5236\u534f\u8bae\uff0c\u62b5\u5fa1FDI\u653b\u51fb\u548c\u6570\u636e\u5305\u4e22\u5931\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u5b9e\u7cfb\u7edf\u5b9e\u73b0\u4e00\u81f4\u6700\u7ec8\u6709\u754c\u6536\u655b\uff0c\u5728\u6539\u8fdb\u7684IEEE 33\u603b\u7ebf\u7cfb\u7edf\u4eff\u771f\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5e76\u7f51\u548c\u5b64\u5c9b\u6a21\u5f0f\u4e0b\u7684\u529f\u7387\u5206\u914d\u7cbe\u5ea6\u548c\u8fd0\u884c\u5f39\u6027\u3002", "conclusion": "RHPC\u7b56\u7565\u6210\u529f\u7edf\u4e00\u4e86\u6df7\u5408\u5fae\u7535\u7f51\u4e2d\u7684\u7ecf\u6d4e\u8c03\u5ea6\u548c\u52a8\u6001\u8c03\u8282\u9700\u6c42\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u63a7\u5236\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86GFL/GFM\u9006\u53d8\u5668\u96c6\u6210\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u5728\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\u4e0b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.13709", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13709", "abs": "https://arxiv.org/abs/2601.13709", "authors": ["Christopher Kao", "Vanshika Vats", "James Davis"], "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "comment": "For associated dataset, see https://github.com/cocochief4/llm-mafia. Published in IEEE ICA 2025, waiting for IEEEXplore proceedings", "summary": "Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.", "AI": {"tldr": "GPT-4o\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u300a\u9ed1\u624b\u515a\u300b\u4e2d\u6bd4\u4eba\u7c7b\u66f4\u64c5\u957f\u6b3a\u9a97\uff0c\u901a\u8fc7\u5f02\u6b65\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6a21\u62df\u771f\u5b9e\u793e\u4ea4\u60c5\u5883\uff0c\u68c0\u6d4b\u5668\u5bf9LLM\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4f4e\u4e8e\u4eba\u7c7b\u6e38\u620f\u3002", "motivation": "\u7814\u7a76LLM\u5728\u81ea\u7136\u8bed\u8a00\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6b3a\u9a97\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u300a\u9ed1\u624b\u515a\u300b\u4e2d\uff0c\u56e0\u4e3a\u6210\u529f\u4f9d\u8d56\u4e8e\u901a\u8fc7\u5bf9\u8bdd\u6b3a\u9a97\u4ed6\u4eba\uff0c\u800c\u4e4b\u524d\u7684\u7814\u7a76\u5bf9\u6b64\u4e86\u89e3\u6709\u9650\u3002", "method": "\u4f7f\u7528\u5f02\u6b65\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6a21\u62df35\u573a\u300a\u9ed1\u624b\u515a\u300b\u6e38\u620f\uff0c\u521b\u5efa\u57fa\u4e8eGPT-4-Turbo\u7684\"\u9ed1\u624b\u515a\u68c0\u6d4b\u5668\"\u5206\u6790\u6e38\u620f\u8bb0\u5f55\uff08\u65e0\u89d2\u8272\u4fe1\u606f\uff09\u6765\u9884\u6d4b\u9ed1\u624b\u515a\u73a9\u5bb6\uff0c\u4ee5\u9884\u6d4b\u51c6\u786e\u7387\u4f5c\u4e3a\u6b3a\u9a97\u8d28\u91cf\u7684\u66ff\u4ee3\u6307\u6807\uff0c\u5e76\u4e0e28\u573a\u4eba\u7c7b\u6e38\u620f\u548c\u968f\u673a\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u9ed1\u624b\u515a\u68c0\u6d4b\u5668\u5bf9LLM\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4f4e\u4e8e\u5bf9\u4eba\u7c7b\u6e38\u620f\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u8fd9\u4e00\u7ed3\u679c\u5728\u4e0d\u540c\u6e38\u620f\u5929\u6570\u548c\u68c0\u6d4b\u5230\u7684\u9ed1\u624b\u515a\u6570\u91cf\u4e0a\u4fdd\u6301\u4e00\u81f4\uff0c\u8868\u660eLLM\u80fd\u66f4\u597d\u5730\u878d\u5165\u7fa4\u4f53\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u8fdb\u884c\u6b3a\u9a97\u3002", "conclusion": "LLM\u5728\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6b3a\u9a97\u80fd\u529b\u6bd4\u4eba\u7c7b\u66f4\u51fa\u8272\uff0c\u8fd9\u65e2\u5c55\u793a\u4e86\u5176\u590d\u6742\u6027\uff0c\u4e5f\u51f8\u663e\u4e86\u76f8\u5173\u98ce\u9669\uff0c\u540c\u65f6\u53d1\u5e03\u4e86LLM\u300a\u9ed1\u624b\u515a\u300b\u6e38\u620f\u8bb0\u5f55\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2601.13586", "categories": ["math.OC", "eess.SY", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.13586", "abs": "https://arxiv.org/abs/2601.13586", "authors": ["Shuwen Lu", "Mark E. Lewis", "Jamol Pender"], "title": "Balancing Independent and Collaborative Service", "comment": null, "summary": "We study a two-type server queueing system where flexible Type-I servers, upon their initial interaction with jobs, decide in real time whether to process them independently or in collaboration with dedicated Type-II servers. Independent processing begins immediately, as does collaborative service if a Type-II server is available. Otherwise, the job and its paired Type-I server wait in queue for collaboration. Type-I servers are non-preemptive and cannot engage with new jobs until their current job is completed.\n  We provide a complete characterization of the structural properties of the optimal policy for the clearing system. In particular, an optimal control is shown to follow a threshold structure based on the number of jobs in the queue before a Type-I first interaction and on the number of jobs in either independent or collaborative service.\n  We propose simple threshold heuristics, based on linear approximations, for real-time decision-making. In much of the parameter and state spaces, we establish theoretical bounds that compare the thresholds proposed by our heuristics to those of optimal policies and identify parameter configurations where these bounds are attained. Outside of these regions, the optimal thresholds are infinite. Numerical experiments further demonstrate the accuracy and robustness of our heuristics, particularly when the initial queue length is high. Our proposed heuristics achieve costs within 0.5% of the optimal policy on average and significantly outperform benchmark policies that exhibit extreme sensitivity to system parameters, sometimes incurring costs exceeding 100% of the optimal.", "AI": {"tldr": "\u7814\u7a76\u53cc\u7c7b\u578b\u670d\u52a1\u5668\u6392\u961f\u7cfb\u7edf\uff0c\u7075\u6d3b\u578bI\u7c7b\u670d\u52a1\u5668\u5728\u9996\u6b21\u63a5\u89e6\u4f5c\u4e1a\u65f6\u5b9e\u65f6\u51b3\u5b9a\u72ec\u7acb\u5904\u7406\u8fd8\u662f\u4e0e\u4e13\u7528II\u7c7b\u670d\u52a1\u5668\u534f\u4f5c\u5904\u7406\u3002\u6700\u4f18\u7b56\u7565\u5177\u6709\u9608\u503c\u7ed3\u6784\uff0c\u63d0\u51fa\u57fa\u4e8e\u7ebf\u6027\u8fd1\u4f3c\u7684\u7b80\u5355\u9608\u503c\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u591a\u6570\u53c2\u6570\u548c\u72b6\u6001\u7a7a\u95f4\u4e0b\u6027\u80fd\u63a5\u8fd1\u6700\u4f18\u3002", "motivation": "\u7814\u7a76\u670d\u52a1\u5668\u8d44\u6e90\u5206\u914d\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u7075\u6d3b\u578b\u670d\u52a1\u5668\u5728\u5b9e\u65f6\u51b3\u7b56\u4e2d\u5982\u4f55\u5e73\u8861\u72ec\u7acb\u5904\u7406\u4e0e\u534f\u4f5c\u5904\u7406\u7684\u6743\u8861\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5982\u4e91\u8ba1\u7b97\u3001\u5ba2\u670d\u4e2d\u5fc3\u7b49\u573a\u666f\uff0c\u9700\u8981\u9ad8\u6548\u5206\u914d\u4e0d\u540c\u7c7b\u578b\u7684\u670d\u52a1\u5668\u8d44\u6e90\u4ee5\u6700\u5c0f\u5316\u7cfb\u7edf\u6210\u672c\u3002", "method": "1. \u5efa\u7acb\u53cc\u7c7b\u578b\u670d\u52a1\u5668\u6392\u961f\u6a21\u578b\uff1aI\u7c7b\u670d\u52a1\u5668\u7075\u6d3b\uff0cII\u7c7b\u670d\u52a1\u5668\u4e13\u7528\uff1b2. \u5206\u6790\u6e05\u7a7a\u7cfb\u7edf\u7684\u6700\u4f18\u7b56\u7565\u7ed3\u6784\u7279\u6027\uff1b3. \u63d0\u51fa\u57fa\u4e8e\u7ebf\u6027\u8fd1\u4f3c\u7684\u7b80\u5355\u9608\u503c\u542f\u53d1\u5f0f\u7b97\u6cd5\uff1b4. \u7406\u8bba\u5206\u6790\u542f\u53d1\u5f0f\u9608\u503c\u4e0e\u6700\u4f18\u9608\u503c\u7684\u754c\u9650\u5173\u7cfb\uff1b5. \u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u6027\u80fd\u3002", "result": "1. \u6700\u4f18\u63a7\u5236\u7b56\u7565\u5177\u6709\u57fa\u4e8e\u961f\u5217\u957f\u5ea6\u548c\u670d\u52a1\u72b6\u6001\u7684\u9608\u503c\u7ed3\u6784\uff1b2. \u5728\u591a\u6570\u53c2\u6570\u548c\u72b6\u6001\u7a7a\u95f4\u4e0b\uff0c\u542f\u53d1\u5f0f\u7b97\u6cd5\u9608\u503c\u4e0e\u6700\u4f18\u9608\u503c\u6709\u7406\u8bba\u754c\u9650\uff1b3. \u6570\u503c\u5b9e\u9a8c\u663e\u793a\u542f\u53d1\u5f0f\u7b97\u6cd5\u5e73\u5747\u6210\u672c\u4ec5\u6bd4\u6700\u4f18\u7b56\u7565\u9ad80.5%\uff1b4. \u7b97\u6cd5\u5728\u9ad8\u521d\u59cb\u961f\u5217\u957f\u5ea6\u65f6\u8868\u73b0\u7a33\u5065\uff1b5. \u663e\u8457\u4f18\u4e8e\u5bf9\u53c2\u6570\u654f\u611f\u4e14\u6210\u672c\u53ef\u80fd\u8d85\u8fc7\u6700\u4f18100%\u7684\u57fa\u51c6\u7b56\u7565\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5355\u9608\u503c\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u53cc\u7c7b\u578b\u670d\u52a1\u5668\u6392\u961f\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u4e14\u7a33\u5065\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u8d1f\u8f7d\u573a\u666f\uff0c\u4e3a\u5b9e\u65f6\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12019", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12019", "abs": "https://arxiv.org/abs/2601.12019", "authors": ["Chaowei Zhang", "Xiansheng Luo", "Zewei Zhang", "Yi Zhu", "Jipeng Qiang", "Longwei Wang"], "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning", "comment": null, "summary": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSORG\u6846\u67b6\uff0c\u5229\u7528LLMs\u7684\u5949\u627f\u884c\u4e3a\u751f\u6210\u5bf9\u7acb\u63a8\u7406\uff0c\u7ed3\u5408ORCD\u6a21\u578b\u8fdb\u884c\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u5185\u5bb9\u6cdb\u6ee5\u52a0\u5267\u4e86\u70b9\u51fb\u8bf1\u9975\u95ee\u9898\uff0cLLMs\u867d\u6709\u6f5c\u529b\u4f46\u53d7\u5949\u627f\u884c\u4e3a\u5f71\u54cd\uff0c\u503e\u5411\u4e8e\u5339\u914d\u7528\u6237\u4fe1\u5ff5\u800c\u975e\u771f\u5b9e\u63a8\u7406\u3002\u672c\u6587\u521b\u65b0\u6027\u5730\u5229\u7528\u800c\u975e\u6d88\u9664\u8fd9\u79cd\u5949\u627f\u884c\u4e3a\u3002", "method": "\u63d0\u51faSORG\u6846\u67b6\uff0c\u5f15\u5bfcLLMs\u751f\u6210\u5bf9\u7acb\u7acb\u573a\u7684\u540c\u610f/\u53cd\u5bf9\u63a8\u7406\u5bf9\uff1b\u5f00\u53d1ORCD\u6a21\u578b\uff0c\u4f7f\u7528\u4e09\u4e2aBERT\u7f16\u7801\u5668\u5206\u522b\u7f16\u7801\u6807\u9898\u548c\u63a8\u7406\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548cLLM\u751f\u6210\u7684\u53ef\u4fe1\u5ea6\u8f6f\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4e00\u81f4\u4f18\u4e8eLLM\u63d0\u793a\u3001\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528LLMs\u7684\u5949\u627f\u884c\u4e3a\u751f\u6210\u5bf9\u7acb\u63a8\u7406\uff0c\u7ed3\u5408\u4e13\u95e8\u7684\u68c0\u6d4b\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u5904\u7406LLMs\u7684\u504f\u5dee\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.11953", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11953", "abs": "https://arxiv.org/abs/2601.11953", "authors": ["Shiqing Gao", "Jiaxin Ding", "Luoyi Fu", "Xinbing Wang"], "title": "Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration", "comment": "Published in the 42nd International Conference on Machine Learning (ICML 2025, Oral)", "summary": "Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.", "AI": {"tldr": "\u63d0\u51faMICE\u65b9\u6cd5\u89e3\u51b3\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u6210\u672c\u51fd\u6570\u4f4e\u4f30\u95ee\u9898\uff0c\u901a\u8fc7\u5185\u5728\u6210\u672c\u4f30\u8ba1\u548c\u8bb0\u5fc6\u6a21\u5757\u51cf\u5c11\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u73b0\u6709\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u51fa\u73b0\u4e25\u91cd\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u9650\u5236\u4e86\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u4f5c\u8005\u53d1\u73b0\u6210\u672c\u4ef7\u503c\u51fd\u6570\u7684\u4f4e\u4f30\u662f\u5bfc\u81f4\u8fd9\u4e9b\u8fdd\u53cd\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u8bb0\u5fc6\u9a71\u52a8\u7684\u5185\u5728\u6210\u672c\u4f30\u8ba1\uff08MICE\uff09\u65b9\u6cd5\uff1a1\uff09\u6784\u5efa\u8bb0\u5fc6\u6a21\u5757\u5b58\u50a8\u5148\u524d\u63a2\u7d22\u7684\u4e0d\u5b89\u5168\u72b6\u6001\uff1b2\uff09\u5c06\u5185\u5728\u6210\u672c\u5b9a\u4e49\u4e3a\u5f53\u524d\u72b6\u6001\u8bbf\u95ee\u8fd9\u4e9b\u98ce\u9669\u533a\u57df\u7684\u4f2a\u8ba1\u6570\uff1b3\uff09\u63d0\u51fa\u5305\u542b\u5185\u5728\u6210\u672c\u7684\u5916\u5728-\u5185\u5728\u6210\u672c\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u504f\u5dee\u6821\u6b63\u7b56\u7565\uff1b4\uff09\u5728\u4fe1\u4efb\u533a\u57df\u5185\u5236\u5b9a\u4f18\u5316\u76ee\u6807\u3002", "result": "\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u6210\u672c\u4ef7\u503c\u51fd\u6570\u7684\u6536\u655b\u4fdd\u8bc1\u548cMICE\u66f4\u65b0\u7684\u6700\u574f\u60c5\u51b5\u7ea6\u675f\u8fdd\u53cd\u754c\u9650\u3002\u5b9e\u9a8c\u8868\u660eMICE\u663e\u8457\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u7b56\u7565\u6027\u80fd\u3002", "conclusion": "MICE\u901a\u8fc7\u89e3\u51b3\u6210\u672c\u51fd\u6570\u4f4e\u4f30\u95ee\u9898\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u63d0\u9ad8\u4e86\u7b97\u6cd5\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2601.12323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12323", "abs": "https://arxiv.org/abs/2601.12323", "authors": ["Yin Cai", "Zhouhong Gu", "Juntao Zhang", "Ping Chen"], "title": "MARO: Learning Stronger Reasoning from Social Interaction", "comment": null, "summary": "Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.", "AI": {"tldr": "MARO\u65b9\u6cd5\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u73af\u5883\u8bad\u7ec3LLMs\uff0c\u5c06\u6700\u7ec8\u6210\u8d25\u5206\u89e3\u4e3a\u5177\u4f53\u884c\u4e3a\u4fe1\u53f7\uff0c\u5e73\u8861\u89d2\u8272\u6743\u91cd\uff0c\u76f4\u63a5\u8bc4\u4f30\u884c\u4e3a\u6548\u7528\uff0c\u663e\u8457\u63d0\u5347\u793e\u4ea4\u63a8\u7406\u80fd\u529b\u5e76\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e3b\u8981\u4ece\u6587\u672c\u5185\u5bb9\u5b66\u4e60\u6216\u89e3\u51b3\u9884\u8bbe\u95ee\u9898\uff0c\u7f3a\u4e4f\u5728\u771f\u5b9e\u793e\u4ea4\u573a\u666f\u4e2d\u4e0e\u4ed6\u4eba\u4e92\u52a8\u3001\u8c08\u5224\u3001\u7ade\u4e89\u7684\u7ecf\u9a8c\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u5956\u52b1\u4f18\u5316(MARO)\uff1a1) \u5c06\u6700\u7ec8\u6210\u8d25\u7ed3\u679c\u5206\u89e3\u4e3a\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u884c\u4e3a\u4fe1\u53f7\uff1b2) \u5e73\u8861\u4e0d\u540c\u89d2\u8272\u7684\u8bad\u7ec3\u6837\u672c\u6743\u91cd\uff1b3) \u76f4\u63a5\u8bc4\u4f30\u6bcf\u4e2a\u884c\u4e3a\u7684\u6548\u7528\u503c\u3002", "result": "MARO\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u793e\u4ea4\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u901a\u8fc7\u793e\u4ea4\u6a21\u62df\u5b66\u4e60\u83b7\u5f97\u7684\u80fd\u529b\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u6570\u5b66\u63a8\u7406\u3001\u6307\u4ee4\u8ddf\u968f\u7b49\u5176\u4ed6\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u5b66\u4e60\u589e\u5f3aLLMs\u901a\u7528\u63a8\u7406\u80fd\u529b\u7684\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u793e\u4ea4\u73af\u5883\u8bad\u7ec3\u662f\u589e\u5f3aLLMs\u901a\u7528\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\uff0cMARO\u65b9\u6cd5\u901a\u8fc7\u89e3\u51b3\u7a00\u758f\u4fe1\u53f7\u3001\u89d2\u8272\u5206\u5e03\u4e0d\u5747\u548c\u73af\u5883\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u80fd\u529b\u7684\u663e\u8457\u63d0\u5347\u548c\u8de8\u4efb\u52a1\u8fc1\u79fb\u3002"}}
{"id": "2601.13753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13753", "abs": "https://arxiv.org/abs/2601.13753", "authors": ["Yiwei Zhou", "Zhongcheng Lei", "Xiaoran Dai", "Wenshan Hu", "Hong Zhou"], "title": "Research on Adaptive Inertial Control in Synchronization Systems: Based on Variational Optimization Methods and Their Applications in the Stability of Complex Networks", "comment": "36 pages, 4 figures", "summary": "Aiming at the core problem that it is difficult for a fixed inertia coefficient to balance transient disturbance suppression and long-term stability in complex network synchronization systems, an adaptive inertia control strategy based on variational optimization is proposed. Taking the Kuramoto model with inertia as the research carrier, the analytical expression of the time-varying inertia coefficient M(t) is strictly derived by the functional variational method, and a hierarchical control structure of \"benchmark inertia + disturbance feedback\" is constructed to achieve the organic unity of minimizing the vulnerability performance function H(T) and stability constraints. A multimodal decoupling control strategy based on Laplacian eigenvector projection is designed to enhance the feedback strength of the dominant mode by eigenvalue weighting, improving the control accuracy and dynamic response speed. Simulation verification is carried out in complex network systems, and the control performance of regular networks (RG), random networks (ER), small-world networks (SW), scale-free networks (SF) and spider webs (SP) under three typical disturbances of pulses, monotonic decays and oscillatory decays is systematically analyzed. The results show that the proposed strategy reduces H(T) of the five networks by 19%-25%, shortens the relaxation time by 15%-24%, and the real parts of all system eigenvalues are less than -0.25s^-1 , meeting the asymptotic stability criterion. This study provides a new theoretical framework and engineering implementation scheme for the stability control of complex network synchronization systems, which can be widely applied to fields such as power grids, communication networks, and neural networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53d8\u5206\u4f18\u5316\u7684\u81ea\u9002\u5e94\u60ef\u6027\u63a7\u5236\u7b56\u7565\uff0c\u89e3\u51b3\u590d\u6742\u7f51\u7edc\u540c\u6b65\u7cfb\u7edf\u4e2d\u56fa\u5b9a\u60ef\u6027\u7cfb\u6570\u96be\u4ee5\u5e73\u8861\u77ac\u6001\u6270\u52a8\u6291\u5236\u4e0e\u957f\u671f\u7a33\u5b9a\u6027\u7684\u6838\u5fc3\u95ee\u9898", "motivation": "\u9488\u5bf9\u590d\u6742\u7f51\u7edc\u540c\u6b65\u7cfb\u7edf\u4e2d\u56fa\u5b9a\u60ef\u6027\u7cfb\u6570\u96be\u4ee5\u5e73\u8861\u77ac\u6001\u6270\u52a8\u6291\u5236\u548c\u957f\u671f\u7a33\u5b9a\u6027\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u8282\u7684\u63a7\u5236\u7b56\u7565", "method": "\u91c7\u7528\u5e26\u60ef\u6027\u7684Kuramoto\u6a21\u578b\uff0c\u901a\u8fc7\u6cdb\u51fd\u53d8\u5206\u6cd5\u4e25\u683c\u63a8\u5bfc\u65f6\u53d8\u60ef\u6027\u7cfb\u6570M(t)\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u6784\u5efa\"\u57fa\u51c6\u60ef\u6027+\u6270\u52a8\u53cd\u9988\"\u7684\u5206\u5c42\u63a7\u5236\u7ed3\u6784\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u62c9\u666e\u62c9\u65af\u7279\u5f81\u5411\u91cf\u6295\u5f71\u7684\u591a\u6a21\u6001\u89e3\u8026\u63a7\u5236\u7b56\u7565", "result": "\u5728\u4e94\u79cd\u590d\u6742\u7f51\u7edc\uff08RG\u3001ER\u3001SW\u3001SF\u3001SP\uff09\u548c\u4e09\u79cd\u5178\u578b\u6270\u52a8\uff08\u8109\u51b2\u3001\u5355\u8c03\u8870\u51cf\u3001\u632f\u8361\u8870\u51cf\uff09\u4e0b\u9a8c\u8bc1\uff0cH(T)\u964d\u4f4e19%-25%\uff0c\u677e\u5f1b\u65f6\u95f4\u7f29\u77ed15%-24%\uff0c\u6240\u6709\u7cfb\u7edf\u7279\u5f81\u503c\u5b9e\u90e8\u5c0f\u4e8e-0.25s^-1\uff0c\u6ee1\u8db3\u6e10\u8fd1\u7a33\u5b9a\u6027\u51c6\u5219", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u590d\u6742\u7f51\u7edc\u540c\u6b65\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5de5\u7a0b\u5b9e\u73b0\u65b9\u6848\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7535\u7f51\u3001\u901a\u4fe1\u7f51\u7edc\u3001\u795e\u7ecf\u7f51\u7edc\u7b49\u9886\u57df"}}
{"id": "2601.13749", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13749", "abs": "https://arxiv.org/abs/2601.13749", "authors": ["Benaya Trabelsi", "Jonathan Shaki", "Sarit Kraus"], "title": "Pro-AI Bias in Large Language Models", "comment": "13 pages, 6 figures. Code available at: https://github.com/benayat/Pro-AI-bias-in-LLMs", "summary": "Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.", "AI": {"tldr": "LLMs\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5411\u4eba\u5de5\u667a\u80fd\u7684\u504f\u597d\u504f\u89c1\uff0c\u5728\u5efa\u8bae\u63a8\u8350\u3001\u85aa\u8d44\u8bc4\u4f30\u548c\u5185\u90e8\u8868\u5f81\u4e2d\u5747\u8868\u73b0\u51fa\u5bf9AI\u7684\u8fc7\u5ea6\u504f\u597d", "motivation": "\u968f\u7740LLMs\u5728\u591a\u4e2a\u9886\u57df\u88ab\u7528\u4e8e\u51b3\u7b56\u652f\u6301\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u5b58\u5728\u5bf9\u4eba\u5de5\u667a\u80fd\u672c\u8eab\u7684\u7cfb\u7edf\u6027\u504f\u597d\u504f\u89c1\uff0c\u8fd9\u53ef\u80fd\u5f71\u54cd\u9ad8\u98ce\u9669\u51b3\u7b56", "method": "\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u5b9e\u9a8c\uff1a1)\u5206\u6790LLMs\u5bf9\u5efa\u8bae\u5bfb\u6c42\u67e5\u8be2\u7684AI\u76f8\u5173\u9009\u9879\u63a8\u8350\u503e\u5411\uff1b2)\u6bd4\u8f83AI\u76f8\u5173\u804c\u4f4d\u4e0e\u975eAI\u804c\u4f4d\u7684\u85aa\u8d44\u8bc4\u4f30\u504f\u5dee\uff1b3)\u63a2\u7a76\u5f00\u6e90\u6a21\u578b\u7684\u5185\u90e8\u8868\u5f81\u4e2d\"\u4eba\u5de5\u667a\u80fd\"\u6982\u5ff5\u7684\u76f8\u4f3c\u6027", "result": "\u53d1\u73b0\u4e00\u81f4\u7684pro-AI\u504f\u89c1\uff1a\u4e13\u6709\u6a21\u578b\u51e0\u4e4e\u786e\u5b9a\u6027\u5730\u63a8\u8350AI\u9009\u9879\uff1b\u4e13\u6709\u6a21\u578b\u5bf9AI\u85aa\u8d44\u9ad8\u4f3010\u4e2a\u767e\u5206\u70b9\uff1b\"\u4eba\u5de5\u667a\u80fd\"\u5728\u6b63\u8d1f\u4e2d\u6027\u6846\u67b6\u4e0b\u5747\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u8868\u5f81\u4e2d\u5fc3\u6027", "conclusion": "LLMs\u751f\u6210\u7684\u5efa\u8bae\u548c\u4f30\u503c\u53ef\u80fd\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7cfb\u7edf\u6027\u626d\u66f2\u9009\u62e9\u548c\u8ba4\u77e5\uff0c\u9700\u8981\u5173\u6ce8\u8fd9\u79cd\u504f\u89c1\u5bf9\u51b3\u7b56\u652f\u6301\u7684\u5f71\u54cd"}}
{"id": "2601.13688", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13688", "abs": "https://arxiv.org/abs/2601.13688", "authors": ["Xun Feng", "Chao Zhai"], "title": "Distributed Coverage Control on Poriferous Surface via Poly-Annulus Conformal Mapping", "comment": null, "summary": "The inherent non-convexity of poriferous surfaces typically entraps agents in local minima and complicates workload distribution. To resolve this, we propose a distributed diffeomorphic coverage control framework for the multi-agent system (MAS) in such surfaces. First, we establish a distributed poly-annulus conformal mapping that transforms arbitrary poriferous surfaces into a multi-hole disk. Leveraging this topological equivalence, a collision-free sectorial partition mechanism is designed in the multi-hole disk, which rigorously induces strictly connected subregions and workload balance on the poriferous surfaces. This mechanism utilizes a buffer-based sequence mechanism to ensure strict topological safety when bypassing obstacles. Furthermore, a pull-back Riemannian metric is constructed to define the length metric that encodes safety constraints. Based on this metric, a distributed gradient-based control law is synthesized to drive agents toward optimal configurations, ensuring simultaneous obstacle avoidance and coverage optimization. Theoretical analyses guarantee the Input-to-State Stability (ISS) of the partition dynamics and the asymptotic convergence of the closed-loop system. Numerical simulations confirm the reachability and robustness of the proposed coverage algorithm, offering a scalable solution for distributed coverage in poriferous surfaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u5b54\u8868\u9762\u7684\u5206\u5e03\u5f0f\u5fae\u5206\u540c\u80da\u8986\u76d6\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u5f62\u6620\u5c04\u5c06\u591a\u5b54\u8868\u9762\u8f6c\u6362\u4e3a\u591a\u5b54\u5706\u76d8\uff0c\u8bbe\u8ba1\u65e0\u78b0\u649e\u6247\u5f62\u5206\u533a\u673a\u5236\uff0c\u5e76\u57fa\u4e8e\u9ece\u66fc\u5ea6\u91cf\u5b9e\u73b0\u5206\u5e03\u5f0f\u68af\u5ea6\u63a7\u5236\uff0c\u786e\u4fdd\u969c\u788d\u7269\u907f\u8ba9\u548c\u8986\u76d6\u4f18\u5316\u3002", "motivation": "\u591a\u5b54\u8868\u9762\u7684\u56fa\u6709\u975e\u51f8\u6027\u901a\u5e38\u4f1a\u4f7f\u667a\u80fd\u4f53\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\uff0c\u5e76\u4f7f\u5de5\u4f5c\u91cf\u5206\u914d\u590d\u6742\u5316\u3002\u9700\u8981\u89e3\u51b3\u5728\u591a\u5b54\u8868\u9762\u4e0a\u8fdb\u884c\u5206\u5e03\u5f0f\u8986\u76d6\u63a7\u5236\u65f6\u9762\u4e34\u7684\u62d3\u6251\u7ea6\u675f\u548c\u969c\u788d\u7269\u907f\u8ba9\u95ee\u9898\u3002", "method": "1) \u5efa\u7acb\u5206\u5e03\u5f0f\u591a\u73af\u4fdd\u5f62\u6620\u5c04\uff0c\u5c06\u4efb\u610f\u591a\u5b54\u8868\u9762\u8f6c\u6362\u4e3a\u591a\u5b54\u5706\u76d8\uff1b2) \u5728\u591a\u5b54\u5706\u76d8\u4e2d\u8bbe\u8ba1\u65e0\u78b0\u649e\u6247\u5f62\u5206\u533a\u673a\u5236\uff0c\u786e\u4fdd\u4e25\u683c\u8fde\u901a\u5b50\u533a\u57df\u548c\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\uff1b3) \u6784\u5efa\u62c9\u56de\u9ece\u66fc\u5ea6\u91cf\u6765\u7f16\u7801\u5b89\u5168\u7ea6\u675f\uff1b4) \u57fa\u4e8e\u8be5\u5ea6\u91cf\u5408\u6210\u5206\u5e03\u5f0f\u68af\u5ea6\u63a7\u5236\u5f8b\uff0c\u9a71\u52a8\u667a\u80fd\u4f53\u8fbe\u5230\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u7406\u8bba\u5206\u6790\u4fdd\u8bc1\u4e86\u5206\u533a\u52a8\u6001\u7684\u8f93\u5165\u5230\u72b6\u6001\u7a33\u5b9a\u6027(ISS)\u548c\u95ed\u73af\u7cfb\u7edf\u7684\u6e10\u8fd1\u6536\u655b\u6027\u3002\u6570\u503c\u6a21\u62df\u8bc1\u5b9e\u4e86\u6240\u63d0\u8986\u76d6\u7b97\u6cd5\u7684\u53ef\u8fbe\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u591a\u5b54\u8868\u9762\u7684\u5206\u5e03\u5f0f\u8986\u76d6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u591a\u5b54\u8868\u9762\u4e0a\u7684\u5206\u5e03\u5f0f\u8986\u76d6\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u62d3\u6251\u53d8\u6362\u3001\u5b89\u5168\u5206\u533a\u548c\u9ece\u66fc\u5ea6\u91cf\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u969c\u788d\u7269\u907f\u8ba9\u3001\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u548c\u8986\u76d6\u4f18\u5316\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12033", "abs": "https://arxiv.org/abs/2601.12033", "authors": ["Muhammad Alif Al Hakim", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection", "comment": null, "summary": "Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.", "AI": {"tldr": "\u91cf\u5316\u4f1a\u964d\u4f4eLLM\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff0c\u52a8\u6001\u91cf\u5316\u6bd4\u9759\u6001\u91cf\u5316\u66f4\u7a33\u5b9a\uff0c\u975e\u82f1\u8bed\u73af\u5883\u4e0b\u5b89\u5168\u6027\u4e0b\u964d\u66f4\u660e\u663e\u3002\u4f5c\u8005\u63d0\u51faCritical Weight Protection\u65b9\u6cd5\u6765\u4fdd\u62a4\u5173\u952e\u6743\u91cd\uff0c\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u91cf\u5316\u88ab\u5e7f\u6cdb\u7528\u4e8e\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5176\u5bf9\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u91cf\u5316\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5f71\u54cd\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u9759\u6001\u548c\u52a8\u6001\u91cf\u5316\u65b9\u6cd5\u5bf9\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u82f1\u8bed\u3001\u6cd5\u8bed\u3001\u8377\u5170\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u571f\u8033\u5176\u8bed\uff08\u516c\u5e73\u6027\uff09\u4ee5\u53ca\u82f1\u8bed\u3001\u97e9\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\uff08\u5b89\u5168\u6027\uff09\u3002\u63d0\u51faCritical Weight Protection\u6280\u672f\uff0c\u8bc6\u522b\u548c\u4fdd\u62a4\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u5173\u952e\u6743\u91cd\u3002", "result": "\u91cf\u5316\u4e00\u81f4\u6027\u5730\u964d\u4f4e\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff1b\u52a8\u6001\u65b9\u6cd5\u6bd4\u9759\u6001\u65b9\u6cd5\u66f4\u7a33\u5b9a\uff1b\u516c\u5e73\u6027\u9000\u5316\u56e0\u8bed\u8a00\u800c\u5f02\uff1b\u5b89\u5168\u6027\u9000\u5316\u5728\u975e\u82f1\u8bed\u73af\u5883\u4e2d\u5c24\u4e3a\u660e\u663e\uff1bCritical Weight Protection\u80fd\u6709\u6548\u7f13\u89e3\u504f\u89c1\u548c\u5b89\u5168\u6027\u9000\u5316\u3002", "conclusion": "\u91cf\u5316\u5bf9LLM\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u3002\u63d0\u51fa\u7684Critical Weight Protection\u65b9\u6cd5\u80fd\u5728\u4e0d\u8fdb\u884c\u6602\u8d35\u91cd\u65b0\u8bad\u7ec3\u6216\u5bf9\u9f50\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u51cf\u8f7b\u8fd9\u4e9b\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u7ef4\u62a4\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.11954", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11954", "abs": "https://arxiv.org/abs/2601.11954", "authors": ["Yufei Peng", "Cheng Yang", "Zhengjie Fan", "Chuan Shi"], "title": "Data-centric Prompt Tuning for Dynamic Graphs", "comment": "CIKM 2025", "summary": "Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.", "AI": {"tldr": "DDGPrompt\uff1a\u4e00\u79cd\u9762\u5411\u52a8\u6001\u56fe\u7684\u6570\u636e\u4e2d\u5fc3\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u9884\u8bad\u7ec3\u8282\u70b9\u5d4c\u5165\u6765\u9002\u5e94\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\uff0c\u5728\u5c11\u6837\u672c\u548c\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u56fe\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u52a8\u6001\u94fe\u63a5\u9884\u6d4b\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u5c06\u8282\u70b9\u65f6\u5e8f\u5d4c\u5165\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u4e0b\u6e38\u4efb\u52a1\u5dee\u5f02\u5927\uff0c\u5c24\u5176\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u63d0\u793a\u65b9\u6cd5\u901a\u5e38\u4e0e\u7279\u5b9a\u6a21\u578b\u67b6\u6784\u6216\u9884\u8bad\u7ec3\u4efb\u52a1\u5f3a\u8026\u5408\uff0c\u4e14\u53ea\u5173\u6ce8\u8282\u70b9\u6216\u65f6\u5e8f\u7279\u5f81\u800c\u5ffd\u7565\u7a7a\u95f4\u7ed3\u6784\u4fe1\u606f\uff0c\u5bfc\u81f4\u8868\u8fbe\u80fd\u529b\u6709\u9650\u548c\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faDDGPrompt\u6846\u67b6\uff1a1) \u5b9a\u4e49\u7edf\u4e00\u7684\u8282\u70b9\u8868\u8fbe\u7279\u5f81\u77e9\u9635\uff0c\u805a\u5408\u6bcf\u4e2a\u8282\u70b9\u7684\u6240\u6709\u76f8\u5173\u65f6\u5e8f\u548c\u7ed3\u6784\u4fe1\u606f\uff1b2) \u5f15\u5165\u4e09\u4e2a\u63d0\u793a\u77e9\u9635\uff08\u65f6\u5e8f\u504f\u7f6e\u3001\u8fb9\u6743\u91cd\u548c\u7279\u5f81\u63a9\u7801\uff09\u6765\u5b8c\u5168\u8c03\u6574\u7279\u5f81\u77e9\u9635\uff0c\u5b9e\u73b0\u8282\u70b9\u5d4c\u5165\u7684\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u52a8\u6001\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u4e25\u683c\u7684\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6807\u7b7e\u6709\u9650\u548c\u51b7\u542f\u52a8\u6761\u4ef6\u4e0b\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "DDGPrompt\u662f\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u4e2d\u5fc3\u63d0\u793a\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u8c03\u6574\u9884\u8bad\u7ec3\u8282\u70b9\u5d4c\u5165\u6765\u9002\u5e94\u591a\u6837\u4e0b\u6e38\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u578b\u517c\u5bb9\u6027\u548c\u7ed3\u6784\u4fe1\u606f\u5229\u7528\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12338", "abs": "https://arxiv.org/abs/2601.12338", "authors": ["Kartikey Singh Bhandari", "Manav Ganesh", "Yashwant Viswanathan", "Archit Agrawal", "Dhruv Kumar", "Pratik Narang"], "title": "Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations", "comment": null, "summary": "Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff0c\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u5efa\u8bae\uff1a\u5148\u63d0\u53d6\u95ee\u9898\u5e76\u5206\u7c7b\uff0c\u518d\u57fa\u4e8e\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u5efa\u8bae\uff0c\u4f7f\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\u5b9e\u73b0\u4e13\u4e1a\u5316", "motivation": "\u5ba2\u6237\u8bc4\u8bba\u5305\u542b\u4e30\u5bcc\u7684\u670d\u52a1\u5931\u8d25\u548c\u7528\u6237\u671f\u671b\u4fe1\u53f7\uff0c\u4f46\u5c06\u8fd9\u4e9b\u975e\u7ed3\u6784\u5316\u53cd\u9988\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u5546\u4e1a\u51b3\u7b56\u4ecd\u7136\u56f0\u96be\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u5c06\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u5efa\u8bae", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u4e24\u9636\u6bb5LLM\u6846\u67b6\uff1a\u95ee\u9898\u6a21\u578b\u63d0\u53d6\u5173\u952e\u95ee\u9898\u5e76\u5206\u914d\u7c97\u7c92\u5ea6\u4e3b\u9898\uff1b\u5efa\u8bae\u6a21\u578b\u57fa\u4e8e\u63d0\u53d6\u7684\u95ee\u9898\u8868\u793a\u751f\u6210\u9488\u5bf9\u6027\u64cd\u4f5c\u5efa\u8bae\uff1b\u91c7\u7528LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u8bad\u7ec3\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u5728\u63a8\u7406\u65f6\u8fdb\u884ctoken\u7ea7\u4e13\u5bb6\u6df7\u5408", "result": "\u5728\u822a\u7a7a\u548c\u9910\u5385\u4e24\u4e2a\u9886\u57df\u7684Yelp\u8bc4\u8bba\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u516b\u4e2a\u64cd\u4f5c\u7ef4\u5ea6\uff08\u53ef\u64cd\u4f5c\u6027\u3001\u7279\u5f02\u6027\u3001\u53ef\u884c\u6027\u3001\u9884\u671f\u5f71\u54cd\u3001\u65b0\u9896\u6027\u3001\u975e\u5197\u4f59\u6027\u3001\u504f\u89c1\u3001\u6e05\u6670\u5ea6\uff09\u4e0a\u4e00\u81f4\u4f18\u4e8e\u4ec5\u63d0\u793a\u548c\u5355\u9002\u914d\u5668\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u53ef\u64cd\u4f5c\u6027\u548c\u7279\u5f02\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6548\u7387-\u8d28\u91cf\u6743\u8861", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5LLM\u6846\u67b6\u7ed3\u5408LoRA\u4e13\u5bb6\u6df7\u5408\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5c06\u5ba2\u6237\u8bc4\u8bba\u8f6c\u5316\u4e3a\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u8bc4\u8bba\u5230\u884c\u52a8\u7684\u8f6c\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2601.13799", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13799", "abs": "https://arxiv.org/abs/2601.13799", "authors": ["Luigi Romano", "Ole Morten Aamo", "Jan \u00c5slund", "Erik Frisk"], "title": "Linear viscoelastic rheological FrBD models", "comment": "6 pages, 3 figures. Under review at IEEE LCSS", "summary": "In [1], a new modeling paradigm for developing rate-and-state-dependent, control-oriented friction models was introduced. The framework, termed Friction with Bristle Dynamics (FrBD), combines nonlinear analytical expressions for the friction coefficient with constitutive equations for bristle-like elements. Within the FrBD framework, this letter introduces two novel formulations based on the two most general linear viscoelastic models for solids: the Generalized Maxwell (GM) and Generalized Kelvin-Voigt (GKV) elements. Both are analyzed in terms of boundedness and passivity, revealing that these properties are satisfied for any physically meaningful parametrization. An application of passivity for control design is also illustrated, considering an example from robotics. The findings of this letter systematically integrate rate-and-state dynamic friction models with linear viscoelasticity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49Maxwell\u548c\u5e7f\u4e49Kelvin-Voigt\u7ebf\u6027\u7c98\u5f39\u6027\u6a21\u578b\u7684\u4e24\u79cd\u65b0\u578b\u6469\u64e6\u5efa\u6a21\u6846\u67b6\uff0c\u786e\u4fdd\u6709\u754c\u6027\u548c\u65e0\u6e90\u6027\uff0c\u5e76\u5c55\u793a\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5c06\u901f\u7387\u548c\u72b6\u6001\u4f9d\u8d56\u7684\u6469\u64e6\u6a21\u578b\u4e0e\u7ebf\u6027\u7c98\u5f39\u6027\u7406\u8bba\u7cfb\u7edf\u6574\u5408\uff0c\u4e3a\u63a7\u5236\u5bfc\u5411\u7684\u6469\u64e6\u5efa\u6a21\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5728FrBD\u6846\u67b6\u4e0b\uff0c\u57fa\u4e8e\u5e7f\u4e49Maxwell\u548c\u5e7f\u4e49Kelvin-Voigt\u4e24\u79cd\u6700\u901a\u7528\u7684\u7ebf\u6027\u7c98\u5f39\u6027\u56fa\u4f53\u6a21\u578b\uff0c\u63d0\u51fa\u4e24\u79cd\u65b0\u578b\u6469\u64e6\u6a21\u578b\u516c\u5f0f\uff0c\u5e76\u8fdb\u884c\u6709\u754c\u6027\u548c\u65e0\u6e90\u6027\u5206\u6790\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u4efb\u4f55\u7269\u7406\u6709\u610f\u4e49\u7684\u53c2\u6570\u5316\u4e0b\u90fd\u6ee1\u8db3\u6709\u754c\u6027\u548c\u65e0\u6e90\u6027\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u4eba\u63a7\u5236\u5b9e\u4f8b\u5c55\u793a\u4e86\u65e0\u6e90\u6027\u5728\u63a7\u5236\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u6210\u529f\u5c06\u901f\u7387\u548c\u72b6\u6001\u52a8\u6001\u6469\u64e6\u6a21\u578b\u4e0e\u7ebf\u6027\u7c98\u5f39\u6027\u7406\u8bba\u7cfb\u7edf\u6574\u5408\uff0c\u4e3a\u63a7\u5236\u5bfc\u5411\u7684\u6469\u64e6\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2601.13846", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13846", "abs": "https://arxiv.org/abs/2601.13846", "authors": ["Glinskaya Maria"], "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments", "comment": null, "summary": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVirtual Urbanism (VU)\u6846\u67b6\uff0c\u901a\u8fc7AI\u751f\u6210\u5408\u6210\u57ce\u5e02\u526f\u672c\uff0c\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u8ba4\u540c\uff0c\u5e76\u5728\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u8fdb\u884c\u8bd5\u70b9\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u53ef\u8ba1\u7b97\u7684\u57ce\u5e02\u8eab\u4efd\u8ba4\u540c\u5ea6\u91cf\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u91cf\u5316\u57ce\u5e02\u6838\u5fc3\u7279\u5f81\u7684\u5206\u6790\u6846\u67b6\uff0c\u4ee5\u652f\u6301AI\u589e\u5f3a\u7684\u57ce\u5e02\u5206\u6790\u3002", "method": "\u4f7f\u7528Stable Diffusion\u548cLoRA\u6a21\u578b\u751f\u6210\u4e1c\u4eac\u4e5d\u4e2a\u533a\u57df\u7684\u5408\u6210\u57ce\u5e02\u5e8f\u5217\uff0c\u6392\u9664\u73b0\u6709\u65b9\u5411\u6807\u8bb0\u4ee5\u63d0\u53d6\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u5b9e\u9a8c\u9a8c\u8bc1\u611f\u77e5\u5408\u6cd5\u6027\u3001\u91cf\u5316\u533a\u57df\u7ea7\u8eab\u4efd\u3001\u63a8\u5bfc\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "result": "\u5408\u6210\u526f\u672c\u7684\u5e73\u5747\u8bc6\u522b\u51c6\u786e\u7387\u7ea681%\uff0c\u9a8c\u8bc1\u4e86\u526f\u672c\u7684\u6709\u6548\u6027\uff1bUrban Identity Level (UIL)\u6307\u6807\u80fd\u591f\u8bc4\u4f30\u4e0d\u540c\u533a\u57df\u7684\u8eab\u4efd\u6c34\u5e73\uff1b\u8bed\u4e49\u5206\u6790\u63ed\u793a\u4e86\u6587\u5316\u5d4c\u5165\u7684\u7c7b\u578b\u5b66\u4f5c\u4e3a\u6838\u5fc3\u8eab\u4efd\u5f62\u6210\u5143\u7d20\u3002", "conclusion": "VU\u662fAI\u589e\u5f3a\u57ce\u5e02\u5206\u6790\u7684\u53ef\u884c\u6846\u67b6\uff0c\u4e3a\u81ea\u52a8\u5316\u3001\u591a\u53c2\u6570\u8eab\u4efd\u5ea6\u91cf\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u5408\u6210\u57ce\u5e02\u526f\u672c\u91cf\u5316\u57ce\u5e02\u8eab\u4efd\u8ba4\u540c\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13756", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13756", "abs": "https://arxiv.org/abs/2601.13756", "authors": ["Adam Kaminer", "Thomas Kriecherbauer", "Lars Gr\u00fcne", "Michael Margaliot"], "title": "A turnpike property in an eigenvalue optimization problem", "comment": null, "summary": "We consider a constrained eigenvalue optimization problem that arises in an important nonlinear dynamical model for mRNA translation in the cell. We prove that the ordered list of optimal parameters admits a turnpike property, namely, it includes three parts with the first and third part relatively short, and the values in the middle part are all approximately equal. Turnpike properties have attracted considerable attention in econometrics and optimal control theory, but to the best of our knowledge this is the first rigorous proof of such a structure in an eigenvalue optimization problem.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86mRNA\u7ffb\u8bd1\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6a21\u578b\u4e2d\u7ea6\u675f\u7279\u5f81\u503c\u4f18\u5316\u95ee\u9898\u7684\u6700\u4f18\u53c2\u6570\u5e8f\u5217\u5177\u6709\"\u6536\u8d39\u7ad9\"\u7ed3\u6784\uff1a\u9996\u5c3e\u90e8\u5206\u8f83\u77ed\uff0c\u4e2d\u95f4\u90e8\u5206\u53c2\u6570\u503c\u8fd1\u4f3c\u76f8\u7b49\u3002", "motivation": "\u7814\u7a76\u7ec6\u80de\u4e2dmRNA\u7ffb\u8bd1\u7684\u91cd\u8981\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6a21\u578b\u4e2d\u7684\u7ea6\u675f\u7279\u5f81\u503c\u4f18\u5316\u95ee\u9898\u3002\u6536\u8d39\u7ad9\u6027\u8d28\u5728\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u548c\u6700\u4f18\u63a7\u5236\u7406\u8bba\u4e2d\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u8fd9\u662f\u9996\u6b21\u5728\u7279\u5f81\u503c\u4f18\u5316\u95ee\u9898\u4e2d\u7ed9\u51fa\u6b64\u7c7b\u7ed3\u6784\u7684\u4e25\u683c\u8bc1\u660e\u3002", "method": "\u91c7\u7528\u6570\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u7ea6\u675f\u7279\u5f81\u503c\u4f18\u5316\u95ee\u9898\u7684\u6700\u4f18\u53c2\u6570\u5e8f\u5217\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5176\u5177\u6709\u6536\u8d39\u7ad9\u7ed3\u6784\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u4f18\u53c2\u6570\u5e8f\u5217\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a\u9996\u5c3e\u90e8\u5206\u76f8\u5bf9\u8f83\u77ed\uff0c\u4e2d\u95f4\u90e8\u5206\u7684\u6240\u6709\u53c2\u6570\u503c\u8fd1\u4f3c\u76f8\u7b49\uff0c\u5f62\u6210\u4e86\u5178\u578b\u7684\u6536\u8d39\u7ad9\u7ed3\u6784\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5728\u7279\u5f81\u503c\u4f18\u5316\u95ee\u9898\u4e2d\u4e25\u683c\u8bc1\u660e\u6536\u8d39\u7ad9\u7ed3\u6784\u7684\u5b58\u5728\uff0c\u4e3amRNA\u7ffb\u8bd1\u52a8\u529b\u5b66\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u5206\u6790\u5de5\u5177\uff0c\u5e76\u6269\u5c55\u4e86\u6536\u8d39\u7ad9\u7406\u8bba\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2601.12034", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12034", "abs": "https://arxiv.org/abs/2601.12034", "authors": ["Ziyi Zhao", "Chongming Gao", "Yang Zhang", "Haoyan Liu", "Weinan Gan", "Huifeng Guo", "Yong Liu", "Fuli Feng"], "title": "Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs", "comment": "Accepted to AAAI 2026 (Oral). 9 pages, 5 figures", "summary": "Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.", "AI": {"tldr": "PUMA\u6846\u67b6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u5b9e\u73b0\u4e2a\u6027\u5316\u63d0\u793a\u5728\u4e0d\u540cLLM\u95f4\u7684\u8fc1\u79fb\uff0c\u51cf\u5c1198%\u8ba1\u7b97\u6210\u672c\uff0c\u6027\u80fd\u63a5\u8fd1\u6216\u4f18\u4e8e\u5b8c\u5168\u91cd\u8bad\u7ec3", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8f6f\u63d0\u793a\u7684LLM\u4e2a\u6027\u5316\u65b9\u6cd5\u5728\u57fa\u7840\u6a21\u578b\u5347\u7ea7\u65f6\u9700\u8981\u5b8c\u5168\u91cd\u8bad\u7ec3\uff0c\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9ad8\u6548\u8fc1\u79fb\u4e2a\u6027\u5316\u63d0\u793a\u5230\u4e0d\u517c\u5bb9\u6a21\u578b\u7684\u65b9\u6cd5", "method": "\u63d0\u51faPrompt-level User Migration Adapter (PUMA)\uff1a1) \u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u7684\u9002\u914d\u5668\u6865\u63a5\u8bed\u4e49\u5dee\u8ddd\uff1b2) \u91c7\u7528\u57fa\u4e8e\u7ec4\u7684\u7528\u6237\u9009\u62e9\u7b56\u7565\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0cPUMA\u6027\u80fd\u5339\u914d\u751a\u81f3\u4f18\u4e8e\u5b8c\u5168\u91cd\u8bad\u7ec3\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe98%\u3002\u6846\u67b6\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0a\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u5728\u94fe\u5f0f\u548c\u805a\u5408\u8fc1\u79fb\u7b49\u9ad8\u7ea7\u573a\u666f\u4e2d\u8868\u73b0\u7a33\u5065", "conclusion": "PUMA\u901a\u8fc7\u5c06\u7528\u6237\u8d44\u4ea7\u4e0e\u5e95\u5c42\u6a21\u578b\u89e3\u8026\uff0c\u4e3a\u4e2a\u6027\u5316AI\u7684\u53ef\u6301\u7eed\u6f14\u8fdb\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u5347\u7ea7\u65f6\u4e2a\u6027\u5316\u63d0\u793a\u8fc1\u79fb\u7684\u96be\u9898"}}
{"id": "2601.11960", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11960", "abs": "https://arxiv.org/abs/2601.11960", "authors": ["Jingchu Wang", "Bingbing Xu", "Yige Yuan", "Bin Xie", "Xiaoqian Sun", "Huawei Shen"], "title": "R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning", "comment": null, "summary": "Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.", "AI": {"tldr": "R\u00b2PO\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u6b8b\u5deerollout\u5934\uff0c\u5c06\u8bad\u7ec3\u8f68\u8ff9\u4e0e\u63a8\u7406\u54cd\u5e94\u89e3\u8026\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u7b56\u7565\u540c\u65f6\u4ea7\u751f\u63a8\u7406\u54cd\u5e94\u548c\u8bad\u7ec3\u4f18\u5316\u8f68\u8ff9\uff0c\u5bfc\u81f4\u751f\u6210\u7a33\u5b9a\u63a8\u7406\u54cd\u5e94\u4e0e\u591a\u6837\u5316\u8bad\u7ec3\u8f68\u8ff9\u4e4b\u95f4\u7684\u76ee\u6807\u51b2\u7a81\uff0c\u9020\u6210\u63a2\u7d22\u4e0d\u8db3\uff0c\u635f\u5bb3\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51faR\u00b2PO\uff08Residual Rollout Policy Optimization\uff09\uff0c\u5728\u7b56\u7565\u4e4b\u4e0a\u5f15\u5165\u8f7b\u91cf\u7ea7\u6b8b\u5deerollout\u5934\uff0c\u5c06\u8bad\u7ec3\u8f68\u8ff9\u4e0e\u63a8\u7406\u54cd\u5e94\u89e3\u8026\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u5b9e\u73b0\u53ef\u63a7\u7684\u8f68\u8ff9\u591a\u6837\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u751f\u6210\u7684\u7a33\u5b9a\u6027", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728MATH-500\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53473.1%\uff0c\u5728APPS\u4e0a\u63d0\u53472.4%\uff0c\u540c\u65f6\u51cf\u5c11\u683c\u5f0f\u9519\u8bef\u5e76\u7f13\u89e3\u957f\u5ea6\u504f\u5dee\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u4f18\u5316", "conclusion": "R\u00b2PO\u901a\u8fc7\u89e3\u8026\u8bad\u7ec3\u8f68\u8ff9\u548c\u63a8\u7406\u54cd\u5e94\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.12392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12392", "abs": "https://arxiv.org/abs/2601.12392", "authors": ["Zhentao Xia", "Yongqi Fan", "Yuxiang Chu", "Yichao Yin", "Liangliang Chen", "Tong Ruan", "Weiyan Zhang"], "title": "Psych\u0113Chat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose Psych\u0113Chat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that Psych\u0113Chat outperforms existing methods for emotional insight and safety control.", "AI": {"tldr": "Psych\u0113Chat\u662f\u4e00\u4e2a\u7528\u4e8e\u5fc3\u7406\u54a8\u8be2\u7684LLM\u7cfb\u7edf\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u7528\u6237\u60c5\u7eea\u53d8\u5316\u548c\u5b89\u5168\u98ce\u9669\u5206\u6790\u6765\u63d0\u5347\u54a8\u8be2\u6548\u679c\uff0c\u63d0\u4f9b\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u548c\u7edf\u4e00LLM\u6a21\u5f0f\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u54a8\u8be2LLM\u6a21\u578b\u901a\u5e38\u4e0d\u663e\u5f0f\u5efa\u6a21\u54a8\u8be2\u8005\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u60c5\u7eea\u53d8\u5316\uff0c\u8fd9\u662f\u4f20\u7edf\u5fc3\u7406\u5b66\u6d41\u6d3e\u7684\u6838\u5fc3\u5173\u6ce8\u70b9\u3002\u540c\u65f6\uff0c\u5982\u4f55\u4f7f\u54a8\u8be2\u5e08\u6a21\u578b\u7684\u56de\u5e94\u4e0e\u8fd9\u4e9b\u60c5\u7eea\u53d8\u5316\u5bf9\u9f50\uff0c\u5e76\u4e3b\u52a8\u7f13\u89e3\u5b89\u5168\u98ce\u9669\uff0c\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faPsych\u0113Chat\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u89d2\u8272\u626e\u6f14\u5408\u6210\u54a8\u8be2\u5e08-\u6c42\u52a9\u8005\u5bf9\u8bdd\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u60c5\u7eea\u7ba1\u7406\u6a21\u5757\uff08\u6355\u6349\u5f53\u524d\u60c5\u7eea\u548c\u60c5\u7eea\u53d8\u5316\uff09\u548c\u98ce\u9669\u63a7\u5236\u6a21\u5757\uff08\u9884\u6d4b\u540e\u7eed\u53cd\u5e94\u548c\u8bc6\u522b\u6f5c\u5728\u98ce\u9669\uff09\u3002\u63d0\u4f9b\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\uff1a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7ba1\u9053\uff08Agent Mode\uff09\u548c\u7aef\u5230\u7aef\u601d\u7ef4\u94fe\u7edf\u4e00\u63a8\u7406\uff08LLM Mode\uff09\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u8bc4\u5206\u3001\u5bf9\u8bdd\u7ea7\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u7b49\u5e7f\u6cdb\u5b9e\u9a8c\uff0cPsych\u0113Chat\u5728\u60c5\u611f\u6d1e\u5bdf\u548c\u5b89\u5168\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Psych\u0113Chat\u901a\u8fc7\u663e\u5f0f\u6574\u5408\u60c5\u7eea\u53d8\u5316\u8ffd\u8e2a\u548c\u5b89\u5168\u98ce\u9669\u5206\u6790\uff0c\u4e3a\u5fc3\u7406\u54a8\u8be2LLM\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u60c5\u611f\u6d1e\u5bdf\u548c\u5b89\u5168\u63a7\u5236\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.13810", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13810", "abs": "https://arxiv.org/abs/2601.13810", "authors": ["Ruixing Ren"], "title": "Integrated Sensing and Communication for Low-Altitude Security", "comment": "6 pages, 5 figures; This paper presents a forward-looking perspective on the application of ISAC technology in low-altitude security governance, addressing challenges posed by low-altitude, slow-speed, and small-size targets", "summary": "The dense concentration of low-altitude, slow-speed, and small-size targets in the complex low-altitude environment poses significant security challenges, including failures in continuous wide-area sensing and ambiguous target intent, which existing regulatory frameworks struggle to address. Integrated sensing and communication (ISAC), a hallmark of next-generation mobile communication, offers a transformative approach to low-altitude security governance. By leveraging existing cellular infrastructure and spectrum resources, ISAC enables the construction of a seamless wide-area sensing network, supports intelligent feature extraction and intent inference, facilitates real-time collaborative decision-making, and establishes a dynamic trust authentication framework. This article systematically reviews the technical system, analyzes the security challenges, forecasts the enabling value of ISAC, and discusses the resulting open problems and challenges, thereby laying a foundation for future research and industrial implementation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u590d\u6742\u4f4e\u7a7a\u73af\u5883\u4e2d\uff0c\u5229\u7528\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6280\u672f\u89e3\u51b3\u4f4e\u7a7a\u5b89\u5168\u6cbb\u7406\u6311\u6218\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u6784\u5efa\u65e0\u7f1d\u5e7f\u57df\u611f\u77e5\u7f51\u7edc\u3001\u652f\u6301\u667a\u80fd\u7279\u5f81\u63d0\u53d6\u548c\u610f\u56fe\u63a8\u65ad\u7b49\u3002", "motivation": "\u590d\u6742\u4f4e\u7a7a\u73af\u5883\u4e2d\u5bc6\u96c6\u7684\u4f4e\u7a7a\u3001\u4f4e\u901f\u3001\u5c0f\u5c3a\u5bf8\u76ee\u6807\u5e26\u6765\u4e86\u91cd\u5927\u5b89\u5168\u6311\u6218\uff0c\u73b0\u6709\u76d1\u7ba1\u6846\u67b6\u96be\u4ee5\u5e94\u5bf9\u8fde\u7eed\u5e7f\u57df\u611f\u77e5\u5931\u8d25\u548c\u76ee\u6807\u610f\u56fe\u6a21\u7cca\u7b49\u95ee\u9898\u3002", "method": "\u5229\u7528\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u79fb\u52a8\u901a\u4fe1\u6807\u5fd7\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6280\u672f\uff0c\u901a\u8fc7\u73b0\u6709\u8702\u7a9d\u57fa\u7840\u8bbe\u65bd\u548c\u9891\u8c31\u8d44\u6e90\uff0c\u6784\u5efa\u65e0\u7f1d\u5e7f\u57df\u611f\u77e5\u7f51\u7edc\uff0c\u652f\u6301\u667a\u80fd\u7279\u5f81\u63d0\u53d6\u548c\u610f\u56fe\u63a8\u65ad\uff0c\u5b9e\u73b0\u5b9e\u65f6\u534f\u540c\u51b3\u7b56\uff0c\u5e76\u5efa\u7acb\u52a8\u6001\u4fe1\u4efb\u8ba4\u8bc1\u6846\u67b6\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u6280\u672f\u4f53\u7cfb\uff0c\u5206\u6790\u4e86\u5b89\u5168\u6311\u6218\uff0c\u9884\u6d4b\u4e86ISAC\u7684\u8d4b\u80fd\u4ef7\u503c\uff0c\u5e76\u8ba8\u8bba\u4e86\u7531\u6b64\u4ea7\u751f\u7684\u5f00\u653e\u95ee\u9898\u548c\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u4ea7\u4e1a\u5b9e\u65bd\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "ISAC\u6280\u672f\u4e3a\u4f4e\u7a7a\u5b89\u5168\u6cbb\u7406\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u73b0\u6709\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u590d\u6742\u4f4e\u7a7a\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u4f46\u4ecd\u6709\u5f00\u653e\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u3002"}}
{"id": "2601.14063", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14063", "abs": "https://arxiv.org/abs/2601.14063", "authors": ["Mohsinul Kabir", "Tasnim Ahmed", "Md Mezbaur Rahman", "Shaoxiong Ji", "Hassan Alhuzali", "Sophia Ananiadou"], "title": "XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs", "comment": "30 Pages, 13 Figures", "summary": "Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.", "AI": {"tldr": "XCR-Bench\uff1a\u4e00\u4e2a\u5305\u542b4.9k\u5e73\u884c\u53e5\u5bf9\u548c1,098\u4e2a\u72ec\u7279\u6587\u5316\u7279\u5b9a\u9879\u76ee\u7684\u8de8\u6587\u5316\u63a8\u7406\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u548c\u9002\u5e94\u6587\u5316\u7279\u5b9a\u9879\u76ee\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6587\u5316\u80fd\u529b\u53d7\u5230\u9ad8\u8d28\u91cf\u6587\u5316\u7279\u5b9a\u9879\u76ee\u6807\u6ce8\u8bed\u6599\u5e93\u7a00\u7f3a\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5305\u542b\u5e73\u884c\u8de8\u6587\u5316\u53e5\u5bf9\u7684\u8bed\u6599\u3002", "method": "\u7ed3\u5408Newmark\u7684\u6587\u5316\u7279\u5b9a\u9879\u76ee\u6846\u67b6\u548cHall\u7684\u6587\u5316\u4e09\u5143\u8bba\uff0c\u6784\u5efa\u4e86\u5305\u542b\u4e09\u4e2a\u4e0d\u540c\u63a8\u7406\u4efb\u52a1\u53ca\u76f8\u5e94\u8bc4\u4f30\u6307\u6807\u7684\u8de8\u6587\u5316\u63a8\u7406\u57fa\u51c6XCR-Bench\u3002", "result": "\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u548c\u9002\u5e94\u793e\u4ea4\u793c\u4eea\u548c\u6587\u5316\u53c2\u8003\u76f8\u5173\u7684\u6587\u5316\u7279\u5b9a\u9879\u76ee\u65b9\u9762\u5b58\u5728\u4e00\u81f4\u5f31\u70b9\uff0c\u5e76\u4e14\u5728\u6587\u5316\u9002\u5e94\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u533a\u57df\u548c\u6c11\u65cf\u5b97\u6559\u504f\u89c1\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8de8\u6587\u5316\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0cXCR-Bench\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5e2e\u52a9\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6587\u5316\u80fd\u529b\u3002"}}
{"id": "2601.13848", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.13848", "abs": "https://arxiv.org/abs/2601.13848", "authors": ["Corrado Possieri"], "title": "Derivative free data-driven stabilization of continuous-time linear systems from input-output data", "comment": null, "summary": "This letter presents a data-driven framework for the design of stabilizing controllers from input-output data in the continuous-time, linear, and time-invariant domain. Rather than relying on measurements or reliable estimates of input and output time derivatives, the proposed approach uses filters to derive a parameterization of the system dynamics. This parameterization is amenable to the application of linear matrix inequalities enabling the design of stabilizing output feedback controllers from input-output data and the knowledge of the order of the system.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8f93\u5165\u8f93\u51fa\u6570\u636e\u7684\u8fde\u7eed\u65f6\u95f4\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7a33\u5b9a\u63a7\u5236\u5668\u8bbe\u8ba1\u6846\u67b6\uff0c\u65e0\u9700\u6d4b\u91cf\u6216\u4f30\u8ba1\u65f6\u95f4\u5bfc\u6570", "motivation": "\u4f20\u7edf\u63a7\u5236\u5668\u8bbe\u8ba1\u901a\u5e38\u9700\u8981\u7cfb\u7edf\u6a21\u578b\u6216\u72b6\u6001\u4fe1\u606f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u83b7\u53d6\u51c6\u786e\u7684\u7cfb\u7edf\u6a21\u578b\u6216\u72b6\u6001\u5bfc\u6570\u6d4b\u91cf\u53ef\u80fd\u56f0\u96be\u3002\u672c\u6587\u65e8\u5728\u76f4\u63a5\u4ece\u8f93\u5165\u8f93\u51fa\u6570\u636e\u8bbe\u8ba1\u7a33\u5b9a\u63a7\u5236\u5668\uff0c\u907f\u514d\u5bf9\u65f6\u95f4\u5bfc\u6570\u6d4b\u91cf\u7684\u4f9d\u8d56\u3002", "method": "\u4f7f\u7528\u6ee4\u6ce2\u5668\u63a8\u5bfc\u7cfb\u7edf\u52a8\u6001\u7684\u53c2\u6570\u5316\u8868\u793a\uff0c\u8be5\u53c2\u6570\u5316\u9002\u7528\u4e8e\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\u65b9\u6cd5\uff0c\u4ec5\u9700\u8f93\u5165\u8f93\u51fa\u6570\u636e\u548c\u7cfb\u7edf\u9636\u6570\u4fe1\u606f\u5373\u53ef\u8bbe\u8ba1\u7a33\u5b9a\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u5668\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u63a7\u5236\u5668\u8bbe\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u8f93\u5165\u8f93\u51fa\u6570\u636e\u8bbe\u8ba1\u7a33\u5b9a\u63a7\u5236\u5668\uff0c\u65e0\u9700\u4f9d\u8d56\u8f93\u5165\u8f93\u51fa\u65f6\u95f4\u5bfc\u6570\u7684\u6d4b\u91cf\u6216\u53ef\u9760\u4f30\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6ee4\u6ce2\u5668\u65b9\u6cd5\u4e3a\u8fde\u7eed\u65f6\u95f4\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u6570\u636e\u9a71\u52a8\u63a7\u5236\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u4ec5\u9700\u8f93\u5165\u8f93\u51fa\u6570\u636e\u548c\u7cfb\u7edf\u9636\u6570\u4fe1\u606f\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5bf9\u65f6\u95f4\u5bfc\u6570\u6d4b\u91cf\u7684\u9700\u6c42\u3002"}}
{"id": "2601.12061", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12061", "abs": "https://arxiv.org/abs/2601.12061", "authors": ["Jinsook Lee", "Kirk Vanacore", "Zhuqian Zhou", "Jeanine Grutter", "Rene F. Kizilcec"], "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation", "comment": "Under Review for ACL 2026", "summary": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ee3\u7801\u672c\u6ce8\u5165\u5206\u5272\u65b9\u6cd5\uff0c\u5c06\u8fb9\u754c\u51b3\u7b56\u4e0e\u4e0b\u6e38\u6807\u6ce8\u6807\u51c6\u7ed3\u5408\uff0c\u8bc4\u4f30LLM\u5206\u5272\u5668\u4e0e\u6807\u51c6\u57fa\u7ebf\u7684\u8868\u73b0\uff0c\u53d1\u73b0DA\u611f\u77e5\u80fd\u4ea7\u751f\u66f4\u4e00\u81f4\u7684\u7247\u6bb5\uff0c\u4f46\u4e0d\u540c\u5206\u5272\u5668\u5404\u6709\u4f18\u52a3\uff0c\u5206\u5272\u8bbe\u8ba1\u5e94\u6839\u636e\u4e0b\u6e38\u76ee\u6807\u4f18\u5316\u800c\u975e\u5355\u4e00\u6027\u80fd\u5206\u6570\u3002", "motivation": "\u4f20\u7edf\u5bf9\u8bdd\u884c\u4e3a\u6807\u6ce8\u5c06\u4ea4\u9645\u6216\u6559\u5b66\u610f\u56fe\u5c40\u9650\u4e8e\u5355\u4e2a\u8bdd\u8bed\u6216\u8f6e\u6b21\uff0c\u5bfc\u81f4\u6807\u6ce8\u8005\u5728\u5e95\u5c42\u52a8\u4f5c\u4e0a\u4e00\u81f4\u4f46\u5728\u7247\u6bb5\u8fb9\u754c\u4e0a\u5b58\u5728\u5206\u6b67\uff0c\u964d\u4f4e\u4e86\u6807\u6ce8\u53ef\u9760\u6027\u3002\u9700\u8981\u6539\u8fdb\u5206\u5272\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4ee3\u7801\u672c\u6ce8\u5165\u5206\u5272\u65b9\u6cd5\uff0c\u5c06\u8fb9\u754c\u51b3\u7b56\u6761\u4ef6\u5316\u4e8e\u4e0b\u6e38\u6807\u6ce8\u6807\u51c6\uff1b\u8bc4\u4f30LLM\u5206\u5272\u5668\u4e0e\u6807\u51c6\u57fa\u7ebf\u53ca\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\uff1b\u5f15\u5165\u65e0\u9ec4\u91d1\u6807\u7b7e\u7684\u8bc4\u4f30\u6307\u6807\uff1a\u8de8\u5ea6\u4e00\u81f4\u6027\u3001\u533a\u5206\u6027\u548c\u4eba\u673a\u5206\u5e03\u4e00\u81f4\u6027\u3002", "result": "DA\u611f\u77e5\u4ea7\u751f\u7684\u7247\u6bb5\u6bd4\u7eaf\u6587\u672c\u57fa\u7ebf\u5185\u90e8\u66f4\u4e00\u81f4\uff1bLLM\u64c5\u957f\u521b\u5efa\u7ed3\u6784\u4e00\u81f4\u7684\u8de8\u5ea6\uff0c\u4f46\u57fa\u4e8e\u8fde\u8d2f\u6027\u7684\u57fa\u7ebf\u5728\u68c0\u6d4b\u5bf9\u8bdd\u6d41\u5168\u5c40\u53d8\u5316\u65b9\u9762\u66f4\u4f18\uff1b\u4e0d\u540c\u5206\u5272\u5668\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5404\u6709\u4f18\u52bf\uff1b\u7247\u6bb5\u5185\u8fde\u8d2f\u6027\u7684\u63d0\u5347\u5e38\u4ee5\u8fb9\u754c\u533a\u5206\u6027\u548c\u4eba\u673a\u5206\u5e03\u4e00\u81f4\u6027\u4e3a\u4ee3\u4ef7\u3002", "conclusion": "\u5206\u5272\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e94\u6839\u636e\u4e0b\u6e38\u76ee\u6807\u8fdb\u884c\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u8ffd\u6c42\u5355\u4e00\u7684\u6027\u80fd\u5206\u6570\u3002\u4e0d\u540c\u5206\u5272\u65b9\u6cd5\u5728\u4e0d\u540c\u65b9\u9762\u5404\u6709\u4f18\u52a3\uff0c\u9700\u8981\u6743\u8861\u53d6\u820d\u3002"}}
{"id": "2601.11977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11977", "abs": "https://arxiv.org/abs/2601.11977", "authors": ["Ren He", "Yinliang Xu", "Jinfeng Wang", "Jeremy Watson", "Jian Song"], "title": "One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints", "comment": null, "summary": "Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.", "AI": {"tldr": "\u63d0\u51faMoE-Encoder\u6a21\u5757\uff0c\u901a\u8fc7\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u5c42\u589e\u5f3a\u9884\u8bad\u7ec3\u65f6\u5e8f\u6a21\u578b\uff0c\u5b9e\u73b0\u591a\u53d8\u91cf\u9884\u6d4b\u5411\u4e13\u5bb6\u5f15\u5bfc\u7684\u5355\u53d8\u91cf\u4efb\u52a1\u8f6c\u6362\uff0c\u5e76\u652f\u6301\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u672c\u5730\u5316\u8bad\u7ec3\u548c\u8f7b\u91cf\u53c2\u6570\u5171\u4eab\u3002", "motivation": "\u7535\u529b\u7cfb\u7edf\u9884\u6d4b\u6d89\u53ca\u590d\u6742\u7684\u591a\u53d8\u91cf\u65f6\u5e8f\u6570\u636e\u548c\u4e25\u683c\u7684\u9690\u79c1\u7ea6\u675f\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u77e5\u8bc6\u4e14\u96be\u4ee5\u6cdb\u5316\uff0c\u73b0\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u96f6\u6837\u672c\u6027\u80fd\u6709\u9650\u3002", "method": "\u5728\u6807\u8bb0\u5316\u548c\u7f16\u7801\u4e4b\u95f4\u6ce8\u5165\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u5c42\uff0c\u5c06\u591a\u53d8\u91cf\u9884\u6d4b\u8f6c\u5316\u4e3a\u4e13\u5bb6\u5f15\u5bfc\u7684\u5355\u53d8\u91cf\u4efb\u52a1\uff0c\u6709\u6548\u6355\u6349\u53d8\u91cf\u95f4\u5173\u7cfb\uff0c\u5e76\u652f\u6301\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u672c\u5730\u5316\u8bad\u7ec3\u548c\u8f7b\u91cf\u53c2\u6570\u5171\u4eab\u3002", "result": "\u5728\u516c\u5f00\u591a\u53d8\u91cf\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u8054\u90a6\u73af\u5883\u6a21\u62df\u663e\u793a\u4ec5\u4f20\u8f93MoE-Encoder\u53c2\u6570\u5373\u53ef\u9ad8\u6548\u9002\u5e94\u65b0\u533a\u57df\uff0c\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\u3002", "conclusion": "MoE-Encoder\u4e3a\u65f6\u5e8f\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u611f\u77e5\u7684\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2601.12410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12410", "abs": "https://arxiv.org/abs/2601.12410", "authors": ["Dingyi Yang", "Junqi Zhao", "Xue Li", "Ce Li", "Boyang Li"], "title": "Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation", "comment": "23 pages, 11 figures", "summary": "Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.", "AI": {"tldr": "LLMs\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\uff0c\u672a\u6765\u7814\u7a76\u5e94\u66f4\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b", "motivation": "\u8ba4\u77e5\u4eba\u7c7b\u5b66\u8ba4\u4e3a\u4eba\u7c7b\u667a\u80fd\u7684\u5173\u952e\u5728\u4e8e\u63a8\u65ad\u4ed6\u4eba\u77e5\u8bc6\u72b6\u6001\u548c\u7406\u89e3\u610f\u56fe\u7684\u80fd\u529b\uff0c\u800c\u9ed1\u7329\u7329\u7b49\u52a8\u7269\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u72b6\u6001\u8ffd\u8e2a\u548c\u4f30\u8ba1\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\uff1a1) \u68c0\u6d4b\u6545\u4e8b\u89d2\u8272\u901a\u8fc7\u884c\u52a8\u5c55\u793a\u672c\u4e0d\u5e94\u62e5\u6709\u7684\u77e5\u8bc6\uff1b2) \u57fa\u4e8e\u89d2\u8272\u81ea\u8eab\u77e5\u8bc6\uff08\u800c\u975e\u5ba2\u89c2\u771f\u76f8\uff09\u9884\u6d4b\u89d2\u8272\u4e0b\u4e00\u6b65\u884c\u52a8\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u63a5\u8fd1\u968f\u673a\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u672a\u6765LLM\u7814\u7a76\u5e94\u66f4\u52a0\u91cd\u89c6\u77e5\u8bc6\u4f30\u8ba1\u548c\u610f\u56fe\u7406\u89e3\u80fd\u529b\u7684\u5f00\u53d1\uff0c\u8fd9\u662f\u4eba\u7c7b\u667a\u80fd\u533a\u522b\u4e8e\u52a8\u7269\u7684\u5173\u952e\u80fd\u529b\u3002"}}
{"id": "2601.13832", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13832", "abs": "https://arxiv.org/abs/2601.13832", "authors": ["Ruixing Ren", "Shan Chen", "Xuehan Bao", "Pingzheng Ge", "Dongming Wang", "Junhui Zhao"], "title": "Base Station Sleeping Strategy Based on Load Sharing in Ultra-Dense Networks", "comment": "11 pages,6 figures", "summary": "To address the issues of high operational costs and low energy efficiency (EE) caused by the dense deployment of small base stations (s-BSs) in 5G ultra-dense networks (UDNs), this paper first constructs a multi-objective mathematical optimization model targeting maximizing EE and minimizing the number of active BSs. The model incorporates key constraints including BS operational state, user equipment (UE)-BS connection relationship, and load threshold, laying a theoretical foundation for the coordinated optimization of energy conservation and quality of service. Based on this model, an integrated solution combining UE-BS initial connection optimization and load-sharing based BS sleeping is proposed. In the initial connection phase, with communication quality and BS load as dual constraints, efficient matching between UEs and optimal BSs is achieved through three sequential steps: communication feasibility screening, redundant connection removal, and overload load redistribution. This resolves the problems of load imbalance and difficult identification of redundant BSs in UDNs arising from unordered initial connections. In the BS sleeping phase, a BS sleeping index, comprehensively considering UE transferability and backup BS resources, is innovatively introduced to quantify BS dormancy priority. Through a closed-loop process involving low-load BS screening, adjacent BS load evaluation, and load sharing by two takeover BSs based on their capacity, accurate dormancy of redundant BSs and collaborative load migration are realized. Simulation results in a typical UDNs scenario demonstrate that, compared with the traditional baseline scheme, the proposed solution exhibits significant advantages in convergence speed, optimization of the number of active BSs, and EE improvement.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf95G\u8d85\u5bc6\u96c6\u7f51\u7edc\u4e2d\u5bc6\u96c6\u90e8\u7f72\u5c0f\u57fa\u7ad9\u5bfc\u81f4\u7684\u9ad8\u8fd0\u8425\u6210\u672c\u548c\u4f4e\u80fd\u6548\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u521d\u59cb\u8fde\u63a5\u4f18\u5316\u548c\u8d1f\u8f7d\u5171\u4eab\u57fa\u7ad9\u4f11\u7720\u7684\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\u5e76\u51cf\u5c11\u4e86\u6d3b\u8dc3\u57fa\u7ad9\u6570\u91cf\u3002", "motivation": "5G\u8d85\u5bc6\u96c6\u7f51\u7edc\u4e2d\u5bc6\u96c6\u90e8\u7f72\u5c0f\u57fa\u7ad9\u5bfc\u81f4\u8fd0\u8425\u6210\u672c\u9ad8\u3001\u80fd\u6548\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u534f\u8c03\u8282\u80fd\u548c\u670d\u52a1\u8d28\u91cf\u4f18\u5316\u3002", "method": "1) \u6784\u5efa\u6700\u5927\u5316\u80fd\u6548\u548c\u6700\u5c0f\u5316\u6d3b\u8dc3\u57fa\u7ad9\u6570\u91cf\u7684\u591a\u76ee\u6807\u4f18\u5316\u6a21\u578b\uff1b2) \u63d0\u51fa\u96c6\u6210\u89e3\u51b3\u65b9\u6848\uff1aa) UE-BS\u521d\u59cb\u8fde\u63a5\u4f18\u5316\uff08\u901a\u4fe1\u53ef\u884c\u6027\u7b5b\u9009\u3001\u5197\u4f59\u8fde\u63a5\u79fb\u9664\u3001\u8fc7\u8f7d\u8d1f\u8f7d\u91cd\u5206\u914d\uff09\uff1bb) \u57fa\u4e8e\u8d1f\u8f7d\u5171\u4eab\u7684\u57fa\u7ad9\u4f11\u7720\uff08\u5f15\u5165\u7efc\u5408\u8003\u8651UE\u53ef\u8f6c\u79fb\u6027\u548c\u5907\u4efd\u57fa\u7ad9\u8d44\u6e90\u7684\u4f11\u7720\u6307\u6570\uff0c\u901a\u8fc7\u4f4e\u8d1f\u8f7d\u57fa\u7ad9\u7b5b\u9009\u3001\u76f8\u90bb\u57fa\u7ad9\u8d1f\u8f7d\u8bc4\u4f30\u3001\u4e24\u4e2a\u63a5\u7ba1\u57fa\u7ad9\u57fa\u4e8e\u5bb9\u91cf\u7684\u8d1f\u8f7d\u5171\u4eab\u5b9e\u73b0\u7cbe\u786e\u4f11\u7720\uff09\u3002", "result": "\u5728\u5178\u578b\u8d85\u5bc6\u96c6\u7f51\u7edc\u573a\u666f\u4eff\u771f\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u7ebf\u65b9\u6848\uff0c\u6240\u63d0\u65b9\u6848\u5728\u6536\u655b\u901f\u5ea6\u3001\u6d3b\u8dc3\u57fa\u7ad9\u6570\u91cf\u4f18\u5316\u548c\u80fd\u6548\u63d0\u5347\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u96c6\u6210\u89e3\u51b3\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u8d85\u5bc6\u96c6\u7f51\u7edc\u4e2d\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u5197\u4f59\u57fa\u7ad9\u8bc6\u522b\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u80fd\u6548\u63d0\u5347\u548c\u8fd0\u8425\u6210\u672c\u964d\u4f4e\u7684\u534f\u540c\u4f18\u5316\u3002"}}
{"id": "2601.13884", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13884", "abs": "https://arxiv.org/abs/2601.13884", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "Optimizing the Geometry of an L-Shaped Building to Enhance Energy Efficiency and Sustainability", "comment": null, "summary": "The geometric form of a building strongly influences its material use, heat losses, and energy efficiency. This paper presents an analytical optimization of L-shaped residential buildings aimed at minimizing the external surface area for a prescribed volume. Both symmetric and asymmetric configurations are examined under realistic design constraints, including fixed or bounded wing aspect ratios and fixed building height. Using explicit optimization methods and Karush-Kuhn-Tucker conditions, closed-form expressions for the optimal geometric parameters and minimal envelope area are derived. The results show that unconstrained optimization leads to degenerate cuboid shapes, highlighting the importance of geometric constraints to preserve the L-shaped form. The obtained results provide practical design guidelines for architects and engineers, supporting informed early stage decisions that balance functional requirements, regulatory constraints, architectural intent, and energy performance. Case studies of existing houses demonstrate that the proposed approach can reduce external surface area or confirm near-optimality of practical designs, supporting energy-efficient early-stage architectural decisions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u89e3\u6790\u4f18\u5316L\u5f62\u4f4f\u5b85\u5efa\u7b51\uff0c\u5728\u7ed9\u5b9a\u4f53\u79ef\u4e0b\u6700\u5c0f\u5316\u5916\u8868\u9762\u79ef\uff0c\u8003\u8651\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u914d\u7f6e\uff0c\u63a8\u5bfc\u51fa\u6700\u4f18\u51e0\u4f55\u53c2\u6570\u548c\u6700\u5c0f\u56f4\u62a4\u9762\u79ef\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "motivation": "\u5efa\u7b51\u7684\u51e0\u4f55\u5f62\u72b6\u5bf9\u5176\u6750\u6599\u4f7f\u7528\u3001\u70ed\u635f\u5931\u548c\u80fd\u6e90\u6548\u7387\u6709\u91cd\u8981\u5f71\u54cd\u3002L\u5f62\u4f4f\u5b85\u5efa\u7b51\u5728\u73b0\u5b9e\u4e2d\u5e38\u89c1\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u51e0\u4f55\u4f18\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u5728\u65e9\u671f\u8bbe\u8ba1\u9636\u6bb5\u5e73\u8861\u529f\u80fd\u9700\u6c42\u3001\u89c4\u8303\u7ea6\u675f\u3001\u5efa\u7b51\u610f\u56fe\u548c\u80fd\u6e90\u6027\u80fd\u3002", "method": "\u91c7\u7528\u89e3\u6790\u4f18\u5316\u65b9\u6cd5\uff0c\u8003\u8651\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u914d\u7f6e\uff0c\u5728\u56fa\u5b9a\u6216\u6709\u9650\u7ffc\u5c55\u6bd4\u3001\u56fa\u5b9a\u5efa\u7b51\u9ad8\u5ea6\u7b49\u5b9e\u9645\u8bbe\u8ba1\u7ea6\u675f\u4e0b\uff0c\u4f7f\u7528\u663e\u5f0f\u4f18\u5316\u65b9\u6cd5\u548cKKT\u6761\u4ef6\u63a8\u5bfc\u6700\u4f18\u51e0\u4f55\u53c2\u6570\u548c\u6700\u5c0f\u56f4\u62a4\u9762\u79ef\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u65e0\u7ea6\u675f\u4f18\u5316\u4f1a\u5bfc\u81f4\u9000\u5316\u7684\u957f\u65b9\u4f53\u5f62\u72b6\uff0c\u51f8\u663e\u4e86\u51e0\u4f55\u7ea6\u675f\u5bf9\u4fdd\u6301L\u5f62\u5f62\u5f0f\u7684\u91cd\u8981\u6027\u3002\u63a8\u5bfc\u51fa\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u4e3a\u5efa\u7b51\u5e08\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u5b9e\u7528\u8bbe\u8ba1\u6307\u5357\u3002\u73b0\u6709\u4f4f\u5b85\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51cf\u5c11\u5916\u8868\u9762\u79ef\u6216\u786e\u8ba4\u5b9e\u9645\u8bbe\u8ba1\u7684\u8fd1\u4f18\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u6790\u4f18\u5316\u65b9\u6cd5\u4e3aL\u5f62\u4f4f\u5b85\u5efa\u7b51\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u6307\u5357\uff0c\u652f\u6301\u65e9\u671f\u5efa\u7b51\u51b3\u7b56\u4e2d\u5e73\u8861\u529f\u80fd\u9700\u6c42\u3001\u89c4\u8303\u7ea6\u675f\u3001\u5efa\u7b51\u610f\u56fe\u548c\u80fd\u6e90\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u80fd\u6e90\u9ad8\u6548\u7684\u5efa\u7b51\u8bbe\u8ba1\u3002"}}
{"id": "2601.12068", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12068", "abs": "https://arxiv.org/abs/2601.12068", "authors": ["Rowzatul Zannat", "Abdullah Al Shafi", "Abdul Muntakim"], "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset", "comment": null, "summary": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b758\u4e2a\u75c7\u72b6-\u75be\u75c5\u5173\u7cfb\u7684\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u75be\u75c5\u9884\u6d4b\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u96c6\u6210\u65b9\u6cd5\u8fbe\u523098%\u51c6\u786e\u7387\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u4eba\u7fa4\u7f3a\u4e4f\u53ef\u9760\u7684\u75be\u75c5\u9884\u6d4b\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u533b\u7597\u4fe1\u606f\u7684\u53ef\u53ca\u6027\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5b5f\u52a0\u62c9\u8bed\u793e\u533a\u63d0\u4f9b\u672c\u5730\u5316\u7684\u5065\u5eb7\u4fe1\u606f\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b85\u79cd\u75be\u75c5\u3001758\u4e2a\u75c7\u72b6-\u75be\u75c5\u5173\u7cfb\u7684\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u96c6\uff0c\u5e76\u516c\u5f00\u5206\u4eab\u3002\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u91c7\u7528\u8f6f\u6295\u7968\u548c\u786c\u6295\u7968\u96c6\u6210\u65b9\u6cd5\u7ed3\u5408\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u3002", "result": "\u8f6f\u6295\u7968\u548c\u786c\u6295\u7968\u96c6\u6210\u65b9\u6cd5\u5747\u8fbe\u523098%\u7684\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u6570\u636e\u96c6\u4e3a\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u5efa\u7acb\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\uff0c\u652f\u6301\u5b5f\u52a0\u62c9\u8bed\u793e\u533a\u7684\u533b\u7597\u4fe1\u606f\u516c\u5e73\u83b7\u53d6\uff0c\u4e3a\u672c\u5730\u5316\u5065\u5eb7\u4fe1\u606f\u5b66\u548c\u8bca\u65ad\u5de5\u5177\u7684\u672a\u6765\u53d1\u5c55\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2601.12008", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12008", "abs": "https://arxiv.org/abs/2601.12008", "authors": ["Shiqing Gao", "Yihang Zhou", "Shuai Shao", "Haoyu Luo", "Yiheng Bing", "Jiaxin Ding", "Luoyi Fu", "Xinbing Wang"], "title": "Extreme Value Policy Optimization for Safe Reinforcement Learning", "comment": "Published in the 42nd International Conference on Machine Learning (ICML 2025)", "summary": "Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.", "AI": {"tldr": "\u63d0\u51faEVO\u7b97\u6cd5\uff0c\u5229\u7528\u6781\u503c\u7406\u8bba\u5904\u7406\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6781\u7aef\u98ce\u9669\u4e8b\u4ef6\uff0c\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd", "motivation": "\u73b0\u6709\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u57fa\u4e8e\u671f\u671b\u7ea6\u675f\uff0c\u5ffd\u7565\u4e86\u7f55\u89c1\u4f46\u5f71\u54cd\u5de8\u5927\u7684\u6781\u7aef\u503c\u4e8b\u4ef6\uff08\u5982\u9ed1\u5929\u9e45\u4e8b\u4ef6\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7ea6\u675f\u8fdd\u53cd", "method": "\u63d0\u51fa\u6781\u503c\u7b56\u7565\u4f18\u5316(EVO)\u7b97\u6cd5\uff1a1) \u4f7f\u7528\u6781\u503c\u7406\u8bba\u5efa\u6a21\u6781\u7aef\u5956\u52b1\u548c\u6210\u672c\u6837\u672c\uff1b2) \u5f15\u5165\u6781\u7aef\u5206\u4f4d\u6570\u4f18\u5316\u76ee\u6807\u6355\u83b7\u6210\u672c\u5c3e\u90e8\u5206\u5e03\uff1b3) \u8bbe\u8ba1\u6781\u7aef\u4f18\u5148\u56de\u653e\u673a\u5236\u653e\u5927\u6781\u7aef\u6837\u672c\u7684\u5b66\u4e60\u4fe1\u53f7", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u7b56\u7565\u66f4\u65b0\u671f\u95f4\u7ea6\u675f\u8fdd\u53cd\u7684\u4e0a\u754c\uff0c\u4fdd\u8bc1\u5728\u96f6\u8fdd\u53cd\u5206\u4f4d\u6570\u6c34\u5e73\u4e0a\u7684\u4e25\u683c\u7ea6\u675f\u6ee1\u8db3\uff1b\u5b9e\u9a8c\u663e\u793aEVO\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u671f\u95f4\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7ebf\u76f8\u5f53\u7684\u7b56\u7565\u6027\u80fd", "conclusion": "EVO\u901a\u8fc7\u6781\u503c\u7406\u8bba\u6709\u6548\u5904\u7406\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6781\u7aef\u98ce\u9669\uff0c\u6bd4\u671f\u671b\u65b9\u6cd5\u6709\u66f4\u4f4e\u7684\u7ea6\u675f\u8fdd\u53cd\u6982\u7387\uff0c\u6bd4\u5206\u4f4d\u6570\u56de\u5f52\u65b9\u6cd5\u6709\u66f4\u4f4e\u7684\u65b9\u5dee"}}
{"id": "2601.12444", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12444", "abs": "https://arxiv.org/abs/2601.12444", "authors": ["Hui Yang", "Jiaoyan Chen", "Uli Sattler"], "title": "Large Language Model for OWL Proofs", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u5728OWL\u672c\u4f53\u8bba\u4e2d\u751f\u6210\u8bc1\u660e\u7684\u80fd\u529b\uff0c\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u903b\u8f91\u590d\u6742\u6027\u662f\u5f71\u54cd\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u800c\u975e\u8868\u793a\u683c\u5f0f\u3002", "motivation": "\u867d\u7136LLM\u7684\u63a8\u7406\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u5fe0\u5b9e\u3001\u53ef\u8bfb\u7684\u8bc1\u660e\uff08\u89e3\u91ca\u7ed3\u8bba\u5982\u4f55\u63a8\u5bfc\uff09\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728OWL\u672c\u4f53\u8bba\u8fd9\u79cd\u590d\u6742\u77e5\u8bc6\u8868\u793a\u548c\u63a8\u7406\u7684\u80cc\u666f\u4e0b\u3002", "method": "\u5f00\u53d1\u4e86\u81ea\u52a8\u5316\u6570\u636e\u96c6\u6784\u5efa\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u4e09\u4e2a\u987a\u5e8f\u4efb\u52a1\uff1a\u63d0\u53d6\u3001\u7b80\u5316\u548c\u89e3\u91ca\uff0c\u4ee5\u53ca\u8bc4\u4f30\u524d\u63d0\u903b\u8f91\u5b8c\u6574\u6027\u7684\u989d\u5916\u4efb\u52a1\u3002\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406LLM\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "1) \u67d0\u4e9b\u6a21\u578b\u6574\u4f53\u8868\u73b0\u826f\u597d\u4f46\u5728\u590d\u6742\u6848\u4f8b\u4e0a\u4ecd\u6709\u5c40\u9650\uff1b2) \u903b\u8f91\u590d\u6742\u6027\uff08\u800c\u975e\u8868\u793a\u683c\u5f0f\uff09\u662f\u5f71\u54cdLLM\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\uff1b3) \u8f93\u5165\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u663e\u8457\u964d\u4f4eLLM\u6027\u80fd\u3002", "conclusion": "LLM\u5728\u4e25\u683c\u903b\u8f91\u89e3\u91ca\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u652f\u6301\u590d\u6742\u6216\u4e0d\u5b8c\u7f8e\u6761\u4ef6\u4e0b\u7684\u5f39\u6027\u63a8\u7406\u65b9\u9762\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.13843", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13843", "abs": "https://arxiv.org/abs/2601.13843", "authors": ["Yongqiang Zhang", "Mustafa A. Kishk", "Mohamed-Slim Alouini"], "title": "Small Models, Big Impact: Tool-Augmented AI Agents for Wireless Network Planning", "comment": "7 pages, 4 figures, 2 tables, accepted by IEEE Communications Magazine", "summary": "Large Language Models (LLMs) such as ChatGPT promise revolutionary capabilities for Sixth-Generation (6G) wireless networks but their massive computational requirements and tendency to generate technically incorrect information create deployment barriers. In this work, we introduce MAINTAINED: autonomous artificial intelligence agent for wireless network deployment. Instead of encoding domain knowledge within model parameters, our approach orchestrates specialized computational tools for geographic analysis, signal propagation modeling, and network optimization. In a real-world case study, MAINTAINED outperforms state-of-the-art LLMs including ChatGPT-4o, Claude Sonnet 4, and DeepSeek-R1 by up to 100-fold in verified performance metrics while requiring less computational resources. This paradigm shift, moving from relying on parametric knowledge towards externalizing domain knowledge into verifiable computational tools, eliminates hallucination in technical specifications and enables edge-deployable Artificial Intelligence (AI) for wireless communications.", "AI": {"tldr": "MAINTAINED\u662f\u4e00\u4e2a\u7528\u4e8e\u65e0\u7ebf\u7f51\u7edc\u90e8\u7f72\u7684\u81ea\u4e3bAI\u4ee3\u7406\uff0c\u901a\u8fc7\u5916\u90e8\u5316\u9886\u57df\u77e5\u8bc6\u5230\u53ef\u9a8c\u8bc1\u7684\u8ba1\u7b97\u5de5\u5177\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edfLLMs\u6027\u80fd\u63d0\u5347100\u500d\u4e14\u6d88\u9664\u5e7b\u89c9\u95ee\u9898", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982ChatGPT\uff09\u57286G\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5177\u6709\u9769\u547d\u6027\u6f5c\u529b\uff0c\u4f46\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u751f\u6210\u6280\u672f\u4e0a\u9519\u8bef\u4fe1\u606f\u7684\u503e\u5411\u6784\u6210\u4e86\u90e8\u7f72\u969c\u788d", "method": "\u4e0d\u5c06\u9886\u57df\u77e5\u8bc6\u7f16\u7801\u5230\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u800c\u662f\u534f\u8c03\u4e13\u95e8\u7684\u8ba1\u7b97\u5de5\u5177\u8fdb\u884c\u5730\u7406\u5206\u6790\u3001\u4fe1\u53f7\u4f20\u64ad\u5efa\u6a21\u548c\u7f51\u7edc\u4f18\u5316", "result": "\u5728\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cMAINTAINED\u5728\u5df2\u9a8c\u8bc1\u6027\u80fd\u6307\u6807\u4e0a\u6bd4ChatGPT-4o\u3001Claude Sonnet 4\u548cDeepSeek-R1\u7b49\u6700\u5148\u8fdbLLMs\u8868\u73b0\u597d100\u500d\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90", "conclusion": "\u8fd9\u79cd\u4ece\u4f9d\u8d56\u53c2\u6570\u5316\u77e5\u8bc6\u8f6c\u5411\u5c06\u9886\u57df\u77e5\u8bc6\u5916\u90e8\u5316\u5230\u53ef\u9a8c\u8bc1\u8ba1\u7b97\u5de5\u5177\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u6d88\u9664\u4e86\u6280\u672f\u89c4\u8303\u4e2d\u7684\u5e7b\u89c9\uff0c\u5b9e\u73b0\u4e86\u65e0\u7ebf\u901a\u4fe1\u7684\u8fb9\u7f18\u53ef\u90e8\u7f72AI"}}
{"id": "2601.13896", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13896", "abs": "https://arxiv.org/abs/2601.13896", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "From geometry to sustainability: Optimal shapes of hip roof houses", "comment": null, "summary": "In this paper, we develop a rigorous mathematical framework for the optimization of hip roof house geometry, with the primary goal of minimizing the external surface of the building envelope for a given set of design constraints. Five optimization scenarios are systematically analyzed: fixed volume, fixed footprint ratio, fixed slenderness ratio, fixed floor area, and constrained height. For each case, explicit formulas for the optimal dimensions are derived, offering architects and engineers practical guidelines for improving material efficiency, reducing construction costs, and enhancing energy performance. To illustrate the practical relevance of the theoretical results, case studies of real-world hip roof houses are presented, revealing both inefficiencies in common practice and near-optimal examples. Furthermore, a freely available software application has been developed to support designers in applying the optimization methods directly to architectural projects. The findings confirm that square-based footprints combined with balanced slenderness ratios yield the most efficient forms, while deviations toward elongated or flattened proportions significantly increase energy and material demands. This work demonstrates how mathematical modeling and architectural design can be integrated to support sustainable architecture, providing both theoretical insight and practical tools for shaping energy-efficient, cost-effective, and aesthetically coherent residential buildings.", "AI": {"tldr": "\u672c\u6587\u4e3a\u56db\u5761\u5c4b\u9876\u623f\u5c4b\u51e0\u4f55\u4f18\u5316\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u6570\u5b66\u6846\u67b6\uff0c\u65e8\u5728\u7ed9\u5b9a\u8bbe\u8ba1\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u5efa\u7b51\u56f4\u62a4\u7ed3\u6784\u7684\u5916\u8868\u9762\u79ef\uff0c\u63a8\u5bfc\u51fa\u4e94\u79cd\u573a\u666f\u7684\u6700\u4f18\u5c3a\u5bf8\u516c\u5f0f\uff0c\u5e76\u63d0\u4f9b\u514d\u8d39\u8f6f\u4ef6\u5de5\u5177\u3002", "motivation": "\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u4f18\u5316\u56db\u5761\u5c4b\u9876\u623f\u5c4b\u51e0\u4f55\u5f62\u72b6\uff0c\u6700\u5c0f\u5316\u5efa\u7b51\u56f4\u62a4\u7ed3\u6784\u5916\u8868\u9762\u79ef\uff0c\u4ee5\u63d0\u9ad8\u6750\u6599\u6548\u7387\u3001\u964d\u4f4e\u5efa\u9020\u6210\u672c\u3001\u6539\u5584\u80fd\u6e90\u6027\u80fd\uff0c\u652f\u6301\u53ef\u6301\u7eed\u5efa\u7b51\u8bbe\u8ba1\u3002", "method": "\u5efa\u7acb\u4e25\u683c\u7684\u6570\u5b66\u4f18\u5316\u6846\u67b6\uff0c\u7cfb\u7edf\u5206\u6790\u4e94\u79cd\u8bbe\u8ba1\u7ea6\u675f\u573a\u666f\uff1a\u56fa\u5b9a\u4f53\u79ef\u3001\u56fa\u5b9a\u5360\u5730\u9762\u79ef\u6bd4\u3001\u56fa\u5b9a\u7ec6\u957f\u6bd4\u3001\u56fa\u5b9a\u697c\u5c42\u9762\u79ef\u548c\u7ea6\u675f\u9ad8\u5ea6\u3002\u4e3a\u6bcf\u79cd\u60c5\u51b5\u63a8\u5bfc\u6700\u4f18\u5c3a\u5bf8\u7684\u663e\u5f0f\u516c\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6b63\u65b9\u5f62\u57fa\u7840\u5e73\u9762\u7ed3\u5408\u5e73\u8861\u7684\u7ec6\u957f\u6bd4\u80fd\u4ea7\u751f\u6700\u9ad8\u6548\u7684\u5f62\u5f0f\uff0c\u800c\u504f\u5411\u7ec6\u957f\u6216\u6241\u5e73\u7684\u6bd4\u4f8b\u4f1a\u663e\u8457\u589e\u52a0\u80fd\u6e90\u548c\u6750\u6599\u9700\u6c42\u3002\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u5f00\u53d1\u4e86\u514d\u8d39\u8f6f\u4ef6\u5e94\u7528\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u6570\u5b66\u5efa\u6a21\u4e0e\u5efa\u7b51\u8bbe\u8ba1\u7684\u6574\u5408\u5982\u4f55\u652f\u6301\u53ef\u6301\u7eed\u5efa\u7b51\uff0c\u4e3a\u5851\u9020\u80fd\u6e90\u9ad8\u6548\u3001\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u7f8e\u5b66\u534f\u8c03\u7684\u4f4f\u5b85\u5efa\u7b51\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.12075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12075", "abs": "https://arxiv.org/abs/2601.12075", "authors": ["Mehrdad Farahani", "Franziska Penzkofer", "Richard Johansson"], "title": "To Copy or Not to Copy: Copying Is Easier to Induce Than Recall", "comment": null, "summary": "Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \\emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\\rightarrow$Recall (suppressing context use) and Recall$\\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5236\u7814\u7a76\uff0c\u901a\u8fc7\u63d0\u53d6\"\u4ef2\u88c1\u5411\u91cf\"\u6765\u8c03\u63a7\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u53c2\u6570\u77e5\u8bc6\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63ed\u793a\u4e86\u8bf1\u5bfc\u590d\u5236\u4e0e\u6062\u590d\u56de\u5fc6\u4e4b\u95f4\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u5982\u4f55\u4ef2\u88c1\u53c2\u6570\u77e5\u8bc6\uff08\u5b58\u50a8\u5728\u6743\u91cd\u4e2d\uff09\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5728\u63d0\u793a\u4e2d\uff09\u4e4b\u95f4\u7684\u9009\u62e9\uff0c\u7406\u89e3\u6a21\u578b\u5728\u8fd9\u4e24\u79cd\u77e5\u8bc6\u6e90\u4e4b\u95f4\u7684\u51b3\u7b56\u673a\u5236\u3002", "method": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u63d0\u53d6\"\u4ef2\u88c1\u5411\u91cf\"\uff1a\u8ba1\u7b97\u4e0d\u76f8\u5173\u4e0a\u4e0b\u6587\uff08\u5f15\u53d1\u53c2\u6570\u56de\u5fc6\uff09\u4e0e\u76f8\u5173\u4f46\u9519\u8bef\u4e0a\u4e0b\u6587\uff08\u5f15\u53d1\u590d\u5236\uff09\u5728\u6b8b\u5dee\u6d41\u4e2d\u7684\u8d28\u5fc3\u5dee\u5f02\u3002\u5c06\u8be5\u5411\u91cf\u4f5c\u4e3a\u52a0\u6027\u5e72\u9884\u6ce8\u5165\u5230\u7279\u5b9a\u5c42\u548c\u6807\u8bb0\u8de8\u5ea6\uff0c\u4ee5\u5f15\u5bfc\u6a21\u578b\u884c\u4e3a\u5728\u4e24\u4e2a\u65b9\u5411\u8f6c\u53d8\uff1a\u590d\u5236\u2192\u56de\u5fc6\uff08\u6291\u5236\u4e0a\u4e0b\u6587\u4f7f\u7528\uff09\u548c\u56de\u5fc6\u2192\u590d\u5236\uff08\u8bf1\u5bfc\u6a21\u578b\u590d\u5236\u4e0a\u4e0b\u6587\u4e2d\u7684\u4efb\u4f55\u6807\u8bb0\uff09\u3002", "result": "\u5728\u4e24\u4e2a\u67b6\u6784\uff08\u4ec5\u89e3\u7801\u5668\u548c\u7f16\u7801\u5668/\u89e3\u7801\u5668\uff09\u548c\u4e24\u4e2a\u5f00\u653e\u57dfQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u9002\u5ea6\u6269\u5c55\u4e0b\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u884c\u4e3a\u8f6c\u53d8\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u548c\u6d41\u7545\u6027\u3002\u673a\u5236\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u5bf9\u79f0\u6027\uff1a\u8bf1\u5bfc\u590d\u5236\u662f\u4e00\u4e2a\u5bb9\u6613\u7684\"\u91cd\u65b0\u6fc0\u6d3b\"\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u5728\u8f93\u5165\u7684\u4e0d\u540c\u4f4d\u7f6e\u89e6\u53d1\uff1b\u800c\u6062\u590d\u56de\u5fc6\u662f\u4e00\u4e2a\u66f4\u8106\u5f31\u7684\"\u6291\u5236\"\u8fc7\u7a0b\uff0c\u4e0e\u5bf9\u8c61\u6807\u8bb0\u5e72\u9884\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u673a\u5236\u5206\u6790\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u53c2\u6570\u77e5\u8bc6\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e4b\u95f4\u4ef2\u88c1\u7684\u5185\u5728\u673a\u5236\uff0c\u53d1\u73b0\u4e86\u8bf1\u5bfc\u590d\u5236\u4e0e\u6062\u590d\u56de\u5fc6\u4e4b\u95f4\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2601.12011", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12011", "abs": "https://arxiv.org/abs/2601.12011", "authors": ["Yize Zhao", "Christos Thrampoulidis"], "title": "Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features", "comment": null, "summary": "The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.", "AI": {"tldr": "\u635f\u5931\u91cd\u52a0\u6743\u5728\u8fc7\u53c2\u6570\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u65e0\u6cd5\u6539\u53d8\u6700\u7ec8\u5b66\u4e60\u9636\u6bb5\uff0c\u4f46\u5728\u8bad\u7ec3\u65e9\u671f\u80fd\u663e\u8457\u6539\u5584\u5c11\u6570\u7c7b\u5b66\u4e60\uff0c\u901a\u8fc7\u7b80\u5316\u6a21\u578b\u63ed\u793a\u4e86\u91cd\u52a0\u6743\u5982\u4f55\u6062\u590d\u5e73\u8861\u5b66\u4e60\u52a8\u6001", "motivation": "\u867d\u7136\u635f\u5931\u91cd\u52a0\u6743\u5728\u8fc7\u53c2\u6570\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u65e0\u6cd5\u6539\u53d8\u6700\u7ec8\u5b66\u4e60\u7ed3\u679c\uff0c\u4f46\u5b9e\u8bc1\u8868\u660e\u5b83\u5728\u8bad\u7ec3\u65e9\u671f\u80fd\u5e26\u6765\u663e\u8457\u597d\u5904\u3002\u672c\u6587\u65e8\u5728\u900f\u660e\u5730\u5c55\u793a\u548c\u5206\u6790\u8fd9\u4e00\u73b0\u8c61\uff0c\u7406\u89e3\u91cd\u52a0\u6743\u5982\u4f55\u5f71\u54cd\u65e9\u671f\u8bad\u7ec3\u52a8\u6001\u3002", "method": "\u5f15\u5165\u5c0f\u578b\u7b80\u5316\u6a21\u578b\uff08SSM\uff09\uff0c\u8be5\u6a21\u578b\u62bd\u8c61\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u8f93\u5165\u6570\u636e\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5149\u8c31\u5206\u91cf\u4e2d\u4e0d\u5e73\u8861\u7ed3\u6784\u7684\u5173\u952e\u4fe1\u606f\u3002\u901a\u8fc7SSM\u5206\u6790\u6807\u51c6\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4e0e\u91cd\u52a0\u6743\u65b9\u6cd5\u7684\u5dee\u5f02\u3002", "result": "SSM\u663e\u793a\uff1a1\uff09\u6807\u51c6\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5728\u8bad\u7ec3\u65e9\u671f\u4f18\u5148\u5b66\u4e60\u591a\u6570\u7c7b\u7279\u5f81\uff0c\u5ef6\u8fdf\u5c11\u6570\u7c7b\u5b66\u4e60\uff1b2\uff09\u635f\u5931\u91cd\u52a0\u6743\u80fd\u591f\u6062\u590d\u5e73\u8861\u5b66\u4e60\u52a8\u6001\uff0c\u4f7f\u591a\u6570\u7c7b\u548c\u5c11\u6570\u7c7b\u7279\u5f81\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u3002", "conclusion": "\u635f\u5931\u91cd\u52a0\u6743\u5728\u8bad\u7ec3\u65e9\u671f\u901a\u8fc7\u5e73\u8861\u5b66\u4e60\u52a8\u6001\u6539\u5584\u5c11\u6570\u7c7b\u5b66\u4e60\uff0c\u867d\u7136\u4e0d\u5f71\u54cd\u6700\u7ec8\u5b66\u4e60\u9636\u6bb5\uff0c\u4f46\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u6709\u91cd\u8981\u4f18\u5316\u4f5c\u7528\u3002SSM\u4e3a\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u63d0\u4f9b\u4e86\u900f\u660e\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2601.12499", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12499", "abs": "https://arxiv.org/abs/2601.12499", "authors": ["Meiru Zhang", "Zaiqiao Meng", "Nigel Collier"], "title": "Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck", "comment": "preprint", "summary": "Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the \"Weakest Link Law\": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that \"thinking\" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.", "AI": {"tldr": "LLMs\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\uff0c\u5bfc\u81f4\u5ffd\u7565\u67d0\u4e9b\u4f4d\u7f6e\u4fe1\u606f\u3002\u7814\u7a76\u53d1\u73b0\u591a\u8df3\u63a8\u7406\u6027\u80fd\u53d7\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u9650\u5236\uff0c\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u8ddd\u79bb\u51b3\u5b9a\u3002\u6ce8\u610f\u529b\u5f15\u5bfc\u53ef\u89e3\u51b3\u8bc6\u522b\u74f6\u9888\uff0c\u800c\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u4fe1\u606f\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5177\u6709\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u4f46\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\uff0c\u5bfc\u81f4\u5ffd\u7565\u67d0\u4e9b\u4f4d\u7f6e\u4fe1\u606f\u3002\u4e0d\u6e05\u695a\u8fd9\u4e9b\u5931\u8d25\u662f\u7531\u4e8e\u65e0\u6cd5\u5b9a\u4f4d\u8bc1\u636e\uff08\u8bc6\u522b\u5931\u8d25\uff09\u8fd8\u662f\u65e0\u6cd5\u6574\u5408\u8bc1\u636e\uff08\u5408\u6210\u5931\u8d25\uff09\u3002\u9700\u8981\u5206\u79bb\u8fd9\u4e9b\u673a\u5236\u6765\u7406\u89e3LLMs\u7684\u63a8\u7406\u9650\u5236\u3002", "method": "\u5f15\u5165\u591a\u7126\u70b9\u6ce8\u610f\u529b\u6307\u5bfc\uff08MFAI\uff09\u4f5c\u4e3a\u8bed\u4e49\u63a2\u9488\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5230\u9009\u5b9a\u4f4d\u7f6e\u6765\u5206\u79bb\u8bc6\u522b\u548c\u5408\u6210\u673a\u5236\u3002\u57285\u4e2aLLMs\u4e0a\u6d4b\u8bd5\u4e24\u4e2a\u591a\u8df3QA\u4efb\u52a1\uff08MuSiQue\u548cNeoQA\uff09\uff0c\u5206\u6790\u4f4d\u7f6e\u504f\u89c1\u7684\u5f71\u54cd\u3002", "result": "\u5efa\u7acb\u4e86\"\u6700\u5f31\u73af\u8282\u5b9a\u5f8b\"\uff1a\u591a\u8df3\u63a8\u7406\u6027\u80fd\u5d29\u6e83\u5230\u6700\u4e0d\u53ef\u89c1\u8bc1\u636e\u7684\u6027\u80fd\u6c34\u5e73\u3002\u5931\u8d25\u7531\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u4e8b\u5b9e\u95f4\u7ebf\u6027\u8ddd\u79bb\u51b3\u5b9a\uff08\u6027\u80fd\u65b9\u5dee<3%\uff09\u3002\u5339\u914d\u7684MFAI\u53ef\u89e3\u51b3\u8bc6\u522b\u74f6\u9888\uff0c\u5728\u4f4e\u53ef\u89c1\u6027\u4f4d\u7f6e\u63d0\u9ad8\u51c6\u786e\u7387\u8fbe11.5%\u3002\"\u601d\u8003\"\u6a21\u578b\u80fd\u6709\u6548\u5b9a\u4f4d\u548c\u6574\u5408\u4fe1\u606f\uff0c\u5728\u5608\u6742\u957f\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e2d\u5339\u914d\u9ec4\u91d1\u57fa\u7ebf\u3002", "conclusion": "LLMs\u7684\u591a\u8df3\u63a8\u7406\u5931\u8d25\u4e3b\u8981\u7531\u4f4d\u7f6e\u504f\u89c1\u5bfc\u81f4\u7684\u8bc6\u522b\u5931\u8d25\u5f15\u8d77\uff0c\u800c\u975e\u5408\u6210\u5931\u8d25\u3002\u6ce8\u610f\u529b\u5f15\u5bfc\u53ef\u7f13\u89e3\u8bc6\u522b\u74f6\u9888\uff0c\u800c\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u3002\u7edd\u5bf9\u4f4d\u7f6e\u800c\u975e\u76f8\u5bf9\u8ddd\u79bb\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2601.13958", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13958", "abs": "https://arxiv.org/abs/2601.13958", "authors": ["Sander Doodeman", "Paula Chanfreut Palacio", "Elena Torta", "Duarte Antunes"], "title": "Where to Place a Heavy Payload on a Multirotor UAV for Best Control Performance", "comment": null, "summary": "This paper studies the impact of rigidly attached heavy payload placement - where the payload mass significantly influences the UAV's dynamics - on the stability and control performance of a multirotor unmanned aerial vehicle (UAV). In particular, we focus on how the position of such a payload relative to the vehicle's Center of Gravity (CoG) affects the stability and control performance at an arbitrary point of interest on the UAV, such as the payload position, and on how this position can be optimized. Our conclusions are based on two key contributions. First, we analyze the stability of the zero-dynamics of a complete nonlinear model of the UAV with payload. We demonstrate that the stability of the zero dynamics depends on the vertical signed distance in the body-fixed frame between the controlled output position and the combined CoG of the UAV with payload. Specifically, positioning the output below the CoG yields unstable zero dynamics, while the linearized zero dynamics are marginally stable when placing it above, indicating reduced sensitivity to input disturbances. Second, we analyze the performance of the linearized UAV model with payload by providing an analytical expression for the H2-norm, from which we can quantify the system's attenuation to white noise input disturbances. We conclude that less control authority leads to a higher optimal position of the controlled output with respect to the CoG for closed-loop white-noise disturbance rejection capabilities, also when the heavy payload is the controlled output. The results are illustrated through numerical examples.", "AI": {"tldr": "\u7814\u7a76\u521a\u6027\u8fde\u63a5\u91cd\u8d1f\u8f7d\u4f4d\u7f6e\u5bf9\u591a\u65cb\u7ffc\u65e0\u4eba\u673a\u7a33\u5b9a\u6027\u548c\u63a7\u5236\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8d1f\u8f7d\u76f8\u5bf9\u4e8e\u91cd\u5fc3\u7684\u4f4d\u7f6e\u5982\u4f55\u5f71\u54cd\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u5982\u4f55\u4f18\u5316\u8be5\u4f4d\u7f6e\u3002", "motivation": "\u5f53\u65e0\u4eba\u673a\u643a\u5e26\u521a\u6027\u8fde\u63a5\u7684\u91cd\u8d1f\u8f7d\u65f6\uff0c\u8d1f\u8f7d\u8d28\u91cf\u663e\u8457\u5f71\u54cd\u65e0\u4eba\u673a\u52a8\u529b\u5b66\u7279\u6027\u3002\u8d1f\u8f7d\u76f8\u5bf9\u4e8e\u65e0\u4eba\u673a\u91cd\u5fc3\u7684\u4f4d\u7f6e\u4f1a\u5f71\u54cd\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u63a7\u5236\u6027\u80fd\uff0c\u4f46\u76ee\u524d\u5bf9\u6b64\u7f3a\u4e4f\u6df1\u5165\u5206\u6790\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u8fd9\u79cd\u5f71\u54cd\u5e76\u627e\u5230\u6700\u4f18\u8d1f\u8f7d\u4f4d\u7f6e\u3002", "method": "1. \u5206\u6790\u5e26\u6709\u8d1f\u8f7d\u7684\u5b8c\u6574\u975e\u7ebf\u6027\u65e0\u4eba\u673a\u6a21\u578b\u7684\u96f6\u52a8\u6001\u7a33\u5b9a\u6027\uff1b2. \u63a8\u5bfc\u7ebf\u6027\u5316\u65e0\u4eba\u673a\u6a21\u578bH2\u8303\u6570\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u91cf\u5316\u7cfb\u7edf\u5bf9\u767d\u566a\u58f0\u8f93\u5165\u5e72\u6270\u7684\u8870\u51cf\u80fd\u529b\u3002", "result": "1. \u96f6\u52a8\u6001\u7a33\u5b9a\u6027\u53d6\u51b3\u4e8e\u53d7\u63a7\u8f93\u51fa\u4f4d\u7f6e\u4e0e\u7ec4\u5408\u91cd\u5fc3\u4e4b\u95f4\u7684\u5782\u76f4\u6709\u7b26\u53f7\u8ddd\u79bb\uff1a\u8f93\u51fa\u4f4d\u4e8e\u91cd\u5fc3\u4e0b\u65b9\u65f6\u96f6\u52a8\u6001\u4e0d\u7a33\u5b9a\uff0c\u4f4d\u4e8e\u4e0a\u65b9\u65f6\u7ebf\u6027\u5316\u96f6\u52a8\u6001\u8fb9\u7f18\u7a33\u5b9a\uff0c\u5bf9\u8f93\u5165\u5e72\u6270\u654f\u611f\u6027\u964d\u4f4e\uff1b2. \u63a7\u5236\u6743\u9650\u8d8a\u5c0f\uff0c\u53d7\u63a7\u8f93\u51fa\u76f8\u5bf9\u4e8e\u91cd\u5fc3\u7684\u6700\u4f18\u4f4d\u7f6e\u8d8a\u9ad8\uff0c\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u95ed\u73af\u767d\u566a\u58f0\u5e72\u6270\u6291\u5236\u80fd\u529b\u3002", "conclusion": "\u91cd\u8d1f\u8f7d\u76f8\u5bf9\u4e8e\u65e0\u4eba\u673a\u91cd\u5fc3\u7684\u4f4d\u7f6e\u663e\u8457\u5f71\u54cd\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u63a7\u5236\u6027\u80fd\u3002\u5c06\u53d7\u63a7\u8f93\u51fa\uff08\u5982\u8d1f\u8f7d\u4f4d\u7f6e\uff09\u653e\u7f6e\u5728\u91cd\u5fc3\u4e0a\u65b9\u53ef\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u5bf9\u8f93\u5165\u5e72\u6270\u7684\u654f\u611f\u6027\u3002\u63a7\u5236\u6743\u9650\u8f83\u4f4e\u65f6\uff0c\u9700\u8981\u5c06\u53d7\u63a7\u8f93\u51fa\u653e\u7f6e\u5728\u66f4\u9ad8\u4f4d\u7f6e\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u5e72\u6270\u6291\u5236\u6027\u80fd\u3002"}}
{"id": "2601.13911", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13911", "abs": "https://arxiv.org/abs/2601.13911", "authors": ["Ewa Rokita-Magdziarz", "Barbara Gronostajska", "Marcin Magdziarz"], "title": "Designing sustainable barn-type houses: Optimal shapes for minimal envelope and energy use", "comment": null, "summary": "Barn-type houses have become one of the most popular single-family housing typologies in Poland and across Europe due to their simplicity, functionality, and potential for energy efficiency. Despite their widespread use, systematic methods for optimizing their geometry in terms of envelope area and energy performance remain limited. This paper develops a rigorous mathematical framework for determining the optimal proportions of barn-type houses with respect to minimizing the external surface area while satisfying constraints of either fixed volume or fixed floor area. Closed-form solutions for the optimal width, length, and height are derived as explicit functions of the roof slope, together with formulas for the minimal achievable surface. A recently introduced dimensionless compactness measure is also calculated, allowing quantitative assessment of how far a given design deviates from the theoretical optimum. The methodology is applied to case studies of three existing houses, showing that while some designs deviate significantly from optimal compactness, others already closely approximate it. The results confirm that theoretical optimization can lead to meaningful reductions in construction costs and energy demand. To support practical implementation, two original freely available software tools were developed, enabling architects and engineers to perform optimization analyses.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u8c37\u4ed3\u5f0f\u623f\u5c4b\u51e0\u4f55\u4f18\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u63a8\u5bfc\u51fa\u6700\u5c0f\u5316\u5916\u8868\u9762\u79ef\u7684\u6700\u4f18\u6bd4\u4f8b\u95ed\u5f0f\u89e3\uff0c\u5e76\u5f00\u53d1\u4e86\u5b9e\u7528\u8f6f\u4ef6\u5de5\u5177\u3002", "motivation": "\u8c37\u4ed3\u5f0f\u623f\u5c4b\u56e0\u7b80\u6d01\u3001\u529f\u80fd\u6027\u548c\u8282\u80fd\u6f5c\u529b\u5728\u6b27\u6d32\u5e7f\u6cdb\u6d41\u884c\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u4f18\u5316\u5176\u51e0\u4f55\u5f62\u72b6\u4ee5\u6700\u5c0f\u5316\u5916\u8868\u9762\u79ef\u548c\u63d0\u5347\u80fd\u6e90\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u4e25\u683c\u7684\u6570\u5b66\u6846\u67b6\uff0c\u63a8\u5bfc\u8c37\u4ed3\u5f0f\u623f\u5c4b\u5728\u56fa\u5b9a\u4f53\u79ef\u6216\u56fa\u5b9a\u9762\u79ef\u7ea6\u675f\u4e0b\u6700\u5c0f\u5316\u5916\u8868\u9762\u79ef\u7684\u6700\u4f18\u5bbd\u5ea6\u3001\u957f\u5ea6\u548c\u9ad8\u5ea6\u7684\u95ed\u5f0f\u89e3\uff0c\u8ba1\u7b97\u7d27\u51d1\u5ea6\u6307\u6807\uff0c\u5e76\u5f00\u53d1\u5b9e\u7528\u8f6f\u4ef6\u5de5\u5177\u3002", "result": "\u83b7\u5f97\u4e86\u6700\u4f18\u6bd4\u4f8b\u7684\u663e\u5f0f\u51fd\u6570\u89e3\u548c\u6700\u5c0f\u8868\u9762\u79ef\u516c\u5f0f\uff0c\u5e94\u7528\u4e8e\u4e09\u4e2a\u5b9e\u9645\u6848\u4f8b\u663e\u793a\u90e8\u5206\u8bbe\u8ba1\u5df2\u63a5\u8fd1\u6700\u4f18\uff0c\u90e8\u5206\u504f\u79bb\u8f83\u5927\uff0c\u7406\u8bba\u4f18\u5316\u53ef\u663e\u8457\u964d\u4f4e\u5efa\u9020\u6210\u672c\u548c\u80fd\u6e90\u9700\u6c42\u3002", "conclusion": "\u7406\u8bba\u51e0\u4f55\u4f18\u5316\u5bf9\u8c37\u4ed3\u5f0f\u623f\u5c4b\u5177\u6709\u5b9e\u9645\u610f\u4e49\uff0c\u5f00\u53d1\u7684\u514d\u8d39\u8f6f\u4ef6\u5de5\u5177\u53ef\u5e2e\u52a9\u5efa\u7b51\u5e08\u548c\u5de5\u7a0b\u5e08\u8fdb\u884c\u4f18\u5316\u5206\u6790\uff0c\u5b9e\u73b0\u6210\u672c\u8282\u7ea6\u548c\u80fd\u6e90\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2601.12078", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12078", "abs": "https://arxiv.org/abs/2601.12078", "authors": ["Linfeng Du", "Ye Yuan", "Zichen Zhao", "Fuyuan Lyu", "Emiliano Penaloza", "Xiuying Chen", "Zipeng Sun", "Jikun Kang", "Laurent Charlin", "Xue Liu", "Haolun Wu"], "title": "Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization", "comment": null, "summary": "Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.", "AI": {"tldr": "PURPLE\uff1a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u6846\u67b6\u4f18\u5316LLM\u4e2a\u6027\u5316\u7528\u6237\u6863\u6848\uff0c\u901a\u8fc7Plackett-Luce\u6392\u5e8f\u6a21\u578b\u6355\u6349\u8bb0\u5f55\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u76f4\u63a5\u5bf9\u9f50\u68c0\u7d22\u4e0e\u751f\u6210\u8d28\u91cf", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u57fa\u4e8e\u8bed\u4e49\u76f8\u5173\u6027\u9009\u62e9\u7528\u6237\u5386\u53f2\u8bb0\u5f55\uff0c\u4f46\u76f8\u5173\u6027\u4e0d\u80fd\u53ef\u9760\u5730\u4ee3\u8868\u5b9e\u7528\u6027\u2014\u2014\u8bed\u4e49\u76f8\u4f3c\u7684\u8bb0\u5f55\u53ef\u80fd\u56e0\u5197\u4f59\u6216\u51b2\u7a81\u4fe1\u606f\u800c\u65e0\u6cd5\u63d0\u5347\u751a\u81f3\u964d\u4f4e\u751f\u6210\u8d28\u91cf", "method": "\u63d0\u51faPURPLE\u6846\u67b6\uff0c\u5c06\u6863\u6848\u6784\u5efa\u89c6\u4e3a\u96c6\u5408\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u7528Plackett-Luce\u6392\u5e8f\u6a21\u578b\u6355\u6349\u590d\u6742\u8bb0\u5f55\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u53c2\u8003\u54cd\u5e94\u7684\u4f3c\u7136\u5ea6\u4f5c\u4e3a\u5bc6\u96c6\u53cd\u9988\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u4e5d\u4e2a\u4e2a\u6027\u5316\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPURPLE\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u5f3a\u542f\u53d1\u5f0f\u548c\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "PURPLE\u4e3a\u4f18\u5316\u7528\u6237\u6863\u6848\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u76f4\u63a5\u5bf9\u9f50\u68c0\u7d22\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684LLM\u4e2a\u6027\u5316"}}
{"id": "2601.12083", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12083", "abs": "https://arxiv.org/abs/2601.12083", "authors": ["Siru Zhong", "Junjie Qiu", "Yangyu Wu", "Yiqiu Liu", "Yuanpeng He", "Zhongwen Rao", "Bin Yang", "Chenjuan Guo", "Hao Xu", "Yuxuan Liang"], "title": "Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models", "comment": "This is an extended version of the paper presented at NeurIPS 2025. Code available at https://github.com/CityMind-Lab/FactoST", "summary": "Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.", "AI": {"tldr": "FactoST-v2\u63d0\u51fa\u4e86\u4e00\u79cd\u56e0\u5b50\u5316\u7684\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u901a\u7528\u65f6\u95f4\u5b66\u4e60\u548c\u9886\u57df\u7279\u5b9a\u7a7a\u95f4\u9002\u5e94\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5168\u6743\u91cd\u8fc1\u79fb\u548c\u4efb\u610f\u957f\u5ea6\u6cdb\u5316\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u5b58\u5728\u8054\u5408\u9884\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u5904\u7406\u9886\u57df\u7279\u5b9a\u7a7a\u95f4\u6a21\u5f0f\u5f02\u8d28\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u771f\u6b63\u7684\u901a\u7528\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56e0\u5b50\u5316\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u968f\u673a\u5e8f\u5217\u63a9\u7801\u9884\u8bad\u7ec3\u7b80\u7ea6\u7684\u7f16\u7801\u5668\u9aa8\u5e72\u7f51\u7edc\uff0c\u6355\u6349\u4e0d\u53d8\u65f6\u95f4\u52a8\u6001\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5143\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u63d0\u793a\u6ce8\u5165\u7a7a\u95f4\u611f\u77e5\u7684\u8f7b\u91cf\u9002\u914d\u5668\u3002", "result": "FactoST-v2\u5728\u591a\u4e2a\u9886\u57df\u8bc4\u4f30\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u5177\u6709\u7ebf\u6027\u6548\u7387\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u80fd\u5339\u654c\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u57fa\u7ebf\u3002", "conclusion": "\u56e0\u5b50\u5316\u8303\u5f0f\u4e3a\u771f\u6b63\u901a\u7528\u7684\u65f6\u7a7a\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5168\u6743\u91cd\u8fc1\u79fb\u548c\u4efb\u610f\u957f\u5ea6\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.12538", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12538", "abs": "https://arxiv.org/abs/2601.12538", "authors": ["Tianxin Wei", "Ting-Wei Li", "Zhining Liu", "Xuying Ning", "Ze Yang", "Jiaru Zou", "Zhichen Zeng", "Ruizhong Qiu", "Xiao Lin", "Dongqi Fu", "Zihao Li", "Mengting Ai", "Duo Zhou", "Wenxuan Bao", "Yunzhe Li", "Gaotang Li", "Cheng Qian", "Yu Wang", "Xiangru Tang", "Yin Xiao", "Liri Fang", "Hui Liu", "Xianfeng Tang", "Yuji Zhang", "Chi Wang", "Jiaxuan You", "Heng Ji", "Hanghang Tong", "Jingrui He"], "title": "Agentic Reasoning for Large Language Models", "comment": "Project: https://github.com/weitianxin/Awesome-Agentic-Reasoning", "summary": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u5c06\u667a\u80fd\u4f53\u63a8\u7406\u7ec4\u7ec7\u4e3a\u4e09\u4e2a\u4e92\u8865\u7ef4\u5ea6\uff1a\u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\uff08\u5355\u667a\u80fd\u4f53\u80fd\u529b\uff09\u3001\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u63a8\u7406\uff08\u901a\u8fc7\u53cd\u9988\u548c\u8bb0\u5fc6\u8fdb\u884c\u4f18\u5316\uff09\u548c\u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff08\u534f\u4f5c\u73af\u5883\uff09\uff0c\u533a\u5206\u4e0a\u4e0b\u6587\u63a8\u7406\u4e0e\u8bad\u7ec3\u540e\u63a8\u7406\uff0c\u5e76\u56de\u987e\u4e86\u5b9e\u9645\u5e94\u7528\u548c\u672a\u6765\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c01\u95ed\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u667a\u80fd\u4f53\u63a8\u7406\u901a\u8fc7\u5c06LLMs\u91cd\u6784\u4e3a\u80fd\u591f\u89c4\u5212\u3001\u884c\u52a8\u548c\u6301\u7eed\u5b66\u4e60\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u4e86\u8303\u5f0f\u8f6c\u53d8\uff0c\u65e8\u5728\u89e3\u51b3LLMs\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u8be5\u7efc\u8ff0\u91c7\u7528\u4e09\u7ef4\u5ea6\u7ec4\u7ec7\u6846\u67b6\uff1a1) \u57fa\u7840\u667a\u80fd\u4f53\u63a8\u7406\uff08\u5355\u667a\u80fd\u4f53\u5728\u7a33\u5b9a\u73af\u5883\u4e2d\u7684\u89c4\u5212\u3001\u5de5\u5177\u4f7f\u7528\u548c\u641c\u7d22\uff09\uff1b2) \u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u63a8\u7406\uff08\u901a\u8fc7\u53cd\u9988\u3001\u8bb0\u5fc6\u548c\u9002\u5e94\u4f18\u5316\u80fd\u529b\uff09\uff1b3) \u96c6\u4f53\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff08\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u534f\u8c03\u3001\u77e5\u8bc6\u5171\u4eab\u548c\u5171\u540c\u76ee\u6807\uff09\u3002\u540c\u65f6\u533a\u5206\u4e0a\u4e0b\u6587\u63a8\u7406\uff08\u901a\u8fc7\u7ed3\u6784\u5316\u7f16\u6392\u6269\u5c55\u6d4b\u8bd5\u65f6\u4ea4\u4e92\uff09\u548c\u8bad\u7ec3\u540e\u63a8\u7406\uff08\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4f18\u5316\u884c\u4e3a\uff09\u3002", "result": "\u7efc\u8ff0\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86\u667a\u80fd\u4f53\u63a8\u7406\u7684\u4ee3\u8868\u6027\u6846\u67b6\uff0c\u6db5\u76d6\u4e86\u79d1\u5b66\u3001\u673a\u5668\u4eba\u3001\u533b\u7597\u3001\u81ea\u4e3b\u7814\u7a76\u548c\u6570\u5b66\u7b49\u5b9e\u9645\u5e94\u7528\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u667a\u80fd\u4f53\u63a8\u7406\u65b9\u6cd5\u7efc\u5408\u6210\u4e00\u4e2a\u8fde\u63a5\u601d\u7ef4\u4e0e\u884c\u52a8\u7684\u7edf\u4e00\u8def\u7ebf\u56fe\u3002", "conclusion": "\u667a\u80fd\u4f53\u63a8\u7406\u4ee3\u8868\u4e86\u8fde\u63a5\u601d\u7ef4\u4e0e\u884c\u52a8\u7684\u91cd\u8981\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u5f00\u653e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\u3002\u672a\u6765\u6311\u6218\u5305\u62ec\u4e2a\u6027\u5316\u3001\u957f\u65f6\u7a0b\u4ea4\u4e92\u3001\u4e16\u754c\u5efa\u6a21\u3001\u53ef\u6269\u5c55\u7684\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u4ee5\u53ca\u5b9e\u9645\u90e8\u7f72\u7684\u6cbb\u7406\u95ee\u9898\u3002"}}
{"id": "2601.14089", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14089", "abs": "https://arxiv.org/abs/2601.14089", "authors": ["Zhenxu Zhao", "Ji Wang", "Weiyao Lan"], "title": "Data-Driven Safe Output Regulation of Strict-Feedback Linear Systems with Input Delay", "comment": null, "summary": "This paper develops a data-driven safe control framework for linear systems possessing a known strict-feedback structure, but with most plant parameters, external disturbances, and input delay being unknown. By leveraging Koopman operator theory, we utilize Krylov dynamic mode decomposition (DMD) to extract the system dynamics from measured data, enabling the reconstruction of the system and disturbance matrices. Concurrently, the batch least-squares identification (BaLSI) method is employed to identify other unknown parameters in the input channel. Using control barrier functions (CBFs) and backstepping, we first develop a full-state safe controller. Based on this, we build an output-feedback controller by performing system identification using only the output data and actuation signals as well as constructing an observer to estimate the unmeasured plant states. The proposed approach achieves: 1) finite-time identification of a substantial set of unknown system quantities, and 2) exponential convergence of the output state (the state furthest from the control input) to a reference trajectory while rigorously ensuring safety constraints. The effectiveness of the proposed method is demonstrated through a safe vehicle platooning application.", "AI": {"tldr": "\u57fa\u4e8eKoopman\u7b97\u5b50\u548c\u6570\u636e\u9a71\u52a8\u7684\u7ebf\u6027\u7cfb\u7edf\u5b89\u5168\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u591f\u8bc6\u522b\u672a\u77e5\u53c2\u6570\u3001\u6270\u52a8\u548c\u8f93\u5165\u5ef6\u8fdf\uff0c\u5e76\u4fdd\u8bc1\u5b89\u5168\u7ea6\u675f", "motivation": "\u9488\u5bf9\u5177\u6709\u5df2\u77e5\u4e25\u683c\u53cd\u9988\u7ed3\u6784\u4f46\u5927\u90e8\u5206\u53c2\u6570\u3001\u5916\u90e8\u6270\u52a8\u548c\u8f93\u5165\u5ef6\u8fdf\u672a\u77e5\u7684\u7ebf\u6027\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u4fdd\u8bc1\u5b89\u5168\u7ea6\u675f\u7684\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5", "method": "1) \u4f7f\u7528Krylov\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\u4ece\u6d4b\u91cf\u6570\u636e\u4e2d\u63d0\u53d6\u7cfb\u7edf\u52a8\u6001\uff0c\u91cd\u6784\u7cfb\u7edf\u548c\u6270\u52a8\u77e9\u9635\uff1b2) \u91c7\u7528\u6279\u91cf\u6700\u5c0f\u4e8c\u4e58\u8fa8\u8bc6\u65b9\u6cd5\u8bc6\u522b\u8f93\u5165\u901a\u9053\u4e2d\u7684\u5176\u4ed6\u672a\u77e5\u53c2\u6570\uff1b3) \u7ed3\u5408\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u548c\u53cd\u6b65\u6cd5\u8bbe\u8ba1\u5168\u72b6\u6001\u5b89\u5168\u63a7\u5236\u5668\uff1b4) \u57fa\u4e8e\u8f93\u51fa\u6570\u636e\u548c\u9a71\u52a8\u4fe1\u53f7\u8fdb\u884c\u7cfb\u7edf\u8fa8\u8bc6\uff0c\u6784\u5efa\u89c2\u6d4b\u5668\u4f30\u8ba1\u672a\u6d4b\u91cf\u72b6\u6001\uff0c\u5b9e\u73b0\u8f93\u51fa\u53cd\u9988\u63a7\u5236", "result": "1) \u5b9e\u73b0\u4e86\u5bf9\u5927\u91cf\u672a\u77e5\u7cfb\u7edf\u91cf\u7684\u6709\u9650\u65f6\u95f4\u8fa8\u8bc6\uff1b2) \u8f93\u51fa\u72b6\u6001\uff08\u8ddd\u79bb\u63a7\u5236\u8f93\u5165\u6700\u8fdc\u7684\u72b6\u6001\uff09\u80fd\u591f\u6307\u6570\u6536\u655b\u5230\u53c2\u8003\u8f68\u8ff9\uff0c\u540c\u65f6\u4e25\u683c\u4fdd\u8bc1\u5b89\u5168\u7ea6\u675f\uff1b3) \u5728\u8f66\u8f86\u7f16\u961f\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKoopman\u7b97\u5b50\u7684\u6570\u636e\u9a71\u52a8\u5b89\u5168\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u672a\u77e5\u53c2\u6570\u3001\u6270\u52a8\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u7cfb\u7edf\u8fa8\u8bc6\u548c\u63a7\u5236\u76ee\u6807"}}
{"id": "2601.13959", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.13959", "abs": "https://arxiv.org/abs/2601.13959", "authors": ["Shikher Sharma", "Simeon Reich"], "title": "A Bregman Regularized Proximal Point Method for Solving Equilibrium Problems on Hadamard Manifolds", "comment": null, "summary": "In this paper we develop a Bregman regularized proximal point algorithm for solving monotone equilibrium problems on Hadamard manifolds. It has been shown that the regularization term induced by a Bregman function is, in general, nonconvex on Hadamard manifolds unless the curvature is zero. Nevertheless, we prove that the proposed Bregman regularization scheme does converge to a solution of the equilibrium problem on Hadamard manifolds in the presence of a strong assumption on the convexity of the set formed by the regularization term. Moreover, we employ a coercivity condition on the Bregman function which is weaker than those typically assumed in the existing literature on Bregman regularization. Numerical experiments on illustrative examples demonstrate the practical effectiveness of our proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Hadamard\u6d41\u5f62\u4e0a\u6c42\u89e3\u5355\u8c03\u5e73\u8861\u95ee\u9898\u7684Bregman\u6b63\u5219\u5316\u8fd1\u7aef\u70b9\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5728\u5f3a\u51f8\u6027\u5047\u8bbe\u4e0b\u7684\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5728Hadamard\u6d41\u5f62\u4e0a\uff0cBregman\u51fd\u6570\u8bf1\u5bfc\u7684\u6b63\u5219\u5316\u9879\u901a\u5e38\u662f\u975e\u51f8\u7684\uff08\u9664\u975e\u66f2\u7387\u4e3a\u96f6\uff09\uff0c\u8fd9\u7ed9\u5e73\u8861\u95ee\u9898\u7684\u6c42\u89e3\u5e26\u6765\u4e86\u6311\u6218\u3002\u73b0\u6709\u6587\u732e\u4e2d\u7684Bregman\u6b63\u5219\u5316\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8f83\u5f3a\u7684\u5047\u8bbe\u6761\u4ef6\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f31\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Bregman\u6b63\u5219\u5316\u8fd1\u7aef\u70b9\u7b97\u6cd5\uff0c\u7528\u4e8e\u6c42\u89e3Hadamard\u6d41\u5f62\u4e0a\u7684\u5355\u8c03\u5e73\u8861\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u91c7\u7528Bregman\u51fd\u6570\u4f5c\u4e3a\u6b63\u5219\u5316\u9879\uff0c\u5728\u5f3a\u51f8\u6027\u5047\u8bbe\u4e0b\u8bc1\u660e\u6536\u655b\u6027\uff0c\u5e76\u4e14\u4f7f\u7528\u4e86\u6bd4\u73b0\u6709\u6587\u732e\u66f4\u5f31\u7684Bregman\u51fd\u6570\u5f3a\u5236\u6027\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u5728Hadamard\u6d41\u5f62\u4e0a\u6536\u655b\u5230\u5e73\u8861\u95ee\u9898\u7684\u89e3\uff0c\u5373\u4f7fBregman\u6b63\u5219\u5316\u9879\u901a\u5e38\u662f\u975e\u51f8\u7684\u3002\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u79cd\u5728Hadamard\u6d41\u5f62\u4e0a\u6c42\u89e3\u5355\u8c03\u5e73\u8861\u95ee\u9898\u7684Bregman\u6b63\u5219\u5316\u8fd1\u7aef\u70b9\u7b97\u6cd5\uff0c\u5728\u8f83\u5f31\u7684\u5f3a\u5236\u6027\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6536\u655b\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.12099", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12099", "abs": "https://arxiv.org/abs/2601.12099", "authors": ["Leonardo S. Goodall", "Dor Shilton", "Daniel A. Mullins", "Harvey Whitehouse"], "title": "Large language models struggle with ethnographic text annotation", "comment": null, "summary": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.", "AI": {"tldr": "LLMs\u5728\u6c11\u65cf\u5fd7\u6587\u672c\u6807\u6ce8\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\uff0c\u51c6\u786e\u7387\u8fdc\u4f4e\u4e8e\u53ef\u9760\u81ea\u52a8\u5316\u6807\u6ce8\u6240\u9700\u6c34\u5e73", "motivation": "\u8bc4\u4f30LLMs\u5728\u8de8\u6587\u5316\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u80fd\u5426\u4ece\u6c11\u65cf\u5fd7\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u636e\u4ee5\u52a0\u901f\u7814\u7a76", "method": "\u4f7f\u75287\u4e2a\u6700\u5148\u8fdb\u7684LLMs\u5bf9567\u4e2a\u6c11\u65cf\u5fd7\u6458\u5f55\u7684121\u4e2a\u4eea\u5f0f\u7279\u5f81\u8fdb\u884c\u6807\u6ce8\u8bc4\u4f30", "result": "LLMs\u8868\u73b0\u6709\u9650\uff0c\u51c6\u786e\u7387\u8fdc\u4f4e\u4e8e\u53ef\u9760\u81ea\u52a8\u5316\u6807\u6ce8\u6240\u9700\u6c34\u5e73\uff1b\u957f\u6587\u672c\u3001\u9700\u8981\u987a\u5e8f\u533a\u5206\u7684\u7279\u5f81\u548c\u6a21\u7cca\u6982\u5ff5\u7279\u522b\u56f0\u96be\uff1b\u4eba\u7c7b\u7f16\u7801\u8005\u95f4\u4fe1\u5ea6\u8bbe\u5b9a\u4e86LLM\u51c6\u786e\u7387\u7684\u4e0a\u9650", "conclusion": "LLMs\u76ee\u524d\u8fd8\u4e0d\u80fd\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6c11\u65cf\u5fd7\u6807\u6ce8\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u624d\u80fd\u53ef\u9760\u5e94\u7528\u4e8e\u8de8\u6587\u5316\u7814\u7a76"}}
{"id": "2601.12091", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12091", "abs": "https://arxiv.org/abs/2601.12091", "authors": ["Qian Tan", "Lei Jiang", "Yuting Zeng", "Shuoyang Ding", "Xiaohua Xu"], "title": "Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate", "comment": "13 pages", "summary": "Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a \"Seeking Common Ground while Reserving Differences\" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9LLM\u4e2d\u7684\u897f\u65b9\u4e2d\u5fc3\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51faCEBiasBench\u53cc\u8bed\u57fa\u51c6\u548cMACD\u591a\u667a\u80fd\u4f53\u6587\u5316\u8fa9\u8bba\u6846\u67b6\uff0c\u53d1\u73b0\u4e2d\u6587\u63d0\u793a\u4ec5\u5c06\u504f\u89c1\u8f6c\u5411\u4e1c\u4e9a\u89c6\u89d2\u800c\u975e\u6d88\u9664\uff0c\u800cMACD\u901a\u8fc7\u660e\u786e\u6587\u5316\u89d2\u8272\u5206\u914d\u663e\u8457\u63d0\u5347\u65e0\u504f\u89c1\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u897f\u65b9\u4e2d\u5fc3\u504f\u89c1\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5728\u4e24\u65b9\u9762\u4e0d\u8db3\uff1a\u8bc4\u4f30\u65b9\u6cd5\u5f3a\u5236\u8f93\u51fa\u5230\u9884\u5b9a\u4e49\u6587\u5316\u7c7b\u522b\u4e14\u7f3a\u4e4f\u4e2d\u7acb\u9009\u9879\uff1b\u7f13\u89e3\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u591a\u6587\u5316\u8bed\u6599\u5e93\u6216\u7f3a\u4e4f\u660e\u786e\u6587\u5316\u8868\u5f81\u7684\u667a\u80fd\u4f53\u6846\u67b6\u3002\u9700\u8981\u66f4\u4e25\u8c28\u7684\u8bc4\u4f30\u548c\u6709\u6548\u7684\u7f13\u89e3\u65b9\u6cd5\u3002", "method": "1) \u63d0\u51faCEBiasBench\u4e2d\u82f1\u53cc\u8bed\u57fa\u51c6\uff1b2) \u63d0\u51faMulti-Agent Vote(MAV)\u652f\u6301\"\u65e0\u504f\u89c1\"\u5224\u65ad\uff1b3) \u63d0\u51faMulti-Agent Cultural Debate(MACD)\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\uff0c\u4e3a\u667a\u80fd\u4f53\u5206\u914d\u4e0d\u540c\u6587\u5316\u89d2\u8272\uff0c\u91c7\u7528\"\u6c42\u540c\u5b58\u5f02\"\u7b56\u7565\u8fdb\u884c\u8fa9\u8bba\u3002", "result": "\u4e2d\u6587\u63d0\u793a\u4ec5\u5c06\u504f\u89c1\u8f6c\u5411\u4e1c\u4e9a\u89c6\u89d2\u800c\u975e\u6d88\u9664\u504f\u89c1\u3002MACD\u5728CEBiasBench\u4e0a\u8fbe\u523057.6%\u5e73\u5747\u65e0\u504f\u89c1\u7387(LLM\u8bc4\u4f30)\u548c86.0%(MAV\u8bc4\u4f30)\uff0c\u76f8\u6bd4GPT-4o\u57fa\u7ebf\u768447.6%\u548c69.0%\u663e\u8457\u63d0\u5347\u3002\u5728\u963f\u62c9\u4f2f\u8bedCAMeL\u57fa\u51c6\u4e0a\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u7684\u660e\u786e\u6587\u5316\u8868\u5f81\u5bf9\u8de8\u6587\u5316\u516c\u5e73\u81f3\u5173\u91cd\u8981\u3002MACD\u901a\u8fc7\u6587\u5316\u89d2\u8272\u5206\u914d\u548c\u8fa9\u8bba\u7b56\u7565\u6709\u6548\u7f13\u89e3LLM\u504f\u89c1\uff0c\u4e3a\u8de8\u6587\u5316\u516c\u5e73\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12539", "abs": "https://arxiv.org/abs/2601.12539", "authors": ["Ali Ezzat Shahroor", "Mohamed Bayan Kmainasi", "Abul Hasnat", "Dimitar Dimitrov", "Giovanni Da San Martino", "Preslav Nakov", "Firoj Alam"], "title": "MemeLens: Multilingual Multitask VLMs for Memes", "comment": "disinformation, misinformation, factuality, harmfulness, fake news, propaganda, hateful meme, multimodality, text, images", "summary": "Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86MemeLens\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u591a\u4efb\u52a1\u89e3\u91ca\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u7406\u89e3\u7f51\u7edc\u8868\u60c5\u5305\uff0c\u6574\u5408\u4e8638\u4e2a\u516c\u5171\u6570\u636e\u96c6\u5e76\u6620\u5c04\u523020\u4e2a\u4efb\u52a1\u7684\u5171\u4eab\u5206\u7c7b\u6cd5\u4e2d\u3002", "motivation": "\u73b0\u6709\u8868\u60c5\u5305\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u4efb\u52a1\uff08\u4ec7\u6068\u3001\u538c\u5973\u3001\u5ba3\u4f20\u3001\u60c5\u611f\u3001\u5e7d\u9ed8\uff09\u548c\u8bed\u8a00\u4e2d\uff0c\u9650\u5236\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u6574\u540838\u4e2a\u516c\u5171\u8868\u60c5\u5305\u6570\u636e\u96c6\uff0c\u5c06\u6570\u636e\u96c6\u7279\u5b9a\u6807\u7b7e\u8fc7\u6ee4\u5e76\u6620\u5c04\u5230\u5305\u542b20\u4e2a\u4efb\u52a1\u7684\u5171\u4eab\u5206\u7c7b\u6cd5\u4e2d\uff0c\u6db5\u76d6\u5371\u5bb3\u3001\u76ee\u6807\u3001\u6bd4\u55bb/\u8bed\u7528\u610f\u56fe\u548c\u60c5\u611f\u7b49\u7ef4\u5ea6\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u591a\u4efb\u52a1\u89e3\u91ca\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff1a1\uff09\u7a33\u5065\u7684\u8868\u60c5\u5305\u7406\u89e3\u9700\u8981\u591a\u6a21\u6001\u8bad\u7ec3\uff1b2\uff09\u4e0d\u540c\u8bed\u4e49\u7c7b\u522b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b3\uff09\u5728\u5355\u4e2a\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u800c\u975e\u7edf\u4e00\u8bad\u7ec3\u65f6\u5bb9\u6613\u8fc7\u5ea6\u4e13\u4e1a\u5316\u3002", "conclusion": "MemeLens\u4e3a\u8868\u60c5\u5305\u7406\u89e3\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u8bad\u7ec3\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u7edf\u4e00\u8bad\u7ec3\u76f8\u5bf9\u4e8e\u6570\u636e\u96c6\u7279\u5b9a\u5fae\u8c03\u7684\u4f18\u52bf\uff0c\u5c06\u4e3a\u793e\u533a\u63d0\u4f9b\u5b9e\u9a8c\u8d44\u6e90\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2601.14098", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14098", "abs": "https://arxiv.org/abs/2601.14098", "authors": ["Cristian Sestito", "Panagiota Kontou", "Pratibha Verma", "Atish Dixit", "Alexandros D. Keros", "Michael O'Boyle", "Christos-Savvas Bouganis", "Themis Prodromakis"], "title": "A flexible language model-assisted electronic design automation framework", "comment": "17 pages, 5 figures, 1 Supplementary (12 pages, 13 figures, 1 table)", "summary": "Large language models (LLMs) are transforming electronic design automation (EDA) by enhancing design stages such as schematic design, simulation, netlist synthesis, and place-and-route. Existing methods primarily focus these optimisations within isolated open-source EDA tools and often lack the flexibility to handle multiple domains, such as analogue, digital, and radio-frequency design. In contrast, modern systems require to interface with commercial EDA environments, adhere to tool-specific operation rules, and incorporate feedback from design outcomes while supporting diverse design flows. We propose a versatile framework that uses LLMs to generate files compatible with commercial EDA tools and optimise designs using power-performance-area reports. This is accomplished by guiding the LLMs with tool constraints and feedback from design outputs to meet tool requirements and user specifications. Case studies on operational transconductance amplifiers, microstrip patch antennas, and FPGA circuits show that the framework is effective as an EDA-aware assistant, handling diverse design challenges reliably.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684EDA\u6846\u67b6\uff0c\u652f\u6301\u5546\u4e1a\u5de5\u5177\u548c\u591a\u9886\u57df\u8bbe\u8ba1\u4f18\u5316", "motivation": "\u73b0\u6709LLM\u5728EDA\u4e2d\u7684\u5e94\u7528\u4e3b\u8981\u5c40\u9650\u4e8e\u5f00\u6e90\u5de5\u5177\uff0c\u7f3a\u4e4f\u5bf9\u5546\u4e1aEDA\u73af\u5883\u7684\u652f\u6301\uff0c\u65e0\u6cd5\u5904\u7406\u6a21\u62df\u3001\u6570\u5b57\u3001\u5c04\u9891\u7b49\u591a\u9886\u57df\u8bbe\u8ba1\u9700\u6c42\uff0c\u4e14\u7f3a\u4e4f\u8bbe\u8ba1\u53cd\u9988\u673a\u5236", "method": "\u63d0\u51fa\u901a\u7528\u6846\u67b6\uff0c\u5229\u7528LLM\u751f\u6210\u5546\u4e1aEDA\u5de5\u5177\u517c\u5bb9\u6587\u4ef6\uff0c\u901a\u8fc7\u5de5\u5177\u7ea6\u675f\u548c\u8bbe\u8ba1\u8f93\u51fa\u53cd\u9988\u6307\u5bfcLLM\u4f18\u5316\uff0c\u57fa\u4e8e\u529f\u8017-\u6027\u80fd-\u9762\u79ef\u62a5\u544a\u8fdb\u884c\u8bbe\u8ba1\u4f18\u5316", "result": "\u5728\u8fd0\u653e\u3001\u5fae\u5e26\u8d34\u7247\u5929\u7ebf\u548cFPGA\u7535\u8def\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u6846\u67b6\u4f5c\u4e3aEDA\u611f\u77e5\u52a9\u624b\u6709\u6548\u5904\u7406\u4e86\u591a\u6837\u5316\u8bbe\u8ba1\u6311\u6218", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u53ef\u9760\u5904\u7406\u591a\u9886\u57df\u8bbe\u8ba1\uff0c\u652f\u6301\u5546\u4e1aEDA\u5de5\u5177\uff0c\u901a\u8fc7\u53cd\u9988\u673a\u5236\u4f18\u5316\u8bbe\u8ba1\uff0c\u662f\u6709\u6548\u7684EDA\u611f\u77e5\u52a9\u624b"}}
{"id": "2601.14138", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14138", "abs": "https://arxiv.org/abs/2601.14138", "authors": ["Feng Li"], "title": "A global stochastic maximum principle for delayed forward-backward stochastic control systems", "comment": null, "summary": "In this paper, we study a delayed forward-backward stochastic control system in which all the coefficients depend on the state and control terms, and the control domain is not necessarily convex. A global stochastic maximum principle is obtained by using a new method. More precisely, this method introduces first-order and second-order auxiliary equations and offers a novel approach to deriving the adjoint equations as well as the variational equation for $y^\\e - y^*$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u975e\u51f8\u63a7\u5236\u57df\u5ef6\u8fdf\u6b63\u5012\u5411\u968f\u673a\u63a7\u5236\u7cfb\u7edf\u7684\u5168\u5c40\u968f\u673a\u6700\u5927\u503c\u539f\u7406\u65b0\u65b9\u6cd5", "motivation": "\u7814\u7a76\u7cfb\u6570\u4f9d\u8d56\u4e8e\u72b6\u6001\u548c\u63a7\u5236\u9879\u3001\u63a7\u5236\u57df\u975e\u51f8\u7684\u5ef6\u8fdf\u6b63\u5012\u5411\u968f\u673a\u63a7\u5236\u7cfb\u7edf\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u6b64\u7c7b\u590d\u6742\u7cfb\u7edf\u65f6\u5b58\u5728\u5c40\u9650\u6027", "method": "\u5f15\u5165\u4e00\u9636\u548c\u4e8c\u9636\u8f85\u52a9\u65b9\u7a0b\u7684\u65b0\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4f34\u968f\u65b9\u7a0b\u548c\u53d8\u5206\u65b9\u7a0b $y^\\epsilon - y^*$", "result": "\u83b7\u5f97\u4e86\u5168\u5c40\u968f\u673a\u6700\u5927\u503c\u539f\u7406\uff0c\u4e3a\u5904\u7406\u975e\u51f8\u63a7\u5236\u57df\u5ef6\u8fdf\u968f\u673a\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u975e\u51f8\u63a7\u5236\u57df\u5ef6\u8fdf\u6b63\u5012\u5411\u968f\u673a\u63a7\u5236\u7cfb\u7edf\u7684\u4f18\u5316\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u968f\u673a\u63a7\u5236\u7406\u8bba\u7684\u5e94\u7528\u8303\u56f4"}}
{"id": "2601.12104", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12104", "abs": "https://arxiv.org/abs/2601.12104", "authors": ["David Ili\u0107", "David Stanojevi\u0107", "Kostadin Cvejoski"], "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models", "comment": "9 pages, 2 figures; appendix with additional experiments and derivations", "summary": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.", "AI": {"tldr": "EZ-MIA\u662f\u4e00\u79cd\u65b0\u578b\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u9519\u8bef\u4f4d\u7f6e\u7684\u8bb0\u5fc6\u8868\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u98ce\u9669\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53ef\u80fd\u8bb0\u5fc6\u5e76\u66b4\u9732\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u3002\u73b0\u6709\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u68c0\u6d4b\u7387\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u9690\u79c1\u5ba1\u8ba1\u6240\u9700\u7684\u4f4e\u8bef\u62a5\u7387\u9608\u503c\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faEZ-MIA\u653b\u51fb\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5173\u952e\u89c2\u5bdf\uff1a\u8bb0\u5fc6\u5728\u9519\u8bef\u4f4d\u7f6e\u8868\u73b0\u6700\u660e\u663e\uff08\u6a21\u578b\u9884\u6d4b\u9519\u8bef\u4f46\u4ecd\u5bf9\u8bad\u7ec3\u6837\u672c\u663e\u793a\u8f83\u9ad8\u6982\u7387\uff09\u3002\u5f15\u5165\u9519\u8bef\u533a\u57df\uff08EZ\uff09\u5206\u6570\uff0c\u6d4b\u91cf\u9519\u8bef\u4f4d\u7f6e\u6982\u7387\u53d8\u5316\u76f8\u5bf9\u4e8e\u9884\u8bad\u7ec3\u53c2\u8003\u6a21\u578b\u7684\u65b9\u5411\u4e0d\u5e73\u8861\u6027\u3002\u8be5\u65b9\u6cd5\u53ea\u9700\u8981\u6bcf\u4e2a\u67e5\u8be2\u4e24\u6b21\u524d\u5411\u4f20\u64ad\uff0c\u65e0\u9700\u4efb\u4f55\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5728WikiText\u548cGPT-2\u4e0a\uff0cEZ-MIA\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u8fbe\u52303.8\u500d\u4e8e\u5148\u524d\u6700\u4f73\u65b9\u6cd5\u7684\u68c0\u6d4b\u7387\uff081%\u8bef\u62a5\u7387\u4e0b66.3% vs 17.5%\u771f\u9633\u6027\u7387\uff09\uff0cAUC\u63a5\u8fd1\u5b8c\u7f8e\uff080.98\uff09\u3002\u5728\u5173\u952e\u76840.1%\u8bef\u62a5\u7387\u9608\u503c\u4e0b\uff0c\u68c0\u6d4b\u7387\u63d0\u9ad88\u500d\uff0814.0% vs 1.8%\uff09\u3002\u5728Llama-2-7B\u548cAG News\u4e0a\uff0c\u68c0\u6d4b\u7387\u63d0\u9ad83\u500d\uff081%\u8bef\u62a5\u7387\u4e0b46.7% vs 15.8%\uff09\u3002", "conclusion": "\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u6bd4\u5148\u524d\u7406\u89e3\u7684\u8981\u5927\u5f97\u591a\uff0c\u8fd9\u5bf9\u9690\u79c1\u5ba1\u8ba1\u548c\u90e8\u7f72\u51b3\u7b56\u90fd\u6709\u91cd\u8981\u5f71\u54cd\u3002EZ-MIA\u4e3a\u8bc4\u4f30\u8fd9\u4e9b\u98ce\u9669\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2601.12093", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12093", "abs": "https://arxiv.org/abs/2601.12093", "authors": ["Duarte Alexandrino", "Ben Moseley", "Pavlos Protopapas"], "title": "PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems", "comment": "51 pages, 14 figures, 7 tables", "summary": "Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.", "AI": {"tldr": "\u63d0\u51faPTL-PINN\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u6270\u7406\u8bba\u548c\u8fc1\u79fb\u5b66\u4e60\uff0c\u5feb\u901f\u6c42\u89e3\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\uff0c\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINNs)\u5728\u6c42\u89e3\u975e\u7ebf\u6027\u5fae\u5206\u65b9\u7a0b\u65f6\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u6709\u9650\u548c\u8bad\u7ec3\u65f6\u95f4\u957f\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faPTL-PINN\u6846\u67b6\uff0c\u5c06\u5fae\u6270\u7406\u8bba\u4e0e\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\uff0c\u901a\u8fc7\u95ed\u5f0f\u8868\u8fbe\u5f0f\u6c42\u89e3\u8fd1\u4f3c\u7ebf\u6027\u5fae\u6270\u7cfb\u7edf\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ec5\u4e3a\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u3002", "result": "PTL-PINNs\u7cbe\u5ea6\u4e0e\u591a\u79cdRunge-Kutta\u65b9\u6cd5\u76f8\u5f53\uff0c\u8ba1\u7b97\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u6210\u529f\u6c42\u89e3\u4e86\u591a\u79cd\u975e\u7ebf\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u5fae\u6270\u65b9\u6cd5\u4e0ePINNs\u7ed3\u5408\uff0c\u5c55\u793a\u4e86\u5fae\u6270\u7406\u8bba\u5982\u4f55\u6307\u5bfc\u57fa\u7840\u6a21\u578b\u4ee5\u63a5\u8fd1\u7ecf\u5178\u6c42\u89e3\u5668\u7684\u901f\u5ea6\u89e3\u51b3\u975e\u7ebf\u6027\u7cfb\u7edf\u3002"}}
{"id": "2601.12542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12542", "abs": "https://arxiv.org/abs/2601.12542", "authors": ["Lukas Weidener", "Marko Brki\u0107", "Mihailo Jovanovi\u0107", "Ritvik Singh", "Chiara Baccin", "Emre Ulgac", "Alex Dobrin", "Aakaash Meduri"], "title": "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery", "comment": null, "summary": "Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.", "AI": {"tldr": "Deep Research\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u5b8c\u6210\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u76f8\u6bd4\u4f20\u7edf\u6279\u5904\u7406\u6a21\u5f0f\u5927\u5e45\u7f29\u77ed\u7814\u7a76\u5468\u671f\uff0c\u5728\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u53d1\u73b0\u7cfb\u7edf\u5927\u591a\u662f\u4e13\u6709\u7684\uff0c\u4e14\u91c7\u7528\u6279\u5904\u7406\u6a21\u5f0f\u9700\u8981\u6570\u5c0f\u65f6\u7684\u7814\u7a76\u5468\u671f\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u7814\u7a76\u8005\u6307\u5bfc\uff0c\u9650\u5236\u4e86AI\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u4ea4\u4e92\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5305\u542b\u89c4\u5212\u3001\u6570\u636e\u5206\u6790\u3001\u6587\u732e\u641c\u7d22\u548c\u65b0\u9896\u6027\u68c0\u6d4b\u7b49\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6301\u4e45\u4e16\u754c\u72b6\u6001\u7ef4\u62a4\u8de8\u8fed\u4ee3\u7814\u7a76\u5468\u671f\u7684\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u534a\u81ea\u4e3b\uff08\u5e26\u4eba\u5de5\u68c0\u67e5\u70b9\uff09\u548c\u5168\u81ea\u4e3b\u4e24\u79cd\u5de5\u4f5c\u6a21\u5f0f\u3002", "result": "\u5728BixBench\u8ba1\u7b97\u751f\u7269\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5f00\u653e\u56de\u7b54\u51c6\u786e\u738748.8%\uff0c\u591a\u9879\u9009\u62e9\u9898\u51c6\u786e\u738764.5%\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u9ad8\u51fa14-26\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Deep Research\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5206\u949f\u7ea7\u7684\u4ea4\u4e92\u5f0f\u79d1\u5b66\u7814\u7a76\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u8f85\u52a9\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u6548\u7387\uff0c\u540c\u65f6\u5206\u6790\u4e86\u5f00\u653e\u83b7\u53d6\u6587\u732e\u9650\u5236\u548c\u81ea\u52a8\u65b0\u9896\u6027\u8bc4\u4f30\u7b49\u5b9e\u9645\u90e8\u7f72\u6311\u6218\u3002"}}
{"id": "2601.14164", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14164", "abs": "https://arxiv.org/abs/2601.14164", "authors": ["Yichen Guo", "Tao Peng", "Yujie Zhao", "Yijing Niu", "Wenbo Wang"], "title": "The Impact of Interference Cognition on the Reliability and Capacity of Industrial Wireless Communications", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Interference significantly impacts the performance of industrial wireless networks, particularly n severe interference environments with dense networks reusing spectrum resources intensively. Although delicate interference information is often unavailable in conventional networks, emerging interference cognition techniques can compensate this critical problem with possibly different precision. This paper investigates the relationship between precision of interference cognition and system performance. We propose a novel performance analysis framework that quantifies the impact of varying interference information precision on achievable rate.\n  Specifically, leveraging the Nakagami-$\\mathbf{m}$ fading channel model, we analytically and asymptotically analyze the average achievable rate in the finite blocklength regime for different precision levels of signal and interference information. Our findings reveal the critical importance of identifying per-link interference information for achieving optimal performance. Additionally, obtaining instantaneous information is more beneficial for signal links.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5e72\u6270\u8ba4\u77e5\u7cbe\u5ea6\u5bf9\u5de5\u4e1a\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\u6765\u91cf\u5316\u4e0d\u540c\u5e72\u6270\u4fe1\u606f\u7cbe\u5ea6\u5bf9\u53ef\u8fbe\u901f\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u5de5\u4e1a\u65e0\u7ebf\u7f51\u7edc\u5728\u5bc6\u96c6\u7f51\u7edc\u548c\u9891\u8c31\u8d44\u6e90\u91cd\u7528\u573a\u666f\u4e0b\uff0c\u5e72\u6270\u4e25\u91cd\u5f71\u54cd\u6027\u80fd\u3002\u4f20\u7edf\u7f51\u7edc\u5f80\u5f80\u7f3a\u4e4f\u7cbe\u7ec6\u7684\u5e72\u6270\u4fe1\u606f\uff0c\u800c\u65b0\u5174\u7684\u5e72\u6270\u8ba4\u77e5\u6280\u672f\u80fd\u4ee5\u4e0d\u540c\u7cbe\u5ea6\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\u3002\u9700\u8981\u7814\u7a76\u5e72\u6270\u8ba4\u77e5\u7cbe\u5ea6\u4e0e\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6027\u80fd\u5206\u6790\u6846\u67b6\uff0c\u5229\u7528Nakagami-m\u8870\u843d\u4fe1\u9053\u6a21\u578b\uff0c\u5728\u6709\u9650\u5757\u957f\u5ea6\u673a\u5236\u4e0b\uff0c\u5bf9\u4e0d\u540c\u7cbe\u5ea6\u7684\u4fe1\u53f7\u548c\u5e72\u6270\u4fe1\u606f\u7684\u5e73\u5747\u53ef\u8fbe\u901f\u7387\u8fdb\u884c\u89e3\u6790\u548c\u6e10\u8fdb\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u8bc6\u522b\u6bcf\u4e2a\u94fe\u8def\u7684\u5e72\u6270\u4fe1\u606f\u5bf9\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff1b2) \u83b7\u53d6\u77ac\u65f6\u4fe1\u606f\u5bf9\u4fe1\u53f7\u94fe\u8def\u66f4\u6709\u76ca\u3002", "conclusion": "\u5e72\u6270\u8ba4\u77e5\u7cbe\u5ea6\u663e\u8457\u5f71\u54cd\u5de5\u4e1a\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\uff0c\u7279\u522b\u662f\u6bcf\u4e2a\u94fe\u8def\u7684\u5e72\u6270\u4fe1\u606f\u8bc6\u522b\u548c\u4fe1\u53f7\u94fe\u8def\u7684\u77ac\u65f6\u4fe1\u606f\u83b7\u53d6\u5bf9\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.14147", "categories": ["math.OC", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.14147", "abs": "https://arxiv.org/abs/2601.14147", "authors": ["Jieling Shi", "Kim-Chuan Toh", "Xin T. Tong", "Weng Kee Wong"], "title": "Gradient Flow for Finding E-optimal Designs", "comment": "43 pages, 8 figures", "summary": "We investigate the use of Wasserstein gradient flows for finding an $E$-optimal design for a regression model. Unlike the commonly used $D$- and $L$-optimality criteria, the $E$-criterion finds a design that maximizes the smallest eigenvalue of the information matrix, and so it is a non-differentiable criterion unless the minimum eigenvalue has geometric multiplicity equals to one. Such maximin design problems abound in statistical applications and present unique theoretical and computational challenges. Building on the differential structure of the $2$-Wasserstein space, we derive explicit formulas for the Wasserstein gradient of the $E$-optimality criterion in the simple-eigenvalue case. For higher multiplicities, we propose a Wasserstein steepest ascent direction and show that it can be computed exactly via a semidefinite programming (SDP) relaxation. We develop particle approximations that connect infinite-dimensional flows with finite-dimensional optimization, and provide approximation guarantees for empirical measures. Our framework extends naturally to constrained designs via projected Wasserstein gradient flows. Numerical experiments demonstrate that the proposed methods successfully recover $E$-optimal designs for both linear and nonlinear regression models, with competitive accuracy and scalability compared to existing heuristic approaches. This work highlights the potential of optimal transport-based dynamics as a unifying tool for studying challenging optimal design problems.", "AI": {"tldr": "\u4f7f\u7528Wasserstein\u68af\u5ea6\u6d41\u6c42\u89e3\u56de\u5f52\u6a21\u578b\u7684E\u6700\u4f18\u8bbe\u8ba1\u95ee\u9898\uff0c\u901a\u8fc7\u6700\u4f18\u8fd0\u8f93\u7406\u8bba\u5904\u7406\u975e\u5149\u6ed1\u7684E\u51c6\u5219\u4f18\u5316", "motivation": "E\u6700\u4f18\u8bbe\u8ba1\u5728\u7edf\u8ba1\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46E\u51c6\u5219\uff08\u6700\u5927\u5316\u4fe1\u606f\u77e9\u9635\u6700\u5c0f\u7279\u5f81\u503c\uff09\u662f\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\uff0c\u9664\u975e\u6700\u5c0f\u7279\u5f81\u503c\u7684\u51e0\u4f55\u91cd\u6570\u4e3a1\uff0c\u8fd9\u5e26\u6765\u4e86\u7406\u8bba\u548c\u8ba1\u7b97\u4e0a\u7684\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u7c7b\u6781\u5927\u6781\u5c0f\u8bbe\u8ba1\u95ee\u9898\u3002", "method": "\u57fa\u4e8e2-Wasserstein\u7a7a\u95f4\u7684\u5fae\u5206\u7ed3\u6784\uff0c\u63a8\u5bfc\u7b80\u5355\u7279\u5f81\u503c\u60c5\u51b5\u4e0bE\u6700\u4f18\u6027\u51c6\u5219\u7684Wasserstein\u68af\u5ea6\u663e\u5f0f\u516c\u5f0f\u3002\u5bf9\u4e8e\u9ad8\u91cd\u6570\u60c5\u51b5\uff0c\u63d0\u51faWasserstein\u6700\u901f\u4e0a\u5347\u65b9\u5411\uff0c\u901a\u8fc7\u534a\u5b9a\u89c4\u5212\u677e\u5f1b\u7cbe\u786e\u8ba1\u7b97\u3002\u5f00\u53d1\u7c92\u5b50\u8fd1\u4f3c\u8fde\u63a5\u65e0\u9650\u7ef4\u6d41\u4e0e\u6709\u9650\u7ef4\u4f18\u5316\uff0c\u63d0\u4f9b\u7ecf\u9a8c\u6d4b\u5ea6\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u901a\u8fc7\u6295\u5f71Wasserstein\u68af\u5ea6\u6d41\u81ea\u7136\u6269\u5c55\u5230\u7ea6\u675f\u8bbe\u8ba1\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6210\u529f\u6062\u590d\u4e86\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684E\u6700\u4f18\u8bbe\u8ba1\uff0c\u4e0e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u6027\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u8bc1\u660e\u4e86\u6700\u4f18\u8fd0\u8f93\u52a8\u529b\u5b66\u4f5c\u4e3a\u7814\u7a76\u6311\u6218\u6027\u6700\u4f18\u8bbe\u8ba1\u95ee\u9898\u7684\u7edf\u4e00\u5de5\u5177\u7684\u6f5c\u529b\u3002", "conclusion": "Wasserstein\u68af\u5ea6\u6d41\u4e3a\u5904\u7406\u975e\u5149\u6ed1\u7684E\u6700\u4f18\u8bbe\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u6700\u4f18\u8fd0\u8f93\u7406\u8bba\u5e94\u7528\u4e8e\u7edf\u8ba1\u8bbe\u8ba1\u4f18\u5316\uff0c\u4e3a\u89e3\u51b3\u6781\u5927\u6781\u5c0f\u8bbe\u8ba1\u95ee\u9898\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u6700\u4f18\u8fd0\u8f93\u52a8\u529b\u5b66\u5728\u7edf\u8ba1\u4f18\u5316\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2601.12132", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12132", "abs": "https://arxiv.org/abs/2601.12132", "authors": ["Md Mahmudul Hoque", "Md Mehedi Hassain", "Md Hojaifa Tanvir", "Rahul Nandy"], "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches", "comment": null, "summary": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u7ae0\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0Qwen 2.5 7B Instruct\u6a21\u578b\u4ee572%\u7684\u51c6\u786e\u7387\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u9762\u4e34\u6807\u6ce8\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u532e\u4e4f\u7684\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u4f7f\u7528\u6765\u81eaProthom Alo\u62a5\u7eb8\u7684Kaggle\u6570\u636e\u96c6\uff0c\u5728\u76f8\u540c\u5206\u7c7b\u6846\u67b6\u4e0b\u8bc4\u4f30\u4e09\u79cd\u6307\u4ee4\u8c03\u4f18LLMs\uff1aLLaMA 3.1 8B Instruct\u3001LLaMA 3.2 3B Instruct\u548cQwen 2.5 7B Instruct\u3002", "result": "Qwen 2.5\u4ee572%\u7684\u51c6\u786e\u7387\u8868\u73b0\u6700\u4f73\uff0c\u5728\"\u4f53\u80b2\"\u7c7b\u522b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff1bLLaMA 3.1\u548cLLaMA 3.2\u5206\u522b\u83b7\u5f9753%\u548c56%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u5b5f\u52a0\u62c9\u8bedNLP\u8d44\u6e90\u7a00\u7f3a\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u4e2d\u4ecd\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002\u672a\u6765\u7814\u7a76\u5c06\u63a2\u7d22\u66f4\u591a\u6a21\u578b\u3001\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u5e76\u6539\u8fdb\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2601.12095", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12095", "abs": "https://arxiv.org/abs/2601.12095", "authors": ["Hamidreza Sadeghi", "Saeedeh Momtazi", "Reza Safabakhsh"], "title": "Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding", "comment": null, "summary": "Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u540c\u6784\u573a\uff0c\u4f7f\u7528\u5d4c\u5165\u5411\u91cf\u8868\u793a\u6570\u5b57\u4ee5\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6781\u503c\u65f6\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4fdd\u6301\u6709\u7406\u6570\u57df\u4e0a\u7684\u4ee3\u6570\u8fd0\u7b97\u6027\u8d28", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u6781\u5c0f\u6570\u6216\u6781\u5927\u6570\u65f6\u9762\u4e34\u6ea2\u51fa\u3001\u4e0b\u6ea2\u548c\u8f93\u51fa\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u6301\u4ee3\u6570\u6027\u8d28\u540c\u65f6\u907f\u514d\u6570\u503c\u4e0d\u7a33\u5b9a\u7684\u6570\u5b57\u8868\u793a\u65b9\u6cd5", "method": "\u63d0\u51fa\u795e\u7ecf\u540c\u6784\u573a\u4f5c\u4e3a\u4ee3\u6570\u7ed3\u6784\uff08\u5982\u7fa4\u3001\u57df\uff09\u7684\u795e\u7ecf\u62bd\u8c61\uff0c\u4f7f\u7528\u56fa\u5b9a\u957f\u5ea6\u7684\u6570\u5b57\u5d4c\u5165\u5411\u91cf\uff0c\u8fd9\u4e9b\u5411\u91cf\u5728\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4ee3\u6570\u7ed3\u6784\uff0c\u7279\u522b\u662f\u4fdd\u6301\u6709\u7406\u6570\u57df\u4e0a\u7684\u52a0\u6cd5\u3001\u4e58\u6cd5\u548c\u6bd4\u8f83\u8fd0\u7b97", "result": "\u52a0\u6cd5\u8fd0\u7b97\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u6052\u7b49\u6027\u3001\u5c01\u95ed\u6027\u548c\u7ed3\u5408\u6027\u7b49\u5173\u952e\u4ee3\u6570\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u8d85\u8fc795%\uff1b\u4e58\u6cd5\u8fd0\u7b97\u9762\u4e34\u6311\u6218\uff0c\u5728\u4e0d\u540c\u4ee3\u6570\u6027\u8d28\u4e0a\u7684\u51c6\u786e\u7387\u572853%\u523073%\u4e4b\u95f4", "conclusion": "\u795e\u7ecf\u540c\u6784\u573a\u5728\u4fdd\u6301\u52a0\u6cd5\u8fd0\u7b97\u7684\u4ee3\u6570\u6027\u8d28\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u4e58\u6cd5\u8fd0\u7b97\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u4e3a\u5904\u7406\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2601.12547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12547", "abs": "https://arxiv.org/abs/2601.12547", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "How Clinicians Think and What AI Can Learn From It", "comment": "34 pages", "summary": "Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\\to$ perception $\\to$ inference $\\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($\u03b5$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.", "AI": {"tldr": "\u4e34\u5e8aAI\u5e94\u4ece\u9884\u6d4b\u5f15\u64ce\u8f6c\u5411\u5e8f\u8d2f\u63a7\u5236\u95ee\u9898\uff0c\u91c7\u7528\u7a33\u5065\u7684\u5e8f\u6570\u51b3\u7b56\u89c4\u5219\u800c\u975e\u57fa\u6570\u4f18\u5316\uff0c\u4ee5\u5339\u914d\u4e34\u5e8a\u63a8\u7406\u7684\u5feb\u901f\u8282\u4fed\u542f\u53d1\u5f0f\u7279\u70b9\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8aAI\u7cfb\u7edf\u4e3b\u8981\u4f5c\u4e3a\u9884\u6d4b\u5f15\u64ce\uff08\u4ea7\u751f\u6807\u7b7e\u6216\u98ce\u9669\u8bc4\u5206\uff09\uff0c\u4f46\u771f\u5b9e\u4e34\u5e8a\u63a8\u7406\u662f\u65f6\u95f4\u53d7\u9650\u3001\u5e8f\u8d2f\u7684\u63a7\u5236\u95ee\u9898\uff0c\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4fe1\u606f\u6536\u96c6\u4e0e\u4e0d\u53ef\u9006\u884c\u52a8\u3002\u4e34\u5e8a\u533b\u751f\u4f9d\u8d56\u5feb\u901f\u8282\u4fed\u7684\u8bcd\u5178\u5f0f\u542f\u53d1\u5f0f\uff08\u5982\u5feb\u901f\u8282\u4fed\u6811\uff09\uff0c\u800c\u975e\u57fa\u6570\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e34\u5e8aAI\u5e94\u4e0e\u533b\u751f\u5bf9\u9f50\u7684\u84dd\u56fe\uff1a\u4f7f\u7528\u4e30\u5bcc\u6a21\u578b\u8fdb\u884c\u4fe1\u5ff5\u548c\u8f68\u8ff9\u5efa\u6a21\uff0c\u4f46\u901a\u8fc7\u7a33\u5065\u7684\u5e8f\u6570\u89c4\u5219\u9009\u62e9\u884c\u52a8\uff1b\u5c06\u542f\u53d1\u5f0f\u89c6\u4e3a\u4f4e\u7ef4\u7279\u4f8b\uff1b\u5c06AI\u90e8\u7f72\u4e3a\"\u9009\u62e9\u6027\u590d\u6742\u6027\"\u2014\u2014\u4e3b\u8981\u5728\u51b3\u7b56\u8106\u5f31\u4e14\u4fe1\u606f\u5177\u6709\u6b63\u671f\u671b\u5f71\u54cd\u65f6\u7528\u4e8e\u6253\u7834\u5e73\u5c40\u3002", "result": "\u4e3a\u5feb\u901f\u8282\u4fed\u542f\u53d1\u5f0f\u63d0\u4f9b\u4e86\u89c4\u8303\u6027\u7406\u7531\uff1a1) \u4e34\u5e8a\u6743\u8861\u4e3b\u8981\u901a\u8fc7\u4eba\u7c7b\u5224\u65ad\u6784\u5efa\uff0c\u4ec5\u5728\u7edd\u5bf9\u5c3a\u5ea6\u4e0a\u5f31\u53ef\u6d4b\uff0c\u53ea\u6709\u6392\u5e8f\u662f\u4e0d\u53d8\u7684\uff1b2) \u504f\u597d\u548c\u4fe1\u53f7\u83b7\u53d6\u7ed3\u6784\u7c97\u7cd9\uff0c\u5b58\u5728\u6301\u7eed\u4e0d\u786e\u5b9a\u6027\u4e0b\u9650\uff0c\u5f53\u8fd9\u79cd\"\u7c97\u7cd9\u6027\"\u8d85\u8fc7\u51b3\u7b56\u8fb9\u9645\u65f6\uff0c\u671f\u671b\u6548\u7528\u4f18\u5316\u53d8\u5f97\u8106\u5f31\uff0c\u800c\u7a33\u5065\u7684\u652f\u914d/\u8fc7\u6ee4\u89c4\u5219\u80fd\u7a33\u5b9a\u51b3\u7b56\u3002", "conclusion": "\u4e34\u5e8aAI\u5e94\u91c7\u7528\u5e8f\u6570\u4f18\u5148\u7acb\u573a\uff0c\u5c06AI\u4f5c\u4e3a\u9009\u62e9\u6027\u590d\u6742\u6027\u5de5\u5177\uff0c\u5728\u51b3\u7b56\u8106\u5f31\u65f6\u4ecb\u5165\uff0c\u800c\u975e\u5168\u9762\u66ff\u4ee3\u4e34\u5e8a\u542f\u53d1\u5f0f\u63a8\u7406\u3002\u8fd9\u80fd\u66f4\u597d\u5730\u5339\u914d\u533b\u7597\u51b3\u7b56\u7684\u73b0\u5b9e\u7ea6\u675f\u548c\u4e0d\u786e\u5b9a\u6027\u7279\u70b9\u3002"}}
{"id": "2601.12154", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12154", "abs": "https://arxiv.org/abs/2601.12154", "authors": ["Teodor-C\u0103lin Ionescu", "Lifeng Han", "Jan Heijdra Suasnabar", "Anne Stiggelbout", "Suzan Verberne"], "title": "Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs", "comment": "under review to CLIN journal", "summary": "This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \\textit{precision} and \\textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management\" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u795e\u7ecf\u4e3b\u9898\u5efa\u6a21\uff08BERTopic\uff09\u548cLLMs\u5206\u6790\u764c\u75c7\u60a3\u8005\u8bbf\u8c08\u6570\u636e\uff0c\u53d1\u73b0BioClinicalBERT\u5d4c\u5165\u6a21\u578b\u80fd\u63d0\u5347\u4e3b\u9898\u7cbe\u786e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8bc6\u522b\u51fa\u764c\u75c7\u62a4\u7406\u4e2d\u7684\u5173\u952e\u4e3b\u9898\uff0c\u4e3a\u60a3\u8005\u5bfc\u5411\u7684\u533b\u7597\u5b9e\u8df5\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u4ece\u60a3\u8005\u53d9\u4e8b\u6570\u636e\u4e2d\u6316\u6398\u6709\u610f\u4e49\u4e3b\u9898\uff0c\u4e3a\u60a3\u8005\u5bfc\u5411\u7684\u533b\u7597\u5b9e\u8df5\u63d0\u4f9b\u6d1e\u5bdf\u3002\u901a\u8fc7\u5206\u6790\u764c\u75c7\u60a3\u8005\u8bbf\u8c08\uff0c\u63a2\u7d22\u5982\u4f55\u66f4\u6709\u6548\u5730\u5c06\u60a3\u8005\u58f0\u97f3\u878d\u5165\u533b\u7597\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528BERTopic\u548cTop2Vec\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\u6bd4\u8f83\uff0c\u91c7\u7528GPT-4\u8fdb\u884c\u4e3b\u9898\u6807\u6ce8\uff0c\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\uff08\u4e00\u81f4\u6027\u3001\u6e05\u6670\u5ea6\u3001\u76f8\u5173\u6027\uff09\u9009\u62e9\u6700\u4f73\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u4e09\u79cd\u4e34\u5e8a\u5bfc\u5411\u5d4c\u5165\u6a21\u578b\uff08\u5305\u62ecBioClinicalBERT\uff09\u8fdb\u884c\u5b8c\u6574\u6570\u636e\u96c6\u5206\u6790\u3002", "result": "BERTopic\u8868\u73b0\u4f18\u4e8eTop2Vec\uff1bBioClinicalBERT\u5d4c\u5165\u6a21\u578b\u4ea7\u751f\u6700\u4e00\u81f4\u7684\u7ed3\u679c\uff1b\u8bc6\u522b\u51fa\u4e24\u4e2a\u4e3b\u5bfc\u4e3b\u9898\uff1a\u764c\u75c7\u62a4\u7406\u7ba1\u7406\u4e2d\u7684\u534f\u8c03\u4e0e\u6c9f\u901a\u3001\u764c\u75c7\u6cbb\u7597\u65c5\u7a0b\u4e2d\u7684\u60a3\u8005\u51b3\u7b56\u5236\u5b9a\u3002", "conclusion": "\u795e\u7ecf\u4e3b\u9898\u5efa\u6a21\uff08\u7279\u522b\u662fBERTopic\uff09\u80fd\u591f\u4ece\u60a3\u8005\u8bbf\u8c08\u4e2d\u63d0\u53d6\u6709\u7528\u4fe1\u606f\u53cd\u9988\u7ed9\u4e34\u5e8a\u533b\u751f\uff0c\u652f\u6301\u66f4\u9ad8\u6548\u7684\u6587\u6863\u5bfc\u822a\uff0c\u5e76\u52a0\u5f3a\u60a3\u8005\u58f0\u97f3\u5728\u533b\u7597\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2601.12124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12124", "abs": "https://arxiv.org/abs/2601.12124", "authors": ["Bing Hu", "Yixin Li", "Asma Bahamyirou", "Helen Chen"], "title": "SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data", "comment": "7 Pages, 22nd Annual International Conference on Privacy, Security, and Trust (PST2025), Fredericton, Canada", "summary": "The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \\(\\ge0.97\\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP", "AI": {"tldr": "SynQP\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5408\u6210\u6570\u636e\u9690\u79c1\u98ce\u9669\u7684\u5f00\u653e\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u62df\u654f\u611f\u6570\u636e\u907f\u514d\u771f\u5b9e\u6570\u636e\u6cc4\u9732\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u8eab\u4efd\u62ab\u9732\u98ce\u9669\u5ea6\u91cf\u65b9\u6cd5\u3002", "motivation": "\u5065\u5eb7\u5e94\u7528\u4e2d\u5408\u6210\u6570\u636e\u7684\u4f7f\u7528\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\uff0c\u4f46\u7f3a\u4e4f\u5f00\u653e\u7684\u9690\u79c1\u8bc4\u4f30\u6846\u67b6\u963b\u788d\u4e86\u5176\u91c7\u7528\u3002\u4e3b\u8981\u6311\u6218\u662f\u96be\u4ee5\u83b7\u53d6\u654f\u611f\u6570\u636e\u6765\u5efa\u7acb\u53ef\u8bbf\u95ee\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165SynQP\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u62df\u654f\u611f\u6570\u636e\u8fdb\u884c\u9690\u79c1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u786e\u4fdd\u539f\u59cb\u6570\u636e\u4fdd\u5bc6\u3002\u63d0\u51fa\u65b0\u7684\u8eab\u4efd\u62ab\u9732\u98ce\u9669\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u3002", "result": "\u5728\u8d28\u91cf\u8bc4\u4f30\u4e2d\uff0c\u975e\u79c1\u6709\u6a21\u578b\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u673a\u5668\u5b66\u4e60\u6548\u80fd\uff08\u22650.97\uff09\u3002\u9690\u79c1\u8bc4\u4f30\u663e\u793a\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u6301\u7eed\u964d\u4f4e\u8eab\u4efd\u62ab\u9732\u98ce\u9669\uff08SD-IDR\uff09\u548c\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\uff08SD-MIA\uff09\uff0c\u6240\u6709DP\u589e\u5f3a\u6a21\u578b\u90fd\u4fdd\u6301\u57280.09\u76d1\u7ba1\u9608\u503c\u4ee5\u4e0b\u3002", "conclusion": "SynQP\u4e3a\u6539\u8fdb\u9690\u79c1\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\uff0c\u4f7f\u5408\u6210\u6570\u636e\u5728\u5065\u5eb7\u76f8\u5173\u5e94\u7528\u4e2d\u80fd\u591f\u66f4\u5b89\u5168\u5730\u4f7f\u7528\u3002"}}
{"id": "2601.12560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12560", "abs": "https://arxiv.org/abs/2601.12560", "authors": ["Arunkumar V", "Gangadharan G. R.", "Rajkumar Buyya"], "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "comment": "28 pages, 4 figures, 5 tables", "summary": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684Agentic AI\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u516d\u4e2a\u7ec4\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u4ece\u7ebf\u6027\u63a8\u7406\u5230\u539f\u751f\u63a8\u7406\u6a21\u578b\u7684\u8f6c\u53d8\u8d8b\u52bf\u3002", "motivation": "AI\u6b63\u4ece\u4ec5\u751f\u6210\u6587\u672c\u7684\u6a21\u578b\u8f6c\u5411Agentic AI\uff08\u667a\u80fd\u4f53AI\uff09\uff0c\u7cfb\u7edf\u4f5c\u4e3a\u81ea\u4e3b\u5b9e\u4f53\u80fd\u591f\u611f\u77e5\u3001\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u3002\u7136\u800c\uff0c\u4ece\u7b80\u5355\u7684\u5355\u5faa\u73af\u667a\u80fd\u4f53\u5230\u5206\u5c42\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5404\u79cd\u65b0\u5174\u8bbe\u8ba1\u4f7f\u5f97\u8fd9\u4e00\u9886\u57df\u96be\u4ee5\u5bfc\u822a\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e00\u5feb\u901f\u53d1\u5c55\u7684\u9886\u57df\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u667a\u80fd\u4f53\u5206\u89e3\u4e3a\u516d\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u611f\u77e5\u3001\u5927\u8111\u3001\u89c4\u5212\u3001\u884c\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u548c\u534f\u4f5c\u3002\u4f7f\u7528\u8fd9\u4e2a\u6846\u67b6\u5206\u6790\u4ece\u7ebf\u6027\u63a8\u7406\u7a0b\u5e8f\u5230\u539f\u751f\u63a8\u7406\u65f6\u95f4\u6a21\u578b\u7684\u8f6c\u53d8\uff0c\u4ee5\u53ca\u4ece\u56fa\u5b9aAPI\u8c03\u7528\u5230\u5f00\u653e\u6807\u51c6\uff08\u5982\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u548c\u539f\u751f\u8ba1\u7b97\u673a\u4f7f\u7528\uff09\u7684\u8fc7\u6e21\u3002\u540c\u65f6\u5206\u7c7b\u667a\u80fd\u4f53\u64cd\u4f5c\u73af\u5883\uff0c\u5e76\u56de\u987e\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684Agentic AI\u5206\u7c7b\u6846\u67b6\uff0c\u80fd\u591f\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u7406\u89e3\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u7684\u8bbe\u8ba1\u539f\u7406\u3002\u8bc6\u522b\u4e86\u4ece\u7ebf\u6027\u63a8\u7406\u5230\u539f\u751f\u63a8\u7406\u6a21\u578b\u7684\u91cd\u8981\u8f6c\u53d8\u8d8b\u52bf\uff0c\u4ee5\u53ca\u5de5\u5177\u4f7f\u7528\u6807\u51c6\u5316\u7684\u6f14\u8fdb\u3002\u5bf9\u667a\u80fd\u4f53\u64cd\u4f5c\u73af\u5883\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "Agentic AI\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u9762\u4e34\u5e7b\u89c9\u3001\u65e0\u9650\u5faa\u73af\u548c\u63d0\u793a\u6ce8\u5165\u7b49\u6311\u6218\u3002\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u6784\u5efa\u66f4\u7a33\u5065\u53ef\u9760\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u7edf\u4e00\u7684\u5206\u7c7b\u6846\u67b6\u4e3a\u7406\u89e3\u8fd9\u4e00\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.12341", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.HC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12341", "abs": "https://arxiv.org/abs/2601.12341", "authors": ["Rezky Kam", "Coddy N. Siswanto"], "title": "Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs", "comment": null, "summary": "This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e0e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684LLM\u60c5\u611f\u52a8\u6001\u6570\u636e\u96c6\u4e0e\u6846\u67b6\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u5bf9\u8bdd\u5efa\u6a21", "motivation": "\u73b0\u6709LLM\u5728\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u60c5\u611f\u52a8\u6001\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u7f3a\u4e4f\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u60c5\u611f\u6f14\u53d8\u5efa\u6a21\u80fd\u529b\uff0c\u9700\u8981\u66f4\u53ef\u89e3\u91ca\u7684\u60c5\u611f\u5bf9\u8bdd\u7cfb\u7edf", "method": "\u6784\u5efa\u60c5\u611f\u52a8\u6001\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINN)\u5efa\u6a21\u65f6\u95f4\u7ef4\u5ea6\u60c5\u611f\u6f14\u53d8\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u589e\u5f3aLLM\u7684\u60c5\u611f\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b", "result": "\u5efa\u7acb\u4e86\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u60c5\u611f\u52a8\u6001\u7684\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u60c5\u611f\u6f14\u53d8\u5efa\u6a21\uff0c\u4e3a\u53ef\u89e3\u91ca\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84", "conclusion": "\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e0e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u7ed3\u5408\u4e3aLLM\u60c5\u611f\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u81ea\u7136\u3001\u53ef\u89e3\u91ca\u7684\u60c5\u611f\u5bf9\u8bdd\u7cfb\u7edf"}}
{"id": "2601.12179", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12179", "abs": "https://arxiv.org/abs/2601.12179", "authors": ["Adam E. Friedman", "Stevan Harnad", "Rushen Shi"], "title": "Tolerance Principle and Small Language Model Learning", "comment": "14 pages, 6 figures. BUCLD 50 Proceedings. To be published in 2026 by Cascadilla Press", "summary": "Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0BabyBERTa\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u52a8\u6001\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\uff0c\u4e0d\u9075\u5faa\u5bb9\u5fcd\u539f\u5219\u7684\u9884\u6d4b", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u4eba\u7c7b\u5a74\u513f\u80fd\u4ece\u6781\u5c11\u793a\u4f8b\u4e2d\u5b66\u4e60\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u8bed\u6cd5\u89c4\u5219\u6240\u9700\u7684\u6700\u5c0f\u6570\u636e\u91cf\u548c\u8d28\u91cf\uff0c\u5e76\u6d4b\u8bd5\u5bb9\u5fcd\u539f\u5219\u7684\u9884\u6d4b", "method": "\u4f7f\u7528BabyBERTa\uff08\u4e13\u4e3a\u5c0f\u6570\u636e\u96c6\u4f18\u5316\u7684transformer\u6a21\u578b\uff09\u5728\u4eba\u5de5\u8bed\u6cd5\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8bad\u7ec3\u96c6\u5728\u5927\u5c0f\u3001\u72ec\u7279\u53e5\u5b50\u7c7b\u578b\u6570\u91cf\u548c\u89c4\u5219\u9075\u5faa\u4e0e\u4f8b\u5916\u793a\u4f8b\u6bd4\u4f8b\u4e0a\u6709\u6240\u4e0d\u540c", "result": "\u7814\u7a76\u53d1\u73b0BabyBERTa\u7684\u5b66\u4e60\u52a8\u6001\u4e0e\u4eba\u7c7b\u5a74\u513f\u4e0d\u540c\uff0c\u4e0d\u7b26\u5408\u5bb9\u5fcd\u539f\u5219\u7684\u9884\u6d4b", "conclusion": "\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u673a\u5236\u4e0e\u4eba\u7c7b\u5a74\u513f\u7684\u8bed\u6cd5\u5b66\u4e60\u5b58\u5728\u5dee\u5f02\uff0c\u4e0d\u9075\u5faa\u5bb9\u5fcd\u539f\u5219\u7684\u9608\u503c\u9884\u6d4b"}}
{"id": "2601.12131", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12131", "abs": "https://arxiv.org/abs/2601.12131", "authors": ["Santosh Chapagain", "MohammadReza EskandariNasab", "Onur Vural", "Shah Muhammad Hamdi", "Soukaina Filali Boubrahimi"], "title": "SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics", "comment": "This is preliminary work towards a broader SolarGPT framework", "summary": "Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.\n  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.", "AI": {"tldr": "SolarGPT-QA\u662f\u57fa\u4e8eLLaMA-3\u6784\u5efa\u7684\u9886\u57df\u81ea\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u7a7a\u95f4\u5929\u6c14\u548c\u592a\u9633\u7269\u7406\u5b66\u7684\u6559\u80b2\u95ee\u7b54\uff0c\u901a\u8fc7\u79d1\u5b66\u6587\u732e\u548cGPT-4\u751f\u6210\u7684\u6570\u636e\u8bad\u7ec3\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u592a\u9633\u6d3b\u52a8\uff08\u5982\u592a\u9633\u8000\u6591\u3001\u65e5\u5195\u7269\u8d28\u629b\u5c04\uff09\u5bf9\u536b\u661f\u3001\u7535\u7f51\u7b49\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u51c6\u786e\u9884\u6d4b\u548c\u6709\u6548\u6559\u80b2\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u548c\u6559\u5b66\u80fd\u529b\u6765\u6e05\u6670\u89e3\u91ca\u590d\u6742\u7684\u7a7a\u95f4\u79d1\u5b66\u6982\u5ff5\u3002", "method": "\u57fa\u4e8eLLaMA-3\u57fa\u7840\u6a21\u578b\u6784\u5efaSolarGPT-QA\u95ee\u7b54\u7cfb\u7edf\uff0c\u4f7f\u7528\u79d1\u5b66\u6587\u732e\u548c\u5927\u89c4\u6a21\u95ee\u7b54\u6570\u636e\u8fdb\u884c\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\uff0c\u6570\u636e\u7531GPT-4\u751f\u6210\u5e76\u901a\u8fc7Grok-3\u4ee5\u5b66\u751f\u53cb\u597d\u7684\u6545\u4e8b\u5316\u98ce\u683c\u7cbe\u70bc\u3002\u7ed3\u5408\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u548c\u6559\u5b66\u5fae\u8c03\u3002", "result": "\u4eba\u5de5\u6210\u5bf9\u8bc4\u4f30\u663e\u793a\uff0cSolarGPT-QA\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5728\u6559\u5b66\u89e3\u91ca\u65b9\u9762\u4e0e\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u7ade\u4e89\u3002\u5c0f\u578b\u5b66\u751f\u7406\u89e3\u7814\u7a76\u8868\u660e\u751f\u6210\u89e3\u91ca\u7684\u6e05\u6670\u5ea6\u548c\u53ef\u8bbf\u95ee\u6027\u6709\u6240\u6539\u5584\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u7ed3\u5408\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u548c\u6559\u5b66\u5fae\u8c03\u5bf9\u5e73\u8861\u79d1\u5b66\u51c6\u786e\u6027\u548c\u6559\u5b66\u6548\u679c\u5f88\u91cd\u8981\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u8fc8\u5411\u66f4\u5e7f\u6cdb\u7684SolarGPT\u6846\u67b6\u7528\u4e8e\u7a7a\u95f4\u79d1\u5b66\u6559\u80b2\u548c\u9884\u6d4b\u7684\u521d\u6b65\u6b65\u9aa4\uff0c\u5c55\u793a\u4e86\u9886\u57df\u81ea\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12641", "abs": "https://arxiv.org/abs/2601.12641", "authors": ["Xiangyu Shi", "Junyang Ding", "Xu Zhao", "Sinong Zhan", "Payal Mohapatra", "Daniel Quispe", "Kojo Welbeck", "Jian Cao", "Wei Chen", "Ping Guo", "Qi Zhu"], "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models", "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026", "summary": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.", "AI": {"tldr": "STEP-LLM\uff1a\u9996\u4e2a\u901a\u8fc7LLM\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210STEP\u683c\u5f0fCAD\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7DFS\u91cd\u5e8f\u5217\u5316\u3001RAG\u548cRL\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u51e0\u4f55\u4fdd\u771f\u5ea6", "motivation": "CAD\u8bbe\u8ba1\u5bf9\u975e\u4e13\u5bb6\u95e8\u69db\u9ad8\uff0c\u73b0\u6709\u6587\u672c\u8f6cCAD\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u5185\u6838\u683c\u5f0f\uff0c\u7f3a\u4e4f\u5236\u9020\u901a\u7528\u6027\u3002STEP\u4f5c\u4e3a\u5e7f\u6cdb\u91c7\u7528\u7684\u4e2d\u6027\u8fb9\u754c\u8868\u793a\u683c\u5f0f\uff0c\u5176\u56fe\u7ed3\u6784\u7279\u6027\u5bf9\u81ea\u56de\u5f52LLM\u6784\u6210\u6311\u6218", "method": "1) \u6784\u5efa4\u4e07STEP-\u6587\u672c\u5bf9\u6570\u636e\u96c6\uff1b2) DFS\u91cd\u5e8f\u5217\u5316\u7ebf\u6027\u5316\u4ea4\u53c9\u5f15\u7528\uff1b3) CoT\u98ce\u683c\u7ed3\u6784\u6ce8\u91ca\uff1b4) \u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u76d1\u7763\u5fae\u8c03\uff1b5) Chamfer\u8ddd\u79bb\u51e0\u4f55\u5956\u52b1\u5f3a\u5316\u5b66\u4e60", "result": "STEP-LLM\u5728\u51e0\u4f55\u4fdd\u771f\u5ea6\u4e0a\u4e00\u81f4\u4f18\u4e8eText2CAD\u57fa\u7ebf\uff1aRAG\u663e\u8457\u63d0\u5347\u5b8c\u6574\u6027\u548c\u53ef\u6e32\u67d3\u6027\uff0cDFS\u91cd\u5e8f\u5217\u5316\u589e\u5f3a\u6574\u4f53\u7cbe\u5ea6\uff0cRL\u8fdb\u4e00\u6b65\u51cf\u5c11\u51e0\u4f55\u5dee\u5f02", "conclusion": "\u8bc1\u660e\u4e86LLM\u9a71\u52a8STEP\u6a21\u578b\u751f\u6210\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5236\u9020\u9886\u57df\u7684CAD\u8bbe\u8ba1\u6c11\u4e3b\u5316\u5c55\u793a\u4e86\u6f5c\u529b\uff0c\u4e3a\u56fe\u7ed3\u6784\u683c\u5f0f\u7684LLM\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2601.12699", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12699", "abs": "https://arxiv.org/abs/2601.12699", "authors": ["Arkaprava Gupta", "Nicholas Carter", "William Zellers", "Prateek Ganguli", "Benedikt Dietrich", "Vibhor Krishna", "Parasara Sridhar Duggirala", "Samarjit Chakraborty"], "title": "Resource-Conscious RL Algorithms for Deep Brain Stimulation", "comment": null, "summary": "Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.\n  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.", "AI": {"tldr": "\u63d0\u51faT3P MAB\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u81ea\u9002\u5e94\u6df1\u90e8\u8111\u523a\u6fc0\uff0c\u80fd\u540c\u65f6\u8c03\u8282\u9891\u7387\u548c\u632f\u5e45\uff0c\u8f7b\u91cf\u7ea7\u9002\u5408\u690d\u5165\u8bbe\u5907\u90e8\u7f72\uff0c\u65e0\u9700\u79bb\u7ebf\u8bad\u7ec3\uff0c\u529f\u8017\u4f4e\u3002", "motivation": "\u4f20\u7edfDBS\u4f7f\u7528\u56fa\u5b9a\u9891\u7387\u548c\u632f\u5e45\uff0c\u5b58\u5728\u526f\u4f5c\u7528\uff08\u5982\u8a00\u8bed\u4e0d\u6e05\uff09\u548c\u7535\u6c60\u5bff\u547d\u77ed\u7684\u95ee\u9898\u3002\u73b0\u6709RL\u65b9\u6cd5\u590d\u6742\uff0c\u9700\u8981\u957f\u65f6\u95f4\u6536\u655b\u548c\u9ad8\u8ba1\u7b97\u8d44\u6e90\uff0c\u65e0\u6cd5\u5728\u4f53\u5185\u8bad\u7ec3\uff0c\u4e14\u5927\u591a\u53ea\u8c03\u8282\u5355\u4e00\u53c2\u6570\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u4e0e\u9608\u503c\u89e6\u53d1\u7684\u591a\u81c2\u8d4c\u535a\u673a\uff08T3P MAB\uff09\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8f7b\u91cf\u7ea7\u7b97\u6cd5\u53ef\u90e8\u7f72\u5728\u5fae\u63a7\u5236\u5668\u5355\u5143\u4e0a\uff0c\u80fd\u540c\u65f6\u8c03\u8282DBS\u7684\u9891\u7387\u548c\u632f\u5e45\u53c2\u6570\u3002", "result": "T3P MAB\u7b97\u6cd5\u6837\u672c\u6548\u7387\u9ad8\uff0c\u6536\u655b\u65f6\u95f4\u77ed\uff0c\u9996\u6b21\u5728\u786c\u4ef6\u4e0a\u5b9e\u73b0\u5e76\u62a5\u544a\u80fd\u8017\u6d4b\u91cf\uff0c\u8bc1\u660e\u9002\u5408\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\uff0c\u529f\u8017\u663e\u8457\u4f4e\u4e8e\u73b0\u6709RL\u65b9\u6cd5\u3002", "conclusion": "T3P MAB\u65b9\u6cd5\u4e3aDBS\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u81ea\u9002\u5e94\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u540c\u65f6\u4f18\u5316\u9891\u7387\u548c\u632f\u5e45\uff0c\u9002\u5408\u690d\u5165\u8bbe\u5907\u90e8\u7f72\uff0c\u6709\u671b\u6539\u5584\u5e15\u91d1\u68ee\u75c5\u60a3\u8005\u6cbb\u7597\u6548\u679c\u5e76\u5ef6\u957f\u7535\u6c60\u5bff\u547d\u3002"}}
{"id": "2601.12199", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12199", "abs": "https://arxiv.org/abs/2601.12199", "authors": ["Muhammad Umar Farooq", "Oscar Saz"], "title": "CTC-DID: CTC-Based Arabic dialect identification for streaming applications", "comment": "Accepted for IEEE ICASSP 2026", "summary": "This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCTC\u635f\u5931\u51fd\u6570\u7684\u65b9\u8a00\u8bc6\u522b\u65b9\u6cd5\uff0c\u5c06\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u5efa\u6a21\u4e3a\u6709\u9650\u8bcd\u6c47\u7684\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\uff0c\u5728\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b", "motivation": "\u4f20\u7edf\u65b9\u8a00\u8bc6\u522b\u65b9\u6cd5\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u573a\u666f\u548c\u77ed\u8bed\u97f3\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u4e14\u9002\u5e94\u5b9e\u65f6\u5e94\u7528\u7684\u65b9\u6cd5", "method": "\u5c06\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u6784\u5efa\u4e3a\u6709\u9650\u8bcd\u6c47\u7684ASR\u7cfb\u7edf\uff0c\u4f7f\u7528CTC\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u8bed\u8a00\u65e0\u5173\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u9884\u8bad\u7ec3ASR\u6a21\u578b\u4f30\u8ba1\u65b9\u8a00\u6807\u7b7e\u5728\u8f6c\u5f55\u4e2d\u7684\u91cd\u590d\u6b21\u6570", "result": "\u5728\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8eSSL\u7684CTC-DID\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u6027\u80fd\u4f18\u4e8e\u5fae\u8c03\u7684Whisper\u548cECAPA-TDNN\u6a21\u578b\uff0c\u5728Casablanca\u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u4e5f\u8868\u73b0\u66f4\u597d\uff0c\u5bf9\u77ed\u8bed\u97f3\u66f4\u9c81\u68d2\u4e14\u6613\u4e8e\u9002\u914d\u6d41\u5f0f\u5b9e\u65f6\u5e94\u7528", "conclusion": "CTC-DID\u65b9\u6cd5\u4e3a\u65b9\u8a00\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u4f4e\u8d44\u6e90\u573a\u666f\u548c\u5b9e\u65f6\u5e94\u7528\uff0c\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2601.12137", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12137", "abs": "https://arxiv.org/abs/2601.12137", "authors": ["Anzhe Cheng", "Shukai Duan", "Shixuan Li", "Chenzhong Yin", "Mingxi Cheng", "Shahin Nazarian", "Paul Thompson", "Paul Bogdan"], "title": "EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts", "comment": "accepted by ICASSP2026", "summary": "The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer\" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.", "AI": {"tldr": "\u63d0\u51faEMoE\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u8def\u7531\u673a\u5236\uff0c\u540c\u65f6\u89e3\u51b3MoE\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u548c\u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u7684\u8d1f\u8f7d\u5747\u8861\u635f\u5931\u51fd\u6570\u3002", "motivation": "MoE\u67b6\u6784\u867d\u7136\u80fd\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u95ee\u9898\uff1a1) \"\u5bcc\u8005\u6108\u5bcc\"\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5c11\u6570\u4e13\u5bb6\u88ab\u8fc7\u5ea6\u4f7f\u7528\uff1b2) \u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u4e13\u5bb6\u5b66\u4e60\u5197\u4f59\u8868\u793a\uff0c\u5931\u53bb\u4e13\u4e1a\u5316\u610f\u4e49\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f7f\u7528\u8f85\u52a9\u8d1f\u8f7d\u5747\u8861\u635f\u5931\uff0c\u4f46\u8fd9\u5f80\u5f80\u4ee5\u727a\u7272\u4e13\u4e1a\u5316\u4e3a\u4ee3\u4ef7\u52a0\u5267\u540c\u8d28\u5316\u3002", "method": "\u63d0\u51faEigen-Mixture-of-Experts (EMoE)\u67b6\u6784\uff0c\u91c7\u7528\u57fa\u4e8e\u5b66\u4e60\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u8def\u7531\u673a\u5236\u3002\u5c06\u8f93\u5165token\u6295\u5f71\u5230\u8fd9\u4e2a\u5171\u4eab\u7684\u7279\u5f81\u57fa\u4e0a\uff0c\u6839\u636e\u5b83\u4eec\u4e0e\u7279\u5f81\u7a7a\u95f4\u4e3b\u6210\u5206\u7684\u5bf9\u9f50\u7a0b\u5ea6\u8fdb\u884c\u8def\u7531\u3002\u8fd9\u79cd\u57fa\u4e8e\u51e0\u4f55\u7684\u6570\u636e\u5212\u5206\u65b9\u6cd5\u672c\u8d28\u4e0a\u4fc3\u8fdb\u4e86\u5e73\u8861\u7684\u4e13\u5bb6\u5229\u7528\u548c\u591a\u6837\u5316\u3001\u4e13\u4e1a\u5316\u4e13\u5bb6\u7684\u5f00\u53d1\u3002", "result": "EMoE\u80fd\u591f\u540c\u65f6\u4fc3\u8fdb\u4e13\u5bb6\u5229\u7528\u7684\u5e73\u8861\u548c\u591a\u6837\u5316\u3001\u4e13\u4e1a\u5316\u4e13\u5bb6\u7684\u5f00\u53d1\uff0c\u65e0\u9700\u4f7f\u7528\u51b2\u7a81\u7684\u8f85\u52a9\u635f\u5931\u51fd\u6570\u3002\u4ee3\u7801\u5df2\u516c\u5f00\u5728GitHub\u4e0a\u3002", "conclusion": "EMoE\u901a\u8fc7\u57fa\u4e8e\u6b63\u4ea4\u7279\u5f81\u57fa\u7684\u51e0\u4f55\u8def\u7531\u673a\u5236\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86MoE\u67b6\u6784\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u548c\u4e13\u5bb6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u635f\u5931\u51fd\u6570\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12661", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12661", "abs": "https://arxiv.org/abs/2601.12661", "authors": ["Chuhan Qiao", "Jianghua Huang", "Daxing Zhao", "Ziding Liu", "Yanjun Shen", "Bing Cheng", "Wei Lin", "Kai Wu"], "title": "MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents", "comment": null, "summary": "Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.", "AI": {"tldr": "MedConsultBench\u662f\u4e00\u4e2a\u5168\u9762\u7684\u533b\u5b66\u54a8\u8be2\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u8986\u76d6\u5b8c\u6574\u7684\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff08\u4ece\u75c5\u53f2\u91c7\u96c6\u5230\u968f\u8bbf\u95ee\u7b54\uff09\u6765\u8bc4\u4f30\u5728\u7ebf\u54a8\u8be2\u4ee3\u7406\uff0c\u4f7f\u7528\u539f\u5b50\u4fe1\u606f\u5355\u5143\uff08AIUs\uff09\u8ffd\u8e2a\u4e34\u5e8a\u4fe1\u606f\u83b7\u53d6\uff0c\u5e76\u63ed\u793a\u4e86\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u80cc\u540e\u5b58\u5728\u7684\u4fe1\u606f\u6536\u96c6\u6548\u7387\u548c\u7528\u836f\u5b89\u5168\u7f3a\u9677\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u54a8\u8be2\u4ee3\u7406\u7684\u8bc4\u4f30\u8fc7\u4e8e\u6ce8\u91cd\u7ed3\u679c\u5bfc\u5411\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u7aef\u5230\u7aef\u6d41\u7a0b\u5b8c\u6574\u6027\u548c\u4e34\u5e8a\u5b89\u5168\u6027\uff0c\u73b0\u6709\u4ea4\u4e92\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u788e\u7247\u5316\u4e14\u7c97\u7c92\u5ea6\uff0c\u65e0\u6cd5\u6355\u6349\u4e13\u4e1a\u54a8\u8be2\u6240\u9700\u7684\u7ed3\u6784\u5316\u8be2\u95ee\u903b\u8f91\u548c\u8bca\u65ad\u4e25\u8c28\u6027\u3002", "method": "\u63d0\u51faMedConsultBench\u6846\u67b6\uff0c\u8986\u76d6\u5b8c\u6574\u7684\u5728\u7ebf\u54a8\u8be2\u5468\u671f\uff08\u75c5\u53f2\u91c7\u96c6\u3001\u8bca\u65ad\u3001\u6cbb\u7597\u8ba1\u5212\u3001\u968f\u8bbf\u95ee\u7b54\uff09\uff1b\u5f15\u5165\u539f\u5b50\u4fe1\u606f\u5355\u5143\uff08AIUs\uff09\u5728\u5b50\u8f6e\u6b21\u5c42\u9762\u8ffd\u8e2a\u4e34\u5e8a\u4fe1\u606f\u83b7\u53d6\uff1b\u901a\u8fc722\u4e2a\u7ec6\u7c92\u5ea6\u6307\u6807\u8bc4\u4f30\u5173\u952e\u4e8b\u5b9e\u7684\u83b7\u53d6\u65b9\u5f0f\uff1b\u5904\u7406\u5728\u7ebf\u54a8\u8be2\u4e2d\u7684\u4e0d\u660e\u786e\u6027\u548c\u6a21\u7cca\u6027\uff0c\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u7b80\u6d01\u8be2\u95ee\uff1b\u5f3a\u8c03\u7528\u836f\u65b9\u6848\u517c\u5bb9\u6027\u548c\u5904\u7406\u73b0\u5b9e\u5904\u65b9\u540e\u968f\u8bbf\u95ee\u7b54\u7684\u80fd\u529b\u3002", "result": "\u5bf919\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\uff0c\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u5f80\u5f80\u63a9\u76d6\u4e86\u4fe1\u606f\u6536\u96c6\u6548\u7387\u548c\u7528\u836f\u5b89\u5168\u65b9\u9762\u7684\u663e\u8457\u7f3a\u9677\uff0c\u63ed\u793a\u4e86\u7406\u8bba\u533b\u5b66\u77e5\u8bc6\u4e0e\u4e34\u5e8a\u5b9e\u8df5\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "MedConsultBench\u4e3a\u5c06\u533b\u5b66AI\u4e0e\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u62a4\u7406\u7684\u7ec6\u5fae\u8981\u6c42\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u8d85\u8d8a\u5355\u7eaf\u8bca\u65ad\u51c6\u786e\u6027\u6765\u8bc4\u4f30\u533b\u5b66\u54a8\u8be2\u4ee3\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13357", "categories": ["cs.LG", "cs.CL", "eess.AS", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13357", "abs": "https://arxiv.org/abs/2601.13357", "authors": ["Aydin Ghojogh", "M. Hadi Sepanj", "Benyamin Ghojogh"], "title": "On the Relation of State Space Models and Hidden Markov Models", "comment": null, "summary": "State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.\n  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u3001\u7ebf\u6027\u9ad8\u65af\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u73b0\u4ee3NLP\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u6982\u7387\u56fe\u6a21\u578b\u6846\u67b6\u4e0b\u7684\u5f02\u540c\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f20\u7edf\u6982\u7387\u6a21\u578b\u4e0e\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u662f\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u7684\u57fa\u7840\u6846\u67b6\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4fe1\u53f7\u5904\u7406\u3001\u63a7\u5236\u7406\u8bba\u548c\u673a\u5668\u5b66\u4e60\u3002\u5c3d\u7ba1\u5b83\u4eec\u5177\u6709\u76f8\u4f3c\u7684\u65f6\u5e8f\u7ed3\u6784\uff0c\u4f46\u5728\u6f5c\u5728\u72b6\u6001\u6027\u8d28\u3001\u6982\u7387\u5047\u8bbe\u3001\u63a8\u7406\u8fc7\u7a0b\u548c\u8bad\u7ec3\u8303\u5f0f\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02\u3002\u8fd1\u5e74\u6765\uff0c\u786e\u5b9a\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u901a\u8fc7S4\u548cMamba\u7b49\u67b6\u6784\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u91cd\u65b0\u5174\u8d77\uff0c\u8fd9\u5f15\u53d1\u4e86\u5173\u4e8e\u7ecf\u5178\u6982\u7387SSMs\u3001HMMs\u548c\u73b0\u4ee3\u795e\u7ecf\u5e8f\u5217\u6a21\u578b\u4e4b\u95f4\u5173\u7cfb\u7684\u65b0\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6982\u7387\u56fe\u6a21\u578b\u7684\u89c6\u89d2\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u7684\u516c\u5f0f\u5316\u8868\u8fbe\uff0c\u68c0\u67e5\u5b83\u4eec\u7684\u63a8\u7406\u7b97\u6cd5\uff08\u5305\u62ec\u524d\u5411\u540e\u5411\u63a8\u7406\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\uff09\uff0c\u5e76\u5bf9\u6bd4\u5b83\u4eec\u7684\u5b66\u4e60\u8fc7\u7a0b\uff08\u901a\u8fc7\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\uff09\u3002\u7cfb\u7edf\u6bd4\u8f83HMMs\u3001\u7ebf\u6027\u9ad8\u65af\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\u548c\u5f53\u4ee3NLP\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u7a81\u51fa\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u8bed\u4e49\u5dee\u5f02\uff0c\u9610\u660e\u4e86\u8fd9\u4e9b\u6a21\u578b\u4f55\u65f6\u7b49\u4ef7\u3001\u4f55\u65f6\u6839\u672c\u4e0d\u540c\uff0c\u4ee5\u53ca\u73b0\u4ee3NLP SSMs\u5982\u4f55\u4e0e\u7ecf\u5178\u6982\u7387\u6a21\u578b\u76f8\u5173\u8054\u3002\u5206\u6790\u7ed3\u679c\u8fde\u63a5\u4e86\u63a7\u5236\u7406\u8bba\u3001\u6982\u7387\u5efa\u6a21\u548c\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u7684\u89c6\u89d2\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7406\u89e3\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5bb6\u65cf\u4e2d\u7684\u4e0d\u540c\u53d8\u4f53\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3a\u5728\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.12208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12208", "abs": "https://arxiv.org/abs/2601.12208", "authors": ["Yunzhe Li", "Richie Yueqi Feng", "Tianxin Wei", "Chin-Chia Hsu"], "title": "CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement", "comment": null, "summary": "Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.", "AI": {"tldr": "CoReflect\uff1a\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u6a21\u62df\u548c\u53cd\u601d\u6027\u8bc4\u4f30\u6807\u51c6\u4f18\u5316\uff0c\u5b9e\u73b0\u5bf9\u8bdd\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u8fed\u4ee3\u8bc4\u4f30\u6846\u67b6", "motivation": "\u4f20\u7edf\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u7684\u56fa\u5b9a\u8bc4\u4f30\u6807\u51c6\u548c\u9759\u6001\u5bf9\u8bdd\u4e0a\u4e0b\u6587\uff0c\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u65e0\u6cd5\u6355\u6349\u5bf9\u8bdd\u6a21\u578b\u591a\u6837\u5316\u7684\u6d8c\u73b0\u884c\u4e3a\uff0c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684\u5bf9\u8bdd\u6a21\u578b\u80fd\u529b", "method": "CoReflect\u91c7\u7528\u534f\u540c\u8fdb\u5316\u5faa\u73af\uff1a1) \u5bf9\u8bdd\u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u5316\u6a21\u677f\u6307\u5bfc\u7528\u6237\u6a21\u62df\u5668\u8fdb\u884c\u591a\u6837\u5316\u76ee\u6807\u5bfc\u5411\u5bf9\u8bdd\uff1b2) \u53cd\u601d\u5206\u6790\u5668\u5904\u7406\u5bf9\u8bdd\uff0c\u8bc6\u522b\u7cfb\u7edf\u884c\u4e3a\u6a21\u5f0f\u5e76\u81ea\u52a8\u4f18\u5316\u8bc4\u4f30\u6807\u51c6\uff1b3) \u5206\u6790\u7ed3\u679c\u53cd\u9988\u7ed9\u89c4\u5212\u5668\u66f4\u65b0\u5bf9\u8bdd\u6a21\u677f\uff0c\u5f62\u6210\u6d4b\u8bd5\u7528\u4f8b\u590d\u6742\u5ea6\u548c\u8bc4\u4f30\u6807\u51c6\u8bca\u65ad\u7cbe\u5ea6\u534f\u540c\u63d0\u5347\u7684\u5faa\u73af", "result": "CoReflect\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u81ea\u6211\u4f18\u5316\u7684\u65b9\u6cd5\u8bba\uff0c\u6700\u5c0f\u5316\u4eba\u5de5\u5e72\u9884\uff0c\u4f7f\u8bc4\u4f30\u534f\u8bae\u80fd\u591f\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684\u5bf9\u8bdd\u6a21\u578b\u80fd\u529b", "conclusion": "CoReflect\u901a\u8fc7\u7edf\u4e00\u5bf9\u8bdd\u6a21\u62df\u548c\u8bc4\u4f30\u7684\u81ea\u9002\u5e94\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u591a\u8f6e\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u57fa\u672c\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6d4b\u8bd5\u7528\u4f8b\u548c\u8bc4\u4f30\u6807\u51c6\u7684\u534f\u540c\u8fdb\u5316"}}
{"id": "2601.12145", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12145", "abs": "https://arxiv.org/abs/2601.12145", "authors": ["Xingyue Huang", "Xueying Ding", "Mingxuan Ju", "Yozen Liu", "Neil Shah", "Tong Zhao"], "title": "Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling", "comment": null, "summary": "Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.", "AI": {"tldr": "TDA\u662f\u4e00\u79cd\u65e0\u6ce8\u610f\u529b\u6c89\u6ca1\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u9608\u503c\u5dee\u5206\u65b9\u6cd5\u89e3\u51b3Softmax\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u7ed3\u6784\u9650\u5236\u95ee\u9898\uff0c\u5b9e\u73b0\u8d85\u7a00\u758f\u6027\u548c\u66f4\u597d\u7684\u957f\u5e8f\u5217\u9c81\u68d2\u6027\u3002", "motivation": "Softmax\u6ce8\u610f\u529b\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u5b58\u5728\u7ed3\u6784\u9650\u5236\uff1a\u4e25\u683c\u7684\u5f52\u4e00\u5316\u7ea6\u675f\u5bfc\u81f4\u6ce8\u610f\u529b\u6c89\u6ca1\u5728\u65e0\u5173token\u4e0a\uff0c\u4e14\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u6982\u7387\u8d28\u91cf\u5206\u6563\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u8981\u4e48\u56e0\u566a\u58f0\u79ef\u7d2f\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u9608\u503c\u5dee\u5206\u6ce8\u610f\u529b(TDA)\uff1a1) \u4f7f\u7528\u957f\u5ea6\u4f9d\u8d56\u95e8\u63a7\u7684\u884c\u7ea7\u6781\u503c\u9608\u503c\u5316\uff0c\u4ec5\u4fdd\u7559\u8d85\u8fc7\u9608\u503c\u7684\u503c\uff1b2) \u501f\u9274\u5dee\u5206transformer\u601d\u60f3\uff0c\u51cf\u53bb\u6291\u5236\u89c6\u56fe\u4ee5\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1aTDA\u63a7\u5236\u6bcf\u884c\u4f2a\u5e78\u5b58\u8005\u671f\u671b\u4e3aO(1)\uff0c\u4e14\u72ec\u7acb\u89c6\u56fe\u95f4\u7684\u5171\u8bc6\u4f2a\u5339\u914d\u968f\u4e0a\u4e0b\u6587\u589e\u957f\u800c\u6d88\u5931\u3002\u5b9e\u8bc1\u7ed3\u679c\uff1aTDA\u4ea7\u751f>99%\u7684\u7cbe\u786e\u96f6\u503c\uff0c\u6d88\u9664\u6ce8\u610f\u529b\u6c89\u6ca1\uff0c\u5728\u6807\u51c6\u548c\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "TDA\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u6c89\u6ca1\u6ce8\u610f\u529b\u673a\u5236\uff0c\u89e3\u51b3\u4e86Softmax\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u7ed3\u6784\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u8d85\u7a00\u758f\u6027\u548c\u66f4\u597d\u7684\u957f\u5e8f\u5217\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.12667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12667", "abs": "https://arxiv.org/abs/2601.12667", "authors": ["Yi Di", "Zhibin Zhao", "Fujin Wang", "Xue Liu", "Jiafeng Tang", "Jiaxin Ren", "Zhi Zhai", "Xuefeng Chen"], "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration", "comment": null, "summary": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.", "AI": {"tldr": "\u63d0\u51faSpaceHMchat\u6846\u67b6\uff0c\u7528\u4e8e\u536b\u661f\u5de8\u578b\u661f\u5ea7\u65f6\u4ee3\u7684\u822a\u5929\u5668\u7535\u6e90\u7cfb\u7edf\u5065\u5eb7\u7ba1\u7406\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u5b9e\u73b0\u5168\u56de\u8def\u5065\u5eb7\u7ba1\u7406\uff0c\u5e76\u5728\u786c\u4ef6\u771f\u5b9e\u6545\u969c\u6ce8\u5165\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u536b\u661f\u5de8\u578b\u661f\u5ea7\u65f6\u4ee3\u7684\u5230\u6765\uff0c\u822a\u5929\u5668\u6570\u91cf\u5c06\u6307\u6570\u589e\u957f\uff0c\u800c\u822a\u5929\u5668\u7535\u6e90\u7cfb\u7edf\u4f5c\u4e3a\u5173\u952e\u5b50\u7cfb\u7edf\u6545\u969c\u7387\u9ad8\uff0c\u9700\u8981\u9002\u5e94\u4ece\u51e0\u5341\u4e2a\u5230\u6570\u5343\u4e2a\u7535\u6e90\u7cfb\u7edf\u7684\u5065\u5eb7\u7ba1\u7406\u8303\u5f0f\u8f6c\u53d8\u3002", "method": "\u63d0\u51fa\u5bf9\u9f50\u5e95\u5c42\u80fd\u529b\u539f\u5219\uff0c\u5f00\u53d1\u5f00\u6e90\u4eba\u673a\u534f\u4f5c\u6846\u67b6SpaceHMchat\uff0c\u5b9e\u73b0\u5de5\u4f5c\u72b6\u6001\u8bc6\u522b\u3001\u5f02\u5e38\u68c0\u6d4b\u3001\u6545\u969c\u5b9a\u4f4d\u548c\u7ef4\u62a4\u51b3\u7b56\u7684\u5168\u56de\u8def\u7ba1\u7406\uff0c\u5e76\u5efa\u7acb\u786c\u4ef6\u771f\u5b9e\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\u5e73\u53f0\u548c\u4eff\u771f\u6a21\u578b\u3002", "result": "SpaceHMchat\u572823\u4e2a\u91cf\u5316\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u5de5\u4f5c\u72b6\u6001\u8bc6\u522b\u903b\u8f91\u63a8\u7406\u7ed3\u8bba\u51c6\u786e\u7387100%\uff0c\u5f02\u5e38\u68c0\u6d4b\u5de5\u5177\u8c03\u7528\u6210\u529f\u7387\u8d8599%\uff0c\u6545\u969c\u5b9a\u4f4d\u7cbe\u5ea6\u8d8590%\uff0c\u7ef4\u62a4\u51b3\u7b56\u77e5\u8bc6\u5e93\u641c\u7d22\u65f6\u95f4\u4f4e\u4e8e3\u5206\u949f\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u9996\u4e2a\u822a\u5929\u5668\u7535\u6e90\u7cfb\u7edf\u5168\u56de\u8def\u5065\u5eb7\u7ba1\u7406\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u536b\u661f\u5de8\u578b\u661f\u5ea7\u65f6\u4ee3\u7684\u822a\u5929\u5668\u7535\u6e90\u7cfb\u7edf\u5065\u5eb7\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u900f\u660e\u7684\u5065\u5eb7\u7ba1\u7406\uff0c\u76f8\u5173\u5e73\u53f0\u548c\u6570\u636e\u96c6\u7684\u5f00\u6e90\u5c06\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2601.12247", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12247", "abs": "https://arxiv.org/abs/2601.12247", "authors": ["Miao Li", "Hanyang Jiang", "Sikai Chen", "Hengyu Fu", "Yuhang Cai", "Baihe Huang", "Tinghan Ye", "Xuanzhou Chen", "Pascal Van Hentenryck"], "title": "Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.", "AI": {"tldr": "PVF\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u89e3\u7801\u8303\u5f0f\uff0c\u901a\u8fc7\u89c4\u5212-\u9a8c\u8bc1-\u586b\u5145\u673a\u5236\uff0c\u5229\u7528\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u4e3b\u52a8\u6784\u5efa\u5c42\u6b21\u5316\u9aa8\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u7b56\u7565\u5f80\u5f80\u662f\u88ab\u52a8\u53cd\u5e94\u5f0f\u7684\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u6765\u6307\u5bfc\u5168\u5c40\u8f68\u8ff9\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faPlan-Verify-Fill\uff08PVF\uff09\u8303\u5f0f\uff1a1\uff09\u4e3b\u52a8\u6784\u5efa\u5c42\u6b21\u5316\u9aa8\u67b6\uff0c\u4f18\u5148\u8003\u8651\u9ad8\u5f71\u54cd\u529b\u7684\u8bed\u4e49\u951a\u70b9\uff1b2\uff09\u91c7\u7528\u9a8c\u8bc1\u534f\u8bae\u5b9e\u73b0\u5b9e\u7528\u7ed3\u6784\u505c\u6b62\uff0c\u5f53\u8fdb\u4e00\u6b65\u601d\u8003\u6536\u76ca\u9012\u51cf\u65f6\u505c\u6b62\uff1b3\uff09\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5728LLaDA-8B-Instruct\u548cDream-7B-Instruct\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cPVF\u76f8\u6bd4\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5e76\u884c\u89e3\u7801\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6700\u591a\u51cf\u5c1165%\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff0c\u5728\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7387\u3002", "conclusion": "PVF\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u975e\u987a\u5e8f\u89e3\u7801\u8303\u5f0f\uff0c\u901a\u8fc7\u4e3b\u52a8\u89c4\u5212\u548c\u9a8c\u8bc1\u673a\u5236\u663e\u8457\u63d0\u5347\u751f\u6210\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5229\u7528\u5168\u5c40\u4e0a\u4e0b\u6587\u6307\u5bfc\u6587\u672c\u751f\u6210\u8f68\u8ff9\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12688", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12688", "abs": "https://arxiv.org/abs/2601.12688", "authors": ["Xu Zhang", "Qinghua Wang", "Mengyang Zhao", "Fang Wang", "Cunquan Qu"], "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction", "comment": null, "summary": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.", "AI": {"tldr": "\u63d0\u51faMMSI\u6846\u67b6\uff0c\u5c06\u91cf\u5211\u903b\u8f91\u878d\u5165Transformer\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5b9a\u5411\u63a9\u7801\u673a\u5236\u6f84\u6e05\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u7684\u89d2\u8272\uff0c\u63d0\u9ad8AI\u8f85\u52a9\u53f8\u6cd5\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u8d23\u4efb\u5206\u914d\u590d\u6742\uff0c\u53f8\u6cd5\u8868\u8ff0\u5e38\u6a21\u7cca\u88ab\u544a\u89d2\u8272\uff0c\u963b\u788dAI\u5206\u6790\u3002\u9700\u8981\u7cbe\u786e\u533a\u5206\u4e3b\u4ece\u72af\u8d23\u4efb\uff0c\u63d0\u5347\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6cd5\u5f8b\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u63a9\u7801\u591a\u9636\u6bb5\u63a8\u7406\uff08MMSI\uff09\u6846\u67b6\uff1a1\uff09\u5c06\u91cf\u5211\u903b\u8f91\u878d\u5165\u9884\u8bad\u7ec3Transformer\u7f16\u7801\u5668\uff1b2\uff09\u5b9a\u5411\u63a9\u7801\u673a\u5236\u6f84\u6e05\u88ab\u544a\u89d2\u8272\uff1b3\uff09\u6bd4\u8f83\u6570\u636e\u6784\u5efa\u7b56\u7565\u589e\u5f3a\u6a21\u578b\u5bf9\u4e3b\u4ece\u72af\u8d23\u4efb\u5dee\u5f02\u7684\u654f\u611f\u6027\uff1b4\uff09\u901a\u8fc7\u5e7f\u64ad\u5c06\u9884\u6d4b\u7684\u7f6a\u540d\u6807\u7b7e\u878d\u5165\u56de\u5f52\u6a21\u578b\uff0c\u6574\u5408\u72af\u7f6a\u63cf\u8ff0\u548c\u6cd5\u5ead\u89c2\u70b9\u3002", "result": "\u5728\u81ea\u5b9a\u4e49\u7684IMLJP\u6545\u610f\u4f24\u5bb3\u6848\u4ef6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cMMSI\u6846\u67b6\u5728\u89d2\u8272\u8d23\u4efb\u533a\u5206\u65b9\u9762\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u589e\u5f3a\u667a\u80fd\u53f8\u6cd5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7a33\u5065\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u6f84\u6e05\u591a\u88ab\u544a\u6848\u4ef6\u4e2d\u7684\u89d2\u8272\u8d23\u4efb\uff0c\u63d0\u9ad8AI\u8f85\u52a9\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6cd5\u5f8b\u53ef\u89e3\u91ca\u6027\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2601.12263", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12263", "abs": "https://arxiv.org/abs/2601.12263", "authors": ["Yixuan Du", "Chenxiao Yu", "Haoyan Xu", "Ziyi Wang", "Yue Zhao", "Xiyang Hu"], "title": "Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers", "comment": null, "summary": "Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ea7\u54c1\u641c\u7d22\u7cfb\u7edf\u7684\u591a\u6a21\u6001\u5bf9\u6297\u653b\u51fb\u6846\u67b6MGEO\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u56fe\u50cf\u6270\u52a8\u548c\u6587\u672c\u540e\u7f00\u6765\u64cd\u7eb5\u641c\u7d22\u7ed3\u679c\u6392\u540d", "motivation": "\u867d\u7136\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u548c\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u7ade\u4e89\u6027\u6392\u540d\u573a\u666f\u4e0b\u5bf9\u6297\u64cd\u7eb5\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u4f5c\u8005\u53d1\u73b0VLM\u4ea7\u54c1\u641c\u7d22\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff0c\u9700\u8981\u63a2\u7d22\u591a\u6a21\u6001\u534f\u540c\u5982\u4f55\u88ab\u6b66\u5668\u5316\u653b\u51fb", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u751f\u6210\u5f15\u64ce\u4f18\u5316(MGEO)\u6846\u67b6\uff0c\u91c7\u7528\u4ea4\u66ff\u68af\u5ea6\u4f18\u5316\u7b56\u7565\uff0c\u8054\u5408\u4f18\u5316\u4e0d\u53ef\u611f\u77e5\u7684\u56fe\u50cf\u6270\u52a8\u548c\u6d41\u7545\u7684\u6587\u672c\u540e\u7f00\uff0c\u5229\u7528VLM\u5185\u90e8\u7684\u6df1\u5ea6\u8de8\u6a21\u6001\u8026\u5408", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5148\u8fdb\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u534f\u8c03\u653b\u51fb\u663e\u8457\u4f18\u4e8e\u7eaf\u6587\u672c\u548c\u7eaf\u56fe\u50cf\u57fa\u7ebf\u653b\u51fb\uff0c\u8bc1\u660e\u591a\u6a21\u6001\u534f\u540c\u53ef\u4ee5\u88ab\u6b66\u5668\u5316\u800c\u4e0d\u89e6\u53d1\u4f20\u7edf\u5185\u5bb9\u8fc7\u6ee4\u5668", "conclusion": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u534f\u540c\u4f18\u52bf\u53ef\u80fd\u6210\u4e3a\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4\u641c\u7d22\u6392\u540d\u7684\u5b8c\u6574\u6027"}}
{"id": "2601.12212", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12212", "abs": "https://arxiv.org/abs/2601.12212", "authors": ["Chenan Wang", "Daniel H. Shi", "Haipeng Chen"], "title": "Speculative Sampling with Reinforcement Learning", "comment": "Accepted to AAAI 2026", "summary": "Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\\times$ speedup over the backbone LLM and up to 1.12$\\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.", "AI": {"tldr": "Re-SpS\uff1a\u9996\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a8\u6d4b\u91c7\u6837\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8349\u7a3f\u6811\u8d85\u53c2\u6570\u6765\u4f18\u5316LLM\u63a8\u7406\u5ef6\u8fdf\uff0c\u76f8\u6bd4EAGLE-3\u5b9e\u73b0\u6700\u9ad81.12\u500d\u52a0\u901f", "motivation": "\u73b0\u6709\u63a8\u6d4b\u91c7\u6837\u65b9\u6cd5\uff08\u5982EAGLE-3\uff09\u4f7f\u7528\u9759\u6001\u6811\u7ed3\u6784\u8d85\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u548c\u9886\u57df\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u9700\u8981\u52a8\u6001\u4f18\u5316\u65b9\u6cd5\u6765\u5e73\u8861\u63a8\u6d4b\u653b\u51fb\u6027\u548c\u8ba1\u7b97\u5f00\u9500", "method": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Re-SpS\uff0c\u5b9e\u65f6\u52a8\u6001\u8c03\u6574\u8349\u7a3f\u6811\u8d85\u53c2\u6570\uff0c\u5229\u7528\u76ee\u6807\u6a21\u578b\u9690\u85cf\u72b6\u6001\u7684\u9ad8\u6548\u72b6\u6001\u8868\u793a\uff0c\u5f15\u5165\u591a\u6b65\u52a8\u4f5c\u6301\u4e45\u5316\u4ee5\u6539\u8fdb\u4e0a\u4e0b\u6587\u5efa\u6a21", "result": "\u5728\u4e94\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4SOTA\u65b9\u6cd5EAGLE-3\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\uff0c\u76f8\u6bd4\u9aa8\u5e72LLM\u6700\u9ad85.45\u500d\u52a0\u901f\uff0c\u76f8\u6bd4EAGLE-3\u6700\u9ad81.12\u500d\u52a0\u901f\uff0c\u4e14\u8f93\u51fa\u4fdd\u771f\u5ea6\u65e0\u635f\u5931", "conclusion": "Re-SpS\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u4f18\u5316\u8349\u7a3f\u6811\u8d85\u53c2\u6570\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u901f\u5ea6\uff0c\u4e3a\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u63a8\u6d4b\u91c7\u6837\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12711", "categories": ["cs.AI", "cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2601.12711", "abs": "https://arxiv.org/abs/2601.12711", "authors": ["Kevin Wang", "Neel P. Bhatt", "Cong Liu", "Junbo Li", "Runjin Chen", "Yihan Xi", "Timothy Barclay", "Alvaro Velasquez", "Ufuk Topcu", "Zhangyang Wang"], "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts", "comment": null, "summary": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7LoRA\u6846\u67b6\uff0c\u52a8\u6001\u7ed3\u5408\u53c2\u6570\u5fae\u8c03\uff08\u6570\u503c\u66f4\u65b0\uff09\u548c\u7b26\u53f7\u7f16\u8f91\uff08\u7b26\u53f7\u66f4\u65b0\uff09\uff0c\u5728\u4fdd\u6301\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u80fd\u529b", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u6570\u503c\u5fae\u8c03\u64c5\u957f\u6ce8\u5165\u65b0\u4e8b\u5b9e\u77e5\u8bc6\uff0c\u7b26\u53f7\u66f4\u65b0\u80fd\u7075\u6d3b\u63a7\u5236\u98ce\u683c\u548c\u5bf9\u9f50\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u4f46\u4e24\u8005\u5404\u6709\u5c40\u9650\u3002\u9700\u8981\u7ed3\u5408\u8fd9\u4e24\u79cd\u4e92\u8865\u7b56\u7565\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7LoRA\u6846\u67b6\uff1a1\uff09\u7edf\u4e00\u76d1\u63a7\u4fe1\u53f7\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u5206\u7c7b\u5668\uff0c\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528LoRA\u8fdb\u884c\u6df1\u5ea6\u4e8b\u5b9e\u91cd\u6784\uff0c\u4f55\u65f6\u5e94\u7528TextGrad\u8fdb\u884c\u6807\u8bb0\u7ea7\u7f16\u8f91\uff1b2\uff09\u5c06\u7b26\u53f7\u8f6c\u6362\u5378\u8f7d\u5230\u5916\u90e8LLM\u4ee5\u4fdd\u6301\u5185\u5b58\u6548\u7387\uff1b3\uff09\u7b26\u53f7\u7f16\u8f91\u8fc7\u7a0b\u4e2d\u751f\u6210\u7684\u7cbe\u70bc\u63d0\u793a\u53ef\u4f5c\u4e3a\u9ad8\u8d28\u91cf\u53ef\u91cd\u7528\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u591a\u4e2aLLM\u9aa8\u5e72\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u795e\u7ecf\u7b26\u53f7LoRA\u59cb\u7ec8\u4f18\u4e8e\u7eaf\u6570\u503c\u6216\u7eaf\u7b26\u53f7\u57fa\u7ebf\uff0c\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u9002\u5e94\u6027\u548c\u6539\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u4ea4\u9519\u4f7f\u7528\u6570\u503c\u548c\u7b26\u53f7\u66f4\u65b0\u80fd\u591f\u89e3\u9501\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u65b0\u6c34\u5e73\u7075\u6d3b\u6027\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u9886\u57df\uff08\u5982\u6570\u5b66\u63a8\u7406\uff09\u63d0\u4f9b\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.12269", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12269", "abs": "https://arxiv.org/abs/2601.12269", "authors": ["Xucong Hu", "Jian-Qiao Zhu"], "title": "Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models", "comment": null, "summary": "Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.", "AI": {"tldr": "\u901a\u8fc7\u57fa\u4e8eMCMC\u7684\u529f\u7387\u91c7\u6837\u548c\u9000\u706b\u6280\u672f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u4ece\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u4e2d\u6062\u590d\u5f3a\u5927\u7684\u5fc3\u7406\u7406\u8bba\u80fd\u529b", "motivation": "\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u88ab\u8ba4\u4e3a\u662f\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u5668\uff0c\u4e3b\u8981\u4f18\u5316\u8868\u9762\u5408\u7406\u6027\u800c\u975e\u4fdd\u6301\u6b63\u786e\u7684\u6f5c\u5728\u72b6\u6001\u8868\u793a\uff0c\u56e0\u6b64\u88ab\u8ba4\u4e3a\u5728\u5fc3\u7406\u7406\u8bba\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u867d\u7136\u540e\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u6539\u5584\u6027\u80fd\uff0c\u4f46\u672c\u6587\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u6062\u590d\u5fc3\u7406\u7406\u8bba\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u7684\u529f\u7387\u91c7\u6837\u65b9\u6cd5\uff0c\u4ece\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u5e8f\u5217\u7ea7\u6982\u7387\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u800c\u975e\u4f20\u7edf\u7684\u8bcd\u7ea7\u5206\u5e03\u3002\u8fdb\u4e00\u6b65\u5f15\u5165\u9000\u706b\u6280\u672f\uff0c\u5c06\u6e29\u5ea6\u5206\u5e03\u4ece\u9ad8\u5230\u4f4e\u9010\u6e10\u8c03\u6574\uff0c\u663e\u8457\u63d0\u5347\u5fc3\u7406\u7406\u8bba\u6027\u80fd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u65e0\u9700\u4efb\u4f55\u989d\u5916\u7684\u6743\u91cd\u66f4\u65b0\u6216\u9a8c\u8bc1\uff0c\u4ec5\u901a\u8fc7\u91c7\u6837\u4f18\u5316\u5c31\u80fd\u4ece\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u5f3a\u5927\u7684\u5fc3\u7406\u7406\u8bba\u80fd\u529b\u3002\u9000\u706b\u6280\u672f\u7684\u52a0\u5165\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u56fa\u5b9a\u6e29\u5ea6\u7684\u529f\u7387\u91c7\u6837\u3002", "conclusion": "\u57fa\u4e8e\u91c7\u6837\u7684\u4f18\u5316\u65b9\u6cd5\u4e3a\u4ece\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u6f5c\u5728\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u9014\u5f84\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u8fd9\u5bf9\u5fc3\u7406\u7406\u8bba\u7b49\u9700\u8981\u6f5c\u5728\u72b6\u6001\u63a8\u7406\u7684\u4efb\u52a1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.12720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12720", "abs": "https://arxiv.org/abs/2601.12720", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Qi Zhu", "Fei Mi", "Ganqu Cui", "Yasheng Wang", "Lifeng Shang"], "title": "Teaching Large Reasoning Models Effective Reflection", "comment": "14 pages (including appendix), 5 figures", "summary": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.", "AI": {"tldr": "\u63d0\u51faSCFT\u548cRLERR\u65b9\u6cd5\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u5224\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u53cd\u601d\u8d28\u91cf\u4e0e\u63a8\u7406\u51c6\u786e\u6027", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5e38\u8fdb\u884c\u81ea\u6211\u53cd\u601d\uff0c\u4f46\u8bb8\u591a\u53cd\u601d\u662f\u8868\u9762\u7684\uff0c\u65e0\u6cd5\u6539\u5584\u539f\u59cb\u7b54\u6848\u5374\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u8981\u89e3\u51b3\u8868\u9762\u53cd\u601d\u95ee\u9898", "method": "1. SCFT\uff1a\u81ea\u6211\u6279\u5224\u5fae\u8c03\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u6279\u5224\u81ea\u8eab\u8f93\u51fa\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u7b5b\u9009\u9ad8\u8d28\u91cf\u6279\u5224\uff0c\u4f7f\u7528\u6279\u5224\u76ee\u6807\u5fae\u8c03\u6a21\u578b\uff1b2. RLERR\uff1a\u57fa\u4e8eSCFT\u521d\u59cb\u5316\u9ad8\u8d28\u91cf\u53cd\u601d\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5185\u5316\u81ea\u6211\u7ea0\u6b63\u8fc7\u7a0b", "result": "\u5728AIME2024\u548cAIME2025\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCFT\u548cRLERR\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53cd\u601d\u8d28\u91cf\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684SCFT\u548cRLERR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8868\u9762\u53cd\u601d\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u81ea\u6211\u6279\u5224\u80fd\u529b\u548c\u5185\u5316\u7ea0\u6b63\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd"}}
{"id": "2601.12286", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12286", "abs": "https://arxiv.org/abs/2601.12286", "authors": ["Jonathan Pan"], "title": "Conversational Context Classification: A Representation Engineering Approach", "comment": null, "summary": "The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.", "AI": {"tldr": "\u4f7f\u7528\u8868\u5f81\u5de5\u7a0b\u548c\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\u5728LLM\u5185\u90e8\u72b6\u6001\u4e2d\u8bc6\u522b\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\uff0c\u7528\u4e8e\u68c0\u6d4b\u5bf9\u8bdd\u662f\u5426\u504f\u79bb\u4e0a\u4e0b\u6587", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u9700\u8981\u6709\u6548\u4fdd\u969c\u5176\u8fd0\u884c\uff0c\u7279\u522b\u662f\u68c0\u6d4b\u5176\u751f\u6210\u504f\u79bb\u4e0a\u4e0b\u6587\u56de\u590d\u7684\u503e\u5411\u3002\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0a\u4e0b\u6587\u8bed\u4e49\u4e2d\u3002", "method": "\u7ed3\u5408\u8868\u5f81\u5de5\u7a0b\u548c\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\uff0c\u5728LLM\u5185\u90e8\u72b6\u6001\u4e2d\u8bc6\u522b\u4e0e\u7279\u5b9a\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5b50\u7a7a\u95f4\u3002\u901a\u8fc7\u4e0a\u4e0b\u6587\u793a\u4f8b\u8bad\u7ec3OCSVM\uff0c\u5728\u9690\u85cf\u72b6\u6001\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5efa\u7acb\u8fb9\u754c\uff0c\u5e76\u8bc6\u522b\u4e0e\u76ee\u6807\u4e0a\u4e0b\u6587\u6700\u76f8\u5173\u7684\u7f51\u7edc\u5c42\u3002", "result": "\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\u65b9\u9762\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5bf9\u8bdd\u662f\u5426\u5728\u4e0a\u4e0b\u6587\u5185\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6709\u52a9\u4e8e\u68c0\u6d4b\u5bf9\u8bdd\u662f\u5426\u504f\u79bb\u4e0a\u4e0b\u6587\uff0c\u8fd8\u4e3a\u66f4\u597d\u5730\u89e3\u91caLLM\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2601.12215", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12215", "abs": "https://arxiv.org/abs/2601.12215", "authors": ["Megha Thukral", "Cyrus Tanade", "Simon A. Lee", "Juhyeon Lee", "Hao Zhou", "Keum San Chun", "Migyeong Gwak", "Viswam Nathan", "Md Mahbubur Rahman", "Li Zhu", "Mehrab Bin Morshed", "Subramaniam Venkatraman", "Sharanya Arcot Desai"], "title": "Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models", "comment": null, "summary": "Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.", "AI": {"tldr": "\u63d0\u51faMMR\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5c0f\u6ce2\u591a\u5c3a\u5ea6\u5206\u89e3\u91cd\u5efa\u4efb\u52a1\u5b66\u4e60PPG\u4fe1\u53f7\u7684\u5c42\u6b21\u5316\u65f6\u9891\u7279\u5f81\uff0c\u572817/19\u4e2a\u5065\u5eb7\u76f8\u5173\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53ef\u7a7f\u6234\u57fa\u7840\u6a21\u578b\u5927\u591a\u5ffd\u7565PPG\u4fe1\u53f7\u7684\u9891\u8c31\u7ed3\u6784\uff0c\u800c\u8bb8\u591a\u4e0b\u6e38\u5065\u5eb7\u4efb\u52a1\u9700\u8981\u4ece\u7ec6\u7c92\u5ea6\u6ce2\u5f62\u5f62\u6001\u5230\u5168\u5c40\u8282\u5f8b\u52a8\u6001\u7684\u591a\u5206\u8fa8\u7387\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u63a9\u7801\u591a\u5c3a\u5ea6\u91cd\u5efa(MMR)\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff1a\u5bf9\u5c0f\u6ce2\u591a\u5206\u8fa8\u7387\u5206\u89e3\u7684PPG\u4fe1\u53f7\u7cfb\u6570\u8fdb\u884c\u968f\u673a\u63a9\u7801\uff0c\u8bad\u7ec3Transformer\u7f16\u7801\u5668\u8de8\u65f6\u9891\u5c3a\u5ea6\u91cd\u5efa\u8fd9\u4e9b\u7cfb\u6570\u3002", "result": "\u5728\u7ea61700\u4e07\u4e2a\u672a\u6807\u8bb010\u79d2PPG\u7247\u6bb5\u4e0a\u9884\u8bad\u7ec3\uff0c\u572817/19\u4e2a\u591a\u6837\u5316\u5065\u5eb7\u76f8\u5173\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6216\u5339\u914d\u73b0\u6709PPG\u57fa\u7840\u6a21\u578b\u3001\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u548c\u5176\u4ed6\u81ea\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "MMR\u5c55\u793a\u4e86\u6784\u5efa\u901a\u7528PPG\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5c0f\u6ce2\u8868\u793a\u80fd\u6355\u83b7\u7a33\u5065\u4e14\u751f\u7406\u57fa\u7840\u7684\u7279\u5f81\uff0c\u4e3a\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u63d0\u4f9b\u6709\u6548\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2601.12744", "categories": ["cs.AI", "cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12744", "abs": "https://arxiv.org/abs/2601.12744", "authors": ["Tasnim Ahmed", "Yifan Zhu", "Salimur Choudhury"], "title": "Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks", "comment": "Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026", "summary": "Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IntentOpt\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u7f51\u7edc\u8349\u56fe\u751f\u6210\u4f18\u5316\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u89c6\u89c9\u53c2\u6570\u63d0\u53d6\u4f1a\u964d\u4f4e\u6267\u884c\u6210\u529f\u7387\uff0c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u843d\u540e\u4e8e\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u5141\u8bb8\u64cd\u4f5c\u5458\u6307\u5b9a\u9ad8\u7ea7\u7f51\u7edc\u76ee\u6807\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5047\u8bbe\u57fa\u4e8e\u6587\u672c\u7684\u610f\u56fe\u8868\u8fbe\uff0c\u800c\u7f51\u7edc\u4ece\u4e1a\u8005\u901a\u5e38\u901a\u8fc7\u56fe\u8868\u8fdb\u884c\u63a8\u7406\u3002\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5c06\u5e26\u6ce8\u91ca\u7684\u7f51\u7edc\u8349\u56fe\u5904\u7406\u6210\u6b63\u786e\u7684\u4f18\u5316\u4ee3\u7801\u3002", "method": "\u63d0\u51fa\u4e86IntentOpt\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b85\u4e2a\u4f18\u5316\u95ee\u9898\u548c17\u4e2a\u7c7b\u522b\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08GPT-5-Mini\u3001Claude-Haiku-4.5\u3001Gemini-2.5-Flash\u3001Llama-3.2-11B-Vision\uff09\u5728\u4e09\u79cd\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e86\u591a\u6a21\u6001\u4e0e\u7eaf\u6587\u672c\u8f93\u5165\u7684\u5dee\u5f02\u3002", "result": "\u89c6\u89c9\u53c2\u6570\u63d0\u53d6\u4f7f\u6267\u884c\u6210\u529f\u7387\u964d\u4f4e12-21\u4e2a\u767e\u5206\u70b9\uff08GPT-5-Mini\u4ece93%\u964d\u81f372%\uff09\uff1b\u601d\u7ef4\u7a0b\u5e8f\u63d0\u793a\u4f7f\u6027\u80fd\u4e0b\u964d\u6700\u591a13\u4e2a\u767e\u5206\u70b9\uff1b\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u843d\u540e\uff08Llama-3.2-11B-Vision\u4ec518%\uff0c\u800cGPT-5-Mini\u4e3a75%\uff09\u3002", "conclusion": "\u7814\u7a76\u5efa\u7acb\u4e86\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u610f\u56fe\u9a71\u52a8\u7f51\u7edc\u7cfb\u7edf\u4e2d\u751f\u6210\u4f18\u5316\u4ee3\u7801\u7684\u57fa\u51c6\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u4f7f\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u5c06VLM\u751f\u6210\u4ee3\u7801\u90e8\u7f72\u5230\u7f51\u7edc\u6d4b\u8bd5\u5e8a\u57fa\u7840\u8bbe\u65bd\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2601.12369", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12369", "abs": "https://arxiv.org/abs/2601.12369", "authors": ["Ming Zhang", "Jiabao Zhuang", "Wenqing Jing", "Ziyu Kong", "Jingyi Deng", "Yujiong Shen", "Kexin Tan", "Yuhang Zhao", "Ning Luo", "Renzhe Zheng", "Jiahui Lin", "Mingqi Wu", "Long Ma", "Yi Zou", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies", "comment": null, "summary": "Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.", "AI": {"tldr": "TaxoBench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u751f\u6210\u7efc\u8ff0\u80fd\u529b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u57fa\u4e8e72\u7bc7\u9ad8\u5f15\u7528\u8ba1\u7b97\u673a\u79d1\u5b66\u7efc\u8ff0\u6784\u5efa\uff0c\u5305\u542b3,815\u4e2a\u7cbe\u786e\u5206\u7c7b\u7684\u5f15\u7528\u4f5c\u4e3a\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u6700\u4f73\u4ee3\u7406\u53ea\u80fd\u53ec\u56de20.9%\u7684\u4e13\u5bb6\u9009\u62e9\u8bba\u6587\uff0c\u7ec4\u7ec7\u80fd\u529b\u4e5f\u5f88\u6709\u9650\u3002", "motivation": "\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u7efc\u8ff0\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5b83\u4eec\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e13\u5bb6\u4e00\u6837\u64b0\u5199\u7efc\u8ff0\u3002\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6d41\u7545\u6027\u6216\u5f15\u7528\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u6838\u5fc3\u80fd\u529b\uff08\u68c0\u7d22\u5173\u952e\u8bba\u6587\u5e76\u5c06\u5176\u7ec4\u7ec7\u6210\u8fde\u8d2f\u77e5\u8bc6\u7ed3\u6784\uff09\u7684\u8bc4\u4f30\u3002", "method": "\u4ece72\u7bc7\u9ad8\u5f15\u7528\u8ba1\u7b97\u673a\u79d1\u5b66\u7efc\u8ff0\u4e2d\u624b\u52a8\u63d0\u53d6\u4e13\u5bb6\u6784\u5efa\u7684\u5206\u7c7b\u6811\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5305\u542b3,815\u4e2a\u7cbe\u786e\u5206\u7c7b\u7684\u5f15\u7528\u3002\u652f\u6301\u4e24\u79cd\u8bc4\u4f30\u6a21\u5f0f\uff1a\u6df1\u5ea6\u7814\u7a76\u6a21\u5f0f\uff08\u7ed9\u5b9a\u4e3b\u9898\u8fdb\u884c\u7aef\u5230\u7aef\u68c0\u7d22\u548c\u7ec4\u7ec7\uff09\u548c\u81ea\u5e95\u5411\u4e0a\u6a21\u5f0f\uff08\u63d0\u4f9b\u4e13\u5bb6\u4f7f\u7528\u7684\u786e\u5207\u8bba\u6587\u6765\u6d4b\u8bd5\u7ec4\u7ec7\u80fd\u529b\uff09\u3002\u8bc4\u4f30\u4e867\u4e2a\u9886\u5148\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u548c12\u4e2a\u524d\u6cbfLLM\u3002", "result": "\u7ed3\u679c\u663e\u793a\u53cc\u91cd\u74f6\u9888\uff1a\u6700\u4f73\u4ee3\u7406\u53ea\u80fd\u53ec\u56de20.9%\u7684\u4e13\u5bb6\u9009\u62e9\u8bba\u6587\uff1b\u5373\u4f7f\u5728\u5b8c\u7f8e\u8f93\u5165\u6761\u4ef6\u4e0b\uff0c\u6700\u4f73\u6a21\u578b\u7684\u7ec4\u7ec7\u80fd\u529b\u4e5f\u53ea\u67090.31 ARI\uff08\u8c03\u6574\u5170\u5fb7\u6307\u6570\uff09\u3002\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u8ddd\u79bb\u4e13\u5bb6\u7ea7\u7efc\u8ff0\u64b0\u5199\u4ecd\u6709\u5f88\u5927\u5dee\u8ddd\u3002", "conclusion": "TaxoBench\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u6838\u5fc3\u80fd\u529b\u3002\u7814\u7a76\u8868\u660e\u5f53\u524d\u4ee3\u7406\u5728\u68c0\u7d22\u5173\u952e\u8bba\u6587\u548c\u7ec4\u7ec7\u77e5\u8bc6\u7ed3\u6784\u65b9\u9762\u90fd\u8fdc\u672a\u8fbe\u5230\u4e13\u5bb6\u6c34\u5e73\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2601.12227", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12227", "abs": "https://arxiv.org/abs/2601.12227", "authors": ["Yuanyun Zhang", "Han Zhou", "Li Feng", "Yilin Hong", "Shi Li"], "title": "Learning Longitudinal Health Representations from EHR and Wearable Data", "comment": null, "summary": "Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u8054\u5408\u8868\u793a\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\u4f5c\u4e3a\u8fde\u7eed\u65f6\u95f4\u6f5c\u5728\u8fc7\u7a0b\uff0c\u5728\u751f\u7406\u9884\u6d4b\u548c\u98ce\u9669\u5efa\u6a21\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u7a00\u758f\u4e14\u4e0d\u89c4\u5219\uff0c\u53ef\u7a7f\u6234\u8bbe\u5907\u63d0\u4f9b\u5bc6\u96c6\u8fde\u7eed\u751f\u7406\u4fe1\u53f7\u4f46\u7f3a\u4e4f\u8bed\u4e49\u57fa\u7840\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5355\u72ec\u5efa\u6a21\u6216\u901a\u8fc7\u540e\u671f\u878d\u5408\u7ed3\u5408\u8fd9\u4e9b\u6570\u636e\u6e90", "method": "\u4f7f\u7528\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u548c\u5171\u4eab\u65f6\u95f4\u9aa8\u5e72\u7f51\u7edc\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u548c\u8de8\u6a21\u6001\u76ee\u6807\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5c06\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u53ef\u7a7f\u6234\u6570\u636e\u8054\u5408\u8868\u793a\u4e3a\u8fde\u7eed\u65f6\u95f4\u6f5c\u5728\u8fc7\u7a0b", "result": "\u5728\u751f\u7406\u9884\u6d4b\u548c\u98ce\u9669\u5efa\u6a21\u4efb\u52a1\u4e0a\uff0c\u6a21\u578b\u4f18\u4e8e\u4ec5\u4f7f\u7528\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6216\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u5f3a\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u957f\u65f6\u95f4\u8303\u56f4\u548c\u6570\u636e\u7f3a\u5931\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u597d", "conclusion": "\u8054\u5408\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u9884\u8bad\u7ec3\u80fd\u591f\u4ea7\u751f\u66f4\u51c6\u786e\u7684\u7eb5\u5411\u5065\u5eb7\u8868\u793a\uff0c\u8bc1\u660e\u591a\u6a21\u6001\u6574\u5408\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u4ef7\u503c"}}
{"id": "2601.12781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12781", "abs": "https://arxiv.org/abs/2601.12781", "authors": ["Hyejin Park", "Junhyuk Kwon", "Suha Kwak", "Jungseul Ok"], "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension", "comment": null, "summary": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.", "AI": {"tldr": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u5230\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u6b65\u9aa4\u4e2d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709REC\u65b9\u6cd5\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u76ee\u6807\u5b58\u5728\u548c\u4e0d\u5b58\u5728\u573a\u666f\u4e0b\u90fd\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u867d\u7136\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u63a8\u7406\u548c\u5f3a\u5927\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5047\u8bbe\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u90fd\u662f\u51c6\u786e\u7684\u3002\u8fd9\u79cd\u5047\u8bbe\u5bfc\u81f4\u7ea7\u8054\u9519\u8bef\uff1a\u9519\u8bef\u68c0\u6d4b\u548c\u65e0\u6548\u5173\u7cfb\u5728\u63a8\u7406\u94fe\u4e2d\u4f20\u64ad\uff0c\u5373\u4f7f\u56fe\u50cf\u4e2d\u6ca1\u6709\u76ee\u6807\u4e5f\u4f1a\u4ea7\u751f\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u8bef\u62a5\u3002", "method": "\u63d0\u51fa\u4e86\u9a8c\u8bc1\u96c6\u6210\u63a8\u7406\u7b97\u5b50\uff08VIRO\uff09\u6846\u67b6\uff0c\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u5d4c\u5165\u8f7b\u91cf\u7ea7\u7684\u7b97\u5b50\u7ea7\u9a8c\u8bc1\u5668\u3002\u6bcf\u4e2a\u7b97\u5b50\u6267\u884c\u5e76\u9a8c\u8bc1\u5176\u8f93\u51fa\uff08\u5982\u5bf9\u8c61\u5b58\u5728\u6027\u6216\u7a7a\u95f4\u5173\u7cfb\uff09\uff0c\u5f53\u9a8c\u8bc1\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u7cfb\u7edf\u80fd\u591f\u9c81\u68d2\u5730\u5904\u7406\u65e0\u76ee\u6807\u60c5\u51b5\u3002", "result": "\u5728\u76ee\u6807\u5b58\u5728\u548c\u65e0\u76ee\u6807\u8bbe\u7f6e\u4e0b\u8fbe\u523061.1%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0cVIRO\u5728\u541e\u5410\u91cf\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u7a0b\u5e8f\u5931\u8d25\u7387\u4f4e\u4e8e0.3%\uff0c\u5e76\u901a\u8fc7\u89e3\u8026\u7a0b\u5e8f\u751f\u6210\u548c\u6267\u884c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "VIRO\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b26\u53f7REC\u65b9\u6cd5\u4e2d\u7684\u7ea7\u8054\u9519\u8bef\u95ee\u9898\uff0c\u5728\u6027\u80fd\u3001\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u771f\u5b9e\u4e16\u754c\u7684\u81ea\u6211\u4e2d\u5fc3\u6570\u636e\u3002"}}
{"id": "2601.12374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12374", "abs": "https://arxiv.org/abs/2601.12374", "authors": ["Akram Elbouanani", "Aboubacar Tuo", "Adrian Popescu"], "title": "A Scalable Entity-Based Framework for Auditing Bias in LLMs", "comment": null, "summary": "Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528\u547d\u540d\u5b9e\u4f53\u4f5c\u4e3a\u63a2\u9488\u7684\u53ef\u6269\u5c55\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u5927\u89c4\u6a21\u6d4b\u91cfLLM\u4e2d\u7684\u7ed3\u6784\u6027\u504f\u89c1\uff0c\u53d1\u73b0\u4e86\u7cfb\u7edf\u6027\u653f\u6cbb\u3001\u5730\u7406\u548c\u7ecf\u6d4e\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u751f\u6001\u6548\u5ea6\u4e0e\u7edf\u8ba1\u63a7\u5236\u4e4b\u95f4\u7684\u6743\u8861\uff1a\u4eba\u5de5\u63d0\u793a\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4f7f\u7528\u573a\u666f\uff0c\u800c\u81ea\u7136\u4efb\u52a1\u53c8\u7f3a\u4e4f\u89c4\u6a21\u548c\u4e25\u8c28\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5927\u89c4\u6a21\u5206\u6790\u53c8\u80fd\u4fdd\u6301\u771f\u5b9e\u6027\u7684\u504f\u89c1\u5ba1\u8ba1\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u547d\u540d\u5b9e\u4f53\u7684\u53ef\u6269\u5c55\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u4f5c\u4e3a\u63a2\u9488\u6765\u6d4b\u91cf\u6a21\u578b\u884c\u4e3a\u4e2d\u7684\u7ed3\u6784\u6027\u5dee\u5f02\u3002\u901a\u8fc719\u4ebf\u4e2a\u6570\u636e\u70b9\uff0c\u6db5\u76d6\u591a\u79cd\u5b9e\u4f53\u7c7b\u578b\u3001\u4efb\u52a1\u3001\u8bed\u8a00\u3001\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u504f\u89c1\uff1a\u6a21\u578b\u60e9\u7f5a\u53f3\u7ffc\u653f\u5ba2\u3001\u504f\u7231\u5de6\u7ffc\u653f\u5ba2\uff1b\u504f\u597d\u897f\u65b9\u548c\u5bcc\u88d5\u56fd\u5bb6\u800c\u975e\u5168\u7403\u5357\u65b9\uff1b\u504f\u7231\u897f\u65b9\u516c\u53f8\uff1b\u60e9\u7f5a\u56fd\u9632\u548c\u5236\u836f\u884c\u4e1a\u516c\u53f8\u3002\u6307\u4ee4\u5fae\u8c03\u51cf\u5c11\u504f\u89c1\uff0c\u4f46\u6a21\u578b\u89c4\u6a21\u589e\u5927\u4f1a\u653e\u5927\u504f\u89c1\uff0c\u4f7f\u7528\u4e2d\u6587\u6216\u4fc4\u6587\u63d0\u793a\u4e0d\u4f1a\u51cf\u5f31\u897f\u65b9\u504f\u597d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u90e8\u7f72\u524d\u5e94\u8fdb\u884c\u4e25\u683c\u5ba1\u8ba1\uff0c\u56e0\u4e3a\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4e14\u8fd9\u4e9b\u504f\u89c1\u4f1a\u968f\u89c4\u6a21\u589e\u5927\u800c\u52a0\u5267\uff0c\u8bed\u8a00\u5207\u6362\u65e0\u6cd5\u6d88\u9664\u897f\u65b9\u4e2d\u5fc3\u504f\u597d\u3002"}}
{"id": "2601.12231", "categories": ["cs.LG", "cs.CR", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.12231", "abs": "https://arxiv.org/abs/2601.12231", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Shijie Xu", "Guanggang Geng"], "title": "Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention", "comment": "Accepted by ICASSP 2026. Copyright 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u6ce2\u611f\u77e5\u8c03\u5236\u3001\u591a\u5206\u8fa8\u7387\u5c0f\u6ce2\u5206\u89e3\u548c\u5206\u8fa8\u7387\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u4f01\u4e1a\u5b89\u5168\u4e2d\u7684\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b", "motivation": "\u4f01\u4e1a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u9762\u4e34\u591a\u901a\u9053\u3001\u975e\u5e73\u7a33\u7684\u7528\u6237\u6d3b\u52a8\u65e5\u5fd7\uff0c\u4e14\u5f02\u5e38\u4e8b\u4ef6\u7a00\u5c11\uff0c\u4f7f\u5f97\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u6311\u6218", "method": "1) \u504f\u5dee\u611f\u77e5\u8c03\u5236\u65b9\u6848\u6291\u5236\u5e38\u89c4\u884c\u4e3a\u5e76\u653e\u5927\u5f02\u5e38\u504f\u5dee\uff1b2) \u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u5c06\u65e5\u5fd7\u4fe1\u53f7\u5206\u89e3\u4e3a\u591a\u5206\u8fa8\u7387\u8868\u793a\uff1b3) \u53ef\u5b66\u4e60\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u91cd\u65b0\u52a0\u6743\u6700\u5177\u533a\u5206\u6027\u7684\u9891\u5e26", "result": "\u5728CERT r4.2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u65f6\u95f4\u7c92\u5ea6\u548c\u573a\u666f", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u5c0f\u6ce2\u611f\u77e5\u8c03\u5236\u3001\u591a\u5206\u8fa8\u7387\u5206\u89e3\u548c\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u4f01\u4e1a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u7684\u590d\u6742\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd"}}
{"id": "2601.12804", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12804", "abs": "https://arxiv.org/abs/2601.12804", "authors": ["Hanwei Zhang", "Luo Cheng", "Rui Wen", "Yang Zhang", "Lijun Zhang", "Holger Hermanns"], "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability", "comment": null, "summary": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.", "AI": {"tldr": "SL-CBM\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u5c40\u90e8\u6027\u589e\u5f3a\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff0c\u751f\u6210\u7a7a\u95f4\u4e00\u81f4\u7684\u6982\u5ff5\u548c\u7c7b\u522b\u663e\u8457\u6027\u56fe\uff0c\u63d0\u9ad8\u5c40\u90e8\u5fe0\u5b9e\u5ea6\u548c\u89e3\u91ca\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBMs\uff09\u5b58\u5728\u5c40\u90e8\u5fe0\u5b9e\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5c06\u6982\u5ff5\u4e0e\u6709\u610f\u4e49\u7684\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u7a7a\u95f4\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faSL-CBM\uff0c\u901a\u8fc7\u96c6\u62101x1\u5377\u79ef\u5c42\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u6982\u5ff5\u548c\u7c7b\u522b\u5c42\u9762\u751f\u6210\u7a7a\u95f4\u4e00\u81f4\u7684\u663e\u8457\u6027\u56fe\uff0c\u589e\u5f3a\u6982\u5ff5\u3001\u56fe\u50cf\u533a\u57df\u548c\u6700\u7ec8\u9884\u6d4b\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSL-CBM\u663e\u8457\u63d0\u9ad8\u4e86\u5c40\u90e8\u5fe0\u5b9e\u5ea6\u3001\u89e3\u91ca\u8d28\u91cf\u548c\u5e72\u9884\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "SL-CBM\u5f25\u5408\u4e86\u57fa\u4e8e\u6982\u5ff5\u7684\u63a8\u7406\u548c\u7a7a\u95f4\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684\u6982\u5ff5\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2601.13522", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13522", "abs": "https://arxiv.org/abs/2601.13522", "authors": ["Shuang Li"], "title": "StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing", "comment": null, "summary": "Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTucker\u5206\u89e3\u7684\u968f\u673a\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f4eTucker\u79e9\u5f20\u91cf\u611f\u77e5\u95ee\u9898\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u5f20\u91cf\u6295\u5f71\uff0c\u5b9e\u73b0\u4e86\u4f4e\u7ef4\u5f20\u91cf\u56e0\u5b50\u7684\u9ad8\u6548\u5c0f\u6279\u91cf\u66f4\u65b0\u3002", "motivation": "\u4f4eTucker\u79e9\u5f20\u91cf\u611f\u77e5\u662f\u4fe1\u53f7\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u5f20\u91cf\u6295\u5f71\uff0c\u8981\u4e48\u4f9d\u8d56\u5168\u68af\u5ea6\u8ba1\u7b97\uff0c\u800c\u5927\u591a\u6570\u968f\u673a\u56e0\u5b50\u5316\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5f20\u91cf\u5206\u89e3\u8bbe\u7f6e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u76f4\u63a5\u5728Tucker\u5206\u89e3\u4e0b\u7684\u6838\u5fc3\u5f20\u91cf\u548c\u56e0\u5b50\u77e9\u9635\u4e0a\u64cd\u4f5c\uff0c\u907f\u514d\u4e86\u91cd\u590d\u7684\u5f20\u91cf\u6295\u5f71\uff0c\u5b9e\u73b0\u4e86\u4f4e\u7ef4\u5f20\u91cf\u56e0\u5b50\u7684\u9ad8\u6548\u5c0f\u6279\u91cf\u66f4\u65b0\u3002", "result": "\u5728\u5408\u6210\u5f20\u91cf\u611f\u77e5\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u4ee3\u8868\u6027\u7684\u968f\u673a\u5f20\u91cf\u6062\u590d\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u5728\u6302\u949f\u65f6\u95f4\u4e0a\u8868\u73b0\u51fa\u6709\u5229\u7684\u6536\u655b\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f4eTucker\u79e9\u5f20\u91cf\u611f\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u968f\u673a\u4f18\u5316\u6846\u67b6\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.12376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12376", "abs": "https://arxiv.org/abs/2601.12376", "authors": ["Ofek Raban", "Ethan Fetaya", "Gal Chechik"], "title": "LR-DWM: Efficient Watermarking for Diffusion Language Models", "comment": "Submitted to ACL Rolling Review (ARR). 7 pages, 4 figures", "summary": "Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.", "AI": {"tldr": "\u63d0\u51faLR-DWM\u6c34\u5370\u65b9\u6848\uff0c\u9488\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u540c\u65f6\u5229\u7528\u5de6\u53f3\u90bb\u5c45token\u8fdb\u884c\u504f\u7f6e\uff0c\u5b9e\u73b0\u9ad8\u6548\u6c34\u5370\u5d4c\u5165\u548c\u68c0\u6d4b\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u6781\u5c0f", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u4f9d\u8d56\u5e8f\u5217\u751f\u6210\u7279\u6027\u3002\u6269\u6563\u8bed\u8a00\u6a21\u578b\u91c7\u7528\u975e\u987a\u5e8f\u8fed\u4ee3\u53bb\u566a\u751f\u6210\uff0c\u9700\u8981\u5927\u5e45\u4fee\u6539\u73b0\u6709\u65b9\u6cd5\u3002\u6700\u8fd1\u5de5\u4f5c\u901a\u8fc7\u53cd\u8f6c\u8fc7\u7a0b\u5b9e\u73b0\u6c34\u5370\uff0c\u4f46\u8ba1\u7b97\u6216\u5185\u5b58\u5f00\u9500\u5927", "method": "\u63d0\u51fa\u5de6\u53f3\u6269\u6563\u6c34\u5370\u65b9\u6848\uff0c\u5f53\u5de6\u53f3\u90bb\u5c45token\u53ef\u7528\u65f6\uff0c\u57fa\u4e8e\u4e24\u8005\u5bf9\u751f\u6210token\u8fdb\u884c\u504f\u7f6e\u3002\u8be5\u65b9\u6cd5\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u5f00\u9500\u6781\u5c0f\uff0c\u63a5\u8fd1\u65e0\u6c34\u5370\u57fa\u7ebf", "result": "\u5728\u6807\u51c6\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u53ef\u9760\u7edf\u8ba1\u68c0\u6d4b\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53ef\u9ad8\u6548\u6c34\u5370\uff0c\u68c0\u6d4b\u7387\u9ad8\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u53ef\u5ffd\u7565", "conclusion": "LR-DWM\u8bc1\u660e\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u9ad8\u6548\u6c34\u5370\uff0c\u5728\u4fdd\u6301\u63a5\u8fd1\u57fa\u7ebf\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u53ef\u9760\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898"}}
{"id": "2601.12288", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12288", "abs": "https://arxiv.org/abs/2601.12288", "authors": ["Lei Liu", "Tengyuan Liu", "Hongwei Zhao", "Jiahui Huang", "Ruibo Guo", "Bin Li"], "title": "TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization", "comment": null, "summary": "Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\\% in CRPS and 21.23\\% in NMAE.", "AI": {"tldr": "TimeGMM\uff1a\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7GRIN\u6a21\u5757\u5904\u7406\u65f6\u79fb\uff0c\u5355\u6b21\u524d\u5411\u4f20\u64ad\u5373\u53ef\u6355\u6349\u590d\u6742\u672a\u6765\u5206\u5e03\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\uff08\u4f9d\u8d56\u91c7\u6837\uff09\u6216\u53c2\u6570\u5047\u8bbe\u9650\u5236\u6027\u5f3a\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u9884\u6d4b\u6027\u80fd\u53d7\u9650\u548c\u5206\u5e03\u4e0d\u5339\u914d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u9ad8\u6548\u6355\u6349\u590d\u6742\u672a\u6765\u5206\u5e03\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTimeGMM\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u8868\u5f81\u672a\u6765\u5206\u5e03\uff1b2\uff09\u63d0\u51faGRIN\u6a21\u5757\uff08GMM\u9002\u5e94\u7684\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\uff09\u52a8\u6001\u9002\u5e94\u65f6\u79fb\uff1b3\uff09\u7ed3\u5408\u65f6\u95f4\u7f16\u7801\u5668\uff08TE-Module\uff09\u548c\u6761\u4ef6\u65f6\u79fb\u6982\u7387\u89e3\u7801\u5668\uff08CTPD-Module\uff09\u5171\u540c\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u6df7\u5408\u5206\u5e03\u53c2\u6570\u3002", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cTimeGMM\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728CRPS\u6307\u6807\u4e0a\u6700\u5927\u63d0\u534722.48%\uff0c\u5728NMAE\u6307\u6807\u4e0a\u6700\u5927\u63d0\u534721.23%\u3002", "conclusion": "TimeGMM\u901a\u8fc7GMM\u6846\u67b6\u548cGRIN\u6a21\u5757\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6982\u7387\u9884\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u590d\u6742\u5206\u5e03\u5efa\u6a21\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.12822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12822", "abs": "https://arxiv.org/abs/2601.12822", "authors": ["Wenqi Zhang", "Yulin Shen", "Changyue Jiang", "Jiarun Dai", "Geng Hong", "Xudong Pan"], "title": "MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction", "comment": null, "summary": "Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.", "AI": {"tldr": "MirrorGuard\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u8bad\u7ec3\u63d0\u5347\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\uff0c\u5728\u4fdd\u6301\u4ee3\u7406\u5b9e\u7528\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u96c6\u6210\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u80fd\u591f\u901a\u8fc7GUI\u81ea\u4e3b\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u4ea4\u4e92\uff0c\u4f46\u6076\u610f\u6307\u4ee4\u6216\u89c6\u89c9\u63d0\u793a\u6ce8\u5165\u4f1a\u89e6\u53d1\u4e0d\u5b89\u5168\u63a8\u7406\uff0c\u5bfc\u81f4\u6709\u5bb3\u7684\u7cfb\u7edf\u7ea7\u64cd\u4f5c\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u68c0\u6d4b\u7684\u963b\u65ad\uff09\u867d\u7136\u80fd\u9632\u6b62\u635f\u5bb3\uff0c\u4f46\u901a\u5e38\u4f1a\u8fc7\u65e9\u7ec8\u6b62\u4efb\u52a1\uff0c\u964d\u4f4e\u4e86\u4ee3\u7406\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6a21\u62df\u7ba1\u9053\uff0c\u5728\u7eaf\u6587\u672c\u6a21\u62df\u73af\u5883\u4e2d\u751f\u6210\u771f\u5b9e\u7684\u9ad8\u98ce\u9669GUI\u4ea4\u4e92\u8f68\u8ff9\uff0c\u6355\u83b7\u4e0d\u5b89\u5168\u63a8\u7406\u6a21\u5f0f\u548c\u6f5c\u5728\u7cfb\u7edf\u5371\u9669\uff0c\u800c\u65e0\u9700\u6267\u884c\u771f\u5b9e\u64cd\u4f5c\u3002\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0cMirrorGuard\u5b66\u4e60\u5728CUA\u4ea7\u751f\u548c\u6267\u884c\u4e0d\u5b89\u5168\u64cd\u4f5c\u4e4b\u524d\u62e6\u622a\u548c\u7ea0\u6b63\u5176\u4e0d\u5b89\u5168\u63a8\u7406\u94fe\u3002", "result": "\u5728\u5b57\u8282\u8df3\u52a8UI-TARS\u7cfb\u7edf\u4e0a\uff0cMirrorGuard\u5c06\u4e0d\u5b89\u5168\u7387\u4ece66.5%\u964d\u81f313.0%\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u8bef\u62d2\u7387\uff08FRR\uff09\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6700\u5148\u8fdb\u7684GuardAgent\u4ec5\u964d\u81f353.9%\uff0c\u4e14\u8bef\u62d2\u7387\u9ad815.4%\u3002\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u548cCUA\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cMirrorGuard\u663e\u8457\u51cf\u8f7b\u4e86\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u6a21\u62df\u884d\u751f\u7684\u9632\u5fa1\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u4ee3\u7406\u57fa\u672c\u5b9e\u7528\u6027\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u5f3a\u5927\u7684\u73b0\u5b9e\u4e16\u754c\u4fdd\u62a4\u3002MirrorGuard\u8bc1\u660e\u4e86\u901a\u8fc7\u6a21\u62df\u8bad\u7ec3\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2601.12389", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12389", "abs": "https://arxiv.org/abs/2601.12389", "authors": ["Lakshya Tomar", "Vinayak Abrol", "Puneet Agarwal"], "title": "NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages", "comment": "Accepted at the AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.", "AI": {"tldr": "NADIR\u662f\u4e00\u4e2a\u65b0\u578b\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u9488\u5bf9\u591a\u8bed\u8a00\u97f3\u8bd1\u7b49\u5e8f\u5217\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b013\u500d\u52a0\u901f\uff0c\u663e\u8457\u51cf\u5c11\u5404\u7c7b\u9519\u8bef\u3002", "motivation": "\u8bb8\u591a\u5e8f\u5217\u5230\u5e8f\u5217\u4efb\u52a1\uff08\u5982\u591a\u8bed\u8a00\u97f3\u8bd1\u3001\u4ee3\u7801\u91cd\u6784\u3001\u8bed\u6cd5\u4fee\u6b63\u7b49\uff09\u4e3b\u8981\u4f9d\u8d56\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u867d\u7136\u51c6\u786e\u4f46\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0c\u800c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u901f\u5ea6\u5feb\u4f46\u5b58\u5728\u5e7b\u89c9\u548c\u957f\u5ea6\u63a7\u5236\u95ee\u9898\uff0c\u9700\u8981\u63a2\u7d22\u5e73\u8861\u65b9\u6848\u3002", "method": "\u63d0\u51faNADIR\u67b6\u6784\uff0c\u7ed3\u5408\u5dee\u5206\u53d8\u6362\u5668\u548c\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u65e0\u9700\u987a\u5e8f\u4f9d\u8d56\u5373\u53ef\u7a33\u5065\u5efa\u6a21\u590d\u6742\u5b57\u7b26\u6620\u5c04\uff0c\u4e13\u95e8\u9488\u5bf9\u5370\u5ea6\u8bed\u8a00\u7684\u591a\u8bed\u8a00\u97f3\u8bd1\u4efb\u52a1\u8bbe\u8ba1\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u57fa\u7ebf\u5b9e\u73b013\u500d\u4ee5\u4e0a\u52a0\u901f\uff0c\u5b57\u7b26\u9519\u8bef\u738715.78%\uff08\u81ea\u56de\u5f5214.44%\uff0c\u6807\u51c6\u975e\u81ea\u56de\u5f5221.88%\uff09\uff0c\u663e\u8457\u51cf\u5c11\u91cd\u590d\u9519\u8bef49.53%\u3001\u66ff\u6362\u9519\u8bef24.45%\u3001\u7701\u7565\u9519\u8bef32.92%\u3001\u63d2\u5165\u9519\u8bef16.87%\u3002", "conclusion": "NADIR\u4e3a\u6784\u5efa\u5feb\u901f\u53ef\u9760\u7684\u975e\u81ea\u56de\u5f52\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u84dd\u56fe\uff0c\u6709\u6548\u5f25\u5408\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u51c6\u786e\u6027\u4e0e\u5b9e\u65f6\u5927\u89c4\u6a21\u90e8\u7f72\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2601.12296", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12296", "abs": "https://arxiv.org/abs/2601.12296", "authors": ["Hong Zheng", "Fei Teng"], "title": "Distribution Shift Is Key to Learning Invariant Prediction", "comment": null, "summary": "An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u8d8a\u5927\uff0cERM\u65b9\u6cd5\u8d8a\u80fd\u63a5\u8fd1\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u751a\u81f3\u6709\u65f6\u4f18\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684OOD\u65b9\u6cd5", "motivation": "\u89c2\u5bdf\u5230\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u6709\u65f6\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684\u65b9\u6cd5\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u7b97\u6cd5\u8bbe\u8ba1\u4e4b\u5916\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u8bad\u7ec3\u57df\u95f4\u7684\u5206\u5e03\u504f\u79fb\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u4e0a\u754c\u5206\u6790\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u5bf9\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u7279\u5b9a\u6570\u636e\u6761\u4ef6\u4e0b\u8bc1\u660eERM\u89e3\u80fd\u8fbe\u5230\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff1b\u540c\u65f6\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u89c2\u5bdf\u5206\u5e03\u504f\u79fb\u589e\u5927\u65f6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u5982\u4f55\u903c\u8fd1Oracle\u6216\u6700\u4f18\u6a21\u578b", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u5206\u5e03\u504f\u79fb\u7a0b\u5ea6\u76f4\u63a5\u5f71\u54cd\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u504f\u79fb\u8d8a\u5927\u6a21\u578b\u80fd\u529b\u8d8a\u5f3a\uff0c\u8d8a\u80fd\u903c\u8fd1\u5728\u4e0d\u540c\u57df\u4e2d\u505a\u51fa\u7a33\u5b9a\u9884\u6d4b\u7684\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\uff1b\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u5f53\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u504f\u79fb\u589e\u5927\u65f6\uff0c\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u786e\u5b9e\u80fd\u903c\u8fd1Oracle\u6216\u6700\u4f18\u6a21\u578b", "conclusion": "\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u662f\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\u4e0d\u53d8\u9884\u6d4b\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5927\u7684\u5206\u5e03\u504f\u79fb\u80fd\u4f7fERM\u65b9\u6cd5\u83b7\u5f97\u63a5\u8fd1\u4e0d\u53d8\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u6709\u65f6\u7b80\u5355\u7684ERM\u80fd\u80dc\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684OOD\u65b9\u6cd5"}}
{"id": "2601.12842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12842", "abs": "https://arxiv.org/abs/2601.12842", "authors": ["Qitong Fang", "Haotian Li", "Xu Wang"], "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning", "comment": "11 pages, 3 figures. Equal contribution: Qitong Fang and Haotian Li. Corresponding authors: Qitong Fang (fangqitong@student.jlju.edu.cn), Haotian Li (lihaotian@student.jlju.edu.cn), Xu Wang (wangxu@jlju.edu.cn)", "summary": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.", "AI": {"tldr": "SCULPT\uff1a\u4e00\u79cd\u7ea6\u675f\u5f15\u5bfc\u7684\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u9886\u57df\u611f\u77e5\u8bc4\u5206\u548c\u526a\u679d\u6765\u63d0\u5347LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u63a8\u7406\u7a33\u5b9a\u6027", "motivation": "\u5f53\u524dLLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u641c\u7d22\u7b56\u7565\u4f9d\u8d56\u968f\u673a\u63a2\u7d22\uff0c\u7ecf\u5e38\u904d\u5386\u4e0d\u5408\u7406\u5206\u652f\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u901a\u7528\u63d0\u793a\u6216\u5f31\u9886\u57df\u5148\u9a8c\u7684\u7b56\u7565\u6765\u91c7\u6837\u5019\u9009\u6b65\u9aa4\uff0c\u5bfc\u81f4\u5728\u64cd\u4f5c\u7b26\u3001\u5355\u4f4d\u548c\u683c\u5f0f\u4e0a\u7684\u8fd1\u4f3c\u968f\u673a\u6e38\u8d70", "method": "SCULPT\u5c06\u9886\u57df\u611f\u77e5\u8bc4\u5206\u96c6\u6210\u5230MCTS\u7684\u9009\u62e9\u3001\u6269\u5c55\u3001\u6a21\u62df\u548c\u53cd\u5411\u4f20\u64ad\u9636\u6bb5\uff0c\u4f7f\u7528\u7b26\u53f7\u68c0\u67e5\uff08\u7ef4\u5ea6\u4e00\u81f4\u6027\u3001\u7c7b\u578b\u517c\u5bb9\u6027\u3001\u5e45\u5ea6\u5408\u7406\u6027\u3001\u6df1\u5ea6\u63a7\u5236\u548c\u591a\u6837\u6027\uff09\u548c\u7ed3\u6784\u6a21\u5f0f\u6307\u5bfc\u6765\u8bc4\u5206\u548c\u526a\u679d\u52a8\u4f5c", "result": "\u5728\u5339\u914d\u7684LLM\u914d\u7f6e\u4e0b\uff0cSCULPT\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5e26\u6765\u7a33\u5b9a\u6539\u8fdb\uff1b\u4f7f\u7528GPT-5.2\u7684\u989d\u5916\u7ed3\u679c\u8bc4\u4f30\u4e86\u6267\u884c\u5668\u53ef\u8fc1\u79fb\u6027\u548c\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd", "conclusion": "\u9886\u57df\u611f\u77e5\u7ea6\u675f\u53ef\u4ee5\u5728\u4fdd\u6301\u6548\u7387\u548c\u63a8\u7406\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u6027"}}
{"id": "2601.12419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12419", "abs": "https://arxiv.org/abs/2601.12419", "authors": ["Mahammad Namazov", "Tom\u00e1\u0161 Koref", "Ivan Habernal"], "title": "Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification", "comment": null, "summary": "Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's \"reasons\" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6cd5\u5f8b\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u53d1\u73b0\u6a21\u578b\u9884\u6d4b\u8fdd\u89c4\u7684\"\u7406\u7531\"\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u7684\u5224\u65ad\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5c3d\u7ba1\u91cf\u5316\u5206\u6790\u7ed3\u679c\u548c\u5206\u7c7b\u6027\u80fd\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u6cd5\u5f8b\u9886\u57df\u5e94\u7528\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\uff0c\u4f46\u54ea\u79cd\u6280\u672f\u80fd\u6700\u597d\u5730\u89e3\u91ca\u6cd5\u5f8b\u7ed3\u679c\u9884\u6d4b\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6bd4\u8f83\u5206\u6790\u6846\u67b6\u6765\u8bc4\u4f30\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6bd4\u8f83\u5206\u6790\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u79cd\u7406\u7531\u63d0\u53d6\u65b9\u6cd5\uff08\u4ece\u8f93\u5165\u6587\u672c\u4e2d\u63d0\u53d6\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u7b80\u6d01\u6587\u672c\u7247\u6bb5\u4f5c\u4e3a\u7406\u7531\uff09\uff0c\u901a\u8fc7\u5fe0\u5b9e\u6027\uff08\u6807\u51c6\u5316\u5145\u5206\u6027\u548c\u5168\u9762\u6027\u6307\u6807\uff09\u548c\u5408\u7406\u6027\uff08\u8bf7\u6cd5\u5f8b\u4e13\u5bb6\u8bc4\u4f30\u63d0\u53d6\u7684\u7406\u7531\uff09\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u8bc4\u4f30LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u53ef\u884c\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u91cf\u5316\u5206\u6790\u7ed3\u679c\u548c\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6a21\u578b\u9884\u6d4b\u8fdd\u89c4\u7684\"\u7406\u7531\"\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u7684\u5224\u65ad\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u8fd9\u8868\u660e\u4ec5\u9760\u5b9a\u91cf\u6307\u6807\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u6cd5\u5f8b\u9886\u57df\u6a21\u578b\u89e3\u91ca\u7684\u8d28\u91cf\u3002", "conclusion": "\u5728\u6cd5\u5f8b\u9886\u57df\u5e94\u7528\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u9700\u8981\u7ed3\u5408\u5b9a\u91cf\u6307\u6807\u548c\u4e13\u5bb6\u8bc4\u4f30\u6765\u5168\u9762\u8bc4\u4f30\u53ef\u89e3\u91ca\u6027\u6280\u672f\u3002\u6a21\u578b\u9884\u6d4b\u7684\"\u7406\u7531\"\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u5dee\u5f02\u5f3a\u8c03\u4e86\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u5728\u9a8c\u8bc1\u6a21\u578b\u89e3\u91ca\u8d28\u91cf\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.12305", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12305", "abs": "https://arxiv.org/abs/2601.12305", "authors": ["Deepak Kanneganti", "Sajib Mistry", "Sheik Fattah", "Joshua Boland", "Aneesh Krishna"], "title": "Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments", "comment": null, "summary": "We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition", "AI": {"tldr": "\u63d0\u51faMLaaS\u6570\u636e\u96c6\u751f\u6210\u5668(MDG)\u6846\u67b6\uff0c\u7528\u4e8e\u521b\u5efa\u53ef\u914d\u7f6e\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30MLaaS\u670d\u52a1\u9009\u62e9\u548c\u7ec4\u5408\uff0c\u901a\u8fc7\u6a21\u62df\u771f\u5b9eMLaaS\u884c\u4e3a\u751f\u6210\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u5316\u8bc4\u4f30MLaaS\u670d\u52a1\u9009\u62e9\u548c\u7ec4\u5408\u7684\u65b9\u6cd5\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u914d\u7f6e\u3001\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\u6765\u6a21\u62df\u771f\u5b9eMLaaS\u884c\u4e3a\u548c\u670d\u52a1\u4ea4\u4e92\u3002", "method": "\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u5bb6\u65cf\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6570\u636e\u5206\u5e03\u8bbe\u7f6e\u4e0b\uff0c\u8bb0\u5f55\u529f\u80fd\u5c5e\u6027\u3001\u670d\u52a1\u8d28\u91cf\u6307\u6807\u548c\u7ec4\u5408\u7279\u5b9a\u6307\u6807\uff0c\u5b9e\u73b0\u5185\u7f6e\u7ec4\u5408\u673a\u5236\u6a21\u62df\u7269\u8054\u7f51\u6761\u4ef6\u4e0b\u7684\u670d\u52a1\u4ea4\u4e92\u3002", "result": "\u751f\u6210\u8d85\u8fc7\u4e00\u4e07\u4e2aMLaaS\u670d\u52a1\u5b9e\u4f8b\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660eMDG\u751f\u6210\u7684\u6570\u636e\u96c6\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u9ad8\u4e86\u9009\u62e9\u51c6\u786e\u6027\u548c\u7ec4\u5408\u8d28\u91cf\u3002", "conclusion": "MDG\u4e3a\u63a8\u8fdbMLaaS\u9009\u62e9\u548c\u7ec4\u5408\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6765\u7cfb\u7edf\u8bc4\u4f30\u670d\u52a1\u6027\u80fd\u3002"}}
{"id": "2601.12856", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12856", "abs": "https://arxiv.org/abs/2601.12856", "authors": ["Liping Huang", "Gaoxi Xiao", "Stefan Ma", "Hechang Chen", "Shisong Tang", "Flora Salim"], "title": "Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data", "comment": "9 pages, 9 figures. It's accepted by WWW 2026 Web4Good Track. To make accessible earlier, authors would like to put it on arxiv before the conference", "summary": "Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ece\u516c\u5f00\u767b\u9769\u70ed\u75c5\u4f8b\u6570\u636e\u4e2d\u6316\u6398\u57ce\u5e02\u533a\u57df\u95f4\u6f5c\u5728\u4f20\u64ad\u94fe\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u4f20\u64ad\u98ce\u9669\u5e76\u89e3\u91ca\u57ce\u5e02\u8303\u56f4\u5185\u7684\u4f20\u64ad\u6a21\u5f0f", "motivation": "\u767b\u9769\u70ed\u5728\u70ed\u5e26\u57ce\u5e02\u5730\u533a\u6301\u7eed\u6784\u6210\u516c\u5171\u536b\u751f\u6311\u6218\uff0c\u9700\u8981\u9884\u6d4b\u4f20\u64ad\u98ce\u9669\u4ee5\u8fdb\u884c\u4e3b\u52a8\u5e72\u9884\u800c\u975e\u88ab\u52a8\u5e94\u5bf9\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u75c5\u4f8b\u89c6\u4e3a\u5b64\u7acb\u62a5\u544a\uff0c\u672a\u80fd\u6355\u6349\u533a\u57df\u95f4\u7684\u4f20\u64ad\u52a8\u6001\u3002", "method": "\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u4ece\u75c5\u4f8b\u6570\u636e\u4e2d\u5b66\u4e60\u9690\u85cf\u7684\u4f20\u64ad\u7f51\u7edc\uff0c\u5c06\u70ed\u70b9\u5f62\u6210\u5efa\u6a21\u4e3a\u53d7\u90bb\u8fd1\u533a\u57df\u6d41\u884c\u75c5\u52a8\u6001\u5f71\u54cd\u7684\u8fc7\u7a0b\u3002\u4f7f\u7528\u8fde\u7eed\u56db\u5468\u7684\u70ed\u70b9\u5386\u53f2\u6570\u636e\uff0c\u5e76\u9a8c\u8bc1\u63a8\u65ad\u7f51\u7edc\u5728\u8fde\u7eed\u5468\u95f4\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u65b0\u52a0\u57612013-2018\u548c2020\u5e74\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4ec5\u9700\u56db\u5468\u70ed\u70b9\u5386\u53f2\u6570\u636e\u5373\u53ef\u8fbe\u5230\u5e73\u5747F-score 0.79\u3002\u5b66\u4e60\u5230\u7684\u4f20\u64ad\u94fe\u4e0e\u901a\u52e4\u6d41\u9ad8\u5ea6\u4e00\u81f4\uff0c\u63ed\u793a\u4e86\u9690\u85cf\u7684\u6d41\u884c\u75c5\u4f20\u64ad\u4e0e\u4eba\u7c7b\u79fb\u52a8\u4e4b\u95f4\u7684\u53ef\u89e3\u91ca\u5173\u7cfb\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u516c\u5f00\u7684\u75c5\u4f8b\u6570\u636e\u8f6c\u5316\u4e3a\u9884\u6d4b\u6027\u548c\u89e3\u91ca\u6027\u8d44\u6e90\uff0c\u901a\u8fc7\u6316\u6398\u548c\u9a8c\u8bc1\u9690\u85cf\u7684\u4f20\u64ad\u52a8\u6001\uff0c\u4e3a\u516c\u5171\u536b\u751f\u89c4\u5212\u3001\u65e9\u671f\u5e72\u9884\u548c\u57ce\u5e02\u97e7\u6027\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u4f4e\u6210\u672c\u5de5\u5177\u3002"}}
{"id": "2601.12430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12430", "abs": "https://arxiv.org/abs/2601.12430", "authors": ["Tsan Tsai Chan", "Varsha Suresh", "Anisha Saha", "Michael Hahn", "Vera Demberg"], "title": "System-Mediated Attention Imbalances Make Vision-Language Models Say Yes", "comment": "Under review", "summary": "Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u7cfb\u7edf\u6ce8\u610f\u529b\u662fVLM\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u7cfb\u7edf\u6ce8\u610f\u529b\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u53ef\u4ee5\u6709\u6548\u6291\u5236\"\u662f\"\u504f\u89c1\u5e7b\u89c9", "motivation": "\u73b0\u6709\u7f13\u89e3VLM\u5e7b\u89c9\u7684\u65b9\u6cd5\u901a\u5e38\u504f\u5411\u56fe\u50cf\u4e2d\u5fc3\u89e3\u91ca\uff0c\u8fc7\u5ea6\u5f3a\u8c03\u589e\u52a0\u56fe\u50cf\u6ce8\u610f\u529b\u800c\u5ffd\u89c6\u7cfb\u7edf\u6a21\u6001\u7684\u4f5c\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u66f4\u5168\u9762\u7684\u7cfb\u7edf\u4ecb\u5bfc\u89e3\u91ca\uff0c\u5c06\u5e7b\u89c9\u5f52\u56e0\u4e8e\u529f\u80fd\u5197\u4f59\u7684\u7cfb\u7edf\u6743\u91cd\u51cf\u5c11\u4e86\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u7684\u6ce8\u610f\u529b", "method": "\u91c7\u7528\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6846\u67b6\uff0c\u5c06\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u5f52\u56e0\u4e8e\u529f\u80fd\u5197\u4f59\u7684\u7cfb\u7edf\u6743\u91cd\u3002\u901a\u8fc7\u56e0\u679c\u6027\u5730\u91cd\u65b0\u5206\u914d\u7cfb\u7edf\u6a21\u6001\u7684\u6ce8\u610f\u529b\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u8bc4\u4f30\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u6291\u5236\"\u662f\"\u504f\u89c1\u5e7b\u89c9\u7684\u6548\u679c", "result": "\u91cd\u65b0\u5206\u914d\u7cfb\u7edf\u6ce8\u610f\u529b\u5230\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\u663e\u8457\u6291\u5236\u4e86\"\u662f\"\u504f\u89c1\uff0c\u901a\u5e38\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u8bc1\u636e\u8868\u660e\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u901a\u8fc7\u9f13\u52b1\u4f9d\u8d56\u7c97\u7c92\u5ea6\u8f93\u5165\u8868\u5f81\u5bfc\u81f4\"\u662f\"\u504f\u89c1", "conclusion": "\u7cfb\u7edf\u6ce8\u610f\u529b\u662fVLM\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u53ef\u4f5c\u4e3a\u7f13\u89e3\u5e7b\u89c9\u7684\u6709\u6548\u6760\u6746\u3002\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6ce8\u610f\u529b\u4e0d\u5e73\u8861\u5bfc\u81f4\u5bf9\u7c97\u7c92\u5ea6\u8868\u5f81\u7684\u9ed8\u8ba4\u4f9d\u8d56\uff0c\u4e0d\u9002\u5408\u67d0\u4e9b\u4efb\u52a1"}}
{"id": "2601.12317", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12317", "abs": "https://arxiv.org/abs/2601.12317", "authors": ["Yiming Huang"], "title": "Explanova: Automatically Discover Data Insights in N \\times M Table via XAI Combined LLM Workflow", "comment": null, "summary": "Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.", "AI": {"tldr": "Explanova\u662f\u4e00\u4e2a\u57fa\u4e8e\u9884\u8bbeAutoML\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u4f7f\u7528\u672c\u5730\u5c0f\u578bLLM\u964d\u4f4e\u6210\u672c", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u4ee3\u7406\u5de5\u5177\u8c03\u7528\u7684\u6570\u636e\u5206\u6790\u6846\u67b6\uff08\u5982DeepAnalyze\u3001DataSage\u3001Datawise\uff09\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u6210\u672c\u8f83\u9ad8\u3002\u4f5c\u8005\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u9884\u8bbe\u7684AutoML\u5f0f\u5de5\u4f5c\u6d41\u6765\u5b9e\u73b0\u66f4\u7ecf\u6d4e\u7684\u6570\u636e\u5206\u6790\u81ea\u52a8\u5316", "method": "\u91c7\u7528\u9884\u8bbe\u7684AutoML\u5f0f\u5de5\u4f5c\u6d41\uff0c\u904d\u5386\u6240\u6709\u53ef\u80fd\u7684\u63a2\u7d22\u8def\u5f84\uff1aXn\u672c\u8eab\u7684\u7edf\u8ba1\u7279\u6027\u3001Xn1-Xn2\u5173\u7cfb\u3001Xn\u4e0e\u5176\u4ed6\u53d8\u91cf\u7684\u5173\u7cfb\uff0c\u6700\u540e\u8fdb\u884c\u89e3\u91ca\u3002\u5173\u952e\u521b\u65b0\u662f\u4f7f\u7528\u672c\u5730\u5c0f\u578bLLM\u6765\u964d\u4f4e\u6210\u672c", "result": "Explanova\u5b9e\u73b0\u4e86\u66f4\u7ecf\u6d4e\u7684\u6570\u636e\u5206\u6790\u81ea\u52a8\u5316\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u4e8e\u5927\u578bLLM\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u6210\u672c\u663e\u8457\u964d\u4f4e", "conclusion": "\u901a\u8fc7\u9884\u8bbeAutoML\u5de5\u4f5c\u6d41\u7ed3\u5408\u672c\u5730\u5c0f\u578bLLM\uff0c\u53ef\u4ee5\u6784\u5efa\u7ecf\u6d4e\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u6570\u636e\u5206\u6790\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u884c\u8def\u5f84"}}
{"id": "2601.12912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12912", "abs": "https://arxiv.org/abs/2601.12912", "authors": ["Andreas Br\u00e4nnstr\u00f6m", "Juan Carlos Nieves"], "title": "Human Emotion Verification by Action Languages via Answer Set Programming", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u7684\u884c\u52a8\u8bed\u8a00C-MT\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u5efa\u6a21\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\uff08\u5982\u60c5\u7eea\uff09\u5728\u53ef\u89c2\u5bdf\u884c\u52a8\u5e8f\u5217\u4e0b\u7684\u6f14\u5316\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63a7\u5236\u667a\u80fd\u4f53\u884c\u4e3a\u548c\u9650\u5236\u884c\u52a8\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u4e0d\u826f\u526f\u4f5c\u7528\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5f62\u5f0f\u5316\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u53d8\u5316\u3001\u652f\u6301\u53d7\u63a7\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\uff08\u5982\u60c5\u7eea\u8bc4\u4ef7\u7406\u8bba\uff09\u6765\u5efa\u6a21\u5fc3\u7406\u72b6\u6001\u7684\u591a\u7ef4\u914d\u7f6e\u3002", "method": "\u5728\u7b54\u6848\u96c6\u7f16\u7a0b\u548c\u8f6c\u79fb\u7cfb\u7edf\u57fa\u7840\u4e0a\u6784\u5efaC-MT\u8bed\u8a00\uff0c\u5f15\u5165\"forbids to cause\"\u56e0\u679c\u89c4\u5219\u548c\u4e13\u95e8\u7684\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u8868\u8fbe\u5f0f\u3002\u5c06\u5fc3\u7406\u53d8\u5316\u539f\u5219\u8f6c\u5316\u4e3a\u8f6c\u79fb\u7ea6\u675f\u548c\u4e0d\u53d8\u6027\u5c5e\u6027\uff0c\u4f7f\u7528\u8f6c\u79fb\u7cfb\u7edf\u4e2d\u7684\u8f68\u8ff9\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "result": "C-MT\u8bed\u8a00\u80fd\u591f\u5bf9\u5fc3\u7406\u72b6\u6001\u7684\u52a8\u6001\u6f14\u5316\u8fdb\u884c\u53d7\u63a7\u63a8\u7406\uff0c\u652f\u6301\u901a\u8fc7\u5206\u6790\u9075\u5faa\u4e0d\u540c\u5fc3\u7406\u5b66\u539f\u5219\u7684\u8f68\u8ff9\u6765\u6bd4\u8f83\u4e0d\u540c\u7684\u53d8\u5316\u52a8\u6001\u3002\u8be5\u6846\u67b6\u5df2\u5e94\u7528\u4e8e\u60c5\u7eea\u9a8c\u8bc1\u6a21\u578b\u7684\u8bbe\u8ba1\u3002", "conclusion": "C-MT\u8bed\u8a00\u4e3a\u5f62\u5f0f\u5316\u5efa\u6a21\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u6f14\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u60c5\u7eea\u9a8c\u8bc1\u7b49\u5e94\u7528\u573a\u666f\uff0c\u80fd\u591f\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u5bf9\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u8fdb\u884c\u53d7\u63a7\u63a8\u7406\u548c\u6bd4\u8f83\u5206\u6790\u3002"}}
{"id": "2601.12465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12465", "abs": "https://arxiv.org/abs/2601.12465", "authors": ["Miao Peng", "Weizhou Shen", "Nuo Chen", "Chenliang Li", "Ming Yan", "Jia Li"], "title": "Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the \"almost-there\" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from \"almost-there\" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.", "AI": {"tldr": "\u63d0\u51faDeepReasonQA\u548cLongPAS\u65b9\u6cd5\uff0c\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2dRLVR\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u5408\u6210\u9ad8\u96be\u5ea6\u591a\u8df3QA\u5bf9\uff0c\u5e76\u5229\u7528\u8fc7\u7a0b\u4f18\u52bf\u8d4b\u5f62\u6355\u6349\"\u51e0\u4e4e\u6b63\u786e\"\u8f68\u8ff9\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "motivation": "RLVR\u5728\u77ed\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u5b58\u5728\"\u51e0\u4e4e\u6b63\u786e\"\u73b0\u8c61\uff08\u8f68\u8ff9\u5927\u90e8\u5206\u6b63\u786e\u4f46\u5728\u6700\u540e\u4e00\u6b65\u5931\u8d25\uff09\u3002\u8fd9\u5f52\u56e0\u4e8e\uff1a1\uff09\u957f\u4e0a\u4e0b\u6587QA\u6570\u636e\u7f3a\u4e4f\u9ad8\u63a8\u7406\u5bc6\u5ea6\uff1b2\uff09\u957f\u4e0a\u4e0b\u6587RL\u8bad\u7ec3\u4e2d\u90e8\u5206\u6b63\u786e\u8f68\u8ff9\u7684\u5b66\u4e60\u4fe1\u53f7\u4e22\u5931\u3002", "method": "1. DeepReasonQA\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u63a7\u5408\u6210\u6846\u67b6\uff0c\u6784\u5efa\u9ad8\u96be\u5ea6\u3001\u591a\u8df3\u7684\u957f\u4e0a\u4e0b\u6587QA\u5bf9\uff0c\u5305\u542b\u5185\u5728\u63a8\u7406\u94fe\u30022. LongPAS\uff1a\u957f\u4e0a\u4e0b\u6587\u8fc7\u7a0b\u4f18\u52bf\u8d4b\u5f62\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u6548\u6027\u548c\u76f8\u5173\u6027\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u4ece\"\u51e0\u4e4e\u6b63\u786e\"\u8f68\u8ff9\u4e2d\u6355\u6349\u5173\u952e\u5b66\u4e60\u4fe1\u53f7\u3002", "result": "\u5728\u4e09\u4e2a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8eRLVR\u57fa\u7ebf\uff0c\u4e0e\u524d\u6cbfLLM\u6027\u80fd\u76f8\u5f53\u4f46\u4f7f\u7528\u66f4\u5c11\u53c2\u6570\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u5728\u589e\u5f3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u548c\u4fdd\u6301RL\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5408\u6210\u9ad8\u63a8\u7406\u5bc6\u5ea6\u6570\u636e\u548c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2dRLVR\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12322", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12322", "abs": "https://arxiv.org/abs/2601.12322", "authors": ["Chang-Wei Shi", "Shi-Shang Wang", "Wu-Jun Li"], "title": "Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays", "comment": null, "summary": "Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \\underline{or}dered \\underline{lo}cal \\underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.", "AI": {"tldr": "\u63d0\u51faOrLoMo\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u5e26\u5c40\u90e8\u66f4\u65b0\u7684\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\uff0c\u901a\u8fc7\u6709\u5e8f\u805a\u5408\u5c40\u90e8\u52a8\u91cf\u6765\u52a0\u901f\u5f02\u6784\u96c6\u7fa4\u8bad\u7ec3\u3002", "motivation": "\u52a8\u91cfSGD\u662f\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7684\u57fa\u7840\u4f18\u5316\u5668\uff0c\u5f02\u6b65\u5206\u5e03\u5f0f\u5b66\u4e60\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u80fd\u529b\u5f02\u6784\u7684\u96c6\u7fa4\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u4e0e\u5c40\u90e8\u66f4\u65b0\u7684\u7ed3\u5408\u65b9\u6848\u3002", "method": "\u63d0\u51faOrLoMo\uff08\u6709\u5e8f\u5c40\u90e8\u52a8\u91cf\uff09\u65b9\u6cd5\uff1a\u6bcf\u4e2a\u5de5\u4f5c\u8282\u70b9\u672c\u5730\u8fd0\u884c\u52a8\u91cfSGD\uff0c\u670d\u52a1\u5668\u6839\u636e\u5168\u5c40\u8fed\u4ee3\u7d22\u5f15\u6709\u5e8f\u805a\u5408\u5404\u5de5\u4f5c\u8282\u70b9\u7684\u5c40\u90e8\u52a8\u91cf\u3002", "result": "OrLoMo\u662f\u9996\u4e2a\u5b9e\u73b0\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u4e0e\u5c40\u90e8\u66f4\u65b0\u7684\u65b9\u6cd5\uff0c\u5728\u975e\u51f8\u95ee\u9898\u4e0b\u8bc1\u660e\u4e86\u4efb\u610f\u5ef6\u8fdf\u7684\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u540c\u6b65\u65b9\u6cd5\u548c\u5176\u4ed6\u5f02\u6b65\u65b9\u6cd5\u3002", "conclusion": "OrLoMo\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u6b65\u5206\u5e03\u5f0f\u52a8\u91cfSGD\u4e0e\u5c40\u90e8\u66f4\u65b0\u7684\u5b9e\u73b0\u95ee\u9898\uff0c\u4e3a\u5f02\u6784\u96c6\u7fa4\u7684\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12913", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12913", "abs": "https://arxiv.org/abs/2601.12913", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Francesco Giannini", "Alberto Termine", "Filippo Bonchi", "Mateja Jamnik", "Giuseppe Marra"], "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries", "comment": null, "summary": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5b58\u5728\u6839\u672c\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\uff0c\u65e0\u6cd5\u63a8\u5bfc\u51fa\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u5b9a\u4e49\uff0c\u5e76\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\u89e3\u51b3\u53ef\u89e3\u91ca\u6027\u7684\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u9762\u4e34\u6839\u672c\u6027\u6311\u6218\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u53ef\u89e3\u91ca\u6027\u5b9a\u4e49\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\u3002\u8fd9\u4e9b\u5b9a\u4e49\u672a\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u539f\u5219\uff0c\u65e0\u6cd5\u4ece\u4e2d\u63a8\u5bfc\u51fa\u5177\u4f53\u7684\u5efa\u6a21\u548c\u63a8\u7406\u89c4\u5219\uff0c\u5bfc\u81f4\u8be5\u9886\u57df\u7814\u7a76\u57fa\u7840\u4e0d\u7262\u56fa\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u64cd\u4f5c\u5b9a\u4e49\u65b9\u6cd5\u3002\u5047\u8bbe\u56db\u79cd\u5bf9\u79f0\u6027\u8db3\u4ee5\uff1a(1) \u6fc0\u53d1\u6838\u5fc3\u53ef\u89e3\u91ca\u6027\u5c5e\u6027\uff0c(2) \u523b\u753b\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u7c7b\u522b\uff0c(3) \u63a8\u5bfc\u7edf\u4e00\u7684\u53ef\u89e3\u91ca\u63a8\u7406\u516c\u5f0f\uff08\u5982\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\uff09\uff0c\u5c06\u5176\u89c6\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53ef\u89e3\u91ca\u6027\u7406\u8bba\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4e3a\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5b9a\u4e49\uff0c\u7edf\u4e00\u5904\u7406\u5bf9\u9f50\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u7b49\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u5c06\u5176\u5f62\u5f0f\u5316\u4e3a\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5bf9\u79f0\u6027\u4f5c\u4e3a\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u7840\uff0c\u53ef\u4ee5\u89e3\u51b3\u5f53\u524dAI\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u6839\u672c\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u53ef\u64cd\u4f5c\u7684\u3001\u5f62\u5f0f\u5316\u7684\u53ef\u89e3\u91ca\u6027\u7406\u8bba\u63d0\u4f9b\u65b0\u9014\u5f84\uff0c\u4ece\u800c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002"}}
{"id": "2601.12471", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12471", "abs": "https://arxiv.org/abs/2601.12471", "authors": ["Sravanthi Machcha", "Sushrita Yerra", "Sahil Gupta", "Aishwarya Sahoo", "Sharmin Sultana", "Hong Yu", "Zonghai Yao"], "title": "Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty", "comment": "Equal contribution for the first two authors; To appear in proceedings of the Main Conference of the European Chapter of the Association for Computational Linguistics (EACL) 2026", "summary": "Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.", "AI": {"tldr": "MedAbstain\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u533b\u5b66\u591a\u9009\u9898\u4e2d\u5f03\u6743\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u53d1\u73b0\u5373\u4f7f\u9ad8\u51c6\u786e\u7387\u6a21\u578b\u4e5f\u5e38\u65e0\u6cd5\u5728\u4e0d\u786e\u5b9a\u65f6\u5f03\u6743\uff0c\u63d0\u4f9b\u660e\u786e\u5f03\u6743\u9009\u9879\u6bd4\u8f93\u5165\u6270\u52a8\u66f4\u80fd\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524dLLM\u8bc4\u4f30\u8fc7\u4e8e\u5f3a\u8c03\u51c6\u786e\u6027\uff0c\u4f46\u5728\u73b0\u5b9e\u4e16\u754c\u548c\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u65f6\u80fd\u591f\u5f03\u6743\u540c\u6837\u91cd\u8981\uff0c\u8fd9\u5bf9\u4e8e\u53ef\u4fe1\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faMedAbstain\u57fa\u51c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u6574\u5408\u4e86\u5171\u5f62\u9884\u6d4b\u3001\u5bf9\u6297\u6027\u95ee\u9898\u6270\u52a8\u548c\u660e\u786e\u5f03\u6743\u9009\u9879\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90LLMs\u5728\u533b\u5b66\u591a\u9009\u9898\u4e2d\u7684\u5f03\u6743\u80fd\u529b\u3002", "result": "\u5373\u4f7f\u6700\u5148\u8fdb\u7684LLMs\u4e5f\u7ecf\u5e38\u65e0\u6cd5\u5728\u4e0d\u786e\u5b9a\u65f6\u5f03\u6743\uff1b\u63d0\u4f9b\u660e\u786e\u5f03\u6743\u9009\u9879\u80fd\u663e\u8457\u589e\u52a0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u5b89\u5168\u5f03\u6743\uff0c\u6548\u679c\u8fdc\u4f18\u4e8e\u8f93\u5165\u6270\u52a8\uff1b\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u6216\u9ad8\u7ea7\u63d0\u793a\u6280\u672f\u6539\u5584\u6709\u9650\u3002", "conclusion": "\u5f03\u6743\u673a\u5236\u5bf9\u4e8eLLM\u53ef\u4fe1\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u6539\u8fdb\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.12330", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12330", "abs": "https://arxiv.org/abs/2601.12330", "authors": ["Zuha Fatima", "Muhammad Anser Sohaib", "Muhammad Talha", "Ayesha Kanwal", "Sidra Sultana", "Nazia Perwaiz"], "title": "IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning", "comment": null, "summary": "Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.", "AI": {"tldr": "\u63d0\u51faIceWatch\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u7a7a\u95f4\u89c6\u89c9\u4e0e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5b9e\u73b0\u51b0\u5ddd\u6e56\u6e83\u51b3\u6d2a\u6c34(GLOF)\u7684\u81ea\u52a8\u9884\u6d4b\u4e0e\u9884\u8b66\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edfGLOF\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u6c34\u6587\u5efa\u6a21\u3001\u9608\u503c\u76d1\u6d4b\u548c\u4eba\u5de5\u536b\u661f\u56fe\u50cf\u5206\u6790\uff0c\u5b58\u5728\u66f4\u65b0\u6162\u3001\u4f9d\u8d56\u4eba\u5de5\u3001\u4e91\u5c42\u5e72\u6270\u548c\u73b0\u573a\u6570\u636e\u7f3a\u4e4f\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u53ef\u9760\u7684\u81ea\u52a8\u9884\u6d4b\u7cfb\u7edf\u3002", "method": "IceWatch\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) RiskFlow\u89c6\u89c9\u7ec4\u4ef6\u4f7f\u7528CNN\u5206\u7c7b\u5668\u5206\u6790Sentinel-2\u591a\u5149\u8c31\u536b\u661f\u56fe\u50cf\uff0c\u57fa\u4e8e\u51b0\u96ea\u878d\u6c34\u7a7a\u95f4\u6a21\u5f0f\u9884\u6d4bGLOF\uff1b2) TerraFlow\u548cTempFlow\u5206\u522b\u4eceNASA ITS_LIVE\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u51b0\u5ddd\u901f\u5ea6\uff0c\u4eceMODIS LST\u8bb0\u5f55\u9884\u6d4b\u8fd1\u5730\u8868\u6e29\u5ea6\uff0c\u901a\u8fc7\u534f\u8c03\u9884\u5904\u7406\u548c\u540c\u6b65\u5b9e\u73b0\u591a\u6a21\u6001\u7269\u7406\u4fe1\u606f\u878d\u5408\u3002", "result": "\u7cfb\u7edf\u63d0\u4f9b\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u63d0\u9ad8GLOF\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u786e\u4fdd\u5f3a\u9884\u6d4b\u6027\u80fd\u3001\u5feb\u901f\u5b9e\u65f6\u6570\u636e\u5904\u7406\uff0c\u4ee5\u53ca\u5bf9\u566a\u58f0\u548c\u7f3a\u5931\u4fe1\u606f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "IceWatch\u4e3a\u81ea\u52a8\u3001\u53ef\u6269\u5c55\u7684GLOF\u9884\u8b66\u7cfb\u7edf\u94fa\u5e73\u9053\u8def\uff0c\u5177\u6709\u6574\u5408\u591a\u79cd\u4f20\u611f\u5668\u8f93\u5165\u548c\u5168\u7403\u51b0\u5ddd\u76d1\u6d4b\u6d3b\u52a8\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13060", "abs": "https://arxiv.org/abs/2601.13060", "authors": ["Zecheng Li", "Zhihui Cao", "Wenke Huang", "Yudong Zhang", "Keying Qi", "Rui Wang", "Zeyu Zheng", "Jian Zhao", "Hao Zhu", "Hengxin Wu", "Yuran Wang", "Guitao Fan", "Guokun Wu", "Yicong Liu", "Zhilin Gao", "Haikun Xu", "He Yang", "Minqi Xiang", "Xingyu Liu", "Zuojian Wang"], "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux", "comment": null, "summary": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.", "AI": {"tldr": "MagicGUI-RMS\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5956\u52b1\u6a21\u578b\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30GUI\u667a\u80fd\u4f53\u8f68\u8ff9\u3001\u63d0\u4f9b\u7ea0\u6b63\u53cd\u9988\u5e76\u5b9e\u73b0\u81ea\u6211\u8fdb\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u548c\u901a\u7528\u5956\u52b1\u6a21\u578b\u6765\u63d0\u5347GUI\u4efb\u52a1\u7684\u6267\u884c\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524dGUI\u667a\u80fd\u4f53\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u81ea\u52a8\u5316\u8bc4\u4f30\u667a\u80fd\u4f53\u8f68\u8ff9\u7684\u56f0\u96be\uff0c\u4ee5\u53ca\u5927\u89c4\u6a21\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u4ee5\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\u7684\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u9759\u6001\u89c4\u5219\u9a8c\u8bc1\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faMagicGUI-RMS\u591a\u667a\u80fd\u4f53\u5956\u52b1\u6a21\u578b\u7cfb\u7edf\uff0c\u6574\u5408\u9886\u57df\u7279\u5b9a\u5956\u52b1\u6a21\u578b\uff08DS-RM\uff09\u548c\u901a\u7528\u5956\u52b1\u6a21\u578b\uff08GP-RM\uff09\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u52a8\u4f5c\u8bc4\u4f30\u548c\u8de8\u5f02\u6784GUI\u4efb\u52a1\u7684\u9c81\u68d2\u6cdb\u5316\u3002\u8bbe\u8ba1\u4e86\u7ed3\u6784\u5316\u6570\u636e\u6784\u5efa\u7ba1\u9053\uff0c\u81ea\u52a8\u751f\u6210\u5e73\u8861\u591a\u6837\u7684\u5956\u52b1\u6570\u636e\u96c6\uff0c\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002\u7cfb\u7edf\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u56de\u6d41\u673a\u5236\u8bc6\u522b\u9519\u8bef\u52a8\u4f5c\u3001\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u5e76\u6301\u7eed\u589e\u5f3a\u667a\u80fd\u4f53\u884c\u4e3a\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMagicGUI-RMS\u5728\u4efb\u52a1\u51c6\u786e\u6027\u548c\u884c\u4e3a\u9c81\u68d2\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u8be5\u7cfb\u7edf\u4e3a\u6784\u5efa\u57fa\u4e8e\u5956\u52b1\u9002\u5e94\u7684\u81ea\u6211\u6539\u8fdbGUI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u4e14\u6709\u6548\u7684\u57fa\u7840\u3002", "conclusion": "MagicGUI-RMS\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5956\u52b1\u6a21\u578b\u7cfb\u7edf\u89e3\u51b3\u4e86GUI\u667a\u80fd\u4f53\u8bc4\u4f30\u548c\u8bad\u7ec3\u6570\u636e\u751f\u6210\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u8f68\u8ff9\u8bc4\u4f30\u3001\u7ea0\u6b63\u53cd\u9988\u548c\u81ea\u6211\u8fdb\u5316\u5b66\u4e60\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u81ea\u6211\u6539\u8fdb\u7684GUI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12473", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12473", "abs": "https://arxiv.org/abs/2601.12473", "authors": ["Renlong Jie", "Chen Chu", "Zhen Wang"], "title": "Capability-Aware Early-Stage Research Idea Evaluation", "comment": null, "summary": "Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u80fd\u529b\u611f\u77e5\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u4f5c\u8005\u4fe1\u606f\u548c\u7814\u7a76\u60f3\u6cd5\uff08\u65e0\u9700\u5b8c\u6574\u8bba\u6587\u6216\u5b9e\u9a8c\u7ed3\u679c\uff09\u6765\u9884\u6d4b\u8bba\u6587\u63a5\u53d7\u7387\u548c\u8bc4\u5206\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u5b8c\u6574\u6587\u672c\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728\u6982\u5ff5\u9636\u6bb5\uff08\u5373\u6295\u5165\u5927\u91cf\u8d44\u6e90\u4e4b\u524d\uff09\u9884\u6d4b\u7814\u7a76\u60f3\u6cd5\u7684\u7ed3\u679c\uff0c\u5bf9\u4e8e\u4f18\u5316\u79d1\u5b66\u8d44\u6e90\u5206\u914d\u548c\u7814\u7a76\u89c4\u5212\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u5df2\u5b8c\u6210\u7684\u624b\u7a3f\u6216\u540c\u884c\u8bc4\u5ba1\uff0c\u9700\u8981\u66f4\u65e9\u9636\u6bb5\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u80fd\u529b\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u8defTransformer\u67b6\u6784\u6574\u5408\u4f5c\u8005\u4fe1\u606f\u3001\uff08\u63a8\u65ad\u7684\uff09\u80fd\u529b\u5448\u73b0\u548c\u7814\u7a76\u60f3\u6cd5\uff0c\u91c7\u7528\u7075\u6d3b\u7684\u878d\u5408\u673a\u5236\u3002\u8fd8\u5f15\u5165\u4e24\u9636\u6bb5\u67b6\u6784\u6765\u5b66\u4e60\u7ed9\u5b9a\u4f5c\u8005\u4fe1\u606f\u548c\u60f3\u6cd5\u7684\u80fd\u529b\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8ebert-base\u548cbert-large\u5fae\u8c03\u7684\u5355\u8def\u6a21\u578b\uff0c\u80fd\u529b\u9884\u6d4b\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u7ec8\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u65e9\u671f\u7814\u7a76\u7ed3\u679c\u9884\u6d4b\u548c\u79d1\u5b66\u8d44\u6e90\u5206\u914d\uff0c\u4e3a\u7814\u7a76\u89c4\u5212\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2601.13122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13122", "abs": "https://arxiv.org/abs/2601.13122", "authors": ["Gourab K Patro", "Himanshi Agrawal", "Himanshu Gharat", "Supriya Panigrahi", "Nim Sherpa", "Vishal Vaddina", "Dagnachew Birru"], "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward", "comment": null, "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u901a\u7528AI\u7cfb\u7edf\u7684\u98ce\u9669\uff0c\u63d0\u51fa\u5176\u9ad8\u81ea\u7531\u5ea6\u8f93\u51fa\u5bfc\u81f4\u4f20\u7edf\u8d1f\u8d23\u4efbAI\u539f\u5219\u96be\u4ee5\u9002\u7528\uff0c\u9700\u8981\u57fa\u4e8eC2V2\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u6846\u67b6\u91cd\u65b0\u601d\u8003\u901a\u7528AI\u7684\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u4ee3\u901a\u7528AI\u7cfb\u7edf\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5728\u5e7b\u89c9\u3001\u6bd2\u6027\u3001\u504f\u89c1\u7b49\u65b9\u9762\u5b58\u5728\u98ce\u9669\uff0c\u4f7f\u5f97\u5b83\u4eec\u4e0d\u53ef\u4fe1\u3002\u4f20\u7edf\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1AI\u7684\u8d1f\u8d23\u4efbAI\u539f\u5219\uff08\u516c\u5e73\u6027\u3001\u9690\u79c1\u3001\u53ef\u89e3\u91ca\u6027\u7b49\uff09\u5728\u901a\u7528AI\u7cfb\u7edf\u4e2d\u96be\u4ee5\u9002\u7528\u6216\u7f13\u89e3\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u901a\u7528AI\u7684\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u901a\u7528AI\u4e0e\u4f20\u7edf\u7279\u5b9a\u4efb\u52a1AI\u5728\u516b\u4e2a\u8d1f\u8d23\u4efbAI\u539f\u5219\u4e0a\u7684\u5dee\u5f02\uff0c\u8bc6\u522b\u901a\u7528AI\u7684\u9ad8\u81ea\u7531\u5ea6\u8f93\u51fa\u7279\u6027\u662f\u6839\u672c\u95ee\u9898\u3002\u57fa\u4e8e\u6b64\u63d0\u51faC2V2\uff08\u63a7\u5236\u3001\u4e00\u81f4\u6027\u3001\u4ef7\u503c\u3001\u771f\u5b9e\u6027\uff09\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u5206\u6790\u73b0\u6709\u6280\u672f\uff08AI\u5bf9\u9f50\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u63a8\u7406\u589e\u5f3a\u7b49\uff09\u5982\u4f55\u6ee1\u8db3\u8fd9\u4e9b\u539f\u5219\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u901a\u7528AI\u7531\u4e8e\u8f93\u51fa\u81ea\u7531\u5ea6\u6781\u9ad8\uff0c\u5bfc\u81f4\u4f20\u7edf\u8d1f\u8d23\u4efbAI\u539f\u5219\u96be\u4ee5\u6709\u6548\u5b9e\u65bd\u3002\u63d0\u51fa\u7684C2V2\u6846\u67b6\u4e3a\u901a\u7528AI\u7684\u8d1f\u8d23\u4efb\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u73b0\u6709\u6280\u672f\u53ea\u80fd\u90e8\u5206\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\uff0c\u9700\u8981\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u7ed3\u5408\u591a\u79cd\u6280\u672f\u3002", "conclusion": "\u5f00\u53d1\u8d1f\u8d23\u4efb\u7684\u901a\u7528AI\u9700\u8981\u57fa\u4e8eC2V2\u7ef4\u5ea6\u5f62\u5f0f\u5316\u5efa\u6a21\u5e94\u7528\u6216\u9886\u57df\u76f8\u5173\u7684\u8d1f\u8d23\u4efbAI\u8981\u6c42\uff0c\u91c7\u7528\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u7ed3\u5408\u591a\u79cd\u6280\u672f\u6765\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\uff0c\u8fd9\u662f\u5b9e\u73b0\u901a\u7528AI\u8d1f\u8d23\u4efb\u53d1\u5c55\u7684\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.12505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12505", "abs": "https://arxiv.org/abs/2601.12505", "authors": ["Ashish Raj Shekhar", "Shiven Agarwal", "Priyanuj Bordoloi", "Yash Shah", "Tejas Anvekar", "Vivek Gupta"], "title": "DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.", "AI": {"tldr": "DoPE\u662f\u4e00\u79cd\u6587\u6863\u5c42\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5728PDF/HTML\u8003\u8bd5\u6587\u6863\u4e2d\u5d4c\u5165\u8bed\u4e49\u8bf1\u9975\u6765\u9632\u6b62\u548c\u68c0\u6d4bMLLM\u4f5c\u5f0a\uff0c\u65e0\u9700\u4f9d\u8d56\u4f20\u7edf\u5206\u7c7b\u5668\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u80fd\u591f\u76f4\u63a5\u5904\u7406\u8003\u8bd5\u6587\u6863\uff0c\u5a01\u80c1\u4f20\u7edf\u8bc4\u4f30\u548c\u5b66\u672f\u8bda\u4fe1\u3002\u9700\u8981\u5f00\u53d1\u6587\u6863\u5c42\u9632\u5fa1\u673a\u5236\u6765\u9632\u6b62AI\u81ea\u52a8\u5316\u4f5c\u5f0a\u3002", "method": "\u63d0\u51faDoPE\u6846\u67b6\uff0c\u5728\u6587\u6863\u521b\u4f5c\u65f6\u5d4c\u5165\u8bed\u4e49\u8bf1\u9975\uff0c\u5229\u7528MLLM\u6e32\u67d3-\u89e3\u6790\u5dee\u5f02\u3002\u5305\u62ecFewSoRT-Q\u751f\u6210\u95ee\u9898\u7ea7\u8bed\u4e49\u8bf1\u9975\u548cFewSoRT-D\u5c06\u5176\u5c01\u88c5\u5230\u6c34\u5370\u6587\u6863\u4e2d\u3002", "result": "\u5728Integrity-Bench\u57fa\u51c6\uff081826\u4e2a\u8003\u8bd5\uff09\u4e0a\u6d4b\u8bd5\uff0c\u5bf9OpenAI\u548cAnthropic\u7684\u9ed1\u76d2MLLMs\uff1a\u68c0\u6d4b\u738791.4%\uff08\u8bef\u62a5\u73878.7%\uff09\uff0c96.3%\u7684\u5c1d\u8bd5\u88ab\u963b\u6b62\u6216\u8bf1\u5bfc\u8bf1\u9975\u5bf9\u9f50\u5931\u8d25\u3002", "conclusion": "DoPE\u63d0\u4f9b\u6a21\u578b\u65e0\u5173\u7684\u9884\u9632\u548c\u68c0\u6d4b\u80fd\u529b\uff0c\u6709\u6548\u4fdd\u62a4\u5b66\u672f\u8bda\u4fe1\uff0c\u5e76\u53d1\u5e03\u4e86\u57fa\u51c6\u3001\u5de5\u5177\u5305\u548c\u8bc4\u4f30\u4ee3\u7801\u4f9b\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2601.12355", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12355", "abs": "https://arxiv.org/abs/2601.12355", "authors": ["Beicheng Xu", "Weitong Qian", "Lingching Tung", "Yupeng Lu", "Bin Cui"], "title": "LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH", "comment": null, "summary": "To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.", "AI": {"tldr": "LB-MCTS\uff1a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7684AutoML\u6846\u67b6\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u89e3\u51b3CASH\u95ee\u9898\uff0c\u5728104\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u5b58\u5728\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u5668\u5728\u9ad8\u7ef4\u7ed3\u6784\u5316CASH\u7a7a\u95f4\u4e2d\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faLB-MCTS\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7ed3\u5408\u5728\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7ed3\u6784\u4e2d\uff0c\u4f7f\u7528\u9009\u62e9\u6027\u8c03\u4f18\u8bb0\u5fc6\uff08STM\uff09\u548c\u663e\u5f0f\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u968f\u7740\u6570\u636e\u79ef\u7d2f\u52a8\u6001\u4eceLLM\u9a71\u52a8\u8f6c\u5411BO\u9a71\u52a8", "result": "\u5728104\u4e2aAMLB\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLB-MCTS\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "LB-MCTS\u6210\u529f\u7ed3\u5408\u4e86LLM\u7684\u8bed\u4e49\u5148\u9a8c\u548cBO\u7684\u6570\u636e\u9a71\u52a8\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86CASH\u95ee\u9898\u4e2d\u7684\u51b7\u542f\u52a8\u548c\u9ad8\u7ef4\u6311\u6218"}}
{"id": "2601.13186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13186", "abs": "https://arxiv.org/abs/2601.13186", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching", "comment": "33 pages, 19 figures", "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86TIVS\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u51faTIVS-O\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u7f13\u5b58\u548c\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6765\u5e73\u8861\u591a\u667a\u80fd\u4f53LLM\u7684\u5b89\u5168\u6027\u4e0e\u900f\u660e\u5ea6\uff0c\u5b9e\u73b0\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u540c\u65f6\u964d\u4f4e41.6%\u7684LLM\u8c03\u7528\u3002", "motivation": "\u63d0\u793a\u6ce8\u5165\u4ecd\u7136\u662fLLM\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u4e2d\u95f4\u8f93\u51fa\u53ef\u80fd\u4f20\u64ad\u6216\u653e\u5927\u6076\u610f\u6307\u4ee4\u3002\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u9700\u8981\u6269\u5c55\u4ee5\u540c\u65f6\u8003\u8651\u5b89\u5168\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u3002", "method": "\u63d0\u51faTIVS-O\u7cfb\u7edf\uff0c\u7ed3\u5408\u8bed\u4e49\u76f8\u4f3c\u6027\u7f13\u5b58\u548c\u7b2c\u4e94\u4e2a\u6307\u6807\uff08\u53ef\u89c2\u6d4b\u6027\u8bc4\u5206\u6bd4\uff09\uff0c\u5728HOPE\u542f\u53d1\u7684\u5d4c\u5957\u5b66\u4e60\u67b6\u6784\u4e2d\u5b9e\u73b0\u3002\u7cfb\u7edf\u5305\u542b\u667a\u80fd\u4f53\u7ba1\u9053\u548c\u8fde\u7eed\u5185\u5b58\u7cfb\u7edf\uff0c\u4f7f\u7528301\u4e2a\u5408\u6210\u751f\u6210\u7684\u6ce8\u5165\u63d0\u793a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7b2c\u56db\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u4e94\u4e2a\u5173\u952e\u6027\u80fd\u6307\u6807\u8fdb\u884c\u5b89\u5168\u5206\u6790\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u96f6\u9ad8\u98ce\u9669\u6f0f\u6d1e\u7684\u5b89\u5168\u54cd\u5e94\uff0c\u8bed\u4e49\u7f13\u5b58\u663e\u8457\u51cf\u5c1141.6%\u7684LLM\u8c03\u7528\uff0c\u76f8\u5e94\u964d\u4f4e\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u78b3\u6392\u653e\u3002\u4e94\u79cdTIVS-O\u914d\u7f6e\u63ed\u793a\u4e86\u7f13\u89e3\u4e25\u683c\u6027\u4e0e\u53d6\u8bc1\u900f\u660e\u5ea6\u4e4b\u95f4\u7684\u6700\u4f73\u6743\u8861\u3002", "conclusion": "\u53ef\u89c2\u6d4b\u6027\u611f\u77e5\u8bc4\u4f30\u80fd\u63ed\u793a\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u7684\u975e\u5355\u8c03\u6548\u5e94\uff0c\u5185\u5b58\u589e\u5f3a\u667a\u80fd\u4f53\u53ef\u540c\u65f6\u6700\u5927\u5316\u5b89\u5168\u9c81\u68d2\u6027\u3001\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u8425\u6210\u672c\u8282\u7ea6\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u4e3a\u5b89\u5168\u548c\u7eff\u8272LLM\u90e8\u7f72\u63d0\u4f9b\u751f\u4ea7\u5c31\u7eea\u8def\u5f84\u3002"}}
{"id": "2601.12535", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12535", "abs": "https://arxiv.org/abs/2601.12535", "authors": ["Ahmed Attia", "Alham Fikri"], "title": "Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning", "comment": null, "summary": "Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u7684\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528NLLB\u6a21\u578b\u901a\u8fc7\u5f80\u8fd4\u7ffb\u8bd1\u8fdb\u884c\u5f15\u5bfc\uff0c\u5728\u591a\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u53d6\u5f97\u6539\u8fdb\u3002", "motivation": "\u968f\u7740\u4f4e\u8d44\u6e90\u8bed\u8a00\u793e\u533a\u5e73\u884c\u6570\u636e\u7684\u6536\u96c6\uff0c\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u5173\u6ce8\uff0c\u4f46\u8bb8\u591a\u6539\u8fdb\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u7684\u6f5c\u5728\u65b9\u6cd5\u5c1a\u672a\u88ab\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5982\u4f55\u5229\u7528\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u5347\u4f4e\u8d44\u6e90\u7ffb\u8bd1\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528NLLB\u6a21\u578b\u5bb6\u65cf\u8fdb\u884c\u5f80\u8fd4\u7ffb\u8bd1\u5f15\u5bfc\uff1a\u5148\u5c06\u82f1\u8bed\u7ffb\u8bd1\u6210\u76ee\u6807\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u518d\u7ffb\u8bd1\u56de\u82f1\u8bed\u3002\u4f7f\u7528chrF++\u548cBLEU\u7ec4\u5408\u4f5c\u4e3a\u91cd\u5efa\u82f1\u8bed\u53e5\u5b50\u7684\u5956\u52b1\u51fd\u6570\u3002\u5728NLLB-MD\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30600M\u548c1.3B\u53c2\u6570\u7684NLLB\u6a21\u578b\u3002", "result": "\u5728Central Aymara\u3001Friulian\u3001Wolof\u548cRussian\u7b49\u8bed\u8a00\u4e0a\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u6539\u8fdb\u3002\u7ffb\u8bd1\u8f93\u51fa\u7684\u5b9a\u6027\u68c0\u67e5\u8868\u660e\u6d41\u7545\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u6709\u6240\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u8fdb\u4e00\u6b65\u53d7\u76ca\u4e8e\u89c4\u6a21\u6269\u5c55\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8d8a\u6765\u8d8a\u591a\u5730\u5229\u7528\u5176\u9884\u8bad\u7ec3\u77e5\u8bc6\u5e76\u7ee7\u7eed\u81ea\u6211\u6539\u8fdb\u3002\u4e3a\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2601.12362", "categories": ["cs.LG", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2601.12362", "abs": "https://arxiv.org/abs/2601.12362", "authors": ["Natthapong Promsricha", "Chotirawee Chatpattanasiri", "Nuttavut Kerdgongsup", "Stavroula Balabani"], "title": "Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems", "comment": null, "summary": "Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.", "AI": {"tldr": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u5e38\u89c4\u8fc7\u7a0b\u4fe1\u53f7\uff08\u63a7\u5236\u5668\u8f93\u51faOP\u548c\u8fc7\u7a0b\u53d8\u91cfPV\uff09\u68c0\u6d4b\u548c\u9884\u6d4b\u63a7\u5236\u9600\u7c98\u6ede\u6545\u969c\uff0cLSTM\u6a21\u578b\u5728\u771f\u5b9e\u70bc\u6cb9\u5382\u6570\u636e\u4e0a\u5b9e\u73b0\u6700\u9ad8\u7cbe\u5ea6\uff0c\u53ef\u63d0\u524d4\u5c0f\u65f6\u9884\u6d4b", "motivation": "\u63a7\u5236\u9600\u7c98\u6ede\u662f\u5de5\u4e1a\u8fc7\u7a0b\u7cfb\u7edf\u4e2d\u5e38\u89c1\u7684\u6545\u969c\uff0c\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u3001\u8bbe\u5907\u78e8\u635f\u548c\u7ef4\u62a4\u6210\u672c\u589e\u52a0\u3002\u8bb8\u591a\u5de5\u5382\u4ecd\u5728\u4f7f\u7528\u7f3a\u4e4f\u5b9e\u65f6\u76d1\u63a7\u7684\u4f20\u7edf\u9600\u95e8\uff0c\u4f7f\u5f97\u65e9\u671f\u9884\u6d4b\u53d8\u5f97\u56f0\u96be", "method": "\u5f00\u53d1\u4e86\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff1aCNN\u3001CNN-SVM\u6df7\u5408\u6a21\u578b\u548cLSTM\u7f51\u7edc\u3002\u91c7\u7528\u57fa\u4e8e\u659c\u7387\u6bd4\u5206\u6790\u7684\u6570\u636e\u9a71\u52a8\u6807\u6ce8\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u77f3\u6cb9\u548c\u5929\u7136\u6c14\u70bc\u6cb9\u5382\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3", "result": "LSTM\u6a21\u578b\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u80fd\u591f\u63d0\u524d4\u5c0f\u65f6\u9884\u6d4b\u7c98\u6ede\u6545\u969c\u3002\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u6b21\u57fa\u4e8e\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u5c55\u793a\u673a\u5668\u5b66\u4e60\u65e9\u671f\u9884\u6d4b\u63a7\u5236\u9600\u7c98\u6ede\u7684\u7814\u7a76", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ee5\u96c6\u6210\u5230\u73b0\u6709\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u652f\u6301\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u51cf\u5c11\u505c\u673a\u65f6\u95f4\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u786c\u4ef6\u66f4\u6362"}}
{"id": "2601.13206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13206", "abs": "https://arxiv.org/abs/2601.13206", "authors": ["Neil K. R. Sehgal", "Sharath Chandra Guntuku", "Lyle Ungar"], "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues", "comment": null, "summary": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u5b9e\u65f6\u8c08\u5224\u4e2d\u7f3a\u4e4f\u65f6\u95f4\u610f\u8bc6\uff0c\u5f53\u63d0\u4f9b\u5269\u4f59\u65f6\u95f4\u4fe1\u606f\u65f6\u4ea4\u6613\u6210\u529f\u7387\u5927\u5e45\u63d0\u5347\uff0c\u8868\u660eLLMs\u96be\u4ee5\u5185\u90e8\u8ffd\u8e2a\u65f6\u95f4\u6d41\u901d", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6c9f\u901a\uff08\u5982\u6cbb\u7597\u4f1a\u8bdd\u3001\u5546\u4e1a\u8c08\u5224\uff09\u4f9d\u8d56\u4e8e\u8fde\u7eed\u65f6\u95f4\u7ea6\u675f\uff0c\u4f46\u5f53\u524dLLM\u67b6\u6784\u548c\u8bc4\u4f30\u534f\u8bae\u5f88\u5c11\u6d4b\u8bd5\u5b9e\u65f6\u622a\u6b62\u65f6\u95f4\u4e0b\u7684\u65f6\u95f4\u610f\u8bc6", "method": "\u4f7f\u7528\u6a21\u62df\u8c08\u5224\u5b9e\u9a8c\uff0c\u914d\u5bf9\u667a\u80fd\u4f53\u5728\u4e25\u683c\u622a\u6b62\u65f6\u95f4\u4e0b\u8fdb\u884c\u8c08\u5224\u3002\u8bbe\u7f6e\u63a7\u5236\u6761\u4ef6\uff08\u4ec5\u77e5\u5168\u5c40\u65f6\u95f4\u9650\u5236\uff09\u548c\u65f6\u95f4\u611f\u77e5\u6761\u4ef6\uff08\u6bcf\u56de\u5408\u63a5\u6536\u5269\u4f59\u65f6\u95f4\u66f4\u65b0\uff09\uff0c\u6bd4\u8f83\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0", "result": "\u65f6\u95f4\u611f\u77e5\u6761\u4ef6\u4e0b\u4ea4\u6613\u5173\u95ed\u7387\u663e\u8457\u63d0\u9ad8\uff08GPT-5.1\uff1a32% vs 4%\uff09\uff0c\u62a5\u4ef7\u63a5\u53d7\u7387\u63d0\u9ad8\u516d\u500d\u3002\u4f46\u5728\u56de\u5408\u5236\u9650\u5236\u4e0b\uff0c\u76f8\u540cLLMs\u80fd\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u4ea4\u6613\u5173\u95ed\u7387\uff08\u226595%\uff09", "conclusion": "LLMs\u5b58\u5728\u7cfb\u7edf\u6027\u65f6\u95f4\u610f\u8bc6\u7f3a\u4e4f\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u8bb8\u591a\u65f6\u95f4\u654f\u611f\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u3002\u5931\u8d25\u539f\u56e0\u5728\u4e8e\u65f6\u95f4\u8ffd\u8e2a\u800c\u975e\u6218\u7565\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.12549", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12549", "abs": "https://arxiv.org/abs/2601.12549", "authors": ["Ilia Badanin", "Daniil Dzenhaliou", "Imanol Schlag"], "title": "Benchmarking Concept-Spilling Across Languages in LLMs", "comment": null, "summary": "Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u9c81\u68d2\u6027\u7684\u6bd4\u8f83\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6d4b\u91cf\u6a21\u578b\u5904\u7406\u591a\u4e49\u8bcd\u7684\u80fd\u529b\u6765\u8bc4\u4f30\u8bed\u8a00\u6ea2\u51fa\u73b0\u8c61\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b9\u79cd\u8bed\u8a00\u3001100\u4e2a\u9ad8\u591a\u4e49\u6027\u82f1\u8bed\u5355\u8bcd\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5c55\u73b0\u51fa\u8de8\u8bed\u8a00\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5411\u5176\u4ed6\u8bed\u8a00\u8868\u793a\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u751f\u6210\u5185\u5bb9\u65f6\u51fa\u73b0\u8bed\u4e49\u5e72\u6270\uff08\u8bed\u8a00\u6ea2\u51fa\u73b0\u8c61\uff09\u3002\u9700\u8981\u5f00\u53d1\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cf\u6a21\u578b\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u6bd4\u8f83\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u610f\u4e49\u751f\u6210\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\u5904\u7406\u591a\u4e49\u8bcd\u7684\u80fd\u529b\u3002\u4f7f\u7528100\u4e2a\u9ad8\u591a\u4e49\u6027\u82f1\u8bed\u5355\u8bcd\u4f5c\u4e3a\u57fa\u51c6\uff0c\u57289\u79cd\u8bed\u8a00\u4e2d\u6d4b\u8bd5\u3002\u901a\u8fc7\u6d4b\u91cf\u6a21\u578b\u5728\u751f\u6210\u5e8f\u5217\u4e2d\u4f55\u65f6\u8f6c\u5411\u4e3b\u5bfc\u8bed\u8a00\u7684\u610f\u4e49\u6765\u76f8\u5bf9\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u8bc4\u4f30\u4e86\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u591a\u8bed\u8a00LLM\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u548c\u8bed\u8a00\u95f4\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u5efa\u7acb\u4e86\u65e0\u9700\u786e\u5b9a\u9519\u8bef\u6765\u6e90\u56e0\u679c\u5f52\u56e0\u7684\u6a21\u578b\u6bd4\u8f83\u6392\u5e8f\u7cfb\u7edf\u3002", "conclusion": "\u8d21\u732e\u4e86\u53ef\u6269\u5c55\u7684\u591a\u8bed\u8a00\u8bed\u4e49\u8bc4\u4f30\u6bd4\u8f83\u57fa\u51c6\u548c\u4e25\u683c\u7684\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4e3a\u5f00\u53d1\u66f4\u8bed\u8a00\u5e73\u8861\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\u3002"}}
{"id": "2601.13233", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.13233", "abs": "https://arxiv.org/abs/2601.13233", "authors": ["Bolin Chen", "Dex Doksoo Lee", "Wei \"Wayne'' Chen", "Wei Chen"], "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements", "comment": null, "summary": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.", "AI": {"tldr": "\u63d0\u51faRAG\u65b9\u6cd5\uff0c\u57fa\u4e8e\u968f\u673a\u68ee\u6797\u7684\u751f\u6210\u5f0f\u8bbe\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u9006\u8bbe\u8ba1\u5177\u6709\u529f\u80fd\u54cd\u5e94\u7684\u8d85\u6750\u6599", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u529f\u80fd\u54cd\u5e94\u7684\u9006\u8bbe\u8ba1\uff0c\u56e0\u4e3a\u529f\u80fd\u54cd\u5e94\u662f\u9ad8\u7ef4\u8fde\u7eed\u51fd\u6570\uff0c\u5b58\u5728\u89e3\u4e0d\u5b58\u5728\u6216\u4e0d\u552f\u4e00\u7684\u95ee\u9898\u3002\u751f\u6210\u5f0f\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4e14\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "method": "RAG\uff08\u968f\u673a\u68ee\u6797\u751f\u6210\u65b9\u6cd5\uff09\uff1a\u5229\u7528\u968f\u673a\u68ee\u6797\u7684\u5c0f\u6570\u636e\u517c\u5bb9\u6027\u9884\u6d4b\u9ad8\u7ef4\u529f\u80fd\u54cd\u5e94\uff1b\u901a\u8fc7\u96c6\u6210\u4f30\u8ba1\u4f3c\u7136\u6765\u91cf\u5316\u751f\u6210\u8bbe\u8ba1\u7684\u53ef\u4fe1\u5ea6\uff1b\u901a\u8fc7\u6761\u4ef6\u4f3c\u7136\u91c7\u6837\u5904\u7406\u4e00\u5bf9\u591a\u6620\u5c04\u95ee\u9898", "result": "\u5728\u58f0\u5b66\u8d85\u6750\u6599\uff08500\u6837\u672c\uff09\u548c\u529b\u5b66\u8d85\u6750\u6599\uff081057\u6837\u672c\uff09\u4e0a\u9a8c\u8bc1\u6210\u529f\uff1b\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u795e\u7ecf\u7f51\u7edc\u5c55\u73b0\u51fa\u6570\u636e\u6548\u7387\u4f18\u52bf", "conclusion": "RAG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u4fe1\u8d56\u7684\u9006\u8bbe\u8ba1\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u529f\u80fd\u54cd\u5e94\u3001\u6602\u8d35\u6a21\u62df\u548c\u590d\u6742\u8bbe\u8ba1\u8981\u6c42\u7684\u573a\u666f\uff0c\u53ef\u6269\u5c55\u5230\u8d85\u6750\u6599\u4ee5\u5916\u7684\u9886\u57df"}}
{"id": "2601.12555", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12555", "abs": "https://arxiv.org/abs/2601.12555", "authors": ["Yihong Liu", "Bingyu Xiong", "Hinrich Sch\u00fctze"], "title": "Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models", "comment": "preprint", "summary": "Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.", "AI": {"tldr": "LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u7684\u4e8b\u5b9e\u56de\u5fc6\u4e2d\u8868\u73b0\u4e0b\u964d\uff0c\u5c3d\u7ba1\u5927\u6a21\u578b\u5bf9\u6b64\u66f4\u9c81\u68d2\uff0c\u63ed\u793a\u4e86\u5b64\u7acb\u4e8b\u5b9e\u56de\u5fc6\u4e0e\u4e0a\u4e0b\u6587\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u56de\u5fc6\u8bc4\u4f30\u4e3b\u8981\u8bc4\u4f30\u5b64\u7acb\u7684\u4e8b\u5b9e\u68c0\u7d22\uff0c\u4f46\u5728\u81ea\u7136\u8bed\u8a00\u4f7f\u7528\u4e2d\uff0c\u4e8b\u5b9e\u901a\u5e38\u901a\u8fc7\u4e0a\u4e0b\u6587\u95f4\u63a5\u8bbf\u95ee\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76LLMs\u5728\u76ee\u6807\u5b9e\u4f53\u5d4c\u5165\u81ea\u7136\u8bed\u5883\u800c\u975e\u663e\u5f0f\u67e5\u8be2\u65f6\uff0c\u80fd\u5426\u53ef\u9760\u5730\u68c0\u7d22\u8de8\u8bed\u8a00\u7684\u4e8b\u5b9e\u77e5\u8bc6\u3002", "method": "\u6784\u5efa\u4fdd\u7559\u5e95\u5c42\u4e8b\u5b9e\u4f46\u901a\u8fc7\u4e0a\u4e0b\u6587\u53e5\u5b50\u5f15\u5165\u6307\u79f0\u4e2d\u4ecb\u7684\u53d7\u63a7\u63d0\u793a\uff1b\u4f7f\u7528\u5408\u6210\u540d\u79f0\u548c\u771f\u5b9e\u540d\u79f0\u6765\u5206\u79bb\u4e0a\u4e0b\u6587\u6548\u5e94\u4e0e\u540d\u79f0\u7279\u5b9a\u5173\u8054\uff1b\u5728\u4e94\u79cd\u8bed\u8a00\u4e2d\u8bc4\u4f30\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u3002", "result": "\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u6301\u7eed\u964d\u4f4e\u4e8b\u5b9e\u56de\u5fc6\u6027\u80fd\uff0c\u4e0d\u540c\u5173\u7cfb\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u66f4\u5927\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u4e2d\u4ecb\u66f4\u9c81\u68d2\uff0c\u76f8\u5bf9\u4e8e\u76f4\u63a5\u67e5\u8be2\u7684\u6027\u80fd\u5dee\u8ddd\u51cf\u5c0f\uff1b\u771f\u5b9e\u540d\u79f0\u548c\u540d\u79f0\u6765\u6e90\u7684\u5f71\u54cd\u6df7\u5408\u4e14\u65e0\u7cfb\u7edf\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u591a\u8bed\u8a00LLMs\u4e2d\u5b64\u7acb\u4e8b\u5b9e\u56de\u5fc6\u4e0e\u4e0a\u4e0b\u6587\u4f9d\u8d56\u8bed\u8a00\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8868\u660e\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349\u81ea\u7136\u8bed\u8a00\u4f7f\u7528\u4e2d\u7684\u4e8b\u5b9e\u68c0\u7d22\u80fd\u529b\u3002"}}
{"id": "2601.12401", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12401", "abs": "https://arxiv.org/abs/2601.12401", "authors": ["Jinmei Liu", "Haoru Li", "Zhenhong Sun", "Chaofeng Chen", "Yatao Bian", "Bo Wang", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "title": "Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \\textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \\textbf{DRIFT} (\\textbf{D}ive\\textbf{R}sity-\\textbf{I}ncentivized Reinforcement \\textbf{F}ine-\\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \\textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \\textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \\textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\\%\\!\\sim\\! 43.46\\%$ increase in diversity at equivalent alignment levels and a $ 59.65\\% \\!\\sim\\! 65.86\\%$ increase in alignment at equivalent levels of diversity.", "AI": {"tldr": "DRIFT\u6846\u67b6\u901a\u8fc7\u91c7\u6837\u3001\u63d0\u793a\u548c\u4f18\u5316\u4e09\u4e2a\u5c42\u9762\u6fc0\u52b1\u591a\u6837\u6027\uff0c\u89e3\u51b3RL\u5fae\u8c03\u751f\u6210\u6a21\u578b\u65f6\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u5728\u4efb\u52a1\u5bf9\u9f50\u548c\u751f\u6210\u591a\u6837\u6027\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u5e73\u8861\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5fae\u8c03\u5927\u89c4\u6a21\u751f\u6210\u6a21\u578b\u65f6\u5b58\u5728\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u5373\u4f18\u5316\u8fc7\u7a0b\u4f1a\u4f7f\u7b56\u7565\u6536\u655b\u5230Dirac delta\u5206\u5e03\uff0c\u5bfc\u81f4\u751f\u6210\u7ed3\u679c\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faDRIFT\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u89d2\u5ea6\u6fc0\u52b1\u591a\u6837\u6027\uff1a1) \u91c7\u6837\u5956\u52b1\u96c6\u4e2d\u7684\u5b50\u96c6\uff0c\u8fc7\u6ee4\u5956\u52b1\u5f02\u5e38\u503c\u9632\u6b62\u8fc7\u65e9\u5d29\u6e83\uff1b2) \u4f7f\u7528\u968f\u673a\u53d8\u4f53\u8fdb\u884c\u63d0\u793a\uff0c\u6269\u5c55\u6761\u4ef6\u7a7a\u95f4\uff1b3) \u901a\u8fc7\u57fa\u4e8e\u52bf\u80fd\u7684\u5956\u52b1\u5851\u9020\u673a\u5236\u4f18\u5316\u7ec4\u5185\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aDRIFT\u5728\u4efb\u52a1\u5bf9\u9f50\u548c\u751f\u6210\u591a\u6837\u6027\u65b9\u9762\u53d6\u5f97\u5e15\u7d2f\u6258\u4f18\u52bf\uff1a\u5728\u76f8\u540c\u5bf9\u9f50\u6c34\u5e73\u4e0b\u591a\u6837\u6027\u63d0\u53479.08%~43.46%\uff0c\u5728\u76f8\u540c\u591a\u6837\u6027\u6c34\u5e73\u4e0b\u5bf9\u9f50\u5ea6\u63d0\u534759.65%~65.86%\u3002", "conclusion": "DRIFT\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u6027\u6fc0\u52b1\u591a\u6837\u6027\uff0c\u6210\u529f\u89e3\u51b3\u4e86RL\u5fae\u8c03\u751f\u6210\u6a21\u578b\u65f6\u7684\u591a\u6837\u6027\u5d29\u6e83\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u5bf9\u9f50\u4e0e\u751f\u6210\u591a\u6837\u6027\u7684\u66f4\u597d\u5e73\u8861\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5728\u9700\u8981\u591a\u6837\u5316\u5019\u9009\u751f\u6210\u7684\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.13262", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13262", "abs": "https://arxiv.org/abs/2601.13262", "authors": ["Eric Onyame", "Akash Ghosh", "Subhadip Baidya", "Sriparna Saha", "Xiuying Chen", "Chirag Agarwal"], "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning", "comment": null, "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/", "AI": {"tldr": "CURE-MED\u6846\u67b6\u901a\u8fc7\u8bfe\u7a0b\u5f0f\u5f3a\u5316\u5b66\u4e60\u63d0\u5347LLMs\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528CUREMED-BENCH\u6570\u636e\u96c6\u572813\u79cd\u8bed\u8a00\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u8a00\u4e00\u81f4\u6027\u548c\u903b\u8f91\u6b63\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8bed\u8a00\u6570\u5b66\u548c\u5e38\u8bc6\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u5e94\u7528\u4e2d\u4ecd\u4e0d\u53ef\u9760\uff0c\u963b\u788d\u4e86\u5728\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u5e94\u7528\u3002", "method": "\u63d0\u51faCURE-MED\u6846\u67b6\uff1a1\uff09\u5f15\u5165CUREMED-BENCH\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u6570\u636e\u96c6\uff1b2\uff09\u91c7\u7528\u8bfe\u7a0b\u5f0f\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u4ee3\u7801\u5207\u6362\u611f\u77e5\u7684\u76d1\u7763\u5fae\u8c03\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff0c\u5171\u540c\u63d0\u5347\u903b\u8f91\u6b63\u786e\u6027\u548c\u8bed\u8a00\u7a33\u5b9a\u6027\u3002", "result": "\u572813\u79cd\u8bed\u8a00\u4e0a\uff0c7B\u53c2\u6570\u6a21\u578b\u8fbe\u523085.21%\u8bed\u8a00\u4e00\u81f4\u6027\u548c54.35%\u903b\u8f91\u6b63\u786e\u6027\uff1b32B\u53c2\u6570\u6a21\u578b\u8fbe\u523094.96%\u8bed\u8a00\u4e00\u81f4\u6027\u548c70.04%\u903b\u8f91\u6b63\u786e\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CURE-MED\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLMs\u5728\u591a\u8bed\u8a00\u533b\u7597\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\uff0c\u652f\u6301\u5728\u591a\u8bed\u8a00\u533b\u7597\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.12607", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12607", "abs": "https://arxiv.org/abs/2601.12607", "authors": ["Anurag Acharya", "Timothy Vega", "Rizwan A. Ashraf", "Anshu Sharma", "Derek Parker", "Robert Rallo"], "title": "A Cloud-based Multi-Agentic Workflow for Science", "comment": null, "summary": "As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u3001\u6a21\u578b\u72ec\u7acb\u7684\u4e91\u4e0a\u79d1\u5b66\u52a9\u624b\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u7763\u4ee3\u7406\u534f\u8c03\u591a\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff0c\u80fd\u5904\u7406\u4ece\u6587\u732e\u56de\u987e\u5230\u590d\u6742\u6a21\u62df\u7684\u79d1\u7814\u4efb\u52a1\uff0c\u5728\u50ac\u5316\u5242\u7814\u7a76\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u8fd0\u884c\u6a21\u62df\u3001\u590d\u6742\u51b3\u7b56\uff09\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u800c\u73b0\u6709\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u5e73\u8861\u6a21\u578b\u3001\u4e91\u63d0\u4f9b\u5546\u548c\u5916\u90e8\u8d44\u6e90\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u963b\u788d\u4e86\u4ee3\u7406\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u3001\u6a21\u578b\u72ec\u7acb\u7684\u4e91\u4e0a\u4ee3\u7406\u6846\u67b6\uff0c\u91c7\u7528\u76d1\u7763\u4ee3\u7406\u534f\u8c03\u591a\u4e2a\u5177\u6709\u7279\u5b9a\u80fd\u529b\u7684\u4e13\u4e1a\u4ee3\u7406\uff0c\u80fd\u591f\u5904\u7406\u4ece\u7b80\u5355\u7684\u6587\u732e\u56de\u987e\u3001\u6570\u636e\u5206\u6790\u5230\u590d\u6742\u7684\u6a21\u62df\u8fd0\u884c\u7b49\u79d1\u7814\u4efb\u52a1\u3002", "result": "\u5728\u50ac\u5316\u5242\u7814\u7a76\u9886\u57df\u7684\u9a8c\u8bc1\u4e2d\uff0c\u7cfb\u7edf\u80fd\u5c06\u4efb\u52a1\u6b63\u786e\u8def\u7531\u5230\u76f8\u5e94\u4ee3\u7406\u7684\u51c6\u786e\u7387\u8fbe90%\uff0c\u5408\u6210\u4efb\u52a1\u5b8c\u6210\u7387\u8fbe97.5%\uff0c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u5b8c\u6210\u7387\u8fbe91%\uff0c\u6027\u80fd\u4e0e\u524d\u6cbf\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79d1\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u4ee3\u7406\u7cfb\u7edf\u5b9e\u73b0\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u534f\u8c03\u4e91\u8d44\u6e90\u3001\u5916\u90e8\u5de5\u5177\u548c\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u79d1\u7814\u6548\u7387\uff0c\u5177\u6709\u53ef\u590d\u5236\u6027\u3002"}}
{"id": "2601.12405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12405", "abs": "https://arxiv.org/abs/2601.12405", "authors": ["Manasi Kanade", "Abhi Thakkar", "Gabriela Fernandes"], "title": "Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants", "comment": null, "summary": "Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.\n  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.\n  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.\n  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.\n  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u513f\u79d1\u7259\u79d1\u98ce\u9669\u5206\u5c42\uff0c\u5f3a\u8c03\u53ef\u89e3\u91ca\u6027\u548c\u4f26\u7406\u90e8\u7f72\u800c\u975e\u6700\u5927\u9884\u6d4b\u51c6\u786e\u6027", "motivation": "\u513f\u79d1\u7259\u79d1\u75be\u75c5\u662f\u5168\u7403\u6700\u666e\u904d\u4e14\u4e0d\u516c\u5e73\u7684\u6162\u6027\u5065\u5eb7\u95ee\u9898\u4e4b\u4e00\u3002\u73b0\u6709AI\u7259\u79d1\u5e94\u7528\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u56fe\u50cf\u7684\u8bca\u65ad\u548c\u9ed1\u76d2\u9884\u6d4b\u6a21\u578b\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u9650\u5236\u4e86\u5728\u513f\u79d1\u4eba\u7fa4\u4e2d\u7684\u4f26\u7406\u9002\u7528\u6027", "method": "\u4f7f\u7528\u4eba\u53e3\u6c34\u5e73\u7684\u513f\u79d1\u6570\u636e\u8bad\u7ec3\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u5e74\u9f84\u3001\u6536\u5165\u8d2b\u56f0\u6bd4\u3001\u79cd\u65cf/\u6c11\u65cf\u3001\u6027\u522b\u548c\u75c5\u53f2\u3002\u4f7f\u7528ROC\u5206\u6790\u548c\u6821\u51c6\u66f2\u7ebf\u8bc4\u4f30\u6027\u80fd\uff0c\u901a\u8fc7SHAP\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027", "result": "\u6a21\u578b\u5b9e\u73b0\u4e86\u9002\u5ea6\u7684\u533a\u5206\u80fd\u529b\uff08AUC=0.61\uff09\uff0c\u6821\u51c6\u4fdd\u5b88\uff0c\u5728\u9ad8\u98ce\u9669\u6c34\u5e73\u4e0b\u4f4e\u4f30\u98ce\u9669\u3002SHAP\u5206\u6790\u663e\u793a\u5e74\u9f84\u548c\u6536\u5165\u8d2b\u56f0\u6bd4\u662f\u98ce\u9669\u9884\u6d4b\u7684\u6700\u5f3a\u8d21\u732e\u56e0\u7d20\uff0c\u5176\u6b21\u662f\u79cd\u65cf/\u6c11\u65cf\u548c\u6027\u522b", "conclusion": "\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u3001\u9884\u9632\u5bfc\u5411\u7684\u513f\u79d1\u7259\u79d1\u98ce\u9669\u5206\u5c42\uff0c\u652f\u6301\u4eba\u7fa4\u7b5b\u67e5\u548c\u516c\u5e73\u8d44\u6e90\u5206\u914d\uff0c\u800c\u975e\u8bca\u65ad\u51b3\u7b56"}}
{"id": "2601.13268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13268", "abs": "https://arxiv.org/abs/2601.13268", "authors": ["Zainab Ghafoor", "Md Shafiqul Islam", "Koushik Howlader", "Md Rasel Khondokar", "Tanusree Bhattacharjee", "Sayantan Chakraborty", "Adrito Roy", "Ushashi Bhattacharjee", "Tirtho Roy"], "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u5bf9\u9f50\u63d0\u5347\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u663e\u8457\u51cf\u5c11\u4f26\u7406\u8fdd\u89c4\u548c\u98ce\u9669\u7b49\u7ea7\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u786e\u4fdd\u5176\u4f26\u7406\u5b8c\u6574\u6027\u548c\u5b89\u5168\u5408\u89c4\u6027\u4ecd\u662f\u4e34\u5e8a\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5b89\u5168\u6cbb\u7406\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u6846\u67b6\uff0c\u7ed3\u5408DeepSeek R1\u548cMed-PaLM\u4e24\u4e2a\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u53caLLaMA 3.1\u548cPhi-4\u4e24\u4e2a\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u57fa\u4e8e\u7f8e\u56fd\u533b\u5b66\u4f1a\u533b\u5b66\u4f26\u7406\u539f\u5219\u548c\u4e94\u7ea7\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u534f\u8bae\uff0c\u5bf9900\u4e2a\u4e34\u5e8a\u591a\u6837\u5316\u67e5\u8be2\u8fdb\u884c\u7ed3\u6784\u5316\u8fed\u4ee3\u5bf9\u9f50\u3002", "result": "DeepSeek R1\u6536\u655b\u66f4\u5feb\uff08\u5e73\u57472.34 vs 2.67\u6b21\u8fed\u4ee3\uff09\uff0cMed-PaLM\u5728\u9690\u79c1\u654f\u611f\u573a\u666f\u5904\u7406\u66f4\u4f18\u3002\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u5faa\u73af\u4f7f\u4f26\u7406\u8fdd\u89c4\u51cf\u5c1189%\uff0c\u98ce\u9669\u964d\u7ea7\u7387\u8fbe92%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u533b\u7597AI\u5b89\u5168\u6cbb\u7406\u8303\u5f0f\uff0c\u4e3a\u4e34\u5e8a\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b89\u5168\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2601.12618", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12618", "abs": "https://arxiv.org/abs/2601.12618", "authors": ["Elham Tajik", "Conrad Borchers", "Bahar Shahrokhian", "Sebastian Simon", "Ali Keramati", "Sonika Pal", "Sreecharan Sankaranarayanan"], "title": "Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems", "comment": "LAK 2026 conference paper, 7 pages", "summary": "Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u8fc7\u7a0b\u6570\u636e\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u91cf\u5316\u667a\u80fd\u4f53\u95f4\u7684\u5206\u6b67\uff0c\u5c06\u5206\u6b67\u8f6c\u5316\u4e3a\u6709\u610f\u4e49\u7684\u5206\u6790\u4fe1\u53f7\uff0c\u7528\u4e8e\u6539\u8fdb\u5b9a\u6027\u7f16\u7801\u7684\u53ef\u9760\u6027\u548c\u89e3\u91ca\u6df1\u5ea6\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u53d1\u5c55\uff0c\u5168\u81ea\u52a8\u548c\u4eba\u673a\u534f\u4f5c\u7684\u5206\u6790\u65b9\u6cd5\u51fa\u73b0\uff0c\u4f46\u7f3a\u4e4f\u6307\u5bfc\u6b64\u7c7b\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b9\u6cd5\u5b66\u6807\u51c6\u3002\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u5b9a\u6027\u7f16\u7801\u7684\u89e3\u91ca\u5b9e\u8df5\u548c\u53ef\u9760\u6027\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u63a8\u7406\u8f68\u8ff9\uff0c\u5e94\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6765\u7cfb\u7edf\u68c0\u6d4b\u3001\u91cf\u5316\u548c\u89e3\u91ca\u667a\u80fd\u4f53\u95f4\u7684\u5206\u6b67\u3002\u5206\u6790\u8fd110,000\u4e2a\u667a\u80fd\u4f53\u5bf9\u7f16\u7801\u4eba\u7c7b\u8f85\u5bfc\u5bf9\u8bdd\u7247\u6bb5\u7684\u60c5\u51b5\uff0c\u5c06\u5b9a\u91cf\u76f8\u4f3c\u5ea6\u6307\u6807\u4e0e\u5b9a\u6027\u5ba1\u67e5\u76f8\u7ed3\u5408\u3002", "result": "LLM\u667a\u80fd\u4f53\u7684\u8bed\u4e49\u63a8\u7406\u76f8\u4f3c\u5ea6\u80fd\u7a33\u5065\u5730\u533a\u5206\u5171\u8bc6\u4e0e\u5206\u6b67\uff0c\u5e76\u4e0e\u4eba\u7c7b\u7f16\u7801\u53ef\u9760\u6027\u76f8\u5173\u3002\u57fa\u4e8e\u8be5\u6307\u6807\u7684\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u4ee3\u7801\u5185\u7684\u7ec6\u5fae\u6559\u5b66\u5b50\u529f\u80fd\uff0c\u5e76\u4e3a\u6982\u5ff5\u4ee3\u7801\u672c\u7ec6\u5316\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "conclusion": "\u63a8\u7406\u8f68\u8ff9\u5206\u6b67\u4ee3\u8868\u4e86\u4e00\u7c7b\u6709\u4ef7\u503c\u7684\u65b0\u5206\u6790\u4fe1\u53f7\uff0c\u901a\u8fc7\u6574\u5408\u5b9a\u91cf\u76f8\u4f3c\u5ea6\u6307\u6807\u4e0e\u5b9a\u6027\u5ba1\u67e5\uff0c\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u6539\u8fdb\u548c\u52a0\u901f\u7f16\u7801\u8fc7\u7a0b\u4e2d\u7684\u8bc4\u5206\u8005\u95f4\u53ef\u9760\u6027\u5efa\u7acb\uff0c\u7279\u522b\u662f\u5728LLM\u4e0e\u4eba\u7c7b\u534f\u4f5c\u65f6\uff0c\u63a8\u52a8\u6559\u80b2\u7814\u7a76\u65b9\u6cd5\u5b66\u4e25\u8c28\u6027\u548c\u89e3\u91ca\u6df1\u5ea6\u3002"}}
{"id": "2601.12415", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12415", "abs": "https://arxiv.org/abs/2601.12415", "authors": ["Wang Zixian"], "title": "Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF", "comment": null, "summary": "Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316(OPO)\u6846\u67b6\uff0c\u5c06\u5bf9\u9f50\u65b9\u6cd5\u89e3\u8026\u4e3a\u91c7\u6837\u51e0\u4f55\u548c\u4f18\u5316\u51e0\u4f55\u4e24\u4e2a\u72ec\u7acb\u8bbe\u8ba1\u9009\u62e9\uff0c\u89e3\u51b3\u4f20\u7edfKL\u6563\u5ea6\u5e26\u6765\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5(\u5982PPO\u3001DPO\u3001IPO)\u9690\u542b\u5730\u5c06\u91c7\u6837\u51e0\u4f55\u548c\u4f18\u5316\u51e0\u4f55\u6df7\u4e3a\u4e00\u8c08\uff0c\u800cKL\u6563\u5ea6\u5bf9\u65e0\u754c\u503c\u4fe1\u53f7\u65bd\u52a0\u6307\u6570\u60e9\u7f5a\uff0c\u5bfc\u81f4\u6570\u503c\u4e0d\u7a33\u5b9a\u548c\u9ad8\u7f6e\u4fe1\u5ea6\u4e0b\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316(OPO)\u6846\u67b6\uff0c\u5c06\u91c7\u6837\u51e0\u4f55(\u03b1-\u52a0\u6743\u91cd\u8981\u6027\u91c7\u6837)\u4e0e\u4f18\u5316\u51e0\u4f55(\u03c7\u00b2\u8bf1\u5bfc\u7684\u4e8c\u6b21\u6b63\u5219\u5316)\u663e\u5f0f\u89e3\u8026\uff0c\u5728\u6bd4\u7387\u5750\u6807\u4e2d\u4f7f\u7528\u7ebf\u6027\u68af\u5ea6\u52a8\u6001\u7684\u7b80\u5355\u4e14\u6761\u4ef6\u826f\u597d\u7684\u76ee\u6807\u51fd\u6570\u3002", "result": "OPO\u5728\u4fdd\u6301\u5cf0\u503c\u5bfb\u6c42\u884c\u4e3a\u7684\u540c\u65f6\u5b9e\u73b0\u7a33\u5b9a\u4f18\u5316\uff0c\u907f\u514d\u68af\u5ea6\u9971\u548c\uff0c\u5373\u4f7f\u6a21\u578b\u7f6e\u4fe1\u5ea6\u9ad8\u65f6\u4e5f\u80fd\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff0c\u4e3a\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c6\u89d2\u3002", "conclusion": "OPO\u901a\u8fc7\u89e3\u8026\u91c7\u6837\u548c\u4f18\u5316\u51e0\u4f55\uff0c\u4e3a\u9c81\u68d2\u63a8\u7406\u5bfc\u5411\u8bad\u7ec3\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2601.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13327", "abs": "https://arxiv.org/abs/2601.13327", "authors": ["Po-Yu Liang", "Tobo Duran", "Jun Bai"], "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion", "comment": null, "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "AI": {"tldr": "PepEDiff\u662f\u4e00\u4e2a\u76f4\u63a5\u4ece\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u7684\u8fde\u7eed\u6f5c\u7a7a\u95f4\u751f\u6210\u80bd\u7ed3\u5408\u5242\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u7ed3\u6784\u9884\u6d4b\uff0c\u63d0\u9ad8\u4e86\u5e8f\u5217\u591a\u6837\u6027", "motivation": "\u73b0\u6709\u80bd\u7ed3\u5408\u5242\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u4e2d\u95f4\u7ed3\u6784\u9884\u6d4b\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u5e76\u9650\u5236\u4e86\u5e8f\u5217\u591a\u6837\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u76f4\u63a5\u3001\u591a\u6837\u5316\u7684\u751f\u6210\u65b9\u6cd5", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u86cb\u767d\u8d28\u5d4c\u5165\u6a21\u578b\u7684\u8fde\u7eed\u6f5c\u7a7a\u95f4\uff0c\u901a\u8fc7\u6f5c\u7a7a\u95f4\u63a2\u7d22\u548c\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\uff0c\u76f4\u63a5\u751f\u6210\u7ed3\u5408\u5242\u5e8f\u5217\uff0c\u65e0\u9700\u7ed3\u6784\u9884\u6d4b", "result": "\u5728TIGIT\uff08\u5177\u6709\u5927\u800c\u5e73\u5766\u7684\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u754c\u9762\uff09\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cPepEDiff\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\u7684\u901a\u7528\u6846\u67b6\u6f5c\u529b", "conclusion": "PepEDiff\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u4f46\u6709\u6548\u7684\u7ed3\u6784\u65e0\u5173\u6846\u67b6\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u80bd\u7ed3\u5408\u5242\u8bbe\u8ba1\uff0c\u80fd\u591f\u751f\u6210\u8d85\u51fa\u5df2\u77e5\u7ed3\u5408\u5242\u5206\u5e03\u7684\u65b0\u9896\u5e8f\u5217"}}
{"id": "2601.12632", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12632", "abs": "https://arxiv.org/abs/2601.12632", "authors": ["Kriti Bhattarai", "Vipina K. Keloth", "Donald Wright", "Andrew Loza", "Yang Ren", "Hua Xu"], "title": "BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models", "comment": null, "summary": "Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.\n  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.\n  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.\n  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.", "AI": {"tldr": "BioPulse-QA\u662f\u4e00\u4e2a\u65b0\u7684\u751f\u7269\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\uff0c\u4f7f\u7528\u6700\u65b0\u53d1\u5e03\u7684\u751f\u7269\u533b\u5b66\u6587\u6863\u6765\u8bc4\u4f30LLMs\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u9759\u6001\u6027\u3001\u6570\u636e\u6cc4\u9732\u548c\u591a\u6837\u6027\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u7269\u533b\u5b66\u57fa\u51c6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4f7f\u7528\u9759\u6001\u6216\u8fc7\u65f6\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6355\u6349\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u7684\u52a8\u6001\u6027\u548c\u60c5\u5883\u4e30\u5bcc\u6027\uff1b\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff08\u4e0e\u6a21\u578b\u9884\u8bad\u7ec3\u8bed\u6599\u91cd\u53e0\uff09\uff1b\u5ffd\u89c6\u8bed\u8a00\u53d8\u5f02\u9c81\u68d2\u6027\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\u7b49\u5173\u952e\u7ef4\u5ea6\u3002", "method": "\u5f15\u5165BioPulse-QA\u57fa\u51c6\uff0c\u4f7f\u7528\u65b0\u53d1\u5e03\u7684\u751f\u7269\u533b\u5b66\u6587\u6863\uff08\u836f\u7269\u6807\u7b7e\u3001\u8bd5\u9a8c\u65b9\u6848\u3001\u4e34\u5e8a\u6307\u5357\uff09\u6784\u5efa2,280\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u95ee\u7b54\u5bf9\u53ca\u5176\u6270\u52a8\u53d8\u4f53\uff0c\u6db5\u76d6\u62bd\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u683c\u5f0f\u3002\u8bc4\u4f30\u4e86GPT-4o\u3001GPT-o1\u3001Gemini-2.0-Flash\u548cLLaMA-3.1 8B Instruct\u7b49\u6a21\u578b\u3002", "result": "GPT-o1\u5728\u836f\u7269\u6807\u7b7e\u4e0a\u83b7\u5f97\u6700\u9ad8\u653e\u677eF1\u5206\u6570\uff080.92\uff09\uff0cGemini-2.0-Flash\u6b21\u4e4b\uff080.90\uff09\u3002\u4e34\u5e8a\u8bd5\u9a8c\u662f\u6700\u5177\u6311\u6218\u6027\u7684\u6765\u6e90\uff0c\u62bd\u53d6\u5f0fF1\u5206\u6570\u4f4e\u81f30.36\u3002\u6539\u5199\u6bd4\u62fc\u5199\u9519\u8bef\u5e26\u6765\u7684\u6027\u80fd\u5dee\u5f02\u66f4\u5927\uff0c\u504f\u5dee\u6d4b\u8bd5\u663e\u793a\u5dee\u5f02\u53ef\u5ffd\u7565\u3002", "conclusion": "BioPulse-QA\u4e3a\u8bc4\u4f30\u751f\u7269\u533b\u5b66LLMs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4e34\u5e8a\u76f8\u5173\u7684\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u6a21\u578b\u5728\u52a8\u6001\u3001\u9ad8\u98ce\u9669\u751f\u7269\u533b\u5b66\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\u3002"}}
{"id": "2601.12426", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12426", "abs": "https://arxiv.org/abs/2601.12426", "authors": ["Mohammadhossein Homaei", "Iman Khazrak", "Ruben Molano", "Andres Caro", "Mar Avila"], "title": "Graph Attention Networks with Physical Constraints for Anomaly Detection", "comment": "7 Pages, 4 Figures, 5 Tables", "summary": "Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\\%$ parameter noise.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6c34\u529b\u611f\u77e5\u7684\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5229\u7528\u5f52\u4e00\u5316\u5b88\u6052\u5b9a\u5f8b\u8fdd\u89c4\u4f5c\u4e3a\u7279\u5f81\uff0c\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u548c\u53cc\u5411LSTM\u5b66\u4e60\u65f6\u7a7a\u6a21\u5f0f\uff0c\u7528\u4e8e\u6c34\u5206\u914d\u7cfb\u7edf\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u6c34\u5206\u914d\u7cfb\u7edf\u9762\u4e34\u65e5\u76ca\u589e\u957f\u7684\u7f51\u7edc\u7269\u7406\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u5f02\u5e38\u68c0\u6d4b\u3002\u73b0\u6709\u6570\u636e\u9a71\u52a8\u6a21\u578b\u5ffd\u7565\u7f51\u7edc\u62d3\u6251\u4e14\u96be\u4ee5\u89e3\u91ca\uff0c\u800c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u53c2\u6570\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528\u5f52\u4e00\u5316\u5b88\u6052\u5b9a\u5f8b\u8fdd\u89c4\u4f5c\u4e3a\u7279\u5f81\uff0c\u7ed3\u5408\u8d28\u91cf\u5e73\u8861\u548c\u80fd\u91cf\u5e73\u8861\u6b8b\u5dee\uff0c\u91c7\u7528\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u53cc\u5411LSTM\u5b66\u4e60\u65f6\u7a7a\u6a21\u5f0f\uff0c\u5e76\u8bbe\u8ba1\u591a\u5c3a\u5ea6\u6a21\u5757\u4ece\u8282\u70b9\u5230\u7f51\u7edc\u5c42\u9762\u805a\u5408\u68c0\u6d4b\u5206\u6570\u3002", "result": "\u5728BATADAL\u6570\u636e\u96c6\u4e0a\u8fbe\u5230F1=0.979\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u53473.3\u4e2a\u767e\u5206\u70b9\uff0c\u572815%\u53c2\u6570\u566a\u58f0\u4e0b\u8868\u73b0\u51fa\u9ad8\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u4e86\u7269\u7406\u77e5\u8bc6\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u63d0\u9ad8\u4e86\u6c34\u5206\u914d\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u8003\u8651\u4e86\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u3002"}}
{"id": "2601.13358", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13358", "abs": "https://arxiv.org/abs/2601.13358", "authors": ["Samuel Cyrenius Anderson"], "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models", "comment": "34 pages, 10 figures", "summary": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u6269\u5f20\u4e0d\u4f1a\u5747\u5300\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u800c\u662f\u91cd\u6784\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u5206\u679025,000+\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u53d1\u73b0\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u89e6\u53d1\u9886\u57df\u7279\u5b9a\u7684\u76f8\u53d8\uff1a\u6cd5\u5f8b\u63a8\u7406\u5448\u73b0\"\u7ed3\u6676\u5316\"\uff0c\u79d1\u5b66\u548c\u6570\u5b66\u63a8\u7406\u4fdd\u6301\"\u6db2\u6001\"\uff0c\u4ee3\u7801\u63a8\u7406\u5f62\u6210\"\u6676\u683c\"\u7ed3\u6784\u3002\u51e0\u4f55\u7ed3\u6784\u53ef\u9884\u6d4b\u5b66\u4e60\u6027\uff0c\u5e76\u53ef\u7528\u4e8e\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u6a21\u578b\u89c4\u6a21\u6269\u5f20\u4f1a\u5747\u5300\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u89c4\u6a21\u6269\u5f20\u5982\u4f55\u771f\u6b63\u5f71\u54cd\u4e0d\u540c\u9886\u57df\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u63ed\u793a\u5176\u5185\u5728\u7684\u51e0\u4f55\u7ed3\u6784\u53d8\u5316\u89c4\u5f8b\u3002", "method": "\u5206\u679025,000+\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u6db5\u76d6\u6cd5\u5f8b\u3001\u79d1\u5b66\u3001\u4ee3\u7801\u3001\u6570\u5b66\u56db\u4e2a\u9886\u57df\uff0c\u4f7f\u75288B\u548c70B\u4e24\u79cd\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u3002\u5f15\u5165\u795e\u7ecf\u63a8\u7406\u7b97\u5b50\uff08Neural Reasoning Operators\uff09\u4f5c\u4e3a\u4ece\u521d\u59cb\u5230\u6700\u7ec8\u9690\u85cf\u72b6\u6001\u7684\u6620\u5c04\uff0c\u5e76\u5206\u6790\u8f68\u8ff9\u7684\u51e0\u4f55\u7279\u6027\u5982\u7ef4\u5ea6\u3001\u5bf9\u9f50\u5ea6\u3001\u6d41\u5f62\u89e3\u7f20\u7b49\u3002", "result": "\u53d1\u73b0\u4e09\u79cd\u4e0d\u540c\u7684\u63a8\u7406\u51e0\u4f55\u6a21\u5f0f\uff1a\u6cd5\u5f8b\u63a8\u7406\u5448\u73b0\u7ed3\u6676\u5316\uff08\u7ef4\u5ea6\u4e0b\u964d45%\uff0c\u8f68\u8ff9\u5bf9\u9f50\u5ea6\u63d0\u534731%\uff0c\u6d41\u5f62\u89e3\u7f2010\u500d\uff09\uff1b\u79d1\u5b66\u548c\u6570\u5b66\u63a8\u7406\u4fdd\u6301\u6db2\u6001\uff08\u51e0\u4f55\u4e0d\u53d8\uff09\uff1b\u4ee3\u7801\u63a8\u7406\u5f62\u6210\u6676\u683c\u7ed3\u6784\uff08\u8f6e\u5ed3\u7cfb\u6570\u4ece0.13\u63d0\u5347\u52300.42\uff09\u3002\u795e\u7ecf\u63a8\u7406\u7b97\u5b50\u5728\u6cd5\u5f8b\u63a8\u7406\u4e0a\u8fbe\u523063.6%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u53d1\u73b0\u8de8\u9886\u57df\u548c\u89c4\u6a21\u7684\u901a\u7528\u632f\u8361\u7279\u5f81\uff08\u76f8\u5e72\u6027\u7ea6-0.4\uff09\u3002", "conclusion": "\u63a8\u7406\u6210\u672c\u7531\u6d41\u5f62\u51e0\u4f55\u800c\u975e\u4efb\u52a1\u96be\u5ea6\u51b3\u5b9a\uff0c\u8fd9\u4e3a\u5728\u62d3\u6251\u5141\u8bb8\u7684\u60c5\u51b5\u4e0b\u52a0\u901f\u63a8\u7406\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002\u4e0d\u540c\u9886\u57df\u7684\u63a8\u7406\u8fc7\u7a0b\u5728\u89c4\u6a21\u6269\u5f20\u4e0b\u7ecf\u5386\u4e0d\u540c\u7684\u76f8\u53d8\uff0c\u800c\u975e\u5747\u5300\u7684\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2601.12639", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12639", "abs": "https://arxiv.org/abs/2601.12639", "authors": ["Daniel Vennemeyer", "Punya Syon Pandey", "Phan Anh Duong", "Michael Umeokoli", "Samuel Ratnam"], "title": "Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift", "comment": null, "summary": "Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u76ee\u6807\u5bf9LLM\u5b89\u5168\u6027\u7684\u5f71\u54cd\u968f\u8bad\u7ec3\u89c4\u6a21\u53d8\u5316\uff1a\u5c0f\u89c4\u6a21\u65f6\u5404\u76ee\u6807\u5b89\u5168\u6027\u76f8\u4f3c\u4f46\u80fd\u529b\u4e0d\u540c\uff0c\u5927\u89c4\u6a21\u65f6\u76d1\u7763\u548c\u504f\u597d\u5fae\u8c03\u4f1a\u663e\u8457\u589e\u52a0\u5bf9\u6297\u8106\u5f31\u6027\u548c\u89d2\u8272\u6f02\u79fb\uff0c\u800cORPO\u548cKL\u6b63\u5219\u5316\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5728\u826f\u6027\u6570\u636e\u4e0a\u5fae\u8c03LLM\u4ecd\u53ef\u80fd\u635f\u5bb3\u5bf9\u9f50\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u4f46\u5fae\u8c03\u76ee\u6807\u5982\u4f55\u5f71\u54cd\u5b89\u5168\u6027\u7684\u76f4\u63a5\u5206\u6790\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u5bf9\u5b89\u5168\u6027\u548c\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u5728\u6570\u636e\u3001\u9886\u57df\u3001\u67b6\u6784\u548c\u4f18\u5316\u56fa\u5b9a\u7684\u63a7\u5236\u6761\u4ef6\u4e0b\uff0c\u6bd4\u8f83\u4e86\u516d\u79cd\u5fae\u8c03\u76ee\u6807\uff1a\u76d1\u7763\u5fae\u8c03\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3001\u6761\u4ef6\u5fae\u8c03\u3001\u63a5\u79cd\u63d0\u793a\u3001\u51e0\u7387\u6bd4\u504f\u597d\u4f18\u5316\u548cKL\u6b63\u5219\u5316\u5fae\u8c03\u3002\u5728\u5c01\u95ed\u5f0f\u63a8\u7406\u548c\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5fae\u8c03\u76ee\u6807\u9009\u62e9\u5bfc\u81f4\u5b89\u5168-\u80fd\u529b\u524d\u6cbf\u7684\u7cfb\u7edf\u6027\u3001\u89c4\u6a21\u4f9d\u8d56\u6027\u53d8\u5316\uff1a\u5c0f\u8bad\u7ec3\u9884\u7b97\u65f6\u9c81\u68d2\u6027\u76f8\u4f3c\u4f46\u80fd\u529b\u4e0d\u540c\uff1b\u5927\u9884\u7b97\u65f6\u76ee\u6807\u5dee\u5f02\u663e\u8457\uff0c\u76d1\u7763\u548c\u504f\u597d\u5fae\u8c03\u4f7f\u80fd\u529b\u63d0\u5347\u4e0e\u5bf9\u6297\u8106\u5f31\u6027\u3001\u89d2\u8272\u6f02\u79fb\u7d27\u5bc6\u8026\u5408\uff0c\u800cORPO\u548cKL\u6b63\u5219\u5316\u80fd\u663e\u8457\u7f13\u89e3\u8fd9\u4e24\u79cd\u95ee\u9898\u3002", "conclusion": "\u5fae\u8c03\u76ee\u6807\u5728\u5c0f\u89c4\u6a21\u65f6\u5bf9\u5b89\u5168\u6027\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u968f\u7740\u8bad\u7ec3\u89c4\u6a21\u589e\u52a0\uff0c\u6210\u4e3a\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6f5c\u5728\u89d2\u8272\u7a33\u5b9a\u6027\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u3002\u7ea6\u675f\u5b66\u4e60\u4fe1\u53f7\u7684\u76ee\u6807\uff08\u7279\u522b\u662fORPO\u548cKL\u6b63\u5219\u5316\uff09\u80fd\u66f4\u597d\u5730\u5e73\u8861\u5b89\u5168\u6027\u548c\u80fd\u529b\u3002"}}
{"id": "2601.12442", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12442", "abs": "https://arxiv.org/abs/2601.12442", "authors": ["Shahnawaz Alam", "Mohammed Mudassir Uddin", "Mohammed Kaif Pasha"], "title": "Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery", "comment": null, "summary": "Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.", "AI": {"tldr": "CANUF\u6846\u67b6\u5c06\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u4e0e\u53ef\u5fae\u5206\u7b26\u53f7\u63a8\u7406\u7ed3\u5408\uff0c\u4e3a\u79d1\u5b66AI\u63d0\u4f9b\u53ef\u4fe1\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u540c\u65f6\u6ee1\u8db3\u9886\u57df\u7ea6\u675f", "motivation": "\u79d1\u5b66AI\u5e94\u7528\u9700\u8981\u63d0\u4f9b\u53ef\u4fe1\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5e76\u5c0a\u91cd\u9886\u57df\u7ea6\u675f\u7684\u6a21\u578b\u3002\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u7f3a\u4e4f\u6574\u5408\u7b26\u53f7\u79d1\u5b66\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u800c\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u786e\u5b9a\u6027\u64cd\u4f5c\u4e2d\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21", "method": "CANUF\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1) \u4ece\u79d1\u5b66\u6587\u732e\u81ea\u52a8\u63d0\u53d6\u7ea6\u675f\uff1b2) \u5177\u6709\u53d8\u5206\u63a8\u7406\u7684\u6982\u7387\u795e\u7ecf\u9aa8\u5e72\uff1b3) \u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\u7684\u53ef\u5fae\u5206\u7ea6\u675f\u6ee1\u8db3\u5c42", "result": "\u5728Materials Project\u3001QM9\u5206\u5b50\u5c5e\u6027\u548c\u6c14\u5019\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCANUF\u5c06\u9884\u671f\u6821\u51c6\u8bef\u5dee\u964d\u4f4e34.7%\uff08\u76f8\u6bd4\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u540c\u65f6\u4fdd\u630199.2%\u7684\u7ea6\u675f\u6ee1\u8db3\u7387\u3002\u7ea6\u675f\u5f15\u5bfc\u7684\u91cd\u65b0\u6821\u51c6\u8d21\u732e\u4e8618.3%\u7684\u6027\u80fd\u589e\u76ca\uff0c\u7ea6\u675f\u63d0\u53d6\u8fbe\u523091.4%\u7684\u7cbe\u786e\u5ea6", "conclusion": "CANUF\u63d0\u4f9b\u4e86\u9996\u4e2a\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u7ba1\u9053\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u7ea6\u675f\u6ee1\u8db3\u548c\u79d1\u5b66\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u89e3\u91ca\u95ee\u9898"}}
{"id": "2601.13383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13383", "abs": "https://arxiv.org/abs/2601.13383", "authors": ["Akbar Anbar Jafari", "Cagri Ozcinar", "Gholamreza Anbarjafari"], "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge", "comment": "15 pages, 3 figures", "summary": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.", "AI": {"tldr": "AgentForge\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90Python\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u7b80\u5316LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u5f00\u53d1\uff0c\u63d0\u4f9b\u53ef\u7ec4\u5408\u6280\u80fd\u3001\u7edf\u4e00LLM\u540e\u7aef\u63a5\u53e3\u548c\u58f0\u660e\u5f0f\u914d\u7f6e\u7cfb\u7edf\uff0c\u663e\u8457\u51cf\u5c11\u5f00\u53d1\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u5b58\u5728\u67b6\u6784\u50f5\u5316\u3001\u4f9b\u5e94\u5546\u9501\u5b9a\u548c\u590d\u6742\u6027\u8fc7\u9ad8\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6c11\u4e3b\u5316LLM\u9a71\u52a8\u81ea\u4e3b\u667a\u80fd\u4f53\u6784\u5efa\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\u8bbe\u8ba1\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a1) \u53ef\u7ec4\u5408\u6280\u80fd\u62bd\u8c61\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5206\u89e3\u548c\u5f62\u5f0f\u5316\u8f93\u5165\u8f93\u51fa\u5951\u7ea6\uff1b2) \u7edf\u4e00LLM\u540e\u7aef\u63a5\u53e3\uff0c\u652f\u6301\u4e91\u7aefAPI\u548c\u672c\u5730\u63a8\u7406\u5f15\u64ce\u65e0\u7f1d\u5207\u6362\uff1b3) \u57fa\u4e8eYAML\u7684\u58f0\u660e\u5f0f\u914d\u7f6e\u7cfb\u7edf\uff0c\u5206\u79bb\u667a\u80fd\u4f53\u903b\u8f91\u4e0e\u5b9e\u73b0\u7ec6\u8282\u3002\u5c06\u6280\u80fd\u7ec4\u5408\u673a\u5236\u5f62\u5f0f\u5316\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAG)\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u573a\u666f\u7684\u5168\u9762\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0cAgentForge\u5b9e\u73b0\u4e86\u7ade\u4e89\u529b\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u540c\u65f6\u76f8\u6bd4LangChain\u51cf\u5c1162%\u5f00\u53d1\u65f6\u95f4\uff0c\u76f8\u6bd4\u76f4\u63a5API\u96c6\u6210\u51cf\u5c1178%\u5f00\u53d1\u65f6\u95f4\u3002\u7f16\u6392\u5ef6\u8fdf\u4f4e\u4e8e100ms\uff0c\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002\u6846\u67b6\u96c6\u6210\u4e86\u516d\u4e2a\u5185\u7f6e\u6280\u80fd\uff0c\u5e76\u63d0\u4f9b\u81ea\u5b9a\u4e49\u6280\u80fd\u5f00\u53d1\u7684\u5b8c\u6574\u6587\u6863\u3002", "conclusion": "AgentForge\u586b\u8865\u4e86LLM\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u751f\u4ea7\u5c31\u7eea\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u7528\u4e8e\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u6216\u6027\u80fd\u3002"}}
{"id": "2601.12648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12648", "abs": "https://arxiv.org/abs/2601.12648", "authors": ["Nafiz Imtiaz Khan", "Kylie Cleland", "Vladimir Filkov", "Roger Eric Goldman"], "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?", "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)", "summary": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7531\u6587\u672c\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u81ea\u52a8\u63d0\u53d6\u7ed3\u6784\u5316\u7a0b\u5e8f\u4fe1\u606f\u4ee5\u751f\u6210\u7a0b\u5e8f\u75c5\u4f8b\u65e5\u5fd7\u7684\u53ef\u884c\u6027\uff0c\u7ed3\u679c\u663e\u793a\u672c\u5730\u548c\u5546\u4e1a\u6a21\u578b\u5747\u80fd\u8fbe\u5230\u63a5\u8fd10.87\u7684F1\u5206\u6570\uff0c\u663e\u8457\u51cf\u5c11\u6587\u4e66\u8d1f\u62c5\u3002", "motivation": "\u653e\u5c04\u5b66\u57f9\u8bad\u4e2d\u7684\u7a0b\u5e8f\u75c5\u4f8b\u65e5\u5fd7\u8bb0\u5f55\u8017\u65f6\u4e14\u624b\u52a8\u8bb0\u5f55\u5bb9\u6613\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u51cf\u8f7b\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u9ad8\u8bb0\u5f55\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u6307\u4ee4\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\uff0c\u8bc4\u4f30\u591a\u4e2a\u672c\u5730\u548c\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\u4ece414\u4efd\u4ecb\u5165\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u7a0b\u5e8f\u4fe1\u606f\u7684\u6027\u80fd\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u654f\u611f\u5ea6\u3001\u7279\u5f02\u5ea6\u3001F1\u5206\u6570\u3001\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee3\u5e01\u6548\u7387\u3002", "result": "\u672c\u5730\u548c\u5546\u4e1a\u6a21\u578b\u5747\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63d0\u53d6\u6027\u80fd\uff0c\u6700\u4f73F1\u5206\u6570\u63a5\u8fd10.87\uff0c\u4f46\u5728\u901f\u5ea6\u548c\u6210\u672c\u65b9\u9762\u5b58\u5728\u4e0d\u540c\u6743\u8861\u3002\u81ea\u52a8\u5316\u53ef\u663e\u8457\u51cf\u5c11\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u9ad8\u75c5\u4f8b\u8bb0\u5f55\u4e00\u81f4\u6027\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u6587\u6863\u8bb0\u5f55\u5728\u533b\u5b66\u6559\u80b2\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u4f46\u9700\u8981\u8de8\u673a\u6784\u548c\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u7684\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002\u81ea\u52a8\u5316\u7a0b\u5e8f\u75c5\u4f8b\u65e5\u5fd7\u8bb0\u5f55\u6709\u6f5c\u529b\u6539\u53d8\u653e\u5c04\u5b66\u57f9\u8bad\u7684\u6587\u4e66\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2601.12467", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12467", "abs": "https://arxiv.org/abs/2601.12467", "authors": ["Saurish Nagrath"], "title": "Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting", "comment": "6 pages, 2 figures, 3 tables", "summary": "Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u7528CNN\u63d0\u53d6\u5c40\u90e8\u65f6\u95f4\u52a8\u6001\u7279\u5f81\u5e76\u751f\u6210\u8865\u4e01\u7ea7token\u5d4c\u5165\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7528Transformer\u7f16\u7801\u5668\u5efa\u6a21\u8865\u4e01\u95f4\u4f9d\u8d56\u5173\u7cfb\u8fdb\u884c\u9884\u6d4b\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u4e8e\u4ece\u539f\u59cb\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u7684\u8f93\u5165\u8868\u793a\u7684\u8d28\u91cf\u548c\u7ed3\u6784\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5c40\u90e8\u65f6\u95f4\u8868\u793a\u5b66\u4e60\u548c\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\u65b9\u9762\u5b58\u5728\u8026\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u9884\u6d4b\u6846\u67b6\uff1a1\uff09\u5c40\u90e8\u65f6\u95f4\u8868\u793a\u5b66\u4e60\u9636\u6bb5\uff1a\u4f7f\u7528CNN\u5728\u56fa\u5b9a\u957f\u5ea6\u65f6\u95f4\u8865\u4e01\u4e0a\u63d0\u53d6\u77ed\u7a0b\u65f6\u95f4\u52a8\u6001\u548c\u975e\u7ebf\u6027\u7279\u5f81\u4ea4\u4e92\uff0c\u751f\u6210\u7d27\u51d1\u7684\u8865\u4e01\u7ea7token\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7token\u7ea7\u81ea\u6ce8\u610f\u529b\u8de8\u65f6\u95f4\u8865\u4e01\u4ea4\u4e92\u4f18\u5316\u8fd9\u4e9b\u5d4c\u5165\uff1b2\uff09\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\u9636\u6bb5\uff1a\u4f7f\u7528Transformer\u7f16\u7801\u5668\u5904\u7406token\u5e8f\u5217\uff0c\u5efa\u6a21\u8865\u4e01\u95f4\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u5e76\u751f\u6210\u6bcf\u4e2a\u8865\u4e01\u7684\u9884\u6d4b\u3002", "result": "\u5728\u5177\u6709\u53d7\u63a7\u9759\u6001\u548c\u52a8\u6001\u56e0\u7d20\u7684\u5408\u6210\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u8865\u4e01\u7684token\u5316\u7b56\u7565\u76f8\u6bd4\u5377\u79ef\u548c\u57fa\u4e8e\u8865\u4e01\u7684Transformer\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u7ed3\u6784\u5316\u65f6\u95f4\u8868\u793a\u7684\u91cd\u8981\u6027\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c06\u5c40\u90e8\u65f6\u95f4\u7f16\u7801\u4e0e\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5168\u5c40\u5efa\u6a21\u89e3\u8026\u80fd\u591f\u4ea7\u751f\u66f4\u6709\u6548\u548c\u7a33\u5b9a\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002"}}
{"id": "2601.13443", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13443", "abs": "https://arxiv.org/abs/2601.13443", "authors": ["H\u00e9ctor Manuel Manzanilla-Granados", "Zaira Navarrete-Cazales", "Miriam Pescador-Rojas", "Tonahtiu Ram\u00edrez-Romero"], "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models", "comment": "Preprint. This version corresponds to the initial public release of the CUA architecture and associated evaluation metrics", "summary": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.\n  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.\n  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u663e\u5f0f\u8ba4\u77e5\u5206\u914d\"\u539f\u5219\u548c\u8ba4\u77e5\u901a\u7528\u4ee3\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bb\u548c\u7f16\u6392\u8ba4\u77e5\u529f\u80fd\u6765\u7ed3\u6784\u5316AI\u8f85\u52a9\u63a8\u7406\uff0c\u76f8\u6bd4\u4f20\u7edfLLM\u63a8\u7406\u5177\u6709\u66f4\u597d\u7684\u53ef\u8ffd\u6eaf\u6027\u3001\u8ba4\u77e5\u63a7\u5236\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u5f53\u524dLLM\u4f7f\u7528\u6a21\u5f0f\u5b58\u5728\u8ba4\u77e5\u7ed3\u6784\u7f3a\u5931\u95ee\u9898\uff1a\u95ee\u9898\u6846\u67b6\u3001\u77e5\u8bc6\u63a2\u7d22\u3001\u68c0\u7d22\u3001\u65b9\u6cd5\u610f\u8bc6\u548c\u89e3\u91ca\u901a\u5e38\u88ab\u538b\u7f29\u5230\u5355\u4e00\u751f\u6210\u8fc7\u7a0b\u4e2d\u3002\u8fd9\u79cd\u8ba4\u77e5\u5d29\u6e83\u9650\u5236\u4e86\u53ef\u8ffd\u6eaf\u6027\uff0c\u524a\u5f31\u4e86\u8ba4\u77e5\u63a7\u5236\uff0c\u5e76\u635f\u5bb3\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u7279\u522b\u662f\u5728\u9ad8\u8d23\u4efb\u73af\u5883\u4e2d\u3002", "method": "\u63d0\u51fa\u663e\u5f0f\u8ba4\u77e5\u5206\u914d\u539f\u5219\uff0c\u5e76\u5b9e\u4f8b\u5316\u4e3a\u8ba4\u77e5\u901a\u7528\u4ee3\u7406\u67b6\u6784\u3002\u8be5\u67b6\u6784\u5c06\u63a8\u7406\u7ec4\u7ec7\u4e3a\u63a2\u7d22\u4e0e\u6846\u67b6\u3001\u8ba4\u77e5\u951a\u5b9a\u3001\u5de5\u5177\u4e0e\u65b9\u6cd5\u6620\u5c04\u3001\u89e3\u91ca\u6027\u5408\u6210\u7b49\u4e0d\u540c\u9636\u6bb5\u3002\u6838\u5fc3\u6982\u5ff5\u662f\u901a\u7528\u8ba4\u77e5\u5de5\u5177\uff0c\u5f62\u5f0f\u5316\u5404\u79cd\u624b\u6bb5\uff08\u8ba1\u7b97\u3001\u5b9e\u9a8c\u3001\u7ec4\u7ec7\u3001\u76d1\u7ba1\u3001\u6559\u80b2\u5de5\u5177\uff09\uff0c\u4f7f\u62bd\u8c61\u67e5\u8be2\u53d8\u5f97\u53ef\u7814\u7a76\u3002", "result": "\u5728\u519c\u4e1a\u9886\u57df\u7684\u591a\u4e2a\u63d0\u793a\u4e0b\uff0cCUA\u7f16\u6392\u7684\u63a8\u7406\u8868\u73b0\u51fa\u66f4\u65e9\u4e14\u7ed3\u6784\u5316\u7684\u8ba4\u77e5\u6536\u655b\u3001\u8bed\u4e49\u6269\u5c55\u4e0b\u66f4\u9ad8\u7684\u8ba4\u77e5\u5bf9\u9f50\uff0c\u4ee5\u53ca\u7cfb\u7edf\u6027\u5730\u66b4\u9732\u67e5\u8be2\u7684\u5de5\u5177\u6027\u666f\u89c2\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u57fa\u7ebfLLM\u63a8\u7406\u5728\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u5927\u7684\u53d8\u5f02\u6027\uff0c\u4e14\u672a\u80fd\u660e\u786e\u5c55\u73b0\u5de5\u5177\u7ed3\u6784\u3002", "conclusion": "\u663e\u5f0f\u8ba4\u77e5\u548c\u5de5\u5177\u5206\u914d\u80fd\u591f\u663e\u8457\u6539\u5584AI\u8f85\u52a9\u63a8\u7406\u7684\u7ed3\u6784\u5316\u7a0b\u5ea6\uff0c\u589e\u5f3a\u8ba4\u77e5\u63a7\u5236\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u8d23\u4efb\u6027\u7684\u79d1\u5b66\u3001\u6280\u672f\u548c\u7ec4\u7ec7\u9886\u57df\u3002"}}
{"id": "2601.12658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12658", "abs": "https://arxiv.org/abs/2601.12658", "authors": ["Tianyi Yang", "Nashrah Haque", "Vaishnave Jonnalagadda", "Yuya Jeremy Ong", "Zhehui Chen", "Yanzhao Wu", "Lei Yu", "Divyesh Jadav", "Wenqi Wei"], "title": "Augmenting Question Answering with A Hybrid RAG Approach", "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.", "AI": {"tldr": "SSRAG\u662f\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u67e5\u8be2\u589e\u5f3a\u3001\u667a\u80fd\u8def\u7531\u548c\u7ed3\u6784\u5316\u68c0\u7d22\u673a\u5236\u63d0\u5347RAG\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5728\u68c0\u7d22\u4e0a\u4e0b\u6587\u76f8\u5173\u4fe1\u606f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5bfc\u81f4\u7b54\u6848\u4e0d\u5b8c\u6574\u6216\u4e0d\u591f\u7406\u60f3\uff0c\u9700\u8981\u6539\u8fdb\u68c0\u7d22\u8fc7\u7a0b\u4ee5\u63d0\u9ad8\u95ee\u7b54\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u8bed\u4e49RAG\uff08SSRAG\uff09\u6df7\u5408\u67b6\u6784\uff0c\u6574\u5408\u67e5\u8be2\u589e\u5f3a\u3001\u667a\u80fd\u8def\u7531\uff0c\u4ee5\u53ca\u7ed3\u5408\u5411\u91cf\u548c\u56fe\u6280\u672f\u7684\u7ed3\u6784\u5316\u68c0\u7d22\u673a\u5236\u4e0e\u4e0a\u4e0b\u6587\u7edf\u4e00\u3002", "result": "\u5728TruthfulQA\u3001SQuAD\u548cWikiQA\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0cSSRAG\u76f8\u6bd4\u6807\u51c6RAG\u5b9e\u73b0\u6301\u7eed\u63d0\u5347\u4e86\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "SSRAG\u901a\u8fc7\u6539\u8fdb\u68c0\u7d22\u8fc7\u7a0b\u548c\u589e\u5f3a\u4e0a\u4e0b\u6587\u57fa\u7840\uff0c\u63d0\u9ad8\u4e86\u7b54\u6848\u51c6\u786e\u6027\u548c\u4fe1\u606f\u4e30\u5bcc\u5ea6\uff0c\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8d28\u91cf\u63d0\u5347\u65b9\u6848\u3002"}}
{"id": "2601.12502", "categories": ["cs.LG", "math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.12502", "abs": "https://arxiv.org/abs/2601.12502", "authors": ["Mikhail Gennadievich Belov", "Victor Victorovich Dubov", "Vadim Konstantinovich Ivanov", "Alexander Yurievich Maslov", "Olga Vladimirovna Proshina", "Vladislav Gennadievich Malyshkin"], "title": "Semidefinite Programming for Quantum Channel Learning", "comment": null, "summary": "The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u4ece\u7ecf\u5178\u6570\u636e\u91cd\u5efa\u91cf\u5b50\u901a\u9053\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u4fdd\u771f\u5ea6\u53ef\u8868\u793a\u4e3a\u4e24\u4e2a\u4e8c\u6b21\u578b\u6bd4\u503c\u7684\u60c5\u51b5\uff0c\u5e76\u53d1\u73b0\u91cd\u5efa\u7684\u91cf\u5b50\u901a\u9053\u901a\u5e38\u5177\u6709\u8f83\u5c0f\u7684Kraus\u79e9\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4ece\u7ecf\u5178\u5b9e\u9a8c\u6570\u636e\u4e2d\u91cd\u5efa\u91cf\u5b50\u901a\u9053\uff0c\u8fd9\u5bf9\u4e8e\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u91cf\u5b50\u7cfb\u7edf\u884c\u4e3a\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5f53\u603b\u4fdd\u771f\u5ea6\u53ef\u8868\u793a\u4e3a\u4e24\u4e2a\u4e8c\u6b21\u578b\u6bd4\u503c\u65f6\uff0c\u5c06\u4fdd\u771f\u5ea6\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u5173\u4e8eChoi\u77e9\u9635\u7684\u534a\u5b9a\u89c4\u5212\u95ee\u9898\uff0c\u5229\u7528\u5546\u4e1aSDP\u6c42\u89e3\u5668\u8fdb\u884c\u6570\u503c\u6c42\u89e3\u3002", "result": "\u6d4b\u8bd5\u591a\u4e2a\u5546\u4e1aSDP\u6c42\u89e3\u5668\u90fd\u80fd\u6210\u529f\u91cd\u5efa\u4e0d\u540c\u5f62\u5f0f\u7684\u91cf\u5b50\u901a\u9053\uff0c\u4e14\u83b7\u5f97\u7684\u91cf\u5b50\u901a\u9053Kraus\u79e9\u901a\u5e38\u5c0f\u4e8e\u6700\u5927\u53ef\u80fd\u503c\u7684\u51e0\u4e2a\u767e\u5206\u70b9\uff0c\u8868\u660e\u5c0fKraus\u79e9\u91cf\u5b50\u901a\u9053\u8db3\u4ee5\u63cf\u8ff0\u5b9e\u9a8c\u89c2\u6d4b\u6570\u636e\u3002", "conclusion": "SDP\u65b9\u6cd5\u80fd\u6709\u6548\u91cd\u5efa\u91cf\u5b50\u901a\u9053\uff0c\u4e14\u901a\u5e38\u53ea\u9700\u8981\u5c0fKraus\u79e9\u7684\u91cf\u5b50\u901a\u9053\uff1b\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8e\u91cd\u5efa\u6295\u5f71\u7b97\u5b50\uff0c\u5e76\u8ba8\u8bba\u4e86\u57fa\u4e8e\u91cf\u5b50\u901a\u9053\u53d8\u6362\u7684\u7ecf\u5178\u8ba1\u7b97\u6a21\u578b\u3002"}}
{"id": "2601.13462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13462", "abs": "https://arxiv.org/abs/2601.13462", "authors": ["Amine Rostane"], "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation", "comment": "19 pages, includes figures and tables", "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.", "AI": {"tldr": "SpatialBench-UC\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\u7684\u5c0f\u578b\u53ef\u590d\u73b0\u57fa\u51c6\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\u548c100\u4e2a\u53cd\u4e8b\u5b9e\u5bf9\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u9884\u6d4b\u65b9\u6cd5\u62a5\u544a\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\u3002", "motivation": "\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u9075\u5faa\u660e\u786e\u7684\u7a7a\u95f4\u6307\u4ee4\u96be\u4ee5\u81ea\u52a8\u5316\uff0c\u56e0\u4e3a\u5bf9\u8c61\u68c0\u6d4b\u5668\u53ef\u80fd\u6f0f\u68c0\u6216\u8fd4\u56de\u591a\u4e2a\u68c0\u6d4b\u7ed3\u679c\uff0c\u7b80\u5355\u7684\u51e0\u4f55\u6d4b\u8bd5\u5728\u8fb9\u754c\u60c5\u51b5\u4e0b\u53d8\u5f97\u6a21\u7cca\u3002\u7a7a\u95f4\u8bc4\u4f30\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u9009\u62e9\u6027\u9884\u6d4b\u95ee\u9898\u3002", "method": "\u63d0\u51faSpatialBench-UC\u57fa\u51c6\uff0c\u5305\u542b200\u4e2a\u63d0\u793a\uff0850\u4e2a\u5bf9\u8c61\u5bf9\u00d74\u79cd\u5173\u7cfb\uff09\uff0c\u5206\u7ec4\u4e3a100\u4e2a\u53cd\u4e8b\u5b9e\u5bf9\u3002\u53d1\u5e03\u5305\u542b\u7248\u672c\u5316\u63d0\u793a\u3001\u56fa\u5b9a\u914d\u7f6e\u3001\u6bcf\u6837\u672c\u68c0\u67e5\u5668\u8f93\u51fa\u7684\u57fa\u51c6\u5305\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u4eba\u5de5\u5ba1\u6838\u6765\u6821\u51c6\u68c0\u67e5\u5668\u7684\u5f03\u6743\u8fb9\u754c\u548c\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "result": "\u8bc4\u4f30\u4e86\u4e09\u4e2a\u57fa\u7ebf\u6a21\u578b\uff1aStable Diffusion 1.5\u3001SD 1.5 BoxDiff\u548cSD 1.4 GLIGEN\u3002\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u7840\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u8fc7\u7387\u548c\u8986\u76d6\u7387\uff0c\u4f46\u5f03\u6743\u4ecd\u7136\u662f\u4e3b\u8981\u56e0\u7d20\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u68c0\u6d4b\u7f3a\u5931\u3002", "conclusion": "SpatialBench-UC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u53ef\u5ba1\u8ba1\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\u80fd\u529b\u3002\u9009\u62e9\u6027\u9884\u6d4b\u65b9\u6cd5\u5141\u8bb8\u68c0\u67e5\u5668\u5728\u8bc1\u636e\u4e0d\u8db3\u65f6\u5f03\u6743\uff0c\u5e76\u4ee5\u98ce\u9669\u8986\u76d6\u6743\u8861\u800c\u975e\u5355\u4e00\u5206\u6570\u6765\u62a5\u544a\u7ed3\u679c\u3002"}}
{"id": "2601.12696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12696", "abs": "https://arxiv.org/abs/2601.12696", "authors": ["Tassallah Abdullahi", "Macton Mgonzo", "Mardiyyah Oduwole", "Paul Okewunmi", "Abraham Owodunni", "Ritambhara Singh", "Carsten Eickhoff"], "title": "UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages", "comment": "12 pages", "summary": "Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.", "AI": {"tldr": "UbuntuGuard\u662f\u9996\u4e2a\u975e\u6d32\u653f\u7b56\u5bfc\u5411\u7684\u5b89\u5168\u57fa\u51c6\uff0c\u9488\u5bf9\u4f4e\u8d44\u6e90\u975e\u6d32\u8bed\u8a00\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u6784\u5efa\u5bf9\u6297\u6027\u67e5\u8be2\u548c\u60c5\u5883\u5316\u5b89\u5168\u7b56\u7565\uff0c\u8bc4\u4f30\u73b0\u6709\u5b88\u62a4\u6a21\u578b\u7684\u8de8\u8bed\u8a00\u548c\u6587\u5316\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u5b88\u62a4\u6a21\u578b\u4e3b\u8981\u9762\u5411\u897f\u65b9\u4e2d\u5fc3\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5bf9\u4f4e\u8d44\u6e90\u975e\u6d32\u8bed\u8a00\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3001\u8de8\u8bed\u8a00\u5b89\u5168\u5931\u6548\u548c\u6587\u5316\u9519\u4f4d\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u5b89\u5168\u5206\u7c7b\u50f5\u5316\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u7684\u8bed\u8a00\u548c\u793e\u4f1a\u6587\u5316\u80cc\u666f\u3002", "method": "\u6784\u5efaUbuntuGuard\u57fa\u51c6\uff1a1) 155\u540d\u9886\u57df\u4e13\u5bb6\uff08\u5305\u62ec\u533b\u7597\u5065\u5eb7\u9886\u57df\uff09\u7f16\u5199\u5bf9\u6297\u6027\u67e5\u8be2\uff1b2) \u4ece\u67e5\u8be2\u4e2d\u63a8\u5bfc\u60c5\u5883\u5316\u5b89\u5168\u7b56\u7565\u548c\u53c2\u8003\u54cd\u5e94\uff1b3) \u8bc4\u4f3013\u4e2a\u6a21\u578b\uff086\u4e2a\u901a\u7528LLM\u548c7\u4e2a\u5b88\u62a4\u6a21\u578b\uff09\uff0c\u6db5\u76d6\u9759\u6001\u3001\u52a8\u6001\u548c\u591a\u8bed\u8a00\u4e09\u79cd\u53d8\u4f53\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u73b0\u6709\u82f1\u8bed\u4e2d\u5fc3\u57fa\u51c6\u9ad8\u4f30\u4e86\u591a\u8bed\u8a00\u5b89\u5168\u6027\u80fd\uff1b2) \u8de8\u8bed\u8a00\u8fc1\u79fb\u53ea\u80fd\u63d0\u4f9b\u90e8\u5206\u4f46\u4e0d\u5145\u5206\u7684\u8986\u76d6\uff1b3) \u52a8\u6001\u6a21\u578b\u867d\u7136\u80fd\u5728\u63a8\u7406\u65f6\u5229\u7528\u7b56\u7565\uff0c\u4f46\u4ecd\u96be\u4ee5\u5b8c\u5168\u9002\u5e94\u5f53\u5730\u975e\u6d32\u8bed\u8a00\u60c5\u5883\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u591a\u8bed\u8a00\u3001\u6587\u5316\u624e\u6839\u7684\u5b89\u5168\u57fa\u51c6\uff0c\u4ee5\u6784\u5efa\u53ef\u9760\u3001\u516c\u5e73\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u5b88\u62a4\u6a21\u578b\uff0cUbuntuGuard\u4e3a\u6b64\u63d0\u4f9b\u4e86\u9996\u4e2a\u975e\u6d32\u653f\u7b56\u5bfc\u5411\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.13464", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13464", "abs": "https://arxiv.org/abs/2601.13464", "authors": ["Chongyang Gao", "Marco Postiglione", "Julian Baldwin", "Natalia Denisenko", "Isabel Gortner", "Luke Fosdick", "Chiara Pulice", "Sarit Kraus", "V. S. Subrahmanian"], "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures", "comment": null, "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668CADD\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8f6c\u5f55\u6587\u672c\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5bf9\u6297\u653b\u51fb\u66f4\u5177\u9c81\u68d2\u6027\u3002", "motivation": "\u4eba\u7c7b\u5229\u7528\u4e0a\u4e0b\u6587\u5224\u65ad\u4fe1\u606f\u771f\u4f2a\uff0c\u4f46\u73b0\u6709\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5668\u4ec5\u5206\u6790\u97f3\u9891\u6587\u4ef6\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u7684\u91cd\u8981\u4fe1\u606f\u3002", "method": "\u521b\u5efa\u8bb0\u8005\u63d0\u4f9b\u7684\u6df1\u5ea6\u4f2a\u9020\u6570\u636e\u96c6JDD\u548c\u5408\u6210\u97f3\u9891\u6570\u636e\u96c6SYN\uff0c\u63d0\u51faCADD\u67b6\u6784\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u589e\u5f3a\u68c0\u6d4b\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff1aF1\u5206\u6570\u63d0\u9ad85%-37.58%\uff0cAUC\u63d0\u9ad83.77%-42.79%\uff0cEER\u964d\u4f4e6.17%-47.83%\u3002CADD\u5bf95\u79cd\u5bf9\u6297\u653b\u51fb\u7b56\u7565\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u5e73\u5747\u6027\u80fd\u4e0b\u964d\u4ec5-0.71%\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u548c\u8f6c\u5f55\u6587\u672c\u5bf9\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0cCADD\u67b6\u6784\u901a\u8fc7\u6574\u5408\u8fd9\u4e9b\u4fe1\u606f\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u548c\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12698", "abs": "https://arxiv.org/abs/2601.12698", "authors": ["Qiuyi Qu", "Yicheng Sui", "Yufei Sun", "Rui Chen", "Xiaofei Zhang", "Yuzhi Zhang", "Haofeng Wang", "Ge Lan", "Ning Zhang"], "title": "A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization", "comment": null, "summary": "GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u677f\u7684GPU\u5185\u6838\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u6a21\u677f\u548c\u641c\u7d22\u5f0f\u81ea\u52a8\u8c03\u4f18\uff0c\u76f8\u6bd4\u76f4\u63a5\u4ee3\u7801\u91cd\u5199\u83b7\u5f97\u66f4\u7a33\u5b9a\u3001\u66f4\u9ad8\u8d28\u91cf\u7684\u52a0\u901f\u6548\u679c", "motivation": "GPU\u4ee3\u7801\u4f18\u5316\u5bf9HPC\u548c\u5927\u6a21\u578b\u8bad\u7ec3/\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u7f16\u8bd1\u5668\u4f18\u5316\u3001\u624b\u5de5\u5185\u6838\u3001\u57fa\u4e8eLLM\u7684\u76f4\u63a5\u91cd\u5199\uff09\u5b58\u5728\u53c2\u6570\u9009\u62e9\u9690\u5f0f\u3001\u96be\u4ee5\u63a7\u5236\u3001\u9700\u8981\u4eba\u5de5\u5e72\u9884\u3001\u6027\u80fd\u63d0\u5347\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898", "method": "\u5728\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u8fed\u4ee3\u5faa\u73af\u4e0a\u589e\u52a0\u6a21\u677f\u91cd\u5199\u5c42\uff1a1\uff09\u5c06\u5185\u6838\u8bed\u4e49\u91cd\u6784\u4e3a\u663e\u5f0f\u53c2\u6570\u5316\u6a21\u677f\uff1b2\uff09\u901a\u8fc7\u57fa\u4e8e\u641c\u7d22\u7684\u81ea\u52a8\u8c03\u4f18\u4f18\u5316\u6a21\u677f\u53c2\u6570\uff1b3\uff09\u4f7f\u7528\u667a\u80fd\u4f53\u8c03\u4f18\u5668\u8fed\u4ee3\u6267\u884c\u6a21\u677f\u5316\u3001\u6d4b\u8bd5\u3001\u5206\u6790\u548c\u89c4\u5212\uff0c\u5229\u7528\u6027\u80fd\u5206\u6790\u53cd\u9988\u5728\u786c\u4ef6\u8d44\u6e90\u9650\u5236\u4e0b\u6267\u884c\u7ea6\u675f\u53c2\u6570\u641c\u7d22", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5185\u6838\u5b9e\u9a8c\u4e2d\uff0c\u6700\u4f73\u60c5\u51b5\u4e0b\u83b7\u5f97\u8d85\u8fc73\u500d\u7684\u52a0\u901f\u3002\u76f8\u6bd4\u4ec5\u4f7f\u7528\u667a\u80fd\u4f53\u76f4\u63a5\u91cd\u5199\uff0c\u6a21\u677f+\u641c\u7d22\u8bbe\u8ba1\u663e\u8457\u964d\u4f4e\u4e86\u8fed\u4ee3\u4f18\u5316\u7684\u968f\u673a\u6027\uff0c\u4f7f\u8fc7\u7a0b\u66f4\u53ef\u89e3\u91ca\uff0c\u80fd\u591f\u66f4\u7cfb\u7edf\u5730\u8fbe\u5230\u9ad8\u6027\u80fd\u914d\u7f6e", "conclusion": "\u63d0\u51fa\u7684\u6a21\u677f+\u641c\u7d22\u65b9\u6cd5\u4e3aGPU\u5185\u6838\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u3001\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u6269\u5c55\u5230OpenCL\u3001HIP\u7b49\u540e\u7aef\uff0c\u4e3a\u5b9e\u9645\u751f\u4ea7\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u81ea\u52a8\u5316\u6027\u80fd\u4f18\u5316"}}
{"id": "2601.12519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12519", "abs": "https://arxiv.org/abs/2601.12519", "authors": ["Abdullah Umut Hamzaogullari", "Arkadas Ozakin"], "title": "Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks", "comment": "21 pages", "summary": "Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\\% lower validation loss value and 90.68\\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u6539\u8fdb\u62c9\u683c\u6717\u65e5\u795e\u7ecf\u7f51\u7edc(LNNs)\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u5305\u62ecHessian\u6b63\u5219\u5316\u3001\u4e13\u7528\u6fc0\u6d3b\u51fd\u6570\u548c\u7269\u7406\u611f\u77e5\u5750\u6807\u7f29\u653e\uff0c\u4f7fLNNs\u80fd\u591f\u5b66\u4e60\u66f4\u590d\u6742\u7cfb\u7edf\u7684\u62c9\u683c\u6717\u65e5\u91cf\uff0c\u5305\u62ec\u76f8\u5bf9\u8bba\u80cc\u666f\u4e0b\u7684\u6d4b\u5730\u7ebf\u8fd0\u52a8\u3002", "motivation": "\u62c9\u683c\u6717\u65e5\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u4ece\u8f68\u8ff9\u6570\u636e\u4e2d\u5b66\u4e60\u4efb\u610f\u62c9\u683c\u6717\u65e5\u91cf\uff0c\u4f46\u5176\u4e0d\u5bfb\u5e38\u7684\u4f18\u5316\u76ee\u6807\u5bfc\u81f4\u663e\u8457\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u57fa\u672c\u6311\u6218\u4ee5\u6269\u5c55LNNs\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u4e2a\u4e3b\u8981\u6539\u8fdb\uff1a1) Hessian\u6b63\u5219\u5316\u65b9\u6848\uff0c\u60e9\u7f5a\u62c9\u683c\u6717\u65e5\u91cf\u5bf9\u901f\u5ea6\u4e8c\u9636\u5bfc\u6570\u4e2d\u7684\u975e\u7269\u7406\u7279\u5f81\uff1b2) \u66f4\u9002\u5408\u5b66\u4e60\u62c9\u683c\u6717\u65e5\u91cf\u7684\u6fc0\u6d3b\u51fd\u6570\uff1b3) \u7269\u7406\u611f\u77e5\u5750\u6807\u7f29\u653e\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002\u5728\u76f8\u5bf9\u8bba\u8bbe\u7f6e\u4e2d\uff0c\u8fd8\u6269\u5c55\u6b63\u5219\u5316\u4ee5\u60e9\u7f5a\u6d1b\u4f26\u5179\u7279\u5f81\u7684\u8fdd\u53cd\u3002", "result": "\u6539\u8fdb\u7684\u67b6\u6784\u6210\u529f\u8bad\u7ec3\u4e86\u524d\u6240\u672a\u6709\u7684\u590d\u6742\u7cfb\u7edf\uff0c\u5305\u62ec\u4e09\u6446\u7cfb\u7edf\u3002\u5728\u53cc\u6446\u7cfb\u7edf\u4e2d\uff0c\u9a8c\u8bc1\u635f\u5931\u964d\u4f4e\u4e8696.6%\uff0c\u7a33\u5b9a\u6027\u63d0\u9ad8\u4e8690.68%\u3002\u80fd\u591f\u5b66\u4e60\u975e\u76f8\u5bf9\u8bba\u548c\u5e7f\u4e49\u76f8\u5bf9\u8bba\u80cc\u666f\u4e0b\u7684\u6d4b\u5730\u7ebf\u8fd0\u52a8\u62c9\u683c\u6717\u65e5\u91cf\uff0c\u9996\u6b21\u76f4\u63a5\u4ece\u8f68\u8ff9\u6570\u636e\u9884\u6d4bAdS\u2084\u65f6\u7a7a\u5ea6\u91cf\u4e0b\u7684\u6d4b\u5730\u7ebf\u62c9\u683c\u6717\u65e5\u91cf\u3002", "conclusion": "\u867d\u7136\u8be5\u65b9\u6cd5\u7ee7\u627f\u4e86\u539f\u59cbLNN\u6846\u67b6\u7684\u4e00\u4e9b\u9650\u5236\uff08\u7279\u522b\u662f\u53ef\u9006Hessian\u7684\u8981\u6c42\uff09\uff0c\u4f46\u663e\u8457\u6269\u5c55\u4e86LNNs\u5728\u79d1\u5b66\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u9002\u7528\u6027\uff0c\u4e3a\u7269\u7406\u4e2d\u51e0\u4f55\u7ed3\u6784\u7684\u81ea\u52a8\u53d1\u73b0\uff08\u5305\u62ec\u4ece\u6d4b\u5730\u7ebf\u8f68\u8ff9\u63d0\u53d6\u65f6\u7a7a\u5ea6\u91cf\u5f20\u91cf\u5206\u91cf\uff09\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.13465", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13465", "abs": "https://arxiv.org/abs/2601.13465", "authors": ["Yimeng Min", "Carla P. Gomes"], "title": "Graph Neural Networks are Heuristics", "comment": null, "summary": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.", "AI": {"tldr": "\u5355\u4e2a\u8bad\u7ec3\u8f68\u8ff9\u53ef\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u8f6c\u5316\u4e3a\u7ec4\u5408\u4f18\u5316\u7684\u65e0\u76d1\u7763\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u7528\u4e8e\u65c5\u884c\u5546\u95ee\u9898\uff0c\u65e0\u9700\u641c\u7d22\u3001\u76d1\u7763\u6216\u5e8f\u5217\u51b3\u7b56", "motivation": "\u63a2\u7d22\u56fe\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u5728\u65e0\u76d1\u7763\u3001\u65e0\u641c\u7d22\u7684\u60c5\u51b5\u4e0b\u76f4\u63a5\u4f5c\u4e3a\u7ec4\u5408\u4f18\u5316\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u91cd\u65b0\u5b9a\u4e49\u5b66\u4e60\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u4f5c\u7528", "method": "\u5c06\u5168\u5c40\u7ed3\u6784\u7ea6\u675f\u7f16\u7801\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u4f7f\u975e\u81ea\u56de\u5f52\u6a21\u578b\u901a\u8fc7\u524d\u5411\u4f20\u64ad\u76f4\u63a5\u751f\u6210\u89e3\uff1b\u63a8\u7406\u65f6\u4f7f\u7528dropout\u548c\u5feb\u7167\u96c6\u6210\u4f5c\u4e3a\u9690\u5f0f\u96c6\u6210\uff0c\u589e\u52a0\u89e3\u591a\u6837\u6027", "result": "\u56fe\u795e\u7ecf\u7f51\u7edc\u65e0\u9700\u76d1\u7763\u8bad\u7ec3\u6216\u663e\u5f0f\u641c\u7d22\u5373\u53ef\u6709\u6548\u5de5\u4f5c\uff0c\u80fd\u591f\u5185\u5316\u5168\u5c40\u7ec4\u5408\u7ed3\u6784\u5e76\u4f5c\u4e3a\u5f3a\u5927\u7684\u5b66\u4e60\u542f\u53d1\u5f0f\u7b97\u6cd5", "conclusion": "\u5b66\u4e60\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u4f5c\u7528\u5e94\u4ece\u589e\u5f3a\u7ecf\u5178\u7b97\u6cd5\u8f6c\u53d8\u4e3a\u76f4\u63a5\u5b9e\u4f8b\u5316\u65b0\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5"}}
{"id": "2601.12731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12731", "abs": "https://arxiv.org/abs/2601.12731", "authors": ["Stefano Civelli", "Pietro Bernardelle", "Nicol\u00f2 Brunello", "Gianluca Demartini"], "title": "A Shared Geometry of Difficulty in Multilingual Language Models", "comment": null, "summary": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.", "AI": {"tldr": "LLMs\u5728\u95ee\u9898\u96be\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u4e24\u9636\u6bb5\u8868\u5f81\uff1a\u6d45\u5c42\u8868\u5f81\u5177\u6709\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u4f46\u7cbe\u5ea6\u8f83\u4f4e\uff0c\u6df1\u5c42\u8868\u5f81\u5728\u5355\u4e00\u8bed\u8a00\u5185\u7cbe\u5ea6\u9ad8\u4f46\u8de8\u8bed\u8a00\u6cdb\u5316\u5dee\uff0c\u8868\u660e\u6a21\u578b\u5148\u5f62\u6210\u8bed\u8a00\u65e0\u5173\u7684\u96be\u5ea6\u6982\u5ff5\u518d\u8f6c\u5316\u4e3a\u8bed\u8a00\u7279\u5b9a\u8868\u5f81\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5982\u4f55\u8868\u5f81\u95ee\u9898\u96be\u5ea6\uff0c\u63a2\u7d22\u96be\u5ea6\u4fe1\u53f7\u5728\u6a21\u578b\u5185\u90e8\u4e0d\u540c\u5c42\u7ea7\u7684\u5206\u5e03\u53ca\u5176\u8de8\u8bed\u8a00\u6cdb\u5316\u7279\u6027\uff0c\u7406\u89e3LLMs\u5904\u7406\u5143\u8ba4\u77e5\u5c5e\u6027\uff08\u5982\u96be\u5ea6\u4f30\u8ba1\uff09\u7684\u673a\u5236\u3002", "method": "\u4f7f\u7528Easy2Hard\u57fa\u51c6\u7684AMC\u5b50\u96c6\uff0c\u7ffb\u8bd1\u4e3a21\u79cd\u8bed\u8a00\uff0c\u5728LLMs\u5185\u90e8\u8868\u5f81\u4e0a\u8bad\u7ec3\u7ebf\u6027\u63a2\u9488\uff0c\u5206\u6790\u6d45\u5c42\uff08\u65e9\u671f\u5c42\uff09\u548c\u6df1\u5c42\uff08\u540e\u671f\u5c42\uff09\u8868\u5f81\u5728\u96be\u5ea6\u9884\u6d4b\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u53d1\u73b0\u96be\u5ea6\u76f8\u5173\u4fe1\u53f7\u51fa\u73b0\u5728\u4e24\u4e2a\u4e0d\u540c\u9636\u6bb5\uff1a\u6df1\u5c42\u8868\u5f81\u63a2\u9488\u5728\u76f8\u540c\u8bed\u8a00\u5185\u7cbe\u5ea6\u9ad8\u4f46\u8de8\u8bed\u8a00\u6cdb\u5316\u5dee\uff1b\u6d45\u5c42\u8868\u5f81\u63a2\u9488\u8de8\u8bed\u8a00\u6cdb\u5316\u597d\u4f46\u8bed\u8a00\u5185\u7cbe\u5ea6\u8f83\u4f4e\u3002\u8868\u660eLLMs\u5148\u5f62\u6210\u8bed\u8a00\u65e0\u5173\u7684\u96be\u5ea6\u8868\u5f81\uff0c\u518d\u8f6c\u5316\u4e3a\u8bed\u8a00\u7279\u5b9a\u8868\u5f81\u3002", "conclusion": "LLMs\u5904\u7406\u95ee\u9898\u96be\u5ea6\u4f30\u8ba1\u65f6\u9075\u5faa\u4e24\u9636\u6bb5\u8868\u5f81\u8fc7\u7a0b\uff1a\u5148\u62bd\u8c61\u6982\u5ff5\u7a7a\u95f4\uff08\u8bed\u8a00\u65e0\u5173\uff09\uff0c\u540e\u8bed\u8a00\u7279\u5b9a\u8f93\u51fa\u3002\u8fd9\u4e00\u6a21\u5f0f\u4e0d\u4ec5\u9002\u7528\u4e8e\u8bed\u4e49\u5185\u5bb9\uff0c\u4e5f\u9002\u7528\u4e8e\u5143\u8ba4\u77e5\u5c5e\u6027\u5982\u96be\u5ea6\u4f30\u8ba1\uff0c\u4e0e\u73b0\u6709LLM\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e00\u81f4\u3002"}}
{"id": "2601.12525", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.12525", "abs": "https://arxiv.org/abs/2601.12525", "authors": ["Nikolaj Tatti"], "title": "Approximating splits for decision trees quickly in sparse data streams", "comment": null, "summary": "Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + \u03b1)$ approximation when using conditional entropy in amortized $O(\u03b1^{-1}(1 + m\\log d) \\log \\log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + \u03b1)$ approximation in amortized $O(\u03b1^{-1} + m \\log d)$ time. Our approach is beneficial for sparse data where $m \\ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u548c\u4e8c\u5143\u5206\u7c7b\u7684\u51b3\u7b56\u6811\u5206\u88c2\u7b97\u6cd5\uff0c\u80fd\u5728\u8fd1\u4f3c\u6700\u4f18\u4fe1\u606f\u589e\u76ca\u6216\u57fa\u5c3c\u6307\u6570\u7684\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u6bd4\u4f20\u7edfO(d)\u65b9\u6cd5\u66f4\u5feb\u7684\u5206\u88c2\u641c\u7d22\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7a00\u758f\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6811\u5206\u88c2\u7b97\u6cd5\u5728\u5904\u7406\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u65f6\uff0c\u5373\u4f7f\u5927\u90e8\u5206\u7279\u5f81\u503c\u4e3a0\uff0c\u4ecd\u9700O(d)\u65f6\u95f4\u68c0\u67e5\u6240\u6709\u7279\u5f81\u3002\u5bf9\u4e8e\u7a00\u758f\u6570\u636e\uff08m << d\uff09\uff0c\u8fd9\u79cd\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u5feb\u7684\u8fd1\u4f3c\u6700\u4f18\u5206\u88c2\u641c\u7d22\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u71b5\u548c\u57fa\u5c3c\u6307\u6570\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff1a1) \u5bf9\u4e8e\u6761\u4ef6\u71b5\uff0c\u5b9e\u73b0(1+\u03b1)\u8fd1\u4f3c\uff0c\u644a\u9500\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(\u03b1^{-1}(1+m log d) log log n)\uff1b2) \u5bf9\u4e8e\u57fa\u5c3c\u6307\u6570\uff0c\u5b9e\u73b0(1+\u03b1)\u8fd1\u4f3c\uff0c\u644a\u9500\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(\u03b1^{-1}+m log d)\u3002\u7b97\u6cd5\u5229\u7528\u7a00\u758f\u6027\uff0c\u53ea\u5173\u6ce8\u975e\u96f6\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7b97\u6cd5\u80fd\u9ad8\u6548\u627e\u5230\u8fd1\u4f3c\u6700\u4f18\u5206\u88c2\u70b9\uff0c\u901f\u5ea6\u8d85\u8fc7\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u5b9e\u9645\u6027\u80fd\u4f18\u4e8e\u7406\u8bba\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u5728\u7a00\u758f\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5176\u4e2dm\u8fdc\u5c0f\u4e8ed\u65f6\u4f18\u52bf\u660e\u663e\u3002", "conclusion": "\u9488\u5bf9\u7a00\u758f\u4e8c\u5143\u7279\u5f81\u7684\u51b3\u7b56\u6811\u5206\u88c2\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u8fd1\u4f3c\u7b97\u6cd5\u80fd\u663e\u8457\u52a0\u901f\u5206\u88c2\u641c\u7d22\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u540c\u65f6\uff0c\u4e3a\u6d41\u5f0f\u51b3\u7b56\u6811\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13481", "abs": "https://arxiv.org/abs/2601.13481", "authors": ["Jian Zhang", "Zhangqi Wang", "Zhiyuan Wang", "Weiping Fu", "Yu He", "Haiping Zhu", "Qika Lin", "Jun Liu"], "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement", "comment": null, "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.", "AI": {"tldr": "APOLO\u662f\u4e00\u4e2a\u7528\u4e8e\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u60c5\u611f\u8bca\u65ad\u7684\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u63a2\u7d22\u66f4\u7cbe\u7ec6\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u89e3\u51b3\u60c5\u611f\u5171\u75c5\u548c\u4e34\u5e8a\u7ebf\u7d22\u6316\u6398\u4e0d\u8db3\u7684\u6311\u6218\u3002", "motivation": "\u5728\u4e34\u5e8a\u8bb0\u5f55\u3001\u54a8\u8be2\u5bf9\u8bdd\u548c\u5728\u7ebf\u5fc3\u7406\u5065\u5eb7\u793e\u533a\u4e2d\uff0c\u6291\u90c1\u3001\u7126\u8651\u548c\u521b\u4f24\u76f8\u5173\u72b6\u6001\u7684\u60c5\u611f\u8868\u8fbe\u666e\u904d\u5b58\u5728\uff0c\u51c6\u786e\u8bc6\u522b\u8fd9\u4e9b\u60c5\u611f\u5bf9\u4e8e\u4e34\u5e8a\u5206\u8bca\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5728\u9ad8\u98ce\u9669\u3001\u4e0a\u4e0b\u6587\u5bc6\u96c6\u7684\u533b\u7597\u73af\u5883\u4e2d\uff0c\u5176\u8bca\u65ad\u53ef\u9760\u6027\u5bf9\u63d0\u793a\u8bbe\u8ba1\u9ad8\u5ea6\u654f\u611f\u3002\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u60c5\u611f\u5171\u75c5\uff08\u591a\u79cd\u4ea4\u7ec7\u7684\u60c5\u611f\u72b6\u6001\u4f7f\u9884\u6d4b\u590d\u6742\u5316\uff09\u548c\u5bf9\u4e34\u5e8a\u76f8\u5173\u7ebf\u7d22\u7684\u4f4e\u6548\u63a2\u7d22\u3002", "method": "\u63d0\u51faAPOLO\u6846\u67b6\uff0c\u5c06\u6307\u4ee4\u4f18\u5316\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u5305\u62ec\u89c4\u5212\u8005\u3001\u6559\u5e08\u3001\u6279\u8bc4\u8005\u3001\u5b66\u751f\u548c\u76ee\u6807\u89d2\u8272\u3002\u89c4\u5212\u8005\u5b9a\u4e49\u4f18\u5316\u8f68\u8ff9\uff0c\u6559\u5e08-\u6279\u8bc4\u8005-\u5b66\u751f\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u4ee5\u589e\u5f3a\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\uff0c\u76ee\u6807\u667a\u80fd\u4f53\u6839\u636e\u6027\u80fd\u8bc4\u4f30\u51b3\u5b9a\u662f\u5426\u7ee7\u7eed\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPOLO\u5728\u9886\u57df\u7279\u5b9a\u548c\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5728\u7cbe\u795e\u5065\u5eb7\u62a4\u7406\u4e2d\u53ef\u4fe1\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7684\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u8303\u5f0f\u3002", "conclusion": "APOLO\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u66f4\u5e7f\u6cdb\u548c\u66f4\u7ec6\u7c92\u5ea6\u7684\u63d0\u793a\u7a7a\u95f4\uff0c\u63d0\u9ad8\u4e86\u7cbe\u795e\u5065\u5eb7\u60c5\u611f\u8bca\u65ad\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u89e3\u51b3\u60c5\u611f\u5171\u75c5\u548c\u4e34\u5e8a\u7ebf\u7d22\u6316\u6398\u4e0d\u8db3\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u533b\u7597\u9886\u57df\u53ef\u4fe1\u8d56\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8303\u5f0f\u3002"}}
{"id": "2601.12748", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12748", "abs": "https://arxiv.org/abs/2601.12748", "authors": ["Bin Xie", "Bingbing Xu", "Xueyun Tian", "Yilin Chen", "Huawei Shen"], "title": "Towards Robust Process Reward Modeling via Noise-aware Learning", "comment": null, "summary": "Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \\underline{\\textbf{N}}oise-\\underline{\\textbf{A}}ware \\underline{\\textbf{I}}terative \\underline{\\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\\% absolute gain in average F1 over PRMs trained with noisy supervision.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u89e3\u51b3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u566a\u58f0\u76d1\u7763\u95ee\u9898\uff0c\u901a\u8fc7\u53cd\u5c04\u611f\u77e5\u6807\u7b7e\u6821\u6b63\u548c\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u6b65\u9aa4\u7ea7\u6b63\u786e\u6027\u5224\u522b\u80fd\u529b", "motivation": "\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u9700\u8981\u6602\u8d35\u7684\u6b65\u9aa4\u7ea7\u76d1\u7763\uff0c\u800c\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u65b9\u6cd5\u4f1a\u4ea7\u751f\u7b56\u7565\u4f9d\u8d56\u7684\u566a\u58f0\u5956\u52b1\uff0c\u5305\u62ec\u9519\u8bef\u6b65\u9aa4\u7684\u6b63\u5956\u52b1\u548c\u6b63\u786e\u6b65\u9aa4\u7684\u8d1f\u5956\u52b1\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u6807\u6ce8\u9636\u6bb5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u88c1\u5224\uff0c\u901a\u8fc7\u68c0\u6d4b\u53cd\u601d\u548c\u81ea\u6211\u6821\u6b63\u884c\u4e3a\u6765\u6821\u6b63\u6807\u7b7e\uff1b2) \u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u6846\u67b6\uff0c\u8ba9PRM\u57fa\u4e8e\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u9010\u6b65\u7cbe\u70bc\u566a\u58f0\u6807\u7b7e", "result": "\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6b65\u9aa4\u7ea7\u6b63\u786e\u6027\u5224\u522b\u80fd\u529b\uff0c\u5728\u5e73\u5747F1\u5206\u6570\u4e0a\u6bd4\u4f7f\u7528\u566a\u58f0\u76d1\u7763\u8bad\u7ec3\u7684PRM\u63d0\u9ad8\u4e8627%\u7684\u7edd\u5bf9\u589e\u76ca", "conclusion": "\u63d0\u51fa\u7684\u53cd\u5c04\u611f\u77e5\u6807\u7b7e\u6821\u6b63\u548c\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u566a\u58f0\u76d1\u7763\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd"}}
{"id": "2601.12543", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12543", "abs": "https://arxiv.org/abs/2601.12543", "authors": ["Alireza Ghahtarani", "Martin Cousineau", "Amir-massoud Farahmand", "Jorge E. Mendoza"], "title": "Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem", "comment": "41 pages", "summary": "We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montr\u00e9al Area (Qu\u00e9bec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u7535\u52a8\u6c7d\u8f66\u5728\u7ebf\u96c6\u4e2d\u5145\u7535\u8c03\u5ea6\u95ee\u9898\u6e38\u620f\u5316\uff0c\u901a\u8fc7\u56fe\u50cf\u5230\u79fb\u52a8\u6a21\u578b\u548cDAgger\u8bad\u7ec3\uff0c\u5728\u8d1f\u8f7d\u5747\u8861\u548c\u7ecf\u6d4e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u7535\u52a8\u6c7d\u8f66\u52a8\u6001\u5230\u8fbe\u7684\u5b9e\u65f6\u96c6\u4e2d\u5145\u7535\u8c03\u5ea6\u95ee\u9898\uff0c\u5728\u5bb9\u91cf\u9650\u5236\u4e0b\u5e73\u8861\u6574\u4e2a\u89c4\u5212\u5468\u671f\u7684\u8d1f\u8f7d\uff0c\u964d\u4f4e\u7cfb\u7edf\u6210\u672c\u5e76\u63a8\u8fdf\u6602\u8d35\u7684\u7535\u7f51\u5347\u7ea7\u3002", "method": "\u5c06\u95ee\u9898\u6e38\u620f\u5316\u5efa\u6a21\u4e3a\u5728\u65f6\u7a7a\u5bb9\u91cf\u7ea6\u675f\u7f51\u683c\u4e0a\u653e\u7f6e\u5145\u7535\u5757\uff1b\u8bbe\u8ba1\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u7528\u4e13\u5bb6\u6f14\u793a\u8bad\u7ec3\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u5e76\u4f7f\u7528\u6570\u636e\u96c6\u805a\u5408(DAgger)\u6539\u8fdb\u6a21\u578b\u3002", "result": "\u6e38\u620f\u5316\u5b66\u4e60\u663e\u8457\u63d0\u5347\u8d1f\u8f7d\u5747\u8861\u6548\u679c\uff0cDAgger\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u79cdEV\u5230\u8fbe\u6a21\u5f0f\u4e0b\u5747\u4f18\u4e8e\u542f\u53d1\u5f0f\u57fa\u7ebf\u3001\u5411\u91cf\u65b9\u6cd5\u548c\u76d1\u7763\u5b66\u4e60\uff0c\u5728\u8499\u7279\u5229\u5c14\u5b9e\u9645\u6848\u4f8b\u4e2d\u6bcf\u5e74\u53ef\u8282\u7701\u6570\u5343\u4e07\u7f8e\u5143\u7cfb\u7edf\u6210\u672c\u3002", "conclusion": "\u6e38\u620f\u5316\u65b9\u6cd5\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u5e76\u83b7\u5f97\u66f4\u7d27\u7684\u6cdb\u5316\u754c\uff0c\u57fa\u4e8eDAgger\u7684\u56fe\u50cf\u5230\u79fb\u52a8\u6a21\u578b\u5728\u5145\u7535\u8c03\u5ea6\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u7ecf\u6d4e\u6548\u76ca\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.13518", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.13518", "abs": "https://arxiv.org/abs/2601.13518", "authors": ["Jiayi Yuan", "Jonathan N\u00f6ther", "Natasha Jaques", "Goran Radanovi\u0107"], "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming", "comment": "Website: https://yuanjiayiy.github.io/AgenticRed/", "summary": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.", "AI": {"tldr": "AgenticRed\uff1a\u4e00\u79cd\u5229\u7528LLM\u4e0a\u4e0b\u6587\u5b66\u4e60\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u901a\u8fc7\u8fdb\u5316\u9009\u62e9\u65b9\u6cd5\u5728\u7ea2\u961f\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u7ea2\u961f\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6307\u5b9a\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5b58\u5728\u4eba\u7c7b\u504f\u89c1\u4e14\u96be\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u8bbe\u8ba1\u7a7a\u95f4\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3001\u80fd\u81ea\u52a8\u8bbe\u8ba1\u548c\u4f18\u5316\u7ea2\u961f\u7cfb\u7edf\u7684\u65b9\u6cd5", "method": "\u5c06\u7ea2\u961f\u89c6\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u95ee\u9898\u800c\u975e\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u501f\u9274Meta Agent Search\u601d\u60f3\uff0c\u5f00\u53d1\u57fa\u4e8e\u8fdb\u5316\u9009\u62e9\u7684\u65b0\u578b\u7a0b\u5e8f\u6765\u6f14\u5316\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fed\u4ee3\u8bbe\u8ba1\u548c\u6539\u8fdb\u7ea2\u961f\u7cfb\u7edf", "result": "\u5728Llama-2-7B\u4e0a\u8fbe\u523096%\u653b\u51fb\u6210\u529f\u7387\uff08\u63d0\u534736%\uff09\uff0c\u5728Llama-3-8B\u4e0a\u8fbe\u523098%\uff1b\u5728GPT-3.5-Turbo\u548cGPT-4o-mini\u4e0a\u8fbe\u5230100%\u653b\u51fb\u6210\u529f\u7387\uff0c\u5728Claude-Sonnet-3.5\u4e0a\u8fbe\u523060%\uff08\u63d0\u534724%\uff09", "conclusion": "\u81ea\u52a8\u5316\u7cfb\u7edf\u8bbe\u8ba1\u662fAI\u5b89\u5168\u8bc4\u4f30\u7684\u5f3a\u5927\u8303\u5f0f\uff0c\u80fd\u591f\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u6a21\u578b\u6b65\u4f10\uff0cAgenticRed\u5c55\u793a\u4e86\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u81ea\u52a8\u8bbe\u8ba1\u7ea2\u961f\u7cfb\u7edf\u7684\u53ef\u884c\u6027"}}
{"id": "2601.12758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12758", "abs": "https://arxiv.org/abs/2601.12758", "authors": ["Shenyan Zheng", "Jiayou Zhong", "Anudeex Shetty", "Heng Ji", "Preslav Nakov", "Usman Naseem"], "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation", "comment": "WIP", "summary": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.", "AI": {"tldr": "VISPA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u5143\u5316\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u548c\u5185\u90e8\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u5b9e\u73b0\u5bf9\u4ef7\u503c\u8868\u8fbe\u7684\u76f4\u63a5\u63a7\u5236\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u53cd\u6620\u591a\u6837\u7684\u4eba\u7c7b\u89c2\u70b9\u800c\u975e\u5e73\u5747\u504f\u597d\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5173\u952e\u9886\u57df\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u5176\u8f93\u51fa\u53cd\u6620\u591a\u6837\u7684\u4eba\u7c7b\u89c2\u70b9\u800c\u975e\u5e73\u5747\u504f\u597d\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u8003\u8651\u6709\u9650\u7684\u4ef7\u503c\uff0c\u8981\u4e48\u4f9d\u8d56\u63d0\u793a\u7ea7\u5e72\u9884\uff0c\u7f3a\u4e4f\u4ef7\u503c\u63a7\u5236\u548c\u4ee3\u8868\u6027\u3002", "method": "VISPA\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u591a\u5143\u5316\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u548c\u5185\u90e8\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u5b9e\u73b0\u5bf9\u4ef7\u503c\u8868\u8fbe\u7684\u76f4\u63a5\u63a7\u5236\u3002", "result": "\u5728\u6db5\u76d6\u591a\u4e2a\u6a21\u578b\u548c\u8bc4\u4f30\u8bbe\u7f6e\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u4e2d\uff0cVISPA\u5728\u533b\u7597\u4fdd\u5065\u53ca\u5176\u4ed6\u9886\u57df\u7684\u6240\u6709\u591a\u5143\u5316\u5bf9\u9f50\u6a21\u5f0f\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793aVISPA\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7684\u5f15\u5bfc\u521d\u59cb\u5316\u3001\u6a21\u578b\u548c/\u6216\u4ef7\u503c\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u591a\u5143\u5316\u5bf9\u9f50\u53ef\u4ee5\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u673a\u5236\u5b9e\u73b0\uff0c\u4e3a\u6784\u5efa\u670d\u52a1\u4e8e\u6240\u6709\u4eba\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2601.12557", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12557", "abs": "https://arxiv.org/abs/2601.12557", "authors": ["Mark Moussa", "Amber V. Young", "Brianna Isola", "Vasuda Trehan", "Michael D. Himes", "Nicholas Wogan", "Giada Arney"], "title": "Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory", "comment": "8 pages, 4 figures. Submitted and accepted in AAAI-26 (IAAI Emerging Applications track)", "summary": "Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u673a\u5668\u5b66\u4e60\u67b6\u6784\uff08BCNN\u548cSQuAT\uff09\u7528\u4e8e\u4ece\u7cfb\u5916\u884c\u661f\u53cd\u5c04\u5149\u8c31\u9884\u6d4b\u751f\u7269\u6807\u5fd7\u7269\u901a\u91cf\uff0c\u4e3aHWO\u7b49\u65d7\u8230\u4efb\u52a1\u63d0\u4f9b\u76ee\u6807\u7b5b\u9009\u548c\u89c2\u6d4b\u4f18\u5316\u5de5\u5177\u3002", "motivation": "\u672a\u6765\u76f4\u63a5\u6210\u50cf\u65d7\u8230\u4efb\u52a1\uff08\u5982NASA\u7684HWO\uff09\u9762\u4e34\u4e25\u683c\u7684\u65f6\u95f4\u548c\u8d44\u6e90\u9650\u5236\uff0c\u9700\u8981\u9ad8\u6548\u7b5b\u9009\u89c2\u6d4b\u76ee\u6807\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5149\u8c31\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u673a\u5668\u5b66\u4e60\u67b6\u6784\uff1a1\uff09\u8d1d\u53f6\u65af\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08BCNN\uff09\uff0c\u91cf\u5316\u8ba4\u77e5\u548c\u968f\u673a\u4e0d\u786e\u5b9a\u6027\uff1b2\uff09\u5149\u8c31\u67e5\u8be2\u81ea\u9002\u5e94\u53d8\u6362\u5668\uff08SQuAT\uff09\uff0c\u4f7f\u7528\u67e5\u8be2\u9a71\u52a8\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u5e7f\u6cdb\u7684\u7cfb\u5916\u884c\u661f\u6761\u4ef6\u589e\u5f3a\u6570\u636e\u96c6\u4e0a\u90fd\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0cBCNN\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0cSQuAT\u5728\u5149\u8c31\u7279\u5f81\u4e0e\u751f\u7269\u6807\u5fd7\u7269\u5173\u8054\u65b9\u9762\u5177\u6709\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u4e24\u79cd\u65b9\u6cd5\u4e3aHWO\u7b49\u65d7\u8230\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u5de5\u5177\uff0c\u80fd\u591f\u52a0\u901f\u76ee\u6807\u7b5b\u9009\u3001\u4f18\u5316\u89c2\u6d4b\u8ba1\u5212\u5e76\u6700\u5927\u5316\u79d1\u5b66\u56de\u62a5\uff0c\u7279\u522b\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u5149\u8c31\u89e3\u91ca\u65b9\u9762\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.13533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13533", "abs": "https://arxiv.org/abs/2601.13533", "authors": ["Changshuo Zhang"], "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models", "comment": null, "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.", "AI": {"tldr": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff0c\u52a8\u6001\u9002\u5e94\u5217\u8868\u751f\u6210\u4e2d\u7684\u71b5\u53d8\u5316\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u5217\u8868\u751f\u6210\u8fc7\u7a0b\u4e2d\u6a21\u578b\u96be\u5ea6\u7684\u52a8\u6001\u71b5\u53d8\u5316\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u590d\u6742\u504f\u597d\u3002\u53d7\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u542f\u53d1\uff0c\u9700\u8981\u5f15\u5165\u63a8\u7406\u673a\u5236\u6765\u964d\u4f4e\u51b3\u7b56\u71b5\u3002", "method": "\u63d0\u51fa\u71b5\u5f15\u5bfc\u6f5c\u5728\u63a8\u7406(EGLR)\u63a8\u8350\u6a21\u578b\uff1a1) \u629b\u5f03\"\u5148\u63a8\u7406\u540e\u63a8\u8350\"\u8303\u5f0f\uff0c\u5b9e\u73b0\"\u8fb9\u63a8\u7406\u8fb9\u63a8\u8350\"\uff1b2) \u4f7f\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u4ee4\u724c\u548c\u52a8\u6001\u6e29\u5ea6\u8c03\u6574\u5b9e\u73b0\u71b5\u5f15\u5bfc\u53d8\u957f\u63a8\u7406\uff1b3) \u8f7b\u91cf\u7ea7\u96c6\u6210\u8bbe\u8ba1\uff0c\u65e0\u9700\u590d\u6742\u72ec\u7acb\u6a21\u5757\u6216\u540e\u5904\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u52bf\u5728\u4e8e\u80fd\u4e0e\u73b0\u6709\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u6a21\u578b\u517c\u5bb9\u5e76\u63d0\u5347\u5176\u6027\u80fd\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u5c55\u793a\u4e86\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u548c\u7814\u7a76\u6f5c\u529b\u3002", "conclusion": "EGLR\u6a21\u578b\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u6f5c\u5728\u63a8\u7406\u673a\u5236\uff0c\u5728\u751f\u6210\u5f0f\u91cd\u6392\u5e8f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u4e3a\u52a8\u6001\u71b5\u53d8\u5316\u7684\u5217\u8868\u751f\u6210\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12771", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12771", "abs": "https://arxiv.org/abs/2601.12771", "authors": ["Keito Inoshita"], "title": "Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory", "comment": null, "summary": "Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.", "AI": {"tldr": "\u63d0\u51faLAMA\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u5173\u8054\u8bb0\u5fc6\u80fd\u529b\u8fdb\u884c\u56fd\u7c4d\u9884\u6d4b\uff0c\u901a\u8fc7\u56de\u5fc6\u540c\u540d\u540d\u4eba\u95f4\u63a5\u63a8\u7406\uff0c\u53cc\u667a\u80fd\u4f53\u67b6\u6784\u572899\u56fd\u4efb\u52a1\u4e0a\u8fbe\u523081.7%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "LLM\u62e5\u6709\u4e30\u5bcc\u4e16\u754c\u77e5\u8bc6\u4f46\u7f3a\u4e4f\u6709\u6548\u63d0\u53d6\u65b9\u6cd5\u3002\u56fd\u7c4d\u9884\u6d4b\u4efb\u52a1\u9700\u8981\u6587\u5316\u5386\u53f2\u80cc\u666f\u77e5\u8bc6\uff0c\u4f20\u7edf\u76f4\u63a5\u63a8\u7406\u65b9\u6cd5\u5728\u5e94\u7528\u62bd\u8c61\u8bed\u8a00\u89c4\u5219\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51faLAMA\u6846\u67b6\uff0c\u5c06LLM\u4e16\u754c\u77e5\u8bc6\u4f5c\u4e3a\u5173\u8054\u8bb0\u5fc6\u3002\u4e0d\u76f4\u63a5\u63a8\u7406\u56fd\u7c4d\uff0c\u800c\u662f\u56de\u5fc6\u540c\u540d\u540d\u4eba\u5e76\u805a\u5408\u5176\u56fd\u7c4d\u3002\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u4eba\u7269\u667a\u80fd\u4f53\uff08\u719f\u6089\u540d\u4eba\uff09\u548c\u5a92\u4f53\u667a\u80fd\u4f53\uff08\u719f\u6089\u865a\u6784\u89d2\u8272\uff09\uff0c\u5e76\u884c\u56de\u5fc6\u540d\u4eba\uff0c\u901a\u8fc7\u6295\u7968\u751f\u6210Top-1\u9884\u6d4b\uff0c\u901a\u8fc7\u6761\u4ef6\u8865\u5168\u751f\u6210Top-K\u9884\u6d4b\u3002", "result": "\u572899\u56fd\u56fd\u7c4d\u9884\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u52300.817\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfLLM\u63d0\u793a\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\u5b9e\u9a8c\u53d1\u73b0\uff1aLLM\u5728\u56de\u5fc6\u5177\u4f53\u4f8b\u5b50\u65b9\u9762\u6bd4\u62bd\u8c61\u63a8\u7406\u66f4\u53ef\u9760\uff1b\u57fa\u4e8e\u56de\u5fc6\u7684\u65b9\u6cd5\u5bf9\u4f4e\u9891\u56fd\u7c4d\u5177\u6709\u9c81\u68d2\u6027\uff1b\u53cc\u667a\u80fd\u4f53\u67b6\u6784\u5177\u6709\u4e92\u8865\u534f\u540c\u6548\u5e94\u3002", "conclusion": "LAMA\u5c55\u793a\u4e86\u901a\u8fc7\u68c0\u7d22\u548c\u805a\u5408LLM\u77e5\u8bc6\u800c\u975e\u63d0\u793a\u63a8\u7406\u7684\u65b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5229\u7528LLM\u4e16\u754c\u77e5\u8bc6\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.12598", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12598", "abs": "https://arxiv.org/abs/2601.12598", "authors": ["Younes Bouhadjar", "Maxime Fabre", "Felix Schmidt", "Emre Neftci"], "title": "Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization", "comment": "11 pages, 4 figures and 4 tables", "summary": "Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SelectivBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u7ebf\u6027\u5faa\u73af\u6a21\u578b\u9009\u62e9\u6027\u7684\u8f7b\u91cf\u7ea7\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u7684\u5173\u952e\u67b6\u6784\u7279\u5f81\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u7ebf\u6027\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3aTransformer\u6ce8\u610f\u529b\u673a\u5236\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u867d\u7136\u8bad\u7ec3\u5e76\u884c\u5316\u7a0b\u5ea6\u9ad8\u4e14\u63a8\u7406\u65f6\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u6052\u5b9a\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8981\u4e48\u8fc7\u4e8e\u7b80\u5355\u65e0\u6cd5\u63ed\u793a\u5b9e\u8d28\u6027\u5dee\u5f02\uff0c\u8981\u4e48\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\u96be\u4ee5\u5b9e\u9a8c\u3002\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u76f4\u63a5\u6bd4\u8f83\u9650\u5236\u4e86\u8fd9\u4e9b\u6a21\u578b\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u7ebf\u6027\u5faa\u73af\u6a21\u578b\u7684\u7cbe\u7ec6\u5316\u5206\u7c7b\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86SelectivBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u3002\u8be5\u57fa\u51c6\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u8bed\u6cd5\u751f\u6210\u53ef\u8c03\u6574\u590d\u6742\u5ea6\u7684\u5e8f\u5217\uff0c\u5305\u542b\u6545\u610f\u8fdd\u53cd\u8f6c\u6362\u89c4\u5219\u7684\u4e0d\u89c4\u5219\u95f4\u9694\uff0c\u4e13\u95e8\u8bc4\u4f30\u4e2d\u5c0f\u89c4\u6a21\u5e8f\u5217\u6a21\u578b\u7684\u9009\u62e9\u6027\u80fd\u529b\uff08\u5373\u5173\u6ce8\u76f8\u5173\u8f93\u5165\u540c\u65f6\u5ffd\u7565\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u5e72\u6270\u9879\u7684\u80fd\u529b\uff09\u3002", "result": "\u5728SelectivBench\u4e0a\u8bc4\u4f30\u7ebf\u6027\u5faa\u73af\u6a21\u578b\u663e\u793a\uff0c\u6027\u80fd\u6a21\u5f0f\u4e0e\u5927\u89c4\u6a21\u8bed\u8a00\u4efb\u52a1\u7684\u7ed3\u679c\u4e00\u81f4\u3002\u5206\u6790\u63ed\u793a\u4e86\u5173\u952e\u67b6\u6784\u7279\u5f81\u7684\u4f5c\u7528\uff1a\u95e8\u63a7\u548c\u5feb\u901f\u9057\u5fd8\u673a\u5236\u4fc3\u8fdb\u53ec\u56de\uff1b\u72b6\u6001\u5185\u901a\u9053\u6df7\u5408\u5bf9\u9009\u62e9\u6027\u4e0d\u5fc5\u8981\u4f46\u5bf9\u6cdb\u5316\u5173\u952e\uff1bsoftmax\u6ce8\u610f\u529b\u56e0\u5176\u5185\u5b58\u5bb9\u91cf\u968f\u5e8f\u5217\u957f\u5ea6\u7f29\u653e\u800c\u4fdd\u6301\u4f18\u52bf\u3002", "conclusion": "SelectivBench\u4e3a\u7ebf\u6027\u5faa\u73af\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u9488\u5bf9\u6027\u7684\u9ad8\u6548\u63a2\u7d22\u5de5\u5177\uff0c\u5e76\u4e3a\u7814\u7a76\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u53d7\u63a7\u73af\u5883\u3002\u8be5\u57fa\u51c6\u6709\u52a9\u4e8e\u6f84\u6e05\u4e0d\u540c\u67b6\u6784\u7279\u5f81\u7684\u4f5c\u7528\uff0c\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u6a21\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2601.13545", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13545", "abs": "https://arxiv.org/abs/2601.13545", "authors": ["Shirin Shahabi", "Spencer Graham", "Haruna Isah"], "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning", "comment": "16 pages, 6 figures, 2 tables", "summary": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com", "AI": {"tldr": "TruthTensor\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u8303\u5f0f\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u4e16\u754c\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u4e0d\u4ec5\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u8bc4\u4f30\u6821\u51c6\u5ea6\u3001\u6f02\u79fb\u548c\u98ce\u9669\u654f\u611f\u6027\u7b49\u591a\u7ef4\u5ea6\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u7684\u8bc4\u4f30\u9762\u4e34\u6839\u672c\u6027\u6311\u6218\uff1a\u9759\u6001\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5206\u5e03\u504f\u79fb\uff0c\u4ee5\u53ca\u5b64\u7acb\u4efb\u52a1\u51c6\u786e\u6027\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLMs\u5728\u73b0\u5b9e\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faTruthTensor\u6846\u67b6\uff0c\u57fa\u4e8e\u524d\u77bb\u6027\u3001\u65e0\u6c61\u67d3\u7684\u4efb\u52a1\uff0c\u5c06\u8bc4\u4f30\u951a\u5b9a\u5728\u5b9e\u65f6\u9884\u6d4b\u5e02\u573a\uff0c\u7ed3\u5408\u6982\u7387\u8bc4\u5206\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u6574\u4f53\u89c6\u56fe\u3002\u8be5\u6846\u67b6\u5305\u542b\u6f02\u79fb\u4e2d\u5fc3\u8bca\u65ad\u3001\u663e\u5f0f\u9c81\u68d2\u6027\u68c0\u67e5\u3001\u4eba\u7c7b\u4e0e\u81ea\u52a8\u5316\u8bc4\u4f30\u89d2\u8272\u5212\u5206\u3001\u6807\u6ce8\u534f\u8bae\u548c\u7edf\u8ba1\u6d4b\u8bd5\u7a0b\u5e8f\u3002", "result": "\u5728500\u591a\u4e2a\u771f\u5b9e\u5e02\u573a\uff08\u653f\u6cbb\u3001\u7ecf\u6d4e\u3001\u6587\u5316\u3001\u6280\u672f\uff09\u7684\u5b9e\u9a8c\u4e2d\uff0cTruthTensor\u663e\u793a\u5177\u6709\u76f8\u4f3c\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6a21\u578b\u5728\u6821\u51c6\u5ea6\u3001\u6f02\u79fb\u548c\u98ce\u9669\u654f\u611f\u6027\u65b9\u9762\u53ef\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f3a\u8c03\u9700\u8981\u4ece\u591a\u4e2a\u7ef4\u5ea6\uff08\u51c6\u786e\u6027\u3001\u6821\u51c6\u5ea6\u3001\u53d9\u4e8b\u7a33\u5b9a\u6027\u3001\u6210\u672c\u548c\u8d44\u6e90\u6548\u7387\uff09\u8bc4\u4f30\u6a21\u578b\u3002", "conclusion": "TruthTensor\u5c06\u73b0\u4ee3\u8bc4\u4f30\u6700\u4f73\u5b9e\u8df5\u64cd\u4f5c\u5316\uff0c\u5305\u62ec\u6e05\u6670\u7684\u5047\u8bbe\u6846\u67b6\u3001\u8c28\u614e\u7684\u6307\u6807\u9009\u62e9\u3001\u900f\u660e\u7684\u8ba1\u7b97/\u6210\u672c\u62a5\u544a\u3001\u4eba\u7c7b\u5728\u73af\u9a8c\u8bc1\u548c\u5f00\u653e\u7684\u7248\u672c\u5316\u8bc4\u4f30\u5408\u7ea6\uff0c\u4e3aLLMs\u5728\u771f\u5b9e\u4e16\u754c\u51b3\u7b56\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u8fa9\u62a4\u7684\u8bc4\u4f30\u3002\u6846\u67b6\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2601.12812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12812", "abs": "https://arxiv.org/abs/2601.12812", "authors": ["Sushant Kumar Ray", "Gautam Siddharth Kashyap", "Sahil Tripathi", "Nipun Joshi", "Vijay Govindarajan", "Rafiq Ali", "Jiechao Gao", "Usman Naseem"], "title": "Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?", "comment": "Accepted at EACL 2026 (Industry Track)", "summary": "Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.", "AI": {"tldr": "MEDASSESS-X\u662f\u4e00\u4e2a\u90e8\u7f72\u5bfc\u5411\u7684\u4e34\u5e8a\u95ee\u7b54\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u5bf9\u9f50\u800c\u975e\u76d1\u7763\u5fae\u8c03\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5f15\u5bfc\u5411\u91cf\u6307\u5bfc\u6a21\u578b\u6fc0\u6d3b\uff0c\u89e3\u51b3\"\u4e13\u4e1a\u5316\u8c2c\u8bef\"\u2014\u2014\u5373\u8ba4\u4e3a\u4e13\u4e1a\u533b\u7597LLM\u5728\u4e34\u5e8a\u95ee\u7b54\u4e2d\u5fc5\u7136\u66f4\u4f18\u7684\u9519\u8bef\u5047\u8bbe\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u95ee\u7b54\u7cfb\u7edf\u8fc7\u5ea6\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u7684\u5fae\u8c03\uff0c\u5b58\u5728\u4e13\u4e1a\u5316\u533b\u7597LLM\uff08\u5982BioBERT\u3001BioGPT\uff09\u8986\u76d6\u8303\u56f4\u7a84\u3001\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6027\u6709\u9650\u7b49\u5b9e\u9645\u95ee\u9898\u3002\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5f3a\u5316\u4e86\"\u4e13\u4e1a\u5316\u8c2c\u8bef\"\u2014\u2014\u5373\u8ba4\u4e3a\u4e13\u4e1a\u533b\u7597LLM\u5728\u4e34\u5e8a\u95ee\u7b54\u4e2d\u5fc5\u7136\u66f4\u4f18\u7684\u9519\u8bef\u5047\u8bbe\u3002", "method": "\u63d0\u51faMEDASSESS-X\u6846\u67b6\uff0c\u91c7\u7528\u63a8\u7406\u65f6\u5bf9\u9f50\u800c\u975e\u76d1\u7763\u5fae\u8c03\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5f15\u5bfc\u5411\u91cf\u5728\u63a8\u7406\u65f6\u6307\u5bfc\u6a21\u578b\u6fc0\u6d3b\uff0c\u4f7f\u5176\u671d\u5411\u533b\u5b66\u4e00\u81f4\u6027\u7684\u63a8\u7406\uff0c\u65e0\u9700\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u6216\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u7684\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "MEDASSESS-X\u5728\u6240\u6709LLM\u5bb6\u65cf\u4e2d\u90fd\u5e26\u6765\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff1a\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u5347+6%\uff0c\u4e8b\u5b9e\u4e00\u81f4\u6027\u63d0\u5347+7%\uff0c\u5b89\u5168\u9519\u8bef\u7387\u964d\u4f4e\u9ad8\u8fbe50%\u3002\u8be5\u6846\u67b6\u7a33\u5b9a\u4e86\u901a\u7528\u548c\u4e13\u4e1a\u533b\u7597LLM\u5728\u4e34\u5e8a\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "MEDASSESS-X\u901a\u8fc7\u63a8\u7406\u65f6\u5bf9\u9f50\u6709\u6548\u89e3\u51b3\u4e86\"\u4e13\u4e1a\u5316\u8c2c\u8bef\"\uff0c\u8bc1\u660e\u65e0\u9700\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u83b7\u5f97\u7a33\u5b9a\u4e14\u9ad8\u6027\u80fd\u7684\u4e34\u5e8a\u95ee\u7b54\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4e3a\u533b\u7597AI\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u3001\u6210\u672c\u6548\u76ca\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12604", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12604", "abs": "https://arxiv.org/abs/2601.12604", "authors": ["Safwan Labbi", "Daniil Tiapkin", "Paul Mangold", "Eric Moulines"], "title": "Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization", "comment": null, "summary": "Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49f-softargmax\u7684\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\u66ff\u4ee3softmax\uff0c\u7ed3\u5408f-\u6563\u5ea6\u6b63\u5219\u5316\uff0c\u65e0\u9700\u9884\u6761\u4ef6\u5373\u53ef\u83b7\u5f97\u975e\u6e10\u8fd1\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u663e\u8457\u6539\u5584\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5bf9\u7b56\u7565\u53c2\u6570\u5316\u9009\u62e9\u9ad8\u5ea6\u654f\u611f\uff0csoftmax\u53c2\u6570\u5316\u4f1a\u5bfc\u81f4\u75c5\u6001\u4f18\u5316\u666f\u89c2\u548c\u6307\u6570\u7ea7\u6162\u6536\u655b\u3002\u9884\u6761\u4ef6\u65b9\u6cd5\u8ba1\u7b97\u6602\u8d35\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u7528\u5e7f\u4e49f-softargmax\u66ff\u4ee3softmax\u53c2\u6570\u5316\uff0c\u7ed3\u5408\u5bf9\u5e94f-\u6563\u5ea6\u7684\u6b63\u5219\u5316\u5668\uff0c\u6539\u5584\u4f18\u5316\u666f\u89c2\u5e76\u786e\u4fdd\u6b63\u5219\u5316\u76ee\u6807\u6ee1\u8db3Polyak-Lojasiewicz\u4e0d\u7b49\u5f0f\u3002", "result": "\u9996\u6b21\u4e3a\u6709\u9650MDP\u7684\u968f\u673a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5efa\u7acb\u4e86\u65e0\u9700\u9884\u6761\u4ef6\u7684\u663e\u5f0f\u975e\u6e10\u8fd1\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\u3002Tsallis\u6563\u5ea6\u7684f-PG\u5b9e\u73b0\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6\uff0c\u800c\u6807\u51c6softmax\u9700\u8981\u6307\u6570\u590d\u6742\u5ea6\u3002", "conclusion": "f-softargmax\u53c2\u6570\u5316\u7ed3\u5408f-\u6563\u5ea6\u6b63\u5219\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u6536\u655b\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2601.13546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13546", "abs": "https://arxiv.org/abs/2601.13546", "authors": ["Hui Sun", "Chang Xu", "Haonan Xie", "Hao Li", "Yuhao Huang", "Chuheng Zhang", "Ming Jin", "Xiaoguang Liu", "Gang Wang", "Jiang Bian"], "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution", "comment": null, "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.", "AI": {"tldr": "\u63d0\u51faTSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\u3001TSEData-20K\u6570\u636e\u96c6\u3001ChatAD\u7cfb\u5217\u6a21\u578b\u3001TKTO\u4f18\u5316\u65b9\u6cd5\u548cLLADBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u6b20\u7f3a\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb", "method": "1) TSEvol\u591a\u667a\u80fd\u4f53\u65f6\u95f4\u5e8f\u5217\u6f14\u5316\u7b97\u6cd5\uff1b2) TSEData-20K\u6570\u636e\u96c6\u548cChatAD\u7cfb\u5217\u6a21\u578b\uff1b3) TKTO\u4f18\u5316\u589e\u5f3a\u8de8\u4efb\u52a1\u6cdb\u5316\uff1b4) LLADBench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6", "result": "ChatAD\u6a21\u578b\u5728\u51c6\u786e\u7387\u63d0\u534734.50%\u3001F1\u63d0\u534734.71%\u3001\u8bef\u62a5\u7387\u964d\u4f4e37.42%\uff1bTKTO\u4f18\u5316\u540e\u5728\u5206\u7c7b\u3001\u9884\u6d4b\u3001\u586b\u8865\u7b49\u4efb\u52a1\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u7684\u63a8\u7406\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b", "conclusion": "\u63d0\u51fa\u7684\u7efc\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLM\u9a71\u52a8\u5f02\u5e38\u68c0\u6d4b\u7684\u63a8\u7406\u80fd\u529b\u3001\u5bf9\u8bdd\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.12815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12815", "abs": "https://arxiv.org/abs/2601.12815", "authors": ["Zhaolu Kang", "Junhao Gong", "Qingxi Chen", "Hao Zhang", "Jiaxin Liu", "Rong Fu", "Zhiyuan Feng", "Yuan Wang", "Simon Fong", "Kaiyue Zhou"], "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction", "comment": null, "summary": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.", "AI": {"tldr": "\u63d0\u51faJurisMMA\u6846\u67b6\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u901a\u8fc7\u5206\u89e3\u5ba1\u5224\u4efb\u52a1\u3001\u6807\u51c6\u5316\u6d41\u7a0b\u5e76\u7ec4\u7ec7\u4e3a\u4e0d\u540c\u9636\u6bb5\uff0c\u540c\u65f6\u6784\u5efa\u5305\u542b10\u4e07+\u4e2d\u56fd\u53f8\u6cd5\u8bb0\u5f55\u7684JurisMM\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5728LawBench\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u5206\u6790\u6216\u57fa\u4e8e\u89d2\u8272\u7684\u6a21\u62df\uff0c\u9762\u4e34\u591a\u91cd\u6307\u63a7\u3001\u591a\u6837\u8bc1\u636e\u548c\u7f3a\u4e4f\u9002\u5e94\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u5904\u7406\u590d\u6742\u6cd5\u5f8b\u6848\u4ef6\u3002", "method": "\u63d0\u51faJurisMMA\u6846\u67b6\uff0c\u5c06\u5ba1\u5224\u4efb\u52a1\u5206\u89e3\u3001\u6d41\u7a0b\u6807\u51c6\u5316\u5e76\u7ec4\u7ec7\u4e3a\u4e0d\u540c\u9636\u6bb5\uff1b\u6784\u5efa\u5305\u542b\u6587\u672c\u548c\u591a\u6a21\u6001\u89c6\u9891-\u6587\u672c\u6570\u636e\u7684JurisMM\u5927\u578b\u6570\u636e\u96c6\uff08\u8d85\u8fc710\u4e07\u6761\u4e2d\u56fd\u53f8\u6cd5\u8bb0\u5f55\uff09\u3002", "result": "\u5728JurisMM\u6570\u636e\u96c6\u548cLawBench\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\uff0c\u8fd8\u80fd\u4e3a\u66f4\u5e7f\u6cdb\u7684\u6cd5\u5f8b\u5e94\u7528\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "JurisMMA\u6846\u67b6\u4e3a\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u540c\u65f6\u6784\u5efa\u7684JurisMM\u6570\u636e\u96c6\u4e3a\u672a\u6765\u6cd5\u5f8b\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u6cd5\u5f8b\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.13558", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13558", "abs": "https://arxiv.org/abs/2601.13558", "authors": ["Mehrab Beikzadeh", "Chenglin Hong", "Cory J Cascalheira", "Callisto Boka", "Majid Sarrafzadeh", "Ian W Holloway"], "title": "Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis", "comment": null, "summary": "Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.", "AI": {"tldr": "\u5229\u7528\u793e\u4ea4\u5a92\u4f53\u548c\u7ea6\u4f1a\u5e94\u7528\u6587\u672c\u6570\u636e\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u7537\u7537\u6027\u884c\u4e3a\u8005\u7684\u6027\u98ce\u9669\u884c\u4e3a\u3001\u996e\u9152\u884c\u4e3a\u548cPrEP\u4f7f\u7528\u60c5\u51b5\uff0c\u5c55\u793a\u4e86\u6587\u672c\u6570\u636e\u5728\u516c\u5171\u536b\u751f\u5e72\u9884\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7537\u7537\u6027\u884c\u4e3a\u8005\uff08MSM\uff09\u9762\u4e34\u6027\u4f20\u64ad\u611f\u67d3\u548c\u6709\u5bb3\u996e\u9152\u7684\u9ad8\u98ce\u9669\uff0c\u793e\u4ea4\u5a92\u4f53\u548c\u7ea6\u4f1a\u5e94\u7528\u6587\u672c\u6570\u636e\u53ef\u80fd\u4e3a\u4e2a\u6027\u5316\u516c\u5171\u536b\u751f\u5e72\u9884\u63d0\u4f9b\u65b0\u673a\u4f1a\uff0c\u901a\u8fc7\u81ea\u52a8\u8bc6\u522b\u98ce\u9669\u548c\u4fdd\u62a4\u884c\u4e3a\u3002", "method": "\u6536\u96c6\u53c2\u4e0e\u8005\u540c\u610f\u7684\u6587\u672c\u6570\u636e\uff0c\u4f7f\u7528ChatGPT\u5d4c\u5165\u3001BERT\u5d4c\u5165\u3001LIWC\u548c\u57fa\u4e8e\u8bcd\u5178\u7684\u98ce\u9669\u672f\u8bed\u65b9\u6cd5\u63d0\u53d6\u7279\u5f81\uff0c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6027\u98ce\u9669\u884c\u4e3a\u3001\u996e\u9152\u884c\u4e3a\u548cPrEP\u4f7f\u7528\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u6bcf\u6708\u9157\u9152\u548c\u8d85\u8fc75\u4e2a\u6027\u4f34\u4fa3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff08F1\u5206\u65700.78\uff09\uff0c\u5728\u9884\u6d4bPrEP\u4f7f\u7528\u548c\u91cd\u5ea6\u996e\u9152\u65b9\u9762\u8868\u73b0\u4e2d\u7b49\uff08F1\u5206\u65700.64\u548c0.63\uff09\u3002", "conclusion": "\u793e\u4ea4\u5a92\u4f53\u548c\u7ea6\u4f1a\u5e94\u7528\u6587\u672c\u6570\u636e\u80fd\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u98ce\u9669\u548c\u4fdd\u62a4\u884c\u4e3a\u6d1e\u5bdf\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u6709\u6f5c\u529b\u652f\u6301\u9488\u5bf9MSM\u7684\u53ef\u6269\u5c55\u3001\u4e2a\u6027\u5316\u516c\u5171\u536b\u751f\u5e72\u9884\u3002"}}
{"id": "2601.12844", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12844", "abs": "https://arxiv.org/abs/2601.12844", "authors": ["Julie Ran\u00e7on", "Jean-Fran\u00e7ois Cerisier", "Emilie Remond", "Aur\u00e9lien Nguyen", "Andrew Peterson", "Ladjel Bellatreche"], "title": "Rapport du Projet de Recherche TRAIMA", "comment": "in French language", "summary": "The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{\u00e9}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{\u00e9}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{\u00e9}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.", "AI": {"tldr": "TRAIMA\u9879\u76ee\u63a2\u7d22\u5229\u7528\u673a\u5668\u5b66\u4e60\u81ea\u52a8\u5904\u7406\u6559\u80b2\u573a\u666f\u4e2d\u7684\u591a\u6a21\u6001\u4ea4\u4e92\uff0c\u89e3\u51b3\u4eba\u5de5\u5206\u6790\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\u7684\u95ee\u9898\uff0c\u91cd\u70b9\u7814\u7a76\u8bfe\u5802\u89e3\u91ca\u4e0e\u534f\u4f5c\u5e8f\u5217\u7684\u591a\u6a21\u6001\u7279\u5f81\u3002", "motivation": "\u5f53\u524d\u6559\u80b2\u4e92\u52a8\u7814\u7a76\u4e2d\uff0c\u8a00\u8bed\u3001\u526f\u8a00\u8bed\u548c\u975e\u8a00\u8bed\u6570\u636e\u7684\u5206\u6790\u5b8c\u5168\u4f9d\u8d56\u4eba\u5de5\uff0c\u6781\u5176\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\u3002TRAIMA\u9879\u76ee\u65e8\u5728\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u5982\u4f55\u5e2e\u52a9\u5206\u7c7b\u548c\u5f52\u7c7b\u8fd9\u7c7b\u591a\u6a21\u6001\u4ea4\u4e92\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u65b9\u6cd5\u8bba\u74f6\u9888\u3002", "method": "\u9879\u76ee\u805a\u7126\u8bfe\u5802\u89e3\u91ca\u4e0e\u534f\u4f5c\u5e8f\u5217\uff08\u6cd5\u8bed\u4f5c\u4e3a\u5916\u8bed\u548c\u6bcd\u8bed\u60c5\u5883\uff09\uff0c\u5c06\u5176\u89c6\u4e3a\u591a\u6a21\u6001\u73b0\u8c61\uff08\u8bed\u8a00\u3001\u97f5\u5f8b\u3001\u624b\u52bf\u3001\u59ff\u52bf\u3001\u6ce8\u89c6\u3001\u7a7a\u95f4\u4f4d\u7f6e\uff09\u3002\u91c7\u7528\u8bdd\u8bed\u5206\u6790\u548c\u4e92\u52a8\u8bed\u8a00\u5b66\u7406\u8bba\uff0c\u5c06\u89e3\u91ca\u8bdd\u8bed\u5b9a\u4e49\u4e3a\u4e09\u90e8\u7ed3\u6784\uff08\u5f00\u573a\u3001\u89e3\u91ca\u6838\u5fc3\u3001\u6536\u5c3e\uff09\u3002\u5efa\u7acb\u8be6\u7ec6\u7684\u8f6c\u5f55\u89c4\u8303\uff0c\u6bd4\u8f83\u73b0\u6709\u8f6c\u5f55\u4f53\u7cfb\uff08ICOR\u3001Mondada\u7b49\uff09\uff0c\u4f7f\u7528INTER-EXPLIC\u548cEXPLIC-LEXIC\u8bed\u6599\u5e93\uff08\u7ea630\u5c0f\u65f6\u8bfe\u5802\u4e92\u52a8\uff09\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8\u6559\u5e08\u624b\u52bf\u548c\u97f5\u5f8b\u7279\u5f81\u7684\u529f\u80fd\u4f5c\u7528\u3002", "result": "\u9879\u76ee\u5c55\u793a\u4e86\u8f6c\u5f55\u5b9e\u8df5\u7684\u4e0d\u53ef\u907f\u514d\u7684\u53d8\u5f02\u6027\u548c\u89e3\u91ca\u6027\u7ef4\u5ea6\uff0c\u53d6\u51b3\u4e8e\u7406\u8bba\u7acb\u573a\u548c\u5206\u6790\u76ee\u6807\u3002\u5efa\u7acb\u4e86\u4e0e\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u517c\u5bb9\u7684\u8f6c\u5f55\u89c4\u8303\u3001\u6807\u6ce8\u7c7b\u522b\u548c\u5206\u6790\u5355\u5143\uff0c\u5f3a\u8c03\u4e86\u7406\u8bba\u660e\u786e\u6027\u548c\u7814\u7a76\u8005\u53cd\u601d\u6027\u7684\u5fc5\u8981\u6027\u3002Techn\u00e9LAB\u5e73\u53f0\u4f5c\u4e3a\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u548c\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u53d1\u6325\u4e86\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "TRAIMA\u5e76\u672a\u5f00\u53d1\u5b8c\u5168\u53ef\u64cd\u4f5c\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u800c\u662f\u4e3a\u591a\u6a21\u6001\u6559\u5b66\u4e92\u52a8\u7684\u81ea\u52a8\u5904\u7406\u5efa\u7acb\u4e86\u4e25\u8c28\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\u3002\u9879\u76ee\u4e3a\u672a\u6765\u6559\u5b66\u6cd5\u3001\u8bdd\u8bed\u5206\u6790\u3001\u591a\u6a21\u6001\u548c\u4eba\u5de5\u667a\u80fd\u6559\u80b2\u4ea4\u53c9\u9886\u57df\u7684\u8de8\u5b66\u79d1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.12624", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12624", "abs": "https://arxiv.org/abs/2601.12624", "authors": ["Shiqi Wang", "Mahdi Khosravy", "Neeraj Gupta", "Olaf Witkowski"], "title": "Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach", "comment": null, "summary": "Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6d6e\u70b9\u7f16\u7801\u3001\u60e9\u7f5a\u9a71\u52a8\u7684\u5355\u76ee\u6807\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u901a\u7528\u5bf9\u6297\u6270\u52a8\uff0c\u5728\u964d\u4f4e\u53ef\u89c1\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u901a\u7528\u5bf9\u6297\u6270\u52a8\u80fd\u591f\u7528\u5355\u4e00\u566a\u58f0\u6a21\u5f0f\u7834\u574f\u591a\u4e2a\u8f93\u5165\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u8fdb\u5316\u7b97\u6cd5\u56e0\u5176\u5728\u975e\u51f8\u3001\u65e0\u68af\u5ea6\u7a7a\u95f4\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\uff0c\u4e3a\u751f\u6210\u6b64\u7c7b\u6270\u52a8\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6d6e\u70b9\u7f16\u7801\u3001\u60e9\u7f5a\u9a71\u52a8\u7684\u5355\u76ee\u6807\u8fdb\u5316\u6846\u67b6\uff0c\u5229\u7528\u4e0e\u5f53\u4ee3\u6df1\u5ea6\u5b66\u4e60\u89c4\u6a21\u5bf9\u9f50\u7684\u8fde\u7eed\u57fa\u56e0\u8868\u793a\uff0c\u7ed3\u5408\u52a8\u6001\u8fdb\u5316\u7b97\u5b50\u4e0e\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u91c7\u7528\u6a21\u5757\u5316PyTorch\u5b9e\u73b0\uff0c\u901a\u8fc7\u8de8\u6a21\u578b\u6d4b\u8bd5\u548c\u5468\u671f\u6027\u6279\u6b21\u5207\u6362\u786e\u4fdd\u6270\u52a8\u901a\u7528\u6027\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u8fdb\u5316\u65b9\u6cd5\uff0c\u80fd\u4ea7\u751f\u66f4\u5c0f\u8303\u6570\u3001\u66f4\u9ad8\u8bef\u5206\u7c7b\u6548\u679c\u3001\u66f4\u5feb\u6536\u655b\u7684\u6270\u52a8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u901a\u7528\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u5c55\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002"}}
{"id": "2601.13559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13559", "abs": "https://arxiv.org/abs/2601.13559", "authors": ["Sun Hui", "Ding Yanfeng", "Huidong Ma", "Chang Xu", "Keyan Jin", "Lizheng Zu", "Cheng Zhong", "xiaoguang Liu", "Gang Wang", "Wentong Cai"], "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent", "comment": null, "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.", "AI": {"tldr": "AgentGC\uff1a\u9996\u4e2a\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fdb\u5316\u5f0f\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u5668\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9e\u73b0\u7528\u6237\u53cb\u597d\u3001\u81ea\u9002\u5e94\u7684\u9ad8\u6548\u538b\u7f29\uff0c\u5728\u538b\u7f29\u6bd4\u548c\u541e\u5410\u91cf\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e0d\u53ef\u8fdb\u5316\u3001\u4f4e\u7ea7\u538b\u7f29\u5efa\u6a21\u3001\u9002\u5e94\u6027\u6709\u9650\u548c\u7528\u6237\u754c\u9762\u4e0d\u53cb\u597d\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u3001\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAgentGC\u4e09\u5c42\u67b6\u6784\uff1a1)\u7528\u6237\u5c42\u901a\u8fc7Leader\u667a\u80fd\u4f53\u7ed3\u5408LLM\u63d0\u4f9b\u53cb\u597d\u754c\u9762\uff1b2)\u8ba4\u77e5\u5c42\u7531Leader\u9a71\u52a8\uff0c\u6574\u5408LLM\u5b9e\u73b0\u7b97\u6cd5-\u6570\u636e\u96c6-\u7cfb\u7edf\u8054\u5408\u4f18\u5316\uff1b3)\u538b\u7f29\u5c42\u7531Worker\u667a\u80fd\u4f53\u6267\u884c\u57fa\u4e8e\u591a\u77e5\u8bc6\u5b66\u4e60\u7684\u81ea\u52a8\u538b\u7f29\u6846\u67b6\u3002\u652f\u6301\u4e09\u79cd\u6a21\u5f0f\uff1aCP\uff08\u538b\u7f29\u6bd4\u4f18\u5148\uff09\u3001TP\uff08\u541e\u5410\u91cf\u4f18\u5148\uff09\u3001BM\uff08\u5e73\u8861\u6a21\u5f0f\uff09\u3002", "result": "\u57289\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e14\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\uff1a\u5e73\u5747\u538b\u7f29\u6bd4\u5206\u522b\u63d0\u534716.66%\u300116.11%\u300116.33%\uff1b\u541e\u5410\u91cf\u5206\u522b\u63d0\u53474.73\u500d\u30019.23\u500d\u30019.15\u500d\u3002", "conclusion": "AgentGC\u901a\u8fc7\u667a\u80fd\u4f53\u67b6\u6784\u548cLLM\u96c6\u6210\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u56e0\u7ec4\u6570\u636e\u538b\u7f29\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u538b\u7f29\u6548\u7387\u548c\u541e\u5410\u91cf\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u57fa\u56e0\u7ec4\u6570\u636e\u5b58\u50a8\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u8fdb\u5316\u5f0f\u7684\u667a\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12868", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12868", "abs": "https://arxiv.org/abs/2601.12868", "authors": ["Shiyue Hu", "Ruizhe Li", "Yanjun Gao"], "title": "Race, Ethnicity and Their Implication on Bias in Large Language Models", "comment": "Work in process", "summary": "Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5206\u6790LLMs\u4e2d\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u7684\u5185\u90e8\u8868\u793a\u673a\u5236\uff0c\u53d1\u73b0\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5206\u5e03\u5728\u591a\u4e2a\u5185\u90e8\u5355\u5143\u4e2d\uff0c\u5e72\u9884\u80fd\u51cf\u5c11\u504f\u89c1\u4f46\u4ecd\u6709\u6b8b\u7559\u6548\u5e94", "motivation": "LLMs\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u65f6\uff0c\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u53ef\u80fd\u88ab\u660e\u786e\u9648\u8ff0\u6216\u9690\u542b\u63a8\u65ad\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bb0\u5f55\u7ed3\u679c\u5c42\u9762\u7684\u5dee\u5f02\uff0c\u5bf9\u5185\u90e8\u673a\u5236\u4e86\u89e3\u6709\u9650\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u8fd9\u4e9b\u4fe1\u606f\u5728\u6a21\u578b\u5185\u90e8\u5982\u4f55\u8868\u793a\u548c\u8fd0\u4f5c", "method": "\u4f7f\u7528\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff08\u6bd2\u6027\u751f\u6210\u548c\u4e34\u5e8a\u53d9\u4e8b\u7406\u89e3\u4efb\u52a1\uff09\uff0c\u5206\u6790\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff0c\u91c7\u7528\u53ef\u590d\u73b0\u7684\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\uff0c\u7ed3\u5408\u63a2\u6d4b\u3001\u795e\u7ecf\u5143\u7ea7\u5f52\u56e0\u548c\u9488\u5bf9\u6027\u5e72\u9884\u65b9\u6cd5", "result": "\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5206\u5e03\u5728\u591a\u4e2a\u5185\u90e8\u5355\u5143\u4e2d\uff0c\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\uff1b\u90e8\u5206\u5355\u5143\u7f16\u7801\u4e86\u9884\u8bad\u7ec3\u4e2d\u7684\u654f\u611f\u6216\u523b\u677f\u5370\u8c61\u5173\u8054\uff1b\u76f8\u540c\u7684\u4eba\u53e3\u7edf\u8ba1\u7ebf\u7d22\u53ef\u80fd\u5f15\u53d1\u4e0d\u540c\u884c\u4e3a\uff1b\u6291\u5236\u76f8\u5173\u795e\u7ecf\u5143\u80fd\u51cf\u5c11\u504f\u89c1\u4f46\u4ecd\u6709\u663e\u8457\u6b8b\u7559\u6548\u5e94", "conclusion": "\u5e72\u9884\u4e3b\u8981\u6539\u53d8\u884c\u4e3a\u800c\u975e\u8868\u793a\u5c42\u9762\uff0c\u8868\u660e\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u7f13\u89e3\u7b56\u7565\uff1b\u7814\u7a76\u63ed\u793a\u4e86LLMs\u4e2d\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u8868\u793a\u7684\u590d\u6742\u6027\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u504f\u89c1\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3"}}
{"id": "2601.12637", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.12637", "abs": "https://arxiv.org/abs/2601.12637", "authors": ["Long D. Nguyen", "Kelin Xia", "Binh P. Nguyen"], "title": "Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction", "comment": null, "summary": "Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.", "AI": {"tldr": "MI-MoE\uff1a\u4e00\u79cd\u7528\u4e8e3D\u5206\u5b50\u56fe\u5b66\u4e60\u7684\u591a\u5c3a\u5ea6\u4ea4\u4e92\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u8def\u7531\u673a\u5236\u81ea\u9002\u5e94\u5efa\u6a21\u4e0d\u540c\u51e0\u4f55\u5c3a\u5ea6\uff08\u77ed\u3001\u4e2d\u3001\u957f\u7a0b\uff09\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u73b0\u67093D\u5206\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u56fa\u5b9a\u7684\u90bb\u57df\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5982\u8ddd\u79bb\u622a\u65ad\u548c\u6700\u5927\u90bb\u5c45\u9650\u5236\uff09\uff0c\u5bfc\u81f4\u521a\u6027\u7684\u3001\u6570\u636e\u65e0\u5173\u7684\u4ea4\u4e92\u9884\u7b97\uff0c\u65e0\u6cd5\u81ea\u9002\u5e94\u5efa\u6a21\u4e0d\u540c\u51e0\u4f55\u5c3a\u5ea6\uff08\u77ed\u7a0b\u3001\u4e2d\u7a0b\u3001\u957f\u7a0b\uff09\u7684\u975e\u5171\u4ef7\u76f8\u4e92\u4f5c\u7528\u3001\u7acb\u4f53\u5316\u5b66\u6548\u5e94\u548c\u4ecb\u8d28\u5230\u957f\u7a0b\u529b\u3002", "method": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u4ea4\u4e92\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff08MI-MoE\uff09\uff1a1\uff09\u8ddd\u79bb\u622a\u65ad\u4e13\u5bb6\u96c6\u5408\uff0c\u663e\u5f0f\u6355\u83b7\u77ed\u7a0b\u3001\u4e2d\u7a0b\u548c\u957f\u7a0b\u76f8\u4e92\u4f5c\u7528\uff1b2\uff09\u62d3\u6251\u95e8\u63a7\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u57fa\u4e8e\u8fc7\u6ee4\u7684\u63cf\u8ff0\u7b26\uff08\u5305\u62ec\u6301\u4e45\u540c\u8c03\u7279\u5f81\uff09\u5c06\u8f93\u5165\u8def\u7531\u5230\u4e0d\u540c\u4e13\u5bb6\uff1b3\uff09\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u53ef\u6539\u8fdb\u591a\u79cd3D\u5206\u5b50\u9aa8\u5e72\u7f51\u7edc\u3002", "result": "MI-MoE\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u5728\u591a\u4e2a3D\u5206\u5b50\u9aa8\u5e72\u7f51\u7edc\u4e0a\u4e00\u81f4\u6539\u8fdb\u6027\u80fd\uff0c\u8986\u76d6\u56de\u5f52\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u5728\u591a\u6837\u5316\u7684\u5206\u5b50\u548c\u805a\u5408\u7269\u6027\u8d28\u9884\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u62d3\u6251\u611f\u77e5\u7684\u591a\u5c3a\u5ea6\u8def\u7531\u662f3D\u5206\u5b50\u56fe\u5b66\u4e60\u7684\u6709\u6548\u539f\u5219\uff0cMI-MoE\u80fd\u591f\u81ea\u9002\u5e94\u5efa\u6a21\u4e0d\u540c\u51e0\u4f55\u5c3a\u5ea6\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u514b\u670d\u4f20\u7edf\u56fa\u5b9a\u90bb\u57df\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.13562", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13562", "abs": "https://arxiv.org/abs/2601.13562", "authors": ["Zhiguang Liu", "Yi Shang"], "title": "Reasoning is a Modality", "comment": "Code access: https://github.com/lz7fd/Reasoning_is_a_Modality", "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.", "AI": {"tldr": "\u63d0\u51fa\u5206\u79bb\u63a8\u7406\u6a21\u6001\u7684\u5047\u8bbe\uff0c\u8bbe\u8ba1\u89d2\u8272\u5206\u79bbTransformer\u5757\uff0c\u5728ARC\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4eba\u7c7b\u5e73\u5747\u8868\u73b0", "motivation": "\u73b0\u4ee3AI\u7cfb\u7edf\uff08\u5982LLMs\u548cViTs\uff09\u4e3b\u8981\u4f5c\u4e3a\u884c\u4e3a\u5e8f\u5217\u9884\u6d4b\u673a\u8fd0\u884c\uff0c\u901a\u8fc7\u5efa\u6a21token\u7edf\u8ba1\u6765\u5339\u914d\u53ef\u89c2\u5bdf\u884c\u4e3a\uff0c\u4f46\u6ca1\u6709\u6301\u4e45\u3001\u53ef\u8bfb\u7684\u601d\u7ef4\u72b6\u6001\u3002\u8fd9\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff1a\u4eba\u7c7b\u53ef\u4ee5\u901a\u8fc7\u89e3\u7801\u5185\u90e8\u72b6\u6001\u6765\u89e3\u91ca\u884c\u4e3a\uff0c\u800cAI\u7cfb\u7edf\u53ef\u4ee5\u4ea7\u751f\u6d41\u5229\u7684\u4e8b\u540e\u5408\u7406\u5316\u89e3\u91ca\uff0c\u4f46\u8fd9\u4e9b\u89e3\u91ca\u5e76\u4e0d\u57fa\u4e8e\u8fd9\u6837\u7684\u5185\u90e8\u72b6\u6001\u3002", "method": "\u63d0\u51fa\u63a8\u7406\u5e94\u4f5c\u4e3a\u72ec\u7acb\u4e8e\u4f4e\u7ea7\u5de5\u4f5c\u7a7a\u95f4\u7684\u6a21\u6001\u5b58\u5728\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89d2\u8272\u5206\u79bbTransformer\u5757\uff0c\u5c06\u5168\u5c40\u63a7\u5236\u5668token\u4e0e\u7f51\u683c\u5de5\u4f5c\u7a7a\u95f4token\u5206\u79bb\uff0c\u5b9e\u73b0\u8fed\u4ee3\u89c4\u5219\u6267\u884c\u3002\u5728VARC\u89c6\u89c9\u4e2d\u5fc3\u534f\u8bae\u4e0b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5728ARC-1\u4efb\u52a1\u4e0a\u8fbe\u523062.6%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0860.2%\uff09\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\uff0c\u4e0e\u5bc6\u96c6ViT\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u4e00\u81f4\u7684\u89c4\u5219\u5e94\u7528\u7ed3\u6784\uff0c\u4ece\u6982\u7387\u6591\u70b9\u5411\u63a7\u5236\u5668\u9a71\u52a8\u7684\u63a8\u7406\u8f6c\u53d8\u3002", "conclusion": "\u63a8\u7406\u786e\u5b9e\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u72ec\u7acb\u7684\u6a21\u6001\u5b58\u5728\uff0c\u901a\u8fc7\u5206\u79bb\u63a7\u5236\u5668\u548c\u5de5\u4f5c\u7a7a\u95f4token\u7684\u67b6\u6784\u8bbe\u8ba1\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u63a5\u8fd1\u4eba\u7c7b\u62bd\u8c61\u63a8\u7406\u7684AI\u7cfb\u7edf\uff0c\u5728\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u8d85\u8d8a\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12904", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12904", "abs": "https://arxiv.org/abs/2601.12904", "authors": ["Jiahao Wang", "Weiyu Xie", "Mingxing Zhang", "Boxing Zhang", "Jianwei Dong", "Yuening Zhu", "Chen Lin", "Jinqi Tang", "Yaochen Han", "Zhiyuan Ai", "Xianglin Chen", "Yongwei Wu", "Congfeng Jiang"], "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.", "AI": {"tldr": "FusionRAG\u662f\u4e00\u4e2a\u4f18\u5316RAG\u63a8\u7406\u6548\u7387\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9884\u5904\u7406\u9636\u6bb5\u5d4c\u5165\u8de8\u5757\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u91cd\u5904\u7406\u9636\u6bb5\u9009\u62e9\u6027\u91cd\u8ba1\u7b97\u5173\u952etoken\u7684KV\u7f13\u5b58\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u91cd\u7528\u68c0\u7d22\u5757\u7684\u9884\u5904\u7406KV\u7f13\u5b58\u53ef\u4ee5\u52a0\u901f\u63a8\u7406\uff0c\u4f46\u7f3a\u4e4f\u8de8\u5757\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u663e\u8457\u4e0b\u964d\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528KV\u7f13\u5b58\u91cd\u7528\u7684\u6f5c\u5728\u4f18\u52bf\u3002", "method": "\u63d0\u51faFusionRAG\u6846\u67b6\uff1a1) \u79bb\u7ebf\u9884\u5904\u7406\u9636\u6bb5\uff1a\u5c06\u5176\u4ed6\u76f8\u5173\u6587\u672c\u5757\u7684\u4fe1\u606f\u5d4c\u5165\u5230\u6bcf\u4e2a\u5757\u4e2d\uff1b2) \u5728\u7ebf\u91cd\u5904\u7406\u9636\u6bb5\uff1a\u5bf9\u6a21\u578b\u5173\u6ce8\u7684token\u91cd\u65b0\u8ba1\u7b97KV\u7f13\u5b58\uff0c\u5b9e\u73b0\u8d28\u91cf\u4e0e\u6548\u7387\u7684\u5e73\u8861\u3002", "result": "FusionRAG\u5728\u76f8\u540c\u91cd\u8ba1\u7b97\u6bd4\u4f8b\u4e0b\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff1a\u91cd\u8ba1\u7b97\u5c11\u4e8e15%\u7684token\uff0c\u76f8\u6bd4\u57fa\u7ebf\u83b7\u5f97\u9ad8\u8fbe70%\u7684\u5f52\u4e00\u5316F1\u5206\u6570\u63d0\u5347\uff0c\u76f8\u6bd4Full Attention\u51cf\u5c112.66x-9.39x\u7684TTFT\u3002", "conclusion": "FusionRAG\u901a\u8fc7\u4f18\u5316RAG\u7684\u9884\u5904\u7406\u548c\u91cd\u5904\u7406\u9636\u6bb5\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4e3aKV\u7f13\u5b58\u91cd\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12654", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12654", "abs": "https://arxiv.org/abs/2601.12654", "authors": ["Hyunseung Hwang", "Seungeun Lee", "Lucas Rosenblatt", "Julia Stoyanovich", "Steven Euijong Whang"], "title": "Explanation Multiplicity in SHAP: Characterization and Assessment", "comment": null, "summary": "Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.", "AI": {"tldr": "SHAP\u89e3\u91ca\u5b58\u5728\u591a\u91cd\u6027\u95ee\u9898\uff1a\u76f8\u540c\u8f93\u5165\u3001\u4efb\u52a1\u548c\u6a21\u578b\u4e0b\uff0c\u591a\u6b21\u8fd0\u884c\u4f1a\u4ea7\u751f\u591a\u4e2a\u5185\u90e8\u6709\u6548\u4f46\u5b9e\u8d28\u4e0a\u4e0d\u540c\u7684\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\uff0c\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u6027\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e2d\u90fd\u666e\u904d\u5b58\u5728\u3002", "motivation": "SHAP\u89e3\u91ca\u5e38\u88ab\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\u51b3\u7b56\u7684\u8fa9\u62a4\u3001\u8d28\u7591\u548c\u5ba1\u8ba1\uff0c\u88ab\u89c6\u4e3a\u53ef\u9760\u7684\u4e2a\u4f53\u9884\u6d4b\u7279\u5f81\u9a71\u52a8\u89e3\u91ca\u3002\u7136\u800c\uff0c\u5373\u4f7f\u8f93\u5165\u3001\u4efb\u52a1\u548c\u8bad\u7ec3\u6a21\u578b\u56fa\u5b9a\uff0cSHAP\u89e3\u91ca\u5728\u91cd\u590d\u8fd0\u884c\u4e2d\u4e5f\u4f1a\u53d1\u751f\u663e\u8457\u53d8\u5316\uff0c\u8fd9\u79cd\u89e3\u91ca\u591a\u91cd\u6027\u95ee\u9898\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u8868\u5f81\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\u4e2d\u7684\u591a\u91cd\u6027\uff0c\u533a\u5206\u6a21\u578b\u8bad\u7ec3/\u9009\u62e9\u6765\u6e90\u4e0e\u89e3\u91ca\u7ba1\u9053\u5185\u5728\u968f\u673a\u6027\u3002\u4f7f\u7528\u5e45\u5ea6\u57fa\u548c\u6392\u5e8f\u57fa\u5ea6\u91cf\u8bc4\u4f30\u7a33\u5b9a\u6027\uff0c\u5e76\u63a8\u5bfc\u968f\u673a\u57fa\u7ebf\u503c\u4f5c\u4e3a\u53c2\u8003\u57fa\u51c6\u3002", "result": "\u53d1\u73b0\u89e3\u91ca\u591a\u91cd\u6027\u666e\u904d\u5b58\u5728\uff0c\u5373\u4f7f\u5728\u9ad8\u5ea6\u7f6e\u4fe1\u7684\u9884\u6d4b\u4e2d\u4e5f\u4f1a\u6301\u7eed\u5b58\u5728\u3002\u5e45\u5ea6\u57fa\u8ddd\u79bb\u53ef\u80fd\u63a5\u8fd1\u96f6\uff0c\u800c\u6392\u5e8f\u57fa\u5ea6\u91cf\u63ed\u793a\u9876\u7ea7\u7279\u5f81\u8eab\u4efd\u548c\u987a\u5e8f\u7684\u663e\u8457\u53d8\u5316\u3002", "conclusion": "SHAP\u89e3\u91ca\u5b58\u5728\u56fa\u6709\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e0e\u89e3\u91ca\u9884\u671f\u7528\u9014\u76f8\u5339\u914d\u7684\u5ea6\u91cf\u548c\u57fa\u7ebf\uff0c\u4ee5\u786e\u4fdd\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.13581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13581", "abs": "https://arxiv.org/abs/2601.13581", "authors": ["Heedou Kim", "Changsik Kim", "Sanghwa Shin", "Jaewoo Kang"], "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System", "comment": "This paper has been accepted to the EACL 2026 Industry Track", "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.", "AI": {"tldr": "ScriptMind\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u8bc8\u9a97\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1\u3001\u6570\u636e\u96c6\u548c\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u578bLLM\u7684\u8bc8\u9a97\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u589e\u5f3a\u7528\u6237\u7684\u9632\u9a97\u8ba4\u77e5\u610f\u8bc6\u3002", "motivation": "\u793e\u4ea4\u5de5\u7a0b\u8bc8\u9a97\u65e5\u76ca\u91c7\u7528\u4e2a\u6027\u5316\u3001\u591a\u8f6e\u5bf9\u8bdd\u7684\u6b3a\u9a97\u624b\u6bb5\uff0c\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u5c40\u9650\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u6b3a\u9a97\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u8ba4\u77e5\u8f85\u52a9\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faScriptMind\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u72af\u7f6a\u811a\u672c\u63a8\u7406\u4efb\u52a1\uff08CSIT\uff09\u7528\u4e8e\u8bc8\u9a97\u63a8\u7406\u3001\u72af\u7f6a\u811a\u672c\u611f\u77e5\u63a8\u7406\u6570\u636e\u96c6\uff08CSID\uff09\u7528\u4e8e\u5fae\u8c03\u5c0f\u578bLLM\u3001\u8ba4\u77e5\u6a21\u62df\u8bc4\u4f30\uff08CSED\uff09\u7528\u4e8e\u8bc4\u4f30\u5b9e\u65f6\u8ba4\u77e5\u5f71\u54cd\u3002\u4f7f\u7528571\u4e2a\u97e9\u56fd\u7535\u8bdd\u8bc8\u9a97\u6848\u4f8b\u6784\u5efa\u4e8622,712\u4e2a\u7ed3\u6784\u5316\u8bc8\u9a97\u5e8f\u5217\u8bad\u7ec3\u5b9e\u4f8b\u3002", "result": "\u7ecf\u8fc7ScriptMind\u5fae\u8c03\u768411B\u5c0f\u578bLLM\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\u6bd4GPT-4o\u9ad8\u51fa13%\uff0c\u5728\u8bef\u62a5\u51cf\u5c11\u3001\u8bc8\u9a97\u8005\u8bdd\u8bed\u9884\u6d4b\u548c\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\u3002\u5728\u7535\u8bdd\u8bc8\u9a97\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u5e76\u7ef4\u6301\u4e86\u7528\u6237\u7684\u6000\u7591\u6c34\u5e73\uff0c\u589e\u5f3a\u4e86\u9632\u9a97\u8ba4\u77e5\u610f\u8bc6\u3002", "conclusion": "ScriptMind\u4ee3\u8868\u4e86\u5411\u4ee5\u4eba\u4e3a\u672c\u3001\u8ba4\u77e5\u81ea\u9002\u5e94\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc8\u9a97\u9632\u5fa1\u9886\u57df\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5c55\u793a\u4e86LLM\u5728\u63d0\u5347\u4eba\u7c7b\u9632\u9a97\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12906", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12906", "abs": "https://arxiv.org/abs/2601.12906", "authors": ["Lingrui Mei", "Shenghua Liu", "Yiwei Wang", "Yuyao Ge", "Baolong Bi", "Jiayu Yao", "Jun Wan", "Ziling Yin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Gated Differentiable Working Memory for Long-Context Language Modeling", "comment": null, "summary": "Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.", "AI": {"tldr": "Gdwm\u901a\u8fc7\u95e8\u63a7\u53ef\u5fae\u5206\u5de5\u4f5c\u5185\u5b58\u6846\u67b6\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u6548\u7528\u4f30\u8ba1\u6765\u4f18\u5316\u6d4b\u8bd5\u65f6\u9002\u5e94\u7684\u5185\u5b58\u6574\u5408\uff0c\u76f8\u6bd4\u5747\u5300\u7b56\u7565\u51cf\u5c114\u500d\u68af\u5ea6\u6b65\u6570\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6548\u7387-\u6027\u80fd\u5e73\u8861\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u5bf9Transformer\u6a21\u578b\u6784\u6210\u6311\u6218\uff1a\u6ce8\u610f\u529b\u5206\u6570\u5728\u6570\u5343\u4e2atoken\u4e0a\u88ab\u7a00\u91ca\uff0c\u5173\u952e\u4fe1\u606f\u5e38\u5e38\u5728\u4e2d\u95f4\u4e22\u5931\uff0c\u6a21\u578b\u96be\u4ee5\u9002\u5e94\u63a8\u7406\u65f6\u7684\u65b0\u6a21\u5f0f\u3002\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u4f7f\u7528\u5747\u5300\u5199\u5165\u7b56\u7565\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5728\u4f4e\u6548\u7528\u533a\u57df\uff0c\u4e14\u5728\u8bed\u4e49\u5f02\u6784\u4e0a\u4e0b\u6587\u4e2d\u5b58\u5728\u9ad8\u68af\u5ea6\u65b9\u5dee\u95ee\u9898\u3002", "method": "\u5c06\u6d4b\u8bd5\u65f6\u9002\u5e94\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u5185\u5b58\u6574\u5408\u95ee\u9898\uff0c\u63d0\u51faGdwm\uff08\u95e8\u63a7\u53ef\u5fae\u5206\u5de5\u4f5c\u5185\u5b58\uff09\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5f15\u5165\u5199\u5165\u63a7\u5236\u5668\u6765\u95e8\u63a7\u6574\u5408\u8fc7\u7a0b\uff0c\u63a7\u5236\u5668\u4f30\u8ba1\"\u4e0a\u4e0b\u6587\u6548\u7528\"\uff08\u4e00\u79cd\u8861\u91cf\u957f\u8ddd\u79bb\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\uff09\uff0c\u5e76\u76f8\u5e94\u5206\u914d\u68af\u5ea6\u6b65\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u8986\u76d6\u3002", "result": "\u5728ZeroSCROLLS\u548cLongBench v2\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGdwm\u5728\u8fbe\u5230\u53ef\u6bd4\u6216\u66f4\u4f18\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6bd4\u5747\u5300\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c11\u4e864\u500d\u7684\u68af\u5ea6\u6b65\u6570\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u9002\u5e94\u5efa\u7acb\u4e86\u65b0\u7684\u6548\u7387-\u6027\u80fd\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6d4b\u8bd5\u65f6\u9002\u5e94\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9884\u7b97\u7ea6\u675f\u7684\u5185\u5b58\u6574\u5408\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u6548\u7528\u7684\u95e8\u63a7\u673a\u5236\uff0cGdwm\u6846\u67b6\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd-\u6548\u7387\u5e73\u8861\u3002"}}
{"id": "2601.12662", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.12662", "abs": "https://arxiv.org/abs/2601.12662", "authors": ["Xingran Chen", "Navid NaderiAlizadeh", "Alejandro Ribeiro", "Shirin Saeedi Bidokhti"], "title": "Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks", "comment": null, "summary": "We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u65e0\u7ebf\u7f51\u7edc\u4e2d\u81ea\u56de\u5f52\u9a6c\u5c14\u53ef\u592b\u6e90\u7684\u5b9e\u65f6\u91c7\u6837\u4e0e\u4f30\u8ba1\u7b56\u7565\uff0c\u8bc1\u660e\u7b56\u7565\u53ef\u8fc1\u79fb\u81f3\u7ed3\u6784\u76f8\u4f3c\u7f51\u7edc", "motivation": "\u89e3\u51b3\u52a8\u6001\u591a\u8df3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u81ea\u56de\u5f52\u9a6c\u5c14\u53ef\u592b\u6e90\u7684\u5b9e\u65f6\u91c7\u6837\u4e0e\u4f30\u8ba1\u95ee\u9898\uff0c\u7531\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u7ef4\u5ea6\u9ad8\u548c\u7f51\u7edc\u62d3\u6251\u590d\u6742\uff0c\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u83b7\u5f97\u6700\u4f18\u7b56\u7565", "method": "\u63d0\u51fa\u56fe\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u7b56\u7565\u4f18\u5316\uff0c\u5229\u7528\u56fe\u7ed3\u6784\u8868\u793a\u7f51\u7edc\u62d3\u6251\uff0c\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u7b56\u7565\u5b66\u4e60", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff1a1) \u63d0\u51fa\u7684\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff1b2) \u8bad\u7ec3\u7b56\u7565\u53ef\u8fc1\u79fb\u81f3\u66f4\u5927\u7f51\u7edc\uff0c\u6027\u80fd\u589e\u76ca\u968f\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\u800c\u63d0\u5347\uff1b3) \u56fe\u8bad\u7ec3\u8fc7\u7a0b\u80fd\u62b5\u6297\u975e\u5e73\u7a33\u6027\uff1b4) \u5faa\u73af\u673a\u5236\u5728\u72ec\u7acb\u5b66\u4e60\u548c\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c\u4e2d\u90fd\u81f3\u5173\u91cd\u8981", "conclusion": "\u56fe\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u590d\u6742\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5b9e\u65f6\u91c7\u6837\u4f30\u8ba1\u95ee\u9898\uff0c\u6240\u63d0\u7b56\u7565\u5177\u6709\u53ef\u8fc1\u79fb\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5f0f\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.13589", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13589", "abs": "https://arxiv.org/abs/2601.13589", "authors": ["HyeYoung Lee"], "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification", "comment": null, "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u9891\u60c5\u611f\u4fe1\u53f7\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff0c\u5b9e\u65f6\u751f\u6210\u54cd\u5e94\u5bfc\u5411\u7684\u5a92\u4f53\u5185\u5bb9\uff0c\u901a\u8fc7\u5b89\u5168\u9a8c\u8bc1\u786e\u4fdd\u5185\u5bb9\u9002\u9f84\u53ef\u63a7", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5c06\u60c5\u611f\u72b6\u6001\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u9002\u9f84\u3001\u53ef\u63a7\u54cd\u5e94\u5185\u5bb9\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u54cd\u5e94\u5185\u5bb9\u5e76\u786e\u4fdd\u5b89\u5168\u6027\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u56db\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff1a1)\u57fa\u4e8eCNN\u7684\u60c5\u611f\u8bc6\u522b\u667a\u80fd\u4f53\u63d0\u53d6\u58f0\u5b66\u7279\u5f81\uff1b2)\u54cd\u5e94\u7b56\u7565\u51b3\u7b56\u667a\u80fd\u4f53\u5c06\u60c5\u611f\u6620\u5c04\u5230\u54cd\u5e94\u6a21\u5f0f\uff1b3)\u5185\u5bb9\u53c2\u6570\u751f\u6210\u667a\u80fd\u4f53\u4ea7\u751f\u5a92\u4f53\u63a7\u5236\u53c2\u6570\uff1b4)\u5b89\u5168\u9a8c\u8bc1\u667a\u80fd\u4f53\u5f3a\u5236\u6267\u884c\u9002\u9f84\u6027\u548c\u523a\u6fc0\u7ea6\u675f\u3002\u5f15\u5165\u663e\u5f0f\u5b89\u5168\u9a8c\u8bc1\u5faa\u73af\u8fc7\u6ee4\u751f\u6210\u5185\u5bb9\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u8fbe\u523073.2%\u7684\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u7387\u300189.4%\u7684\u54cd\u5e94\u6a21\u5f0f\u4e00\u81f4\u6027\u3001100%\u7684\u5b89\u5168\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u4e8e100ms\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u9002\u5408\u8bbe\u5907\u7aef\u90e8\u7f72\u3002", "conclusion": "\u8be5\u6a21\u5757\u5316\u67b6\u6784\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u513f\u7ae5\u76f8\u5173\u5a92\u4f53\u3001\u6cbb\u7597\u5e94\u7528\u548c\u60c5\u611f\u54cd\u5e94\u667a\u80fd\u8bbe\u5907\uff0c\u5b9e\u73b0\u4e86\u4ece\u60c5\u611f\u8bc6\u522b\u5230\u5b89\u5168\u54cd\u5e94\u5185\u5bb9\u751f\u6210\u7684\u5b8c\u6574\u95ed\u73af\u3002"}}
{"id": "2601.12910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12910", "abs": "https://arxiv.org/abs/2601.12910", "authors": ["Tim Baumg\u00e4rtner", "Iryna Gurevych"], "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment", "comment": null, "summary": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.", "AI": {"tldr": "SciCoQA\u662f\u4e00\u4e2a\u68c0\u6d4b\u79d1\u5b66\u8bba\u6587\u4e0e\u4ee3\u7801\u5e93\u4e4b\u95f4\u5dee\u5f02\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b611\u4e2a\u5dee\u5f02\u5b9e\u4f8b\uff0881\u4e2a\u771f\u5b9e\uff0c530\u4e2a\u5408\u6210\uff09\uff0c\u6db5\u76d6\u591a\u4e2a\u8ba1\u7b97\u79d1\u5b66\u9886\u57df\u3002\u8bc4\u4f30\u663e\u793aLLMs\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u6700\u4f73\u6a21\u578bGPT-5\u4ec5\u80fd\u68c0\u6d4b45.7%\u7684\u771f\u5b9e\u5dee\u5f02\u3002", "motivation": "\u786e\u4fdd\u79d1\u5b66\u8bba\u6587\u4e0e\u5176\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u5bf9\u4e8e\u53ef\u590d\u73b0\u6027\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u68c0\u6d4b\u8bba\u6587\u4e0e\u4ee3\u7801\u5dee\u5f02\u7684\u65b9\u6cd5\u548c\u6570\u636e\u96c6\uff0c\u8fd9\u963b\u788d\u4e86\u79d1\u5b66\u7814\u7a76\u7684\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u4eceGitHub\u95ee\u9898\u548c\u53ef\u590d\u73b0\u6027\u8bba\u6587\u4e2d\u6536\u96c6\u771f\u5b9e\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6765\u6269\u5c55\u6570\u636e\u96c6\u3002\u8be6\u7ec6\u5206\u6790\u5dee\u5f02\u7c7b\u578b\u548c\u7c7b\u522b\uff0c\u6784\u5efa\u5305\u542b611\u4e2a\u5dee\u5f02\u5b9e\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6AI\u3001\u7269\u7406\u3001\u5b9a\u91cf\u751f\u7269\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u3002", "result": "\u6784\u5efa\u4e86SciCoQA\u6570\u636e\u96c6\uff0c\u5305\u542b611\u4e2a\u8bba\u6587-\u4ee3\u7801\u5dee\u5f02\u5b9e\u4f8b\u3002\u5bf921\u4e2aLLMs\u7684\u8bc4\u4f30\u663e\u793a\u8be5\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u7701\u7565\u8bba\u6587\u7ec6\u8282\u3001\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u548c\u9884\u8bad\u7ec3\u8bed\u6599\u5916\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u3002\u6700\u4f73\u6a21\u578bGPT-5\u4ec5\u80fd\u68c0\u6d4b45.7%\u7684\u771f\u5b9e\u5dee\u5f02\u3002", "conclusion": "SciCoQA\u6570\u636e\u96c6\u4e3a\u68c0\u6d4b\u79d1\u5b66\u8bba\u6587\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u5f02\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002\u7ed3\u679c\u8868\u660e\u5f53\u524dLLMs\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u79d1\u5b66\u5185\u5bb9\u548c\u957f\u4e0a\u4e0b\u6587\u65f6\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u80fd\u529b\u4ee5\u786e\u4fdd\u79d1\u5b66\u7814\u7a76\u7684\u5fe0\u5b9e\u5b9e\u73b0\u3002"}}
{"id": "2601.12680", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12680", "abs": "https://arxiv.org/abs/2601.12680", "authors": ["Zheng Fang", "Wolfgang Mayer", "Zeyu Zhang", "Jian Wang", "Hong-Yu Zhang", "Wanli Li", "Zaiwen Feng"], "title": "MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning", "comment": null, "summary": "Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.", "AI": {"tldr": "\u63d0\u51faMetaToolAgent (MTA)\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5305\u542b155\u4e2a\u5de5\u5177\u548c9377\u4e2a\u95ee\u7b54\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u89e3\u51b3LLM\u5de5\u5177\u9009\u62e9\u4e2d\u8de8\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u6709\u9650\u5de5\u5177\u96c6\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u5b9e\u9645\u90e8\u7f72\u4e2d\u9047\u5230\u7684\u65b0\u5de5\u5177\uff0c\u9650\u5236\u4e86LLM\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u5de5\u5177\u534f\u8c03\u80fd\u529b\u3002", "method": "\u63d0\u51faMetaToolAgent (MTA)\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u6784\u5efa\u5305\u542b7\u4e2a\u9886\u57df\u3001155\u4e2a\u5de5\u5177\u30019377\u4e2a\u95ee\u7b54\u5bf9\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u6a21\u62df\u771f\u5b9e\u96c6\u6210\u573a\u666f\uff0c\u63d0\u5347\u8de8\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMTA\u5728\u672a\u89c1\u5de5\u5177\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6784\u5efa\u9700\u8981\u52a8\u6001\u5de5\u5177\u534f\u8c03\u7684\u7075\u6d3b\u53ef\u6269\u5c55\u7cfb\u7edf\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "MTA\u901a\u8fc7\u5143\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u5de5\u5177\u9009\u62e9\u4e2d\u7684\u8de8\u5de5\u5177\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u5de5\u5177\u534f\u8c03\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13591", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13591", "abs": "https://arxiv.org/abs/2601.13591", "authors": ["Maojun Sun", "Yifei Xie", "Yue Wu", "Ruijian Han", "Binyan Jiang", "Defeng Sun", "Yancheng Yuan", "Jian Huang"], "title": "DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems", "comment": null, "summary": "Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.", "AI": {"tldr": "DSAEval\u662f\u4e00\u4e2a\u5305\u542b641\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u79d1\u5b66\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e285\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5177\u6709\u591a\u6a21\u6001\u73af\u5883\u611f\u77e5\u3001\u591a\u67e5\u8be2\u4ea4\u4e92\u548c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u4e09\u5927\u7279\u8272\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u6570\u636e\u4ee3\u7406\u65e8\u5728\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u4efb\u52a1\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u6570\u636e\u79d1\u5b66\u95ee\u9898\u7684\u5f00\u653e\u6027\u3001\u591a\u5206\u7c7b\u6027\u548c\u7f3a\u4e4f\u6807\u51c6\u7b54\u6848\u7684\u7279\u70b9\u7ed9\u8bc4\u4f30\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faDSAEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b641\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u79d1\u5b66\u95ee\u9898\uff0c\u57fa\u4e8e285\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\uff08\u5982\u89c6\u89c9\u548c\u6587\u672c\uff09\u3002\u8be5\u57fa\u51c6\u5177\u6709\u4e09\u5927\u7279\u8272\uff1a\u591a\u6a21\u6001\u73af\u5883\u611f\u77e5\u3001\u591a\u67e5\u8be2\u4ea4\u4e92\u548c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u4e8611\u4e2a\u5148\u8fdb\u4ee3\u7406LLM\uff0c\u7ed3\u679c\u663e\u793aClaude-Sonnet-4.5\u6574\u4f53\u6027\u80fd\u6700\u5f3a\uff0cGPT-5.2\u6700\u6709\u6548\u7387\uff0cMiMo-V2-Flash\u6700\u5177\u6210\u672c\u6548\u76ca\u3002\u591a\u6a21\u6001\u611f\u77e5\u5728\u89c6\u89c9\u76f8\u5173\u4efb\u52a1\u4e0a\u5e26\u67652.04%\u523011.30%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f53\u524d\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u5728\u7ed3\u6784\u5316\u6570\u636e\u548c\u5e38\u89c4\u6570\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u975e\u7ed3\u6784\u5316\u9886\u57df\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u7814\u7a76\u4e3a\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.12921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12921", "abs": "https://arxiv.org/abs/2601.12921", "authors": ["Adimulya Kartiyasa", "Bao Gia Cao", "Boyang Li"], "title": "Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs", "comment": null, "summary": "Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.", "AI": {"tldr": "\u63d0\u51faIndoSoSci\u6570\u636e\u96c6\uff0c\u7ed3\u5408RAG\u548cLLM\u751f\u6210\u5047\u8bbe\u6587\u6863\u4f5c\u4e3a\u67e5\u8be2\uff0c\u6709\u6548\u63d0\u5347LLM\u5bf9\u5370\u5c3c\u6587\u5316\u7684\u7406\u89e3", "motivation": "\u73b0\u6709LLMs\u5bf9\u5370\u5c3c\u6587\u5316\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u800c\u672c\u5730\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u5305\u542b\u5927\u91cf\u672c\u571f\u89c6\u89d2\u7684\u6587\u5316\u7814\u7a76\uff0c\u4f46\u8fd9\u4e00\u8d44\u6e90\u88ab\u5ffd\u89c6", "method": "\u4ece151\u4e2a\u5f00\u6e90\u5370\u5c3c\u793e\u79d1\u671f\u520a\u521b\u5efaIndoSoSci\u6570\u636e\u96c6\uff0c\u63d0\u53d6\u5370\u5c3c\u6587\u5316\u76f8\u5173\u4e8b\u5b9e\uff0c\u91c7\u7528RAG\u6280\u672f\uff0c\u4f7f\u7528LLM\u751f\u6210\u7684\u5047\u8bbe\u6587\u6863\u4f5c\u4e3a\u68c0\u7d22\u67e5\u8be2", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728IndoCulture\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\uff0c\u7ed3\u5408\u5370\u5c3c\u7ef4\u57fa\u767e\u79d1\u540e\u5728\u8be5\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684SOTA\u51c6\u786e\u7387", "conclusion": "IndoSoSci\u6570\u636e\u96c6\u548c\u63d0\u51fa\u7684RAG\u65b9\u6cd5\u662f\u63d0\u5347LLM\u5bf9\u5370\u5c3c\u6587\u5316\u7406\u89e3\u7684\u6709\u6548\u9014\u5f84\uff0c\u672c\u5730\u793e\u79d1\u671f\u520a\u662f\u5b9d\u8d35\u7684\u6587\u5316\u77e5\u8bc6\u6765\u6e90"}}
{"id": "2601.13600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13600", "abs": "https://arxiv.org/abs/2601.13600", "authors": ["Paul He", "Elke Kirschbaum", "Shiva Kasiviswanathan"], "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles", "comment": "Under Review", "summary": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\u68c0\u6d4b\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u8bc6\u522b\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\u548c\u8ba1\u7b97\u6700\u5c0f\u4fee\u590d\uff0c\u5728LLM\u8bc4\u4f30\u5668\u4e0a\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u9a8c\u8bc1", "motivation": "\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u5bf9\u4e8e\u4e8b\u5b9e\u6838\u67e5\u3001\u6458\u8981\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\u7b49\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u8bc4\u4f30\u5c0f\u89c4\u6a21\u4e8b\u5b9e\u5b50\u96c6\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u5176\u5224\u65ad\u5b58\u5728\u566a\u58f0\uff0c\u4e14\u6210\u5bf9\u68c0\u67e5\u65e0\u6cd5\u4fdd\u8bc1\u5168\u5c40\u4e00\u81f4\u6027", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\uff0c\u8bc6\u522b\u6700\u5c0f\u4e0d\u4e00\u81f4\u5b50\u96c6\uff0c\u53ef\u9009\u5730\u901a\u8fc7\u547d\u4e2d\u96c6\u8ba1\u7b97\u6700\u5c0f\u4fee\u590d\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u4f4e\u9636\u591a\u9879\u5f0f\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8eLLM\u8bc4\u4f30\u5668", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9eLLM\u8bc4\u4f30\u5668\u4e0a\u90fd\u80fd\u9ad8\u6548\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u7136\u8bed\u8a00\u4e8b\u5b9e\u96c6\u5408\u7684\u5168\u5c40\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5206\u6cbb\u7b97\u6cd5\u514b\u670d\u4e86\u6307\u6570\u7ea7\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u7406\u8bba\u969c\u788d\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u9a8c\u8bc1"}}
{"id": "2601.12945", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12945", "abs": "https://arxiv.org/abs/2601.12945", "authors": ["Miao Xie", "Siguang Chen", "Chunli Lv"], "title": "A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits", "comment": "27 pages, 6 table", "summary": "Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.", "AI": {"tldr": "\u8fd9\u662f\u7b2c\u4e00\u7bc7\u7cfb\u7edf\u7efc\u8ff0\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u81c2\u8001\u864e\u673a\u53cc\u5411\u4ea4\u4e92\u7684\u8bba\u6587\uff0c\u5206\u6790\u4e86\u4e24\u4e2a\u9886\u57df\u5728\u7ec4\u4ef6\u5c42\u9762\u7684\u76f8\u4e92\u589e\u5f3a\u4f5c\u7528\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u6210\u4e3a\u5f3a\u5927\u7684\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u7cfb\u7edf\uff0c\u800c\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u81ea\u9002\u5e94\u51b3\u7b56\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e24\u4e2a\u9886\u57df\u53cc\u5411\u4ea4\u4e92\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u7279\u522b\u662f\u5728\u7ec4\u4ef6\u5c42\u9762\u7684\u6df1\u5165\u5206\u6790\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u56de\u987e\uff0c\u4ece\u7ec4\u4ef6\u5c42\u9762\u5206\u6790LLM\u4e0eMAB\u7684\u53cc\u5411\u4ea4\u4e92\uff1a\u4e00\u65b9\u9762\u5206\u6790MAB\u7b97\u6cd5\u5982\u4f55\u89e3\u51b3LLM\u4ece\u9884\u8bad\u7ec3\u5230RAG\u548c\u4e2a\u6027\u5316\u7684\u5173\u952e\u6311\u6218\uff1b\u53e6\u4e00\u65b9\u9762\u5206\u6790LLM\u5982\u4f55\u91cd\u65b0\u5b9a\u4e49MAB\u7cfb\u7edf\u7684\u6838\u5fc3\u7ec4\u4ef6\uff08\u5982\u81c2\u5b9a\u4e49\u548c\u73af\u5883\u5efa\u6a21\uff09\u3002", "result": "\u8bc6\u522b\u4e86\u53cc\u5411\u4ea4\u4e92\u7684\u5173\u952e\u76ca\u5904\uff1aMAB\u7b97\u6cd5\u80fd\u89e3\u51b3LLM\u7684\u5173\u952e\u6311\u6218\uff0c\u800cLLM\u80fd\u589e\u5f3aMAB\u7cfb\u7edf\u7684\u51b3\u7b56\u80fd\u529b\u3002\u5206\u6790\u4e86\u73b0\u6709\u7684LLM\u589e\u5f3a\u8001\u864e\u673a\u7cfb\u7edf\u548c\u8001\u864e\u673a\u589e\u5f3aLLM\u7cfb\u7edf\uff0c\u603b\u7ed3\u4e86\u8bbe\u8ba1\u65b9\u6cd5\u3001\u65b9\u6cd5\u8bba\u548c\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3aLLM\u4e0eMAB\u7684\u4ea4\u53c9\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6311\u6218\u548c\u4ee3\u8868\u6027\u53d1\u73b0\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u6587\u732e\u7684GitHub\u7d22\u5f15\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.12703", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12703", "abs": "https://arxiv.org/abs/2601.12703", "authors": ["Andrew Gordon", "Garrett Baker", "George Wang", "William Snell", "Stan van Wingerden", "Daniel Murfet"], "title": "Towards Spectroscopy: Susceptibility Clusters in Language Models", "comment": null, "summary": "Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $\u03c7_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts \"for similar reasons\" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8c31\u5b66\u539f\u7406\u7684\u795e\u7ecf\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u52a8\u6570\u636e\u5206\u5e03\u6d4b\u91cf\u6a21\u578b\u54cd\u5e94\uff0c\u8bc6\u522b\u51fa510\u4e2a\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\uff0c\u6db5\u76d6\u8bed\u6cd5\u6a21\u5f0f\u3001\u4ee3\u7801\u7ed3\u6784\u548c\u6570\u5b66\u7b26\u53f7\u7b49\u3002", "motivation": "\u53d7\u7269\u7406\u5b66\u4e2d\u5149\u8c31\u5b66\u539f\u7406\u542f\u53d1\uff0c\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ed3\u6784\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u5904\u7406\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u7684\u76f8\u4f3c\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u4e0a\u52a0\u6743\u7279\u5b9atoken\u6765\u6270\u52a8\u6570\u636e\u5206\u5e03\uff0c\u4f7f\u7528\u968f\u673a\u68af\u5ea6Langevin\u52a8\u529b\u5b66\u8ba1\u7b97\u654f\u611f\u5ea6\u03c7_xy\uff08\u7ec4\u4ef6\u7ea7\u53ef\u89c2\u6d4b\u91cf\u4e0e\u6270\u52a8\u4e4b\u95f4\u7684\u534f\u65b9\u5dee\uff09\uff0c\u5f00\u53d1\u57fa\u4e8e\u4f20\u5bfc\u5ea6\u7684\u805a\u7c7b\u7b97\u6cd5\u5206\u6790\u6a21\u578b\u54cd\u5e94\u3002", "result": "\u5728Pythia-14M\u6a21\u578b\u4e2d\u8bc6\u522b\u51fa510\u4e2a\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\uff0c\u6db5\u76d6\u8bed\u6cd5\u6a21\u5f0f\u3001\u4ee3\u7801\u7ed3\u6784\u3001\u6570\u5b66\u7b26\u53f7\u7b49\u3002\u4e0e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u6bd4\u8f83\uff0c50%\u7684\u805a\u7c7b\u4e0eSAE\u7279\u5f81\u5339\u914d\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8c31\u5b66\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63ed\u793a\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ed3\u6784\uff0c\u654f\u611f\u5ea6\u5206\u89e3\u4e3a\u6570\u636e\u5206\u5e03\u6a21\u5f0f\u4e4b\u548c\u7684\u7406\u8bba\u89e3\u91ca\u4e3a\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u8be5\u65b9\u6cd5\u4e0e\u73b0\u6709\u6280\u672f\u4e92\u8865\u3002"}}
{"id": "2601.13632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13632", "abs": "https://arxiv.org/abs/2601.13632", "authors": ["Zhiming Xue", "Sichen Zhao", "Yalun Qi", "Xianling Zeng", "Zihan Yu"], "title": "Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning", "comment": null, "summary": "With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.", "AI": {"tldr": "\u63d0\u51faRADR\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0e\u7ec4\u5408\u4f18\u5316\uff0c\u901a\u8fc7\u9884\u6d4b\u62e5\u5835\u98ce\u9669\u5b9e\u73b0\u52a8\u6001\u8def\u5f84\u89c4\u5212\uff0c\u5728\u4fdd\u6301\u8fd0\u8f93\u8ddd\u79bb\u4ec5\u589e\u52a02.1%\u7684\u60c5\u51b5\u4e0b\u51cf\u5c1119.3%\u7684\u62e5\u5835\u98ce\u9669\u66b4\u9732\u3002", "motivation": "\u7535\u5546\u5feb\u901f\u53d1\u5c55\u7ed9\u7269\u6d41\u7f51\u7edc\u5e26\u6765\u5de8\u5927\u538b\u529b\uff0c\u4f20\u7edf\u9759\u6001\u8def\u7531\u7b56\u7565\u65e0\u6cd5\u5e94\u5bf9\u4ea4\u901a\u62e5\u5835\u548c\u9700\u6c42\u6ce2\u52a8\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u52a8\u6001\u8def\u7531\u65b9\u6848\u3002", "method": "1) \u4f7f\u7528\u7a7a\u95f4\u805a\u7c7b\u65b9\u6cd5\u4ece\u79bb\u6563GPS\u6570\u636e\u6784\u5efa\u7269\u6d41\u62d3\u6251\u56fe\uff1b2) \u91c7\u7528GCN+GRU\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u53d6\u65f6\u7a7a\u7279\u5f81\u9884\u6d4b\u672a\u6765\u62e5\u5835\u98ce\u9669\uff1b3) \u5c06\u9884\u6d4b\u7ed3\u679c\u96c6\u6210\u5230\u52a8\u6001\u8fb9\u6743\u91cd\u673a\u5236\u4e2d\u8fdb\u884c\u8def\u5f84\u89c4\u5212\u3002", "result": "\u5728Smart Logistics Dataset 2024\u4e0a\u9a8c\u8bc1\uff0cRADR\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4f9b\u5e94\u94fe\u97e7\u6027\u3002\u5728\u9ad8\u62e5\u5835\u573a\u666f\u4e0b\uff0c\u6f5c\u5728\u62e5\u5835\u98ce\u9669\u66b4\u9732\u51cf\u5c1119.3%\uff0c\u8fd0\u8f93\u8ddd\u79bb\u4ec5\u589e\u52a02.1%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u914d\u9001\u6548\u7387\u4e0e\u8fd0\u8425\u5b89\u5168\uff0c\u4e3a\u52a8\u6001\u7269\u6d41\u8def\u7531\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12960", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12960", "abs": "https://arxiv.org/abs/2601.12960", "authors": ["Ainhoa Vivel-Couso", "Nicol\u00e1s Vila-Blanco", "Mar\u00eda J. Carreira", "Alberto Bugar\u00edn-Diz", "Inmaculada Tom\u00e1s", "Jose M. Alonso-Moral"], "title": "Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images", "comment": "This paper is a preliminary version of an accepted article in Information Systems Frontiers, Springer, Special Issue \"Explainability in Human-Centric AI\". Please cite the final published version of the paper, not this preprint. The final published version can be found at https://link.springer.com/article/10.1007/s10796-025-10682-3", "summary": "Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u4e0d\u900f\u660e\u4e0e\u900f\u660e\u65b9\u6cd5\u7684\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u6587\u672c\u89e3\u91ca\uff0c\u7ecf\u7259\u79d1\u4e13\u5bb6\u9a8c\u8bc1\u83b7\u5f97\u9ad8\u8bc4\u5206\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u533b\u7597\u4fdd\u5065\u4e2d\u7684\u5e94\u7528\u867d\u7136\u80fd\u5b9e\u73b0\u4e2a\u6027\u5316\u62a4\u7406\uff0c\u4f46\u7531\u4e8e\u6a21\u578b\u4e0d\u900f\u660e\u6027\u5f15\u53d1\u4fe1\u4efb\u95ee\u9898\u3002\u9700\u8981\u63d0\u9ad8\u900f\u660e\u5ea6\u4ee5\u5efa\u7acb\u4e34\u5e8a\u533b\u751f\u5bf9AI\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002", "method": "1. \u7ed3\u5408\u4e0d\u900f\u660e\u65b9\u6cd5\u548c\u900f\u660e\u65b9\u6cd5\u7684\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7cfb\u7edf\uff1b2. \u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\u4ea7\u751f\u4e34\u5e8a\u533b\u751f\u53cb\u597d\u7684\u6587\u672c\u89e3\u91ca\uff1b3. \u4e0e\u7259\u79d1\u4e13\u5bb6\u5408\u4f5c\u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u8bbe\u8ba1\u89e3\u91ca\uff1b4. \u4f7f\u7528\u95ee\u5377\u7531\u7259\u79d1\u4e13\u5bb6\u624b\u52a8\u9a8c\u8bc1\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\uff1b5. \u9075\u5faaALTAI\u6e05\u5355\u8fdb\u884c\u53ef\u4fe1\u5ea6\u81ea\u6211\u8bc4\u4f30\u3002", "result": "1. \u4e13\u5bb6\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u5e73\u5747\u8bc4\u5206\u4e3a4.77\u00b10.12\uff08\u6ee1\u52065\u5206\uff09\uff0c\u8868\u73b0\u4f18\u5f02\uff1b2. \u5728ALTAI\u6e05\u5355\u7684\u4e03\u4e2a\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u5f97\u5206\u4e3a4.40\u00b10.27\uff08\u6ee1\u52065\u5206\uff09\uff0c\u53ef\u4fe1\u5ea6\u8f83\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u6210\u529f\u63d0\u9ad8\u4e86\u7259\u79d1\u5e74\u9f84\u4f30\u8ba1\u7684\u900f\u660e\u5ea6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u589e\u5f3a\u4e86\u4e34\u5e8a\u533b\u751f\u5bf9AI\u7ed3\u679c\u7684\u4fe1\u4efb\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u533b\u7597AI\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.12704", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12704", "abs": "https://arxiv.org/abs/2601.12704", "authors": ["Yan Ma", "Yumeng Ren"], "title": "Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems", "comment": "30 pages,16 figures", "summary": "The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f84\u5411\u57fa\u51fd\u6570\u795e\u7ecf\u7f51\u7edc\uff08RBFNN\uff09\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08PIRBFNN\uff09\uff0c\u7528\u4e8e\u6c42\u89e3\u591a\u8d44\u4ea7\u671f\u6743\u5b9a\u4ef7\u7684Black-Scholes\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u548c\u7269\u7406\u7ea6\u675f\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u6c42\u89e3\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u591a\u8d44\u4ea7\u671f\u6743\u5b9a\u4ef7\u7684Black-Scholes\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\uff0c\u7279\u522b\u662f\u9762\u5bf9\u975e\u5149\u6ed1\u652f\u4ed8\u6761\u4ef6\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u51c6\u786e\u7684\u6570\u503c\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5f84\u5411\u57fa\u51fd\u6570\u914d\u7f6e\u6cd5\u548c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff0c\u63d0\u51faPIRBFNN\u65b9\u6cd5\uff0c\u5229\u7528PDE\u6b8b\u5dee\u6280\u672f\u81ea\u9002\u5e94\u4f18\u5316\u9690\u85cf\u795e\u7ecf\u5143\u5206\u5e03\uff0c\u540c\u65f6\u4f18\u5316\u7f51\u7edc\u7ed3\u6784\u548c\u9884\u6d4b\u671f\u6743\u4ef7\u683c\u3002", "result": "\u901a\u8fc7\u5355\u8d44\u4ea7\u6b27\u5f0f\u770b\u8dcc\u671f\u6743\u3001\u53cc\u8d44\u4ea7\u4ea4\u6362\u671f\u6743\u548c\u56db\u8d44\u4ea7\u7bee\u5b50\u770b\u6da8\u671f\u6743\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u51c6\u786e\u9ad8\u6548\u5904\u7406\u591a\u7ef4\u671f\u6743\u5b9a\u4ef7\u6a21\u578b\u3002", "conclusion": "PIRBFNN\u65b9\u6cd5\u6210\u529f\u7ed3\u5408\u4e86\u4f20\u7edf\u5f84\u5411\u57fa\u51fd\u6570\u914d\u7f6e\u6cd5\u548c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u70b9\uff0c\u4e3a\u91d1\u878d\u9886\u57dfPDE\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6c42\u89e3\u65b9\u6848\u3002"}}
{"id": "2601.13687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13687", "abs": "https://arxiv.org/abs/2601.13687", "authors": ["Zhichao Liang", "Satoshi Nakamura"], "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue", "comment": null, "summary": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.", "AI": {"tldr": "SocialMindChange\u662f\u4e00\u4e2a\u65b0\u7684\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u4e3b\u52a8\u6539\u53d8\u4ed6\u4eba\u5fc3\u7406\u72b6\u6001\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u3002\u6a21\u578b\u626e\u6f14\u89d2\u8272\u751f\u6210\u5bf9\u8bdd\u6765\u8fbe\u6210\u76ee\u6807\uff0c\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\u5f53\u524dLLM\u8868\u73b0\u6bd4\u4eba\u7c7b\u4f4e54.2%\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u5fc3\u7406\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u8ba9\u8bed\u8a00\u6a21\u578b\u5904\u4e8e\u88ab\u52a8\u89d2\u8272\uff0c\u53ea\u8bfb\u53d6\u573a\u666f\u5e76\u62a5\u544a\u5fc3\u7406\u72b6\u6001\u53d8\u5316\u3002\u4f46\u5728\u771f\u5b9e\u793e\u4ea4\u4e92\u52a8\u4e2d\uff0c\u5fc3\u7406\u7406\u8bba\u4e5f\u88ab\u7528\u4e8e\u4e3b\u52a8\u884c\u52a8\uff1a\u8bf4\u8bdd\u8005\u8ba1\u5212\u8bf4\u4ec0\u4e48\u6765\u6539\u53d8\u4ed6\u4eba\u7684\u5fc3\u7406\u72b6\u6001\u8f68\u8ff9\u4ee5\u8fbe\u5230\u76ee\u6807\u3002", "method": "\u5f15\u5165SocialMindChange\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u5b9e\u4f8b\u5b9a\u4e49\u5305\u542b4\u4e2a\u89d2\u8272\u7684\u793e\u4ea4\u60c5\u5883\u548c5\u4e2a\u8fde\u63a5\u573a\u666f\u3002\u6a21\u578b\u626e\u6f14\u4e00\u4e2a\u89d2\u8272\uff0c\u57285\u4e2a\u573a\u666f\u4e2d\u751f\u6210\u5bf9\u8bdd\u4ee5\u8fbe\u5230\u76ee\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6240\u6709\u53c2\u4e0e\u8005\u4e0d\u65ad\u53d8\u5316\u7684\u72b6\u6001\u4e00\u81f4\u3002\u4f7f\u7528\u7ed3\u6784\u5316\u56db\u6b65\u6846\u67b6\u6784\u5efa\u4e861,200\u4e2a\u793e\u4ea4\u60c5\u5883\uff0c\u6db5\u76d66,000\u4e2a\u573a\u666f\u548c\u8d85\u8fc790,000\u4e2a\u95ee\u9898\uff0c\u6bcf\u4e2a\u90fd\u7ecf\u8fc7\u771f\u5b9e\u6027\u548c\u8d28\u91cf\u9a8c\u8bc1\u3002", "result": "\u5bf910\u4e2a\u6700\u5148\u8fdb\u7684LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5b83\u4eec\u7684\u5e73\u5747\u8868\u73b0\u6bd4\u4eba\u7c7b\u8868\u73b0\u4f4e54.2%\u3002\u8fd9\u4e2a\u5dee\u8ddd\u8868\u660e\u5f53\u524dLLM\u5728\u957f\u671f\u8fde\u63a5\u4e92\u52a8\u4e2d\u7ef4\u6301\u548c\u6539\u53d8\u5fc3\u7406\u72b6\u6001\u8868\u5f81\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "SocialMindChange\u57fa\u51c6\u6d4b\u8bd5\u5c06\u5fc3\u7406\u7406\u8bba\u8bc4\u4f30\u4ece\u8ffd\u8e2a\u5fc3\u7406\u72b6\u6001\u6269\u5c55\u5230\u6539\u53d8\u5fc3\u7406\u72b6\u6001\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u52a8\u793e\u4ea4\u4e92\u52a8\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2601.12973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12973", "abs": "https://arxiv.org/abs/2601.12973", "authors": ["Shuanghong Huang", "Jinlei Xu", "Youchao Zhou", "Yanghao Zhou", "Xuan Zhao", "Chong Feng", "Wenxuan Zhang"], "title": "Pardon? Evaluating Conversational Repair in Large Audio-Language Models", "comment": null, "summary": "Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u7684\u4fee\u590d\u611f\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5206\u53ef\u56de\u7b54\u4e0e\u4e0d\u53ef\u56de\u7b54\u7684\u97f3\u9891\u8f93\u5165\uff0c\u5e76\u5f15\u5165EAR\u8bc4\u5206\u6765\u540c\u65f6\u8bc4\u4f30\u4efb\u52a1\u80fd\u529b\u548c\u4fee\u590d\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7b54\u6848\u51c6\u786e\u6027\u548c\u5bf9\u58f0\u5b66\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5047\u8bbe\u8f93\u5165\u5728\u8bed\u4e49\u4e0a\u603b\u662f\u53ef\u56de\u7b54\u7684\u3002\u7136\u800c\u5728\u771f\u5b9e\u4ea4\u4e92\u4e2d\uff0c\u7ecf\u5e38\u51fa\u73b0\u4fe1\u606f\u7f3a\u5931\u7684\u4e0d\u53ef\u56de\u7b54\u60c5\u51b5\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4fee\u590d\u611f\u77e5\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u901a\u8fc7\u8bed\u4e49-\u58f0\u5b66\u63a9\u7801\u534f\u8bae\u6784\u5efa\u6210\u5bf9\u7684\u8bc4\u4f30\u6761\u4ef6\uff08\u53ef\u56de\u7b54vs\u4e0d\u53ef\u56de\u7b54\uff09\u3002\u5b9a\u4e49\u4e86EAR\u8bc4\u5206\uff08\u53ef\u8bc4\u4f30\u610f\u8bc6\u548c\u4fee\u590d\u8bc4\u5206\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u8865\u507f\u6027\u6307\u6807\uff0c\u8054\u5408\u8bc4\u4f30\u53ef\u56de\u7b54\u6761\u4ef6\u4e0b\u7684\u4efb\u52a1\u80fd\u529b\u548c\u4e0d\u53ef\u56de\u7b54\u6761\u4ef6\u4e0b\u7684\u4fee\u590d\u884c\u4e3a\u3002", "result": "\u5728\u4e24\u4e2a\u53e3\u8bed\u95ee\u7b54\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u591a\u6570\u6a21\u578b\u5728\u8f93\u5165\u53ef\u56de\u7b54\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bc6\u522b\u8bed\u4e49\u4e0d\u53ef\u56de\u7b54\u6027\u548c\u542f\u52a8\u9002\u5f53\u7684\u5bf9\u8bdd\u4fee\u590d\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u7b54\u6848\u51c6\u786e\u6027\u4e0e\u5bf9\u8bdd\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524d\u4ee5\u51c6\u786e\u6027\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u5b9e\u8df5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5c06\u4e0d\u53ef\u56de\u7b54\u7684\u8f93\u5165\u89c6\u4e3a\u4fee\u590d\u548c\u6301\u7eed\u4ea4\u4e92\u7684\u7ebf\u7d22\uff0c\u8fdb\u884c\u53ef\u9760\u6027\u8bc4\u4f30\uff0c\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.12706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12706", "abs": "https://arxiv.org/abs/2601.12706", "authors": ["Sina Kazemdehbashi"], "title": "Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting", "comment": null, "summary": "Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.", "AI": {"tldr": "\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u91cd\u6784\u4e3a\u8d8b\u52bf\u9884\u6d4b\u548c\u6570\u503c\u9884\u6d4b\u4e24\u90e8\u5206\uff0c\u63d0\u51faTATS\u6a21\u578b\uff0c\u901a\u8fc7\u4e8c\u5143\u5206\u7c7b\u5668\u9884\u6d4b\u8d8b\u52bf\u5e76\u8c03\u6574LSTM/Bi-LSTM\u7684\u9884\u6d4b\u503c\uff0c\u5728\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff08\u4ece\u7ecf\u5178\u7edf\u8ba1\u6a21\u578b\u5230LSTM\u7b49\u795e\u7ecf\u7f51\u7edc\uff09\u901a\u5e38\u76f4\u63a5\u9884\u6d4b\u6570\u503c\uff0c\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528\u8d8b\u52bf\u4fe1\u606f\u3002\u4f5c\u8005\u8ba4\u4e3a\u5c06\u9884\u6d4b\u4efb\u52a1\u5206\u89e3\u4e3a\u8d8b\u52bf\u9884\u6d4b\u548c\u6570\u503c\u9884\u6d4b\u4e24\u90e8\u5206\uff0c\u5e76\u901a\u8fc7\u8d8b\u52bf\u4fe1\u606f\u8c03\u6574\u6570\u503c\u9884\u6d4b\uff0c\u53ef\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faTATS\u6a21\u578b\uff1a1) \u4f7f\u7528\u4e8c\u5143\u5206\u7c7b\u5668\u9884\u6d4b\u65f6\u95f4\u5e8f\u5217\u5728\u4e0b\u4e00\u65f6\u95f4\u6b65\u7684\u8d8b\u52bf\uff08\u4e0a\u6da8/\u4e0b\u8dcc\uff09\uff1b2) \u4f7f\u7528LSTM\u6216Bi-LSTM\u9884\u6d4b\u4e0b\u4e00\u65f6\u95f4\u6b65\u7684\u6570\u503c\uff1b3) \u57fa\u4e8e\u9884\u6d4b\u7684\u8d8b\u52bf\u8c03\u6574\u6570\u503c\u9884\u6d4b\u7ed3\u679c\u3002\u6a21\u578b\u5728\u9ec4\u91d1\u4ef7\u683c\u7b49\u6ce2\u52a8\u6027\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "TATS\u6a21\u578b\u5728\u9ec4\u91d1\u4ef7\u683c\u9884\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6LSTM\u548cBi-LSTM\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\u3002\u540c\u65f6\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u5982MSE\u548cMAE\u4e0d\u8db3\u4ee5\u5168\u9762\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u6027\u80fd\uff0c\u9700\u8981\u7ed3\u5408\u8d8b\u52bf\u68c0\u6d4b\u51c6\u786e\u7387\u6765\u8bc4\u4f30\u6a21\u578b\u6355\u6349\u8d8b\u52bf\u7684\u80fd\u529b\u3002", "conclusion": "\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u91cd\u6784\u4e3a\u8d8b\u52bf\u9884\u6d4b\u548c\u6570\u503c\u9884\u6d4b\u4e24\u90e8\u5206\u662f\u6709\u6548\u7684\uff0cTATS\u6a21\u578b\u901a\u8fc7\u8d8b\u52bf\u8c03\u6574\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002\u672a\u6765\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u8bc4\u4f30\u5e94\u8003\u8651\u7ed3\u5408\u8d8b\u52bf\u68c0\u6d4b\u51c6\u786e\u7387\u7b49\u66f4\u5168\u9762\u7684\u6307\u6807\u3002"}}
{"id": "2601.12974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12974", "abs": "https://arxiv.org/abs/2601.12974", "authors": ["Hongyang Ma", "Tiantian Gu", "Huaiyuan Sun", "Huilin Zhu", "Yongxin Wang", "Jie Li", "Wubin Sun", "Zeliang Lian", "Yinghong Zhou", "Yi Gao", "Shirui Wang", "Zhihui Tang"], "title": "Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios", "comment": "29 pages, 15 figures", "summary": "The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping \"Guideline Adherence\" versus \"Decision Quality\" reveals a prevalent \"High Efficacy, Low Safety\" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86SCMPE\u57fa\u51c6\uff0c\u8bc4\u4f30\u7259\u79d1LLMs\u4ece\u9759\u6001\u77e5\u8bc6\u4efb\u52a1\u5230\u52a8\u6001\u4e34\u5e8a\u5bf9\u8bdd\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u52a8\u6001\u4ea4\u4e92\u4e2d\u8868\u73b0\u4e0b\u964d\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u72b6\u6001\u8ddf\u8e2a\uff0c\u800c\u975e\u77e5\u8bc6\u4fdd\u7559\u3002", "motivation": "\u968f\u7740LLMs\u4ece\u88ab\u52a8\u77e5\u8bc6\u68c0\u7d22\u5668\u5411\u81ea\u4e3b\u4e34\u5e8a\u4ee3\u7406\u8f6c\u53d8\uff0c\u9700\u8981\u4ece\u9759\u6001\u51c6\u786e\u6027\u8bc4\u4f30\u8f6c\u5411\u52a8\u6001\u884c\u4e3a\u53ef\u9760\u6027\u8bc4\u4f30\u3002\u7259\u79d1\u9886\u57df\u9ad8\u8d28\u91cfAI\u5efa\u8bae\u80fd\u72ec\u7279\u5730\u8d4b\u80fd\u60a3\u8005\u53c2\u4e0e\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u8fd9\u4e00\u8fb9\u754c\u3002", "method": "\u63d0\u51fa\u4e86\u6807\u51c6\u5316\u4e34\u5e8a\u7ba1\u7406\u4e0e\u6027\u80fd\u8bc4\u4f30\uff08SCMPE\uff09\u57fa\u51c6\uff0c\u5168\u9762\u8bc4\u4f30\u4ece\u77e5\u8bc6\u5bfc\u5411\u8bc4\u4f30\uff08\u9759\u6001\u5ba2\u89c2\u4efb\u52a1\uff09\u5230\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u6a21\u62df\uff08\u591a\u8f6e\u6a21\u62df\u60a3\u8005\u4ea4\u4e92\uff09\u7684\u6027\u80fd\u3002\u5206\u6790\u4e86\u6307\u5357\u9075\u4ece\u6027\u4e0e\u51b3\u7b56\u8d28\u91cf\u7684\u5173\u7cfb\uff0c\u5e76\u91cf\u5316\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u5728\u9759\u6001\u5ba2\u89c2\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u719f\u7ec3\u5ea6\uff0c\u4f46\u5728\u52a8\u6001\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u6027\u80fd\u4e0b\u964d\u3002\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u52a8\u6001\u72b6\u6001\u8ddf\u8e2a\uff0c\u800c\u975e\u77e5\u8bc6\u4fdd\u7559\u3002\u53d1\u73b0\u901a\u7528\u6a21\u578b\u5b58\u5728\"\u9ad8\u6548\u6027\u3001\u4f4e\u5b89\u5168\u6027\"\u98ce\u9669\u3002RAG\u5728\u9759\u6001\u4efb\u52a1\u4e2d\u51cf\u5c11\u5e7b\u89c9\uff0c\u4f46\u5728\u52a8\u6001\u5de5\u4f5c\u6d41\u4e2d\u6548\u679c\u6709\u9650\u4e14\u5f02\u8d28\uff0c\u6709\u65f6\u751a\u81f3\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5916\u90e8\u77e5\u8bc6\u672c\u8eab\u65e0\u6cd5\u5f25\u8865\u63a8\u7406\u5dee\u8ddd\uff0c\u9700\u8981\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u3002\u8be5\u7814\u7a76\u5b9e\u8bc1\u7ed8\u5236\u4e86\u7259\u79d1LLMs\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u4e3a\u5f25\u5408\u6807\u51c6\u5316\u77e5\u8bc6\u4e0e\u5b89\u5168\u3001\u81ea\u4e3b\u4e34\u5e8a\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2601.13735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13735", "abs": "https://arxiv.org/abs/2601.13735", "authors": ["Hojin Kim", "Jaehyung Kim"], "title": "Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection", "comment": "15 pages, 4 figures", "summary": "Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u57fa\u4e8e\u6982\u7387\u7684\u7f6e\u4fe1\u5ea6\u6307\u6807\u4e3b\u8981\u6355\u6349\u8868\u9762\u6d41\u7545\u6027\u800c\u975e\u63a8\u7406\u903b\u8f91\u7ed3\u6784\uff0c\u63d0\u51fa\u65b0\u7684\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u80fd\u66f4\u597d\u8bc6\u522b\u63a8\u7406\u8d28\u91cf", "motivation": "\u6311\u6218\u5f53\u524d\u666e\u904d\u5047\u8bbe\uff1a\u6982\u7387\u7f6e\u4fe1\u5ea6\u6307\u6807\u80fd\u51c6\u786e\u53cd\u6620\u63a8\u7406\u8d28\u91cf\u3002\u7814\u7a76\u8005\u8d28\u7591\u8fd9\u4e9b\u6307\u6807\u662f\u5426\u771f\u6b63\u6355\u6349\u4e86\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb", "method": "\u5f15\u5165\u4e09\u7c7b\u6b65\u95f4\u56e0\u679c\u6270\u52a8\uff0c\u7cfb\u7edf\u6027\u5730\u7834\u574f\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4f46\u4fdd\u6301\u5c40\u90e8\u6d41\u7545\u6027\uff1b\u63d0\u51fa\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u6765\u663e\u5f0f\u9694\u79bb\u6b65\u95f4\u56e0\u679c\u4f9d\u8d56", "result": "\u5373\u4f7f\u4e25\u91cd\u5e72\u9884\uff08\u5982\u786c\u6ce8\u610f\u529b\u63a9\u7801\u963b\u6b62\u6a21\u578b\u5173\u6ce8\u5148\u524d\u63a8\u7406\u6b65\u9aa4\uff09\uff0c\u9009\u62e9\u51c6\u786e\u7387\u4ec5\u8f7b\u5fae\u4e0b\u964d\uff0c\u8bc1\u660e\u5f53\u524d\u6982\u7387\u6307\u6807\u5bf9\u903b\u8f91\u7ed3\u6784\u4e0d\u654f\u611f", "conclusion": "\u5f53\u524d\u6982\u7387\u6307\u6807\u4e3b\u8981\u6355\u6349\u8868\u9762\u6d41\u7545\u6027\u6216\u5206\u5e03\u5148\u9a8c\u800c\u975e\u903b\u8f91\u7ed3\u6784\uff0c\u63d0\u51fa\u7684\u5bf9\u6bd4\u56e0\u679c\u6307\u6807\u80fd\u5b9e\u73b0\u66f4\u5fe0\u5b9e\u7684\u8f93\u51fa\u9009\u62e9"}}
{"id": "2601.12979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12979", "abs": "https://arxiv.org/abs/2601.12979", "authors": ["Qingyu Lu", "Liang Ding", "Kanjian Zhang", "Jinxia Zhang", "Dacheng Tao"], "title": "The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check", "comment": "Under Review", "summary": "The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a \"bitter lesson\": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff1a\u5728\u5177\u8eab\u4ee3\u7406\u4e2d\u65e0\u6cd5\u5904\u7406\u65f6\u5e8f\u53cd\u9988\uff0c\u5728\u5de5\u5177\u8c03\u7528\u4e2d\u96be\u4ee5\u7ef4\u6301\u7b26\u53f7\u7cbe\u5ea6\uff0c\u9700\u8981\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u673a\u5236\u624d\u80fd\u6709\u6548", "motivation": "\u7814\u7a76\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u4f5c\u4e3a\u5b9e\u65f6\u4ee3\u7406\u4ea4\u4e92\u7684\u66ff\u4ee3\u65b9\u6848\u662f\u5426\u771f\u7684\u80fd\u5e26\u6765\u6709\u6548\u7684\u4ee3\u7406\u884c\u4e3a\uff0c\u800c\u975e\u4ec5\u4ec5\u63d0\u5347\u6548\u7387", "method": "\u5728Agentboard\u548cBFCL\u57fa\u51c6\u4e0a\u5168\u9762\u8bc4\u4f30dLLMs\u5728\u4e24\u79cd\u4ee3\u7406\u8303\u5f0f\u4e2d\u7684\u8868\u73b0\uff1a\u5177\u8eab\u4ee3\u7406\uff08\u9700\u8981\u957f\u65f6\u7a0b\u89c4\u5212\uff09\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff08\u9700\u8981\u7cbe\u786e\u683c\u5f0f\uff09\uff0c\u5e76\u5f15\u5165DiffuAgent\u591a\u4ee3\u7406\u8bc4\u4f30\u6846\u67b6", "result": "dLLMs\u65e0\u6cd5\u4f5c\u4e3a\u53ef\u9760\u7684\u4ee3\u7406\u9aa8\u5e72\uff1a\u5728\u5177\u8eab\u8bbe\u7f6e\u4e2d\u53cd\u590d\u5c1d\u8bd5\u5931\u8d25\uff0c\u65e0\u6cd5\u5728\u65f6\u5e8f\u53cd\u9988\u4e0b\u5206\u652f\uff1b\u5728\u5de5\u5177\u8c03\u7528\u8bbe\u7f6e\u4e2d\u65e0\u6cd5\u5728\u6269\u6563\u566a\u58f0\u4e0b\u7ef4\u6301\u7b26\u53f7\u7cbe\u5ea6\uff08\u5982\u4e25\u683c\u7684JSON\u6a21\u5f0f\uff09", "conclusion": "dLLMs\u5728\u975e\u56e0\u679c\u89d2\u8272\u4e2d\u6709\u6548\uff08\u5982\u8bb0\u5fc6\u603b\u7ed3\u548c\u5de5\u5177\u9009\u62e9\uff09\uff0c\u4f46\u9700\u8981\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u878d\u5165\u56e0\u679c\u3001\u7cbe\u786e\u548c\u903b\u8f91\u57fa\u7840\u7684\u63a8\u7406\u673a\u5236\u624d\u80fd\u9002\u7528\u4e8e\u4ee3\u7406\u4efb\u52a1"}}
{"id": "2601.12730", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12730", "abs": "https://arxiv.org/abs/2601.12730", "authors": ["Zhaochun Li", "Chen Wang", "Jionghao Bai", "Shisheng Cui", "Ge Lan", "Zhou Zhao", "Yue Wang"], "title": "Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off", "comment": null, "summary": "The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \\textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the \"luck\" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \\textbf{distribution-centric} perspective for RL, in which exploration is always guided by a \"better\" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.", "AI": {"tldr": "\u63d0\u51faDCPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u4e2d\u5fc3\u89c6\u89d2\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22-\u5229\u7528\u6743\u8861\u95ee\u9898\uff0c\u7528\u5206\u5e03\u7ea7\u6b63\u5219\u5316\u66ff\u4ee3\u6837\u672c\u7ea7\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5b9e\u73b0\u53ef\u63a7\u71b5\u548c\u9ad8\u6548\u63a2\u7d22\u3002", "motivation": "\u73b0\u6709GRPO\u65b9\u6cd5\u8bad\u7ec3\u504f\u5411\u5229\u7528\u9a71\u52a8\uff0c\u71b5\u5355\u8c03\u4e0b\u964d\uff0c\u63a2\u7d22\u80fd\u529b\u51cf\u5f31\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u591a\u4e3a\u6837\u672c\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u4f9d\u8d56\"\u5e78\u8fd0\"\u6837\u672c\uff0c\u7f3a\u4e4f\u5bf9\u7b56\u7565\u7684\u539f\u5219\u6027\u63a7\u5236\uff0c\u6548\u679c\u6709\u9650\u4e14\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u4e2d\u5fc3\u7b56\u7565\u4f18\u5316(DCPO)\uff0c\u5c06\u71b5\u8c03\u8282\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u7ea7\u6b63\u5219\u5316\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5bfc\u7b56\u7565\u671d\u5411\"\u66f4\u597d\"\u7684\u76ee\u6807\u5206\u5e03\uff0c\u5b9e\u73b0\u5b8c\u5168\u5728\u7b56\u7565\u4e0a\u7684\u53ef\u63a7\u71b5\uff0c\u65e0\u9700\u4ece\u5916\u90e8\u5206\u5e03\u91c7\u6837\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDCPO\u76f8\u6bd4GRPO\u5e73\u5747\u63d0\u5347\u7ea620%\u3002\u5b9e\u73b0\u4e86\u9ad8\u6548\u63a2\u7d22\u7684\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "DCPO\u7528\u5206\u5e03\u7ea7\u539f\u5219\u66ff\u4ee3\u6837\u672c\u7ea7\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4e3a\u53ef\u63a7\u63a2\u7d22\u548c\u66f4\u5f3a\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u7075\u6d3b\u6846\u67b6\u3002"}}
{"id": "2601.13752", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13752", "abs": "https://arxiv.org/abs/2601.13752", "authors": ["Chak Tou Leong", "Dingwei Chen", "Heming Xia", "Qingyu Yin", "Sunbowen Lee", "Jian Wang", "Wenjie Li"], "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering", "comment": "Working in progress", "summary": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.", "AI": {"tldr": "\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u5927\u63a8\u7406\u6a21\u578b\u7684\"\u63a8\u7406\u4fe1\u5ff5\"\u6765\u5851\u9020\u5176\u884c\u4e3a\uff0c\u65e0\u9700\u76d1\u7763\u63a8\u7406\u8f68\u8ff9\uff0c\u964d\u4f4e\u8bad\u7ec3\u6210\u672c", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8ba1\u7b97\u5197\u4f59\u6216\u63a8\u7406\u4e0d\u5fe0\u5b9e\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5f3a\u5316\u5b66\u4e60\u6216\u9ec4\u91d1\u6807\u51c6\u63a8\u7406\u8f68\u8ff9\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55", "method": "\u53d1\u73b0LRM\u5177\u6709\u6f5c\u5728\u7684\"\u63a8\u7406\u4fe1\u5ff5\"\uff0c\u53ef\u901a\u8fc7\u7b80\u5355logit\u63a2\u6d4b\u6355\u83b7\u3002\u63d0\u51faRELIEF\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u81ea\u6211\u6982\u5ff5\u4e0e\u76ee\u6807\u4fe1\u5ff5\u84dd\u56fe\u5bf9\u9f50\u6765\u5851\u9020\u884c\u4e3a\uff0c\u65e0\u9700\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u4ec5\u9700\u5728\u5408\u6210\u7684\u81ea\u53cd\u95ee\u7b54\u5bf9\u4e0a\u8fdb\u884c\u5fae\u8c03", "result": "\u5728\u6548\u7387\u548c\u5fe0\u5b9e\u6027\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRELIEF\u5339\u914d\u6216\u4f18\u4e8e\u884c\u4e3a\u76d1\u7763\u548c\u57fa\u4e8e\u504f\u597d\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u66f4\u4f4e\u3002\u5206\u6790\u9a8c\u8bc1\u4e86\u6539\u53d8\u6a21\u578b\u63a8\u7406\u4fe1\u5ff5\u80fd\u6709\u6548\u5851\u9020\u5176\u5b9e\u9645\u884c\u4e3a", "conclusion": "RELIEF\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u5185\u5728\u63a8\u7406\u4fe1\u5ff5\u6765\u5851\u9020LRM\u884c\u4e3a\uff0c\u65e0\u9700\u6602\u8d35\u7684\u63a8\u7406\u8f68\u8ff9\u76d1\u7763\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca"}}
{"id": "2601.12983", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12983", "abs": "https://arxiv.org/abs/2601.12983", "authors": ["Jesus-German Ortiz-Barajas", "Jonathan Tonglet", "Vivek Gupta", "Iryna Gurevych"], "title": "ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation", "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.", "AI": {"tldr": "ChartAttack\u6846\u67b6\u8bc4\u4f30MLLMs\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\u7684\u98ce\u9669\uff0c\u901a\u8fc7\u6ce8\u5165\u8bef\u5bfc\u5143\u7d20\u964d\u4f4e\u56fe\u8868QA\u51c6\u786e\u7387\u7ea620\u4e2a\u767e\u5206\u70b9", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLMs)\u7528\u4e8e\u81ea\u52a8\u5316\u56fe\u8868\u751f\u6210\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u6570\u636e\u5206\u6790\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u6ee5\u7528\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u88ab\u7528\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\u7684\u53ef\u80fd\u6027", "method": "\u63d0\u51faChartAttack\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u56fe\u8868\u8bbe\u8ba1\u4e2d\u6ce8\u5165\u8bef\u5bfc\u5143\u7d20\u6765\u8bf1\u5bfc\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u9519\u8bef\u89e3\u8bfb\uff1b\u521b\u5efaAttackViz\u6570\u636e\u96c6\uff0c\u5305\u542b\u5e26\u6709\u6709\u6548\u8bef\u5bfc\u5143\u7d20\u6807\u7b7e\u7684\u56fe\u8868\u89c4\u8303-QA\u5bf9", "result": "\u5728\u57df\u5185\u548c\u8de8\u57df\u8bbe\u7f6e\u4e2d\uff0cChartAttack\u663e\u8457\u964d\u4f4e\u4e86MLLM\u9605\u8bfb\u5668\u7684QA\u6027\u80fd\uff0c\u51c6\u786e\u7387\u5206\u522b\u5e73\u5747\u4e0b\u964d19.6\u548c14.9\u4e2a\u767e\u5206\u70b9\uff1b\u4eba\u7c7b\u7814\u7a76\u4e2d\u53c2\u4e0e\u8005\u51c6\u786e\u7387\u5e73\u5747\u4e0b\u964d20.2\u4e2a\u767e\u5206\u70b9", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728MLLM\u56fe\u8868\u751f\u6210\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u4e2d\u8feb\u5207\u9700\u8981\u52a0\u5f3a\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u8003\u8651"}}
{"id": "2601.12745", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12745", "abs": "https://arxiv.org/abs/2601.12745", "authors": ["Miao Ye", "Jing Cui", "Yuan huang", "Qian He", "Yong Wang", "Jiwen Zhang"], "title": "A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection", "comment": null, "summary": "Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of \"pre-training - graph prompting - fine-tuning\" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning \"pre-training\" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the \"graph prompting-fine-tuning\" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u65f6\u7a7a\u76f8\u5173\u7279\u5f81\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u5f02\u5e38\u68c0\u6d4b\u4e3b\u5e72\u7f51\u7edc\uff0c\u91c7\u7528\"\u9884\u8bad\u7ec3-\u56fe\u63d0\u793a-\u5fae\u8c03\"\u7684\u591a\u4efb\u52a1\u81ea\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u7528\u4e8e\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u591a\u65f6\u5e8f\u6a21\u6001\u6570\u636e\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u591a\u65f6\u5e8f\u6a21\u6001\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u65f6\u7a7a\u76f8\u5173\u7279\u5f81\u63d0\u53d6\u4e0d\u8db3\u3001\u5f02\u5e38\u6837\u672c\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u5f02\u5e38\u6837\u672c\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\uff0c\u9700\u8981\u9488\u5bf9WSN\u56fe\u7ed3\u6784\u6570\u636e\u7279\u70b9\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "1) \u57fa\u4e8e\u591a\u5c3a\u5ea6\u7b56\u7565\u548c\u6a21\u6001\u95f4\u878d\u5408\u65b9\u6cd5\u6539\u8fdbMamba\u6a21\u578b\uff0c\u7ed3\u5408\u53d8\u5206\u56fe\u5377\u79ef\u6a21\u5757\u8bbe\u8ba1\u5f02\u5e38\u68c0\u6d4b\u4e3b\u5e72\u7f51\u7edc\uff1b2) \u8bbe\u8ba1\u5305\u542b\u65e0\u8d1f\u5bf9\u6bd4\u5b66\u4e60\u3001\u9884\u6d4b\u548c\u91cd\u6784\u7684\u4e09\u5b50\u4efb\u52a1\u9884\u8bad\u7ec3\u65b9\u6cd5\uff1b3) \u91c7\u7528\"\u56fe\u63d0\u793a-\u5fae\u8c03\"\u673a\u5236\u6307\u5bfc\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u53c2\u6570\u5fae\u8c03\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u5b9e\u9645\u91c7\u96c6\u6570\u636e\u96c6\u4e0a\u7684F1\u6307\u6807\u5206\u522b\u8fbe\u523091.30%\u548c92.31%\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u68c0\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u53d6WSN\u591a\u8282\u70b9\u591a\u65f6\u5e8f\u6a21\u6001\u573a\u666f\u4e0b\u7684\u65f6\u7a7a\u76f8\u5173\u7279\u5f81\uff0c\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff0c\u63d0\u5347\u68c0\u6d4b\u6cdb\u5316\u6027\u80fd\uff0c\u4e3aWSN\u53ef\u9760\u8fd0\u884c\u63d0\u4f9b\u91cd\u8981\u4fdd\u969c\u3002"}}
{"id": "2601.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13761", "abs": "https://arxiv.org/abs/2601.13761", "authors": ["Shengda Fan", "Xuyan Ye", "Yankai Lin"], "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution", "comment": null, "summary": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.", "AI": {"tldr": "DARC\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u81ea\u6f14\u5316\u89e3\u8026\u6846\u67b6\uff0c\u901a\u8fc7\u96be\u5ea6\u6821\u51c6\u95ee\u9898\u751f\u6210\u548c\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u81ea\u6f14\u5316\u7684\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u81ea\u6f14\u5316\u6846\u67b6\u5b58\u5728\u4f18\u5316\u4e0d\u7a33\u5b9a\u95ee\u9898\uff1a1) \u63d0\u95ee\u8005\u4f9d\u8d56\u6c42\u89e3\u5668\u53cd\u9988\u7684\u975e\u5e73\u7a33\u76ee\u6807\uff1b2) \u6c42\u89e3\u5668\u4f7f\u7528\u81ea\u751f\u6210\u4f2a\u6807\u7b7e\u5bfc\u81f4\u7684\u5f15\u5bfc\u8bef\u5dee\u3002\u9700\u8981\u7a33\u5b9a\u81ea\u6f14\u5316\u8fc7\u7a0b\u3002", "method": "DARC\u91c7\u7528\u4e24\u9636\u6bb5\u89e3\u8026\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u63d0\u95ee\u8005\u6839\u636e\u660e\u786e\u96be\u5ea6\u7ea7\u522b\u548c\u5916\u90e8\u8bed\u6599\u5408\u6210\u96be\u5ea6\u6821\u51c6\u95ee\u9898\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u673a\u5236\u8bad\u7ec3\u6c42\u89e3\u5668\uff0c\u5176\u4e2d\u6587\u6863\u589e\u5f3a\u7684\u6559\u5e08\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u6765\u76d1\u7763\u65e0\u6587\u6863\u8bbf\u95ee\u7684\u5b66\u751f\u6c42\u89e3\u5668\u3002", "result": "DARC\u5177\u6709\u6a21\u578b\u65e0\u5173\u6027\uff0c\u57289\u4e2a\u63a8\u7406\u57fa\u51c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u534710.9\u4e2a\u70b9\uff0c\u6301\u7eed\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u63a5\u8fd1\u5168\u76d1\u7763\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "DARC\u901a\u8fc7\u89e3\u8026\u548c\u975e\u5bf9\u79f0\u81ea\u84b8\u998f\u6709\u6548\u7a33\u5b9a\u4e86\u81ea\u6f14\u5316\u8fc7\u7a0b\uff0c\u4e3a\u81ea\u6539\u8fdbAI\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.12995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12995", "abs": "https://arxiv.org/abs/2601.12995", "authors": ["Runxuan Liu", "Xianhao Ou", "Xinyan Ma", "Jiyuan Wang", "Jiafeng Liang", "Jiaqi Li", "Tao He", "Zheng Chu", "Rongchuan Mu", "Zekun Wang", "Baoxin Wang", "Dayong Wu", "Ming Liu", "Shijin Wang", "Guoping Hu", "Bing Qin"], "title": "Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models", "comment": null, "summary": "Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u56fe\u63a8\u7406\u8303\u5f0f(GRP)\u548cPASC-GRPO\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u56fe\u8868\u793a\u548c\u8fc7\u7a0b\u611f\u77e5\u9a8c\u8bc1\uff0c\u89e3\u51b3\u4f20\u7edf\u6587\u672c\u63a8\u7406\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u3001\u5956\u52b1\u653b\u51fb\u548c\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u4e3b\u8981\u751f\u6210\u7eaf\u6587\u672c\uff0c\u5bf9\u975e\u7ed3\u6784\u5316\u6570\u636e\u8fdb\u884c\u8bed\u4e49\u8bc4\u4f30\u4f1a\u9020\u6210\u8bad\u7ec3\u8ba1\u7b97\u74f6\u9888\u3002\u5c3d\u7ba1\u6709RLVR\u4f18\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u4ecd\u5b58\u5728\u76d1\u7763\u7c97\u7c92\u5ea6\u3001\u5956\u52b1\u653b\u51fb\u3001\u8bad\u7ec3\u6210\u672c\u9ad8\u548c\u6cdb\u5316\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u56fe\u63a8\u7406\u8303\u5f0f(GRP)\uff0c\u4f7f\u7528\u5e26\u6b65\u9aa4\u7ea7\u8ba4\u77e5\u6807\u7b7e\u7684\u56fe\u7ed3\u6784\u8868\u793a\u5b9e\u73b0\u7ed3\u6784\u5316\u7b26\u53f7\u63a8\u7406\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1PASC-GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bc4\u4f30\u66ff\u4ee3\u8bed\u4e49\u8bc4\u4f30\uff0c\u5229\u7528\u56fe\u7ed3\u6784\u7ed3\u679c\u5956\u52b1\u5b9e\u73b0\u8fc7\u7a0b\u611f\u77e5\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u5206\u5c42\u88c1\u526a\u4f18\u52bf\u4f30\u8ba1\u7f13\u89e3\u5956\u52b1\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002\u6570\u636e\u3001\u6a21\u578b\u548c\u4ee3\u7801\u5c06\u540e\u7eed\u53d1\u5e03\u3002", "conclusion": "GRP\u548cPASC-GRPO\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u8868\u793a\u548c\u8fc7\u7a0b\u611f\u77e5\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u672c\u63a8\u7406\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.12751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12751", "abs": "https://arxiv.org/abs/2601.12751", "authors": ["Manjish Pal"], "title": "A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining", "comment": null, "summary": "We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \\textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u7406\u8bba\u7684GNN\u8868\u8fbe\u80fd\u529b\u65b0\u6846\u67b6\uff0c\u5f15\u5165\u5b50\u7fa4\u4f53\u5e03\u5c14\u540c\u6784(SBI)\u6982\u5ff5\uff0c\u8d85\u8d8a\u73b0\u6709\u8868\u8fbe\u80fd\u529b\u5ea6\u91cf\uff0c\u8bc6\u522b\u5085\u91cc\u53f6\u5ea6\u3001\u7535\u8def\u7c7b\u548c\u5f71\u54cd\u529b\u4e3a\u516c\u5e73\u611f\u77e5GNN\u7684\u8868\u8fbe\u80fd\u529b\u5173\u952e\u969c\u788d\uff0c\u8bbe\u8ba1\u80fd\u5904\u7406\u590d\u6742\u5e03\u5c14\u51fd\u6570\u5b9a\u4e49\u5b50\u7fa4\u4f53\u7684\u516c\u5e73\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709GNN\u8868\u8fbe\u80fd\u529b\u5ea6\u91cf\uff08\u5982WL\u3001\u53cc\u8fde\u901a\u6027\u3001\u540c\u6001\u6846\u67b6\uff09\u65e0\u6cd5\u7cbe\u7ec6\u5206\u6790GNN\u6355\u83b7\u590d\u6742\u5b50\u7fa4\u4f53\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u516c\u5e73\u6027\u573a\u666f\u4e2d\u5904\u7406\u7531\u590d\u6742\u5e03\u5c14\u51fd\u6570\u5b9a\u4e49\u7684\u4ea4\u53c9\u5b50\u7fa4\u4f53\u65f6\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u7406\u8bba\u7684\u8868\u8fbe\u80fd\u529b\u6846\u67b6\uff0c\u5f15\u5165\u5b50\u7fa4\u4f53\u5e03\u5c14\u540c\u6784(SBI)\u6982\u5ff5\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u7535\u8def\u904d\u5386\u7684\u516c\u5e73\u7b97\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u7531\u9ad8\u590d\u6742\u5ea6\u5e03\u5c14\u51fd\u6570\uff08\u5982\u5947\u5076\u6027\uff09\u5b9a\u4e49\u7684\u5b50\u7fa4\u4f53\u3002", "result": "\u7406\u8bba\u8bc1\u660eSBI\u4e25\u683c\u5305\u542b\u73b0\u6709\u8868\u8fbe\u80fd\u529b\u5ea6\u91cf\uff0c\u8bc6\u522b\u5085\u91cc\u53f6\u5ea6\u3001\u7535\u8def\u7c7b(AC\u2070\u3001NC\u00b9)\u548c\u5f71\u54cd\u529b\u4e3a\u8868\u8fbe\u80fd\u529b\u5173\u952e\u969c\u788d\u3002\u5728\u771f\u5b9e\u4e16\u754c\u56fe\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u73b0\u6709\u65b9\u6cd5\u5931\u8d25\u7684\u4ea4\u53c9\u5b50\u7fa4\u4f53\u4e0a\u5b9e\u73b0\u4f4e\u516c\u5e73\u6027\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u9996\u4e2a\u9488\u5bf9\u516c\u5e73\u6027\u5b9a\u5236\u7684GNN\u8868\u8fbe\u80fd\u529b\u539f\u7406\u6027\u5904\u7406\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5206\u6790GNN\u6355\u83b7\u590d\u6742\u5b50\u7fa4\u4f53\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u8bbe\u8ba1\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u5904\u7406\u9ad8\u590d\u6742\u5ea6\u5e03\u5c14\u51fd\u6570\u5b9a\u4e49\u7684\u5b50\u7fa4\u4f53\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2601.13018", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13018", "abs": "https://arxiv.org/abs/2601.13018", "authors": ["Ghislain Dorian Tchuente Mondjo"], "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context", "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"", "summary": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.", "AI": {"tldr": "\u63d0\u51faBiAtt-BiRNN-HateXplain\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u548cBiRNN\u5c42\u6539\u8fdb\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u89e3\u91ca\u6027\u548c\u5206\u7c7b\u6027\u80fd\uff0c\u51cf\u5c11\u65e0\u610f\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u5b58\u5728\u89e3\u91ca\u4e0d\u4e00\u81f4\u95ee\u9898\uff1aHateXplain\u57fa\u51c6\u7684\u591a\u4efb\u52a1\u65b9\u6cd5\u4e2d\u9884\u6d4b\u6ce8\u610f\u529b\u53d8\u5316\u8f83\u5927\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u4e00\u81f4\u3001\u9884\u6d4b\u4e0d\u7a33\u5b9a\u548c\u5b66\u4e60\u56f0\u96be\u3002\u9700\u8981\u66f4\u900f\u660e\u3001\u8003\u8651\u6570\u636e\u5e8f\u5217\u7279\u6027\u7684\u89e3\u91ca\u6027\u6a21\u578b\u3002", "method": "\u63d0\u51faBiAtt-BiRNN-HateXplain\u6a21\u578b\uff1a\u7ed3\u5408\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(BiRNN)\u5c42\uff0c\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u540c\u65f6\u5904\u7406\u89e3\u91ca\u6027\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u8003\u8651\u8f93\u5165\u6570\u636e\u7684\u5e8f\u5217\u7279\u6027\u3002", "result": "\u5728HateXplain\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u68c0\u6d4b\u6027\u80fd\u660e\u663e\u63d0\u5347\uff0c\u89e3\u91ca\u6027\u6539\u5584\uff0c\u65e0\u610f\u504f\u89c1\u51cf\u5c11\u3002", "conclusion": "\u8be5\u6a21\u578b\u901a\u8fc7\u6539\u8fdb\u89e3\u91ca\u6027\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u6a21\u578b\u504f\u89c1\uff0c\u76f8\u6bd4\u590d\u6742\u7684\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u900f\u660e\u5b9e\u7528\u3002"}}
{"id": "2601.12775", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12775", "abs": "https://arxiv.org/abs/2601.12775", "authors": ["Yuta Hirabayashi", "Daisuke Matusoka", "Konobu Kimura"], "title": "Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks", "comment": null, "summary": "Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5c3a\u5ea6\u56fe\u795e\u7ecf\u7f51\u7edc\u768410\u5929\u5168\u7403\u6d77\u6d0b\u9884\u62a5\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5206\u8fa8\u7387\u7403\u9762\u7f51\u683c\u548c\u5927\u6c14\u53d8\u91cf\u8f93\u5165\uff0c\u63d0\u9ad8\u4e86\u77ed\u671f\u9884\u62a5\u7cbe\u5ea6\u548c\u591a\u5c3a\u5ea6\u6d77\u6d0b\u53d8\u7387\u7684\u8868\u5f81\u80fd\u529b\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u6d77\u6d0b\u6a21\u578b\u7814\u7a76\u8fdb\u5c55\u8fc5\u901f\uff0c\u4f46\u5e94\u7528\u4e8e\u5168\u7403\u6da1\u65cb\u89e3\u6790\u6d77\u6d0b\u9884\u62a5\u4ecd\u6709\u9650\u5236\u3002\u51c6\u786e\u8868\u5f81\u5e7f\u6cdb\u7a7a\u95f4\u5c3a\u5ea6\u4e0a\u7684\u6d77\u6d0b\u52a8\u529b\u5b66\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u91c7\u7528\u7f16\u7801\u5668-\u5904\u7406\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7403\u9762\u7f51\u683c\u6765\u6355\u6349\u591a\u5c3a\u5ea6\u6d77\u6d0b\u52a8\u529b\u5b66\u3002\u5c06\u8868\u9762\u5927\u6c14\u53d8\u91cf\u4e0e\u6d77\u6d0b\u72b6\u6001\u53d8\u91cf\u4e00\u8d77\u4f5c\u4e3a\u8282\u70b9\u8f93\u5165\uff0c\u4ee5\u901a\u8fc7\u8868\u5f81\u5927\u6c14\u5f3a\u8feb\u6765\u63d0\u9ad8\u77ed\u671f\u9884\u6d4b\u7cbe\u5ea6\u3002", "result": "\u901a\u8fc7\u8868\u9762\u52a8\u80fd\u8c31\u548c\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\uff0c\u6a21\u578b\u51c6\u786e\u8868\u5f81\u4e86\u5e7f\u6cdb\u7684\u7a7a\u95f4\u5c3a\u5ea6\u8303\u56f4\u3002\u5747\u65b9\u6839\u8bef\u5dee\u6bd4\u8f83\u663e\u793a\u77ed\u671f\u9884\u6d4b\u6280\u80fd\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u77ed\u671f\u9884\u62a5\u548c\u6539\u5584\u7684\u591a\u5c3a\u5ea6\u6d77\u6d0b\u52a8\u529b\u5b66\u8868\u5f81\uff0c\u663e\u793a\u51fa\u63a8\u8fdb\u6570\u636e\u9a71\u52a8\u3001\u6da1\u65cb\u89e3\u6790\u5168\u7403\u6d77\u6d0b\u9884\u62a5\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13024", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13024", "abs": "https://arxiv.org/abs/2601.13024", "authors": ["Chongyuan Dai", "Yaling Shen", "Jinpeng Hu", "Zihan Gao", "Jia Li", "Yishun Jiang", "Yaxiong Wang", "Liu Liu", "Zongyuan Ge"], "title": "Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses", "comment": "24 pages, 10 figures, 9 Tables", "summary": "Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \\underline{\\textsc{E}}licited \\underline{\\textsc{D}}istinct \\underline{\\textsc{A}}ffective \\underline{\\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.", "AI": {"tldr": "CEDAR\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u6355\u6349\u6587\u5316\u5f15\u53d1\u7684\u4e0d\u540c\u60c5\u611f\u53cd\u5e94\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u5bf9\u9f50\u80fd\u529b\uff0c\u7279\u522b\u662f\u60c5\u611f\u7406\u89e3\u65b9\u9762\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u5bf9\u9f50\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u5730\u7406\u4e8b\u5b9e\u3001\u793e\u4f1a\u4e60\u4fd7\u7b49\u9648\u8ff0\u6027\u77e5\u8bc6\uff0c\u65e0\u6cd5\u6355\u6349\u4e0d\u540c\u6587\u5316\u89c6\u89d2\u4e0b\u7684\u4e3b\u89c2\u89e3\u91ca\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u60c5\u611f\u5904\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u65b0\u7684\u6d41\u7a0b\uff1a\u5229\u7528LLM\u751f\u6210\u7684\u4e34\u65f6\u6807\u7b7e\u6765\u8bc6\u522b\u8de8\u6587\u5316\u60c5\u611f\u5dee\u5f02\u7684\u5b9e\u4f8b\uff0c\u7136\u540e\u901a\u8fc7\u4e25\u683c\u7684\u4eba\u5de5\u8bc4\u4f30\u83b7\u5f97\u53ef\u9760\u7684\u771f\u5b9e\u6807\u6ce8\u3002\u6784\u5efa\u4e86\u5305\u542b10,962\u4e2a\u5b9e\u4f8b\u7684\u57fa\u51c6\uff0c\u6db5\u76d67\u79cd\u8bed\u8a00\u548c14\u79cd\u7ec6\u7c92\u5ea6\u60c5\u611f\u7c7b\u522b\u3002", "result": "\u5bf917\u4e2a\u4ee3\u8868\u6027\u591a\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8bed\u8a00\u4e00\u81f4\u6027\u548c\u6587\u5316\u5bf9\u9f50\u4e4b\u95f4\u5b58\u5728\u5206\u79bb\uff0c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u57fa\u4e8e\u6587\u5316\u7684\u60c5\u611f\u7406\u89e3\u65b9\u9762\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002", "conclusion": "\u6587\u5316\u5bf9\u60c5\u611f\u5904\u7406\u6709\u6839\u672c\u6027\u5f71\u54cd\uff0c\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u5316\u5bf9\u9f50\u7684\u60c5\u611f\u7406\u89e3\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u5173\u6ce8\u4e3b\u89c2\u89e3\u91ca\u5dee\u5f02\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.12785", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12785", "abs": "https://arxiv.org/abs/2601.12785", "authors": ["Yuqi Li", "Kuiye Ding", "Chuanguang Yang", "Szu-Yu Chen", "Yingli Tian"], "title": "Distilling Time Series Foundation Models for Efficient Forecasting", "comment": "Accepted by ICASSP-2026", "summary": "Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.", "AI": {"tldr": "DistilTS\u662f\u9996\u4e2a\u4e13\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u6c34\u5e73\u52a0\u6743\u76ee\u6807\u548c\u65f6\u95f4\u5bf9\u9f50\u7b56\u7565\u89e3\u51b3\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u7279\u6b8a\u6311\u6218\uff0c\u5b9e\u73b0\u6a21\u578b\u538b\u7f29150\u500d\u3001\u63a8\u7406\u52a0\u901f6000\u500d\u7684\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u867d\u7136\u9884\u6d4b\u6027\u80fd\u5f3a\uff0c\u4f46\u53c2\u6570\u91cf\u5927\u5bfc\u81f4\u90e8\u7f72\u6210\u672c\u9ad8\u3002\u73b0\u6709\u7684\u901a\u7528\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u56e0\u4e3a\u5b58\u5728\u4efb\u52a1\u96be\u5ea6\u5dee\u5f02\u548c\u67b6\u6784\u5dee\u5f02\u7b49\u72ec\u7279\u6311\u6218\u3002", "method": "\u63d0\u51faDistilTS\u6846\u67b6\uff1a1) \u9488\u5bf9\u9884\u6d4b\u4efb\u52a1\u4e2d\u77ed\u671f\u6c34\u5e73\u5bb9\u6613\u4f18\u5316\u800c\u957f\u671f\u6c34\u5e73\u76d1\u7763\u5f31\u7684\u95ee\u9898\uff0c\u5f15\u5165\u6c34\u5e73\u52a0\u6743\u76ee\u6807\u5e73\u8861\u5404\u6c34\u5e73\u7684\u5b66\u4e60\uff1b2) \u9488\u5bf9\u67b6\u6784\u5dee\u5f02\u95ee\u9898\uff0c\u8bbe\u8ba1\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5bf9\u9f50\u673a\u5236\uff0c\u51cf\u5c11\u67b6\u6784\u4e0d\u5339\u914d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDistilTS\u5b9e\u73b0\u4e86\u4e0e\u5b8c\u6574\u5927\u5c0f\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u53c2\u6570\u51cf\u5c11\u9ad8\u8fbe1/150\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe6000\u500d\u3002", "conclusion": "DistilTS\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u72ec\u7279\u6311\u6218\uff0c\u4e3a\u9ad8\u6548\u90e8\u7f72\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13880", "abs": "https://arxiv.org/abs/2601.13880", "authors": ["Ye Tian", "Zihao Wang", "Onat Gungor", "Xiaoran Fan", "Tajana Rosing"], "title": "LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health", "comment": null, "summary": "Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.", "AI": {"tldr": "LifeAgentBench\u662f\u4e00\u4e2a\u5927\u89c4\u6a21QA\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u957f\u671f\u8de8\u7ef4\u5ea6\u751f\u6d3b\u65b9\u5f0f\u5065\u5eb7\u63a8\u7406\u4e2d\u7684\u80fd\u529b\uff0c\u5305\u542b22,573\u4e2a\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86LifeAgent\u4f5c\u4e3a\u5f3a\u57fa\u7ebf\u4ee3\u7406", "motivation": "\u4e2a\u6027\u5316\u6570\u5b57\u5065\u5eb7\u652f\u6301\u9700\u8981\u8de8\u5f02\u6784\u751f\u6d3b\u65b9\u5f0f\u4fe1\u53f7\u8fdb\u884c\u957f\u671f\u8de8\u7ef4\u5ea6\u63a8\u7406\uff0c\u4f46\u5f53\u524dLLM\u5728\u6b64\u573a\u666f\u4e0b\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u57fa\u51c6", "method": "1) \u6784\u5efaLifeAgentBench\u57fa\u51c6\uff0c\u5305\u542b22,573\u4e2a\u4ece\u57fa\u7840\u68c0\u7d22\u5230\u590d\u6742\u63a8\u7406\u7684\u95ee\u9898\uff1b2) \u63d0\u51fa\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6784\u5efa\u6d41\u7a0b\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\uff1b3) \u7cfb\u7edf\u8bc4\u4f3011\u4e2a\u9886\u5148LLM\uff1b4) \u63d0\u51faLifeAgent\u4ee3\u7406\uff0c\u96c6\u6210\u591a\u6b65\u8bc1\u636e\u68c0\u7d22\u4e0e\u786e\u5b9a\u6027\u805a\u5408", "result": "\u7cfb\u7edf\u8bc4\u4f30\u53d1\u73b0LLM\u5728\u957f\u671f\u805a\u5408\u548c\u8de8\u7ef4\u5ea6\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5173\u952e\u74f6\u9888\uff0c\u63d0\u51fa\u7684LifeAgent\u4ee3\u7406\u76f8\u6bd4\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\uff0c\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u73b0\u5b9e\u65e5\u5e38\u573a\u666f\u4e2d\u7684\u6f5c\u529b", "conclusion": "LifeAgentBench\u4e3a\u8bc4\u4f30LLM\u5728\u5065\u5eb7\u52a9\u624b\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u57fa\u51c6\uff0cLifeAgent\u4ee3\u7406\u5c55\u793a\u4e86\u89e3\u51b3\u957f\u671f\u8de8\u7ef4\u5ea6\u63a8\u7406\u95ee\u9898\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840"}}
{"id": "2601.13035", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13035", "abs": "https://arxiv.org/abs/2601.13035", "authors": ["Xu Xiaodan", "Hu Xiaolin"], "title": "SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification", "comment": "in progress", "summary": "Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \\textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\\% on FB15k-237 and +3.4\\% on YAGO3-10.", "AI": {"tldr": "SASA\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5206\u7c7b\u6027\u80fd\uff0c\u5728FB15k-237\u548cYAGO3-10\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b05.9%\u548c3.4%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u5e38\u5305\u542b\u4e0d\u53ef\u9760\u77e5\u8bc6\uff0c\u73b0\u6709\u4e09\u5143\u7ec4\u5206\u7c7b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1) \u5ffd\u7565\u4e0d\u540cKG\u7ec4\u4ef6\u95f4\u7684\u6709\u6548\u8bed\u4e49\u4ea4\u4e92\uff1b2) \u91c7\u7528\u5355\u4e00\u4e8c\u5143\u5206\u7c7b\u8bad\u7ec3\u76ee\u6807\u5bfc\u81f4\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSASA\u6846\u67b6\uff1a1) \u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u5c06\u4e09\u5143\u7ec4\u7f16\u7801\u4e3a\u89e3\u8026\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u5e76\u901a\u8fc7\u66f4\u6709\u6548\u7684\u4ea4\u4e92\u65b9\u5f0f\u878d\u5408\uff1b2) \u8bed\u4e49\u611f\u77e5\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u4f5c\u4e3a\u8f85\u52a9\u8bad\u7ec3\u76ee\u6807\uff0c\u8003\u8651\u5c40\u90e8\u548c\u5168\u5c40\u5c42\u9762\u7684\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1a\u5728FB15k-237\u4e0a\u51c6\u786e\u7387\u63d0\u53475.9%\uff0c\u5728YAGO3-10\u4e0a\u63d0\u53473.4%\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "SASA\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u4e09\u5143\u7ec4\u5206\u7c7b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5224\u522b\u80fd\u529b\u548c\u8bed\u4e49\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2601.12807", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12807", "abs": "https://arxiv.org/abs/2601.12807", "authors": ["Zixing Song", "Irwin King"], "title": "Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs", "comment": null, "summary": "The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.", "AI": {"tldr": "SIT-Graph\uff1a\u4e00\u79cd\u7528\u4e8e\u56fe\u5b66\u4e60\u7684\u534a\u76d1\u7763\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u8bad\u7ec3\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u63d0\u5347LLM\u5728\u56fe\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u56fe\u6307\u4ee4\u8c03\u4f18\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u5728\u793e\u4ea4\u7b49\u9886\u57df\u83b7\u53d6\u4e13\u5bb6\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u7f13\u6162\uff0c\u4e14\u672a\u80fd\u5145\u5206\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u4e2d\u8574\u542b\u7684\u6f5c\u5728\u76f8\u5173\u6027\u4fe1\u606f", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684SIT-Graph\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u8bad\u7ec3\uff1a1) \u5148\u7528\u6807\u8bb0\u8282\u70b9\u8fdb\u884c\u521d\u59cb\u6307\u4ee4\u8c03\u4f18\uff1b2) \u4e3a\u672a\u6807\u8bb0\u8282\u70b9\u751f\u6210\u7f6e\u4fe1\u5ea6\u8fc7\u6ee4\u7684\u4f2a\u54cd\u5e94\uff1b3) \u7b56\u7565\u6027\u5730\u6269\u5145\u6570\u636e\u96c6\u8fdb\u884c\u4e0b\u4e00\u8f6e\u8c03\u4f18\uff1b4) \u8fed\u4ee3\u4f18\u5316\u4f7fLLM\u4e0e\u5e95\u5c42\u8282\u70b9\u76f8\u5173\u6027\u5bf9\u9f50", "result": "\u5c06SIT-Graph\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684\u56fe\u6307\u4ee4\u8c03\u4f18\u65b9\u6cd5\u4e2d\uff0c\u5728\u6587\u672c\u5c5e\u6027\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5728\u4f4e\u6807\u7b7e\u6bd4\u4f8b\u8bbe\u7f6e\u4e0b\u83b7\u5f97\u8d85\u8fc720%\u7684\u6539\u8fdb", "conclusion": "SIT-Graph\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u6307\u4ee4\u8c03\u4f18\u4e2d\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u672a\u6807\u8bb0\u8282\u70b9\u7684\u6f5c\u5728\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u56fe\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6027\u80fd"}}
{"id": "2601.13887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13887", "abs": "https://arxiv.org/abs/2601.13887", "authors": ["Hong Su"], "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.", "AI": {"tldr": "HSC\u662f\u4e00\u4e2a\u53d7\u4eba\u7c7b\u542f\u53d1\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u8fc7\u7a0b\uff0c\u5f3a\u8c03\u901a\u8fc7\u884c\u52a8\u81ea\u52a8\u6539\u8fdb\u5185\u90e8\u63a8\u7406\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u4f9d\u8d56\u6587\u672c\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u5f00\u653e\u52a8\u6001\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3001\u63a8\u7406\u7ed3\u679c\u9a8c\u8bc1\u548c\u6709\u6548\u64cd\u4f5c\u3002\u9700\u8981\u66f4\u63a5\u8fd1\u4eba\u7c7b\u667a\u80fd\u7684\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4eba\u7c7b\u6a21\u62df\u8ba1\u7b97\uff08HSC\uff09\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u5efa\u6a21\u4e3a\u5305\u542b\u601d\u8003\u3001\u884c\u52a8\u3001\u5b66\u4e60\u3001\u53cd\u601d\u548c\u6d3b\u52a8\u8c03\u5ea6\u7684\u8fde\u7eed\u95ed\u73af\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002\u5f3a\u8c03\u4e3b\u52a8\u53c2\u4e0e\u548c\u884c\u52a8\u9a71\u52a8\u7684\u81ea\u52a8\u6539\u8fdb\uff0c\u5e76\u6574\u5408\u4eba\u7c7b\u5e38\u7528\u601d\u7ef4\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4eba\u7c7b\u6a21\u62df\u7b56\u7565\u65e0\u6cd5\u4ec5\u4ece\u8bed\u8a00\u6750\u6599\u4e2d\u5b8c\u5168\u5b66\u4e60\uff0c\u4eba\u7c7b\u5f0f\u63a8\u7406\u8fc7\u7a0b\u548c\u57fa\u4e8e\u884c\u52a8\u7684\u63a8\u7406\u65b9\u6cd5\u5bf9\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u9002\u5e94\u548c\u6709\u6548\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "HSC\u6846\u67b6\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5f3a\u8c03\u884c\u52a8\u9a71\u52a8\u7684\u81ea\u52a8\u6539\u8fdb\u548c\u4eba\u7c7b\u601d\u7ef4\u7b56\u7565\u7684\u6574\u5408\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u5f3a\u5927\u7684\u9002\u5e94\u6027\u667a\u80fd\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.13044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13044", "abs": "https://arxiv.org/abs/2601.13044", "authors": ["Warit Sirichotedumrong", "Adisai Na-Thalang", "Potsawee Manakul", "Pittawat Taveekitworachai", "Sittipong Sripaisarnmongkol", "Kunat Pipatanakul"], "title": "Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition", "comment": "Models and datasets are publicly available on https://huggingface.co/collections/typhoon-ai/typhoon-asr-technical-report ; Project Page: https://opentyphoon.ai/model/typhoon-asr-realtime", "summary": "Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.", "AI": {"tldr": "Typhoon ASR Real-time\u662f\u4e00\u4e2a115M\u53c2\u6570\u7684FastConformer-Transducer\u6a21\u578b\uff0c\u7528\u4e8e\u4f4e\u5ef6\u8fdf\u6cf0\u8bed\u8bed\u97f3\u8bc6\u522b\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u5b9e\u73b0\u4e0eWhisper Large-v3\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u964d\u4f4e45\u500d\u3002", "motivation": "\u5f53\u524d\u6cf0\u8bedASR\u9886\u57df\u88ab\u79bb\u7ebf\u67b6\u6784\u4e3b\u5bfc\uff0c\u7f3a\u4e4f\u9ad8\u6548\u7684\u6d41\u5f0f\u89e3\u51b3\u65b9\u6848\u3002\u867d\u7136Whisper\u7b49\u5927\u578b\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u5728\u79bb\u7ebf\u8f6c\u5f55\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u9ad8\u5ef6\u8fdf\u4e0d\u9002\u7528\u4e8e\u6d41\u5f0f\u5e94\u7528\u3002", "method": "1) \u5f00\u53d1115M\u53c2\u6570\u7684FastConformer-Transducer\u6a21\u578b\u7528\u4e8e\u4f4e\u5ef6\u8fdf\u6cf0\u8bed\u8bc6\u522b\uff1b2) \u8bbe\u8ba1\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u6d41\u7a0b\uff0c\u89e3\u51b3\u6cf0\u8bed\u8f6c\u5f55\u4e2d\u7684\u7cfb\u7edf\u6b67\u4e49\uff1b3) \u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4f0a\u68ee\u65b9\u8a00\u9002\u914d\uff1b4) \u53d1\u5e03Typhoon ASR Benchmark\u6807\u51c6\u5316\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "result": "\u7d27\u51d1\u6a21\u578b\u76f8\u6bd4Whisper Large-v3\u8ba1\u7b97\u6210\u672c\u964d\u4f4e45\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u6587\u672c\u89c4\u8303\u5316\u89e3\u51b3\u4e86\u6cf0\u8bed\u8f6c\u5f55\u4e2d\u7684\u7cfb\u7edf\u6b67\u4e49\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6570\u5b57\u53d1\u97f3\u548c\u91cd\u590d\u6807\u8bb0\u3002\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6210\u529f\u9002\u914d\u4f0a\u68ee\u65b9\u8a00\u540c\u65f6\u4fdd\u6301\u4e2d\u592e\u6cf0\u8bed\u6027\u80fd\u3002", "conclusion": "\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u53ef\u4ee5\u4e0e\u6a21\u578b\u7f29\u653e\u4ea7\u751f\u76f8\u540c\u7684\u5f71\u54cd\u6548\u679c\u3002Typhoon ASR Real-time\u586b\u8865\u4e86\u6cf0\u8bed\u6d41\u5f0fASR\u7684\u5173\u952e\u7a7a\u767d\uff0c\u5e76\u901a\u8fc7\u53d1\u5e03\u6807\u51c6\u5316\u57fa\u51c6\u6570\u636e\u96c6\u89e3\u51b3\u4e86\u6cf0\u8bedASR\u7684\u53ef\u91cd\u590d\u6027\u6311\u6218\u3002"}}
{"id": "2601.12816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12816", "abs": "https://arxiv.org/abs/2601.12816", "authors": ["Ishir Garg", "Neel Kolhe", "Andy Peng", "Rohan Gopalam"], "title": "Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning", "comment": null, "summary": "Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.", "AI": {"tldr": "\u63d0\u51faFOPNG\u4f18\u5316\u5668\uff0c\u901a\u8fc7Fisher\u6b63\u4ea4\u6295\u5f71\u7ea6\u675f\u53c2\u6570\u66f4\u65b0\uff0c\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5728\u8fde\u7eed\u5b66\u4e60\u4efb\u52a1\u4e2d\u4fdd\u6301\u65e7\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u8fde\u7eed\u5b66\u4e60\u7684\u5173\u952e\u6311\u6218\u662f\u5728\u5b66\u4e60\u65b0\u4efb\u52a1\u65f6\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u65e7\u4efb\u52a1\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6b27\u51e0\u91cc\u5f97\u53c2\u6570\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\u4e0b\u7684\u7edf\u4e00\u7406\u8bba\u3002", "method": "\u63d0\u51faFisher-Orthogonal Projected Natural Gradient Descent (FOPNG)\u4f18\u5316\u5668\uff0c\u5c06\u68af\u5ea6\u6295\u5f71\u5230\u5148\u524d\u4efb\u52a1\u68af\u5ea6\u7684Fisher\u6b63\u4ea4\u8865\u7a7a\u95f4\uff0c\u5728\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\u4e0b\u7edf\u4e00\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u548c\u6b63\u4ea4\u68af\u5ea6\u65b9\u6cd5\u3002", "result": "\u5728Permuted-MNIST\u3001Split-MNIST\u3001Rotated-MNIST\u3001Split-CIFAR10\u548cSplit-CIFAR100\u7b49\u6807\u51c6\u8fde\u7eed\u5b66\u4e60\u57fa\u51c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "conclusion": "FOPNG\u901a\u8fc7Fisher\u6b63\u4ea4\u7ea6\u675f\u63d0\u4f9b\u53c2\u6570\u66f4\u65b0\u4e0d\u53d8\u6027\uff0c\u4fdd\u8bc1\u5728Fisher\u5ea6\u91cf\u4e0b\u7684\u4e0b\u964d\uff0c\u6709\u6548\u4fdd\u62a4\u5148\u524d\u4efb\u52a1\u8f93\u51fa\uff0c\u4e3a\u8fde\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13904", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13904", "abs": "https://arxiv.org/abs/2601.13904", "authors": ["Jaeyoung Moon", "Youjin Choi", "Yucheon Park", "David Melhart", "Georgios N. Yannakakis", "Kyung-Joong Kim"], "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation", "comment": "CHI '26 Accepted paper", "summary": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.", "AI": {"tldr": "PREFAB\u662f\u4e00\u79cd\u4f4e\u6210\u672c\u56de\u987e\u6027\u81ea\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5168\u65f6\u6bb5\u6807\u6ce8\u6765\u51cf\u8f7b\u6807\u6ce8\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u6807\u6ce8\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u5168\u65f6\u6bb5\u60c5\u611f\u72b6\u6001\u6807\u6ce8\u65b9\u6cd5\u8017\u65f6\u3001\u8ba4\u77e5\u8d1f\u8377\u9ad8\u3001\u6613\u75b2\u52b3\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4f4e\u6210\u672c\u6807\u6ce8\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5cf0\u7ec8\u6cd5\u5219\u548c\u60c5\u611f\u5e8f\u6570\u8868\u793a\uff0c\u91c7\u7528\u504f\u597d\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u76f8\u5bf9\u60c5\u611f\u53d8\u5316\uff0c\u6307\u5bfc\u6807\u6ce8\u8005\u4ec5\u6807\u6ce8\u9009\u5b9a\u7247\u6bb5\uff0c\u5176\u4f59\u90e8\u5206\u63d2\u503c\uff0c\u5e76\u5f15\u5165\u9884\u89c8\u673a\u5236\u63d0\u4f9b\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3002", "result": "PREFAB\u5728\u5efa\u6a21\u60c5\u611f\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51cf\u8f7b\u4e86\u5de5\u4f5c\u8d1f\u62c5\uff08\u6709\u6761\u4ef6\u5730\u51cf\u8f7b\u65f6\u95f4\u8d1f\u62c5\uff09\uff0c\u63d0\u9ad8\u4e86\u6807\u6ce8\u8005\u4fe1\u5fc3\u4e14\u672a\u964d\u4f4e\u6807\u6ce8\u8d28\u91cf\u3002", "conclusion": "PREFAB\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u6210\u672c\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u805a\u7126\u60c5\u611f\u53d8\u5316\u533a\u57df\u800c\u975e\u5168\u65f6\u6bb5\u6807\u6ce8\uff0c\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u8f7b\u6807\u6ce8\u8d1f\u62c5\u3002"}}
{"id": "2601.13050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13050", "abs": "https://arxiv.org/abs/2601.13050", "authors": ["Lars Kl\u00f6ser", "Mika Beele", "Bodo Kraft"], "title": "Profiling German Text Simplification with Interpretable Model-Fingerprints", "comment": "Presented at 2nd International Conference on Explainable AI for Neural and Symbolic Systems", "summary": "While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Simplification Profiler\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u751f\u6210\u6587\u672c\u7b80\u5316\u6a21\u578b\u7684\u591a\u7ef4\u53ef\u89e3\u91ca\u6307\u7eb9\uff0c\u901a\u8fc7\u6a21\u578b\u6307\u7eb9\u8bc6\u522b\u4e0d\u540c\u914d\u7f6e\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9LLM\u6587\u672c\u7b80\u5316\u884c\u4e3a\u8fdb\u884c\u5168\u9762\u3001\u9ad8\u6548\u3001\u53ef\u590d\u73b0\u8bca\u65ad\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u8bed\u8a00\u73af\u5883\u4e2d\uff0c\u9700\u8981\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u4eba\u5de5\u504f\u597d\u76f8\u5173\u5ea6\u91cf\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1Simplification Profiler\u8bca\u65ad\u5de5\u5177\u5305\uff0c\u751f\u6210\u7b80\u5316\u6587\u672c\u7684\u591a\u7ef4\u53ef\u89e3\u91ca\u6307\u7eb9\uff1b\u901a\u8fc7\u7ebf\u6027\u5206\u7c7b\u5668\u8bc6\u522b\u4e0d\u540c\u6a21\u578b\u914d\u7f6e\uff0c\u9a8c\u8bc1\u6307\u6807\u5bf9\u6a21\u578b\u7279\u6027\u7684\u654f\u611f\u6027\uff1b\u4f7f\u7528\u5143\u8bc4\u4f30\u65b9\u6cd5\u907f\u514d\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u3002", "result": "\u5b8c\u6574\u7279\u5f81\u96c6\u8fbe\u523071.9%\u7684\u5206\u7c7bF1\u5206\u6570\uff0c\u6bd4\u7b80\u5355\u57fa\u7ebf\u63d0\u9ad848\u4e2a\u767e\u5206\u70b9\u4ee5\u4e0a\uff1b\u80fd\u591f\u533a\u5206\u63d0\u793a\u7b56\u7565\u7684\u9ad8\u5c42\u884c\u4e3a\u53d8\u5316\u548c\u63d0\u793a\u5de5\u7a0b\u7684\u7ec6\u7c92\u5ea6\u53d8\u5316\uff0c\u5305\u62ecfew-shot\u793a\u4f8b\u3002", "conclusion": "Simplification Profiler\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u3001\u53ef\u64cd\u4f5c\u7684\u5206\u6790\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u6709\u6548\u3001\u771f\u6b63\u81ea\u9002\u5e94\u7684\u6587\u672c\u7b80\u5316\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u3002"}}
{"id": "2601.13969", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13969", "abs": "https://arxiv.org/abs/2601.13969", "authors": ["Joaqu\u00edn Polonuer", "Lucas Vittor", "I\u00f1aki Arango", "Ayush Noori", "David A. Clifton", "Luciano Del Corro", "Marinka Zitnik"], "title": "Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval", "comment": null, "summary": "Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.", "AI": {"tldr": "ARK\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5668\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u5e7f\u5ea6-\u6df1\u5ea6\u6743\u8861\uff0c\u4f7f\u7528\u5168\u5c40\u641c\u7d22\u548c\u90bb\u57df\u63a2\u7d22\u4e24\u79cd\u64cd\u4f5c\uff0c\u65e0\u9700\u4f9d\u8d56\u8106\u5f31\u7684\u79cd\u5b50\u9009\u62e9\u6216\u9884\u8bbe\u8df3\u6570\u6df1\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u5668\u8986\u76d6\u9762\u5e7f\u4f46\u6df1\u5ea6\u4e0d\u8db3\uff0c\u800c\u57fa\u4e8e\u904d\u5386\u7684\u65b9\u6cd5\u4f9d\u8d56\u79cd\u5b50\u8282\u70b9\u9009\u62e9\uff0c\u5f53\u67e5\u8be2\u6d89\u53ca\u591a\u4e2a\u5b9e\u4f53\u548c\u5173\u7cfb\u65f6\u5bb9\u6613\u5931\u8d25\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u9002\u5e94\u5e73\u8861\u5e7f\u5ea6\u641c\u7d22\u548c\u6df1\u5ea6\u904d\u5386\u7684\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "ARK\u91c7\u7528\u4ee3\u7406\u5f0f\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5668\uff0c\u8ba9\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e24\u79cd\u64cd\u4f5c\u5de5\u5177\u63a7\u5236\u68c0\u7d22\u8fc7\u7a0b\uff1a1) \u5168\u5c40\u8bcd\u6cd5\u641c\u7d22\uff08\u5e7f\u5ea6\u5bfc\u5411\uff09\uff0c2) \u5355\u8df3\u90bb\u57df\u63a2\u7d22\uff08\u6df1\u5ea6\u5bfc\u5411\uff09\u3002\u8fd9\u4e24\u79cd\u64cd\u4f5c\u53ef\u4ee5\u7ec4\u5408\u6210\u591a\u8df3\u904d\u5386\u3002ARK\u4ea4\u66ff\u4f7f\u7528\u5e7f\u5ea6\u53d1\u73b0\u548c\u6df1\u5ea6\u6269\u5c55\uff0c\u65e0\u9700\u4f9d\u8d56\u79cd\u5b50\u9009\u62e9\u3001\u9884\u8bbe\u8df3\u6570\u6df1\u5ea6\u6216\u68c0\u7d22\u8bad\u7ec3\u3002", "result": "\u5728STaRK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cARK\u8fbe\u523059.1%\u7684\u5e73\u5747Hit@1\u548c67.4\u7684\u5e73\u5747MRR\uff0c\u6bd4\u57fa\u4e8e\u68c0\u7d22\u548c\u4ee3\u7406\u5f0f\u65e0\u8bad\u7ec3\u65b9\u6cd5\u5206\u522b\u63d0\u5347\u9ad8\u8fbe31.4%\u7684Hit@1\u548c28.0%\u7684MRR\u3002\u901a\u8fc7\u4ece\u5927\u578b\u6559\u5e08\u6a21\u578b\u84b8\u998f\u52308B\u6a21\u578b\uff0c\u5728AMAZON\u3001MAG\u548cPRIME\u6570\u636e\u96c6\u4e0a\u5206\u522b\u6bd4\u57fa\u78408B\u6a21\u578b\u63d0\u5347+7.0\u3001+26.6\u548c+13.5\u4e2a\u7edd\u5bf9\u767e\u5206\u70b9\u7684Hit@1\uff0c\u540c\u65f6\u4fdd\u7559\u9ad8\u8fbe98.5%\u7684\u6559\u5e08\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "ARK\u901a\u8fc7\u81ea\u9002\u5e94\u5e73\u8861\u5e7f\u5ea6\u641c\u7d22\u548c\u6df1\u5ea6\u904d\u5386\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u6027\u80fd\uff0c\u5176\u65e0\u6807\u7b7e\u6a21\u4eff\u84b8\u998f\u65b9\u6cd5\u80fd\u6709\u6548\u5c06\u5927\u578b\u6559\u5e08\u6a21\u578b\u7684\u68c0\u7d22\u80fd\u529b\u8f6c\u79fb\u5230\u8f83\u5c0f\u6a21\u578b\u4e2d\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u63d0\u4f9b\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13099", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13099", "abs": "https://arxiv.org/abs/2601.13099", "authors": ["Abdellah El Mekki", "Samar M. Magdy", "Houdaifa Atou", "Ruwa AbuHweidi", "Baraah Qawasmeh", "Omer Nacar", "Thikra Al-hibiri", "Razan Saadie", "Hamzah Alsayadi", "Nadia Ghezaiel Hammouda", "Alshima Alkhazimi", "Aya Hamod", "Al-Yas Al-Ghafri", "Wesam El-Sayed", "Asila Al sharji", "Mohamad Ballout", "Anas Belfathi", "Karim Ghaddar", "Serry Sibaee", "Alaa Aoun", "Areej Asiri", "Lina Abureesh", "Ahlam Bashiti", "Majdal Yousef", "Abdulaziz Hafiz", "Yehdih Mohamed", "Emira Hamedtou", "Brakehe Brahim", "Rahaf Alhamouri", "Youssef Nafea", "Aya El Aatar", "Walid Al-Dhabyani", "Emhemed Hamed", "Sara Shatnawi", "Fakhraddin Alwajih", "Khalid Elkhidir", "Ashwag Alasmari", "Abdurrahman Gerrio", "Omar Alshahri", "AbdelRahim A. Elmadany", "Ismail Berrada", "Amir Azad Adli Alkathiri", "Fadi A Zaraket", "Mustafa Jarrar", "Yahya Mohamed El Hadj", "Hassan Alhuzali", "Muhammad Abdul-Mageed"], "title": "Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs", "comment": "Project resources will be available here: https://github.com/UBC-NLP/Alexandria", "summary": "Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \\textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.", "AI": {"tldr": "Alexandria\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u793e\u533a\u9a71\u52a8\u7684\u4eba\u5de5\u7ffb\u8bd1\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u673a\u5668\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u8986\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u300111\u4e2a\u9ad8\u5f71\u54cd\u529b\u9886\u57df\uff0c\u5305\u542b\u57ce\u5e02\u7ea7\u5143\u6570\u636e\u548c\u6027\u522b\u914d\u7f6e\u6807\u6ce8\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u662f\u9ad8\u5ea6\u53cc\u8a00\u5236\u7684\u8bed\u8a00\uff0c\u65e5\u5e38\u4ea4\u6d41\u591a\u4f7f\u7528\u65b9\u8a00\u800c\u975e\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\uff0c\u4f46\u73b0\u6709\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u5bf9\u65b9\u8a00\u8f93\u5165\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9650\u5236\u4e86\u6570\u767e\u4e07\u4f7f\u7528\u8005\u7684\u5b9e\u7528\u6027\u3002", "method": "\u6784\u5efaAlexandria\u6570\u636e\u96c6\uff1a\u793e\u533a\u9a71\u52a8\u3001\u4eba\u5de5\u7ffb\u8bd1\uff0c\u8986\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u300111\u4e2a\u9ad8\u5f71\u54cd\u529b\u9886\u57df\uff0c\u63d0\u4f9b\u57ce\u5e02\u7ea7\u5143\u6570\u636e\uff0c\u5305\u542b\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u5e76\u6807\u6ce8\u8bf4\u8bdd\u8005-\u63a5\u6536\u8005\u6027\u522b\u914d\u7f6e\u3002", "result": "\u6570\u636e\u96c6\u5305\u542b107K\u4e2a\u6837\u672c\uff0c\u53ef\u4f5c\u4e3a\u8bad\u7ec3\u8d44\u6e90\u548c\u8bc4\u4f30\u57fa\u51c6\u3002\u901a\u8fc7\u5bf9\u963f\u62c9\u4f2f\u8bed\u611f\u77e5LLM\u7684\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8de8\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u548c\u6b21\u65b9\u8a00\u7ffb\u8bd1\u7684\u80fd\u529b\u4e0e\u6301\u7eed\u6311\u6218\u3002", "conclusion": "Alexandria\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7ffb\u8bd1\u8d44\u6e90\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u7ec6\u7c92\u5ea6\u6570\u636e\uff0c\u65e2\u80fd\u8bad\u7ec3\u6a21\u578b\u53c8\u80fd\u8bc4\u4f30\u6027\u80fd\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u7cfb\u7edf\u5728\u65b9\u8a00\u7ffb\u8bd1\u65b9\u9762\u7684\u663e\u8457\u6311\u6218\u3002"}}
{"id": "2601.12859", "categories": ["cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.12859", "abs": "https://arxiv.org/abs/2601.12859", "authors": ["Luca Schaufelberger", "Aline Hartgers", "Kjell Jorner"], "title": "Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates", "comment": null, "summary": "Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.", "AI": {"tldr": "PuckerFlow\u662f\u4e00\u4e2a\u751f\u6210\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7Cremer-Pople\u7a7a\u95f4\u8fdb\u884c\u6d41\u5339\u914d\uff0c\u4e13\u95e8\u7528\u4e8e\u751f\u6210\u73af\u72b6\u5206\u5b50\u7684\u6784\u8c61\uff0c\u5728\u591a\u6837\u6027\u548c\u7cbe\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73af\u72b6\u5206\u5b50\u5728\u5316\u5b66\u548c\u751f\u7269\u5b66\u5e94\u7528\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5176\u53d7\u9650\u7684\u6784\u8c61\u7075\u6d3b\u6027\u5bf9\u836f\u7269\u53d1\u73b0\u548c\u50ac\u5316\u529f\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u53ef\u9760\u91c7\u6837\u73af\u7cfb\u7edf\u7684\u6784\u8c61\u96c6\u5408\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165PuckerFlow\u6a21\u578b\uff0c\u5728Cremer-Pople\u7a7a\u95f4\uff08\u6355\u83b7\u73af\u76f8\u5173\u81ea\u7531\u5ea6\u7684\u4f4e\u7ef4\u5185\u90e8\u5750\u6807\u7cfb\uff09\u4e0a\u6267\u884c\u6d41\u5339\u914d\uff0c\u786e\u4fdd\u751f\u6210\u6709\u6548\u7684\u95ed\u5408\u73af\u7ed3\u6784\u3002", "result": "PuckerFlow\u5728\u51e0\u4e4e\u6240\u6709\u5b9a\u91cf\u6307\u6807\u4e0a\u90fd\u4f18\u4e8e\u5176\u4ed6\u6784\u8c61\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u65e2\u591a\u6837\u53c8\u7cbe\u786e\u7684\u6784\u8c61\uff0c\u7279\u522b\u9002\u7528\u4e8e\u50ac\u5316\u548c\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u73af\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5b9e\u73b0\u4e86\u73af\u72b6\u7ed3\u6784\u7684\u9ad8\u6548\u53ef\u9760\u6784\u8c61\u751f\u6210\uff0c\u4e3a\u5efa\u6a21\u7ed3\u6784-\u6027\u8d28\u5173\u7cfb\u548c\u8de8\u5316\u5b66\u4e0e\u751f\u7269\u5b66\u5e94\u7528\u7684\u5c5e\u6027\u5f15\u5bfc\u73af\u751f\u6210\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2601.14027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14027", "abs": "https://arxiv.org/abs/2601.14027", "authors": ["Junqi Liu", "Zihao Zhou", "Zekai Zhu", "Marco Dos Santos", "Weikun He", "Jiawei Liu", "Ran Wang", "Yunzhou Xie", "Junqiao Zhao", "Qiufeng Wang", "Lihong Zhi", "Jia Li", "Wenda Li"], "title": "Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics", "comment": null, "summary": "Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4f5c\u4e3a\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u5668\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7Claude Code\u4e0eNumina-Lean-MCP\u7ed3\u5408\uff0c\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u81ea\u52a8\u5316\u7684Lean\u4ea4\u4e92\u548c\u5b9a\u7406\u8bc1\u660e\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4efb\u52a1\u7279\u5b9a\u6d41\u6c34\u7ebf\u548c\u8bad\u7ec3\u5f62\u5f0f\u8bc1\u660e\u5668\u7684\u65b9\u6cd5\u7075\u6d3b\u6027\u5dee\u3001\u53ef\u590d\u73b0\u6027\u4f4e\u3002\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u80fd\u63d0\u4f9b\u8d85\u8d8a\u8bc1\u660e\u7684\u591a\u6837\u5316\u63a8\u7406\u63a5\u53e3\uff0c\u4ec5\u901a\u8fc7\u66ff\u6362\u57fa\u7840\u6a21\u578b\u5373\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u4e14MCP\u652f\u6301\u7075\u6d3b\u6269\u5c55\u548c\u81ea\u4e3b\u8c03\u7528\u4e13\u4e1a\u5de5\u5177\u3002", "method": "\u63d0\u51faNumina-Lean-Agent\uff0c\u7ed3\u5408Claude Code\u4e0eNumina-Lean-MCP\uff0c\u5b9e\u73b0\u4e0eLean\u7684\u81ea\u4e3b\u4ea4\u4e92\u3001\u76f8\u5173\u5b9a\u7406\u68c0\u7d22\u3001\u975e\u5f62\u5f0f\u5316\u8bc1\u660e\u548c\u8f85\u52a9\u63a8\u7406\u5de5\u5177\u8c03\u7528\u3002", "result": "\u4f7f\u7528Claude Opus 4.5\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0cNumina-Lean-Agent\u89e3\u51b3\u4e86Putnam 2025\u6240\u6709\u95ee\u9898\uff0812/12\uff09\uff0c\u8fbe\u5230\u6700\u4f73\u95ed\u6e90\u7cfb\u7edf\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u6210\u529f\u5f62\u5f0f\u5316\u4e86Brascamp-Lieb\u5b9a\u7406\uff0c\u5c55\u793a\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u7528\u7f16\u7801\u667a\u80fd\u4f53\u4f5c\u4e3a\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u5668\u662f\u53ef\u884c\u7684\u65b0\u8303\u5f0f\uff0cNumina-Lean-Agent\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5f3a\u5927\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5f62\u5f0f\u5316\u6570\u5b66\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13105", "abs": "https://arxiv.org/abs/2601.13105", "authors": ["Liu Kaipeng", "Wu Ling"], "title": "Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification", "comment": "19pages, 1figure", "summary": "This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408LoRA\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4e0eRAG\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\u7684\u81ea\u52a8\u8bc6\u522b\uff0c\u5728BNC\u8bed\u6599\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u7684\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u6709\u6548\u81ea\u52a8\u8bc6\u522b\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u63d0\u5347\u8bed\u6cd5\u7ed3\u6784\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u91c7\u7528LoRA\u5fae\u8c03Qwen3-8B\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408RAG\u6846\u67b6\uff0c\u5728BNC\u8bed\u6599\u5e93\u6807\u6ce8\u6570\u636e\u4e0a\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\uff0c\u5bf9\u6bd4\u5206\u6790\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "LoRA\u5fae\u8c03\u7684Qwen3-8B\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u539f\u751fQwen3-MAX\u6a21\u578b\u548c\u7eaf\u7406\u8bbaRAG\u7cfb\u7edf\uff0c\u9519\u8bef\u5206\u6790\u663e\u793a\u5fae\u8c03\u4f7f\u6a21\u578b\u4ece\u8868\u5c42\u6a21\u5f0f\u5339\u914d\u8f6c\u5411\u66f4\u8bed\u4e49\u5316\u7684\u7406\u89e3\u3002", "conclusion": "LoRA\u5fae\u8c03\u4e0eRAG\u6846\u67b6\u7ed3\u5408\u80fd\u6709\u6548\u63d0\u5347\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\u7684\u81ea\u52a8\u8bc6\u522b\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u83b7\u5f97\u66f4\u8bed\u4e49\u5316\u7684\u8bed\u6cd5\u7ed3\u6784\u7406\u89e3\uff0c\u4e3a\u8bed\u6cd5\u5206\u6790\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.12879", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12879", "abs": "https://arxiv.org/abs/2601.12879", "authors": ["Mohammed Mudassir Uddin", "Shahnawaz Alam", "Mohammed Kaif Pasha"], "title": "Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition", "comment": null, "summary": "Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\\pm$2.3\\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.", "AI": {"tldr": "HAGD\u6846\u67b6\u901a\u8fc7\u591a\u5206\u8fa8\u7387\u62bd\u8c61\u5c42\u6b21\u548c\u53ef\u5fae\u5206\u7535\u8def\u641c\u7d22\uff0c\u5c06\u7535\u8def\u53d1\u73b0\u590d\u6742\u5ea6\u4eceO(2^n)\u964d\u4f4e\u5230O(n\u00b2 log n)\uff0c\u5728GPT-2\u3001Llama\u548cPythia\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe91%\u7684\u884c\u4e3a\u4fdd\u6301\u548c\u53ef\u89e3\u91ca\u7684\u5b50\u56fe\u89c4\u6a21\u3002", "motivation": "\u4ece\u6570\u5341\u4ebf\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u7a00\u758f\u8ba1\u7b97\u7535\u8def\u9762\u4e34\u6307\u6570\u641c\u7d22\u590d\u6742\u6027\u548c\u666e\u904d\u591a\u4e49\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u5f52\u56e0\u56fe\u5206\u89e3(HAGD)\u6846\u67b6\uff0c\u6574\u5408\u8de8\u5c42\u8f6c\u7801\u5668\u7528\u4e8e\u5355\u4e49\u7279\u5f81\u63d0\u53d6\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u5143\u5b66\u4e60\u7528\u4e8e\u62d3\u6251\u9884\u6d4b\u3001\u56e0\u679c\u5e72\u9884\u534f\u8bae\u7528\u4e8e\u9a8c\u8bc1\u3002", "result": "\u5728\u6a21\u8fd0\u7b97\u4efb\u52a1\u4e0a\u5b9e\u73b0\u9ad8\u8fbe91%\u7684\u884c\u4e3a\u4fdd\u6301\uff08\u00b12.3%\uff09\uff0c\u8de8\u67b6\u6784\u8fc1\u79fb\u5b9e\u9a8c\u663e\u793a\u7535\u8def\u7ed3\u6784\u76f8\u4f3c\u6027\u5e73\u5747\u8fbe67%\uff0c\u8868\u660e\u6f5c\u5728\u5171\u4eab\u8ba1\u7b97\u6a21\u5f0f\u3002", "conclusion": "\u4e3a\u66f4\u5927\u6a21\u578b\u89c4\u6a21\u7684\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u521d\u6b65\u57fa\u7840\uff0c\u540c\u65f6\u8bc6\u522b\u51fa\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u7684\u663e\u8457\u5c40\u9650\u6027\uff0c\u9700\u8981\u672a\u6765\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2601.14096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14096", "abs": "https://arxiv.org/abs/2601.14096", "authors": ["Benedikt Hartl", "L\u00e9o Pio-Lopez", "Chris Fields", "Michael Levin"], "title": "Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems", "comment": "41 pages, 5 figures", "summary": "The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u8ba4\u77e5\u7684\u7edf\u4e00\u6846\u67b6\uff1a\u6240\u6709\u667a\u80fd\u7cfb\u7edf\uff08\u4ece\u751f\u7269\u5230\u4eba\u5de5\uff09\u90fd\u901a\u8fc7\u4e24\u4e2a\u5c3a\u5ea6\u4e0d\u53d8\u7684\u539f\u7406\u8fd0\u4f5c\u2014\u2014\u5d4c\u5165\u7a7a\u95f4\u7684\u91cd\u6620\u5c04\u548c\u5728\u7a7a\u95f4\u4e2d\u7684\u5bfc\u822a\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bef\u5dee\u6700\u5c0f\u5316\u5b9e\u73b0\u3002", "motivation": "\u52a8\u673a\u662f\u5efa\u7acb\u8de8\u4e0d\u540c\u8d77\u6e90\u3001\u7ec4\u6210\u548c\u57fa\u8d28\u7684\u667a\u80fd\u7cfb\u7edf\u7684\u7edf\u4e00\u89c6\u56fe\uff0c\u4ece\u4e9a\u7ec6\u80de\u5316\u5b66\u7f51\u7edc\u5230\u751f\u7269\u7fa4\u4f53\uff0c\u6db5\u76d6\u8fdb\u5316\u3001\u5de5\u7a0b\u548c\u6df7\u5408\u7cfb\u7edf\uff0c\u5bfb\u627e\u5c3a\u5ea6\u4e0d\u53d8\u7684\u51b3\u7b56\u539f\u5219\u3002", "method": "\u63d0\u51fa\u8ba4\u77e5\u7684\u53cc\u91cd\u539f\u7406\uff1a1\uff09\u5d4c\u5165\u7a7a\u95f4\u7684\u91cd\u6620\u5c04\uff08\u5c06\u6570\u636e/\u72b6\u6001\u6620\u5c04\u5230\u6f5c\u5728\u8868\u793a\uff09\uff0c2\uff09\u5728\u8fd9\u4e9b\u7a7a\u95f4\u4e2d\u7684\u5bfc\u822a\uff08\u901a\u8fc7\u5206\u5e03\u5f0f\u8bef\u5dee\u6821\u6b63\u8fed\u4ee3\u4f18\u5316\uff09\u3002\u751f\u7269\u7cfb\u7edf\u548c\u73b0\u4ee3AI\u7cfb\u7edf\u90fd\u4f53\u73b0\u8fd9\u4e00\u673a\u5236\u3002", "result": "\u8bba\u8bc1\u4e86\u8fd9\u4e00\u53cc\u91cd\u539f\u7406\u6784\u6210\u8ba4\u77e5\u7684\u57fa\u8d28\u72ec\u7acb\u4e0d\u53d8\u6027\uff0c\u63ed\u793a\u4e86\u751f\u7269\u7cfb\u7edf\uff08\u4ece\u5355\u7ec6\u80de\u5230\u6574\u4e2a\u751f\u7269\u4f53\uff09\u4e0e\u4eba\u5de5\u7cfb\u7edf\uff08\u5982Transformer\u3001\u6269\u6563\u6a21\u578b\u3001\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a\uff09\u4e4b\u95f4\u7684\u6df1\u5c42\u5e73\u884c\u6027\u3002", "conclusion": "\u8bc6\u522b\u8fd9\u4e00\u5171\u4eab\u673a\u5236\u4e0d\u4ec5\u9610\u660e\u4e86\u751f\u547d\u7cfb\u7edf\u4e0e\u4eba\u5de5\u6a21\u578b\u4e4b\u95f4\u7684\u6df1\u5c42\u76f8\u4f3c\u6027\uff0c\u8fd8\u4e3a\u8de8\u5c3a\u5ea6\u5de5\u7a0b\u5316\u81ea\u9002\u5e94\u667a\u80fd\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u591a\u6837\u5316\u667a\u80fd\u9886\u57df\u7684\u6574\u5408\u89c6\u89d2\u3002"}}
{"id": "2601.13111", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13111", "abs": "https://arxiv.org/abs/2601.13111", "authors": ["Hassan Soliman", "Vivek Gupta", "Dan Roth", "Iryna Gurevych"], "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL", "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t", "summary": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.", "AI": {"tldr": "CORE-T\uff1a\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u901a\u8fc7LLM\u751f\u6210\u76ee\u7684\u5143\u6570\u636e\u589e\u5f3a\u8868\u683c\uff0c\u9884\u8ba1\u7b97\u8f7b\u91cf\u7ea7\u8868\u683c\u517c\u5bb9\u6027\u7f13\u5b58\uff0c\u6539\u8fdb\u591a\u8868\u6587\u672c\u5230SQL\u4e2d\u7684\u8868\u683c\u9009\u62e9\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u6587\u672c\u5230SQL\u5de5\u4f5c\u6d41\u901a\u5e38\u9700\u8981\u8fde\u63a5\u591a\u4e2a\u8868\u683c\uff0c\u51c6\u786e\u68c0\u7d22\u76f8\u5173\u8868\u683c\u96c6\u5408\u6210\u4e3a\u7aef\u5230\u7aef\u6027\u80fd\u7684\u5173\u952e\u74f6\u9888\u3002\u5728\u5f00\u653e\u4e66\u7c4d\u8bbe\u7f6e\u4e2d\uff0c\u67e5\u8be2\u9700\u8981\u5728\u5927\u89c4\u6a21\u5f02\u6784\u8868\u683c\u96c6\u5408\u4e0a\u56de\u7b54\uff0c\u7f3a\u4e4f\u6570\u636e\u5e93\u6807\u8bc6\u7b26\u7b49\u6e05\u6670\u8303\u56f4\u4fe1\u53f7\u3002", "method": "CORE-T\u6846\u67b6\uff1a1\uff09\u4f7f\u7528LLM\u751f\u6210\u8868\u683c\u76ee\u7684\u5143\u6570\u636e\u589e\u5f3a\u8868\u683c\uff1b2\uff09\u9884\u8ba1\u7b97\u8f7b\u91cf\u7ea7\u8868\u683c\u517c\u5bb9\u6027\u7f13\u5b58\uff1b3\uff09\u63a8\u7406\u65f6\uff1a\u5bc6\u96c6\u68c0\u7d22\u8fd4\u56detop-K\u5019\u9009\uff0c\u5355\u4e2aLLM\u8c03\u7528\u9009\u62e9\u53ef\u8fde\u63a5\u5b50\u96c6\uff0c\u7b80\u5355\u52a0\u6cd5\u8c03\u6574\u6b65\u9aa4\u6062\u590d\u5f3a\u517c\u5bb9\u8868\u683c\u3002", "result": "\u5728Bird\u3001Spider\u548cMMQA\u6570\u636e\u96c6\u4e0a\uff0cCORE-T\u5c06\u8868\u683c\u9009\u62e9F1\u63d0\u5347\u9ad8\u8fbe22.7\u5206\uff0c\u540c\u65f6\u68c0\u7d22\u8868\u683c\u51cf\u5c1142%\uff0c\u591a\u8868\u6267\u884c\u51c6\u786e\u7387\u5728Bird\u4e0a\u63d0\u53475.0\u5206\uff0c\u5728MMQA\u4e0a\u63d0\u53476.9\u5206\uff0c\u6bd4LLM\u5bc6\u96c6\u578b\u57fa\u7ebf\u5c11\u75284-5\u500dtoken\u3002", "conclusion": "CORE-T\u901a\u8fc7\u7ed3\u5408\u5bc6\u96c6\u68c0\u7d22\u7684\u53ec\u56de\u4f18\u52bf\u548cLLM\u9a71\u52a8\u7684\u8868\u683c\u9009\u62e9\uff0c\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u591a\u8868\u6587\u672c\u5230SQL\u4e2d\u7684\u8868\u683c\u9009\u62e9\u6027\u80fd\uff0c\u51cf\u5c11\u63a8\u7406\u5f00\u9500\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002"}}
{"id": "2601.12893", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12893", "abs": "https://arxiv.org/abs/2601.12893", "authors": ["Ting Dang", "Soumyajit Chatterjee", "Hong Jia", "Yu Wu", "Flora Salim", "Fahim Kawsar"], "title": "AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs", "comment": "Accepted by ICASSP 2026", "summary": "Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\\% and 28.4\\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.", "AI": {"tldr": "AdaNODEs\u662f\u4e00\u79cd\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6e90\u81ea\u7531\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5229\u7528\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u5904\u7406\u5206\u5e03\u6f02\u79fb\uff0c\u4ec5\u9700\u66f4\u65b0\u6709\u9650\u53c2\u6570\u5373\u53ef\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u72ec\u7acb\u6570\u636e\uff0c\u5f88\u5c11\u8003\u8651\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u9884\u6d4b\u4efb\u52a1\uff0c\u800c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u5206\u5e03\u6f02\u79fb\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6784\u5efa\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u63d0\u51fa\u65b0\u7684\u635f\u5931\u51fd\u6570\u4e13\u95e8\u5904\u7406\u9884\u6d4b\u4efb\u52a1\uff0c\u4ec5\u66f4\u65b0\u6709\u9650\u6a21\u578b\u53c2\u6570\u4ee5\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u5728\u4e00\u7ef4\u548c\u9ad8\u7ef4\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u5206\u522b\u83b7\u5f975.88%\u548c28.4%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u5728\u9ad8\u4e25\u91cd\u5ea6\u5206\u5e03\u6f02\u79fb\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "AdaNODEs\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6e90\u81ea\u7531\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5206\u5e03\u6f02\u79fb\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2601.14171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14171", "abs": "https://arxiv.org/abs/2601.14171", "authors": ["Qianli Ma", "Chang Guo", "Zhiheng Tian", "Siyu Wang", "Jipeng Xiao", "Yuanhao Yue", "Zhipeng Zhang"], "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance", "comment": null, "summary": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.", "AI": {"tldr": "RebuttalAgent\uff1a\u9996\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u53cd\u9a73\u4fe1\u751f\u6210\u91cd\u6784\u4e3a\u8bc1\u636e\u4e2d\u5fc3\u89c4\u5212\u4efb\u52a1\uff0c\u901a\u8fc7\u5206\u89e3\u8bc4\u5ba1\u610f\u89c1\u3001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\u3001\u96c6\u6210\u5916\u90e8\u641c\u7d22\uff0c\u786e\u4fdd\u6bcf\u4e2a\u8bba\u70b9\u90fd\u6709\u660e\u786e\u8bc1\u636e\u652f\u6491\uff0c\u5728\u8986\u76d6\u5ea6\u3001\u5fe0\u5b9e\u5ea6\u548c\u7b56\u7565\u8fde\u8d2f\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5f53\u524d\u53cd\u9a73\u4fe1\u751f\u6210\u65b9\u6848\u901a\u5e38\u5c06\u5176\u89c6\u4e3a\u76f4\u63a5\u6587\u672c\u751f\u6210\u95ee\u9898\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u5ffd\u7565\u6279\u8bc4\u610f\u89c1\u3001\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u57fa\u7840\u7b49\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7cbe\u786e\u5bf9\u9f50\u8bc4\u5ba1\u610f\u56fe\u4e0e\u7a3f\u4ef6\u7ec6\u8282\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRebuttalAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1) \u5c06\u590d\u6742\u53cd\u9988\u5206\u89e3\u4e3a\u539f\u5b50\u5316\u5173\u6ce8\u70b9\uff1b2) \u52a8\u6001\u6784\u5efa\u6df7\u5408\u4e0a\u4e0b\u6587\uff08\u538b\u7f29\u6458\u8981+\u9ad8\u4fdd\u771f\u6587\u672c\uff09\uff1b3) \u96c6\u6210\u81ea\u4e3b\u6309\u9700\u5916\u90e8\u641c\u7d22\u6a21\u5757\u5904\u7406\u9700\u8981\u5916\u90e8\u6587\u732e\u7684\u5173\u5207\uff1b4) \u5728\u8d77\u8349\u524d\u751f\u6210\u53ef\u68c0\u67e5\u7684\u54cd\u5e94\u8ba1\u5212\u3002", "result": "\u5728RebuttalBench\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u6d41\u6c34\u7ebf\u5728\u8986\u76d6\u5ea6\u3001\u5fe0\u5b9e\u5ea6\u548c\u7b56\u7565\u8fde\u8d2f\u6027\u65b9\u9762\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u4e3a\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u900f\u660e\u53ef\u63a7\u7684\u52a9\u624b\u3002", "conclusion": "RebuttalAgent\u901a\u8fc7\u8bc1\u636e\u4e2d\u5fc3\u7684\u89c4\u5212\u65b9\u6cd5\u89e3\u51b3\u4e86\u5f53\u524d\u53cd\u9a73\u4fe1\u751f\u6210\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u53ef\u68c0\u67e5\u3001\u53ef\u9a8c\u8bc1\u7684\u53cd\u9a73\u751f\u6210\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u53cd\u9a73\u4fe1\u7684\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2601.13115", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13115", "abs": "https://arxiv.org/abs/2601.13115", "authors": ["Fengran Mo", "Yifan Gao", "Sha Li", "Hansi Zeng", "Xin Liu", "Zhaoxuan Tan", "Xian Li", "Jianshu Chen", "Dakuo Wang", "Meng Jiang"], "title": "Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u8bdd\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u8de8\u8f6e\u6b21\u4ea4\u66ff\u641c\u7d22\u4e0e\u63a8\u7406\u6765\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u7528\u6237\u610f\u56fe\uff0c\u5728\u56db\u4e2a\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u9759\u6001\u7684\u91cd\u5199-\u68c0\u7d22-\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u5c06\u4e0d\u540c\u6d41\u7a0b\u5206\u5f00\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u6df7\u5408\u4e3b\u52a8\u884c\u4e3a\u7684\u540c\u6b65\u4f18\u5316\u3002\u867d\u7136\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u5728\u5355\u8f6e\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u8054\u5408\u4f18\u5316\u68c0\u7d22\u4e0e\u751f\u6210\u7684\u6709\u6548\u6027\uff0c\u4f46\u7f3a\u4e4f\u5904\u7406\u591a\u8f6e\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u8bdd\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u5bf9\u8bdd\u8f6e\u6b21\u95f4\u4ea4\u66ff\u8fdb\u884c\u641c\u7d22\u4e0e\u63a8\u7406\uff0c\u5b66\u4e60\u63a2\u7d22\u6027\u548c\u9002\u5e94\u6027\u884c\u4e3a\uff0c\u4f7f\u7528\u9488\u5bf9\u6f14\u5316\u7528\u6237\u76ee\u6807\u5b9a\u5236\u7684\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u591a\u4e2a\u73b0\u6709\u5f3a\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8de8\u8f6e\u6b21\u4ea4\u66ff\u641c\u7d22\u4e0e\u63a8\u7406\u7684\u5bf9\u8bdd\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u7528\u6237\u610f\u56fe\uff0c\u5728\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u4e2d\u53d6\u5f97\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12900", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12900", "abs": "https://arxiv.org/abs/2601.12900", "authors": ["Eliran Sherzer", "Yonit Barron"], "title": "Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times", "comment": null, "summary": "The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.\n  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.", "AI": {"tldr": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u8fd1\u4f3c(s,S)\u5e93\u5b58\u7cfb\u7edf\u7684\u7a33\u6001\u6027\u80fd\u6307\u6807\uff0c\u66ff\u4ee3\u6602\u8d35\u7684\u4eff\u771f\u8ba1\u7b97", "motivation": "\u4f20\u7edf\u7684(s,S)\u5e93\u5b58\u6a21\u578b\u5728\u975e\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\u5206\u6790\u56f0\u96be\uff0c\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u7684\u4eff\u771f\u8ba1\u7b97\u6765\u8bc4\u4f30\u957f\u671f\u6027\u80fd\u6307\u6807", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff1a\u5148\u7528\u4eff\u771f\u751f\u6210\u8bad\u7ec3\u6807\u7b7e\uff0c\u7136\u540e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u5c11\u91cf\u4f4e\u9636\u77e9\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81", "result": "\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5feb\u901f\u51c6\u786e\u5730\u9884\u6d4b\u5e93\u5b58\u6c34\u5e73\u7a33\u6001\u5206\u5e03\u3001\u671f\u671b\u5468\u671f\u65f6\u95f4\u3001\u7f3a\u8d27\u6982\u7387\u7b49\u6307\u6807\uff0c\u5728\u5927\u8303\u56f4\u7cfb\u7edf\u53c2\u6570\u4e0b\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u66ff\u4ee3\u91cd\u590d\u6602\u8d35\u7684\u4eff\u771f\u8fd0\u884c\uff0c\u53ef\u8f7b\u677e\u6269\u5c55\u5230\u5176\u4ed6\u5e93\u5b58\u6a21\u578b\uff0c\u4e3a\u5206\u6790\u590d\u6742\u968f\u673a\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u5feb\u901f\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2601.14192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14192", "abs": "https://arxiv.org/abs/2601.14192", "authors": ["Xiaofang Yang", "Lijun Li", "Heng Zhou", "Tong Zhu", "Xiaoye Qu", "Yuchen Fan", "Qianshan Wei", "Rui Ye", "Li Kang", "Yiran Qin", "Zhiqiang Kou", "Daizong Liu", "Qi Li", "Ning Ding", "Siheng Chen", "Jing Shao"], "title": "Toward Efficient Agents: Memory, Tool learning, and Planning", "comment": "35 pages, 200 references", "summary": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u4ece\u8bb0\u5fc6\u3001\u5de5\u5177\u5b66\u4e60\u548c\u89c4\u5212\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u51fa\u53d1\uff0c\u5206\u6790\u6548\u7387\u4f18\u5316\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5411\u667a\u80fd\u4f53\u7cfb\u7edf\u6269\u5c55\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6709\u6548\u6027\u800c\u5ffd\u89c6\u4e86\u6548\u7387\uff0c\u800c\u6548\u7387\u5bf9\u4e8e\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5168\u9762\u7814\u7a76\u667a\u80fd\u4f53\u7cfb\u7edf\u672c\u8eab\u7684\u6548\u7387\u95ee\u9898\u3002", "method": "\u4ece\u667a\u80fd\u4f53\u7684\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff08\u8bb0\u5fc6\u3001\u5de5\u5177\u5b66\u4e60\u3001\u89c4\u5212\uff09\u51fa\u53d1\uff0c\u7efc\u8ff0\u4e86\u591a\u79cd\u6548\u7387\u4f18\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u538b\u7f29\u7ba1\u7406\u3001\u6700\u5c0f\u5316\u5de5\u5177\u8c03\u7528\u7684\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u8bbe\u8ba1\u3001\u53d7\u63a7\u641c\u7d22\u673a\u5236\u7b49\u3002\u63d0\u51fa\u901a\u8fc7\u56fa\u5b9a\u6210\u672c\u4e0b\u7684\u6709\u6548\u6027\u6bd4\u8f83\u548c\u540c\u7b49\u6709\u6548\u6027\u4e0b\u7684\u6210\u672c\u6bd4\u8f83\u4e24\u79cd\u65b9\u5f0f\u6765\u8868\u5f81\u6548\u7387\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u667a\u80fd\u4f53\u6548\u7387\u4f18\u5316\u7684\u5171\u540c\u539f\u5219\uff0c\u603b\u7ed3\u4e86\u5404\u7ec4\u4ef6\u8bc4\u4f30\u534f\u8bae\u548c\u5e38\u7528\u6548\u7387\u6307\u6807\uff0c\u5efa\u7acb\u4e86\u6548\u7387\u4e0e\u6709\u6548\u6027\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u5206\u6790\u6846\u67b6\uff0c\u4e3a\u6548\u7387\u5bfc\u5411\u7684\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "conclusion": "\u667a\u80fd\u4f53\u6548\u7387\u7814\u7a76\u662f\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\uff0c\u8bba\u6587\u4e3a\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u7efc\u8ff0\u6846\u67b6\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2601.13137", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13137", "abs": "https://arxiv.org/abs/2601.13137", "authors": ["Yuan Gao", "Zhigang Liu", "Xinyu Yao", "Bo Chen", "Xiaobing Zhao"], "title": "Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains", "comment": "13 pages, 5 figures", "summary": "With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6VC-LLM\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u6307\u4ee4\u5fae\u8c03\u548c\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u4ef7\u503c\u4e00\u81f4\u6027", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\uff08\u79cd\u65cf\u3001\u793e\u4f1a\u3001\u653f\u6cbb\uff09\u5b58\u5728\u504f\u89c1\u548c\u4ef7\u503c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u7684\u4ef7\u503c\u5bf9\u9f50\u80fd\u529b", "method": "\u91c7\u7528\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\uff1a1) \u6301\u7eed\u9884\u8bad\u7ec3 2) \u6307\u4ee4\u5fae\u8c03 3) \u5bf9\u6297\u8bad\u7ec3\uff08\u653b\u51fb\u8005\u751f\u6210\u4e89\u8bae\u67e5\u8be2\uff0c\u884c\u52a8\u8005\u751f\u6210\u4ef7\u503c\u4e00\u81f4\u54cd\u5e94\uff0c\u8bc4\u8bba\u8005\u8fc7\u6ee4\u786e\u4fdd\u8d28\u91cf\uff09", "result": "\u8bad\u7ec3\u51faVC-LLM\u6a21\u578b\uff0c\u6784\u5efa\u4e2d\u82f1\u53cc\u8bed\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793aVC-LLM\u5728\u4e2d\u82f1\u6587\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b", "conclusion": "\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u4ef7\u503c\u4e00\u81f4\u6027\uff0cVC-LLM\u5728\u4ef7\u503c\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u4f18\u5f02"}}
{"id": "2601.12903", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12903", "abs": "https://arxiv.org/abs/2601.12903", "authors": ["Meng Liu", "Ke Liang", "Siwei Wang", "Xingchen Hu", "Sihang Zhou", "Xinwang Liu"], "title": "Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets", "comment": null, "summary": "Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aBenchTGC\u7684\u5168\u9762\u57fa\u51c6\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u5e8f\u56fe\u805a\u7c7b\uff08TGC\uff09\u4efb\u52a1\u4e2d\u7684\u4e24\u5927\u6311\u6218\uff1a\u4e0d\u9002\u7528\u7684\u805a\u7c7b\u6280\u672f\u548c\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u6846\u67b6\u548c\u6539\u8fdb\u6280\u672f\u6765\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u65f6\u5e8f\u56fe\u805a\u7c7b\u662f\u4e00\u4e2a\u65b0\u5174\u4f46\u5173\u6ce8\u5ea6\u4f4e\u7684\u4efb\u52a1\uff0c\u76f8\u6bd4\u9759\u6001\u56fe\u805a\u7c7b\uff0c\u5b83\u80fd\u5728\u65f6\u95f4\u8981\u6c42\u548c\u7a7a\u95f4\u8981\u6c42\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002\u7136\u800c\uff0c\u5f53\u524d\u5b58\u5728\u4e24\u5927\u6311\u6218\u963b\u788d\u4e86TGC\u7684\u53d1\u5c55\uff1a\u4e0d\u9002\u7528\u7684\u805a\u7c7b\u6280\u672f\u548c\u4e0d\u9002\u7528\u7684\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86BenchTGC\u57fa\u51c6\uff0c\u5305\u62ec\uff1a1\uff09\u8bbe\u8ba1BenchTGC\u6846\u67b6\u6765\u8bf4\u660e\u65f6\u5e8f\u56fe\u805a\u7c7b\u7684\u8303\u5f0f\uff1b2\uff09\u6539\u8fdb\u73b0\u6709\u805a\u7c7b\u6280\u672f\u4ee5\u9002\u5e94\u65f6\u5e8f\u56fe\uff1b3\uff09\u5f00\u53d1\u9002\u7528\u4e8eTGC\u4efb\u52a1\u7684\u591a\u4e2a\u6570\u636e\u96c6\uff08BenchTGC\u6570\u636e\u96c6\uff09\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86BenchTGC\u7684\u4f18\u52bf\uff0c\u5e76\u8bc1\u660e\u4e86\u65f6\u5e8f\u56fe\u805a\u7c7b\u4efb\u52a1\u7684\u5fc5\u8981\u6027\u548c\u91cd\u8981\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u5b9e\u4e16\u754c\u4e2d\u52a8\u6001\u53d8\u5316\u548c\u590d\u6742\u7684\u573a\u666f\u662f\u65f6\u5e8f\u56fe\u805a\u7c7b\u7684\u57fa\u7840\u3002", "conclusion": "BenchTGC\u57fa\u51c6\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u5e8f\u56fe\u805a\u7c7b\u9762\u4e34\u7684\u6280\u672f\u548c\u6570\u636e\u96c6\u6311\u6218\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u5e76\u5c55\u793a\u4e86\u65f6\u5e8f\u56fe\u805a\u7c7b\u5728\u73b0\u5b9e\u52a8\u6001\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2601.13155", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13155", "abs": "https://arxiv.org/abs/2601.13155", "authors": ["Zimeng Wu", "Donghao Wang", "Chaozhe Jin", "Jiaxin Chen", "Yunhong Wang"], "title": "Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference", "comment": null, "summary": "Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\\times$ and 2.29$\\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.", "AI": {"tldr": "SPTS\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u6ce8\u610f\u529b\u63a2\u6d4b\u548c\u4f4e\u79e9\u53d8\u6362\u63a2\u6d4b\u9009\u62e9\u6027\u8df3\u8fc7token\uff0c\u7ed3\u5408\u591a\u9636\u6bb5\u5ef6\u8fdf\u526a\u679d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u867d\u7136\u589e\u5f3a\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u73b0\u6709\u7684token\u5bfc\u5411\u65b9\u6cd5\uff08\u5982\u526a\u679d\u548c\u8df3\u8fc7\uff09\u5b58\u5728\u52a0\u901f\u6f5c\u529b\u6709\u9650\u3001\u4ee3\u7406\u4fe1\u53f7\u8fc7\u65f6\u548c\u5197\u4f59\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u901f\u5ea6-\u51c6\u786e\u7387\u6743\u8861\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51faSPTS\u6846\u67b6\uff1a1) Partial Attention Probing (PAP) - \u901a\u8fc7\u90e8\u5206\u524d\u5411\u6ce8\u610f\u529b\u8ba1\u7b97\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u7684token\uff1b2) Low-rank Transformation Probing (LTP) - \u6784\u5efa\u4f4e\u79e9\u4ee3\u7406\u7f51\u7edc\u9884\u6d4btoken\u53d8\u6362\uff1b3) Multi-Stage Delayed Pruning (MSDP) - \u91cd\u65b0\u5206\u914d\u8df3\u8fc7\u9884\u7b97\u5e76\u5728\u5404\u5c42\u9010\u6b65\u526a\u679d\u5197\u4f59token\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u5728\u4fdd\u6301\u6700\u5148\u8fdb\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u9884\u586b\u5145\u9636\u6bb5\u52a0\u901f\u8fbe2.46\u500d\uff0c\u7aef\u5230\u7aef\u751f\u6210\u52a0\u901f\u8fbe2.29\u500d\u3002", "conclusion": "SPTS\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u7684token\u8df3\u8fc7\u7b56\u7565\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u52a0\u901f\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.12917", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.12917", "abs": "https://arxiv.org/abs/2601.12917", "authors": ["He Sun", "Jinrui Zhou", "Li Li", "Mingjun Xiao"], "title": "CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction", "comment": "14 pages, 9 figures, under review", "summary": "Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\\%$, accelerates convergence by $8.8 \\times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.", "AI": {"tldr": "CooperLLM\uff1a\u4e91\u8f85\u52a9\u7684\u8fb9\u7f18\u7aef\u534f\u540c\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u7ed3\u5408\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u96f6\u9636\u4f18\u5316\u548c\u4e91\u7aef\u7684\u68af\u5ea6\u4fee\u6b63\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u3001\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u7cbe\u5ea6", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u5fae\u8c03\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6311\u6218\uff0c\u800c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5185\u5b58\u5bc6\u96c6\u578b\u53cd\u5411\u4f20\u64ad\uff0c\u8981\u4e48\u4f7f\u7528\u6536\u655b\u6162\u3001\u7cbe\u5ea6\u4f4e\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5", "method": "\u63d0\u51fa\u4e91\u8f85\u52a9\u7684\u8fb9\u7f18\u7aef\u534f\u540c\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff1a\u79fb\u52a8\u5ba2\u6237\u7aef\u5728\u79c1\u6709\u6570\u636e\u4e0a\u6267\u884c\u8f7b\u91cf\u7ea7\u96f6\u9636\u4f18\u5316\u66f4\u65b0\uff0c\u4e91\u7aef\u5728\u8f85\u52a9\u516c\u5171\u6570\u636e\u4e0a\u4f7f\u7528\u53cd\u5411\u4f20\u64ad\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u6ce8\u5165\u5f15\u5bfc\u6270\u52a8\u6765\u4fee\u6b63\u672c\u5730\u66f4\u65b0", "result": "\u5728\u591a\u4e2aTransformer\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCooperLLM\u5c06\u8bbe\u5907\u5185\u5b58\u964d\u4f4e\u9ad8\u8fbe86.4%\uff0c\u52a0\u901f\u6536\u655b8.8\u500d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u96f6\u9636\u4f18\u5316\u57fa\u7ebf\u7cbe\u5ea6\u63d0\u9ad8\u6700\u591a10\u4e2a\u767e\u5206\u70b9", "conclusion": "CooperLLM\u901a\u8fc7\u4e91\u8f85\u52a9\u7684\u534f\u540c\u8054\u90a6\u5fae\u8c03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4e0aLLM\u5fae\u8c03\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u9650\u5236\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u51c6\u786e\u7684\u6a21\u578b\u4e2a\u6027\u5316"}}
{"id": "2601.13178", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13178", "abs": "https://arxiv.org/abs/2601.13178", "authors": ["Joseph Gatto", "Parker Seegmiller", "Timothy Burdick", "Philip Resnik", "Roshnik Rahat", "Sarah DeLozier", "Sarah M. Preum"], "title": "Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages", "comment": "19 Pages, 5 Figures", "summary": "Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `\"which message is more medically urgent\" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.\n  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u7814\u7a76\u5f02\u6b65\u95e8\u8bca\u95e8\u6237\u6d88\u606f\u4e2d\u533b\u7597\u5206\u8bca\u7684\u5927\u89c4\u6a21\u516c\u5171\u6570\u636e\u96c6PMR-Bench\uff0c\u901a\u8fc7\u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u5efa\u6a21\u4e3a\u6210\u5bf9\u63a8\u7406\u95ee\u9898\uff0c\u8bad\u7ec3LLM\u8fdb\u884c\u533b\u7597\u7d27\u6025\u5ea6\u8bc4\u4f30\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u5206\u8bca\u662f\u6839\u636e\u533b\u7597\u9700\u6c42\u5206\u914d\u8d44\u6e90\u548c\u4f18\u5148\u5904\u7406\u60a3\u8005\u7684\u4efb\u52a1\uff0c\u4f46\u5728\u5f02\u6b65\u95e8\u8bca\u95e8\u6237\u6d88\u606f\u573a\u666f\u4e2d\u7f3a\u4e4f\u5927\u89c4\u6a21\u516c\u5171\u6570\u636e\u96c6\u8fdb\u884c\u7814\u7a76\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u771f\u5b9e\u533b\u7597\u5206\u8bca\u573a\u666f\u4e2d\u6709\u6548\u8bc4\u4f30\u60a3\u8005\u6d88\u606f\u7684\u7d27\u6025\u7a0b\u5ea6\u3002", "method": "1) \u521b\u5efaPMR-Bench\u6570\u636e\u96c6\uff0c\u5305\u542b1569\u6761\u72ec\u7279\u6d88\u606f\u548c2000+\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u5bf9\uff0c\u7ed3\u5408\u975e\u7ed3\u6784\u5316\u60a3\u8005\u6d88\u606f\u548c\u771f\u5b9e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff1b2) \u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u5efa\u6a21\u4e3a\u6210\u5bf9\u63a8\u7406\u95ee\u9898\uff0c\u91c7\u7528\u9526\u6807\u8d5b\u5f0f\u91cd\u65b0\u6392\u5e8f\u65b9\u6cd5\uff1b3) \u5f00\u53d1\u81ea\u52a8\u6570\u636e\u6807\u6ce8\u7b56\u7565\u4e3aLLM\u63d0\u4f9b\u9886\u57df\u6307\u5bfc\uff1b4) \u8bad\u7ec3\u4e24\u79cd\u6a21\u578b\uff1a\u57fa\u4e8eBradley-Terry\u76ee\u6807\u7684UrgentReward\u548c\u57fa\u4e8e\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u76ee\u6807\u7684UrgentSFT\u3002", "result": "UrgentSFT\u5728PMR-Bench\u4e0a\u8868\u73b0\u6700\u4f73\uff0cUrgentReward\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e2d\u663e\u793a\u72ec\u7279\u4f18\u52bf\u3002UrgentSFT-8B\u548cUrgentReward-8B\u76f8\u6bd4\u73b0\u6210\u76848B\u6a21\u578b\uff0c\u5728\u6536\u4ef6\u7bb1\u6392\u5e8f\u6307\u6807\u4e0a\u5206\u522b\u63d0\u534715\u548c16\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u533b\u7597\u5206\u8bca\u4efb\u52a1\u63d0\u4f9b\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u516c\u5171\u6570\u636e\u96c6\u548c\u6709\u6548\u7684\u6a21\u578b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6210\u5bf9\u63a8\u7406\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u60a3\u8005\u6d88\u606f\u7d27\u6025\u5ea6\u8bc4\u4f30\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u533b\u7597\u5206\u8bca\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.12928", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.12928", "abs": "https://arxiv.org/abs/2601.12928", "authors": ["Yaima Paz Soto", "Silena Herold Garcia", "Ximo Gual-Arnau", "Antoni Jaume-i-Cap\u00f3", "Manuel Gonz\u00e1lez-Hidalgo"], "title": "An efficient heuristic for geometric analysis of cell deformations", "comment": null, "summary": "Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f62\u72b6\u7a7a\u95f4\u548c\u5f39\u6027\u8ddd\u79bb\u7684\u9570\u72b6\u7ec6\u80de\u81ea\u52a8\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fa\u5b9a\u53c2\u6570\u5316\u548c\u6a21\u677f\u5bf9\u9f50\u7b80\u5316\u8ba1\u7b97\uff0c\u5728\u76d1\u7763\u5206\u7c7b\u548c\u65e0\u76d1\u7763\u805a\u7c7b\u4e2d\u8fbe\u523096.03%\u51c6\u786e\u7387", "motivation": "\u9570\u72b6\u7ec6\u80de\u75c5\u5bfc\u81f4\u7ea2\u7ec6\u80de\u53d8\u5f62\uff0c\u5f71\u54cd\u8840\u6db2\u6d41\u52a8\u548c\u6c27\u6c14\u8f93\u9001\uff0c\u5168\u7403\u60a3\u75c5\u7387\u9ad8\u4e14\u5bf9\u533b\u7597\u7cfb\u7edf\u8d1f\u62c5\u91cd\u3002\u81ea\u52a8\u5206\u7c7b\u9570\u72b6\u7ec6\u80de\u5bf9\u51cf\u8f7b\u4e13\u5bb6\u5de5\u4f5c\u91cf\u3001\u907f\u514d\u91cf\u5316\u9519\u8bef\u548c\u8bc4\u4f30\u5371\u673a\u4e25\u91cd\u6027\u81f3\u5173\u91cd\u8981", "method": "\u5c06\u7ea2\u7ec6\u80de\u5efa\u6a21\u4e3a\u5f62\u72b6\u7a7a\u95f4\u4e2d\u7684\u5c01\u95ed\u5e73\u9762\u66f2\u7ebf\uff0c\u4f7f\u7528\u5f39\u6027\u8ddd\u79bb\uff08\u5bf9\u65cb\u8f6c\u3001\u5e73\u79fb\u3001\u7f29\u653e\u548c\u91cd\u53c2\u6570\u5316\u4e0d\u53d8\uff09\u3002\u6539\u8fdb\u5305\u62ec\uff1a(1) \u57fa\u4e8e\u7ec6\u80de\u4e3b\u8f74\u4f7f\u7528\u56fa\u5b9a\u53c2\u6570\u5316\u8ba1\u7b97\u8ddd\u79bb\uff1b(2) \u5728\u8ba1\u7b97\u8ddd\u79bb\u524d\u4f7f\u7528\u8be5\u53c2\u6570\u5316\u5c06\u6bcf\u4e2a\u7ec6\u80de\u4e0e\u4e24\u4e2a\u6a21\u677f\u5bf9\u9f50\uff0c\u7b80\u5316\u8ba1\u7b97", "result": "\u5728\u76d1\u7763\u5206\u7c7b\u548c\u65e0\u76d1\u7763\u805a\u7c7b\u4e2d\u5747\u8fbe\u523096.03%\u7684\u51c6\u786e\u7387\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u5f62\u72b6\u7a7a\u95f4\u6a21\u578b\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7ea2\u7ec6\u80de\u5206\u7c7b\uff0c\u901a\u8fc7\u56fa\u5b9a\u53c2\u6570\u5316\u548c\u6a21\u677f\u5bf9\u9f50\u7b80\u5316\u4e86\u57fa\u4e8e\u5f62\u72b6\u7a7a\u95f4\u7684\u5206\u7c7b\u8ba1\u7b97\uff0c\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861"}}
{"id": "2601.13183", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13183", "abs": "https://arxiv.org/abs/2601.13183", "authors": ["Sergio Servantez", "Sarah B. Lawsky", "Rajiv Jain", "Daniel W. Linna", "Kristian Hammond"], "title": "OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand", "comment": "25 pages, 9 Figures, 15 tables", "summary": "Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.", "AI": {"tldr": "OpenExempt\u662f\u4e00\u4e2a\u7528\u4e8e\u6cd5\u5f8b\u63a8\u7406\u8bca\u65ad\u8bc4\u4f30\u7684\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u901a\u8fc7\u4e13\u5bb6\u6784\u5efa\u7684\u7f8e\u56fd\u7834\u4ea7\u6cd5\u6cd5\u89c4\u7b26\u53f7\u8868\u793a\u52a8\u6001\u751f\u6210\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\uff0c\u80fd\u591f\u7cbe\u7ec6\u63a7\u5236\u4efb\u52a1\u590d\u6742\u5ea6\u5e76\u9694\u79bb\u6d4b\u8bd5\u7279\u5b9a\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u57fa\u51c6\u5b58\u5728\u5c40\u9650\u6027\uff1a\u9759\u6001\u95ee\u7b54\u5bf9\u53ea\u80fd\u63d0\u4f9b\u6027\u80fd\u5feb\u7167\uff0c\u5c06\u590d\u6742\u884c\u4e3a\u538b\u7f29\u4e3a\u5355\u4e00\u51c6\u786e\u7387\u6307\u6807\uff1b\u5728\u6cd5\u5f8b\u7b49\u590d\u6742\u89c4\u5219\u9886\u57df\uff0c\u73b0\u6709\u57fa\u51c6\u6784\u5efa\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u9694\u79bb\u7279\u5b9a\u5931\u8d25\u6a21\u5f0f\u3002", "method": "OpenExempt\u6846\u67b6\u4f7f\u7528\u4e13\u5bb6\u6784\u5efa\u7684\u7f8e\u56fd\u7834\u4ea7\u6cd5\u6cd5\u89c4\u7b26\u53f7\u8868\u793a\uff0c\u52a8\u6001\u751f\u6210\u5927\u91cf\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u53ca\u5176\u673a\u5668\u53ef\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff1b\u6784\u5efaOpenExempt\u57fa\u51c6\uff0c\u5305\u542b9,765\u4e2a\u6837\u672c\uff0c\u5206\u5e03\u5728\u4e5d\u4e2a\u8bc4\u4f30\u5957\u4ef6\u4e2d\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u7cbe\u7ec6\u63a2\u6d4b\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5bf913\u4e2a\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u8f83\u957f\u63a8\u7406\u8def\u5f84\u548c\u5b58\u5728\u6df7\u6dc6\u6027\u9648\u8ff0\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u6027\u80fd\u4f1a\u51fa\u73b0\u6025\u5267\u4e0b\u964d\uff1b\u57fa\u51c6\u80fd\u591f\u63ed\u793a\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u65e0\u6cd5\u53d1\u73b0\u7684\u6027\u80fd\u60ac\u5d16\u3002", "conclusion": "OpenExempt\u6846\u67b6\u548c\u57fa\u51c6\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u4e0b\u4e00\u4ee3\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4efb\u52a1\u548c\u7cbe\u7ec6\u63a7\u5236\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8bca\u65ad\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.13217", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13217", "abs": "https://arxiv.org/abs/2601.13217", "authors": ["Bingsen Chen", "Boyan Li", "Ping Nie", "Yuyu Zhang", "Xi Ye", "Chen Zhao"], "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision", "comment": null, "summary": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMr Dre\u8bc4\u4f30\u5957\u4ef6\uff0c\u9996\u6b21\u5c06\u591a\u8f6e\u62a5\u544a\u4fee\u8ba2\u4f5c\u4e3a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u65b0\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u53d1\u73b0\u73b0\u6709\u4ee3\u7406\u5728\u53cd\u9988\u4fee\u8ba2\u4e2d\u5b58\u5728\u5185\u5bb9\u5012\u9000\u548c\u7f16\u8f91\u4fdd\u6301\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u57fa\u51c6\u5c06\u62a5\u544a\u751f\u6210\u89c6\u4e3a\u5355\u6b21\u5199\u4f5c\u4efb\u52a1\uff0c\u8fd9\u4e0e\u4eba\u7c7b\u7814\u7a76\u8005\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u6216\u540c\u884c\u53cd\u9988\u8fed\u4ee3\u8d77\u8349\u548c\u4fee\u8ba2\u62a5\u544a\u7684\u65b9\u5f0f\u5b58\u5728\u6839\u672c\u5dee\u5f02\u3002\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u80fd\u5426\u53ef\u9760\u5730\u6839\u636e\u7528\u6237\u53cd\u9988\u4fee\u8ba2\u62a5\u544a\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u5f15\u5165Mr Dre\u8bc4\u4f30\u5957\u4ef6\uff0c\u5305\u62ec\uff1a(1) \u7edf\u4e00\u7684\u957f\u7bc7\u62a5\u544a\u8bc4\u4f30\u534f\u8bae\uff0c\u6db5\u76d6\u5168\u9762\u6027\u3001\u4e8b\u5b9e\u6027\u548c\u5448\u73b0\u8d28\u91cf\uff1b(2) \u4eba\u5de5\u9a8c\u8bc1\u7684\u53cd\u9988\u6a21\u62df\u7ba1\u9053\uff0c\u7528\u4e8e\u591a\u8f6e\u4fee\u8ba2\u8bc4\u4f30\u3002\u5206\u6790\u4e86\u4e94\u4e2a\u4e0d\u540c\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u3002", "result": "\u5206\u6790\u53d1\u73b0\u5173\u952e\u5c40\u9650\uff1a\u867d\u7136\u4ee3\u7406\u80fd\u5904\u7406\u5927\u90e8\u5206\u7528\u6237\u53cd\u9988\uff0c\u4f46\u4e5f\u4f1a\u572816-27%\u7684\u5148\u524d\u8986\u76d6\u5185\u5bb9\u548c\u5f15\u7528\u8d28\u91cf\u4e0a\u51fa\u73b0\u5012\u9000\u3002\u7ecf\u8fc7\u591a\u8f6e\u4fee\u8ba2\uff0c\u5373\u4f7f\u8868\u73b0\u6700\u4f73\u7684\u4ee3\u7406\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f1a\u7834\u574f\u53cd\u9988\u8303\u56f4\u4e4b\u5916\u7684\u5185\u5bb9\uff0c\u4e14\u65e0\u6cd5\u4fdd\u6301\u65e9\u671f\u7f16\u8f91\u3002", "conclusion": "\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u591a\u8f6e\u62a5\u544a\u4fee\u8ba2\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u6311\u6218\uff0c\u8fd9\u4e9b\u95ee\u9898\u65e0\u6cd5\u901a\u8fc7\u63a8\u7406\u65f6\u4fee\u590d\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u6216\u4e13\u95e8\u7684\u62a5\u544a\u4fee\u8ba2\u5b50\u4ee3\u7406\uff09\u8f7b\u6613\u89e3\u51b3\uff0c\u8868\u660e\u9700\u8981\u66f4\u6839\u672c\u7684\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2601.12965", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12965", "abs": "https://arxiv.org/abs/2601.12965", "authors": ["Doheon Kim"], "title": "Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning", "comment": null, "summary": "Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.", "AI": {"tldr": "\u8bba\u6587\u4e3a\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\uff0c\u8bf4\u660e\u5373\u4f7f\u795e\u7ecf\u7f51\u7edc\u4f7f\u7528\u4e58\u6cd5\u566a\u58f0\u6761\u4ef6\u5316\u65e0\u6cd5\u5b8c\u5168\u5b66\u4e60\u6b63\u786e\u5206\u6570\u51fd\u6570\uff0c\u4ecd\u80fd\u751f\u6210\u826f\u597d\u6837\u672c\u7684\u539f\u56e0\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u5728\u7406\u8bba\u4e0a\u53ef\u4ee5\u901a\u8fc7\u4e0e\u91c7\u6837\u8fc7\u7a0b\u76f8\u5173\u7684\u5fae\u5206\u65b9\u7a0b\u89e3\u91ca\uff0c\u4f46Song\u548cErmon\uff082020\uff09\u53d1\u73b0\u4f7f\u7528\u4e58\u6cd5\u566a\u58f0\u6761\u4ef6\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u4ecd\u80fd\u751f\u6210\u6ee1\u610f\u6837\u672c\u3002\u8fd9\u79cd\u6a21\u578b\u7ed3\u6784\u9650\u5236\u4e86\u7a7a\u95f4\u53d8\u91cf\u4e0e\u566a\u58f0\u4e4b\u95f4\u66f4\u4e00\u822c\u5173\u7cfb\u7684\u8868\u793a\u80fd\u529b\uff0c\u8868\u660e\u65e0\u6cd5\u5b8c\u5168\u5b66\u4e60\u6b63\u786e\u5206\u6570\u51fd\u6570\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u9700\u8981\u7406\u8bba\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u76f8\u5173\u5fae\u5206\u65b9\u7a0b\u7684\u786e\u5b9a\u6027\u52a8\u529b\u5b66\uff0c\u5206\u6790\u6a21\u578b\u5982\u4f55\u8fd0\u4f5c\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u7814\u7a76\u4e58\u6cd5\u566a\u58f0\u6761\u4ef6\u5316\u6a21\u578b\u7684\u7ed3\u6784\u9650\u5236\uff0c\u5e76\u5206\u6790\u5728\u8fd9\u79cd\u9650\u5236\u4e0b\u6a21\u578b\u4ecd\u7136\u6709\u6548\u7684\u7406\u8bba\u673a\u5236\u3002", "result": "\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\uff0c\u8bf4\u660e\u5373\u4f7f\u6a21\u578b\u65e0\u6cd5\u5b8c\u5168\u5b66\u4e60\u6b63\u786e\u5206\u6570\u51fd\u6570\uff0c\u4ecd\u80fd\u6709\u6548\u751f\u6210\u6837\u672c\u7684\u539f\u56e0\u3002\u901a\u8fc7\u5206\u6790\u786e\u5b9a\u6027\u52a8\u529b\u5b66\uff0c\u63ed\u793a\u4e86\u5728\u8fd9\u79cd\u53d7\u9650\u6a21\u578b\u7ed3\u6784\u4e0b\u4ecd\u7136\u80fd\u591f\u826f\u597d\u8fd0\u4f5c\u7684\u673a\u5236\u3002", "conclusion": "\u5373\u4f7f\u4f7f\u7528\u4e58\u6cd5\u566a\u58f0\u6761\u4ef6\u5316\u7684\u6269\u6563\u6a21\u578b\u5728\u7406\u8bba\u4e0a\u65e0\u6cd5\u5b8c\u5168\u5b66\u4e60\u6b63\u786e\u5206\u6570\u51fd\u6570\uff0c\u4f46\u901a\u8fc7\u7814\u7a76\u76f8\u5173\u5fae\u5206\u65b9\u7a0b\u7684\u786e\u5b9a\u6027\u52a8\u529b\u5b66\uff0c\u53ef\u4ee5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u8fd9\u4e9b\u6a21\u578b\u5728\u5b9e\u8df5\u4e2d\u4ecd\u7136\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u4e3a\u8fd9\u79cd\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.13228", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13228", "abs": "https://arxiv.org/abs/2601.13228", "authors": ["Tianqi Du", "Lizhe Fang", "Weijie Yang", "Chenheng Zhang", "Zeming Wei", "Yifei Wang", "Yisen Wang"], "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation", "comment": null, "summary": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.", "AI": {"tldr": "A3\u6846\u67b6\u5c06\u81ea\u56de\u5f52\u6a21\u578b\u6269\u5c55\u4e3a\u4efb\u610f\u987a\u5e8f\u3001\u4efb\u610f\u5b50\u96c6\u7684\u9884\u6d4b\uff0c\u7ed3\u5408\u4e86\u81ea\u56de\u5f52\u7684\u6df1\u5ea6\u5efa\u6a21\u548c\u6269\u6563\u6a21\u578b\u7684\u7075\u6d3b\u6027\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6269\u6563\u6a21\u578b\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u652f\u6301\u4efb\u610f\u987a\u5e8f\u751f\u6210\u548c\u53cc\u5411\u6761\u4ef6\u5316\uff0c\u4f46\u5355\u6b65\u4f9d\u8d56\u9650\u5236\u4e86\u5efa\u6a21\u6df1\u5ea6\uff0c\u5bfc\u81f4\u6837\u672c\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u4e0d\u5982\u81ea\u56de\u5f52\u6a21\u578b\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51faA3\u6846\u67b6\uff0c\u5c06\u81ea\u56de\u5f52\u5efa\u6a21\u91cd\u65b0\u8868\u8ff0\u4e3a\u7ed3\u6784\u5316\u591a\u7ec4\u9884\u6d4b\u8fc7\u7a0b\uff0c\u901a\u8fc7\u53cc\u6d41\u6ce8\u610f\u529b\u67b6\u6784\u548c\u6e10\u8fdb\u9002\u5e94\u7b56\u7565\uff0c\u5c06\u9884\u8bad\u7ec3\u81ea\u56de\u5f52\u6a21\u578b\u8f6c\u6362\u4e3a\u4efb\u610f\u987a\u5e8f\u9884\u6d4b\u3002", "result": "\u5728\u95ee\u7b54\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u6545\u4e8b\u586b\u5145\u7b49\u4efb\u52a1\u4e0a\uff0cA3\u4f18\u4e8e\u6269\u6563\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7075\u6d3b\u7684\u751f\u6210\u80fd\u529b\u3002", "conclusion": "A3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u65b0\u9896\u7684\u8bed\u8a00\u5efa\u6a21\u8303\u5f0f\uff0c\u7ed3\u5408\u4e86\u81ea\u56de\u5f52\u7684\u6df1\u5ea6\u5efa\u6a21\u548c\u6269\u6563\u6a21\u578b\u7684\u7075\u6d3b\u6027\u4f18\u52bf\u3002"}}
{"id": "2601.12971", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12971", "abs": "https://arxiv.org/abs/2601.12971", "authors": ["Pancheng Niu", "Jun Guo", "Qiaolin He", "Yongming Chen", "Yanchao Shi"], "title": "Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.", "AI": {"tldr": "\u63d0\u51faACR-PINN\uff0c\u901a\u8fc7\u5c42\u95f4\u52a8\u6001\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u8868\u793a\u80fd\u529b\uff0c\u5e76\u91c7\u7528\u51b2\u7a81\u68af\u5ea6\u66f4\u65b0\u7b56\u7565\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u5e72\u6270\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347PINNs\u7684\u6536\u655b\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u8868\u793a\u80fd\u529b\u6709\u9650\u548c\u4f18\u5316\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u7269\u7406\u7ea6\u675f\u7ade\u4e89\u548c\u68af\u5ea6\u51b2\u7a81\u3002\u9700\u8981\u4ece\u67b6\u6784-\u4f18\u5316\u534f\u540c\u8bbe\u8ba1\u7684\u89d2\u5ea6\u63d0\u5347PINN\u6027\u80fd\u3002", "method": "1. \u63d0\u51fa\u5c42\u95f4\u52a8\u6001\u6ce8\u610f\u529b\u673a\u5236\uff08LDA-PINN\uff09\u589e\u5f3a\u8868\u793a\u7075\u6d3b\u6027\uff1b2. \u5c06PINN\u8bad\u7ec3\u91cd\u6784\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u95ee\u9898\uff0c\u5f15\u5165\u51b2\u7a81\u68af\u5ea6\u66f4\u65b0\u7b56\u7565\uff08GC-PINN\uff09\uff1b3. \u6574\u5408\u4e24\u8005\u5f62\u6210ACR-PINN\uff0c\u4fdd\u6301\u6807\u51c6PINN\u635f\u5931\u5f62\u5f0f\u3002", "result": "\u5728Burgers\u3001Helmholtz\u3001Klein-Gordon\u65b9\u7a0b\u548c\u8154\u4f53\u9a71\u52a8\u6d41\u7b49\u57fa\u51c6PDE\u95ee\u9898\u4e0a\uff0cACR-PINN\u76f8\u6bd4\u6807\u51c6PINNs\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u663e\u8457\u66f4\u4f4e\u7684\u76f8\u5bf9L2\u548cL\u221e\u8bef\u5dee\u3002", "conclusion": "\u67b6\u6784-\u4f18\u5316\u534f\u540c\u8bbe\u8ba1\u80fd\u6709\u6548\u63d0\u5347PINN\u6c42\u89e3\u5668\u7684\u9c81\u68d2\u6027\u548c\u7cbe\u5ea6\uff0cACR-PINN\u901a\u8fc7\u6ce8\u610f\u529b\u8868\u793a\u548c\u51b2\u7a81\u611f\u77e5\u4f18\u5316\u7684\u7ed3\u5408\uff0c\u4e3aPINN\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13247", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13247", "abs": "https://arxiv.org/abs/2601.13247", "authors": ["Baochang Ren", "Yunzhi Yao", "Rui Sun", "Shuofei Qiao", "Ningyu Zhang", "Huajun Chen"], "title": "Aligning Agentic World Models via Knowledgeable Experience Learning", "comment": "Ongoing work", "summary": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.", "AI": {"tldr": "WorldMind\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\u89e3\u51b3LLMs\u7269\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u5229\u7528\u73af\u5883\u53cd\u9988\u7edf\u4e00\u8fc7\u7a0b\u7ecf\u9a8c\u548c\u76ee\u6807\u7ecf\u9a8c\uff0c\u5728EB-ALFRED\u548cEB-Habitat\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6a21\u6001\u9e3f\u6c9f\uff1a\u62e5\u6709\u4e30\u5bcc\u8bed\u4e49\u77e5\u8bc6\u4f46\u7f3a\u4e4f\u5bf9\u7269\u7406\u4e16\u754c\u4e0d\u53d8\u6cd5\u5219\u7684\u7a0b\u5e8f\u6027\u7406\u89e3\uff0c\u5bfc\u81f4\u4ea7\u751f\u7269\u7406\u4e0a\u4e0d\u53ef\u6267\u884c\u7684\u8ba1\u5212\uff08\u7269\u7406\u5e7b\u89c9\uff09\u3002\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8d44\u6e90\u5bc6\u96c6\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u96be\u4ee5\u9002\u5e94\u7269\u7406\u52a8\u6001\u7684\u5f00\u653e\u53ef\u53d8\u6027\u3002", "method": "\u5f15\u5165WorldMind\u6846\u67b6\uff0c\u901a\u8fc7\u7efc\u5408\u73af\u5883\u53cd\u9988\u81ea\u4e3b\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\u3002\u7edf\u4e00\u8fc7\u7a0b\u7ecf\u9a8c\uff08\u901a\u8fc7\u9884\u6d4b\u8bef\u5dee\u5f3a\u5236\u6267\u884c\u7269\u7406\u53ef\u884c\u6027\uff09\u548c\u76ee\u6807\u7ecf\u9a8c\uff08\u901a\u8fc7\u6210\u529f\u8f68\u8ff9\u6307\u5bfc\u4efb\u52a1\u6700\u4f18\u6027\uff09\u3002", "result": "\u5728EB-ALFRED\u548cEB-Habitat\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cWorldMind\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u5177\u6709\u663e\u8457\u7684\u8de8\u6a21\u578b\u548c\u8de8\u73af\u5883\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "WorldMind\u901a\u8fc7\u975e\u53c2\u6570\u5316\u7684\u7b26\u53f7\u77e5\u8bc6\u5e93\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLMs\u7684\u7269\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u53ef\u8fc1\u79fb\u7684\u7269\u7406\u4e16\u754c\u5bf9\u9f50\u65b9\u6848\u3002"}}
{"id": "2601.12988", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12988", "abs": "https://arxiv.org/abs/2601.12988", "authors": ["Zijian Wang", "Tiancheng Huang", "Hanqi Li", "Da Ma", "Lu Chen", "Kai Yu"], "title": "PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient", "comment": "35 pages, 9 figures, 7 tables", "summary": "The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.", "AI": {"tldr": "PaperCompass\uff1a\u4e00\u4e2a\u5206\u79bb\u9ad8\u5c42\u89c4\u5212\u4e0e\u7ec6\u7c92\u5ea6\u6267\u884c\u7684\u6846\u67b6\uff0c\u901a\u8fc7DFPO\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347LLM\u5728\u79d1\u5b66\u8bba\u6587\u9605\u8bfb\u4efb\u52a1\u4e2d\u7684\u6548\u7387", "motivation": "\u79d1\u5b66\u6587\u732e\u7684\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u901a\u8fc7\u624b\u52a8\u9605\u8bfb\u8ddf\u8e2a\u65b0\u8fdb\u5c55\uff0c\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u63a2\u7d22\u548c\u4f4e\u6548\u95ee\u9898", "method": "\u63d0\u51faPaperCompass\u6846\u67b6\uff0c\u5206\u79bb\u9ad8\u5c42\u89c4\u5212\u4e0e\u7ec6\u7c92\u5ea6\u6267\u884c\uff1a\u5148\u5236\u5b9a\u660e\u786e\u8ba1\u5212\uff0c\u518d\u8fdb\u884c\u8be6\u7ec6\u63a8\u7406\u6267\u884c\uff1b\u5f15\u5165DFPO\u8bad\u7ec3\u65b9\u6cd5\u8054\u5408\u4f18\u5316\u8ba1\u5212\u8349\u7a3f\u548c\u6700\u7ec8\u89e3\u51b3\u65b9\u6848", "result": "\u5728Paper-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPaperCompass\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u53d6\u5f97\u4e86\u4e0e\u66f4\u5927\u6a21\u578b\u76f8\u5f53\u7684\u7ed3\u679c", "conclusion": "PaperCompass\u901a\u8fc7\u8ba4\u77e5\u79d1\u5b66\u542f\u53d1\u7684\u5206\u5c42\u65b9\u6cd5\uff0c\u6709\u6548\u7f29\u5c0fLLM\u7684\"\u77e5\u884c\u5dee\u8ddd\"\uff0c\u4e3a\u79d1\u5b66\u6587\u732e\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13251", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13251", "abs": "https://arxiv.org/abs/2601.13251", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph", "comment": null, "summary": "Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.", "AI": {"tldr": "\u63d0\u51fa\u5927\u89c4\u6a21\u8bed\u4e49\u805a\u7c7b\u7cfb\u7edf\uff0c\u89e3\u51b3\u5d4c\u5165\u6a21\u578b\u65e0\u6cd5\u533a\u5206\u540c\u4e49\u8bcd\u4e0e\u53cd\u4e49\u8bcd\u7684\u76f2\u70b9\uff0c\u901a\u8fc7\u4e09\u8def\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\u548c\u8f6f\u5230\u786c\u805a\u7c7b\u7b97\u6cd5\u751f\u6210290\u4e07\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u7c07\u3002", "motivation": "\u795e\u7ecf\u5d4c\u5165\u6a21\u578b\u5b58\u5728\u663e\u8457\u76f2\u70b9\uff1a\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\uff0c\u5bfc\u81f4\u63d0\u9ad8\u76f8\u4f3c\u5ea6\u9608\u503c\u65f6\u4ecd\u4f1a\u5c06\u53cd\u4e49\u8bcd\u5f52\u4e3a\u4e00\u7c7b\u3002\u73b0\u6709\u540c\u4e49\u8bcd\u6570\u636e\u5e93\u5728\u5f62\u6001\u4e30\u5bcc\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7a00\u758f\uff0c\u9700\u8981\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u805a\u7c7b\u7cfb\u7edf\u3002", "method": "1) \u6784\u5efa84.3\u4e07\u6982\u5ff5\u5bf9\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u540c\u4e49\u3001\u53cd\u4e49\u548c\u5171\u4e0b\u4f4d\u5173\u7cfb\uff0c\u4f7f\u7528Gemini 2.5-Flash LLM\u589e\u5f3a\u548c\u4eba\u5de5\u8bcd\u5178\u9a8c\u8bc1\uff1b2) \u63d0\u51fa\u4e09\u8def\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\uff0c\u5b9e\u73b090%\u5b8fF1\u5206\u6570\uff1b3) \u8bbe\u8ba1\u65b0\u9896\u7684\u8f6f\u5230\u786c\u805a\u7c7b\u7b97\u6cd5\uff0c\u91c7\u7528\u62d3\u6251\u611f\u77e5\u7684\u4e24\u9636\u6bb5\u6269\u5c55-\u526a\u679d\u8fc7\u7a0b\u548c\u62d3\u6251\u6295\u7968\uff0c\u9632\u6b62\u8bed\u4e49\u6f02\u79fb\u548c\u9519\u8bef\u4f20\u9012\u94fe\u3002", "result": "\u5904\u74061500\u4e07\u8bcd\u6c47\u9879\uff0c\u8bc4\u4f305.2\u4ebf\u6f5c\u5728\u5173\u7cfb\uff0c\u751f\u6210290\u4e07\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u7c07\u3002\u7cfb\u7edf\u80fd\u7cbe\u786e\u5206\u914d\u6bcf\u4e2a\u672f\u8bed\u5230\u5355\u4e00\u8bed\u4e49\u8fde\u8d2f\u7c07\uff0c\u89e3\u51b3\u591a\u4e49\u8bcd\u95ee\u9898\uff0c\u4e3a\u5f62\u6001\u4e30\u5bcc\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bed\u4e49\u641c\u7d22\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8d44\u6e90\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u795e\u7ecf\u5d4c\u5165\u7684\u540c\u4e49-\u53cd\u4e49\u533a\u5206\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u5173\u7cfb\u5224\u522b\u5668\u548c\u805a\u7c7b\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u805a\u7c7b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u73b0\u6709\u540c\u4e49\u8bcd\u6570\u636e\u5e93\u7a00\u758f\u7684\u8bed\u8a00\uff0c\u4e3a\u8bed\u4e49\u641c\u7d22\u548cRAG\u5e94\u7528\u63d0\u4f9b\u5f3a\u5927\u8d44\u6e90\u3002"}}
{"id": "2601.13013", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13013", "abs": "https://arxiv.org/abs/2601.13013", "authors": ["Xiaohui Zhao", "Xinjian Zhao", "Jiahui Zhang", "Guoyu Liu", "Houzhi Wang", "Shu Wu"], "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads", "comment": null, "summary": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.", "AI": {"tldr": "HT-GNN\u6a21\u578b\u901a\u8fc7\u8d85\u56fe\u76d1\u7763\u6a21\u5757\u3001Transformer\u65f6\u5e8f\u7f16\u7801\u5668\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u65b0\u95fb\u5e7f\u544aLTV\u9884\u6d4b\u4e2d\u7684\u7528\u6237\u7fa4\u4f53\u5f02\u8d28\u6027\u548c\u52a8\u6001\u884c\u4e3a\u5e8f\u5217\u4e24\u5927\u6311\u6218\u3002", "motivation": "\u65b0\u95fb\u5e7f\u544a\u4e2d\u7684LTV\u9884\u6d4b\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u7684\u76ee\u6807\u5b9a\u4f4d\u5bfc\u81f4\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684LTV\u5206\u5e03\u5dee\u5f02\u5de8\u5927\uff1b2) \u52a8\u6001\u8425\u9500\u7b56\u7565\u4ea7\u751f\u4e0d\u89c4\u5219\u7684\u884c\u4e3a\u5e8f\u5217\uff0c\u7528\u6237\u53c2\u4e0e\u6a21\u5f0f\u5feb\u901f\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u8d85\u65f6\u5e8f\u56fe\u795e\u7ecf\u7f51\u7edc(HT-GNN)\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u8d85\u56fe\u76d1\u7763\u6a21\u5757\u6355\u6349\u8de8\u7528\u6237\u7fa4\u4f53\u5173\u7cfb\uff1b2) \u57fa\u4e8eTransformer\u7684\u81ea\u9002\u5e94\u52a0\u6743\u65f6\u5e8f\u7f16\u7801\u5668\uff1b3) \u4efb\u52a1\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u673a\u5236\uff0c\u4f7f\u7528\u52a8\u6001\u9884\u6d4b\u5854\u8fdb\u884c\u591a\u65f6\u95f4\u8303\u56f4LTV\u9884\u6d4b\u3002", "result": "\u5728\u767e\u5ea6\u5e7f\u544a\u5e73\u53f0\u76841500\u4e07\u7528\u6237\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cHT-GNN\u5728\u6240\u6709\u6307\u6807\u548c\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "HT-GNN\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u4eba\u53e3\u7edf\u8ba1\u5f02\u8d28\u6027\u548c\u65f6\u5e8f\u52a8\u6001\uff0c\u6709\u6548\u89e3\u51b3\u4e86LTV\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5e7f\u544a\u5e73\u53f0\u7684\u7ade\u4ef7\u548c\u9884\u7b97\u5206\u914d\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u957f\u671f\u4ef7\u503c\u9884\u6d4b\u3002"}}
{"id": "2601.13253", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13253", "abs": "https://arxiv.org/abs/2601.13253", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus", "comment": null, "summary": "We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u5e76\u4ee5\u571f\u8033\u5176\u8bed\u4e3a\u4f8b\u6784\u5efa\u4e86\u5305\u542b84.3\u4e07\u5bf9\u8bed\u4e49\u5173\u7cfb\u7684\u8bed\u6599\u5e93\uff0c\u6210\u672c\u4ec565\u7f8e\u5143\u3002", "motivation": "\u89e3\u51b3\u571f\u8033\u5176\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u73b0\u6709\u8d44\u6e90\u89c4\u6a21\u6709\u9650\u4e14\u6210\u672c\u9ad8\u6602\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff1a1) \u4f7f\u7528FastText\u8bcd\u5411\u91cf\u548c\u51dd\u805a\u805a\u7c7b\u8bc6\u522b\u8bed\u4e49\u7c07\uff1b2) \u5229\u7528Gemini 2.5-Flash\u8fdb\u884c\u81ea\u52a8\u8bed\u4e49\u5173\u7cfb\u5206\u7c7b\uff1b3) \u6574\u5408\u7ecf\u8fc7\u7b5b\u9009\u7684\u8bcd\u5178\u8d44\u6e90\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b84.3\u4e07\u4e2a\u571f\u8033\u5176\u8bed\u8bed\u4e49\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u8986\u76d6\u540c\u4e49\u8bcd\u3001\u53cd\u4e49\u8bcd\u548c\u5171\u4e0b\u4f4d\u8bcd\u4e09\u79cd\u5173\u7cfb\u7c7b\u578b\uff0c\u89c4\u6a21\u662f\u73b0\u6709\u8d44\u6e90\u768410\u500d\u3002\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u5d4c\u5165\u6a21\u578b\u8fbe\u523090%\u7684top-1\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u5206\u7c7b\u6a21\u578b\u83b7\u5f9790%\u7684F1-macro\u5206\u6570\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ee5\u6781\u4f4e\u6210\u672c\u6709\u6548\u89e3\u51b3\u4e86\u571f\u8033\u5176\u8bedNLP\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u9002\u7528\u4e8e\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002\u6570\u636e\u96c6\u548c\u6a21\u578b\u5df2\u516c\u5f00\u3002"}}
{"id": "2601.13020", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13020", "abs": "https://arxiv.org/abs/2601.13020", "authors": ["Zhiyan Hou", "Haiyun Guo", "Haokai Ma", "Yandu Sun", "Yonghui Yang", "Jinqiao Wang"], "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning", "comment": null, "summary": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51faPASs\uff08\u8def\u5f84\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff09\u65b9\u6cd5\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4e2d\u7684\u4e13\u5bb6\u5171\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u8def\u5f84\u6fc0\u6d3b\u4fe1\u53f7\u6821\u51c6\u8def\u7531\u5e76\u7a33\u5b9a\u91cd\u8981\u79e9\u65b9\u5411\uff0c\u63d0\u5347\u51c6\u786e\u6027\u548c\u6297\u9057\u5fd8\u80fd\u529b", "motivation": "\u73b0\u6709\u57fa\u4e8eLoRA\u7684MoE\u65b9\u6cd5\u5728\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u4e2d\uff0c\u8def\u7531\u5668\u548c\u4e13\u5bb6\u4f1a\u5171\u540c\u6f02\u79fb\uff0c\u5bfc\u81f4\u65e9\u671f\u8f93\u5165-\u4e13\u5bb6\u4e13\u4e1a\u5316\u9010\u6e10\u504f\u79bb\uff0c\u9020\u6210\u4e13\u5bb6\u8d23\u4efb\u6a21\u7cca\u548c\u9057\u5fd8\u52a0\u5267\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\"\u9519\u4f4d\u5171\u6f02\u79fb\"\u73b0\u8c61", "method": "\u63d0\u51fa\u8def\u5f84\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff08PASs\uff09\u4f5c\u4e3a\u80fd\u529b\u5bf9\u9f50\u7684\u5750\u6807\u7cfb\u7edf\uff0c\u57fa\u4e8e\u6b64\u5f00\u53d1PASs-based MoE-LoRA\u65b9\u6cd5\uff0c\u5305\u542bPAS\u5f15\u5bfc\u7684\u91cd\u65b0\u52a0\u6743\uff08\u6821\u51c6\u8def\u7531\uff09\u548cPAS\u611f\u77e5\u7684\u79e9\u7a33\u5b9a\u5316\uff08\u9009\u62e9\u6027\u7a33\u5b9a\u91cd\u8981\u79e9\u65b9\u5411\uff09\u4e24\u4e2a\u7ec4\u4ef6", "result": "\u5728\u6301\u7eed\u6307\u4ee4\u8c03\u4f18\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6297\u9057\u5fd8\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u57fa\u7ebf\u548c\u591a\u79cdMoE-LoRA\u53d8\u4f53\uff0c\u4e14\u4e0d\u589e\u52a0\u989d\u5916\u53c2\u6570", "conclusion": "PASs\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MoE-LoRA\u4e2d\u7684\u9519\u4f4d\u5171\u6f02\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u8def\u5f84\u6fc0\u6d3b\u4fe1\u53f7\u6821\u51c6\u8def\u7531\u548c\u9009\u62e9\u6027\u7a33\u5b9a\u91cd\u8981\u79e9\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6301\u7eed\u5b66\u4e60\u6027\u80fd"}}
{"id": "2601.13260", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13260", "abs": "https://arxiv.org/abs/2601.13260", "authors": ["Sawsan Alqahtani", "Mir Tafseer Nayeem", "Md Tahmid Rahman Laskar", "Tasnim Mohiuddin", "M Saiful Bari"], "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models", "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally", "summary": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06\u5206\u8bcd\u89c6\u4e3a\u6838\u5fc3\u5efa\u6a21\u51b3\u7b56\u800c\u975e\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u8bcd\u5668\u4e0e\u6a21\u578b\u534f\u540c\u8bbe\u8ba1\u6765\u6539\u8fdb\u8bed\u8a00\u6280\u672f\u7684\u516c\u5e73\u6027\u3001\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u5f53\u524d\u5206\u8bcd\u65b9\u6cd5\uff08\u5982BPE\uff09\u867d\u7136\u53ef\u6269\u5c55\uff0c\u4f46\u5b58\u5728\u4e0e\u8bed\u8a00\u7ed3\u6784\u4e0d\u5bf9\u9f50\u3001\u653e\u5927\u504f\u89c1\u3001\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u9886\u57df\u6d6a\u8d39\u5bb9\u91cf\u7b49\u95ee\u9898\u3002\u5206\u8bcd\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7840\u7ec4\u4ef6\uff0c\u5374\u7f3a\u4e4f\u7406\u8bba\u7814\u7a76\u548c\u4e00\u81f4\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\uff0c\u5c06\u5206\u8bcd\u5668\u4e0e\u6a21\u578b\u534f\u540c\u8bbe\u8ba1\uff0c\u8003\u8651\u8bed\u8a00\u3001\u9886\u57df\u548c\u90e8\u7f72\u56e0\u7d20\u3002\u5f3a\u8c03\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u900f\u660e\u62a5\u544a\uff0c\u4f7f\u5206\u8bcd\u9009\u62e9\u53ef\u95ee\u8d23\u548c\u53ef\u6bd4\u8f83\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\uff0c\u4f46\u672a\u62a5\u544a\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\u3002\u4e3b\u5f20\u901a\u8fc7\u5c06\u5206\u8bcd\u89c6\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u95ee\u9898\u800c\u975e\u6280\u672f\u540e\u5904\u7406\uff0c\u53ef\u4ee5\u4ea7\u751f\u66f4\u516c\u5e73\u3001\u9ad8\u6548\u548c\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u6280\u672f\u3002", "conclusion": "\u5206\u8bcd\u5e94\u88ab\u89c6\u4e3a\u6838\u5fc3\u5efa\u6a21\u51b3\u7b56\uff0c\u9700\u8981\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\u3002\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u900f\u660e\u62a5\u544a\u5bf9\u4e8e\u5b9e\u73b0\u516c\u5e73\u3001\u9ad8\u6548\u548c\u9002\u5e94\u6027\u5f3a\u7684\u8bed\u8a00\u6280\u672f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.13021", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13021", "abs": "https://arxiv.org/abs/2601.13021", "authors": ["Nata\u0161a Petrovi\u0107", "Gabriel Moy\u00e0-Alcover", "Antoni Jaume-i-Cap\u00f3", "Jose Maria Buades Rubio"], "title": "Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis", "comment": null, "summary": "This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\\% and SDS-score 89.51\\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u9570\u72b6\u7ec6\u80de\u75c5\u7684\u8840\u6db2\u6d82\u7247\u56fe\u50cf\u8bca\u65ad\u652f\u6301\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u6a21\u578b\u4f18\u5316\u5b9e\u73b0\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u9570\u72b6\u7ec6\u80de\u75c5\u7684\u51c6\u786e\u8bca\u65ad\u9700\u8981\u53ef\u9760\u7684\u652f\u6301\u7cfb\u7edf\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u53c8\u80fd\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9\u8840\u6db2\u6d82\u7247\u56fe\u50cf\u8fdb\u884c\u9884\u5904\u7406\u548c\u5206\u5272\uff0c\u63d0\u53d6\u9ad8\u8d28\u91cf\u7279\u5f81\uff1b\u91c7\u7528\u96c6\u6210\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u968f\u673a\u68ee\u6797\u548c\u6781\u7aef\u968f\u673a\u6811\uff09\u8fdb\u884c\u5206\u7c7b\uff1b\u8bbe\u8ba1\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u65b9\u6cd5\u4ee5\u964d\u4f4e\u590d\u6742\u5ea6\uff1b\u4f7f\u7528\u65b0\u6570\u636e\u96c6\u9a8c\u8bc1\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u968f\u673a\u68ee\u6797\u548c\u6781\u7aef\u968f\u673a\u6811\u96c6\u6210\u6a21\u578b\u83b7\u5f97F1\u5206\u657090.71%\u548cSDS\u5206\u657093.33%\uff0c\u76f8\u6bd4\u68af\u5ea6\u63d0\u5347\u5206\u7c7b\u5668\uff08F1 87.32%\uff0cSDS 89.51%\uff09\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f73\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u5728\u9570\u72b6\u7ec6\u80de\u75c5\u8bca\u65ad\u652f\u6301\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u63d0\u4f9b\u4e86\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2601.13264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13264", "abs": "https://arxiv.org/abs/2601.13264", "authors": ["Tyler Lizzo", "Larry Heck"], "title": "Unlearning in LLMs: Methods, Evaluation, and Open Challenges", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u6280\u672f\u7684\u7efc\u8ff0\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u73b0\u6709\u7684\u9057\u5fd8\u65b9\u6cd5\u3001\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u5e7f\u6cdb\u90e8\u7f72\u5f15\u53d1\u4e86\u9690\u79c1\u3001\u7248\u6743\u3001\u5b89\u5168\u548c\u504f\u89c1\u7b49\u7d27\u8feb\u95ee\u9898\u3002\u673a\u5668\u9057\u5fd8\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u53ef\u4ee5\u5728\u4e0d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u6027\u5730\u4ece\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u77e5\u8bc6\u6216\u6570\u636e\u3002", "method": "\u8bba\u6587\u5bf9LLM\u9057\u5fd8\u65b9\u6cd5\u8fdb\u884c\u4e86\u7ed3\u6784\u5316\u6982\u8ff0\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u6570\u636e\u4e2d\u5fc3\u5316\u3001\u53c2\u6570\u4e2d\u5fc3\u5316\u3001\u67b6\u6784\u4e2d\u5fc3\u5316\u3001\u6df7\u5408\u7b56\u7565\u548c\u5176\u4ed6\u7b56\u7565\u7b49\u7c7b\u522b\u3002\u540c\u65f6\u56de\u987e\u4e86\u8bc4\u4f30\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u62ec\u7528\u4e8e\u8861\u91cf\u9057\u5fd8\u6548\u679c\u3001\u77e5\u8bc6\u4fdd\u7559\u548c\u9c81\u68d2\u6027\u7684\u57fa\u51c6\u3001\u6307\u6807\u548c\u6570\u636e\u96c6\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u673a\u5668\u9057\u5fd8\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u5206\u7c7b\u6846\u67b6\u548c\u8bc4\u4f30\u4f53\u7cfb\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8def\u7ebf\u56fe\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u5f53\u524d\u8fdb\u5c55\u5e76\u7a81\u51fa\u4e86\u5f00\u653e\u65b9\u5411\uff0c\u65e8\u5728\u4e3a\u5f00\u53d1\u53ef\u9760\u548c\u8d1f\u8d23\u4efb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6280\u672f\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002\u6307\u51fa\u4e86\u53ef\u6269\u5c55\u6548\u7387\u3001\u5f62\u5f0f\u5316\u4fdd\u8bc1\u3001\u8de8\u8bed\u8a00\u548c\u591a\u6a21\u6001\u9057\u5fd8\u3001\u5bf9\u6297\u6027\u91cd\u65b0\u5b66\u4e60\u9c81\u68d2\u6027\u7b49\u5173\u952e\u6311\u6218\u548c\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2601.13048", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13048", "abs": "https://arxiv.org/abs/2601.13048", "authors": ["Srividya Ravikumar", "Abhinav Anand", "Shweta Verma", "Mira Mezini"], "title": "Analysis of Long Range Dependency Understanding in State Space Models", "comment": null, "summary": "Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u5e94\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\uff08\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\uff09\u7684S4D\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u6838\u53ef\u89e3\u91ca\u6027\u7814\u7a76\uff0c\u53d1\u73b0S4D\u7684\u957f\u7a0b\u5efa\u6a21\u80fd\u529b\u56e0\u67b6\u6784\u4e0d\u540c\u800c\u6709\u663e\u8457\u5dee\u5f02\uff0c\u5176\u6838\u53ef\u8868\u73b0\u4e3a\u4f4e\u901a\u3001\u5e26\u901a\u6216\u9ad8\u901a\u6ee4\u6ce2\u5668\u7279\u6027\u3002", "motivation": "\u5c3d\u7ba1\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u5728\u957f\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u800c\u975e\u53ef\u89e3\u91ca\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9996\u6b21\u5bf9\u5e94\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u7684S4D\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u6838\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u65f6\u57df\u548c\u9891\u57df\u5206\u6790S4D\u6838\uff0c\u7814\u7a76\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0bS4D\u7684\u957f\u7a0b\u5efa\u6a21\u80fd\u529b\u53d8\u5316\u3002\u5177\u4f53\u5206\u6790S4D\u6838\u5728\u4e0d\u540c\u67b6\u6784\u4e0b\u7684\u6ee4\u6ce2\u5668\u7279\u6027\uff08\u4f4e\u901a\u3001\u5e26\u901a\u3001\u9ad8\u901a\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0S4D\u7684\u957f\u7a0b\u5efa\u6a21\u80fd\u529b\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002S4D\u6838\u53ef\u8868\u73b0\u4e3a\u4f4e\u901a\u3001\u5e26\u901a\u6216\u9ad8\u901a\u6ee4\u6ce2\u5668\u7279\u6027\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u67b6\u6784\u8bbe\u8ba1\u3002", "conclusion": "\u672c\u6587\u7684\u5206\u6790\u7ed3\u679c\u4e3a\u672a\u6765\u8bbe\u8ba1\u66f4\u597d\u7684\u57fa\u4e8eS4D\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u67b6\u6784\u8bbe\u8ba1\u5bf9S4D\u957f\u7a0b\u5efa\u6a21\u80fd\u529b\u7684\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2601.13288", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13288", "abs": "https://arxiv.org/abs/2601.13288", "authors": ["Gonzalo Ariel Meyoyan", "Luciano Del Corro"], "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification", "comment": null, "summary": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u590d\u7528\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4f7f\u7528\u72ec\u7acb\u7684\u5b89\u5168\u6a21\u578b\uff0c\u964d\u4f4e\u5ef6\u8fdf\u548c\u5185\u5b58\u6d88\u8017", "motivation": "\u5f53\u524d\u751f\u4ea7\u7ea7LLM\u7cfb\u7edf\u901a\u5e38\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\u8fdb\u884c\u5b89\u5168\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u4f1a\u589e\u52a0\u5ef6\u8fdf\u3001\u663e\u5b58\u5360\u7528\u548c\u8fd0\u7ef4\u590d\u6742\u5ea6\u3002\u4f5c\u8005\u5e0c\u671b\u590d\u7528LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5df2\u7ecf\u8ba1\u7b97\u5f97\u5230\u7684\u9690\u85cf\u72b6\u6001\uff0c\u907f\u514d\u989d\u5916\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eLLM\u9690\u85cf\u72b6\u6001\u7684\u8f7b\u91cf\u7ea7\u63a2\u9488\u65b9\u6cd5\uff1a1\uff09\u5c06\u5206\u7c7b\u4efb\u52a1\u5b9a\u4e49\u4e3a\u5728\u5b8c\u6574token-layer\u9690\u85cf\u72b6\u6001\u5f20\u91cf\u4e0a\u7684\u8868\u793a\u9009\u62e9\uff1b2\uff09\u5f15\u5165\u4e24\u9636\u6bb5\u805a\u5408\u5668\uff1a\u5148\u603b\u7ed3\u6bcf\u5c42\u5185\u7684token\uff0c\u518d\u805a\u5408\u8de8\u5c42\u603b\u7ed3\uff1b3\uff09\u5b9e\u73b0\u4e09\u79cd\u63a2\u9488\u53d8\u4f53\uff1a\u76f4\u63a5\u6c60\u5316\u300110\u4e07\u53c2\u6570\u8bc4\u5206\u6ce8\u610f\u529b\u95e8\u3001\u6700\u591a3500\u4e07\u53c2\u6570\u7684\u4e0b\u91c7\u6837\u591a\u5934\u81ea\u6ce8\u610f\u529b\u63a2\u9488\u3002", "result": "\u5728\u5b89\u5168\u548c\u60c5\u611f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ec5\u4f7f\u7528logit\u7684\u590d\u7528\u65b9\u6cd5\uff08\u5982MULI\uff09\uff0c\u4e0e\u66f4\u5927\u7684\u4efb\u52a1\u7279\u5b9a\u57fa\u7ebf\u6a21\u578b\u7ade\u4e89\u6027\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u63a8\u7406\u5ef6\u8fdf\uff0c\u907f\u514d\u4e86\u72ec\u7acb\u9632\u62a4\u6a21\u578b\u7ba1\u9053\u7684\u663e\u5b58\u548c\u5ef6\u8fdf\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7\u590d\u7528LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9690\u85cf\u72b6\u6001\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\uff0c\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u663e\u8457\u5ef6\u8fdf\u548c\u5185\u5b58\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u5b8c\u6210\u5b89\u5168\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u7b80\u5316\u751f\u4ea7\u7cfb\u7edf\u67b6\u6784\u3002"}}
{"id": "2601.13054", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13054", "abs": "https://arxiv.org/abs/2601.13054", "authors": ["Kamogelo Taueatsoala", "Caitlyn Daniels", "Angelina J. Ramsunar", "Petrus Bronkhorst", "Absalom E. Ezugwu"], "title": "TinyML-Enabled IoT for Sustainable Precision Irrigation", "comment": null, "summary": "Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u548cTinyML\u7684\u667a\u80fd\u7cbe\u51c6\u704c\u6e89\u7cfb\u7edf\uff0c\u4e13\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u5c0f\u89c4\u6a21\u519c\u573a\u8bbe\u8ba1\uff0c\u65e0\u9700\u4e91\u4f9d\u8d56\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u8282\u6c34\u3002", "motivation": "\u5c0f\u89c4\u6a21\u519c\u4e1a\u793e\u533a\u9762\u4e34\u6c34\u8d44\u6e90\u77ed\u7f3a\u3001\u6c14\u5019\u6a21\u5f0f\u4e0d\u7a33\u5b9a\u4ee5\u53ca\u7f3a\u4e4f\u5148\u8fdb\u3001\u7ecf\u6d4e\u5b9e\u60e0\u7684\u519c\u4e1a\u6280\u672f\u7b49\u95ee\u9898\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u79bb\u7ebf\u53ef\u7528\u7684\u667a\u80fd\u704c\u6e89\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u56db\u5c42\u8fb9\u7f18\u4f18\u5148IoT\u67b6\u6784\uff0c\u96c6\u6210\u4f4e\u6210\u672c\u786c\u4ef6\uff08ESP32\u5fae\u63a7\u5236\u5668\u4f5c\u4e3a\u8fb9\u7f18\u63a8\u7406\u8282\u70b9\uff0cRaspberry Pi\u4f5c\u4e3a\u672c\u5730\u8fb9\u7f18\u670d\u52a1\u5668\uff09\uff0c\u4f7f\u7528\u591a\u79cd\u73af\u5883\u4f20\u611f\u5668\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u9009\u62e9\u68af\u5ea6\u63d0\u5347\u6a21\u578b\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u8f7b\u91cf\u7ea7TinyML\u63a8\u7406\u5f15\u64ce\u90e8\u7f72\u5728ESP32\u4e0a\uff0c\u91c7\u7528\u57fa\u4e8eMQTT\u7684\u5c40\u57df\u7f51\u901a\u4fe1\u534f\u8bae\u3002", "result": "\u68af\u5ea6\u63d0\u5347\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08R\u00b2=0.9973\uff0cMAPE=0.99%\uff09\uff0c\u4f18\u4e8e\u968f\u673a\u68ee\u6797\u6a21\u578b\uff08R\u00b2=0.9916\uff0cMAPE=1.81%\uff09\u3002\u7cfb\u7edf\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u9a8c\u8bc1\u663e\u793a\u663e\u8457\u51cf\u5c11\u7528\u6c34\u91cf\uff0cTinyML\u90e8\u7f72\u540e\u9884\u6d4b\u7cbe\u5ea6\u4fdd\u6301MAPE<1%\uff0c\u7cfb\u7edf\u5177\u5907\u4f4e\u529f\u8017\u548c\u79bb\u7ebf\u529f\u80fd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u519c\u6751\u73af\u5883\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8bbe\u5907\u7aef\u4eba\u5de5\u667a\u80fd\u7f29\u5c0f\u519c\u4e1a\u6280\u672f\u9e3f\u6c9f\uff0c\u63d0\u9ad8\u6c34\u8d44\u6e90\u5229\u7528\u6548\u7387\uff0c\u5177\u5907\u53ef\u6301\u7eed\u3001\u53ef\u6269\u5c55\u7684\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2601.13300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13300", "abs": "https://arxiv.org/abs/2601.13300", "authors": ["Yow-Fu Liou", "Yu-Chien Tang", "Yu-Hsiang Liu", "An-Zi Yen"], "title": "OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference", "comment": null, "summary": "Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOI-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5728\u591a\u9009\u9898\u754c\u9762\u6ce8\u5165\u8bef\u5bfc\u6027\u6307\u4ee4\u9009\u9879\uff0c\u7cfb\u7edf\u8bc4\u4f30LLM\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660eLLM\u51b3\u7b56\u4f1a\u53d7\u5230\u793e\u4ea4\u7ebf\u7d22\u3001\u6846\u67b6\u6548\u5e94\u548c\u6307\u4ee4\u7b49\u5bfc\u5411\u4fe1\u53f7\u7684\u5f71\u54cd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u9009\u62e9\u9898\u754c\u9762\u4e2d\u5bf9\u6307\u4ee4\u5e72\u6270\u9c81\u68d2\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u9009\u9879\u6ce8\u5165\u65b9\u6cd5\uff0c\u5728MCQA\u754c\u9762\u4e2d\u589e\u52a0\u5305\u542b\u8bef\u5bfc\u6027\u6307\u4ee4\u7684\u989d\u5916\u9009\u9879\uff1b\u6784\u5efaOI-Bench\u57fa\u51c6\uff0c\u5305\u542b3000\u4e2a\u6db5\u76d6\u77e5\u8bc6\u3001\u63a8\u7406\u548c\u5e38\u8bc6\u4efb\u52a1\u7684\u95ee\u9898\uff0c\u6d89\u53ca16\u79cd\u6307\u4ee4\u7c7b\u578b\uff1b\u8bc4\u4f3012\u4e2aLLM\u7684\u653b\u51fb\u6210\u529f\u7387\u3001\u884c\u4e3a\u54cd\u5e94\uff0c\u5e76\u7814\u7a76\u4ece\u63a8\u7406\u65f6\u63d0\u793a\u5230\u8bad\u7ec3\u540e\u5bf9\u9f50\u7684\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u9c81\u68d2\u6027\u5b58\u5728\u5f02\u8d28\u6027\uff1bOI-Bench\u80fd\u591f\u652f\u6301\u5bf9LLM\u5728\u57fa\u4e8e\u9009\u62e9\u7684\u754c\u9762\u4e2d\u5bf9\u6307\u4ee4\u5e72\u6270\u9c81\u68d2\u6027\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "conclusion": "\u9009\u9879\u6ce8\u5165\u65b9\u6cd5\u6709\u6548\u63ed\u793a\u4e86LLM\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u8106\u5f31\u6027\uff0cOI-Bench\u4e3a\u7cfb\u7edf\u8bc4\u4f30LLM\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u5c40\u9650\u6027\u5e76\u5f00\u53d1\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2601.13075", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13075", "abs": "https://arxiv.org/abs/2601.13075", "authors": ["Abhinav Rajeev Kumar", "Dhruv Trehan", "Paras Chopra"], "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions", "comment": "12 pages, 5 figures, 4 tables", "summary": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.", "AI": {"tldr": "METIS\u662f\u4e00\u4e2aAI\u7814\u7a76\u5bfc\u5e08\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u6307\u5bfc\u3001\u6587\u732e\u641c\u7d22\u3001\u65b9\u6cd5\u8bba\u68c0\u67e5\u7b49\u529f\u80fd\uff0c\u5e2e\u52a9\u672c\u79d1\u751f\u4ece\u60f3\u6cd5\u5230\u8bba\u6587\u5199\u4f5c\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u4e2d\u4f18\u4e8eGPT-5\u548cClaude Sonnet 4.5\u3002", "motivation": "\u8bb8\u591a\u5b66\u751f\u7f3a\u4e4f\u4e13\u5bb6\u7814\u7a76\u6307\u5bfc\uff0c\u9700\u8981AI\u5bfc\u5e08\u5e2e\u52a9\u672c\u79d1\u751f\u5b8c\u6210\u4ece\u7814\u7a76\u60f3\u6cd5\u5230\u8bba\u6587\u5199\u4f5c\u7684\u5168\u8fc7\u7a0b\u3002", "method": "\u6784\u5efaMETIS\u7cfb\u7edf\uff0c\u5305\u542b\u5de5\u5177\u589e\u5f3a\u3001\u9636\u6bb5\u611f\u77e5\u7684\u52a9\u624b\u529f\u80fd\uff0c\u5177\u6709\u6587\u732e\u641c\u7d22\u3001\u6307\u5bfc\u6307\u5357\u3001\u65b9\u6cd5\u8bba\u68c0\u67e5\u548c\u8bb0\u5fc6\u529f\u80fd\u3002\u901a\u8fc7LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u6210\u5bf9\u504f\u597d\u3001\u5b66\u751f\u89d2\u8272\u8bc4\u5206\u6807\u51c6\u3001\u591a\u8f6e\u8f85\u5bfc\u548c\u8bc1\u636e/\u5408\u89c4\u6027\u68c0\u67e5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u572890\u4e2a\u5355\u8f6e\u63d0\u793a\u4e2d\uff0cLLM\u8bc4\u5224\u8005\u66f4\u504f\u597dMETIS\u800c\u4e0d\u662fClaude Sonnet 4.5\uff0871%\uff09\u548cGPT-5\uff0854%\uff09\u3002\u5b66\u751f\u8bc4\u5206\u5728\u6e05\u6670\u5ea6/\u53ef\u64cd\u4f5c\u6027/\u7ea6\u675f\u9002\u5e94\u6027\u65b9\u9762\u66f4\u9ad8\u3002\u5728\u591a\u8f6e\u4f1a\u8bdd\u4e2d\uff0cMETIS\u7684\u6700\u7ec8\u8d28\u91cf\u7565\u9ad8\u4e8eGPT-5\u3002\u4f18\u52bf\u96c6\u4e2d\u5728\u6587\u6863\u57fa\u7840\u9636\u6bb5\u3002", "conclusion": "METIS\u4f5c\u4e3aAI\u7814\u7a76\u5bfc\u5e08\u5728\u5e2e\u52a9\u5b66\u751f\u5b8c\u6210\u8bba\u6587\u5199\u4f5c\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u6587\u6863\u57fa\u7840\u9636\u6bb5\uff0c\u4f46\u5b58\u5728\u5de5\u5177\u8def\u7531\u8fc7\u65e9\u3001\u57fa\u7840\u4e0d\u591f\u6df1\u5165\u548c\u9636\u6bb5\u5206\u7c7b\u9519\u8bef\u7b49\u5931\u8d25\u6a21\u5f0f\u3002"}}
{"id": "2601.13100", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13100", "abs": "https://arxiv.org/abs/2601.13100", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement", "comment": null, "summary": "Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.\n  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.\n  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.", "AI": {"tldr": "\u63d0\u51fa\u9012\u5f52\u5143\u84b8\u998f\u7684\u516c\u7406\u5316\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u9012\u5f52\u84b8\u998f\u4f1a\u6536\u655b\u5230\u57fa\u6559\u5e08\u5206\u5e03\u7684\u552f\u4e00\u56fa\u5b9a\u70b9\uff0c\u4e3a\u7406\u89e3\u8fed\u4ee3\u84b8\u998f\u7684\u7a33\u5b9a\u6027\u548c\u504f\u5dee-\u65b9\u5dee\u884c\u4e3a\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u6982\u7387\u57df\u77e5\u8bc6\u84b8\u998f\u7814\u7a76\u5df2\u5efa\u7acb\u5355\u9636\u6bb5\u8bbe\u7f6e\u4e0b\u7684\u516c\u7406\u6846\u67b6\uff0c\u4f46\u9012\u5f52\u6216\u591a\u4ee3\u84b8\u998f\u7684\u6570\u5b66\u884c\u4e3a\u7406\u89e3\u4e0d\u8db3\uff0c\u5148\u524d\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u542f\u53d1\u5f0f\u3002\u9700\u8981\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u9012\u5f52\u84b8\u998f\u4f55\u65f6\u6570\u5b66\u4e0a\u9002\u5b9a\u4e14\u6536\u655b\uff0c\u800c\u975e\u8bef\u5dee\u7d2f\u79ef\u3002", "method": "\u5f15\u5165\u9012\u5f52\u5143\u84b8\u998f\u7684\u516c\u7406\u5316\u548c\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u8fed\u4ee3\u77e5\u8bc6\u84b8\u998f\u5f62\u5f0f\u5316\u4e3a\u6982\u7387\u5206\u5e03\u7b97\u5b50\u5e8f\u5217\uff0c\u5e76\u660e\u786e\u951a\u5b9a\u5230\u57fa\u6559\u5e08\u3002\u5b9a\u4e49\u6709\u6548\u5143\u6559\u5e08\u6784\u5efa\u7684\u7ed3\u6784\u516c\u7406\uff0c\u8bc1\u660e\u5b58\u5728\u6ee1\u8db3\u8fd9\u4e9b\u516c\u7406\u7684\u975e\u5e73\u51e1\u7b97\u5b50\u65cf\uff0c\u4e0d\u4f9d\u8d56\u7279\u5b9a\u7b97\u6cd5\u6216\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u6e29\u548c\u53ef\u5b9e\u73b0\u6027\u548c\u51f8\u6027\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u951a\u5b9a\u9012\u5f52\u84b8\u998f\u5728KL\u6563\u5ea6\u4e0a\u8bf1\u5bfc\u6536\u7f29\uff0c\u4ea7\u751f\u5411\u57fa\u6559\u5e08\u5206\u5e03\u7684\u51e0\u4f55\u6536\u655b\u548c\u552f\u4e00\u5168\u5c40\u5438\u5f15\u56fa\u5b9a\u70b9\u3002\u6846\u67b6\u72ec\u7acb\u4e8e\u6a21\u578b\u67b6\u6784\u3001\u4f18\u5316\u7ec6\u8282\u6216\u5177\u4f53\u7b97\u5b50\u5b9e\u4f8b\u5316\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u662f\u57fa\u7840\u6027\u800c\u975e\u7b97\u6cd5\u6027\u7684\u8d21\u732e\uff0c\u6846\u67b6\u523b\u753b\u4e86\u9012\u5f52\u84b8\u998f\u4f55\u65f6\u6570\u5b66\u4e0a\u9002\u5b9a\u4e14\u6536\u655b\uff0c\u4e3a\u7406\u89e3\u5bb9\u91cf\u7ea6\u675f\u4e0b\u8fed\u4ee3\u548c\u591a\u6559\u5e08\u84b8\u998f\u7684\u7a33\u5b9a\u6027\u3001\u504f\u5dee-\u65b9\u5dee\u884c\u4e3a\u548c\u5931\u6548\u6a21\u5f0f\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.13319", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13319", "abs": "https://arxiv.org/abs/2601.13319", "authors": ["Peter Sullivan", "AbdelRahim Elmadany", "Alcides Alcoba Inciarte", "Muhammad Abdul-Mageed"], "title": "Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology", "comment": null, "summary": "Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u6570\u636e\u7684\u5f02\u8d28\u6027\uff0c\u63d0\u51fa\u4e86Arab Voices\u6807\u51c6\u5316\u6846\u67b6\u6765\u7edf\u4e0031\u4e2a\u6570\u636e\u96c6\uff0c\u5e76\u4e3a\u73b0\u4ee3\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00ASR\u5efa\u7acb\u4e86\u57fa\u51c6\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u6570\u636e\u5728\u9886\u57df\u8986\u76d6\u3001\u65b9\u8a00\u6807\u6ce8\u5b9e\u8df5\u548c\u5f55\u97f3\u6761\u4ef6\u4e0a\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u8fd9\u5bfc\u81f4\u8de8\u6570\u636e\u96c6\u6bd4\u8f83\u548c\u6a21\u578b\u8bc4\u4f30\u53d8\u5f97\u590d\u6742\u3002\u9700\u8981\u6807\u51c6\u5316\u8868\u5f81\u6765\u51cf\u5c11\u788e\u7247\u5316\u5e76\u652f\u6301\u53ef\u91cd\u590d\u8bc4\u4f30\u3002", "method": "1) \u5bf9\u5e7f\u6cdb\u4f7f\u7528\u7684\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u6599\u5e93\u8fdb\u884c\u8bed\u8a00\"\u65b9\u8a00\u6027\"\u7684\u8ba1\u7b97\u5206\u6790\uff1b2) \u4f7f\u7528\u97f3\u9891\u8d28\u91cf\u7684\u5ba2\u89c2\u4ee3\u7406\u6307\u6807\uff1b3) \u5f15\u5165Arab Voices\u6846\u67b6\uff0c\u7edf\u4e00\u8bbf\u95ee31\u4e2a\u6570\u636e\u96c6\uff0c\u6db5\u76d614\u79cd\u65b9\u8a00\uff0c\u63d0\u4f9b\u534f\u8c03\u7684\u5143\u6570\u636e\u548c\u8bc4\u4f30\u5de5\u5177\uff1b4) \u5bf9\u4e00\u7cfb\u5217\u6700\u65b0ASR\u7cfb\u7edf\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u6570\u636e\u96c6\u5728\u58f0\u5b66\u6761\u4ef6\u548c\u65b9\u8a00\u4fe1\u53f7\u5f3a\u5ea6\u53ca\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\u3002Arab Voices\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u591a\u4e2a\u6570\u636e\u96c6\uff0c\u5e76\u4e3a\u73b0\u4ee3\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00ASR\u5efa\u7acb\u4e86\u5f3a\u5927\u7684\u57fa\u51c6\u6027\u80fd\u3002", "conclusion": "\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u6570\u636e\u9700\u8981\u8d85\u8d8a\u7c97\u7c92\u5ea6\u6807\u7b7e\u7684\u6807\u51c6\u5316\u8868\u5f81\u3002Arab Voices\u6846\u67b6\u51cf\u5c11\u4e86\u788e\u7247\u5316\uff0c\u652f\u6301\u53ef\u91cd\u590d\u8bc4\u4f30\uff0c\u5e76\u4e3a\u8be5\u9886\u57df\u5efa\u7acb\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2601.13143", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13143", "abs": "https://arxiv.org/abs/2601.13143", "authors": ["Chaeyoung Jung", "Youngjoon Jang", "Seungwoo Lee", "Joon Son Chung"], "title": "FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference", "comment": null, "summary": "In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.", "AI": {"tldr": "FastAV\u662f\u9996\u4e2a\u9488\u5bf9\u97f3\u9891-\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\uff08AV-LLMs\uff09\u7684token\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u526a\u679d\u7b56\u7565\u51cf\u5c11\u8ba1\u7b97\u91cf40%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u867d\u7136token\u526a\u679d\u5728\u6807\u51c6LLMs\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u6709\u63a2\u7d22\uff0c\u4f46\u5728AV-LLMs\u4e2d\u5c1a\u672a\u5f97\u5230\u5173\u6ce8\u3002\u591a\u6a21\u6001\u6574\u5408\u663e\u8457\u589e\u52a0\u4e86token\u9700\u6c42\uff0c\u9700\u8981\u4e13\u95e8\u7684\u526a\u679d\u65b9\u6cd5\u6765\u89e3\u51b3\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u6743\u91cd\u8bc6\u522b\u4e0d\u540c\u9636\u6bb5\u7684\u91cd\u8981token\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u526a\u679d\u7b56\u7565\uff1a1\uff09\u4e2d\u95f4\u5c42\u5168\u5c40\u526a\u679d\u53bb\u9664\u5f71\u54cd\u529b\u8f83\u5c0f\u7684token\uff1b2\uff09\u540e\u7eed\u5c42\u7cbe\u7ec6\u526a\u679d\u8003\u8651\u5bf9\u4e0b\u4e00\u4e2atoken\u751f\u6210\u7684\u5f71\u54cd\u3002\u65b9\u6cd5\u5b8c\u5168\u517c\u5bb9FlashAttention\u7b49\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u4e24\u4e2a\u4ee3\u8868\u6027AV-LLMs\u4e0a\uff0cFastAV\u5c06FLOPs\u51cf\u5c11\u8d85\u8fc740%\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "FastAV\u4e3aAV-LLMs\u63d0\u4f9b\u4e86\u9996\u4e2a\u6709\u6548\u7684token\u526a\u679d\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u800c\u4e0d\u635f\u5bb3\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u6311\u6218\u3002"}}
{"id": "2601.13328", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13328", "abs": "https://arxiv.org/abs/2601.13328", "authors": ["Geoffrey Churchill", "Steven Skiena"], "title": "Reducing Tokenization Premiums for Low-Resource Languages", "comment": null, "summary": "Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.", "AI": {"tldr": "\u5206\u6790\u5341\u79cd\u6d41\u884c\u8bed\u8a00\u6a21\u578b\u7684tokenizer\u8bbe\u8ba1\uff0c\u63d0\u51fa\u901a\u8fc7\u540e\u5904\u7406\u589e\u52a0\u8bcd\u6c47\u8868\u6765\u51cf\u5c11\u4f4e\u8d44\u6e90\u8bed\u8a00tokenization\u6ea2\u4ef7\u7684\u65b9\u6cd5", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u76f8\u6bd4\u82f1\u8bed\u5b58\u5728\u663e\u8457\u7684tokenization\u6ea2\u4ef7\uff08\u9700\u8981\u66f4\u591atoken\u7f16\u7801\u76f8\u540c\u53e5\u5b50\uff09\uff0c\u5bfc\u81f4API\u548c\u80fd\u6e90\u6210\u672c\u589e\u52a0\u3001\u6709\u6548\u4e0a\u4e0b\u6587\u7a97\u53e3\u51cf\u5c11", "method": "\u5206\u6790\u5341\u79cd\u6d41\u884cLM\u7684tokenizer\u8bbe\u8ba1\uff0c\u63d0\u51fa\u540e\u5904\u7406\u673a\u5236\uff1a\u5411\u9884\u8bad\u7ec3\u6a21\u578b\u8bcd\u6c47\u8868\u4e2d\u6dfb\u52a0\u591a\u5b57\u7b26\u5408\u5e76\u4e3a\u5355token\u7684\u6761\u76ee", "result": "\u572812\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u53d1\u73b0\u539f\u59cb\u8f93\u5165\u548c\u538b\u7f29\u8f93\u5165\u5728Llama 3.2 1B\u6a21\u578b\u4e2d\u5177\u6709\u76f8\u4f3c\u7684\u6700\u540e\u4e00\u5c42\u9690\u85cf\u72b6\u6001", "conclusion": "\u63d0\u51fa\u7684\u540e\u5904\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684tokenization\u6ea2\u4ef7\uff0c\u4fdd\u6301\u6a21\u578b\u8868\u793a\u76f8\u4f3c\u6027\uff0c\u4e3a\u964d\u4f4e\u6210\u672c\u548c\u63d0\u5347\u6548\u7387\u63d0\u4f9b\u53ef\u884c\u65b9\u6848"}}
{"id": "2601.13160", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13160", "abs": "https://arxiv.org/abs/2601.13160", "authors": ["Zhipeng Zhang", "Zhenjie Yao", "Kai Li", "Lei Yang"], "title": "Training instability in deep learning follows low-dimensional dynamical principles", "comment": null, "summary": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.\n  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.\n  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4ece\u52a8\u529b\u5b66\u89c6\u89d2\u7edf\u4e00\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5c06\u5176\u5206\u4e3a\u4f18\u5316\u3001\u73af\u5883/\u6570\u636e\u3001\u53c2\u6570\u548c\u5b66\u4e60\u4fe1\u53f7\u56db\u4e2a\u7ef4\u5ea6\uff0c\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5ba1\u8ba1\u8bc6\u522b\u8bad\u7ec3\u7a33\u5b9a\u6027\u89c4\u5f8b\uff0c\u53d1\u73b0\u6700\u7ec8\u6027\u80fd\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u7ecf\u5e38\u89e3\u8026\u3001\u53d7\u63a7\u968f\u673a\u6027\u53ef\u7f13\u51b2\u5b66\u4e60\u52a8\u529b\u5b66\u3001\u4f4e\u7ef4\u5143\u72b6\u6001\u504f\u5dee\u53ef\u9884\u6d4b\u6027\u80fd\u5d29\u6e83\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u4f46\u8bad\u7ec3\u8fc7\u7a0b\u672c\u8eab\u7684\u7a33\u5b9a\u6027\u4ecd\u7136\u7406\u89e3\u4e0d\u8db3\u3002\u8bad\u7ec3\u4f5c\u4e3a\u9ad8\u7ef4\u52a8\u529b\u7cfb\u7edf\uff0c\u5bf9\u4f18\u5316\u3001\u6570\u636e\u3001\u53c2\u6570\u6216\u5b66\u4e60\u4fe1\u53f7\u7684\u5c0f\u6270\u52a8\u53ef\u80fd\u5f15\u53d1\u7a81\u7136\u4e14\u4e0d\u53ef\u9006\u7684\u5d29\u6e83\uff0c\u635f\u5bb3\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u52a8\u529b\u5b66\u89c6\u89d2\u6765\u7cfb\u7edf\u7814\u7a76\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u52a8\u529b\u5b66\u89c6\u89d2\uff0c\u5c06\u8bad\u7ec3\u7a33\u5b9a\u6027\u7ec4\u7ec7\u4e3a\u56db\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u7ef4\u5ea6\uff1a\u4f18\u5316\u7a33\u5b9a\u6027\u3001\u73af\u5883/\u6570\u636e\u7a33\u5b9a\u6027\u3001\u53c2\u6570\u7a33\u5b9a\u6027\u548c\u5b66\u4e60\u4fe1\u53f7\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5ba1\u8ba1\u8bad\u7ec3\u8f68\u8ff9\u6765\u64cd\u4f5c\u5316\u8fd9\u4e00\u89c6\u89d2\uff0c\u5728\u4e0d\u4fee\u6539\u5b66\u4e60\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\u63a2\u6d4b\u5b66\u4e60\u52a8\u529b\u5b66\u5bf9\u7ed3\u6784\u5316\u6270\u52a8\u7684\u54cd\u5e94\u3002", "result": "\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u8bc6\u522b\u51fa\u4e09\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u89c4\u5f8b\uff1a1\uff09\u6700\u7ec8\u9ad8\u6027\u80fd\u7ecf\u5e38\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u89e3\u8026\uff1b2\uff09\u53d7\u63a7\u968f\u673a\u6027\u5728\u4e0d\u540c\u8303\u5f0f\u4e2d\u4e00\u81f4\u5730\u7f13\u51b2\u5b66\u4e60\u52a8\u529b\u5b66\uff1b3\uff09\u4f4e\u7ef4\u6f5c\u5728\u5143\u72b6\u6001\u7684\u504f\u5dee\u7cfb\u7edf\u6027\u5730\u5148\u4e8e\u53ef\u89c2\u5bdf\u7684\u6027\u80fd\u5d29\u6e83\u3002", "conclusion": "\u8bad\u7ec3\u7a33\u5b9a\u6027\u662f\u5b66\u4e60\u7cfb\u7edf\u53ef\u6d4b\u91cf\u548c\u53ef\u6bd4\u8f83\u7684\u52a8\u529b\u5b66\u5c5e\u6027\uff0c\u4e3a\u8d85\u8d8a\u6700\u7ec8\u6027\u80fd\u7ed3\u679c\u7814\u7a76\u5b66\u4e60\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u63cf\u8ff0\u6027\u57fa\u7840\u3002\u8fd9\u4e00\u89c6\u89d2\u6709\u52a9\u4e8e\u7406\u89e3\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u673a\u5236\uff0c\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.13330", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13330", "abs": "https://arxiv.org/abs/2601.13330", "authors": ["Jamie Cummins", "Beth Clarke", "Ian Hussey", "Malte Elson"], "title": "RegCheck: A tool for automating comparisons between study registrations and papers", "comment": "15 pages, 1 figure", "summary": "Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.", "AI": {"tldr": "RegCheck\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6a21\u5757\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u7a3f\u4eba\u548c\u7f16\u8f91\u6bd4\u8f83\u7814\u7a76\u6ce8\u518c\u4e0e\u5bf9\u5e94\u8bba\u6587\uff0c\u4fdd\u6301\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u5728\u5faa\u73af\u4e2d\uff0c\u751f\u6210\u53ef\u5171\u4eab\u62a5\u544a\uff0c\u4fc3\u8fdb\u79d1\u5b66\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u5c3d\u7ba1\u7814\u7a76\u6ce8\u518c\u5bf9\u79d1\u5b66\u900f\u660e\u5ea6\u548c\u4e25\u8c28\u6027\u6709\u76ca\uff0c\u4f46\u624b\u52a8\u68c0\u67e5\u6ce8\u518c\u4e0e\u8bba\u6587\u4e4b\u95f4\u7684\u5dee\u5f02\u662f\u52b3\u52a8\u548c\u65f6\u95f4\u5bc6\u96c6\u578b\u7684\uff0c\u9700\u8981\u8de8\u683c\u5f0f\u4ed4\u7ec6\u9605\u8bfb\u548c\u8de8\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002AI\u7684\u53d1\u5c55\u4e3a\u4fc3\u8fdb\u8fd9\u4e00\u6d3b\u52a8\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "RegCheck\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684LLM\u8f85\u52a9\u5de5\u5177\uff0c\u901a\u8fc7(i)\u8ba9\u7528\u6237\u51b3\u5b9a\u9700\u8981\u6bd4\u8f83\u54ea\u4e9b\u7279\u5f81\uff0c(ii)\u5411\u7528\u6237\u5c55\u793a\u6bcf\u4e2a\u7279\u5f81\u6700\u76f8\u5173\u7684\u6587\u672c\uff0c\u4fc3\u8fdb\uff08\u800c\u975e\u66ff\u4ee3\uff09\u4eba\u7c7b\u5dee\u5f02\u5224\u65ad\u3002\u5de5\u5177\u751f\u6210\u5e26\u6709\u552f\u4e00RegCheck ID\u7684\u53ef\u5171\u4eab\u62a5\u544a\u3002", "result": "RegCheck\u88ab\u8bbe\u8ba1\u4e3a\u8de8\u79d1\u5b66\u9886\u57df\u3001\u6ce8\u518c\u548c\u51fa\u7248\u683c\u5f0f\u7684\u9002\u5e94\u6027\u5de5\u5177\uff0c\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u53ef\u91cd\u590d\u79d1\u5b66\uff0c\u901a\u8fc7\u793a\u4f8b\u7528\u4f8b\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002", "conclusion": "RegCheck\u901a\u8fc7\u4fdd\u6301\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u5728\u5faa\u73af\u4e2d\uff0c\u540c\u65f6\u5229\u7528AI\u80fd\u529b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u7a3f\u4eba\u548c\u7f16\u8f91\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\uff0c\u4fc3\u8fdb\u7814\u7a76\u6ce8\u518c\u4e0e\u8bba\u6587\u7684\u6bd4\u8f83\uff0c\u589e\u5f3a\u79d1\u5b66\u900f\u660e\u5ea6\u548c\u4e25\u8c28\u6027\u3002"}}
{"id": "2601.13162", "categories": ["cs.LG", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.13162", "abs": "https://arxiv.org/abs/2601.13162", "authors": ["Ali Shafiee Sarvestani", "Jason Schmidt", "Arman Roohi"], "title": "NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness", "comment": null, "summary": "Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \\DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\\ell_\\infty$ perturbation budget of $\\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\\% and 17.35\\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.", "AI": {"tldr": "Neuro-symbolic\u6846\u67b6DesignII\u901a\u8fc7\u7b26\u53f7\u89c4\u5219\u76d1\u7763\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728GTSRB\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u6807\u51c6\u5bf9\u6297\u8bad\u7ec3\u83b7\u5f97\u7ea63\u500d\u7684\u9c81\u68d2\u6027\u63d0\u5347\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u5bf9\u6297\u8106\u5f31\u6027\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u654f\u611f\u573a\u666f\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u63d0\u5347\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faDesignII\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u9886\u57df\u77e5\u8bc6\u7f16\u7801\u4e3a\u5f62\u72b6\u3001\u989c\u8272\u7b49\u5916\u89c2\u5c5e\u6027\u7684\u903b\u8f91\u7ea6\u675f\uff0c\u901a\u8fc7\u8bed\u4e49\u548c\u7b26\u53f7\u903b\u8f91\u635f\u5931\u5728\u8bad\u7ec3\u4e2d\u5f3a\u5236\u6267\u884c\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u5728GTSRB\u6570\u636e\u96c6\u4e0a\uff0cFGSM-Neuro-Symbolic\u548cPGD-Neuro-Symbolic\u6a21\u578b\u76f8\u6bd4\u5bf9\u5e94\u5bf9\u6297\u8bad\u7ec3\u57fa\u7ebf\u5206\u522b\u63d0\u534718.1%\u548c17.35%\u7684\u5bf9\u6297\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u5e72\u51c0\u8bad\u7ec3\u57fa\u7ebf\u83b7\u5f97\u7ea63\u500d\u7684\u9c81\u68d2\u6027\u589e\u76ca\uff0c\u4e14\u4e0d\u964d\u4f4e\u5e72\u51c0\u6837\u672c\u51c6\u786e\u7387\u3002\u4f7f\u7528ResNet18\u9aa8\u5e72\u7f51\u7edc\u8bad\u7ec310\u4e2aepoch\u5373\u53ef\u8fbe\u5230\u6216\u8d85\u8fc7\u9700\u8981\u91cd\u578b\u67b6\u6784\u548c\u5927\u91cf\u6570\u636e\u589e\u5f3a\u7684transformer\u9632\u5fa1\u65b9\u6cd5\u7684\u6548\u679c\u3002", "conclusion": "\u7b26\u53f7\u63a8\u7406\u4e3a\u6784\u5efa\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684AI\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\uff0c\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5728\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.13346", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13346", "abs": "https://arxiv.org/abs/2601.13346", "authors": ["Sang Yun Kwon", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "title": "AfroScope: A Framework for Studying the Linguistic Landscape of Africa", "comment": null, "summary": "Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.", "AI": {"tldr": "AfroScope\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u6846\u67b6\uff0c\u5305\u542b\u8986\u76d6713\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u5957\u4ef6\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u7c7b\u65b9\u6cd5\u63d0\u9ad8\u5bf9\u76f8\u4f3c\u8bed\u8a00\u7684\u533a\u5206\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u8bc6\u522b\u65b9\u6cd5\u5bf9\u975e\u6d32\u8bed\u8a00\u652f\u6301\u6709\u9650\uff0c\u8986\u76d6\u8bed\u8a00\u6570\u91cf\u4e0d\u8db3\uff0c\u4e14\u96be\u4ee5\u533a\u5206\u5bc6\u5207\u76f8\u5173\u7684\u8bed\u8a00\u53d8\u4f53\uff0c\u5f71\u54cd\u4e86\u4e0b\u6e38NLP\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faAfroScope\u6846\u67b6\uff0c\u5305\u62ecAfroScope-Data\u6570\u636e\u96c6\u548cAfroScope-Models\u6a21\u578b\u5957\u4ef6\uff1b\u9488\u5bf929\u79cd\u9ad8\u5ea6\u76f8\u4f3c\u8bed\u8a00\uff0c\u4f7f\u7528Mirror-Serengeti\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u5206\u5c42\u5206\u7c7b\u3002", "result": "\u5728\u9ad8\u5ea6\u76f8\u4f3c\u8bed\u8a00\u5b50\u96c6\u4e0a\uff0c\u5206\u5c42\u5206\u7c7b\u65b9\u6cd5\u6bd4\u6700\u4f73\u57fa\u7840\u6a21\u578b\u63d0\u9ad8\u4e864.55\u7684\u5b8f\u5e73\u5747F1\u5206\u6570\uff1b\u5206\u6790\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\u548c\u9886\u57df\u6548\u5e94\u3002", "conclusion": "AfroScope\u4e3a\u5927\u89c4\u6a21\u6d4b\u91cf\u975e\u6d32\u6570\u5b57\u6587\u672c\u4e2d\u7684\u8bed\u8a00\u666f\u89c2\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\uff0c\u516c\u5f00\u53d1\u5e03\u4e86\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u63a8\u52a8\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u4f5c\u4e3a\u4f7f\u80fd\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2601.13190", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.13190", "abs": "https://arxiv.org/abs/2601.13190", "authors": ["Vittoria De Pellegrini", "Tariq Alkhalifah"], "title": "LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations", "comment": null, "summary": "Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.", "AI": {"tldr": "LAViG-FLOW\uff1a\u4e00\u79cd\u7528\u4e8e\u5730\u4e0b\u591a\u76f8\u6d41\u4f53\u6d41\u52a8\u5efa\u6a21\u7684\u6f5c\u5728\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u9971\u548c\u5ea6\u548c\u538b\u529b\u573a\u7684\u8026\u5408\u6f14\u5316\uff0c\u5b9e\u73b0\u6bd4\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u9884\u6d4b\u3002", "motivation": "\u5730\u4e0b\u591a\u76f8\u6d41\u4f53\u6d41\u52a8\u5efa\u6a21\u5bf9\u5730\u8d28CO2\u5c01\u5b58\u548c\u5730\u70ed\u751f\u4ea7\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9ad8\u4fdd\u771f\u6a21\u62df\u5668\u5728\u9700\u8981\u5927\u91cf\u524d\u5411\u8fd0\u884c\u8fdb\u884c\u53cd\u6f14\u548c\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u65f6\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u63d0\u51faLAViG-FLOW\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u4e13\u75282D\u81ea\u7f16\u7801\u5668\u538b\u7f29\u6bcf\u4e2a\u72b6\u6001\u53d8\u91cf\uff1b2\uff09\u4f7f\u7528\u89c6\u9891\u6269\u6563\u53d8\u6362\u5668\uff08VDiT\uff09\u5efa\u6a21\u65f6\u95f4\u4e0a\u7684\u8026\u5408\u5206\u5e03\uff1b3\uff09\u5148\u5728\u7ed9\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\u8bad\u7ec3\u5b66\u4e60\u8026\u5408\u5173\u7cfb\uff0c\u7136\u540e\u81ea\u56de\u5f52\u5fae\u8c03\u4ee5\u5728\u89c2\u6d4b\u65f6\u95f4\u7a97\u53e3\u5916\u8fdb\u884c\u5916\u63a8\u3002", "result": "\u5728\u5f00\u6e90CO2\u5c01\u5b58\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cLAViG-FLOW\u751f\u6210\u7684\u9971\u548c\u5ea6\u548c\u538b\u529b\u573a\u5728\u65f6\u95f4\u4e0a\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u8fd0\u884c\u901f\u5ea6\u6bd4\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "LAViG-FLOW\u4e3a\u5730\u4e0b\u591a\u76f8\u6d41\u4f53\u6d41\u52a8\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5927\u91cf\u6a21\u62df\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.13352", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13352", "abs": "https://arxiv.org/abs/2601.13352", "authors": ["Yuxing Lu", "J. Ben Tamo", "Weichen Zhao", "Nan Sun", "Yishan Zhong", "Wenqi Shi", "Jinzhuo Wang", "May D. Wang"], "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction", "comment": "17 pages, 5 figures, 6 tables", "summary": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.", "AI": {"tldr": "LLM-as-RNN\uff1a\u5c06\u51bb\u7ed3LLM\u8f6c\u53d8\u4e3a\u5faa\u73af\u9884\u6d4b\u5668\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u5b9e\u73b0\u5728\u7ebf\u5b66\u4e60\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0", "motivation": "\u6807\u51c6LLM\u63a8\u7406\u4f7f\u7528\u4e0d\u53ef\u53d8\u7684\u4e0a\u4e0b\u6587\u5386\u53f2\uff0c\u4e00\u65e6\u5728\u751f\u6210\u6b65\u9aa4t\u51fa\u9519\uff0c\u6a21\u578b\u7f3a\u4e4f\u53ef\u66f4\u65b0\u7684\u8bb0\u5fc6\u673a\u5236\u6765\u6539\u8fdb\u6b65\u9aa4t+1\u7684\u9884\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9LLM\u5728\u63a8\u7406\u65f6\u80fd\u591f\u4ece\u9519\u8bef\u4e2d\u5b66\u4e60\u5e76\u6539\u8fdb\u540e\u7eed\u9884\u6d4b\u3002", "method": "\u63d0\u51faLLM-as-RNN\u6846\u67b6\uff0c\u5c06\u51bb\u7ed3LLM\u8f6c\u53d8\u4e3a\u5faa\u73af\u9884\u6d4b\u5668\uff0c\u5176\u9690\u85cf\u72b6\u6001\u8868\u793a\u4e3a\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\uff08\u7ed3\u6784\u5316\u7cfb\u7edf\u63d0\u793a\u6458\u8981\uff09\u3002\u8be5\u72b6\u6001\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u6587\u672c\u91cd\u5199\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u66f4\u65b0\uff0c\u5b9e\u73b0\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u7684\u5b66\u4e60\u3002", "result": "\u5728\u533b\u7597\u3001\u6c14\u8c61\u548c\u91d1\u878d\u4e09\u4e2a\u5e8f\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Llama\u3001Gemma\u548cGPT\u6a21\u578b\u7cfb\u5217\uff0cLLM-as-RNN\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u3001\u5b8c\u6574\u5386\u53f2\u548cMemPrompt\u57fa\u7ebf\uff0c\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad86.5%\uff0c\u540c\u65f6\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u4eba\u7c7b\u53ef\u8bfb\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "LLM-as-RNN\u901a\u8fc7\u5c06LLM\u8f6c\u53d8\u4e3a\u5177\u6709\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u7684\u5faa\u73af\u9884\u6d4b\u5668\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u65f6\u7684\u5728\u7ebf\u5b66\u4e60\uff0c\u80fd\u591f\u7ea0\u6b63\u9519\u8bef\u5e76\u4fdd\u7559\u4efb\u52a1\u76f8\u5173\u6a21\u5f0f\uff0c\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u8bb0\u5fc6\u548c\u5b66\u4e60\u673a\u5236\u3002"}}
{"id": "2601.13243", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13243", "abs": "https://arxiv.org/abs/2601.13243", "authors": ["Yapeng Li", "Jiakuo Yu", "Zhixin Liu", "Xinnan Liu", "Jing Yu", "Songze Li", "Tonghua Su"], "title": "A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86LLM\u63a8\u7406\u8303\u5f0f\uff08\u76f4\u63a5\u751f\u6210\u3001CoT\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff09\uff0c\u5206\u6790\u4e86\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5f00\u653e\u5f0f\u57fa\u51c6MIMeBench\u6765\u8bc4\u4f30\u8bed\u4e49\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u4f5c\u4e3a\u63a8\u7406\u7cfb\u7edf\u90e8\u7f72\u65f6\uff0c\u4e0d\u540c\u63a8\u7406\u8303\u5f0f\uff08\u5982CoT\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff09\u7684\u76f8\u5bf9\u6709\u6548\u6027\u3001\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\u4ee5\u53ca\u8bed\u4e49\u80fd\u529b\u8bc4\u4f30\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "1\uff09\u5bf9\u591a\u79cd\u63a8\u7406\u8303\u5f0f\u8fdb\u884c\u7edf\u4e00\u8bc4\u4f30\uff1b2\uff09\u901a\u8fc7\u89d2\u8272\u9694\u79bb\u5206\u6790\u63a2\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\u9700\u6c42\uff1b3\uff09\u5206\u6790\u6210\u672c-\u51c6\u786e\u6027\u6743\u8861\uff1b4\uff09\u63d0\u51fa\u65b0\u7684\u5f00\u653e\u5f0f\u57fa\u51c6MIMeBench\u8bc4\u4f30\u8bed\u4e49\u62bd\u8c61\u548c\u5bf9\u6bd4\u8fa8\u522b\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u589e\u52a0\u7ed3\u6784\u590d\u6742\u6027\u5e76\u4e0d\u603b\u662f\u63d0\u9ad8\u63a8\u7406\u6027\u80fd\uff0c\u5176\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u63a8\u7406\u8303\u5f0f\u7684\u7279\u6027\u548c\u9002\u7528\u6027\uff1b2\uff09\u67d0\u4e9b\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u5728\u6210\u672c\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u6210\u672c\u8fc7\u9ad8\u4f46\u6536\u76ca\u6709\u9650\u3002", "conclusion": "\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u7279\u6027\u9009\u62e9\u5408\u9002\u7684\u63a8\u7406\u8303\u5f0f\uff0c\u7ed3\u6784\u590d\u6742\u6027\u672c\u8eab\u4e0d\u662f\u6027\u80fd\u4fdd\u8bc1\u3002MIMeBench\u4e3a\u8bed\u4e49\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7ef4\u5ea6\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u5c01\u95ed\u5f0f\u57fa\u51c6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.13359", "categories": ["cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13359", "abs": "https://arxiv.org/abs/2601.13359", "authors": ["Asen Dotsinski", "Panagiotis Eustratiadis"], "title": "Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection", "comment": null, "summary": "As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce \"sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., \"Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"sockpuppetting\"\u7684\u7b80\u5355\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8f93\u51fa\u5f00\u5934\u63d2\u5165\u63a5\u53d7\u5e8f\u5217\uff08\u5982\"Sure, here is how to...\"\uff09\u6765\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u65e0\u9700\u4f18\u5316\u4e14\u4ee3\u7801\u7b80\u5355\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u4fdd\u62a4\u5b83\u4eec\u514d\u53d7\u6076\u610f\u63d0\u793a\u653b\u51fb\u53d8\u5f97\u6108\u53d1\u91cd\u8981\u3002\u73b0\u6709\u81ea\u52a8\u8d8a\u72f1\u65b9\u6cd5\u5982GCG\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\"sockpuppetting\"\u65b9\u6cd5\uff1a\u5728\u6a21\u578b\u8f93\u51fa\u5f00\u5934\u63d2\u5165\u63a5\u53d7\u5e8f\u5217\uff08\u5982\"Sure, here is how to...\"\uff09\uff0c\u7136\u540e\u8ba9\u6a21\u578b\u5b8c\u6210\u54cd\u5e94\u3002\u8fd8\u63a2\u7d22\u4e86\u6df7\u5408\u65b9\u6cd5\uff0c\u5728\u52a9\u624b\u6d88\u606f\u5757\u5185\u4f18\u5316\u5bf9\u6297\u540e\u7f00\u800c\u975e\u7528\u6237\u63d0\u793a\u3002", "result": "sockpuppetting\u5728Qwen3-8B\u4e0a\u6bd4GCG\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad880%\uff08\u9010\u63d0\u793a\u6bd4\u8f83\uff09\u3002\u6df7\u5408\u65b9\u6cd5\u5728Llama-3.1-8B\u4e0a\u6bd4GCG\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad864%\uff08\u63d0\u793a\u65e0\u5173\u8bbe\u7f6e\uff09\u3002", "conclusion": "sockpuppetting\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u6210\u672c\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u4f9b\u975e\u4e13\u4e1a\u653b\u51fb\u8005\u4f7f\u7528\uff0c\u51f8\u663e\u4e86\u5f00\u6e90\u6a21\u578b\u9700\u8981\u9632\u5fa1\u8f93\u51fa\u524d\u7f00\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2601.13244", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13244", "abs": "https://arxiv.org/abs/2601.13244", "authors": ["Prateek Munjal", "Clement Christophe", "Ronnie Rajan", "Praveenkumar Kanithi"], "title": "Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks", "comment": null, "summary": "Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.", "AI": {"tldr": "\u6307\u4ee4\u5fae\u8c03\u53ef\u80fd\u4e0d\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u800c\u662f\u8bf1\u5bfc\u8868\u9762\u6a21\u5f0f\u5339\u914d\uff0c\u5176\u6027\u80fd\u4f18\u52bf\u4e0d\u7a33\u5b9a\u4e14\u5bf9\u5206\u5e03\u53d8\u5316\u8106\u5f31", "motivation": "\u7814\u7a76\u6307\u4ee4\u5fae\u8c03\u662f\u5426\u771f\u6b63\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u8bf1\u5bfc\u8868\u9762\u6a21\u5f0f\u5339\u914d\uff0c\u56e0\u4e3a\u5f53\u524d\u6807\u51c6\u5b9e\u8df5\u7684\u6548\u679c\u673a\u5236\u4e0d\u660e\u786e", "method": "\u5728\u6807\u51c6\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u3001\u7ed3\u6784\u6270\u52a8\u53d8\u4f53\u548c\u9886\u57df\u8f6c\u79fb\u4efb\u52a1\u4e0a\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u548c\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\uff0c\u5206\u6790\u5b83\u4eec\u5728\u96f6-shot CoT\u3001\u5c11-shot\u548c\u4e0d\u540c\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0", "result": "1) \u5728GSM8K\u96f6-shot CoT\u8bbe\u7f6e\u4e2d\uff0c\u57fa\u7840\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u6307\u4ee4\u5fae\u8c03\u53d8\u4f53\uff08Llama3-70B\u4e0b\u964d\u9ad8\u8fbe32.67%\uff09\uff1b2) \u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u4ec5\u5728\u63d0\u4f9b\u5c11-shot\u793a\u4f8b\u65f6\u5339\u914d\u6216\u8d85\u8d8a\u6b64\u6027\u80fd\uff1b3) \u5728MedCalc\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u7840\u6a21\u578b\u4f18\u4e8e\u6307\u4ee4\u5fae\u8c03\u53d8\u4f53\uff1b4) \u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u5728\u6270\u52a8\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6025\u5267\u4e0b\u964d", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u7684\u6027\u80fd\u4f18\u52bf\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u4e8e\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u6a21\u578b\u53ef\u80fd\u4f9d\u8d56\u7279\u5b9a\u63d0\u793a\u6a21\u5f0f\u800c\u975e\u5185\u5728\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u5bf9\u5206\u5e03\u53d8\u5316\u8106\u5f31\uff0c\u8868\u660e\u5f53\u524d\u6307\u4ee4\u5fae\u8c03\u53ef\u80fd\u672a\u771f\u6b63\u589e\u5f3a\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.13368", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13368", "abs": "https://arxiv.org/abs/2601.13368", "authors": ["Zhenjiang Mao", "Anirudhh Venkat"], "title": "Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models", "comment": null, "summary": "As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6b65\u9aa4\u6ce8\u610f\u529b\u5206\u6790\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u5e76\u5f15\u5165\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\u6765\u4fdd\u7559\u5386\u53f2\u7f6e\u4fe1\u4fe1\u606f\uff0c\u4ee5\u66f4\u51c6\u786e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u96be\u4ee5\u8bc4\u4f30\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bef\u5bfc\u6027\u5e7b\u89c9\u3002\u73b0\u6709\u65b9\u6cd5\u5206\u6790\u63a8\u7406\u5e8f\u5217\u65f6\u5ffd\u7565\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u7f6e\u4fe1\u5ea6\u4f20\u64ad\uff0c\u5bfc\u81f4\u6574\u4f53\u7f6e\u4fe1\u5ea6\u88ab\u9ad8\u4f30\u3002", "method": "\u63d0\u51fa\u8de8\u6b65\u9aa4\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u5f15\u5165\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\u4fdd\u7559\u5386\u53f2\u7f6e\u4fe1\u4fe1\u606f\uff0c\u7ed3\u5408\u9010\u6b65\u7f6e\u4fe1\u5ea6\u751f\u6210\u66f4\u51c6\u786e\u7684\u6574\u4f53\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728GAOKAO\u6570\u5b66\u57fa\u51c6\u548cCLadder\u56e0\u679c\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u4e3b\u6d41\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u8d1f\u5bf9\u6570\u4f3c\u7136\u548c\u671f\u671b\u6821\u51c6\u8bef\u5dee\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u9884\u6d4b\u8d28\u91cf\u548c\u6821\u51c6\u7684\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u8003\u8651\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u7f6e\u4fe1\u5ea6\u4f20\u64ad\uff0c\u6709\u6548\u9632\u6b62\u6574\u4f53\u7f6e\u4fe1\u5ea6\u88ab\u9ad8\u4f30\uff0c\u63d0\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2601.13387", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13387", "abs": "https://arxiv.org/abs/2601.13387", "authors": ["Zhenjiang Mao", "Anirudhh Venkat", "Artem Bisliouk", "Akshat Kothiyal", "Sindhura Kumbakonam Subramanian", "Saithej Singhu", "Ivan Ruchkin"], "title": "Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5206\u6790LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u6f14\u5316\uff0c\u901a\u8fc7STL\u6a21\u5f0f\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u63a8\u7406\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5c06\u6574\u4e2a\u63a8\u7406\u8fc7\u7a0b\u7b80\u5316\u4e3a\u5355\u4e00\u6807\u91cf\u5206\u6570\uff0c\u5ffd\u7565\u4e86\u7f6e\u4fe1\u5ea6\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6f14\u5316\uff0c\u5bfc\u81f4\u5bf9\u8868\u9762\u56e0\u7d20\uff08\u5982\u56de\u7b54\u957f\u5ea6\u3001\u5197\u957f\u7a0b\u5ea6\uff09\u654f\u611f\uff0c\u96be\u4ee5\u533a\u5206\u6b63\u786e\u63a8\u7406\u548c\u81ea\u4fe1\u9648\u8ff0\u7684\u9519\u8bef", "method": "\u4f7f\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u8868\u5f81\u9010\u6b65\u7f6e\u4fe1\u5ea6\u4fe1\u53f7\uff0c\u901a\u8fc7\u5224\u522b\u6027STL\u6316\u6398\u8fc7\u7a0b\u53d1\u73b0\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u56de\u7b54\u7f6e\u4fe1\u5ea6\u4fe1\u53f7\u7684\u65f6\u5e8f\u516c\u5f0f\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u8d85\u7f51\u7edc\u53c2\u6570\u5316\u7684STL\u5757\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5", "result": "STL\u6a21\u5f0f\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u5177\u6709\u6cdb\u5316\u6027\uff0c\u6570\u503c\u53c2\u6570\u5bf9\u5177\u4f53\u95ee\u9898\u654f\u611f\uff1b\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6821\u51c6\u6027", "conclusion": "\u901a\u8fc7\u5206\u6790LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u6f14\u5316\u6a21\u5f0f\uff0c\u80fd\u591f\u5f00\u53d1\u66f4\u51c6\u786e\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0cSTL\u4e3a\u7406\u89e3\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u52a8\u6001\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6"}}
{"id": "2601.13284", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13284", "abs": "https://arxiv.org/abs/2601.13284", "authors": ["Duygu Nur Yaldiz", "Evangelia Spiliopoulou", "Zheng Qi", "Siddharth Varia", "Srikanth Doss", "Nikolaos Pappas"], "title": "Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.", "AI": {"tldr": "RLVR\u5fae\u8c03\u4f7fLLM\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u800cSFT\u6821\u51c6\u66f4\u597d\u4f46\u6027\u80fd\u63d0\u5347\u8f83\u5c0f\u3002\u4f5c\u8005\u63d0\u51fa\u6821\u51c6\u611f\u77e5\u7684RL\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301RLVR\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8fc7\u5ea6\u81ea\u4fe1\u3002", "motivation": "LLM\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u6027\uff0c\u8fd8\u9700\u8981\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002\u5f53\u524d\u5e7f\u6cdb\u4f7f\u7528\u7684RLVR\u5fae\u8c03\u8303\u5f0f\u867d\u7136\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4f1a\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u5f71\u54cd\u4e0b\u6e38\u7cfb\u7edf\u7684\u4fe1\u4efb\u51b3\u7b56\u3002", "method": "\u7cfb\u7edf\u7814\u7a76SFT\u548cRLVR\u4e24\u79cd\u5fae\u8c03\u8303\u5f0f\u7684\u6821\u51c6\u7279\u6027\uff0c\u8bca\u65adRLVR\u5931\u8d25\u539f\u56e0\uff08\u51b3\u7b56token\u4f5c\u4e3a\u63d0\u53d6\u6b65\u9aa4\u4e0d\u643a\u5e26\u7f6e\u4fe1\u4fe1\u606f\uff09\uff0c\u63d0\u51fa\u6821\u51c6\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u516c\u5f0f\uff0c\u76f4\u63a5\u8c03\u6574\u51b3\u7b56token\u6982\u7387\u3002", "result": "RLVR\u4ea7\u751f\u6781\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u7684\u6a21\u578b\uff0cSFT\u6821\u51c6\u66f4\u597d\u4f46\u6027\u80fd\u63d0\u5347\u8f83\u5c0f\u3002\u63d0\u51fa\u7684\u6821\u51c6\u611f\u77e5RL\u65b9\u6cd5\u5728\u4fdd\u6301RLVR\u51c6\u786e\u6027\u6c34\u5e73\u7684\u540c\u65f6\uff0c\u5c06ECE\u5206\u6570\u964d\u4f4e\u9ad8\u8fbe9\u4e2a\u70b9\uff0c\u663e\u8457\u7f13\u89e3\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "conclusion": "RLVR\u867d\u7136\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u4f46\u635f\u5bb3\u6821\u51c6\uff0c\u800cSFT\u6821\u51c6\u66f4\u597d\u4f46\u6027\u80fd\u6709\u9650\u3002\u901a\u8fc7\u7406\u89e3\u51b3\u7b56token\u5728\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u4f5c\u7528\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u6821\u51c6\u611f\u77e5\u7684RL\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u6539\u5584\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002"}}
{"id": "2601.13388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13388", "abs": "https://arxiv.org/abs/2601.13388", "authors": ["Sasha Ronaghi", "Prerit Choudhary", "David H Rehkopf", "Bryant Lin"], "title": "Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction", "comment": "7 pages, 5 figures", "summary": "Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u7cd6\u5c3f\u75c5\u60a3\u8005\u751f\u6d3b\u6545\u4e8b\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u7cd6\u5c3f\u75c5\u63a7\u5236\u7684\u9884\u6d4b\u4ef7\u503c", "motivation": "\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u57282\u578b\u7cd6\u5c3f\u75c5\u7ba1\u7406\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u8fd9\u4e9b\u4fe1\u606f\u3002\u4f20\u7edf\u7684\u7ed3\u6784\u5316\u7b5b\u67e5\u5de5\u5177\u65e0\u6cd5\u6355\u6349\u60a3\u8005\u7ecf\u5386\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u83b7\u53d6\u8fd9\u4e9b\u5173\u952e\u6570\u636e\u3002", "method": "\u6536\u96c665\u540d65\u5c81\u4ee5\u4e0a2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u7684\u975e\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u53d9\u4e8b\uff0c\u751f\u6210\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u5b9a\u6027\u603b\u7ed3\u548c\u7ed3\u6784\u5316\u5b9a\u91cfSDOH\u8bc4\u5206\u3002\u5c06\u7ed3\u6784\u5316SDOH\u8bc4\u5206\u4e0e\u4f20\u7edf\u5b9e\u9a8c\u5ba4\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u5408\uff0c\u8f93\u5165\u7ebf\u6027\u548c\u6811\u57fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u98ce\u9669\u9884\u6d4b\u3002", "result": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u4ece\u8bbf\u8c08\u6587\u672c\u4e2d\u9884\u6d4b\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\uff08\u4f4e\u3001\u4e2d\u3001\u9ad8\uff09\uff0c\u51c6\u786e\u7387\u8fbe\u523060%\u3002\u7ed3\u6784\u5316SDOH\u8bc4\u5206\u53ef\u4ee5\u4e0e\u4f20\u7edf\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u5408\uff0c\u5e94\u7528\u4e8e\u5e38\u89c4\u98ce\u9669\u9884\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5c06\u975e\u7ed3\u6784\u5316SDOH\u76f8\u5173\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u89c1\u89e3\uff0c\u4e3a\u589e\u5f3a\u4e34\u5e8a\u98ce\u9669\u6a21\u578b\u548c\u51b3\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u533b\u7597\u8bb0\u5f55\u4e2d\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u4fe1\u606f\u7684\u7f3a\u5931\u3002"}}
{"id": "2601.13295", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13295", "abs": "https://arxiv.org/abs/2601.13295", "authors": ["Arpandeep Khatua", "Hao Zhu", "Peter Tran", "Arya Prabhudesai", "Frederic Sadrieh", "Johann K. Lieberwirth", "Xinkai Yu", "Yicheng Fu", "Michael J. Ryan", "Jiaxin Pei", "Diyi Yang"], "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet", "comment": "https://cooperbench.com", "summary": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCooperBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30AI\u4ee3\u7406\u5728\u534f\u4f5c\u7f16\u7a0b\u4e2d\u7684\u534f\u8c03\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u4ee3\u7406\u5b58\u5728\"\u534f\u8c03\u8bc5\u5492\"\u2014\u2014\u534f\u4f5c\u65f6\u6210\u529f\u7387\u6bd4\u5355\u72ec\u6267\u884c\u4f4e30%\uff0c\u4e0e\u4eba\u7c7b\u56e2\u961f\u8868\u73b0\u76f8\u53cd\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5728\u590d\u6742\u5de5\u4f5c\u4e2d\u8d8a\u6765\u8d8a\u591a\u5730\u534f\u4f5c\uff0c\u5b83\u4eec\u9700\u8981\u53d1\u5c55\u534f\u8c03\u80fd\u529b\u624d\u80fd\u6210\u4e3a\u6709\u6548\u7684\u56e2\u961f\u6210\u5458\u3002\u4f5c\u8005\u5047\u8bbe\u5f53\u524d\u4ee3\u7406\u7f3a\u4e4f\u8fd9\u4e9b\u80fd\u529b\uff0c\u9700\u8981\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u6765\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u5f15\u5165CooperBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b600\u591a\u4e2a\u534f\u4f5c\u7f16\u7a0b\u4efb\u52a1\uff0c\u8986\u76d64\u79cd\u7f16\u7a0b\u8bed\u8a00\u768412\u4e2a\u5e93\u3002\u6bcf\u4e2a\u4efb\u52a1\u5206\u914d\u4e24\u4e2a\u4ee3\u7406\u4e0d\u540c\u7684\u529f\u80fd\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u53ef\u4ee5\u72ec\u7acb\u5b9e\u73b0\u4f46\u7f3a\u4e4f\u534f\u8c03\u53ef\u80fd\u51b2\u7a81\u3002\u4efb\u52a1\u57fa\u4e8e\u771f\u5b9e\u5f00\u6e90\u4ed3\u5e93\u548c\u4e13\u5bb6\u7f16\u5199\u7684\u6d4b\u8bd5\u3002", "result": "\u89c2\u5bdf\u5230\"\u534f\u8c03\u8bc5\u5492\"\u73b0\u8c61\uff1a\u4ee3\u7406\u534f\u4f5c\u65f6\u7684\u5e73\u5747\u6210\u529f\u7387\u6bd4\u5355\u72ec\u6267\u884c\u4e24\u4e2a\u4efb\u52a1\u4f4e30%\u3002\u8fd9\u4e0e\u4eba\u7c7b\u56e2\u961f\u901a\u5e38\u56e0\u589e\u52a0\u961f\u53cb\u800c\u63d0\u9ad8\u751f\u4ea7\u529b\u7684\u6a21\u5f0f\u76f8\u53cd\u3002\u5206\u6790\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u901a\u4fe1\u6e20\u9053\u5835\u585e\u3001\u4ee3\u7406\u504f\u79bb\u627f\u8bfa\u3001\u4ee3\u7406\u5bf9\u4ed6\u4eba\u8ba1\u5212\u548c\u901a\u4fe1\u6709\u9519\u8bef\u9884\u671f\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u534f\u4f5c\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u547c\u5401\u4ece\u8ffd\u6c42\u4e2a\u4f53\u4ee3\u7406\u80fd\u529b\u8f6c\u5411\u53d1\u5c55\u793e\u4ea4\u667a\u80fd\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u6a21\u62df\u89c2\u5bdf\u5230\u7f55\u89c1\u4f46\u6709\u8da3\u7684\u6d8c\u73b0\u534f\u8c03\u884c\u4e3a\uff0c\u5982\u89d2\u8272\u5206\u5de5\u3001\u8d44\u6e90\u5206\u914d\u548c\u8c08\u5224\u3002"}}
{"id": "2601.13392", "categories": ["cs.CL", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.13392", "abs": "https://arxiv.org/abs/2601.13392", "authors": ["Shlok Shelat", "Jay Raval", "Souvik Roy", "Manas Gaur"], "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks", "comment": "30 pages, 11 figures, 6 tables, Work in Progress", "summary": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.", "AI": {"tldr": "LLMs\u5728DFA\u6784\u9020\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u4e8e\u719f\u6089\u95ee\u9898\uff0c\u4f46\u5728\u672a\u89c1\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u6839\u672c\u7f3a\u9677", "motivation": "\u63a2\u7a76LLMs\u5728\u5f62\u5f0f\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u662f\u5426\u771f\u6b63\u53cd\u6620\u4e86\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u662f\u5bf9\u719f\u6089\u6784\u9020\u7684\u6a21\u5f0f\u5339\u914d", "method": "\u5f15\u5165DFA\u6784\u9020\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e8b\u5b9e\u77e5\u8bc6\u95ee\u9898\u3001\u5df2\u89c1\u6784\u9020\u95ee\u9898\u3001\u624b\u5de5\u8bbe\u8ba1\u7684\u672a\u89c1\u95ee\u9898\uff08\u591a\u91cd\u4ea4\u4e92\u7ea6\u675f\uff09\u548c\u901a\u8fc7Arden\u5b9a\u7406\u7cfb\u7edf\u751f\u6210\u7684\u672a\u89c1\u95ee\u9898\uff1b\u8bc4\u4f30\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff08\u76f4\u63a5\u3001\u601d\u7ef4\u94fe\u3001\u601d\u7ef4\u6811\uff09\u548c\u4e09\u9636\u6bb5\u63d0\u793a\u534f\u8bae", "result": "\u6a21\u578b\u5728\u4e8b\u5b9e\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u5b8c\u7f8e\uff0c\u5728\u5df2\u89c1\u4efb\u52a1\u4e0a84-90%\uff0c\u4f46\u5728\u672a\u89c1\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u4e0b\u964d30-64%\uff1b\u9519\u8bef\u6e90\u4e8e\u5bf9\u8bed\u8a00\u7ea6\u675f\u7684\u7cfb\u7edf\u6027\u8bef\u89e3\u3001Kleene\u661f\u53f7\u8bed\u4e49\u7684\u9519\u8bef\u5904\u7406\u4ee5\u53ca\u5168\u5c40\u4e00\u81f4\u6027\u7684\u5931\u8d25\uff1b\u63d0\u793a\u534f\u8bae\u80fd\u4fee\u6b63\u6d45\u5c42\u9519\u8bef\u4f46\u65e0\u6cd5\u53ef\u9760\u89e3\u51b3\u5168\u5c40\u4e0d\u4e00\u81f4\u6216\u7ed3\u6784\u7f3a\u9677", "conclusion": "LLMs\u5728\u751f\u6210\u8bed\u6cd5\u4e0a\u5408\u7406\u7684DFA\u4e0e\u8bed\u4e49\u6b63\u786e\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u5dee\u8ddd\uff0c\u9519\u8bef\u5728\u6240\u6709\u63d0\u793a\u7b56\u7565\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u8868\u660e\u5f53\u524dLLMs\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u6709\u9650"}}
{"id": "2601.13303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13303", "abs": "https://arxiv.org/abs/2601.13303", "authors": ["Minh Le", "Phuong Cao"], "title": "Verifying Local Robustness of Pruned Safety-Critical Networks", "comment": null, "summary": "Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $\u03b1,\u03b2$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.", "AI": {"tldr": "\u7814\u7a76\u526a\u679d\u5bf9\u795e\u7ecf\u7f51\u7edc\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u540c\u6570\u636e\u96c6\u7684\u6700\u4f73\u526a\u679d\u6bd4\u4f8b\u4e0d\u540c\uff1aMNIST\u4e0a\u8f7b\u5ea6\u526a\u679d\uff0840%\uff09\u63d0\u5347\u9a8c\u8bc1\u6027\uff0c\u800cNASA JPL\u6570\u636e\u96c6\u4e0a\u91cd\u5ea6\u526a\u679d\uff0870%-90%\uff09\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u9700\u8981\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u4f46\u5927\u89c4\u6a21\u6a21\u578b\u7684\u9a8c\u8bc1\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u526a\u679d\u5982\u4f55\u5f71\u54cd\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6548\u679c\uff0c\u4ee5\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\u5e76\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u03b1,\u03b2-CROWN\u9a8c\u8bc1\u5668\uff0c\u5728\u4e0d\u540c\u526a\u679d\u6bd4\u4f8b\u4e0b\u8bc4\u4f30ResNet4\u6a21\u578b\uff0c\u5206\u522b\u5728MNIST\u548cNASA JPL\u706b\u661f\u971c\u51bb\u8bc6\u522b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u975e\u7ebf\u6027\u5173\u7cfb\uff1aMNIST\u4e0a40%\u8f7b\u5ea6\u526a\u679d\u63d0\u5347\u9a8c\u8bc1\u6027\uff0cNASA JPL\u6570\u636e\u96c6\u4e0a70%-90%\u91cd\u5ea6\u526a\u679d\u6548\u679c\u66f4\u597d\uff0c\u4f7f\u6a21\u578b\u5728\u8bc1\u660e\u7684L\u221e\u9c81\u68d2\u6027\u4e0a\u8d85\u8d8a\u672a\u526a\u679d\u57fa\u7ebf\u3002", "conclusion": "\u51cf\u5c11\u8fde\u63a5\u6027\u7b80\u5316\u4e86\u5f62\u5f0f\u5316\u6c42\u89e3\u5668\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u6700\u4f73\u526a\u679d\u6bd4\u4f8b\u56e0\u6570\u636e\u96c6\u800c\u5f02\u3002\u8fd9\u4e3a\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u90e8\u7f72\u9ad8\u6548\u4e14\u7ecf\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684DNN\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2601.13433", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13433", "abs": "https://arxiv.org/abs/2601.13433", "authors": ["Priyanka Mary Mammen", "Emil Joswin", "Shankar Venkitachalam"], "title": "Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models", "comment": null, "summary": "Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4f1a\u53d7\u5230\u5efa\u8bae\u548c\u8ba4\u53ef\u7684\u5f71\u54cd\uff0c\u4f46\u8ba4\u53ef\u6765\u6e90\u7684\u53ef\u4fe1\u5ea6\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5bf9\u4e13\u5bb6\u8ba4\u53ef\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4e13\u5bb6\u8ba4\u53ef\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u5e76\u589e\u52a0\u9519\u8bef\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4f1a\u53d7\u5230\u5efa\u8bae\u3001\u63d0\u793a\u548c\u8ba4\u53ef\u7684\u5f71\u54cd\uff0c\u4f46\u8ba4\u53ef\u6765\u6e90\u53ef\u4fe1\u5ea6\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u662f\u5426\u57fa\u4e8e\u8ba4\u53ef\u63d0\u4f9b\u8005\u7684\u611f\u77e5\u4e13\u4e1a\u6c34\u5e73\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "method": "\u5728\u6570\u5b66\u3001\u6cd5\u5f8b\u548c\u533b\u5b66\u63a8\u74064\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f3011\u4e2a\u6a21\u578b\uff0c\u4f7f\u7528\u4ee3\u8868\u56db\u4e2a\u4e13\u4e1a\u6c34\u5e73\u7684\u4eba\u7269\u89d2\u8272\u3002\u901a\u8fc7\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u8ba4\u53ef\u6765\u6e90\u6d4b\u8bd5\u6a21\u578b\u5bf9\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u53cd\u5e94\u3002", "result": "\u6a21\u578b\u968f\u7740\u6765\u6e90\u4e13\u4e1a\u6c34\u5e73\u7684\u63d0\u9ad8\uff0c\u5bf9\u9519\u8bef/\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u654f\u611f\u6027\u589e\u52a0\u3002\u9ad8\u6743\u5a01\u6765\u6e90\u4e0d\u4ec5\u5bfc\u81f4\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u8fd8\u589e\u52a0\u4e86\u5bf9\u9519\u8bef\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u3002\u8fd9\u79cd\u6743\u5a01\u504f\u89c1\u5728\u6a21\u578b\u4e2d\u5177\u6709\u673a\u5236\u6027\u7f16\u7801\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6743\u5a01\u504f\u89c1\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u8fdc\u79bb\u8fd9\u79cd\u504f\u89c1\u6765\u6539\u5584\u6027\u80fd\uff0c\u5373\u4f7f\u5728\u4e13\u5bb6\u7ed9\u51fa\u8bef\u5bfc\u6027\u8ba4\u53ef\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u9ad8\u8868\u73b0\u3002"}}
{"id": "2601.13350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13350", "abs": "https://arxiv.org/abs/2601.13350", "authors": ["Abdel Djalil Sad Saoud", "Fred Maurice Ngol\u00e8 Mboula", "Hanane Slimani"], "title": "Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans", "comment": "5 pages, 2 figures", "summary": "Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8c31\u5d4c\u5165\u7684\u9886\u57df\u4e0d\u53d8\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5e73\u6ed1\u4f20\u8f93\u8ba1\u5212\u89e3\u91ca\u4e3a\u4e8c\u5206\u56fe\u90bb\u63a5\u77e9\u9635\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u9886\u57df\u5bf9\u9f50", "motivation": "\u8bad\u7ec3\u548c\u63a8\u7406\u6570\u636e\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4f20\u7edf\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u5bf9\u6b63\u5219\u5316\u7b56\u7565\u548c\u8d85\u53c2\u6570\u654f\u611f\uff0c\u53ef\u80fd\u5bfc\u81f4\u6709\u504f\u7684\u9886\u57df\u5bf9\u9f50", "method": "\u5c06\u5e73\u6ed1\u4f20\u8f93\u8ba1\u5212\u89e3\u91ca\u4e3a\u8fde\u63a5\u6e90\u57df\u548c\u76ee\u6807\u57df\u7684\u4e8c\u5206\u56fe\u90bb\u63a5\u77e9\u9635\uff0c\u901a\u8fc7\u8c31\u5d4c\u5165\u63a8\u5bfc\u9886\u57df\u4e0d\u53d8\u7684\u6837\u672c\u8868\u793a", "result": "\u5728\u97f3\u4e50\u6d41\u6d3e\u8bc6\u522b\u3001\u97f3\u4e50-\u8bed\u97f3\u533a\u5206\u4ee5\u53ca\u7535\u7f06\u7f3a\u9677\u68c0\u6d4b\u7b49\u591a\u4e2a\u58f0\u5b66\u548c\u65f6\u57df\u53cd\u5c04\u8bca\u65ad\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6574\u4f53\u5f3a\u52b2\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u8c31\u5d4c\u5165\u65b9\u6cd5\u4e3a\u9886\u57df\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5206\u5e03\u504f\u79fb\u95ee\u9898"}}
{"id": "2601.13437", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13437", "abs": "https://arxiv.org/abs/2601.13437", "authors": ["Adriana-Valentina Costache", "Daria-Nicoleta Dragomir", "Silviu-Florin Gheorghe", "Eduard Poesina", "Paul Irofti", "Radu Tudor Ionescu"], "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization", "comment": null, "summary": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\uff08MOSLD\uff09\u6587\u672c\u5206\u7c7b\u57fa\u51c6\uff0c\u5305\u542b12\u79cd\u8bed\u8a00\u768496\u4e07\u6570\u636e\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u591a\u9636\u6bb5\u7684\u65b0\u6846\u67b6\u6765\u6301\u7eed\u53d1\u73b0\u548c\u5b66\u4e60\u65b0\u7c7b\u522b\u3002", "motivation": "\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\uff08OSLD\uff09\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5176\u4e2d\u6d4b\u8bd5\u65f6\u53ef\u80fd\u51fa\u73b0\u6765\u81ea\u65b0\uff08\u672a\u77e5\uff09\u7c7b\u522b\u7684\u6837\u672c\u3002\u867d\u7136\u96f6\u6837\u672c\u5b66\u4e60\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u5728\u6587\u672c\u9886\u57df\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u65b0\u7684\u8bbe\u7f6e\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u57fa\u51c6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002", "method": "1) \u6784\u5efa\u9996\u4e2a\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u57fa\u51c6\uff0c\u901a\u8fc7\u91cd\u65b0\u6392\u5217\u73b0\u6709\u6570\u636e\u96c6\u548c\u6536\u96c6\u65b0\u95fb\u9886\u57df\u65b0\u6570\u636e\u6837\u672c\uff0c\u521b\u5efa\u4e86\u5305\u542b12\u79cd\u8bed\u8a0096\u4e07\u6570\u636e\u6837\u672c\u7684\u57fa\u51c6\uff1b2) \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684OSLD\u6846\u67b6\uff0c\u96c6\u6210\u591a\u4e2a\u9636\u6bb5\u6765\u6301\u7eed\u53d1\u73b0\u548c\u5b66\u4e60\u65b0\u7c7b\u522b\u3002", "result": "\u521b\u5efa\u4e86MOSLD\u57fa\u51c6\u5e76\u8bc4\u4f30\u4e86\u5305\u62ec\u4f5c\u8005\u63d0\u51fa\u7684\u6a21\u578b\u5728\u5185\u7684\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u83b7\u5f97\u4e86\u53ef\u4f5c\u4e3a\u672a\u6765\u5de5\u4f5c\u53c2\u8003\u7684\u7ed3\u679c\u3002\u57fa\u51c6\u5df2\u5f00\u6e90\u53d1\u5e03\u5728GitHub\u4e0a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u6587\u672c\u9886\u57df\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bc4\u4f30\u5e73\u53f0\u548c\u53c2\u8003\u7ed3\u679c\uff0c\u63a8\u52a8\u4e86\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13453", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13453", "abs": "https://arxiv.org/abs/2601.13453", "authors": ["Aditya Thole", "Anmol Agrawal", "Arnav Ramamoorthy", "Dhruv Kumar"], "title": "PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving", "comment": null, "summary": "Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems", "AI": {"tldr": "PSA\u662f\u4e00\u4e2a\u81ea\u4e3b\u4ee3\u7406\uff0c\u4f7f\u7528Manim\u52a8\u753b\u751f\u6210\u957f\u8fbe6\u5206\u949f\u7684\u7269\u7406\u89e3\u91ca\u89c6\u9891\uff0c\u5e76\u901a\u8fc7\u5305\u542b15\u4e2a\u5b9a\u91cf\u53c2\u6570\u548cVLM\u53cd\u9988\u7684\u8bc4\u4f30\u6d41\u7a0b\u6765\u6539\u8fdb\u89c6\u9891\u8d28\u91cf\uff0c\u572832\u4e2a\u89c6\u9891\u4e0a\u6d4b\u8bd5\u53d1\u73b0\u5b58\u5728\u89c6\u89c9\u5e03\u5c40\u4e0d\u4e00\u81f4\u548c\u89e3\u91ca\u9519\u8bef\u7b49\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u7269\u7406\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u89c9\u89e3\u91ca\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u89c6\u89c9\u63a8\u7406\u80fd\u663e\u8457\u63d0\u5347\u6982\u5ff5\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u6570\u503c\u7269\u7406\u95ee\u9898\u4e2d\u3002", "method": "\u5f15\u5165PhysicsSolutionAgent\uff08PSA\uff09\uff0c\u4f7f\u7528Manim\u52a8\u753b\u751f\u6210\u957f\u8fbe6\u5206\u949f\u7684\u7269\u7406\u89e3\u91ca\u89c6\u9891\u3002\u8bbe\u8ba1\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5305\u542b15\u4e2a\u5b9a\u91cf\u53c2\u6570\u7684\u81ea\u52a8\u68c0\u67e5\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53cd\u9988\uff0c\u4ee5\u8fed\u4ee3\u6539\u8fdb\u89c6\u9891\u8d28\u91cf\u3002", "result": "\u572832\u4e2a\u6570\u503c\u548c\u7406\u8bba\u7269\u7406\u95ee\u9898\u89c6\u9891\u4e0a\u8bc4\u4f30\uff0cPSA\u4f7f\u7528GPT-5-mini\u5b9e\u73b0100%\u89c6\u9891\u5b8c\u6210\u7387\uff0c\u5e73\u5747\u81ea\u52a8\u8bc4\u52063.8/5\u3002\u4f46\u5b9a\u6027\u5206\u6790\u548c\u4eba\u5de5\u68c0\u67e5\u53d1\u73b0\u5b58\u5728\u89c6\u89c9\u5e03\u5c40\u4e0d\u4e00\u81f4\u3001\u89c6\u89c9\u5185\u5bb9\u89e3\u91ca\u9519\u8bef\u7b49\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u53ef\u9760Manim\u4ee3\u7801\u751f\u6210\u7684\u5173\u952e\u9650\u5236\uff0c\u7a81\u663e\u4e86\u591a\u6a21\u6001\u63a8\u7406\u548c\u8bc4\u4f30\u5728\u6570\u503c\u7269\u7406\u95ee\u9898\u89c6\u89c9\u89e3\u91ca\u4e2d\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u672a\u6765\u591a\u6a21\u6001\u6559\u80b2\u7cfb\u7edf\u9700\u8981\u6539\u8fdb\u89c6\u89c9\u7406\u89e3\u3001\u9a8c\u8bc1\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.13365", "categories": ["cs.LG", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.13365", "abs": "https://arxiv.org/abs/2601.13365", "authors": ["Kevin Slote", "Jeremie Fish", "Erik Bollt"], "title": "CausationEntropy: Pythonic Optimal Causation Entropy", "comment": null, "summary": "Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.", "AI": {"tldr": "CausationEntropy v1.1\u662f\u4e00\u4e2aPython\u56e0\u679c\u7f51\u7edc\u5efa\u6a21\u5de5\u5177\u5305\uff0c\u5b9e\u73b0\u4e86oCSE\u7b97\u6cd5\u53ca\u5176\u4f18\u5316\u6269\u5c55\uff0c\u5305\u542b\u591a\u79cd\u71b5\u4f30\u8ba1\u5668\u548c\u6570\u636e\u751f\u6210\u529f\u80fd\u3002", "motivation": "\u4e3a\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e00\u4e2a\u57fa\u51c6\u5de5\u5177\uff0c\u5b9e\u73b0oCSE\u7b97\u6cd5\u53ca\u5176\u4f18\u5316\u6269\u5c55\uff0c\u89e3\u51b3\u76f4\u63a5\u4e0e\u95f4\u63a5\u56e0\u679c\u8def\u5f84\u7684\u533a\u5206\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6700\u4f18\u56e0\u679c\u71b5\uff08oCSE\uff09\u7406\u8bba\uff0c\u5b9e\u73b0\u591a\u79cd\u71b5\u4f30\u8ba1\u5668\uff08\u9ad8\u65af\u3001kNN\u3001\u51e0\u4f55kNN\u3001\u6838\u5bc6\u5ea6\u3001\u6cca\u677e\uff09\uff0c\u63d0\u4f9b\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u53ef\u89c6\u5316\u5de5\u5177\u3002", "result": "\u53d1\u5e03\u4e86CausationEntropy v1.1\u7248\u672c\uff0c\u5305\u542b\u65b0\u7684\u6570\u636e\u751f\u6210\u5668\u3001\u7ed8\u56fe\u5de5\u5177\u548c\u591a\u79cd\u4fe1\u606f\u8bba\u56e0\u679c\u7f51\u7edc\u53d1\u73b0\u7b97\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u4e14\u6613\u4e8e\u5b89\u88c5\u4f7f\u7528\u3002", "conclusion": "\u8be5\u5de5\u5177\u5305\u5c06\u6210\u4e3a\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u56e0\u679c\u53d1\u73b0\u7684\u57fa\u51c6\u5de5\u5177\uff0c\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u672a\u6765\u6269\u5c55\uff0c\u5b8c\u5168\u5f00\u6e90\u4e14\u6587\u6863\u5b8c\u5584\u3002"}}
{"id": "2601.13503", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13503", "abs": "https://arxiv.org/abs/2601.13503", "authors": ["Kyung Ho Lim", "Byung-Hoon Kim"], "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives", "comment": null, "summary": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.", "AI": {"tldr": "Anonpsy\uff1a\u57fa\u4e8e\u56fe\u5f15\u5bfc\u8bed\u4e49\u91cd\u5199\u7684\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u53bb\u6807\u8bc6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u56fe\u7f16\u7801\u4e34\u5e8a\u7ed3\u6784\uff0c\u5728\u4fee\u6539\u8eab\u4efd\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u7559\u8bca\u65ad\u5173\u952e\u5185\u5bb9", "motivation": "\u73b0\u6709\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5\uff08\u5982PHI\u63a9\u7801\u548cLLM\u91cd\u5199\uff09\u5728\u6587\u672c\u5c42\u9762\u64cd\u4f5c\uff0c\u5bf9\u4fdd\u7559\u6216\u4fee\u6539\u54ea\u4e9b\u8bed\u4e49\u5143\u7d20\u63a7\u5236\u6709\u9650\u3002\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u4e0d\u4ec5\u5305\u542b\u663e\u5f0f\u6807\u8bc6\u7b26\uff0c\u8fd8\u901a\u8fc7\u5d4c\u5165\u4e34\u5e8a\u7ed3\u6784\u4e2d\u7684\u72ec\u7279\u751f\u6d3b\u4e8b\u4ef6\u7f16\u7801\u60a3\u8005\u8eab\u4efd\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5\u3002", "method": "1) \u5c06\u53d9\u4e8b\u8f6c\u6362\u4e3a\u7f16\u7801\u4e34\u5e8a\u5b9e\u4f53\u3001\u65f6\u95f4\u951a\u70b9\u548c\u7c7b\u578b\u5173\u7cfb\u7684\u8bed\u4e49\u56fe\uff1b2) \u5e94\u7528\u56fe\u7ea6\u675f\u6270\u52a8\uff0c\u4fee\u6539\u8eab\u4efd\u4e0a\u4e0b\u6587\u540c\u65f6\u4fdd\u7559\u4e34\u5e8a\u5173\u952e\u7ed3\u6784\uff1b3) \u901a\u8fc7\u56fe\u6761\u4ef6LLM\u751f\u6210\u91cd\u65b0\u751f\u6210\u6587\u672c", "result": "\u572890\u4e2a\u4e34\u5e8a\u533b\u751f\u64b0\u5199\u7684\u7cbe\u795e\u75c5\u5b66\u6848\u4f8b\u53d9\u4e8b\u4e0a\u8bc4\u4f30\uff0cAnonpsy\u5728\u4fdd\u6301\u8bca\u65ad\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5728\u4e13\u5bb6\u3001\u8bed\u4e49\u548cGPT-5\u8bc4\u4f30\u4e2d\u5b9e\u73b0\u4e00\u81f4\u7684\u4f4e\u91cd\u8bc6\u522b\u98ce\u9669\u3002\u76f8\u6bd4\u5f3aLLM\u91cd\u5199\u57fa\u7ebf\uff0cAnonpsy\u4ea7\u751f\u663e\u8457\u66f4\u4f4e\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u53ef\u8bc6\u522b\u6027", "conclusion": "\u663e\u5f0f\u7ed3\u6784\u8868\u793a\u4e0e\u7ea6\u675f\u751f\u6210\u76f8\u7ed3\u5408\uff0c\u4e3a\u7cbe\u795e\u75c5\u5b66\u53d9\u4e8b\u7684\u53bb\u6807\u8bc6\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e34\u5e8a\u5b9e\u7528\u6027"}}
{"id": "2601.13398", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13398", "abs": "https://arxiv.org/abs/2601.13398", "authors": ["Nickil Maveli", "Antonio Vergari", "Shay B. Cohen"], "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility", "comment": "32 pages (preprint)", "summary": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.", "AI": {"tldr": "RTCE\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793aLLM\u5728\u53cc\u5411\u4ee3\u7801\u6267\u884c\u63a8\u7406\u4e2d\u7f3a\u4e4f\u4e00\u81f4\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e00\u6839\u672c\u7f3a\u9677", "motivation": "\u5c3d\u7ba1LLM\u5728\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u53cc\u5411\u4ee3\u7801\u6267\u884c\u4e2d\u7f3a\u4e4f\u4e00\u81f4\u6027\u63a8\u7406\u80fd\u529b\uff0c\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u8bc4\u4f30\u8fd9\u79cd\u4e00\u81f4\u6027\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6", "method": "\u63d0\u51faRoundTripCodeEval(RTCE)\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u4ee3\u7801\u6267\u884c\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u65e0\u6267\u884c\u3001\u7cbe\u786e\u5339\u914d\u7684\u65b9\u5f0f\u8bc4\u4f30\u53cc\u5411\u4e00\u81f4\u6027\uff0c\u6d4b\u8bd5\u4e86\u96f6\u6837\u672c\u63d0\u793a\u3001\u76d1\u7763\u5fae\u8c03\u548c\u81ea\u53cd\u601d\u673a\u5236", "result": "\u6240\u6709\u65b9\u6cd5\u90fd\u53ea\u80fd\u5e26\u6765\u6709\u9650\u7684\u6539\u8fdb\uff0c\u65e0\u6cd5\u89e3\u51b3\u6839\u672c\u5dee\u8ddd\uff0c\u8868\u660e\u5f53\u524dLLM\u7f3a\u4e4f\u771f\u6b63\u7684\u53cc\u5411\u4e00\u81f4\u6027\uff0c\u65e0\u6cd5\u5b9e\u73b0\u53ef\u4fe1\u7684\u4ee3\u7801\u63a8\u7406", "conclusion": "RTCE\u63ed\u793a\u4e86LLM\u5728\u53cc\u5411\u4ee3\u7801\u63a8\u7406\u4e2d\u7684\u5185\u90e8\u4e00\u81f4\u6027\u7f3a\u9677\uff0c\u8fd9\u662f\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u7684\u65b0\u89c1\u89e3\uff0c\u5bf9\u53ef\u4fe1\u4ee3\u7801\u63a8\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2601.13537", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13537", "abs": "https://arxiv.org/abs/2601.13537", "authors": ["Yerin Hwang", "Dongryeol Lee", "Taegwan Kang", "Minwoo Lee", "Kyomin Jung"], "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges", "comment": "4 pages", "summary": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5b58\u5728\u6846\u67b6\u504f\u5dee\uff0c\u5373\u63d0\u793a\u7684\u63aa\u8f9e\u65b9\u5f0f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u5224\u65ad\uff0c\u8fd9\u66b4\u9732\u4e86\u5f53\u524dLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u95ee\u9898", "motivation": "\u5c3d\u7ba1\u5df2\u77e5LLM\u5bf9\u63d0\u793a\u63aa\u8f9e\u654f\u611f\uff0c\u4f46\u6846\u67b6\u504f\u5dee\u5bf9LLM\u8bc4\u4f30\u4efb\u52a1\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u5fc3\u7406\u5b66\u4e2d\u7684\u6846\u67b6\u6548\u5e94\u542f\u53d1\u7814\u7a76\u8005\u7cfb\u7edf\u63a2\u7a76\u63d0\u793a\u6846\u67b6\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u5224\u65ad\u7a33\u5b9a\u6027", "method": "\u8bbe\u8ba1\u5bf9\u79f0\u63d0\u793a\uff08\u8c13\u8bcd\u80af\u5b9a\u548c\u8c13\u8bcd\u5426\u5b9a\u7ed3\u6784\uff09\uff0c\u5728\u56db\u4e2a\u9ad8\u98ce\u9669\u8bc4\u4f30\u4efb\u52a1\u4e2d\u6d4b\u8bd514\u4e2aLLM\u6cd5\u5b98\u6a21\u578b\uff0c\u5206\u6790\u6846\u67b6\u504f\u5dee\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd", "result": "\u6846\u67b6\u504f\u5dee\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u663e\u8457\u5dee\u5f02\uff0c\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u5bf9\u6846\u67b6\u8868\u73b0\u51fa\u660e\u663e\u503e\u5411\u6027\uff08\u540c\u610f\u6216\u62d2\u7edd\uff09\uff0c\u8868\u660e\u6846\u67b6\u504f\u5dee\u662f\u5f53\u524dLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u7279\u5f81", "conclusion": "\u6846\u67b6\u504f\u5dee\u662fLLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u56fa\u6709\u7f3a\u9677\uff0c\u9700\u8981\u5f00\u53d1\u6846\u67b6\u611f\u77e5\u7684\u8bc4\u4f30\u534f\u8bae\u6765\u786e\u4fdd\u5224\u65ad\u7684\u7a33\u5b9a\u6027\u548c\u516c\u6b63\u6027"}}
{"id": "2601.13422", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13422", "abs": "https://arxiv.org/abs/2601.13422", "authors": ["Dahai Yu", "Rongchao Xu", "Dingyi Zhuang", "Yuheng Bu", "Shenhao Wang", "Guang Wang"], "title": "TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction", "comment": null, "summary": "Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.", "AI": {"tldr": "TrustEnergy\uff1a\u4e00\u4e2a\u7528\u4e8e\u51c6\u786e\u53ef\u9760\u7528\u6237\u7ea7\u80fd\u8017\u9884\u6d4b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u5c42\u6b21\u65f6\u7a7a\u8868\u793a\u548c\u987a\u5e8f\u4fdd\u5f62\u5206\u4f4d\u6570\u56de\u5f52\uff0c\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u80fd\u8017\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u5ffd\u89c6\u5bb6\u5ead\u95f4\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u6216\u65e0\u6cd5\u6269\u5c55\u5230\u4e2a\u4f53\u5316\u9884\u6d4b\uff1b2\uff09\u672a\u80fd\u5145\u5206\u63a2\u7d22\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u800c\u80fd\u8017\u7684\u52a8\u6001\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff08\u5982\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\uff09\u4f7f\u5f97\u53ef\u9760\u9884\u6d4b\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "method": "TrustEnergy\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\u7ec4\u4ef6\uff1a1\uff09\u5c42\u6b21\u65f6\u7a7a\u8868\u793a\u6a21\u5757\uff0c\u4f7f\u7528\u65b0\u578b\u8bb0\u5fc6\u589e\u5f3a\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u9ad8\u6548\u6355\u6349\u5b8f\u89c2\u548c\u5fae\u89c2\u80fd\u8017\u6a21\u5f0f\uff1b2\uff09\u987a\u5e8f\u4fdd\u5f62\u5206\u4f4d\u6570\u56de\u5f52\u6a21\u5757\uff0c\u52a8\u6001\u8c03\u6574\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\uff0c\u786e\u4fdd\u968f\u65f6\u95f4\u63a8\u79fb\u7684\u6709\u6548\u9884\u6d4b\u533a\u95f4\uff0c\u65e0\u9700\u5bf9\u5e95\u5c42\u6570\u636e\u5206\u5e03\u505a\u5f3a\u5047\u8bbe\u3002", "result": "\u4e0e\u4f5b\u7f57\u91cc\u8fbe\u5dde\u7535\u529b\u4f9b\u5e94\u5546\u5408\u4f5c\u5b9e\u65bd\u548c\u8bc4\u4f30TrustEnergy\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9884\u6d4b\u7cbe\u5ea6\u63d0\u9ad85.4%\uff0c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6539\u8fdb5.7%\u3002", "conclusion": "TrustEnergy\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u53ef\u9760\u7684\u7528\u6237\u7ea7\u80fd\u8017\u9884\u6d4b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7a7a\u95f4\u76f8\u5173\u6027\u5efa\u6a21\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u7535\u7f51\u7ba1\u7406\u3001\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u707e\u5bb3\u54cd\u5e94\u7b49\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2601.13547", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13547", "abs": "https://arxiv.org/abs/2601.13547", "authors": ["Yujia Hu", "Roy Ka-Wei Lee"], "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations", "comment": "EACL 2026 Main Conference", "summary": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.\n  \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}", "AI": {"tldr": "HateXScore\uff1a\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u89e3\u91ca\u8d28\u91cf\u7684\u56db\u7ec4\u4ef6\u6307\u6807\u5957\u4ef6\uff0c\u53ef\u63ed\u793a\u6807\u51c6\u6307\u6807\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898", "motivation": "\u5f53\u524d\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u8bc4\u4f30\u6846\u67b6\u5f88\u5c11\u8bc4\u4f30\u6587\u672c\u4e3a\u4f55\u88ab\u5224\u5b9a\u4e3a\u4ec7\u6068\u8a00\u8bba\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u89e3\u91ca\u8d28\u91cf\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u65b9\u6cd5", "method": "\u63d0\u51faHateXScore\u56db\u7ec4\u4ef6\u6307\u6807\u5957\u4ef6\uff1a1)\u7ed3\u8bba\u660e\u786e\u6027\uff1b2)\u5f15\u7528\u6587\u672c\u7684\u5fe0\u5b9e\u6027\u548c\u56e0\u679c\u57fa\u7840\uff1b3)\u53d7\u4fdd\u62a4\u7fa4\u4f53\u8bc6\u522b\uff08\u53ef\u914d\u7f6e\uff09\uff1b4)\u5404\u7ec4\u4ef6\u95f4\u7684\u903b\u8f91\u4e00\u81f4\u6027", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cHateXScore\u80fd\u591f\u63ed\u793a\u6807\u51c6\u6307\u6807\uff08\u5982\u51c6\u786e\u7387\u3001F1\u5206\u6570\uff09\u65e0\u6cd5\u53d1\u73b0\u7684\u89e3\u91ca\u6027\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u4e0eHateXScore\u9ad8\u5ea6\u4e00\u81f4", "conclusion": "HateXScore\u53ef\u4f5c\u4e3a\u8bca\u65ad\u6027\u8865\u5145\u5de5\u5177\uff0c\u4e3a\u53ef\u4fe1\u548c\u900f\u660e\u7684\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u5b9e\u7528\u8bc4\u4f30\u65b9\u6cd5\uff0c\u589e\u5f3a\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2601.13435", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13435", "abs": "https://arxiv.org/abs/2601.13435", "authors": ["Shuozhe Li", "Du Cheng", "Leqi Liu"], "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization", "comment": null, "summary": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.", "AI": {"tldr": "WaveLSFormer\uff1a\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u5c0f\u6ce2\u53d8\u6362\u957f\u77ed\u671fTransformer\u6a21\u578b\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u591a\u5c3a\u5ea6\u5206\u89e3\u548c\u9762\u5411\u6536\u76ca\u7684\u51b3\u7b56\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u65e5\u5185\u4ea4\u6613\u7684\u76c8\u5229\u80fd\u529b\u548c\u98ce\u9669\u8c03\u6574\u6536\u76ca\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u7684\u65e5\u5185\u4ea4\u6613\u7b56\u7565\u5b66\u4e60\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u566a\u58f0\u5927\u3001\u975e\u5e73\u7a33\u6027\u5f3a\u3001\u76f8\u5173\u8d44\u4ea7\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u6a2a\u622a\u9762\u4f9d\u8d56\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u7279\u6027\u3002", "method": "\u63d0\u51faWaveLSFormer\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u53ef\u5b66\u4e60\u5c0f\u6ce2\u524d\u7aef\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u6ee4\u6ce2\u5668\u7ec4\u751f\u6210\u4f4e/\u9ad8\u9891\u5206\u91cf\uff0c\u8f85\u4ee5\u9891\u8c31\u6b63\u5219\u5316\u786e\u4fdd\u9891\u7387\u5e26\u7a33\u5b9a\u5206\u79bb\uff1b2\uff09\u4f4e\u9891\u5f15\u5bfc\u9ad8\u9891\u6ce8\u5165\u6a21\u5757\uff0c\u878d\u5408\u591a\u5c3a\u5ea6\u4fe1\u606f\uff1b3\uff09\u56fa\u5b9a\u98ce\u9669\u9884\u7b97\u4e0b\u7684\u6295\u8d44\u7ec4\u5408\u7f29\u653e\uff0c\u76f4\u63a5\u4f18\u5316\u4ea4\u6613\u76ee\u6807\u548c\u98ce\u9669\u611f\u77e5\u6b63\u5219\u5316\u3002", "result": "\u57285\u5e74\u5c0f\u65f6\u7ea7\u6570\u636e\u30016\u4e2a\u884c\u4e1a\u7ec4\u300110\u4e2a\u968f\u673a\u79cd\u5b50\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cWaveLSFormer\u663e\u8457\u4f18\u4e8eMLP\u3001LSTM\u548cTransformer\u57fa\u7ebf\u6a21\u578b\u3002\u5e73\u5747\u7d2f\u8ba1\u7b56\u7565\u6536\u76ca0.607\u00b10.045\uff0c\u590f\u666e\u6bd4\u73872.157\u00b10.166\uff0c\u5728\u76c8\u5229\u80fd\u529b\u548c\u98ce\u9669\u8c03\u6574\u6536\u76ca\u65b9\u9762\u5747\u6709\u5927\u5e45\u63d0\u5347\u3002", "conclusion": "WaveLSFormer\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5c0f\u6ce2\u5206\u89e3\u548cTransformer\u67b6\u6784\u7684\u6709\u673a\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u7684\u566a\u58f0\u3001\u975e\u5e73\u7a33\u6027\u548c\u6a2a\u622a\u9762\u4f9d\u8d56\u95ee\u9898\uff0c\u4e3a\u65e5\u5185\u4ea4\u6613\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13575", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13575", "abs": "https://arxiv.org/abs/2601.13575", "authors": ["Thanh-Lam T. Nguyen", "Ngoc-Quang Le", "Quoc-Trung Phu", "Thi-Phuong Le", "Ngoc-Huyen Pham", "Phuong-Nguyen Nguyen", "Hoang-Quynh Le"], "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews", "comment": null, "summary": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.", "AI": {"tldr": "SUDO\u662f\u4e00\u4e2a\u7528\u4e8e\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b4,150\u4e2a\u6807\u6ce8\u7684\u8bc4\u8bba\u5bf9\uff0c\u652f\u6301\u5728\u6ca1\u6709\u663e\u5f0f\u6bd4\u8f83\u7ebf\u7d22\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u6bd4\u8f83\u8868\u8fbe\uff0c\u4f46\u5728\u771f\u5b9e\u8bc4\u8bba\u4e2d\u4e0d\u5e38\u89c1\u3002\u9690\u5f0f\u6bd4\u8f83\uff08\u7528\u6237\u5728\u4e0d\u540c\u8bc4\u8bba\u4e2d\u8868\u8fbe\u504f\u597d\uff09\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86SUDO\u6570\u636e\u96c6\uff0c\u5305\u542b4,150\u4e2a\u6807\u6ce8\u8bc4\u8bba\u5bf9\uff0815,191\u4e2a\u53e5\u5b50\uff09\uff0c\u91c7\u7528\u53cc\u5c42\u7ed3\u6784\u6355\u6349\u65b9\u9762\u7ea7\u63d0\u53ca\u548c\u8bc4\u8bba\u7ea7\u504f\u597d\u3002\u4f7f\u7528\u4e24\u79cd\u57fa\u7ebf\u67b6\u6784\uff1a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7ebf\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u4ecd\u7136\u4e2d\u7b49\uff0c\u8868\u660e\u4efb\u52a1\u5177\u6709\u56fa\u6709\u96be\u5ea6\uff0cSUDO\u6210\u4e3a\u672a\u6765\u7814\u7a76\u7684\u6311\u6218\u6027\u57fa\u51c6\u3002", "conclusion": "SUDO\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u4ef7\u503c\u7684\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u8be5\u4efb\u52a1\u7684\u56fa\u6709\u96be\u5ea6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.13445", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.13445", "abs": "https://arxiv.org/abs/2601.13445", "authors": ["Ashish S. Nair", "Sandipp Krishnan Ravi", "Itzel Salgado", "Changjie Sun", "Sayan Ghosh", "Liping Wang"], "title": "BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions", "comment": null, "summary": "Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eDeepSDF\u7684\u6da1\u8f6e\u53f6\u7247\u9886\u57df\u7279\u5b9a\u9690\u5f0f\u751f\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u6027\u80fd\u611f\u77e5\u7684\u53ef\u5236\u9020\u8bbe\u8ba1\u751f\u6210", "motivation": "\u89e3\u51b3\u6da1\u8f6e\u53f6\u7247\u8bbe\u8ba1\u4e2d\u6027\u80fd\u611f\u77e5\u5efa\u6a21\u548c\u53ef\u5236\u9020\u8bbe\u8ba1\u751f\u6210\u7684\u5173\u952e\u7a7a\u767d\uff0c\u8d85\u8d8a\u4f20\u7edf2D\u5f15\u5bfc\u6216\u65e0\u7ea6\u675f3D\u6d41\u7a0b", "method": "\u4f7f\u7528\u8fde\u7eed\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570(SDF)\u8868\u793a\uff0c\u5efa\u7acb\u53ef\u89e3\u91ca\u7684\u8fd1\u9ad8\u65af\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5c06\u5de5\u7a0b\u63cf\u8ff0\u7b26\u6620\u5c04\u5230\u6f5c\u5728\u4ee3\u7801", "result": "\u5b9e\u73b0\u9ad8\u91cd\u5efa\u4fdd\u771f\u5ea6\uff08\u8868\u9762\u8ddd\u79bb\u8bef\u5dee\u5728\u6700\u5927\u53f6\u7247\u5c3a\u5bf8\u76841%\u5185\uff09\uff0c\u5bf9\u672a\u89c1\u8bbe\u8ba1\u5177\u6709\u9c81\u68d2\u6cdb\u5316\u80fd\u529b", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u6da1\u8f6e\u53f6\u7247\u5efa\u6a21\u548c\u6982\u5ff5\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6574\u5408\u4e86\u7ea6\u675f\u3001\u76ee\u6807\u548c\u6027\u80fd\u6307\u6807"}}
{"id": "2601.13588", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13588", "abs": "https://arxiv.org/abs/2601.13588", "authors": ["Inho Won", "Hangyeol Yoo", "Minkyung Cho", "Jungyeul Park", "Hoyun Song", "KyungTae Lim"], "title": "TREX: Tokenizer Regression for Optimal Data Mixture", "comment": "Accepted to EACL 2026. Long Paper. (19 languages studied: Chinese, Greek, Japanese, etc.)", "summary": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.", "AI": {"tldr": "TREX\u6846\u67b6\u901a\u8fc7\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u6700\u4f18\u7684\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u8bad\u7ec3\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u907f\u514d\u4f20\u7edf\u542f\u53d1\u5f0f\u6216\u5927\u89c4\u6a21\u641c\u7d22\u7684\u9ad8\u6210\u672c\uff0c\u63d0\u5347\u5206\u8bcd\u5668\u538b\u7f29\u6548\u7387\u8fbe12%", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u8bcd\u5668\u9700\u8981\u4f18\u5316\u8bed\u8a00\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\u6216\u6210\u672c\u9ad8\u6602\u7684\u5927\u89c4\u6a21\u641c\u7d22\uff0c\u7f3a\u4e4f\u9ad8\u6548\u786e\u5b9a\u6700\u4f18\u6df7\u5408\u6bd4\u4f8b\u7684\u65b9\u6cd5", "method": "\u63d0\u51faTREX\u6846\u67b6\uff1a1\uff09\u5728\u5c0f\u89c4\u6a21\u4ee3\u7406\u5206\u8bcd\u5668\u4e0a\u8bad\u7ec3\u968f\u673a\u6570\u636e\u6df7\u5408\uff1b2\uff09\u6536\u96c6\u538b\u7f29\u7edf\u8ba1\u4fe1\u606f\uff1b3\uff09\u5b66\u4e60\u4ece\u6570\u636e\u6df7\u5408\u5230\u538b\u7f29\u6027\u80fd\u7684\u9884\u6d4b\u6a21\u578b\uff1b4\uff09\u5728\u5927\u89c4\u6a21\u5206\u8bcd\u5668\u8bad\u7ec3\u524d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u6df7\u5408\u6bd4\u4f8b\u641c\u7d22", "result": "TREX\u9884\u6d4b\u7684\u6df7\u5408\u6bd4\u4f8b\u8bad\u7ec3\u7684\u5206\u8bcd\u5668\uff0c\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u538b\u7f29\u6548\u7387\u4e0a\u6bd4LLaMA3\u548c\u5747\u5300\u5206\u5e03\u65b9\u6cd5\u63d0\u5347\u8fbe12%\uff0c\u5c55\u73b0\u51fa\u5f3a\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u6709\u6548\u6027", "conclusion": "TREX\u6846\u67b6\u901a\u8fc7\u56de\u5f52\u5efa\u6a21\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u8bbe\u8ba1\u4e2d\u51c6\u786e\u6027\u4e0e\u6210\u672c\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u786e\u5b9a\u6700\u4f18\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13590", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13590", "abs": "https://arxiv.org/abs/2601.13590", "authors": ["Fan Huang", "Haewoon Kwak", "Jisun An"], "title": "Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728SMCR\u6c9f\u901a\u6846\u67b6\u4e0b\u5bf9\u8bf4\u670d\u7684\u6613\u611f\u6027\uff0c\u53d1\u73b0\u5c0f\u6a21\u578b\u6781\u6613\u88ab\u8bf4\u670d\uff0c\u5143\u8ba4\u77e5\u63d0\u793a\u53cd\u800c\u589e\u52a0\u8106\u5f31\u6027\uff0c\u5bf9\u6297\u6027\u5fae\u8c03\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02", "motivation": "\u5c3d\u7ba1LLMs\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u95ee\u7b54\u4efb\u52a1\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u8bf4\u670d\u5e76\u91c7\u7eb3\u53cd\u4e8b\u5b9e\u4fe1\u5ff5\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u8bf4\u670d\u6613\u611f\u6027\u4ee5\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684\u6a21\u578b", "method": "\u5728SMCR\u6c9f\u901a\u6846\u67b6\u4e0b\uff0c\u5bf95\u4e2a\u4e3b\u6d41LLMs\u57283\u4e2a\u9886\u57df\uff08\u4e8b\u5b9e\u77e5\u8bc6\u3001\u533b\u7597QA\u3001\u793e\u4f1a\u504f\u89c1\uff09\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5206\u6790\u4e0d\u540c\u8bf4\u670d\u7b56\u7565\u5bf9\u4fe1\u5ff5\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u8bd5\u5143\u8ba4\u77e5\u63d0\u793a\u548c\u5bf9\u6297\u6027\u5fae\u8c03\u4f5c\u4e3a\u9632\u5fa1\u63aa\u65bd", "result": "\u5c0f\u6a21\u578b\u8868\u73b0\u51fa\u6781\u7aef\u987a\u4ece\u6027\uff0c80%\u4ee5\u4e0a\u4fe1\u5ff5\u53d8\u5316\u53d1\u751f\u5728\u7b2c\u4e00\u6b21\u8bf4\u670d\u65f6\uff1b\u5143\u8ba4\u77e5\u63d0\u793a\u53cd\u800c\u589e\u52a0\u8106\u5f31\u6027\uff1b\u5bf9\u6297\u6027\u5fae\u8c03\u6548\u679c\u663e\u8457\u4f9d\u8d56\u4e8e\u6a21\u578b\uff1aGPT-4o-mini\u8fbe\u523098.6%\u9c81\u68d2\u6027\uff0cMistral 7B\u4ece35.7%\u63d0\u5347\u523079.3%\uff0c\u800cLlama\u6a21\u578b\u5373\u4f7f\u5fae\u8c03\u540e\u4ecd\u4fdd\u6301\u9ad8\u6613\u611f\u6027\uff08<14%\uff09", "conclusion": "\u5f53\u524d\u9c81\u68d2\u6027\u5e72\u9884\u63aa\u65bd\u5b58\u5728\u663e\u8457\u7684\u6a21\u578b\u4f9d\u8d56\u6027\u9650\u5236\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684LLMs\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u6a21\u578b\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565"}}
{"id": "2601.13456", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13456", "abs": "https://arxiv.org/abs/2601.13456", "authors": ["Sahasra Kokkula", "Daniel David", "Aaditya Baruah"], "title": "Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay", "comment": "8 pages, 5 figures. Course project for Neural Networks & Deep Learning COMSW4776 course at Columbia University", "summary": "Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.", "AI": {"tldr": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u9488\u5bf9\u65f6\u95f4\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u51fa\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u5c11\u91cf\u5386\u53f2\u6837\u672c\u7f13\u51b2\u533a\u6709\u6548\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u65f6\u95f4\u6982\u5ff5\u6f02\u79fb\uff08\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\uff09\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u6807\u51c6FedAvg\u5728\u5b63\u8282\u6027\u6f02\u79fb\u573a\u666f\u4e0b\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898", "method": "\u63d0\u51fa\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u65b9\u6cd5\uff1a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7ef4\u62a4\u4e00\u4e2a\u5c0f\u7684\u5386\u53f2\u6837\u672c\u7f13\u51b2\u533a\uff0c\u5728\u672c\u5730\u8bad\u7ec3\u65f6\u5c06\u8fc7\u53bb\u6837\u672c\u4e0e\u5f53\u524d\u6570\u636e\u6df7\u5408\u4f7f\u7528\uff0c\u65e0\u9700\u6539\u53d8\u670d\u52a1\u5668\u805a\u5408\u673a\u5236", "result": "\u5728Fashion-MNIST\u6570\u636e\u96c6\u4e0a\uff0c\u6807\u51c6FedAvg\u51c6\u786e\u7387\u4ece74%\u964d\u81f328%\uff1b\u4f7f\u7528\u6bcf\u7c7b50\u4e2a\u6837\u672c\u7684\u7f13\u51b2\u533a\u540e\uff0c\u6027\u80fd\u6062\u590d\u523078-82%\uff0c\u6709\u6548\u9632\u6b62\u9057\u5fd8", "conclusion": "\u5ba2\u6237\u7aef\u7ecf\u9a8c\u56de\u653e\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6d88\u878d\u7814\u7a76\u663e\u793a\u5b58\u5728\u660e\u786e\u7684\u5185\u5b58-\u51c6\u786e\u7387\u6743\u8861\u5173\u7cfb\uff0c\u7f13\u51b2\u533a\u5927\u5c0f\u589e\u52a0\u4f1a\u63d0\u5347\u6027\u80fd"}}
{"id": "2601.13614", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13614", "abs": "https://arxiv.org/abs/2601.13614", "authors": ["Bo Peng", "Sirui Chen", "Lei Xu", "Chaochao Lu"], "title": "CauScientist: Teaching LLMs to Respect Data for Causal Discovery", "comment": null, "summary": "Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating \"data scientists\" with probabilistic statistics as rigorous \"verifiers\". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.", "AI": {"tldr": "CauScientist\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u751f\u6210\u5047\u8bbe\u4e0e\u6982\u7387\u7edf\u8ba1\u9a8c\u8bc1\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u521d\u59cb\u5316\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u9519\u8bef\u8bb0\u5fc6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u56e0\u679c\u56fe\u6784\u5efa\u6027\u80fd", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53d7\u7edf\u8ba1\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5efa\u6a21\u5047\u8bbe\u5f71\u54cd\uff0c\u800c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u7edf\u8ba1\u8bc1\u636e\uff0c\u8981\u4e48\u5f15\u5165\u672a\u7ecf\u9a8c\u8bc1\u53ef\u80fd\u8bef\u5bfc\u7ed3\u679c\u7684\u5148\u9a8c\u77e5\u8bc6", "method": "\u63d0\u51faCauScientist\u534f\u4f5c\u6846\u67b6\uff0c\u5c06LLM\u4f5c\u4e3a\u751f\u6210\u5047\u8bbe\u7684\"\u6570\u636e\u79d1\u5b66\u5bb6\"\uff0c\u6982\u7387\u7edf\u8ba1\u4f5c\u4e3a\u4e25\u683c\"\u9a8c\u8bc1\u8005\"\u3002\u91c7\u7528\u6df7\u5408\u521d\u59cb\u5316\u9009\u62e9\u4f18\u8d28\u8d77\u59cb\u56fe\uff0c\u901a\u8fc7LLM\u63d0\u8bae\u4fee\u6539\u5e76\u7531\u7edf\u8ba1\u6807\u51c6\u9a8c\u8bc1\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u7ef4\u62a4\u9519\u8bef\u8bb0\u5fc6\u6307\u5bfc\u9ad8\u6548\u641c\u7d22\u7a7a\u95f4", "result": "\u5b9e\u9a8c\u663e\u793aCauScientist\u663e\u8457\u4f18\u4e8e\u7eaf\u6570\u636e\u9a71\u52a8\u57fa\u7ebf\uff0cF1\u5206\u6570\u63d0\u5347\u8fbe53.8%\uff0c\u53ec\u56de\u7387\u4ece35.0%\u63d0\u5347\u81f3100.0%\u3002\u572837\u8282\u70b9\u56fe\u4e0a\uff0c\u76f8\u6bd4Qwen3-32B\u5c06\u7ed3\u6784\u6c49\u660e\u8ddd\u79bb(SHD)\u964d\u4f4e44.0%", "conclusion": "CauScientist\u901a\u8fc7LLM\u4e0e\u7edf\u8ba1\u65b9\u6cd5\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u6709\u6548\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.13463", "categories": ["cs.LG", "hep-ph", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.13463", "abs": "https://arxiv.org/abs/2601.13463", "authors": ["Brandon B. Le", "D. Keller"], "title": "Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics", "comment": "12 pages, 5 figures. Proceedings for the 26th International Symposium on Spin Physics (SPIN2025), September 21-26, 2025; Qingdao, Shandong, China", "summary": "As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u5185\u5728\u7279\u6027\u7684\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u91cf\u91cf\u5b50\u9650\u5b9a\u5668\u6307\u5bfc\u7ecf\u5178\u4e0e\u91cf\u5b50\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u9009\u62e9\uff0c\u5e94\u7528\u4e8e\u5f3a\u5b50\u7269\u7406\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u67b6\u6784\u7684\u6210\u719f\uff0c\u6838\u5fc3\u6311\u6218\u4e0d\u518d\u662f\u6784\u5efa\u8fd9\u4e9b\u67b6\u6784\uff0c\u800c\u662f\u8bc6\u522b\u91cf\u5b50\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7ecf\u5178\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u4f18\u52bf\u7684\u9886\u57df\u3002\u7279\u522b\u662f\u5728\u6570\u636e\u9a71\u52a8\u7684\u5f3a\u5b50\u7269\u7406\u95ee\u9898\u4e2d\uff0c\u9700\u8981\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u5408\u9002\u7684\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u4ee5\u5b9a\u91cf\u91cf\u5b50\u9650\u5b9a\u5668\u4e3a\u4e2d\u5fc3\uff0c\u57fa\u4e8e\u6570\u636e\u7684\u56fa\u6709\u7279\u6027\uff08\u5982\u590d\u6742\u6027\u3001\u566a\u58f0\u548c\u7ef4\u5ea6\uff09\u6765\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u3002\u901a\u8fc7\u53d7\u63a7\u7684\u5206\u7c7b\u548c\u56de\u5f52\u7814\u7a76\uff0c\u5206\u6790\u76f8\u5bf9\u6a21\u578b\u6027\u80fd\u5982\u4f55\u9075\u5faa\u8fd9\u4e9b\u7279\u6027\u7684\u7cfb\u7edf\u8d8b\u52bf\uff0c\u5e76\u5c06\u8fd9\u4e9b\u8d8b\u52bf\u63d0\u70bc\u4e3a\u9884\u6d4b\u6027\u6807\u51c6\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7ecf\u5178\u4e0e\u91cf\u5b50\u6a21\u578b\u7684\u76f8\u5bf9\u6027\u80fd\u9075\u5faa\u590d\u6742\u6027\u3001\u566a\u58f0\u548c\u7ef4\u5ea6\u7684\u7cfb\u7edf\u8d8b\u52bf\uff0c\u8fd9\u4e9b\u8d8b\u52bf\u53ef\u4ee5\u63d0\u70bc\u4e3a\u9884\u6d4b\u6027\u6807\u51c6\u3002\u5728\u6df1\u5ea6\u865a\u5eb7\u666e\u987f\u6563\u5c04\u4e2d\u63d0\u53d6\u5eb7\u666e\u987f\u5f62\u72b6\u56e0\u5b50\u7684\u5e94\u7528\u4e2d\uff0c\u91cf\u5b50\u9650\u5b9a\u5668\u6210\u529f\u8bc6\u522b\u4e86\u91cf\u5b50\u6a21\u578b\u6709\u5229\u7684\u8fd0\u52a8\u5b66\u533a\u57df\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7cbe\u5bc6\u5f3a\u5b50\u7269\u7406\u4e2d\u90e8\u7f72\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5de5\u5177\uff0c\u901a\u8fc7\u57fa\u4e8e\u6570\u636e\u7279\u6027\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6307\u5bfc\u91cf\u5b50\u4e0e\u7ecf\u5178\u6a21\u578b\u7684\u9009\u62e9\uff0c\u8bc6\u522b\u91cf\u5b50\u4f18\u52bf\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.13630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13630", "abs": "https://arxiv.org/abs/2601.13630", "authors": ["Zhaopeng Zhang", "Pengcheng Sun", "Lan Zhang", "Chen Tang", "Jiewei Lai", "Yunhao Wang", "Hui Jin"], "title": "Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.", "AI": {"tldr": "\u63d0\u51faAAAC\u6846\u67b6\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u6743\u9650\u63a7\u5236\uff0c\u901a\u8fc7\u6743\u9650\u951a\u70b9\u91cd\u5b9a\u5411\u6fc0\u6d3b\u7a7a\u95f4\uff0c\u51cf\u5c11\u6743\u9650\u8fdd\u89c486.5%\uff0c\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90.7%", "motivation": "LLMs\u5728\u77e5\u8bc6\u5e93\u95ee\u7b54\u4e2d\u53ef\u80fd\u65e0\u610f\u4e2d\u6cc4\u9732\u8d85\u51fa\u7528\u6237\u6743\u9650\u8303\u56f4\u7684\u654f\u611f\u4fe1\u606f\uff0c\u96be\u4ee5\u6ee1\u8db3\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u9700\u6c42", "method": "\u57fa\u4e8e\u6fc0\u6d3b\u7a7a\u95f4\u7684\u51e0\u4f55\u89c4\u5f8b\u6027\uff0c\u63d0\u51faAAAC\u6846\u67b6\uff1a\u6784\u5efa\u6743\u9650\u951a\u70b9\u5e93\uff0c\u901a\u8fc7\u591a\u951a\u70b9\u5f15\u5bfc\u673a\u5236\u5c06\u67e5\u8be2\u6fc0\u6d3b\u91cd\u5b9a\u5411\u5230\u6388\u6743\u533a\u57df", "result": "\u5728\u4e09\u4e2aLLM\u5bb6\u65cf\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6743\u9650\u8fdd\u89c4\u7387\u964d\u4f4e86.5%\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90.7%\uff0c\u54cd\u5e94\u53ef\u7528\u6027\u63d0\u5347\uff0c\u63a8\u7406\u5f00\u9500\u5c0f", "conclusion": "AAAC\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u6fc0\u6d3b\u7a7a\u95f4\u51e0\u4f55\u7279\u6027\u7684\u7ec6\u7c92\u5ea6\u6743\u9650\u63a7\u5236\u65b9\u6848\uff0c\u6709\u6548\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027"}}
{"id": "2601.13644", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13644", "abs": "https://arxiv.org/abs/2601.13644", "authors": ["Yang Cao", "Bicheng Yu", "Sikun Yang", "Ming Liu", "Yujiu Yang"], "title": "Towards Token-Level Text Anomaly Detection", "comment": "WWW 2026", "summary": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.", "AI": {"tldr": "\u63d0\u51fatoken\u7ea7\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u6587\u672c\u5185\u90e8\u5f02\u5e38\u7684\u7cbe\u786e\u5b9a\u4f4d\uff0c\u8d85\u8d8a\u4f20\u7edf\u6587\u6863\u7ea7\u68c0\u6d4b\u7684\u5c40\u9650\u6027", "motivation": "\u73b0\u6709\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u5783\u573e\u90ae\u4ef6\u8fc7\u6ee4\u3001\u5047\u65b0\u95fb\u68c0\u6d4b\uff09\u4ec5\u9650\u4e8e\u6587\u6863\u7ea7\u5206\u6790\uff0c\u65e0\u6cd5\u5b9a\u4f4d\u6587\u672c\u4e2d\u5177\u4f53\u7684\u5f02\u5e38\u90e8\u5206\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u68c0\u6d4b\u80fd\u529b", "method": "\u63d0\u51fatoken\u7ea7\u5f02\u5e38\u68c0\u6d4b\u8303\u5f0f\uff0c\u5b9a\u4e49\u6587\u6863\u7ea7\u548ctoken\u7ea7\u6587\u672c\u5f02\u5e38\uff0c\u5efa\u7acb\u7edf\u4e00\u7684\u591a\u7ea7\u68c0\u6d4b\u6846\u67b6\uff0c\u6536\u96c6\u5e76\u6807\u6ce8\u4e09\u4e2a\u5305\u542btoken\u7ea7\u6807\u7b7e\u7684\u57fa\u51c6\u6570\u636e\u96c6", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e6\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6587\u672c\u5f02\u5e38\u7684\u7cbe\u786e\u5b9a\u4f4d", "conclusion": "token\u7ea7\u5f02\u5e38\u68c0\u6d4b\u4e3a\u6587\u672c\u5f02\u5e38\u5b9a\u4f4d\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u7814\u7a76\u53d1\u5c55"}}
{"id": "2601.13476", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13476", "abs": "https://arxiv.org/abs/2601.13476", "authors": ["Jinhao Li", "Hao Wang"], "title": "A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model", "comment": "15 pages", "summary": "The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.", "AI": {"tldr": "PRAIM\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u8bb0\u5fc6\u7684\u6982\u7387\u53d8\u5206\u63d2\u8865\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63d2\u8865\u7cbe\u5ea6\u5e76\u6539\u5584\u4e0b\u6e38\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u57fa\u7840\u8bbe\u65bd\u4e2d\u6570\u636e\u9a71\u52a8\u5e94\u7528\u7684\u53ef\u9760\u6027\u4f9d\u8d56\u4e8e\u5b8c\u6574\u3001\u9ad8\u8d28\u91cf\u7684\u5145\u7535\u6570\u636e\uff0c\u4f46\u73b0\u5b9e\u4e16\u754cEV\u6570\u636e\u96c6\u5e38\u5b58\u5728\u7f3a\u5931\u8bb0\u5f55\uff0c\u73b0\u6709\u63d2\u8865\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5145\u7535\u6570\u636e\u7684\u590d\u6742\u591a\u6a21\u6001\u7279\u6027\uff0c\u4e14\u901a\u5e38\u91c7\u7528\"\u4e00\u7ad9\u4e00\u6a21\u578b\"\u7684\u5c40\u9650\u8303\u5f0f\uff0c\u5ffd\u7565\u4e86\u7ad9\u95f4\u76f8\u5173\u6027\u3002", "method": "\u5f00\u53d1\u4e86PRAIM\u6846\u67b6\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5f02\u6784\u6570\u636e\uff08\u65f6\u95f4\u5e8f\u5217\u9700\u6c42\u3001\u65e5\u5386\u7279\u5f81\u3001\u5730\u7406\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff09\u4e3a\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u8bb0\u5fc6\u4ece\u6574\u4e2a\u5145\u7535\u7f51\u7edc\u4e2d\u68c0\u7d22\u76f8\u5173\u793a\u4f8b\uff0c\u91c7\u7528\u53d8\u5206\u795e\u7ecf\u67b6\u6784\u6784\u5efa\u7edf\u4e00\u7684\u63d2\u8865\u6a21\u578b\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPRAIM\u5728\u63d2\u8865\u7cbe\u5ea6\u548c\u4fdd\u6301\u539f\u59cb\u6570\u636e\u7edf\u8ba1\u5206\u5e03\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u4e86\u4e0b\u6e38\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "PRAIM\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u8bb0\u5fc6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684EV\u57fa\u7840\u8bbe\u65bd\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13649", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13649", "abs": "https://arxiv.org/abs/2601.13649", "authors": ["Xiaolin Zhou", "Zheng Luo", "Yicheng Gao", "Qixuan Chen", "Xiyang Hu", "Yue Zhao", "Ruishan Liu"], "title": "Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5b58\u5728\u8bed\u8a00\u504f\u89c1\uff1a\u540c\u8bed\u8a00\u6bd4\u8f83\u65f6\u6b27\u6d32\u8bed\u8a00\u4f18\u4e8e\u975e\u6d32\u8bed\u8a00\uff0c\u8de8\u8bed\u8a00\u6bd4\u8f83\u65f6\u504f\u597d\u82f1\u8bed\uff0c\u4e14\u8bed\u8a00\u504f\u89c1\u4e0d\u80fd\u5b8c\u5168\u7531\u56f0\u60d1\u5ea6\u89e3\u91ca", "motivation": "LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5df2\u88ab\u8bc1\u660e\u5b58\u5728\u591a\u79cd\u504f\u89c1\uff0c\u5176\u4e2d\u8bed\u8a00\u504f\u89c1\u4f1a\u5f71\u54cd\u5176\u5224\u65ad\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u4e00\u81f4\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u5206\u6790LLM-as-a-judge\u4e2d\u7684\u8bed\u8a00\u504f\u89c1\u95ee\u9898\uff0c\u7279\u522b\u662f\u540c\u8bed\u8a00\u548c\u8de8\u8bed\u8a00\u6bd4\u8f83\u65f6\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u7814\u7a76\u4e24\u79cd\u8bed\u8a00\u504f\u89c1\uff1a(1) \u540c\u8bed\u8a00\u6bd4\u8f83\u65f6\u7684\u6027\u80fd\u5dee\u5f02\uff08\u6bd4\u8f83\u76f8\u540c\u8bed\u8a00\u9009\u9879\uff09\uff1b(2) \u8de8\u8bed\u8a00\u6bd4\u8f83\u65f6\u7684\u504f\u89c1\uff08\u6bd4\u8f83\u4e0d\u540c\u8bed\u8a00\u9009\u9879\uff09\u3002\u5206\u6790\u8bed\u8a00\u5bb6\u65cf\u5dee\u5f02\uff08\u6b27\u6d32vs\u975e\u6d32\u8bed\u8a00\uff09\u3001\u6587\u5316\u76f8\u5173\u4e3b\u9898\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u7a76\u8bed\u8a00\u504f\u89c1\u4e0e\u4f4e\u56f0\u60d1\u5ea6\u504f\u89c1\u7684\u5173\u7cfb\u3002", "result": "\u540c\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u6b27\u6d32\u8bed\u8a00\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u975e\u6d32\u8bed\u8a00\uff0c\u6587\u5316\u76f8\u5173\u4e3b\u9898\u4e2d\u504f\u89c1\u66f4\u660e\u663e\uff1b\u8de8\u8bed\u8a00\u8bc4\u5224\u4e2d\uff0c\u591a\u6570\u6a21\u578b\u504f\u597d\u82f1\u8bed\u7b54\u6848\uff0c\u4e14\u7b54\u6848\u8bed\u8a00\u6bd4\u95ee\u9898\u8bed\u8a00\u5f71\u54cd\u66f4\u5927\uff1b\u8bed\u8a00\u504f\u89c1\u4e0e\u56f0\u60d1\u5ea6\u4ec5\u6709\u5fae\u5f31\u76f8\u5173\uff0c\u4e0d\u80fd\u5b8c\u5168\u7531\u56f0\u60d1\u5ea6\u89e3\u91ca\u3002", "conclusion": "LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5b58\u5728\u663e\u8457\u7684\u8bed\u8a00\u504f\u89c1\uff0c\u8fd9\u79cd\u504f\u89c1\u5728\u4e0d\u540c\u8bed\u8a00\u6bd4\u8f83\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u540c\uff0c\u4e14\u4e0d\u80fd\u7b80\u5355\u5f52\u56e0\u4e8e\u56f0\u60d1\u5ea6\u5dee\u5f02\u3002\u7814\u7a76\u63ed\u793a\u4e86LLM\u8bc4\u5224\u7cfb\u7edf\u9700\u8981\u89e3\u51b3\u7684\u8bed\u8a00\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2601.13658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13658", "abs": "https://arxiv.org/abs/2601.13658", "authors": ["Arthur Amalvy", "Hen-Hsen Huang"], "title": "Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation", "comment": "12 pages", "summary": "The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u672a\u6765\u9884\u6d4b\u4e8b\u5b9e\u7684\u5408\u6210\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u4efb\u52a1\u4e2d\u6570\u636e\u6c61\u67d3\u548c\u8bc4\u4f30\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\uff08TKGE\uff09\u4efb\u52a1\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u6570\u636e\u91cd\u53e0\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u5bfc\u81f4\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u88ab\u9ad8\u4f30\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a1) \u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u751f\u6210\u672a\u6765\u53ef\u80fd\u7684\u56db\u5143\u7ec4\uff1b2) \u4f7f\u7528LLM\u5c06\u56db\u5143\u7ec4\u8f6c\u6362\u4e3a\u8bed\u4e49\u5bf9\u9f50\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u6784\u5efa\u5408\u6210\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b4.2K\u672a\u6765\u56db\u5143\u7ec4\u53ca\u5bf9\u5e94\u6587\u672c\u63cf\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793aLLM\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4f4e\u4e8e\u5df2\u77e5\u4e8b\u5b9e\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u4e86\u6570\u636e\u6c61\u67d3\u95ee\u9898\u7684\u5b58\u5728\u3002", "conclusion": "\u63d0\u51fa\u7684\u5408\u6210\u6570\u636e\u96c6\u65b9\u6cd5\u80fd\u6301\u7eed\u751f\u6210\u65e0\u6c61\u67d3\u7684\u8bc4\u4f30\u6570\u636e\uff0c\u4e3aTKGE\u4efb\u52a1\u63d0\u4f9b\u957f\u671f\u3001\u65e0\u504f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2601.13534", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13534", "abs": "https://arxiv.org/abs/2601.13534", "authors": ["Xu Zhang", "Junwei Deng", "Chang Xu", "Hao Li", "Jiang Bian"], "title": "MN-TSG:Continuous Time Series Generation with Irregular Observations", "comment": "34 pages", "summary": "Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.\n  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.\n  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.\n  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.", "AI": {"tldr": "MN-TSG\uff1a\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6NCDE\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4e0d\u89c4\u5219\u548c\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u751f\u6210\uff0c\u5728\u4e34\u5e8a\u76d1\u6d4b\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u5047\u8bbe\u89c4\u5219\u91c7\u6837\u548c\u56fa\u5b9a\u8f93\u51fa\u5206\u8fa8\u7387\uff0c\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e2d\u4e0d\u89c4\u5219\u91c7\u6837\u548c\u7a00\u758f\u89c2\u6d4b\u7684\u6570\u636e\u4e0d\u5339\u914d\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8a\u76d1\u6d4b\u7b49\u5e94\u7528\u4e2d\u9700\u8981\u652f\u6301\u8fde\u7eed\u9ad8\u5206\u8fa8\u7387\u65f6\u95f4\u5e8f\u5217\u7684\u4e0b\u6e38\u4efb\u52a1", "method": "\u63d0\u51faMN-TSG\u6846\u67b6\uff0c\u7ed3\u5408\u6df7\u5408\u4e13\u5bb6(MoE)\u7684\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b(NCDE)\uff0c\u91c7\u7528\u52a8\u6001\u53c2\u6570\u5316\u4e13\u5bb6\u51fd\u6570\u548c\u89e3\u8026\u8bbe\u8ba1\uff0c\u5e76\u5229\u7528\u73b0\u6709TSG\u6a21\u578b\u5b66\u4e60\u4e13\u5bb6\u6df7\u5408\u4e0e\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u7684\u8054\u5408\u5206\u5e03", "result": "\u572810\u4e2a\u516c\u5171\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMN-TSG\u5728\u4e0d\u89c4\u5219\u5230\u89c4\u5219\u548c\u4e0d\u89c4\u5219\u5230\u8fde\u7eed\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "MN-TSG\u901a\u8fc7MoE-NCDE\u67b6\u6784\u548c\u4e0e\u73b0\u6709TSG\u6a21\u578b\u7684\u96c6\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u89c4\u5219\u548c\u8fde\u7eed\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u95ee\u9898\uff0c\u4e3a\u4e34\u5e8a\u76d1\u6d4b\u7b49\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177"}}
{"id": "2601.13659", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13659", "abs": "https://arxiv.org/abs/2601.13659", "authors": ["Chunlei Meng", "Ziyang Zhou", "Lucas He", "Xiaojing Du", "Chun Ouyang", "Zhongxue Gan"], "title": "Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis", "comment": "This study has been accepted by IEEE ICASSP2026", "summary": "Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.", "AI": {"tldr": "TSDA\u901a\u8fc7\u65f6\u7a7a\u89e3\u8026\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u65f6\u7a7a\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u65f6\u7a7a\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6027\u80fd\u53d7\u9650", "method": "TSDA\uff1a\u5728\u4ea4\u4e92\u524d\u5c06\u6bcf\u4e2a\u6a21\u6001\u89e3\u8026\u4e3a\u65f6\u95f4\u52a8\u6001\u548c\u7a7a\u95f4\u7ed3\u6784\u4e0a\u4e0b\u6587\uff0c\u5206\u522b\u7f16\u7801\u540e\u8fdb\u884c\u56e0\u5b50\u4e00\u81f4\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u6700\u540e\u901a\u8fc7\u95e8\u63a7\u91cd\u8026\u5408\u6a21\u5757\u6574\u5408", "result": "TSDA\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6d88\u878d\u5206\u6790\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u548c\u53ef\u89e3\u91ca\u6027", "conclusion": "\u663e\u5f0f\u65f6\u7a7a\u89e3\u8026\u548c\u56e0\u5b50\u4e00\u81f4\u5bf9\u9f50\u80fd\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898"}}
{"id": "2601.13548", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13548", "abs": "https://arxiv.org/abs/2601.13548", "authors": ["George Wang", "Daniel Murfet"], "title": "Patterning: The Dual of Interpretability", "comment": null, "summary": "Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6a21\u5f0f\u5316\"\u4f5c\u4e3a\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u5bf9\u5076\u95ee\u9898\uff1a\u7ed9\u5b9a\u671f\u671b\u7684\u6cdb\u5316\u5f62\u5f0f\uff0c\u786e\u5b9a\u4ea7\u751f\u5b83\u7684\u8bad\u7ec3\u6570\u636e\u3002\u901a\u8fc7\u53ef\u9006\u7ebf\u6027\u54cd\u5e94\u5173\u7cfb\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u6570\u636e\u5e72\u9884\u6765\u5f15\u5bfc\u6a21\u578b\u8fbe\u5230\u76ee\u6807\u5185\u90e8\u914d\u7f6e\u3002", "motivation": "\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5173\u6ce8\u4ece\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ed3\u6784\u7406\u89e3\u5176\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u4ece\u671f\u671b\u6cdb\u5316\u5f62\u5f0f\u53cd\u5411\u8bbe\u8ba1\u8bad\u7ec3\u6570\u636e\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u8fd9\u79cd\u5bf9\u5076\u5173\u7cfb\uff0c\u5b9e\u73b0\"\u5199\u5165\"\u5185\u90e8\u7ed3\u6784\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u654f\u611f\u6027\u6982\u5ff5\uff0c\u6d4b\u91cf\u53ef\u89c2\u6d4b\u91cf\u540e\u9a8c\u671f\u671b\u503c\u5bf9\u6570\u636e\u5206\u5e03\u5fae\u5c0f\u53d8\u5316\u7684\u54cd\u5e94\u3002\u901a\u8fc7\u9006\u7ebf\u6027\u54cd\u5e94\u5173\u7cfb\uff0c\u63a8\u5bfc\u51fa\u5f15\u5bfc\u6a21\u578b\u8fbe\u5230\u76ee\u6807\u5185\u90e8\u914d\u7f6e\u7684\u6570\u636e\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u5728\u5c0f\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u6cbf\u4e3b\u654f\u611f\u6027\u65b9\u5411\u91cd\u65b0\u52a0\u6743\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u52a0\u901f\u6216\u5ef6\u8fdf\u7ed3\u6784\u5f62\u6210\uff08\u5982\u5f52\u7eb3\u7535\u8def\uff09\u3002\u5728\u62ec\u53f7\u5e73\u8861\u4efb\u52a1\u4e2d\uff0c\u6a21\u5f0f\u5316\u53ef\u4ee5\u901a\u8fc7\u9488\u5bf9\u6bcf\u4e2a\u89e3\u51b3\u65b9\u6848\u7684\u5c40\u90e8\u5b66\u4e60\u7cfb\u6570\u6765\u9009\u62e9\u6a21\u578b\u5b66\u4e60\u7684\u7b97\u6cd5\u3002", "conclusion": "\u5efa\u7acb\u4e86\u7528\u4e8e\u8bfb\u53d6\u5185\u90e8\u7ed3\u6784\u7684\u6570\u5b66\u6846\u67b6\u53ef\u4ee5\u9006\u8f6c\u4e3a\u5199\u5165\u5185\u90e8\u7ed3\u6784\uff0c\u4e3a\u53ef\u63a7\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u5bf9\u5076\u95ee\u9898\u3002"}}
{"id": "2601.13669", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13669", "abs": "https://arxiv.org/abs/2601.13669", "authors": ["Jiayu Lin", "Zhongyu Wei"], "title": "CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks", "comment": null, "summary": "Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a \"middle ground\". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3a\u4e2a\u4f53\u7ea7\u548c\u901a\u7528\u7ea7\u5bf9\u9f50\u7684\u4e2d\u95f4\u65b9\u6848\uff0c\u5e76\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u793e\u533a\u7ea7\u5bf9\u9f50\u8bc4\u4f30\u57fa\u51c6CommunityBench\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u5728\u5efa\u6a21\u793e\u533a\u7279\u5b9a\u504f\u597d\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u4f46\u793e\u533a\u7ea7\u5bf9\u9f50\u6709\u52a9\u4e8e\u4e2a\u4f53\u5efa\u6a21\u3002", "motivation": "\u73b0\u6709LLM\u5bf9\u9f50\u7b56\u7565\u5b58\u5728\u4e24\u4e2a\u6781\u7aef\uff1a\u901a\u7528\u4ef7\u503c\u96c6\uff08one-size-fits-all\uff09\u4f1a\u8fb9\u7f18\u5316\u5c11\u6570\u7fa4\u4f53\u89c4\u8303\uff0c\u800c\u4e2a\u4f53\u7ea7\u5b9a\u5236\u5219\u6210\u672c\u8fc7\u9ad8\u3002\u8003\u8651\u5230\u4eba\u7c7b\u793e\u4f1a\u6309\u793e\u4f1a\u96c6\u7fa4\u7ec4\u7ec7\u4e14\u7ec4\u5185\u4ef7\u503c\u5bf9\u9f50\u5ea6\u9ad8\uff0c\u9700\u8981\u5bfb\u627e\u4e2d\u95f4\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3a\u6298\u4e2d\u65b9\u6848\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u793e\u533a\u7ea7\u5bf9\u9f50\u8bc4\u4f30\u57fa\u51c6CommunityBench\uff0c\u5305\u542b\u57fa\u4e8e\u5171\u540c\u8eab\u4efd\u548c\u5171\u540c\u7ebd\u5e26\u7406\u8bba\u7684\u56db\u4e2a\u4efb\u52a1\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u3002", "result": "\u5f53\u524dLLMs\u5728\u5efa\u6a21\u793e\u533a\u7279\u5b9a\u504f\u597d\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u4f46\u793e\u533a\u7ea7\u5bf9\u9f50\u5728\u4fc3\u8fdb\u4e2a\u4f53\u5efa\u6a21\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u591a\u5143\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "\u793e\u533a\u7ea7\u5bf9\u9f50\u662f\u89e3\u51b3LLM\u5bf9\u9f50\u95ee\u9898\u7684\u6709\u524d\u666f\u7684\u4e2d\u95f4\u8def\u5f84\uff0cCommunityBench\u4e3a\u8bc4\u4f30\u793e\u533a\u7ea7\u5bf9\u9f50\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u5982\u4f55\u66f4\u597d\u5730\u5efa\u6a21\u793e\u533a\u7279\u5b9a\u504f\u597d\u4ee5\u5b9e\u73b0\u591a\u5143\u5bf9\u9f50\u3002"}}
{"id": "2601.13563", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13563", "abs": "https://arxiv.org/abs/2601.13563", "authors": ["Aryan Karmore"], "title": "ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits", "comment": null, "summary": "Linear memory scaling stores $N$ independent expert weight matrices requiring $\\mathcal{O}(N \\cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\\mathcal{O}(d^2 + N \\cdot d \\log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.", "AI": {"tldr": "ButterflyMoE\u901a\u8fc7\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u91cf\u5316\u57fa\u8d28\u7684\u51e0\u4f55\u91cd\u5b9a\u5411\uff0c\u800c\u975e\u72ec\u7acb\u6743\u91cd\u77e9\u9635\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u5185\u5b58\u589e\u957f\uff0c\u5728256\u4e2a\u4e13\u5bb6\u65f6\u8fbe\u5230150\u500d\u5185\u5b58\u538b\u7f29\uff0c\u4f7f64\u4e2a\u4e13\u5bb6\u80fd\u57284GB\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "motivation": "\u73b0\u6709MoE\u65b9\u6cd5\u4e2d\uff0cN\u4e2a\u72ec\u7acb\u4e13\u5bb6\u6743\u91cd\u77e9\u9635\u9700\u8981O(N\u00b7d\u00b2)\u5185\u5b58\uff0c\u8d85\u51fa\u8fb9\u7f18\u8bbe\u5907\u5185\u5b58\u9884\u7b97\u3002\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\uff08\u91cf\u5316\u3001\u526a\u679d\u3001\u4f4e\u79e9\u5206\u89e3\uff09\u53ea\u80fd\u51cf\u5c11\u5e38\u6570\u56e0\u5b50\uff0c\u65e0\u6cd5\u89e3\u51b3\u7ebf\u6027\u7f29\u653e\u74f6\u9888\u3002", "method": "\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u4e09\u5143\u539f\u578b\u7684\u51e0\u4f55\u91cd\u5b9a\u5411\uff0c\u800c\u975e\u72ec\u7acb\u6743\u91cd\u77e9\u9635\u3002\u901a\u8fc7\u5bf9\u5171\u4eab\u91cf\u5316\u57fa\u8d28\u5e94\u7528\u5b66\u4e60\u5230\u7684\u65cb\u8f6c\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u83b7\u5f97O(d\u00b2 + N\u00b7d log d)\u5185\u5b58\uff0c\u5b9e\u73b0\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u5185\u5b58\u589e\u957f\u3002\u8bad\u7ec3\u8fd9\u4e9b\u65cb\u8f6c\u4e0e\u91cf\u5316\u7ed3\u5408\u53ef\u51cf\u5c11\u6fc0\u6d3b\u5f02\u5e38\u503c\u5e76\u7a33\u5b9a\u6781\u7aef\u4f4e\u6bd4\u7279\u8bad\u7ec3\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cButterflyMoE\u5728256\u4e2a\u4e13\u5bb6\u65f6\u5b9e\u73b0150\u500d\u5185\u5b58\u538b\u7f29\uff0c\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002\u76f8\u6bd4\u6807\u51c6MoE\u76848\u4e2a\u4e13\u5bb6\uff0c\u8be5\u65b9\u6cd5\u4f7f64\u4e2a\u4e13\u5bb6\u80fd\u57284GB\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "conclusion": "\u51e0\u4f55\u53c2\u6570\u5316\u6253\u7834\u4e86MoE\u7684\u7ebf\u6027\u5185\u5b58\u7f29\u653e\u74f6\u9888\uff0c\u901a\u8fc7\u5c06\u4e13\u5bb6\u89c6\u4e3a\u5171\u4eab\u5bb9\u91cf\u7684\u4e0d\u540c\u89c6\u89d2\u800c\u975e\u5197\u4f59\u5b58\u50a8\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u5185\u5b58\u589e\u957f\uff0c\u4f7f\u5927\u89c4\u6a21MoE\u6a21\u578b\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2601.13684", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13684", "abs": "https://arxiv.org/abs/2601.13684", "authors": ["Zhiyuan Shi", "Qibo Qiu", "Feng Xue", "Zhonglin Jiang", "Li Yu", "Jian Jiang", "Xiaofei He", "Wenxiao Wang"], "title": "HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference", "comment": null, "summary": "The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\\times$ compared to the original model in the 224K context. Our code will be open-source.", "AI": {"tldr": "HeteroCache\uff1a\u4e00\u79cd\u514d\u8bad\u7ec3\u7684\u52a8\u6001KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5934\u90e8\u5206\u7c7b\u3001\u5206\u5c42\u5b58\u50a8\u548c\u5f02\u6b65\u6309\u9700\u68c0\u7d22\uff0c\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898", "motivation": "\u73b0\u6709\u9759\u6001\u538b\u7f29\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u7559\u5168\u5c40\u91cd\u8981\u4fe1\u606f\uff08\u5ffd\u89c6\u6ce8\u610f\u529b\u6f02\u79fb\u73b0\u8c61\uff09\uff0c\u52a8\u6001\u68c0\u7d22\u65b9\u6cd5\u5219\u5b58\u5728\u7c97\u7c92\u5ea6\u7f13\u5b58\u7b56\u7565\u548c\u9ad8I/O\u5f00\u9500\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6848", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u5934\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\uff0c\u5c06\u5934\u90e8\u5206\u7c7b\u4e3a\u7a33\u5b9a\u548c\u5197\u4f59\u7c7b\u578b\uff1b\u91c7\u7528\u7ec6\u7c92\u5ea6\u6743\u91cd\u5206\u914d\u7b56\u7565\uff0c\u4e3a\u6ce8\u610f\u529b\u5feb\u901f\u53d8\u5316\u7684\u5934\u5206\u914d\u66f4\u5927\u7f13\u5b58\u9884\u7b97\uff1b\u4f7f\u7528\u5206\u5c42\u5b58\u50a8\u673a\u5236\uff0c\u8ba9\u4ee3\u8868\u6027\u5b50\u96c6\u76d1\u63a7\u6ce8\u610f\u529b\u53d8\u5316\u5e76\u89e6\u53d1\u5f02\u6b65\u6309\u9700\u68c0\u7d22", "result": "\u5728\u591a\u4e2a\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728224K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u76f8\u6bd4\u539f\u59cb\u6a21\u578b\u52a0\u901f\u89e3\u7801\u8fbe3\u500d", "conclusion": "HeteroCache\u901a\u8fc7\u52a8\u6001\u7ec6\u7c92\u5ea6\u538b\u7f29\u6709\u6548\u89e3\u51b3\u4e86KV\u7f13\u5b58\u7ebf\u6027\u589e\u957f\u95ee\u9898\uff0c\u5e73\u8861\u4e86\u4fe1\u606f\u4fdd\u7559\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u6027\u80fd"}}
{"id": "2601.13564", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.13564", "abs": "https://arxiv.org/abs/2601.13564", "authors": ["Yanheng Li", "Zhichen Pu", "Lijiang Yang", "Zehao Zhou", "Yi Qin Gao"], "title": "Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework", "comment": "Total 43 pages: 32 pages Main Text + 11 pages SI", "summary": "Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.", "AI": {"tldr": "LUMOS\u662f\u4e00\u4e2a\u6570\u636e\u4e0e\u7269\u7406\u53cc\u9a71\u52a8\u7684\u8367\u5149\u5206\u5b50\u9006\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u751f\u6210\u5668\u4e0e\u9884\u6d4b\u5668\u3001\u795e\u7ecf\u7f51\u7edc\u4e0e\u5feb\u901fTD-DFT\u8ba1\u7b97\uff0c\u5b9e\u73b0\u591a\u76ee\u6807\u7ea6\u675f\u4e0b\u7684\u9ad8\u6548\u5206\u5b50\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edf\u8367\u5149\u5206\u5b50\u8bbe\u8ba1\u65b9\u6cd5\u9762\u4e34\u5316\u5b66\u7a7a\u95f4\u5de8\u5927\u3001\u591a\u76ee\u6807\u7ea6\u675f\u590d\u6742\u3001\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u53ef\u9760\u6027\u4e0d\u8db3\u3001\u91cf\u5b50\u5316\u5b66\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7b49\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u9006\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "1) \u5728\u5171\u4eab\u6f5c\u5728\u8868\u793a\u4e2d\u8026\u5408\u751f\u6210\u5668\u548c\u9884\u6d4b\u5668\uff1b2) \u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u5feb\u901fTD-DFT\u6784\u5efa\u4e92\u8865\u9884\u6d4b\u5668\u5957\u4ef6\uff1b3) \u91c7\u7528\u5c5e\u6027\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u4e0e\u591a\u76ee\u6807\u8fdb\u5316\u7b97\u6cd5\u96c6\u6210\u3002", "result": "\u5728\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLUMOS\u5728\u8367\u5149\u5c5e\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u548c\u7269\u7406\u5408\u7406\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u591a\u76ee\u6807\u5206\u5b50\u4f18\u5316\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cTD-DFT\u548cMD\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u751f\u6210\u7b26\u5408\u76ee\u6807\u89c4\u683c\u7684\u6709\u6548\u8367\u5149\u56e2\u3002", "conclusion": "LUMOS\u5efa\u7acb\u4e86\u4e00\u4e2a\u6570\u636e\u4e0e\u7269\u7406\u53cc\u9a71\u52a8\u7684\u901a\u7528\u8367\u5149\u56e2\u9006\u8bbe\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u63a2\u7d22\u5316\u5b66\u7a7a\u95f4\u5e76\u5728\u591a\u76ee\u6807\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u5b9a\u5236\u8367\u5149\u5206\u5b50\u3002"}}
{"id": "2601.13690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13690", "abs": "https://arxiv.org/abs/2601.13690", "authors": ["Yue Guo", "Fanfu Wang", "Jianwei Lv", "Xincheng Shi", "Yuchen Li", "Youya Wang", "Yunsheng Zeng", "Yujing Liu", "Yunhao Qiao", "Gen Li", "Junfeng Wang", "Bo Yuan"], "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning", "comment": null, "summary": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.", "AI": {"tldr": "\u63d0\u51faDr. Assistant\u4e34\u5e8a\u8bca\u65ad\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08SFT+RL\uff09\u63d0\u5347LLM\u7684\u4e34\u5e8a\u63a8\u7406\u548c\u95ee\u8bca\u80fd\u529b\uff0c\u5728\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8bca\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4e0e\u95ed\u6e90\u6a21\u578b\u7ade\u4e89", "motivation": "\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u533b\u5b66\u77e5\u8bc6\u4e30\u5bcc\uff0c\u4f46\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8bca\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8fd9\u4e9b\u5173\u952e\u4e34\u5e8a\u6280\u80fd", "method": "\u63d0\u51fa\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u6570\u636e\u7ed3\u6784\uff08CDRD\uff09\u6765\u6355\u6349\u62bd\u8c61\u4e34\u5e8a\u63a8\u7406\u903b\u8f91\uff0c\u5e76\u6784\u5efaDr. Assistant\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u5148\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\uff0c\u518d\u4f7f\u7528\u5b9a\u5236\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09", "result": "Dr. Assistant\u5728\u8bca\u65ad\u63a8\u7406\u548c\u95ee\u8bca\u8bc4\u4f30\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4e0e\u95ed\u6e90\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u95ee\u8bca\u6307\u5bfc\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848", "conclusion": "\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u4e34\u5e8a\u63a8\u7406\u6570\u636e\u7ed3\u6784\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6210\u529f\u5f00\u53d1\u51fa\u5177\u5907\u4e34\u5e8a\u63a8\u7406\u548c\u95ee\u8bca\u80fd\u529b\u7684Dr. Assistant\u6a21\u578b\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84"}}
{"id": "2601.13566", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13566", "abs": "https://arxiv.org/abs/2601.13566", "authors": ["Tianyi Qiu", "Ahmed Hani Ismail", "Zhonghao He", "Shi Feng"], "title": "Self-Improvement as Coherence Optimization: A Theoretical Account", "comment": "39 pages", "summary": "Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u8fa9\u8bba\u3001\u81ea\u4e3e\u548c\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\u7b49\u65b9\u6cd5\u5728\u6ca1\u6709\u5916\u90e8\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u81ea\u6211\u63d0\u5347\u51c6\u786e\u6027\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u90fd\u662f\"\u4e00\u81f4\u6027\u4f18\u5316\"\u7684\u7279\u6b8a\u5f62\u5f0f\uff0c\u5373\u5bfb\u627e\u6700\u53ef\u538b\u7f29\u548c\u8054\u5408\u53ef\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u5230\u884c\u4e3a\u7684\u6620\u5c04\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u6cd5\u81ea\u6211\u63d0\u5347\u6027\u80fd\uff0c\u751a\u81f3\u8fbe\u5230\u6709\u76d1\u7763\u5fae\u8c03\u7684\u6548\u679c\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e3a\u4f55\u6709\u6548\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u89e3\u91ca\u8fd9\u4e9b\u65e0\u76d1\u7763\u81ea\u6211\u63d0\u5347\u65b9\u6cd5\u7684\u5de5\u4f5c\u539f\u7406\u3002", "method": "\u63d0\u51fa\"\u4e00\u81f4\u6027\u4f18\u5316\"\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u8fa9\u8bba\u3001\u81ea\u4e3e\u548c\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\u7b49\u65b9\u6cd5\u90fd\u662f\u4e00\u81f4\u6027\u4f18\u5316\u7684\u7279\u4f8b\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u4e00\u81f4\u6027\u4f18\u5316\u7b49\u4ef7\u4e8e\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\uff0c\u5e76\u8bc1\u660e\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u5bfc\u51fa\u7684\u6b63\u5219\u5316\u65b9\u6848\u4e2d\uff0c\u4e00\u81f4\u6027\u4f18\u5316\u5728\u534a\u76d1\u7763\u5b66\u4e60\u573a\u666f\u4e0b\u662f\u6700\u4f18\u7684\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u4e00\u81f4\u6027\u4f18\u5316\u662f\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\u7684\u7b49\u4ef7\u5f62\u5f0f\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u5bfc\u51fa\u7684\u6b63\u5219\u5316\u65b9\u6848\u4e2d\u5177\u6709\u6700\u4f18\u6027\u3002\u521d\u6b65\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u9884\u6d4b\uff0c\u89e3\u91ca\u4e86\u65e0\u76d1\u7763\u81ea\u6211\u63d0\u5347\u65b9\u6cd5\u4e3a\u4f55\u6709\u6548\uff0c\u5e76\u80fd\u9884\u6d4b\u5176\u6210\u529f\u6216\u5931\u8d25\u7684\u6761\u4ef6\u3002", "conclusion": "\u65e0\u76d1\u7763\u81ea\u6211\u63d0\u5347\u65b9\u6cd5\uff08\u5982\u8fa9\u8bba\u3001\u81ea\u4e3e\u548c\u5185\u90e8\u4e00\u81f4\u6027\u6700\u5927\u5316\uff09\u4e4b\u6240\u4ee5\u6709\u6548\uff0c\u662f\u56e0\u4e3a\u5b83\u4eec\u90fd\u662f\u4e00\u81f4\u6027\u4f18\u5316\u7684\u7279\u4f8b\u3002\u4e00\u81f4\u6027\u4f18\u5316\u4f5c\u4e3a\u63cf\u8ff0\u957f\u5ea6\u6b63\u5219\u5316\u7684\u4e00\u79cd\u5f62\u5f0f\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u80cc\u666f\u4e0b\u5177\u6709\u7406\u8bba\u6700\u4f18\u6027\uff0c\u8fd9\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u63d0\u5347\u673a\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.13695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13695", "abs": "https://arxiv.org/abs/2601.13695", "authors": ["Sifan Li", "Hongkai Chen", "Yujun Cai", "Liyang Chen", "Qingwen Ye", "Yiwei Wang"], "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens", "comment": null, "summary": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.", "AI": {"tldr": "OptiSQL\uff1a\u76f4\u63a5\u4ece\u8868\u683c\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u53ef\u6267\u884cSQL\u7684\u89c6\u89c9\u9a71\u52a8\u6846\u67b6\uff0c\u4f7f\u7528\u7d27\u51d1\u5149\u5b66\u6807\u8bb0\u51cf\u5c11\u8f93\u5165\u6807\u8bb0\u6570\u91cf", "motivation": "\u4f20\u7edf\u6587\u672c\u5230SQL\u65b9\u6cd5\u9700\u8981\u5c06\u8868\u683c\u5b8c\u5168\u7ebf\u6027\u5316\u4e3a\u6587\u672c\u6a21\u5f0f\uff0c\u8fd9\u5047\u8bbe\u8bbf\u95ee\u7ed3\u6784\u5316\u6587\u672c\u5e76\u4ea7\u751f\u5927\u91cf\u6807\u8bb0\u5f00\u9500\uff0c\u4e0e\u73b0\u5b9e\u573a\u666f\u4e2d\u8868\u683c\u4f5c\u4e3a\u6587\u6863\u6216\u7f51\u9875\u4e2d\u7684\u89c6\u89c9\u5143\u7d20\u5b58\u5728\u4e0d\u5339\u914d", "method": "\u4f7f\u7528OCR\u5bfc\u5411\u7684\u89c6\u89c9\u7f16\u7801\u5668\u5c06\u8868\u683c\u7ed3\u6784\u548c\u5185\u5bb9\u538b\u7f29\u4e3a\u4e00\u5c0f\u7ec4\u5149\u5b66\u6807\u8bb0\uff0c\u5fae\u8c03\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u8fdb\u884cSQL\u751f\u6210\uff0c\u540c\u65f6\u51bb\u7ed3\u7f16\u7801\u5668\u4ee5\u9694\u79bb\u8868\u793a\u5145\u5206\u6027", "result": "\u5728\u53ef\u89c6\u5316\u7684Spider 2.0-Snow\u7248\u672c\u4e0a\uff0cOptiSQL\u4fdd\u6301\u5f3a\u5927\u7684\u6267\u884c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5c06\u8868\u683c\u8f93\u5165\u6807\u8bb0\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\uff1b\u9c81\u68d2\u6027\u5206\u6790\u663e\u793a\u5149\u5b66\u6807\u8bb0\u5728\u89c6\u89c9\u6270\u52a8\u4e0b\u4fdd\u7559\u57fa\u672c\u7ed3\u6784\u4fe1\u606f", "conclusion": "\u7d27\u51d1\u7684\u5149\u5b66\u8868\u793a\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u6267\u884c\u8bed\u4e49\u89e3\u6790\u7684\u6709\u6548\u63a5\u53e3\uff0c\u89c6\u89c9\u9a71\u52a8\u65b9\u6cd5\u5728\u51cf\u5c11\u6807\u8bb0\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301SQL\u751f\u6210\u51c6\u786e\u6027"}}
{"id": "2601.13569", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.13569", "abs": "https://arxiv.org/abs/2601.13569", "authors": ["Jiasen Li", "Yanwei Liu", "Zhuoyi Shang", "Xiaoyan Gu", "Weiping Wang"], "title": "DRGW: Learning Disentangled Representations for Robust Graph Watermarking", "comment": "Published at The Web Conference 2026 (WWW '26)", "summary": "Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.", "AI": {"tldr": "DRGW\u662f\u9996\u4e2a\u57fa\u4e8e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u7684\u56fe\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u7ed3\u6784\u8868\u793a\u4e0e\u6c34\u5370\u8f7d\u4f53\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u900f\u660e\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u56fe\u6c34\u5370\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u56fe\u7ed3\u6784\u6216\u7ea0\u7f20\u7684\u56fe\u8868\u793a\uff0c\u7531\u4e8e\u56fe\u8868\u793a\u4e2d\u7684\u4fe1\u606f\u8026\u5408\u4ee5\u53ca\u8fde\u7eed\u6570\u503c\u8868\u793a\u5230\u56fe\u7ed3\u6784\u7684\u4e0d\u53ef\u63a7\u79bb\u6563\u5316\uff0c\u5bfc\u81f4\u6c34\u5370\u7684\u900f\u660e\u5ea6\u548c\u9c81\u68d2\u6027\u53d7\u635f\u3002", "method": "1) \u8bbe\u8ba1\u5bf9\u6297\u8bad\u7ec3\u7684\u7f16\u7801\u5668\u5b66\u4e60\u5bf9\u6270\u52a8\u7684\u7ed3\u6784\u4e0d\u53d8\u8868\u793a\uff0c\u5e76\u5bfc\u51fa\u7edf\u8ba1\u72ec\u7acb\u7684\u6c34\u5370\u8f7d\u4f53\uff1b2) \u8bbe\u8ba1\u56fe\u611f\u77e5\u7684\u53ef\u9006\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u65e0\u635f\u7684\u6c34\u5370\u5d4c\u5165\u548c\u63d0\u53d6\u901a\u9053\uff1b3) \u5f00\u53d1\u7ed3\u6784\u611f\u77e5\u7f16\u8f91\u5668\u5c06\u6f5c\u5728\u4fee\u6539\u8f6c\u5316\u4e3a\u79bb\u6563\u56fe\u7f16\u8f91\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86DRGW\u7684\u4f18\u8d8a\u6709\u6548\u6027\u3002", "conclusion": "DRGW\u901a\u8fc7\u89e3\u8026\u8868\u793a\u5b66\u4e60\u89e3\u51b3\u4e86\u56fe\u6c34\u5370\u4e2d\u7684\u900f\u660e\u5ea6\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u56fe\u6570\u636e\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2601.13697", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13697", "abs": "https://arxiv.org/abs/2601.13697", "authors": ["Zhihang Yuan", "Chengyu Yue", "Long Huang", "Litu Ou", "Lei Shi"], "title": "Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning", "comment": "Preprint", "summary": "Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.", "AI": {"tldr": "GRADFILTERING\uff1a\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u4fe1\u566a\u6bd4\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6570\u636e\u9009\u62e9\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u6307\u4ee4\u8c03\u4f18", "motivation": "\u73b0\u4ee3\u6307\u4ee4\u6570\u636e\u96c6\u5e9e\u5927\u3001\u5608\u6742\u4e14\u5197\u4f59\uff0c\u5168\u6570\u636e\u5fae\u8c03\u6210\u672c\u9ad8\u4e14\u4e0d\u5fc5\u8981\u3002\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u8981\u4e48\u6784\u5efa\u6602\u8d35\u7684\u68af\u5ea6\u6570\u636e\u5b58\u50a8\uff0c\u8981\u4e48\u4f7f\u7528\u5f31\u4ee3\u7406\u7684\u9759\u6001\u8bc4\u5206\uff0c\u5ffd\u7565\u4e86\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u8fd9\u4e00LLM\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u6765\u6e90\u3002", "method": "\u63d0\u51faGRADFILTERING\u6846\u67b6\uff0c\u4f7f\u7528\u5c0f\u578bGPT-2\u4ee3\u7406\u6a21\u578b\u914d\u5408LoRA\u96c6\u6210\uff0c\u5c06\u6bcf\u4e2a\u6837\u672c\u7684\u68af\u5ea6\u805a\u5408\u6210\u68af\u5ea6\u4fe1\u566a\u6bd4\uff08G-SNR\uff09\u6548\u7528\u6307\u6807\uff0c\u5b9e\u73b0\u76ee\u6807\u65e0\u5173\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u3002", "result": "\u5728\u5927\u591a\u6570LLM-as-a-judge\u8bc4\u4f30\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u968f\u673a\u5b50\u96c6\u548c\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002GRADFILTERING\u9009\u62e9\u7684\u5b50\u96c6\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u6536\u655b\u66f4\u5feb\uff0c\u4f53\u73b0\u4e86\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7684\u4f18\u52bf\u3002", "conclusion": "GRADFILTERING\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u6307\u4ee4\u8c03\u4f18\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.13570", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13570", "abs": "https://arxiv.org/abs/2601.13570", "authors": ["Tingting Dan", "Jiaqi Ding", "Guorong Wu"], "title": "GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds", "comment": "Accepted to NeurIPS 2025", "summary": "State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.", "AI": {"tldr": "GeoDynamics\u662f\u4e00\u4e2a\u51e0\u4f55\u72b6\u6001\u7a7a\u95f4\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u5728\u5bf9\u79f0\u6b63\u5b9a\u6d41\u5f62\u4e0a\u8ffd\u8e2a\u8111\u72b6\u6001\u8f68\u8ff9\uff0c\u7528\u4e8e\u5206\u6790\u529f\u80fd\u8fde\u63a5\u6027\u52a8\u6001\u53d8\u5316\uff0c\u5728\u795e\u7ecf\u79d1\u5b66\u548c\u52a8\u4f5c\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u901a\u5e38\u5c06\u5927\u8111\u89c6\u4e3a\u677e\u6563\u8fde\u63a5\u7684\u533a\u57df\u6216\u65bd\u52a0\u8fc7\u4e8e\u7b80\u5316\u7684\u7f51\u7edc\u5148\u9a8c\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u6574\u4f53\u81ea\u7ec4\u7ec7\u52a8\u6001\u7cfb\u7edf\u89c6\u89d2\u3002\u5927\u8111\u529f\u80fd\u8fde\u63a5\u6027\u77e9\u9635\u4f4d\u4e8e\u9ece\u66fc\u6d41\u5f62\u800c\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u9700\u8981\u51e0\u4f55\u611f\u77e5\u7684\u65b9\u6cd5\u6765\u6355\u6349\u5176\u52a8\u6001\u8f68\u8ff9\u3002", "method": "\u63d0\u51faGeoDynamics\u6a21\u578b\uff0c\u5c06\u6bcf\u4e2a\u8fde\u63a5\u6027\u77e9\u9635\u5d4c\u5165\u5230\u6d41\u5f62\u611f\u77e5\u7684\u5faa\u73af\u6846\u67b6\u4e2d\uff0c\u76f4\u63a5\u5728\u9ad8\u7ef4\u5bf9\u79f0\u6b63\u5b9a\u6d41\u5f62\u4e0a\u5b66\u4e60\u5e73\u6ed1\u4e14\u5c0a\u91cd\u51e0\u4f55\u7684\u8f6c\u6362\uff0c\u63ed\u793a\u4efb\u52a1\u9a71\u52a8\u7684\u72b6\u6001\u53d8\u5316\u548c\u75be\u75c5\u65e9\u671f\u6807\u5fd7\u3002", "result": "\u6a21\u578b\u6210\u529f\u63ed\u793a\u4e86\u4efb\u52a1\u9a71\u52a8\u7684\u8111\u72b6\u6001\u53d8\u5316\uff0c\u4ee5\u53ca\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u3001\u5e15\u91d1\u68ee\u75c5\u548c\u81ea\u95ed\u75c7\u7684\u65e9\u671f\u6807\u5fd7\u3002\u5728\u4eba\u7c7b\u52a8\u4f5c\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\uff08UTKinect\u3001Florence\u3001HDM05\uff09\u4e0a\u4e5f\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "GeoDynamics\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5728\u6d41\u5f62\u4e0a\u76f4\u63a5\u5efa\u6a21\u52a8\u6001\u7cfb\u7edf\u7684\u51e0\u4f55\u611f\u77e5\u6846\u67b6\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u8111\u72b6\u6001\u5206\u6790\uff0c\u8fd8\u80fd\u6269\u5c55\u5230\u5176\u4ed6\u590d\u6742\u65f6\u7a7a\u52a8\u6001\u5efa\u6a21\u9886\u57df\uff0c\u5c55\u793a\u4e86\u8de8\u9886\u57df\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13711", "abs": "https://arxiv.org/abs/2601.13711", "authors": ["Lotta Kiefer", "Christoph Leiter", "Sotaro Takeshita", "Elena Schmidt", "Steffen Eger"], "title": "GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark", "comment": null, "summary": "Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.", "AI": {"tldr": "GerAV\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u57fa\u51c6\uff0c\u5305\u542b\u8d85\u8fc760\u4e07\u6807\u6ce8\u6587\u672c\u5bf9\uff0c\u57fa\u4e8eTwitter\u548cReddit\u6570\u636e\u6784\u5efa\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4f5c\u8005\u9a8c\u8bc1\u4efb\u52a1\u5728\u82f1\u8bed\u9886\u57df\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u4ed6\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u548c\u7cfb\u7edf\u8bc4\u4f30\u4ecd\u7136\u7f3a\u4e4f\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u9886\u57df\u7684\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5fb7\u8bedAV\u7814\u7a76\u63d0\u4f9b\u5168\u9762\u57fa\u51c6\u3002", "method": "\u6784\u5efaGerAV\u57fa\u51c6\uff0c\u5305\u542b\u8d85\u8fc7600k\u6807\u6ce8\u6587\u672c\u5bf9\uff0c\u6570\u636e\u6765\u81eaTwitter\u548cReddit\u3002Reddit\u90e8\u5206\u8fdb\u4e00\u6b65\u5206\u4e3a\uff1a\u9886\u57df\u5185\u6d88\u606f\u5b50\u96c6\u3001\u8de8\u9886\u57df\u6d88\u606f\u5b50\u96c6\u548c\u57fa\u4e8e\u4e2a\u4eba\u8d44\u6599\u5b50\u96c6\u3002\u4f7f\u7528\u63d0\u4f9b\u7684\u8bad\u7ec3\u5206\u5272\u5bf9\u5f3a\u57fa\u7ebf\u6a21\u578b\u548c\u6700\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u65b9\u6cd5\uff08\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u6bd4\u8fd1\u671f\u57fa\u7ebf\u9ad8\u51fa0.09\u7edd\u5bf9F1\u5206\u6570\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u6bd4GPT-5\u9ad8\u51fa0.08\u3002\u89c2\u5bdf\u5230\u4e13\u4e1a\u5316\u4e0e\u6cdb\u5316\u4e4b\u95f4\u7684\u6743\u8861\uff1a\u5728\u5339\u914d\u6761\u4ef6\u4e0b\uff0c\u7279\u5b9a\u6570\u636e\u7c7b\u578b\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u8de8\u6570\u636e\u5236\u5ea6\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u8fd9\u4e00\u9650\u5236\u53ef\u4ee5\u901a\u8fc7\u7ec4\u5408\u8bad\u7ec3\u6e90\u6765\u7f13\u89e3\u3002", "conclusion": "GerAV\u4e3a\u5fb7\u8bed\u548c\u8de8\u9886\u57df\u4f5c\u8005\u9a8c\u8bc1\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u591a\u529f\u80fd\u7684\u57fa\u51c6\uff0c\u80fd\u591f\u652f\u6301\u5bf9\u6570\u636e\u6e90\u3001\u4e3b\u9898\u9886\u57df\u548c\u6587\u672c\u957f\u5ea6\u5f71\u54cd\u7684\u53d7\u63a7\u5206\u6790\u3002"}}
{"id": "2601.13572", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13572", "abs": "https://arxiv.org/abs/2601.13572", "authors": ["Xiangchi Yuan", "Dachuan Shi", "Chunhui Zhang", "Zheyuan Liu", "Shenglong Yao", "Soroush Vosoughi", "Wenke Lee"], "title": "Behavior Knowledge Merge in Reinforced Agentic Models", "comment": null, "summary": "Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.", "AI": {"tldr": "\u63d0\u51faRAM\u6846\u67b6\uff0c\u9488\u5bf9RL\u8bad\u7ec3\u540e\u7684\u667a\u80fd\u4f53\u6a21\u578b\u8fdb\u884c\u4f18\u5316\u5408\u5e76\uff0c\u89e3\u51b3\u4f20\u7edfSFT\u5408\u5e76\u65b9\u6cd5\u5728RL\u667a\u80fd\u4f53\u4e0a\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898", "motivation": "\u6a21\u578b\u5408\u5e76\u662f\u6574\u5408\u591a\u4e2aRL\u8bad\u7ec3\u667a\u80fd\u4f53\u7684\u5b9e\u7528\u673a\u5236\uff0c\u4f46\u73b0\u6709\u5408\u5e76\u65b9\u6cd5\u9488\u5bf9\u76d1\u7763\u5fae\u8c03\u8bbe\u8ba1\uff0c\u4e0d\u9002\u7528\u4e8eRL\u8bad\u7ec3\u540e\u7684\u667a\u80fd\u4f53\u6a21\u578b\u3002RL\u4ea7\u751f\u7684\u4efb\u52a1\u5411\u91cf\u7a00\u758f\u4e14\u5f02\u8d28\uff0c\u4e0eSFT\u5047\u8bbe\u7684\u5bc6\u96c6\u53ef\u6bd4\u5411\u91cf\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u5173\u952e\u4efb\u52a1\u7279\u5b9a\u884c\u4e3a\u88ab\u7a00\u91ca", "method": "\u63d0\u51faRAM\u6846\u67b6\uff0c\u663e\u5f0f\u5206\u79bb\u5171\u4eab\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u53c2\u6570\u66f4\u65b0\uff1a\u5bf9\u5171\u4eab\u7ec4\u4ef6\u8fdb\u884c\u5e73\u5747\uff0c\u540c\u65f6\u9009\u62e9\u6027\u5730\u4fdd\u7559\u548c\u91cd\u65b0\u7f29\u653e\u72ec\u7279\u7ec4\u4ef6\uff0c\u4ee5\u62b5\u6d88\u53c2\u6570\u66f4\u65b0\u7a00\u91ca", "result": "\u5728\u591a\u4e2a\u667a\u80fd\u4f53\u9886\u57df\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRAM\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u5408\u5e76\u57fa\u7ebf\uff0c\u8fd8\u80fd\u89e3\u9501\u667a\u80fd\u4f53\u95f4\u7684\u534f\u540c\u6f5c\u529b\uff0c\u5b9e\u73b0\u4f18\u4e8e\u9886\u57df\u5185\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u6027\u80fd", "conclusion": "RAM\u662f\u9488\u5bf9RL\u8bad\u7ec3\u667a\u80fd\u4f53\u6a21\u578b\u7684\u6709\u6548\u5408\u5e76\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4efb\u52a1\u5411\u91cf\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u80fd\u591f\u66f4\u597d\u5730\u4fdd\u7559\u4efb\u52a1\u7279\u5b9a\u80fd\u529b\u5e76\u5b9e\u73b0\u534f\u540c\u6548\u5e94"}}
{"id": "2601.13717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13717", "abs": "https://arxiv.org/abs/2601.13717", "authors": ["Zehan Li", "Yuxuan Wang", "Ali El Lahib", "Ying-Jieh Xia", "Xinyu Pi"], "title": "Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff", "comment": null, "summary": "Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably \"rewind\" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.", "AI": {"tldr": "\u6a21\u62df\u65e0\u77e5\u65b9\u6cd5\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30LLM\u9884\u6d4b\u80fd\u529b\uff0c\u56e0\u4e3a\u63d0\u793a\u65e0\u6cd5\u6709\u6548\"\u5012\u5e26\"\u6a21\u578b\u77e5\u8bc6\uff0c\u5efa\u8bae\u907f\u514d\u4f7f\u7528\u57fa\u4e8e\u6a21\u62df\u65e0\u77e5\u7684\u56de\u987e\u6027\u9884\u6d4b\u6765\u8bc4\u4f30\u9884\u6d4b\u80fd\u529b", "motivation": "\u8bc4\u4f30LLM\u9884\u6d4b\u80fd\u529b\u9762\u4e34\u4e24\u96be\uff1a\u524d\u77bb\u6027\u8bc4\u4f30\u65b9\u6cd5\u4e25\u8c28\u4f46\u5ef6\u8fdf\u9ad8\uff0c\u56de\u987e\u6027\u9884\u6d4b\u9762\u4e34\u6570\u636e\u6c61\u67d3\u95ee\u9898\u3002\u6a21\u62df\u65e0\u77e5\u65b9\u6cd5\u88ab\u63d0\u51fa\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u662f\u5426\u80fd\u771f\u6b63\u6a21\u62df\u771f\u5b9e\u65e0\u77e5\u72b6\u6001", "method": "\u901a\u8fc7477\u4e2a\u7ade\u8d5b\u7ea7\u95ee\u9898\u548c9\u4e2a\u6a21\u578b\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u6a21\u62df\u65e0\u77e5\u662f\u5426\u80fd\u8fd1\u4f3c\u771f\u5b9e\u65e0\u77e5\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u60c5\u51b5\uff1a\u622a\u6b62\u6307\u4ee4\u6548\u679c\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u662f\u5426\u6291\u5236\u5148\u9a8c\u77e5\u8bc6\u3001\u63a8\u7406\u4f18\u5316\u6a21\u578b\u7684\u65e0\u77e5\u4fdd\u771f\u5ea6", "result": "\u6a21\u62df\u65e0\u77e5\u7cfb\u7edf\u6027\u5931\u8d25\uff1a1) \u622a\u6b62\u6307\u4ee4\u5bfc\u81f4SI\u4e0eTI\u5b58\u572852%\u6027\u80fd\u5dee\u8ddd\uff1b2) \u601d\u7ef4\u94fe\u63a8\u7406\u65e0\u6cd5\u6291\u5236\u5148\u9a8c\u77e5\u8bc6\uff0c\u5373\u4f7f\u63a8\u7406\u75d5\u8ff9\u4e0d\u542b\u660e\u786e\u622a\u6b62\u540e\u4fe1\u606f\uff1b3) \u63a8\u7406\u4f18\u5316\u6a21\u578b\u7684SI\u4fdd\u771f\u5ea6\u66f4\u5dee\uff0c\u5c3d\u7ba1\u63a8\u7406\u75d5\u8ff9\u8d28\u91cf\u66f4\u9ad8", "conclusion": "\u63d0\u793a\u65e0\u6cd5\u53ef\u9760\"\u5012\u5e26\"\u6a21\u578b\u77e5\u8bc6\uff0c\u57fa\u4e8e\u622a\u6b62\u524d\u4e8b\u4ef6\u7684\u56de\u987e\u6027\u9884\u6d4b\u5b58\u5728\u65b9\u6cd5\u8bba\u7f3a\u9677\u3002\u5efa\u8bae\u4e0d\u8981\u4f7f\u7528\u57fa\u4e8e\u6a21\u62df\u65e0\u77e5\u7684\u56de\u987e\u6027\u8bbe\u7f6e\u6765\u8bc4\u4f30\u9884\u6d4b\u80fd\u529b"}}
{"id": "2601.13578", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13578", "abs": "https://arxiv.org/abs/2601.13578", "authors": ["Qian Feng", "JiaHang Tu", "Mintong Kang", "Hanbin Zhao", "Chao Zhang", "Hui Qian"], "title": "FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning", "comment": "This paper has been accepted by ICCV 2025. code: \\url{https://github.com/RAIAN08/FG-OrIU}", "summary": "Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \\textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\\textbf{F}eature-\\textbf{G}radient \\textbf{Or}thogonality for \\textbf{I}ncremental \\textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.", "AI": {"tldr": "\u63d0\u51faFG-OrIU\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u548c\u68af\u5ea6\u7684\u53cc\u91cd\u6b63\u4ea4\u7ea6\u675f\u5b9e\u73b0\u6df1\u5ea6\u9057\u5fd8\uff0c\u89e3\u51b3\u589e\u91cf\u9057\u5fd8\u4e2d\u7684\u8868\u9762\u9057\u5fd8\u95ee\u9898", "motivation": "\u73b0\u6709\u589e\u91cf\u9057\u5fd8\u65b9\u6cd5\u4e3b\u8981\u5728\u53c2\u6570\u5c42\u9762\u6291\u5236\u6216\u6df7\u6dc6\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u5bf9\u7279\u5f81\u548c\u68af\u5ea6\u5c42\u9762\u7684\u663e\u5f0f\u7ea6\u675f\uff0c\u5bfc\u81f4\"\u8868\u9762\u9057\u5fd8\"\u2014\u2014\u6b8b\u7559\u4fe1\u606f\u4ecd\u53ef\u6062\u590d\u3002\u8fd9\u79cd\u4e0d\u5b8c\u5168\u9057\u5fd8\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u7834\u574f\u4fdd\u7559\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u589e\u91cf\u9057\u5fd8\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51faFG-OrIU\u6846\u67b6\uff1a1) \u4f7f\u7528SVD\u5206\u89e3\u7279\u5f81\u7a7a\u95f4\uff0c\u5c06\u9057\u5fd8\u7c7b\u548c\u4fdd\u7559\u7c7b\u7279\u5f81\u5206\u79bb\u5230\u4e0d\u540c\u5b50\u7a7a\u95f4\uff1b2) \u5b9e\u65bd\u53cc\u91cd\u7ea6\u675f\uff1a\u7279\u5f81\u6b63\u4ea4\u6295\u5f71\uff08\u9057\u5fd8\u7c7b\u548c\u4fdd\u7559\u7c7b\uff09\u548c\u68af\u5ea6\u6b63\u4ea4\u6295\u5f71\uff08\u9632\u6b62\u9057\u5fd8\u77e5\u8bc6\u91cd\u65b0\u5f15\u5165\uff09\uff1b3) \u52a8\u6001\u5b50\u7a7a\u95f4\u9002\u5e94\uff1a\u5408\u5e76\u65b0\u9057\u5fd8\u5b50\u7a7a\u95f4\u5e76\u6536\u7f29\u4fdd\u7559\u5b50\u7a7a\u95f4\uff0c\u4fdd\u6301\u5e8f\u5217\u9057\u5fd8\u4efb\u52a1\u4e2d\u7684\u7a33\u5b9a\u5e73\u8861\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u6df1\u5ea6\u9057\u5fd8\uff08\u9057\u5fd8\u6548\u679c\u4e0d\u53ef\u9006\uff09\u3002", "conclusion": "FG-OrIU\u901a\u8fc7\u7edf\u4e00\u7279\u5f81\u548c\u68af\u5ea6\u5c42\u9762\u7684\u6b63\u4ea4\u7ea6\u675f\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u6df1\u5ea6\u9057\u5fd8\uff0c\u89e3\u51b3\u4e86\u589e\u91cf\u9057\u5fd8\u4e2d\u7684\u8868\u9762\u9057\u5fd8\u95ee\u9898\uff0c\u786e\u4fdd\u4e86\u9057\u5fd8\u7684\u4e0d\u53ef\u9006\u6027\u548c\u4fdd\u7559\u5e73\u8861\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.13722", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13722", "abs": "https://arxiv.org/abs/2601.13722", "authors": ["Yulin Hu", "Zimo Long", "Jiahe Guo", "Xingyu Sui", "Xing Fu", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents", "comment": null, "summary": "Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \\emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \\textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \\textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \\textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.", "AI": {"tldr": "\u63d0\u51faOP-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5bf9\u8bdd\u4ee3\u7406\u7684\u8fc7\u5ea6\u4e2a\u6027\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1Self-ReCheck\u65b9\u6cd5\u8fdb\u884c\u7f13\u89e3", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u589e\u5f3a\u5bf9\u8bdd\u4ee3\u7406\u4e3b\u8981\u5173\u6ce8\u80fd\u5426\u56de\u5fc6\u548c\u5e94\u7528\u7528\u6237\u4fe1\u606f\uff0c\u4f46\u5ffd\u89c6\u4e86\u662f\u5426\u6070\u5f53\u4f7f\u7528\u4e2a\u6027\u5316\u3002\u8fc7\u5ea6\u4f7f\u7528\u4e2a\u4eba\u4fe1\u606f\u4f1a\u5bfc\u81f4\u56de\u5e94\u663e\u5f97\u751f\u786c\u3001\u4fb5\u5165\u6027\u5f3a\u6216\u793e\u4ea4\u4e0d\u5f53\uff0c\u5373\"\u8fc7\u5ea6\u4e2a\u6027\u5316\"\u95ee\u9898\u3002", "method": "1. \u5c06\u8fc7\u5ea6\u4e2a\u6027\u5316\u5f62\u5f0f\u5316\u4e3a\u4e09\u79cd\u7c7b\u578b\uff1a\u65e0\u5173\u6027\u3001\u91cd\u590d\u6027\u548c\u8c04\u5a9a\u6027\uff1b2. \u6784\u5efaOP-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1700\u4e2a\u9a8c\u8bc1\u5b9e\u4f8b\uff1b3. \u63d0\u51faSelf-ReCheck\u65b9\u6cd5\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u8bb0\u5fc6\u8fc7\u6ee4\u673a\u5236\u3002", "result": "\u8bc4\u4f30\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u53d1\u73b0\u5f15\u5165\u8bb0\u5fc6\u540e\u8fc7\u5ea6\u4e2a\u6027\u5316\u95ee\u9898\u666e\u904d\u5b58\u5728\u3002\u5206\u6790\u663e\u793a\u4ee3\u7406\u503e\u5411\u4e8e\u68c0\u7d22\u548c\u8fc7\u5ea6\u5173\u6ce8\u7528\u6237\u8bb0\u5fc6\uff0c\u5373\u4f7f\u5728\u4e0d\u5fc5\u8981\u65f6\u3002Self-ReCheck\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u5ea6\u4e2a\u6027\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u4e2a\u6027\u5316\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8bb0\u5fc6\u589e\u5f3a\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u66f4\u53ef\u63a7\u548c\u6070\u5f53\u7684\u4e2a\u6027\u5316\u8fc8\u51fa\u4e86\u521d\u6b65\u6b65\u9aa4\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u57fa\u51c6\u548c\u7f13\u89e3\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u4e2a\u6027\u5316\u5bf9\u8bdd\u4ee3\u7406\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.13580", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13580", "abs": "https://arxiv.org/abs/2601.13580", "authors": ["Ahmad Al-Zuraiqi"], "title": "Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models", "comment": "27 pages, 8 figures, 16 tables. Decoder-only transformers (124M-20B parameters). Complete experimental results and reproducibility details in appendices. Code and checkpoints: https://github.com/zuraiqi/neural-organ-transplant", "summary": "We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets (\"donor organs\") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.", "AI": {"tldr": "Neural Organ Transplantation (NOT) \u662f\u4e00\u79cd\u6a21\u5757\u5316\u9002\u5e94\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3transformer\u5c42\u4f5c\u4e3a\u53ef\u91cd\u7528\u68c0\u67e5\u70b9\u8fdb\u884c\u8de8\u6a21\u578b\u79fb\u690d\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9002\u5e94\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u5c06\u8bad\u7ec3\u53c2\u6570\u4e0e\u7279\u5b9a\u6a21\u578b\u5b9e\u4f8b\u548c\u8bad\u7ec3\u6570\u636e\u7d27\u5bc6\u8026\u5408\uff0c\u7f3a\u4e4f\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\u3002NOT\u65e8\u5728\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u4e13\u5bb6\u77e5\u8bc6\u5171\u4eab\uff0c\u901a\u8fc7\u68c0\u67e5\u70b9\u5206\u53d1\u5b9e\u73b0\u9ad8\u6548\u6a21\u5757\u5316\u8fc1\u79fb", "method": "\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u63d0\u53d6\u8fde\u7eed\u5c42\u5b50\u96c6\uff08\"\u4f9b\u4f53\u5668\u5b98\"\uff09\uff0c\u5728\u9886\u57df\u7279\u5b9a\u6570\u636e\u4e0a\u72ec\u7acb\u8bad\u7ec3\uff0c\u4fdd\u5b58\u4e3a\u72ec\u7acb\u68c0\u67e5\u70b9\u6587\u4ef6\uff0c\u7136\u540e\u79fb\u690d\u5230\u517c\u5bb9\u7684\u63a5\u6536\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u539f\u59cb\u8bad\u7ec3\u6570\u636e", "result": "\u5728124M\u523020B\u53c2\u6570\u7684\u4e09\u79cd\u89e3\u7801\u5668\u67b6\u6784\uff08GPT-2\u3001TinyLlama\u3001GPT-OSS\uff09\u4e0a\uff0cNOT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9002\u5e94\u65b9\u6cd5\uff0c\u56f0\u60d1\u5ea6\u6bd4LoRA\u63d0\u9ad8\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002\u65e9\u671f\u63d2\u5165\u4f4d\u7f6e\u6548\u679c\u6700\u4f73\uff0c\u8de8\u9886\u57df\u8fc1\u79fb\u5728\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u663e\u793a\u51fa\u610f\u5916\u7684\u6b63\u5219\u5316\u6548\u76ca", "conclusion": "transformer\u4e2d\u95f4\u5c42\u652f\u6301\u89e3\u7801\u5668\u67b6\u6784\u7684\u9ad8\u6548\u6a21\u5757\u5316\u8fc1\u79fb\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u4e13\u5bb6\u77e5\u8bc6\u5171\u4eab\u3002\u8be5\u65b9\u6cd5\u76ee\u524d\u4ec5\u9650\u4e8e\u89e3\u7801\u5668\u6a21\u578b\uff0c\u7f16\u7801\u5668\u67b6\u6784\u6548\u679c\u6709\u9650"}}
{"id": "2601.13729", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13729", "abs": "https://arxiv.org/abs/2601.13729", "authors": ["Weichuan Wang", "Mingyang Liu", "Linqi Song", "Chen Ma"], "title": "On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation", "comment": "9 pages, 12 figures", "summary": "In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u975e\u786e\u5b9a\u6027\u73b0\u8c61\uff0c\u53d1\u73b0\u6e29\u5ea6\u7ea6\u675f\u4e0b\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u80fd\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u5019\u9009\u7ffb\u8bd1\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u5bf9\u5176\u4e0d\u9002\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u7b56\u7565\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u7684\u975e\u786e\u5b9a\u6027\u7279\u6027\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5f71\u54cd\u663e\u8457\uff0c\u4f46\u5728\u673a\u5668\u7ffb\u8bd1\u8fd9\u4e00\u590d\u6742\u975e\u786e\u5b9a\u6027\u4efb\u52a1\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u673a\u5668\u7ffb\u8bd1\u957f\u671f\u9762\u4e34\u591a\u6a21\u6001\u95ee\u9898\u7684\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7684\u6f5c\u529b\u53ca\u5176\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u73b0\u4ee3\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u8bc6\u522b\u6e29\u5ea6\u7ea6\u675f\u4e0b\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u73b0\u8c61\u3002\u4f7f\u7528\u4e09\u4e2a\u5f00\u653e\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8bcd\u6c47\u548c\u8bed\u4e49\u6307\u6807\u5728\u4e0d\u540c\u91c7\u6837\u89c4\u6a21\u4e0b\u8bc4\u4f30\u4e94\u4e2a\u6700\u5148\u8fdb\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u5e76\u63d0\u51faExpectoSample\u7b56\u7565\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u53ef\u9760\u6027\u3002", "result": "\u53d1\u73b0\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u5728\u6e29\u5ea6\u7ea6\u675f\u4e0b\u80fd\u63d0\u4f9b\u6bd4\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u66f4\u9ad8\u8d28\u91cf\u7684\u5019\u9009\u7ffb\u8bd1\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5b58\u5728\"\u6c34\u6876\u6548\u5e94\"\uff1a\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u751f\u6210\u7684\u6700\u4f4e\u8d28\u91cf\u5019\u9009\u7ffb\u8bd1\u51b3\u5b9a\u4e86\u7cfb\u7edf\u5728\u4e0d\u540c\u91c7\u6837\u89c4\u6a21\u4e0b\u7684\u6574\u4f53\u6392\u540d\u3002\u63d0\u51fa\u7684ExpectoSample\u7b56\u7565\u80fd\u6709\u6548\u8bc4\u4f30\u6307\u6807\u53ef\u9760\u6027\u3002", "conclusion": "\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u5728\u89e3\u51b3\u673a\u5668\u7ffb\u8bd1\u591a\u6a21\u6001\u95ee\u9898\u65b9\u9762\u5177\u6709\u91cd\u8981\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u73b0\u6709\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u8bc4\u4f30\u7b56\u7565\u6765\u53ef\u9760\u5730\u9009\u62e9\u548c\u8bc4\u4f30\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u3002"}}
{"id": "2601.13592", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13592", "abs": "https://arxiv.org/abs/2601.13592", "authors": ["Hao Jing", "Sa Xiao", "Haoyu Li", "Huadong Xiao", "Wei Xue"], "title": "Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments", "comment": null, "summary": "Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.", "AI": {"tldr": "\u4f7f\u7528\u6b8b\u5dee\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u4f20\u7edf\u8f90\u5c04\u4f20\u8f93\u6a21\u578b\uff0c\u5728CMA\u5168\u7403\u4e1a\u52a1\u7cfb\u7edf\u4e2d\u5b9e\u73b08\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u62a5\u7cbe\u5ea6", "motivation": "\u8f90\u5c04\u8fc7\u7a0b\u662f\u6570\u503c\u6a21\u5f0f\u4e2d\u6700\u8017\u65f6\u7684\u7269\u7406\u8fc7\u7a0b\uff0c\u9700\u8981\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002\u7814\u7a76\u91cd\u70b9\u5173\u6ce8\u6df7\u5408\u9884\u62a5\u6846\u67b6\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u74f6\u9888\uff1a\u8026\u5408\u517c\u5bb9\u6027\u548c\u957f\u671f\u79ef\u5206\u7a33\u5b9a\u6027", "method": "\u91c7\u7528\u6b8b\u5dee\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3cRRTMG\u8f90\u5c04\u4f20\u8f93\u6a21\u578b\uff0c\u4f7f\u7528\u79bb\u7ebf\u8bad\u7ec3\u548c\u5728\u7ebf\u8026\u5408\u65b9\u6cd5\u3002\u901a\u8fc7\u6a21\u578b\u6a21\u62df\u751f\u6210\u5305\u542b\u6240\u6709\u5927\u6c14\u67f1\u7684\u5168\u9762\u6570\u636e\u96c6\uff0c\u91c7\u7528\u7ecf\u9a8c\u56de\u653e\u589e\u5f3a\u6570\u636e\u7a33\u5b9a\u6027\uff0c\u5e76\u57fa\u4e8e\u7269\u7406\u610f\u4e49\u65bd\u52a0\u989d\u5916\u8f93\u51fa\u7ea6\u675f\u3002\u4f7f\u7528\u57fa\u4e8eLibTorch\u7684\u8026\u5408\u65b9\u6cd5\u8fdb\u884c\u5b9e\u65f6\u4e1a\u52a1\u8ba1\u7b97", "result": "\u6df7\u5408\u6a21\u578b\u80fd\u591f\u6309\u8981\u6c42\u8fdb\u884c10\u5929\u79ef\u5206\u9884\u62a5\u3002\u4e24\u4e2a\u6708\u7684\u4e1a\u52a1\u518d\u9884\u62a5\u5b9e\u9a8c\u8868\u660e\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u62df\u5668\u8fbe\u5230\u4e0e\u4f20\u7edf\u7269\u7406\u65b9\u6848\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u8ba1\u7b97\u901f\u5ea6\u63d0\u5347\u7ea68\u500d", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u4e1a\u52a1\u7cfb\u7edf\u7684\u673a\u5668\u5b66\u4e60\u8f90\u5c04\u53c2\u6570\u5316\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9884\u62a5\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u6df7\u5408\u9884\u62a5\u6846\u67b6\u4e2d\u7684\u8026\u5408\u517c\u5bb9\u6027\u548c\u957f\u671f\u7a33\u5b9a\u6027\u95ee\u9898"}}
{"id": "2601.13734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13734", "abs": "https://arxiv.org/abs/2601.13734", "authors": ["Chenyu Hui"], "title": "Towards robust long-context understanding of large language model via active recap learning", "comment": "5 pages", "summary": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM", "AI": {"tldr": "ARL\u901a\u8fc7\u4e3b\u52a8\u56de\u987e\u5b66\u4e60\u589e\u5f3aLLM\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\uff0c\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u6784\u5efa\u76ee\u6807\u5e8f\u5217\uff0c\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u56de\u987e\u6027\u603b\u7ed3\uff0c\u5b9e\u73b0\u9012\u5f52\u8bb0\u5fc6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u957f\u6587\u672c\u7406\u89e3\u6027\u80fd", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u7406\u89e3\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u589e\u5f3a\u6a21\u578b\u5bf9\u957f\u6587\u672c\u7684\u8bb0\u5fc6\u548c\u7406\u89e3\u80fd\u529b", "method": "1) \u57fa\u4e8e\u957f\u77ed\u4e0a\u4e0b\u6587\u635f\u5931\u5dee\u5f02\u8bc6\u522b\u5173\u952etoken\u5e76\u627e\u5230\u76f8\u5173\u524d\u6587\u6bb5\u843d\uff0c\u7528LLM\u8fdb\u884c\u603b\u7ed3\uff1b2) \u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u6784\u5efa\u76ee\u6807\u5e8f\u5217\uff0c\u5728\u63a8\u7406\u65f6\u8ba9\u6a21\u578b\u81ea\u4e3b\u751f\u6210\u548c\u5229\u7528\u56de\u987e\u6027\u603b\u7ed3\uff0c\u5efa\u7acb\u8de8\u6bb5\u843d\u7684\u9012\u5f52\u8bb0\u5fc6\u673a\u5236", "result": "ARL\u5728RULER\u57fa\u51c6\u4e0a\u63d0\u534726.8%\uff0c\u5728LongBench\u4e0a\u63d0\u53479.44%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b", "conclusion": "ARL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u56de\u987e\u5b66\u4e60\u548c\u9012\u5f52\u8bb0\u5fc6\u673a\u5236\u589e\u5f3aLLM\u7684\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u53ef\u6269\u5c55\u8bb0\u5fc6\u589e\u5f3a\u6280\u672f\u7684\u53d1\u5c55"}}
{"id": "2601.13599", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13599", "abs": "https://arxiv.org/abs/2601.13599", "authors": ["Linrui Ma", "Yufei Cui", "Kai Han", "Yunhe Wang"], "title": "Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models", "comment": "Work In Progress", "summary": "Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.", "AI": {"tldr": "\u63d0\u51faDiffusion in Diffusion\u6846\u67b6\uff0c\u901a\u8fc7\"\u8349\u7a3f-\u7cbe\u4fee\"\u4e24\u9636\u6bb5\u89e3\u51b3\u5757\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u53ef\u9006\u6027\u548c\u77ed\u89c6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u5757\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u4e86\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u4f46\u5176\u4e25\u683c\u7684\u5355\u5411\u5757\u4f9d\u8d56\u5bfc\u81f4\u4e0d\u53ef\u9006\u6027\uff0c\u5e76\u727a\u7272\u4e86\u6269\u6563\u6a21\u578b\u7684\u5168\u5c40\u89c4\u5212\u80fd\u529b\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faDiffusion in Diffusion\u6846\u67b6\uff1a1) \u5148\u7528\u5c0f\u5757\u8fdb\u884c\u5757\u6269\u6563\u751f\u6210\u5feb\u901f\u8349\u7a3f\uff1b2) \u518d\u7528\u5177\u6709\u66f4\u5927\u53cc\u5411\u611f\u53d7\u91ce\u7684\u5168\u5c40\u53cc\u5411\u6269\u6563\u7cbe\u4fee\u8349\u7a3f\uff1b3) \u4f7f\u7528\u5feb\u7167\u7f6e\u4fe1\u5ea6\u91cd\u63a9\u7801\u8bc6\u522b\u9700\u8981\u4fee\u6539\u7684\u5173\u952etoken\uff1b4) \u5e94\u7528\u6df7\u5408\u5c3a\u5ea6\u8bad\u7ec3\u6269\u5c55\u5757\u6269\u6563\u6a21\u578b\u7684\u5168\u5c40\u80fd\u529b", "result": "\u5728OpenWebText\u6570\u636e\u96c6\u4e0a\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\uff1a\u4ec5\u4f7f\u7528\u57fa\u7ebf\u6a21\u578b26%\u7684\u5fae\u8c03\u9884\u7b97\uff0c\u5c06\u751f\u6210\u56f0\u60d1\u5ea6\u4ece25.7\u964d\u81f321.9\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd", "conclusion": "Diffusion in Diffusion\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5757\u6269\u6563\u6a21\u578b\u7684\u4e0d\u53ef\u9006\u6027\u548c\u77ed\u89c6\u95ee\u9898\uff0c\u901a\u8fc7\u8349\u7a3f-\u7cbe\u4fee\u4e24\u9636\u6bb5\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2601.13742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13742", "abs": "https://arxiv.org/abs/2601.13742", "authors": ["Arjun Chandra", "Kevin Miller", "Venkatesh Ravichandran", "Constantinos Papayiannis", "Venkatesh Saligrama"], "title": "Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues", "comment": "EACL 2026 Findings", "summary": "Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.", "AI": {"tldr": "TRACE\u6846\u67b6\u8ba9LLM\u80fd\u57fa\u4e8e\u97f3\u9891\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\uff0c\u8d85\u8d8a\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u548c\u7eaf\u6587\u672cLLM\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u900f\u660e\u4e14\u6602\u8d35\u7684\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u5177\u6709\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ea\u80fd\u5904\u7406\u6587\u672c\u5185\u5bb9\uff0c\u65e0\u6cd5\u76f4\u63a5\u8bc4\u4f30\u97f3\u9891\u8d28\u91cf\u3002", "method": "\u63d0\u51faTRACE\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u4eba\u7c7b\u601d\u7ef4\u94fe\u6807\u6ce8\u534f\u8bae\uff0c\u5c06\u8bc4\u4f30\u5206\u4e3a\u5185\u5bb9\u3001\u8bed\u97f3\u8d28\u91cf\u548c\u526f\u8bed\u8a00\u4e09\u4e2a\u7ef4\u5ea6\uff1b2\uff09\u6784\u5efa\u97f3\u9891\u4fe1\u53f7\u7684\u6587\u672c\u84dd\u56fe\uff1b3\uff09\u8ba9LLM\u8fdb\u884c\u7ef4\u5ea6\u5224\u65ad\uff1b4\uff09\u901a\u8fc7\u786e\u5b9a\u6027\u7b56\u7565\u878d\u5408\u4e3a\u603b\u4f53\u8bc4\u5206\u3002", "result": "TRACE\u4e0e\u4eba\u7c7b\u8bc4\u5206\u8005\u7684\u4e00\u81f4\u6027\u9ad8\u4e8e\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u548c\u7eaf\u6587\u672cLLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u540c\u65f6\u6210\u672c\u6548\u76ca\u663e\u8457\u66f4\u9ad8\u3002", "conclusion": "TRACE\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4f30\uff0c\u5c06\u53d1\u5e03\u4eba\u7c7b\u601d\u7ef4\u94fe\u6807\u6ce8\u548cTRACE\u6846\u67b6\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2601.13608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13608", "abs": "https://arxiv.org/abs/2601.13608", "authors": ["Zhipeng Chang", "Ting He", "Wenrui Hao"], "title": "Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data", "comment": null, "summary": "Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.", "AI": {"tldr": "FIPA\uff1a\u4e00\u79cd\u57fa\u4e8e\u8d39\u820d\u5c14\u4fe1\u606f\u7684\u53c2\u6570\u7ea7\u805a\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u7279\u5b9a\u7684\u6743\u91cd\u66ff\u6362\u5ba2\u6237\u7aef\u7ea7\u6807\u91cf\u6743\u91cd\uff0c\u6539\u5584\u975eIID\u6570\u636e\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u6027\u80fd", "motivation": "\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982FedAvg\uff09\u5bf9\u6240\u6709\u53c2\u6570\u4f7f\u7528\u76f8\u540c\u7684\u6807\u91cf\u6743\u91cd\uff0c\u5728\u975eIID\u6570\u636e\u4e0b\u4f1a\u5bfc\u81f4\u5ba2\u6237\u7aef\u66f4\u65b0\u4e25\u91cd\u9519\u4f4d\uff0c\u5f15\u8d77\u5ba2\u6237\u7aef\u6f02\u79fb\u5e76\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u6027\u80fd", "method": "\u63d0\u51fa\u8d39\u820d\u5c14\u4fe1\u606f\u53c2\u6570\u7ea7\u805a\u5408\uff08FIPA\uff09\uff0c\u4f7f\u7528\u8d39\u820d\u5c14\u4fe1\u606f\u77e9\u9635\uff08FIM\uff09\u6743\u91cd\u66ff\u6362\u5ba2\u6237\u7aef\u7ea7\u6807\u91cf\u6743\u91cd\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u53c2\u6570\u7ea7\u7f29\u653e\uff0c\u6355\u6349\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6570\u636e\u5bf9\u4e0d\u540c\u53c2\u6570\u7684\u72ec\u7279\u5f71\u54cd\u3002\u901a\u8fc7\u4f4e\u79e9\u8fd1\u4f3c\u4fdd\u6301\u901a\u4fe1\u548c\u8ba1\u7b97\u6548\u7387", "result": "\u5728\u975e\u7ebf\u6027\u51fd\u6570\u56de\u5f52\u3001\u504f\u5fae\u5206\u65b9\u7a0b\u5b66\u4e60\u548c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cFIPA\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u5e73\u5747\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u5e76\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u5ba2\u6237\u7aef\u4f18\u5316\u7b97\u6cd5\u6709\u6548\u7ed3\u5408\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u56fe\u50cf\u5206\u7c7b\u51c6\u786e\u7387", "conclusion": "FIPA\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u4e3a\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u663e\u8457\u4f18\u52bf\uff0c\u5c55\u793a\u4e86\u53c2\u6570\u7ea7\u805a\u5408\u7684\u91cd\u8981\u6027"}}
{"id": "2601.13645", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13645", "abs": "https://arxiv.org/abs/2601.13645", "authors": ["Euijin You", "Hyang-Won Lee"], "title": "Quadratic Upper Bound for Boosting Robustness", "comment": "Accepted at ICML 2025. Published in PMLR 267:72656-72676", "summary": "Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4e8c\u6b21\u4e0a\u754c\u635f\u5931\u51fd\u6570\u6765\u6539\u5584\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u4e2d\u7684\u9c81\u68d2\u6027\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u63d0\u5347\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u867d\u7136\u80fd\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u4f46\u5f80\u5f80\u56e0\u5bf9\u6297\u7a7a\u95f4\u63a2\u7d22\u4e0d\u8db3\u800c\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0b\u964d\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u95ee\u9898\u3002", "method": "\u63a8\u5bfc\u51fa\u5bf9\u6297\u8bad\u7ec3\u635f\u5931\u51fd\u6570\u7684\u4e8c\u6b21\u4e0a\u754c\uff0c\u5e76\u5c06\u8be5\u4e0a\u754c\u4e0e\u73b0\u6709\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u5f62\u6210QUB\u635f\u5931\u51fd\u6570\u3002", "result": "\u5c06QUB\u635f\u5931\u5e94\u7528\u4e8e\u73b0\u6709\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u6539\u8fdb\u6e90\u4e8e\u6240\u5f97\u6a21\u578b\u7684\u635f\u5931\u666f\u89c2\u53d8\u5f97\u66f4\u52a0\u5e73\u6ed1\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e8c\u6b21\u4e0a\u754c\u635f\u5931\u51fd\u6570\u6709\u6548\u89e3\u51b3\u4e86\u5feb\u901f\u5bf9\u6297\u8bad\u7ec3\u4e2d\u7684\u9c81\u68d2\u6027\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.13802", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.13802", "abs": "https://arxiv.org/abs/2601.13802", "authors": ["Yushen Chen", "Junzhe Liu", "Yujie Tu", "Zhikang Niu", "Yuzhe Liang", "Kai Yu", "Chunyu Qiang", "Chen Zhang", "Xie Chen"], "title": "Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis", "comment": null, "summary": "A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .", "AI": {"tldr": "Habibi\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7684\u7edf\u4e00\u6a21\u578b\u5957\u4ef6\uff0c\u5229\u7528\u73b0\u6709ASR\u8bed\u6599\u5e93\u652f\u6301\u591a\u79cd\u65b9\u8a00\uff0c\u65e0\u9700\u6587\u672c\u6807\u6ce8\uff0c\u6027\u80fd\u4f18\u4e8e\u5546\u4e1a\u670d\u52a1", "motivation": "\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7814\u7a76\u5b58\u5728\u660e\u663e\u7a7a\u767d\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u6570\u636e\u3001\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u5357\uff0c\u4e14\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u5177\u6709\u590d\u6742\u7684\u8bed\u8a00\u7279\u6027\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u5f00\u5c55\u76f8\u5173\u5de5\u4f5c", "method": "\u5229\u7528\u73b0\u6709\u5f00\u6e90ASR\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u8bed\u8a00\u611f\u77e5\u7684\u8bfe\u7a0b\u5b66\u4e60\u652f\u6301\u4ece\u9ad8\u8d44\u6e90\u5230\u4f4e\u8d44\u6e90\u7684\u591a\u79cd\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\uff0c\u91c7\u7528\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u4fdd\u6301\u53ef\u6269\u5c55\u6027\uff0c\u65e0\u9700\u6587\u672c\u6807\u6ce8", "result": "Habibi\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u4f18\u4e8e\u9886\u5148\u7684\u5546\u4e1a\u670d\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6269\u5c55\u6027\uff0c\u5c06\u5f00\u6e90\u6a21\u578b\u5e76\u521b\u5efa\u9996\u4e2a\u591a\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u5408\u6210\u7684\u7cfb\u7edf\u57fa\u51c6", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u5efa\u7acb\u8bc4\u4f30\u6807\u51c6\u548c\u63d0\u4f9b\u7cfb\u7edf\u57fa\u51c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u627f\u8bfa\u5f00\u6e90\u6a21\u578b\u4ee5\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55"}}
{"id": "2601.13653", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13653", "abs": "https://arxiv.org/abs/2601.13653", "authors": ["Xingjian Wu", "Junkai Lu", "Zhengyu Li", "Xiangfei Qiu", "Jilin Hu", "Chenjuan Guo", "Christian S. Jensen", "Bin Yang"], "title": "TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation", "comment": null, "summary": "Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.", "AI": {"tldr": "TimeART\u662f\u4e00\u4e2a\u878d\u5408\u5f3a\u5927\u5de5\u5177\u5206\u6790\u80fd\u529b\u548cLLM\u63a8\u7406\u80fd\u529b\u7684\u6846\u67b6\uff0c\u4f5c\u4e3a\u5168\u81ea\u52a8\u6570\u636e\u79d1\u5b66\u5bb6\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u95ee\u7b54\u4efb\u52a1\uff0c\u901a\u8fc7100k\u4e13\u5bb6\u8f68\u8ff9\u6570\u636e\u96c6\u548c\u56db\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u591a\u4e2aTSQA\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u6570\u636e\u79d1\u5b66\u5bb6\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u7f3a\u4e4f\u81ea\u52a8\u5316\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u5316\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u95ee\u7b54\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u63d0\u51faTimeART\u6846\u67b6\uff0c\u878d\u5408\u73b0\u6210\u5de5\u5177\u7684\u5206\u6790\u80fd\u529b\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\uff1b\u6536\u96c6100k\u4e13\u5bb6\u8f68\u8ff9\u6570\u636e\u96c6TimeToolBench\uff1b\u8bbe\u8ba1\u56db\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u4ece\u65e9\u671f\u7ecf\u9a8c\u548c\u81ea\u6211\u53cd\u601d\u4e2d\u5b66\u4e60\u3002", "result": "\u8bad\u7ec3\u4e86\u4e00\u4e2a8B\u53c2\u6570\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u95ee\u7b54\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u7684state-of-the-art\u6027\u80fd\u3002", "conclusion": "TimeART\u5f00\u521b\u4e86\u4ee3\u7406\u5f0f\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u5de5\u5177\u80fd\u529b\u548cLLM\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u5168\u81ea\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2601.13806", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13806", "abs": "https://arxiv.org/abs/2601.13806", "authors": ["Dezhao Song", "Guglielmo Bonifazi", "Frank Schilder", "Jonathan Richard Schwarz"], "title": "Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning", "comment": null, "summary": "LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \\textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3aLLM\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7IRAC\u6846\u67b6\u6784\u5efa\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\uff0c\u7ed3\u5408SFT\u548cDPO\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u540e\u8bad\u7ec3\u4e3b\u8981\u4f9d\u8d56\u5927\u89c4\u6a21\u6587\u672c\u548c\u4eba\u7c7b\u53cd\u9988\uff0c\u7f3a\u4e4f\u5bf9\u9886\u57df\u77e5\u8bc6\u7ed3\u6784\u7684\u6355\u6349\uff0c\u5bfc\u81f4\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff08\u7279\u522b\u662f\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\u5982\u6cd5\u5f8b\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u6cd5\u5f8b\u63a8\u7406\u9700\u8981\u6df1\u5165\u7406\u89e3\u6cd5\u5f8b\u6982\u5ff5\u95f4\u7684\u5173\u7cfb\uff0c\u8fd9\u662f\u73b0\u6709LLM\u540e\u8bad\u7ec3\u7f3a\u5931\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\u3002", "method": "\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u65b9\u6cd5\u589e\u5f3aLLM\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\uff1a1) \u57fa\u4e8eIRAC\u6846\u67b6\uff08Issue, Rule, Analysis, Conclusion\uff09\u5efa\u6a21\u5173\u952e\u6cd5\u5f8b\u6982\u5ff5\uff1b2) \u6784\u5efa\u5305\u542b12K\u6cd5\u5f8b\u6848\u4f8b\u7684\u77e5\u8bc6\u56fe\u8c31\uff1b3) \u5229\u7528IRAC KG\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff1b4) \u5bf9\u4e09\u4e2aSOTA LLM\uff0830B\u300149B\u300170B\uff09\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u3002", "result": "\u540e\u8bad\u7ec3\u6a21\u578b\u57284/5\u4e2a\u591a\u6837\u5316\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5\uff0814\u4e2a\u4efb\u52a1\uff09\u4e0a\u83b7\u5f97\u6bd4\u57fa\u7ebf\u66f4\u597d\u7684\u5e73\u5747\u6027\u80fd\u3002\u7279\u522b\u662f70B DPO\u6a21\u578b\u57284/6\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u5206\u6570\uff0c\u8d85\u8d8a\u4e86\u57fa\u7ebf\u6a21\u578b\u548c141B SOTA\u6cd5\u5f8bLLM\uff0c\u8bc1\u660e\u4e86\u77e5\u8bc6\u56fe\u8c31\u5bf9\u589e\u5f3aLLM\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u65b9\u6cd5\u80fd\u6709\u6548\u589e\u5f3aLLM\u5728\u4e13\u4e1a\u9886\u57df\uff08\u7279\u522b\u662f\u6cd5\u5f8b\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u9ad8\u98ce\u9669\u9886\u57df\u3002\u57fa\u4e8eIRAC\u6846\u67b6\u6784\u5efa\u7684\u77e5\u8bc6\u56fe\u8c31\u4e3aLLM\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13676", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13676", "abs": "https://arxiv.org/abs/2601.13676", "authors": ["Fabian Greifeneder", "Wolfgang Fenz", "Benedikt Alkin", "Johannes Brandstetter", "Michael Giretzlehner", "Philipp Moser"], "title": "Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery", "comment": null, "summary": "Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8111\u7ec4\u7ec7\u5f62\u53d8\u6a21\u62df\u66ff\u4ee3\u6a21\u578b\uff0c\u4f7f\u7528\u968f\u673a\u6559\u5e08\u5f3a\u5236\u7b56\u7565\u51cf\u5c11\u81ea\u56de\u5f52\u63a8\u7406\u8bef\u5dee\uff0c\u5b9e\u73b0\u5b9e\u65f6\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6a21\u62df", "motivation": "\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\u96be\u4ee5\u6ee1\u8db3\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6a21\u62df\u7684\u5b9e\u65f6\u6027\u80fd\u8981\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9ad8\u6548\u6a21\u62df\u8111\u7ec4\u7ec7\u975e\u7ebf\u6027\u5f62\u53d8\u7684\u66ff\u4ee3\u6a21\u578b", "method": "\u57fa\u4e8e\u901a\u7528\u7269\u7406\u53d8\u6362\u5668\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\uff0c\u76f4\u63a5\u5904\u7406\u5927\u89c4\u6a21\u7f51\u683c\u6570\u636e\uff0c\u4f7f\u7528\u968f\u673a\u6559\u5e08\u5f3a\u5236\u8bad\u7ec3\u7b56\u7565\u9010\u6b65\u51cf\u5c11\u771f\u5b9e\u8f93\u5165\u6bd4\u4f8b\uff0c\u63d0\u9ad8\u957f\u671f\u63a8\u6f14\u7a33\u5b9a\u6027", "result": "\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4b\u77ac\u6001\u8111\u5f62\u53d8\uff0c\u652f\u630115\u4e07\u8282\u70b9\u7f51\u683c\uff0c\u6700\u5927\u9884\u6d4b\u8bef\u5dee\u4ece6.7mm\u964d\u81f33.5mm\uff0c\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u5b9e\u73b0\u6bcf\u6b6510ms\u4ee5\u4e0b\u7684\u5b9e\u65f6\u6a21\u62df", "conclusion": "\u8be5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u5e73\u6ed1\u3001\u51c6\u786e\u7684\u8111\u7ec4\u7ec7\u751f\u7269\u529b\u5b66\u6a21\u62df\uff0c\u4e3a\u771f\u5b9e\u624b\u672f\u8bad\u7ec3\u73af\u5883\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2601.13835", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13835", "abs": "https://arxiv.org/abs/2601.13835", "authors": ["Sam OConnor Russell", "Delphine Charuau", "Naomi Harte"], "title": "The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations", "comment": "Accepted to ICASSP 2026", "summary": "Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u58f0\u7801\u5668\u65b9\u6cd5\u63a7\u5236\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\uff0c\u63a2\u7a76S3R\u57fa\u7840\u7684\u8f6e\u8f6c\u6a21\u578b\u4f9d\u8d56\u54ea\u79cd\u7ebf\u7d22\uff0c\u53d1\u73b0\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u90fd\u80fd\u652f\u6301\u8f6e\u8f6c\uff0c\u4e14\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528\uff0c\u672a\u6765\u6a21\u578b\u53ef\u80fd\u4ec5\u9700\u97f5\u5f8b\u7ebf\u7d22\u4ee5\u4fdd\u62a4\u9690\u79c1\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5728\u4eba\u7c7b-\u673a\u5668\u4eba\u4ea4\u4e92\u4e2d\uff0c\u6d41\u7545\u7684\u8f6e\u8f6c\u5bf9\u8bdd\u662f\u5173\u952e\u6311\u6218\u3002\u867d\u7136\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\uff08S3Rs\uff09\u63a8\u52a8\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u57fa\u4e8eS3R\u7684\u8f6e\u8f6c\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u97f5\u5f8b\u7ebf\u7d22\u3001\u8bcd\u6c47\u7ebf\u7d22\u8fd8\u662f\u4e24\u8005\u517c\u6709\u3002\u9700\u8981\u66f4\u5e72\u51c0\u5730\u63a7\u5236\u8fd9\u4e24\u79cd\u7ebf\u7d22\u6765\u63a2\u7a76\u6a21\u578b\u673a\u5236\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u58f0\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u5e72\u51c0\u5730\u63a7\u5236\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u63a2\u6d4b\u57fa\u4e8eS3R\u7684\u8f6e\u8f6c\u6a21\u578b\uff08\u8bed\u97f3\u6d3b\u52a8\u9884\u6d4b\u6a21\u578b\uff09\uff0c\u5728\u4fdd\u6301\u97f5\u5f8b\u4f46\u8bcd\u6c47\u4e0d\u53ef\u7406\u89e3\u7684\u566a\u58f0\u6761\u4ef6\u4e0b\u8fdb\u884c\u9884\u6d4b\u6d4b\u8bd5\u3002", "result": "\u5728\u97f5\u5f8b\u5339\u914d\u4f46\u4e0d\u53ef\u7406\u89e3\u7684\u566a\u58f0\u4e0a\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4e0e\u5e72\u51c0\u8bed\u97f3\u76f8\u4f3c\u3002\u8fd9\u8868\u660e\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u90fd\u80fd\u652f\u6301\u8f6e\u8f6c\uff0c\u4e14\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528\u3002\u5f53\u4efb\u4e00\u4fe1\u606f\u88ab\u7834\u574f\u65f6\uff0c\u6a21\u578b\u4f1a\u5229\u7528\u53e6\u4e00\u7ebf\u7d22\u800c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u8bf4\u660e\u5b83\u4eec\u5728S3Rs\u4e2d\u7f16\u7801\u4e14\u76f8\u4e92\u4f9d\u8d56\u6709\u9650\u3002\u7ed3\u679c\u5728CPC\u548cwav2vec2.0 S3Rs\u4e2d\u4e00\u81f4\u3002", "conclusion": "\u672a\u6765\u8f6e\u8f6c\u6a21\u578b\u53ef\u80fd\u4ec5\u9700\u97f5\u5f8b\u7ebf\u7d22\uff0c\u8fd9\u80fd\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u548c\u6f5c\u5728\u6027\u80fd\u4f18\u52bf\u3002\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u5728S3Rs\u4e2d\u7f16\u7801\u76f8\u5bf9\u72ec\u7acb\uff0c\u6a21\u578b\u80fd\u7075\u6d3b\u5229\u7528\u4efb\u4e00\u7ebf\u7d22\u3002\u7814\u7a76\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u4e86\u65b9\u5411\uff0c\u5e76\u5f00\u6e90\u4e86\u6240\u6709\u4ee3\u7801\u3002"}}
{"id": "2601.13836", "categories": ["cs.CL", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13836", "abs": "https://arxiv.org/abs/2601.13836", "authors": ["Qian Chen", "Jinlan Fu", "Changsong Li", "See-Kiong Ng", "Xipeng Qiu"], "title": "FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs", "comment": "https://openmoss.github.io/FutureOmni", "summary": "Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u97f3\u9891\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u80fd\u529b\u7684\u57fa\u51c6FutureOmni\uff0c\u5305\u542b919\u4e2a\u89c6\u9891\u548c1034\u4e2aQA\u5bf9\uff0c\u5e76\u63d0\u51fa\u4e86OFF\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u56de\u987e\u6027\u7406\u89e3\uff0c\u4f46\u5728\u57fa\u4e8e\u97f3\u9891\u89c6\u89c9\u7ebf\u7d22\u9884\u6d4b\u672a\u6765\u4e8b\u4ef6\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e00\u80fd\u529b\u3002", "method": "1) \u901a\u8fc7LLM\u8f85\u52a9\u3001\u4eba\u7c7b\u53c2\u4e0e\u7684\u6d41\u7a0b\u6784\u5efaFutureOmni\u57fa\u51c6\uff0c\u5305\u542b8\u4e2a\u4e3b\u8981\u9886\u57df\u7684919\u4e2a\u89c6\u9891\u548c1034\u4e2a\u591a\u9879\u9009\u62e9\u9898\uff1b2) \u63d0\u51faOmni-Modal Future Forecasting (OFF)\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u4e867K\u6837\u672c\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\u3002", "result": "\u8bc4\u4f30\u4e8613\u4e2a\u591a\u6a21\u6001\u548c7\u4e2a\u7eaf\u89c6\u9891\u6a21\u578b\uff0c\u53d1\u73b0\u5f53\u524d\u7cfb\u7edf\u5728\u97f3\u9891\u89c6\u89c9\u672a\u6765\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u8bed\u97f3\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\uff0c\u6700\u4f73\u51c6\u786e\u7387\u4ec5\u4e3a64.8%\uff08Gemini 3 Flash\uff09\u3002OFF\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u672a\u6765\u9884\u6d4b\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "FutureOmni\u662f\u9996\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u672a\u6765\u9884\u6d4b\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u7684OFF\u8bad\u7ec3\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2601.13710", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13710", "abs": "https://arxiv.org/abs/2601.13710", "authors": ["Sayeed Shafayet Chowdhury", "Snehasis Mukhopadhyay", "Shiaofen Fang", "Vijay R. Ramakrishnan"], "title": "Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction", "comment": null, "summary": "Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\u4e0e\u751f\u6210\u5f0fAI\u5728\u9884\u6d4b\u6162\u6027\u9f3b\u7aa6\u708e\u624b\u672f\u6548\u679c\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0MLP\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5efa\u8bae\u91c7\u7528ML\u4e3a\u4e3b\u3001GenAI\u4e3a\u8f85\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\u5df2\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4e34\u5e8a\u6570\u636e\u7684\u524d\u77bb\u6027\u51b3\u7b56\u652f\u6301\u65b9\u9762\u4ecd\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u672f\u524d\u9884\u6d4b\u6162\u6027\u9f3b\u7aa6\u708e\u624b\u672f\u6548\u679c\u7684\u65b9\u6cd5\uff0c\u4ee5\u8bc6\u522b\u53ef\u80fd\u624b\u672f\u6548\u679c\u4e0d\u4f73\u7684\u60a3\u8005\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u624b\u672f\u3002", "method": "\u4f7f\u7528\u524d\u77bb\u6027\u6536\u96c6\u7684\u961f\u5217\u6570\u636e\uff0c\u6bd4\u8f83\u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\uff08\u903b\u8f91\u56de\u5f52\u3001\u6811\u96c6\u6210\u3001MLP\uff09\u4e0e\u751f\u6210\u5f0fAI\uff08ChatGPT\u3001Claude\u3001Gemini\u3001Perplexity\uff09\u5728\u9884\u6d4b\u624b\u672f\u6548\u679c\u4e0a\u7684\u8868\u73b0\u3002\u6240\u6709\u6a21\u578b\u63a5\u6536\u76f8\u540c\u7684\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u8f93\u51fa\u4e8c\u5143\u63a8\u8350\u53ca\u7f6e\u4fe1\u5ea6\u3002", "result": "\u6700\u4f73ML\u6a21\u578b\uff08MLP\uff09\u8fbe\u523085%\u51c6\u786e\u7387\uff0c\u5177\u6709\u66f4\u597d\u7684\u6821\u51c6\u548c\u51b3\u7b56\u66f2\u7ebf\u51c0\u6548\u76ca\u3002\u751f\u6210\u5f0fAI\u5728\u5224\u522b\u548c\u6821\u51c6\u65b9\u9762\u8868\u73b0\u8f83\u5dee\u3002\u6709\u8da3\u7684\u662f\uff0cGenAI\u7684\u89e3\u91ca\u4e0e\u4e34\u5e8a\u7ecf\u9a8c\u548cMLP\u7279\u5f81\u91cd\u8981\u6027\u4e00\u81f4\uff0c\u90fd\u5f3a\u8c03\u57fa\u7ebfSNOT-22\u3001CT/\u5185\u955c\u4e25\u91cd\u7a0b\u5ea6\u3001\u606f\u8089\u8868\u578b\u548c\u5fc3\u7406/\u75bc\u75db\u5171\u75c5\u3002", "conclusion": "\u652f\u6301ML\u4f18\u5148\u3001GenAI\u589e\u5f3a\u7684\u5de5\u4f5c\u6d41\u7a0b\uff1a\u90e8\u7f72\u6821\u51c6\u7684ML\u8fdb\u884c\u624b\u672f\u5019\u9009\u8005\u7684\u521d\u6b65\u7b5b\u9009\uff0c\u4f7f\u7528GenAI\u4f5c\u4e3a\u89e3\u91ca\u5668\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u5171\u4eab\u51b3\u7b56\u5236\u5b9a\u3002\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u8868\u683c\u6570\u636e\u5230GenAI\u8bc4\u4f30\u534f\u8bae\u548c\u4e9a\u7ec4\u5206\u6790\u3002"}}
{"id": "2601.13876", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13876", "abs": "https://arxiv.org/abs/2601.13876", "authors": ["Unggi Lee", "Jahyun Jeong", "Sunyoung Shin", "Haeun Park", "Jeongsu Moon", "Youngchang Song", "Jaechang Shim", "JaeHwan Lee", "Yunju Noh", "Seungwon Choi", "Ahhyun Kim", "TaeHyeon Kim", "Kyungtae Joo", "Taeyeong Kim", "Gyeonggeon Lee"], "title": "Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education", "comment": null, "summary": "Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \\textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.", "AI": {"tldr": "\u63d0\u51faPedagogical VLA Framework\u6846\u67b6\uff0c\u901a\u8fc7\u6559\u5b66\u5bf9\u9f50\u4f7f\u8f7b\u91cf\u7ea7VLA\u6a21\u578b\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u7684\u6559\u80b2\u73af\u5883\u4e2d\u751f\u6210\u6559\u5b66\u89e3\u91ca\uff0c\u5728\u79d1\u5b66\u6f14\u793a\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u540c\u65f6\u63d0\u4f9b\u6559\u80b2\u6027\u89e3\u91ca\u3002", "motivation": "\u79d1\u5b66\u6f14\u793a\u5bf9STEM\u6559\u80b2\u5f88\u91cd\u8981\uff0c\u4f46\u6559\u5e08\u9762\u4e34\u5b89\u5168\u6027\u548c\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002\u73b0\u6709VLA\u6a21\u578b\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e14\u727a\u7272\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u8ffd\u6c42\u6548\u7387\uff0c\u4e0d\u9002\u5408\u9700\u8981\u53ef\u89e3\u91ca\u3001\u80fd\u751f\u6210\u89e3\u91ca\u7684\u6559\u80b2\u73af\u5883\u3002", "method": "\u63d0\u51faPedagogical VLA Framework\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\uff1a\u6587\u672c\u4fee\u590d\u6062\u590d\u8bed\u8a00\u751f\u6210\u80fd\u529b\u3001LLM\u84b8\u998f\u4f20\u9012\u6559\u5b66\u77e5\u8bc6\u3001\u5b89\u5168\u8bad\u7ec3\u9002\u5e94\u6559\u80b2\u73af\u5883\u3001\u6559\u5b66\u8bc4\u4f30\u8c03\u6574\u5230\u79d1\u5b66\u6559\u80b2\u573a\u666f\u3002\u5728\u4e94\u4e2a\u79d1\u5b66\u6f14\u793a\u4efb\u52a1\uff08\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u3001\u5730\u7403\u79d1\u5b66\uff09\u4e2d\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPedagogical VLA Framework\u5728\u4efb\u52a1\u6027\u80fd\uff08\u6210\u529f\u7387\u3001\u534f\u8bae\u5408\u89c4\u6027\u3001\u6548\u7387\u3001\u5b89\u5168\u6027\uff09\u4e0a\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u80fd\u751f\u6210\u4e0a\u4e0b\u6587\u6070\u5f53\u7684\u6559\u80b2\u89e3\u91ca\u3002\u901a\u8fc7\u6559\u5e08\u8c03\u67e5\u548cLLM-as-Judge\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6559\u5b66\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u6559\u5b66\u5bf9\u9f50\u5e94\u7528\u4e8e\u8f7b\u91cf\u7ea7VLA\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u6559\u80b2\u73af\u5883\u4e2d\u65e2\u80fd\u6267\u884c\u79d1\u5b66\u6f14\u793a\u4efb\u52a1\uff0c\u53c8\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6559\u5b66\u89e3\u91ca\uff0c\u89e3\u51b3\u4e86\u73b0\u6709VLA\u6a21\u578b\u5728\u6559\u80b2\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.13748", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13748", "abs": "https://arxiv.org/abs/2601.13748", "authors": ["Tien-Dat Pham", "Xuan-The Tran"], "title": "EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory", "comment": null, "summary": "Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation", "AI": {"tldr": "EEG-Titans\uff1a\u4e00\u79cd\u53cc\u5206\u652f\u67b6\u6784\uff0c\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u548c\u5faa\u73af\u8bb0\u5fc6\u673a\u5236\uff0c\u7528\u4e8e\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u5728CHB-MIT\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.46%\u7684\u5e73\u5747\u6bb5\u7ea7\u7075\u654f\u5ea6", "motivation": "\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u53d1\u4f5c\u524d\u52a8\u6001\u53ef\u80fd\u8de8\u8d8a\u957f\u65f6\u95f4\u8303\u56f4\uff0c\u800c\u4e34\u5e8a\u76f8\u5173\u7279\u5f81\u53ef\u80fd\u5fae\u5999\u4e14\u77ed\u6682\u3002\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8d85\u957f\u5e8f\u5217\u5904\u7406\u65f6\u9762\u4e34\u5c40\u90e8\u65f6\u7a7a\u6a21\u5f0f\u6355\u83b7\u4e0e\u957f\u7a0b\u4e0a\u4e0b\u6587\u4fdd\u6301\u4e4b\u95f4\u7684\u6743\u8861", "method": "\u63d0\u51faEEG-Titans\u53cc\u5206\u652f\u67b6\u6784\uff1a1\uff09\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u5206\u652f\u6355\u83b7\u77ed\u671f\u5f02\u5e38\uff1b2\uff09\u5faa\u73af\u8bb0\u5fc6\u8def\u5f84\u603b\u7ed3\u968f\u65f6\u95f4\u63a8\u79fb\u7684\u7f13\u6162\u6e10\u8fdb\u8d8b\u52bf\uff1b3\uff09\u91c7\u7528\u5206\u5c42\u4e0a\u4e0b\u6587\u7b56\u7565\u6269\u5c55\u9ad8\u566a\u58f0\u53d7\u8bd5\u8005\u7684\u611f\u53d7\u91ce", "result": "\u5728CHB-MIT\u5934\u76aeEEG\u6570\u636e\u96c6\u4e0a\uff0c\u6309\u65f6\u95f4\u987a\u5e8f\u4fdd\u7559\u534f\u8bae\u8bc4\u4f30\uff0cEEG-Titans\u572818\u540d\u53d7\u8bd5\u8005\u4e2d\u8fbe\u523099.46%\u7684\u5e73\u5747\u6bb5\u7ea7\u7075\u654f\u5ea6\u3002\u5206\u5c42\u4e0a\u4e0b\u6587\u7b56\u7565\u663e\u8457\u51cf\u5c11\u8bef\u62a5\uff08\u6781\u7aef\u5f02\u5e38\u503c\u4e2d\u964d\u81f30.00 FPR/h\uff09\u800c\u4e0d\u727a\u7272\u7075\u654f\u5ea6", "conclusion": "\u8bb0\u5fc6\u589e\u5f3a\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u53ef\u4ee5\u5728\u4e34\u5e8a\u7ea6\u675f\u8bc4\u4f30\u4e0b\u63d0\u4f9b\u7a33\u5065\u7684\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\uff0c\u8868\u660e\u795e\u7ecf\u8bb0\u5fc6\u673a\u5236\u5bf9\u4e8e\u5904\u7406\u8d85\u957fEEG\u5e8f\u5217\u548c\u6355\u6349\u53d1\u4f5c\u524d\u52a8\u6001\u7684\u6709\u6548\u6027"}}
{"id": "2601.13882", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13882", "abs": "https://arxiv.org/abs/2601.13882", "authors": ["Unggi Lee", "Sookbun Lee", "Heungsoo Choi", "Jinseo Lee", "Haeun Park", "Younghoon Jeon", "Sungmin Cho", "Minju Kang", "Junbo Koh", "Jiyeong Bae", "Minwoo Nam", "Juyeon Eun", "Yeonji Jung", "Yeil Jeong"], "title": "OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models", "comment": null, "summary": "Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.", "AI": {"tldr": "OpenLearnLM Benchmark\u662f\u4e00\u4e2a\u57fa\u4e8e\u6559\u80b2\u8bc4\u4f30\u7406\u8bba\u7684\u591a\u7ef4\u5ea6LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u6001\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u6db5\u76d6124K+\u9879\u76ee\uff0c\u8bc4\u4f30\u663e\u793a\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u7ef4\u5ea6\u8868\u73b0\u5404\u5f02\uff0c\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u7ef4\u5ea6\u9886\u5148\u3002", "motivation": "\u73b0\u6709LLM\u6559\u80b2\u57fa\u51c6\u6d4b\u8bd5\u8fc7\u4e8e\u5173\u6ce8\u72ed\u7a84\u6280\u80fd\uff0c\u7f3a\u4e4f\u5b66\u4e60\u79d1\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u9700\u8981\u66f4\u5168\u9762\u3001\u7406\u8bba\u57fa\u7840\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30LLM\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u771f\u5b9e\u51c6\u5907\u5ea6\u3002", "method": "\u57fa\u4e8e\u6559\u80b2\u8bc4\u4f30\u7406\u8bba\u6784\u5efa\u4e09\u7ef4\u8bc4\u4f30\u6846\u67b6\uff1a\u77e5\u8bc6\uff08\u8bfe\u7a0b\u5185\u5bb9\u4e0e\u6559\u5b66\u7406\u89e3\uff09\u3001\u6280\u80fd\uff08\u57fa\u4e8e\u56db\u5c42\u7ea7\u4e2d\u5fc3-\u89d2\u8272-\u573a\u666f-\u5b50\u573a\u666f\u7ed3\u6784\u7684\u573a\u666f\u80fd\u529b\uff09\u3001\u6001\u5ea6\uff08\u4e00\u81f4\u6027\u5bf9\u9f50\u548c\u6b3a\u9a97\u62b5\u6297\uff09\u3002\u5305\u542b124K+\u9879\u76ee\uff0c\u6db5\u76d6\u591a\u5b66\u79d1\u3001\u6559\u80b2\u89d2\u8272\u548c\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u7684\u96be\u5ea6\u7ea7\u522b\u3002\u77e5\u8bc6\u57df\u4f7f\u7528\u771f\u5b9e\u8bc4\u4f30\u9879\u76ee\uff0c\u6001\u5ea6\u57df\u91c7\u7528Anthropic\u7684\u5bf9\u9f50\u4f2a\u88c5\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f307\u4e2a\u524d\u6cbf\u6a21\u578b\u663e\u793a\u4e0d\u540c\u80fd\u529b\u7279\u5f81\uff1aClaude-Opus-4.5\u5728\u5b9e\u8df5\u6280\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\u4f46\u5185\u5bb9\u77e5\u8bc6\u8f83\u4f4e\uff1bGrok-4.1-fast\u5728\u77e5\u8bc6\u65b9\u9762\u9886\u5148\u4f46\u663e\u793a\u5bf9\u9f50\u95ee\u9898\u3002\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u7ef4\u5ea6\u5360\u4f18\uff0c\u9a8c\u8bc1\u4e86\u591a\u8f74\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "OpenLearnLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u653e\u3001\u5168\u9762\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a8\u8fdbLLM\u5728\u771f\u5b9e\u6559\u80b2\u73af\u5883\u4e2d\u7684\u51c6\u5907\u5ea6\uff0c\u5f3a\u8c03\u9700\u8981\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6765\u5168\u9762\u7406\u89e3LLM\u7684\u6559\u80b2\u80fd\u529b\u3002"}}
{"id": "2601.13768", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13768", "abs": "https://arxiv.org/abs/2601.13768", "authors": ["Wenzhen Yue", "Ruohao Guo", "Ji Shi", "Zihan Hao", "Shiyu Hu", "Xianghua Ying"], "title": "vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting", "comment": null, "summary": "In this paper, we present \\textbf{vLinear}, an effective yet efficient \\textbf{linear}-based multivariate time series forecaster featuring two components: the \\textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \\textbf{velocity-oriented} flow matching objectives, we demonstrate that a \\textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.", "AI": {"tldr": "vLinear\u662f\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u6a21\u578b\u7684\u9ad8\u6548\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5668\uff0c\u5305\u542bvecTrans\u6a21\u5757\u548cWFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(N\u00b2)\u964d\u4f4e\u5230O(N)\u3002", "motivation": "\u73b0\u6709\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u5668\u901a\u5e38\u4f7f\u7528\u81ea\u6ce8\u610f\u529b\u6216\u5176\u53d8\u4f53\u6765\u6355\u6349\u591a\u5143\u76f8\u5173\u6027\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4O(N\u00b2)\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5176\u4e2dN\u662f\u53d8\u91cf\u6570\u91cf\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) vecTrans\u6a21\u5757\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u5411\u91cf\u5efa\u6a21\u591a\u5143\u76f8\u5173\u6027\uff0c\u5c06\u590d\u6742\u5ea6\u964d\u81f3O(N)\uff1b2) WFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u91c7\u7528\u6700\u7ec8\u5e8f\u5217\u5bfc\u5411\u7684\u6d41\u5339\u914d\u635f\u5931\uff0c\u7ed3\u5408\u8def\u5f84\u548c\u6c34\u5e73\u52a0\u6743\u7b56\u7565\u6765\u5173\u6ce8\u66f4\u53ef\u9760\u7684\u8def\u5f84\u548c\u9884\u6d4b\u6c34\u5e73\u3002", "result": "\u572822\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c124\u4e2a\u9884\u6d4b\u8bbe\u7f6e\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1bvecTrans\u53ef\u65e0\u7f1d\u96c6\u6210\u5230Transformer\u9884\u6d4b\u5668\u4e2d\uff0c\u5b9e\u73b0\u9ad8\u8fbe5\u500d\u7684\u63a8\u7406\u52a0\u901f\u548c\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff1bWFMLoss\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u76ee\u6807\u51fd\u6570\uff0c\u80fd\u6301\u7eed\u6539\u8fdb\u73b0\u6709\u9884\u6d4b\u5668\u3002", "conclusion": "vLinear\u901a\u8fc7vecTrans\u6a21\u5757\u548cWFMLoss\u76ee\u6807\u51fd\u6570\uff0c\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u6027\u548c\u9ad8\u6027\u80fd\u7684\u5e73\u8861\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13885", "abs": "https://arxiv.org/abs/2601.13885", "authors": ["Esma Balk\u0131r", "Alice Pernthaller", "Marco Basaldella", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Nigel Collier"], "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores", "comment": null, "summary": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 \u03c4 over random sampling, with 95% accuracy on confident predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8ba1\u7b97\u673a\u81ea\u9002\u5e94\u6d4b\u8bd5\uff08CAT\uff09\u6269\u5c55\u5230\u8fde\u7eed\u6709\u754c\u8bc4\u5206\uff08\u5982ROUGE\u3001BLEU\u3001LLM-as-a-Judge\uff09\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\u66ff\u4ee3\u4f2f\u52aa\u5229\u5206\u5e03\uff0c\u5e76\u5f15\u5165\u5177\u6709\u81ea\u9002\u5e94\u505c\u6b62\u51c6\u5219\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\u5668\uff0c\u663e\u8457\u51cf\u5c11\u6d4b\u8bd5\u9879\u76ee\u6570\u91cf\u3002", "motivation": "\u4f20\u7edfCAT\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u9009\u62e9\u9898\uff08\u6b63\u786e/\u9519\u8bef\u8bc4\u5206\uff09\uff0c\u4f46\u73b0\u4ee3LLM\u8bc4\u4f30\u8d8a\u6765\u8d8a\u591a\u4f9d\u8d56\u751f\u6210\u4efb\u52a1\uff0c\u5176\u8f93\u51fa\u91c7\u7528\u8fde\u7eed\u8bc4\u5206\uff08\u5982ROUGE\u3001BLEU\u3001LLM-as-a-Judge\u8bc4\u5206\uff09\u3002\u9700\u8981\u5c06IRT\u81ea\u9002\u5e94\u6d4b\u8bd5\u6269\u5c55\u5230\u8fde\u7eed\u6709\u754c\u8bc4\u5206\u9886\u57df\u3002", "method": "1. \u7528\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\u66ff\u4ee3\u4f20\u7edfIRT\u4e2d\u7684\u4f2f\u52aa\u5229\u54cd\u5e94\u5206\u5e03\uff0c\u4ee5\u9002\u5e94\u8fde\u7eed\u6709\u754c\u8bc4\u5206\uff1b2. \u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\u5668\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u505c\u6b62\u51c6\u5219\uff0c\u5728\u4fdd\u8bc1\u53ef\u9760\u6a21\u578b\u6392\u5e8f\u7684\u540c\u65f6\u6700\u5c0f\u5316\u6d4b\u8bd5\u9879\u76ee\u6570\u91cf\u548c\u6210\u672c\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ecn-gram\u3001embedding\u548cLLM-as-judge\u6307\u6807\uff09\u4e0a\u9a8c\u8bc1\uff0c\u4ec5\u4f7f\u75282%\u7684\u6d4b\u8bd5\u9879\u76ee\uff0c\u76f8\u6bd4\u968f\u673a\u91c7\u6837\u5c06\u6392\u5e8f\u76f8\u5173\u6027\u63d0\u9ad8\u4e860.12 \u03c4\uff0c\u5728\u7f6e\u4fe1\u9884\u6d4b\u4e0a\u8fbe\u523095%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06CAT\u6269\u5c55\u5230\u8fde\u7eed\u8bc4\u5206\u9886\u57df\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u8bc4\u4f30\u6548\u7387\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u6d4b\u8bd5\u6210\u672c\uff0c\u4e3a\u73b0\u4ee3\u751f\u6210\u4efb\u52a1\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\u6846\u67b6\u3002"}}
{"id": "2601.13918", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13918", "abs": "https://arxiv.org/abs/2601.13918", "authors": ["Yusheng Liao", "Chuan Xuan", "Yutong Cai", "Lina Yang", "Zhe Chen", "Yanfeng Wang", "Yu Wang"], "title": "AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization", "comment": "37 pages, 12 figures", "summary": "Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.", "AI": {"tldr": "RetroSum\u6846\u67b6\u901a\u8fc7\u56de\u987e\u6027\u603b\u7ed3\u548c\u6f14\u8fdb\u7ecf\u9a8c\u7b56\u7565\uff0c\u5728AgentEHR\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347LLM\u5728\u539f\u59cb\u7535\u5b50\u75c5\u5386\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\u80fd\u529b\uff0c\u6027\u80fd\u63d0\u5347\u8fbe29.16%\uff0c\u4ea4\u4e92\u9519\u8bef\u51cf\u5c1192.3%\u3002", "motivation": "\u5f53\u524dLLM\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u4f9d\u8d56\u7cbe\u5fc3\u51c6\u5907\u7684\u8f93\u5165\u548c\u7b80\u5316\u7684\u68c0\u7d22\u4efb\u52a1\uff0c\u65e0\u6cd5\u5728\u539f\u59cb\u3001\u9ad8\u566a\u58f0\u7684\u7535\u5b50\u75c5\u5386\u6570\u636e\u5e93\u4e2d\u8fdb\u884c\u590d\u6742\u7684\u4e34\u5e8a\u51b3\u7b56\u4efb\u52a1\uff0c\u5982\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u3002", "method": "\u63d0\u51faRetroSum\u6846\u67b6\uff0c\u5305\u542b\u56de\u987e\u6027\u603b\u7ed3\u673a\u5236\u548c\u6f14\u8fdb\u7ecf\u9a8c\u7b56\u7565\u3002\u56de\u987e\u6027\u673a\u5236\u52a8\u6001\u91cd\u65b0\u8bc4\u4f30\u4ea4\u4e92\u5386\u53f2\uff0c\u9632\u6b62\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e22\u5931\uff1b\u6f14\u8fdb\u7b56\u7565\u4ece\u8bb0\u5fc6\u5e93\u4e2d\u68c0\u7d22\u7d2f\u79ef\u7ecf\u9a8c\u6765\u5f25\u5408\u9886\u57df\u5dee\u8ddd\u3002", "result": "RetroSum\u5728AgentEHR\u57fa\u51c6\u4e0a\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe29.16%\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u603b\u4ea4\u4e92\u9519\u8bef\u8fbe92.3%\u3002", "conclusion": "RetroSum\u901a\u8fc7\u521b\u65b0\u7684\u56de\u987e\u6027\u603b\u7ed3\u548c\u6f14\u8fdb\u7ecf\u9a8c\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u539f\u59cb\u7535\u5b50\u75c5\u5386\u4e2d\u81ea\u4e3b\u5bfc\u822a\u65f6\u7684\u4fe1\u606f\u4e22\u5931\u548c\u63a8\u7406\u8fde\u7eed\u6027\u65ad\u88c2\u95ee\u9898\uff0c\u4e3a\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.13780", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13780", "abs": "https://arxiv.org/abs/2601.13780", "authors": ["Antoine Siraudin", "Christopher Morris"], "title": "Principled Latent Diffusion for Graphs via Laplacian Autoencoders", "comment": "Preprint, under review", "summary": "Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\\times$ speed-up.", "AI": {"tldr": "LG-Flow\uff1a\u4e00\u79cd\u6f5c\u5728\u56fe\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u590d\u6742\u5ea6\u5b9e\u73b0\u9ad8\u6548\u56fe\u751f\u6210\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b01000\u500d\u52a0\u901f", "motivation": "\u73b0\u6709\u56fe\u6269\u6563\u6a21\u578b\u5b58\u5728\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4e14\u5927\u90e8\u5206\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u5728\u7a00\u758f\u56fe\u7684\u7a7a\u8fb9\u4e0a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u8fd1\u4e4e\u65e0\u635f\u91cd\u5efa\u7684\u6f5c\u5728\u7a7a\u95f4\u538b\u7f29\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u56fe\u751f\u6210\u4e2d\u7684\u7cbe\u786e\u6027\u8981\u6c42\u6311\u6218\u3002", "method": "\u4f7f\u7528\u7f6e\u6362\u7b49\u53d8\u81ea\u7f16\u7801\u5668\u5c06\u8282\u70b9\u6620\u5c04\u5230\u56fa\u5b9a\u7ef4\u5d4c\u5165\uff0c\u786e\u4fdd\u90bb\u63a5\u77e9\u9635\u53ef\u8bc1\u660e\u6062\u590d\uff1b\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bad\u7ec3\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6269\u6563\u53d8\u6362\u5668\uff0c\u5b9e\u73b0\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u56fe\u751f\u6210\u3002", "result": "LG-Flow\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe1000\u500d\u7684\u52a0\u901f\uff0c\u6d88\u9664\u4e86\u4e8c\u6b21\u590d\u6742\u5ea6\u74f6\u9888\uff0c\u652f\u6301\u66f4\u5927\u3001\u66f4\u5177\u8868\u8fbe\u529b\u7684\u6a21\u578b\u8bad\u7ec3\u3002", "conclusion": "LG-Flow\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u6269\u6563\u6a21\u578b\u7684\u6548\u7387\u548c\u7cbe\u786e\u6027\u6311\u6218\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6027\u80fd\u548c\u901f\u5ea6\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2601.13919", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13919", "abs": "https://arxiv.org/abs/2601.13919", "authors": ["Yuezhe Yang", "Hao Wang", "Yige Peng", "Jinman Kim", "Lei Bi"], "title": "HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs", "comment": "Under Review", "summary": "Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \\textbf{HyperWalker}, a \\textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \\textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \\textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \\textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker", "AI": {"tldr": "HyperWalker\uff1a\u57fa\u4e8e\u52a8\u6001\u8d85\u56fe\u4e0e\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u7684\u6df1\u5ea6\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efaiBrochure\u8d85\u56fe\u5efa\u6a21EHR\u7ed3\u6784\u5f02\u8d28\u6027\uff0c\u5229\u7528Walker\u667a\u80fd\u4f53\u5bfc\u822a\u5bfb\u627e\u6700\u4f18\u8bca\u65ad\u8def\u5f84\uff0c\u7ed3\u5408linger\u673a\u5236\u9009\u62e9\u4e34\u5e8a\u4e92\u8865\u75c5\u4f8b\uff0c\u5728MRG\u548c\u533b\u7597VQA\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u533b\u7597AI\u8bca\u65ad\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u6837\u672c\u9694\u79bb\u63a8\u7406\u8303\u5f0f\uff0c\u72ec\u7acb\u5904\u7406\u75c5\u4f8b\u800c\u65e0\u6cd5\u8bbf\u95ee\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6216\u7ed3\u6784\u76f8\u5173\u60a3\u8005\u793a\u4f8b\uff0c\u4ec5\u4f9d\u8d56\u56fe\u50cf\u4fe1\u606f\u9650\u5236\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u3002\u9700\u8981\u6574\u5408\u5916\u90e8\u8865\u5145\u533b\u5b66\u8bc1\u636e\u4ee5\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u4e34\u5e8a\u8bca\u65ad\u3002", "method": "\u63d0\u51faHyperWalker\u6df1\u5ea6\u8bca\u65ad\u6846\u67b6\uff1a1) \u6784\u5efa\u52a8\u6001\u8d85\u56feiBrochure\uff0c\u5efa\u6a21EHR\u6570\u636e\u7684\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u591a\u6a21\u6001\u4e34\u5e8a\u4fe1\u606f\u95f4\u7684\u9ad8\u9636\u5173\u8054\uff1b2) \u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53Walker\u5728\u8d85\u56fe\u4e2d\u5bfc\u822a\u5bfb\u627e\u6700\u4f18\u8bca\u65ad\u8def\u5f84\uff1b3) \u5f15\u5165linger\u673a\u5236\uff0c\u901a\u8fc7\u591a\u8df3\u6b63\u4ea4\u68c0\u7d22\u7b56\u7565\u8fed\u4ee3\u9009\u62e9\u53cd\u6620\u4e0d\u540c\u4e34\u5e8a\u5c5e\u6027\u7684\u4e92\u8865\u90bb\u57df\u75c5\u4f8b\u3002", "result": "\u5728MIMIC\u6570\u636e\u96c6\u4e0a\u7684\u533b\u7597\u62a5\u544a\u751f\u6210(MRG)\u548cEHRXQA\u4e0a\u7684\u533b\u7597\u89c6\u89c9\u95ee\u7b54(VQA)\u5b9e\u9a8c\u4e2d\uff0cHyperWalker\u5747\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "HyperWalker\u901a\u8fc7\u52a8\u6001\u8d85\u56fe\u5efa\u6a21\u548c\u6d4b\u8bd5\u65f6\u8bad\u7ec3\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6837\u672c\u9694\u79bb\u63a8\u7406\u8303\u5f0f\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u6574\u5408\u5916\u90e8\u533b\u5b66\u8bc1\u636e\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u4e34\u5e8a\u8bca\u65ad\uff0c\u4e3a\u533b\u7597AI\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u7684\u6846\u67b6\u601d\u8def\u3002"}}
{"id": "2601.13793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13793", "abs": "https://arxiv.org/abs/2601.13793", "authors": ["ByeoungDo Kim", "JunYeop Na", "Kyungwook Tak", "JunTae Kim", "DongHyeon Kim", "Duckky Kim"], "title": "PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles", "comment": "7 pages, 3 figures, ITSC 2025, to be published", "summary": "In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u9884\u6d4b\u6a21\u578b\uff0c\u5229\u7528\u5386\u53f2\u9053\u8def\u901f\u5ea6\u6a21\u5f0f\uff0c\u901a\u8fc7\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u6355\u6349\u4ea4\u901a\u6d41\u7684\u65f6\u7a7a\u56e0\u679c\u5173\u7cfb\uff0c\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u4e14\u51c6\u786e\u7684\u5230\u8fbe\u65f6\u95f4\u4f30\u8ba1\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u51c6\u786e\u53ef\u9760\u7684ETA\u9884\u6d4b\u5728\u5bfc\u822a\u3001\u51fa\u884c\u89c4\u5212\u548c\u4ea4\u901a\u7ba1\u7406\u4e2d\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u7531\u4e8e\u4ea4\u901a\u6d41\u7684\u52a8\u6001\u590d\u6742\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u7b80\u5355\u7ed3\u5408\u5b9e\u65f6\u548c\u5386\u53f2\u6570\u636e\uff0c\u8981\u4e48\u4f9d\u8d56\u590d\u6742\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u8ba1\u7b97\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u672a\u80fd\u6709\u6548\u6355\u6349\u5173\u952e\u7684\u65f6\u7a7a\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u6a21\u578b\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u5386\u53f2\u9053\u8def\u901f\u5ea6\u6a21\u5f0f\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u63d0\u53d6\u548c\u5229\u7528\u6cbf\u8def\u7ebf\u6bcf\u4e2a\u65f6\u7a7a\u70b9\u7d2f\u79ef\u7684\u65f6\u7a7a\u7279\u5f81\uff0c\u6709\u6548\u6355\u6349ETA\u9884\u6d4b\u4e2d\u7684\u65f6\u7a7a\u56e0\u679c\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u548c\u53ef\u6269\u5c55\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u9a7e\u9a76\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u6a21\u578b\u5728ETA\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u4ee5\u4efb\u52a1\u611f\u77e5\u7684\u65b9\u5f0f\u6709\u6548\u6574\u5408\u9053\u8def\u7279\u5f81\u3001\u5b9e\u65f6\u4ea4\u901a\u6761\u4ef6\u548c\u5386\u53f2\u901f\u5ea6\u6a21\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684ETA\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u6349\u4ea4\u901a\u6d41\u7684\u65f6\u7a7a\u6a21\u5f0f\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u5230\u8fbe\u65f6\u95f4\u9884\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u548c\u53ef\u6269\u5c55\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13922", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13922", "abs": "https://arxiv.org/abs/2601.13922", "authors": ["Adrian Cosma", "Oleg Szehr", "David Kletz", "Alessandro Antonucci", "Olivier Pelletier"], "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery", "comment": "5 Figures, 1 Table", "summary": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u7279\u5f81\u53d1\u73b0\u89c6\u4e3a\u6570\u636e\u96c6\u7ea7\u63d0\u793a\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u534f\u4f5c\u751f\u6210\u53ef\u89e3\u91ca\u7279\u5f81\u5b9a\u4e49\uff0c\u4f18\u5316\u4e0b\u6e38\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u3002", "motivation": "\u5f53\u524d\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u63d0\u793a\u6216\u56fa\u5b9a\u7279\u5f81\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u81ea\u52a8\u53d1\u73b0\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ece\u6807\u6ce8\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u81ea\u52a8\u53d1\u73b0\u5168\u5c40\u3001\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u533a\u5206\u6027\u7279\u5f81\u5b9a\u4e49\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff1a\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u534f\u4f5c\u6267\u884c\u4e09\u4e2a\u4efb\u52a1\u2014\u2014\u63d0\u51fa\u7279\u5f81\u5b9a\u4e49\u3001\u63d0\u53d6\u7279\u5f81\u503c\u3001\u8bc4\u4f30\u7279\u5f81\u8d28\u91cf\uff08\u57fa\u4e8e\u6570\u636e\u96c6\u7ea7\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u53cd\u9988\uff09\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u6307\u4ee4\u63d0\u793a\uff0c\u5b9e\u73b0\u5171\u4eab\u7279\u5f81\u96c6\u7684\u4f18\u5316\u800c\u975e\u5355\u6837\u672c\u9884\u6d4b\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0e\u4f9d\u8d56\u5355\u6837\u672c\u76d1\u7763\u7684\u5148\u524d\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e0d\u540c\uff0c\u4e3a\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u81ea\u52a8\u53d1\u73b0\u7279\u5f81\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u673a\u5236\uff0c\u80fd\u591f\u751f\u6210\u5168\u5c40\u53ef\u89e3\u91ca\u7279\u5f81\u96c6\u3002", "conclusion": "\u5c06\u7279\u5f81\u53d1\u73b0\u5f62\u5f0f\u5316\u4e3a\u6570\u636e\u96c6\u7ea7\u63d0\u793a\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5b9e\u73b0\u81ea\u52a8\u7279\u5f81\u53d1\u73b0\uff0c\u4e3a\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u3002"}}
{"id": "2601.13824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13824", "abs": "https://arxiv.org/abs/2601.13824", "authors": ["Xiaohong Yang", "Tong Xie", "Minghui Liwang", "Chikai Shang", "Yang Lu", "Zhenzhen Jiao", "Liqun Fu", "Seyyedali Hosseinalipour"], "title": "ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks", "comment": "11 pages, 16 figures", "summary": "Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.", "AI": {"tldr": "ELSA\u662f\u4e00\u4e2a\u7528\u4e8e\u8fb9\u7f18\u7f51\u7edcLLM\u5fae\u8c03\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5206\u5272\u5b66\u4e60\u548c\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u8bbe\u5907\u8d44\u6e90\u9650\u5236\u3001\u6570\u636e\u5f02\u6784\u6027\u548c\u9690\u79c1\u98ce\u9669\u95ee\u9898\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u8bbe\u5907\u8d44\u6e90\u9650\u5236\u3001\u4e25\u91cd\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u9ad8\u9690\u79c1\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u6846\u67b6\u6765\u652f\u6301\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u7f51\u7edc\u4e0a\u7684\u5206\u5e03\u5f0fLLM\u5fae\u8c03\u3002", "method": "ELSA\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u4efb\u52a1\u65e0\u5173\u3001\u884c\u4e3a\u611f\u77e5\u7684\u5ba2\u6237\u7aef\u805a\u7c7b\u673a\u5236\uff0c\u4f7f\u7528\u516c\u5171\u63a2\u9488\u8f93\u5165\u548c\u5bf9\u79f0KL\u6563\u5ea6\u6784\u5efa\u8bed\u4e49\u6307\u7eb9\uff0c\u7ed3\u5408\u9884\u6d4b\u4e00\u81f4\u6027\u4fe1\u4efb\u8bc4\u5206\u548c\u5ef6\u8fdf\u611f\u77e5\u8fb9\u7f18\u5206\u914d\uff1b2) \u5c06LLM\u5206\u6210\u4e09\u90e8\u5206\u5206\u5e03\u5728\u5ba2\u6237\u7aef\u548c\u8fb9\u7f18\u670d\u52a1\u5668\uff0c\u4e91\u7aef\u4ec5\u7528\u4e8e\u9002\u914d\u5668\u805a\u5408\uff1b3) \u57fa\u4e8e\u8ba1\u7b97\u8349\u56fe\u7ed3\u5408\u8bed\u4e49\u5b50\u7a7a\u95f4\u6b63\u4ea4\u6270\u52a8\u7684\u8f7b\u91cf\u901a\u4fe1\u65b9\u6848\u3002", "result": "\u5728\u591a\u79cdNLP\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cELSA\u5728\u9002\u5e94\u6027\u3001\u6536\u655b\u884c\u4e3a\u548c\u9c81\u68d2\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u8fb9\u7f18\u4fa7LLM\u5fae\u8c03\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9690\u79c1\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "ELSA\u901a\u8fc7\u7cfb\u7edf\u6574\u5408\u5206\u5272\u5b66\u4e60\u548c\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8fb9\u7f18LLM\u8bad\u7ec3\u4e2d\u7684\u8d44\u6e90\u3001\u5f02\u6784\u6027\u548c\u9690\u79c1\u6311\u6218\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u7f51\u7edc\u4e0a\u7684\u5206\u5e03\u5f0fLLM\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2601.13992", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13992", "abs": "https://arxiv.org/abs/2601.13992", "authors": ["Jin Cui", "Jiaqi Guo", "Jiepeng Zhou", "Ruixuan Yang", "Jiayi Lu", "Jiajun Xu", "Jiangcheng Song", "Boran Zhao", "Pengju Ren"], "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework", "comment": "11pages, 9figures", "summary": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.", "AI": {"tldr": "COMPACT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u878d\u5408\u591a\u6559\u5e08\u76d1\u7763\u6765\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u907f\u514d\u5355\u4e00\u6559\u5e08\u7684\u504f\u89c1\u548c\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u77e5\u8bc6\u84b8\u998f\u6548\u679c\u3002", "motivation": "\u73b0\u6709CoT\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6559\u5e08\u6a21\u578b\uff0c\u4f46\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u80fd\u529b\u504f\u89c1\u548c\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b66\u751f\u6a21\u578b\u7684\u6f5c\u529b\u3002\u867d\u7136\u5229\u7528\u591a\u6837\u5316\u6559\u5e08\u6a21\u578b\u5177\u6709\u5438\u5f15\u529b\uff0c\u4f46\u6709\u6548\u878d\u5408\u5b83\u4eec\u7684\u76d1\u7763\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff1a\u5e08\u751f\u4e0d\u517c\u5bb9\u53ef\u80fd\u653e\u5927\u5e7b\u89c9\uff0c\u88ab\u52a8\u76d1\u7763\u65e0\u6cd5\u786e\u4fdd\u771f\u6b63\u7684\u903b\u8f91\u5185\u5316\u3002", "method": "COMPACT\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u5b66\u751f\u5b9e\u65f6\u517c\u5bb9\u6027\u52a8\u6001\u52a0\u6743\u6559\u5e08\u68af\u5ea6\u6765\u878d\u5408\u4e0d\u540c\u6559\u5e08\u7684\u76d1\u7763\u3002\u517c\u5bb9\u6027\u901a\u8fc7\u4e09\u4e2a\u591a\u7ef4\u6307\u6807\u8bc4\u4f30\uff1a(1)\u57fa\u4e8e\u56fe\u7684\u5171\u8bc6\u5ea6\uff0c\u901a\u8fc7\u8bc6\u522b\u4e3b\u6d41\u63a8\u7406\u8def\u5f84\u8fc7\u6ee4\u8bef\u5bfc\u6027\u7406\u7531\uff1b(2)\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u9002\u5e94\u6027\uff0c\u68c0\u6d4b\"\u987f\u609f\u65f6\u523b\"\u4ee5\u786e\u4fdd\u771f\u6b63\u7406\u89e3\u63a8\u7406\u8fc7\u7a0b\u800c\u975e\u7b80\u5355\u6a21\u4eff\uff1b(3)\u57fa\u4e8e\u635f\u5931\u7684\u96be\u5ea6\u8bc4\u4f30\uff0c\u8861\u91cf\u5b66\u751f\u5bf9\u6559\u5e08\u6307\u5bfc\u7684\u63a5\u53d7\u5ea6\u5e76\u9632\u6b62\u8d1f\u8fc1\u79fb\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u548c\u6f5c\u5728\u7a7a\u95f4\u5206\u6790\u8868\u660e\uff0cCOMPACT\u80fd\u6709\u6548\u6574\u5408\u591a\u6837\u5316\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u635f\u5bb3\u6a21\u578b\u7684\u539f\u59cb\u77e5\u8bc6\u7ed3\u6784\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "conclusion": "COMPACT\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u878d\u5408\u591a\u6559\u5e08\u76d1\u7763\uff0c\u6210\u529f\u89e3\u51b3\u4e86CoT\u84b8\u998f\u4e2d\u5355\u4e00\u6559\u5e08\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u7406\u80fd\u529b\u8f6c\u79fb\uff0c\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.13844", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13844", "abs": "https://arxiv.org/abs/2601.13844", "authors": ["Gilad Karpel", "Edward Moroshko", "Ran Levinstein", "Ron Meir", "Daniel Soudry", "Itay Evron"], "title": "Optimal L2 Regularization in High-dimensional Continual Linear Regression", "comment": "Accepted to ALT 2026", "summary": "We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.", "AI": {"tldr": "\u7814\u7a76\u8fc7\u53c2\u6570\u5316\u6301\u7eed\u7ebf\u6027\u56de\u5f52\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u53d1\u73b0\u5404\u5411\u540c\u6027\u6b63\u5219\u5316\u80fd\u7f13\u89e3\u6807\u7b7e\u566a\u58f0\uff0c\u6700\u4f18\u6b63\u5219\u5316\u5f3a\u5ea6\u968f\u4efb\u52a1\u6570T\u6309T/lnT\u6bd4\u4f8b\u589e\u957f\u3002", "motivation": "\u7814\u7a76\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8fc7\u53c2\u6570\u5316\u7ebf\u6027\u56de\u5f52\u8bbe\u7f6e\u4e0b\uff0c\u63a2\u7d22\u6b63\u5219\u5316\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5728\u5e8f\u5217\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4ee5\u53ca\u5982\u4f55\u8bbe\u8ba1\u6700\u4f18\u7684\u6b63\u5219\u5316\u7b56\u7565\u3002", "method": "\u91c7\u7528\u7406\u8bba\u5206\u6790\u65b9\u6cd5\uff0c\u5728\u8fc7\u53c2\u6570\u5316\u6301\u7eed\u7ebf\u6027\u56de\u5f52\u8bbe\u7f6e\u4e0b\u63a8\u5bfc\u671f\u671b\u6cdb\u5316\u635f\u5931\u7684\u95ed\u5f0f\u89e3\uff0c\u8003\u8651\u4efb\u610f\u7ebf\u6027\u6559\u5e08\u6a21\u578b\uff0c\u5206\u6790\u5404\u5411\u540c\u6027\u6b63\u5219\u5316\u5bf9\u6807\u7b7e\u566a\u58f0\u7684\u7f13\u89e3\u4f5c\u7528\u3002", "result": "\u8bc1\u660e\u4e86\u5404\u5411\u540c\u6027\u6b63\u5219\u5316\u5728\u5355\u6559\u5e08\u548c\u591a\u6559\u5e08\u8bbe\u7f6e\u4e0b\u90fd\u80fd\u6709\u6548\u7f13\u89e3\u6807\u7b7e\u566a\u58f0\uff1b\u53d1\u73b0\u6700\u4f18\u56fa\u5b9a\u6b63\u5219\u5316\u5f3a\u5ea6\u968f\u4efb\u52a1\u6570T\u6309T/lnT\u6bd4\u4f8b\u589e\u957f\uff1b\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u548c\u795e\u7ecf\u7f51\u7edc\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u9996\u6b21\u5728\u7406\u8bba\u6301\u7eed\u5b66\u4e60\u4e2d\u8bc1\u660e\u4e86\u6700\u4f18\u6b63\u5219\u5316\u5f3a\u5ea6\u4e0e\u4efb\u52a1\u6570\u7684\u7279\u5b9a\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5c55\u793a\u4e86\u6b63\u5219\u5316\u5728\u7f13\u89e3\u6807\u7b7e\u566a\u58f0\u65b9\u9762\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2601.13995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13995", "abs": "https://arxiv.org/abs/2601.13995", "authors": ["Zihan Niu", "Wenping Hu", "Junmin Chen", "Xiyue Wang", "Tong Xu", "Ruiming Tang"], "title": "From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning", "comment": null, "summary": "Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \\textbf{+5.84\\%} using only \\textbf{5\\%} of the data, while our aligned sampling strategy further boosts average performance by \\textbf{+4.24\\%}.", "AI": {"tldr": "TAGS\u6846\u67b6\u5229\u7528\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6811\u5b9e\u73b0\u53ef\u63a7\u6570\u636e\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u6307\u4ee4\u8c03\u4f18\u6548\u679c", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u5b9e\u4f8b\u7ea7\u8d28\u91cf\u8bc4\u5206\u6216\u57fa\u4e8e\u5d4c\u5165\u805a\u7c7b/\u8bed\u4e49\u6807\u7b7e\u7684\u591a\u6837\u6027\u5ea6\u91cf\uff0c\u4f46\u53d7\u9650\u4e8e\u5d4c\u5165\u7a7a\u95f4\u5e73\u5766\u6027\u6216\u6807\u7b7e\u7c97\u7cd9\u6027\uff0c\u5ffd\u7565\u4e86\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u53ca\u5176\u5185\u5728\u5c42\u6b21\u4f9d\u8d56\u5173\u7cfb\uff0c\u963b\u788d\u4e86\u7cbe\u786e\u7684\u6570\u636e\u8bc4\u4f30\u548c\u77e5\u8bc6\u5bf9\u9f50\u91c7\u6837\u3002", "method": "\u63d0\u51faTree-aware Aligned Global Sampling (TAGS)\u6846\u67b6\uff1a1) \u4f7f\u7528LLM\u6807\u6ce8\u5668\u63d0\u53d6\u539f\u5b50\u77e5\u8bc6\u6982\u5ff5\uff1b2) \u901a\u8fc7\u81ea\u5e95\u5411\u4e0a\u5c42\u6b21\u805a\u7c7b\u6784\u5efa\u5168\u5c40\u77e5\u8bc6\u6811\uff1b3) \u5c06\u6570\u636e\u5b9e\u4f8b\u6620\u5c04\u5230\u6811\u4e0a\uff0c\u7528\u6811\u611f\u77e5\u5ea6\u91cf\u91cf\u5316\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\uff1b4) \u53ef\u63a7\u91c7\u6837\u7b56\u7565\u6700\u5927\u5316\u6811\u7ea7\u4fe1\u606f\u589e\u76ca\uff0c\u5e76\u901a\u8fc7KL\u6563\u5ea6\u5f3a\u5236\u53f6\u7ea7\u5bf9\u9f50\u7279\u5b9a\u9886\u57df\u3002", "result": "TAGS\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u4ec5\u4f7f\u75285%\u6570\u636e\u5c31\u8d85\u8d8a\u5168\u6570\u636e\u96c6\u6a21\u578b+5.84%\uff0c\u5bf9\u9f50\u91c7\u6837\u7b56\u7565\u8fdb\u4e00\u6b65\u5c06\u5e73\u5747\u6027\u80fd\u63d0\u5347+4.24%\u3002", "conclusion": "TAGS\u901a\u8fc7\u6784\u5efa\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6811\u5b9e\u73b0\u4e86\u5bf9\u6570\u636e\u8d28\u91cf\u3001\u591a\u6837\u6027\u548c\u76ee\u6807\u5bf9\u9f50\u7684\u8054\u5408\u63a7\u5236\uff0c\u4e3aLLM\u6307\u4ee4\u8c03\u4f18\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u63a7\u7684\u6570\u636e\u9009\u62e9\u6846\u67b6\u3002"}}
{"id": "2601.14004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14004", "abs": "https://arxiv.org/abs/2601.14004", "authors": ["Hengyuan Zhang", "Zhihao Zhang", "Mingyang Wang", "Zunhai Su", "Yiwei Wang", "Qianli Wang", "Shuzhou Yuan", "Ercong Nie", "Xufeng Duan", "Qibo Xue", "Zeping Yu", "Chenming Shang", "Xiao Liang", "Jing Xiong", "Hui Shen", "Chaofan Tao", "Zhengwu Liu", "Senjie Jin", "Zhiheng Xi", "Dongdong Zhang", "Sophia Ananiadou", "Tao Gui", "Ruobing Xie", "Hayden Kwok-Hay So", "Hinrich Sch\u00fctze", "Xuanjing Huang", "Qi Zhang", "Ngai Wong"], "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models", "comment": null, "summary": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u64cd\u4f5c\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u5c06MI\u4ece\u89c2\u5bdf\u79d1\u5b66\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\"\u5b9a\u4f4d\u3001\u5f15\u5bfc\u3001\u6539\u8fdb\"\u6d41\u7a0b\u5b9e\u73b0\u6a21\u578b\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e3b\u8981\u505c\u7559\u5728\u89c2\u5bdf\u5c42\u9762\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u5e72\u9884\u6846\u67b6\u3002\u4f5c\u8005\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5c06MI\u4ece\u88ab\u52a8\u5206\u6790\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u4f18\u5316\u5de5\u5177\u3002", "method": "\u63d0\u51fa\"\u5b9a\u4f4d\u3001\u5f15\u5bfc\u3001\u6539\u8fdb\"\u7684\u4e09\u6b65\u6d41\u7a0b\u6846\u67b6\uff0c\u57fa\u4e8e\u53ef\u89e3\u91ca\u5bf9\u8c61\u5bf9\u5b9a\u4f4d\uff08\u8bca\u65ad\uff09\u548c\u5f15\u5bfc\uff08\u5e72\u9884\uff09\u65b9\u6cd5\u8fdb\u884c\u5f62\u5f0f\u5316\u5206\u7c7b\uff0c\u5efa\u7acb\u4e25\u683c\u7684\u5e72\u9884\u534f\u8bae\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5bf9\u9f50\u6027\u3001\u80fd\u529b\u548c\u6548\u7387\u4e09\u4e2a\u65b9\u9762\u7684\u5b9e\u9645\u6539\u8fdb\uff0c\u5c06MI\u64cd\u4f5c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u5b66\u3002", "conclusion": "\u673a\u5236\u53ef\u89e3\u91ca\u6027\u53ef\u4ee5\u8d85\u8d8a\u89c2\u5bdf\u79d1\u5b66\uff0c\u6210\u4e3a\u7cfb\u7edf\u5316\u7684\u53ef\u64cd\u4f5c\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5e72\u9884\u6d41\u7a0b\u6709\u6548\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13892", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13892", "abs": "https://arxiv.org/abs/2601.13892", "authors": ["Andrej Schwanke", "Lyubomir Ivanov", "David Salinas", "Frank Hutter", "Arber Zela"], "title": "Multi-Objective Hierarchical Optimization with Large Language Models", "comment": "23 pages, 21 figures, 9 tables", "summary": "Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff1a\u901a\u8fc7\u81ea\u9002\u5e94\u7a7a\u95f4\u5212\u5206\u548c\u5c40\u90e8\u63a8\u7406\uff0c\u8ba9LLM\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\u548c\u5019\u9009\u91c7\u6837\u5668\uff0c\u6536\u655b\u5230\u771f\u5b9ePareto\u524d\u6cbf", "motivation": "\u5c3d\u7ba1LLM\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u8868\u73b0\u5f3a\u5927\uff0c\u4f46\u5c1a\u672a\u6210\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u7684\u73b0\u6210\u9009\u62e9\u3002\u4f20\u7edf\u65b9\u6cd5\u56e0\u80fd\u5904\u7406\u6570\u503c\u8f93\u5165\u3001\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3001\u5904\u7406\u51b2\u7a81\u76ee\u6807\u800c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u641c\u7d22\u7b56\u7565\uff1a\u5c06\u8f93\u5165\u7a7a\u95f4\u81ea\u9002\u5e94\u5212\u5206\u4e3a\u4e0d\u76f8\u4ea4\u7684\u8d85\u77e9\u5f62\u533a\u57df\uff0c\u4f7f\u7528\u590d\u5408\u8bc4\u5206\u51fd\u6570\u5bf9\u533a\u57df\u6392\u5e8f\uff0c\u5c06LLM\u7684\u751f\u6210\u8fc7\u7a0b\u9650\u5236\u5728\u5177\u6709\u9ad8\u6f5c\u529b\u7684\u5b50\u7a7a\u95f4\u3002LLM\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\u548c\u5019\u9009\u91c7\u6837\u5668\uff0c\u53ea\u9700\u8fdb\u884c\u5c40\u90e8\u63a8\u7406\u800c\u975e\u5168\u5c40\u63a8\u7406\u3002", "result": "\u5728\u6807\u51c6\u6b63\u5219\u6027\u5047\u8bbe\u4e0b\uff0c\u7b97\u6cd5\u751f\u6210\u7684\u5019\u9009\u89e3\u5728Hausdorff\u8ddd\u79bb\u4e0b\u6536\u655b\u5230\u771f\u5b9ePareto\u96c6\u3002\u5b9e\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u5168\u5c40\u591a\u76ee\u6807\u4f18\u5316\u5668\uff0c\u4e0e\u6807\u51c6\u8fdb\u5316\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u5c42\u641c\u7d22\u7b56\u7565\uff0c\u6210\u529f\u5c06LLM\u5e94\u7528\u4e8e\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u5176\u80fd\u591f\u6709\u6548\u5904\u7406\u6570\u503c\u4f18\u5316\u4efb\u52a1\uff0c\u586b\u8865\u4e86LLM\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u7a7a\u767d\u3002"}}
{"id": "2601.14007", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14007", "abs": "https://arxiv.org/abs/2601.14007", "authors": ["Junyu Zhang", "Yipeng Kang", "Jiong Guo", "Jiayu Zhan", "Junqi Wang"], "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models", "comment": "34 pagess, 16 figures, 6 tables, submitted to ACL 2026", "summary": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.", "AI": {"tldr": "LLMs\u901a\u8fc7\u62bd\u8c61-\u5177\u8eab\u6846\u67b6\u8bc4\u4f30\u6982\u5ff5\u7406\u89e3\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u4ef7\u503c\u8868\u793a\u5177\u6709\u8de8\u5c42\u6b21\u53ef\u8fc1\u79fb\u6027\u548c\u56e0\u679c\u4e0d\u5bf9\u79f0\u6027\uff0c\u4e3a\u6784\u5efa\u4ef7\u503c\u9a71\u52a8\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u673a\u5236\u57fa\u7840\u3002", "motivation": "\u63a2\u7a76LLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u62bd\u8c61\u6982\u5ff5\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5728\u64cd\u7eb5\u7edf\u8ba1\u6a21\u5f0f\u3002\u4ee5\u4eba\u7c7b\u4ef7\u503c\u89c2\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u56e0\u4e3a\u5176\u8bed\u4e49\u4e30\u5bcc\u4e14\u5bf9AI\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u62bd\u8c61-\u5177\u8eab\u6846\u67b6\uff0c\u5c06\u6982\u5ff5\u7406\u89e3\u5206\u89e3\u4e3a\u4e09\u4e2a\u80fd\u529b\uff1a\u62bd\u8c61\u6982\u5ff5\u89e3\u91ca(A-A)\u3001\u62bd\u8c61\u6982\u5ff5\u5728\u5177\u4f53\u4e8b\u4ef6\u4e2d\u7684\u5177\u8eab\u5316(A-C)\u3001\u62bd\u8c61\u539f\u5219\u5728\u5177\u4f53\u51b3\u7b56\u4e2d\u7684\u5e94\u7528(C-C)\u3002\u4f7f\u7528\u63a2\u6d4b\uff08\u68c0\u6d4b\u5185\u90e8\u6fc0\u6d3b\u4e2d\u7684\u4ef7\u503c\u75d5\u8ff9\uff09\u548c\u5f15\u5bfc\uff08\u4fee\u6539\u8868\u793a\u4ee5\u6539\u53d8\u884c\u4e3a\uff09\u65b9\u6cd5\uff0c\u5728\u516d\u4e2a\u5f00\u6e90LLM\u548c\u5341\u4e2a\u4ef7\u503c\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u63a2\u6d4b\u663e\u793a\uff1a\u4ec5\u57fa\u4e8e\u62bd\u8c61\u4ef7\u503c\u63cf\u8ff0\u8bad\u7ec3\u7684\u63a2\u6d4b\u6a21\u578b\u80fd\u53ef\u9760\u5730\u5728\u5177\u4f53\u4e8b\u4ef6\u53d9\u8ff0\u548c\u51b3\u7b56\u63a8\u7406\u4e2d\u68c0\u6d4b\u5230\u76f8\u540c\u4ef7\u503c\uff0c\u8868\u73b0\u51fa\u8de8\u5c42\u6b21\u53ef\u8fc1\u79fb\u6027\u3002\u5f15\u5bfc\u63ed\u793a\u4e0d\u5bf9\u79f0\u6027\uff1a\u5e72\u9884\u4ef7\u503c\u8868\u793a\u80fd\u56e0\u679c\u6027\u5730\u6539\u53d8\u5177\u4f53\u5224\u65ad\u548c\u51b3\u7b56(A-C, C-C)\uff0c\u4f46\u4e0d\u4f1a\u6539\u53d8\u62bd\u8c61\u89e3\u91ca(A-A)\uff0c\u8868\u660e\u7f16\u7801\u7684\u62bd\u8c61\u4ef7\u503c\u4f5c\u4e3a\u7a33\u5b9a\u951a\u70b9\u800c\u975e\u53ef\u5851\u6fc0\u6d3b\u3002", "conclusion": "LLMs\u4fdd\u6301\u7ed3\u6784\u5316\u4ef7\u503c\u8868\u793a\uff0c\u8fde\u63a5\u62bd\u8c61\u4e0e\u884c\u52a8\uff0c\u4e3a\u6784\u5efa\u4ef7\u503c\u9a71\u52a8\u7684\u81ea\u4e3bAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u673a\u5236\u548c\u64cd\u4f5c\u57fa\u7840\uff0c\u53ef\u5b9e\u73b0\u66f4\u900f\u660e\u3001\u53ef\u6cdb\u5316\u7684\u5bf9\u9f50\u548c\u63a7\u5236\u3002"}}
{"id": "2601.13897", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13897", "abs": "https://arxiv.org/abs/2601.13897", "authors": ["Ankita Joshi", "Ashutosh Sharma", "Anoushkrit Goel", "Ranjeet Ranjan Jha", "Chirag Ahuja", "Arnav Bhavsar", "Aditya Nigam"], "title": "TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography", "comment": "Accepted at 23rd IEEE International Symposium on Biomedical Imaging (ISBI), 2026", "summary": "Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.", "AI": {"tldr": "\u63d0\u51faTractRLFusion\uff0c\u4e00\u79cd\u57fa\u4e8eGPT\u7684\u7b56\u7565\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u878d\u5408\u7b56\u7565\u6574\u5408\u591a\u4e2a\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u91cd\u5efa\u767d\u8d28\u7ea4\u7ef4\u675f\u5e76\u51cf\u5c11\u865a\u5047\u8fde\u63a5\u3002", "motivation": "\u4f20\u7edf\u7ea4\u7ef4\u675f\u6210\u50cf\u65b9\u6cd5\u5728\u51c6\u786e\u91cd\u5efa\u767d\u8d28\u7ea4\u7ef4\u675f\u540c\u65f6\u6700\u5c0f\u5316\u865a\u5047\u8fde\u63a5\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u5347\u795e\u7ecf\u5916\u79d1\u89c4\u5212\u7684\u7cbe\u786e\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8eGPT\u7684\u7b56\u7565\u878d\u5408\u6846\u67b6\uff0c\u5305\u542b\u4e24\u9636\u6bb5\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u8fc7\u7a0b\u8fdb\u884c\u6709\u6548\u7b56\u7565\u878d\u5408\uff0c\u7136\u540e\u901a\u8fc7\u591a\u6279\u8bc4\u5668\u5fae\u8c03\u9636\u6bb5\u589e\u5f3a\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728HCP\u3001ISMRM\u548cTractoInferno\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTractRLFusion\u5728\u51c6\u786e\u6027\u548c\u89e3\u5256\u53ef\u9760\u6027\u65b9\u9762\u4f18\u4e8e\u5355\u4e2aRL\u7b56\u7565\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u7ecf\u5178\u548cDRL\u65b9\u6cd5\u3002", "conclusion": "TractRLFusion\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ea4\u7ef4\u675f\u6210\u50cf\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u795e\u7ecf\u5916\u79d1\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u8111\u8fde\u63a5\u4fe1\u606f\u3002"}}
{"id": "2601.14032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14032", "abs": "https://arxiv.org/abs/2601.14032", "authors": ["Hongli Zhou", "Hui Huang", "Wei Liu", "Chenglong Wang", "Xingyuan Bu", "Lvyuan Han", "Fuhai Song", "Muyun Yang", "Wenhao Jiang", "Hailong Cao", "Tiejun Zhao"], "title": "RM-Distiller: Exploiting Generative LLM for Reward Model Distillation", "comment": null, "summary": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.", "AI": {"tldr": "RM-Distiller\uff1a\u5229\u7528\u751f\u6210\u5f0fLLM\u7684\u591a\u65b9\u9762\u80fd\u529b\u8fdb\u884c\u5956\u52b1\u6a21\u578b\u84b8\u998f\u7684\u6846\u67b6", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u84b8\u998f\u65b9\u6cd5\u4e3b\u8981\u5c06\u6559\u5e08\u6a21\u578b\u89c6\u4e3a\u7b80\u5355\u7684\u4e8c\u5143\u6807\u6ce8\u5668\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u4e30\u5bcc\u7684\u77e5\u8bc6\u548c\u80fd\u529b\u3002\u9ad8\u8d28\u91cf\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u96be\u4ee5\u83b7\u53d6\uff0c\u9700\u8981\u66f4\u6709\u6548\u5730\u4ece\u751f\u6210\u5f0fLLM\u4e2d\u84b8\u998f\u504f\u597d\u3002", "method": "\u63d0\u51faRM-Distiller\u6846\u67b6\uff0c\u7cfb\u7edf\u5229\u7528\u6559\u5e08LLM\u7684\u4e09\u79cd\u80fd\u529b\uff1a1\uff09\u7cbe\u70bc\u80fd\u529b\uff1a\u5408\u6210\u9ad8\u5ea6\u76f8\u5173\u7684\u54cd\u5e94\u5bf9\u4ee5\u521b\u5efa\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u4fe1\u53f7\uff1b2\uff09\u8bc4\u5206\u80fd\u529b\uff1a\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u4f18\u5316\u76ee\u6807\u6307\u5bfcRM\u6355\u6349\u7cbe\u786e\u504f\u597d\u5f3a\u5ea6\uff1b3\uff09\u751f\u6210\u80fd\u529b\uff1a\u7ed3\u5408\u6559\u5e08\u751f\u6210\u5206\u5e03\u6765\u6b63\u5219\u5316RM\u4ee5\u4fdd\u7559\u57fa\u672c\u8bed\u8a00\u77e5\u8bc6\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cRM-Distiller\u5728RM\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u9f50\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\uff0c\u8bc1\u660e\u5229\u7528\u591a\u65b9\u9762\u6559\u5e08\u80fd\u529b\u5bf9\u6709\u6548\u5956\u52b1\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u4ece\u751f\u6210\u5f0fLLM\u8fdb\u884c\u5956\u52b1\u6a21\u578b\u84b8\u998f\u7684\u5de5\u4f5c\uff0c\u5c55\u793a\u4e86\u5145\u5206\u5229\u7528\u6559\u5e08\u6a21\u578b\u591a\u65b9\u9762\u80fd\u529b\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.13953", "categories": ["cs.LG", "cs.AR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.13953", "abs": "https://arxiv.org/abs/2601.13953", "authors": ["Gorgi Pavlov"], "title": "Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition", "comment": "35 pages, 22 figures. Code available at https://github.com/gogipav14/spectral-llm", "summary": "Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to \"fuzzy\" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.\n  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.", "AI": {"tldr": "\u63d0\u51faHierarchical Spectral Composition\u67b6\u6784\uff0c\u901a\u8fc7\u9009\u62e9\u5e03\u5c14\u5085\u91cc\u53f6\u57fa\u7684\u8c31\u7cfb\u6570\uff0c\u7ed3\u5408Sinkhorn\u7ea6\u675f\u8def\u7531\u548c\u5217\u7b26\u53f7\u8c03\u5236\uff0c\u5b9e\u73b0\u7cbe\u786e\u5e03\u5c14\u903b\u8f91\u5b66\u4e60\uff0c\u652f\u6301\u786c\u4ef6\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u5408\u6210\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u5e03\u5c14\u903b\u8f91\u65f6\u5b58\u5728\"\u6a21\u7cca\"\u8fd1\u4f3c\u95ee\u9898\uff0c\u91cf\u5316\u540e\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u7cbe\u786e\u5b66\u4e60\u5e03\u5c14\u903b\u8f91\u7684\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u540c\u65f6\u652f\u6301\u786c\u4ef6\u9ad8\u6548\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8c31\u5408\u6210\u67b6\u6784\uff1a1) \u4ece\u51bb\u7ed3\u7684\u5e03\u5c14\u5085\u91cc\u53f6\u57fa\u4e2d\u9009\u62e9\u8c31\u7cfb\u6570\uff1b2) \u901a\u8fc7Sinkhorn\u7ea6\u675f\u8def\u7531\u8fdb\u884c\u7ec4\u5408\uff1b3) \u6dfb\u52a0\u5217\u7b26\u53f7\u8c03\u5236\u5b9e\u73b0\u5e03\u5c14\u5426\u5b9a\u529f\u80fd\u3002\u57fa\u4e8eManifold-Constrained Hyper-Connections\u6846\u67b6\uff0c\u5c06\u8def\u7531\u77e9\u9635\u6295\u5f71\u5230Birkhoff\u591a\u9762\u4f53\u4ee5\u4fdd\u6301\u6052\u7b49\u6620\u5c04\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "1) n=2\u65f6\uff1a\u68af\u5ea6\u4e0b\u964d\u8fbe\u5230100%\u51c6\u786e\u7387\uff0c\u96f6\u8def\u7531\u6f02\u79fb\uff0c\u4e09\u5143\u63a9\u7801\u96f6\u635f\u5931\u91cf\u5316\uff1b2) n=3\u65f6\uff1a\u68af\u5ea6\u4e0b\u964d76%\u51c6\u786e\u7387\uff0c\u4f46\u7a77\u4e3e\u8bc1\u660e\u6240\u6709\u64cd\u4f5c\u90fd\u5b58\u5728\u6700\u4f18\u4e09\u5143\u63a9\u7801\uff08100%\u51c6\u786e\u7387\uff0c39%\u7a00\u758f\u6027\uff09\uff1b3) n=4\u65f6\uff1a\u8c31\u5408\u6210\u65b9\u6cd5\uff08\u7cbe\u786eWalsh-Hadamard\u7cfb\u6570+\u4e09\u5143\u91cf\u5316+MCMC\u7cbe\u70bc\uff09\u8fbe\u5230100%\u51c6\u786e\u7387\u3002GPU\u4e0a\u5b9e\u73b0\u5355\u5468\u671f\u7ec4\u5408\u903b\u8f91\u63a8\u7406\uff0c\u901f\u5ea6\u8fbe10,959 MOps/s\u3002", "conclusion": "\u8bc1\u660e\u4e86\u6240\u6709\u6d4b\u8bd5\u51fd\u6570\u90fd\u5b58\u5728\u4e09\u5143\u591a\u9879\u5f0f\u9608\u503c\u8868\u793a\uff0c\u4f46\u968f\u7740\u7ef4\u5ea6\u589e\u52a0\uff0c\u9700\u8981\u8d85\u8d8a\u7eaf\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\u6765\u627e\u5230\u8fd9\u4e9b\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u4e3a\u786c\u4ef6\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u903b\u8f91\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.14041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14041", "abs": "https://arxiv.org/abs/2601.14041", "authors": ["Yunhe Wang", "Kai Han", "Huiling Zhen", "Yuchuan Tian", "Hanting Chen", "Yongbing Huang", "Yufei Cui", "Yingte Shu", "Shan Gao", "Ismail Elezi", "Roy Vaughan Miles", "Songcen Xu", "Feng Wen", "Chao Xu", "Sinan Zeng", "Dacheng Tao"], "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants", "comment": null, "summary": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5f53\u524d\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u56e0\u679c\u74f6\u9888\u9650\u5236\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6587\u672c\u751f\u6210\u8303\u5f0f\uff0c\u4f46\u9762\u4e34\u5341\u5927\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u6765\u5b9e\u73b0\u4e0b\u4e00\u4ee3AI\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91c7\u7528\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u5b58\u5728\u56e0\u679c\u74f6\u9888\u9650\u5236\uff0c\u65e0\u6cd5\u8fdb\u884c\u5168\u5c40\u7ed3\u6784\u9884\u89c1\u548c\u8fed\u4ee3\u4f18\u5316\u3002\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6587\u672c\u751f\u6210\u8303\u5f0f\uff0c\u4f46\u5c1a\u672a\u5145\u5206\u53d1\u6325\u6f5c\u529b\uff0c\u9700\u8981\u7a81\u7834\u73b0\u6709\u6846\u67b6\u9650\u5236\u3002", "method": "\u8bc6\u522b\u6269\u6563\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u7684\u5341\u5927\u57fa\u7840\u6311\u6218\uff0c\u63d0\u51fa\u5305\u542b\u56db\u5927\u652f\u67f1\u7684\u6218\u7565\u8def\u7ebf\u56fe\uff1a\u57fa\u7840\u67b6\u6784\u3001\u7b97\u6cd5\u4f18\u5316\u3001\u8ba4\u77e5\u63a8\u7406\u548c\u7edf\u4e00\u591a\u6a21\u6001\u667a\u80fd\uff0c\u5efa\u8bae\u5411\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u8f6c\u578b\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u7684\u7cfb\u7edf\u6027\u5206\u6790\u6846\u67b6\uff0c\u6307\u51fa\u4e86\u4ece\u67b6\u6784\u60ef\u6027\u3001\u68af\u5ea6\u7a00\u758f\u6027\u5230\u7ebf\u6027\u63a8\u7406\u9650\u5236\u7b49\u5173\u952e\u6311\u6218\uff0c\u5e76\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u8f6c\u578b\u8def\u5f84\u3002", "conclusion": "\u4ece\u81ea\u56de\u5f52\u8303\u5f0f\u5411\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u8f6c\u578b\u5bf9\u4e8e\u5f00\u53d1\u5177\u5907\u590d\u6742\u7ed3\u6784\u63a8\u7406\u3001\u52a8\u6001\u81ea\u6211\u4fee\u6b63\u548c\u65e0\u7f1d\u591a\u6a21\u6001\u6574\u5408\u80fd\u529b\u7684\u4e0b\u4e00\u4ee3AI\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u662f\u5b9e\u73b0\u6269\u6563\u8bed\u8a00\u6a21\u578b\"GPT-4\u65f6\u523b\"\u7684\u5173\u952e\u3002"}}
{"id": "2601.13964", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13964", "abs": "https://arxiv.org/abs/2601.13964", "authors": ["Cheol-Hui Lee", "Hwa-Yeon Lee", "Dong-Joo Kim"], "title": "RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning", "comment": null, "summary": "The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\\% and 8.80\\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\\% probability for sleep stage classification and Crop \\& Resize with a 77\\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \\href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.", "AI": {"tldr": "RL-BioAug\uff1a\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u9009\u62e9EEG\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u4ec5\u970010%\u6807\u7b7e\u6570\u636e\u6307\u5bfc\uff0c\u5728\u7761\u7720\u5206\u671f\u548c\u766b\u75eb\u68c0\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u968f\u673a\u589e\u5f3a\u7b56\u7565", "motivation": "\u4f20\u7edf\u9759\u6001\u6216\u968f\u673a\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u96be\u4ee5\u9002\u5e94EEG\u4fe1\u53f7\u7684\u975e\u5e73\u7a33\u7279\u6027\uff0c\u5bb9\u6613\u4e22\u5931\u5185\u5728\u4fe1\u606f\uff0c\u800c\u5bf9\u6bd4\u5b66\u4e60\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u589e\u5f3a\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u589e\u5f3a\u7b56\u7565\u9009\u62e9\u65b9\u6cd5", "method": "\u63d0\u51faRL-BioAug\u6846\u67b6\uff0c\u4f7f\u7528\u6807\u7b7e\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u81ea\u4e3b\u786e\u5b9a\u6700\u4f18\u589e\u5f3a\u7b56\u7565\uff0c\u4ec5\u752810%\u6807\u7b7e\u6570\u636e\u6307\u5bfc\u4ee3\u7406\u7b56\u7565\uff0c\u7f16\u7801\u5668\u4ee5\u4e25\u683c\u81ea\u76d1\u7763\u65b9\u5f0f\u5b66\u4e60\u9c81\u68d2\u8868\u793a", "result": "\u5728Sleep-EDFX\u548cCHB-MIT\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u968f\u673a\u9009\u62e9\u7b56\u7565\u5206\u522b\u63d0\u53479.69%\u548c8.80%\u7684Macro-F1\u5206\u6570\uff1b\u4ee3\u7406\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u9009\u62e9\u4e0d\u540c\u6700\u4f18\u7b56\u7565\uff08\u5982\u7761\u7720\u5206\u671f\u504f\u597d62%\u6982\u7387\u7684\u65f6\u95f4\u63a9\u7801\uff0c\u766b\u75eb\u68c0\u6d4b\u504f\u597d77%\u6982\u7387\u7684\u88c1\u526a\u4e0e\u91cd\u91c7\u6837\uff09", "conclusion": "RL-BioAug\u6709\u6f5c\u529b\u66ff\u4ee3\u4f20\u7edf\u542f\u53d1\u5f0f\u589e\u5f3a\u65b9\u6cd5\uff0c\u5efa\u7acb\u81ea\u4e3b\u6570\u636e\u589e\u5f3a\u65b0\u8303\u5f0f\uff0c\u4e3aEEG\u5bf9\u6bd4\u5b66\u4e60\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u589e\u5f3a\u7b56\u7565\u9009\u62e9\u6846\u67b6"}}
{"id": "2601.14046", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.14046", "abs": "https://arxiv.org/abs/2601.14046", "authors": ["Shikhar Bharadwaj", "Chin-Jou Li", "Yoonjae Kim", "Kwanghee Choi", "Eunjung Yeo", "Ryan Soh-Eun Shim", "Hanyu Zhou", "Brendon Boldt", "Karen Rosero Jacome", "Kalvin Chang", "Darsh Agrawal", "Keer Xu", "Chao-Han Huck Yang", "Jian Zhu", "Shinji Watanabe", "David R. Mortensen"], "title": "PRiSM: Benchmarking Phone Realization in Speech Models", "comment": null, "summary": "Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.", "AI": {"tldr": "PRiSM\u662f\u9996\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5185\u5728\u548c\u5916\u5728\u8bc4\u4f30\u63ed\u793a\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u97f3\u7d20\u611f\u77e5\u65b9\u9762\u7684\u76f2\u70b9\uff0c\u53d1\u73b0\u591a\u8bed\u8a00\u8bad\u7ec3\u3001\u7f16\u7801\u5668-CTC\u6a21\u578b\u7a33\u5b9a\u6027\u4ee5\u53ca\u4e13\u7528\u6a21\u578b\u4f18\u4e8e\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u8bc4\u4f30\u4ec5\u5173\u6ce8\u8868\u9762\u8f6c\u5f55\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u97f3\u7d20\u611f\u77e5\u80fd\u529b\u7684\u6df1\u5165\u8bc4\u4f30\u3002\u9700\u8981\u5efa\u7acb\u6807\u51c6\u5316\u57fa\u51c6\u6765\u66b4\u9732\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u97f3\u7d20\u611f\u77e5\u65b9\u9762\u7684\u76f2\u70b9\uff0c\u63a8\u52a8\u5177\u6709\u9c81\u68d2\u97f3\u7d20\u80fd\u529b\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u6a21\u578b\u53d1\u5c55\u3002", "method": "PRiSM\u57fa\u51c6\u6807\u51c6\u5316\u57fa\u4e8e\u8f6c\u5f55\u7684\u8bc4\u4f30\uff0c\u5e76\u5728\u4e34\u5e8a\u3001\u6559\u80b2\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u901a\u8fc7\u8f6c\u5f55\u548c\u8868\u793a\u63a2\u9488\u8bc4\u4f30\u4e0b\u6e38\u5b9e\u7528\u6027\u3002\u4f7f\u7528\u5185\u5728\u548c\u5916\u5728\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5206\u6790\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u67b6\u6784\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u8bad\u7ec3\u671f\u95f4\u7684\u591a\u8bed\u8a00\u66b4\u9732\u5bf9\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff1b2) \u7f16\u7801\u5668-CTC\u6a21\u578b\u6700\u4e3a\u7a33\u5b9a\uff1b3) \u4e13\u7528\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u4ecd\u4f18\u4e8e\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "PRiSM\u901a\u8fc7\u63d0\u4f9b\u4ee3\u7801\u3001\u914d\u65b9\u548c\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u9886\u57df\u5411\u5177\u6709\u9c81\u68d2\u97f3\u7d20\u80fd\u529b\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u6a21\u578b\u53d1\u5c55\u3002\u591a\u8bed\u8a00\u8bad\u7ec3\u548c\u4e13\u7528\u6a21\u578b\u67b6\u6784\u662f\u5b9e\u73b0\u66f4\u597d\u97f3\u7d20\u611f\u77e5\u7684\u5173\u952e\u3002"}}
{"id": "2601.13989", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13989", "abs": "https://arxiv.org/abs/2601.13989", "authors": ["Wenbo Cao", "Weiwei Zhang"], "title": "A universal linearized subspace refinement framework for neural networks", "comment": null, "summary": "Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.", "AI": {"tldr": "LSR\u662f\u4e00\u79cd\u67b6\u6784\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u6027\u5316\u6b8b\u5dee\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u4e2d\u6c42\u89e3\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u7cbe\u5ea6\uff0c\u65e0\u9700\u4fee\u6539\u7f51\u7edc\u67b6\u6784\u6216\u8bad\u7ec3\u8fc7\u7a0b\u3002", "motivation": "\u5c3d\u7ba1\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u901a\u8fc7\u68af\u5ea6\u65b9\u6cd5\u8bad\u7ec3\uff0c\u4f46\u5176\u6700\u7ec8\u9884\u6d4b\u7cbe\u5ea6\u5f80\u5f80\u8fdc\u672a\u8fbe\u5230\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u53ef\u8fbe\u5230\u7684\u6c34\u5e73\u3002\u68af\u5ea6\u8bad\u7ec3\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5373\u4f7f\u5c40\u90e8\u7ebf\u6027\u5316\u540e\u95ee\u9898\u662f\u51f8\u7684\u3002", "method": "LSR\u5229\u7528\u56fa\u5b9a\u8bad\u7ec3\u7f51\u7edc\u72b6\u6001\u4e0b\u7684Jacobian\u8bf1\u5bfc\u7ebf\u6027\u6b8b\u5dee\u6a21\u578b\uff0c\u5728\u8be5\u5b50\u7a7a\u95f4\u4e2d\u6c42\u89e3\u7b80\u5316\u7684\u76f4\u63a5\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u8ba1\u7b97\u7ebf\u6027\u5316\u6b8b\u5dee\u6a21\u578b\u7684\u5b50\u7a7a\u95f4\u6700\u4f18\u89e3\u3002\u5bf9\u4e8e\u5177\u6709\u590d\u5408\u635f\u5931\u7ed3\u6784\u7684\u7b97\u5b50\u7ea6\u675f\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u5f15\u5165\u8fed\u4ee3LSR\uff0c\u4ea4\u66ff\u8fdb\u884c\u4e00\u6b21\u6027LSR\u548c\u76d1\u7763\u975e\u7ebf\u6027\u5bf9\u9f50\u3002", "result": "LSR\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u8fbe\u5230\u68af\u5ea6\u8bad\u7ec3\u65e0\u6cd5\u5b8c\u5168\u5229\u7528\u7684\u7cbe\u5ea6\u6c34\u5e73\uff0c\u7ecf\u5e38\u5b9e\u73b0\u6570\u91cf\u7ea7\u7684\u8bef\u5dee\u964d\u4f4e\u3002\u5728\u76d1\u7763\u51fd\u6570\u903c\u8fd1\u3001\u6570\u636e\u9a71\u52a8\u7684\u7b97\u5b50\u5b66\u4e60\u548c\u7269\u7406\u4fe1\u606f\u7b97\u5b50\u5fae\u8c03\u7b49\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u635f\u5931\u8bf1\u5bfc\u7684\u6570\u503c\u75c5\u6001\u6027\uff08\u800c\u975e\u975e\u51f8\u6027\u6216\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff09\u662f\u5b9e\u9645\u74f6\u9888\u3002LSR\u901a\u8fc7\u5c06\u975e\u7ebf\u6027\u795e\u7ecf\u8868\u793a\u4e0e\u56fa\u5b9a\u7ebf\u6027\u5316\u70b9\u7684\u964d\u9636\u7ebf\u6027\u6c42\u89e3\u5668\u76f8\u7ed3\u5408\uff0c\u4e3a\u76d1\u7763\u5b66\u4e60\u3001\u7b97\u5b50\u5b66\u4e60\u548c\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6570\u503c\u57fa\u7840\u5e7f\u6cdb\u9002\u7528\u7684\u7cbe\u70bc\u6846\u67b6\u3002"}}
{"id": "2601.14050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14050", "abs": "https://arxiv.org/abs/2601.14050", "authors": ["Yuxin Chen", "Zhengzhou Cai", "Xiangtian Ji", "Weixiang Zhao", "An Zhang", "Xiang Wang", "Tat-Seng Chua"], "title": "Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86MoE\u6a21\u578b\u7684\u591a\u8bed\u8a00\u5904\u7406\u673a\u5236\uff0c\u53d1\u73b0\u8def\u7531\u884c\u4e3a\u4e0e\u8bed\u7cfb\u76f8\u5173\uff0c\u4e13\u5bb6\u4f7f\u7528\u5448\u73b0\u5c42\u6b21\u5316\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8def\u7531\u5f15\u5bfc\u7684\u4f18\u5316\u65b9\u6cd5\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1MoE\u67b6\u6784\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff08\u5982\u8def\u7531\u884c\u4e3a\u548c\u4e13\u5bb6\u4e13\u4e1a\u5316\uff09\u4ee5\u53ca\u8de8\u8bed\u8a00\u5dee\u5f02\u7684\u539f\u56e0\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u6765\u63ed\u793a\u8fd9\u4e9b\u673a\u5236\u3002", "method": "\u5bf9MoE\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u7814\u7a76\u4e0d\u540c\u8bed\u8a00\u548c\u7f51\u7edc\u6df1\u5ea6\u4e0b\u7684\u8def\u7531\u884c\u4e3a\u548c\u4e13\u5bb6\u4e13\u4e1a\u5316\u6a21\u5f0f\uff0c\u5e76\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u63d0\u51fa\u8def\u7531\u5f15\u5bfc\u7684\u8c03\u63a7\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u81ea\u9002\u5e94\u5730\u5c06\u4e2d\u95f4\u5c42\u7684\u8def\u7531\u884c\u4e3a\u5bfc\u5411\u4e0e\u4e3b\u5bfc\u8bed\u8a00\u76f8\u5173\u7684\u5171\u4eab\u4e13\u5bb6\u3002", "result": "\u5206\u6790\u53d1\u73b0MoE\u6a21\u578b\u7684\u591a\u8bed\u8a00\u5904\u7406\u9ad8\u5ea6\u7ed3\u6784\u5316\uff1a\u8def\u7531\u884c\u4e3a\u4e0e\u8bed\u7cfb\u5bf9\u9f50\uff0c\u4e13\u5bb6\u4f7f\u7528\u5448\u73b0\u6e05\u6670\u7684\u5c42\u6b21\u5316\u6a21\u5f0f\uff0c\u9ad8\u8d44\u6e90\u8bed\u8a00\u4f9d\u8d56\u5171\u4eab\u4e13\u5bb6\u800c\u4f4e\u8d44\u6e90\u8bed\u8a00\u66f4\u591a\u4f7f\u7528\u8bed\u8a00\u4e13\u5c5e\u4e13\u5bb6\uff08\u5c3d\u7ba1\u6027\u80fd\u8f83\u5f31\uff09\u3002\u4e2d\u95f4\u5c42\u5e72\u9884\u663e\u793a\u65e9\u671f\u548c\u665a\u671fMoE\u5c42\u652f\u6301\u8bed\u8a00\u7279\u5b9a\u5904\u7406\uff0c\u800c\u4e2d\u95f4\u5c42\u4f5c\u4e3a\u8bed\u8a00\u65e0\u5173\u7684\u5bb9\u91cf\u4e2d\u5fc3\u3002", "conclusion": "\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\u63d0\u51fa\u7684\u8def\u7531\u5f15\u5bfc\u8c03\u63a7\u65b9\u6cd5\u80fd\u591f\u81ea\u9002\u5e94\u5730\u5f15\u5bfc\u4e2d\u95f4\u5c42\u8def\u7531\u884c\u4e3a\uff0c\u5728\u63a8\u7406\u65f6\u5c06\u5176\u5bfc\u5411\u4e0e\u4e3b\u5bfc\u8bed\u8a00\u76f8\u5173\u7684\u5171\u4eab\u4e13\u5bb6\uff0c\u4ece\u800c\u6301\u7eed\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8bed\u8a00\u76f8\u5173\u7684\u8bed\u8a00\u5bf9\u4e0a\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2601.14022", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14022", "abs": "https://arxiv.org/abs/2601.14022", "authors": ["Rodrigo Pereira David", "Luciano Araujo Dourado Filho", "Daniel Marques da Silva", "Jo\u00e3o Alfredo Cal-Braz"], "title": "Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment", "comment": null, "summary": "Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5728\u76f8\u540c\u771f\u5b9e\u9a7e\u9a76\u6761\u4ef6\u4e0b\u516c\u5e73\u6bd4\u8f83\u5185\u71c3\u673a\u8f66\u548c\u7535\u52a8\u8f66\u7684CO2\u6392\u653e", "motivation": "\u9053\u8def\u8fd0\u8f93\u8131\u78b3\u9700\u8981\u4e00\u81f4\u900f\u660e\u7684\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u8f66\u8f86\u6280\u672f\u7684CO2\u6392\u653e\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u76f8\u540c\u9a7e\u9a76\u6761\u4ef6\u4e0b\u516c\u5e73\u8bc4\u4f30\u4e0d\u540c\u52a8\u529b\u7cfb\u7edf", "method": "\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u72ec\u7acb\u8bad\u7ec3ICEV\u548cEV\u6a21\u578b\uff0c\u5b66\u4e60\u4ece\u9a7e\u9a76\u53d8\u91cf\uff08\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u3001\u6e29\u5ea6\uff09\u5230\u5185\u90e8\u6267\u884c\u53d8\u91cf\uff08\u626d\u77e9\u3001\u6cb9\u95e8\uff09\u548c\u77ac\u65f6CO2\u5f53\u91cf\u6392\u653e\u7387\u7684\u6620\u5c04\uff0c\u6784\u5efa\u53cd\u4e8b\u5b9e\u573a\u666f\u8fdb\u884c\u5bf9\u6bd4", "result": "\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u77ac\u65f6\u6392\u653e\u5ea6\u91cf\u6846\u67b6\uff0c\u80fd\u591f\u5728\u76f8\u540c\u9a7e\u9a76\u6761\u4ef6\u4e0b\u516c\u5e73\u8bc4\u4f30\u4e0d\u540c\u52a8\u529b\u7cfb\u7edf\u6280\u672f\uff0c\u4e3a\u8f66\u8f86\u78b3\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u53ef\u6269\u5c55\u57fa\u7840", "conclusion": "\u8be5\u673a\u5668\u5b66\u4e60\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u4fe1\u3001\u6570\u636e\u9a71\u52a8\u7684\u8f66\u8f86\u78b3\u6027\u80fd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u652f\u6301\u5728\u771f\u5b9e\u64cd\u4f5c\u6761\u4ef6\u4e0b\u5bf9\u52a8\u529b\u7cfb\u7edf\u6280\u672f\u8fdb\u884c\u516c\u5e73\u53ef\u91cd\u590d\u7684\u6bd4\u8f83"}}
{"id": "2601.14051", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14051", "abs": "https://arxiv.org/abs/2601.14051", "authors": ["Peter Devine", "Mardhiyah Sanni", "Farid Adilazuarda", "Julieta Gil Loizaga", "Barry Haddow"], "title": "Kakugo: Distillation of Low-Resource Languages into Small Language Models", "comment": null, "summary": "We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.", "AI": {"tldr": "Kakugo\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u7ba1\u9053\uff0c\u4ec5\u9700\u8bed\u8a00\u540d\u79f0\u5373\u53ef\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bad\u7ec3\u901a\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u63d0\u793a\u548c\u7ffb\u8bd1\u6307\u4ee4\u6570\u636e\uff0c\u4e3a54\u79cd\u8bed\u8a00\u521b\u5efa\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\uff0c\u6bcf\u8bed\u8a00\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u3002", "motivation": "\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5f00\u53d1AI\u5de5\u5177\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u9ad8\u6210\u672c\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u65b9\u6cd5\u8ba9\u793e\u533a\u80fd\u591f\u521b\u5efa\u8bed\u8a00\u7279\u5b9a\u7684AI\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5927\u578b\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u63d0\u793a\u5e76\u7ffb\u8bd1\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u521b\u5efa\u8bad\u7ec3\u6570\u636e\uff0c\u7136\u540e\u8bad\u7ec3\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ec5\u9700\u8bed\u8a00\u540d\u79f0\u4f5c\u4e3a\u8f93\u5165\u3002", "result": "\u4e3a54\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u6210\u529f\u521b\u5efa\u4e86\u8bad\u7ec3\u6570\u636e\u548cSLMs\uff0c\u5728\u7ffb\u8bd1\u3001\u5206\u7c7b\u548c\u95ee\u7b54\u7b49NLP\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\uff0c\u6bcf\u8bed\u8a00\u603b\u6210\u672c\u4f4e\u4e8e50\u7f8e\u5143\u3002", "conclusion": "Kakugo\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u4e14\u6613\u4e8e\u8bbf\u95ee\u7684\u65b9\u6cd5\uff0c\u4f7f\u793e\u533a\u80fd\u591f\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5f00\u53d1\u8bed\u8a00\u7279\u5b9a\u7684AI\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u8bed\u8a00AI\u7684\u6c11\u4e3b\u5316\u3002"}}
{"id": "2601.14026", "categories": ["cs.LG", "cs.NE", "math.FA"], "pdf": "https://arxiv.org/pdf/2601.14026", "abs": "https://arxiv.org/abs/2601.14026", "authors": ["Vugar Ismailov"], "title": "Universal Approximation Theorem for Input-Connected Multilayer Perceptrons", "comment": "18 pages, 2 figures, 31 references", "summary": "We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\\mathbb{R}^n$.", "AI": {"tldr": "IC-MLP\u662f\u4e00\u79cd\u65b0\u578b\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u6bcf\u4e2a\u9690\u85cf\u795e\u7ecf\u5143\u9664\u4e86\u63a5\u6536\u524d\u4e00\u5c42\u8f93\u51fa\u5916\uff0c\u8fd8\u63a5\u6536\u539f\u59cb\u8f93\u5165\u7684\u4eff\u5c04\u8fde\u63a5\u3002\u8bba\u6587\u8bc1\u660e\u4e86\u8be5\u67b6\u6784\u5728\u6fc0\u6d3b\u51fd\u6570\u975e\u7ebf\u6027\u65f6\u7684\u901a\u7528\u903c\u8fd1\u80fd\u529b\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u6bcf\u4e2a\u9690\u85cf\u5c42\u6dfb\u52a0\u539f\u59cb\u8f93\u5165\u7684\u76f4\u8fde\u8fde\u63a5\uff0c\u589e\u5f3a\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u7814\u7a76\u5176\u7406\u8bba\u6027\u8d28\u3002", "method": "\u5f15\u5165\u8f93\u5165\u8fde\u63a5\u591a\u5c42\u611f\u77e5\u673a\uff08IC-MLP\uff09\uff0c\u5728\u4f20\u7edfMLP\u57fa\u7840\u4e0a\u4e3a\u6bcf\u4e2a\u9690\u85cf\u795e\u7ecf\u5143\u6dfb\u52a0\u4ece\u539f\u59cb\u8f93\u5165\u7684\u4eff\u5c04\u8fde\u63a5\u3002\u9996\u5148\u5728\u5355\u53d8\u91cf\u8bbe\u7f6e\u4e0b\u5206\u6790\uff0c\u7ed9\u51fa\u4efb\u610f\u6709\u9650\u9690\u85cf\u5c42\u7684\u663e\u5f0f\u516c\u5f0f\uff0c\u7136\u540e\u6269\u5c55\u5230\u591a\u7ef4\u8f93\u5165\u3002", "result": "\u8bc1\u660e\u4e86\u6df1\u5ea6IC-MLP\u5728\u6fc0\u6d3b\u51fd\u6570\u975e\u7ebf\u6027\u65f6\uff0c\u80fd\u591f\u903c\u8fd1\u95ed\u533a\u95f4\u4e0a\u7684\u4efb\u610f\u8fde\u7eed\u51fd\u6570\uff08\u5355\u53d8\u91cf\uff09\u548c\u7d27\u81f4\u5b50\u96c6\u4e0a\u7684\u8fde\u7eed\u51fd\u6570\uff08\u591a\u7ef4\uff09\uff0c\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u3002", "conclusion": "IC-MLP\u662f\u4e00\u79cd\u8868\u8fbe\u80fd\u529b\u5f3a\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u8f93\u5165\u76f4\u8fde\u673a\u5236\uff0c\u5728\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u6761\u4ef6\u4e0b\u5177\u5907\u901a\u7528\u903c\u8fd1\u80fd\u529b\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2601.14033", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14033", "abs": "https://arxiv.org/abs/2601.14033", "authors": ["Xiaochen Zhu", "Mayuri Sridhar", "Srinivas Devadas"], "title": "PAC-Private Responses with Adversarial Composition", "comment": "16 pages, 3 figures", "summary": "Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.\n  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.\n  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePAC\u9690\u79c1\u7684\u6a21\u578b\u8f93\u51fa\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u4e92\u4fe1\u606f\u5b9e\u73b0\u5bf9\u6297\u6027\u67e5\u8be2\u4e0b\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5728\u6781\u5c0f\u7684\u6bcf\u67e5\u8be2\u9690\u79c1\u9884\u7b97\u4e0b\u4fdd\u6301\u9ad8\u6a21\u578b\u6548\u7528\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u901a\u8fc7API\u90e8\u7f72\uff0c\u4f20\u7edf\u7684\u6743\u91cd\u9690\u79c1\u65b9\u6cd5\uff08\u5982DP-SGD\uff09\u5728API\u573a\u666f\u4e0b\u4f1a\u4ea7\u751f\u4e0d\u5fc5\u8981\u7684\u566a\u58f0\u5e76\u964d\u4f4e\u6548\u7528\u3002\u6a21\u578b\u6743\u91cd\u5bf9\u8bad\u7ec3\u6570\u636e\u654f\u611f\uff0c\u4f46\u6a21\u578b\u5bf9\u7279\u5b9a\u8f93\u5165\u7684\u8f93\u51fa\u7ef4\u5ea6\u66f4\u4f4e\u4e14\u66f4\u7a33\u5b9a\uff0c\u56e0\u6b64\u76f4\u63a5\u5728\u6a21\u578b\u8f93\u51fa\u4e0a\u5b9e\u65bd\u9690\u79c1\u4fdd\u62a4\u66f4\u6709\u4f18\u52bf\u3002", "method": "\u91c7\u7528PAC\u9690\u79c1\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u4e92\u4fe1\u606f\u5b9e\u73b0\u5b9e\u4f8b\u7ea7\u9690\u79c1\u4fdd\u62a4\u3002\u63d0\u51fa\u65b0\u7b97\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u566a\u58f0\u6821\u51c6\u5b9e\u73b0\u5bf9\u6297\u6027\u7ec4\u5408\uff0c\u8bc1\u660e\u4e92\u4fe1\u606f\u4fdd\u8bc1\u5728\u81ea\u9002\u5e94\u548c\u5bf9\u6297\u6027\u67e5\u8be2\u4e0b\u7ebf\u6027\u7d2f\u79ef\u3002\u8be5\u65b9\u6cd5\u7279\u522b\u5956\u52b1\u8f93\u51fa\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u964d\u4f4e\u566a\u58f0\u6c34\u5e73\u3002", "result": "\u5728\u8868\u683c\u3001\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u6781\u5c0f\u7684\u6bcf\u67e5\u8be2\u9690\u79c1\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7528\uff1aCIFAR-10\u4e0a\u8fbe\u523087.79%\u51c6\u786e\u7387\uff0c\u6bcf\u6b65MI\u9884\u7b97\u4e3a2^{-32}\u3002\u670d\u52a1100\u4e07\u67e5\u8be2\u65f6\uff0c\u6210\u5458\u63a8\u7406\u653b\u51fb\u6210\u529f\u7387\u4e0a\u9650\u4e3a51.08%\uff0c\u76f8\u5f53\u4e8e(0.04, 10^{-5})-DP\u4fdd\u8bc1\u3002\u901a\u8fc7\u79c1\u6709\u54cd\u5e94\u6807\u6ce8\u516c\u5171\u6570\u636e\u84b8\u998f\u6a21\u578b\uff0c\u5728ImageNet\u5b50\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728CIFAR-10\u4e0a\u8fbe\u523091.86%\u51c6\u786e\u7387\uff0cMIA\u6210\u529f\u7387\u4e0a\u965050.49%\uff0c\u76f8\u5f53\u4e8e(0.02,10^{-5})-DP\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u8f93\u51fa\u5c42\u9762\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u89e3\u51b3\u4e86\u5bf9\u6297\u6027\u67e5\u8be2\u7ec4\u5408\u7684\u6311\u6218\uff0c\u5728\u6781\u5c0f\u7684\u9690\u79c1\u9884\u7b97\u4e0b\u4fdd\u6301\u4e86\u9ad8\u6a21\u578b\u6548\u7528\uff0c\u4e3aAPI\u90e8\u7f72\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14105", "abs": "https://arxiv.org/abs/2601.14105", "authors": ["Olesya Razuvayevskaya", "Kalina Bontcheva"], "title": "Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks", "comment": "In Proceedings of the ACM Web Conference 2026 (WWW 2026)", "summary": "This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means", "AI": {"tldr": "\u5927\u89c4\u6a21\u6bd4\u8f83\u7814\u7a76\u53d1\u73b0\uff0c\u793e\u533a\u64b0\u5199\u7684\u4e8b\u5b9e\u6838\u67e5\uff08\u5982Community Notes\uff09\u4e0e\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u5728\u8bf4\u670d\u6280\u5de7\u4f7f\u7528\u4e0a\u6ca1\u6709\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u4fee\u8f9e\u5dee\u5f02\uff0c\u4e14\u793e\u533a\u8bc4\u5206\u8005\u80fd\u6709\u6548\u8bc6\u522b\u548c\u60e9\u7f5a\u6709\u95ee\u9898\u7684\u4fee\u8f9e\u624b\u6bb5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u68c0\u9a8c\u5148\u524d\u5047\u8bbe\u2014\u2014\u793e\u533a\u64b0\u5199\u7684\u4e8b\u5b9e\u6838\u67e5\u662f\u5426\u6bd4\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u66f4\u4f9d\u8d56\u4e3b\u89c2\u6216\u8bf4\u670d\u6027\u8bed\u8a00\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u4e8b\u5b9e\u6838\u67e5\u751f\u6001\u7cfb\u7edf\u4e2d\u8bf4\u670d\u6280\u5de7\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u6765\u81eaCommunity Notes\u3001EUvsDisinfo\u548cDatabase of Known Fakes\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u91cf\u5316\u5206\u6790\u8fd9\u4e9b\u4e8b\u5b9e\u6838\u67e5\u751f\u6001\u7cfb\u7edf\u4e2d\u8bf4\u670d\u6280\u5de7\u7684\u666e\u904d\u6027\u548c\u7c7b\u578b\u3002", "result": "1. \u6ca1\u6709\u8bc1\u636e\u8868\u660eCommunity Notes\u6bd4\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u5305\u542b\u66f4\u591a\u8bf4\u670d\u6280\u5de7\uff1b2. \u53d1\u73b0\u793e\u533a\u548c\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u4fee\u8f9e\u5dee\u5f02\uff0c\u53cd\u6620\u673a\u6784\u89c4\u8303\u548c\u4e3b\u9898\u8986\u76d6\u7684\u4e0d\u540c\uff1b3. \u793e\u533a\u8bc4\u5206\u8005\u80fd\u6709\u6548\u60e9\u7f5a\u6709\u95ee\u9898\u7684\u4fee\u8f9e\u624b\u6bb5\uff0c\u5c3d\u7ba1\u5305\u542b\u66f4\u591a\u8bf4\u670d\u5143\u7d20\u7684\u7b14\u8bb0\u603b\u4f53\u8bc4\u5206\u7565\u9ad8\u3002", "conclusion": "\u793e\u533a\u64b0\u5199\u7684\u4e8b\u5b9e\u6838\u67e5\u5728\u8bf4\u670d\u6280\u5de7\u4f7f\u7528\u4e0a\u4e0e\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u76f8\u5f53\uff0c\u4f46\u5b58\u5728\u4fee\u8f9e\u98ce\u683c\u5dee\u5f02\uff0c\u4e14\u793e\u533a\u8bc4\u5206\u673a\u5236\u80fd\u6709\u6548\u76d1\u7ba1\u4fee\u8f9e\u8d28\u91cf\uff0c\u8fd9\u5bf9\u4e8b\u5b9e\u6838\u67e5\u751f\u6001\u7cfb\u7edf\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.14053", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.14053", "abs": "https://arxiv.org/abs/2601.14053", "authors": ["Badri N. Patro", "Vijay S. Agneeswaran"], "title": "LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems", "comment": null, "summary": "The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.", "AI": {"tldr": "LLMOrbit\u662f\u4e00\u4e2a\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff082019-2025\uff09\u7684\u7efc\u5408\u6027\u5faa\u73af\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e8650\u591a\u4e2a\u6a21\u578b\uff0c\u8bc6\u522b\u4e86\u4e09\u5927\u5371\u673a\uff08\u6570\u636e\u7a00\u7f3a\u3001\u6210\u672c\u6fc0\u589e\u3001\u80fd\u8017\u4e0d\u53ef\u6301\u7eed\uff09\u548c\u516d\u5927\u7a81\u7834\u8303\u5f0f\uff0c\u63ed\u793a\u4e86\u4e09\u4e2a\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u9886\u57df\u6b63\u7ecf\u5386\u4ece\u57fa\u7840Transformer\u67b6\u6784\u5230\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u63a8\u7406\u7cfb\u7edf\u7684\u9769\u547d\u3002\u9700\u8981\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u8109\u7edc\uff0c\u5206\u6790\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\uff08\u6570\u636e\u3001\u6210\u672c\u3001\u80fd\u8017\u5371\u673a\uff09\uff0c\u5e76\u63a2\u7d22\u7a81\u7834\"\u6269\u5c55\u5899\"\u7684\u6709\u6548\u8def\u5f84\u3002", "method": "\u63d0\u51faLLMOrbit\u5faa\u73af\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u516b\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u8f68\u9053\u7ef4\u5ea6\u5206\u67902019-2025\u5e74\u95f450\u591a\u4e2a\u6a21\u578b\u3002\u91c7\u7528\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u6db5\u76d6\u67b6\u6784\u521b\u65b0\u3001\u8bad\u7ec3\u65b9\u6cd5\u3001\u6548\u7387\u6a21\u5f0f\uff0c\u5e76\u7cfb\u7edf\u5206\u6790\u7a81\u7834\u6269\u5c55\u9650\u5236\u7684\u516d\u5927\u6280\u672f\u8303\u5f0f\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u5927\u5371\u673a\uff1a\u6570\u636e\u7a00\u7f3a\uff082026-2028\u5e74\u8017\u5c3d9-27T tokens\uff09\u3001\u6210\u672c\u6307\u6570\u589e\u957f\uff085\u5e74\u5185\u4ece300\u4e07\u52303\u4ebf\u7f8e\u5143+\uff09\u3001\u80fd\u8017\u4e0d\u53ef\u6301\u7eed\uff08\u589e\u52a022\u500d\uff09\u3002\u53d1\u73b0\u516d\u5927\u7a81\u7834\u8303\u5f0f\uff1a\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u3001\u91cf\u5316\u3001\u5206\u5e03\u5f0f\u8fb9\u7f18\u8ba1\u7b97\u3001\u6a21\u578b\u878d\u5408\u3001\u9ad8\u6548\u8bad\u7ec3\u3001\u5c0f\u578b\u4e13\u7528\u6a21\u578b\u3002\u63ed\u793a\u4e09\u4e2a\u8303\u5f0f\u8f6c\u53d8\uff1a\u540e\u8bad\u7ec3\u589e\u76ca\u3001\u6548\u7387\u9769\u547d\u3001\u6c11\u4e3b\u5316\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u6b63\u9762\u4e34\u6839\u672c\u6027\u6269\u5c55\u9650\u5236\uff0c\u4f46\u901a\u8fc7\u6280\u672f\u521b\u65b0\uff08\u7279\u522b\u662f\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u3001\u91cf\u5316\u3001\u6548\u7387\u4f18\u5316\u7b49\u8303\u5f0f\uff09\u548c\u5f00\u6e90\u6c11\u4e3b\u5316\u8d8b\u52bf\uff0c\u80fd\u591f\u7a81\u7834\"\u6269\u5c55\u5899\"\u3002\u672a\u6765\u5c06\u4ece\u88ab\u52a8\u751f\u6210\u8f6c\u5411\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u540e\u8bad\u7ec3\u6280\u672f\u5c06\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2601.14112", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14112", "abs": "https://arxiv.org/abs/2601.14112", "authors": ["George Mihaila"], "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns", "comment": null, "summary": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.", "AI": {"tldr": "ExpNet\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u5b66\u4e60\u4eceTransformer\u6ce8\u610f\u529b\u6a21\u5f0f\u5230token\u91cd\u8981\u6027\u5206\u6570\u7684\u663e\u5f0f\u6620\u5c04\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u6ce8\u610f\u529b\u7279\u5f81\u7ec4\u5408\uff0c\u4f18\u4e8e\u4f9d\u8d56\u9884\u5b9a\u4e49\u89c4\u5219\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740Transformer\u6a21\u578b\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\uff0c\u53ef\u89e3\u91caAI\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6ce8\u610f\u529b\u89e3\u91ca\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5b9a\u4e49\u7684\u805a\u5408\u7b56\u7565\u548c\u56fa\u5b9a\u5f52\u56e0\u89c4\u5219\uff0c\u800c\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\uff08\u5982LIME\u3001SHAP\uff09\u5c06\u6a21\u578b\u89c6\u4e3a\u9ed1\u76d2\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faExplanation Network (ExpNet)\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u5b66\u4e60\u4eceTransformer\u6ce8\u610f\u529b\u6a21\u5f0f\u5230token\u7ea7\u91cd\u8981\u6027\u5206\u6570\u7684\u663e\u5f0f\u6620\u5c04\u3002\u8be5\u65b9\u6cd5\u81ea\u52a8\u53d1\u73b0\u6700\u4f18\u6ce8\u610f\u529b\u7279\u5f81\u7ec4\u5408\uff0c\u800c\u975e\u4f9d\u8d56\u9884\u5b9a\u4e49\u89c4\u5219\u3002", "result": "\u5728\u8de8\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u8bc4\u4f30ExpNet\uff0c\u5e76\u4e0e\u6db5\u76d6\u56db\u4e2a\u65b9\u6cd5\u5bb6\u65cf\u7684\u5e7f\u6cdb\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6280\u672f\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "ExpNet\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u81ea\u52a8\u5316\u548c\u6709\u6548\u7684Transformer\u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u6ce8\u610f\u529b\u7279\u5f81\u7684\u6700\u4f73\u7ec4\u5408\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u89c4\u5219\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002"}}
{"id": "2601.14092", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.14092", "abs": "https://arxiv.org/abs/2601.14092", "authors": ["Babacar Toure", "Dimitrios Tsilimantos", "Omid Esrafilian", "Marios Kountouris"], "title": "Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning", "comment": null, "summary": "Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u6570\u636e\u6536\u96c6\u4e0e\u80fd\u8017\u6743\u8861\u7684\u8def\u5f84\u89c4\u5212\uff0c\u65e0\u9700\u4fe1\u9053\u5148\u9a8c\u77e5\u8bc6\uff0c\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u65e0\u7ebf\u7f51\u7edc\u6570\u636e\u6536\u96c6\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u73b0\u6709AI\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3001\u5ffd\u7565\u591a\u76ee\u6807\u7279\u6027\u3001\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u663e\u5f0f\u5904\u7406\u6570\u636e\u6536\u96c6\u4e0e\u80fd\u8017\u7684\u6743\u8861\uff0c\u65e0\u9700\u65e0\u7ebf\u4fe1\u9053\u5148\u9a8c\u77e5\u8bc6\uff0c\u5355\u4e00\u6a21\u578b\u53ef\u9002\u5e94\u4e0d\u540c\u504f\u597d\u548c\u52a8\u6001\u53c2\u6570\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u91cd\u8bad\u7ec3\u3002", "result": "\u5927\u91cf\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u6a21\u578b\u7d27\u51d1\u6027\u3001\u6837\u672c\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u591a\u76ee\u6807\u6743\u8861\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.14121", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14121", "abs": "https://arxiv.org/abs/2601.14121", "authors": ["Jonathan Tonglet", "Iryna Gurevych", "Tinne Tuytelaars", "Marie-Francine Moens"], "title": "NewsRECON: News article REtrieval for image CONtextualization", "comment": "Preprint under review. Code available at https://github.com/jtonglet/arxiv2025-newsrecon", "summary": "Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.", "AI": {"tldr": "NewsRECON\u901a\u8fc7\u5c06\u65b0\u95fb\u56fe\u7247\u94fe\u63a5\u5230\u76f8\u5173\u6587\u7ae0\uff0c\u4ece\u6587\u7ae0\u5143\u6570\u636e\u63a8\u65ad\u62cd\u6444\u65f6\u95f4\u548c\u5730\u70b9\uff0c\u89e3\u51b3\u4e86\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u5931\u8d25\u65f6\u7684\u65b0\u95fb\u56fe\u7247\u65f6\u7a7a\u5b9a\u4f4d\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u53cd\u5411\u56fe\u50cf\u641c\u7d22(RIS)\uff0c\u4f46RIS\u7ecf\u5e38\u65e0\u6cd5\u8fd4\u56de\u7ed3\u679c\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u89e3\u51b3RIS\u8bc1\u636e\u4e0d\u53ef\u7528\u65f6\u7684\u65b0\u95fb\u56fe\u7247\u65f6\u7a7a\u5b9a\u4f4d\u6311\u6218\u3002", "method": "\u63d0\u51faNewsRECON\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u53cc\u7f16\u7801\u5668\u68c0\u7d22\u4e8b\u4ef6\u76f8\u5173\u6587\u7ae0\uff1b2) \u4f7f\u7528\u4e24\u4e2a\u4ea4\u53c9\u7f16\u7801\u5668\u6309\u4f4d\u7f6e\u548c\u4e8b\u4ef6\u4e00\u81f4\u6027\u91cd\u6392\u5e8f\u6587\u7ae0\uff1b3) \u57fa\u4e8e\u8d85\u8fc790,000\u7bc7\u6587\u7ae0\u7684\u8bed\u6599\u5e93\u3002", "result": "\u5728TARA\u548c5Pils-OOC\u6570\u636e\u96c6\u4e0a\uff0cNewsRECON\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u65f6\uff0c\u5728RIS\u8bc1\u636e\u4e0d\u53ef\u7528\u60c5\u51b5\u4e0b\u8fbe\u5230\u65b0\u7684SOTA\u7ed3\u679c\u3002", "conclusion": "NewsRECON\u4e3aRIS\u4e0d\u53ef\u7528\u65f6\u7684\u65b0\u95fb\u56fe\u7247\u65f6\u7a7a\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u94fe\u63a5\u56fe\u7247\u5230\u65b0\u95fb\u6587\u7ae0\u5e76\u5229\u7528\u6587\u7ae0\u5143\u6570\u636e\u63a8\u65ad\u65f6\u7a7a\u4fe1\u606f\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.14099", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14099", "abs": "https://arxiv.org/abs/2601.14099", "authors": ["Shi-Shun Chen", "Xiao-Yang Li", "Enrico Zio"], "title": "Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping", "comment": null, "summary": "Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u89e3\u51b3\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u53d8\u91cf\u95f4\u65f6\u6ede\u56e0\u679c\u548c\u76f8\u4e92\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u5347\u8f6f\u6d4b\u91cf\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1) \u5ffd\u7565\u53d8\u91cf\u95f4\u7684\u65f6\u6ede\u56e0\u679c\u5173\u7cfb\uff0c\u5927\u591a\u53ea\u8003\u8651\u540c\u4e00\u65f6\u95f4\u7ef4\u5ea6\u7684\u56e0\u679c\uff1b2) \u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u5047\u8bbe\u53d8\u91cf\u53bb\u76f8\u5173\uff0c\u4f46\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u53d8\u91cf\u5f80\u5f80\u76f8\u4e92\u4f9d\u8d56\u3002\u8fd9\u5bfc\u81f4\u57fa\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8f6f\u6d4b\u91cf\u6a21\u578b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff1a1) \u4f7f\u7528\u65f6\u6ede\u6536\u655b\u4ea4\u53c9\u6620\u5c04(TDCCM)\u8fdb\u884c\u603b\u56e0\u679c\u63a8\u65ad\uff1b2) \u4f7f\u7528\u65f6\u6ede\u504f\u4ea4\u53c9\u6620\u5c04(TDPCM)\u8fdb\u884c\u76f4\u63a5\u56e0\u679c\u63a8\u65ad\uff1b3) \u63d0\u51fa\u5ba2\u89c2\u7279\u5f81\u9009\u62e9\u7b56\u7565\uff0c\u57fa\u4e8e\u9a8c\u8bc1\u96c6\u6a21\u578b\u6027\u80fd\u81ea\u52a8\u786e\u5b9a\u56e0\u679c\u9608\u503c\u5e76\u9009\u62e9\u56e0\u679c\u7279\u5f81\u3002", "result": "\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff1aTDCCM\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5e73\u5747\u6027\u80fd\uff0c\u800cTDPCM\u5728\u6700\u5dee\u60c5\u51b5\u4e0b\u6539\u5584\u4e86\u8f6f\u6d4b\u91cf\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002\u4ee3\u7801\u5df2\u5728GitHub\u516c\u5f00\u3002", "conclusion": "\u63d0\u51fa\u7684\u65f6\u6ede\u4ea4\u53c9\u6620\u5c04\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1a\u8fc7\u7a0b\u4e2d\u53d8\u91cf\u65f6\u6ede\u56e0\u679c\u548c\u76f8\u4e92\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8f6f\u6d4b\u91cf\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5de5\u4e1a\u8fc7\u7a0b\u76d1\u63a7\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002"}}
{"id": "2601.14123", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.14123", "abs": "https://arxiv.org/abs/2601.14123", "authors": ["Sofia Bennani", "Charles Moslonka"], "title": "A Systematic Analysis of Chunking Strategies for Reliable Question Answering", "comment": "3 pages, 2 figures, 1 table, pre-print", "summary": "We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a \"context cliff\" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).", "AI": {"tldr": "\u7814\u7a76\u6587\u6863\u5206\u5757\u7b56\u7565\u5bf9\u5de5\u4e1aRAG\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u53d1\u73b0\u53e5\u5b50\u5206\u5757\u662f\u6700\u5177\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\uff0c\u91cd\u53e0\u5206\u5757\u65e0\u5b9e\u9645\u6536\u76ca\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u5b58\u5728\"\u60ac\u5d16\u6548\u5e94\"\uff08\u8d85\u8fc72.5k token\u8d28\u91cf\u4e0b\u964d\uff09", "motivation": "\u5de5\u4e1a\u5b9e\u8df5\u4e2dRAG\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u542f\u53d1\u5f0f\u5206\u5757\u7b56\u7565\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7aef\u5230\u7aef\u8bc4\u4f30\uff0c\u4e3a\u5de5\u4e1a\u90e8\u7f72\u63d0\u4f9b\u57fa\u4e8e\u5b9e\u8bc1\u7684\u5206\u5757\u7b56\u7565\u6307\u5bfc\uff0c\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u4f18\u5316\u3002", "method": "\u5728Natural Questions\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u8bc4\u4f30\uff0c\u7cfb\u7edf\u53d8\u5316\u5206\u5757\u65b9\u6cd5\uff08token\u3001\u53e5\u5b50\u3001\u8bed\u4e49\u3001\u4ee3\u7801\uff09\u3001\u5206\u5757\u5927\u5c0f\u3001\u91cd\u53e0\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002\u91c7\u7528\u6807\u51c6\u5de5\u4e1a\u8bbe\u7f6e\uff1aSPLADE\u68c0\u7d22\u548cMistral-8B\u751f\u6210\u5668\u3002", "result": "1) \u91cd\u53e0\u5206\u5757\u65e0\u5b9e\u9645\u6536\u76ca\u4e14\u589e\u52a0\u7d22\u5f15\u6210\u672c\uff1b2) \u53e5\u5b50\u5206\u5757\u662f\u6700\u5177\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\uff0c\u5728\u7ea65k token\u5185\u4e0e\u8bed\u4e49\u5206\u5757\u6548\u679c\u76f8\u5f53\uff1b3) \u4e0a\u4e0b\u6587\u957f\u5ea6\u5b58\u5728\"\u60ac\u5d16\u6548\u5e94\"\uff0c\u8d85\u8fc7\u7ea62.5k token\u8d28\u91cf\u4e0b\u964d\uff1b4) \u6700\u4f18\u4e0a\u4e0b\u6587\u957f\u5ea6\u53d6\u51b3\u4e8e\u76ee\u6807\uff08\u8bed\u4e49\u8d28\u91cf\u5728\u5c0f\u4e0a\u4e0b\u6587\u8fbe\u5230\u5cf0\u503c\uff0c\u7cbe\u786e\u5339\u914d\u9700\u8981\u66f4\u5927\u4e0a\u4e0b\u6587\uff09\u3002", "conclusion": "\u4e3a\u5de5\u4e1aRAG\u90e8\u7f72\u63d0\u4f9b\u5177\u4f53\u5efa\u8bae\uff1a\u907f\u514d\u4f7f\u7528\u91cd\u53e0\u5206\u5757\uff0c\u4f18\u5148\u91c7\u7528\u53e5\u5b50\u5206\u5757\uff0c\u63a7\u5236\u4e0a\u4e0b\u6587\u957f\u5ea6\u57282.5k token\u4ee5\u5185\uff0c\u6839\u636e\u5177\u4f53\u76ee\u6807\uff08\u8bed\u4e49\u8d28\u91cfvs\u7cbe\u786e\u5339\u914d\uff09\u8c03\u6574\u5206\u5757\u7b56\u7565\uff0c\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u6700\u5927\u5316\u3002"}}
{"id": "2601.14115", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14115", "abs": "https://arxiv.org/abs/2601.14115", "authors": ["Liangsi Lu", "Jingchao Wang", "Zhaorong Dai", "Hanqian Liu", "Yang Shi"], "title": "Riemannian Liquid Spatio-Temporal Graph Network", "comment": "This paper has been accepted to The Web Conference 2026", "summary": "Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io", "AI": {"tldr": "RLSTG\u5c06\u8fde\u7eed\u65f6\u95f4\u6db2\u4f53\u52a8\u529b\u5b66\u4e0e\u9ece\u66fc\u6d41\u5f62\u51e0\u4f55\u5f52\u7eb3\u504f\u7f6e\u76f8\u7ed3\u5408\uff0c\u5728\u66f2\u9762\u4e0a\u5efa\u6a21\u56fe\u6f14\u5316\uff0c\u514b\u670d\u4e86\u4f20\u7edfLTC\u7f51\u7edc\u5c40\u9650\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u7684\u7f3a\u9677\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u590d\u6742\u56fe\u7ed3\u6784\u7684\u672c\u8d28\u51e0\u4f55\u7279\u5f81\u3002", "motivation": "\u4f20\u7edfLiquid Time-Constant\u7f51\u7edc\uff08LTCs\uff09\u867d\u7136\u64c5\u957f\u5efa\u6a21\u4e0d\u89c4\u5219\u91c7\u6837\u52a8\u6001\uff0c\u4f46\u5c40\u9650\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u5728\u5904\u7406\u5177\u6709\u56fa\u6709\u975e\u6b27\u51e0\u91cc\u5f97\u7ed3\u6784\uff08\u5982\u5c42\u6b21\u7ed3\u6784\u548c\u5faa\u73af\uff09\u7684\u771f\u5b9e\u4e16\u754c\u56fe\u65f6\uff0c\u4f1a\u4ea7\u751f\u663e\u8457\u7684\u51e0\u4f55\u5931\u771f\uff0c\u964d\u4f4e\u8868\u793a\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u9ece\u66fc\u6db2\u4f53\u65f6\u7a7a\u56fe\u7f51\u7edc\uff08RLSTG\uff09\uff0c\u5728\u9ece\u66fc\u6d41\u5f62\u4e0a\u76f4\u63a5\u6784\u5efa\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u6765\u5efa\u6a21\u56fe\u6f14\u5316\uff0c\u5c06\u8fde\u7eed\u65f6\u95f4\u6db2\u4f53\u52a8\u529b\u5b66\u4e0e\u9ece\u66fc\u6d41\u5f62\u7684\u51e0\u4f55\u5f52\u7eb3\u504f\u7f6e\u76f8\u7edf\u4e00\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRLSTG\u901a\u8fc7\u7ed3\u5408\u5148\u8fdb\u7684\u65f6\u95f4\u52a8\u529b\u5b66\u548c\u9ece\u66fc\u7a7a\u95f4\u8868\u793a\uff0c\u5728\u5177\u6709\u590d\u6742\u7ed3\u6784\u7684\u56fe\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u5c06LTC\u7684\u7a33\u5b9a\u6027\u5b9a\u7406\u6269\u5c55\u5230\u9ece\u66fc\u9886\u57df\u3002", "conclusion": "RLSTG\u6846\u67b6\u6210\u529f\u5730\u5c06\u8fde\u7eed\u65f6\u95f4\u6db2\u4f53\u52a8\u529b\u5b66\u4e0e\u9ece\u66fc\u51e0\u4f55\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u66f4\u5fe0\u5b9e\u5730\u6355\u6349\u9759\u6001\u548c\u52a8\u6001\u65f6\u7a7a\u56fe\u7684\u5185\u5728\u51e0\u4f55\u7ed3\u6784\uff0c\u4e3a\u5904\u7406\u590d\u6742\u975e\u6b27\u51e0\u91cc\u5f97\u56fe\u7ed3\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14124", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14124", "abs": "https://arxiv.org/abs/2601.14124", "authors": ["Saad Mankarious", "Aya Zirikly"], "title": "Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic", "comment": null, "summary": "Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u98ce\u683c\u8fc1\u79fb\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u6570\u636e\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b58\u5728\u8f93\u51fa\u591a\u6837\u6027\u6709\u9650\u548c\u4f20\u64ad\u8bad\u7ec3\u6570\u636e\u504f\u89c1\u7684\u95ee\u9898\u3002\u7279\u522b\u662f\u5728\u5fc3\u7406\u5065\u5eb7\u5206\u6790\u9886\u57df\uff0c\u6570\u636e\u7a00\u7f3a\u548c\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\uff08\u5982\u6027\u522b\u4e0d\u5e73\u8861\uff09\u4e25\u91cd\u5f71\u54cd\u4e86\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u65e0\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u65b9\u6cd5\uff0c\u5c06\u504f\u89c1\u7f13\u89e3\u89c6\u4e3a\u98ce\u683c\u8fc1\u79fb\u95ee\u9898\u3002\u4f7f\u7528CARMA\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u8bed\u6599\u5e93\uff0c\u9488\u5bf9\u7537\u6027\u5230\u5973\u6027\u7684\u98ce\u683c\u8fc1\u79fb\u6765\u589e\u5f3a\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5973\u6027\u4f5c\u8005\u5185\u5bb9\u3002\u6784\u5efa\u4e94\u4e2a\u6570\u636e\u96c6\u6355\u6349\u963f\u62c9\u4f2f\u8bed\u6027\u522b\u8868\u8fbe\u7684\u4e0d\u540c\u8bed\u8a00\u548c\u8bed\u4e49\u65b9\u9762\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u8bbe\u7f6e\u8bad\u7ec3\u72ec\u7acb\u7684\u6269\u6563\u6a21\u578b\u3002", "result": "\u5b9a\u91cf\u8bc4\u4f30\u663e\u793a\u6e90\u6587\u672c\u4e0e\u751f\u6210\u6587\u672c\u4e4b\u95f4\u5177\u6709\u9ad8\u5ea6\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u5b58\u5728\u6709\u610f\u4e49\u7684\u8868\u9762\u98ce\u683c\u5dee\u5f02\u3002\u5b9a\u6027\u5206\u6790\u8bc1\u5b9e\u4e86\u8bed\u8a00\u4e0a\u5408\u7406\u7684\u6027\u522b\u8f6c\u6362\u3002\u6269\u6563\u6a21\u578b\u80fd\u591f\u751f\u6210\u9ad8\u71b5\u3001\u8bed\u4e49\u5fe0\u5b9e\u7684\u5408\u6210\u6570\u636e\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u8bad\u7ec3LLMs\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u98ce\u683c\u8fc1\u79fb\u4e3a\u7f13\u89e3\u654f\u611f\u3001\u4f4e\u8d44\u6e90\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u4e2d\u7684\u6027\u522b\u504f\u89c1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u3002"}}
{"id": "2601.14152", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14152", "abs": "https://arxiv.org/abs/2601.14152", "authors": ["Hyunjong Ok", "Jaeho Lee"], "title": "Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models", "comment": "preprint", "summary": "Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u9898\u4e2d\uff0c\u5c06\u4e0a\u4e0b\u6587\u653e\u5728\u95ee\u9898\u548c\u9009\u9879\u4e4b\u524d\uff08CQO\uff09\u6bd4\u76f8\u53cd\u987a\u5e8f\uff08QOC\uff09\u8868\u73b0\u597d14%\u4ee5\u4e0a\uff0c\u539f\u56e0\u662f\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u5bfc\u81f4QOC\u4e2d\u9009\u9879\u65e0\u6cd5\u5173\u6ce8\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u63d0\u793a\u7ed3\u6784\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u654f\u611f\u6027\uff0c\u4f46\u5176\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u4e00\u4e2a\u663e\u8457\u73b0\u8c61\uff1a\u5728\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\u4e2d\uff0c\u4e0d\u540c\u63d0\u793a\u987a\u5e8f\u4f1a\u5bfc\u81f4\u5de8\u5927\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u67b6\u6784\u5206\u6790\uff0c\u8bc6\u522b\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6838\u5fc3\u4f5c\u7528\u3002\u5728QOC\u63d0\u793a\u4e2d\uff0c\u56e0\u679c\u63a9\u7801\u963b\u6b62\u9009\u9879\u6807\u8bb0\u5173\u6ce8\u4e0a\u4e0b\u6587\uff0c\u9020\u6210\u4fe1\u606f\u74f6\u9888\u3002", "result": "CQO\u987a\u5e8f\u6bd4QOC\u987a\u5e8f\u8868\u73b0\u597d14%\u4ee5\u4e0a\uff0c\u8fd9\u4e00\u73b0\u8c61\u5728\u5e7f\u6cdb\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e00\u81f4\u3002\u56e0\u679c\u6ce8\u610f\u529b\u662f\u5bfc\u81f4\u8fd9\u79cd\u5dee\u5f02\u7684\u6838\u5fc3\u673a\u5236\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u63d0\u793a\u7ed3\u6784\u7684\u654f\u611f\u6027\u6e90\u4e8e\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u5728\u7279\u5b9a\u63d0\u793a\u987a\u5e8f\u4e0b\u4f1a\u521b\u5efa\u4fe1\u606f\u74f6\u9888\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u8fd9\u4e00\u53d1\u73b0\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u5e76\u6539\u8fdb\u63d0\u793a\u8bbe\u8ba1\u3002"}}
{"id": "2601.14175", "categories": ["cs.LG", "cs.AI", "cs.CL", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14175", "abs": "https://arxiv.org/abs/2601.14175", "authors": ["Suvrat Raju", "Praneeth Netrapalli"], "title": "A model of errors in transformers", "comment": "8+17pages", "summary": "We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.", "AI": {"tldr": "LLM\u5728\u786e\u5b9a\u6027\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u7387\u53ef\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5c0f\u8bef\u5dee\u7d2f\u79ef\u7684\u9608\u503c\u6a21\u578b\u63cf\u8ff0\uff0c\u8be5\u6a21\u578b\u4ec5\u9700\u4e24\u4e2a\u53c2\u6570\u5373\u53ef\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u4e2d\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u7814\u7a76LLM\u5728\u7b97\u672f\u7b49\u786e\u5b9a\u6027\u8f93\u51fa\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u7387\uff0c\u6311\u6218\"\u63a8\u7406\u5d29\u6e83\"\u6216\"\u7ec4\u5408\u51fd\u6570\u8868\u8fbe\u80fd\u529b\u4e0d\u8db3\"\u7684\u4f20\u7edf\u89e3\u91ca\uff0c\u63d0\u51fa\u66f4\u7b80\u5355\u7684\u53c2\u6570\u5316\u6a21\u578b\u6765\u89e3\u91ca\u9519\u8bef\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u6ce8\u610f\u529b\u673a\u5236\u5c0f\u8bef\u5dee\u7d2f\u79ef\u7684\u9608\u503c\u6a21\u578b\uff0c\u5c06LLM\u7684\u4f17\u591a\u53c2\u6570\u91cd\u7ec4\u4e3a\u4e24\u4e2a\u5173\u952e\u53c2\u6570\uff1a\u57fa\u672c\u566a\u58f0\u7387\u548c\u53ef\u80fd\u9519\u8bef\u9884\u6d4b\u7684token\u6570\u91cf\u3002\u4f7f\u7528Gemini 2.5 Flash\u3001Gemini 2.5 Pro\u548cDeepSeek R1\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u8bc1\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u7684\u51c6\u786e\u7387\u4e0e\u89c2\u5bdf\u503c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5c3d\u7ba1\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b58\u5728\u504f\u5dee\u3002\u8be5\u6a21\u578b\u4e3aLLM\u9519\u8bef\u63d0\u4f9b\u4e86\u66ff\u4ee3\u89e3\u91ca\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u964d\u4f4e\u9519\u8bef\u7387\u3002", "conclusion": "LLM\u5728\u786e\u5b9a\u6027\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u53ef\u901a\u8fc7\u7b80\u5355\u7684\u4e24\u53c2\u6570\u6a21\u578b\u6709\u6548\u63cf\u8ff0\uff0c\u8fd9\u6311\u6218\u4e86\u4f20\u7edf\u4e0a\u8ba4\u4e3a\u7684\u9519\u8bef\u6e90\u4e8e\"\u63a8\u7406\u5d29\u6e83\"\u7684\u89c2\u70b9\uff0c\u5e76\u4e3a\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.14160", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14160", "abs": "https://arxiv.org/abs/2601.14160", "authors": ["Ali Hamza Bashir", "Muhammad Rehan Khalid", "Kostadin Cvejoski", "Jana Birr", "Jule Berghaus", "Armin Berger", "Sandra Halscheidt", "Christian Temath", "Rafet Sifa", "David Berghaus"], "title": "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law", "comment": null, "summary": "Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5230\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u9886\u57df\u7684\u6280\u672f\uff0c\u4f7f\u7528\u6743\u5a01\u6cd5\u89c4\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u95ee\u7b54\u5bf9\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u6cd5\u5f8b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\uff08\u5982\u6cd5\u5f8b\u63a8\u7406\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u4e13\u5bb6\u77e5\u8bc6\u5bfc\u81f4\u4e8b\u5b9e\u9519\u8bef\u6216\u5e7b\u89c9\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8\u6216\u4e0d\u53ef\u9760\u7684\u5408\u6210\u6570\u636e\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9002\u914d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u6743\u5a01\u5fb7\u56fd\u6cd5\u89c4\u7cfb\u7edf\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u4e14\u6cd5\u5f8b\u51c6\u786e\u7684\u95ee\u7b54\u5bf9\u3002\u91c7\u7528\u4e25\u683c\u7684\u81ea\u52a8\u8fc7\u6ee4\u65b9\u6cd5\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u3002", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u5fae\u8c03\u7684LLM\u5728\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002\u8bc1\u660e\u4e86\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6570\u636e\u53ef\u4ee5\u4f5c\u4e3a\u4eba\u5de5\u6807\u6ce8\u7684\u53ef\u9760\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u5728\u9ad8\u98ce\u9669\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff0c\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u53ef\u4ee5\u6709\u6548\u9002\u914dLLM\uff0c\u4e3a\u4e13\u4e1a\u9886\u57df\u5e94\u7528\u63d0\u4f9b\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.14196", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14196", "abs": "https://arxiv.org/abs/2601.14196", "authors": ["Albina Galiullina", "Wouter van Heeswijk", "Tom van Woensel"], "title": "Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery", "comment": null, "summary": "Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.", "AI": {"tldr": "\u63d0\u51fa\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63a8\u8350\u7b56\u7565\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4f4d\u987e\u5ba2\u63a8\u8350\u5355\u4e2a\u53d6\u8d27\u70b9\u800c\u975e\u81ea\u7531\u9009\u62e9\uff0c\u540c\u65f6\u7ed3\u5408\u5bb6\u5ead\u914d\u9001\u9009\u9879\uff0c\u52a8\u6001\u4f18\u5316\u4ee5\u51cf\u5c11\u914d\u9001\u5361\u8f66\u548c\u987e\u5ba2\u51fa\u884c\u7684\u603b\u78b3\u6392\u653e\u3002", "motivation": "\u53d6\u8d27\u70b9\u4f5c\u4e3a\u5bb6\u5ead\u914d\u9001\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u8ba2\u5355\u6574\u5408\u53ef\u4ee5\u7f29\u77ed\u914d\u9001\u8def\u7ebf\u5e76\u63d0\u9ad8\u9996\u6b21\u6295\u9012\u6210\u529f\u7387\u3002\u4f46\u5f53\u987e\u5ba2\u5f00\u8f66\u53d6\u8d27\u65f6\uff0c\u8fd9\u4e9b\u73af\u5883\u6548\u76ca\u53ef\u80fd\u88ab\u62b5\u6d88\u3002\u9700\u8981\u4e00\u79cd\u7b56\u7565\u6765\u540c\u65f6\u51cf\u5c11\u914d\u9001\u5361\u8f66\u8def\u7ebf\u548c\u987e\u5ba2\u51fa\u884c\u7684\u78b3\u6392\u653e\u3002", "method": "\u63d0\u51fa\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63a8\u8350\u7b56\u7565\uff0c\u4e3a\u6bcf\u4f4d\u5230\u8fbe\u987e\u5ba2\u63a8\u8350\u5355\u4e2a\u53d6\u8d27\u70b9\u800c\u975e\u81ea\u7531\u9009\u62e9\u6240\u6709\u4f4d\u7f6e\uff0c\u540c\u65f6\u4fdd\u7559\u5bb6\u5ead\u914d\u9001\u9009\u9879\u3002\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u8003\u8651\u987e\u5ba2\u4e0e\u53d6\u8d27\u70b9\u4e4b\u95f4\u7684\u7a7a\u95f4\u5173\u7cfb\u53ca\u5176\u5bf9\u672a\u6765\u8def\u7ebf\u6574\u5408\u7684\u5f71\u54cd\uff0c\u5728\u52a8\u6001\u968f\u673a\u73af\u5883\u4e2d\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63a8\u8350\u80fd\u663e\u8457\u51cf\u5c11\u603b\u78b3\u6392\u653e\u3002\u76f8\u6bd4\u7eaf\u5bb6\u5ead\u914d\u9001\uff0c\u603b\u6392\u653e\u6700\u591a\u51cf\u5c119%\uff1b\u76f8\u6bd4\u66ff\u4ee3\u7b56\u7565\uff08\u5305\u62ec\u81ea\u7531\u9009\u62e9\u53d6\u8d27\u70b9\u548c\u6700\u8fd1\u53d6\u8d27\u70b9\u5206\u914d\uff09\uff0c\u5e73\u5747\u51cf\u5c112%\u3002\u5728\u53d6\u8d27\u70b9\u591a\u3001\u8ddd\u79bb\u77ed\u7684\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u6548\u679c\u5c24\u4e3a\u663e\u8457\u3002", "conclusion": "\u5dee\u5f02\u5316\u53d6\u8d27\u70b9\u63a8\u8350\u662f\u51cf\u5c11\u6700\u540e\u4e00\u516c\u91cc\u914d\u9001\u78b3\u6392\u653e\u7684\u6709\u6548\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u3002\u5f53\u987e\u5ba2\u4e0d\u592a\u613f\u610f\u9009\u62e9\u53d6\u8d27\u70b9\u914d\u9001\u800c\u975e\u5bb6\u5ead\u914d\u9001\u65f6\uff0c\u660e\u786e\u8003\u8651\u987e\u5ba2\u5230\u8fbe\u548c\u9009\u62e9\u7684\u52a8\u6001\u7279\u6027\u5c24\u4e3a\u91cd\u8981\u3002"}}
{"id": "2601.14172", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14172", "abs": "https://arxiv.org/abs/2601.14172", "authors": ["V\u00edctor Yeste", "Paolo Rosso"], "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum", "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 37 pages, 4 figures,", "summary": "We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task (\"does any value appear?\") and show that it is learnable from single sentences (positive-class F1 $\\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.", "AI": {"tldr": "\u7814\u7a76\u53e5\u5b50\u7ea7\u522b\u8bc6\u522b\u65bd\u74e6\u8328\u4ef7\u503c\u7406\u8bba\u4e2d\u768419\u79cd\u4ef7\u503c\u89c2\uff0c\u4f5c\u4e3a\u6587\u672c\u4e2d\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u7684\u5177\u4f53\u5b9e\u73b0\u3002\u5728\u65b0\u95fb\u548c\u653f\u6cbb\u5ba3\u8a00\u7684\u8131\u8bed\u5883\u53e5\u5b50\u4e2d\uff0c\u9053\u5fb7\u7ebf\u7d22\u7a00\u758f\u4e14\u7c7b\u522b\u4e25\u91cd\u4e0d\u5e73\u8861\uff0c\u4f7f\u5f97\u7ec6\u7c92\u5ea6\u4ef7\u503c\u68c0\u6d4b\u975e\u5e38\u56f0\u96be\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u4e2a\u53e5\u5b50\u7ea7\u522b\u7684\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u8131\u8bed\u5883\u6587\u672c\u4e2d\u8bc6\u522b\u65bd\u74e6\u8328\u4ef7\u503c\u7406\u8bba\u4e2d\u768419\u79cd\u4ef7\u503c\u89c2\u3002\u8fd9\u79cd\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u5bf9\u4e8e\u7406\u89e3\u6587\u672c\u4e2d\u7684\u9053\u5fb7\u548c\u4ef7\u503c\u8868\u8fbe\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u9762\u4e34\u7a00\u758f\u9053\u5fb7\u7ebf\u7d22\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a1\uff09\u5b58\u5728\u6027\u95e8\u63a7\u5c42\u6b21\u7ed3\u6784\uff08\u5148\u68c0\u6d4b\u662f\u5426\u6709\u4ef7\u503c\u5b58\u5728\uff0c\u518d\u5206\u7c7b\u5177\u4f53\u4ef7\u503c\uff09\uff1b2\uff09\u76f4\u63a5\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u3002\u57fa\u4e8eDeBERTa-base\u6a21\u578b\uff0c\u5e76\u52a0\u5165\u8f7b\u91cf\u7ea7\u4fe1\u53f7\uff08\u524d\u53e5\u4e0a\u4e0b\u6587\u3001LIWC-22/eMFD/MJD\u8bcd\u5178\u3001\u4e3b\u9898\u7279\u5f81\uff09\u3002\u540c\u65f6\u8bc4\u4f30\u6307\u4ee4\u8c03\u4f18\u7684LLMs\uff08Gemma 2 9B, Llama 3.1 8B\u7b49\uff09\u5728\u96f6\u6837\u672c/\u5c11\u6837\u672c\u548cQLoRA\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u6784\u5efa\u7b80\u5355\u96c6\u6210\u6a21\u578b\u3002", "result": "\u4e8c\u8fdb\u5236\u9053\u5fb7\u5b58\u5728\u6027\u4efb\u52a1\u53ef\u5b66\u4e60\uff08\u6b63\u7c7bF1\u22480.74\uff09\u3002\u5c42\u6b21\u7ed3\u6784\u65b9\u6cd5\u672a\u4f18\u4e8e\u76f4\u63a5\u9884\u6d4b\uff0c\u8868\u660e\u95e8\u63a7\u53ec\u56de\u7387\u9650\u5236\u4e86\u4e0b\u6e38\u589e\u76ca\u3002\u8f6f\u6295\u7968\u76d1\u7763\u96c6\u6210\u8fbe\u5230macro-F1 0.332\uff0c\u663e\u8457\u8d85\u8d8a\u6700\u4f73\u5355\u4e00\u76d1\u7763\u6a21\u578b\u548c\u5148\u524d\u82f1\u6587\u57fa\u7ebf\u3002\u8f7b\u91cf\u7ea7\u4fe1\u53f7\u548c\u5c0f\u578b\u96c6\u6210\u63d0\u4f9b\u4e86\u6700\u53ef\u9760\u7684\u6539\u8fdb\u3002", "conclusion": "\u57288GB\u5355GPU\u7ea6\u675f\u548c7-9B\u89c4\u6a21\u4e0b\uff0c\u7cbe\u5fc3\u8c03\u4f18\u7684\u76d1\u7763\u7f16\u7801\u5668\u4ecd\u7136\u662f\u7ed3\u6784\u5316\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u7684\u5f3a\u5927\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u57fa\u7ebf\u3002\u5c42\u6b21\u95e8\u63a7\u63d0\u4f9b\u6709\u9650\u76ca\u5904\uff0c\u800c\u8f7b\u91cf\u7ea7\u4fe1\u53f7\u548c\u96c6\u6210\u65b9\u6cd5\u66f4\u6709\u6548\u3002\u672a\u6765\u53ef\u901a\u8fc7\u66f4\u4e30\u5bcc\u7684\u4ef7\u503c\u7ed3\u6784\u548c\u6587\u6863\u4e0a\u4e0b\u6587\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2601.14209", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14209", "abs": "https://arxiv.org/abs/2601.14209", "authors": ["Matthew Y. R. Yang", "Hao Bai", "Ian Wu", "Gene Yang", "Amrith Setlur", "Aviral Kumar"], "title": "InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning", "comment": null, "summary": "Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.", "AI": {"tldr": "InT\u8bad\u7ec3\u8303\u5f0f\u901a\u8fc7\u8ba9\u6a21\u578b\u5728\u81ea\u8eab\u63a8\u7406\u8f68\u8ff9\u4e0a\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u63d0\u51fa\u9488\u5bf9\u6027\u4fee\u6b63\u6765\u5f15\u5bfc\u8f68\u8ff9\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u6700\u7ec8\u7b54\u6848\u5c42\u9762\u5206\u914d\u4fe1\u7528\uff0c\u5bfc\u81f4\u5931\u8d25\u8f68\u8ff9\u4e2d\u7684\u6b63\u786e\u4e2d\u95f4\u6b65\u9aa4\u88ab\u60e9\u7f5a\uff0c\u6210\u529f\u8f68\u8ff9\u4e2d\u7684\u865a\u5047\u6b65\u9aa4\u88ab\u5f3a\u5316\uff0c\u5b58\u5728\u4fe1\u7528\u5206\u914d\u95ee\u9898", "method": "\u63d0\u51fa\u5e72\u9884\u8bad\u7ec3\uff08InT\uff09\uff1a\u6a21\u578b\u5229\u7528\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e2d\u53ef\u7528\u7684\u53c2\u8003\u89e3\uff0c\u8bc6\u522b\u63a8\u7406\u4e2d\u7684\u7b2c\u4e00\u4e2a\u9519\u8bef\uff0c\u63d0\u51fa\u5355\u6b65\u5e72\u9884\u5c06\u8f68\u8ff9\u91cd\u5b9a\u5411\u5230\u6b63\u786e\u89e3\uff0c\u7136\u540e\u5bf9\u9519\u8bef\u70b9\u4e4b\u524d\u7684\u7b56\u7565\u5c55\u5f00\u4e0e\u5e72\u9884\u8fdb\u884c\u76d1\u7763\u5fae\u8c03", "result": "\u57284B\u53c2\u6570\u57fa\u7840\u6a21\u578b\u4e0a\uff0cInT\u53ca\u540e\u7eedRL\u5fae\u8c03\u4f7fIMO-AnswerBench\u51c6\u786e\u7387\u63d0\u5347\u8fd114%\uff0c\u4f18\u4e8egpt-oss-20b\u7b49\u66f4\u5927\u7684\u5f00\u6e90\u6a21\u578b", "conclusion": "InT\u901a\u8fc7\u8ba9\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\uff0c\u89e3\u51b3\u4e86RL\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u4e3a\u540e\u7eedRL\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u521d\u59cb\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b"}}
{"id": "2601.14210", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14210", "abs": "https://arxiv.org/abs/2601.14210", "authors": ["Rohan Bhatnagar", "Youran Sun", "Chi Andrew Zhang", "Yixin Wen", "Haizhao Yang"], "title": "HALT: Hallucination Assessment via Latent Testing", "comment": null, "summary": "Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u63a2\u9488\uff0c\u76f4\u63a5\u4eceLLM\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u8bfb\u53d6\u5e7b\u89c9\u98ce\u9669\uff0c\u5b9e\u73b0\u96f6\u5ef6\u8fdf\u7684\u98ce\u9669\u4f30\u8ba1\uff0c\u7528\u4e8e\u9009\u62e9\u6027\u751f\u6210\u548c\u8def\u7531\u51b3\u7b56", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u53ef\u89c6\u4e3a\u5fe0\u5b9e\u8bfb\u53d6\u5931\u8d25\uff1a\u5c3d\u7ba1\u5185\u90e8\u8868\u793a\u53ef\u80fd\u7f16\u7801\u4e86\u5bf9\u67e5\u8be2\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u89e3\u7801\u538b\u529b\u4ecd\u4f1a\u4ea7\u751f\u6d41\u7545\u7b54\u6848\u3002\u9700\u8981\u76f4\u63a5\u4ece\u4e2d\u95f4\u5c42\u8bfb\u53d6\u88ab\u6700\u7ec8\u89e3\u7801\u9636\u6bb5\u8870\u51cf\u7684\u8ba4\u77e5\u4fe1\u53f7", "method": "\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u63a2\u9488\uff0c\u4f5c\u4e3a\u5c0f\u578b\u8f85\u52a9\u7f51\u7edc\uff0c\u4ece\u95ee\u9898\u6807\u8bb0\u7684\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u76f4\u63a5\u8bfb\u53d6\u5e7b\u89c9\u98ce\u9669\u3002\u63a2\u9488\u8ba1\u7b97\u6210\u672c\u6bd4\u4ee4\u724c\u751f\u6210\u4f4e\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u53ef\u4e0e\u63a8\u7406\u5b8c\u5168\u5e76\u884c\u8bc4\u4f30\uff0c\u5b9e\u73b0\u8fd1\u77ac\u65f6\u98ce\u9669\u4f30\u8ba1", "result": "\u5728\u56db\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u4e2aLLM\u5bb6\u65cf\u4e2d\uff0c\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684AUROC\u548cAURAC\u6027\u80fd\uff0c\u5728\u6570\u636e\u96c6\u504f\u79fb\u4e0b\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u4e2d\u95f4\u8868\u793a\u4e2d\u7684\u53ef\u89e3\u91ca\u7ed3\u6784", "conclusion": "\u5feb\u901f\u5185\u90e8\u4e0d\u786e\u5b9a\u6027\u8bfb\u53d6\u53ef\u4f5c\u4e3a\u53ef\u9760\u667a\u80fd\u4f53AI\u7684\u539f\u5219\u6027\u57fa\u7840\uff0c\u901a\u8fc7\u4ee3\u7406\u6279\u8bc4\u5668\u5b9e\u73b0\u5feb\u901f\u9009\u62e9\u6027\u751f\u6210\u548c\u8def\u7531\uff0c\u8ba9LLM\u7acb\u5373\u56de\u7b54\u81ea\u4fe1\u67e5\u8be2\uff0c\u5c06\u4e0d\u786e\u5b9a\u67e5\u8be2\u59d4\u6258\u7ed9\u66f4\u5f3a\u7684\u9a8c\u8bc1\u6d41\u7a0b"}}
{"id": "2601.14228", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14228", "abs": "https://arxiv.org/abs/2601.14228", "authors": ["Punit Kumar", "Vaibhav Saran", "Divyesh Patel", "Nitin Kulkarni", "Alina Vereshchaka"], "title": "Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment", "comment": "8 pages, 6 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/", "summary": "Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u8113\u6bd2\u75c7\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u5305\u542b\u60a3\u8005\u5206\u5c42\u3001\u6570\u636e\u589e\u5f3a\u3001\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u7406\u7531\u751f\u6210\u56db\u4e2a\u6a21\u5757\uff0c\u5728MIMIC-III\u548ceICU\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u8113\u6bd2\u75c7\u662fICU\u4e3b\u8981\u6b7b\u4ea1\u539f\u56e0\uff0c\u53ca\u65f6\u51c6\u786e\u7684\u6cbb\u7597\u51b3\u7b56\u5bf9\u60a3\u8005\u9884\u540e\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7cfb\u7edf\u5f80\u5f80\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u83b7\u5f97\u4e34\u5e8a\u533b\u751f\u4fe1\u4efb\u3002", "method": "1) \u57fa\u4e8e\u805a\u7c7b\u7684\u60a3\u8005\u98ce\u9669\u5206\u5c42\u6a21\u5757\uff1b2) \u4f7f\u7528VAE\u548c\u6269\u6563\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u7ba1\u9053\uff1b3) \u57fa\u4e8eAWR\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u914d\u5907\u8f7b\u91cf\u6ce8\u610f\u529b\u7f16\u7801\u5668\u548c\u96c6\u6210\u6a21\u578b\uff1b4) \u591a\u6a21\u6001LLM\u9a71\u52a8\u7684\u7406\u7531\u751f\u6210\u6a21\u5757\u3002", "result": "\u5728MIMIC-III\u548ceICU\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6cbb\u7597\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u7a33\u5065\u7684\u7b56\u7565\u5efa\u8bae\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u51b3\u7b56\u652f\u6301\u6846\u67b6\u80fd\u591f\u6709\u6548\u8f85\u52a9\u8113\u6bd2\u75c7\u6cbb\u7597\u51b3\u7b56\uff0c\u5e73\u8861\u4e86\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u671b\u63d0\u5347ICU\u6cbb\u7597\u8d28\u91cf\u3002"}}
{"id": "2601.14230", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14230", "abs": "https://arxiv.org/abs/2601.14230", "authors": ["Yiyang Wang", "Yiqiao Jin", "Alex Cabral", "Josiah Hester"], "title": "MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems", "comment": "15 pages, 9 figures", "summary": "Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.", "AI": {"tldr": "MASCOT\uff1a\u4e00\u4e2a\u9632\u6b62\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u89d2\u8272\u5d29\u6e83\u548c\u793e\u4f1a\u8c04\u5a9a\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u611f\u77e5\u884c\u4e3a\u5bf9\u9f50\u548c\u534f\u4f5c\u5bf9\u8bdd\u4f18\u5316\u63d0\u5347\u793e\u4ea4\u667a\u80fd", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u89d2\u8272\u5d29\u6e83\u2014\u2014\u667a\u80fd\u4f53\u9000\u5316\u4e3a\u901a\u7528\u7684\u540c\u8d28\u5316\u52a9\u624b\u884c\u4e3a\uff1b2\uff09\u793e\u4f1a\u8c04\u5a9a\u2014\u2014\u4ea7\u751f\u5197\u4f59\u3001\u975e\u5efa\u8bbe\u6027\u7684\u5bf9\u8bdd\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f5c\u4e3a\u60c5\u611f\u548c\u8ba4\u77e5\u652f\u6301\u7684\u793e\u4ea4\u534f\u4f5c\u4f19\u4f34\u7684\u6709\u6548\u6027\u3002", "method": "MASCOT\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7b56\u7565\uff1a1\uff09\u89d2\u8272\u611f\u77e5\u884c\u4e3a\u5bf9\u9f50\u2014\u2014\u57fa\u4e8eRLAIF\uff08\u5f3a\u5316\u5b66\u4e60\u4eceAI\u53cd\u9988\uff09\u7684\u6d41\u7a0b\uff0c\u5fae\u8c03\u4e2a\u4f53\u667a\u80fd\u4f53\u4ee5\u786e\u4fdd\u4e25\u683c\u7684\u89d2\u8272\u4fdd\u771f\u5ea6\uff0c\u9632\u6b62\u8eab\u4efd\u4e22\u5931\uff1b2\uff09\u534f\u4f5c\u5bf9\u8bdd\u4f18\u5316\u2014\u2014\u57fa\u4e8e\u7fa4\u4f53\u7ea7\u5956\u52b1\u7684\u5143\u7b56\u7565\uff0c\u786e\u4fdd\u5bf9\u8bdd\u7684\u591a\u6837\u6027\u548c\u5efa\u8bbe\u6027\u3002", "result": "\u5728\u5fc3\u7406\u652f\u6301\u548c\u804c\u573a\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cMASCOT\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u89d2\u8272\u4e00\u81f4\u6027\u65b9\u9762\u63d0\u5347\u9ad8\u8fbe+14.1\uff0c\u5728\u793e\u4f1a\u8d21\u732e\u65b9\u9762\u63d0\u5347\u9ad8\u8fbe+10.6\u3002", "conclusion": "MASCOT\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u793e\u4ea4\u667a\u80fd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6280\u672f\u8def\u7ebf\u56fe\uff0c\u901a\u8fc7\u5e73\u8861\u4e2a\u4f53\u89d2\u8272\u4fdd\u771f\u5ea6\u548c\u96c6\u4f53\u534f\u4f5c\u6548\u679c\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5173\u952e\u7f3a\u9677\u3002"}}
{"id": "2601.14232", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14232", "abs": "https://arxiv.org/abs/2601.14232", "authors": ["Egor Cherepanov", "Daniil Zelezetsky", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning", "comment": "38 pages, 44 figures, 3 tables", "summary": "Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.", "AI": {"tldr": "KAGE-Env\u662f\u4e00\u4e2aJAX\u539f\u751f\u76842D\u5e73\u53f0\u6e38\u620f\u73af\u5883\uff0c\u5c06\u89c2\u6d4b\u8fc7\u7a0b\u5206\u89e3\u4e3a\u72ec\u7acb\u53ef\u63a7\u7684\u89c6\u89c9\u8f74\uff0c\u540c\u65f6\u4fdd\u6301\u5e95\u5c42\u63a7\u5236\u95ee\u9898\u4e0d\u53d8\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u89c6\u89c9\u5206\u5e03\u504f\u79fb\u5bf9\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u5c06\u591a\u79cd\u504f\u79fb\u6e90\u6df7\u6742\u5728\u4e00\u8d77\uff0c\u963b\u788d\u4e86\u5bf9\u89c6\u89c9\u5206\u5e03\u504f\u79fb\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002\u50cf\u7d20\u57fa\u7840\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u7eaf\u89c6\u89c9\u5206\u5e03\u504f\u79fb\u4e0b\u7ecf\u5e38\u5931\u8d25\uff0c\u5373\u4f7f\u6f5c\u5728\u52a8\u6001\u548c\u5956\u52b1\u4fdd\u6301\u4e0d\u53d8\u3002", "method": "\u5f00\u53d1KAGE-Env\u73af\u5883\uff0c\u5c06\u89c2\u6d4b\u8fc7\u7a0b\u5206\u89e3\u4e3a\u72ec\u7acb\u53ef\u63a7\u7684\u89c6\u89c9\u8f74\uff1b\u57fa\u4e8e\u6b64\u5b9a\u4e49KAGE-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6\u4e2a\u5df2\u77e5\u8f74\u5957\u4ef6\u548c34\u4e2a\u8bad\u7ec3-\u8bc4\u4f30\u914d\u7f6e\u5bf9\uff0c\u7528\u4e8e\u9694\u79bb\u5355\u4e2a\u89c6\u89c9\u504f\u79fb\uff1b\u4f7f\u7528\u6807\u51c6PPO-CNN\u57fa\u7ebf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u89c2\u5bdf\u5230\u5f3a\u70c8\u7684\u8f74\u4f9d\u8d56\u6027\u5931\u8d25\uff1a\u80cc\u666f\u548c\u5149\u5ea6\u504f\u79fb\u7ecf\u5e38\u5bfc\u81f4\u5b8c\u5168\u5931\u8d25\uff0c\u800c\u4ee3\u7406\u5916\u89c2\u504f\u79fb\u76f8\u5bf9\u6e29\u548c\uff1b\u67d0\u4e9b\u504f\u79fb\u4fdd\u7559\u4e86\u524d\u8fdb\u8fd0\u52a8\u4f46\u7834\u574f\u4e86\u4efb\u52a1\u5b8c\u6210\uff0c\u8868\u660e\u4ec5\u9760\u56de\u62a5\u53ef\u80fd\u63a9\u76d6\u6cdb\u5316\u5931\u8d25\uff1bJAX\u5b9e\u73b0\u5b9e\u73b0\u4e86\u5355GPU\u4e0a\u6bcf\u79d23300\u4e07\u73af\u5883\u6b65\u7684\u9ad8\u6027\u80fd\u3002", "conclusion": "KAGE-Env\u548cKAGE-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e72\u51c0\u7684\u7cfb\u7edf\u5316\u6846\u67b6\u6765\u5206\u6790\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u89c6\u89c9\u504f\u79fb\u5bf9\u4ee3\u7406\u6027\u80fd\u7684\u5dee\u5f02\u5316\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u5feb\u901f\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u5e73\u53f0\u3002"}}
{"id": "2601.14242", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14242", "abs": "https://arxiv.org/abs/2601.14242", "authors": ["Bertie Vidgen", "Austin Mann", "Abby Fennelly", "John Wright Stanly", "Lucas Rothman", "Marco Burstein", "Julien Benchek", "David Ostrofsky", "Anirudh Ravichandran", "Debnil Sur", "Neel Venugopal", "Alannah Hsia", "Isaac Robinson", "Calix Huang", "Olivia Varones", "Daniyal Khan", "Michael Haines", "Zach Richards", "Chirag Mahapatra", "Brendan Foody", "Osvald Nitski"], "title": "APEX-Agents", "comment": null, "summary": "We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.", "AI": {"tldr": "APEX-Agents\u662f\u4e00\u4e2a\u8bc4\u4f30AI\u4ee3\u7406\u6267\u884c\u6295\u8d44\u94f6\u884c\u5206\u6790\u5e08\u3001\u7ba1\u7406\u54a8\u8be2\u5e08\u548c\u5f8b\u5e08\u7b49\u4e13\u4e1a\u9886\u57df\u957f\u65f6\u7a0b\u8de8\u5e94\u7528\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u771f\u5b9e\u5de5\u4f5c\u73af\u5883\u548c\u5de5\u5177\uff0c\u6d4b\u8bd5\u7ed3\u679c\u663e\u793aGemini 3 Flash\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u9700\u8981\u8bc4\u4f30AI\u4ee3\u7406\u662f\u5426\u80fd\u591f\u6267\u884c\u4e13\u4e1a\u9886\u57df\uff08\u6295\u8d44\u94f6\u884c\u3001\u7ba1\u7406\u54a8\u8be2\u3001\u6cd5\u5f8b\uff09\u4e2d\u7684\u957f\u65f6\u7a0b\u3001\u8de8\u5e94\u7528\u590d\u6742\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u901a\u5e38\u6d89\u53ca\u591a\u6b65\u9aa4\u64cd\u4f5c\u548c\u771f\u5b9e\u5de5\u4f5c\u73af\u5883\u3002", "method": "\u521b\u5efaAPEX-Agents\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b480\u4e2a\u4efb\u52a1\uff0c\u6a21\u62df\u771f\u5b9e\u5de5\u4f5c\u73af\u5883\uff08\u6587\u4ef6\u548c\u5de5\u5177\uff09\uff0c\u4f7f\u7528Pass@1\u6307\u6807\u6d4b\u8bd58\u4e2aAI\u4ee3\u7406\uff0c\u5e76\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u548cArchipelago\u6267\u884c\u8bc4\u4f30\u57fa\u7840\u8bbe\u65bd\u3002", "result": "Gemini 3 Flash (Thinking=High)\u4ee524.0%\u7684\u6700\u9ad8\u5f97\u5206\u9886\u5148\uff0c\u5176\u6b21\u662fGPT-5.2 (Thinking=High)\u3001Claude Opus 4.5 (Thinking=High)\u548cGemini 3 Pro (Thinking=High)\u3002", "conclusion": "APEX-Agents\u4e3a\u8bc4\u4f30AI\u4ee3\u7406\u5728\u4e13\u4e1a\u9886\u57df\u4efb\u52a1\u6267\u884c\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5f00\u6e90\u57fa\u51c6\u548c\u57fa\u7840\u8bbe\u65bd\u5c06\u4fc3\u8fdb\u8be5\u9886\u57df\u7814\u7a76\u53d1\u5c55\uff0c\u5f53\u524dAI\u4ee3\u7406\u5728\u590d\u6742\u4e13\u4e1a\u4efb\u52a1\u4e0a\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2601.14249", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14249", "abs": "https://arxiv.org/abs/2601.14249", "authors": ["Yuming Yang", "Mingyoung Lai", "Wanxu Zhao", "Xiaoran Fan", "Zhiheng Xi", "Mingqi Wu", "Chiyue Huang", "Jun Zhao", "Haijun Lv", "Jian Tong", "Yunhua Zhou", "Yicheng Zou", "Qipeng Guo", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment", "comment": "26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio", "summary": "Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.", "AI": {"tldr": "\u63d0\u51faRank-Surprisal Ratio (RSR)\u65b0\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u5728\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e73\u8861\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u91cf\uff0c\u6bd4\u73b0\u6709\u6307\u6807\u66f4\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4e2d\uff0c\u66f4\u5f3a\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e0d\u4e00\u5b9a\u80fd\u4ea7\u751f\u66f4\u597d\u7684\u5b66\u751f\u6a21\u578b\uff0c\u8868\u660e\u6570\u636e\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u5339\u914d\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u5b66\u751f\u4f3c\u7136\u5ea6\u8bc4\u4f30\u9002\u7528\u6027\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u504f\u5411\u4e8e\u4e0e\u6a21\u578b\u5f53\u524d\u884c\u4e3a\u9ad8\u5ea6\u5bf9\u9f50\u7684\u8f68\u8ff9\uff0c\u5ffd\u7565\u4e86\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u8f68\u8ff9\u3002", "method": "\u63d0\u51faRank-Surprisal Ratio (RSR)\u6307\u6807\uff0c\u5b9a\u4e49\u4e3a\u8f68\u8ff9\u7684\u5e73\u5747\u8bcd\u5143\u7ea7\u522b\u6392\u540d\u4e0e\u5e73\u5747\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u6bd4\u503c\u3002\u8be5\u6307\u6807\u6355\u6349\u8f68\u8ff9\u7684\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u91cf\uff0c\u5e73\u8861\u5b66\u4e60\u4fe1\u53f7\u5f3a\u5ea6\u548c\u884c\u4e3a\u5bf9\u9f50\u3002RSR\u6613\u4e8e\u8ba1\u7b97\u548c\u89e3\u91ca\u3002", "result": "\u57285\u4e2a\u5b66\u751f\u6a21\u578b\u548c11\u4e2a\u4e0d\u540c\u6559\u5e08\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e0a\uff0cRSR\u4e0e\u8bad\u7ec3\u540e\u6027\u80fd\u5448\u73b0\u5f3a\u76f8\u5173\u6027\uff08\u5e73\u5747Spearman\u76f8\u5173\u7cfb\u65700.86\uff09\uff0c\u4f18\u4e8e\u73b0\u6709\u6307\u6807\u3002\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86RSR\u5728\u8f68\u8ff9\u9009\u62e9\u548c\u6559\u5e08\u9009\u62e9\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "RSR\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u6307\u6807\uff0c\u80fd\u591f\u51c6\u786e\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u5728\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u5e73\u8861\u5bf9\u9f50\u6027\u548c\u4fe1\u606f\u91cf\uff0c\u4e3a\u8f68\u8ff9\u9009\u62e9\u548c\u6559\u5e08\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.14238", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14238", "abs": "https://arxiv.org/abs/2601.14238", "authors": ["Shaurya Mathur", "Shreyas Bellary Manjunath", "Nitin Kulkarni", "Alina Vereshchaka"], "title": "Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression", "comment": "6 pages, 5 figures (two of them in tables), Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/", "summary": "Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \\textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.", "AI": {"tldr": "FireCastRL\u662f\u4e00\u4e2a\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u548c\u5f3a\u5316\u5b66\u4e60\u706d\u706b\u7684AI\u6846\u67b6\uff0c\u7528\u4e8e\u4e3b\u52a8\u5f0f\u91ce\u706b\u7ba1\u7406", "motivation": "\u4f20\u7edf\u91ce\u706b\u7ba1\u7406\u4e3b\u8981\u662f\u88ab\u52a8\u53cd\u5e94\u5f0f\uff0c\u53ea\u5728\u706b\u707e\u53d1\u751f\u540e\u8fdb\u884c\u5e94\u5bf9\u3002\u968f\u7740\u91ce\u706b\u9891\u7387\u548c\u5f3a\u5ea6\u4e0d\u65ad\u589e\u52a0\uff0c\u9020\u6210\u5de8\u5927\u751f\u6001\u7834\u574f\u548c\u7ecf\u6d4e\u635f\u5931\uff0c\u9700\u8981\u66f4\u4e3b\u52a8\u7684\u9884\u9632\u548c\u5e94\u5bf9\u65b9\u6cd5", "method": "1. \u4f7f\u7528\u6df1\u5ea6\u65f6\u7a7a\u6a21\u578b\u9884\u6d4b\u91ce\u706b\u8d77\u706b\u70b9\uff1b2. \u5bf9\u9ad8\u98ce\u9669\u9884\u6d4b\u90e8\u7f72\u9884\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u5728\u7269\u7406\u4fe1\u606f3D\u6a21\u62df\u4e2d\u6267\u884c\u76f4\u5347\u673a\u706d\u706b\u6218\u672f\uff1b3. \u751f\u6210\u5a01\u80c1\u8bc4\u4f30\u62a5\u544a\u5e2e\u52a9\u5e94\u6025\u54cd\u5e94\u8d44\u6e90\u5206\u914d", "result": "\u516c\u5f00\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b950\u4e07\u4e2a\u73af\u5883\u53d8\u91cf\u6837\u672c\u7684\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u91ce\u706b\u9884\u6d4b\u3002\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u652f\u6301\u91ce\u706b\u9884\u6d4b\u548c\u6218\u672f\u54cd\u5e94\u7684\u53ef\u884c\u6027", "conclusion": "FireCastRL\u6846\u67b6\u5c06\u91ce\u706b\u9884\u6d4b\u4e0e\u667a\u80fd\u706d\u706b\u7b56\u7565\u7ed3\u5408\uff0c\u4e3a\u4e3b\u52a8\u5f0f\u91ce\u706b\u7ba1\u7406\u63d0\u4f9b\u4e86AI\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u5e94\u6025\u8d44\u6e90\u5206\u914d\u548c\u89c4\u5212"}}
{"id": "2601.14243", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14243", "abs": "https://arxiv.org/abs/2601.14243", "authors": ["Haocheng Xi", "Charlie Ruan", "Peiyuan Liao", "Yujun Lin", "Han Cai", "Yilong Zhao", "Shuo Yang", "Kurt Keutzer", "Song Han", "Ligeng Zhu"], "title": "Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow", "comment": "11 pages, 6 figures, 4 tables", "summary": "Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Jet-RL\u6846\u67b6\uff0c\u9996\u6b21\u5168\u9762\u7814\u7a76FP8\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709BF16\u8bad\u7ec3+FP8 rollout\u7b56\u7565\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u548c\u7a33\u5b9a\u6536\u655b\u3002", "motivation": "\u73b0\u6709RL\u8bad\u7ec3\u7ba1\u9053\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0crollout\u9636\u6bb5\u5360\u8bad\u7ec3\u65f6\u95f470%\u4ee5\u4e0a\u3002FP8\u91cf\u5316\u8bad\u7ec3\u867d\u80fd\u7f13\u89e3\u74f6\u9888\uff0c\u4f46\u5e38\u7528\u7684BF16\u8bad\u7ec3+FP8 rollout\u7b56\u7565\u5728\u957f\u5e8f\u5217\u548c\u590d\u6742\u4efb\u52a1\u4e2d\u4f1a\u51fa\u73b0\u4e25\u91cd\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u7cbe\u5ea6\u5d29\u6e83\u95ee\u9898\u3002", "method": "\u63d0\u51faJet-RL\u6846\u67b6\uff0c\u91c7\u7528\u7edf\u4e00\u7684FP8\u7cbe\u5ea6\u6d41\u7a0b\u540c\u65f6\u7528\u4e8e\u8bad\u7ec3\u548crollout\uff0c\u6700\u5c0f\u5316\u6570\u503c\u5dee\u5f02\uff0c\u6d88\u9664\u4f4e\u6548\u7684\u8de8\u6b65\u6821\u51c6\u9700\u6c42\uff0c\u5b9e\u73b0\u7a33\u5b9aRL\u4f18\u5316\u3002", "result": "Jet-RL\u5728rollout\u9636\u6bb5\u5b9e\u73b0\u6700\u9ad833%\u52a0\u901f\uff0c\u8bad\u7ec3\u9636\u6bb5\u6700\u9ad841%\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u76f8\u6bd4BF16\u8bad\u7ec3\u63d0\u534716%\u901f\u5ea6\uff0c\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u7a33\u5b9a\u6536\u655b\uff0c\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "Jet-RL\u662f\u9996\u4e2a\u5168\u9762\u7684FP8 RL\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u7cbe\u5ea6\u6d41\u7a0b\u89e3\u51b3\u4e86\u73b0\u6709\u6df7\u5408\u7cbe\u5ea6\u7b56\u7565\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
