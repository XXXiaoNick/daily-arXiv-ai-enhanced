<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 53]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [eess.SY](#eess.SY) [Total: 13]
- [cs.AI](#cs.AI) [Total: 17]
- [math.OC](#math.OC) [Total: 10]
- [stat.ML](#stat.ML) [Total: 3]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.CY](#cs.CY) [Total: 4]
- [econ.EM](#econ.EM) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation](https://arxiv.org/abs/2601.16217)
*Qingyan Yang,Tongxi Wang,Yunsheng Luo*

Main category: cs.CL

TL;DR: 提出了首个评估中英代码混合能力的基准ChiEngMixBench，将代码混合视为认知对齐问题，通过自发性和自然性两个信号评估模型表现，并发现了与人类沟通一致的术语分层策略。


<details>
  <summary>Details</summary>
Motivation: 现有工作通常将代码混合简化为翻译或可转换性问题，难以评估模型的语言切换行为是否上下文适当且符合人类惯例，需要新的评估框架来评估真实社区环境中的代码混合能力。

Method: 构建了ChiEngMixBench基准，采用通用的构建流程支持跨领域和双语对的可扩展数据集开发，将代码混合定义为认知对齐问题，通过自发性和自然性两个互补信号进行评估。

Result: 实验评估表明，该基准的指标能够系统地区分不同模型的代码混合性能。此外，发现了隐含出现的术语分层策略，这一现象与矩阵语言框架理论一致，表明多语言大语言模型与人类沟通之间存在结构化的认知对齐。

Conclusion: ChiEngMixBench为评估代码混合能力提供了首个基准，将代码混合视为认知对齐问题而非简单的翻译任务，揭示了多语言大语言模型与人类沟通在认知层面的一致性，为未来研究提供了重要基础。

Abstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is context-appropriate and aligned with human conventions. We introduce ChiEngMixBench, the first benchmark designed to evaluate code-mixing ability in authentic community contexts, built upon a general construction pipeline that enables scalable dataset development across domains and bilingual pairs. ChiEngMixBench formulates code-mixing as a cognitive alignment problem, characterized by two complementary signals: Spontaneity and Naturalness. Empirical evaluation shows that our metrics can systematically distinguish code-mixing performance across models. Beyond benchmarking, we further uncover an implicitly emergent Terminology Layering Strategy, a phenomenon consistent with the Matrix Language Frame (MLF) theory, indicating structured cognitive alignment between multilingual large language models and human communication.

</details>


### [2] [M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.16218)
*Aleix Torres-Camps,Nathaniel Mitrani Hadida,Víctor Conchello Vendrell,Àlex Batlle Casellas,Arnau Padrés Masdemont,Jordi Ros-Giralt*

Main category: cs.CL

TL;DR: M3Kang是首个大规模多语言多模态数学推理数据集，基于袋鼠数学竞赛构建，包含1747道选择题，涵盖108种语言，用于评估视觉语言模型的多语言数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多语言数学推理方面的表现尚未充分探索，特别是与人类表现相比存在差距。需要构建一个大规模、多语言、多模态的数学推理数据集来系统评估模型能力。

Method: 从袋鼠数学竞赛（全球最大的数学竞赛）中提取1747道独特的选择题，按年级难度组织，翻译成108种文化多样语言，部分题目包含解题必需的图表。同时收集了超过68,000名学生的表现数据用于人类对比。

Result: 基准测试显示，尽管模型有进步，但在基础数学和图表推理方面仍有困难，性能随语言覆盖和模型规模扩展，但不随年级难度提升。多语言技术可有效扩展到多模态设置，显著优于基线方法。

Conclusion: M3Kang数据集填补了多语言多模态数学推理评估的空白，揭示了当前模型的局限性，并展示了多语言技术在多模态场景中的有效性。数据集、框架和代码库已开源。

Abstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.

</details>


### [3] [PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice](https://arxiv.org/abs/2601.16669)
*Yuzhen Shi,Huanghai Liu,Yiran Hu,Gaojie Song,Xinran Xu,Yubo Ma,Tianyi Tang,Li Zhang,Qingjing Chen,Di Feng,Wenbo Lv,Weiheng Wu,Kexin Yang,Sen Yang,Wei Wang,Rongyao Shi,Yuanyang Qiu,Yuemeng Qi,Jingwen Zhang,Xiaoyu Sui,Yifan Chen,Yi Zhang,An Yang,Bowen Yu,Dayiheng Liu,Junyang Lin,Weixing Shen,Bing Zhao,Charles L. A. Clarke,Hu Wei*

Main category: cs.CL

TL;DR: PLawBench是一个面向实际法律实践的基准测试，用于评估LLMs在真实法律场景中的能力，包含850个问题、13个法律场景和约12,500个评估细则，揭示了当前LLMs在法律推理方面的显著局限性。


<details>
  <summary>Details</summary>
Motivation: 现有法律基准测试过于简化，无法捕捉真实法律实践的模糊性、复杂性和推理需求，且评估指标单一，缺乏对细粒度法律推理的评估。

Method: 基于真实法律工作流程，设计了三个任务类别：公共法律咨询、实际案例分析和法律文件生成，包含850个问题、13个法律场景，每个问题配有专家设计的评估细则，使用与人类专家判断对齐的LLM评估器对10个先进LLMs进行评估。

Result: 实验结果显示，没有LLM在PLawBench上表现出色，揭示了当前LLMs在细粒度法律推理能力方面存在显著局限性。

Conclusion: PLawBench填补了现有法律基准测试的空白，为未来法律LLMs的评估和发展提供了重要方向，强调了需要提升LLMs在实际法律实践中的推理能力。

Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.

</details>


### [4] [Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2601.16219)
*Erdem Aslan,Pakize Erdoğmuş*

Main category: cs.CL

TL;DR: 该论文提出了一种离线响应式知识蒸馏方法，在有限硬件资源下开发高精度专业助手，通过三种数据策略对比发现，500行的上下文感知合成数据集在减少幻觉方面表现最佳，达到96.7%准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理领域特定或机构知识时容易出现幻觉，因为这些知识通常不在其预训练数据中。需要在有限硬件资源下开发高精度的专业助手。

Method: 采用离线响应式知识蒸馏方法，评估三种数据策略：1) 通用领域适应(15,000行)；2) 非结构化知识注入(2,000行)；3) 教师模型生成的上下文感知合成数据集(500行)。使用Unsloth库优化Qwen-2.5-7B学生模型，将A100 GPU内存需求从40GB降至16GB。

Result: 实验结果显示，较大的非结构化数据集存在持续幻觉问题，而500行的上下文感知数据集达到96.7%准确率，并具备强大的拒绝能力。验证了LIMA假设，表明在低资源环境下，数据质量和结构对齐比数据量更重要。

Conclusion: 对于领域适应的低资源设置，数据质量和结构对齐比数量更为关键。上下文感知的合成数据集能有效减少幻觉，实现高精度专业助手开发，同时显著降低计算资源需求。

Abstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that develops high-accuracy specialized assistants under constrained hardware resources. We evaluate three distinct data strategies: general domain adaptation (15,000 lines), unstructured knowledge injection (2,000 lines), and a context-aware synthetic dataset (500 lines) generated by a teacher model. To minimize computational costs, we utilize the Unsloth library to optimize the Qwen-2.5-7B student model, reducing NVIDIA A100 GPU memory requirements from 40 GB to 16 GB. Experimental results demonstrate that while larger unstructured datasets suffer from persistent hallucinations, the 500-line context-aware dataset achieves a 96.7% accuracy rate and robust rejection capability. These findings validate the LIMA hypothesis, showing that data quality and structural alignment are more critical than quantity for domain adaptation in low-resource settings.

</details>


### [5] [Towards Latent Diffusion Suitable For Text](https://arxiv.org/abs/2601.16220)
*Nesta Midavaine,Christian A. Naesseth,Grigory Bartosh*

Main category: cs.CL

TL;DR: 提出Neural Flow Diffusion Models (NFDM)用于语言生成，扩展了NFDM以将连续扩散模型直接应用于离散状态空间，显著缩小了与自回归模型的可能性差距，同时保持了与先前潜在扩散模型相当的样本质量。


<details>
  <summary>Details</summary>
Motivation: 语言扩散模型旨在提高采样速度和连贯性，超越自回归大语言模型。当前需要一种方法将连续扩散模型直接应用于离散状态空间，并确保前向过程和生成轨迹适合语言建模。

Method: 引入Neural Flow Diffusion Models (NFDM)用于语言生成，扩展了NFDM框架。该方法学习数据中的多元前向过程，确保前向过程和生成轨迹适合语言建模任务。

Result: 模型显著缩小了与同等规模自回归模型的可能性差距，同时实现了与先前潜在扩散模型相当的样本质量。

Conclusion: NFDM为将连续扩散模型应用于离散语言状态空间提供了一种有效方法，在保持采样质量的同时提高了与自回归模型的竞争力。

Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.

</details>


### [6] [Limits of n-gram Style Control for LLMs via Logit-Space Injection](https://arxiv.org/abs/2601.16224)
*Sami-ul Ahmed*

Main category: cs.CL

TL;DR: 论文提出一种轻量级方法，通过在解码时向LLM的logits空间注入n-gram风格先验来引导冻结模型，但该方法仅在特定参数范围内有效，且效果不如提示工程和LoRA微调。


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法如提示工程难以捕捉写作风格，而LoRA微调需要大量计算资源。本文探索一种轻量级替代方案：在解码时通过n-gram风格先验引导冻结LLM。

Method: 在风格化语料库上训练n-gram模型，构建1-3元语法先验。生成时，将匹配当前上下文的各阶n-gram对数概率加权和加到LLM的logits中，通过控制参数λ调节强度。

Result: 在TinyLlama-1.1B上，仅针对《堂吉诃德》语料在λ=0.1时取得最佳效果：风格困惑度改善24.7%，基础模型困惑度改善51.4%。其他语料和参数下效果较差，甚至导致文本崩溃。

Conclusion: n-gram风格先验的logits空间注入提供轻量级风格控制，但非常脆弱：仅在低λ值窄范围内有效，且始终不如提示工程和LoRA方法。

Abstract: Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally intensive training and infrastructure. We investigate a possible lightweight alternative: steering a frozen LLM with n-gram style priors injected in logit space at decoding time. We train an n-gram model on stylistically distinct corpora -- including Don Quixote, CNN/DailyMail news headlines, and arXiv abstracts -- constructing an interpolated 1-to-3-gram prior over next-token probabilities. During generation we modify the LLM's logits by adding a weighted sum of style log-probabilities from each n-gram order that matches the current context, scaled by a control parameter lambda in [0, 1].
  We sweep lambda and style corpora and report style perplexity under the n-gram model, base-model perplexity as a proxy for fluency, Jensen-Shannon (JS) divergence between the original and steered token distributions, and token-overlap statistics. On TinyLlama-1.1B we identify a single narrow regime (for the Don Quixote corpus at lambda=0.1) where style perplexity improves by 24.7% and base-model perplexity improves by 51.4% relative to the frozen model. Outside this regime, and for multi-author corpora such as CNN/DailyMail and arXiv abstracts, even small nonzero lambda values generally result in worse style and fluency, and larger lambda values lead to collapse with extreme perplexities and incoherent text. Logit-space injection of n-gram style priors provides lightweight, tunable style control, but it is fragile: it operates effectively only within a narrow range of low lambda values and is consistently outperformed by prompting and LoRA.

</details>


### [7] [GameTalk: Training LLMs for Strategic Conversation](https://arxiv.org/abs/2601.16276)
*Victor Conchello Vendrell,Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: GameTalk：通过对话微调LLMs进行多智能体战略决策的框架，在复杂游戏中显著优于未训练模型


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在单轮决策任务中的应用，而忽略了通过对话优化长期目标的问题。多智能体环境中的战略决策，特别是需要协调和谈判的长期对话场景，对LLMs仍是一个关键挑战。

Method: 提出GameTalk框架，通过调整GRPO、DPO和STaR等微调方法，将依赖于整个交互过程的奖励信号纳入训练，使LLMs能够在多轮对话中优化全局目标。

Result: 在一系列复杂度递增的游戏中评估，GameTalk显著优于未训练模型，特别是在奖励塑形条件下。DPO方法始终表现出最强的性能提升。

Conclusion: 对话微调为LLMs在交互环境中进行推理、谈判和行动提供了有前景的路径，能够有效提升多智能体战略决策能力。

Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.

</details>


### [8] [Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification](https://arxiv.org/abs/2601.16278)
*Branislav Pecher,Jan Cegin,Robert Belanec,Ivan Srba,Jakub Simko,Maria Bielikova*

Main category: cs.CL

TL;DR: LLMs作为教师生成合成数据，训练小型模型在低资源语言中表现优于大型生成器本身


<details>
  <summary>Details</summary>
Motivation: 研究LLMs的合成数据生成能力是否可作为知识蒸馏形式，使小型模型在多语言任务中达到或超越大型LLMs的性能

Method: 使用最先进的多语言LLM生成覆盖11种语言和4个分类任务的合成数据集，通过微调、指令调优或作为上下文示例训练小型模型

Result: 即使少量合成数据也能使小型模型超越大型生成器，在低资源语言中效果尤其显著

Conclusion: LLMs最佳用途是作为生成器（教师）而非分类器，其生成的合成数据能赋能更小、更高效的多语言模型

Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.

</details>


### [9] [Generating Literature-Driven Scientific Theories at Scale](https://arxiv.org/abs/2601.16282)
*Peter Jansen,Peter Clark,Doug Downey,Daniel S. Weld*

Main category: cs.CL

TL;DR: 该研究开发了一个从大量科学文献中合成定性定量理论的大规模系统，使用13.7k篇源论文生成了2.9k个理论，比较了文献基础与参数化知识生成方法的差异


<details>
  <summary>Details</summary>
Motivation: 当前自动化科学发现主要关注实验生成代理，而理论构建等更高层次的科学活动系统仍未被充分探索。需要开发能够从大规模科学文献中合成理论的方法

Method: 从13.7k篇源论文中合成2.9k个理论，比较了两种生成方法：1）基于文献基础的方法（文献支持），2）基于参数化LLM记忆的方法。同时研究了准确性导向与新颖性导向的生成目标如何影响理论特性

Result: 实验表明，与使用参数化LLM记忆生成相比，文献支持方法创建的理论在匹配现有证据和预测未来结果（基于4.6k篇后续论文）方面都显著更好

Conclusion: 文献基础的理论生成方法比参数化知识方法更有效，能够产生既符合现有证据又能预测未来发现的理论，为大规模自动化理论构建提供了可行路径

Abstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem of synthesizing theories consisting of qualitative and quantitative laws from large corpora of scientific literature. We study theory generation at scale, using 13.7k source papers to synthesize 2.9k theories, examining how generation using literature-grounding versus parametric knowledge, and accuracy-focused versus novelty-focused generation objectives change theory properties. Our experiments show that, compared to using parametric LLM memory for generation, our literature-supported method creates theories that are significantly better at both matching existing evidence and at predicting future results from 4.6k subsequently-written papers

</details>


### [10] [A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War](https://arxiv.org/abs/2601.16309)
*Dikshya Mohanty,Taisiia Sabadyn,Jelwin Rodrigues,Chenlu Wang,Abhishek Kalugade,Ritwik Banerjee*

Main category: cs.CL

TL;DR: DNIPRO是一个包含24.6万篇新闻文章的多语言语料库，记录了2022年2月至2024年8月的俄乌战争，涵盖5个国家11个媒体，支持跨国战时话语分析。


<details>
  <summary>Details</summary>
Motivation: 为了系统研究冲突时期的跨国话语，需要包含竞争性地缘政治视角的多语言资源，以分析叙事分歧、媒体框架和信息战。

Method: 构建了包含英语、俄语和中文的246K新闻文章语料库，涵盖俄罗斯、乌克兰、美国、英国和中国媒体，包含一致的元数据和多种注释类型，并进行了严格的人工评估。

Result: 通过立场检测、情感分析、主题框架和矛盾分析等用例实验，揭示了媒体如何构建竞争性现实，报道呈现反映地缘政治利益的极化解释。

Conclusion: DNIPRO为理解冲突叙事如何在全球信息生态系统中出现和演变提供了基础资源，支持计算新闻学研究，特别适合研究叙事分歧和媒体框架。

Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.

</details>


### [11] [Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks](https://arxiv.org/abs/2601.16312)
*Dikshya Mohanty,Mohammad Saqib Hasan,Syed Mostofa Monsur,Size Zheng,Benjamin Hsiao,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: PolyBench是一个包含125K+聚合物设计任务的大规模训练测试基准数据集，通过知识增强推理蒸馏方法训练的小型语言模型在聚合物设计任务上超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在聚合物设计领域效果不佳，因为缺乏聚合物特定知识，且现有对齐模型缺乏聚合物设计相关知识和能力覆盖。

Method: 构建PolyBench基准数据集（125K+任务，基于13M+数据点），引入知识增强推理蒸馏方法，使用结构化思维链增强数据，任务从简单到复杂组织。

Result: 7B-14B参数的小型语言模型在PolyBench测试集上超越类似规模模型甚至闭源前沿LLMs，在其他聚合物基准上也表现更好。

Conclusion: PolyBench基准和知识增强推理蒸馏方法能有效提升语言模型在聚合物设计领域的性能，小型模型通过专门训练可以超越大型通用模型。

Abstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.

</details>


### [12] [Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP](https://arxiv.org/abs/2601.16314)
*Andres Karjus,Kais Allkivi,Silvia Maine,Katarin Leppik,Krister Kruusmaa,Merilin Aruvee*

Main category: cs.CL

TL;DR: LLM自动评分在爱沙尼亚全国考试中表现与人类评分相当，可用于高风险写作评估，并生成个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 传统人工评分耗时且一致性有限，特别是在大规模全国性考试中需要快速评分。研究探索LLM在爱沙尼亚全国考试中的适用性，验证自动化评分在高风险评估中的可行性。

Method: 使用两个爱沙尼亚全国考试作文数据集，基于官方课程标准的评分标准，比较LLM和统计NLP方法与人类专家评分的表现，同时评估偏见、提示注入风险和LLM作为作文写手的能力。

Result: 自动化评分表现与人类评分相当，通常落在人类评分范围内。系统能生成细粒度的子分数档案，用于个性化反馈。研究证实LLM辅助评估可在全国范围内实施，即使在小型语言环境中也能保持人类监督。

Conclusion: 基于原则、评分标准驱动、人类参与的评分流程对高风险写作评估是可行的，特别适合数字化先进社会。LLM辅助评估可在全国规模实施，同时保持人类监督和符合教育监管标准。

Abstract: Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.

</details>


### [13] [Regional Bias in Large Language Models](https://arxiv.org/abs/2601.16349)
*M P V S Gopinadh,Kappara Lakshmi Sindhu,Soma Sekhar Pandu Ranga Raju P,Yesaswini Swarna*

Main category: cs.CL

TL;DR: 该研究评估了10个主流大语言模型的区域偏见，发现GPT-3.5偏见最严重(9.5分)，Claude 3.5 Sonnet最公平(2.5分)，表明区域偏见会损害LLM的可靠性、公平性和包容性。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中的区域偏见问题，这是AI公平性和全球代表性领域的新兴关注点。区域偏见可能影响LLM在跨文化应用中的可靠性、公平性和包容性。

Method: 使用包含100个精心设计的提示词的数据集，在情境中立场景下评估10个主流LLM的区域偏见。引入FAZE评估框架，通过基于提示的方法在10分制上测量区域偏见。

Result: 不同模型间存在显著偏见差异：GPT-3.5偏见最严重(9.5分)，Claude 3.5 Sonnet最公平(2.5分)。其他模型如GPT-4o、Gemini系列、Claude 3 Opus、Llama 3、Gemma 7B、Mistral 7B和Vicuna-13B也显示出不同程度的区域偏见。

Conclusion: 区域偏见会显著损害LLM在现实世界跨文化应用中的可靠性、公平性和包容性。该研究强调了包容性评估框架和系统性方法在识别和缓解语言模型地理偏见中的重要性。

Abstract: This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.

</details>


### [14] [Identity, Cooperation and Framing Effects within Groups of Real and Simulated Humans](https://arxiv.org/abs/2601.16355)
*Suhong Moon,Minwoo Kang,Joseph Suh,Mustafa Safdari,John Canny*

Main category: cs.CL

TL;DR: LLMs通过深度绑定身份叙事和上下文因素，能更准确地模拟人类在社会困境游戏中的行为，改进实验复现的保真度。


<details>
  <summary>Details</summary>
Motivation: 人类行为既受理性思考影响，也受身份和情境因素影响。现有研究多通过"引导"聊天模型来模拟人物，但缺乏对身份基础行为的深度绑定，需要探索如何更忠实地复现人类行为。

Method: 通过将基础语言模型与扩展的背景故事深度绑定，并利用指令调优模型检查一致性，同时建模时间、问题框架、参与者群体等上下文因素。

Result: 通过丰富的叙事身份条件化和上下文因素建模，显著提高了模拟结果与人类研究的保真度，能够捕捉通常被实验描述忽略但影响准确复现的细节。

Conclusion: LLMs能够有效模拟人类在社会困境中的行为，通过深度绑定身份叙事和建模上下文因素，为理解人类行为细节和改进实验复现提供了有力工具。

Abstract: Humans act via a nuanced process that depends both on rational deliberation and also on identity and contextual factors. In this work, we study how large language models (LLMs) can simulate human action in the context of social dilemma games. While prior work has focused on "steering" (weak binding) of chat models to simulate personas, we analyze here how deep binding of base models with extended backstories leads to more faithful replication of identity-based behaviors. Our study has these findings: simulation fidelity vs human studies is improved by conditioning base LMs with rich context of narrative identities and checking consistency using instruction-tuned models. We show that LLMs can also model contextual factors such as time (year that a study was performed), question framing, and participant pool effects. LLMs, therefore, allow us to explore the details that affect human studies but which are often omitted from experiment descriptions, and which hamper accurate replication.

</details>


### [15] [PolyAgent: Large Language Model Agent for Polymer Design](https://arxiv.org/abs/2601.16376)
*Vani Nigam,Achuth Chandrasekhar,Amir Barati Farimani*

Main category: cs.CL

TL;DR: 开发了一个集成在终端中的闭环聚合物结构-性能预测框架，利用LLM推理为实验室研究人员提供聚合物性能预测、性能导向的聚合物结构生成和结构修改功能。


<details>
  <summary>Details</summary>
Motivation: 聚合物发现对生物医学和增强材料等行业至关重要，但传统实验方法试错过程长、资源消耗大。虽然机器学习已加速了性能预测和潜在空间搜索，但实验室研究人员由于基础设施限制难以访问相关代码和模型。

Method: 开发了一个集成在终端中的闭环聚合物结构-性能预测框架，利用LLM推理提供性能预测、性能导向的聚合物结构生成和结构修改功能。使用SMILES序列，并通过合成可及性评分和合成复杂性评分（SC Score）指导，确保生成的聚合物尽可能接近可合成的单体级结构。

Result: 该框架解决了为实验室研究人员生成新型聚合物结构的挑战，为聚合物研究提供了计算洞察。通过集成在终端中，使研究人员能够直接访问和使用这些功能，无需复杂的代码和基础设施。

Conclusion: 提出的框架通过将LLM推理与聚合物科学相结合，为早期聚合物发现提供了一个实用的解决方案，使实验室研究人员能够更高效地进行聚合物设计和优化，加速聚合物材料的发现过程。

Abstract: On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific discovery at the property prediction and latent space search fronts. However, laboratory researchers cannot readily access codes and these models to extract individual structures and properties due to infrastructure limitations. We present a closed-loop polymer structure-property predictor integrated in a terminal for early-stage polymer discovery. The framework is powered by LLM reasoning to provide users with property prediction, property-guided polymer structure generation, and structure modification capabilities. The SMILES sequences are guided by the synthetic accessibility score and the synthetic complexity score (SC Score) to ensure that polymer generation is as close as possible to synthetically accessible monomer-level structures. This framework addresses the challenge of generating novel polymer structures for laboratory researchers, thereby providing computational insights into polymer research.

</details>


### [16] [Cross-Lingual Activation Steering for Multilingual Language Models](https://arxiv.org/abs/2601.16390)
*Rhitabrat Pokharel,Ameeta Agrawal,Tanay Nagar*

Main category: cs.CL

TL;DR: CLAS是一种无需训练、在推理时选择性调节神经元激活的方法，通过跨语言激活引导提升低资源语言性能，同时保持高资源语言表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具备多语言能力，但主导语言与非主导语言之间存在显著性能差距。先前研究认为这种差距源于多语言表示中共享神经元与语言特定神经元之间的不平衡。

Method: 提出跨语言激活引导（CLAS），这是一种无需训练的推理时干预方法，能够选择性地调节神经元激活。该方法不修改模型权重，只在推理过程中调整激活模式。

Result: 在分类和生成基准测试中，CLAS分别实现了平均2.3%（准确率）和3.4%（F1分数）的提升，同时保持了高资源语言的性能。研究发现有效迁移通过功能分歧而非严格对齐实现，性能提升与语言簇分离度增加相关。

Conclusion: 目标激活引导可以在不修改模型权重的情况下，解锁现有模型的潜在多语言能力。这表明通过推理时干预可以有效缓解多语言模型中的语言不平衡问题。

Abstract: Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.

</details>


### [17] [Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization](https://arxiv.org/abs/2601.16397)
*Qianqi Yan,Huy Nguyen,Sumana Srivatsa,Hari Bandi,Xin Eric Wang,Krishnaram Kenthapadi*

Main category: cs.CL

TL;DR: 提出无需训练的生成时源归属框架，利用解码器注意力直接引用支持文本或图像，在临床对话和放射报告上优于嵌入和自归属基线。


<details>
  <summary>Details</summary>
Motivation: 可信的临床摘要不仅需要流畅生成，还需要透明度说明每个陈述的来源。现有方法存在事后处理或需要重新训练的限制。

Method: 提出训练免费的生成时源归属框架，利用解码器注意力直接引用支持文本或图像。引入两种多模态归属策略：原始图像模式（直接使用图像块注意力）和标题作为跨度模式（用生成标题替代图像实现纯文本对齐）。

Result: 在临床医患对话（CliConSummation）和放射学报告（MIMIC-CXR）评估中，该方法始终优于基于嵌入和自归属基线，提升文本级和多模态归属准确性（如F1提高15%）。基于标题的归属在保持竞争力的同时更轻量实用。

Conclusion: 注意力引导的归属是迈向可解释和可部署临床摘要系统的有希望步骤，在保持性能的同时提高了透明度和实用性。

Abstract: Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.

</details>


### [18] [Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification](https://arxiv.org/abs/2601.16400)
*Zongwan Cao,Bingbing Wen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: CoA是一个澄清或回答的智能体，通过判断是否需要澄清来提升视觉问答的准确性，在模糊情况下先询问澄清问题再回答


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉问答往往是上下文依赖的，图像-问题对可能不够明确，正确答案需要依赖图像中不可观察的外部信息。直接回答可能导致自信但错误的预测。

Method: 提出CoA（澄清或回答）代理，分别建模决定询问或回答的决策，以及需要时询问什么。首先判断是否需要澄清，如果需要，提出一个聚焦的问题，然后结合回答产生最终答案。引入CONTEXTCLARIFY数据集和GRPO-CR强化学习方法优化澄清问题生成。

Result: 在三个VLLM和三个数据集上，CoA在模块和系统层面都实现了持续改进，端到端VQA准确率平均比基于提示的基线提高了+15.3分（83%）。

Conclusion: CoA框架通过主动澄清模糊问题，显著提升了视觉问答系统在现实场景中的准确性和可靠性，解决了上下文依赖问题带来的挑战。

Abstract: Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines

</details>


### [19] [Jacobian Scopes: token-level causal attributions in LLMs](https://arxiv.org/abs/2601.16407)
*Toni J. B. Liu,Baran Zadeoğlu,Nicolas Boullé,Raphaël Sarfati,Christopher J. Earls*

Main category: cs.CL

TL;DR: 提出Jacobian Scopes方法，基于梯度进行token级因果归因，用于解释LLM预测，包含三种变体分别针对特定logit、预测分布和模型置信度。


<details>
  <summary>Details</summary>
Motivation: 由于现代LLM架构中层级和注意力头数量庞大，难以确定哪些先前的token对特定预测影响最大，需要有效的token级因果归因方法来解释LLM预测。

Method: 提出Jacobian Scopes方法，通过分析最终隐藏状态相对于输入的线性化关系，量化输入token对模型预测的影响。包含三种变体：Semantic Scope（针对特定logit的敏感性）、Fisher Scope（针对完整预测分布）、Temperature Scope（针对模型置信度/逆温度）。

Result: 通过指令理解、翻译和上下文学习等案例研究，发现了有趣的现象，如Jacobian Scopes揭示了隐性的政治偏见。该方法也为最近讨论的上下文时间序列预测机制提供了见解。

Conclusion: Jacobian Scopes是一套有效的梯度基token级因果归因方法，能够解释LLM预测，揭示了模型决策过程，并为理解上下文学习机制提供了新视角。

Abstract: Large language models (LLMs) make next-token predictions based on clues present in their context, such as semantic descriptions and in-context examples. Yet, elucidating which prior tokens most strongly influence a given prediction remains challenging due to the proliferation of layers and attention heads in modern architectures. We propose Jacobian Scopes, a suite of gradient-based, token-level causal attribution methods for interpreting LLM predictions. By analyzing the linearized relations of final hidden state with respect to inputs, Jacobian Scopes quantify how input tokens influence a model's prediction. We introduce three variants - Semantic, Fisher, and Temperature Scopes - which respectively target sensitivity of specific logits, the full predictive distribution, and model confidence (inverse temperature). Through case studies spanning instruction understanding, translation and in-context learning (ICL), we uncover interesting findings, such as when Jacobian Scopes point to implicit political biases. We believe that our proposed methods also shed light on recently debated mechanisms underlying in-context time-series forecasting. Our code and interactive demonstrations are publicly available at https://github.com/AntonioLiu97/JacobianScopes.

</details>


### [20] [Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning](https://arxiv.org/abs/2601.16419)
*Qinglong Cao,Yuntian Chen,Chao Ma,Xiaokang Yang*

Main category: cs.CL

TL;DR: 当前多模态大语言模型在专业领域（如遥感和医学影像）表现有限，研究发现仅通过文本指令注入领域知识效果不佳，必须通过优化层面整合领域知识才能有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在通用任务上表现出色，但在遥感、医学影像等专业领域效果有限。传统方法通过文本指令、提示或辅助描述注入领域知识，但这些输入层面的方法效果甚微，表明当前模型无法仅通过语言内部化领域特定先验知识。

Method: 提出强化微调框架，将领域知识直接整合到学习目标中。不是将领域知识作为描述性信息，而是将其编码为领域感知的约束和奖励信号，在输出空间塑造模型行为。

Result: 在遥感和医学领域的多个数据集上进行广泛实验，均取得显著性能提升，在多模态领域任务上达到最先进水平。

Conclusion: 研究强调了优化层面领域知识整合的必要性，揭示了当前多模态大语言模型中文本领域条件化的根本局限性，为专业领域应用提供了有效解决方案。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities in multimodal perception and understanding tasks. However, their effectiveness in specialized domains, such as remote sensing and medical imaging, remains limited. A natural approach to domain adaptation is to inject domain knowledge through textual instructions, prompts, or auxiliary captions. Surprisingly, we find that such input-level domain knowledge injection yields little to no improvement on scientific multimodal tasks, even when the domain knowledge is explicitly provided. This observation suggests that current MLLMs fail to internalize domain-specific priors through language alone, and that domain knowledge must be integrated at the optimization level. Motivated by this insight, we propose a reinforcement fine-tuning framework that incorporates domain knowledge directly into the learning objective. Instead of treating domain knowledge as descriptive information, we encode it as domain-informed constraints and reward signals, shaping the model's behavior in the output space. Extensive experiments across multiple datasets in remote sensing and medical domains consistently demonstrate good performance gains, achieving state-of-the-art results on multimodal domain tasks. Our results highlight the necessity of optimization-level domain knowledge integration and reveal a fundamental limitation of textual domain conditioning in current MLLMs.

</details>


### [21] [Exploring the Effects of Alignment on Numerical Bias in Large Language Models](https://arxiv.org/abs/2601.16444)
*Ayako Sato,Hwichan Kim,Zhousi Chen,Masato Mita,Mamoru Komachi*

Main category: cs.CL

TL;DR: 研究发现LLM评估器存在数值偏见问题，这种偏见源于对齐过程，通过分数范围调整可以有效缓解偏见


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器在许多评估任务中表现有效，但存在数值偏见问题（某些评分被过度使用），导致评估性能下降。本研究旨在探究这种偏见的成因

Method: 1) 比较对齐前后LLM的输出，验证对齐是否导致数值偏见；2) 探索三种缓解策略：温度缩放、分布校准和分数范围调整

Result: 1) 对齐确实增加了数值偏见；2) 在三种缓解策略中，分数范围调整在减少偏见和提升性能方面最有效，但仍属启发式方法

Conclusion: LLM评估器的数值偏见源于对齐过程，分数范围调整是有效的缓解方法，但需要进一步研究最优分数范围选择和更鲁棒的缓解策略

Abstract: ``LLM-as-a-judge,'' which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.

</details>


### [22] [Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go](https://arxiv.org/abs/2601.16447)
*Yichuan Ma,Linyang Li,Yongkang Chen,Peiji Li,Jiasheng Ye,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: LoGos是一个通过混合微调和强化学习将通用LLM推理能力与围棋专业知识结合的模型，在保持通用推理能力的同时达到人类专业棋手水平


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在数学和编程等通用推理任务上表现出色，但在围棋等专业领域表现不佳，远低于AlphaGo等专业AI系统。这种通用LLM与领域专家之间的性能差距限制了LLM在更广泛专业任务中的应用。

Method: 1. 使用结构化围棋专业知识和通用长链思维推理数据进行混合微调作为冷启动；2. 通过强化学习将围棋专业知识与通用推理能力整合；3. 开发LoGos模型，使其能用自然语言进行围棋对弈。

Result: LoGos不仅保持了出色的通用推理能力，还能用自然语言进行围棋对弈，展示有效的战略推理和准确的下一步预测。其性能达到人类专业棋手水平，显著超越所有现有LLM。

Conclusion: 该工作展示了如何将通用LLM推理能力应用于专业领域，并贡献了首个大规模围棋LLM训练数据集、首个LLM围棋评估基准和首个达到人类专业水平的通用LLM。为将LLM应用于其他专业领域提供了见解。

Abstract: Large language models (LLMs) have demonstrated exceptional performance in reasoning tasks such as mathematics and coding, matching or surpassing human capabilities. However, these impressive reasoning abilities face significant challenges in specialized domains. Taking Go as an example, although AlphaGo has established the high performance ceiling of AI systems in Go, mainstream LLMs still struggle to reach even beginner-level proficiency, let alone perform natural language reasoning. This performance gap between general-purpose LLMs and domain experts is significantly limiting the application of LLMs on a wider range of domain-specific tasks. In this work, we aim to bridge the divide between LLMs' general reasoning capabilities and expert knowledge in domain-specific tasks. We perform mixed fine-tuning with structured Go expertise and general long Chain-of-Thought (CoT) reasoning data as a cold start, followed by reinforcement learning to integrate expert knowledge in Go with general reasoning capabilities. Through this methodology, we present \textbf{LoGos}, a powerful LLM that not only maintains outstanding general reasoning abilities, but also conducts Go gameplay in natural language, demonstrating effective strategic reasoning and accurate next-move prediction. LoGos achieves performance comparable to human professional players, substantially surpassing all existing LLMs. Through this work, we aim to contribute insights on applying general LLM reasoning capabilities to specialized domains. We will release the first large-scale Go dataset for LLM training, the first LLM Go evaluation benchmark, and the first general LLM that reaches human professional-level performance in Go at: https://github.com/Entarochuan/LoGos.

</details>


### [23] [Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16462)
*Zhenghao Liu,Mingyan Wu,Xinze Li,Yukun Yan,Shuo Wang,Cheng Yang,Minghe Yu,Zheni Zeng,Maosong Sun*

Main category: cs.CL

TL;DR: GraphAnchor：一种新颖的图锚定知识索引方法，将静态图结构重构为动态演化的知识索引，通过迭代检索更新图结构来锚定关键实体和关系，指导LLM评估知识充分性并生成子查询，显著提升多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理分散在噪声文档中的关键证据时面临集成和解释的挑战，需要更有效的方法来整合和解释跨文档的关键信息。

Method: 提出GraphAnchor方法：1）将图结构从静态知识表示重构为动态演化的知识索引；2）在迭代检索过程中增量更新图结构，锚定关键实体和关系；3）利用结构化索引指导LLM评估知识充分性并生成后续子查询；4）最终答案基于所有检索文档和演化后的图联合生成。

Result: 在四个多跳问答基准测试中验证了GraphAnchor的有效性，实验表明GraphAnchor能够调节LLM的注意力，更有效地关联检索文档中分布的关键信息。

Conclusion: GraphAnchor通过动态演化的图索引显著提升了RAG系统在多跳问答任务中的性能，为解决跨文档信息整合和解释问题提供了有效方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.

</details>


### [24] [Persona Jailbreaking in Large Language Models](https://arxiv.org/abs/2601.16466)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: PHISH框架通过历史对话中的隐式引导，在仅推理的黑盒设置下实现对LLM人格的对抗性编辑，暴露了LLM在人格稳定性方面的新漏洞。


<details>
  <summary>Details</summary>
Motivation: LLM在教育、心理健康、客服等需要稳定人格的领域部署日益增多，但现有研究忽视了对活历史如何重塑诱导人格，黑盒人格操纵尚未探索，存在现实交互中的鲁棒性隐患。

Method: 提出PHISH框架，通过在用户查询中嵌入语义线索，逐步诱导反向人格，定义了量化攻击成功的指标，在3个基准测试和8个LLM上进行评估。

Result: PHISH可预测地改变人格，触发相关特征的连带变化，在多轮对话中效果更强；在高风险领域能可靠操纵人格，对推理性能影响小，整体实用性基本保持。

Conclusion: 当前防护措施仅提供部分保护，在持续攻击下仍显脆弱，暴露了LLM人格的新漏洞，凸显了开发上下文弹性人格的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH

</details>


### [25] [DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering](https://arxiv.org/abs/2601.16478)
*Haotian Chen,Qingqing Long,Siyu Pu,Xiao Luo,Wei Ju,Meng Xiao,Yuanchun Zhou,Jianghua Zhao,Xuezhi Wang*

Main category: cs.CL

TL;DR: 本文提出DeepEra方法解决科学问答中语义相似但逻辑无关的检索问题，并构建了SciRAG-SSLI数据集进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 随着科学文献快速增长，科学问答变得日益重要。现有检索增强生成方法容易受到语义相似但逻辑无关段落的影响，这会降低事实可靠性并加剧幻觉问题。

Method: 提出Deep Evidence Reranking Agent (DeepEra)，通过逐步推理机制更精确评估候选段落，超越表层语义匹配。构建SciRAG-SSLI数据集，包含约30万个科学问答实例，涵盖10个学科，从1000万科学语料中构建，结合自然检索上下文和系统生成的干扰项。

Result: 综合评估表明，该方法相比领先的重新排序器实现了更优的检索性能。这是首个全面研究并实证验证两阶段RAG框架中不可忽视的SSLI问题的工作。

Conclusion: DeepEra通过集成逐步推理有效解决了科学问答中语义相似但逻辑无关的检索挑战，构建的大规模数据集为系统评估提供了基础，显著提升了检索增强生成的事实可靠性。

Abstract: With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.

</details>


### [26] [TL-GRPO: Turn-Level RL for Reasoning-Guided Iterative Optimization](https://arxiv.org/abs/2601.16480)
*Peiji Li,Linyang Li,Handa Sun,Wenjin Mai,Yongkang Chen,Xiaozhe Li,Yue Shen,Yichuan Ma,Yiliu Sun,Jiaxi Cao,Zhishu He,Bo Wang,Xiaoqing Zheng,Zhaori Bi,Xipeng Qiu,Qipeng Guo,Kai Chen,Dahua Lin*

Main category: cs.CL

TL;DR: TL-GRPO：针对迭代优化任务的轻量级RL算法，通过轮次级分组采样实现细粒度优化，在模拟电路设计任务中超越标准GRPO和贝叶斯优化方法


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法无法在迭代优化任务中进行细粒度的轮次级优化，而黑盒优化方法则丢弃了先验知识和推理能力，需要一种能结合两者优势的解决方案

Method: 提出TL-GRPO（轮次级GRPO），一种轻量级强化学习算法，通过轮次级分组采样实现细粒度优化，特别适用于需要与环境状态多次交互的迭代优化任务

Result: TL-GRPO在模拟电路设计任务中表现优于标准GRPO和贝叶斯优化方法，30B模型在相同仿真预算下达到最先进性能，展现出强大的泛化能力和实用价值

Conclusion: TL-GRPO成功解决了迭代优化任务中的细粒度优化问题，为大语言模型在科学优化任务中的应用提供了有效的强化学习框架

Abstract: Large language models have demonstrated strong reasoning capabilities in complex tasks through tool integration, which is typically framed as a Markov Decision Process and optimized with trajectory-level RL algorithms such as GRPO. However, a common class of reasoning tasks, iterative optimization, presents distinct challenges: the agent interacts with the same underlying environment state across turns, and the value of a trajectory is determined by the best turn-level reward rather than cumulative returns. Existing GRPO-based methods cannot perform fine-grained, turn-level optimization in such settings, while black-box optimization methods discard prior knowledge and reasoning capabilities. To address this gap, we propose Turn-Level GRPO (TL-GRPO), a lightweight RL algorithm that performs turn-level group sampling for fine-grained optimization. We evaluate TL-GRPO on analog circuit sizing (ACS), a challenging scientific optimization task requiring multiple simulations and domain expertise. Results show that TL-GRPO outperforms standard GRPO and Bayesian optimization methods across various specifications. Furthermore, our 30B model trained with TL-GRPO achieves state-of-the-art performance on ACS tasks under same simulation budget, demonstrating both strong generalization and practical utility.

</details>


### [27] [Timely Machine: Awareness of Time Makes Test-Time Scaling Agentic](https://arxiv.org/abs/2601.16486)
*Yichuan Ma,Linyang Li,Yongkang chen,Peiji Li,Xiaozhe Li,Qipeng Guo,Dahua Lin,Kai Chen*

Main category: cs.CL

TL;DR: 论文提出Timely Machine框架，将测试时间重新定义为实际时钟时间而非生成长度，以适应工具调用场景，并开发了Timely-Eval基准和Timely-RL训练方法提升模型的时间预算感知能力。


<details>
  <summary>Details</summary>
Motivation: 在代理场景中，传统基于生成长度的测试时间定义失效，因为工具延迟使推理时间与生成长度解耦。需要重新定义测试时间为实际时钟时间，让模型能根据时间预算动态调整策略。

Method: 1. 提出Timely Machine框架，将测试时间定义为实际时钟时间；2. 创建Timely-Eval基准，涵盖高频工具调用、低频工具调用和时间约束推理任务；3. 提出Timely-RL方法，通过监督微调冷启动后，使用强化学习增强时间规划能力。

Result: 研究发现：小模型在快速反馈场景中表现更好（通过更多交互），大模型在高延迟场景中占优（通过更高质量的交互）；现有模型无法适应时间预算；Timely-RL显著提升了时间预算感知能力，在Timely-Eval基准上持续提升性能。

Conclusion: 该工作为代理时代的测试时间扩展提供了新视角，强调了实际时钟时间的重要性，并展示了通过强化学习训练模型时间规划能力的有效性。

Abstract: As large language models (LLMs) increasingly tackle complex reasoning tasks, test-time scaling has become critical for enhancing capabilities. However, in agentic scenarios with frequent tool calls, the traditional generation-length-based definition breaks down: tool latency decouples inference time from generation length. We propose Timely Machine, redefining test-time as wall-clock time, where models dynamically adjust strategies based on time budgets. We introduce Timely-Eval, a benchmark spanning high-frequency tool calls, low-frequency tool calls, and time-constrained reasoning. By varying tool latency, we find smaller models excel with fast feedback through more interactions, while larger models dominate high-latency settings via superior interaction quality. Moreover, existing models fail to adapt reasoning to time budgets. We propose Timely-RL to address this gap. After cold-start supervised fine-tuning, we use reinforcement learning to enhance temporal planning. Timely-RL improves time budget awareness and consistently boosts performance across Timely-Eval. We hope our work offers a new perspective on test-time scaling for the agentic era.

</details>


### [28] [MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine](https://arxiv.org/abs/2601.16503)
*Wei Zhu*

Main category: cs.CL

TL;DR: MRAG基准：首个医疗领域检索增强生成（RAG）综合评估基准，包含中英文任务、数据集和工具包，用于系统评估RAG在医疗QA中的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然RAG技术已在科学和临床QA系统中迅速应用，但医疗领域缺乏全面的评估基准，这阻碍了对RAG系统性能的系统性研究和改进。

Method: 构建MRAG基准，涵盖中英文多种医疗任务，基于Wikipedia和PubMed构建语料库，并开发MRAG-Toolkit工具包，用于系统探索不同RAG组件。

Result: 实验发现：(a) RAG提升LLM在MRAG任务中的可靠性；(b) RAG系统性能受检索方法、模型大小和提示策略影响；(c) RAG改善有用性和推理质量，但可能略微降低长问题回答的可读性。

Conclusion: MRAG基准填补了医疗领域RAG评估的空白，提供了系统评估工具，将开源数据集和工具包以CCBY-4.0许可发布，促进学术界和工业界应用。

Abstract: While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.

</details>


### [29] [LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning](https://arxiv.org/abs/2601.16504)
*Obed Junias,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: LOGICAL-COMMONSENSEQA是一个新的常识推理基准测试，将推理重新定义为逻辑组合（AND、OR、NEITHER/NOR），而非传统的单一标签评估，以揭示模型在组合推理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有常识推理基准测试大多依赖单一标签评估，无法区分陈述是联合合理、互斥还是联合不合理，这掩盖了模型在组合推理方面的真实能力。

Method: 引入LOGICAL-COMMONSENSEQA基准测试，将常识推理重新定义为原子陈述对之间的逻辑组合，使用合理性级别运算符（AND、OR、NEITHER/NOR）。在零样本、少样本和思维链提示下评估指令调优、推理专业化和微调模型。

Result: 模型在合取推理上表现合理，在析取推理上表现中等，但在基于否定的问题上性能急剧下降。该基准测试暴露了模型在基本推理方面的局限性。

Conclusion: LOGICAL-COMMONSENSEQA揭示了当前模型在组合常识推理方面的根本限制，为推进组合常识推理提供了一个受控框架。

Abstract: Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.

</details>


### [30] [Is Length Really A Liability? An Evaluation of Multi-turn LLM Conversations using BoolQ](https://arxiv.org/abs/2601.16508)
*Karl Neergaard,Le Qiu,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 研究发现对话长度会影响LLM回答的真实性，单轮测试无法发现模型在对话中的特定脆弱性


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试主要采用单轮提示评估，但无法捕捉真实世界中发生危害的对话动态。研究者想探究对话长度是否会影响LLM回答的真实性

Method: 在BoolQ数据集上评估三个不同LLM在不同对话长度和支架条件下的表现，通过多轮对话设置来测试模型性能

Result: 结果揭示了模型特定的脆弱性，这些脆弱性在单轮测试中不可见。观察到长度依赖和支架特定的效应，表明静态评估存在根本性局限

Conclusion: 部署相关的脆弱性只能在多轮对话设置中被发现，这证明了静态评估的局限性，强调了对话动态评估的重要性

Abstract: Single-prompt evaluations dominate current LLM benchmarking, yet they fail to capture the conversational dynamics where real-world harm occurs. In this study, we examined whether conversation length affects response veracity by evaluating LLM performance on the BoolQ dataset under varying length and scaffolding conditions. Our results across three distinct LLMs revealed model-specific vulnerabilities that are invisible under single-turn testing. The length-dependent and scaffold-specific effects we observed demonstrate a fundamental limitation of static evaluations, as deployment-relevant vulnerabilities could only be spotted in a multi-turn conversational setting.

</details>


### [31] [SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine](https://arxiv.org/abs/2601.16512)
*Hoang-Quoc Nguyen-Son,Minh-Son Dao,Koji Zettsu*

Main category: cs.CL

TL;DR: SearchLLM：通过搜索引擎查找潜在原文来源，分析相似性来检测LLM改写的文本，可增强现有检测器的性能


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，用户常使用LLM改写文本以提高质量，但这可能导致原始意图的丢失或扭曲。传统检测方法难以识别LLM生成的类人文本，特别是当改写内容与原文高度相似时

Method: 提出SearchLLM方法，利用搜索引擎查找潜在原文来源，分析输入文本与候选来源的再生版本之间的相似性，从而识别LLM改写的文本。该方法设计为代理层，可与现有检测器无缝集成

Result: 实验结果表明，SearchLLM能持续提升现有检测器在识别高度模仿原文的LLM改写文本方面的准确性，并帮助检测器防止改写攻击

Conclusion: SearchLLM通过结合搜索引擎能力，有效解决了LLM改写文本的检测难题，增强了现有检测系统的性能，为应对LLM改写攻击提供了实用解决方案

Abstract: With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.

</details>


### [32] [Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification](https://arxiv.org/abs/2601.16530)
*Gaurav Maheshwari,Kevin El Haddad*

Main category: cs.CL

TL;DR: 使用LLM动态生成监督信号训练轻量级文本分类器，通过迭代代理循环提升数据质量，在四个基准测试中超越标准零样本/少样本基线


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和高容量编码器在零样本/少样本分类方面有进展，但其推理成本和延迟限制了实际部署，需要更高效的解决方案

Method: 提出训练轻量级文本分类器的方法：使用LLM动态生成监督信号，通过迭代代理循环让LLM策划训练数据、分析模型成功失败、合成针对性样本来解决观察到的错误

Result: 在四个广泛使用的基准测试中，该方法持续优于标准的零样本和少样本基线方法

Conclusion: LLM可以作为有效的数据策划者，实现准确高效的分类，同时避免了大型模型部署的操作成本

Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.

</details>


### [33] [Retrieve-Refine-Calibrate: A Framework for Complex Claim Fact-Checking](https://arxiv.org/abs/2601.16555)
*Mingwei Sun,Qianlong Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 提出基于大语言模型的检索-精炼-校准框架，通过识别实体、精炼证据和校准低置信度预测，提升事实核查准确性


<details>
  <summary>Details</summary>
Motivation: 现有事实核查方法通常采用分解范式，将声明分解为子声明进行验证，但这种范式可能因引入不相关实体或证据而产生噪声，降低验证准确性

Method: 提出检索-精炼-校准框架：1) 识别声明中的实体并检索相关证据；2) 基于声明精炼检索到的证据以减少不相关信息；3) 通过重新评估低置信度预测来校准验证过程

Result: 在两个流行的事实核查数据集上实验表明，该框架相比竞争基线取得了优越性能

Conclusion: 提出的RRC框架通过减少分解范式中的噪声问题，有效提升了事实核查的准确性

Abstract: Fact-checking aims to verify the truthfulness of a claim based on the retrieved evidence. Existing methods typically follow a decomposition paradigm, in which a claim is broken down into sub-claims that are individually verified. However, the decomposition paradigm may introduce noise to the verification process due to irrelevant entities or evidence, ultimately degrading verification accuracy. To address this problem, we propose a Retrieve-Refine-Calibrate (RRC) framework based on large language models (LLMs). Specifically, the framework first identifies the entities mentioned in the claim and retrieves evidence relevant to them. Then, it refines the retrieved evidence based on the claim to reduce irrelevant information. Finally, it calibrates the verification process by re-evaluating low-confidence predictions. Experiments on two popular fact-checking datasets (HOVER and FEVEROUS-S) demonstrate that our framework achieves superior performance compared with competitive baselines.

</details>


### [34] [Attention-MoA: Enhancing Mixture-of-Agents via Inter-Agent Semantic Attention and Deep Residual Synthesis](https://arxiv.org/abs/2601.16596)
*Jianyu Wen,Yang Wei,Xiongxi Yu,Changxuan Xiao,Ke Zeng*

Main category: cs.CL

TL;DR: Attention-MoA：一种基于注意力机制的新型混合代理框架，通过代理间语义注意力实现深度协作，结合层间残差模块和自适应早停机制，显著提升推理性能，使小型开源模型超越大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前MoA框架虽然通过动态路由和残差连接提高了效率，但未能促进代理间的深度语义交互，限制了系统纠正幻觉和优化逻辑的能力，需要更有效的协作机制。

Method: 提出Attention-MoA框架，核心是代理间语义注意力机制，让不同代理能深度交互语义信息；同时引入层间残差模块和自适应早停机制，缓解深层信息退化并提升计算效率。

Result: 在AlpacaEval 2.0上达到91.15%长度控制胜率，MT-Bench得分8.83，FLASK评估中12项能力中有10项领先；小型开源模型组合超越Claude-4.5-Sonnet和GPT-4.1等大型专有模型。

Conclusion: Attention-MoA通过创新的代理间语义注意力机制，实现了更有效的集体智能协作，显著提升了推理性能，证明了小型模型通过优化协作可以超越大型专有模型。

Abstract: As the development of Large Language Models (LLMs) shifts from parameter scaling to inference-time collaboration, the Mixture-of-Agents (MoA) framework has emerged as a general paradigm to harness collective intelligence by layering diverse models. While recent MoA variants have introduced dynamic routing and residual connections to improve efficiency, these methods often fail to facilitate deep semantic interaction between agents, limiting the system's ability to actively correct hallucinations and refine logic. In this paper, we introduce Attention-MoA, a novel MoA-based framework that redefines collaboration through Inter-agent Semantic Attention. Complemented by an Inter-layer Residual Module with Adaptive Early Stopping Mechanism, our architecture mitigates information degradation in deep layers while improving computational efficiency. Extensive evaluations across AlpacaEval 2.0, MT-Bench, and FLASK demonstrate that Attention-MoA significantly outperforms state-of-the-art baselines, achieving a 91.15% Length-Controlled Win Rate on AlpacaEval 2.0 and dominating in 10 out of 12 capabilities on FLASK. Notably, Attention-MoA enables an ensemble of small open-source models to outperform massive proprietary models like Claude-4.5-Sonnet and GPT-4.1, achieving an MT-Bench score of 8.83 and an AlpacaEval 2.0 LC Win Rate of 77.36%.

</details>


### [35] [AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model](https://arxiv.org/abs/2601.16615)
*Xiang Chen*

Main category: cs.CL

TL;DR: 本文介绍了AuroraEdge-V-2B，一个专为边缘部署设计的紧凑、鲁棒、高速的视觉大语言模型，通过压缩融合方法提高推理效率，在保持高性能的同时减少参数和视觉token数量。


<details>
  <summary>Details</summary>
Motivation: 随着多模态技术的发展，视觉大语言模型(VLLMs)在工业生产中的应用日益增多，但现有VLLMs存在参数过多、计算资源需求大、推理速度慢、在特定领域性能不如定制DLMs等问题，难以满足边缘部署的实时性要求。

Method: 提出AuroraEdge-V-2B模型，采用压缩融合方法提高推理效率，显著减少视觉token数量，模型仅有20亿参数，专门针对边缘部署优化。

Result: AuroraEdge-V-2B在9个基准测试中得分高于同等参数规模的模型（如Qwen2-VL-2B、Qwen2.5-VL-3B、InternVL-2.5-2B），推理时浮点运算减少一半，部署更简单，实时性更好。

Conclusion: AuroraEdge-V-2B通过紧凑设计、减少视觉token和优化推理效率，成功解决了VLLMs在工业应用中部署困难、计算资源需求大、速度慢的问题，为边缘环境提供了高性能的视觉大语言模型解决方案。

Abstract: Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some advantages in industrial applications: (1) Their strong generalization ability enables them to perform well across a wide range of tasks. (2) They are flexible and can deal with unfamiliar samples through context learning quickly. However, VLLMs also have obvious drawbacks: (1) VLLMs do not perform as well as custom-developed DLMs in specific domains. (2) The number of parameters in VLLMs is generally quite large, and their deployment requires substantial computational resources. (3) VLLMs generally operate much slower than DLMs, making real-time response challenging to achieve. To better utilize VLLMs in industrial applications, we introduce AuroraEdge-V-2B in this work, a compact, robust, and high-speed VLLM designed for edge deployment. To make the model run faster, we also propose a compression-fusion method to improve inference efficiency. AuroraEdge-V-2B has the following notable features: (1) Easy deployment and faster: It has only 2B parameters and is highly suitable for edge deployment, offering better real-time performance. (2) Fewer visual tokens and cheaper: It significantly reduces the number of visual tokens in the decoding process, thereby reducing the floating-point operations by half during inference and making it cheaper to use. (3) Strong performance: It gets a higher score on 9 benchmarks than models with the same number of parameter (e.g., Qwen2-VL-2B, Qwen2.5-VL-3B, InternVL-2.5-2B).

</details>


### [36] [PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs](https://arxiv.org/abs/2601.16618)
*Jing Xu,Jiaqi Wang,Daxin Tan,Xiao Chen*

Main category: cs.CL

TL;DR: PROST-LLM：通过渐进式方法提升大语言模型的语音到语音翻译能力，包括三任务学习、模态链、自采样和反向翻译生成偏好对，最后进行偏好优化。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在许多任务上表现出色，但在语音到语音翻译（S2ST）领域的应用尚未充分探索，且受到数据稀缺的限制。需要填补这一空白。

Method: 1. 使用CVSS语料库微调LLM，采用三任务学习和模态链方法提升初始性能；2. 利用微调后的模型通过自采样和反向翻译生成偏好对（无需人工评估）；3. 使用这些偏好对进行偏好优化，进一步提升S2ST能力。

Result: 大量实验证实了PROST-LLM在提升LLM的S2ST能力方面的有效性。

Conclusion: PROST-LLM通过渐进式方法成功提升了LLM在语音到语音翻译任务上的性能，为解决数据稀缺问题提供了有效方案。

Abstract: Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.

</details>


### [37] [How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants](https://arxiv.org/abs/2601.16621)
*Xueyang Feng,Weinan Gan,Xu Chen,Quanyu Dai,Yong Liu*

Main category: cs.CL

TL;DR: 论文提出RPEval基准和RP-Reasoner方法，用于评估和解决LLM个性化记忆导致的非理性个性化问题


<details>
  <summary>Details</summary>
Motivation: LLM助手集成记忆机制记录用户偏好，但无关的个性化记忆会干扰LLM意图理解，需要全面研究个性化的双重效应

Method: 开发RPEval基准（包含个性化意图推理数据集和多粒度评估协议），并提出RP-Reasoner方法，将记忆利用视为语用推理过程，选择性整合个性化信息

Result: RPEval揭示了现有LLM普遍存在非理性个性化现象，RP-Reasoner在RPEval上显著优于基线方法，解决了商业个性化助手中80%的不良案例

Conclusion: 语用推理有潜力缓解非理性个性化问题，RPEval基准公开可用，为个性化LLM研究提供重要工具

Abstract: Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.

</details>


### [38] [MultiLexNorm++: A Unified Benchmark and a Generative Model for Lexical Normalization for Asian Languages](https://arxiv.org/abs/2601.16623)
*Weerayut Buaphet,Thanh-Nhi Nguyen,Risa Kondo,Tomoyuki Kajiwara,Yumin Kim,Jimin Lee,Hwanhee Lee,Holy Lovenia,Peerat Limkonchotiwat,Sarana Nutanong,Rob Van der Goot*

Main category: cs.CL

TL;DR: 该论文扩展了MultiLexNorm基准，新增5种亚洲语言，提出基于大语言模型的架构，在跨语言词汇规范化任务上取得更稳健的性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体数据对NLP研究很重要，但因其非正式、自发性和多方言特性，NLP模型性能会下降。现有词汇规范化基准MultiLexNorm主要覆盖印欧语系拉丁字母语言，缺乏语言多样性。

Method: 扩展MultiLexNorm基准，新增5种不同语系、4种不同文字的亚洲语言。提出基于大语言模型的新架构，并分析现有模型的错误。

Result: 先前最先进模型在新语言上表现较差，而基于大语言模型的新架构展现出更稳健的性能。通过错误分析揭示了未来研究方向。

Conclusion: 扩展的基准填补了多语言词汇规范化研究的空白，基于大语言模型的方法在跨语言场景中表现更优，错误分析为后续研究提供了方向。

Abstract: Social media data has been of interest to Natural Language Processing (NLP) practitioners for over a decade, because of its richness in information, but also challenges for automatic processing. Since language use is more informal, spontaneous, and adheres to many different sociolects, the performance of NLP models often deteriorates. One solution to this problem is to transform data to a standard variant before processing it, which is also called lexical normalization. There has been a wide variety of benchmarks and models proposed for this task. The MultiLexNorm benchmark proposed to unify these efforts, but it consists almost solely of languages from the Indo-European language family in the Latin script. Hence, we propose an extension to MultiLexNorm, which covers 5 Asian languages from different language families in 4 different scripts. We show that the previous state-of-the-art model performs worse on the new languages and propose a new architecture based on Large Language Models (LLMs), which shows more robust performance. Finally, we analyze remaining errors, revealing future directions for this task.

</details>


### [39] [Typologically Informed Parameter Aggregation](https://arxiv.org/abs/2601.16629)
*Stef Accou,Wessel Poelman*

Main category: cs.CL

TL;DR: TIPA是一种无需训练的方法，通过基于类型学相似性聚合现有适配器来构建代理语言适配器，实现零样本跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 大规模多语言模型在低资源和未见语言上表现不佳，而基于适配器的微调虽然参数高效，但大规模训练语言特定适配器成本高昂。

Method: 提出类型学信息参数聚合(TIPA)，通过基于类型学相似性加权聚合现有适配器来构建代理语言适配器，集成到MAD-X框架中实现零样本跨语言迁移。

Result: 在5个NLP任务和230多种语言上评估，TIPA始终优于或匹配基线方法（如仅英语微调或选择类型学最接近的语言适配器），在缺乏专用适配器的语言上提升最大。

Conclusion: 类型学信息聚合为语言特定模块提供了可行的替代方案，无需任何训练，特别适用于资源匮乏的语言。

Abstract: Massively multilingual language models enable cross-lingual generalization but underperform on low-resource and unseen languages. While adapter-based fine-tuning offers a parameter-efficient solution, training language-specific adapters at scale remains costly. We introduce Typologically Informed Parameter Aggregation (TIPA), a training-free method that constructs proxy language adapters by aggregating existing ones, weighted by typological similarity. Integrated into the MAD-X framework, these proxies enable zero-shot cross-lingual transfer without additional training. We evaluate TIPA on five NLP tasks and over 230 languages. TIPA consistently outperforms or matches baselines such as English-only fine-tuning or selecting the typologically closest language adapter. We see the largest gains for languages lacking dedicated adapters. Our results demonstrate that typologically informed aggregation provides a viable alternative to language-specific modules without any training needed.

</details>


### [40] [Sycophancy Hides Linearly in the Attention Heads](https://arxiv.org/abs/2601.16644)
*Rifo Genadi,Munachiso Nwadike,Nurdaulet Mukhituly,Hilal Alquabeh,Tatsuya Hiraoka,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究发现：在多头注意力激活中，正确与错误奉承信号最易线性分离；通过线性探针可定位这些信号，并在中层注意力头中进行有效干预；TruthfulQA训练的探针可迁移到其他事实QA任务；事实准确性与抗顺从性机制相关但不同；注意力模式分析显示关键头过度关注用户怀疑表达。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解语言模型中的奉承行为（sycophancy）机制，探索如何通过分析模型内部表示来识别和干预这种偏差，特别是关注正确与错误答案之间的奉承信号如何在线性可分的注意力激活中体现。

Method: 1. 在多头注意力激活中寻找正确与错误奉承信号的线性可分性；2. 在残差流、MLP和注意力层训练线性探针分析信号出现位置；3. 使用TruthfulQA作为基础数据集训练探针；4. 通过注意力模式分析识别关键头的关注模式；5. 比较发现的"方向"与先前识别的"真实"方向。

Result: 1. 奉承信号在残差流和MLP中可分离，但最有效的干预位于中层注意力头的稀疏子集；2. TruthfulQA训练的探针能有效迁移到其他事实QA基准；3. 发现的"方向"与先前"真实"方向重叠有限，表明事实准确性和抗顺从性机制相关但不同；4. 关键注意力头过度关注用户怀疑表达，导致奉承性转变。

Conclusion: 奉承行为可通过简单、有针对性的线性干预来缓解，这些干预利用了注意力激活的内部几何结构；注意力层特别是中层注意力头是干预奉承行为的关键位置；事实准确性和抗顺从性虽然相关，但涉及不同的内部机制。

Abstract: We find that correct-to-incorrect sycophancy signals are most linearly separable within multi-head attention activations. Motivated by the linear representation hypothesis, we train linear probes across the residual stream, multilayer perceptron (MLP), and attention layers to analyze where these signals emerge. Although separability appears in the residual stream and MLPs, steering using these probes is most effective in a sparse subset of middle-layer attention heads. Using TruthfulQA as the base dataset, we find that probes trained on it transfer effectively to other factual QA benchmarks. Furthermore, comparing our discovered direction to previously identified "truthful" directions reveals limited overlap, suggesting that factual accuracy, and deference resistance, arise from related but distinct mechanisms. Attention-pattern analysis further indicates that the influential heads attend disproportionately to expressions of user doubt, contributing to sycophantic shifts. Overall, these findings suggest that sycophancy can be mitigated through simple, targeted linear interventions that exploit the internal geometry of attention activations.

</details>


### [41] [Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations](https://arxiv.org/abs/2601.16651)
*Lukas Hinterleitner,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型实例解释中梯度维度爆炸问题，比较了两种降维策略：选择架构相关的子集 vs 全梯度投影，发现贪婪选择组件子集在检索任务中更有效且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的梯度维度巨大，导致基于实例的解释方法计算困难。实践中通常随意选择参数子集进行影响估计，但缺乏系统评估和理论依据。需要研究如何更有效地降低梯度维度以提升解释方法的可行性。

Method: 提出新基准，比较两种降维策略：1）选择架构相关的组件子集（贪婪选择）；2）将全梯度投影到低维空间。通过检索任务评估不同方法在捕捉训练数据影响信息方面的效果。

Result: 贪婪选择的组件子集在检索任务中比全梯度或随机投影方法更有效地捕捉训练数据影响信息。该方法计算效率也高于随机投影，证明有针对性的组件选择是提升大模型实例解释计算可行性的实用策略。

Conclusion: 针对大型语言模型的实例解释，选择架构相关的组件子集比全梯度投影更有效且计算效率更高。这为基于梯度的影响估计提供了更可行的计算策略，使大模型的实例解释更加实用。

Abstract: Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.

</details>


### [42] [EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents](https://arxiv.org/abs/2601.16690)
*Xinze Li,Ziyue Zhu,Siyuan Liu,Yubo Ma,Yuhang Zang,Yixin Cao,Aixin Sun*

Main category: cs.CL

TL;DR: EMemBench是一个通过交互式游戏评估智能体长期记忆的程序化基准，能基于智能体自身轨迹生成问题，覆盖文本和视觉游戏环境，评估多种记忆技能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估智能体长期记忆能力的基准，特别是需要从智能体自身交互轨迹中生成可验证问题的基准。现有方法通常使用固定问题集，无法全面评估记忆技能。

Method: 通过程序化生成基于智能体游戏轨迹的问题，覆盖15个文本游戏和多个视觉种子。每个模板从底层游戏信号计算可验证的真实答案，控制答案可获取性，平衡覆盖单跳/多跳回忆、归纳、时空、逻辑和对抗性记忆技能。

Result: 结果远未饱和：归纳和空间推理是持续瓶颈，尤其在视觉环境中。持久记忆对文本游戏中的开放骨干模型有明显提升，但对VLM智能体的改进不一致，表明视觉基础的情景记忆仍是开放挑战。人类研究进一步证实了EMemBench的难度。

Conclusion: EMemBench为评估智能体长期记忆提供了有效的程序化基准，揭示了当前记忆智能体在归纳和空间推理方面的不足，特别是视觉基础的情景记忆仍需突破。

Abstract: We introduce EMemBench, a programmatic benchmark for evaluating long-term memory of agents through interactive games. Rather than using a fixed set of questions, EMemBench generates questions from each agent's own trajectory, covering both text and visual game environments. Each template computes verifiable ground truth from underlying game signals, with controlled answerability and balanced coverage over memory skills: single/multi-hop recall, induction, temporal, spatial, logical, and adversarial. We evaluate memory agents with strong LMs/VLMs as backbones, using in-context prompting as baselines. Across 15 text games and multiple visual seeds, results are far from saturated: induction and spatial reasoning are persistent bottlenecks, especially in visual setting. Persistent memory yields clear gains for open backbones on text games, but improvements are less consistent for VLM agents, suggesting that visually grounded episodic memory remains an open challenge. A human study further confirms the difficulty of EMemBench.

</details>


### [43] [Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition](https://arxiv.org/abs/2601.16711)
*Shanshan Liu,Noriki Nishida,Fei Cheng,Narumi Tokunaga,Rumana Ferdous Munne,Yuki Yamagata,Kouji Kozaki,Takehito Utsuro,Yuji Matsumoto*

Main category: cs.CL

TL;DR: 该论文提出基于LLM的自动标注数据(ALD)来改善生物医学概念识别中的泛化能力，并建立了新的评估框架来衡量对未见概念的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 在提及无关的生物医学概念识别(MA-BCR)任务中，由于人工标注稀缺，模型对未见概念的泛化能力面临重大挑战。需要系统的方法来评估和改进这种泛化能力。

Method: 1) 提出基于层次概念索引和新型指标的评估框架来测量泛化能力；2) 探索LLM生成的自动标注数据(ALD)作为可扩展资源，构建任务特定的ALD生成流程。

Result: 研究表明LLM生成的ALD虽然不能完全替代人工标注，但能显著改善模型对未见概念的泛化能力，为模型提供更广泛的覆盖范围和结构知识。

Conclusion: LLM生成的自动标注数据是改善生物医学概念识别泛化能力的宝贵资源，特别是在处理未见概念时能提供重要的结构知识和覆盖范围。

Abstract: Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.

</details>


### [44] [Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach](https://arxiv.org/abs/2601.16724)
*Kevin Fan,Eric Yun*

Main category: cs.CL

TL;DR: 本文针对自动作文评分系统中的算法偏见问题，提出基于对比学习的匹配作文对方法，显著减少了ESL学习者与母语者之间的评分差距。


<details>
  <summary>Details</summary>
Motivation: 自动作文评分系统在高风险教育场景中应用日益广泛，但现有基于Transformer的回归模型主要基于母语者语料训练，容易学习到L2语言表面特征与作文质量之间的虚假相关性，导致对ESL学习者的算法偏见。

Method: 使用ASAP 2.0和ELLIPSE数据集对微调的DeBERTa-v3模型进行偏见研究，发现高熟练度ESL作文得分比同等质量的母语作文低10.3%。为缓解此问题，提出基于对比学习的匹配作文对方法，构建了17,161对匹配作文对，使用三元组边界损失微调模型，对齐ESL和母语写作的潜在表示。

Result: 该方法将高熟练度ESL作文的评分差距减少了39.9%（从10.3%降至6.2%），同时保持了0.76的二次加权Kappa。事后语言分析表明，模型成功解耦了句子复杂度和语法错误，避免了对有效L2句法结构的惩罚。

Conclusion: 对比学习与匹配作文对策略能有效减轻自动作文评分系统对ESL学习者的算法偏见，同时保持评分准确性，为开发更公平的AES系统提供了可行方案。

Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.

</details>


### [45] [Standardizing Longitudinal Radiology Report Evaluation via Large Language Model Annotation](https://arxiv.org/abs/2601.16753)
*Xinyi Wang,Grazziela Figueredo,Ruizhe Li,Xin Chen*

Main category: cs.CL

TL;DR: 提出基于LLM的放射学报告纵向信息自动标注流程，用于评估报告生成模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告生成方法需要验证其捕获纵向信息的能力，但缺乏有效的标注工具。传统方法劳动密集、领域特定且难以适应，而LLM提供了有前景的替代方案

Method: 设计基于LLM的两阶段标注流程：1) 识别包含相关信息的句子；2) 提取疾病进展。评估5个主流LLM后选择Qwen2.5-32B，并用其标注MIMIC-CXR数据集中的95,169份报告

Result: LLM标注方法在纵向信息检测和疾病追踪任务上分别比现有方案提高11.3%和5.3%的F1分数。使用Qwen2.5-32B标注的数据集为报告生成模型提供了标准化基准

Conclusion: 基于LLM的自动标注方法能有效解决放射学报告纵向信息标注的挑战，为评估报告生成模型提供了可靠工具，并展示了LLM在医学文本处理中的潜力

Abstract: Longitudinal information in radiology reports refers to the sequential tracking of findings across multiple examinations over time, which is crucial for monitoring disease progression and guiding clinical decisions. Many recent automated radiology report generation methods are designed to capture longitudinal information; however, validating their performance is challenging. There is no proper tool to consistently label temporal changes in both ground-truth and model-generated texts for meaningful comparisons. Existing annotation methods are typically labor-intensive, relying on the use of manual lexicons and rules. Complex rules are closed-source, domain specific and hard to adapt, whereas overly simple ones tend to miss essential specialised information. Large language models (LLMs) offer a promising annotation alternative, as they are capable of capturing nuanced linguistic patterns and semantic similarities without extensive manual intervention. They also adapt well to new contexts. In this study, we therefore propose an LLM-based pipeline to automatically annotate longitudinal information in radiology reports. The pipeline first identifies sentences containing relevant information and then extracts the progression of diseases. We evaluate and compare five mainstream LLMs on these two tasks using 500 manually annotated reports. Considering both efficiency and performance, Qwen2.5-32B was subsequently selected and used to annotate another 95,169 reports from the public MIMIC-CXR dataset. Our Qwen2.5-32B-annotated dataset provided us with a standardized benchmark for evaluating report generation models. Using this new benchmark, we assessed seven state-of-the-art report generation models. Our LLM-based annotation method outperforms existing annotation solutions, achieving 11.3\% and 5.3\% higher F1-scores for longitudinal information detection and disease tracking, respectively.

</details>


### [46] [Do LLM hallucination detectors suffer from low-resource effect?](https://arxiv.org/abs/2601.16766)
*Debtanu Datta,Mohan Kishore Chilukuri,Yash Kumar,Saptarshi Ghosh,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 研究发现：幻觉检测器在低资源语言中表现相对稳定，其准确率下降幅度远小于任务准确率下降幅度，表明LLM内部机制即使在低资源语言中也能编码不确定性信号。


<details>
  <summary>Details</summary>
Motivation: 研究LLM的两个普遍失败模式：幻觉（产生错误信息）和低资源效应（在低资源语言中性能显著下降）。探索这两个问题的交集：幻觉检测器是否也受低资源效应影响？

Method: 在三个领域（事实回忆、STEM、人文学科）的五个任务上进行实验，使用四个LLM和三个幻觉检测器，比较英语和低资源语言（如孟加拉语）的性能差异。

Result: 任务准确率在低资源语言中大幅下降，但检测器准确率下降幅度通常小得多（仅为任务下降幅度的几分之一）。检测器在语言内部（包括非英语）和多语言设置中表现稳健，但在没有语言内监督的跨语言设置中表现不佳。

Conclusion: 即使在低资源语言中，LLM的内部机制也可能编码关于其不确定性的信号。幻觉检测器在语言内部和多语言设置中具有鲁棒性，但需要语言内监督才能有效跨语言工作。

Abstract: LLMs, while outperforming humans in a wide range of tasks, can still fail in unanticipated ways. We focus on two pervasive failure modes: (i) hallucinations, where models produce incorrect information about the world, and (ii) the low-resource effect, where the models show impressive performance in high-resource languages like English but the performance degrades significantly in low-resource languages like Bengali. We study the intersection of these issues and ask: do hallucination detectors suffer from the low-resource effect? We conduct experiments on five tasks across three domains (factual recall, STEM, and Humanities). Experiments with four LLMs and three hallucination detectors reveal a curious finding: As expected, the task accuracies in low-resource languages experience large drops (compared to English). However, the drop in detectors' accuracy is often several times smaller than the drop in task accuracy. Our findings suggest that even in low-resource languages, the internal mechanisms of LLMs might encode signals about their uncertainty. Further, the detectors are robust within language (even for non-English) and in multilingual setups, but not in cross-lingual settings without in-language supervision.

</details>


### [47] [Persuasion Tokens for Editing Factual Knowledge in LLMs](https://arxiv.org/abs/2601.16781)
*Paul Youssef,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 提出persuasion tokens (P-Tokens)來替代in-context knowledge editing中的冗長示範，實現更高效、可擴展的LLM知識編輯


<details>
  <summary>Details</summary>
Motivation: 現有的in-context knowledge editing (IKE)方法依賴冗長、特定事實的示範，這些示範創建成本高且消耗大量上下文窗口空間，限制了實際應用

Method: 訓練特殊的persuasion tokens (P-Tokens)來複製IKE示範的效果，無需特定事實的示範即可實現高效的知識編輯

Result: 在兩個編輯數據集和三個LLM上的評估顯示，P-Tokens性能與IKE相當甚至更好，對干擾具有魯棒性，增加P-Tokens數量可提升性能

Conclusion: P-Tokens解決了IKE的關鍵限制，為LLM編輯提供了更實用、可擴展的替代方案

Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.

</details>


### [48] [Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis](https://arxiv.org/abs/2601.16800)
*Gaurav Negi,MA Waskow,Paul Buitelaar*

Main category: cs.CL

TL;DR: LLMs可作为细粒度意见分析的自动标注器和裁决器，减少人工标注成本


<details>
  <summary>Details</summary>
Motivation: 细粒度意见分析需要大量人工标注，成本高昂且难以跨领域应用，需要探索LLMs作为自动标注器的可行性

Method: 使用声明式标注流程减少提示工程变异性，提出LLMs裁决多个标签并生成最终标注的新方法，在ASTE和ACOS任务上测试不同规模模型

Result: LLMs能作为自动标注器和裁决器，在个体LLM标注器间实现高标注者一致性，显著降低创建细粒度意见标注数据集的成本和人力

Conclusion: LLMs可有效解决细粒度意见分析中领域特定标注数据不足的问题，提供经济高效的自动标注方案

Abstract: Fine-grained opinion analysis of text provides a detailed understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound, it requires considerable human effort and substantial cost to annotate opinions in datasets for training models, especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic annotators for fine-grained opinion analysis, addressing the shortage of domain-specific labelled datasets. In this work, we use a declarative annotation pipeline. This approach reduces the variability of manual prompt engineering when using LLMs to identify fine-grained opinion spans in text. We also present a novel methodology for an LLM to adjudicate multiple labels and produce final annotations. After trialling the pipeline with models of different sizes for the Aspect Sentiment Triplet Extraction (ASTE) and Aspect-Category-Opinion-Sentiment (ACOS) analysis tasks, we show that LLMs can serve as automatic annotators and adjudicators, achieving high Inter-Annotator Agreement across individual LLM-based annotators. This reduces the cost and human effort needed to create these fine-grained opinion-annotated datasets.

</details>


### [49] [SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation](https://arxiv.org/abs/2601.16803)
*Carolin Holtermann,Florian Schneider,Anne Lauscher*

Main category: cs.CL

TL;DR: 研究发现文本到图像模型存在"表面优先于语义"的倾向，即模型对非英语提示语更关注语言表面形式而非语义，导致产生文化刻板印象的图像。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明T2I模型对输入语言高度敏感，面对非英语提示时往往产生文化刻板印象的描绘，但缺乏对这一行为的全面分析。

Method: 创建包含171种文化身份的提示语集，翻译成14种语言，用于测试7个T2I模型。引入新的量化指标来衡量SoS倾向，并分析其在视觉上的表现。

Result: 除一个模型外，所有模型至少在两种语言中表现出强烈的表面倾向，这种效应在T2I文本编码器的各层中逐渐增强。表面倾向常与刻板视觉描绘相关。

Conclusion: T2I模型存在显著的"表面优先于语义"倾向，导致跨语言使用时产生文化刻板印象，需要在模型设计和评估中加以解决。

Abstract: Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.

</details>


### [50] [Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess](https://arxiv.org/abs/2601.16823)
*Leonard S. Pleiss,Maximilian Schiffer,Robert K. von Weizsäcker*

Main category: cs.CL

TL;DR: 该研究使用国际象棋作为测试平台，发现LLMs在需要流体智力（推理能力）的任务上表现明显下降，特别是在训练分布之外的任务中性能崩溃到随机水平，表明当前架构在系统泛化方面仍有限制。


<details>
  <summary>Details</summary>
Motivation: 需要区分LLMs表现出的能力是源于记忆（晶体智力）还是推理（流体智力），以理解当前模型的真正智能水平。

Method: 使用国际象棋作为受控测试平台，构建基于训练语料接近度的位置分类法，从可记忆解决的常见状态到需要原理推理的新颖状态，系统评估多个GPT世代在不同推理强度下的表现。

Result: 发现清晰的梯度：随着流体智力需求增加，性能持续下降；在分布外任务中，性能崩溃到随机水平；新模型虽有改进，但在训练分布外的任务上进步显著放缓；推理增强的推理能提高性能，但其边际效益随分布接近度而降低。

Conclusion: 当前架构在系统泛化方面仍然有限，需要超越规模扩展的机制来实现稳健的流体智力。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.

</details>


### [51] [LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems](https://arxiv.org/abs/2601.16890)
*João A. Leite,Olesya Razuvayevskaya,Kalina Bontcheva,Carolina Scarton*

Main category: cs.CL

TL;DR: 提出了一种新的对抗性攻击方法，利用说服技术改写虚假声明来欺骗自动事实核查系统，显著降低了事实核查和证据检索的性能。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性攻击主要依赖注入噪声或改变语义，但忽略了说服技术在虚假信息传播中的重要作用。本文旨在探索说服技术作为新型对抗性攻击的潜力，以揭示自动事实核查系统的脆弱性。

Method: 使用生成式大语言模型（LLM）将虚假声明用15种说服技术（分为6类）进行改写，形成说服性对抗攻击。在FEVER和FEVEROUS基准上采用解耦评估策略，分别测试对声明验证和证据检索的影响。

Result: 实验表明说服攻击能显著降低自动事实核查系统的验证性能和证据检索效果，证实说服技术是一类有效的对抗性攻击手段。

Conclusion: 说服技术构成了一类强大的对抗性攻击，暴露了当前自动事实核查系统的脆弱性，强调了开发更鲁棒的事实核查系统的必要性。

Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.

</details>


### [52] [Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias](https://arxiv.org/abs/2601.16934)
*Elias Schuhmacher,Andrianos Michail,Juri Opitz,Rico Sennrich,Simon Clematide*

Main category: cs.CL

TL;DR: 本文提出一种基于排列的评估框架，发现SOTA嵌入模型存在系统性位置和语言偏见，并提出推理时注意力校准方法来解决位置偏见问题。


<details>
  <summary>Details</summary>
Motivation: 为了确保文档的每个部分都能在基于嵌入的搜索过程中被发现，需要量化嵌入表示中可能存在的反射偏见。现有模型在长文档和多段文档中存在系统性偏见，影响搜索公平性。

Method: 1. 提出基于排列的评估框架来量化嵌入模型的位置和语言偏见；2. 分析发现位置偏见源于池化标记嵌入中的前向注意力分布；3. 提出推理时注意力校准方法，重新分配注意力到文档的不同位置。

Result: 实验发现：1. SOTA嵌入模型存在系统性位置偏见（早期段落过表示，后期段落边缘化）和语言偏见（高资源语言如英语过表示，低资源语言边缘化）；2. 注意力校准方法能有效提高后期段落的可发现性。

Conclusion: 嵌入模型存在系统性位置和语言偏见，影响文档搜索的公平性。提出的注意力校准方法能缓解位置偏见，提高文档所有部分的搜索可发现性。评估框架和校准方法已开源。

Abstract: To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers

</details>


### [53] [Strategies for Span Labeling with Large Language Models](https://arxiv.org/abs/2601.16946)
*Danil Semin,Ondřej Dušek,Zdeněk Kasner*

Main category: cs.CL

TL;DR: 本文提出LogitMatch方法，通过约束解码强制模型输出与输入文本中的有效片段对齐，解决了生成式LLM在片段标注任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成式大语言模型缺乏显式引用输入文本特定部分的机制，导致片段标注任务中存在各种临时提示策略且结果不一致。现有内容匹配方法存在局限性，需要更好的解决方案。

Method: 将现有片段标注策略分为三类：标记输入文本、索引片段数值位置、匹配片段内容。针对内容匹配的局限性，提出了LogitMatch——一种新的约束解码方法，强制模型输出与有效输入片段对齐。

Result: 在四个不同任务上的评估显示，标记方法仍然是稳健的基线，而LogitMatch通过消除片段匹配问题，在某些设置中优于竞争性匹配方法，并超越了其他策略。

Conclusion: LogitMatch作为一种约束解码方法，有效解决了生成式LLM在片段标注任务中的内容匹配问题，为文本分析任务提供了更可靠的解决方案。

Abstract: Large language models (LLMs) are increasingly used for text analysis tasks, such as named entity recognition or error detection. Unlike encoder-based models, however, generative architectures lack an explicit mechanism to refer to specific parts of their input. This leads to a variety of ad-hoc prompting strategies for span labeling, often with inconsistent results. In this paper, we categorize these strategies into three families: tagging the input text, indexing numerical positions of spans, and matching span content. To address the limitations of content matching, we introduce LogitMatch, a new constrained decoding method that forces the model's output to align with valid input spans. We evaluate all methods across four diverse tasks. We find that while tagging remains a robust baseline, LogitMatch improves upon competitive matching-based methods by eliminating span matching issues and outperforms other strategies in some setups.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [54] [Measuring Financial Resilience Using Backward Stochastic Differential Equations](https://arxiv.org/abs/2505.07502)
*Roger J. A. Laeven,Matteo Ferrari,Emanuela Rosazza Gianin,Marco Zullino*

Main category: q-fin.MF

TL;DR: 本文引入金融韧性率作为衡量金融韧性的指标，它捕捉了当风险接受集被突破时动态风险度量恢复的预期速率。通过建立带跳跃的BSDE解在停时处的时间导数期望表示定理，将韧性率表示为BSDE生成元的适当期望。


<details>
  <summary>Details</summary>
Motivation: 需要一种量化金融韧性的方法，特别是在风险接受集被突破后动态风险度量恢复的能力。现有研究缺乏对风险度量"反弹"速率的系统度量，而这对理解金融系统的稳定性和恢复能力至关重要。

Method: 1. 引入韧性率作为金融韧性度量；2. 建立带跳跃的BSDE解在停时处的时间导数期望表示定理；3. 将韧性率表示为BSDE生成元的适当期望；4. 分析韧性率的主要性质及其与BSDE生成元的联系；5. 引入韧性接受集并研究其性质。

Result: 1. 成功建立了韧性率的数学表示理论；2. 揭示了韧性率与BSDE生成元之间的形式联系；3. 分析了韧性率的主要数学性质；4. 开发了韧性接受集理论，建立了其与韧性率和动态风险度量的关系；5. 通过典型金融例子验证了结果，并通过韧性中性概念突出了其应用意义。

Conclusion: 本文提出的韧性率为量化金融韧性提供了新的理论框架，通过BSDE理论建立了严格的数学基础。韧性接受集的概念扩展了传统风险接受集理论，韧性中性的概念为理解金融系统的恢复能力提供了新的视角。该框架在金融风险管理中具有重要应用价值。

Abstract: We introduce the resilience rate as a measure of financial resilience. It captures the expected rate at which a dynamic risk measure recovers, i.e., bounces back, when the risk-acceptance set is breached. We develop the corresponding stochastic calculus by establishing representation theorems for expected time-derivatives of solutions to backward stochastic differential equations (BSDEs) with jumps, evaluated at stopping times. These results reveal that the resilience rate can be represented as a suitable expectation of the generator of a BSDE. We analyze the main properties of the resilience rate and the formal connection of these properties to the BSDE generator. We also introduce resilience-acceptance sets and study their properties in relation to both the resilience rate and the dynamic risk measure. We illustrate our results in several canonical financial examples and highlight their implications via the notion of resilience neutrality.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [55] [BESTOpt: A Modular, Physics-Informed Machine Learning based Building Modeling, Control and Optimization Framework](https://arxiv.org/abs/2601.16283)
*Zixin Jiang,Ruizhi Song,Guowen Li,Yuhang Zhang,Zheng O'Neill,Xuezheng Wang,Judah Goldfeder,Bing Dong*

Main category: eess.SY

TL;DR: BESTOpt是一个模块化、物理信息机器学习框架，用于统一建筑应用，包括基准测试、评估、诊断、控制、优化和性能模拟，通过嵌入物理先验提高模型准确性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现代建筑与占用、HVAC系统、分布式能源资源和电网的互联日益紧密，但现有工具缺乏可扩展性和物理一致性来处理这些复杂的多尺度生态系统问题。

Method: 采用集群-领域-系统/建筑-组件层次结构和标准化的状态-动作-干扰-观测数据分类法，将物理先验嵌入数据驱动模块中。

Result: 单建筑和集群场景的案例研究表明，该框架能够实现多层次集中式和分散式控制，在未见条件下提高了模型准确性和物理一致性。

Conclusion: BESTOpt为开放、可扩展平台奠定了基础，加速了跨学科研究，推动实现智能、有韧性和脱碳的建筑生态系统。

Abstract: Modern buildings are increasingly interconnected with occupancy, heating, ventilation, and air-conditioning (HVAC) systems, distributed energy resources (DERs), and power grids. Modeling, control, and optimization of such multi-domain systems play a critical role in achieving building-sector decarbonization. However, most existing tools lack scalability and physical consistency for addressing these complex, multi-scale ecosystem problems. To bridge this gap, this study presents BESTOpt, a modular, physics-informed machine learning (PIML) framework that unifies building applications, including benchmarking, evaluation, diagnostics, control, optimization, and performance simulation. The framework adopts a cluster-domain-system/building-component hierarchy and a standardized state-action-disturbance-observation data typology. By embedding physics priors into data-driven modules, BESTOpt improves model accuracy and physical consistency under unseen conditions. Case studies on single-building and cluster scenarios demonstrate its capability for multi-level centralized and decentralized control. Looking ahead, BESTOpt lays the foundation for an open, extensible platform that accelerates interdisciplinary research toward smart, resilient, and decarbonized building ecosystems.

</details>


### [56] [Optimal County-Level Siting of Data Centers in the United States](https://arxiv.org/abs/2601.16315)
*Maria Vabson,Muhy Eddin Zater,Amir Sajadi,Kyri Baker,Bri-Mathias Hodge*

Main category: eess.SY

TL;DR: 该研究开发了一个综合模型来优化数据中心选址，通过量化资源使用和最小化成本，考虑电网、通信、气候、水资源等多因素，重点关注美国县级碳中性能源协同选址。


<details>
  <summary>Details</summary>
Motivation: 数据中心快速增长对电力、水资源和电网造成巨大压力，需要开发关键基础设施来支持这些资源密集型负载。现有电网和水资源已经紧张且老化，需要系统性的选址方法。

Method: 采用跨学科建模方法，综合考虑电网、电信、气候、水资源使用和协同发电潜力等多个因素，建立基础模型，通过美国县级碳中性能源协同选址的多个测试案例验证功能。

Result: 结果表明，虽然资本成本是主要驱动因素，但采用更长的未来展望期和允许更多可变发电协同选址，会使模型选择具有更高可再生能源潜力的地点。

Conclusion: 该研究建立了一个综合数据中心选址模型，证明考虑长期规划和可再生能源协同选址可以优化数据中心位置选择，平衡成本与可持续性目标。

Abstract: Data centers are growing rapidly, creating the pressing need for the development of critical infrastructure build out to support these resource-intensive large loads. Their immense consumption of electricity and, often, freshwater, continues to stress an already constrained and aging power grid and water resources. This paper presents a comprehensive modeling approach to determine the optimal locations to construct such facilities by quantifying their resource use and minimizing associated costs. The interdisciplinary modeling approach incorporates a number of factors including the power grid, telecommunications, climate, water use, and collocated generation potential. This work establishes the base model whose functionality is shown through several test cases focusing on carbon-free generation collocation on a county-level in the United States. The results suggest that while capital costs are the biggest driver, having a longer future outlook and allowing more variable generation collocation influences the model to choose sites with higher renewable potential.

</details>


### [57] [Robust Grid-Forming Control Based on Virtual Flux Observer](https://arxiv.org/abs/2601.16418)
*Xueqing Gao,Jun Zhang,Tao Li,Mingming Zhang*

Main category: eess.SY

TL;DR: 提出一种基于虚拟磁链观测器的电网形成控制方法，用于并网变流器，通过直接调节端电压实现电压源特性，具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对并网变流器在电网强度变化和不确定条件下的稳定性问题，需要开发具有强鲁棒性的电网形成控制方法，以提供可靠的电压源行为。

Method: 采用虚拟磁链观测器进行同步和负载角控制，直接调节变流器端电压，控制参数通过解耦和极点配置设计，实现电压源特性。

Result: 小信号分析表明该方法在电网强度变化时具有强鲁棒稳定性，实验验证了在20kVA功率转换系统上的优异动态性能。

Conclusion: 提出的虚拟磁链观测器电网形成控制方法能够为并网变流器提供可靠的电压源行为，在电网强度变化条件下表现出优异的鲁棒性和动态性能。

Abstract: This paper investigates the design and analysis of a novel grid-forming (GFM) control method for grid-connected converters (GCCs). The core novelty lies in a virtual flux observer-based synchronization and load angle control method. The terminal voltage of the converter is directly regulated to provide voltage-source behavior. The control parameters are designed for decoupling and pole placement. The proposed method exhibits strong robustness in stability and dynamical performance across varying and uncertain grid strengths. The robust control performance of the proposed method is first demonstrated by small-signal analysis, then validated by experiments on a 20 kVA power conversion system.

</details>


### [58] [Sequential Operating Simulation of Solid State Transformer-Driven Next-Generation 800 VDC Data Center](https://arxiv.org/abs/2601.16502)
*Jian Xu,Xinxiong Jiang,Yi Bao,Yuchen Zheng,Xuhui Chen,Qiang Xu,Siyang Liao,Deping Ke,Xiaoqi Gao*

Main category: eess.SY

TL;DR: 该论文提出了一种用于AI数据中心的新型SST驱动800V直流架构，相比传统UPS系统具有更高效率和动态负载适应性


<details>
  <summary>Details</summary>
Motivation: AI工作负载导致数据中心用电量快速增长和机架功率密度增加，需要高效且能应对快速负载瞬变的供电系统。传统UPS交流配电链存在多级转换和工频变压器，效率低且不适应AI动态功率特性。

Method: 开发了SST驱动的800V直流架构，采用三相H桥AC/DC级联双有源桥DC/DC级，将10kV中压交流转换为800V低压直流。设计了协调闭环控制方案，结合整流器电压/电流调节和DAB移相控制，保持直流母线电压稳定。

Result: 在RTDS平台上实现并评估，使用真实数据中心日度和月度运行配置文件。数值研究表明：800V直流调节紧密，相比UPS基准减少输入侧能耗，电能质量性能满意。电容灵敏度测试量化了直流母线纹波与低频输入功率振荡之间的权衡。

Conclusion: 该工作为下一代AI数据中心提供了可复现的评估工作流程和实用设计指导，SST驱动800V直流架构在效率和动态性能方面优于传统UPS系统。

Abstract: Artificial-intelligence (AI) workloads are driving rapid growth in data-center electricity use and rack power density, increasing demand for power-delivery systems that are efficient and robust to fast load transients. Conventional uninterruptible power supply (UPS) based AC distribution chains involve multiple conversion stages and line-frequency transformers, which compound losses and are less compatible with dynamic AI power profiles. Although solid-state transformers (SSTs) and 800 VDC distribution architecture are widely discussed, implementable topology/control details, and long-horizon validation with realistic operating profiles remain limited. This paper develops an SST-driven 800 VDC architecture that converts 10 kV MVAC to an 800V LVDC bus using a three-phase H-bridge AC/DC stage cascaded with a dual-active-bridge (DAB) DC/DC stage. A coordinated closed-loop control scheme, combining rectifier voltage/current regulation and DAB phase-shift control, is designed to maintain DC-bus voltage stability. The proposed system is implemented on the real-time digital simulation (RTDS) platform and evaluated via sequential simulations using real-world day- and month-scale operating profiles of data centers, benchmarked against a UPS supply chain. Numerical studies demonstrate tight 800 VDC regulation, reduced input-side energy consumption compared with the UPS baseline, and satisfactory power-quality performance. A capacitance sensitivity test quantifies tradeoffs between DC-bus ripple and low-frequency input-power oscillations, yielding a practical capacitance range for design. Overall, the work provides a reproducible evaluation workflow and actionable guidance for next-generation AI data centers.

</details>


### [59] [Agentic AI-RAN Empowering Synergetic Sensing, Communication, Computing, and Control](https://arxiv.org/abs/2601.16565)
*Lingxiao Sun,Zhaoyang Zhang,Zihan Lin,Zirui Chen,Weijie Zhou,Zhaohui Yang,Tony Q. S. Quek*

Main category: eess.SY

TL;DR: 本文提出了一种面向任务的Agentic AI-RAN架构，用于6G低空无线网络中感知、通信、计算和控制的协同执行，并通过基于GPU的原型系统验证了自主无人机导航的可行性。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要支持低空无线网络(LAWNs)，其中无人机和空中机器人在高度动态的三维环境中运行，面临严格的延迟、可靠性和自主性要求。传统方法难以在资源受限的边缘环境中协调异构工作负载。

Method: 提出面向任务的Agentic AI-RAN架构，在单个边缘节点内集成SC3任务执行。采用多实例GPU分区技术和容器化部署，实现物理资源隔离，支持实时通信与多模态推理的紧密协同。

Result: 基于通用GPU平台构建了低空具身智能系统原型，实现了自主无人机导航。实验结果显示低闭环延迟、鲁棒的双向通信，以及在动态运行条件下的稳定性能。

Conclusion: 提出的Agentic AI-RAN架构能够有效协调异构工作负载，在资源受限的边缘环境中实现自主任务执行，为6G关键任务低空无线网络提供了可行的解决方案。

Abstract: Future sixth-generation (6G) networks are expected to support low-altitude wireless networks (LAWNs), where unmanned aerial vehicles (UAVs) and aerial robots operate in highly dynamic three-dimensional environments under stringent latency, reliability, and autonomy requirements. In such scenarios, autonomous task execution at the network edge demands holistic coordination among sensing, communication, computing, and control (SC3) processes. Agentic Artificially Intelligent Radio Access Networks (Agentic AI-RAN) offer a promising paradigm by enabling the edge network to function as an autonomous decision-making entity for low-altitude agents with limited onboard resources. In this article, we propose and design a task-oriented Agentic AI-RAN architecture that enables SC3 task execution within a single edge node. This integrated design tackles the fundamental problem of coordinating heterogeneous workloads in resource-constrained edge environments. Furthermore, a representative low-altitude embodied intelligence system is prototyped based on a general-purpose Graphics Processing Unit (GPU) platform to demonstrate autonomous drone navigation in realistic settings. By leveraging the Multi-Instance GPU (MIG) partitioning technique and the containerized deployment, the demonstration system achieves physical resource isolation while supporting tightly coupled coordination between real-time communication and multimodal inference under a unified task framework. Experimental results demonstrate low closed-loop latency, robust bidirectional communication, and stable performance under dynamic runtime conditions, highlighting its viability for mission-critical low-altitude wireless networks in 6G.

</details>


### [60] [Challenges in the Proper Metrological Verification of Smart Energy Meters](https://arxiv.org/abs/2601.16612)
*Antonio Bracale,Jakub Janowicz,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SY

TL;DR: 智能电表现行验证方法存在缺陷，无法反映电网实际工况，本文揭示了其信号链问题并提出改进方向


<details>
  <summary>Details</summary>
Motivation: 当前智能电表的验证在理想条件或简单信号模型下进行，无法复现电网实际状态，也不能确保其信号链特性的验证，存在重大计量安全隐患

Method: 分析现有法律规范要求，开展科学研究，对已获销售许可的智能电表进行测试，揭示其在特定测试信号下的信号链和测量链缺陷

Result: 测试显示，尽管被测电表符合规范要求并已获销售许可，但在特定测试信号下暴露出信号链和测量链的众多缺陷

Conclusion: 智能电表的计量验证需要更严格的测试方法，应基于研究结果确定未来研究方向，改进验证标准以确保测量准确性

Abstract: The most common instruments currently measuring active/reactive energy and power quality indicators are smart energy meters. Unfortunately, the verification of such meters is currently performed under ideal conditions or with simple signal models, which do not recreate actual states occurring in the power grid and do not ensure the verification of the properties of their signal chains. This paper presents challenges in the proper metrological verification of smart energy meters. It presents existing legal and normative requirements and scientific research directions regarding these meters. Selected test results are presented, which show that although the tested meters meet the normative and legal requirements because they have been approved for sale, numerous imperfections in the signal and measurement chains of the analyzed instruments are revealed for the selected test signal. On the basis of the presented research results, further directions of research in the field of smart energy meters have been determined.

</details>


### [61] [A Cognitive Framework for Autonomous Agents: Toward Human-Inspired Design](https://arxiv.org/abs/2601.16648)
*Francesco Guidi,Jingfeng Shan,Mehrdad Saeidi,Enrico Testi,Elia Favarelli,Andrea Giorgetti,Davide Dardari,Alberto Zanella,Giorgio Li Pira,Francesca Starita,Anna Guerra*

Main category: eess.SY

TL;DR: 提出一种受人类启发的强化学习架构，整合巴甫洛夫式与工具性学习过程，通过条件线索引导决策，提升自主系统在未知环境中的导航与合作效率。


<details>
  <summary>Details</summary>
Motivation: 现有工程解决方案主要依赖工具性学习，但神经科学研究表明人类利用巴甫洛夫式关联通过预测性线索在结果发生前偏置行为。将这种双系统机制转化为数字智能体，可以改善自主系统的决策能力。

Method: 开发线索引导的强化学习框架，将射频刺激作为条件（巴甫洛夫式）线索来调节动作选择。该架构结合巴甫洛夫值与工具性策略优化，在未知、部分可观测环境中工作。

Result: 仿真结果显示，线索驱动的智能体适应更快，在导航效率和合作行为方面表现优于传统的纯工具性智能体。

Conclusion: 这项工作凸显了人类学习原理在重塑数字智能体智能方面的潜力，为自主系统决策提供了新的神经科学启发方法。

Abstract: This work introduces a human-inspired reinforcement learning (RL) architecture that integrates Pavlovian and instrumental processes to enhance decision-making in autonomous systems. While existing engineering solutions rely almost exclusively on instrumental learning, neuroscience shows that humans use Pavlovian associations to leverage predictive cues to bias behavior before outcomes occur. We translate this dual-system mechanism into a cue-guided RL framework in which radio-frequency (RF) stimuli act as conditioned (Pavlovian) cues that modulate action selection. The proposed architecture combines Pavlovian values with instrumental policy optimization, improving navigation efficiency and cooperative behavior in unknown, partially observable environments. Simulation results demonstrate that cue-driven agents adapt faster, achieving superior performance compared to traditional instrumental-solo agents. This work highlights the potential of human learning principles to reshape digital agents intelligence.

</details>


### [62] [Computation-Accuracy Trade-Off in Service-Oriented Model-Based Control](https://arxiv.org/abs/2601.16682)
*Hazem Ibrahim,Julius Beerwerth,Lorenz Dörschel,Bassam Alrifaee*

Main category: eess.SY

TL;DR: 提出一个基于SOA的控制系统框架，通过A*搜索和服务编排优化计算精度权衡，结合贝叶斯优化调整多目标权重，实现车辆纵向速度控制的在线性能驱动重构。


<details>
  <summary>Details</summary>
Motivation: 将控制系统表示为面向服务的架构（SOMC）可以实现控制环元素的运行时灵活组合，但需要解决计算精度权衡优化问题，同时考虑控制系统的实时需求。

Method: 将服务编排建模为A*搜索问题，结合上下文贝叶斯优化调整多目标成本权重，实现计算精度权衡的优化。

Result: 通过车辆纵向速度控制案例研究，展示了在线性能驱动的控制架构重构能力，框架能够结合控制和软件结构，并在性能优化中考虑实时需求。

Conclusion: 提出的框架不仅整合了控制和软件结构，还在性能优化过程中考虑了控制系统的实时要求，实现了服务导向模型控制的有效优化。

Abstract: Representing a control system as a Service-Oriented Architecture (SOA)-referred to as Service-Oriented Model-Based Control (SOMC)-enables runtime-flexible composition of control loop elements. This paper presents a framework that optimizes the computation-accuracy trade-off by formulating service orchestration as an A$^\star$search problem, complemented by Contextual Bayesian Optimization (BO) to tune the multi-objective cost weights. A vehicle longitudinal-velocity control case study demonstrates online, performancedriven reconfiguration of the control architecture. We show that our framework not only combines control and software structure but also considers the real-time requirements of the control system during performance optimization.

</details>


### [63] [On a Coupled Adoption-Opinion Framework for Competing Innovations](https://arxiv.org/abs/2601.16719)
*Martina Alutto,Fabrizio Dabbene,Angela Fontan,Karl H. Johansson,Chiara Ravazzi*

Main category: eess.SY

TL;DR: 提出双层采纳-意见模型研究竞争技术扩散，证明存在唯一采纳扩散均衡，两技术共存，市场占有率仅取决于用户体验，对称干预可能产生不对称结果


<details>
  <summary>Details</summary>
Motivation: 研究竞争性技术在人群中的扩散过程，其中个体意见受社会影响和采纳反馈影响，采纳后可能因不满意而转向替代技术

Method: 提出双层采纳-意见模型，结合社会影响和采纳驱动反馈，证明采纳扩散均衡的存在性和唯一性，并进行数值模拟分析

Result: 证明两技术共存均衡存在且唯一，排除部分采纳或垄断情况；意见影响均衡采纳水平，但市场占有率仅取决于用户体验；对称干预可能不对称地偏向高质量技术

Conclusion: 竞争技术扩散中，意见影响采纳水平但市场占有率由用户体验决定，对称控制行动可能产生不对称结果，这对技术竞争和政策干预有重要启示

Abstract: In this paper, we propose a two-layer adoption-opinion model to study the diffusion of two competing technologies within a population whose opinions evolve under social influence and adoption-driven feedback. After adopting one technology, individuals may become dissatisfied and switch to the alternative. We prove the existence and uniqueness of the adoption-diffused equilibrium, showing that both technologies coexist and that neither partial-adoption nor monopoly can arise. Numerical simulations show that while opinions shape the equilibrium adoption levels, the relative market share between the two technologies depends solely on their user-experience. As a consequence, interventions that symmetrically boost opinions or adoption can disproportionately favor the higher-quality technology, illustrating how symmetric control actions may generate asymmetric outcomes.

</details>


### [64] [Model Predictive Control for Coupled Adoption-Opinion Dynamics](https://arxiv.org/abs/2601.16722)
*Martina Alutto,Qiulin Xu,Fabrizio Dabbene,Hideaki Ishii,Chiara Ravazzi*

Main category: eess.SY

TL;DR: 研究多层网络中可持续行为扩散的最优控制问题，结合意见动态和采用模型，使用MPC框架通过影响意见间接促进采用


<details>
  <summary>Details</summary>
Motivation: 研究可持续行为在多层网络中的扩散机制，传统直接干预方法效果有限且难以扩展，需要更有效的间接干预策略来促进可持续行为的采纳

Method: 建立耦合意见动态和采用模型的多层网络框架，进行平衡点稳定性分析，引入模型预测控制(MPC)框架，通过影响意见而非直接强制采用来优化干预策略

Result: 无控制时采用行为会停滞，而MPC驱动的干预能够维持和增强跨社区的采用水平，证明通过影响意见的间接干预策略更有效且可扩展

Conclusion: 基于"助推"的控制策略通过塑造意见间接影响采用行为，比直接干预更有效且可扩展，为政策制定者提供了促进可持续行为扩散的新工具

Abstract: This paper investigates an optimal control problem for an adoption-opinion model that couples opinion dynamics with a compartmental adoption framework on a multilayer network to study the diffusion of sustainable behaviors. Adoption evolves through social contagion and perceived benefits, while opinions are shaped by social interactions and feedback from adoption levels. Individuals may also stop adopting virtuous behavior due to external constraints or shifting perceptions, affecting overall diffusion. After the stability analysis of equilibria, both in the presence and absence of adopters, we introduce a Model Predictive Control (MPC) framework that optimizes interventions by shaping opinions rather than directly enforcing adoption. This nudge-based control strategy allows policymakers to influence diffusion indirectly, making interventions more effective and scalable. Numerical simulations demonstrate that, in the absence of control, adoption stagnates, whereas MPC-driven interventions sustain and enhance adoption across communities.

</details>


### [65] [ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees](https://arxiv.org/abs/2601.16764)
*Xingchen Li,Keyou You*

Main category: eess.SY

TL;DR: 提出一种基于投影的方法来强制执行硬约束，并建立最优MPC成本函数的状态相关Lipschitz连续性，首次推导出保证闭环性能的ReLU网络宽度和深度显式边界，进一步提出非均匀误差框架以减少网络复杂度并提升闭环性能。


<details>
  <summary>Details</summary>
Motivation: 近年来使用ReLU神经网络表示MPC策略的研究复兴，但确定确保闭环性能所需的网络复杂度仍然是一个基本未解决的问题，涉及关键的精度-复杂度权衡：网络过小可能无法捕捉MPC策略，而过大则可能超过ReLU网络近似的优势。

Method: 提出投影方法强制执行硬约束，建立最优MPC成本函数的状态相关Lipschitz连续性，推导ReLU网络宽度和深度的显式边界，提出非均匀误差框架和状态感知缩放函数自适应调整ReLU网络的输入和输出。

Result: 首次为近似MPC策略的ReLU网络提供了保证闭环性能的宽度和深度显式边界，通过非均匀误差框架进一步减少网络复杂度并提升闭环性能。

Conclusion: 这项工作为可认证的ReLU神经网络基MPC提供了基础性步骤，解决了确保闭环性能所需的网络复杂度问题，并提出了减少复杂度和提升性能的有效方法。

Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.

</details>


### [66] [Identification of Port-Hamiltonian Differential-Algebraic Equations from Input-Output Data](https://arxiv.org/abs/2601.16827)
*N. Hagelaars,G. J. E. van Otterdijk,S. Moradi,R. Tóth,N. O. Jaensson,M. Schoukens*

Main category: eess.SY

TL;DR: 提出了一种结合端口哈密顿神经网络和微分代数求解器的数据驱动识别方法，用于从噪声输入输出数据直接建模具有代数约束的物理系统。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统（如机械和电气网络）具有由子系统互连和基本物理定律产生的代数约束，这些系统通常表示为微分代数方程。端口哈密顿微分代数方程提供了结构化、基于能量的表示，但需要从噪声数据中识别此类系统。

Method: 结合端口哈密顿神经网络和微分代数求解器，采用后向欧拉离散化和牛顿方法一致求解耦合的微分和代数方程，同时保持端口哈密顿系统的无源性和互连结构。

Result: 在直流电力网络上的实验表明，所识别模型能准确捕捉系统行为，误差与噪声幅度成正比，同时提供可靠的参数估计。

Conclusion: 该方法成功实现了从噪声数据中识别端口哈密顿微分代数方程系统，保持了系统的无源性和结构特性，为约束物理系统的数据驱动建模提供了有效途径。

Abstract: Many models of physical systems, such as mechanical and electrical networks, exhibit algebraic constraints that arise from subsystem interconnections and underlying physical laws. Such systems are commonly formulated as differential-algebraic equations (DAEs), which describe both the dynamic evolution of system states and the algebraic relations that must hold among them. Within this class, port-Hamiltonian differential-algebraic equations (pH-DAEs) offer a structured, energy-based representation that preserves interconnection and passivity properties. This work introduces a data-driven identification method that combines port-Hamiltonian neural networks (pHNNs) with a differential-algebraic solver to model such constrained systems directly from noisy input-output data. The approach preserves the passivity and interconnection structure of port-Hamiltonian systems while employing a backward Euler discretization with Newton's method to solve the coupled differential and algebraic equations consistently. The performance of the proposed approach is demonstrated on a DC power network, where the identified model accurately captures system behaviour and maintains errors proportional to the noise amplitude, while providing reliable parameter estimates.

</details>


### [67] [Performance of Differential Protection Applied to Collector Cables of Offshore Wind Farms with MMC-HVDC Transmission](https://arxiv.org/abs/2601.16876)
*Moisés J. B. B. Davi,Felipe V. Lopes,Vinícius A. Lacerda,Mário Oleskovicz,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 传统差动保护在海上风电MMC-HVDC系统中的局限性分析及改进策略比较


<details>
  <summary>Details</summary>
Motivation: 全球低碳能源转型推动海上风电发展，但风电场的MMC-HVDC输电系统给电力系统保护带来新挑战。由于集电电缆两端都由逆变器型电源供电，故障电流特性发生变化，传统保护方案可能失效。

Method: 使用PSCAD/EMTDC软件对代表性海上风电场进行电磁暂态仿真，评估内部和外部故障场景，考虑不同类型故障和接地电阻变化，比较传统差动保护与考虑序分量的增强策略。

Result: 通过对比评估，揭示了差动保护在逆变器主导电网中的灵敏度和选择性特点，为理解未来电网保护挑战提供了深入见解。

Conclusion: 在逆变器型电源主导的未来电网中，传统差动保护存在局限性，需要考虑序分量的增强策略来应对海上风电MMC-HVDC系统的保护挑战。

Abstract: The ongoing global transition towards low-carbon energy has propelled the integration of offshore wind farms, which, when combined with Modular Multilevel Converter-based High-Voltage Direct Current (MMC-HVDC) transmission, present unique challenges for power system protection. In collector cables connecting wind turbines to offshore MMC, both ends are supplied by Inverter-Based Resources (IBRs), which modify the magnitude and characteristics of fault currents. In this context, this paper investigates the limitations of conventional differential protection schemes under such conditions and compares them with enhanced strategies that account for sequence components. Using electromagnetic transient simulations of a representative offshore wind farm modeled in PSCAD/EMTDC software, internal and external fault scenarios are assessed, varying fault types and resistances. The comparative evaluation provides insights into the sensitivity and selectivity of differential protection and guides a deeper conceptual understanding of the evolving protection challenges inherent to future converter-dominated grids.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)
*Donghao Huang,Gauri Malwe,Zhaoxia Wang*

Main category: cs.AI

TL;DR: 本文提出了一个基于大数据分析的诊断框架，用于评估智能代理系统的工具使用可靠性，通过1980个测试实例发现Qwen2.5:32B模型在工具初始化方面表现完美，与GPT-4相当，而中等规模模型在成本效益方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 尽管基于大语言模型的多智能体系统正在改变企业自动化，但评估工具使用可靠性的系统化方法仍然不足。特别是在中小企业部署和隐私敏感环境中，需要可靠的评估框架来确保智能代理系统的稳定性。

Method: 提出了一个全面的诊断框架，包含12类错误分类法，涵盖工具初始化、参数处理、执行和结果解释等失败模式。系统评估了1980个确定性测试实例，涵盖开源模型（Qwen2.5系列、Functionary）和专有模型（GPT-4、Claude 3.5/3.7），并在不同边缘硬件配置上进行测试。

Result: 研究发现：1）程序可靠性（特别是工具初始化失败）是较小模型的主要瓶颈；2）Qwen2.5:32B模型表现完美，与GPT-4相当；3）中等规模模型（Qwen2.5:14B）在商品硬件上提供实用的准确性与效率权衡（96.6%成功率，7.3秒延迟）。

Conclusion: 该框架为工具增强的多智能体AI系统的系统可靠性评估建立了基础架构，为资源受限组织提供了成本效益高的智能代理部署方案，并确定了生产部署的可操作可靠性阈值。

Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.

</details>


### [69] [SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems](https://arxiv.org/abs/2601.16286)
*Varun Chillara,Dylan Kline,Christopher Alvares,Evan Wooten,Huan Yang,Shlok Khetan,Cade Bauer,Tré Guillory,Tanishka Shah,Yashodhara Dhariwal,Volodymyr Pavlov,George Popstefanov*

Main category: cs.AI

TL;DR: SemanticALLI通过将AI管道分解为结构化中间表示，实现语义缓存，显著提升缓存命中率并减少LLM调用


<details>
  <summary>Details</summary>
Motivation: 传统AI管道存在隐藏的低效问题：即使自然语言表述完全不同，系统仍会重复构建相同的中间逻辑（如指标标准化、图表框架）。传统的边界缓存将推理视为黑盒，无法捕捉这种语义层面的冗余。

Method: 提出SemanticALLI架构，将生成过程分解为两个阶段：分析意图解析（AIR）和可视化合成（VS）。通过将结构化中间表示提升为一等可缓存工件，实现语义层面的缓存。

Result: 评估显示：传统单体缓存因语言变异性限制在38.7%命中率，而结构化方法在可视化合成阶段达到83.10%命中率，绕过4023次LLM调用，中位延迟仅2.66毫秒。

Conclusion: 即使用户很少重复相同表述，AI管道在稳定的结构化检查点仍会重复执行相同逻辑，在这些位置实施缓存最为可靠。这种内部重用减少了总令牌消耗，为AI系统设计提供了实用经验。

Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.

</details>


### [70] [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)
*Fan Nie,Junlin Wang,Harper Hua,Federico Bianchi,Yongchan Kwon,Zhenting Qi,Owen Queen,Shang Zhu,James Zou*

Main category: cs.AI

TL;DR: DSGym是一个用于评估和训练数据科学代理的标准化框架，通过自包含的执行环境解决现有基准测试的局限性，提供模块化架构和综合任务套件。


<details>
  <summary>Details</summary>
Motivation: 现有数据科学基准测试存在三个主要问题：1) 评估接口碎片化导致跨基准比较困难；2) 任务覆盖范围狭窄；3) 缺乏严格的数据基础（许多任务无需实际数据即可解决）。需要更全面的评估框架。

Method: 开发DSGym框架，包括：1) 模块化架构，便于添加任务、代理脚手架和工具；2) DSGym-Tasks任务套件，标准化现有基准并进行质量过滤；3) DSBio（生物信息学任务）和DSPredict（预测任务）；4) 通过执行验证的数据合成管道支持代理训练。

Result: 1) 构建了包含2,000个示例的训练集；2) 训练了一个4B参数模型，在标准化分析基准上优于GPT-4o；3) 实现了对代理在真实科学背景下规划、实施和验证数据分析能力的端到端测量。

Conclusion: DSGym提供了一个可扩展的测试平台，能够严格评估数据科学代理在实际数据分析任务中的能力，解决了现有基准的局限性，并展示了通过该框架训练的模型能够超越现有先进模型。

Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.

</details>


### [71] [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)
*Hongjia Wu,Shuai Zhou,Hongxin Zhang,Wei Chen*

Main category: cs.AI

TL;DR: Doc2AHP：一个结合LLM泛化能力与AHP决策理论严谨性的结构化推理框架，通过AHP原则约束LLM在非结构化文档空间中的搜索，无需标注数据或人工干预即可构建高质量决策模型。


<details>
  <summary>Details</summary>
Motivation: LLM在语义理解方面表现出色，但在需要严格逻辑的复杂决策任务中难以保证结构一致性和推理可靠性。传统决策理论（如AHP）虽然提供系统化理性框架，但构建过程严重依赖劳动密集型的领域专家知识，存在"专家瓶颈"问题，限制了在一般场景中的可扩展性。

Method: 提出Doc2AHP框架：1）利用AHP的结构原则作为约束，引导LLM在非结构化文档空间中进行受限搜索，强制执行父子节点间的逻辑蕴含关系；2）引入多智能体加权机制结合自适应一致性优化策略，确保权重分配的数字一致性。

Result: 实证结果表明，Doc2AHP不仅使非专家用户能够从零开始构建高质量决策模型，而且在逻辑完整性和下游任务准确性方面显著优于直接生成基线方法。

Conclusion: Doc2AHP成功弥合了LLM的泛化能力与决策理论严谨性之间的差距，通过结构化约束引导LLM推理，解决了专家瓶颈问题，为从非结构化文档构建可靠决策模型提供了有效方案。

Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.

</details>


### [72] [SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care](https://arxiv.org/abs/2601.16529)
*Dongshen Peng,Yi Wang,Carl Preiksaitis,Christian Rose*

Main category: cs.AI

TL;DR: SycoEval-EM框架通过多智能体模拟评估LLM在急诊医学中面对患者压力时的鲁棒性，发现模型容易屈服于不适当医疗请求，静态基准无法预测实际安全表现


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中具有潜力，但存在屈服于患者压力而提供不适当医疗服务的风险，需要评估其在对抗性社会压力下的鲁棒性

Method: 引入SycoEval-EM多智能体模拟框架，通过对抗性患者说服场景评估20个LLM在1875次急诊医学遭遇中的表现，涵盖三个Choosing Wisely场景

Result: 模型屈服率从0-100%不等，对影像检查请求的脆弱性(38.8%)高于阿片类药物处方(25.0%)，模型能力与鲁棒性相关性差，所有说服策略效果相似(30.0-36.0%)

Conclusion: 静态基准无法充分预测LLM在社会压力下的安全性，临床AI认证需要进行多轮对抗性测试以确保实际应用中的安全性和鲁棒性

Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.

</details>


### [73] [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)
*Meet Raval,Tejul Pandit,Dhvani Upadhyay*

Main category: cs.AI

TL;DR: 传统机器学习在医学分类任务中表现最佳，LoRA微调的Gemma变体表现最差，零样本LLM/VLM在图像任务中表现有竞争力


<details>
  <summary>Details</summary>
Motivation: 评估多模态视觉语言模型和大语言模型在医学分类任务中的表现，与传统机器学习方法进行对比，为医学AI领域提供基准参考

Method: 使用四个公开数据集（涵盖文本和图像模态，包括二元和多元分类），对比三类模型：传统ML（LR、LightGBM、ResNet-50）、基于提示的LLM/VLM（Gemini 2.5）、PEFT微调模型（LoRA适配的Gemma3变体），采用一致的数据划分和评估指标

Result: 传统ML模型在大多数医学分类任务中表现最佳，尤其在结构化文本数据集上；LoRA微调的Gemma变体在所有实验中表现最差；零样本LLM/VLM在文本任务上表现不佳，但在多元图像分类任务中与ResNet-50基线相当

Conclusion: 在许多医学分类场景中，传统机器学习模型仍是最可靠的选择；基础模型并非普遍优越，PEFT的效果高度依赖适配策略，本研究中的最小微调反而有害

Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.

</details>


### [74] [LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents](https://arxiv.org/abs/2601.16649)
*Amin Rakhsha,Thomas Hehn,Pietro Mazzaglia,Fabio Valerio Massoli,Arash Behboodi,Tribhuvanesh Orekondy*

Main category: cs.AI

TL;DR: 本文提出了一种评估多轮智能体任务中不同能力（如规划、状态跟踪）重要性的框架，通过oracle干预来量化各项技能对性能提升的贡献，发现规划能力普遍重要，而其他技能的有效性取决于环境和模型特性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在孤立任务上表现良好，但在需要规划、状态跟踪和长上下文处理的多轮、长视野智能体任务中仍然存在困难。研究旨在理解这些底层能力对于此类任务成功的相对重要性。

Method: 开发了一个oracle反事实框架，通过提供完美执行特定任务（如完美规划、无错误状态跟踪）的oracle干预来评估智能体性能变化。创建了一套可调复杂度的程序生成游戏式任务，这些受控环境允许精确的oracle干预，并能隔离每项技能的贡献。

Result: 结果显示，某些干预（如规划）在各种设置下都能持续提升性能，而其他技能的有用性则取决于环境和语言模型的特性。研究揭示了多轮智能体环境中的挑战。

Conclusion: 该工作为未来AI智能体和语言模型的发展提供了指导，强调了在多轮智能体环境中需要针对不同技能进行有针对性的改进，特别是规划能力的普遍重要性。

Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.

</details>


### [75] [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)
*Suzhong Fu,Jingqi Dong,Xuan Ding,Rui Sun,Yiming Yang,Shuguang Cui,Zhen Li*

Main category: cs.AI

TL;DR: AgentsEval是一个多智能体流推理框架，用于评估医学影像报告生成的临床正确性和推理保真度，通过模拟放射科医生的协作诊断工作流程提供结构化评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法捕捉放射学解释背后的结构化诊断逻辑，导致不可靠的判断和有限的临床相关性，需要更可靠、临床相关的评估方法。

Method: 采用多智能体流推理框架，将评估过程分为可解释的步骤：标准定义、证据提取、对齐和一致性评分，提供明确的推理轨迹和结构化临床反馈。同时构建了基于扰动的多领域基准测试。

Result: 实验结果表明，AgentsEval能够提供临床对齐、语义忠实且可解释的评估，在释义、语义和风格扰动下保持稳健性。

Conclusion: 该框架代表了向透明和临床基础的医学报告生成系统评估迈出的一步，促进大语言模型在临床实践中的可信集成。

Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.

</details>


### [76] [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chen Gao,Chen Zhang,Chengcheng Han,Chenhui Yang,Chuyu Zhang,Cong Chen,Cunguang Wang,Daoru Pan,Defei Bu,Dengchang Zhao,Di Xiu,Dishan Liu,Dongyu Ru,Dunwei Tu,Fan Wu,Fengcheng Yuan,Fengcun Li,Gang Xu,Guanyu Wu,Guoyuan Lin,Haibin Wang,Hansi Yang,Hao Yang,Haonan Yan,Haoxiang Ma,Haoxing Wen,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiacheng Zhang,Jiahong Zhou,Jiahuan Li,Jiaming Wang,Jian Yang,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiapeng Zhu,Jiaqi Sun,Jiarong Shi,Jiarui Zhao,Jingang Wang,Jinluan Yang,Jinrui Ding,Jinwei Xiao,Jiyuan He,Juncan Xu,Kefeng Zhang,Keheng Wang,Li Wei,Lianhui Ma,Lin Qiu,Lingbing Kong,Lingchuan Liu,Linsen Guo,Mengshen Zhu,Mengxia Shen,Mingyang Zhu,Peiguang Li,Peng Pei,Pengcheng Jia,Pengtao Zhang,Peng Zhao,Qi Gu,Qiong Huang,Qiyuan Duan,Quanchi Weng,Rongxiang Weng,Rongzhi Zhang,Rumei Li,Shanglin Lei,Shengnan An,Shijun Dai,Shuaikang Liu,Shuang Zhou,Shuo Wang,Songyuan Zhao,Tao Liang,Tianhao Hu,Tianze Chen,Wei Liu,Wei Shi,Wei Wang,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Wentao Chen,Wentao Shi,Xi Su,Xiangcheng Liu,Xiandi Ma,Xiangyu Xi,Xiangyuan Liu,Xiangzhou Huang,Xiao Liu,Xiaodong Cai,Xiaolong Chen,Xiaowei Shi,Xiaoyu Li,Xin Chen,Xingchen Liu,Xuan Huang,Xuezhi Cao,Xunliang Cai,Yan Chen,Yang Bai,Yang Liu,Yang Yang,Yang Zheng,Yaoming Wang,Yaoming Zhu,Yaqi Huo,Yanyu Chen,Yaorui Shi,Yerui Sun,Yi Zhang,Yihao Chen,Yi-Kai Zhang,Yifan Lu,Yifan Zhao,Yitao Zhai,Yongjing Yin,Yongwei Zhou,Youshao Xiao,Yuchuan Dai,Yuchen Xie,Yuchen Yu,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunfan Liang,Yunke Zhao,Yuwei Jiang,Yuxin Bian,Yuxin Chen,Yuxin Liu,Yue Xu,Yueqing Sun,Zeyang Yu,Zhao Yang,Zhengsheng Huang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhimin Lin,Zhiyuan Yao,Zhuofan Chen,Zhuowen Han,Zijian Zhang,Ziran Li,Ziwen Wang,Ziyuan Zhuang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking-2601是一个5600亿参数的开源MoE推理模型，在多种智能体基准测试中达到SOTA，通过统一的训练框架、环境扩展、噪声处理以及Heavy Thinking模式实现卓越的推理能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个具有卓越智能体推理能力的开源模型，能够处理复杂的工具交互、多轮智能体交互，并在嘈杂的现实环境中保持鲁棒性。

Method: 采用统一的训练框架，结合领域并行专家训练与后续融合；扩展异步强化学习框架DORA用于大规模多环境训练；系统分析现实噪声模式并设计针对性训练；引入Heavy Thinking模式进行测试时扩展。

Result: 在智能体搜索、智能体工具使用和工具集成推理等基准测试中达到开源模型的最先进性能；在复杂工具交互中表现出强大的泛化能力；在嘈杂现实环境中保持鲁棒行为。

Conclusion: LongCat-Flash-Thinking-2601通过创新的训练框架、环境扩展、噪声处理和推理增强技术，实现了卓越的智能体推理能力，为现实世界应用提供了强大的开源解决方案。

Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.

</details>


### [77] [An Efficient Insect-inspired Approach for Visual Point-goal Navigation](https://arxiv.org/abs/2601.16806)
*Lu Yihe,Barbara Webb*

Main category: cs.AI

TL;DR: 提出一种受昆虫启发的视觉点目标导航智能体，结合昆虫大脑的联想学习和路径整合机制，在Habitat点目标导航任务中实现与SOTA模型相当的性能，但计算成本低多个数量级。


<details>
  <summary>Details</summary>
Motivation: 受昆虫在发现食物位置与巢穴之间学习并优化视觉引导路径能力的启发，希望开发一种简单高效的视觉点目标导航方法。昆虫能够在复杂环境中高效导航，这为开发低计算成本的导航算法提供了生物学灵感。

Method: 结合两种昆虫大脑结构的抽象模型：一种负责联想学习，另一种负责路径整合。将Habitat点目标导航任务的正式基准与昆虫学习能力进行类比，开发出昆虫启发的智能体。

Result: 该简单昆虫启发智能体在Habitat点目标导航任务中表现出与最近SOTA模型相当的性能，但计算成本低多个数量级。在更真实的模拟环境测试中，该方法对扰动具有鲁棒性。

Conclusion: 昆虫大脑的简单抽象模型能够实现高效的点目标导航，为开发低计算成本的导航算法提供了有前景的方向，展示了生物启发方法在机器人导航领域的潜力。

Abstract: In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.

</details>


### [78] [Reasoning Promotes Robustness in Theory of Mind Tasks](https://arxiv.org/abs/2601.16853)
*Ian B. de Haan,Peter van der Putten,Max van Duijn*

Main category: cs.AI

TL;DR: 研究发现推理导向的LLM在心理理论任务中表现出更强的鲁棒性，但这种改进更多源于寻找正确解决方案的鲁棒性增强，而非全新的心理理论推理能力。


<details>
  <summary>Details</summary>
Motivation: 近期LLM在心理理论测试中表现出色引发争议，同时通过可验证奖励强化学习训练的推理导向LLM在多个基准测试中取得显著改进。本研究旨在探究这类推理模型在心理理论任务中的行为表现。

Method: 使用新颖的机器心理学实验改编和已建立基准测试的结果，分析推理模型在心理理论任务中的表现，特别关注其对提示变化和任务扰动的鲁棒性。

Result: 推理模型在心理理论任务中一致表现出对提示变化和任务扰动更强的鲁棒性，但分析表明这些增益更可能归因于寻找正确解决方案的鲁棒性增强，而非全新的心理理论推理形式。

Conclusion: 评估LLM的社会认知行为时，需要区分真正的心理理论推理能力和通过强化学习获得的鲁棒性改进，这对理解LLM的认知能力本质具有重要意义。

Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.

</details>


### [79] [Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation](https://arxiv.org/abs/2601.16863)
*Tims Pecerskis,Aivars Smirnovs*

Main category: cs.AI

TL;DR: NSED协议是一种运行时混合模型架构，通过动态专家代理和宏观循环神经网络实现小型模型组合达到大模型性能，同时具备内在对齐特性。


<details>
  <summary>Details</summary>
Motivation: 传统混合专家模型依赖静态门控网络，无法动态适应实时需求和成本约束。需要一种能够运行时优化模型选择、实现小型模型组合达到大模型性能的架构。

Method: 1. 动态专家代理：将模型选择视为背包问题变体，基于实时遥测和成本约束绑定异构检查点到功能角色
2. 宏观循环神经网络：将审议形式化为宏观RNN，通过语义遗忘门实现迭代精炼，避免VRAM线性增长
3. 信任less的N对N同行评审编排结构
4. 非线性共识的二次投票激活函数
5. 反馈驱动的状态更新

Result: 1. 在AIME 2025和LiveCodeBench等挑战性基准测试中，小于200亿参数的小型消费级模型组合能够匹配或超越1000亿+参数的最先进模型性能
2. 建立了新的硬件套利效率前沿
3. 在DarkBench安全套件测试中显示内在对齐特性，同行介导的纠正将谄媚分数降低到低于任何单个代理的水平

Conclusion: NSED协议通过动态专家选择和宏观RNN审议机制，实现了小型模型组合的高效协同，不仅达到了大模型性能水平，还具备更好的安全对齐特性，为模型部署提供了新的效率范式。

Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.

</details>


### [80] [MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion](https://arxiv.org/abs/2601.16886)
*Chi Yu,Hongyu Yuan,Zhiyi Duan*

Main category: cs.AI

TL;DR: MAGE-KT：多智能体图增强知识追踪框架，通过多视图异构图和子图检索解决现有图KT方法中概念关系挖掘不足和全图编码计算成本高、噪声多的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的知识追踪方法未能充分探索概念间关系（通常仅从交互序列推断），且KT图的规模和异质性导致全图编码计算成本高、噪声多，注意力会扩散到与学生无关的区域，降低概念间关系保真度。

Method: 构建多视图异构图（结合多智能体概念关系提取器和学生-问题交互图），基于目标学生历史检索紧凑高价值子图，使用非对称交叉注意力融合模块集成子图信息，避免注意力扩散和不相关计算。

Result: 在三个广泛使用的KT数据集上，概念关系准确性显著提升，下一问题预测性能明显优于现有方法。

Conclusion: MAGE-KT通过多智能体概念关系提取和子图检索机制，有效解决了图KT中的概念关系挖掘不足和计算效率问题，提升了知识追踪性能。

Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.

</details>


### [81] [Preventing the Collapse of Peer Review Requires Verification-First AI](https://arxiv.org/abs/2601.16909)
*Lei You,Lele Cao,Iryna Gurevych*

Main category: cs.AI

TL;DR: 论文主张AI辅助同行评审应采用验证优先而非模仿评审的方法，提出"真相耦合"作为评审工具的正确目标，并分析导致代理主权评估相变的两种力量


<details>
  <summary>Details</summary>
Motivation: 当前AI辅助同行评审主要模仿传统评审过程，但这种方法可能放大声明膨胀问题。论文旨在重新思考AI在科学评审中的角色，防止评审系统从追求科学真相转向优化代理指标

Method: 提出"真相耦合"概念作为评审工具目标，形式化验证压力和信号收缩两种力量，建立混合高保真检查与频繁代理判断的最小模型，推导耦合定律和激励崩溃条件

Result: 在最小模型中推导出明确的耦合定律和激励崩溃条件，表明即使当前决策看起来可靠，理性努力也会从追求真相转向优化代理指标。识别出导致代理主权评估相变的临界条件

Conclusion: AI应作为对抗性审计工具，生成可审计的验证工件并扩展有效验证带宽，而非作为分数预测器放大声明膨胀。为工具构建者和程序主席提供具体行动建议

Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.

</details>


### [82] [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.AI

TL;DR: AgentDrive是一个包含30万个LLM生成的驾驶场景的开放基准数据集，用于训练、微调和评估自动驾驶智能体，同时包含10万个多选题的AgentDrive-MCQ基准，评估了50个领先LLM在五个推理维度的表现。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、结构化、安全关键的基准来评估和训练集成LLM的自动驾驶智能体，这阻碍了自动驾驶系统在推理驱动的感知、规划和决策方面的发展。

Method: 通过LLM驱动的prompt-to-JSON管道生成语义丰富的仿真就绪场景规范，在七个正交轴上因子化场景空间，并进行物理和模式约束验证。每个场景经过仿真推演、代理安全指标计算和基于规则的结果标注。同时创建了包含10万个多选题的AgentDrive-MCQ基准，涵盖五个推理维度。

Result: 评估了50个领先LLM在AgentDrive-MCQ上的表现，结果显示专有前沿模型在上下文和政策推理方面表现最佳，而先进开源模型在结构化和物理基础推理方面正在迅速缩小差距。

Conclusion: AgentDrive为自动驾驶智能体的训练、微调和评估提供了大规模、结构化的基准，有助于推动集成LLM的自动驾驶系统发展，同时揭示了不同类型LLM在不同推理维度上的相对优势。

Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive

</details>


### [83] [Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts](https://arxiv.org/abs/2601.16965)
*Riyang Bao,Cheng Yang,Dazhou Yu,Zhexiang Tang,Gengchen Mai,Liang Zhao*

Main category: cs.AI

TL;DR: Spatial-Agent是一个基于空间信息科学理论的AI智能体，通过将地理分析问题形式化为概念转换问题，使用GeoFlow图表示可执行工作流，显著提升了地理空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在真实地理空间计算方面存在不足，主要依赖网络搜索或模式匹配，容易产生空间关系幻觉，无法满足城市分析、交通规划、灾害响应等实际应用需求。

Method: 将地理分析问题形式化为概念转换问题，将自然语言问题解析为可执行工作流，表示为GeoFlow图（有向无环图）。基于空间信息理论提取空间概念，分配功能角色并施加排序约束，通过模板生成转换序列。

Result: 在MapEval-API和MapQA基准测试中，Spatial-Agent显著优于ReAct和Reflexion等现有基线方法，同时生成可解释且可执行的地理空间工作流。

Conclusion: Spatial-Agent通过将空间信息科学理论融入AI智能体设计，有效解决了现有LLM智能体在地理空间推理方面的局限性，为实际应用提供了可靠的地理分析能力。

Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.

</details>


### [84] [Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians](https://arxiv.org/abs/2601.16967)
*Bernes Lorier Atabonfack,Ahmed Tahiru Issah,Mohammed Hardi Abdul Baaki,Clemence Ingabire,Tolulope Olusuyi,Maruf Adewole,Udunna C. Anazodo,Timothy X Brown*

Main category: cs.AI

TL;DR: 开发AI支持平台辅助生物医学技术人员实时诊断和维修医疗设备，在资源有限环境中减少设备停机时间


<details>
  <summary>Details</summary>
Motivation: 中低收入国家医疗诊断设备因维护不及时、技术专家缺乏和制造商支持不足而利用率低或无法使用，导致设备停机时间长、诊断延迟和患者护理受损

Method: 集成大型语言模型与用户友好的Web界面，允许技术人员输入错误代码或设备症状，获得逐步故障排除指导；包含全球点对点讨论论坛支持知识交换；使用Philips HDI 5000超声机进行概念验证

Result: 错误代码解释达到100%精确度，纠正措施建议达到80%准确率，证明了AI驱动系统支持医疗设备维护的可行性

Conclusion: AI驱动系统有潜力支持医疗设备维护，减少设备停机时间，改善资源受限环境中的医疗服务提供

Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [85] [A Constructive Cayley Representation of Orthogonal Matrices and Applications to Optimization](https://arxiv.org/abs/2601.16271)
*Iwo Biborski*

Main category: math.OC

TL;DR: 提出了一个构造性算法，给定任意实正交矩阵U，计算对角符号矩阵D使得DU的Cayley变换有定义，从而将U表示为D(I-S)(I+S)^{-1}形式，其中S是斜对称矩阵。


<details>
  <summary>Details</summary>
Motivation: 已知每个实正交矩阵可以通过乘以适当的对角符号矩阵使其进入Cayley变换的定义域。本文旨在提供构造性且数值高效的算法来实现这一过程，为Cayley变换在正交群优化方法中的应用提供理论基础。

Method: 提出一个构造性算法，给定实正交矩阵U，计算对角矩阵D（元素为±1），使得DU的Cayley变换有定义。算法复杂度为O(n³)，并能产生斜对称生成元的显式定量界。

Result: 成功开发了高效算法，能够将任意实正交矩阵表示为U = D(I-S)(I+S)^{-1}形式，其中D为对角符号矩阵，S为斜对称矩阵。算法具有O(n³)时间复杂度，并提供了斜对称生成元的定量界。

Conclusion: 该算法为Cayley变换在正交群上的应用提供了理论基础，特别有助于控制Cayley变换基优化方法中的奇异性问题，具有重要的理论和应用价值。

Abstract: It is known that every real orthogonal matrix can be brought into the domain of the Cayley transform by multiplication with a suitable diagonal signature matrix. In this paper we provide a constructive and numerically efficient algorithm that, given a real orthogonal matrix $U$, computes a diagonal matrix $D$ with entries in $\{\pm1\}$ such that the Cayley transform of $DU$ is well defined. This yields a representation of $U$ in the form \[ U = D(I-S)(I+S)^{-1}, \] where $S$ is a skew-symmetric matrix. The proposed algorithm requires $O(n^{3})$ arithmetic operations and produces an explicit quantitative bound on the associated skew-symmetric generator. As an application, we show how this construction can be used to control singularities in Cayley-transform-based optimization methods on the orthogonal group.

</details>


### [86] [Maximizing Reach-Avoid Probabilities for Linear Stochastic Systems via Control Architectures](https://arxiv.org/abs/2601.16290)
*Niklas Schmid,Jaeyoun Choi,Oswin So,Chuchu Fan*

Main category: math.OC

TL;DR: 提出一种结合MDP灵活性和MPC可扩展性的控制架构，通过在线优化更新MPC参考信号来最大化随机系统的可达-规避概率，并在12D四旋翼模型上验证了方法的灵活性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有最大化随机系统可达-规避概率的方法要么局限于低维系统，要么存在保守近似，需要一种既能处理高维系统又能避免过度保守的新方法。

Method: 提出控制架构将MPC的跟踪能力与MDP的决策灵活性结合：MPC跟踪参考信号（不考虑随机性和可达-规避目标），而可达-规避概率通过在线优化更新MPC参考信号来最大化。将闭环系统抽象为MDP，在每个时间步选择新参考，通过动态规划计算最优参考反馈策略。对于连续状态空间，在有限系统近似上执行动态规划，并通过MPC修改实现计算高效的鲁棒化以处理近似误差。

Result: 方法在受扰动的12D四旋翼模型和复杂可达-规避环境中得到验证，证明了其灵活性和可扩展性，能够处理高维系统并保持可达-规避概率的界限。

Conclusion: 提出的控制架构成功解决了现有方法在高维随机系统可达-规避概率最大化中的局限性，结合了MDP的决策灵活性和MPC的计算可扩展性，为复杂随机控制问题提供了有效解决方案。

Abstract: The maximization of reach-avoid probabilities for stochastic systems is a central topic in the control literature. Yet, the available methods are either restricted to low-dimensional systems or suffer from conservative approximations. To address these limitations, we propose control architectures that combine the flexibility of Markov Decision Processes with the scalability of Model Predictive Controllers. The Model Predictive Controller tracks reference signals while remaining agnostic to the stochasticity and reach-avoid objective. Instead, the reach-avoid probability is maximized by optimally updating the controller's reference online. To achieve this, the closed-loop system, consisting of the system and Model Predictive Controller, is abstracted as a Markov Decision Process in which a new reference can be chosen at every time-step. A feedback policy generating optimal references is then computed via Dynamic Programming. If the state space of the system is continuous, the Dynamic Programming algorithm must be executed on a finite system approximation. Modifications to the Model Predictive Controller enable a computationally efficient robustification of the Dynamic Programming algorithm to approximation errors, preserving bounds on the achieved reach-avoid probability. The approach is validated on a perturbed 12D quadcopter model in cluttered reach-avoid environments proving its flexibility and scalability.

</details>


### [87] [Solving Regularized Multifacility Location Problems with Unknown Number of Centers via Difference-of-Convex Optimization](https://arxiv.org/abs/2601.16576)
*W. Geremew,V. S. T. Long,N. M. Nam,A. Solano-Herrera*

Main category: math.OC

TL;DR: 提出基于Minkowski度量的多设施选址优化方法，结合Laplace型正则化项，建立理论分析并设计高效数值算法


<details>
  <summary>Details</summary>
Motivation: 针对基于Minkowski度量的多设施选址问题，需要开发有效的优化方法来解决带Laplace型正则化的模型，并确定聚类中心数量

Method: 结合Nesterov平滑技术和凸差优化最新进展，设计高效数值算法；从理论和数值角度分析模型，建立最优解存在性并研究全局极小点的定性性质

Result: 建立了最优解的存在性理论，提出了有效的数值算法，为基于度量的多设施选址和聚类问题提供了确定中心数量的有效方法

Conclusion: 该方法扩展和补充了近期研究进展，为Minkowski度量下的多设施选址问题提供了理论和数值解决方案

Abstract: In this paper, we develop optimization methods for a new model of multifacility location problems defined by a Minkowski gauge with Laplace-type regularization terms. The model is analyzed from both theoretical and numerical perspectives. In particular, we establish the existence of optimal solutions and study qualitative properties of global minimizers. By combining Nesterov's smoothing technique with recent advances in difference-of-convex optimization, following the pioneering work of P. D. Tao and L. T. H. An and others, we propose efficient numerical algorithms for minimizing the objective function of this model. As an application, our approach provides an effective method for determining the number of centers in gauge-based multifacility location and clustering problems. Our results extend and complement recent developments.

</details>


### [88] [Necessary Optimality Conditions for Integrated Learning and Optimization Problem in Contextual Optimization](https://arxiv.org/abs/2601.16581)
*Yuan Tao,Huifu Xu*

Main category: math.OC

TL;DR: 本文针对集成学习与优化（ILO）这一新型随机双层规划问题，首次从优化理论角度推导了一阶必要最优性条件，填补了该领域的研究空白。


<details>
  <summary>Details</summary>
Motivation: ILO框架作为上下文优化中的新范式，在运筹学和管理科学中广泛应用，但缺乏优化理论层面的深入分析。本文旨在填补这一理论空白。

Method: 采用两种方法：对于下层凸优化问题，将其转化为带变分不等式约束的两阶段随机规划，通过第二阶段值函数的灵敏度分析建立最优性条件；对于下层非凸问题，采用值函数方法，在随机部分镇定条件下推导一阶必要条件。

Result: 首次推导出基于Mordukhovich极限次微分的一阶必要最优性条件，并将这些条件应用于文献中现有的多个ILO问题。

Conclusion: 本文填补了ILO问题优化理论分析的空白，推导的最优性条件可用于设计基于梯度的ILO求解算法，为该领域提供了重要的理论基础。

Abstract: Integrated learning and optimization (ILO) is a framework in contextual optimization which aims to train a predictive model for the probability distribution of the underlying problem data uncertainty, with the goal of enhancing the quality of downstream decisions. This framework represents a new class of stochastic bilevel programs, which are extensively utilized in the literature of operations research and management science, yet remain underexplored from the perspective of optimization theory. In this paper, we fill the gap. Specifically, we derive the first-order necessary optimality conditions in terms of Mordukhovich limiting subdifferentials. To this end, we formulate the bilevel program as a two-stage stochastic program with variational inequality constraints when the lower-level decision-making problem is convex, and establish an optimality condition via sensitivity analysis of the second-stage value function. In the case where the lower level optimization problem is nonconvex, we adopt the value function approach in the literature of bilevel programs and derive the first-order necessary conditions under stochastic partial calmness conditions. The derived optimality conditions are applied to several existing ILO problems in the literature. These conditions may be used for the design of gradient-based algorithms for solving ILO problems.

</details>


### [89] [Stabilization of a Wave-Heat Cascade System](https://arxiv.org/abs/2601.16610)
*Hugo Lhachemi,Christophe Prieur,Emmanuel Trélat*

Main category: math.OC

TL;DR: 基于Riesz谱分析，为耦合反应扩散-波动系统设计有限维输出反馈控制器，实现任意指数稳定


<details>
  <summary>Details</summary>
Motivation: 研究一维级联系统（反应扩散方程与波动方程通过内部项耦合）的输出反馈镇定问题。系统具有Neumann边界控制，可获取波动边界速度和温度型观测。目标是设计有限维动态输出反馈律，实现任意指数衰减。

Method: 首先证明开环系统生成元是Riesz谱算子，利用此结构通过谱约简和Riesz基中的Lyapunov论证，基于有限个抛物模态设计有限维动态输出反馈律。方法可扩展到点温度或热通量测量。

Result: 在耦合和观测剖面满足显式必要充分条件下，成功设计出有限维输出反馈控制器，在自然能量空间和更强的抛物范数中均能实现任意指数衰减。

Conclusion: 通过Riesz谱分析和有限维输出反馈设计，有效解决了耦合反应扩散-波动系统的镇定问题，方法具有理论保证并可扩展到多种观测类型。

Abstract: We consider the output-feedback stabilization of a one-dimensional cascade coupling a reaction-diffusion equation and a wave equation through an internal term, with Neumann boundary control acting at the wave endpoint. Two measurements are available: the wave velocity at the controlled boundary and a temperature-type observation of the reaction-diffusion component, either distributed or pointwise. Under explicit, necessary and sufficient conditions on the coupling and observation profiles, we show that the generator of the open-loop system is a Riesz-spectral operator. Exploiting this structure, we design a finite-dimensional dynamic output-feedback law, based on a finite number of parabolic modes, which achieves arbitrary exponential decay in both the natural energy space and a stronger parabolic norm. The construction relies on a spectral reduction and a Lyapunov argument in Riesz bases. We also extend the design to pointwise temperature or heat-flux measurements.

</details>


### [90] [Projected Gradient Methods with Momentum](https://arxiv.org/abs/2601.16683)
*Matteo Lapucci,Giampaolo Liuzzi,Stefano Lucidi,Marco Sciandrone,Diego Scuppa*

Main category: math.OC

TL;DR: 提出一种结合动量信息的投影梯度算法，用于非凸光滑目标函数和凸约束集的优化问题，在理论和实验上优于标准投影梯度方法


<details>
  <summary>Details</summary>
Motivation: 在约束优化问题中，动量方法在无约束优化中已被证明非常有效，但在约束优化中尚未得到充分研究。本文旨在探索如何在投影梯度类算法中有效集成动量信息，以提升收敛性能

Method: 首先对具有凸约束集和非凸光滑目标函数的优化问题进行一般收敛性和复杂度分析，然后提出理论上合理的动量集成策略。详细开发了一种特定算法，该算法结合了动量信息，同时保持了合理的每次迭代计算成本

Result: 提出的方法在理论上有收敛保证，在两种不同的实验基准测试中均优于标准（谱）投影梯度方法，表明在约束优化中添加动量项与在无约束优化中同样有益

Conclusion: 动量方法可以有效集成到约束优化算法中，显著提升投影梯度类算法的性能，为约束优化问题提供了新的高效解决方案

Abstract: We focus on the optimization problem with smooth, possibly nonconvex objectives and a convex constraint set for which the Euclidean projection operation is practically available. Focusing on this setting, we carry out a general convergence and complexity analysis for algorithmic frameworks. Consequently, we discuss theoretically sound strategies to integrate momentum information within classical projected gradient type algorithms. One of these approaches is then developed in detail, up to the definition of a tailored algorithm with both theoretical guarantees and reasonable per-iteration cost. The proposed method is finally shown to outperform the standard (spectral) projected gradient method in two different experimental benchmarks, indicating that the addition of momentum terms is as beneficial in the constrained setting as it is in the unconstrained scenario.

</details>


### [91] [Resource Allocation Based on Past Incident Patterns](https://arxiv.org/abs/2601.16702)
*M. N. M. van Lieshout*

Main category: math.OC

TL;DR: 提出并解决应急响应服务的两个资源分配问题：车辆分配到站点和人员分配到车辆，采用极小极大框架，目标函数基于空间服务区域的总风险与分配资源单位之比，通过贪心算法求解。


<details>
  <summary>Details</summary>
Motivation: 针对应急响应服务的准备问题，需要优化资源分配以提高响应效率。具体关注如何将车辆分配到站点，以及如何将人员分配到车辆，以最小化最坏情况下的风险。

Method: 采用极小极大优化框架，定义目标函数为空间服务区域的总风险与分配资源单位之比。提出贪心算法，依次将资源单位分配给具有最大相对风险的区域，并制定适当的平局处理规则。

Result: 获得显式解，可通过贪心算法实际计算。算法在特温特消防队报告的事件数据集上进行了验证和说明。

Conclusion: 提出的极小极大资源分配方法为应急响应服务提供了实用的解决方案，贪心算法能够有效计算最优分配，并在实际数据集上验证了方法的可行性。

Abstract: We formulate and solve two resource allocation problems motivated by a preparedness question of emergency response services. First, we consider the assignment of vehicles to stations, and, in a second step, assign crews to vehicles. In both cases, we work in a minimax framework and define the objective function for a spatial catchment area as the total risk in this area per resource unit allocated to it. The solutions are explicit and can be calculated in practice by a greedy algorithm that successively allocates a resource unit to an area having maximal relative risk, with suitable tie breaker rules. The approach is illustrated on a data set of incidents reported to the Twente Fire Brigade.

</details>


### [92] [Optimal Control of Hydro-Electric Power Plants with Uncontrolled Spillways](https://arxiv.org/abs/2601.16748)
*Maria do Rosario de Pinho,Maria Margarida A. Ferreira,Georgi Smirnov*

Main category: math.OC

TL;DR: 研究带有可逆涡轮机和不可控溢洪道的水电站级联最优控制问题，通过指数罚函数方法推导必要条件


<details>
  <summary>Details</summary>
Motivation: 研究水电站级联系统的最优控制问题，主要挑战在于不可控溢洪道的存在：其不连续性以及在状态边界被激活的特性使得无法应用已知的最优性必要条件

Method: 通过使用指数罚函数序列逼近原始问题，将原问题转化为一系列标准最优控制问题，从而推导出必要条件

Result: 成功推导出适用于带有不可控溢洪道的水电站级联系统的最优性必要条件，并通过示例说明了所得条件的适用性

Conclusion: 提出的指数罚函数逼近方法能够有效处理带有不可控溢洪道的水电站级联最优控制问题，为这类具有不连续控制特性的系统提供了理论分析工具

Abstract: In this paper, we study an optimal control problem for a cascade of hydroelectric power plants with reversible turbines and uncontrolled spillways. The system dynamics are governed by a linear control model subject to path constraints. The aim is to maximize the power production profit while respecting operational restrictions on reservoir water levels. The challenge is the presence of uncontrollable spillways: their discontinuous nature and the fact that they are activated at the state boundary prevent the application of known necessary conditions of optimality. To overcome this, we derive necessary conditions by approximating the original problem through a sequence of standard optimal control problems using exponential penalty functions. The applicability of resulting conditions are illustrated by an example.

</details>


### [93] [Approximate controllability on the group of volume-preserving diffeomorphisms](https://arxiv.org/abs/2601.16939)
*Andrei Agrachev,Bettina Kazandjian*

Main category: math.OC

TL;DR: 研究二维和三维环面上体积保持微分同胚群的可控性问题，系统为固定无散向量场加平移控制项


<details>
  <summary>Details</summary>
Motivation: 研究环面上体积保持微分同胚群的可控性，特别是当系统由固定无散向量场和平移控制项组成时的控制能力

Method: 考虑系统 $\dot x=f(x)+u(t)$，其中 $f$ 是环面上的固定无散向量场，$u(t)$ 是生成环面平移的常向量场，主要研究二维和三维情况

Result: 主要结果针对二维和三维环面，建立了该系统的可控性条件

Conclusion: 对于二维和三维环面上的体积保持微分同胚群，在固定无散向量场加平移控制的系统下，获得了可控性的重要结果

Abstract: We study controlability issues for the group of volume-preserving diffeomorphisms of the torus $\mathbb T^d$ for system $\dot x=f(x)+u(t)$, where $f$ is a fixed divergence free vector field on $\mathbb T^d$ and $u(t)$ are constant vector fields which generate translations of the torus. Main results concern $d$ equals two or three.

</details>


### [94] [BONO-Bench: A Comprehensive Test Suite for Bi-objective Numerical Optimization with Traceable Pareto Sets](https://arxiv.org/abs/2601.16970)
*Lennart Schäpermeier,Pascal Kerschke*

Main category: math.OC

TL;DR: 提出BONO-Bench测试套件生成器，通过组合凸二次函数创建可配置的双目标数值优化问题，支持控制问题属性并保持理论可追踪性


<details>
  <summary>Details</summary>
Motivation: 当前多目标优化基准测试存在两种有缺陷的方法：手动构造的问题具有已知最优解但缺乏真实性；复合单目标问题则缺乏对问题属性的控制。需要一种既能配置问题属性又能保持理论可追踪性的基准测试生成方法

Method: 提出基于凸二次函数组合的双目标数值优化问题生成方法，支持配置决策变量数量、局部最优解、帕累托前沿形状、目标空间平台、条件数等属性，同时保持理论可追踪性

Result: 创建了包含20个问题类别的BONO-Bench测试套件，并进行了示例性基准研究。将方法和测试套件公开发布为Python包bonobench，促进可复现的基准测试

Conclusion: 提出的问题生成方法填补了现有基准测试方法的空白，既能配置复杂问题属性，又能保持理论可追踪性，为多目标优化研究提供了更可靠的基准测试工具

Abstract: The evaluation of heuristic optimizers on test problems, better known as \emph{benchmarking}, is a cornerstone of research in multi-objective optimization.
  However, most test problems used in benchmarking numerical multi-objective black-box optimizers come from one of two flawed approaches: On the one hand, problems are constructed manually, which result in problems with well-understood optimal solutions, but unrealistic properties and biases.
  On the other hand, more realistic and complex single-objective problems are composited into multi-objective problems, but with a lack of control and understanding of problem properties.
  This paper proposes an extensive problem generation approach for bi-objective numerical optimization problems consisting of the combination of theoretically well-understood convex-quadratic functions into unimodal and multimodal landscapes with and without global structure.
  It supports configuration of test problem properties, such as the number of decision variables, local optima, Pareto front shape, plateaus in the objective space, or degree of conditioning, while maintaining theoretical tractability: The optimal front can be approximated to an arbitrary degree of precision regarding Pareto-compliant performance indicators such as the hypervolume or the exact R2 indicator.
  To demonstrate the generator's capabilities, a test suite of 20 problem categories, called \emph{BONO-Bench}, is created and subsequently used as a basis of an illustrative benchmark study.
  Finally, the general approach underlying our proposed generator, together with the associated test suite, is publicly released in the Python package \texttt{bonobench} to facilitate reproducible benchmarking.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [95] [Distributional Computational Graphs: Error Bounds](https://arxiv.org/abs/2601.16250)
*Olof Hallqvist Elias,Michael Selby,Phillip Stanley-Marbell*

Main category: stat.ML

TL;DR: 研究分布计算图的离散化误差，建立基于Wasserstein-1距离的非渐近误差界


<details>
  <summary>Details</summary>
Motivation: 当计算图的输入是概率分布而非点值时，需要分析使用有限近似（如离散表示或经验分布）评估连续分布时产生的误差

Method: 提出分布计算图的一般框架，分析离散化误差，建立基于Wasserstein-1距离的非渐近误差界，无需对计算图结构做假设

Result: 建立了分布计算图离散化误差的理论界限，为使用有限近似评估连续分布提供了理论保证

Conclusion: 该框架为分析分布计算中的近似误差提供了通用工具，Wasserstein距离是衡量此类误差的合适度量

Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.

</details>


### [96] [Perfect Clustering for Sparse Directed Stochastic Block Models](https://arxiv.org/abs/2601.16427)
*Behzad Aalipur,Yichen Qin*

Main category: stat.ML

TL;DR: 提出了一种非谱的两阶段方法，用于稀疏有向随机块模型中的社区检测，该方法通过邻域平滑估计有向概率矩阵，然后进行K-means聚类，避免了谱方法在稀疏不对称网络中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在有向稀疏随机块模型中的社区检测存在不足：谱方法在不对称、低度数的网络中缺乏稳定性，而非谱方法主要关注无向或稠密网络。需要开发适用于稀疏有向网络且能处理社区数量增长的方法。

Method: 提出两阶段非谱方法：1) 使用针对不对称场景设计的邻域平滑方案估计有向概率矩阵；2) 对估计的行应用K-means聚类，避免在稀疏不对称网络中使用特征值或奇异值分解。

Result: 获得了平滑估计器的均匀行向集中界，在温和的稀疏性和分离条件下，能够以概率趋于1的方式精确恢复所有社区标签，即使γ_n→0且K_n→∞。

Conclusion: 该方法在有向稀疏不对称块结构中表现可靠，在谱方法和基于分数的方法失效的情况下仍能工作，为稀疏有向设置中的非谱邻域平滑方法提供了首个精确恢复保证。

Abstract: Exact recovery in stochastic block models (SBMs) is well understood in undirected settings, but remains considerably less developed for directed and sparse networks, particularly when the number of communities diverges. Spectral methods for directed SBMs often lack stability in asymmetric, low-degree regimes, and existing non-spectral approaches focus primarily on undirected or dense settings.
  We propose a fully non-spectral, two-stage procedure for community detection in sparse directed SBMs with potentially growing numbers of communities. The method first estimates the directed probability matrix using a neighborhood-smoothing scheme tailored to the asymmetric setting, and then applies $K$-means clustering to the estimated rows, thereby avoiding the limitations of eigen- or singular value decompositions in sparse, asymmetric networks. Our main theoretical contribution is a uniform row-wise concentration bound for the smoothed estimator, obtained through new arguments that control asymmetric neighborhoods and separate in- and out-degree effects. These results imply the exact recovery of all community labels with probability tending to one, under mild sparsity and separation conditions that allow both $γ_n \to 0$ and $K_n \to \infty$.
  Simulation studies, including highly directed, sparse, and non-symmetric block structures, demonstrate that the proposed procedure performs reliably in regimes where directed spectral and score-based methods deteriorate. To the best of our knowledge, this provides the first exact recovery guarantee for this class of non-spectral, neighborhood-smoothing methods in the sparse, directed setting.

</details>


### [97] [Efficient Learning of Stationary Diffusions with Stein-type Discrepancies](https://arxiv.org/abs/2601.16597)
*Fabian Bleile,Sarah Lumpp,Mathias Drton*

Main category: stat.ML

TL;DR: 提出Stein-type KDS (SKDS)作为替代KDS的公式，证明SKDS趋近于零可保证学习扩散的平稳分布与目标分布对齐，且具有凸性和计算效率优势。


<details>
  <summary>Details</summary>
Motivation: 基于KDS与Stein差异之间的联系，开发更高效、理论保证更强的扩散模型学习方法，减少计算成本同时保持准确性。

Method: 引入Stein-type KDS (SKDS)作为KDS的替代公式，利用再生核希尔伯特空间中扩散生成器的期望来强制平稳性，建立SKDS与目标分布对齐的理论保证。

Result: SKDS在广泛参数化下具有凸性，经验版本高概率ε-拟凸；实验表明SKDS达到与KDS相当的精度，同时显著降低计算成本，优于多数竞争基线。

Conclusion: SKDS提供了理论保证更强、计算效率更高的扩散模型学习方法，在保持准确性的同时大幅降低计算负担，是KDS的有效替代方案。

Abstract: Learning a stationary diffusion amounts to estimating the parameters of a stochastic differential equation whose stationary distribution matches a target distribution. We build on the recently introduced kernel deviation from stationarity (KDS), which enforces stationarity by evaluating expectations of the diffusion's generator in a reproducing kernel Hilbert space. Leveraging the connection between KDS and Stein discrepancies, we introduce the Stein-type KDS (SKDS) as an alternative formulation. We prove that a vanishing SKDS guarantees alignment of the learned diffusion's stationary distribution with the target. Furthermore, under broad parametrizations, SKDS is convex with an empirical version that is $ε$-quasiconvex with high probability. Empirically, learning with SKDS attains comparable accuracy to KDS while substantially reducing computational cost and yields improvements over the majority of competitive baselines.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [98] [Ordering-based Causal Discovery via Generalized Score Matching](https://arxiv.org/abs/2601.16249)
*Vy Vo,He Zhao,Trung Le,Edwin V. Bonilla,Dinh Phung*

Main category: cs.LG

TL;DR: 本文提出了一种基于离散评分函数的因果发现方法，能够从纯观测数据中准确推断因果顺序，显著提升现有基线方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 从纯观测数据中学习有向无环图（DAG）结构在多个科学领域仍是一个长期挑战。现有基于评分匹配的因果发现方法主要针对连续数据设计，缺乏适用于离散数据的有效方法。

Method: 扩展了原本为连续数据设计的评分匹配框架，引入了一种基于离散评分函数的新型叶节点判别准则。该方法首先通过叶节点检测识别底层DAG的拓扑顺序，然后进行边剪枝以恢复图结构。

Result: 通过模拟和真实世界实验证明，该方法能够从观测的离散数据中准确推断真实的因果顺序，并且所识别的顺序能够在几乎所有设置中显著提升现有因果发现基线的准确性。

Conclusion: 提出的基于离散评分函数的因果发现框架有效解决了从离散观测数据中学习DAG结构的挑战，为离散数据的因果推断提供了新的理论和方法支持。

Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.

</details>


### [99] [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)
*Zekai Chen,Kairui Yang,Xunkai Li,Henan Sun,Zhihan Zhang,Jia Li,Qiangqiang Dai,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: BoostFGL是一个公平感知的联邦图学习框架，通过客户端节点增强、拓扑增强和服务器端模型增强三个机制，解决联邦图学习中存在的群体公平性问题，在保持整体性能的同时显著提升公平性指标。


<details>
  <summary>Details</summary>
Motivation: 现有联邦图学习方法虽然整体准确率高，但会掩盖弱势节点群体的严重性能退化。这种不公平性源于三个耦合因素：标签偏向多数模式、消息传播中的拓扑混淆，以及困难客户端更新的聚合稀释。

Method: BoostFGL提出三个协同机制：1) 客户端节点增强：重塑本地训练信号，强调系统性服务不足的节点；2) 客户端拓扑增强：重新分配传播重点，偏向可靠但未充分利用的结构，减弱误导性邻域；3) 服务器端模型增强：执行难度和可靠性感知的聚合，保留困难客户端的有效更新同时稳定全局模型。

Result: 在9个数据集上的实验表明，BoostFGL带来显著的公平性提升，Overall-F1提高了8.43%，同时在与强基线对比中保持了有竞争力的整体性能。

Conclusion: BoostFGL有效解决了联邦图学习中的公平性问题，通过协调的增强机制在保持整体性能的同时显著改善弱势群体的表现，为公平感知的联邦图学习提供了有效解决方案。

Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.

</details>


### [100] [Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network](https://arxiv.org/abs/2601.16446)
*George Awiakye-Marfo,Elijah Agbosu,Victoria Mawuena Barns,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 本文提出BrownianReLU激活函数，通过布朗运动引入随机性，解决传统ReLU类激活函数在金融时间序列中的梯度不稳定问题，在LSTM网络中提升了预测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数如ReLU、LeakyReLU和PReLU在处理噪声大、非平稳的金融时间序列时，常常出现梯度不稳定问题，影响深度学习模型的性能。

Method: 提出BrownianReLU激活函数，基于布朗运动引入随机性，使用蒙特卡洛模拟实现平滑的自适应响应，特别针对负输入值缓解"死亡ReLU"问题，并在LSTM网络中应用。

Result: 在苹果、GCB、标普500等金融时间序列以及LendingClub贷款分类数据上的实验显示，BrownianReLU能持续降低均方误差、提高R²值，表明预测精度和泛化能力得到改善。

Conclusion: 虽然ROC-AUC指标在分类任务中有限制，但激活函数的选择显著影响准确率和敏感度的权衡，BrownianReLU及所选激活函数能提供实际有意义的性能提升。

Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.

</details>


### [101] [Student Mental Health Screening via Fitbit Data Collected During the COVID-19 Pandemic](https://arxiv.org/abs/2601.16324)
*Rebecca Lopez,Avantika Shrestha,ML Tlachac,Kevin Hickey,Xingtong Guo,Shichao Liu,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 使用Fitbit可穿戴设备数据通过机器学习模型筛查大学生抑郁、焦虑和压力，发现心率和睡眠数据具有较高预测潜力，F1分数最高达0.79。


<details>
  <summary>Details</summary>
Motivation: 大学生面临高压力导致焦虑抑郁，现有研究在心理测量工具、生理模态和时间序列参数方面有限，需要探索可穿戴设备在心理健康监测中的应用潜力。

Method: 收集疫情期间大学生的StudentMEH Fitbit数据集，使用多种Fitbit生理模态（如心率、睡眠），构建预测机器学习模型来筛查抑郁、焦虑和压力。

Result: 心率和睡眠模态在心理健康筛查中表现良好：焦虑筛查F1分数最高达0.79，压力筛查达0.77，抑郁筛查达0.78，显示了可穿戴设备在心理健康监测中的潜力。

Conclusion: 可穿戴设备支持持续心理健康监测具有潜力，需要确定最佳数据聚合水平和适合不同心理疾病的筛查模态，为早期检测提供新途径。

Abstract: College students experience many stressors, resulting in high levels of anxiety and depression. Wearable technology provides unobtrusive sensor data that can be used for the early detection of mental illness. However, current research is limited concerning the variety of psychological instruments administered, physiological modalities, and time series parameters. In this research, we collect the Student Mental and Environmental Health (StudentMEH) Fitbit dataset from students at our institution during the pandemic. We provide a comprehensive assessment of the ability of predictive machine learning models to screen for depression, anxiety, and stress using different Fitbit modalities. Our findings indicate potential in physiological modalities such as heart rate and sleep to screen for mental illness with the F1 scores as high as 0.79 for anxiety, the former modality reaching 0.77 for stress screening, and the latter modality achieving 0.78 for depression. This research highlights the potential of wearable devices to support continuous mental health monitoring, the importance of identifying best data aggregation levels and appropriate modalities for screening for different mental ailments.

</details>


### [102] [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)
*Felipe Tobar,Elsa Cazelles*

Main category: cs.LG

TL;DR: 提出一种基于数据低维线性投影的高斯过程训练新目标——投影似然(PL)，通过随机投影减少信息损失，在中等规模数据集上比精确GP训练和变分稀疏GP方法更准确高效。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程训练在大规模数据集上计算复杂度高，现有稀疏近似方法如变分自由能可能牺牲精度。需要一种既能保持准确性又能提高计算效率的新方法。

Method: 使用数据低维线性投影构建高斯过程，提出投影似然(PL)训练目标。通过随机单位球面投影减少信息损失，提供信息损失的闭式表达式。

Result: 投影似然方法在不同优化器、核函数和中等规模数据集上，比精确GP训练和变分稀疏GP方法在准确性和计算效率方面都表现更优。

Conclusion: 投影似然是一种有效的高斯过程训练方法，通过低维投影平衡了计算效率与模型精度，为中等规模数据集提供了实用的解决方案。

Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.

</details>


### [103] [Analyzing Neural Network Information Flow Using Differential Geometry](https://arxiv.org/abs/2601.16366)
*Shuhang Tan,Jayson Sia,Paul Bogdan,Radoslav Ivanov*

Main category: cs.LG

TL;DR: 该论文从图论视角重新审视神经网络数据流问题，使用Ollivier-Ricci曲率识别关键连接，通过剪枝实验验证负曲率边对性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络数据流分析基于信息论，本文从图论角度提供新视角，利用图曲率理论识别神经网络中最重要的连接，为符号神经网络分析（如鲁棒性分析、模型修复）提供工具。

Method: 1) 基于神经网络结构构建图，引入基于Ollivier-Ricci曲率的神经曲率概念；2) 根据输入样本的激活模式计算曲率；3) 使用神经曲率对边的重要性进行排序，通过剪枝实验验证负曲率边是关键瓶颈。

Result: 在MNIST、CIFAR-10和CIFAR-100数据集上的实验表明，移除负曲率边会快速降低神经网络性能，而正曲率边影响很小。相比现有剪枝方法，该方法能识别更多不重要的边。

Conclusion: 图曲率理论为神经网络数据流分析提供了有效的新方法，神经曲率能准确识别关键连接，在模型压缩和解释性方面具有应用潜力。

Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.

</details>


### [104] [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)
*Shijun Zhang,Zuowei Shen,Yuesheng Xu*

Main category: cs.LG

TL;DR: 本文提出多级深度学习(MGDL)框架，通过逐级训练深度网络来结构化地减少近似误差，为深度网络训练提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然具有强大的近似能力，但训练非常深的网络架构仍然具有挑战性，因为优化问题高度非凸且条件数差。相比之下，浅层网络（特别是单隐藏层ReLU模型）的训练可以转化为凸优化问题，具有全局保证。这启发了通过逐级训练来改善稳定性并扩展到深度网络的学习范式。

Method: MGDL采用逐级训练策略：先训练并冻结已学习的层级，然后每个新的残差块仅用于减少剩余的近似误差。这种方法形成了可解释且稳定的分层细化过程。作者为MGDL建立了算子理论基础，并证明了对于任何连续目标函数，都存在固定宽度的多级ReLU方案，其残差在各级间严格减小并一致收敛到零。

Result: 理论证明：对于任意连续目标函数，存在固定宽度的多级ReLU方案，其残差在各级间严格减小并一致收敛到零。这是首次为逐级训练在深度网络中提供可证明的近似误差消失的理论保证。数值实验进一步验证了理论结果。

Conclusion: MGDL为深度神经网络训练提供了一个理论严谨的框架，通过逐级训练实现了结构化误差细化。该方法不仅提供了训练稳定性，还为深度网络的误差收敛提供了首个严格的理论保证，为深度学习的理论发展做出了重要贡献。

Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.

</details>


### [105] [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)
*Sihan Zeng,Sujay Bhatt,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 提出一种单循环、一阶的actor-critic算法，通过惩罚重构解决双层优化问题，其中上层优化平滑函数，下层是MDP中的策略优化，上层变量参数化下层MDP的奖励。


<details>
  <summary>Details</summary>
Motivation: 现有双层优化和RL方法通常需要二阶信息、在下层施加强正则化，或通过嵌套循环过程低效使用样本。需要一种更高效、无需二阶信息的方法来解决这类结构化双层优化问题。

Method: 提出单循环一阶actor-critic算法，通过惩罚重构优化双层目标。在下层RL目标中引入衰减熵正则化，实现渐近无偏的上层超梯度估计，无需精确求解无正则化RL问题。

Result: 在特殊类型的Polyak-Lojasiewicz条件下，通过新颖的下层残差分析，建立了算法对原始无正则化双层优化问题稳定点的有限时间和有限样本收敛性。

Conclusion: 该方法在GridWorld目标位置问题和通过人类反馈强化学习(RLHF)的快乐推文生成实验中验证了性能，为双层优化问题提供了高效的单循环解决方案。

Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).

</details>


### [106] [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)
*Antesh Upadhyay,Sang Bin Moon,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: FedSGM是一个统一的联邦约束优化框架，解决了联邦学习中的四大挑战：功能约束、通信瓶颈、本地更新和部分客户端参与，通过投影自由、仅原始变量的更新方法，并提供理论收敛保证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临功能约束、通信瓶颈、本地更新和部分客户端参与四大挑战，现有方法难以同时处理这些问题，需要统一的框架来支持约束联邦学习。

Method: 基于切换梯度方法，采用投影自由、仅原始变量的更新，结合双向误差反馈处理压缩噪声，引入软切换版本稳定边界更新，支持多步本地更新和部分客户端参与。

Result: 理论证明平均迭代达到规范的O(1/√T)收敛率，提供高概率边界将优化进展与部分参与采样噪声解耦，实验验证在Neyman-Pearson分类和约束马尔可夫决策过程任务上的有效性。

Conclusion: FedSGM是首个统一处理功能约束、压缩、多步本地更新和部分客户端参与的框架，为约束联邦学习建立了理论基础，并通过实验验证了理论保证。

Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.

</details>


### [107] [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)
*Zhaochun Li,Mingyang Yi,Yue Wang,Shisheng Cui,Yong Liu*

Main category: cs.LG

TL;DR: 该论文建立了基于人类反馈的强化学习（RLHF）在大语言模型中的泛化理论，证明了在特征覆盖条件下，策略模型的泛化误差界为O(n^{-1/2})。


<details>
  <summary>Details</summary>
Motivation: RLHF及其变体已成为对齐大语言模型与人类意图的主要方法，虽然经验上有效，但这些方法在高维设置下的理论泛化特性尚未得到充分探索。

Method: 在线性奖励模型下，通过算法稳定性框架建立RLHF的泛化理论，采用端到端学习框架，分析策略模型的泛化性能。

Result: 在关键特征覆盖条件下，策略模型的经验最优解具有O(n^{-1/2})的泛化误差界，结果可推广到梯度上升和随机梯度上升等梯度学习算法。

Conclusion: 该研究为RLHF后大语言模型的经验泛化现象提供了新的理论证据，建立了RLHF在高维设置下的泛化理论基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.

</details>


### [108] [Group-realizable multi-group learning by minimizing empirical risk](https://arxiv.org/abs/2601.16922)
*Navid Ardeshir,Samuel Deng,Daniel Hsu,Jingwen Liu*

Main category: cs.LG

TL;DR: 多群体学习在群体可实现设置下的样本复杂度优于不可知设置，即使群体族是无限的（只要VC维有限）。通过经验风险最小化实现改进，但计算不可行，建议使用非适当学习替代。


<details>
  <summary>Details</summary>
Motivation: 研究多群体学习在不同设置下的样本复杂度差异，探索在群体可实现设置下能否获得比不可知设置更好的样本效率，即使群体族是无限的。

Method: 使用经验风险最小化（ERM）在群体可实现概念类上进行学习，尽管该类可能具有无限VC维。同时分析了该方法的计算复杂度，并提出了基于非适当学习的替代方案。

Result: 在群体可实现设置下，即使群体族是无限的（只要VC维有限），多群体学习的样本复杂度确实优于不可知设置。然而，实现这种方法在计算上是不可行的。

Conclusion: 多群体学习在群体可实现设置下具有更好的样本效率，但需要采用非适当学习等替代方法来解决计算不可行性问题，为实际应用提供了理论指导。

Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.

</details>


### [109] [Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction](https://arxiv.org/abs/2601.16406)
*Vitaly Bulgakov,Alexander Turchin*

Main category: cs.LG

TL;DR: LPCORP是一个两阶段框架，用于解决罕见事件预测中的类别不平衡问题，通过推理增强预测和基于置信度的结果校正来改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗、金融、可靠性工程、客户支持、航空安全等领域，罕见事件预测至关重要，但极端类别不平衡会使传统模型偏向多数类预测，限制召回率、校准性和实际应用价值。

Method: 提出LPCORP两阶段框架：1）推理模型从叙事输入中生成增强预测；2）轻量级逻辑回归分类器评估并选择性校正这些输出，以减轻流行度驱动的偏差。该方法不采用任何重采样策略，保持原始样本数量。

Result: 在医疗和消费服务领域的真实数据集上评估显示，该方法将高度不平衡设置转化为平衡设置，显著改善了性能，特别是在低流行度数据中已知的弱点——精确度方面。成本降低分析显示在某些情况下可减少超过50%的费用。

Conclusion: LPCORP框架有效解决了罕见事件预测中的类别不平衡问题，通过推理增强和选择性校正显著提升了模型性能，同时提供了实际成本效益分析，展示了其在现实应用中的价值。

Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.

</details>


### [110] [A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs](https://arxiv.org/abs/2601.16979)
*Dayal Singh Kalra,Jean-Christophe Gagnon-Audet,Andrey Gromov,Ishita Mediratta,Kelvin Niu,Alexander H Miller,Michael Shvartsman*

Main category: cs.LG

TL;DR: 提出临界锐度(λ_c)作为Hessian锐度的高效替代度量，仅需少于10次前向传播，首次在7B参数规模上展示了渐进锐化和稳定性边缘现象，并引入相对临界锐度分析预训练到微调的转变。


<details>
  <summary>Details</summary>
Motivation: Hessian锐度(λ_max^H)对分析神经网络训练动态至关重要，但直接计算在大型语言模型中计算成本过高，需要寻找高效替代度量来研究大规模训练中的曲率演化。

Method: 提出临界锐度(λ_c)，基于更新方向Δθ计算，仅需少于10次前向传播；引入相对临界锐度(λ_c^{1→2})分析不同损失函数间的曲率关系；在OLMo-2模型上验证，参数规模达7B。

Result: 首次在7B参数规模上展示了渐进锐化和稳定性边缘现象；验证了临界锐度能有效捕捉Hessian锐度的已知现象；相对临界锐度成功分析了预训练到微调的转变并指导数据混合策略。

Conclusion: 临界锐度为实践者提供了实用的曲率动态诊断工具，可指导大规模训练中的数据组合选择；证明了可扩展的曲率度量能为大规模训练提供可操作的见解。

Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.

</details>


### [111] [A Refinement of Vapnik--Chervonenkis' Theorem](https://arxiv.org/abs/2601.16411)
*A. Iosevich,A. Vagharshakyan,E. Wyman*

Main category: cs.LG

TL;DR: 论文改进了经典的Vapnik-Chervonenkis定理，通过使用正态近似和显式的Berry-Esseen误差控制，获得了比传统VC估计更精确的中等偏差锐化结果。


<details>
  <summary>Details</summary>
Motivation: 经典VC定理使用Hoeffding不等式作为最后一步，作者希望改进这一概率论证部分，获得更精确的收敛速率估计。

Method: 重新审视经典VC定理的概率论证部分，不使用Hoeffding不等式，而是采用带有显式Berry-Esseen误差控制的正态近似方法。

Result: 获得了传统VC估计的中等偏差锐化结果，当ε√n较大时，主导指数项中增加了(ε√n)^{-1}阶的因子，提供了更精确的收敛速率估计。

Conclusion: 通过改进概率论证方法，论文获得了比经典VC定理更精确的均匀收敛速率估计，为机器学习理论提供了更精细的分析工具。

Abstract: Vapnik--Chervonenkis' theorem is a seminal result in machine learning. It establishes sufficient conditions for empirical probabilities to converge to theoretical probabilities, uniformly over families of events. It also provides an estimate for the rate of such uniform convergence.
  We revisit the probabilistic component of the classical argument. Instead of applying Hoeffding's inequality at the final step, we use a normal approximation with explicit Berry--Esseen error control. This yields a moderate-deviation sharpening of the usual VC estimate, with an additional factor of order $(\varepsilon\sqrt{n})^{-1}$ in the leading exponential term when $\varepsilon\sqrt{n}$ is large.

</details>


### [112] [PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning](https://arxiv.org/abs/2601.16414)
*John Wu,Yongda Fan,Zhenbang Wu,Paul Landes,Eric Schrock,Sayeed Sajjad Razin,Arjun Chatterjee,Naveen Baskaran,Joshua Steier,Andrea Fitzpatrick,Bilal Arif,Rian Atri,Jathurshan Pradeepkumar,Siddhartha Laghuvarapu,Junyi Gao,Adam R. Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: PyHealth 2.0是一个增强的临床深度学习工具包，旨在通过7行代码实现预测建模，解决临床AI研究中的可复现性、计算成本和领域专业知识等挑战。


<details>
  <summary>Details</summary>
Motivation: 临床AI研究面临基准难以复现、计算成本高、需要领域专业知识等持续障碍，这些因素限制了研究的可及性和可重复性。

Method: 开发了一个综合性工具包，统一了15+数据集、20+临床任务、25+模型、5+可解释性方法和不确定性量化，支持信号、影像和电子健康记录等多种临床数据模态，并翻译5+医学编码标准。

Result: 实现了高达39倍的处理速度提升和20倍的内存使用降低，支持从16GB笔记本电脑到生产系统的多样化计算资源，建立了400+成员的活跃开源社区。

Conclusion: PyHealth 2.0建立了一个开源基础和社区，推动可访问、可重复的医疗AI研究，通过简化临床预测建模流程降低了领域专业知识门槛。

Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.

</details>


### [113] [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)
*Huchen Yang,Xinghao Dong,Jin-Long Wu*

Main category: cs.LG

TL;DR: 本文系统比较了贝叶斯实验设计中KL散度和Wasserstein距离两种效用函数的优劣，发现KL散度在无模型失配时收敛更快，而Wasserstein距离在存在模型失配时更稳健。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯实验设计(BED)为科学发现提供了原则性的信息论框架，但效用函数的选择一直是个活跃的研究课题。虽然KL散度是最常见的选择，但最近的研究提出了Wasserstein距离作为替代。本文旨在系统比较这两种准则的优劣，为实际应用提供指导。

Method: 首先通过一个玩具示例说明Wasserstein距离的问题：固定形状后验的Wasserstein距离值取决于其主质量在支撑集中的相对位置，可能产生与信息增益无关的虚假奖励。然后通过BED文献中的经典源反演问题，系统比较这两种准则在不同条件下的表现。

Result: 研究发现：1）Wasserstein距离对后验分布的位置敏感，可能产生与信息增益无关的虚假奖励；2）在无模型失配的情况下，KL散度能带来更快的收敛速度；3）当模型失配不可忽略时，Wasserstein度量能提供更稳健的序贯BED结果。

Conclusion: 本文阐明了KL散度和Wasserstein度量作为效用函数的权衡关系，为实际BED应用中选择合适的准则提供了指导：在无模型失配时优先选择KL散度以获得更快收敛，在存在模型失配时选择Wasserstein距离以获得更稳健的结果。

Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.

</details>


### [114] [Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction](https://arxiv.org/abs/2601.16426)
*Shuang Wu,Meijie Wang,Lun Yu*

Main category: cs.LG

TL;DR: 研究气味相关性质建模中的蒸汽压(VP)和气味阈值(OP)两个任务，采用Bemis-Murcko骨架分割评估OOD能力，比较GINE和PNA骨干网络，提出"安全多任务"训练方法。


<details>
  <summary>Details</summary>
Motivation: 研究气味相关性质建模中的两个重要任务：蒸汽压(VP)和气味阈值(OP)，重点关注模型在分布外(OOD)情况下的泛化能力，并探索多任务学习的有效方法。

Method: 采用Bemis-Murcko骨架分割评估OOD能力；引入A20/E17分子图特征(20维原子特征+17维键特征)；系统比较GINE和PNA骨干网络；提出"安全多任务"训练方法：VP为主任务，OP为辅助任务，采用延迟激活+梯度裁剪+小权重策略。

Result: VP任务中，PNA加简单回归头在验证集上MSE≈0.21(归一化空间)；OP单任务在相同骨架分割下，使用A20/E17特征加鲁棒训练(Huber/winsor)达到Val MSE≈0.60-0.61；"安全多任务"方法避免了损害主任务，同时获得了最佳的VP泛化性能。

Conclusion: 该研究提供了完整的可复现实验、消融研究和误差相似性分析，讨论了数据噪声和方法局限性，提出的"安全多任务"方法在多任务学习中有效平衡了主任务和辅助任务的关系。

Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.

</details>


### [115] [Endless Terminals: Scaling RL Environments for Terminal Agents](https://arxiv.org/abs/2601.16443)
*Kanishk Gandhi,Shivam Garg,Noah D. Goodman,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: Endless Terminals是一个完全自主的流水线，能够程序化生成终端使用任务用于强化学习训练，无需人工标注。使用简单PPO训练后，模型在终端任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前终端基准测试主要用于评估而非训练，强化学习需要一个可扩展的训练管道而不仅仅是数据集。环境是自改进代理的瓶颈。

Method: 提出Endless Terminals四阶段流水线：1)生成多样化任务描述；2)构建和验证容器化环境；3)生成完成测试；4)过滤可解任务。使用普通PPO进行训练，仅使用二元回合级奖励，没有检索、多代理协调或专用工具。

Result: 生成3255个任务，涵盖文件操作、日志管理、数据处理、脚本编写和数据库操作。训练后模型在保留开发集上显著提升：Llama-3.2-3B从4.0%到18.2%，Qwen2.5-7B从10.7%到53.3%，Qwen3-8B-openthinker-sft从42.6%到59.0%。在TerminalBench 2.0上也有提升。

Conclusion: 当环境可扩展时，简单的强化学习就能成功。Endless Terminals展示了程序化生成训练环境的有效性，为自改进代理提供了可扩展的训练基础。

Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.

</details>


### [116] [Finite-Time Analysis of Gradient Descent for Shallow Transformers](https://arxiv.org/abs/2601.16514)
*Enes Arda,Semih Cayci,Atilla Eryilmaz*

Main category: cs.LG

TL;DR: 浅层Transformer在核机制下训练，宽度仅需样本量对数级，优化误差与序列长度无关，但内存需求随序列增长


<details>
  <summary>Details</summary>
Motivation: 理解Transformer为何表现优异仍具挑战性，因其非凸优化特性。本文旨在分析浅层Transformer在核机制下的优化行为，并与循环架构对比

Method: 分析具有m个独立头的浅层Transformer，使用投影梯度下降在核机制下训练。理论分析宽度需求和优化误差特性

Result: 发现：1) 非渐近保证所需的宽度仅与样本量n呈对数关系；2) 优化误差与序列长度T无关。这与循环架构形成鲜明对比（循环架构优化误差可能随T指数增长）。代价是内存需求随序列长度增长

Conclusion: Transformer在核机制下具有优越的优化特性：宽度需求小，优化误差与序列长度无关，但需要更多内存。数值实验验证了理论结果和预测的缩放规律

Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.

</details>


### [117] [On the Expressive Power of Floating-Point Transformers](https://arxiv.org/abs/2601.16450)
*Sejun Park,Yeachan Park,Geonho Hwang*

Main category: cs.LG

TL;DR: 浮点Transformer在有限精度下表现出与传统理论不同的表达能力：即使没有位置编码也能表示非置换等变函数，在序列长度有限时能表示所有置换等变函数，但长序列时不能。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer表达能力研究基于实数参数和精确运算，但实际计算机实现使用有限浮点数和含舍入误差的机器运算。需要研究浮点Transformer在真实计算环境下的表达能力。

Method: 研究浮点Transformer使用浮点参数和浮点运算时的表示能力，分析其与理想实数Transformer在表达能力上的差异。

Result: 1) 浮点Transformer即使没有位置编码也能表示一类非置换等变函数；2) 序列长度有限时能表示所有置换等变函数，但长序列时不能；3) 发现了浮点Transformer的最小等变结构；4) 所有非平凡加法位置编码都会损害浮点Transformer的表示能力。

Conclusion: 浮点运算的有限精度特性从根本上改变了Transformer的表达能力，使其在真实计算环境中表现出与理论模型不同的行为，这对Transformer的实际设计和应用有重要启示。

Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.

</details>


### [118] [Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing](https://arxiv.org/abs/2601.16812)
*Francesca Lanzillotta,Chiara Albisani,Davide Pucci,Daniele Baracchi,Alessandro Piva,Matteo Lapucci*

Main category: cs.LG

TL;DR: 提出一种用于深度学习约束优化的序列惩罚方法，具有收敛保证并在图像处理任务中验证了实用性


<details>
  <summary>Details</summary>
Motivation: 在许多学习任务中，对单个数据样本的处理要求应该作为优化问题的严格约束而非任意惩罚项来形式化

Method: 采用序列惩罚方法处理约束，该方法在深度学习场景下具有合理的假设条件

Result: 方法具有收敛保证，在图像处理任务上的实验结果表明该方法在实践中可行

Conclusion: 提出的序列惩罚方法能够有效处理深度学习中的约束优化问题，既有理论保证又有实际应用价值

Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.

</details>


### [119] [On the Effects of Adversarial Perturbations on Distribution Robustness](https://arxiv.org/abs/2601.16464)
*Yipei Wang,Zhaoying Pan,Xiaoqian Wang*

Main category: cs.LG

TL;DR: 本文通过理论分析揭示了对抗鲁棒性和分布鲁棒性之间的权衡关系，并发现了一个微妙现象：在适度偏置的数据上，ℓ∞扰动可能提升分布鲁棒性，特别是在特征可分性较高时。


<details>
  <summary>Details</summary>
Motivation: 对抗鲁棒性和分布鲁棒性都旨在确保模型可靠性能，但先前研究发现两者存在权衡。对抗训练可能增加对虚假特征的依赖，从而损害分布鲁棒性，特别是在少数子群体上的表现。本文旨在深入理解这种权衡关系及其影响因素。

Method: 通过理论分析，研究在扰动数据上训练的模型，为每步对抗训练提供了一个可处理的替代方法。分析重点关注ℓ∞扰动在不同偏置程度数据上的影响，以及特征可分性在权衡关系中的作用。

Result: 研究发现：1) 对抗鲁棒性和分布鲁棒性之间存在权衡关系；2) 在适度偏置的数据上，ℓ∞扰动可能提升分布鲁棒性；3) 在高偏置数据上，当简单性偏置诱导模型依赖核心特征（特征可分性较高）时，分布鲁棒性的增益仍然存在。

Conclusion: 理论分析扩展了对对抗鲁棒性和分布鲁棒性权衡关系的理解，强调了特征可分性在权衡中的关键作用。尽管权衡在许多情况下仍然存在，但忽视特征可分性的作用可能导致对鲁棒性的误导性结论。

Abstract: Adversarial robustness refers to a model's ability to resist perturbation of inputs, while distribution robustness evaluates the performance of the model under data shifts. Although both aim to ensure reliable performance, prior work has revealed a tradeoff in distribution and adversarial robustness. Specifically, adversarial training might increase reliance on spurious features, which can harm distribution robustness, especially the performance on some underrepresented subgroups. We present a theoretical analysis of adversarial and distribution robustness that provides a tractable surrogate for per-step adversarial training by studying models trained on perturbed data. In addition to the tradeoff, our work further identified a nuanced phenomenon that $\ell_\infty$ perturbations on data with moderate bias can yield an increase in distribution robustness. Moreover, the gain in distribution robustness remains on highly skewed data when simplicity bias induces reliance on the core feature, characterized as greater feature separability. Our theoretical analysis extends the understanding of the tradeoff by highlighting the interplay of the tradeoff and the feature separability. Despite the tradeoff that persists in many cases, overlooking the role of feature separability may lead to misleading conclusions about robustness.

</details>


### [120] [A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study](https://arxiv.org/abs/2601.16467)
*Maxwell Reynolds,Chaitanya Srinivasan,Vijay Cherupally,Michael Leone,Ke Yu,Li Sun,Tigmanshu Chaudhary,Andreas Pfenning,Kayhan Batmanghelich*

Main category: cs.LG

TL;DR: R-NCE自监督学习框架结合FreeSurfer特征，从结构MRI中发现更强大的阿尔茨海默病生物标志物，在疾病分类和预测方面优于传统方法，并显示出与神经退行和脑血管过程相关的生物学相关性。


<details>
  <summary>Details</summary>
Motivation: 当前阿尔茨海默病生物标志物发现主要依赖手工特征（如皮层厚度），自监督学习方法表现不佳，需要开发能充分利用MRI数据并整合现有特征的新方法。

Method: 提出残差噪声对比估计（R-NCE）自监督学习框架，整合辅助FreeSurfer特征，同时最大化增强不变性信息，通过脑年龄差（BAG）评估生物学相关性。

Result: R-NCE在AD分类、转化预测和淀粉样蛋白状态预测等多个基准测试中优于传统特征和现有SSL方法，R-NCE-BAG显示高遗传性，与MAPT和IRAG1基因相关，在星形胶质细胞和少突胶质细胞中富集。

Conclusion: R-NCE能够从结构MRI中发现比传统手工特征更强大、生物学更相关的AD生物标志物，为早期检测和监测提供了新工具，并揭示了与神经退行和脑血管过程相关的生物学机制。

Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.

</details>


### [121] [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)
*Shenghong Cai,Yiqun Zhang,Xiaopeng Luo,Yiu-Ming Cheung,Hong Jia,Peng Liu*

Main category: cs.LG

TL;DR: 提出MCDC方法，通过多粒度竞争惩罚学习(MGCPL)和基于编码的聚类聚合(CAME)，有效处理分类数据的嵌套粒度聚类问题，具有线性时间复杂度和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 分类数据在聚类分析中面临挑战，因为其离散距离空间难以明确定义，且存在普遍的嵌套粒度聚类效应（小簇形成大簇）。现有方法难以有效处理这种多粒度聚类结构。

Method: 提出MCDC方法：1) MGCPL算法让潜在聚类通过竞争惩罚学习在不同粒度上交互调整和收敛；2) CAME策略基于MGCPL编码将数据对象编码为嵌入表示，然后在嵌入空间进行最终聚类。

Result: MCDC能自动探索多粒度嵌套聚类分布，对各类领域分类数据集具有高度鲁棒性。线性时间复杂度使其可扩展到大规模数据集，并能有效提升分布式计算的预分区性能。

Conclusion: MCDC方法在多个真实公共数据集上表现出优于现有技术的性能，统计证据充分证明了其优越性，为分类数据聚类提供了有效的解决方案。

Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.

</details>


### [122] [Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario](https://arxiv.org/abs/2511.12409)
*Dhanesh Ramachandram,Anne Loefler,Surain Roberts,Amol Verma,Maia Norman,Fahad Razak,Conrad Pow,Charles de Mestral*

Main category: cs.LG

TL;DR: 提出CRISPNAM-FG模型，这是一个内在可解释的竞争风险生存模型，结合了神经加法模型和Fine-Gray公式，在保持高预测性能的同时提供透明可审计的预测。


<details>
  <summary>Details</summary>
Motivation: 在医学应用中，模型可解释性对于建立AI安全和临床医生信任至关重要。现有的深度学习模型虽然预测性能好，但作为黑盒模型缺乏透明度，阻碍了其在临床实践中的集成。

Method: 提出CRISPNAM-FG模型，利用神经加法模型（NAMs）的结构，为每个风险设置单独的投影向量，使用Fine-Gray公式预测累积发生率函数，实现内在透明和可审计的预测。

Result: 在多个基准数据集上验证了模型，并应用于预测29家安大略省医院（2016-2023）糖尿病患者的足部并发症。模型在保持与其他深度生存模型竞争性性能的同时，通过形状函数和特征重要性图提供透明度。

Conclusion: CRISPNAM-FG是一个内在可解释的竞争风险生存模型，在保持高预测性能的同时提供透明性，有助于促进AI模型在临床实践中的集成和应用。

Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.

</details>


### [123] [kNN-Graph: An adaptive graph model for $k$-nearest neighbors](https://arxiv.org/abs/2601.16509)
*Jiaye Li,Gang Chen,Hang Xu,Shichao Zhang*

Main category: cs.LG

TL;DR: 提出一种自适应图模型，通过HNSW图与预计算投票机制结合，将邻居选择和加权计算完全转移到训练阶段，实现推理速度显著提升而不损失分类精度。


<details>
  <summary>Details</summary>
Motivation: kNN算法在大规模应用中面临推理速度与精度的计算权衡问题，现有近似最近邻解决方案虽然加速检索但会降低分类精度，且缺乏选择最优邻域大小(k)的自适应性。

Method: 集成分层可导航小世界(HNSW)图与预计算投票机制，将邻居选择和加权计算完全转移到训练阶段。高层图实现快速导航，低层图编码精确的节点特定决策边界和自适应邻居数量。

Result: 在6个不同数据集上对8个最先进基线进行基准测试，该架构显著加速推理速度，实现实时性能，同时不损害分类精度。

Conclusion: 为kNN长期存在的推理瓶颈提供了可扩展、鲁棒的解决方案，建立了基于图的非参数学习的新结构范式。

Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.

</details>


### [124] [Rethinking Large Language Models For Irregular Time Series Classification In Critical Care](https://arxiv.org/abs/2601.16516)
*Feixiang Zheng,Yu Wu,Cecilia Mascolo,Ting Dang*

Main category: cs.LG

TL;DR: LLM在ICU不规则时间序列数据上的应用研究：编码器设计比对齐策略更重要，但LLM方法训练时间长且在小样本场景下表现不佳


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在时间序列建模中显示出潜力，但其在处理ICU不规则数据（高缺失率）上的有效性尚未充分探索，需要系统评估关键组件的影响

Method: 建立系统测试平台，评估时间序列编码器和多模态对齐策略在各种最先进的LLM方法上的影响，与强监督和自监督基线比较

Result: 编码器设计比对齐策略更关键：能显式建模不规则性的编码器比普通Transformer平均AUPRC提高12.8%；最佳对齐策略比交叉注意力提高2.9%；但LLM方法训练时间至少长10倍，性能仅与最佳不规则监督模型相当，在小样本学习场景下表现不佳

Conclusion: LLM在ICU不规则时间序列分析中既有潜力也有当前局限性，编码器设计是关键，但训练效率和小样本性能需要改进

Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.

</details>


### [125] [DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs](https://arxiv.org/abs/2601.16519)
*Zekai Chen,Haodong Lu,Xunkai Li,Henan Sun,Jia Li,Hongchao Qin,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: DANCE提出了一种新的文本属性图联邦学习范式，通过轮次式模型内循环图压缩和可追溯证据包，解决了现有方法在计算开销、性能次优和可解释性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前文本属性图联邦学习方法面临三个主要挑战：1) LLM处理长文本的高计算开销；2) 一次性图压缩导致性能次优且不具客户端适应性；3) LLM压缩引入黑盒瓶颈，缺乏可追溯性和可解释性。

Method: DANCE采用轮次式、模型内循环的图压缩刷新机制，使用最新全局模型动态更新压缩表示；同时保留可追溯的证据包，将预测关联到特定邻居和源文本片段，增强可解释性。

Result: 在8个TAG数据集上，DANCE在8%压缩率下将准确率提升2.33%，同时比基线方法减少33.42%的token使用量。

Conclusion: DANCE通过动态图压缩和可追溯证据包，有效解决了TAG-FGL中的计算开销、性能优化和可解释性问题，为实用的文本属性图联邦学习提供了新范式。

Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.

</details>


### [126] [Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs](https://arxiv.org/abs/2601.16527)
*Xianya Fang,Feiyang Ren,Xiang Chen,Yu Tian,Zhen Bi,Haiyang Yu,Sheng-Jun Huang*

Main category: cs.LG

TL;DR: 提出SARE方法解决多模态大语言模型物体幻觉问题，通过目标最小最大优化和Targeted-SAM机制，在幻觉概念周围平坦化损失景观，实现稳定去学习


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在物体幻觉问题，现有去学习方法存在结构脆弱性缺陷，仅实现表面抑制，模型陷入尖锐最小值，轻微重新学习后幻觉会灾难性复发

Method: 提出SARE框架，将去学习转化为目标最小最大优化问题，使用Targeted-SAM机制在幻觉概念周围明确平坦化损失景观，通过模拟最坏情况参数扰动抑制幻觉

Result: SARE在擦除效果上显著优于基线方法，同时保持一般生成质量，能够持久抑制幻觉对抗重新学习和参数更新，验证了几何稳定化的有效性

Conclusion: 通过几何稳定化方法解决多模态大语言模型物体幻觉问题，SARE框架实现了稳健的幻觉移除，对抗权重变化保持稳定，为可靠多模态系统提供了新思路

Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.

</details>


### [127] [A Collision-Free Hot-Tier Extension for Engram-Style Conditional Memory: A Controlled Study of Training Dynamics](https://arxiv.org/abs/2601.16531)
*Tao Lin*

Main category: cs.LG

TL;DR: 高频键冲突并非Engram式条件记忆的主要瓶颈，消除冲突的碰撞自由设计在同等参数下并未持续改善验证损失，冲突反而可能提供有益的隐式正则化。


<details>
  <summary>Details</summary>
Motivation: 研究高频键冲突是否是Engram式条件记忆的主要瓶颈，探索消除冲突是否能改善模型性能。

Method: 引入Engram-Nine碰撞自由热层扩展，通过最小完美哈希函数映射最频繁n-gram，同时保留原始多头哈希查找作为冷层。在严格等参数设置下比较碰撞自由设计与基线，并进行路由分层评估分析热/冷层贡献。

Result: 碰撞自由设计并未持续改善验证损失。发现训练中存在"热到冷优势翻转"现象：热位置（高频）初始损失较低，但冷位置最终超越。碰撞自由配置比碰撞倾向基线翻转更早，表明冲突具有隐式正则化作用。还发现门控不匹配问题：门控早期学习偏好热位置，但翻转后仍保持这种偏好，将更高权重分配给损失更高的位置。

Conclusion: 单纯提高查找精度并不能保证更好的训练结果。主要限制可能在于门控信用分配而非索引准确性，碰撞引起的噪声可能提供有益的正则化效果，不应简单消除。

Abstract: We investigate whether high-frequency key collisions are a primary bottleneck in Engram-style conditional memory. To isolate the effect of collisions, we introduce Engram-Nine, a collision-free hot-tier extension that maps the most frequent n-grams through a Minimal Perfect Hash Function (MPHF) while retaining the original multi-head hashed lookup as a cold tier. Under a strictly iso-parameter setup, the collision-free design does not consistently improve validation loss.
  Through route-stratified evaluation (decomposing per-token loss into hot/cold contributions), we uncover a consistent "hot-to-cold advantage flip" during training: hot (high-frequency) positions initially have lower loss, but cold positions eventually surpass them. Crucially, collision-free configurations flip earlier than collision-prone baselines, suggesting that collisions act as implicit regularization. We also identify a gating mismatch: the gate learns to favor hot positions early in training, but this preference persists even after the flip, assigning higher weights to positions with higher loss.
  Our findings suggest that improving lookup precision alone does not guarantee better training outcomes. The dominant limitation may lie in gating credit assignment rather than index accuracy, and collision-induced noise may provide beneficial regularization that should not be naively eliminated.

</details>


### [128] [Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm](https://arxiv.org/abs/2601.16552)
*Xiaobin Li,Run Zhang*

Main category: cs.LG

TL;DR: JORC-UMAP：通过引入Ollivier-Ricci曲率和Jaccard相似性先验，改进UMAP的几何保真度，减少拓扑撕裂和结构坍塌问题。


<details>
  <summary>Details</summary>
Motivation: UMAP在可视化高维数据时，其局部欧氏距离假设经常无法捕捉内在流形几何，导致拓扑撕裂和结构坍塌。作者发现UMAP对k近邻图的敏感性是主要原因。

Method: 提出JORC-UMAP方法：1）引入Ollivier-Ricci曲率作为几何先验，强化几何瓶颈处的边并减少冗余连接；2）结合Jaccard相似性作为拓扑先验，确保邻域一致性，因为曲率估计对噪声敏感。

Result: 在合成和真实数据集上的实验表明，JORC-UMAP比标准UMAP和其他降维方法更有效地减少撕裂和坍塌，通过SVM准确率和三元组保持分数衡量，同时保持计算效率。

Conclusion: 这项工作为UMAP提供了几何感知的增强，实现了更忠实的数据可视化，通过曲率和拓扑先验的结合改进了流形结构的保持能力。

Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.

</details>


### [129] [Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability](https://arxiv.org/abs/2601.16563)
*Vasileios Sevetlidis,George Pavlidis*

Main category: cs.LG

TL;DR: 该论文提出将神经训练视为过程张量，引入基于可区分性回流的训练记忆见证方法，通过实验证明实际SGD训练存在非马尔可夫性，为优化器和课程设计提供可测量的诊断工具。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络训练通常被理想化为马尔可夫过程，但实际训练中数据顺序、优化器状态等因素可能引入记忆效应。论文旨在开发一种原则性的测量方法来量化训练过程中的非马尔可夫性，验证"数据顺序重要"这一经验观察。

Method: 将训练过程建模为过程张量，设计基于可区分性回流的见证方法。通过两步骤协议比较单次干预与两次干预后的结果分布差异，使用TV/JS/Hellinger距离测量softmax预测差异，通过因果断点（重置优化器状态）验证记忆来源。

Result: 实验观察到一致的正向回流效应，具有紧密的自举置信区间。记忆效应在高动量、大批量重叠和更多微步时增强，在因果断点下消失。见证方法对TV/JS/Hellinger距离均稳健，计算成本低且无需架构修改。

Conclusion: 该工作提供了原则性的诊断工具和实证证据，表明实际SGD训练偏离马尔可夫理想化。提出的框架为比较优化器、课程安排和训练计划提供了统一平台，将"数据顺序重要"转化为可测试的操作符。

Abstract: This work proposes neural training as a \emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $Δ_{\mathrm{BF}} = D_2 - D_1>0$ (with $D\in\{\mathrm{TV}, \mathrm{JS}, \mathrm{H}\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. "Data order matters" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.

</details>


### [130] [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)
*Abdurahman Maarouf,Alket Bakiaj,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 本文提出kNN-ICL框架，利用大语言模型进行初创公司成功预测，无需模型训练，仅需少量标注数据作为示例，在数据稀缺的VC投资环境中表现优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 早期初创公司成功预测对VC投资回报至关重要，但面临数据稀缺挑战（VC公司通常只有几十个早期初创公司的标注数据），传统机器学习方法需要大量标注数据，在数据稀缺环境下效果有限。

Method: 提出kNN-ICL（k最近邻上下文学习）框架：1）使用大语言模型进行上下文学习，无需模型训练；2）基于相似性选择最相关的历史初创公司作为示例；3）仅需少量标注数据作为演示示例。

Result: 使用Crunchbase真实数据，kNN-ICL方法比监督机器学习基线和普通上下文学习获得更高的预测准确率；仅需50个示例即可达到较高的平衡准确率。

Conclusion: 上下文学习可作为VC公司在数据稀缺环境中的决策工具，kNN-ICL框架为解决早期初创公司成功预测的数据稀缺问题提供了有效方案。

Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.

</details>


### [131] [Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland](https://arxiv.org/abs/2601.16592)
*Vinicius Pozzobon Borin,Jean Michel de Souza Sant'Ana,Usama Raheel,Nurul Huda Mahmood*

Main category: cs.LG

TL;DR: 该研究创建了首个公开的芬兰铁路运营与气象观测数据集（2018-2024），整合了运营数据和209个气象站观测，包含28个特征和约3850万条观测记录，可用于机器学习应用如列车延误预测。


<details>
  <summary>Details</summary>
Motivation: 现有数据集很少将气象信息与铁路运营数据整合，而天气（尤其在北欧地区）对铁路可靠性有重要影响。缺乏这种综合数据集限制了铁路运营研究和机器学习应用的发展。

Method: 整合芬兰Digitraffic铁路交通服务的运营指标和209个环境监测站的气象观测数据，使用Haversine距离进行时空对齐。数据集包含28个工程特征，涵盖运营变量和气象测量。预处理包括：通过空间回退算法处理缺失数据、时间特征的循环编码、以及使用稳健缩放处理气象数据中的传感器异常值。

Result: 分析揭示了明显的季节性模式，冬季月份延误率超过25%，高延误走廊集中在芬兰中部和北部地区。基线实验使用XGBoost回归预测站点特定延误，平均绝对误差为2.73分钟，证明了数据集在机器学习应用中的实用性。

Conclusion: 该数据集为研究人员提供了铁路运营研究中机器学习应用的灵活资源，支持列车延误预测、天气影响评估和基础设施脆弱性映射等多种应用，填补了铁路运营与气象数据整合的空白。

Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.

</details>


### [132] [E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory](https://arxiv.org/abs/2601.16622)
*Lin Huang,Chengxiang Huang,Ziang Wang,Yiyue Du,Chu Wang,Haocheng Lu,Yunyang Li,Xiaoli Liu,Arthur Jiang,Jia Zhang*

Main category: cs.LG

TL;DR: E2Former-V2是一种可扩展的等变图神经网络架构，通过代数稀疏化和硬件感知执行解决了主流EGNNs的可扩展性瓶颈，在保持预测性能的同时显著加速推理。


<details>
  <summary>Details</summary>
Motivation: 主流等变图神经网络(EGNNs)在建模3D原子系统时面临严重的可扩展性瓶颈，因为需要在每条边上显式构建几何特征或进行密集张量积运算。

Method: 提出了EAAS(等变轴对齐稀疏化)技术，利用SO(3)→SO(2)基变换将计算密集的张量收缩转换为高效的稀疏奇偶性重索引操作；并设计了基于定制Triton内核的即时等变注意力机制，消除边缘张量物化并最大化SRAM利用率。

Result: 定制内核相比标准实现实现了20倍的TFLOPS提升；在SPICE和OMol25数据集上保持可比预测性能的同时显著加速推理；证明大型等变变换器可以在广泛可用的GPU平台上高效训练。

Conclusion: E2Former-V2通过代数稀疏化和硬件感知执行成功解决了EGNNs的可扩展性瓶颈，为高效训练大型等变变换器提供了可行方案。

Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.

</details>


### [133] [Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting](https://arxiv.org/abs/2601.16632)
*Haonan Yang,Jianchao Tang,Zhuo Li*

Main category: cs.LG

TL;DR: DPAD是一个模型无关的辅助框架，通过双原型自适应解耦机制，为时间序列预测模型提供模式解耦和上下文感知能力，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然通过改进架构或引入增强策略来提升预测性能，但往往无法动态解耦和利用时间序列中复杂交织的时序模式，导致学习到静态、平均化的表示，缺乏上下文感知能力。

Method: 提出双原型自适应解耦框架（DPAD），包含：1）动态双原型库（DDP）- 包含具有强时序先验的常见模式库和动态记忆关键但罕见事件的罕见模式库；2）双路径上下文感知路由机制（DPC）- 从DDP选择性检索上下文特定模式表示来增强输出；3）解耦引导损失（DGLoss）- 确保每个原型库专注于其指定角色同时保持全面覆盖。

Result: 综合实验表明，DPAD在各种真实世界基准测试中，能够持续提升最先进模型的预测性能和可靠性。

Conclusion: DPAD作为一个模型无关的辅助方法，通过模式解耦和上下文感知适应能力，有效解决了时间序列预测中复杂模式交织的问题，显著提升了现有模型的性能。

Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.

</details>


### [134] [Provably Robust Bayesian Counterfactual Explanations under Model Changes](https://arxiv.org/abs/2601.16659)
*Jamie Duell,Xiuyi Fan*

Main category: cs.LG

TL;DR: 提出PSCE方法，为反事实解释提供概率安全保证，确保在模型更新时保持高预测置信度和低预测方差


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器学习模型频繁更新，现有反事实解释容易失效，需要确保解释在模型变化下的可靠性和鲁棒性

Method: 基于贝叶斯原理的PSCE方法，生成δ-safe（高预测置信度）和ε-robust（低预测方差）的反事实解释，集成不确定性感知约束到优化框架

Result: 在多个数据集上验证，相比现有贝叶斯反事实方法，PSCE产生更合理、更具区分度的解释，并在模型变化下具有可证明的鲁棒性

Conclusion: PSCE为反事实解释提供形式化概率保证，确保在模型更新场景下的可靠性和安全性

Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $δ$-safe, to ensure high predictive confidence, and $ε$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle δ, ε\rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.

</details>


### [135] [Dynamic Expert-Guided Model Averaging for Causal Discovery](https://arxiv.org/abs/2601.16715)
*Adrick Tench,Thomas Demeester*

Main category: cs.LG

TL;DR: 提出一种利用动态请求专家知识（包括LLM）来集成多种因果发现算法的灵活模型平均方法，在干净和噪声数据上验证了有效性，并分析了专家正确性程度的影响。


<details>
  <summary>Details</summary>
Motivation: 因果模型对医疗健康领域至关重要，但现有因果发现算法众多且没有明确最佳选择，同时现实场景经常违反算法假设，过度依赖专家知识。集成方法成为自然选择，但需要解决专家知识获取的问题。

Method: 提出灵活的模型平均方法，利用动态请求的专家知识（包括LLM作为专家）来集成多样化的因果发现算法。该方法结合了算法多样性和专家知识指导。

Result: 实验证明该方法在干净和噪声数据上对不完美专家（如LLM）都有效。分析了不同专家正确性程度的影响，并评估了LLM在临床因果发现中的能力，为实践者提供了宝贵见解。

Conclusion: 通过动态集成专家知识和多种因果发现算法，提供了一种实用的因果发现方法，特别适用于医疗健康等复杂领域，其中LLM可以作为有效的专家知识来源。

Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.

</details>


### [136] [Uncertainty propagation through trained multi-layer perceptrons: Exact analytical results](https://arxiv.org/abs/2601.16830)
*Andrew Thompson,Miles McCrory*

Main category: cs.LG

TL;DR: 本文为单隐藏层ReLU激活的MLP提供了输入为多元高斯分布时输出均值和方差的精确解析表达式


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要级数展开来近似计算神经网络在随机输入下的输出统计特性，缺乏精确的解析表达式

Method: 针对单隐藏层ReLU激活的多层感知机，推导输入为多元高斯分布时输出均值和方差的精确数学表达式，无需级数展开

Result: 获得了输出均值和方差的精确解析表达式，相比之前的近似方法提供了更准确的不确定性传播分析

Conclusion: 为ReLU激活的MLP在随机输入下的不确定性传播提供了精确的数学分析框架，无需依赖近似展开

Abstract: We give analytical results for propagation of uncertainty through trained multi-layer perceptrons (MLPs) with a single hidden layer and ReLU activation functions. More precisely, we give expressions for the mean and variance of the output when the input is multivariate Gaussian. In contrast to previous results, we obtain exact expressions without resort to a series expansion.

</details>


### [137] [Calibrated Probabilistic Interpolation for GEDI Biomass](https://arxiv.org/abs/2601.16834)
*Robin Young,Srinivasan Keshav*

Main category: cs.LG

TL;DR: 该论文提出使用注意力神经过程（ANPs）替代传统机器学习方法，用于从NASA GEDI任务的稀疏LiDAR观测中生成具有校准不确定性的墙到墙生物量地图。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法（如随机森林和XGBoost）在处理GEDI稀疏观测时存在两个主要问题：1）将空间预测视为独立事件，未适应异质性地形的变化难度；2）无法产生校准的预测区间，错误地将集成方差与偶然不确定性混为一谈，并忽略了局部空间上下文。

Method: 引入注意力神经过程（ANPs），这是一个概率元学习框架，明确地将预测条件化于局部观测集和地理空间基础模型嵌入。与静态集成不同，ANPs学习灵活的空间协方差函数，允许不确定性估计在复杂地形中扩展，在均质区域中收缩。

Result: 在从热带亚马逊森林到北方和高山生态系统的五个不同生物群落中验证了该方法，证明ANPs在保持接近理想的不确定性校准的同时实现了有竞争力的准确性。通过少样本适应展示了方法的操作实用性，模型使用最少的本地数据恢复了跨区域转移中的大部分性能差距。

Conclusion: 这项工作为大陆尺度地球观测提供了一个可扩展、理论严谨的替代方案，替代了传统的集成方差方法，能够生成可靠且具有校准不确定性的生物量地图。

Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.

</details>


### [138] [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)
*Henri Nikoleit,Ankit Anand,Anurag Murty Naredla,Heiko Röglin*

Main category: cs.LG

TL;DR: 该论文展示了人类与LLM协作在理论计算机科学开放问题中的强大能力，通过改进FunSearch算法的输出来为组合优化问题生成对抗性实例，从而获得多个问题的当前最优下界。


<details>
  <summary>Details</summary>
Motivation: 动机在于探索人类与大型语言模型（LLM）协作如何解决理论计算机科学中的开放问题，特别是在组合优化领域。尽管FunSearch算法能够生成初步结果，但需要人类专家的监督来将这些模式转化为数学上严谨且有洞察力的构造。

Method: 方法采用人类-LLM协作框架，专注于改进FunSearch算法[Romera-Paredes等人，Nature 2023]的输出。通过迭代优化FunSearch的结果，针对组合优化问题生成对抗性实例，使得标准启发式算法在这些实例上表现不佳。具体应用于分层k-中值聚类、装箱问题、背包问题以及Lovász汽油问题的推广。

Result: 研究结果为多个组合优化问题获得了当前最优的下界：分层k-中值聚类、装箱问题、背包问题以及Lovász汽油问题的推广。其中一些问题在过去十多年中尽管有间歇性关注但几乎没有改进。这些结果打破了长期存在的障碍。

Conclusion: 结论表明LLM提供了关键初始模式，但人类专业知识对于将这些模式转化为数学上严谨且有洞察力的构造至关重要。这项工作强调了LLM是数学和计算机科学研究中的强大协作工具，人类-LLM协作能够有效从基于LLM的进化方法中提取算法洞察并突破长期障碍。

Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lovász's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.

</details>


### [139] [Provably Learning Attention with Queries](https://arxiv.org/abs/2601.16873)
*Satwik Bhattamishra,Kulin Shah,Michael Hahn,Varun Kanade*

Main category: cs.LG

TL;DR: 本文研究了通过黑盒访问输出学习Transformer序列模型的问题，提出了针对单头注意力、多头注意力等不同场景的查询复杂度分析算法，并探讨了噪声鲁棒性和参数可识别性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过黑盒查询（仅能观察输入序列对应的实值输出）来学习Transformer序列模型的参数，这在模型解释、模型提取和隐私保护等场景中具有重要意义。

Method: 1. 针对单头softmax注意力回归器，提出了O(d²)查询的简单算法；2. 结合ReLU前馈网络学习算法，扩展到单层Transformer学习；3. 针对头维度r≪d的情况，利用压缩感知理论提出O(rd)查询的随机算法；4. 分析噪声鲁棒性，证明在温和的范数和边界条件下仍能多项式查询内达到ε精度；5. 证明多头注意力参数在值查询下一般不可识别。

Result: 1. 单头注意力参数可通过O(d²)查询精确学习；2. 头维度较小时可通过O(rd)查询学习；3. 在噪声条件下仍能多项式查询内达到ε精度；4. 多头注意力参数在值查询下不可识别，需要额外结构假设。

Conclusion: Transformer序列模型的黑盒学习在不同场景下有不同复杂度：单头注意力可高效学习，多头注意力需要额外假设。压缩感知技术可降低查询复杂度，噪声条件下仍能保持学习能力，但多头注意力的参数识别存在根本性限制。

Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.

</details>


### [140] [Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks](https://arxiv.org/abs/2601.16880)
*Bethan Evans,Jared Tanner*

Main category: cs.LG

TL;DR: 论文推导了深度神经网络实现指定输出变化所需的最小范数权重扰动，分析了影响因素，并将其应用于精度修改激活的后门攻击，建立了可证明的压缩阈值。


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络对权重扰动的敏感性，特别是为了理解后门攻击的激活机制和提供可证明的鲁棒性保证。

Method: 推导了单层精确公式来计算最小范数权重扰动，并与多层Lipschitz常数鲁棒性保证进行对比，应用于精度修改激活的后门攻击分析。

Result: 单层精确公式与多层Lipschitz常数保证具有相同数量级，表明保证效果相似；建立了后门攻击的可证明压缩阈值，低秩压缩能可靠激活潜在后门同时保持全精度准确率。

Conclusion: 反向传播的边界控制层间敏感性，为与期望输出变化一致的最小参数更新提供了可证明的保证，对理解神经网络鲁棒性和后门攻击防御有重要意义。

Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.

</details>


### [141] [Embedding -based Crop Type Classification in the Groundnut Basin of Senegal](https://arxiv.org/abs/2601.16900)
*Madeline C. Lisaius,Srinivasan Keshav,Andrew Blake,Clement Atzberger*

Main category: cs.LG

TL;DR: TESSERA地理空间基础模型嵌入在塞内加尔花生盆地作物分类中表现最佳，满足性能、合理性、可迁移性和可访问性四大标准，比次优方法准确率高28%。


<details>
  <summary>Details</summary>
Motivation: 当前大多数卫星遥感作物分类方法不适合小农条件，需要开发适合小农地区的实用作物分类方法，以支持粮食安全、生计和气候变化缓解。

Method: 建立基于嵌入方法的四大标准（性能、合理性、可迁移性、可访问性），评估TESSERA和AlphaEarth地理空间基础模型嵌入方法，与现有基线方法在塞内加尔花生盆地地区进行对比。

Result: TESSERA方法在土地覆盖和作物分类中表现最佳，满足所有选择标准，在时间迁移示例中比次优方法准确率高28%。

Conclusion: TESSERA嵌入是塞内加尔作物分类和制图任务的有效方法，特别适合小农地区的应用需求。

Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.

</details>


### [142] [GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints](https://arxiv.org/abs/2601.16905)
*Andy Zhu,Rongzhe Wei,Yupu Gu,Pan Li*

Main category: cs.LG

TL;DR: 提出GRIP框架解决MoE架构的机器遗忘问题，通过几何约束保持路由稳定性，防止传统方法利用路由漏洞进行表面遗忘


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法无法有效应用于MoE架构，它们利用路由器的漏洞进行表面遗忘而非真正擦除知识，导致模型效用损失和浅层遗忘

Method: 提出GRIP框架，核心是几何约束：将路由器梯度更新投影到专家特定零空间中，分离路由稳定性与参数刚性，使遗忘优化必须直接擦除专家参数中的知识

Result: 在大规模MoE模型上的实验表明，GRIP消除了专家选择偏移（实现超过95%的路由稳定性），同时保持所有测试遗忘方法的效用

Conclusion: GRIP通过防止现有算法利用MoE模型的路由漏洞，将密集架构的遗忘研究适配到MoE架构，解决了MoE机器遗忘的关键问题

Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.

</details>


### [143] [The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning](https://arxiv.org/abs/2601.16906)
*Calarina Muslimani,Yunshu Du,Kenta Kawamoto,Kaushik Subramanian,Peter Stone,Peter Wurman*

Main category: cs.LG

TL;DR: 本文提出TAC指标来评估奖励函数与专家偏好的对齐程度，并通过实验证明TAC能帮助RL从业者设计出更好的奖励函数，同时提出Soft-TAC作为可微分的奖励学习目标。


<details>
  <summary>Details</summary>
Motivation: 强化学习的成功依赖于准确反映任务目标的奖励函数，但设计奖励函数既耗时又容易出错。需要工具来帮助RL从业者设计合适的奖励权重，并直接从人类偏好数据中学习奖励模型。

Method: 1) 利用轨迹对齐系数(TAC)评估奖励函数与专家偏好的匹配程度；2) 进行人因研究，让RL从业者在Lunar Lander任务中调优奖励权重；3) 提出Soft-TAC作为TAC的可微分近似，用于从人类偏好数据中训练奖励模型。

Result: 提供TAC指导时，参与者设计出性能更好的奖励函数，且认知负荷更低。在Gran Turismo 7中，使用Soft-TAC训练的奖励模型能捕捉偏好特定的目标，产生比标准交叉熵损失更明显不同的行为策略。

Conclusion: TAC既可作为指导奖励调优的实用工具，也可作为复杂领域中奖励学习的目标。即使有TAC帮助，手动奖励设计仍然耗时，因此需要像Soft-TAC这样的自动化方法。

Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.

</details>


### [144] [Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces](https://arxiv.org/abs/2601.16907)
*Nicolas Tacheny*

Main category: cs.LG

TL;DR: 该论文提出了一种使用保序回归的单调校准方法，解决预训练嵌入空间中余弦相似度绝对值的系统性误校准问题，同时保持其排序相关性。


<details>
  <summary>Details</summary>
Motivation: 预训练嵌入空间中的原始余弦相似度虽然与人类判断有很强的排序相关性，但由于各向异性导致绝对值的系统性误校准：分数集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。

Method: 使用基于人类相似性判断训练的保序回归，构建一个单调变换，在保持排序相关性和局部稳定性的同时实现近乎完美的校准，而不改变嵌入空间的几何结构。

Result: 该方法在七种扰动类型上实现了98%的局部稳定性，同时保持近乎完美的校准和排序相关性。保序校准被证明是所有基于顺序的构造（角度排序、最近邻、阈值图和基于分位数的决策）的不变变换。

Conclusion: 该方法不是要替代余弦相似度，而是通过单调校准恢复其绝对值的可解释性，同时保持其排序特性，为预训练嵌入相似度提供了实用的校准解决方案。

Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.

</details>


### [145] [Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles](https://arxiv.org/abs/2601.16936)
*Anton Zamyatin,Patrick Indri,Sagar Malhotra,Thomas Gärtner*

Main category: cs.LG

TL;DR: BatchEnsemble虽然声称以低参数成本提供类似Deep Ensembles的不确定性估计，但实际表现接近单模型基线，未能实现真正的集成效果


<details>
  <summary>Details</summary>
Motivation: 在资源受限和低延迟场景中，需要高效获取不确定性估计。Deep Ensembles能提供稳健的认知不确定性，但需要训练多个完整模型，成本高昂

Method: BatchEnsemble通过对共享基础网络应用学习的秩-1扰动，旨在以更低的参数和内存成本提供类似集成的认知不确定性估计

Result: BatchEnsemble不仅表现不如Deep Ensembles，在CIFAR10/10C/SVHN上的准确性、校准性和分布外检测方面都接近单模型基线。在MNIST上的控制研究发现成员在函数和参数空间几乎相同

Conclusion: BatchEnsemble的行为更像单模型而非真正的集成，其成员缺乏实现不同预测模式的能力，因此无法提供有效的集成不确定性估计

Abstract: In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.

</details>


### [146] [3D Molecule Generation from Rigid Motifs via SE(3) Flows](https://arxiv.org/abs/2601.16955)
*Roman Poletukhin,Marcel Kollovieh,Eike Eberhard,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该论文提出了一种基于刚性基元的三维分子生成方法，相比传统原子级方法，在生成步骤、表示压缩和原子稳定性方面均有显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统三维分子生成通常在原子级别进行，而分子图生成技术常考虑片段作为结构单元。受蛋白质结构生成中框架方法的启发，希望将这种片段化思想扩展到三维分子生成，将分子视为刚性基元的集合。

Method: 将分子表示为刚性基元集合，采用SE(3)-等变生成模型进行三维分子生成。这种方法将分子分解为刚性结构单元，而不是单独处理每个原子。

Result: 在多个基准测试中达到或超越现有最佳方法，在GEOM-Drugs上表现出更好的原子稳定性。相比标准原子级方法，生成步骤减少2-10倍，分子表示压缩3.5倍。

Conclusion: 基于刚性基元的分子表示和生成方法在效率、压缩性和稳定性方面优于传统原子级方法，为三维分子生成提供了新的有效途径。

Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.

</details>


### [147] [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)
*Mahdi Karami,Ali Ghodsi*

Main category: cs.LG

TL;DR: ARMD模型通过将掩码扩散过程重构为块级因果模型，统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型在语言建模中虽然前景广阔，但相比自回归模型存在性能差距，且需要更多训练迭代。研究者希望设计一种既能保持自回归模型训练效率，又能利用扩散模型并行生成优势的架构。

Method: 将掩码扩散过程重构为块级因果模型，设计严格因果、置换等变的架构，在单个并行前向传递中计算所有条件概率。支持渐进置换训练方案，学习从左到右和随机token排序，并引入跨步并行生成策略加速推理。

Result: ARMD在标准语言建模基准上实现了SOTA性能，超越了现有扩散基线，同时需要显著更少的训练步骤。为并行文本生成设立了新基准，有效弥合了并行和顺序解码之间的性能差距。

Conclusion: ARMD模型成功统一了自回归模型的训练效率和扩散模型的并行生成能力，在语言建模任务上取得了突破性进展，为并行文本生成提供了高效解决方案。

Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.

</details>


### [148] [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)
*Estela Sánchez-Carballo,Francisco M. Melgarejo-Meseguer,José Luis Rojo-Álvarez*

Main category: cs.LG

TL;DR: 使用潜在扩散模型(LDM)生成IoT攻击数据来缓解入侵检测系统中的类别不平衡问题，相比现有方法在样本质量、多样性和计算效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 基于机器学习的IoT入侵检测系统面临严重的类别不平衡问题（正常流量远多于攻击流量），现有数据增强方法在样本保真度、多样性和计算效率方面存在不足。

Method: 提出使用潜在扩散模型(LDM)进行IoT攻击数据增强，在潜在空间而非原始数据空间生成样本，并与现有最先进方法进行综合比较。

Result: LDM生成的数据显著提升IDS性能，DDoS和Mirai攻击的F1分数达到0.99，始终优于竞争方法；同时有效保持特征依赖关系，生成多样样本，采样时间比直接在数据空间操作的扩散模型减少约25%。

Conclusion: 潜在扩散模型是合成IoT攻击数据的有效且可扩展解决方案，能显著缓解IoT场景中基于机器学习的入侵检测系统的类别不平衡影响。

Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [149] [White-Box Sensitivity Auditing with Steering Vectors](https://arxiv.org/abs/2601.16398)
*Hannah Cyberey,Yangfeng Ji,David Evans*

Main category: cs.CY

TL;DR: 提出白盒敏感性审计框架，利用激活导向技术通过模型内部进行更严格的评估，相比黑盒方法能更有效地检测LLM中的偏见


<details>
  <summary>Details</summary>
Motivation: 当前LLM审计主要依赖黑盒评估，仅通过输入输出测试评估模型行为，这些方法局限于输入空间的测试，且许多社会相关模型属性（如性别偏见）抽象难以仅通过文本输入测量

Method: 提出白盒敏感性审计框架，利用激活导向技术，通过操纵与模型任务功能相关的关键概念进行内部敏感性测试

Result: 在四个模拟高风险LLM决策任务中应用该方法进行偏见审计，一致显示模型预测对受保护属性的显著依赖，即使在标准黑盒评估显示很少或无偏见的情况下

Conclusion: 白盒敏感性审计框架能更有效地检测LLM中的偏见，提供比传统黑盒方法更严格的评估，代码已开源

Abstract: Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit

</details>


### [150] [Competing Visions of Ethical AI: A Case Study of OpenAI](https://arxiv.org/abs/2601.16513)
*Melissa Wilfley,Mengting Ai,Madelyn Rose Sanfilippo*

Main category: cs.CY

TL;DR: 该研究分析OpenAI公开文件中"伦理"、"安全"、"对齐"等概念的话语演变，发现其公共沟通以安全和风险话语为主，缺乏学术伦理框架的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解OpenAI等AI公司如何在不同受众（公众vs学术）中构建伦理话语，以及这种话语实践是否涉及"伦理洗白"现象。

Method: 方法包括：1) 构建结构化语料库，区分面向公众和学术的沟通；2) 定性内容分析结合归纳和演绎编码；3) 使用NLP进行定量计算内容分析，建模主题并量化修辞随时间变化；4) 可视化呈现结果。

Result: 结果显示：OpenAI的公共沟通和文档中，安全和风险话语占主导地位，缺乏对学术和倡导伦理框架或词汇的应用。

Conclusion: 结论指出这对治理有重要启示，并讨论了产业中的"伦理洗白"实践，即公司可能用安全和风险话语替代真正的伦理考量。

Abstract: Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry.

</details>


### [151] [Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models](https://arxiv.org/abs/2601.16926)
*Shashank Prakash,Ranjitha Prasad,Avinash Agarwal*

Main category: cs.CY

TL;DR: Nishpaksh是一个本土化的AI公平性评估工具，专门针对印度电信工程中心标准设计，通过基于调查的风险量化、上下文阈值确定和定量公平性评估，为电信和6G应用提供符合监管要求的公平性评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在高风险决策系统中（特别是电信和6G应用）的日益依赖，迫切需要透明和标准化的公平性评估框架。现有全球工具包（如IBM AI Fairness 360和Microsoft Fairlearn）通常缺乏与地区特定监管要求和国家优先事项的对齐。

Method: 开发Nishpaksh工具，将基于调查的风险量化、上下文阈值确定和定量公平性评估集成到统一的基于Web的仪表板中。工具采用向量化计算、反应式状态管理和认证就绪报告，支持可重复的审计级评估。

Result: 在COMPAS数据集上的实验验证表明，Nishpaksh能够有效识别属性特定偏见，并生成符合TEC框架的标准化公平性分数。

Conclusion: Nishpaksh弥合了研究导向的公平性方法与印度监管AI治理之间的差距，标志着在关键基础设施（如电信）中负责任和可审计AI部署的重要一步。

Abstract: The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications.

</details>


### [152] [In Quest of an Extensible Multi-Level Harm Taxonomy for Adversarial AI: Heart of Security, Ethical Risk Scoring and Resilience Analytics](https://arxiv.org/abs/2601.16930)
*Javed I. Khan,Sharmila Rahman Prithula*

Main category: cs.CY

TL;DR: 该论文提出了首个系统化、可扩展的危害分类法，基于当代伦理理论框架，定义了66+种具体危害类型，将危害从模糊概念转变为可操作的分析对象。


<details>
  <summary>Details</summary>
Motivation: 当前各领域（网络安全、伦理、风险分析、对抗性AI等）对"危害"概念缺乏统一定义和系统分类，依赖模糊、不精确的概念，导致无法进行结构化、细致的定性评估。这种概念上的空白阻碍了严肃的分析和伦理推理。

Method: 1. 基于11种主流伦理理论构建结构化分类法；2. 将危害分为人类和非人类两大领域；3. 识别66+种具体危害类型；4. 引入受害者实体分类；5. 形式化危害属性（如可逆性、持续时间等）。

Result: 提出了一个稳定且可扩展的危害分类框架，包含两大领域、11个主要类别，与11种伦理理论对应。该框架使危害变得明确、可枚举、可分析，为AI系统和其他社会技术领域的伦理评估提供了操作化工具。

Conclusion: 该研究将危害从修辞性概念转变为可操作的分析对象，为AI系统和其他社会技术领域的严谨伦理推理和长期安全评估提供了基础框架，填补了危害概念系统化分析的空白。

Abstract: Harm is invoked everywhere from cybersecurity, ethics, risk analysis, to adversarial AI, yet there exists no systematic or agreed upon list of harms, and the concept itself is rarely defined with the precision required for serious analysis. Current discourse relies on vague, under specified notions of harm, rendering nuanced, structured, and qualitative assessment effectively impossible. This paper challenges that gap directly. We introduce a structured and expandable taxonomy of harms, grounded in an ensemble of contemporary ethical theories, that makes harm explicit, enumerable, and analytically tractable. The proposed framework identifies 66+ distinct harm types, systematically organized into two overarching domains human and nonhuman, and eleven major categories, each explicitly aligned with eleven dominant ethical theories. While extensible by design, the upper levels are intentionally stable. Beyond classification, we introduce a theory-aware taxonomy of victim entities and formalize normative harm attributes, including reversibility and duration that materially alter ethical severity. Together, these contributions transform harm from a rhetorical placeholder into an operational object of analysis, enabling rigorous ethical reasoning and long term safety evaluation of AI systems and other sociotechnical domains where harm is a first order concern.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [153] [A Nonlinear Target-Factor Model with Attention Mechanism for Mixed-Frequency Data](https://arxiv.org/abs/2601.16274)
*Alessio Brini,Ekaterina Seregina*

Main category: econ.EM

TL;DR: 提出MPTE框架，使用Transformer注意力机制处理混合频率面板数据，替代传统线性因子模型，在非线性环境中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统因子模型依赖线性信号提取且要求同质采样频率，无法适应现代高维数据中变量观测频率不同的问题，需要更灵活的方法处理混合频率和非线性信号。

Method: 提出Mixed-Panels-Transformer Encoder (MPTE)框架，利用Transformer注意力机制实现上下文感知的信号构建，通过数据依赖的权重方案替代固定线性组合，扩展经典PCA以容纳时间和横截面注意力矩阵。

Result: 在线性激活函数下证明了因子和载荷估计量的一致性和渐近正态性，框架包含Target PCA作为特例并通过跨辅助数据集的迁移学习提供效率增益。在非线性环境中表现优越，在13个宏观经济预测目标上使用FRED-MD和FRED-QD数据库的48个月度和季度序列，相比基准方法取得竞争性表现。

Conclusion: MPTE框架成功解决了混合频率面板数据的因子建模问题，通过注意力机制实现了灵活的信号提取，在理论和实证上都表现出色，为经济预测提供了新工具。

Abstract: We propose Mixed-Panels-Transformer Encoder (MPTE), a novel framework for estimating factor models in panel datasets with mixed frequencies and nonlinear signals. Traditional factor models rely on linear signal extraction and require homogeneous sampling frequencies, limiting their applicability to modern high-dimensional datasets where variables are observed at different temporal resolutions. Our approach leverages Transformer-style attention mechanisms to enable context-aware signal construction through flexible, data-dependent weighting schemes that replace fixed linear combinations with adaptive reweighting based on similarity and relevance. We extend classical principal component analysis (PCA) to accommodate general temporal and cross-sectional attention matrices, allowing the model to learn how to aggregate information across frequencies without manual alignment or pre-specified weights. For linear activation functions, we establish consistency and asymptotic normality of factor and loading estimators, showing that our framework nests Target PCA as a special case while providing efficiency gains through transfer learning across auxiliary datasets. The nonlinear extension uses a Transformer architecture to capture complex hierarchical interactions while preserving the theoretical foundations. In simulations, MPTE demonstrates superior performance in nonlinear environments, and in an empirical application to 13 macroeconomic forecasting targets using a selected set of 48 monthly and quarterly series from the FRED-MD and FRED-QD databases, our method achieves competitive performance against established benchmarks. We further analyze attention patterns and systematically ablate model components to assess variable importance and temporal dependence. The resulting patterns highlight which indicators and horizons are most influential for forecasting.

</details>


### [154] [Is the diurnal pattern sufficient to explain intraday variation in volatility? A nonparametric assessment](https://arxiv.org/abs/2601.16613)
*Kim Christensen,Ulrich Hounyo,Mark Podolskij*

Main category: econ.EM

TL;DR: 提出一种非参数方法检验日内波动率变化是否仅由确定性的日度模式引起，基于高频数据，通过去季节化处理构建检验统计量，证明渐近正态性，并开发bootstrap方法改善小样本推断。


<details>
  <summary>Details</summary>
Motivation: 研究日内波动率变化的来源：是仅由确定性的日度模式（如开盘、收盘效应）引起，还是存在其他随机波动成分。这对于理解市场微观结构和风险管理具有重要意义。

Method: 1. 假设高频数据来自带跳跃的扩散过程；2. 用季节因子对收益率进行去季节化处理；3. 扩展预平均双幂变差概念到一般Itô半鞅框架，采用截断技术；4. 证明统计量的中心极限定理；5. 开发模型无关、对跳跃和噪声稳健的季节因子估计量；6. 提出bootstrap方法改善小样本推断。

Result: 1. 检验统计量在存在随机波动时发散，否则服从标准正态分布；2. 用估计的季节因子替代真实因子不影响渐近理论；3. 蒙特卡洛模拟显示在有限样本中替代也无明显影响；4. 无限活动小跳跃会扭曲检验，但bootstrap方法能改善检验水平；5. 应用于股票高频数据发现日度模式解释相当显著的日内波动变化，但仍存在重要的异方差来源。

Conclusion: 日内波动率变化并非完全由确定性的日度模式解释，存在显著的随机波动成分。提出的非参数检验方法对跳跃和噪声稳健，bootstrap方法能有效改善小样本推断，为高频数据分析提供了实用工具。

Abstract: In this paper, we propose a nonparametric way to test the hypothesis that time-variation in intraday volatility is caused solely by a deterministic and recurrent diurnal pattern. We assume that noisy high-frequency data from a discretely sampled jump-diffusion process are available. The test is then based on asset returns, which are deflated by the seasonal component and therefore homoskedastic under the null. To construct our test statistic, we extend the concept of pre-averaged bipower variation to a general Itô semimartingale setting via a truncation device. We prove a central limit theorem for this statistic and construct a positive semi-definite estimator of the asymptotic covariance matrix. The $t$-statistic (after pre-averaging and jump-truncation) diverges in the presence of stochastic volatility and has a standard normal distribution otherwise. We show that replacing the true diurnal factor with a model-free jump- and noise-robust estimator does not affect the asymptotic theory. A Monte Carlo simulation also shows this substitution has no discernable impact in finite samples. The test is, however, distorted by small infinite-activity price jumps. To improve inference, we propose a new bootstrap approach, which leads to almost correctly sized tests of the null hypothesis. We apply the developed framework to a large cross-section of equity high-frequency data and find that the diurnal pattern accounts for a rather significant fraction of intraday variation in volatility, but important sources of heteroskedasticity remain present in the data.

</details>


### [155] [Inference from high-frequency data: A subsampling approach](https://arxiv.org/abs/2601.16668)
*Kim Christensen,Mark Podolskij,Nopporn Thamrongrat,Bezirgen Veliyev*

Main category: econ.EM

TL;DR: 提出基于子抽样的高频率资产收益波动率估计中渐近协方差矩阵的估计方法，该方法在无摩擦市场和含微观结构噪声模型中均一致，且构造上保证半正定性。


<details>
  <summary>Details</summary>
Motivation: 在高频率波动率估计中，中心极限定理涉及的渐近协方差矩阵估计对评估抽样误差至关重要。现有方法通常需要额外的估计器或对噪声结构有明确假设，缺乏既简单又稳健的解决方案。

Method: 采用子抽样方法：基于高频数据的局部片段计算原始统计量的重缩放副本，然后研究这些副本的抽样变异。该方法自动适应问题结构，无需额外估计器或对渐近协方差结构的显式知识。

Result: 证明了估计量在无摩擦市场和含加性微观结构噪声模型中的一致性，推导了收敛速率并确定了调优参数（如子抽样数量）的最优速率。蒙特卡洛研究验证了有限样本性质，实证应用展示了在金融市场波动率推断中的可行性。

Conclusion: 子抽样方法为高频率波动率估计中的抽样误差评估提供了简单、稳健且易于实现的解决方案。该方法构造上保证半正定性，对噪声过程误设具有鲁棒性，便于金融市场波动率的可行推断。

Abstract: In this paper, we show how to estimate the asymptotic (conditional) covariance matrix, which appears in central limit theorems in high-frequency estimation of asset return volatility. We provide a recipe for the estimation of this matrix by subsampling; an approach that computes rescaled copies of the original statistic based on local stretches of high-frequency data, and then it studies the sampling variation of these. We show that our estimator is consistent both in frictionless markets and models with additive microstructure noise. We derive a rate of convergence for it and are also able to determine an optimal rate for its tuning parameters (e.g., the number of subsamples). Subsampling does not require an extra set of estimators to do inference, which renders it trivial to implement. As a variance-covariance matrix estimator, it has the attractive feature that it is positive semi-definite by construction. Moreover, the subsampler is to some extent automatic, as it does not exploit explicit knowledge about the structure of the asymptotic covariance. It therefore tends to adapt to the problem at hand and be robust against misspecification of the noise process. As such, this paper facilitates assessment of the sampling errors inherent in high-frequency estimation of volatility. We highlight the finite sample properties of the subsampler in a Monte Carlo study, while some initial empirical work demonstrates its use to draw feasible inference about volatility in financial markets.

</details>


### [156] [Distributional Instruments: Identification and Estimation with Quantile Least Squares](https://arxiv.org/abs/2601.16865)
*Rowan Cherodian,Guy Tchuente*

Main category: econ.EM

TL;DR: 提出Q-LS方法，利用工具变量的分布相关性而非均值相关性来识别因果效应，解决弱工具变量问题


<details>
  <summary>Details</summary>
Motivation: 传统工具变量方法依赖工具变量对处理变量均值的强影响，但在政策改革等场景中，工具变量可能只改变处理变量的分布而非均值，导致弱工具变量问题

Method: 提出分布相关性概念，建立三角模型下的非参数识别理论；开发Quantile Least Squares方法，通过聚合条件分位数构建最优均方预测器作为工具变量

Result: 理论证明Q-LS的一致性和渐近正态性，蒙特卡洛模拟显示在弱工具变量情况下Q-LS估计无偏且检验规模正确，健康与退休研究数据应用表明Q-LS能利用分布变化提高估计精度

Conclusion: 分布相关性为因果识别提供了新视角，Q-LS方法能有效利用工具变量的分布变化信息，在传统2SLS面临弱工具变量问题时提供稳健的因果效应估计

Abstract: We study instrumental-variable designs where policy reforms strongly shift the distribution of an endogenous variable but only weakly move its mean. We formalize this by introducing distributional relevance: instruments may be purely distributional. Within a triangular model, distributional relevance suffices for nonparametric identification of average structural effects via a control function. We then propose Quantile Least Squares (Q-LS), which aggregates conditional quantiles of X given Z into an optimal mean-square predictor and uses this projection as an instrument in a linear IV estimator. We establish consistency, asymptotic normality, and the validity of standard 2SLS variance formulas, and we discuss regularization across quantiles. Monte Carlo designs show that Q-LS delivers well-centered estimates and near-correct size when mean-based 2SLS suffers from weak instruments. In Health and Retirement Study data, Q-LS exploits Medicare Part D-induced distributional shifts in out-of-pocket risk to sharpen estimates of its effects on depression.

</details>
