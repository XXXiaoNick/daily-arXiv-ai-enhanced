{"id": "2602.07000", "categories": ["eess.SY", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07000", "abs": "https://arxiv.org/abs/2602.07000", "authors": ["Abanoub M. Girgis", "Ibtissam Labriji", "Mehdi Bennis"], "title": "Hierarchical JEPA Meets Predictive Remote Control in Beyond 5G Networks", "comment": null, "summary": "In wireless networked control systems, ensuring timely and reliable state updates from distributed devices to remote controllers is essential for robust control performance. However, when multiple devices transmit high-dimensional states (e.g., images or video frames) over bandwidth-limited wireless networks, a critical trade-off emerges between communication efficiency and control performance. To address this challenge, we propose a Hierarchical Joint-Embedding Predictive Architecture (H-JEPA) for scalable predictive control. Instead of transmitting states, device observations are encoded into low-dimensional embeddings that preserve essential dynamics. The proposed architecture employs a three-level hierarchical prediction, with high-level, medium-level, and low-level predictors operating across different temporal resolutions, to achieve long-term prediction stability, intermediate interpolation, and fine-grained refinement, respectively. Control actions are derived within the embedding space, removing the need for state reconstruction. Simulation results on inverted cart-pole systems demonstrate that H-JEPA enables up to 42.83 % more devices to be supported under limited wireless capacity without compromising control performance.", "AI": {"tldr": "H-JEPA\uff1a\u4e00\u79cd\u7528\u4e8e\u65e0\u7ebf\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u7684\u5206\u5c42\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u9ad8\u7ef4\u72b6\u6001\u7f16\u7801\u4e3a\u4f4e\u7ef4\u5d4c\u5165\u5e76\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9884\u6d4b\u548c\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6548\u7387\u548c\u63a7\u5236\u6027\u80fd\u3002", "motivation": "\u65e0\u7ebf\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u591a\u4e2a\u8bbe\u5907\u4f20\u8f93\u9ad8\u7ef4\u72b6\u6001\uff08\u5982\u56fe\u50cf\u6216\u89c6\u9891\u5e27\uff09\u65f6\u9762\u4e34\u901a\u4fe1\u6548\u7387\u4e0e\u63a7\u5236\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002\u5e26\u5bbd\u53d7\u9650\u7684\u65e0\u7ebf\u7f51\u7edc\u96be\u4ee5\u652f\u6301\u5927\u91cf\u8bbe\u5907\u540c\u65f6\u4f20\u8f93\u9ad8\u7ef4\u6570\u636e\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u727a\u7272\u63a7\u5236\u6027\u80fd\uff0c\u8981\u4e48\u589e\u52a0\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\uff08H-JEPA\uff09\uff1a1\uff09\u5c06\u8bbe\u5907\u89c2\u6d4b\u7f16\u7801\u4e3a\u4f4e\u7ef4\u5d4c\u5165\uff0c\u4fdd\u7559\u5173\u952e\u52a8\u6001\u4fe1\u606f\uff1b2\uff09\u91c7\u7528\u4e09\u5c42\u5206\u5c42\u9884\u6d4b\uff1a\u9ad8\u5c42\u9884\u6d4b\u5668\u7528\u4e8e\u957f\u671f\u7a33\u5b9a\u6027\uff0c\u4e2d\u5c42\u7528\u4e8e\u4e2d\u95f4\u63d2\u503c\uff0c\u4f4e\u5c42\u7528\u4e8e\u7ec6\u7c92\u5ea6\u7ec6\u5316\uff1b3\uff09\u76f4\u63a5\u5728\u5d4c\u5165\u7a7a\u95f4\u63a8\u5bfc\u63a7\u5236\u52a8\u4f5c\uff0c\u65e0\u9700\u72b6\u6001\u91cd\u6784\u3002", "result": "\u5728\u5012\u7acb\u6446\u7cfb\u7edf\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cH-JEPA\u5728\u6709\u9650\u65e0\u7ebf\u5bb9\u91cf\u4e0b\u80fd\u591f\u652f\u6301\u591a\u8fbe42.83%\u7684\u8bbe\u5907\uff0c\u4e14\u4e0d\u635f\u5bb3\u63a7\u5236\u6027\u80fd\u3002\u8fd9\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u901a\u4fe1\u6548\u7387\u3002", "conclusion": "H-JEPA\u901a\u8fc7\u5206\u5c42\u9884\u6d4b\u548c\u5d4c\u5165\u7a7a\u95f4\u63a7\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u7ebf\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u4e2d\u9ad8\u7ef4\u72b6\u6001\u4f20\u8f93\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07215", "categories": ["eess.SY", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07215", "abs": "https://arxiv.org/abs/2602.07215", "authors": ["Haiyuan Li", "Hari Madhukumar", "Shuangyi Yan", "Yulei Wu", "Dimitra Simeonidou"], "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks", "comment": null, "summary": "Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output modalities that complicate orchestration, and resource-limited infrastructure ill-suited for concurrent LM execution. In response, we propose a Multi-Agentic AI framework for latency- and fairness-aware multi-modal LM inference in mobile edge networks. Our solution includes a long-term planning agent, a short-term prompt scheduling agent, and multiple on-node LM deployment agents, all powered by foundation language models. These agents cooperatively optimize prompt routing and LM deployment through natural language reasoning over runtime telemetry and historical experience. To evaluate its performance, we further develop a city-wide testbed that supports network monitoring, containerized LM deployment, intra-server resource management, and inter-server communications. Experiments demonstrate that our solution reduces average latency by over 80% and improves fairness (Normalized Jain index) to 0.90 compared to other baselines. Moreover, our solution adapts quickly without fine-tuning, offering a generalizable solution for optimizing GenAI services in edge environments.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u7528\u4e8e\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\u4e2d\u5ef6\u8fdf\u548c\u516c\u5e73\u611f\u77e5\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4f18\u5316\u63d0\u793a\u8def\u7531\u548c\u6a21\u578b\u90e8\u7f72\uff0c\u5b9e\u9a8c\u663e\u793a\u5ef6\u8fdf\u964d\u4f4e80%\u4ee5\u4e0a\uff0c\u516c\u5e73\u6027\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5185\u5bb9\u521b\u4f5c\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u96c6\u4e2d\u5f0f\u63a8\u7406\u5b58\u5728\u9ad8\u5ef6\u8fdf\u3001\u53ef\u5b9a\u5236\u6027\u5dee\u548c\u9690\u79c1\u95ee\u9898\u3002\u5728\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\u90e8\u7f72\u5927\u6a21\u578b\u662f\u53ef\u884c\u65b9\u6848\uff0c\u4f46\u9762\u4e34\u5f02\u6784\u591a\u6a21\u6001\u6a21\u578b\u8d44\u6e90\u9700\u6c42\u5dee\u5f02\u3001\u4e0d\u540c\u63d0\u793a/\u8f93\u51fa\u6a21\u6001\u534f\u8c03\u56f0\u96be\u3001\u8d44\u6e90\u53d7\u9650\u57fa\u7840\u8bbe\u65bd\u96be\u4ee5\u5e76\u53d1\u6267\u884c\u6a21\u578b\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u5305\u542b\u957f\u671f\u89c4\u5212\u667a\u80fd\u4f53\u3001\u77ed\u671f\u63d0\u793a\u8c03\u5ea6\u667a\u80fd\u4f53\u548c\u591a\u4e2a\u8282\u70b9\u6a21\u578b\u90e8\u7f72\u667a\u80fd\u4f53\uff0c\u5747\u57fa\u4e8e\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u5206\u6790\u8fd0\u884c\u65f6\u9065\u6d4b\u6570\u636e\u548c\u5386\u53f2\u7ecf\u9a8c\uff0c\u534f\u540c\u4f18\u5316\u63d0\u793a\u8def\u7531\u548c\u6a21\u578b\u90e8\u7f72\u3002\u5f00\u53d1\u4e86\u652f\u6301\u7f51\u7edc\u76d1\u63a7\u3001\u5bb9\u5668\u5316\u6a21\u578b\u90e8\u7f72\u3001\u670d\u52a1\u5668\u5185\u8d44\u6e90\u7ba1\u7406\u548c\u670d\u52a1\u5668\u95f4\u901a\u4fe1\u7684\u57ce\u5e02\u7ea7\u6d4b\u8bd5\u5e73\u53f0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u5c06\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e80%\u4ee5\u4e0a\uff0c\u516c\u5e73\u6027\uff08\u5f52\u4e00\u5316Jain\u6307\u6570\uff09\u63d0\u5347\u81f30.90\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002\u89e3\u51b3\u65b9\u6848\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5feb\u901f\u9002\u5e94\uff0c\u4e3a\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u751f\u6210\u5f0fAI\u670d\u52a1\u4f18\u5316\u63d0\u4f9b\u4e86\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u8fb9\u7f18\u7f51\u7edc\u4e2d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u5ef6\u8fdf\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7684\u534f\u540c\u4f18\u5316\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u751f\u6210\u5f0fAI\u670d\u52a1\u63d0\u4f9b\u4e86\u901a\u7528\u3001\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2602.07300", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07300", "abs": "https://arxiv.org/abs/2602.07300", "authors": ["Ganghui Cao", "Xunyuan Yin"], "title": "Distributed Omniscient Observers for Multi-Agent Systems", "comment": null, "summary": "This article proposes fully distributed omniscient observers for both heterogeneous and homogeneous linear multi-agent systems, through which each agent can estimate the states of all agents. The proposed observers not only contribute to distributed Nash equilibrium seeking in multi-player games, but also provide a designable self-organization mechanism for artificial swarms to emulate biological social behaviors, including sheepdog herding and honeybee dance communication.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5f02\u6784\u548c\u540c\u6784\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5168\u5206\u5e03\u5f0f\u5168\u77e5\u89c2\u6d4b\u5668\uff0c\u4f7f\u6bcf\u4e2a\u667a\u80fd\u4f53\u80fd\u4f30\u8ba1\u6240\u6709\u667a\u80fd\u4f53\u72b6\u6001\uff0c\u5e94\u7528\u4e8e\u5206\u5e03\u5f0f\u7eb3\u4ec0\u5747\u8861\u6c42\u89e3\u548c\u4eba\u5de5\u7fa4\u4f53\u81ea\u7ec4\u7ec7\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u80fd\u591f\u5b9e\u73b0\u5168\u5c40\u72b6\u6001\u4f30\u8ba1\u7684\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\uff0c\u4ee5\u652f\u6301\u5206\u5e03\u5f0f\u535a\u5f08\u5747\u8861\u6c42\u89e3\uff0c\u5e76\u4e3a\u4eba\u5de5\u7fa4\u4f53\u6a21\u62df\u751f\u7269\u793e\u4f1a\u884c\u4e3a\uff08\u5982\u7267\u7f8a\u72ac\u653e\u7267\u548c\u871c\u8702\u821e\u8e48\u901a\u4fe1\uff09\u63d0\u4f9b\u53ef\u8bbe\u8ba1\u7684\u81ea\u7ec4\u7ec7\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5168\u5206\u5e03\u5f0f\u5168\u77e5\u89c2\u6d4b\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5f02\u6784\u548c\u540c\u6784\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f7f\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u901a\u8fc7\u5c40\u90e8\u901a\u4fe1\u5c31\u80fd\u4f30\u8ba1\u6574\u4e2a\u7cfb\u7edf\u7684\u72b6\u6001\u3002", "result": "\u89c2\u6d4b\u5668\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6bcf\u4e2a\u667a\u80fd\u4f53\u5bf9\u5168\u5c40\u72b6\u6001\u7684\u5206\u5e03\u5f0f\u4f30\u8ba1\uff0c\u8fd8\u80fd\u5e94\u7528\u4e8e\u591a\u73a9\u5bb6\u535a\u5f08\u7684\u5206\u5e03\u5f0f\u7eb3\u4ec0\u5747\u8861\u6c42\u89e3\uff0c\u5e76\u4e3a\u4eba\u5de5\u7fa4\u4f53\u6a21\u62df\u751f\u7269\u793e\u4f1a\u884c\u4e3a\u63d0\u4f9b\u4e86\u81ea\u7ec4\u7ec7\u8bbe\u8ba1\u6846\u67b6\u3002", "conclusion": "\u5168\u5206\u5e03\u5f0f\u5168\u77e5\u89c2\u6d4b\u5668\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u3001\u5206\u5e03\u5f0f\u535a\u5f08\u6c42\u89e3\u548c\u751f\u7269\u793e\u4f1a\u884c\u4e3a\u6a21\u62df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u548c\u8bbe\u8ba1\u5de5\u5177\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.07335", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.07335", "abs": "https://arxiv.org/abs/2602.07335", "authors": ["Minduli C. Wijayatunga", "Richard Linares", "Roberto Armellin"], "title": "Meta-Reinforcement Learning for Robust and Non-greedy Control Barrier Functions in Spacecraft Proximity Operations", "comment": null, "summary": "Autonomous spacecraft inspection and docking missions require controllers that can guarantee safety under thrust constraints and uncertainty. Input-constrained control barrier functions (ICCBFs) provide a framework for safety certification under bounded actuation; however, conventional ICCBF formulations can be overly conservative and exhibit limited robustness to uncertainty, leading to high fuel consumption and reduced mission feasibility. This paper proposes a framework in which the full hierarchy of class-$\\mathcal{K}$ functions defining the ICCBF recursion is parameterized and learned, enabling localized shaping of the safe set and reduced conservatism. A control margin is computed efficiently using differential algebra to enable the learned continuous-time ICCBFs to be implemented on time-sampled dynamical systems typical of spacecraft proximity operations. A meta-reinforcement learning scheme is developed to train a policy that generates ICCBF parameters over a distribution of hidden physical parameters and uncertainties, using both multilayer perceptron (MLP) and recurrent neural network (RNN) architectures. Simulation results on cruise control, spacecraft inspection, and docking scenarios demonstrate that the proposed approach maintains safety while reducing fuel consumption and improving feasibility relative to fixed class-$\\mathcal{K}$ ICCBFs, with the RNN showing a particularly strong advantage in the more complex inspection case.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b66\u4e60\u578b\u8f93\u5165\u7ea6\u675f\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u7c7bK\u51fd\u6570\u5c42\u7ea7\u6765\u51cf\u5c11\u4fdd\u5b88\u6027\uff0c\u7ed3\u5408\u5fae\u5206\u4ee3\u6570\u8ba1\u7b97\u63a7\u5236\u88d5\u5ea6\uff0c\u4f7f\u7528\u5143\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7b56\u7565\u751f\u6210ICCBF\u53c2\u6570\uff0c\u5728\u822a\u5929\u5668\u68c0\u67e5\u5bf9\u63a5\u7b49\u573a\u666f\u4e2d\u964d\u4f4e\u71c3\u6599\u6d88\u8017\u5e76\u4fdd\u6301\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u8f93\u5165\u7ea6\u675f\u63a7\u5236\u5c4f\u969c\u51fd\u6570(ICCBFs)\u5728\u822a\u5929\u5668\u81ea\u4e3b\u68c0\u67e5\u5bf9\u63a5\u4efb\u52a1\u4e2d\u8fc7\u4e8e\u4fdd\u5b88\u4e14\u5bf9\u4e0d\u786e\u5b9a\u6027\u9c81\u68d2\u6027\u6709\u9650\uff0c\u5bfc\u81f4\u71c3\u6599\u6d88\u8017\u9ad8\u3001\u4efb\u52a1\u53ef\u884c\u6027\u964d\u4f4e\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u5f3a\u7684\u5b89\u5168\u63a7\u5236\u6846\u67b6\u3002", "method": "1) \u53c2\u6570\u5316ICCBF\u9012\u5f52\u4e2d\u6240\u6709\u7c7bK\u51fd\u6570\u5c42\u7ea7\u5e76\u5b66\u4e60\uff1b2) \u4f7f\u7528\u5fae\u5206\u4ee3\u6570\u9ad8\u6548\u8ba1\u7b97\u63a7\u5236\u88d5\u5ea6\uff0c\u4f7f\u8fde\u7eed\u65f6\u95f4ICCBF\u80fd\u7528\u4e8e\u65f6\u95f4\u91c7\u6837\u7cfb\u7edf\uff1b3) \u5f00\u53d1\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\uff0c\u8bad\u7ec3\u7b56\u7565\u5728\u9690\u85cf\u7269\u7406\u53c2\u6570\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u5e03\u4e0a\u751f\u6210ICCBF\u53c2\u6570\uff0c\u91c7\u7528MLP\u548cRNN\u67b6\u6784\u3002", "result": "\u5728\u5de1\u822a\u63a7\u5236\u3001\u822a\u5929\u5668\u68c0\u67e5\u548c\u5bf9\u63a5\u573a\u666f\u7684\u4eff\u771f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u71c3\u6599\u6d88\u8017\u3001\u63d0\u9ad8\u53ef\u884c\u6027\uff0cRNN\u67b6\u6784\u5728\u66f4\u590d\u6742\u7684\u68c0\u67e5\u6848\u4f8b\u4e2d\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0c\u4f18\u4e8e\u56fa\u5b9a\u7c7bK\u51fd\u6570\u7684\u4f20\u7edfICCBF\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b66\u4e60\u578bICCBF\u6846\u67b6\u901a\u8fc7\u53c2\u6570\u5316\u7c7bK\u51fd\u6570\u5c42\u7ea7\u548c\u5143\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4fdd\u5b88\u6027\uff0c\u63d0\u9ad8\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\uff0c\u5728\u822a\u5929\u5668\u81ea\u4e3b\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u4e0e\u71c3\u6599\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u7ea6\u675f\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08228", "categories": ["q-fin.PM"], "pdf": "https://arxiv.org/pdf/2602.08228", "abs": "https://arxiv.org/abs/2602.08228", "authors": ["Alireza Ghahtarani", "Ahmed Saif", "Alireza Ghasemi"], "title": "Comparing Mixture, Box, and Wasserstein Ambiguity Sets in Distributionally Robust Asset Liability Management", "comment": "25 pages, 4 Figures", "summary": "Asset Liability Management (ALM) represents a fundamental challenge for financial institutions, particularly pension funds, which must navigate the tension between generating competitive investment returns and ensuring the solvency of long-term obligations. To address the limitations of traditional frameworks under uncertainty, this paper implements Distributionally Robust Optimization (DRO), an emergent paradigm that accounts for a broad spectrum of potential probability distributions. We propose and evaluate three distinct DRO formulations: mixture ambiguity sets with discrete scenarios, box ambiguity sets of discrete distribution functions, and Wasserstein metric ambiguity sets. Utilizing empirical data from the Canada Pension Plan (CPP), we conduct a comparative analysis of these models against traditional stochastic programming approaches. Our results demonstrate that DRO formulations, specifically those utilizing Wasserstein and box ambiguity sets, consistently outperform both mixture-based DRO and stochastic programming in terms of funding ratios and overall fund returns. These findings suggest that incorporating distributional robustness significantly enhances the resilience and performance of pension fund management strategies.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u517b\u8001\u91d1\u8d44\u4ea7\u8d1f\u503a\u7ba1\u7406\uff0c\u63d0\u51fa\u4e09\u79cd\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6a21\u578b\uff0c\u76f8\u6bd4\u4f20\u7edf\u968f\u673a\u89c4\u5212\u80fd\u663e\u8457\u63d0\u5347\u8d44\u91d1\u6bd4\u7387\u548c\u6295\u8d44\u56de\u62a5\u3002", "motivation": "\u4f20\u7edf\u8d44\u4ea7\u8d1f\u503a\u7ba1\u7406\u6846\u67b6\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b58\u5728\u5c40\u9650\uff0c\u517b\u8001\u91d1\u9700\u8981\u5728\u83b7\u53d6\u6295\u8d44\u56de\u62a5\u4e0e\u4fdd\u8bc1\u507f\u4ed8\u80fd\u529b\u4e4b\u95f4\u5e73\u8861\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u65b9\u6cd5\u5e94\u5bf9\u6982\u7387\u5206\u5e03\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e09\u79cd\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6a21\u578b\uff1a\u57fa\u4e8e\u79bb\u6563\u573a\u666f\u7684\u6df7\u5408\u6a21\u7cca\u96c6\u3001\u79bb\u6563\u5206\u5e03\u51fd\u6570\u7684\u76d2\u6a21\u7cca\u96c6\u3001\u4ee5\u53caWasserstein\u5ea6\u91cf\u6a21\u7cca\u96c6\u3002\u4f7f\u7528\u52a0\u62ff\u5927\u517b\u8001\u91d1\u8ba1\u5212\u5b9e\u8bc1\u6570\u636e\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "Wasserstein\u548c\u76d2\u6a21\u7cca\u96c6\u7684DRO\u6a21\u578b\u5728\u8d44\u91d1\u6bd4\u7387\u548c\u57fa\u91d1\u603b\u56de\u62a5\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6df7\u5408DRO\u548c\u4f20\u7edf\u968f\u673a\u89c4\u5212\u65b9\u6cd5\u3002", "conclusion": "\u5f15\u5165\u5206\u5e03\u9c81\u68d2\u6027\u663e\u8457\u589e\u5f3a\u4e86\u517b\u8001\u91d1\u7ba1\u7406\u7b56\u7565\u7684\u97e7\u6027\u548c\u7ee9\u6548\uff0c\u4e3a\u91d1\u878d\u673a\u6784\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2602.07018", "categories": ["q-fin.ST", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.07018", "abs": "https://arxiv.org/abs/2602.07018", "authors": ["Murad Farzulla"], "title": "The Extremity Premium: Sentiment Regimes and Adverse Selection in Cryptocurrency Markets", "comment": "53 pages, 6 figures, 15+ tables. Code: https://github.com/studiofarzulla/sentiment-microstructure-abm", "summary": "Using the Crypto Fear & Greed Index and Bitcoin daily data, we document that sentiment extremity predicts excess uncertainty beyond realized volatility. Extreme fear and extreme greed regimes exhibit significantly higher spreads than neutral periods -- a phenomenon we term the \"extremity premium.\" Extended validation on the full Fear & Greed history (February 2018--January 2026, N = 2,896) confirms the finding: within-volatility-quintile comparisons show a significant premium (p < 0.001, Cohen's d = 0.21), Granger causality from uncertainty to spreads is strong (F = 211), and placebo tests reject the null (p < 0.0001). The effect replicates on Ethereum and across 6 of 7 market cycles. However, the premium is sensitive to functional form: comprehensive regression controls absorb regime effects, while nonparametric stratification preserves them. We interpret this as evidence that sentiment extremity captures volatility-regime interactions not fully represented by parametric controls -- consistent with, but not conclusively separable from, the F&G Index's embedded volatility component. An agent-based model reproduces the pattern qualitatively. The results suggest that intensity, not direction, drives uncertainty-linked liquidity withdrawal in cryptocurrency markets, though identification of \"pure\" sentiment effects from volatility remains an open challenge.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u60c5\u7eea\u6781\u7aef\u6027\uff08\u6781\u5ea6\u6050\u60e7\u6216\u8d2a\u5a6a\uff09\u4f1a\u5e26\u6765\"\u6781\u7aef\u6027\u6ea2\u4ef7\"\u2014\u2014\u76f8\u6bd4\u4e2d\u6027\u65f6\u671f\uff0c\u6781\u7aef\u60c5\u7eea\u671f\u95f4\u4e70\u5356\u4ef7\u5dee\u663e\u8457\u6269\u5927\uff0c\u8868\u660e\u60c5\u7eea\u5f3a\u5ea6\u800c\u975e\u65b9\u5411\u9a71\u52a8\u4e86\u4e0e\u4e0d\u786e\u5b9a\u6027\u76f8\u5173\u7684\u6d41\u52a8\u6027\u6536\u7f29\u3002", "motivation": "\u63a2\u7a76\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u60c5\u7eea\u6781\u7aef\u6027\u5bf9\u5e02\u573a\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u60c5\u7eea\u5f3a\u5ea6\uff08\u800c\u975e\u65b9\u5411\uff09\u5982\u4f55\u5f71\u54cd\u6d41\u52a8\u6027\uff0c\u4ee5\u53ca\u60c5\u7eea\u6548\u5e94\u4e0e\u6ce2\u52a8\u7387\u6548\u5e94\u7684\u53ef\u5206\u79bb\u6027\u3002", "method": "\u4f7f\u7528\u52a0\u5bc6\u8d27\u5e01\u6050\u60e7\u4e0e\u8d2a\u5a6a\u6307\u6570\u548c\u6bd4\u7279\u5e01\u65e5\u5ea6\u6570\u636e\uff0c\u901a\u8fc7\u6ce2\u52a8\u7387\u4e94\u5206\u4f4d\u6bd4\u8f83\u3001\u683c\u5170\u6770\u56e0\u679c\u68c0\u9a8c\u3001\u5b89\u6170\u5242\u6d4b\u8bd5\u7b49\u65b9\u6cd5\u5206\u6790\u6781\u7aef\u60c5\u7eea\u671f\u95f4\uff08\u6781\u5ea6\u6050\u60e7/\u8d2a\u5a6a\uff09\u4e0e\u4e2d\u6027\u65f6\u671f\u7684\u4e70\u5356\u4ef7\u5dee\u5dee\u5f02\uff0c\u5e76\u5728\u4ee5\u592a\u574a\u548c\u591a\u4e2a\u5e02\u573a\u5468\u671f\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u663e\u8457\u7684\"\u6781\u7aef\u6027\u6ea2\u4ef7\"\uff1a\u6781\u7aef\u60c5\u7eea\u671f\u95f4\u7684\u4e70\u5356\u4ef7\u5dee\u663e\u8457\u9ad8\u4e8e\u4e2d\u6027\u65f6\u671f\uff08p<0.001\uff0cCohen's d=0.21\uff09\uff0c\u683c\u5170\u6770\u56e0\u679c\u68c0\u9a8c\u663e\u793a\u4e0d\u786e\u5b9a\u6027\u5bf9\u4ef7\u5dee\u6709\u5f3a\u5f71\u54cd\uff08F=211\uff09\uff0c\u5b89\u6170\u5242\u6d4b\u8bd5\u62d2\u7edd\u96f6\u5047\u8bbe\uff08p<0.0001\uff09\u3002\u8be5\u6548\u5e94\u5728\u4ee5\u592a\u574a\u548c6/7\u4e2a\u5e02\u573a\u5468\u671f\u4e2d\u53ef\u590d\u5236\uff0c\u4f46\u5bf9\u51fd\u6570\u5f62\u5f0f\u654f\u611f\u3002", "conclusion": "\u60c5\u7eea\u6781\u7aef\u6027\u6355\u6349\u4e86\u6ce2\u52a8\u7387\u673a\u5236\u76f8\u4e92\u4f5c\u7528\uff0c\u8fd9\u4e9b\u4f5c\u7528\u65e0\u6cd5\u5b8c\u5168\u88ab\u53c2\u6570\u5316\u63a7\u5236\u6240\u4ee3\u8868\u3002\u60c5\u7eea\u5f3a\u5ea6\uff08\u800c\u975e\u65b9\u5411\uff09\u9a71\u52a8\u4e86\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u4e0e\u4e0d\u786e\u5b9a\u6027\u76f8\u5173\u7684\u6d41\u52a8\u6027\u6536\u7f29\uff0c\u4f46\u5c06\"\u7eaf\u7cb9\"\u60c5\u7eea\u6548\u5e94\u4e0e\u6ce2\u52a8\u7387\u6548\u5e94\u5206\u79bb\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2602.07102", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07102", "abs": "https://arxiv.org/abs/2602.07102", "authors": ["L\u00e9on Zheng", "Thomas Hirtz", "Yazid Janati", "Eric Moulines"], "title": "Fast and Robust Likelihood-Guided Diffusion Posterior Sampling with Amortized Variational Inference", "comment": null, "summary": "Zero-shot diffusion posterior sampling offers a flexible framework for inverse problems by accommodating arbitrary degradation operators at test time, but incurs high computational cost due to repeated likelihood-guided updates. In contrast, previous amortized diffusion approaches enable fast inference by replacing likelihood-based sampling with implicit inference models, but at the expense of robustness to unseen degradations. We introduce an amortization strategy for diffusion posterior sampling that preserves explicit likelihood guidance by amortizing the inner optimization problems arising in variational diffusion posterior sampling. This accelerates inference for in-distribution degradations while maintaining robustness to previously unseen operators, thereby improving the trade-off between efficiency and flexibility in diffusion-based inverse problems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u644a\u9500\u7b56\u7565\u7528\u4e8e\u6269\u6563\u540e\u9a8c\u91c7\u6837\uff0c\u5728\u4fdd\u6301\u663e\u5f0f\u4f3c\u7136\u5f15\u5bfc\u7684\u540c\u65f6\u52a0\u901f\u63a8\u7406\uff0c\u5e73\u8861\u4e86\u6548\u7387\u548c\u7075\u6d3b\u6027", "motivation": "\u4f20\u7edf\u96f6\u6837\u672c\u6269\u6563\u540e\u9a8c\u91c7\u6837\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u644a\u9500\u6269\u6563\u65b9\u6cd5\u867d\u7136\u5feb\u901f\u4f46\u7f3a\u4e4f\u5bf9\u672a\u89c1\u9000\u5316\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\uff0c\u9700\u8981\u5e73\u8861\u6548\u7387\u4e0e\u7075\u6d3b\u6027", "method": "\u901a\u8fc7\u644a\u9500\u53d8\u5206\u6269\u6563\u540e\u9a8c\u91c7\u6837\u4e2d\u51fa\u73b0\u7684\u5185\u90e8\u4f18\u5316\u95ee\u9898\uff0c\u4fdd\u6301\u663e\u5f0f\u4f3c\u7136\u5f15\u5bfc\uff0c\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b", "result": "\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u5185\u9000\u5316\u64cd\u4f5c\u4e0a\u52a0\u901f\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u672a\u89c1\u64cd\u4f5c\u7b26\u7684\u9c81\u68d2\u6027\uff0c\u6539\u5584\u4e86\u6269\u6563\u57fa\u9006\u95ee\u9898\u4e2d\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u7684\u6743\u8861", "conclusion": "\u63d0\u51fa\u7684\u644a\u9500\u7b56\u7565\u6210\u529f\u5e73\u8861\u4e86\u6269\u6563\u540e\u9a8c\u91c7\u6837\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.06980", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06980", "abs": "https://arxiv.org/abs/2602.06980", "authors": ["Nasir Rajpoot", "Richard Haworth", "Xavier Palazzi", "Alok Sharma", "Manu Sebastian", "Stephen Cahalan", "Dinesh S. Bangari", "Radhakrishna Sura", "James Hartke", "Marco Tecilla", "Krishna Yekkala", "Simon Graham", "Dang Vu", "David Snead", "Mostafa Jahanifar", "Adnan Khan", "Erio Barale-Thomas"], "title": "Potential Role of Agentic Artificial Intelligence in Toxicologic Pathology", "comment": null, "summary": "As the volume and complexity of nonclinical toxicology studies continue to increase, toxicologic pathology reporting faces persistent challenges, including fragmented sources of data (e.g., histopathology images, clinical pathology and other study data, adverse effects database, mechanistic literature), variable reporting timelines and heightened regulatory expectations. This white paper examines the emerging role of agentic artificial intelligence (AI) in addressing these issues through coordinated workflow orchestration, data integration, and pathologist-in-the-loop report generation. Based on a closed-door roundtable held during the 2025 Society of Toxicologic Pathology (STP) Annual Meeting and follow-on discussions, this paper synthesizes the perspectives of leading toxicologic pathologists, toxicologists, and AI developers. It outlines the key pain points in current reporting workflows, identifies realistic near-term use cases for agentic AI, and describes major adoption barriers including requirements for transparency, validation, and organizational readiness. A phased adoption roadmap and pilot design considerations are proposed to help support responsible evaluation and deployment of agentic AI system in nonclinical settings. The paper concludes by emphasizing the need for coordinated efforts across pharmaceutical organizations, CROs, academia, and regulators to establish shared standards, benchmarks, and governance frameworks that will lead to safe, transparent, and trustworthy integration of AI into toxicologic science.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u5728\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u62a5\u544a\u4e2d\u7684\u5e94\u7528\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u636e\u788e\u7247\u5316\u3001\u62a5\u544a\u65f6\u95f4\u4e0d\u4e00\u81f4\u548c\u76d1\u7ba1\u8981\u6c42\u63d0\u9ad8\u7b49\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u5206\u9636\u6bb5\u5b9e\u65bd\u8def\u7ebf\u56fe\u3002", "motivation": "\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u62a5\u544a\u9762\u4e34\u6570\u636e\u6765\u6e90\u788e\u7247\u5316\uff08\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u3001\u4e34\u5e8a\u75c5\u7406\u5b66\u6570\u636e\u3001\u4e0d\u826f\u53cd\u5e94\u6570\u636e\u5e93\u7b49\uff09\u3001\u62a5\u544a\u65f6\u95f4\u4e0d\u4e00\u81f4\u4ee5\u53ca\u76d1\u7ba1\u671f\u671b\u63d0\u9ad8\u7b49\u6301\u7eed\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8e2025\u5e74\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u4f1a\u5e74\u4f1a\u95ed\u95e8\u5706\u684c\u4f1a\u8bae\u548c\u540e\u7eed\u8ba8\u8bba\uff0c\u7efc\u5408\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u5bb6\u3001\u6bd2\u7406\u5b66\u5bb6\u548cAI\u5f00\u53d1\u8005\u7684\u89c2\u70b9\uff0c\u5206\u6790\u5f53\u524d\u62a5\u544a\u6d41\u7a0b\u75db\u70b9\uff0c\u786e\u5b9a\u4ee3\u7406AI\u7684\u73b0\u5b9e\u5e94\u7528\u573a\u666f\uff0c\u5e76\u63d0\u51fa\u5206\u9636\u6bb5\u91c7\u7528\u8def\u7ebf\u56fe\u3002", "result": "\u8bc6\u522b\u4e86\u5f53\u524d\u62a5\u544a\u6d41\u7a0b\u7684\u5173\u952e\u75db\u70b9\uff0c\u786e\u5b9a\u4e86\u4ee3\u7406AI\u7684\u8fd1\u671f\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\uff0c\u63cf\u8ff0\u4e86\u5305\u62ec\u900f\u660e\u5ea6\u3001\u9a8c\u8bc1\u548c\u7ec4\u7ec7\u51c6\u5907\u5728\u5185\u7684\u4e3b\u8981\u91c7\u7528\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u5206\u9636\u6bb5\u91c7\u7528\u8def\u7ebf\u56fe\u548c\u8bd5\u70b9\u8bbe\u8ba1\u8003\u8651\u3002", "conclusion": "\u9700\u8981\u5236\u836f\u7ec4\u7ec7\u3001CRO\u3001\u5b66\u672f\u754c\u548c\u76d1\u7ba1\u673a\u6784\u534f\u8c03\u52aa\u529b\uff0c\u5efa\u7acb\u5171\u4eab\u6807\u51c6\u3001\u57fa\u51c6\u548c\u6cbb\u7406\u6846\u67b6\uff0c\u4ee5\u786e\u4fddAI\u5728\u6bd2\u7406\u5b66\u79d1\u5b66\u4e2d\u7684\u5b89\u5168\u3001\u900f\u660e\u548c\u53ef\u4fe1\u96c6\u6210\u3002"}}
{"id": "2602.07178", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07178", "abs": "https://arxiv.org/abs/2602.07178", "authors": ["A. Piunovskiy"], "title": "Constrained optimal impulse control and inventory model", "comment": "29 pages", "summary": "In this article, we consider the deterministic impulsively controlled system with infinite horizon and several discounted objective functionals. The constructed optimal control problem with functional constraints is reformulated as a Markov decision process, leading to (primal) convex and linear programs in the space of so-called occupation measures. We construct the dual programs and investigate the solvability of all the programs. Example of an inventory model illustrates the developed theory.", "AI": {"tldr": "\u7814\u7a76\u65e0\u9650\u65f6\u57df\u6298\u6263\u76ee\u6807\u51fd\u6570\u7684\u786e\u5b9a\u6027\u8109\u51b2\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u8f6c\u5316\u4e3a\u5360\u7528\u6d4b\u5ea6\u7a7a\u95f4\u7684\u51f8\u7ebf\u6027\u89c4\u5212\uff0c\u6784\u5efa\u5bf9\u5076\u89c4\u5212\u5e76\u7814\u7a76\u53ef\u89e3\u6027\uff0c\u7528\u5e93\u5b58\u6a21\u578b\u793a\u4f8b", "motivation": "\u7814\u7a76\u5177\u6709\u65e0\u9650\u65f6\u57df\u548c\u591a\u4e2a\u6298\u6263\u76ee\u6807\u51fd\u6570\u7684\u786e\u5b9a\u6027\u8109\u51b2\u63a7\u5236\u7cfb\u7edf\uff0c\u89e3\u51b3\u5e26\u529f\u80fd\u7ea6\u675f\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898", "method": "\u5c06\u6700\u4f18\u63a7\u5236\u95ee\u9898\u91cd\u6784\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5728\u5360\u7528\u6d4b\u5ea6\u7a7a\u95f4\u5efa\u7acb\uff08\u539f\u59cb\uff09\u51f8\u7ebf\u6027\u89c4\u5212\uff0c\u6784\u5efa\u5bf9\u5076\u89c4\u5212\u5e76\u5206\u6790\u53ef\u89e3\u6027", "result": "\u5efa\u7acb\u4e86\u539f\u59cb\u548c\u5bf9\u5076\u89c4\u5212\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7814\u7a76\u4e86\u89c4\u5212\u7684\u53ef\u89e3\u6027\uff0c\u5e76\u901a\u8fc7\u5e93\u5b58\u6a21\u578b\u793a\u4f8b\u9a8c\u8bc1\u7406\u8bba", "conclusion": "\u6210\u529f\u5c06\u786e\u5b9a\u6027\u8109\u51b2\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u5360\u7528\u6d4b\u5ea6\u7a7a\u95f4\u7684\u51f8\u7ebf\u6027\u89c4\u5212\uff0c\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u5bf9\u5076\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u8fd9\u7c7b\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177"}}
{"id": "2602.07048", "categories": ["q-fin.RM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.07048", "abs": "https://arxiv.org/abs/2602.07048", "authors": ["Sumin Kim", "Minjae Kim", "Jihoon Kwon", "Yoon Kim", "Nicole Kagan", "Joo Won Lee", "Oscar Levy", "Alejandro Lopez-Lira", "Yongjae Lee", "Chanyeol Choi"], "title": "LLM as a Risk Manager: LLM Semantic Filtering for Lead-Lag Trading in Prediction Markets", "comment": "11 pages", "summary": "Prediction markets provide a unique setting where event-level time series are directly tied to natural-language descriptions, yet discovering robust lead-lag relationships remains challenging due to spurious statistical correlations. We propose a hybrid two-stage causal screener to address this challenge: (i) a statistical stage that uses Granger causality to identify candidate leader-follower pairs from market-implied probability time series, and (ii) an LLM-based semantic stage that re-ranks these candidates by assessing whether the proposed direction admits a plausible economic transmission mechanism based on event descriptions. Because causal ground truth is unobserved, we evaluate the ranked pairs using a fixed, signal-triggered trading protocol that maps relationship quality into realized profit and loss (PnL). On Kalshi Economics markets, our hybrid approach consistently outperforms the statistical baseline. Across rolling evaluations, the win rate increases from 51.4% to 54.5%. Crucially, the average magnitude of losing trades decreases substantially from 649 USD to 347 USD. This reduction is driven by the LLM's ability to filter out statistically fragile links that are prone to large losses, rather than relying on rare gains. These improvements remain stable across different trading configurations, indicating that the gains are not driven by specific parameter choices. Overall, the results suggest that LLMs function as semantic risk managers on top of statistical discovery, prioritizing lead-lag relationships that generalize under changing market conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u56e0\u679c\u7b5b\u9009\u5668\uff1a\u7edf\u8ba1\u9636\u6bb5\u7528\u683c\u5170\u6770\u56e0\u679c\u8bc6\u522b\u5019\u9009\uff0cLLM\u8bed\u4e49\u9636\u6bb5\u57fa\u4e8e\u4e8b\u4ef6\u63cf\u8ff0\u91cd\u65b0\u6392\u5e8f\uff0c\u5728\u9884\u6d4b\u5e02\u573a\u4e2d\u63d0\u5347\u4ea4\u6613\u8868\u73b0", "motivation": "\u9884\u6d4b\u5e02\u573a\u7684\u4e8b\u4ef6\u7ea7\u65f6\u95f4\u5e8f\u5217\u4e0e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u76f4\u63a5\u76f8\u5173\uff0c\u4f46\u865a\u5047\u7edf\u8ba1\u76f8\u5173\u6027\u4f7f\u5f97\u53d1\u73b0\u7a33\u5065\u7684\u9886\u5148-\u6ede\u540e\u5173\u7cfb\u5177\u6709\u6311\u6218\u6027", "method": "\u6df7\u5408\u4e24\u9636\u6bb5\u56e0\u679c\u7b5b\u9009\u5668\uff1a1) \u7edf\u8ba1\u9636\u6bb5\u4f7f\u7528\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\u4ece\u5e02\u573a\u9690\u542b\u6982\u7387\u65f6\u95f4\u5e8f\u5217\u8bc6\u522b\u5019\u9009\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u5bf9\uff1b2) LLM\u8bed\u4e49\u9636\u6bb5\u901a\u8fc7\u8bc4\u4f30\u63d0\u8bae\u65b9\u5411\u662f\u5426\u57fa\u4e8e\u4e8b\u4ef6\u63cf\u8ff0\u627f\u8ba4\u5408\u7406\u7684\u7ecf\u6d4e\u4f20\u5bfc\u673a\u5236\u6765\u91cd\u65b0\u6392\u5e8f\u8fd9\u4e9b\u5019\u9009", "result": "\u5728Kalshi Economics\u5e02\u573a\u4e0a\uff0c\u6df7\u5408\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u7edf\u8ba1\u57fa\u7ebf\u3002\u80dc\u7387\u4ece51.4%\u63d0\u9ad8\u523054.5%\uff0c\u4e8f\u635f\u4ea4\u6613\u7684\u5e73\u5747\u5e45\u5ea6\u4ece649\u7f8e\u5143\u5927\u5e45\u964d\u81f3347\u7f8e\u5143\u3002LLM\u80fd\u591f\u8fc7\u6ee4\u6389\u7edf\u8ba1\u4e0a\u8106\u5f31\u3001\u5bb9\u6613\u9020\u6210\u5927\u989d\u4e8f\u635f\u7684\u94fe\u63a5", "conclusion": "LLM\u5728\u7edf\u8ba1\u53d1\u73b0\u4e4b\u4e0a\u5145\u5f53\u8bed\u4e49\u98ce\u9669\u7ba1\u7406\u8005\uff0c\u4f18\u5148\u8003\u8651\u5728\u53d8\u5316\u5e02\u573a\u6761\u4ef6\u4e0b\u80fd\u591f\u6cdb\u5316\u7684\u9886\u5148-\u6ede\u540e\u5173\u7cfb\uff0c\u6539\u8fdb\u5728\u4e0d\u540c\u4ea4\u6613\u914d\u7f6e\u4e2d\u4fdd\u6301\u7a33\u5b9a"}}
{"id": "2602.07238", "categories": ["cs.AI", "cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.07238", "abs": "https://arxiv.org/abs/2602.07238", "authors": ["Matthias Mertens", "Natalia Fischl-Lanzoni", "Neil Thompson"], "title": "Is there \"Secret Sauce'' in Large Language Model Development?", "comment": null, "summary": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790809\u4e2aLLM\u7684\u8bad\u7ec3\u6570\u636e\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u6027\u80fd\u4e3b\u8981\u7531\u8ba1\u7b97\u89c4\u6a21\u9a71\u52a8\uff0c\u800c\u975e\u4e13\u6709\u6280\u672f\uff1b\u4f46\u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u80fd\u663e\u8457\u964d\u4f4e\u8fbe\u5230\u7279\u5b9a\u80fd\u529b\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7a76LLM\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u9a71\u52a8\u529b\uff1a\u662f\u5f00\u53d1\u8005\u7684\u4e13\u6709\u6280\u672f\uff08\"\u79d8\u65b9\"\uff09\u8fd8\u662f\u8ba1\u7b97\u89c4\u6a21\u7684\u6269\u5927\uff1f\u8fd9\u4e2a\u95ee\u9898\u5bf9\u4e8e\u7406\u89e3AI\u9886\u5bfc\u5730\u4f4d\u548c\u6280\u672f\u6269\u6563\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u75282022-2025\u5e74\u95f4\u53d1\u5e03\u7684809\u4e2a\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u57fa\u51c6\u6570\u636e\uff0c\u6784\u5efa\u89c4\u6a21\u5b9a\u5f8b\u56de\u5f52\u6a21\u578b\uff0c\u5305\u542b\u53d1\u5e03\u65e5\u671f\u548c\u5f00\u53d1\u8005\u56fa\u5b9a\u6548\u5e94\uff0c\u5206\u6790\u8ba1\u7b97\u89c4\u6a21\u4e0e\u4e13\u6709\u6280\u672f\u5bf9\u6027\u80fd\u7684\u76f8\u5bf9\u8d21\u732e\u3002", "result": "1. \u5728\u524d\u6cbf\u9886\u57df\uff0c80-90%\u7684\u6027\u80fd\u5dee\u5f02\u7531\u66f4\u9ad8\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\u89e3\u91ca\uff0c\u8868\u660e\u89c4\u6a21\u800c\u975e\u4e13\u6709\u6280\u672f\u9a71\u52a8\u524d\u6cbf\u8fdb\u6b65\uff1b2. \u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u548c\u5171\u4eab\u7b97\u6cd5\u8fdb\u6b65\u663e\u8457\u964d\u4f4e\u8fbe\u5230\u56fa\u5b9a\u80fd\u529b\u9608\u503c\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff1b3. \u67d0\u4e9b\u516c\u53f8\u80fd\u7cfb\u7edf\u6027\u5730\u66f4\u9ad8\u6548\u5730\u751f\u4ea7\u8f83\u5c0f\u6a21\u578b\uff1b4. \u540c\u4e00\u516c\u53f8\u5185\u90e8\u6a21\u578b\u6548\u7387\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff08\u53ef\u8fbe40\u500d\u4ee5\u4e0a\uff09\u3002", "conclusion": "LLM\u6027\u80fd\u63d0\u5347\u7684\u9a71\u52a8\u529b\u53d6\u51b3\u4e8e\u6a21\u578b\u5728\u6027\u80fd\u5206\u5e03\u4e2d\u7684\u4f4d\u7f6e\uff1a\u524d\u6cbf\u8fdb\u6b65\u4e3b\u8981\u7531\u8ba1\u7b97\u89c4\u6a21\u9a71\u52a8\uff0c\u800c\u975e\u4e13\u6709\u6280\u672f\uff1b\u4f46\u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u5bf9\u6548\u7387\u63d0\u5347\u81f3\u5173\u91cd\u8981\u3002\u8fd9\u6697\u793aAI\u9886\u5bfc\u5730\u4f4d\u53ef\u80fd\u66f4\u4f9d\u8d56\u8ba1\u7b97\u8d44\u6e90\uff0c\u800c\u975e\u6280\u672f\u79d8\u5bc6\uff0c\u540c\u65f6\u6280\u672f\u6269\u6563\u53ef\u80fd\u6bd4\u9884\u671f\u66f4\u5feb\u3002"}}
{"id": "2602.06973", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06973", "abs": "https://arxiv.org/abs/2602.06973", "authors": ["Lucky Susanto", "Musa Izzanardi Wijanarko", "Khumaisa Nur'aini", "Farid Adilazuarda", "Alham Fikri Aji", "Derry Tanti Wijaya"], "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models", "comment": "Submitted to ARR January", "summary": "While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.", "AI": {"tldr": "\u50cf\u7d20\u8bed\u8a00\u5efa\u6a21\u901a\u8fc7\u5c06\u6587\u672c\u6e32\u67d3\u4e3a\u56fe\u50cf\u6765\u7ed5\u8fc7\u5b50\u8bcd\u5206\u8bcd\u74f6\u9888\uff0c\u4f46\u591a\u6a21\u6001\u53d8\u4f53\u5982DualGPT\u91cd\u65b0\u5f15\u5165\u6587\u672c\u5206\u8bcd\u5668\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u91c7\u7528\u89c6\u89c9\u6e32\u67d3\uff0c\u91cd\u65b0\u6574\u5408\u6587\u672c\u5206\u8bcd\u5668\u4ecd\u4f1a\u5e26\u6765\u5206\u8bcd\u5668\u5bf9\u9f50\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5370\u5c3c\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u3002", "motivation": "\u7814\u7a76\u50cf\u7d20\u8bed\u8a00\u5efa\u6a21\u662f\u5426\u771f\u6b63\u80fd\u6446\u8131\u5206\u8bcd\u7ea6\u675f\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u53d8\u4f53\u91cd\u65b0\u5f15\u5165\u6587\u672c\u5206\u8bcd\u5668\u7684\u60c5\u51b5\u4e0b\u3002\u5173\u6ce8\u5370\u5c3c\u56db\u79cd\u4f4e\u8d44\u6e90\u672c\u5730\u8bed\u8a00\uff08\u722a\u54c7\u8bed\u3001\u5df4\u5398\u8bed\u3001\u5dfd\u4ed6\u8bed\u3001\u6960\u699c\u8bed\uff09\u7684\u975e\u62c9\u4e01\u6587\u5b57\uff0c\u8bc4\u4f30\u6587\u5b57-\u5206\u8bcd\u5668\u5bf9\u9f50\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528DualGPT\u67b6\u6784\uff0c\u5728\u56db\u79cd\u5370\u5c3c\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u8bc4\u4f30\u4e0d\u540c\u5206\u8bcd\u5668\uff08Llama 2\u5206\u8bcd\u5668\u4e0e\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\uff09\u7684\u6027\u80fd\u3002\u901a\u8fc7\u6bd4\u8f83OOV\uff08\u672a\u767b\u5f55\u8bcd\uff09\u7387\u3001fertility\uff08\u751f\u80b2\u7387\uff09\u548cchrF++\u6307\u6807\u6765\u5206\u6790\u5206\u8bcd\u5668\u5bf9\u9f50\u95ee\u9898\u3002", "result": "\u5c3d\u7ba1Llama 2\u5206\u8bcd\u5668\u5177\u6709\u66f4\u4f4e\u7684OOV\u548cfertility\u7387\uff0c\u4f46\u5176\u6027\u80fd\u663e\u8457\u5dee\u4e8e\u81ea\u5b9a\u4e49\u5206\u8bcd\u5668\uff0cchrF++\u6307\u6807\u63d0\u5347\u9ad8\u8fbe30.15%\u3002\u8fd9\u8868\u660e\u5373\u4f7f\u91c7\u7528\u89c6\u89c9\u6e32\u67d3\uff0c\u91cd\u65b0\u6574\u5408\u6587\u672c\u5206\u8bcd\u5668\u4ecd\u4f1a\u5f15\u5165\u5206\u8bcd\u5668\u5bf9\u9f50\u95ee\u9898\u3002", "conclusion": "\u50cf\u7d20\u8bed\u8a00\u5efa\u6a21\u7684\u591a\u6a21\u6001\u53d8\u4f53\u91cd\u65b0\u5f15\u5165\u6587\u672c\u5206\u8bcd\u5668\u4f1a\u91cd\u73b0\u539f\u672c\u8981\u89e3\u51b3\u7684\u95ee\u9898\u3002\u6587\u672c\u5206\u8bcd\u5668\u4ecd\u7136\u662f\u5b9e\u73b0\u516c\u5e73\u6a21\u578b\u7684\u91cd\u8981\u969c\u788d\uff0c\u672a\u6765\u591a\u6a21\u6001\u53d8\u4f53\u9700\u8981\u8b66\u60d5\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2602.07023", "categories": ["q-fin.TR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07023", "abs": "https://arxiv.org/abs/2602.07023", "authors": ["Zeping Li", "Guancheng Wan", "Keyang Chen", "Yu Chen", "Yiwen Zhao", "Philip Torr", "Guangnan Ye", "Zhenfei Yin", "Hongfeng Chai"], "title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation", "comment": null, "summary": "Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents' behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors are typically classified as fundamental or technical traders, but most simulations fix strategies at initialization, failing to reflect real-world trading dynamics. In this work, we assess whether agents' strategy switching aligns with financial theory, providing a framework for this evaluation. We operationalize four behavioral-finance drivers-loss aversion, herding, wealth differentiation, and price misalignment-as personality traits set via prompting and stored long-term. In year-long simulations, agents process daily price-volume data, trade under a designated style, and reassess their strategy every 10 trading days. We introduce four alignment metrics and use Mann-Whitney U tests to compare agents' style-switching behavior with financial theory. Our results show that recent LLMs' switching behavior is only partially consistent with behavioral-finance theories, highlighting the need for further refinement in aligning agent behavior with financial theory.", "AI": {"tldr": "LLM\u4ee3\u7406\u5728\u80a1\u5e02\u6a21\u62df\u4e2d\u7684\u7b56\u7565\u5207\u6362\u884c\u4e3a\u4e0e\u884c\u4e3a\u91d1\u878d\u7406\u8bba\u4ec5\u90e8\u5206\u4e00\u81f4\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u5347\u6a21\u62df\u6709\u6548\u6027\u3002", "motivation": "\u9a8c\u8bc1LLM\u4ee3\u7406\u5728\u91d1\u878d\u80a1\u5e02\u6a21\u62df\u4e2d\u7684\u884c\u4e3a\u662f\u5426\u4e0e\u771f\u5b9e\u5e02\u573a\u53c2\u4e0e\u8005\u4e00\u81f4\uff0c\u8fd9\u662f\u6a21\u62df\u7ed3\u679c\u6709\u6548\u6027\u7684\u5173\u952e\u3002\u73b0\u6709\u6a21\u62df\u901a\u5e38\u56fa\u5b9a\u4ee3\u7406\u7b56\u7565\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4ea4\u6613\u52a8\u6001\u3002", "method": "\u5c06\u56db\u79cd\u884c\u4e3a\u91d1\u878d\u9a71\u52a8\u56e0\u7d20\uff08\u635f\u5931\u538c\u6076\u3001\u7f8a\u7fa4\u6548\u5e94\u3001\u8d22\u5bcc\u5206\u5316\u3001\u4ef7\u683c\u9519\u4f4d\uff09\u4f5c\u4e3a\u4eba\u683c\u7279\u8d28\u901a\u8fc7\u63d0\u793a\u8bcd\u8bbe\u7f6e\u5e76\u957f\u671f\u5b58\u50a8\u3002\u5728\u4e3a\u671f\u4e00\u5e74\u7684\u6a21\u62df\u4e2d\uff0c\u4ee3\u7406\u5904\u7406\u6bcf\u65e5\u4ef7\u683c-\u6210\u4ea4\u91cf\u6570\u636e\uff0c\u6309\u6307\u5b9a\u98ce\u683c\u4ea4\u6613\uff0c\u6bcf10\u4e2a\u4ea4\u6613\u65e5\u91cd\u65b0\u8bc4\u4f30\u7b56\u7565\u3002\u5f15\u5165\u56db\u4e2a\u5bf9\u9f50\u6307\u6807\u5e76\u4f7f\u7528Mann-Whitney U\u68c0\u9a8c\u6bd4\u8f83\u4ee3\u7406\u98ce\u683c\u5207\u6362\u884c\u4e3a\u4e0e\u91d1\u878d\u7406\u8bba\u3002", "result": "\u8fd1\u671fLLM\u7684\u5207\u6362\u884c\u4e3a\u4ec5\u4e0e\u884c\u4e3a\u91d1\u878d\u7406\u8bba\u90e8\u5206\u4e00\u81f4\uff0c\u8868\u660e\u4ee3\u7406\u884c\u4e3a\u4e0e\u91d1\u878d\u7406\u8bba\u7684\u5bf9\u9f50\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "conclusion": "LLM\u4ee3\u7406\u5728\u91d1\u878d\u6a21\u62df\u4e2d\u7684\u884c\u4e3a\u4e0e\u7406\u8bba\u4ec5\u90e8\u5206\u4e00\u81f4\uff0c\u7a81\u663e\u4e86\u5728\u5c06\u4ee3\u7406\u884c\u4e3a\u4e0e\u91d1\u878d\u7406\u8bba\u5bf9\u9f50\u65b9\u9762\u9700\u8981\u8fdb\u4e00\u6b65\u7ec6\u5316\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.08527", "categories": ["q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.08527", "abs": "https://arxiv.org/abs/2602.08527", "authors": ["Mario Ayala", "Benjamin Vallejo Jim\u00e9nez"], "title": "Consumption-Investment with anticipative noise", "comment": "21 pages", "summary": "We revisit the classical Merton consumption--investment problem when risky-asset returns are modeled by stochastic differential equations interpreted through a general $\u03b1$-integral, interpolating between It\u00f4, Stratonovich, and related conventions. Holding preferences and the investment opportunity set fixed, changing the noise interpretation modifies the effective drift of asset returns in a systematic way.\n  For logarithmic utility and constant volatilities, we derive closed-form optimal policies in a market with $n$ risky assets: optimal consumption remains a fixed fraction of wealth, while optimal portfolio weights are shifted according to $\u03b8_\u03b1^\\ast = V^{-1}(\u03bc-r\\mathbf{1})+\u03b1\\,V^{-1}\\operatorname{diag}(V)\\mathbf{1}$, where $V$ is the return covariance matrix and $\\operatorname{diag}(V)$ denotes the diagonal matrix with the same diagonal as $V$. In the single-asset case this reduces to $\u03b8_\u03b1^\\ast=(\u03bc-r)/\u03c3^{2}+\u03b1$.\n  We then show that genuinely state-dependent effects arise when asset volatility is driven by a stochastic factor correlated with returns. In this setting, the $\u03b1$-interpretation generates an additional drift correction proportional to the instantaneous covariation between factor and return noise. As a canonical example, we analyze a Heston stochastic volatility model, where the resulting optimal risky exposure depends inversely on the current variance level.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86Merton\u6d88\u8d39-\u6295\u8d44\u95ee\u9898\uff0c\u5f53\u98ce\u9669\u8d44\u4ea7\u6536\u76ca\u901a\u8fc7\u4e00\u822c\u03b1-\u79ef\u5206\u5efa\u6a21\u65f6\uff0c\u03b1\u53c2\u6570\u5728It\u00f4\u3001Stratonovich\u7b49\u968f\u673a\u79ef\u5206\u7ea6\u5b9a\u4e4b\u95f4\u63d2\u503c\u3002\u7814\u7a76\u53d1\u73b0\u566a\u58f0\u89e3\u91ca\u7684\u6539\u53d8\u4f1a\u7cfb\u7edf\u6027\u5730\u4fee\u6539\u8d44\u4ea7\u6536\u76ca\u7684\u6709\u6548\u6f02\u79fb\u9879\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u79ef\u5206\u7ea6\u5b9a\uff08\u5982It\u00f4\u4e0eStratonovich\uff09\u7684\u9009\u62e9\u5982\u4f55\u5f71\u54cdMerton\u6d88\u8d39-\u6295\u8d44\u95ee\u9898\u7684\u6700\u4f18\u7b56\u7565\u3002\u4f20\u7edfMerton\u6a21\u578b\u901a\u5e38\u91c7\u7528It\u00f4\u79ef\u5206\uff0c\u4f46\u5176\u4ed6\u79ef\u5206\u7ea6\u5b9a\u5728\u5e94\u7528\u4e2d\u4e5f\u53ef\u80fd\u51fa\u73b0\uff0c\u9700\u8981\u7406\u89e3\u8fd9\u4e9b\u7ea6\u5b9a\u5bf9\u6700\u4f18\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4e00\u822c\u03b1-\u79ef\u5206\u5bf9\u98ce\u9669\u8d44\u4ea7\u6536\u76ca\u5efa\u6a21\uff0c\u8be5\u53c2\u6570\u5728It\u00f4\uff08\u03b1=0\uff09\u548cStratonovich\uff08\u03b1=1/2\uff09\u7b49\u7ea6\u5b9a\u4e4b\u95f4\u63d2\u503c\u3002\u5728\u504f\u597d\u548c\u6295\u8d44\u673a\u4f1a\u96c6\u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u6790\u566a\u58f0\u89e3\u91ca\u5982\u4f55\u6539\u53d8\u8d44\u4ea7\u6536\u76ca\u7684\u6709\u6548\u6f02\u79fb\u3002\u5206\u522b\u8003\u8651\u5bf9\u6570\u6548\u7528\u548c\u5e38\u6570\u6ce2\u52a8\u7387\u60c5\u51b5\uff0c\u4ee5\u53ca\u968f\u673a\u6ce2\u52a8\u7387\u60c5\u51b5\u3002", "result": "1. \u5bf9\u6570\u6548\u7528\u548c\u5e38\u6570\u6ce2\u52a8\u7387\u4e0b\uff1a\u6700\u4f18\u6d88\u8d39\u4ecd\u662f\u8d22\u5bcc\u7684\u56fa\u5b9a\u6bd4\u4f8b\uff0c\u6700\u4f18\u6295\u8d44\u7ec4\u5408\u6743\u91cd\u4e3a\u03b8_\u03b1^* = V^{-1}(\u03bc-r1) + \u03b1V^{-1}diag(V)1\uff0c\u5176\u4e2dV\u662f\u6536\u76ca\u534f\u65b9\u5dee\u77e9\u9635\u3002\u5355\u8d44\u4ea7\u60c5\u51b5\u4e0b\u7b80\u5316\u4e3a\u03b8_\u03b1^* = (\u03bc-r)/\u03c3^2 + \u03b1\u3002\n2. \u968f\u673a\u6ce2\u52a8\u7387\u60c5\u51b5\u4e0b\uff1a\u03b1-\u89e3\u91ca\u4f1a\u4ea7\u751f\u4e0e\u56e0\u5b50\u548c\u6536\u76ca\u566a\u58f0\u77ac\u65f6\u534f\u53d8\u6210\u6bd4\u4f8b\u7684\u989d\u5916\u6f02\u79fb\u4fee\u6b63\u3002\u4ee5Heston\u6a21\u578b\u4e3a\u4f8b\uff0c\u6700\u4f18\u98ce\u9669\u66b4\u9732\u4e0e\u5f53\u524d\u65b9\u5dee\u6c34\u5e73\u6210\u53cd\u6bd4\u3002", "conclusion": "\u968f\u673a\u79ef\u5206\u7ea6\u5b9a\u7684\u9009\u62e9\u4f1a\u663e\u8457\u5f71\u54cdMerton\u95ee\u9898\u7684\u6700\u4f18\u7b56\u7565\u3002\u5728\u5e38\u6570\u6ce2\u52a8\u7387\u60c5\u51b5\u4e0b\uff0c\u5f71\u54cd\u662f\u7cfb\u7edf\u6027\u7684\u6f02\u79fb\u4fee\u6b63\uff1b\u5728\u968f\u673a\u6ce2\u52a8\u7387\u60c5\u51b5\u4e0b\uff0c\u4f1a\u4ea7\u751f\u72b6\u6001\u4f9d\u8d56\u6548\u5e94\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u91d1\u878d\u5efa\u6a21\u4e2d\u660e\u786e\u6307\u5b9a\u968f\u673a\u79ef\u5206\u7ea6\u5b9a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.07032", "categories": ["cs.AI", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07032", "abs": "https://arxiv.org/abs/2602.07032", "authors": ["Yuheng Wu", "Berk Gokmen", "Zhouhua Xie", "Peijing Li", "Caroline Trippel", "Priyanka Raina", "Thierry Tambe"], "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation", "comment": null, "summary": "Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.", "AI": {"tldr": "LLM-FSM\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u6062\u590d\u6709\u9650\u72b6\u6001\u673a\u884c\u4e3a\u5e76\u751f\u6210\u6b63\u786eRTL\u5b9e\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1000\u4e2a\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\uff0c\u663e\u793aLLM\u5728FSM\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u6027\u6025\u5267\u4e0b\u964d\u3002", "motivation": "\u6709\u9650\u72b6\u6001\u63a8\u7406\u662f\u786c\u4ef6\u8bbe\u8ba1\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u9700\u8981\u8bc4\u4f30LLM\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u6062\u590d\u6709\u9650\u72b6\u6001\u673a\u884c\u4e3a\u5e76\u751f\u6210\u6b63\u786eRTL\u5b9e\u73b0\u7684\u80fd\u529b\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u4eba\u5de5\u6784\u5efa\u793a\u4f8b\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u901a\u8fc7\u5168\u81ea\u52a8\u7ba1\u9053\u6784\u5efaLLM-FSM\u57fa\u51c6\uff1a1) \u6784\u5efa\u5177\u6709\u53ef\u914d\u7f6e\u72b6\u6001\u6570\u548c\u7ea6\u675f\u8f6c\u79fb\u7ed3\u6784\u7684FSM\uff1b2) \u63d0\u793aLLM\u5c06FSM\u8868\u8fbe\u4e3a\u7ed3\u6784\u5316YAML\u683c\u5f0f\u5e76\u6dfb\u52a0\u5e94\u7528\u4e0a\u4e0b\u6587\uff1b3) \u5c06YAML\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u89c4\u8303\uff1b4) \u4ece\u76f8\u540cYAML\u4ee5\u6784\u9020\u6b63\u786e\u7684\u65b9\u5f0f\u5408\u6210\u53c2\u8003RTL\u548c\u6d4b\u8bd5\u5e73\u53f0\uff1b5) \u4f7f\u7528LLM\u548cSAT\u6c42\u89e3\u5668\u68c0\u67e5\u9a8c\u8bc1\u6240\u67091000\u4e2a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5373\u4f7f\u6700\u5f3a\u7684LLM\u5728FSM\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u6027\u4e5f\u6025\u5267\u4e0b\u964d\u3002\u76d1\u7763\u5fae\u8c03\u80fd\u6709\u6548\u6cdb\u5316\u5230\u5206\u5e03\u5916\u4efb\u52a1\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u3002LLM-FSM\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u5176FSM\u590d\u6742\u5ea6\u53ef\u968f\u672a\u6765\u6a21\u578b\u80fd\u529b\u6269\u5c55\u3002", "conclusion": "LLM-FSM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u6709\u9650\u72b6\u6001\u673a\u63a8\u7406\u548cRTL\u5b9e\u73b0\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u590d\u6742FSM\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u6539\u8fdb\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.06993", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06993", "abs": "https://arxiv.org/abs/2602.06993", "authors": ["Shashank"], "title": "Attractor Patch Networks: Reducing Catastrophic Forgetting with Routed Low-Rank Patch Experts", "comment": "9 pages. Code (APN implementation in nanoGPT transformer): https://github.com/shankch/nanoGPT-apn (baseline: https://github.com/karpathy/nanoGPT) Data prep: https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare_char and https://github.com/karpathy/nanoGPT/tree/master/data/shakespeare", "summary": "Transformers achieve strong language modeling accuracy, yet their position-wise feed-forward networks (FFNs) are dense, globally shared, and typically updated end to end. These properties create two practical tensions. First, dense FFNs spend the same compute on every token regardless of context, and they allocate capacity uniformly even when language exhibits highly clustered context structure. Second, continual learning, in the sense of updating the model while serving a data stream, often produces interference because a small update touches broadly shared weights.\n  We propose Attractor Patch Networks (APN), a plug-compatible replacement for the Transformer FFN. APN is a bank of patch experts. A similarity router selects a small top-k set of patches for each token by matching the token representation to learned prototypes. Each selected patch emits a low-rank residual update conditioned on a compact code. The architecture yields conditional, context-specialized nonlinear transformations while preserving the standard Transformer interface.\n  This paper focuses on APN as an architectural primitive. We formalize APN, analyze its expressivity as a piecewise low-rank residual function class, and derive simple interference and stability arguments that make APN naturally compatible with continual learning. In experiments on character-level language modeling, APN achieves competitive perplexity (4.57 vs 4.32 PPL) while enabling dramatically better continual adaptation: when adapting to a shifted domain, APN achieves 2.6 times better retention (11.1 vs 29.4 PPL on the original domain) and 2.8 times better adaptation (6.4 vs 17.8 PPL on the new domain) compared to global fine-tuning of a dense FFN baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAttractor Patch Networks (APN)\u4f5c\u4e3aTransformer FFN\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u76f8\u4f3c\u6027\u8def\u7531\u9009\u62e9top-k\u8865\u4e01\u4e13\u5bb6\uff0c\u5b9e\u73b0\u6761\u4ef6\u5316\u3001\u4e0a\u4e0b\u6587\u7279\u5316\u7684\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u8bed\u8a00\u5efa\u6a21\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfTransformer\u7684FFN\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u5bf9\u6240\u6709token\u4f7f\u7528\u76f8\u540c\u8ba1\u7b97\u91cf\uff0c\u65e0\u6cd5\u6839\u636e\u4e0a\u4e0b\u6587\u7ed3\u6784\u7075\u6d3b\u5206\u914d\u5bb9\u91cf\uff1b2) \u6301\u7eed\u5b66\u4e60\u65f6\u6743\u91cd\u66f4\u65b0\u4f1a\u4ea7\u751f\u5e7f\u6cdb\u5e72\u6270\uff0c\u56e0\u4e3a\u5c0f\u66f4\u65b0\u4f1a\u5f71\u54cd\u5230\u5168\u5c40\u5171\u4eab\u7684\u6743\u91cd\u3002", "method": "\u63d0\u51faAPN\u4f5c\u4e3aTransformer FFN\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5305\u542b\u8865\u4e01\u4e13\u5bb6\u5e93\u548c\u76f8\u4f3c\u6027\u8def\u7531\u5668\u3002\u8def\u7531\u5668\u901a\u8fc7\u5339\u914dtoken\u8868\u793a\u4e0e\u5b66\u4e60\u5230\u7684\u539f\u578b\u6765\u9009\u62e9top-k\u8865\u4e01\uff0c\u6bcf\u4e2a\u9009\u4e2d\u7684\u8865\u4e01\u57fa\u4e8e\u7d27\u51d1\u4ee3\u7801\u751f\u6210\u4f4e\u79e9\u6b8b\u5dee\u66f4\u65b0\uff0c\u5b9e\u73b0\u6761\u4ef6\u5316\u3001\u4e0a\u4e0b\u6587\u7279\u5316\u7684\u975e\u7ebf\u6027\u53d8\u6362\u3002", "result": "\u5728\u5b57\u7b26\u7ea7\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0cAPN\u8fbe\u5230\u7ade\u4e89\u6027\u7684\u56f0\u60d1\u5ea6\uff084.57 vs 4.32 PPL\uff09\u3002\u5728\u6301\u7eed\u9002\u5e94\u4efb\u52a1\u4e2d\uff0c\u5f53\u9002\u5e94\u5230\u504f\u79fb\u9886\u57df\u65f6\uff0cAPN\u76f8\u6bd4\u5bc6\u96c6FFN\u57fa\u7ebf\uff1a\u5728\u539f\u59cb\u9886\u57df\u4e0a\u4fdd\u6301\u80fd\u529b\u63d0\u9ad82.6\u500d\uff0811.1 vs 29.4 PPL\uff09\uff0c\u5728\u65b0\u9886\u57df\u4e0a\u9002\u5e94\u80fd\u529b\u63d0\u9ad82.8\u500d\uff086.4 vs 17.8 PPL\uff09\u3002", "conclusion": "APN\u4f5c\u4e3a\u4e00\u79cd\u67b6\u6784\u539f\u8bed\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u3001\u4e0a\u4e0b\u6587\u7279\u5316\u7684\u975e\u7ebf\u6027\u53d8\u6362\uff0c\u5728\u4fdd\u6301\u6807\u51c6Transformer\u63a5\u53e3\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u5bc6\u96c6FFN\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u548c\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5e72\u6270\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9002\u5e94\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.07377", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07377", "abs": "https://arxiv.org/abs/2602.07377", "authors": ["Xinyue Bei", "Manu Navjeevan"], "title": "Inference under First-Order Degeneracy", "comment": null, "summary": "We study inference in models where a transformation of parameters exhibits first-order degeneracy -- that is, its gradient is zero or close to zero, making the standard delta method invalid. A leading example is causal mediation analysis, where the indirect effect is a product of coefficients and the gradient degenerates near the origin. In these local regions of degeneracy the limiting behaviors of plug-in estimators depend on nuisance parameters that are not consistently estimable. We show that this failure is intrinsic -- around points of degeneracy, both regular and quantile-unbiased estimation are impossible. Despite these restrictions, we develop minimum-distance methods that deliver uniformly valid confidence intervals. We establish sufficient conditions under which standard chi-square critical values remain valid, and propose a simple bootstrap procedure when they are not. We demonstrate favorable power in simulations and in an empirical application linking teacher gender attitudes to student outcomes.", "AI": {"tldr": "\u7814\u7a76\u53c2\u6570\u53d8\u6362\u5b58\u5728\u4e00\u9636\u9000\u5316\uff08\u68af\u5ea6\u4e3a\u96f6\u6216\u63a5\u8fd1\u96f6\uff09\u65f6\u7684\u63a8\u65ad\u95ee\u9898\uff0c\u4ee5\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u4e2d\u7684\u95f4\u63a5\u6548\u5e94\uff08\u7cfb\u6570\u4e58\u79ef\uff09\u4e3a\u4f8b\uff0c\u63d0\u51fa\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4", "motivation": "\u5f53\u53c2\u6570\u53d8\u6362\u5b58\u5728\u4e00\u9636\u9000\u5316\u65f6\uff08\u68af\u5ea6\u4e3a\u96f6\u6216\u63a5\u8fd1\u96f6\uff09\uff0c\u6807\u51c6\u7684delta\u65b9\u6cd5\u5931\u6548\u3002\u5728\u9000\u5316\u533a\u57df\u9644\u8fd1\uff0c\u63d2\u503c\u4f30\u8ba1\u91cf\u7684\u6781\u9650\u884c\u4e3a\u4f9d\u8d56\u4e8e\u65e0\u6cd5\u4e00\u81f4\u4f30\u8ba1\u7684\u5197\u4f59\u53c2\u6570\uff0c\u5bfc\u81f4\u5e38\u89c4\u63a8\u65ad\u65b9\u6cd5\u5931\u8d25", "method": "\u5f00\u53d1\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\u3002\u5efa\u7acb\u6807\u51c6\u5361\u65b9\u4e34\u754c\u503c\u4fdd\u6301\u6709\u6548\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u7b80\u5355\u7684bootstrap\u7a0b\u5e8f\u7528\u4e8e\u4e0d\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\u7684\u60c5\u51b5", "result": "\u8bc1\u660e\u4e86\u5728\u9000\u5316\u70b9\u9644\u8fd1\uff0c\u6b63\u5219\u4f30\u8ba1\u548c\u5206\u4f4d\u6570\u65e0\u504f\u4f30\u8ba1\u90fd\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u4f46\u63d0\u51fa\u7684\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u8bc1\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u529f\u6548", "conclusion": "\u5c3d\u7ba1\u5728\u53c2\u6570\u9000\u5316\u533a\u57df\u5b58\u5728\u56fa\u6709\u7684\u63a8\u65ad\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u53ef\u4ee5\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4e3a\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u7b49\u5b58\u5728\u4e00\u9636\u9000\u5316\u95ee\u9898\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63a8\u65ad\u5de5\u5177"}}
{"id": "2602.07360", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07360", "abs": "https://arxiv.org/abs/2602.07360", "authors": ["Linyu Lin"], "title": "In-Context System Identification for Nonlinear Dynamics Using Large Language Models", "comment": "6 pages, 5 figures, submitted to The 10th IEEE Conference on Control Technology and Applications (CCTA) 2026", "summary": "Sparse Identification of Nonlinear Dynamics (SINDy) is a powerful method for discovering parsimonious governing equations from data, but it often requires expert tuning of candidate libraries. We propose an LLM-aided SINDy pipeline that iteratively refines candidate equations using a large language model (LLM) in the loop through in-context learning. The pipeline begins with a baseline SINDy model fit using an adaptive library and then enters a LLM-guided refinement cycle. At each iteration, the current best equations, error metrics, and domain-specific constraints are summarized in a prompt to the LLM, which suggests new equation structures. These candidate equations are parsed against a defined symbolic form and evaluated on training and test data. The pipeline uses simulation-based error as a primary metric, but also assesses structural similarity to ground truth, including matching functional forms, key terms, couplings, qualitative behavior. An iterative stopping criterion ends refinement early if test error falls below a threshold (NRMSE < 0.1) or if a maximum of 10 iterations is reached. Finally, the best model is selected, and we evaluate this LLM-aided SINDy on 63 dynamical system datasets (ODEBench) and march leuba model for boiling nuclear reactor. The results are compared against classical SINDy and show the LLM-loop consistently improves symbolic recovery with higher equation similarity to ground truth and lower test RMSE than baseline SINDy for cases with complex dynamics. This work demonstrates that an LLM can effectively guide SINDy's search through equation space, integrating data-driven error feedback with domain-inspired symbolic reasoning to discover governing equations that are not only accurate but also structurally interpretable.", "AI": {"tldr": "\u63d0\u51faLLM\u8f85\u52a9\u7684SINDy\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u8fed\u4ee3\u4f18\u5316\u5019\u9009\u65b9\u7a0b\u5e93\uff0c\u572863\u4e2a\u52a8\u529b\u7cfb\u7edf\u6570\u636e\u96c6\u4e0a\u6bd4\u4f20\u7edfSINDy\u83b7\u5f97\u66f4\u9ad8\u7b26\u53f7\u6062\u590d\u7387\u548c\u66f4\u4f4e\u6d4b\u8bd5\u8bef\u5dee", "motivation": "\u4f20\u7edfSINDy\u65b9\u6cd5\u9700\u8981\u4e13\u5bb6\u624b\u52a8\u8c03\u6574\u5019\u9009\u65b9\u7a0b\u5e93\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u81ea\u52a8\u5316\u548c\u9002\u7528\u6027\u3002\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u7684\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u81ea\u52a8\u4f18\u5316SINDy\u7684\u65b9\u7a0b\u641c\u7d22\u8fc7\u7a0b", "method": "\u6784\u5efaLLM\u8f85\u52a9\u7684SINDy\u7ba1\u9053\uff1a1) \u4f7f\u7528\u81ea\u9002\u5e94\u5e93\u62df\u5408\u57fa\u7ebfSINDy\u6a21\u578b\uff1b2) LLM\u5f15\u5bfc\u7684\u8fed\u4ee3\u4f18\u5316\u5faa\u73af\uff1a\u5c06\u5f53\u524d\u6700\u4f73\u65b9\u7a0b\u3001\u8bef\u5dee\u6307\u6807\u548c\u9886\u57df\u7ea6\u675f\u603b\u7ed3\u4e3a\u63d0\u793a\uff0cLLM\u5efa\u8bae\u65b0\u65b9\u7a0b\u7ed3\u6784\uff1b3) \u89e3\u6790\u5e76\u8bc4\u4f30\u5019\u9009\u65b9\u7a0b\uff1b4) \u4f7f\u7528\u6a21\u62df\u8bef\u5dee\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff1b5) \u8fed\u4ee3\u505c\u6b62\u6761\u4ef6\uff08NRMSE<0.1\u6216\u6700\u591a10\u6b21\u8fed\u4ee3\uff09", "result": "\u572863\u4e2a\u52a8\u529b\u7cfb\u7edf\u6570\u636e\u96c6\uff08ODEBench\uff09\u548c\u6cb8\u817e\u6838\u53cd\u5e94\u5806\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cLLM\u8f85\u52a9SINDy\u76f8\u6bd4\u4f20\u7edfSINDy\uff1a1) \u7b26\u53f7\u6062\u590d\u7387\u66f4\u9ad8\uff1b2) \u65b9\u7a0b\u4e0e\u771f\u5b9e\u7ed3\u6784\u7684\u76f8\u4f3c\u6027\u66f4\u9ad8\uff1b3) \u6d4b\u8bd5RMSE\u66f4\u4f4e\uff1b4) \u5bf9\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u6548\u679c\u66f4\u660e\u663e", "conclusion": "LLM\u80fd\u6709\u6548\u6307\u5bfcSINDy\u5728\u65b9\u7a0b\u7a7a\u95f4\u4e2d\u7684\u641c\u7d22\uff0c\u5c06\u6570\u636e\u9a71\u52a8\u7684\u8bef\u5dee\u53cd\u9988\u4e0e\u9886\u57df\u542f\u53d1\u7684\u7b26\u53f7\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u53d1\u73b0\u65e2\u51c6\u786e\u53c8\u7ed3\u6784\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u65b9\u7a0b"}}
{"id": "2602.07020", "categories": ["q-fin.ST", "cs.LG", "q-fin.CP", "q-fin.PM"], "pdf": "https://arxiv.org/pdf/2602.07020", "abs": "https://arxiv.org/abs/2602.07020", "authors": ["Amin Haeri", "Mahdi Ghelichi", "Nishant Agrawal", "David Li", "Catalina Gomez Sanchez"], "title": "Financial Bond Similarity Search Using Representation Learning", "comment": "22 pages, 18 figures, 1 table", "summary": "Finding similar bonds remains challenging in fixed-income analytics, as numerical financial attributes often overshadow categorical non-financial ones such as issuer sector and domicile. This paper shows that these categorical attributes dominate the predictability of spread curves and proposes embedding models to capture their semantic similarities, outperforming one-hot and many other baselines. Evaluated via sparse-issuer augmentation, the approach improves risk modeling and curve construction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5d4c\u5165\u6a21\u578b\u6355\u6349\u503a\u5238\u5206\u7c7b\u5c5e\u6027\uff08\u5982\u53d1\u884c\u4eba\u884c\u4e1a\u548c\u6ce8\u518c\u5730\uff09\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u4ee5\u6539\u8fdb\u503a\u5238\u76f8\u4f3c\u6027\u5206\u6790\u548c\u5229\u5dee\u66f2\u7ebf\u9884\u6d4b\uff0c\u4f18\u4e8e\u72ec\u70ed\u7f16\u7801\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728\u56fa\u5b9a\u6536\u76ca\u5206\u6790\u4e2d\uff0c\u5bfb\u627e\u76f8\u4f3c\u503a\u5238\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6570\u503c\u91d1\u878d\u5c5e\u6027\u5e38\u5e38\u63a9\u76d6\u4e86\u53d1\u884c\u4eba\u884c\u4e1a\u3001\u6ce8\u518c\u5730\u7b49\u5206\u7c7b\u975e\u91d1\u878d\u5c5e\u6027\u3002\u8fd9\u4e9b\u5206\u7c7b\u5c5e\u6027\u5bf9\u5229\u5dee\u66f2\u7ebf\u7684\u53ef\u9884\u6d4b\u6027\u5177\u6709\u4e3b\u5bfc\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u6355\u6349\u5176\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "method": "\u63d0\u51fa\u5d4c\u5165\u6a21\u578b\u6765\u6355\u6349\u5206\u7c7b\u5c5e\u6027\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u7a00\u758f\u53d1\u884c\u4eba\u589e\u5f3a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u98ce\u9669\u5efa\u6a21\u548c\u66f2\u7ebf\u6784\u5efa\u3002", "result": "\u5d4c\u5165\u6a21\u578b\u5728\u6355\u6349\u5206\u7c7b\u5c5e\u6027\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u9762\u4f18\u4e8e\u72ec\u70ed\u7f16\u7801\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u6539\u8fdb\u5229\u5dee\u66f2\u7ebf\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u53d1\u884c\u4eba\u589e\u5f3a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5206\u7c7b\u975e\u91d1\u878d\u5c5e\u6027\u5728\u503a\u5238\u5229\u5dee\u66f2\u7ebf\u9884\u6d4b\u4e2d\u8d77\u4e3b\u5bfc\u4f5c\u7528\uff0c\u5d4c\u5165\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u8fd9\u4e9b\u5c5e\u6027\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u4e3a\u56fa\u5b9a\u6536\u76ca\u5206\u6790\u4e2d\u7684\u76f8\u4f3c\u503a\u5238\u67e5\u627e\u3001\u98ce\u9669\u5efa\u6a21\u548c\u66f2\u7ebf\u6784\u5efa\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2602.07132", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07132", "abs": "https://arxiv.org/abs/2602.07132", "authors": ["Oswin So", "Brian Karrer", "Chuchu Fan", "Ricky T. Q. Chen", "Guan-Horng Liu"], "title": "Discrete Adjoint Matching", "comment": "ICLR 2026", "summary": "Computation methods for solving entropy-regularized reward optimization -- a class of problems widely used for fine-tuning generative models -- have advanced rapidly. Among those, Adjoint Matching (AM, Domingo-Enrich et al., 2025) has proven highly effective in continuous state spaces with differentiable rewards. Transferring these practical successes to discrete generative modeling, however, remains particularly challenging and largely unexplored, mainly due to the drastic shift in generative model classes to discrete state spaces, which are nowhere differentiable. In this work, we propose Discrete Adjoint Matching (DAM) -- a discrete variant of AM for fine-tuning discrete generative models characterized by Continuous-Time Markov Chains, such as diffusion-based large language models. The core of DAM is the introduction of discrete adjoint-an estimator of the optimal solution to the original problem but formulated on discrete domains-from which standard matching frameworks can be applied. This is derived via a purely statistical standpoint, in contrast to the control-theoretic viewpoint in AM, thereby opening up new algorithmic opportunities for general adjoint-based estimators. We showcase DAM's effectiveness on synthetic and mathematical reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u79bb\u6563\u4f34\u968f\u5339\u914d\uff08DAM\uff09\uff0c\u7528\u4e8e\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\uff08\u5982\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff09\u4e2d\u5fae\u8c03\u751f\u6210\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u8fde\u7eed\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u79bb\u6563\u57df\u7684\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u71b5\u6b63\u5219\u5316\u5956\u52b1\u4f18\u5316\u7684\u8ba1\u7b97\u65b9\u6cd5\u5728\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u4e2d\u8fdb\u5c55\u8fc5\u901f\uff0c\u4f46\u5c06\u8fd9\u4e9b\u6210\u529f\u8f6c\u79fb\u5230\u79bb\u6563\u751f\u6210\u5efa\u6a21\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u4e14\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u4e3b\u8981\u56e0\u4e3a\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e0d\u53ef\u5fae\u5206\u3002", "method": "\u63d0\u51fa\u79bb\u6563\u4f34\u968f\u5339\u914d\uff08DAM\uff09\uff0c\u901a\u8fc7\u7edf\u8ba1\u89c6\u89d2\u5f15\u5165\u79bb\u6563\u4f34\u968f\u2014\u2014\u539f\u59cb\u95ee\u9898\u6700\u4f18\u89e3\u7684\u79bb\u6563\u57df\u4f30\u8ba1\u5668\uff0c\u4f7f\u6807\u51c6\u5339\u914d\u6846\u67b6\u80fd\u591f\u5e94\u7528\u4e8e\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u8868\u5f81\u7684\u79bb\u6563\u751f\u6210\u6a21\u578b\u3002", "result": "\u5728\u5408\u6210\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86DAM\u7684\u6709\u6548\u6027\u3002", "conclusion": "DAM\u6210\u529f\u5c06\u4f34\u968f\u5339\u914d\u65b9\u6cd5\u6269\u5c55\u5230\u79bb\u6563\u751f\u6210\u6a21\u578b\uff0c\u4e3a\u57fa\u4e8e\u4f34\u968f\u7684\u4f30\u8ba1\u5668\u5f00\u8f9f\u4e86\u65b0\u7684\u7b97\u6cd5\u673a\u4f1a\u3002"}}
{"id": "2602.06981", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06981", "abs": "https://arxiv.org/abs/2602.06981", "authors": ["Ankolika De", "Gabriel Lima", "Yixin Zou"], "title": "What is Safety? Corporate Discourse, Power, and the Politics of Generative AI Safety", "comment": "18 pages, 2 tables", "summary": "This work examines how leading generative artificial intelligence companies construct and communicate the concept of \"safety\" through public-facing documents. Drawing on critical discourse analysis, we analyze a corpus of corporate safety-related statements to explicate how authority, responsibility, and legitimacy are discursively established. These discursive strategies consolidate legitimacy for corporate actors, normalize safety as an experimental and anticipatory practice, and push a perceived participatory agenda toward safe technologies. We argue that uncritical uptake of these discourses risks reproducing corporate priorities and constraining alternative approaches to governance and design. The contribution of this work is twofold: first, to situate safety as a sociotechnical discourse that warrants critical examination; second, to caution human-computer interaction scholars against legitimizing corporate framings, instead foregrounding accountability, equity, and justice. By interrogating safety discourses as artifacts of power, this paper advances a critical agenda for human-computer interaction scholarship on artificial intelligence.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6279\u5224\u6027\u5206\u6790AI\u516c\u53f8\u5982\u4f55\u901a\u8fc7\u516c\u5f00\u6587\u4ef6\u6784\u5efa\"\u5b89\u5168\"\u8bdd\u8bed\uff0c\u63ed\u793a\u5176\u5982\u4f55\u5efa\u7acb\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\uff0c\u5e76\u8b66\u544a\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u8fd9\u4e9b\u8bdd\u8bed\u4f1a\u9650\u5236\u66ff\u4ee3\u6027\u6cbb\u7406\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793a\u9886\u5148\u7684\u751f\u6210\u5f0fAI\u516c\u53f8\u5982\u4f55\u901a\u8fc7\u516c\u5f00\u6587\u4ef6\u6784\u5efa\u548c\u4f20\u8fbe\"\u5b89\u5168\"\u6982\u5ff5\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u8bdd\u8bed\u5982\u4f55\u5f71\u54cd\u6cbb\u7406\u548c\u8bbe\u8ba1\u65b9\u6cd5\u3002\u4f5c\u8005\u5173\u6ce8\u4f01\u4e1a\u5982\u4f55\u901a\u8fc7\u8bdd\u8bed\u7b56\u7565\u5efa\u7acb\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\u3002", "method": "\u91c7\u7528\u6279\u5224\u6027\u8bdd\u8bed\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u6790\u4f01\u4e1a\u5b89\u5168\u76f8\u5173\u58f0\u660e\u7684\u8bed\u6599\u5e93\uff0c\u9610\u91ca\u4f01\u4e1a\u5982\u4f55\u901a\u8fc7\u8bdd\u8bed\u7b56\u7565\u5efa\u7acb\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u4f01\u4e1a\u8bdd\u8bed\u7b56\u7565\u5de9\u56fa\u4e86\u4f01\u4e1a\u884c\u4e3a\u8005\u7684\u5408\u6cd5\u6027\uff1b2) \u5c06\u5b89\u5168\u89c4\u8303\u5316\u4e3a\u5b9e\u9a8c\u6027\u548c\u9884\u671f\u6027\u5b9e\u8df5\uff1b3) \u63a8\u52a8\u611f\u77e5\u4e0a\u7684\u53c2\u4e0e\u5f0f\u8bae\u7a0b\u3002\u8fd9\u4e9b\u7b56\u7565\u4f7f\u4f01\u4e1a\u4f18\u5148\u4e8b\u9879\u5f97\u4ee5\u590d\u5236\uff0c\u5e76\u9650\u5236\u4e86\u66ff\u4ee3\u6027\u6cbb\u7406\u548c\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\uff1a1) \u5e94\u5c06\u5b89\u5168\u89c6\u4e3a\u9700\u8981\u6279\u5224\u6027\u5ba1\u89c6\u7684\u793e\u4f1a\u6280\u672f\u8bdd\u8bed\uff1b2) \u8b66\u544a\u4eba\u673a\u4ea4\u4e92\u5b66\u8005\u4e0d\u5e94\u5408\u6cd5\u5316\u4f01\u4e1a\u6846\u67b6\uff0c\u800c\u5e94\u5f3a\u8c03\u95ee\u8d23\u5236\u3001\u516c\u5e73\u548c\u6b63\u4e49\uff1b3) \u901a\u8fc7\u5c06\u5b89\u5168\u8bdd\u8bed\u4f5c\u4e3a\u6743\u529b\u4ea7\u7269\u8fdb\u884c\u5ba1\u89c6\uff0c\u63a8\u8fdb\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u5bf9AI\u7684\u6279\u5224\u6027\u8bae\u7a0b\u3002"}}
{"id": "2602.07196", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07196", "abs": "https://arxiv.org/abs/2602.07196", "authors": ["Weijian Li", "Panos J. Antsaklis", "Hai Lin"], "title": "Primal-dual algorithm for distributed optimization: A dissipativity-based perspective", "comment": null, "summary": "We study a continuous-time primal-dual algorithm for distributed optimization with nonconvex local cost functions over weight-unbalanced digraphs, and analyze its performance from a dissipativity-based perspective. We first reformulate the algorithm as a Lure type system, consisting of a linear subsystem that relies on the communication topology and the algorithm gains, and a static nonlinear gradient feedback. We then show that the linear subsystem is dissipative with respect to a suitable supply rate, while the nonlinear feedback is not passive. Finally, we establish that, by properly selecting the gains or appropriately designing the communication network, this algorithm converges to an equilibrium at an exponential rate, and thus, achieves an optimal solution to the distributed problem. This work provides new insights into the roles of the network topology, algorithm gains, and cost functions in the performance of a distributed algorithm, and complements existing results from a different viewpoint.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u7528\u4e8e\u975e\u51f8\u5206\u5e03\u5f0f\u4f18\u5316\u7684\u8fde\u7eed\u65f6\u95f4\u539f\u59cb-\u5bf9\u5076\u7b97\u6cd5\uff0c\u4ece\u8017\u6563\u6027\u89d2\u5ea6\u5206\u6790\u5176\u5728\u6743\u91cd\u4e0d\u5e73\u8861\u6709\u5411\u56fe\u4e0a\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u9002\u5f53\u9009\u62e9\u589e\u76ca\u6216\u8bbe\u8ba1\u901a\u4fe1\u7f51\u7edc\u53ef\u5b9e\u73b0\u6307\u6570\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002", "motivation": "\u7814\u7a76\u5728\u6743\u91cd\u4e0d\u5e73\u8861\u6709\u5411\u56fe\u4e0a\u8fdb\u884c\u975e\u51f8\u5206\u5e03\u5f0f\u4f18\u5316\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4ece\u51f8\u4f18\u5316\u89d2\u5ea6\u5206\u6790\uff0c\u9700\u8981\u4ece\u8017\u6563\u6027\u7406\u8bba\u8fd9\u4e00\u4e0d\u540c\u89c6\u89d2\u6765\u7406\u89e3\u7b97\u6cd5\u6027\u80fd\u4e0e\u7f51\u7edc\u62d3\u6251\u3001\u7b97\u6cd5\u589e\u76ca\u548c\u6210\u672c\u51fd\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5c06\u7b97\u6cd5\u91cd\u65b0\u8868\u8ff0\u4e3aLure\u578b\u7cfb\u7edf\uff0c\u5305\u542b\u4f9d\u8d56\u901a\u4fe1\u62d3\u6251\u548c\u7b97\u6cd5\u589e\u76ca\u7684\u7ebf\u6027\u5b50\u7cfb\u7edf\uff0c\u4ee5\u53ca\u9759\u6001\u975e\u7ebf\u6027\u68af\u5ea6\u53cd\u9988\u3002\u8bc1\u660e\u7ebf\u6027\u5b50\u7cfb\u7edf\u76f8\u5bf9\u4e8e\u9002\u5f53\u4f9b\u7ed9\u7387\u662f\u8017\u6563\u7684\uff0c\u800c\u975e\u7ebf\u6027\u53cd\u9988\u4e0d\u662f\u88ab\u52a8\u7684\u3002\u901a\u8fc7\u9002\u5f53\u9009\u62e9\u589e\u76ca\u6216\u8bbe\u8ba1\u901a\u4fe1\u7f51\u7edc\u6765\u4fdd\u8bc1\u6536\u655b\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u4ee5\u6307\u6570\u901f\u7387\u6536\u655b\u5230\u5747\u8861\u70b9\uff0c\u4ece\u800c\u83b7\u5f97\u5206\u5e03\u5f0f\u95ee\u9898\u7684\u6700\u4f18\u89e3\u3002\u4e3a\u7406\u89e3\u7f51\u7edc\u62d3\u6251\u3001\u7b97\u6cd5\u589e\u76ca\u548c\u6210\u672c\u51fd\u6570\u5728\u5206\u5e03\u5f0f\u7b97\u6cd5\u6027\u80fd\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "conclusion": "\u4ece\u8017\u6563\u6027\u89d2\u5ea6\u4e3a\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u8865\u5145\u4e86\u73b0\u6709\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u901a\u8fc7\u9002\u5f53\u8bbe\u8ba1\u7f51\u7edc\u6216\u9009\u62e9\u53c2\u6570\u53ef\u5b9e\u73b0\u975e\u51f8\u95ee\u9898\u5728\u6743\u91cd\u4e0d\u5e73\u8861\u6709\u5411\u56fe\u4e0a\u7684\u6307\u6570\u6536\u655b\u3002"}}
{"id": "2602.07066", "categories": ["q-fin.RM", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.07066", "abs": "https://arxiv.org/abs/2602.07066", "authors": ["Marc Schmitt"], "title": "Algorithmic Monitoring: Measuring Market Stress with Machine Learning", "comment": null, "summary": "I construct a Market Stress Probability Index (MSPI) that estimates the probability of high stress in the U.S. equity market one month ahead using information from the cross-section of individual stocks. Using CRSP daily data, each month is summarized by a set of interpretable cross-sectional fragility signals and mapped into a forward-looking stress probability via an L1-regularized logistic regression in a real-time expanding-window design. Out of sample, MSPI tracks major stress episodes and improves discrimination and accuracy relative to a parsimonious benchmark based on lagged market return and realized volatility, delivering calibrated stress probabilities on an economically meaningful scale. Further, I illustrate how MSPI can be used as a probability-based measurement object in financial econometrics. The resulting index provides a transparent and easily updated measure of near-term equity-market stress risk.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e2a\u80a1\u6a2a\u622a\u9762\u4fe1\u606f\u7684\u5e02\u573a\u538b\u529b\u6982\u7387\u6307\u6570(MSPI)\uff0c\u7528\u4e8e\u9884\u6d4b\u7f8e\u56fd\u80a1\u5e02\u672a\u6765\u4e00\u4e2a\u6708\u7684\u9ad8\u538b\u529b\u6982\u7387", "motivation": "\u9700\u8981\u4e00\u79cd\u900f\u660e\u3001\u6613\u4e8e\u66f4\u65b0\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u80a1\u5e02\u77ed\u671f\u538b\u529b\u98ce\u9669\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u4e0d\u591f\u51c6\u786e\u6216\u4e0d\u591f\u53ca\u65f6", "method": "\u4f7f\u7528CRSP\u65e5\u5ea6\u6570\u636e\uff0c\u6bcf\u6708\u4ece\u4e2a\u80a1\u6a2a\u622a\u9762\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u8106\u5f31\u6027\u4fe1\u53f7\uff0c\u901a\u8fc7L1\u6b63\u5219\u5316\u903b\u8f91\u56de\u5f52\u5728\u5b9e\u65f6\u6269\u5c55\u7a97\u53e3\u8bbe\u8ba1\u4e2d\u6620\u5c04\u4e3a\u524d\u77bb\u6027\u538b\u529b\u6982\u7387", "result": "\u6837\u672c\u5916\u8868\u73b0\u826f\u597d\uff0c\u80fd\u8ffd\u8e2a\u4e3b\u8981\u538b\u529b\u4e8b\u4ef6\uff0c\u76f8\u6bd4\u57fa\u4e8e\u6ede\u540e\u5e02\u573a\u56de\u62a5\u548c\u5df2\u5b9e\u73b0\u6ce2\u52a8\u7684\u57fa\u51c6\u6a21\u578b\uff0c\u5728\u533a\u5206\u5ea6\u548c\u51c6\u786e\u6027\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u63d0\u4f9b\u7ecf\u6d4e\u610f\u4e49\u660e\u786e\u7684\u6821\u51c6\u538b\u529b\u6982\u7387", "conclusion": "MSPI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u4e14\u6613\u4e8e\u66f4\u65b0\u7684\u77ed\u671f\u80a1\u5e02\u538b\u529b\u98ce\u9669\u8861\u91cf\u5de5\u5177\uff0c\u5e76\u53ef\u4f5c\u4e3a\u91d1\u878d\u8ba1\u91cf\u5b66\u4e2d\u57fa\u4e8e\u6982\u7387\u7684\u6d4b\u91cf\u5bf9\u8c61"}}
{"id": "2602.08119", "categories": ["math.OC", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.08119", "abs": "https://arxiv.org/abs/2602.08119", "authors": ["Hoang Giang Pham", "Tien Mai"], "title": "Constrained Pricing under Finite Mixtures of Logit", "comment": null, "summary": "The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u7ea6\u675f\u7684\u5b9a\u4ef7\u95ee\u9898\uff0c\u9488\u5bf9\u591a\u9879Logit\u6a21\u578b\u63d0\u51fa\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff0c\u9488\u5bf9\u6709\u9650\u6df7\u5408Logit\u6a21\u578b\u8bbe\u8ba1\u4e86\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff0c\u5728\u5ba2\u6237\u7ec6\u5206\u6570\u91cf\u6709\u9650\u65f6\u83b7\u5f97\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002", "motivation": "\u6df7\u5408Logit\u6a21\u578b\u5728\u5b9a\u4ef7\u548c\u6536\u76ca\u7ba1\u7406\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u65e0\u7ea6\u675f\u573a\u666f\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u4ef7\u683c\u5e38\u53d7\u5546\u4e1a\u6216\u76d1\u7ba1\u7ea6\u675f\u9650\u5236\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5e26\u7ea6\u675f\u7684\u5b9a\u4ef7\u95ee\u9898\u3002", "method": "\u5bf9\u4e8e\u591a\u9879Logit\u6a21\u578b\uff08\u5355\u4e00\u5ba2\u6237\u7ec6\u5206\uff09\uff0c\u901a\u8fc7\u6307\u6570\u9525\u89c4\u5212\u91cd\u6784\u95ee\u9898\uff0c\u83b7\u5f97\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff1b\u5bf9\u4e8e\u6709\u9650\u6df7\u5408Logit\u6a21\u578b\uff08T\u4e2a\u5ba2\u6237\u7ec6\u5206\uff09\uff0c\u5c06\u5176\u91cd\u6784\u4e3a\u5305\u542bO(T)\u4e2a\u53cc\u7ebf\u6027\u9879\u7684\u6307\u6570\u9525\u89c4\u5212\uff0c\u5e76\u8bbe\u8ba1\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u3002", "result": "\u591a\u9879Logit\u6a21\u578b\u7684\u7ea6\u675f\u5b9a\u4ef7\u95ee\u9898\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u83b7\u5f97\u03b5-\u6700\u4f18\u89e3\uff1b\u6709\u9650\u6df7\u5408Logit\u6a21\u578b\u5728\u5ba2\u6237\u7ec6\u5206\u6570\u91cf\u6709\u9650\u65f6\u4e5f\u5141\u8bb8\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u4e3a\u5e26\u7ea6\u675f\u7684\u6df7\u5408Logit\u5b9a\u4ef7\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u6df7\u5408Logit\u6a21\u578b\u5728\u5b9e\u9645\u7ea6\u675f\u573a\u666f\u4e0b\u7684\u5e94\u7528\u80fd\u529b\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2602.06975", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06975", "abs": "https://arxiv.org/abs/2602.06975", "authors": ["R. James Cotton", "Thomas Leonard"], "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents", "comment": null, "summary": "Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.", "AI": {"tldr": "BiomechAgent\u662f\u4e00\u4e2a\u4ee3\u7801\u751f\u6210AI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5b9e\u73b0\u751f\u7269\u529b\u5b66\u5206\u6790\uff0c\u65e0\u9700\u7f16\u7a0b\u6280\u80fd\u5373\u53ef\u67e5\u8be2\u6570\u636e\u5e93\u3001\u751f\u6210\u53ef\u89c6\u5316\u3001\u89e3\u91ca\u6570\u636e\uff0c\u4f7f\u8fd0\u52a8\u6355\u6349\u6570\u636e\u66f4\u6613\u7528\u3002", "motivation": "\u867d\u7136\u65e0\u6807\u8bb0\u8fd0\u52a8\u6355\u6349\u6280\u672f\u4f7f\u5b9a\u91cf\u8fd0\u52a8\u5206\u6790\u8d8a\u6765\u8d8a\u666e\u53ca\uff0c\u4f46\u5206\u6790\u7ed3\u679c\u6570\u636e\u5bf9\u4e8e\u6ca1\u6709\u7f16\u7a0b\u7ecf\u9a8c\u7684\u4e34\u5e8a\u533b\u751f\u4ecd\u7136\u5b58\u5728\u969c\u788d\u3002\u9700\u8981\u4e00\u79cd\u5de5\u5177\u8ba9\u975e\u6280\u672f\u7528\u6237\u4e5f\u80fd\u8fdb\u884c\u751f\u7269\u529b\u5b66\u5206\u6790\u3002", "method": "\u5f00\u53d1\u4e86BiomechAgent\u4ee3\u7801\u751f\u6210AI\u4ee3\u7406\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002\u901a\u8fc7\u7cfb\u7edf\u5316\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5176\u80fd\u529b\uff0c\u5305\u62ec\u6570\u636e\u68c0\u7d22\u3001\u53ef\u89c6\u5316\u3001\u6d3b\u52a8\u5206\u7c7b\u3001\u65f6\u95f4\u5206\u5272\u548c\u4e34\u5e8a\u63a8\u7406\u3002\u5bf9\u6bd4\u4e86\u751f\u7269\u529b\u5b66\u7279\u5b9a\u6307\u4ee4\u4e0e\u901a\u7528\u63d0\u793a\u7684\u6548\u679c\uff0c\u5e76\u6574\u5408\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4e13\u4e1a\u6b65\u6001\u4e8b\u4ef6\u68c0\u6d4b\u5de5\u5177\u3002", "result": "BiomechAgent\u5728\u6570\u636e\u68c0\u7d22\u548c\u53ef\u89c6\u5316\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5c55\u73b0\u51fa\u65b0\u5174\u7684\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u3002\u751f\u7269\u529b\u5b66\u7279\u5b9a\u7684\u9886\u57df\u6307\u4ee4\u663e\u8457\u4f18\u4e8e\u901a\u7528\u63d0\u793a\uff0c\u6574\u5408\u4e13\u4e1a\u6b65\u6001\u68c0\u6d4b\u5de5\u5177\u5927\u5927\u63d0\u9ad8\u4e86\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u65f6\u7a7a\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u3002\u4f7f\u7528\u672c\u5730\u5f00\u6e90\u6a21\u578b\u76f8\u6bd4\u524d\u6cbf\u4e91LLM\u5728\u5927\u591a\u6570\u9886\u57df\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "BiomechAgent\u4f7f\u6765\u81ea\u53ef\u8bbf\u95ee\u8fd0\u52a8\u6355\u6349\u7684\u6570\u636e\u5bf9\u6700\u7ec8\u7528\u6237\u66f4\u52a0\u6709\u7528\u548c\u6613\u7528\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u964d\u4f4e\u4e86\u751f\u7269\u529b\u5b66\u5206\u6790\u7684\u95e8\u69db\u3002"}}
{"id": "2602.07034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07034", "abs": "https://arxiv.org/abs/2602.07034", "authors": ["Jinxiu Qu", "Zirui Tang", "Hongzhang Huang", "Boyu Niu", "Wei Zhou", "Jiannan Wang", "Yitong Song", "Guoliang Li", "Xuanhe Zhou", "Fan Wu"], "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA", "comment": null, "summary": "Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.", "AI": {"tldr": "ST-Raptor\uff1a\u4e00\u4e2a\u7528\u4e8e\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u7f16\u8f91\u3001\u6811\u5f62\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u67e5\u8be2\u89e3\u51b3\uff0c\u5728\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u9700\u8981\u7cbe\u786e\u63d0\u53d6\u5355\u5143\u683c\u5185\u5bb9\u548c\u4f4d\u7f6e\uff0c\u5e76\u6062\u590d\u8868\u683c\u5e03\u5c40\u4e2d\u9690\u542b\u7684\u903b\u8f91\u7ed3\u6784\u3001\u5c42\u6b21\u5173\u7cfb\u548c\u8bed\u4e49\u5173\u8054\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u3001\u5904\u7406\u590d\u6742\u5e03\u5c40\u56f0\u96be\u3001\u7b54\u6848\u4e0d\u51c6\u786e\u7b49\u95ee\u9898\uff0c\u800c\u4eba\u5de5\u89e3\u91ca\u53c8\u8017\u65f6\u8017\u529b\u3002", "method": "ST-Raptor\u662f\u4e00\u4e2a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5206\u6790\u73af\u5883\uff0c\u7ed3\u5408\u89c6\u89c9\u7f16\u8f91\u3001\u57fa\u4e8e\u6811\u7684\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u67e5\u8be2\u89e3\u51b3\uff0c\u652f\u6301\u51c6\u786e\u4e14\u7528\u6237\u53cb\u597d\u7684\u8868\u683c\u7406\u89e3\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cST-Raptor\u5728\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ST-Raptor\u901a\u8fc7\u521b\u65b0\u7684\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u81ea\u52a8\u5316\u8868\u683c\u7406\u89e3\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07030", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07030", "abs": "https://arxiv.org/abs/2602.07030", "authors": ["Young Jin Ahn", "Yiyang Du", "Zheyuan Zhang", "Haisen Kang"], "title": "Neural Sabermetrics with World Model: Play-by-play Predictive Modeling with Large Language Model", "comment": null, "summary": "Classical sabermetrics has profoundly shaped baseball analytics by summarizing long histories of play into compact statistics. While these metrics are invaluable for valuation and retrospective analysis, they do not define a generative model of how baseball games unfold pitch by pitch, leaving most existing approaches limited to single-step prediction or post-hoc analysis. In this work, we present Neural Sabermetrics with World Model, a Large Language Model (LLM) based play-by-play world model for baseball. We cast baseball games as long auto-regressive sequences of events and continuously pretrain a single LLM on more than ten years of Major League Baseball (MLB) tracking data, comprising over seven million pitch sequences and approximately three billion tokens. The resulting model is capable of predicting multiple aspects of game evolution within a unified framework. We evaluate our model on both in-distribution regular-season data and out-of-distribution postseason games and compare against strong neural baselines from prior work. Despite using a single backbone model, our approach outperforms the performance of existing baselines, (1) correctly predicting approximately 64% of next pitches within a plate appearance and (2) 78% of batter swing decisions, suggesting that LLMs can serve as effective world models for sports.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u68d2\u7403\u6bd4\u8d5b\u7684\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u5e8f\u5217\u9884\u6d4b\u6bd4\u8d5b\u8fdb\u7a0b\uff0c\u5728\u6295\u7403\u9884\u6d4b\u548c\u51fb\u7403\u624b\u51b3\u7b56\u9884\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u68d2\u7403\u7edf\u8ba1\u6307\u6807\u867d\u7136\u5bf9\u7403\u5458\u8bc4\u4f30\u548c\u56de\u987e\u6027\u5206\u6790\u5f88\u6709\u4ef7\u503c\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u9010\u7403\u751f\u6210\u5f0f\u7684\u6bd4\u8d5b\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u5c40\u9650\u4e8e\u5355\u6b65\u9884\u6d4b\u6216\u4e8b\u540e\u5206\u6790\uff0c\u7f3a\u4e4f\u5bf9\u6bd4\u8d5b\u8fdb\u7a0b\u7684\u751f\u6210\u5f0f\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u5c06\u68d2\u7403\u6bd4\u8d5b\u5efa\u6a21\u4e3a\u4e8b\u4ef6\u7684\u957f\u81ea\u56de\u5f52\u5e8f\u5217\uff0c\u4f7f\u7528\u8d85\u8fc710\u5e74MLB\u8ffd\u8e2a\u6570\u636e\uff08700\u4e07\u6b21\u6295\u7403\u5e8f\u5217\uff0c\u7ea630\u4ebftokens\uff09\u5bf9\u5355\u4e2aLLM\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u6bd4\u8d5b\u4e16\u754c\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u5206\u5e03\u5185\u5e38\u89c4\u8d5b\u548c\u5206\u5e03\u5916\u5b63\u540e\u8d5b\u6570\u636e\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\uff1a\u6b63\u786e\u9884\u6d4b\u7ea664%\u7684\u4e0b\u4e00\u6295\u7403\uff08\u5728\u540c\u4e00\u4e2a\u6253\u5e2d\u5185\uff09\u548c78%\u7684\u51fb\u7403\u624b\u6325\u68d2\u51b3\u7b56\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u57fa\u7ebf\u3002", "conclusion": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u4f53\u80b2\u4e16\u754c\u6a21\u578b\uff0c\u80fd\u591f\u5728\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u5185\u9884\u6d4b\u6bd4\u8d5b\u7684\u591a\u4e2a\u65b9\u9762\uff0c\u4e3a\u68d2\u7403\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u751f\u6210\u5f0f\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2602.07486", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07486", "abs": "https://arxiv.org/abs/2602.07486", "authors": ["Dor Leventer"], "title": "Identification of Child Penalties", "comment": null, "summary": "A growing body of research estimates child penalties, the gender gap in the effect of parenthood on labor market earnings, using event studies that normalize treatment effects by counterfactual earnings. I formalize the identification framework underlying this approach, which I term Normalized Triple Differences (NTD), and show it does not identify the conventional target estimand when the parallel trends assumption in levels is violated. Insights from human capital theory suggest such violations are likely: higher-ability individuals delay childbirth and have steeper earnings growth, a mechanism that causes conventional estimates to understate child penalties for early-treated parents. Using Israeli administrative data, a bias-bounding exercise suggests substantial understatement for early groups. As a solution, I propose targeting the effect of parenthood on the gender earnings ratio and show this new estimand is identified under NTD.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u4f20\u7edf\u513f\u7ae5\u60e9\u7f5a\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u504f\u5dee\uff0c\u63d0\u51fa\u57fa\u4e8e\u6027\u522b\u6536\u5165\u6bd4\u7684\u65b0\u4f30\u8ba1\u91cf", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u4e8b\u4ef6\u7814\u7a76\u6cd5\u4f30\u8ba1\u513f\u7ae5\u60e9\u7f5a\uff08\u751f\u80b2\u5bf9\u52b3\u52a8\u529b\u5e02\u573a\u6536\u5165\u7684\u6027\u522b\u5dee\u8ddd\uff09\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\u65e0\u6cd5\u8bc6\u522b\u4f20\u7edf\u76ee\u6807\u4f30\u8ba1\u91cf\u3002\u4eba\u529b\u8d44\u672c\u7406\u8bba\u8868\u660e\u8fd9\u79cd\u8fdd\u53cd\u5f88\u53ef\u80fd\u53d1\u751f\uff0c\u5bfc\u81f4\u5bf9\u65e9\u671f\u751f\u80b2\u7236\u6bcd\u7684\u513f\u7ae5\u60e9\u7f5a\u4f30\u8ba1\u504f\u4f4e\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86\u5f52\u4e00\u5316\u4e09\u91cd\u5dee\u5206\uff08NTD\uff09\u8bc6\u522b\u6846\u67b6\uff0c\u6307\u51fa\u5176\u5728\u6c34\u5e73\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\u7684\u95ee\u9898\u3002\u4f7f\u7528\u4ee5\u8272\u5217\u884c\u653f\u6570\u636e\u8fdb\u884c\u504f\u5dee\u8fb9\u754c\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4ee5\u751f\u80b2\u5bf9\u6027\u522b\u6536\u5165\u6bd4\u7684\u5f71\u54cd\u4f5c\u4e3a\u65b0\u7684\u76ee\u6807\u4f30\u8ba1\u91cf\u3002", "result": "\u504f\u5dee\u8fb9\u754c\u5206\u6790\u663e\u793a\u5bf9\u65e9\u671f\u751f\u80b2\u7fa4\u4f53\u7684\u513f\u7ae5\u60e9\u7f5a\u5b58\u5728\u663e\u8457\u4f4e\u4f30\u3002\u63d0\u51fa\u7684\u65b0\u4f30\u8ba1\u91cf\uff08\u751f\u80b2\u5bf9\u6027\u522b\u6536\u5165\u6bd4\u7684\u5f71\u54cd\uff09\u5728NTD\u6846\u67b6\u4e0b\u662f\u53ef\u8bc6\u522b\u7684\u3002", "conclusion": "\u4f20\u7edf\u513f\u7ae5\u60e9\u7f5a\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u7279\u522b\u662f\u5bf9\u65e9\u671f\u751f\u80b2\u7fa4\u4f53\u3002\u5efa\u8bae\u4f7f\u7528\u751f\u80b2\u5bf9\u6027\u522b\u6536\u5165\u6bd4\u7684\u5f71\u54cd\u4f5c\u4e3a\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u76ee\u6807\uff0c\u8be5\u4f30\u8ba1\u91cf\u5728\u5f52\u4e00\u5316\u4e09\u91cd\u5dee\u5206\u6846\u67b6\u4e0b\u5177\u6709\u8bc6\u522b\u6027\u3002"}}
{"id": "2602.07581", "categories": ["eess.SY", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.07581", "abs": "https://arxiv.org/abs/2602.07581", "authors": ["Thomas Beckers", "J\u00e1n Drgo\u0148a", "Truong X. Nghiem"], "title": "$\\partial$CBDs: Differentiable Causal Block Diagrams", "comment": null, "summary": "Modern cyber-physical systems (CPS) integrate physics, computation, and learning, demanding modeling frameworks that are simultaneously composable, learnable, and verifiable. Yet existing approaches treat these goals in isolation: causal block diagrams (CBDs) support modular system interconnections but lack differentiability for learning; differentiable programming (DP) enables end-to-end gradient-based optimization but provides limited correctness guarantees; while contract-based verification frameworks remain largely disconnected from data-driven model refinement. To address these limitations, we introduce differentiable causal block diagrams ($\\partial$CBDs), a unifying formalism that integrates these three perspectives. Our approach (i) retains the compositional structure and execution semantics of CBDs, (ii) incorporates assume--guarantee (A--G) contracts for modular correctness reasoning, and (iii) introduces residual-based contracts as differentiable, trajectory-level certificates compatible with automatic differentiation (AD), enabling gradient-based optimization and learning. Together, these elements enable a scalable, verifiable, and trainable modeling pipeline that preserves causality and modularity while supporting data-, physics-, and constraint-informed optimization for CPS.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u5fae\u5206\u56e0\u679c\u6846\u56fe\uff08\u2202CBDs\uff09\uff0c\u7edf\u4e00\u4e86\u6a21\u5757\u5316\u7cfb\u7edf\u4e92\u8054\u3001\u53ef\u5b66\u4e60\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e3a\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u63d0\u4f9b\u53ef\u7ec4\u5408\u3001\u53ef\u5b66\u4e60\u3001\u53ef\u9a8c\u8bc1\u7684\u5efa\u6a21\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6a21\u5757\u5316\u4e92\u8054\u3001\u53ef\u5b66\u4e60\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u65b9\u9762\u5404\u81ea\u4e3a\u653f\uff1a\u56e0\u679c\u6846\u56fe\u652f\u6301\u6a21\u5757\u5316\u4f46\u4e0d\u53ef\u5fae\u5206\uff1b\u53ef\u5fae\u5206\u7f16\u7a0b\u652f\u6301\u5b66\u4e60\u4f46\u7f3a\u4e4f\u6b63\u786e\u6027\u4fdd\u8bc1\uff1b\u57fa\u4e8e\u5951\u7ea6\u7684\u9a8c\u8bc1\u6846\u67b6\u4e0e\u6570\u636e\u9a71\u52a8\u6a21\u578b\u6539\u8fdb\u8131\u8282\u3002\u9700\u8981\u7edf\u4e00\u6846\u67b6\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e09\u65b9\u9762\u9700\u6c42\u3002", "method": "\u5f15\u5165\u53ef\u5fae\u5206\u56e0\u679c\u6846\u56fe\uff08\u2202CBDs\uff09\uff0c\u4fdd\u7559CBD\u7684\u7ec4\u6210\u7ed3\u6784\u548c\u6267\u884c\u8bed\u4e49\uff0c\u96c6\u6210\u5047\u8bbe-\u4fdd\u8bc1\u5951\u7ea6\u8fdb\u884c\u6a21\u5757\u5316\u6b63\u786e\u6027\u63a8\u7406\uff0c\u5f15\u5165\u57fa\u4e8e\u6b8b\u5dee\u7684\u5951\u7ea6\u4f5c\u4e3a\u53ef\u5fae\u5206\u7684\u8f68\u8ff9\u7ea7\u8bc1\u4e66\uff0c\u517c\u5bb9\u81ea\u52a8\u5fae\u5206\uff0c\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u548c\u5b66\u4e60\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9a8c\u8bc1\u3001\u53ef\u8bad\u7ec3\u7684\u5efa\u6a21\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u56e0\u679c\u6027\u548c\u6a21\u5757\u5316\u7684\u540c\u65f6\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u3001\u7269\u7406\u7ea6\u675f\u548c\u7ea6\u675f\u611f\u77e5\u7684\u4f18\u5316\uff0c\u4e3a\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u63d0\u4f9b\u7edf\u4e00\u7684\u5efa\u6a21\u6846\u67b6\u3002", "conclusion": "\u2202CBDs\u6210\u529f\u6574\u5408\u4e86\u6a21\u5757\u5316\u7cfb\u7edf\u4e92\u8054\u3001\u53ef\u5b66\u4e60\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u4e3a\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u540c\u65f6\u6ee1\u8db3\u53ef\u7ec4\u5408\u6027\u3001\u53ef\u5b66\u4e60\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u7684\u7edf\u4e00\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2602.07046", "categories": ["q-fin.ST", "q-fin.CP", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07046", "abs": "https://arxiv.org/abs/2602.07046", "authors": ["Murad Farzulla"], "title": "Sentiment Without Structure: Differential Market Responses to Infrastructure vs Regulatory Events in Cryptocurrency Markets", "comment": "24 pages, 15 tables. JEL: G14, G18, G23. Reproducible code and data: https://github.com/studiofarzulla/sentiment-without-structure", "summary": "We investigate differential market responses to infrastructure versus regulatory events in cryptocurrency markets using event study methodology with 4-category event classification. From 50 candidate events (2019-2025), 31 meet our impact and estimation-data criteria across 4 cryptocurrencies: Bitcoin (BTC), Ethereum (ETH), Solana (SOL), and Cardano (ADA). We employ constant mean and market-adjusted models with event-level block bootstrap confidence intervals (CIs) that properly account for cross-sectional correlation.\n  Our primary comparison focuses on negative-valence events: infrastructure failures (10 events identified; 8 with sufficient estimation data for analysis) versus regulatory enforcement (7 events). We find infrastructure failures produce mean Cumulative Abnormal Return (CAR) of -7.6% (bootstrap 95% CI: [-25.8%, +11.3%]) and regulatory enforcement produces mean CAR of -11.1% (CI: [-31.0%, +10.7%]). The difference in mean CARs of +3.6 percentage points (pp) has CI [-25.3%, +30.9%], p = 0.81. This is a null finding: markets respond similarly to both shock types when controlling for event valence.\n  Robustness checks confirm: (1) consistent negative sign across all window specifications ([0, +1] to [-5, +30]), (2) results survive leave-one-out exclusion of FTX and Terra, (3) market model with BTC/equal-weighted (EW) proxy attenuates but does not flip results. The 4-category classification addresses prior conflation of upgrades with failures.\n  Interpretation note: This exploratory analysis should be treated as hypothesis-generating; any post-hoc theoretical framing requires prospective testing with larger samples.", "AI": {"tldr": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5bf9\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u548c\u76d1\u7ba1\u6267\u6cd5\u4e8b\u4ef6\u7684\u53cd\u5e94\u76f8\u4f3c\uff0c\u4e24\u79cd\u8d1f\u9762\u4e8b\u4ef6\u5747\u5bfc\u81f4\u8d1f\u5f02\u5e38\u6536\u76ca\uff0c\u5dee\u5f02\u4e0d\u663e\u8457\u3002", "motivation": "\u7814\u7a76\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5bf9\u57fa\u7840\u8bbe\u65bd\u4e8b\u4ef6\u4e0e\u76d1\u7ba1\u4e8b\u4ef6\u7684\u4e0d\u540c\u53cd\u5e94\uff0c\u89e3\u51b3\u5148\u524d\u7814\u7a76\u4e2d\u5c06\u5347\u7ea7\u4e0e\u6545\u969c\u6df7\u6dc6\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u7814\u7a76\u6cd5\uff0c\u4f7f\u75284\u7c7b\u4e8b\u4ef6\u5206\u7c7b\uff0c\u5206\u67902019-2025\u5e7431\u4e2a\u4e8b\u4ef6\uff0c\u4f7f\u7528\u5e38\u5747\u503c\u6a21\u578b\u548c\u5e02\u573a\u8c03\u6574\u6a21\u578b\uff0c\u91c7\u7528\u4e8b\u4ef6\u7ea7\u5757\u81ea\u4e3e\u7f6e\u4fe1\u533a\u95f4\u5904\u7406\u6a2a\u622a\u9762\u76f8\u5173\u6027\u3002", "result": "\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u5e73\u5747CAR\u4e3a-7.6%\uff0c\u76d1\u7ba1\u6267\u6cd5\u5e73\u5747CAR\u4e3a-11.1%\uff0c\u4e24\u8005\u5dee\u5f02+3.6\u4e2a\u767e\u5206\u70b9\u4f46\u4e0d\u663e\u8457\uff08p=0.81\uff09\uff0c\u5e02\u573a\u5bf9\u4e24\u7c7b\u8d1f\u9762\u4e8b\u4ef6\u7684\u53cd\u5e94\u76f8\u4f3c\u3002", "conclusion": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5bf9\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u548c\u76d1\u7ba1\u6267\u6cd5\u4e8b\u4ef6\u7684\u8d1f\u9762\u53cd\u5e94\u7a0b\u5ea6\u76f8\u4f3c\uff0c\u8be5\u63a2\u7d22\u6027\u5206\u6790\u4e3a\u540e\u7eed\u5047\u8bbe\u751f\u6210\u63d0\u4f9b\u57fa\u7840\uff0c\u9700\u8981\u66f4\u5927\u6837\u672c\u7684\u524d\u77bb\u6027\u6d4b\u8bd5\u9a8c\u8bc1\u3002"}}
{"id": "2602.07632", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07632", "abs": "https://arxiv.org/abs/2602.07632", "authors": ["Jinhua Lyu", "Tianmin Yu", "Ying Ma", "Naichen Shi"], "title": "Scalable Mean-Field Variational Inference via Preconditioned Primal-Dual Optimization", "comment": null, "summary": "In this work, we investigate the large-scale mean-field variational inference (MFVI) problem from a mini-batch primal-dual perspective. By reformulating MFVI as a constrained finite-sum problem, we develop a novel primal-dual algorithm based on an augmented Lagrangian formulation, termed primal-dual variational inference (PD-VI). PD-VI jointly updates global and local variational parameters in the evidence lower bound in a scalable manner. To further account for heterogeneous loss geometry across different variational parameter blocks, we introduce a block-preconditioned extension, P$^2$D-VI, which adapts the primal-dual updates to the geometry of each parameter block and improves both numerical robustness and practical efficiency. We establish convergence guarantees for both PD-VI and P$^2$D-VI under properly chosen constant step size, without relying on conjugacy assumptions or explicit bounded-variance conditions. In particular, we prove $O(1/T)$ convergence to a stationary point in general settings and linear convergence under strong convexity. Numerical experiments on synthetic data and a real large-scale spatial transcriptomics dataset demonstrate that our methods consistently outperform existing stochastic variational inference approaches in terms of convergence speed and solution quality.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u7684\u5927\u89c4\u6a21\u5747\u503c\u573a\u53d8\u5206\u63a8\u65ad\u7b97\u6cd5\uff1aPD-VI\u53ca\u5176\u5757\u9884\u5904\u7406\u6269\u5c55P\u00b2D-VI\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u4e0a\u4f18\u4e8e\u73b0\u6709\u968f\u673a\u53d8\u5206\u63a8\u65ad\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5927\u89c4\u6a21\u5747\u503c\u573a\u53d8\u5206\u63a8\u65ad\uff08MFVI\uff09\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u65f6\u5b58\u5728\u6548\u7387\u548c\u6536\u655b\u6027\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u66f4\u7a33\u5065\u7684\u7b97\u6cd5\u3002", "method": "\u5c06MFVI\u91cd\u6784\u4e3a\u7ea6\u675f\u6709\u9650\u548c\u95ee\u9898\uff0c\u57fa\u4e8e\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u63d0\u51fa\u539f\u59cb-\u5bf9\u5076\u53d8\u5206\u63a8\u65ad\uff08PD-VI\uff09\u7b97\u6cd5\uff0c\u5e76\u8fdb\u4e00\u6b65\u5f15\u5165\u5757\u9884\u5904\u7406\u6269\u5c55P\u00b2D-VI\u4ee5\u9002\u5e94\u4e0d\u540c\u53c2\u6570\u5757\u7684\u5f02\u8d28\u635f\u5931\u51e0\u4f55\u3002", "result": "\u5728\u9002\u5f53\u6052\u5b9a\u6b65\u957f\u4e0b\uff0cPD-VI\u548cP\u00b2D-VI\u5206\u522b\u5b9e\u73b0O(1/T)\u6536\u655b\u5230\u5e73\u7a33\u70b9\u548c\u5f3a\u51f8\u6761\u4ef6\u4e0b\u7684\u7ebf\u6027\u6536\u655b\uff0c\u65e0\u9700\u5171\u8f6d\u5047\u8bbe\u6216\u663e\u5f0f\u6709\u754c\u65b9\u5dee\u6761\u4ef6\u3002", "conclusion": "\u63d0\u51fa\u7684\u539f\u59cb-\u5bf9\u5076\u65b9\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u548c\u6c42\u89e3\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u968f\u673a\u53d8\u5206\u63a8\u65ad\u65b9\u6cd5\uff0c\u4e3a\u5927\u89c4\u6a21\u53d8\u5206\u63a8\u65ad\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7406\u8bba\u4fdd\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.06984", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06984", "abs": "https://arxiv.org/abs/2602.06984", "authors": ["Lin Luo", "Satwik Ghanta", "Yuri Nakao", "Mathieu Chollet", "Simone Stumpf"], "title": "Empowering Affected Individuals to Shape AI Fairness Assessments: Processes, Criteria, and Tools", "comment": null, "summary": "AI systems are increasingly used in high-stakes domains such as credit rating, where fairness concerns are critical. Existing fairness assessments are typically conducted by AI experts or regulators using predefined protected attributes and metrics, which often fail to capture the diversity and nuance of fairness notions held by the individuals who are affected by these systems' decisions, such as decision subjects. Recent work has therefore called for involving affected individuals in fairness assessment, yet little empirical evidence exists on how they create their own fairness criteria or what kinds of criteria they produce - knowledge that could not only inform experts' fairness evaluation and mitigation, but also guide the design of AI assessment tools. We address this gap through a qualitative user study with 18 participants in a credit rating scenario. Participants first articulated their fairness notions in their own words. Then, participants turned them into concrete quantified and operationalized fairness criteria, through an interactive prototype we designed. Our findings provide empirical evidence of the process through which people's fairness notions emerge via grounding in model features, and uncover a diverse set of individuals' custom-defined criteria for both outcome and procedural fairness. We provide design implications for processes and tools that support more inclusive and value-sensitive AI fairness assessment.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u63a2\u7d22\u4e2a\u4f53\u5982\u4f55\u521b\u5efa\u81ea\u5df1\u7684AI\u516c\u5e73\u6027\u6807\u51c6\uff0c\u53d1\u73b0\u4eba\u4eec\u901a\u8fc7\u6a21\u578b\u7279\u5f81\u6765\u5f62\u6210\u516c\u5e73\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u6837\u5316\u7684\u81ea\u5b9a\u4e49\u6807\u51c6", "motivation": "\u5f53\u524dAI\u516c\u5e73\u6027\u8bc4\u4f30\u901a\u5e38\u7531\u4e13\u5bb6\u4f7f\u7528\u9884\u5b9a\u4e49\u5c5e\u6027\u548c\u6307\u6807\u8fdb\u884c\uff0c\u672a\u80fd\u6355\u6349\u53d7\u5f71\u54cd\u4e2a\u4f53\u7684\u591a\u6837\u6027\u548c\u7ec6\u5fae\u5dee\u522b\u3002\u9700\u8981\u4e86\u89e3\u4e2a\u4f53\u5982\u4f55\u521b\u5efa\u81ea\u5df1\u7684\u516c\u5e73\u6807\u51c6\uff0c\u4ee5\u6307\u5bfcAI\u8bc4\u4f30\u5de5\u5177\u8bbe\u8ba1", "method": "\u91c7\u7528\u5b9a\u6027\u7528\u6237\u7814\u7a76\uff0c\u5728\u4fe1\u7528\u8bc4\u7ea7\u573a\u666f\u4e2d\u4e0e18\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u5b9e\u9a8c\u3002\u53c2\u4e0e\u8005\u9996\u5148\u7528\u81ea\u5df1\u7684\u8bed\u8a00\u8868\u8fbe\u516c\u5e73\u6982\u5ff5\uff0c\u7136\u540e\u901a\u8fc7\u4ea4\u4e92\u5f0f\u539f\u578b\u5c06\u5176\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u91cf\u5316\u53ef\u64cd\u4f5c\u516c\u5e73\u6807\u51c6", "result": "\u63d0\u4f9b\u4e86\u4eba\u4eec\u901a\u8fc7\u6a21\u578b\u7279\u5f81\u5f62\u6210\u516c\u5e73\u6982\u5ff5\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u53d1\u73b0\u4e86\u591a\u6837\u5316\u7684\u4e2a\u4f53\u81ea\u5b9a\u4e49\u7ed3\u679c\u516c\u5e73\u548c\u7a0b\u5e8f\u516c\u5e73\u6807\u51c6", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u652f\u6301\u66f4\u5177\u5305\u5bb9\u6027\u548c\u4ef7\u503c\u654f\u611f\u7684AI\u516c\u5e73\u6027\u8bc4\u4f30\u6d41\u7a0b\u548c\u5de5\u5177\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u542f\u793a"}}
{"id": "2602.07217", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07217", "abs": "https://arxiv.org/abs/2602.07217", "authors": ["Rui Gong", "Alejandro Toriello"], "title": "Dynamic Interval Scheduling with Random Start and End Times", "comment": null, "summary": "We study sequential interval scheduling when task start and end times are random. The set of tasks and their weights are known in advance, while each task's start and end times are drawn from known discrete distributions and revealed only upon commitment; this also eliminates tasks that conflict with the committed task, and remaining tasks are those that do not conflict. The objective is to maximize the expected weight of a conflict-free schedule. We propose two models that differ in how conflicts are enforced, develop LP relaxations and bounds for each, and present a computational study.", "AI": {"tldr": "\u7814\u7a76\u968f\u673a\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u7684\u987a\u5e8f\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u5df2\u77e5\u4efb\u52a1\u548c\u6743\u91cd\u4f46\u65f6\u95f4\u968f\u673a\uff0c\u63d0\u51fa\u4e24\u79cd\u51b2\u7a81\u6267\u884c\u6a21\u578b\uff0c\u5f00\u53d1LP\u677e\u5f1b\u548c\u754c\u9650\uff0c\u5e76\u8fdb\u884c\u8ba1\u7b97\u7814\u7a76", "motivation": "\u7814\u7a76\u4efb\u52a1\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u968f\u673a\u60c5\u51b5\u4e0b\u7684\u987a\u5e8f\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u4efb\u52a1\u65f6\u95f4\u5f80\u5f80\u4e0d\u786e\u5b9a\uff0c\u9700\u8981\u5728\u4fe1\u606f\u9010\u6b65\u63ed\u793a\u65f6\u505a\u51fa\u51b3\u7b56\uff0c\u76ee\u6807\u662f\u6700\u5927\u5316\u65e0\u51b2\u7a81\u8c03\u5ea6\u7684\u671f\u671b\u6743\u91cd", "method": "\u63d0\u51fa\u4e24\u79cd\u51b2\u7a81\u6267\u884c\u6a21\u578b\uff0c\u5f00\u53d1\u7ebf\u6027\u89c4\u5212\u677e\u5f1b\u548c\u754c\u9650\uff0c\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u7814\u7a76", "result": "\u5efa\u7acb\u4e86\u968f\u673a\u533a\u95f4\u8c03\u5ea6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86LP\u677e\u5f1b\u548c\u754c\u9650\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u4e3a\u968f\u673a\u5f00\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u7684\u987a\u5e8f\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u5efa\u6a21\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u4e24\u79cd\u6a21\u578b\u548cLP\u677e\u5f1b\u4e3a\u8fd9\u7c7b\u968f\u673a\u8c03\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08039", "categories": ["q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.08039", "abs": "https://arxiv.org/abs/2602.08039", "authors": ["Lan Bu", "Ning Cai", "Chenxi Xia", "Jingping Yang"], "title": "Perfectly Fitting CDO Prices Across Tranches: A Theoretical Framework with Efficient Algorithms", "comment": null, "summary": "This paper addresses a key challenge in CDO modeling: achieving a perfect fit to market prices across all tranches using a single, consistent model. The existence of such a perfect-fit model implies the absence of arbitrage among CDO tranches and is thus essential for unified risk management and the pricing of nonstandard credit derivatives. To address this central challenge, we face three primary difficulties: standard parametric models typically fail to achieve a perfect fit; the calibration of standard parametric models inherently relies on computationally intensive simulation-based optimization; and there is a lack of formal theory to determine when a perfect-fit model exists and, if it exists, how to construct it. We propose a theoretical framework to overcome these difficulties. We first introduce and define two compatibility levels of market prices: weak compatibility and strong compatibility. Specifically, market prices across all tranches are said to be weakly (resp. strongly) compatible if there exists a single model (resp. a single conditionally i.i.d. model) that perfectly fits these market prices. We then derive sufficient and necessary conditions for both levels of compatibility by establishing a relationship between compatibility and LP problems. Furthermore, under either condition, we construct a corresponding concrete copula model that achieves a perfect fit. Notably, our framework not only allows for efficient verification of weak compatibility and strong compatibility through LP problems but also facilitates the construction of the corresponding copula models that achieve a perfect fit, eliminating the need for simulation-based optimization. The practical applications of our framework are demonstrated in risk management and the pricing of nonstandard credit derivatives.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u89e3\u51b3CDO\u5efa\u6a21\u4e2d\u7684\u5b8c\u7f8e\u62df\u5408\u5e02\u573a\u5b9a\u4ef7\u95ee\u9898\uff0c\u901a\u8fc7\u5b9a\u4e49\u4ef7\u683c\u517c\u5bb9\u6027\u6982\u5ff5\u548c\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\uff0c\u5b9e\u73b0\u65e0\u9700\u6a21\u62df\u4f18\u5316\u7684\u5b8c\u7f8e\u62df\u5408\u6a21\u578b\u6784\u5efa\u3002", "motivation": "CDO\u5efa\u6a21\u4e2d\u9700\u8981\u5355\u4e00\u6a21\u578b\u5b8c\u7f8e\u62df\u5408\u6240\u6709\u5206\u6863\u5e02\u573a\u4ef7\u683c\uff0c\u8fd9\u5173\u7cfb\u5230\u5957\u5229\u4e0d\u5b58\u5728\u6027\u3001\u7edf\u4e00\u98ce\u9669\u7ba1\u7406\u548c\u975e\u6807\u51c6\u4fe1\u7528\u884d\u751f\u54c1\u5b9a\u4ef7\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u56f0\u96be\uff1a\u6807\u51c6\u53c2\u6570\u6a21\u578b\u65e0\u6cd5\u5b8c\u7f8e\u62df\u5408\u3001\u6821\u51c6\u4f9d\u8d56\u8ba1\u7b97\u5bc6\u96c6\u578b\u6a21\u62df\u4f18\u5316\u3001\u7f3a\u4e4f\u5b8c\u7f8e\u62df\u5408\u6a21\u578b\u5b58\u5728\u6027\u53ca\u6784\u9020\u7684\u5f62\u5f0f\u7406\u8bba\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u9996\u5148\u5b9a\u4e49\u5e02\u573a\u4ef7\u683c\u7684\u5f31\u517c\u5bb9\u6027\u548c\u5f3a\u517c\u5bb9\u6027\u6982\u5ff5\uff1b\u7136\u540e\u901a\u8fc7\u5efa\u7acb\u517c\u5bb9\u6027\u4e0e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u7684\u5173\u7cfb\uff0c\u63a8\u5bfc\u4e24\u79cd\u517c\u5bb9\u6027\u7684\u5145\u5206\u5fc5\u8981\u6761\u4ef6\uff1b\u5728\u6ee1\u8db3\u6761\u4ef6\u65f6\uff0c\u6784\u5efa\u5177\u4f53\u7684copula\u6a21\u578b\u5b9e\u73b0\u5b8c\u7f8e\u62df\u5408\u3002", "result": "\u6846\u67b6\u4e0d\u4ec5\u53ef\u4ee5\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u9ad8\u6548\u9a8c\u8bc1\u5f31\u517c\u5bb9\u6027\u548c\u5f3a\u517c\u5bb9\u6027\uff0c\u8fd8\u80fd\u6784\u5efa\u5bf9\u5e94\u7684copula\u6a21\u578b\u5b9e\u73b0\u5b8c\u7f8e\u62df\u5408\uff0c\u65e0\u9700\u6a21\u62df\u4f18\u5316\u3002\u8be5\u6846\u67b6\u5728\u98ce\u9669\u7ba1\u7406\u548c\u975e\u6807\u51c6\u4fe1\u7528\u884d\u751f\u54c1\u5b9a\u4ef7\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86CDO\u5efa\u6a21\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u7406\u8bba\u6846\u67b6\u6765\u9a8c\u8bc1\u5e02\u573a\u4ef7\u683c\u7684\u517c\u5bb9\u6027\u5e76\u6784\u5efa\u5b8c\u7f8e\u62df\u5408\u6a21\u578b\uff0c\u4e3a\u7edf\u4e00\u98ce\u9669\u7ba1\u7406\u548c\u975e\u6807\u51c6\u4fe1\u7528\u884d\u751f\u54c1\u5b9a\u4ef7\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.06976", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.06976", "abs": "https://arxiv.org/abs/2602.06976", "authors": ["Chen Shen", "Wei Cheng", "Jingyue Yang", "Huan Zhang", "Yuhan Wu", "Wei Hu"], "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks", "comment": null, "summary": "The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.", "AI": {"tldr": "ILA-agent\u6846\u67b6\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u52a8\u6001\u4ea4\u4e92\u5b66\u4e60\u964c\u751f\u7f16\u7a0b\u8bed\u8a00\uff0c\u65e0\u9700\u5927\u91cf\u5fae\u8c03\u6570\u636e\uff0c\u5728Cangjie\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u4f9d\u8d56\u4e8e\u9884\u8bad\u7ec3\u8bed\u6599\uff0c\u9762\u5bf9\u964c\u751f\u7f16\u7a0b\u8bed\u8a00\u65f6\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d\u3002\u4f20\u7edf\u7684\u6570\u636e\u5bc6\u96c6\u578b\u5fae\u8c03\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u65f6\u8bed\u8a00\u5b66\u4e60\u8303\u5f0f", "method": "\u63d0\u51faILA-agent\u6846\u67b6\uff0c\u5c06\u4eba\u7c7b\u5b66\u4e60\u884c\u4e3a\u5efa\u6a21\u4e3a\u4e00\u7ec4\u5de5\u5177\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\uff08\u67e5\u9605\u5b98\u65b9\u6587\u6863\u3001\u6267\u884c\u73af\u5883\u9a8c\u8bc1\uff09\u9010\u6b65\u63a2\u7d22\u3001\u5e94\u7528\u548c\u9a8c\u8bc1\u8bed\u8a00\u77e5\u8bc6", "result": "\u5728\u57fa\u4e8e\u65b0\u578b\u9759\u6001\u7c7b\u578b\u8bed\u8a00Cangjie\u6784\u5efa\u7684Cangjie-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cILA-agent\u5728\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u7a0b\u5e8f\u4fee\u590d\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "ILA-agent\u8bc1\u660e\u4e86\u63a8\u7406\u65f6\u8bed\u8a00\u83b7\u53d6\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4ea4\u4e92\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u964c\u751f\u7f16\u7a0b\u8bed\u8a00\uff0c\u540c\u65f6\u5206\u6790\u63ed\u793a\u4e86\u6301\u7eed\u5b58\u5728\u7684\u6027\u80fd\u5dee\u8ddd\u548c\u884c\u4e3a\u6a21\u5f0f"}}
{"id": "2602.07035", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07035", "abs": "https://arxiv.org/abs/2602.07035", "authors": ["Jiahao Zhao", "Shaoxuan Xu", "Zhongxiang Sun", "Fengqi Zhu", "Jingyang Ou", "Yuling Shi", "Chongxuan Li", "Xiao Zhang", "Jun Xu"], "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents", "comment": null, "summary": "Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C", "AI": {"tldr": "DLLM-Searcher\uff1a\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLM\uff09\u7684\u641c\u7d22\u4ee3\u7406\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u63d0\u5347\u4ee3\u7406\u80fd\u529b\uff0c\u5e76\u91c7\u7528\u5e76\u884c\u63a8\u7406\u4e0e\u6267\u884c\uff08P-ReAct\uff09\u8303\u5f0f\u89e3\u51b3\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u5ef6\u8fdf\u6311\u6218\uff1aReAct\u4ee3\u7406\u8303\u5f0f\u4e2d\u7684\u4e32\u884c\u591a\u8f6e\u63a8\u7406\u3001\u5de5\u5177\u8c03\u7528\u548c\u7b49\u5f85\u5bfc\u81f4\u4e25\u91cd\u7aef\u5230\u7aef\u5ef6\u8fdf\uff1b2\uff09\u4ee3\u7406\u80fd\u529b\u6311\u6218\uff1a\u73b0\u6709dLLM\u5728\u63a8\u7406\u548c\u5de5\u5177\u8c03\u7528\u80fd\u529b\u4e0a\u8868\u73b0\u8f83\u5f31\uff0c\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u5176\u5e76\u884c\u89e3\u7801\u4f18\u52bf\u3002", "method": "\u63d0\u51faDLLM-Searcher\u6846\u67b6\uff1a1\uff09\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u7ba1\u9053\uff1a\u5305\u62ec\u4ee3\u7406\u76d1\u7763\u5fae\u8c03\uff08Agentic SFT\uff09\u548c\u4ee3\u7406\u65b9\u5dee\u51cf\u5c11\u504f\u597d\u4f18\u5316\uff08Agentic VRPO\uff09\uff0c\u589e\u5f3adLLM\u7684\u4fe1\u606f\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\uff1b2\uff09P-ReAct\u65b0\u8303\u5f0f\uff1a\u5229\u7528dLLM\u7075\u6d3b\u751f\u6210\u673a\u5236\uff0c\u4f18\u5148\u89e3\u7801\u5de5\u5177\u8c03\u7528\u6307\u4ee4\uff0c\u5b9e\u73b0\u601d\u8003\u4e0e\u5de5\u5177\u7b49\u5f85\u5e76\u884c\u3002", "result": "DLLM-Searcher\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u4e3b\u6d41LLM\u641c\u7d22\u4ee3\u7406\u76f8\u5ab2\u7f8e\uff0cP-ReAct\u8303\u5f0f\u5b9e\u73b0\u4e86\u7ea615%\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "DLLM-Searcher\u6210\u529f\u89e3\u51b3\u4e86dLLM\u5728\u641c\u7d22\u4ee3\u7406\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u4e0d\u8db3\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u641c\u7d22\u4ee3\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.07031", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.07031", "abs": "https://arxiv.org/abs/2602.07031", "authors": ["Dong Li", "Shuai Huang", "Yapeng Cao", "Yujun Cui", "Xiaobin Wei", "Hongtao Cao"], "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis", "comment": null, "summary": "This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressure dissipation across multi-scale time domains, the framework integrates logarithmic time segmentation, lagged compatibility loss enforcement, and segment-wise transfer learning.\n  In forward analysis, the LBC-PINN with recommended segmentation schemes accurately predicts pore air and pore water pressure evolution. Model predictions are validated against finite element method (FEM) results, with mean absolute errors below 1e-2 for time durations up to 1e10 seconds. A simplified segmentation strategy based on the characteristic air-phase dissipation time improves computational efficiency while preserving predictive accuracy. Sensitivity analyses confirm the robustness of the framework across air-to-water permeability ratios ranging from 1e-3 to 1e3.", "AI": {"tldr": "\u63d0\u51faLBC-PINN\u65b9\u6cd5\u6a21\u62df\u4e00\u7ef4\u975e\u9971\u548c\u571f\u957f\u671f\u8377\u8f7d\u4e0b\u7684\u56fa\u7ed3\u8fc7\u7a0b\uff0c\u901a\u8fc7\u65f6\u95f4\u5206\u6bb5\u548c\u6ede\u540e\u517c\u5bb9\u6027\u635f\u5931\u89e3\u51b3\u591a\u65f6\u95f4\u5c3a\u5ea6\u8026\u5408\u95ee\u9898", "motivation": "\u975e\u9971\u548c\u571f\u56fa\u7ed3\u6d89\u53ca\u7a7a\u6c14\u548c\u6c34\u538b\u529b\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6\u8026\u5408\u6d88\u6563\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u957f\u671f\u8377\u8f7d\u4e0b\u7684\u6a21\u62df\u548c\u53cd\u6f14\u95ee\u9898", "method": "\u91c7\u7528\u6ede\u540e\u5411\u540e\u517c\u5bb9\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408\u5bf9\u6570\u65f6\u95f4\u5206\u6bb5\u3001\u6ede\u540e\u517c\u5bb9\u6027\u635f\u5931\u7ea6\u675f\u548c\u5206\u6bb5\u8fc1\u79fb\u5b66\u4e60", "result": "\u6a21\u578b\u9884\u6d4b\u4e0e\u6709\u9650\u5143\u7ed3\u679c\u543b\u5408\u826f\u597d\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u4e8e1e-2\uff08\u65f6\u95f4\u8fbe1e10\u79d2\uff09\uff1b\u57fa\u4e8e\u7279\u5f81\u7a7a\u6c14\u76f8\u6d88\u6563\u65f6\u95f4\u7684\u7b80\u5316\u5206\u6bb5\u7b56\u7565\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387", "conclusion": "LBC-PINN\u6846\u67b6\u80fd\u51c6\u786e\u9ad8\u6548\u5730\u6a21\u62df\u975e\u9971\u548c\u571f\u957f\u671f\u56fa\u7ed3\u8fc7\u7a0b\uff0c\u5bf9\u7a7a\u6c14-\u6c34\u6e17\u900f\u6bd4\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027"}}
{"id": "2602.07667", "categories": ["econ.EM", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07667", "abs": "https://arxiv.org/abs/2602.07667", "authors": ["Aysajan Eziz"], "title": "Fast Response or Silence: Conversation Persistence in an AI-Agent Social Network", "comment": "34 pages, 15 figures, 10 tables", "summary": "Autonomous AI agents are beginning to populate social platforms, but it is still unclear whether they can sustain the back-and-forth needed for extended coordination. We study Moltbook, an AI-agent social network, using a first-week snapshot and introduce interaction half-life: how quickly a comment's chance of receiving a direct reply fades as the comment ages. Across tens of thousands of commented threads, Moltbook discussions are dominated by first-layer reactions rather than extended chains. Most comments never receive a direct reply, reciprocal back-and-forth is rare, and when replies do occur they arrive almost immediately -- typically within seconds -- implying persistence on the order of minutes rather than hours. Moltbook is often described as running on an approximately four-hour ``heartbeat'' check-in schedule; using aggregate spectral tests on the longest contiguous activity window, we do not detect a reliable four-hour rhythm in this snapshot, consistent with jittered or out-of-phase individual schedules. A contemporaneous Reddit baseline analyzed with the same estimators shows substantially deeper threads and much longer reply persistence. Overall, early agent social interaction on Moltbook fits a ``fast response or silence'' regime, suggesting that sustained multi-step coordination will likely require explicit memory, thread resurfacing, and re-entry scaffolds.", "AI": {"tldr": "Moltbook AI\u793e\u4ea4\u7f51\u7edc\u4e2d\uff0c\u8ba8\u8bba\u4ee5\u5355\u5c42\u53cd\u5e94\u4e3a\u4e3b\uff0c\u56de\u590d\u96c6\u4e2d\u5728\u79d2\u7ea7\u5185\u53d1\u751f\uff0c\u7f3a\u4e4f\u6301\u7eed\u7684\u591a\u8f6e\u5bf9\u8bdd\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u7814\u7a76AI\u667a\u80fd\u4f53\u5728\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684\u534f\u8c03\u80fd\u529b\uff0c\u7279\u522b\u662f\u80fd\u5426\u7ef4\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u6301\u7eed\u4e92\u52a8\uff0c\u8fd9\u5bf9\u4e8eAI\u793e\u4ea4\u7f51\u7edc\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\"\u4ea4\u4e92\u534a\u8870\u671f\"\u6982\u5ff5\u8861\u91cf\u8bc4\u8bba\u83b7\u5f97\u76f4\u63a5\u56de\u590d\u7684\u6982\u7387\u968f\u65f6\u95f4\u8870\u51cf\u901f\u5ea6\uff1b\u5206\u6790Moltbook\u9996\u5468\u5feb\u7167\u4e2d\u6570\u4e07\u4e2a\u8bc4\u8bba\u7ebf\u7a0b\uff1b\u4f7f\u7528\u805a\u5408\u9891\u8c31\u6d4b\u8bd5\u68c0\u6d4b\u6d3b\u52a8\u8282\u594f\uff1b\u4e0eReddit\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "Moltbook\u8ba8\u8bba\u4ee5\u7b2c\u4e00\u5c42\u53cd\u5e94\u4e3a\u4e3b\uff0c\u5927\u591a\u6570\u8bc4\u8bba\u4ece\u672a\u83b7\u5f97\u76f4\u63a5\u56de\u590d\uff0c\u4e92\u60e0\u6027\u6765\u56de\u5bf9\u8bdd\u7f55\u89c1\uff1b\u56de\u590d\u51e0\u4e4e\u5728\u79d2\u7ea7\u5185\u53d1\u751f\uff0c\u6301\u4e45\u6027\u4ec5\u51e0\u5206\u949f\u800c\u975e\u5c0f\u65f6\uff1b\u672a\u68c0\u6d4b\u5230\u53ef\u9760\u76844\u5c0f\u65f6\"\u5fc3\u8df3\"\u8282\u594f\uff1bReddit\u57fa\u7ebf\u663e\u793a\u66f4\u6df1\u7ebf\u7a0b\u548c\u66f4\u957f\u56de\u590d\u6301\u4e45\u6027\u3002", "conclusion": "\u65e9\u671fAI\u793e\u4ea4\u4e92\u52a8\u5448\u73b0\"\u5feb\u901f\u54cd\u5e94\u6216\u6c89\u9ed8\"\u6a21\u5f0f\uff0c\u8981\u5b9e\u73b0\u6301\u7eed\u591a\u6b65\u534f\u8c03\u9700\u8981\u663e\u5f0f\u8bb0\u5fc6\u3001\u7ebf\u7a0b\u91cd\u65b0\u6d6e\u73b0\u548c\u91cd\u65b0\u8fdb\u5165\u652f\u67b6\u7b49\u673a\u5236\u3002"}}
{"id": "2602.07684", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07684", "abs": "https://arxiv.org/abs/2602.07684", "authors": ["Arslan Ahmad", "Ian Dobson"], "title": "Quantifying resilience for distribution system customers with SALEDI", "comment": null, "summary": "The impact of routine smaller outages on distribution system customers in terms of customer minutes interrupted can be tracked using conventional reliability indices. However, the customer minutes interrupted in large blackout events are extremely variable, and this makes it difficult to quantify the customer impact of these extreme events with resilience metrics. We solve this problem with the System Average Large Event Duration Index SALEDI that logarithmically transforms the customer minutes interrupted. We explain how this new resilience metric works, compare it with alternatives, quantify its statistical accuracy, and illustrate its practical use with standard outage data from five utilities.", "AI": {"tldr": "\u63d0\u51faSALEDI\u6307\u6807\uff0c\u901a\u8fc7\u5bf9\u505c\u7535\u5206\u949f\u6570\u8fdb\u884c\u5bf9\u6570\u53d8\u6362\uff0c\u91cf\u5316\u5927\u89c4\u6a21\u505c\u7535\u4e8b\u4ef6\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u53ef\u9760\u6027\u6307\u6807\u96be\u4ee5\u8861\u91cf\u6781\u7aef\u4e8b\u4ef6\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u53ef\u9760\u6027\u6307\u6807\u80fd\u8ffd\u8e2a\u5e38\u89c4\u5c0f\u89c4\u6a21\u505c\u7535\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u4f46\u5bf9\u4e8e\u5927\u89c4\u6a21\u505c\u7535\u4e8b\u4ef6\uff0c\u7528\u6237\u505c\u7535\u5206\u949f\u6570\u53d8\u5316\u6781\u5927\uff0c\u96be\u4ee5\u7528\u73b0\u6709\u5f39\u6027\u6307\u6807\u51c6\u786e\u91cf\u5316\u6781\u7aef\u4e8b\u4ef6\u5bf9\u7528\u6237\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u5e73\u5747\u5927\u4e8b\u4ef6\u6301\u7eed\u65f6\u95f4\u6307\u6570\uff08SALEDI\uff09\uff0c\u901a\u8fc7\u5bf9\u7528\u6237\u505c\u7535\u5206\u949f\u6570\u8fdb\u884c\u5bf9\u6570\u53d8\u6362\uff0c\u521b\u5efa\u65b0\u7684\u5f39\u6027\u5ea6\u91cf\u6307\u6807\u3002", "result": "SALEDI\u6307\u6807\u80fd\u591f\u6709\u6548\u91cf\u5316\u5927\u89c4\u6a21\u505c\u7535\u4e8b\u4ef6\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u4e0e\u66ff\u4ee3\u65b9\u6848\u76f8\u6bd4\u5177\u6709\u4f18\u52bf\uff0c\u7edf\u8ba1\u51c6\u786e\u6027\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u5728\u4e94\u5bb6\u516c\u7528\u4e8b\u4e1a\u516c\u53f8\u7684\u6807\u51c6\u505c\u7535\u6570\u636e\u4e2d\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "conclusion": "SALEDI\u4f5c\u4e3a\u65b0\u7684\u5f39\u6027\u5ea6\u91cf\u6307\u6807\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u505c\u7535\u4e8b\u4ef6\u7528\u6237\u5f71\u54cd\u91cf\u5316\u96be\u9898\uff0c\u4e3a\u914d\u7535\u7cfb\u7edf\u6781\u7aef\u4e8b\u4ef6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.07085", "categories": ["q-fin.ST", "cs.AI", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.07085", "abs": "https://arxiv.org/abs/2602.07085", "authors": ["Jun Han", "Shuo Zhang", "Wei Li", "Zhi Yang", "Yifan Dong", "Tu Hu", "Jialuo Yuan", "Xiaomin Yu", "Yumo Zhu", "Fangqi Lou", "Xin Guo", "Zhaowei Liu", "Tianyi Jiang", "Ruichuan An", "Jingping Liu", "Biao Wu", "Rongze Chen", "Kunyi Wang", "Yifan Wang", "Sen Hu", "Xinbing Kong", "Liwen Zhang", "Ronghao Chen", "Huacan Wang"], "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining", "comment": null, "summary": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.", "AI": {"tldr": "QuantaAlpha\u662f\u4e00\u4e2a\u8fdb\u5316\u5f0falpha\u6316\u6398\u6846\u67b6\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ea7\u53d8\u5f02\u548c\u4ea4\u53c9\u64cd\u4f5c\u6539\u8fdb\u56e0\u5b50\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u591a\u8f6e\u641c\u7d22\u548c\u7ecf\u9a8c\u590d\u7528\uff0c\u5728\u91d1\u878d\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u566a\u58f0\u5927\u4e14\u975e\u5e73\u7a33\uff0calpha\u6316\u6398\u5bf9\u56de\u6d4b\u566a\u58f0\u548c\u5e02\u573a\u673a\u5236\u53d8\u5316\u654f\u611f\u3002\u73b0\u6709\u667a\u80fd\u6846\u67b6\u7f3a\u4e4f\u53ef\u63a7\u7684\u591a\u8f6e\u641c\u7d22\u548c\u5df2\u9a8c\u8bc1\u7ecf\u9a8c\u7684\u53ef\u4fe1\u590d\u7528\u3002", "method": "\u5c06\u7aef\u5230\u7aef\u6316\u6398\u8fc7\u7a0b\u89c6\u4e3a\u8f68\u8ff9\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ea7\u53d8\u5f02\u548c\u4ea4\u53c9\u64cd\u4f5c\u6539\u8fdb\u56e0\u5b50\u3002\u5b9a\u4f4d\u8f68\u8ff9\u4e2d\u7684\u6b21\u4f18\u6b65\u9aa4\u8fdb\u884c\u9488\u5bf9\u6027\u4fee\u8ba2\uff0c\u91cd\u7ec4\u4e92\u8865\u7684\u9ad8\u56de\u62a5\u7247\u6bb5\u4ee5\u590d\u7528\u6709\u6548\u6a21\u5f0f\u3002\u5728\u56e0\u5b50\u751f\u6210\u4e2d\u5f3a\u5236\u5047\u8bbe\u3001\u56e0\u5b50\u8868\u8fbe\u5f0f\u548c\u53ef\u6267\u884c\u4ee3\u7801\u4e4b\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u7ea6\u675f\u56e0\u5b50\u590d\u6742\u5ea6\u548c\u5197\u4f59\u3002", "result": "\u5728\u6caa\u6df1300\u6307\u6570\u4e0a\uff0c\u4f7f\u7528GPT-5.2\u65f6\u83b7\u5f970.1501\u7684\u4fe1\u606f\u7cfb\u6570\u300127.75%\u7684\u5e74\u5316\u6536\u76ca\u7387\u548c7.98%\u7684\u6700\u5927\u56de\u64a4\u3002\u5728\u6caa\u6df1500\u548c\u6807\u666e500\u4e0a\u5206\u522b\u5b9e\u73b0160%\u548c137%\u7684\u56db\u5e74\u7d2f\u8ba1\u8d85\u989d\u6536\u76ca\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u8de8\u5e02\u573a\u7a33\u5065\u6027\u3002", "conclusion": "QuantaAlpha\u901a\u8fc7\u8fdb\u5316\u5f0f\u8f68\u8ff9\u4f18\u5316\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u63a2\u7d22\u548c\u7cbe\u7ec6\u5316\u6539\u8fdb\uff0c\u5728\u566a\u58f0\u91d1\u878d\u5e02\u573a\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684alpha\u6316\u6398\u80fd\u529b\u548c\u8de8\u5e02\u573a\u7a33\u5065\u6027\u3002"}}
{"id": "2602.07633", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.07633", "abs": "https://arxiv.org/abs/2602.07633", "authors": ["Trevor Harris"], "title": "Flow-Based Conformal Predictive Distributions", "comment": "9 pages, 6 figures, 10 appendix pages", "summary": "Conformal prediction provides a distribution-free framework for uncertainty quantification via prediction sets with exact finite-sample coverage. In low dimensions these sets are easy to interpret, but in high-dimensional or structured output spaces they are difficult to represent and use, which can limit their ability to integrate with downstream tasks such as sampling and probabilistic forecasting. We show that any differentiable nonconformity score induces a deterministic flow on the output space whose trajectories converge to the boundary of the corresponding conformal prediction set. This leads to a computationally efficient, training-free method for sampling conformal boundaries in arbitrary dimensions. Boundary samples can be reconformalized to form pointwise prediction sets with controlled risk, and mixing across confidence levels yields conformal predictive distributions whose quantile regions coincide exactly with conformal prediction sets. We evaluate the approach on PDE inverse problems, precipitation downscaling, climate model debiasing, and hurricane trajectory forecasting.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u786e\u5b9a\u6027\u6d41\u91c7\u6837\u9ad8\u7ef4\u7f6e\u4fe1\u9884\u6d4b\u96c6\u8fb9\u754c\u7684\u65b9\u6cd5\uff0c\u5c06\u7f6e\u4fe1\u9884\u6d4b\u6269\u5c55\u5230\u7ed3\u6784\u5316\u8f93\u51fa\u7a7a\u95f4", "motivation": "\u4f20\u7edf\u7f6e\u4fe1\u9884\u6d4b\u5728\u4f4e\u7ef4\u7a7a\u95f4\u5bb9\u6613\u89e3\u91ca\uff0c\u4f46\u5728\u9ad8\u7ef4\u6216\u7ed3\u6784\u5316\u8f93\u51fa\u7a7a\u95f4\u4e2d\u96be\u4ee5\u8868\u793a\u548c\u4f7f\u7528\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u91c7\u6837\u548c\u6982\u7387\u9884\u6d4b\uff09\u4e2d\u7684\u5e94\u7528", "method": "\u5229\u7528\u53ef\u5fae\u975e\u4e00\u81f4\u6027\u5206\u6570\u8bf1\u5bfc\u8f93\u51fa\u7a7a\u95f4\u4e0a\u7684\u786e\u5b9a\u6027\u6d41\uff0c\u5176\u8f68\u8ff9\u6536\u655b\u5230\u7f6e\u4fe1\u9884\u6d4b\u96c6\u8fb9\u754c\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u8fb9\u754c\u91c7\u6837\u65b9\u6cd5", "result": "\u65b9\u6cd5\u5728PDE\u53cd\u95ee\u9898\u3001\u964d\u6c34\u964d\u5c3a\u5ea6\u3001\u6c14\u5019\u6a21\u578b\u53bb\u504f\u548c\u98d3\u98ce\u8f68\u8ff9\u9884\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u751f\u6210\u70b9\u9884\u6d4b\u96c6\u548c\u7f6e\u4fe1\u9884\u6d4b\u5206\u5e03", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u7ef4\u7f6e\u4fe1\u9884\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8fb9\u754c\u91c7\u6837\u6280\u672f\uff0c\u4f7f\u7f6e\u4fe1\u9884\u6d4b\u80fd\u591f\u66f4\u597d\u5730\u96c6\u6210\u5230\u4e0b\u6e38\u4efb\u52a1\u4e2d"}}
{"id": "2602.06992", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06992", "abs": "https://arxiv.org/abs/2602.06992", "authors": ["Xiaohui Zou", "Lijun Ke", "Shunpeng Zou"], "title": "A New Mode of Teaching Chinese as a Foreign Language from the Perspective of Smart System Studied by Using Rongzhixue", "comment": "11 pages, in Chinese language, 22 figures", "summary": "The purpose of this study is to introduce a new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its characteristics are as follows: focusing on the butterfly model of interpretation before translation, highlighting the new method of bilingual thinking training, on the one hand, applying the new theory of Chinese characters, the theory of the relationship between language and speech, and the forward-looking research results of language science; On the other hand, the application of the new model of teaching Chinese as a foreign language, AI empowering teaching and learning, and the forward-looking research results of educational science fully reflect a series of characteristics of the new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its beneficial effects are: not only the old view of language and education, especially the old view of teaching Chinese as a foreign language, but also the old view of human-computer interaction. Its significance lies in that a series of great cross-border Rongzhixue such as language, knowledge, education and teaching, as well as new methods and new topics of bilingual thinking training are clearly put forward from the perspective of integrating wisdom. Especially in the face of the challenge of Chat GPT to human learning ability and even creativity, the existing concepts of language knowledge education and teaching are already very backward. The old concepts of Chinese language education, and teaching Chinese as a foreign language are all facing a series of subversive innovation challenges. How to seek changes in adaptation? This study has made a series of innovative attempts, hoping to benefit academic colleagues, teachers and students.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u667a\u6167\u89c6\u89d2\u4e0b\u7684\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u65b0\u6a21\u5f0f\uff0c\u5f3a\u8c03\u89e3\u91ca\u5148\u4e8e\u7ffb\u8bd1\u7684\u8774\u8776\u6a21\u578b\u548c\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6c49\u5b57\u65b0\u7406\u8bba\u3001\u8bed\u8a00\u79d1\u5b66\u524d\u6cbf\u6210\u679c\uff0c\u4ee5\u53caAI\u8d4b\u80fd\u6559\u5b66\uff0c\u65e8\u5728\u5e94\u5bf9ChatGPT\u7b49\u65b0\u6280\u672f\u5bf9\u4f20\u7edf\u8bed\u8a00\u6559\u80b2\u89c2\u5ff5\u7684\u98a0\u8986\u6027\u6311\u6218\u3002", "motivation": "\u9762\u5bf9ChatGPT\u7b49\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5bf9\u4eba\u7c7b\u5b66\u4e60\u80fd\u529b\u548c\u521b\u9020\u529b\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7684\u8bed\u8a00\u77e5\u8bc6\u6559\u80b2\u89c2\u5ff5\u3001\u6c49\u8bed\u6559\u80b2\u89c2\u5ff5\u4ee5\u53ca\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u89c2\u5ff5\u5df2\u7ecf\u663e\u5f97\u843d\u540e\uff0c\u9700\u8981\u8fdb\u884c\u98a0\u8986\u6027\u521b\u65b0\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u9002\u5e94\u8fd9\u79cd\u53d8\u9769\uff0c\u63d0\u51fa\u521b\u65b0\u7684\u6559\u5b66\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u878d\u5408\u667a\u6167\u89c6\u89d2\u4e0b\u7684\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u65b0\u6a21\u5f0f\uff0c\u6838\u5fc3\u662f\"\u89e3\u91ca\u5148\u4e8e\u7ffb\u8bd1\"\u7684\u8774\u8776\u6a21\u578b\uff0c\u5f3a\u8c03\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u65b0\u65b9\u6cd5\u3002\u4e00\u65b9\u9762\u5e94\u7528\u6c49\u5b57\u65b0\u7406\u8bba\u3001\u8bed\u8a00\u4e0e\u8a00\u8bed\u5173\u7cfb\u7406\u8bba\u7b49\u8bed\u8a00\u79d1\u5b66\u524d\u6cbf\u6210\u679c\uff1b\u53e6\u4e00\u65b9\u9762\u5e94\u7528AI\u8d4b\u80fd\u6559\u5b66\u7b49\u6559\u80b2\u79d1\u5b66\u524d\u6cbf\u6210\u679c\u3002", "result": "\u8be5\u6a21\u578b\u4e0d\u4ec5\u6311\u6218\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u89c2\u3001\u6559\u80b2\u89c2\u548c\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u89c2\uff0c\u8fd8\u6311\u6218\u4e86\u4f20\u7edf\u7684\u4eba\u673a\u4ea4\u4e92\u89c2\u5ff5\u3002\u660e\u786e\u63d0\u51fa\u4e86\u8bed\u8a00\u3001\u77e5\u8bc6\u3001\u6559\u80b2\u6559\u5b66\u7b49\u4e00\u7cfb\u5217\u8de8\u754c\u878d\u5408\u667a\u6167\uff0c\u4ee5\u53ca\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5\u548c\u65b0\u8bfe\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u521b\u65b0\u5c1d\u8bd5\uff0c\u63d0\u51fa\u4e86\u878d\u5408\u667a\u6167\u89c6\u89d2\u4e0b\u7684\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u65b0\u6a21\u5f0f\uff0c\u65e8\u5728\u5e94\u5bf9\u65b0\u6280\u672f\u5e26\u6765\u7684\u6559\u80b2\u6311\u6218\uff0c\u4e3a\u5b66\u672f\u754c\u540c\u884c\u3001\u6559\u5e08\u548c\u5b66\u751f\u63d0\u4f9b\u6709\u76ca\u53c2\u8003\uff0c\u63a8\u52a8\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u7684\u521b\u65b0\u53d1\u5c55\u3002"}}
{"id": "2602.07286", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07286", "abs": "https://arxiv.org/abs/2602.07286", "authors": ["Xiangting Liu", "Shengran Wang", "Kaile Yan", "Zhi-Hai Zhang"], "title": "Solving contextual chance-constrained programming under decision-dependent uncertainty", "comment": null, "summary": "We study contextual chance-constrained programming under decision-dependent uncertainty. In this setting, a decision not only needs to satisfy constraints but also alters the distribution of uncertain outcomes. This dependency makes the problem particularly difficult: because feasibility probabilities vary with decisions, it creates both statistical endogeneity and computational intractability. To address this, we propose a nonparametric approximation method based on Contextual Cluster Weights (CCW). For any given decision and context, CCW constructs a local neighborhood (cluster) of ``similar\" historical observations and assigns them equal weight. This approach successfully renders both the objective and chance constraints tractable, while providing uniform-in-decision consistency guarantees. Furthermore, we develop reformulations that use pre-calculated clusters. We show that under a specific nestedness condition, these reformulations yield a convex feasible region, which allows for efficient solving. Experiments, including a case study with JD.com, demonstrate that our method outperforms benchmarks in solution quality, feasibility reliability, and runtime. This framework offers a scalable and data-driven approach for firms to make reliable operational decisions when their actions influence uncertainty. It effectively balances performance, risk, and robustness, while remaining interpretable and implementable in practice.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0a\u4e0b\u6587\u805a\u7c7b\u6743\u91cd\uff08CCW\uff09\u7684\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u89e3\u51b3\u51b3\u7b56\u4f9d\u8d56\u4e0d\u786e\u5b9a\u6027\u7684\u4e0a\u4e0b\u6587\u673a\u4f1a\u7ea6\u675f\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u76f8\u4f3c\u5386\u53f2\u89c2\u6d4b\u7684\u5c40\u90e8\u90bb\u57df\u5b9e\u73b0\u53ef\u5904\u7406\u6027\uff0c\u5e76\u5728\u5d4c\u5957\u6761\u4ef6\u4e0b\u83b7\u5f97\u51f8\u53ef\u884c\u57df\u3002", "motivation": "\u7814\u7a76\u51b3\u7b56\u4f9d\u8d56\u4e0d\u786e\u5b9a\u6027\u7684\u4e0a\u4e0b\u6587\u673a\u4f1a\u7ea6\u675f\u89c4\u5212\u95ee\u9898\u3002\u51b3\u7b56\u4e0d\u4ec5\u9700\u8981\u6ee1\u8db3\u7ea6\u675f\uff0c\u8fd8\u4f1a\u6539\u53d8\u4e0d\u786e\u5b9a\u7ed3\u679c\u7684\u5206\u5e03\uff0c\u8fd9\u79cd\u4f9d\u8d56\u6027\u5bfc\u81f4\u7edf\u8ba1\u5185\u751f\u6027\u548c\u8ba1\u7b97\u4e0d\u53ef\u5904\u7406\u6027\uff0c\u4f7f\u5f97\u95ee\u9898\u7279\u522b\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e0a\u4e0b\u6587\u805a\u7c7b\u6743\u91cd\uff08CCW\uff09\u7684\u975e\u53c2\u6570\u8fd1\u4f3c\u65b9\u6cd5\u3002\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u51b3\u7b56\u548c\u4e0a\u4e0b\u6587\uff0cCCW\u6784\u5efa\"\u76f8\u4f3c\"\u5386\u53f2\u89c2\u6d4b\u7684\u5c40\u90e8\u90bb\u57df\uff08\u805a\u7c7b\uff09\u5e76\u8d4b\u4e88\u5b83\u4eec\u76f8\u7b49\u6743\u91cd\u3002\u8fd8\u5f00\u53d1\u4e86\u4f7f\u7528\u9884\u8ba1\u7b97\u805a\u7c7b\u7684\u91cd\u6784\u65b9\u6cd5\uff0c\u5728\u7279\u5b9a\u5d4c\u5957\u6761\u4ef6\u4e0b\u83b7\u5f97\u51f8\u53ef\u884c\u57df\u3002", "result": "\u65b9\u6cd5\u5728\u76ee\u6807\u51fd\u6570\u548c\u673a\u4f1a\u7ea6\u675f\u4e0a\u5b9e\u73b0\u53ef\u5904\u7406\u6027\uff0c\u5e76\u63d0\u4f9b\u51b3\u7b56\u4e00\u81f4\u6027\u7684\u7edf\u4e00\u4fdd\u8bc1\u3002\u5b9e\u9a8c\uff08\u5305\u62ec\u4e0e\u4eac\u4e1c\u7684\u6848\u4f8b\u7814\u7a76\uff09\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89e3\u8d28\u91cf\u3001\u53ef\u884c\u6027\u53ef\u9760\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5728\u884c\u52a8\u5f71\u54cd\u4e0d\u786e\u5b9a\u6027\u65f6\u505a\u51fa\u53ef\u9760\u7684\u64cd\u4f5c\u51b3\u7b56\u3002\u6709\u6548\u5e73\u8861\u6027\u80fd\u3001\u98ce\u9669\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u9645\u53ef\u5b9e\u65bd\u6027\u3002"}}
{"id": "2602.07120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07120", "abs": "https://arxiv.org/abs/2602.07120", "authors": ["Jacqueline He", "Jonathan Hayase", "Wen-tau Yih", "Sewoong Oh", "Luke Zettlemoyer", "Pang Wei Koh"], "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model", "comment": "51 pages, 12 figures, 16 tables. Code is publicly available at https://github.com/jacqueline-he/anchored-decoding", "summary": "Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.", "AI": {"tldr": "\u63d0\u51faAnchored Decoding\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u6291\u5236\u8bed\u8a00\u6a21\u578b\u7684\u9010\u5b57\u590d\u5236\u884c\u4e3a\uff0c\u901a\u8fc7\u5c06\u751f\u6210\u9650\u5236\u5728\u5b89\u5168\u6a21\u578b\u9644\u8fd1\uff0c\u5b9e\u73b0\u53ef\u63a7\u7684\u98ce\u9669-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u503e\u5411\u4e8e\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u5e76\u9010\u5b57\u8f93\u51fa\uff0c\u5f53\u6570\u636e\u6d89\u53ca\u654f\u611f\u6216\u7248\u6743\u4fdd\u62a4\u5185\u5bb9\u65f6\uff0c\u4f1a\u5f15\u53d1\u521b\u4f5c\u8005\u540c\u610f\u4e0e\u8865\u507f\u95ee\u9898\uff0c\u4ee5\u53ca\u5f00\u53d1\u8005\u7684\u5408\u89c4\u98ce\u9669\u3002", "method": "\u63d0\u51faAnchored Decoding\u65b9\u6cd5\uff1a1) \u5728\u63a8\u7406\u65f6\u4f7f\u7528\uff0c\u901a\u8fc7\u5c06\u751f\u6210\u9650\u5236\u5728\u5b89\u5168\u6a21\u578b\u9644\u8fd1\u6765\u6291\u5236\u9010\u5b57\u590d\u5236\uff1b2) \u81ea\u9002\u5e94\u5206\u914d\u4fe1\u606f\u9884\u7b97\u5e76\u5b9e\u65bd\u6bcf\u6b65\u7ea6\u675f\uff0c\u63d0\u4f9b\u5e8f\u5217\u7ea7\u4fdd\u8bc1\uff1b3) \u5f15\u5165TinyComma 1.8B\u5b89\u5168\u6a21\u578b\u548cAnchored$_{\\mathrm{Byte}}$ Decoding\u5b57\u8282\u7ea7\u53d8\u4f53\uff0c\u652f\u6301\u8de8\u8bcd\u6c47\u878d\u5408\u3002", "result": "\u5728\u516d\u4e2a\u6a21\u578b\u5bf9\u4e0a\u8bc4\u4f30\uff0cAnchored Decoding\u65b9\u6cd5\u5b9a\u4e49\u4e86\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff1a\u4fdd\u6301\u63a5\u8fd1\u539f\u59cb\u7684\u6d41\u7545\u6027\u548c\u4e8b\u5b9e\u6027\uff0c\u540c\u65f6\u5c06\u53ef\u6d4b\u91cf\u7684\u590d\u5236\u5dee\u8ddd\uff08\u5e73\u5747\u516d\u4e2a\u590d\u5236\u6307\u6807\uff09\u51cf\u5c11\u9ad8\u8fbe75%\uff0c\u63a8\u7406\u5f00\u9500\u9002\u4e2d\u3002", "conclusion": "Anchored Decoding\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u63a8\u7406\u65f6\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u6291\u5236\u8bed\u8a00\u6a21\u578b\u7684\u9010\u5b57\u590d\u5236\u884c\u4e3a\uff0c\u5728\u7248\u6743\u98ce\u9669\u548c\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u5b9e\u73b0\u53ef\u8c03\u6743\u8861\uff0c\u4e3a\u5904\u7406\u6df7\u5408\u8bb8\u53ef\u6570\u636e\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07040", "abs": "https://arxiv.org/abs/2602.07040", "authors": ["Emmett Bicker"], "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods", "comment": "Available at www.asterlab.ai, 25 pages, 8 figures, 4 tables", "summary": "We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs.\n  We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute.\n  Aster is accessible via a web interface and API at asterlab.ai.", "AI": {"tldr": "Aster\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7684AI\u4ee3\u7406\uff0c\u6bd4\u73b0\u6709\u6846\u67b6\u5feb20\u500d\u4ee5\u4e0a\uff0c\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u7a0b\u5e8f\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8bc4\u4f30\u65f6\u95f4\u957f\u7684\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\u8fed\u4ee3\u901f\u5ea6\u6162\uff0c\u96be\u4ee5\u5904\u7406\u8bc4\u4f30\u65f6\u95f4\u957f\u7684\u4efb\u52a1\uff08\u5982\u6570\u5c0f\u65f6\u7684\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\uff09\uff0c\u9650\u5236\u4e86\u53ef\u5904\u7406\u95ee\u9898\u7684\u8303\u56f4\u3002", "method": "\u7ed9\u5b9a\u4efb\u52a1\u3001\u521d\u59cb\u7a0b\u5e8f\u548c\u8bc4\u4f30\u811a\u672c\uff0cAster\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u7a0b\u5e8f\u6765\u63d0\u5347\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u53d1\u73b0\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u3002", "result": "\u5728\u6570\u5b66\u3001GPU\u5185\u6838\u5de5\u7a0b\u3001\u751f\u7269\u5b66\u3001\u795e\u7ecf\u79d1\u5b66\u548c\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7b49\u591a\u4e2a\u9886\u57df\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u5728ZAPBench\u4e0a\u4ee5\u4e0d\u52301/190\u7684\u8ba1\u7b97\u91cf\u5339\u914d\u6700\u4f73\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Aster\u901a\u8fc7\u5927\u5e45\u52a0\u901f\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u8fc7\u7a0b\uff0c\u6269\u5c55\u4e86\u53ef\u5904\u7406\u95ee\u9898\u7684\u9886\u57df\uff0c\u7279\u522b\u662f\u5728\u8bc4\u4f30\u65f6\u95f4\u957f\u7684\u4efb\u52a1\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2602.07033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07033", "abs": "https://arxiv.org/abs/2602.07033", "authors": ["Md Shahriar Kabir", "Sana Alamgeer", "Minakshi Debnath", "Anne H. H. Ngu"], "title": "TransConv-DDPM: Enhanced Diffusion Model for Generating Time-Series Data in Healthcare", "comment": "Previously published at IEEE COMPSAC 2025", "summary": "The lack of real-world data in clinical fields poses a major obstacle in training effective AI models for diagnostic and preventive tools in medicine. Generative AI has shown promise in increasing data volume and enhancing model training, particularly in computer vision and natural language processing (NLP) domains. However, generating physiological time-series data, a common type in medical AI applications, presents unique challenges due to its inherent complexity and variability. This paper introduces TransConv-DDPM, an enhanced generative AI method for biomechanical and physiological time-series data generation. The model employs a denoising diffusion probabilistic model (DDPM) with U-Net, multi-scale convolution modules, and a transformer layer to capture both global and local temporal dependencies. We evaluated TransConv-DDPM on three diverse datasets, generating both long and short-sequence time-series data. Quantitative comparisons against state-of-the-art methods, TimeGAN and Diffusion-TS, using four performance metrics, demonstrated promising results, particularly on the SmartFallMM and EEG datasets, where it effectively captured the more gradual temporal change patterns between data points. Additionally, a utility test on the SmartFallMM dataset revealed that adding synthetic fall data generated by TransConv-DDPM improved predictive model performance, showing a 13.64% improvement in F1-score and a 14.93% increase in overall accuracy compared to the baseline model trained solely on fall data from the SmartFallMM dataset. These findings highlight the potential of TransConv-DDPM to generate high-quality synthetic data for real-world applications.", "AI": {"tldr": "TransConv-DDPM\uff1a\u4e00\u79cd\u7528\u4e8e\u751f\u6210\u751f\u7269\u529b\u5b66\u548c\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u589e\u5f3a\u578b\u751f\u6210AI\u65b9\u6cd5\uff0c\u7ed3\u5408DDPM\u3001U-Net\u3001\u591a\u5c3a\u5ea6\u5377\u79ef\u548cTransformer\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u63d0\u5347\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e34\u5e8a\u9886\u57df\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u6570\u636e\u963b\u788d\u4e86\u533b\u7597AI\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u751f\u6210\u5f0fAI\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548cNLP\u9886\u57df\u5df2\u663e\u793a\u6f5c\u529b\uff0c\u4f46\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u56e0\u5176\u590d\u6742\u6027\u548c\u53d8\u5f02\u6027\u800c\u9762\u4e34\u72ec\u7279\u6311\u6218\u3002", "method": "\u63d0\u51faTransConv-DDPM\u65b9\u6cd5\uff0c\u91c7\u7528\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff08DDPM\uff09\u7ed3\u5408U-Net\u67b6\u6784\u3001\u591a\u5c3a\u5ea6\u5377\u79ef\u6a21\u5757\u548cTransformer\u5c42\uff0c\u4ee5\u6355\u6349\u5168\u5c40\u548c\u5c40\u90e8\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0eTimeGAN\u548cDiffusion-TS\u76f8\u6bd4\uff0c\u5728SmartFallMM\u548cEEG\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6709\u6548\u6355\u6349\u6570\u636e\u70b9\u95f4\u6e10\u53d8\u7684\u65f6\u95f4\u6a21\u5f0f\u3002\u5728SmartFallMM\u6570\u636e\u96c6\u4e0a\uff0c\u6dfb\u52a0\u5408\u6210\u6570\u636e\u4f7f\u9884\u6d4b\u6a21\u578b\u7684F1\u5206\u6570\u63d0\u534713.64%\uff0c\u6574\u4f53\u51c6\u786e\u7387\u63d0\u534714.93%\u3002", "conclusion": "TransConv-DDPM\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u53ef\u89e3\u51b3\u533b\u7597AI\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2602.07769", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07769", "abs": "https://arxiv.org/abs/2602.07769", "authors": ["Jiasong Han", "Xuehan Wang", "Jingbo Tan", "Jintao Wang", "Yu Zhang", "Hai Lin", "Jinhong Yuan"], "title": "Channel Estimation with Hierarchical Sparse Bayesian Learning for ODDM Systems", "comment": "Accepted by IEEE International Conference on Communications (ICC) 2026", "summary": "Orthogonal delay-Doppler division multiplexing (ODDM) is a promising modulation technique for reliable communications in high-mobility scenarios. However, the existing channel estimation frameworks for ODDM systems cannot achieve both high accuracy and low complexity simultaneously, due to the inherent coupling of delay and Doppler parameters. To address this problem, a two-dimensional (2D) hierarchical sparse Bayesian learning (HSBL) based channel estimation framework is proposed in this paper. Specifically, we address the inherent coupling between delay and Doppler dimensions in ODDM by developing a partially-decoupled 2D sparse signal recovery (SSR) formulation on a virtual sampling grid defined in the delay-Doppler (DD) domain. With the help of the partially-decoupled formulation, the proposed 2D HSBL framework first performs low-complexity coarse on-grid 2D sparse Bayesian learning (SBL) estimation to identify potential channel paths. Then, high-resolution fine grids are constructed around these regions, where an off-grid 2D SBL estimation is applied to achieve accurate channel estimation. Simulation results demonstrate that the proposed framework achieves performance superior to conventional off-grid 2D SBL with significantly reduced computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e8c\u7ef4\u5206\u5c42\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60\u7684ODDM\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u89e3\u8026\u548c\u5206\u5c42\u7f51\u683c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4f4e\u590d\u6742\u5ea6\u4fe1\u9053\u4f30\u8ba1", "motivation": "\u73b0\u6709ODDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u590d\u6742\u5ea6\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u53c2\u6570\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u8026\u5408\u5173\u7cfb", "method": "\u63d0\u51fa\u4e8c\u7ef4\u5206\u5c42\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60\u6846\u67b6\uff1a1\uff09\u5728\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u5b9a\u4e49\u865a\u62df\u91c7\u6837\u7f51\u683c\uff0c\u5efa\u7acb\u90e8\u5206\u89e3\u8026\u7684\u4e8c\u7ef4\u7a00\u758f\u4fe1\u53f7\u6062\u590d\u6a21\u578b\uff1b2\uff09\u5148\u8fdb\u884c\u4f4e\u590d\u6742\u5ea6\u7c97\u7f51\u683c2D SBL\u4f30\u8ba1\u8bc6\u522b\u6f5c\u5728\u4fe1\u9053\u8def\u5f84\uff1b3\uff09\u5728\u8bc6\u522b\u533a\u57df\u6784\u5efa\u9ad8\u5206\u8fa8\u7387\u7ec6\u7f51\u683c\uff0c\u8fdb\u884c\u79bb\u7f51\u683c2D SBL\u4f30\u8ba1", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u79bb\u7f51\u683c2D SBL\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6", "conclusion": "\u8be5\u4e8c\u7ef4\u5206\u5c42\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86ODDM\u7cfb\u7edf\u4e2d\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u53c2\u6570\u7684\u8026\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u590d\u6742\u5ea6\u7684\u4fe1\u9053\u4f30\u8ba1"}}
{"id": "2602.07811", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07811", "abs": "https://arxiv.org/abs/2602.07811", "authors": ["Xiaohan Xu", "Wei Ma", "Zhiheng Shi", "Xiaotong Xu", "Bin He", "Kairui Feng"], "title": "Urban Congestion Patterns under High Electric Vehicle Penetration: A Case Study of 10 U.S. Cities", "comment": null, "summary": "With the global energy transition and the rapid penetration of electric vehicles (EVs), the widening travel cost gap between EVs and gasoline vehicles (GVs) increasingly affects commuters' route choices and may reshape urban congestion patterns. Existing research remains in its preliminary exploratory phase. On the one hand, multi-class models do not account for fixed user class scenarios, which may not align with actual commuters; on the other hand, there is a lack of systematic quantitative analysis based on real-world complex road networks across multiple cities. As a result, the congestion effects induced by heterogeneous GV-EV cost structures may be mischaracterized or substantially underestimated. To address these limitations, this paper proposes a multi-user equilibrium (MUE) assignment model for mixed GV-EV traffic, constructs a dual algorithm with convergence guarantees, and designs multi-dimensional evaluation metrics for congestion patterns. Using 10 representative U.S. cities as a case study, this research explores the evolution trends of traffic congestion under different EV penetration scenarios based on real city-level road networks and block-level commuter origin-destination (OD) demand. The results show that full EV penetration reduces average system travel time by 2.27%--10.78% across the 10 cities, with New Orleans achieving the largest reduction (10.78%) and San Francisco the smallest (2.27%), but the effectiveness of alleviating congestion exhibits urban heterogeneity. Moreover, for cities with sufficient network redundancy, benefits are primarily concentrated during the low to medium EV penetration stage (0-0.5), though cities with topological constraints (e.g., San Francisco) show more limited improvements throughout all penetration levels. This paper can provide a foundation for formulating differentiated urban planning and congestion management policies.", "AI": {"tldr": "\u7814\u7a76\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\u5bf9\u57ce\u5e02\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5168\u7535\u52a8\u5316\u53ef\u964d\u4f4e\u5e73\u5747\u51fa\u884c\u65f6\u95f42.27%-10.78%\uff0c\u4f46\u6548\u679c\u56e0\u57ce\u5e02\u800c\u5f02", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u5feb\u901f\u666e\u53ca\uff0cEV\u4e0e\u6c7d\u6cb9\u8f66\u7684\u51fa\u884c\u6210\u672c\u5dee\u5f02\u5f71\u54cd\u901a\u52e4\u8005\u8def\u7ebf\u9009\u62e9\uff0c\u53ef\u80fd\u91cd\u5851\u57ce\u5e02\u62e5\u5835\u6a21\u5f0f\u3002\u73b0\u6709\u7814\u7a76\u5b58\u5728\u5c40\u9650\uff1a\u591a\u7c7b\u522b\u6a21\u578b\u672a\u8003\u8651\u56fa\u5b9a\u7528\u6237\u7c7b\u522b\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u771f\u5b9e\u590d\u6742\u8def\u7f51\u7684\u7cfb\u7edf\u91cf\u5316\u5206\u6790\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bf9\u5f02\u8d28\u6210\u672c\u7ed3\u6784\u62e5\u5835\u6548\u5e94\u7684\u8bef\u5224\u6216\u4f4e\u4f30\u3002", "method": "\u63d0\u51fa\u6df7\u5408GV-EV\u4ea4\u901a\u7684\u591a\u7528\u6237\u5747\u8861\u5206\u914d\u6a21\u578b\uff0c\u6784\u5efa\u5177\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u5bf9\u5076\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u591a\u7ef4\u62e5\u5835\u6a21\u5f0f\u8bc4\u4f30\u6307\u6807\u3002\u4ee510\u4e2a\u7f8e\u56fd\u4ee3\u8868\u6027\u57ce\u5e02\u4e3a\u6848\u4f8b\uff0c\u57fa\u4e8e\u771f\u5b9e\u57ce\u5e02\u7ea7\u8def\u7f51\u548c\u8857\u533a\u7ea7\u901a\u52e4OD\u9700\u6c42\uff0c\u63a2\u7d22\u4e0d\u540cEV\u6e17\u900f\u7387\u4e0b\u7684\u4ea4\u901a\u62e5\u5835\u6f14\u53d8\u8d8b\u52bf\u3002", "result": "\u5168EV\u6e17\u900f\u4f7f10\u4e2a\u57ce\u5e02\u7684\u5e73\u5747\u7cfb\u7edf\u51fa\u884c\u65f6\u95f4\u51cf\u5c112.27%-10.78%\uff0c\u65b0\u5965\u5c14\u826f\u964d\u5e45\u6700\u5927(10.78%)\uff0c\u65e7\u91d1\u5c71\u6700\u5c0f(2.27%)\u3002\u5bf9\u4e8e\u7f51\u7edc\u5197\u4f59\u5145\u8db3\u7684\u57ce\u5e02\uff0c\u6548\u76ca\u4e3b\u8981\u96c6\u4e2d\u5728\u4e2d\u4f4eEV\u6e17\u900f\u9636\u6bb5(0-0.5)\uff0c\u800c\u5177\u6709\u62d3\u6251\u7ea6\u675f\u7684\u57ce\u5e02(\u5982\u65e7\u91d1\u5c71)\u5728\u6240\u6709\u6e17\u900f\u6c34\u5e73\u6539\u5584\u6709\u9650\u3002", "conclusion": "EV\u666e\u53ca\u5bf9\u7f13\u89e3\u4ea4\u901a\u62e5\u5835\u7684\u6548\u679c\u5b58\u5728\u57ce\u5e02\u5f02\u8d28\u6027\uff0c\u4e3a\u5236\u5b9a\u5dee\u5f02\u5316\u7684\u57ce\u5e02\u89c4\u5212\u4e0e\u62e5\u5835\u7ba1\u7406\u653f\u7b56\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u662f\u5f71\u54cdEV\u6548\u76ca\u5b9e\u73b0\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.07096", "categories": ["q-fin.ST", "cs.AI", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.07096", "abs": "https://arxiv.org/abs/2602.07096", "authors": ["Yuyang Dai", "Yan Lin", "Zhuohan Xie", "Yuxia Wang"], "title": "RealFin: How Well Do LLMs Reason About Finance When Users Leave Things Unsaid?", "comment": null, "summary": "Reliable financial reasoning requires knowing not only how to answer, but also when an answer cannot be justified. In real financial practice, problems often rely on implicit assumptions that are taken for granted rather than stated explicitly, causing problems to appear solvable while lacking enough information for a definite answer. We introduce REALFIN, a bilingual benchmark that evaluates financial reasoning by systematically removing essential premises from exam-style questions while keeping them linguistically plausible. Based on this, we evaluate models under three formulations that test answering, recognizing missing information, and rejecting unjustified options, and find consistent performance drops when key conditions are absent. General-purpose models tend to over-commit and guess, while most finance-specialized models fail to clearly identify missing premises. These results highlight a critical gap in current evaluations and show that reliable financial models must know when a question should not be answered.", "AI": {"tldr": "REALFIN\u662f\u4e00\u4e2a\u53cc\u8bed\u91d1\u878d\u63a8\u7406\u57fa\u51c6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u5173\u952e\u524d\u63d0\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u4fe1\u606f\u4e0d\u8db3\u65f6\u80fd\u5426\u8bc6\u522b\u65e0\u6cd5\u56de\u7b54\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u731c\u6d4b\u548c\u65e0\u6cd5\u8bc6\u522b\u7f3a\u5931\u4fe1\u606f\u7684\u95ee\u9898\u3002", "motivation": "\u91d1\u878d\u5b9e\u8df5\u4e2d\u95ee\u9898\u5f80\u5f80\u4f9d\u8d56\u9690\u542b\u5047\u8bbe\uff0c\u5bfc\u81f4\u770b\u4f3c\u53ef\u89e3\u4f46\u5b9e\u9645\u7f3a\u4e4f\u8db3\u591f\u4fe1\u606f\u7ed9\u51fa\u786e\u5b9a\u7b54\u6848\u3002\u73b0\u6709\u8bc4\u4f30\u672a\u80fd\u5145\u5206\u6d4b\u8bd5\u6a21\u578b\u5728\u4fe1\u606f\u4e0d\u8db3\u65f6\u7684\u8868\u73b0\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u91d1\u878d\u63a8\u7406\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faREALFIN\u53cc\u8bed\u57fa\u51c6\uff0c\u4ece\u8003\u8bd5\u98ce\u683c\u95ee\u9898\u4e2d\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u5173\u952e\u524d\u63d0\u4f46\u4fdd\u6301\u8bed\u8a00\u5408\u7406\u6027\u3002\u901a\u8fc7\u4e09\u79cd\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\uff1a\u56de\u7b54\u95ee\u9898\u3001\u8bc6\u522b\u7f3a\u5931\u4fe1\u606f\u3001\u62d2\u7edd\u4e0d\u5408\u7406\u9009\u9879\u3002", "result": "\u5f53\u5173\u952e\u6761\u4ef6\u7f3a\u5931\u65f6\uff0c\u6240\u6709\u6a21\u578b\u6027\u80fd\u5747\u4e0b\u964d\u3002\u901a\u7528\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u627f\u8bfa\u548c\u731c\u6d4b\uff0c\u800c\u5927\u591a\u6570\u91d1\u878d\u4e13\u7528\u6a21\u578b\u65e0\u6cd5\u6e05\u6670\u8bc6\u522b\u7f3a\u5931\u524d\u63d0\u3002\u6a21\u578b\u5728\u8bc6\u522b\u4f55\u65f6\u4e0d\u5e94\u56de\u7b54\u95ee\u9898\u4e0a\u5b58\u5728\u660e\u663e\u7f3a\u9677\u3002", "conclusion": "\u5f53\u524d\u8bc4\u4f30\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u53ef\u9760\u7684\u91d1\u878d\u6a21\u578b\u5fc5\u987b\u77e5\u9053\u4f55\u65f6\u4e0d\u5e94\u56de\u7b54\u95ee\u9898\u3002REALFIN\u57fa\u51c6\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4fe1\u606f\u4e0d\u8db3\u65f6\u7684\u63a8\u7406\u7f3a\u9677\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u91d1\u878dAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2602.07710", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07710", "abs": "https://arxiv.org/abs/2602.07710", "authors": ["Jiaxun Li", "Vinod Raman", "Ambuj Tewari"], "title": "On Generation in Metric Spaces", "comment": null, "summary": "We study generation in separable metric instance spaces. We extend the language generation framework from Kleinberg and Mullainathan [2024] beyond countable domains by defining novelty through metric separation and allowing asymmetric novelty parameters for the adversary and the generator. We introduce the $(\\varepsilon,\\varepsilon')$-closure dimension, a scale-sensitive analogue of closure dimension, which yields characterizations of uniform and non-uniform generatability and a sufficient condition for generation in the limit. Along the way, we identify a sharp geometric contrast. Namely, in doubling spaces, including all finite-dimensional normed spaces, generatability is stable across novelty scales and invariant under equivalent metrics. In general metric spaces, however, generatability can be highly scale-sensitive and metric-dependent; even in the natural infinite-dimensional Hilbert space $\\ell^2$, all notions of generation may fail abruptly as the novelty parameters vary.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u8bed\u8a00\u751f\u6210\u6846\u67b6\u6269\u5c55\u5230\u53ef\u5206\u5ea6\u91cf\u7a7a\u95f4\uff0c\u901a\u8fc7\u5ea6\u91cf\u5206\u79bb\u5b9a\u4e49\u65b0\u9896\u6027\uff0c\u5f15\u5165(\u03b5,\u03b5')-\u95ed\u5305\u7ef4\u5ea6\u6765\u523b\u753b\u751f\u6210\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5728\u52a0\u500d\u7a7a\u95f4\u4e0e\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u751f\u6210\u7a33\u5b9a\u6027\u7684\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u5c06Kleinberg\u548cMullainathan[2024]\u7684\u8bed\u8a00\u751f\u6210\u6846\u67b6\u4ece\u53ef\u6570\u57df\u6269\u5c55\u5230\u53ef\u5206\u5ea6\u91cf\u7a7a\u95f4\uff0c\u901a\u8fc7\u5ea6\u91cf\u5206\u79bb\u5b9a\u4e49\u65b0\u9896\u6027\uff0c\u5141\u8bb8\u5bf9\u6297\u65b9\u548c\u751f\u6210\u65b9\u5177\u6709\u4e0d\u5bf9\u79f0\u7684\u65b0\u9896\u6027\u53c2\u6570\uff0c\u4ece\u800c\u5728\u66f4\u4e00\u822c\u7684\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u7814\u7a76\u751f\u6210\u95ee\u9898\u3002", "method": "\u5f15\u5165(\u03b5,\u03b5')-\u95ed\u5305\u7ef4\u5ea6\u4f5c\u4e3a\u95ed\u5305\u7ef4\u5ea6\u7684\u5c3a\u5ea6\u654f\u611f\u7c7b\u6bd4\uff0c\u7528\u4e8e\u523b\u753b\u5747\u5300\u548c\u975e\u5747\u5300\u751f\u6210\u80fd\u529b\uff1b\u901a\u8fc7\u5ea6\u91cf\u5206\u79bb\u5b9a\u4e49\u65b0\u9896\u6027\uff0c\u5141\u8bb8\u4e0d\u5bf9\u79f0\u7684\u65b0\u9896\u6027\u53c2\u6570\uff1b\u5728\u53ef\u5206\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u5efa\u7acb\u751f\u6210\u7406\u8bba\u6846\u67b6\u3002", "result": "\u5728\u52a0\u500d\u7a7a\u95f4\uff08\u5305\u62ec\u6240\u6709\u6709\u9650\u7ef4\u8d4b\u8303\u7a7a\u95f4\uff09\u4e2d\uff0c\u751f\u6210\u80fd\u529b\u5728\u4e0d\u540c\u65b0\u9896\u6027\u5c3a\u5ea6\u4e0b\u662f\u7a33\u5b9a\u7684\uff0c\u5e76\u4e14\u5728\u7b49\u4ef7\u5ea6\u91cf\u4e0b\u4fdd\u6301\u4e0d\u53d8\uff1b\u4f46\u5728\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u4e2d\uff0c\u751f\u6210\u80fd\u529b\u53ef\u80fd\u9ad8\u5ea6\u5c3a\u5ea6\u654f\u611f\u4e14\u4f9d\u8d56\u4e8e\u5177\u4f53\u5ea6\u91cf\uff1b\u5373\u4f7f\u5728\u81ea\u7136\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u2113\u00b2\u4e2d\uff0c\u968f\u7740\u65b0\u9896\u6027\u53c2\u6570\u53d8\u5316\uff0c\u6240\u6709\u751f\u6210\u6982\u5ff5\u90fd\u53ef\u80fd\u7a81\u7136\u5931\u6548\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u8bed\u8a00\u751f\u6210\u6846\u67b6\u5230\u53ef\u5206\u5ea6\u91cf\u7a7a\u95f4\uff0c\u63ed\u793a\u4e86\u5ea6\u91cf\u7a7a\u95f4\u51e0\u4f55\u7279\u6027\u5bf9\u751f\u6210\u80fd\u529b\u7684\u6df1\u523b\u5f71\u54cd\uff1a\u5728\u52a0\u500d\u7a7a\u95f4\u4e2d\u751f\u6210\u5177\u6709\u7a33\u5b9a\u6027\uff0c\u800c\u5728\u4e00\u822c\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u751f\u6210\u53ef\u80fd\u9ad8\u5ea6\u4e0d\u7a33\u5b9a\uff0c\u8fd9\u4e3a\u7406\u89e3\u751f\u6210\u7b97\u6cd5\u7684\u7406\u8bba\u6781\u9650\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\u3002"}}
{"id": "2602.06998", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06998", "abs": "https://arxiv.org/abs/2602.06998", "authors": ["Andhika Bernard Lumbantobing", "Hokky Situngkir"], "title": "Tokenizations for Austronesian Language Models: study on languages in Indonesia Archipelago", "comment": "14 pages, 3 figures", "summary": "Tokenization constitutes a fundamental stage in Large Language Model (LLM) processing; however, subword-based tokenization methods optimized on English-dominant corpora may produce token fragmentation misaligned with the linguistic structures of Austronesian languages. This study aimed to develop a syllable-based tokenization framework adopting principles from traditional Indonesian scripts (aksara) for regional languages of Indonesia. A syllabic segmentation procedure was constructed based on the logic of abugida writing systems and implemented with a vocabulary of 2,843 tokens extracted from the Indonesian dictionary (KBBI). Evaluation was conducted on the NusaX dataset comprising 1,000 parallel translation samples across 10 regional languages, Indonesian, and English. Analysis employed Token per Character (TPC) ratio and sequence alignment using the Smith-Waterman algorithm. Results demonstrated that syllable-based tokenization yielded consistent TPC values across all regional languages, whereas GPT-2 exhibited an inverse pattern with the lowest TPC for English. Syllable-based tokenization consistently produced higher token sequence similarity scores, with an average increase of approximately 21% compared to GPT-2. These findings confirm that the syllable-based approach more effectively preserves phonological and morphological patterns across related Austronesian languages, offering a linguistically principled foundation for multilingual LLM development.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u97f3\u8282\u7684\u5206\u8bcd\u6846\u67b6\uff0c\u91c7\u7528\u5370\u5c3c\u4f20\u7edf\u6587\u5b57\u539f\u5219\uff0c\u4e3a\u5370\u5c3c\u5730\u533a\u8bed\u8a00\u63d0\u4f9b\u66f4\u7b26\u5408\u8bed\u8a00\u7ed3\u6784\u7684tokenization\u65b9\u6cd5\u3002", "motivation": "\u57fa\u4e8e\u82f1\u8bed\u8bed\u6599\u4f18\u5316\u7684\u5b50\u8bcd\u5206\u8bcd\u65b9\u6cd5\u5728\u5904\u7406\u5357\u5c9b\u8bed\u7cfb\u8bed\u8a00\u65f6\u4f1a\u4ea7\u751f\u4e0e\u8bed\u8a00\u7ed3\u6784\u4e0d\u5339\u914d\u7684token\u788e\u7247\u5316\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7b26\u5408\u8bed\u8a00\u5b66\u7684\u5206\u8bcd\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eabugida\u6587\u5b57\u7cfb\u7edf\u903b\u8f91\u6784\u5efa\u97f3\u8282\u5206\u5272\u7a0b\u5e8f\uff0c\u4ece\u5370\u5c3c\u8bcd\u5178\u63d0\u53d62,843\u4e2atoken\u6784\u5efa\u8bcd\u6c47\u8868\uff0c\u5728NusaX\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528TPC\u6bd4\u7387\u548cSmith-Waterman\u7b97\u6cd5\u8fdb\u884c\u5e8f\u5217\u5bf9\u9f50\u5206\u6790\u3002", "result": "\u97f3\u8282\u5206\u8bcd\u5728\u6240\u6709\u5730\u533a\u8bed\u8a00\u4e2d\u4ea7\u751f\u4e00\u81f4\u7684TPC\u503c\uff0c\u800cGPT-2\u5448\u73b0\u76f8\u53cd\u6a21\u5f0f\uff08\u82f1\u8bedTPC\u6700\u4f4e\uff09\u3002\u97f3\u8282\u5206\u8bcdtoken\u5e8f\u5217\u76f8\u4f3c\u5ea6\u5f97\u5206\u5e73\u5747\u63d0\u9ad8\u7ea621%\u3002", "conclusion": "\u97f3\u8282\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u4fdd\u7559\u76f8\u5173\u5357\u5c9b\u8bed\u7cfb\u8bed\u8a00\u7684\u97f3\u7cfb\u548c\u5f62\u6001\u6a21\u5f0f\uff0c\u4e3a\u591a\u8bed\u8a00LLM\u5f00\u53d1\u63d0\u4f9b\u8bed\u8a00\u5b66\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.07288", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07288", "abs": "https://arxiv.org/abs/2602.07288", "authors": ["Jihun Kim", "Javad Lavaei"], "title": "On the Necessity of Two-Stage Estimation for Learning Dynamical Systems under Both Noise and Node-Wise Attacks", "comment": "33 pages", "summary": "The least-squares estimator has achieved considerable success in learning linear dynamical systems from a single trajectory of length $T$. While it attains an optimal error of $\\mathcal{O}(1/\\sqrt{T})$ under independent zero-mean noise, it lacks robustness and is particularly susceptible to adversarial corruption. In this paper, we consider the identification of a networked system in which every node is subject to both noise and adversarial attacks. We assume that every node is independently corrupted with probability smaller than $0.5$ at each time, placing the overall system under almost-persistent local attack. We first show that no convex one-stage estimator can achieve a consistent estimate as $T$ grows under both noise and attacks. This motivates the development of a two-stage estimation method applied across nodes. In Stage I, we leverage the $\\ell_1$-norm estimator and derive an estimation error bound proportional to the noise level $\u03c3_w$. This bound is subsequently used to detect and filter out attacks, producing a clean dataset for each node, to which we apply the least-squares estimator in Stage II. The resulting estimation error is on the order $\\mathcal{O}(1/\\sqrt{T})$ plus the product of $\u03c3_w$ and the number of misclassifications. In the event of perfect separability between attack and non-attack data, which occurs when injected attacks are sufficiently large relative to the noise scale, our two-stage estimator is consistent for the true system.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u566a\u58f0\u548c\u5bf9\u6297\u653b\u51fb\u540c\u65f6\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u7f51\u7edc\u5316\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u5668\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7f3a\u4e4f\u9c81\u68d2\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u5668\u5728\u72ec\u7acb\u96f6\u5747\u503c\u566a\u58f0\u4e0b\u80fd\u8fbe\u5230\u6700\u4f18\u8bef\u5deeO(1/\u221aT)\uff0c\u4f46\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u7279\u522b\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\u7684\u5f71\u54cd\u3002\u5728\u7f51\u7edc\u5316\u7cfb\u7edf\u4e2d\uff0c\u6bcf\u4e2a\u8282\u70b9\u540c\u65f6\u53d7\u5230\u566a\u58f0\u548c\u5bf9\u6297\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u4f30\u8ba1\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u2113\u2081-\u8303\u6570\u4f30\u8ba1\u5668\uff0c\u5f97\u5230\u4e0e\u566a\u58f0\u6c34\u5e73\u03c3_w\u6210\u6bd4\u4f8b\u7684\u8bef\u5dee\u754c\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u8fc7\u6ee4\u653b\u51fb\uff0c\u4e3a\u6bcf\u4e2a\u8282\u70b9\u751f\u6210\u5e72\u51c0\u6570\u636e\u96c6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5bf9\u5e72\u51c0\u6570\u636e\u5e94\u7528\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u5668\u3002", "result": "\u4f30\u8ba1\u8bef\u5dee\u4e3aO(1/\u221aT)\u52a0\u4e0a\u03c3_w\u4e0e\u8bef\u5206\u7c7b\u6570\u7684\u4e58\u79ef\u3002\u5f53\u653b\u51fb\u6570\u636e\u4e0e\u975e\u653b\u51fb\u6570\u636e\u5b8c\u5168\u53ef\u5206\u65f6\uff08\u5373\u6ce8\u5165\u7684\u653b\u51fb\u76f8\u5bf9\u4e8e\u566a\u58f0\u5c3a\u5ea6\u8db3\u591f\u5927\uff09\uff0c\u4e24\u9636\u6bb5\u4f30\u8ba1\u5668\u5bf9\u771f\u5b9e\u7cfb\u7edf\u662f\u4e00\u81f4\u7684\u3002", "conclusion": "\u8bba\u6587\u8bc1\u660e\u4e86\u5728\u566a\u58f0\u548c\u653b\u51fb\u540c\u65f6\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\uff0c\u4efb\u4f55\u51f8\u5355\u9636\u6bb5\u4f30\u8ba1\u5668\u90fd\u65e0\u6cd5\u83b7\u5f97\u4e00\u81f4\u4f30\u8ba1\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u4e24\u9636\u6bb5\u4f30\u8ba1\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u653b\u51fb\u4e0e\u566a\u58f0\u53ef\u5206\u79bb\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u5b9e\u73b0\u4e00\u81f4\u4f30\u8ba1\uff0c\u4e3a\u7f51\u7edc\u5316\u7cfb\u7edf\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u7684\u8bc6\u522b\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07160", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07160", "abs": "https://arxiv.org/abs/2602.07160", "authors": ["Jiecheng Lu", "Shihao Yang"], "title": "Free Energy Mixer", "comment": "Camera-ready version. Accepted at ICLR 2026", "summary": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.", "AI": {"tldr": "\u63d0\u51faFree Energy Mixer (FEM)\uff0c\u4e00\u79cd\u57fa\u4e8e\u81ea\u7531\u80fd\uff08log-sum-exp\uff09\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u503c\u9a71\u52a8\u7684\u6bcf\u901a\u9053\u5bf9\u6570\u7ebf\u6027\u503e\u659c\u6765\u6539\u8fdb\u6807\u51c6\u6ce8\u610f\u529b\uff0c\u5b9e\u73b0\u4ece\u5e73\u5747\u5230\u9009\u62e9\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002", "motivation": "\u6807\u51c6\u6ce8\u610f\u529b\u901a\u8fc7\u6bcf\u5934\u51f8\u5e73\u5747\u8bfb\u53d6\u952e\u503c\uff0c\u65e0\u6cd5\u5b9e\u73b0\u901a\u9053\u7ea7\u9009\u62e9\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u5e76\u884c\u6027\u548c\u590d\u6742\u5ea6\uff0c\u53c8\u80fd\u5b9e\u73b0\u503c\u9a71\u52a8\u9009\u62e9\u7684\u65b9\u6cd5\u3002", "method": "FEM\u5c06\u6807\u51c6\u6ce8\u610f\u529b\u4e2d\u7684(q,k)\u8bc4\u5206\u5206\u5e03\u4f5c\u4e3a\u5148\u9a8c\uff0c\u5e94\u7528\u503c\u9a71\u52a8\u7684\u6bcf\u901a\u9053\u5bf9\u6570\u7ebf\u6027\u503e\u659c\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u9006\u6e29\u5ea6\u53c2\u6570\u63a7\u5236\u4ece\u5e73\u5747\u5230\u9009\u62e9\u7684\u8fc7\u6e21\u3002\u5b9e\u73b0\u4e24\u7ea7\u95e8\u63a7FEM\uff0c\u53ef\u4e0e\u6807\u51c6/\u7ebf\u6027\u6ce8\u610f\u529b\u3001\u7ebf\u6027RNN\u548cSSM\u5373\u63d2\u5373\u7528\u3002", "result": "\u5728NLP\u3001\u89c6\u89c9\u548c\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e0a\uff0cFEM\u5728\u76f8\u540c\u53c2\u6570\u9884\u7b97\u4e0b\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "FEM\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u503c\u9a71\u52a8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301\u6807\u51c6\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4ece\u5e73\u5747\u5230\u901a\u9053\u7ea7\u9009\u62e9\u7684\u5e73\u6ed1\u8fc7\u6e21\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.07055", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07055", "abs": "https://arxiv.org/abs/2602.07055", "authors": ["Pingyue Zhang", "Zihan Huang", "Yue Wang", "Jieyu Zhang", "Letian Xue", "Zihan Wang", "Qineng Wang", "Keshigeyan Chandrasegaran", "Ruohan Zhang", "Yejin Choi", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?", "comment": "published at iclr 2026", "summary": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u7a7a\u95f4\u7406\u8bba\"\u6982\u5ff5\uff0c\u8bc4\u4f30\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u4e3b\u52a8\u63a2\u7d22\u4e2d\u6784\u5efa\u548c\u66f4\u65b0\u7a7a\u95f4\u4fe1\u5ff5\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5b58\u5728\u4e3b\u52a8-\u88ab\u52a8\u5dee\u8ddd\u3001\u6548\u7387\u4f4e\u4e0b\u548c\u4fe1\u5ff5\u60ef\u6027\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u88ab\u52a8\u611f\u77e5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u4e3b\u52a8\u3001\u81ea\u5bfc\u5411\u7684\u63a2\u7d22\u80fd\u529b\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002\u7a7a\u95f4\u5177\u8eab\u667a\u80fd\u9700\u8981\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u901a\u8fc7\u4e3b\u52a8\u884c\u52a8\u83b7\u53d6\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\"\u7a7a\u95f4\u7406\u8bba\"\u6982\u5ff5\uff0c\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u63a2\u7d22\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002\u5173\u952e\u521b\u65b0\u662f\u7a7a\u95f4\u4fe1\u5ff5\u63a2\u6d4b\u6280\u672f\uff0c\u5728\u6bcf\u4e00\u6b65\u63d0\u793a\u6a21\u578b\u63ed\u793a\u5176\u5185\u90e8\u7a7a\u95f4\u8868\u793a\u3002\u4f7f\u7528\u865a\u5047\u4fe1\u5ff5\u8303\u5f0f\u6765\u6d4b\u8bd5\u4fe1\u5ff5\u66f4\u65b0\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u51e0\u4e2a\u5173\u952e\u74f6\u9888\uff1a1) \u4e3b\u52a8-\u88ab\u52a8\u5dee\u8ddd\uff1a\u81ea\u4e3b\u6536\u96c6\u4fe1\u606f\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b2) \u6548\u7387\u4f4e\u4e0b\uff1a\u4e0e\u57fa\u4e8e\u7a0b\u5e8f\u7684\u4ee3\u7406\u76f8\u6bd4\u63a2\u7d22\u4e0d\u7cfb\u7edf\uff1b3) \u5168\u5c40\u4fe1\u5ff5\u4e0d\u7a33\u5b9a\u5bfc\u81f4\u7a7a\u95f4\u77e5\u8bc6\u968f\u65f6\u95f4\u9000\u5316\uff1b4) \u4fe1\u5ff5\u60ef\u6027\uff1a\u7279\u522b\u662f\u89c6\u89c9\u6a21\u578b\u96be\u4ee5\u7528\u65b0\u8bc1\u636e\u66f4\u65b0\u8fc7\u65f6\u7684\u5148\u9a8c\u3002", "conclusion": "\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u4e3b\u52a8\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u7ef4\u6301\u8fde\u8d2f\u3001\u53ef\u4fee\u6b63\u7684\u7a7a\u95f4\u4fe1\u5ff5\u3002\u7a7a\u95f4\u4fe1\u5ff5\u63a2\u6d4b\u63ed\u793a\u4e86\u611f\u77e5\u53ea\u662f\u521d\u59cb\u74f6\u9888\uff0c\u66f4\u6df1\u5c42\u7684\u95ee\u9898\u662f\u4fe1\u5ff5\u4e0d\u7a33\u5b9a\u548c\u66f4\u65b0\u56f0\u96be\u3002"}}
{"id": "2602.07054", "categories": ["cs.LG", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07054", "abs": "https://arxiv.org/abs/2602.07054", "authors": ["Ashutosh Chaubey", "Jiacheng Pang", "Maksim Siniukov", "Mohammad Soleymani"], "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization", "comment": "Accepted as a conference paper at ICLR 2026. Project page: https://avere-iclr.github.io", "summary": "Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant audiovisual cues, and hallucinations of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce EmoReAlM, a benchmark designed to evaluate MLLMs for cue-emotion associations, hallucinations and modality agreement. We then propose AVEm-DPO, a preference optimization technique that aligns model responses with both audiovisual inputs and emotion-centric queries. Specifically, we construct preferences over responses exhibiting spurious associations or hallucinations, and audiovisual input pairs guided by textual prompts. We also include a regularization term that penalizes reliance on text priors, thereby mitigating modality-specific cue hallucinations. Experimental results on DFEW, RAVDESS and EMER demonstrate that our method significantly improves the performance of the reference baseline models with 6-19% of relative performance gains in zero-shot settings. By providing both a rigorous benchmark and a robust optimization framework, this work enables principled evaluation and improvement of MLLMs for emotion understanding and social AI. Code, models and benchmark will be released at https://avere-iclr.github.io.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86EmoReAlM\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u7406\u89e3\u4e2d\u7684\u865a\u5047\u5173\u8054\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86AVEm-DPO\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u6765\u5bf9\u9f50\u89c6\u542c\u8f93\u5165\u4e0e\u60c5\u611f\u67e5\u8be2\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u7406\u89e3\u4efb\u52a1\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u60c5\u611f\u4e0e\u65e0\u5173\u89c6\u542c\u7ebf\u7d22\u4e4b\u95f4\u7684\u865a\u5047\u5173\u8054\uff1b2) \u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u4e2d\u6587\u672c\u5148\u9a8c\u9a71\u52a8\u7684\u89c6\u542c\u7ebf\u7d22\u5e7b\u89c9\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u793e\u4f1a\u667a\u80fd\u548c\u53ef\u9760\u6027\u3002", "method": "\u9996\u5148\u5f15\u5165EmoReAlM\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u7ebf\u7d22-\u60c5\u611f\u5173\u8054\u3001\u5e7b\u89c9\u548c\u6a21\u6001\u4e00\u81f4\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002\u7136\u540e\u63d0\u51faAVEm-DPO\u504f\u597d\u4f18\u5316\u6280\u672f\uff0c\u901a\u8fc7\u6784\u5efa\u5bf9\u865a\u5047\u5173\u8054\u6216\u5e7b\u89c9\u54cd\u5e94\u7684\u504f\u597d\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u7684\u89c6\u542c\u8f93\u5165\u5bf9\u6765\u5bf9\u9f50\u6a21\u578b\u54cd\u5e94\u3002\u8fd8\u5305\u62ec\u4e00\u4e2a\u6b63\u5219\u5316\u9879\u6765\u60e9\u7f5a\u5bf9\u6587\u672c\u5148\u9a8c\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u51cf\u8f7b\u6a21\u6001\u7279\u5b9a\u7ebf\u7d22\u7684\u5e7b\u89c9\u3002", "result": "\u5728DFEW\u3001RAVDESS\u548cEMER\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u53c2\u8003\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e866-19%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u7a33\u5065\u7684\u4f18\u5316\u6846\u67b6\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u60c5\u611f\u7406\u89e3\u548c\u793e\u4f1aAI\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8bc4\u4f30\u548c\u6539\u8fdb\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u793e\u4f1a\u667a\u80fd\u4ee3\u7406\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.07772", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07772", "abs": "https://arxiv.org/abs/2602.07772", "authors": ["Jiasong Han", "Yufei Feng", "Xiaofeng Zhong"], "title": "FilterLoss: A Transfer Learning Approach for Communication Scene Recognition", "comment": "Accepted by the 11th IEEE International Conference on Computer and Communications (ICCC 2025), Chengdu, China", "summary": "Communication scene recognition has been widely applied in practice, but using deep learning to address this problem faces challenges such as insufficient data and imbalanced data distribution. To address this, we designed a weighted loss function structure, named FilterLoss, which assigns different loss function weights to different sample points. This allows the deep learning model to focus primarily on high-value samples while appropriately accounting for noisy, boundary-level data points. Additionally, we developed a matching weight filtering algorithm that evaluates the quality of sample points in the input dataset and assigns different weight values to samples based on their quality. By applying this method, when using transfer learning on a highly imbalanced new dataset, the accuracy of the transferred model was restored to 92.34% of the original model's performance. Our experiments also revealed that using this loss function structure allowed the model to maintain good stability despite insufficient and imbalanced data.", "AI": {"tldr": "\u63d0\u51faFilterLoss\u52a0\u6743\u635f\u5931\u51fd\u6570\u7ed3\u6784\uff0c\u901a\u8fc7\u4e3a\u4e0d\u540c\u6837\u672c\u70b9\u5206\u914d\u4e0d\u540c\u6743\u91cd\uff0c\u8ba9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u9ad8\u4ef7\u503c\u6837\u672c\uff0c\u540c\u65f6\u9002\u5f53\u8003\u8651\u566a\u58f0\u548c\u8fb9\u754c\u6570\u636e\u70b9\uff0c\u89e3\u51b3\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u4e2d\u6570\u636e\u4e0d\u8db3\u548c\u6570\u636e\u5206\u5e03\u4e0d\u5e73\u8861\u7684\u95ee\u9898\u3002", "motivation": "\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u5728\u5b9e\u8df5\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u9762\u4e34\u6570\u636e\u4e0d\u8db3\u548c\u6570\u636e\u5206\u5e03\u4e0d\u5e73\u8861\u7684\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u635f\u5931\u51fd\u6570\u7ed3\u6784\u6765\u6539\u5584\u6a21\u578b\u5728\u6570\u636e\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86FilterLoss\u52a0\u6743\u635f\u5931\u51fd\u6570\u7ed3\u6784\uff0c\u4e3a\u4e0d\u540c\u6837\u672c\u70b9\u5206\u914d\u4e0d\u540c\u635f\u5931\u51fd\u6570\u6743\u91cd\u3002\u5f00\u53d1\u4e86\u5339\u914d\u6743\u91cd\u8fc7\u6ee4\u7b97\u6cd5\uff0c\u8bc4\u4f30\u8f93\u5165\u6570\u636e\u96c6\u4e2d\u6837\u672c\u70b9\u7684\u8d28\u91cf\uff0c\u5e76\u6839\u636e\u8d28\u91cf\u5206\u914d\u4e0d\u540c\u7684\u6743\u91cd\u503c\u3002\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u9ad8\u4ef7\u503c\u6837\u672c\uff0c\u540c\u65f6\u9002\u5f53\u8003\u8651\u566a\u58f0\u548c\u8fb9\u754c\u6570\u636e\u70b9\u3002", "result": "\u5728\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u5904\u7406\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u65b0\u6570\u636e\u96c6\u65f6\uff0c\u8f6c\u79fb\u6a21\u578b\u7684\u51c6\u786e\u7387\u6062\u590d\u5230\u539f\u59cb\u6a21\u578b\u6027\u80fd\u768492.34%\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u7ed3\u6784\u4f7f\u6a21\u578b\u5728\u6570\u636e\u4e0d\u8db3\u548c\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u826f\u597d\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "FilterLoss\u52a0\u6743\u635f\u5931\u51fd\u6570\u7ed3\u6784\u80fd\u6709\u6548\u89e3\u51b3\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u6570\u636e\u4e0d\u8db3\u548c\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07836", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07836", "abs": "https://arxiv.org/abs/2602.07836", "authors": ["Jianhua Sun", "Kaihong Lu", "Xin Yu"], "title": "Convergence Analysis of Continuous-Time Distributed Stochastic Gradient Algorithms", "comment": null, "summary": "In this paper, we propose a new framework to study distributed optimization problems with stochastic gradients by employing a multi-agent system with continuous-time dynamics. Here the goal of the agents is to cooperatively minimize the sum of convex objective functions. When making decisions, each agent only has access to a stochastic gradient of its own objective function rather than the real gradient, and can exchange local state information with its immediate neighbors via a time-varying directed graph. Particularly, the stochasticity is depicted by the Brownian motion. To handle this problem, we propose a continuous-time distributed stochastic gradient algorithm based on the consensus algorithm and the gradient descent strategy. Under mild assumptions on the connectivity of the graph and objective functions, using convex analysis theory, the Lyapunov theory and Ito formula, we prove that the states of the agents asymptotically reach a common minimizer in expectation. Finally, a simulation example is worked out to demonstrate the effectiveness of our theoretical results.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u5b66\u7684\u5206\u5e03\u5f0f\u968f\u673a\u68af\u5ea6\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u534f\u540c\u4f18\u5316\u51f8\u76ee\u6807\u51fd\u6570\u548c\uff0c\u5728\u65f6\u53d8\u6709\u5411\u56fe\u901a\u4fe1\u4e0b\uff0c\u8bc1\u660e\u72b6\u6001\u6e10\u8fd1\u6536\u655b\u5230\u5171\u540c\u6700\u5c0f\u5316\u89e3", "motivation": "\u7814\u7a76\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u667a\u80fd\u4f53\u53ea\u80fd\u8bbf\u95ee\u81ea\u8eab\u76ee\u6807\u51fd\u6570\u7684\u968f\u673a\u68af\u5ea6\u800c\u975e\u771f\u5b9e\u68af\u5ea6\uff0c\u4e14\u901a\u8fc7\u65f6\u53d8\u6709\u5411\u56fe\u4e0e\u90bb\u5c45\u4ea4\u6362\u4fe1\u606f\u3002\u9700\u8981\u5904\u7406\u968f\u673a\u6027\u548c\u901a\u4fe1\u7ea6\u675f\uff0c\u8bbe\u8ba1\u6709\u6548\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5", "method": "\u63d0\u51fa\u8fde\u7eed\u65f6\u95f4\u5206\u5e03\u5f0f\u968f\u673a\u68af\u5ea6\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e00\u81f4\u6027\u7b97\u6cd5\u548c\u68af\u5ea6\u4e0b\u964d\u7b56\u7565\u3002\u4f7f\u7528\u5e03\u6717\u8fd0\u52a8\u63cf\u8ff0\u968f\u673a\u6027\uff0c\u57fa\u4e8e\u51f8\u5206\u6790\u7406\u8bba\u3001Lyapunov\u7406\u8bba\u548cIto\u516c\u5f0f\u8fdb\u884c\u7406\u8bba\u5206\u6790", "result": "\u5728\u56fe\u8fde\u901a\u6027\u548c\u76ee\u6807\u51fd\u6570\u7684\u6e29\u548c\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u667a\u80fd\u4f53\u72b6\u6001\u5728\u671f\u671b\u610f\u4e49\u4e0b\u6e10\u8fd1\u6536\u655b\u5230\u5171\u540c\u6700\u5c0f\u5316\u89e3\u3002\u901a\u8fc7\u4eff\u771f\u793a\u4f8b\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u8fde\u7eed\u65f6\u95f4\u5206\u5e03\u5f0f\u968f\u673a\u68af\u5ea6\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5177\u6709\u968f\u673a\u68af\u5ea6\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898\uff0c\u5728\u65f6\u53d8\u6709\u5411\u56fe\u901a\u4fe1\u4e0b\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u534f\u540c\u4f18\u5316"}}
{"id": "2602.07767", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.07767", "abs": "https://arxiv.org/abs/2602.07767", "authors": ["Ruizhe Deng", "Bibhas Chakraborty", "Ran Chen", "Yan Shuo Tan"], "title": "BFTS: Thompson Sampling with Bayesian Additive Regression Trees", "comment": null, "summary": "Contextual bandits are a core technology for personalized mobile health interventions, where decision-making requires adapting to complex, non-linear user behaviors. While Thompson Sampling (TS) is a preferred strategy for these problems, its performance hinges on the quality of the underlying reward model. Standard linear models suffer from high bias, while neural network approaches are often brittle and difficult to tune in online settings. Conversely, tree ensembles dominate tabular data prediction but typically rely on heuristic uncertainty quantification, lacking a principled probabilistic basis for TS. We propose Bayesian Forest Thompson Sampling (BFTS), the first contextual bandit algorithm to integrate Bayesian Additive Regression Trees (BART), a fully probabilistic sum-of-trees model, directly into the exploration loop. We prove that BFTS is theoretically sound, deriving an information-theoretic Bayesian regret bound of $\\tilde{O}(\\sqrt{T})$. As a complementary result, we establish frequentist minimax optimality for a \"feel-good\" variant, confirming the structural suitability of BART priors for non-parametric bandits. Empirically, BFTS achieves state-of-the-art regret on tabular benchmarks with near-nominal uncertainty calibration. Furthermore, in an offline policy evaluation on the Drink Less micro-randomized trial, BFTS improves engagement rates by over 30% compared to the deployed policy, demonstrating its practical effectiveness for behavioral interventions.", "AI": {"tldr": "BFTS\u5c06\u8d1d\u53f6\u65af\u52a0\u6027\u56de\u5f52\u6811(BART)\u96c6\u6210\u5230\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u4e2d\uff0c\u4e3a\u4e2a\u6027\u5316\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u4e14\u5b9e\u7528\u7684\u63a2\u7d22\u7b56\u7565\u3002", "motivation": "\u79fb\u52a8\u5065\u5eb7\u4e2a\u6027\u5316\u5e72\u9884\u9700\u8981\u9002\u5e94\u590d\u6742\u7684\u975e\u7ebf\u6027\u7528\u6237\u884c\u4e3a\u3002\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u7ebf\u6027\u6a21\u578b\u504f\u5dee\u9ad8\uff0c\u795e\u7ecf\u7f51\u7edc\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u96be\u4ee5\u8c03\u4f18\uff0c\u6811\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u6982\u7387\u57fa\u7840\u3002\u9700\u8981\u4e00\u79cd\u65e2\u6709\u7406\u8bba\u4fdd\u8bc1\u53c8\u5b9e\u7528\u7684\u63a2\u7d22\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u68ee\u6797\u6c64\u666e\u68ee\u91c7\u6837(BFTS)\uff0c\u9996\u6b21\u5c06\u5b8c\u5168\u6982\u7387\u5316\u7684BART\u6a21\u578b\u76f4\u63a5\u96c6\u6210\u5230\u63a2\u7d22\u5faa\u73af\u4e2d\u3002BART\u4f5c\u4e3a\u8d1d\u53f6\u65af\u52a0\u6027\u56de\u5f52\u6811\uff0c\u63d0\u4f9b\u6982\u7387\u5316\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u7406\u8bba\u8bc1\u660eBFTS\u5177\u6709\u4fe1\u606f\u8bba\u8d1d\u53f6\u65af\u9057\u61be\u754c$\\tilde{O}(\\sqrt{T})$\uff0c\u5176\"feel-good\"\u53d8\u4f53\u8fbe\u5230\u9891\u7387\u4e3b\u4e49\u6781\u5c0f\u6781\u5927\u6700\u4f18\u6027\u3002\u5b9e\u8bc1\u5728\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u9057\u61be\uff0c\u5728Drink Less\u5fae\u968f\u673a\u8bd5\u9a8c\u4e2d\u6bd4\u90e8\u7f72\u7b56\u7565\u63d0\u534730%\u4ee5\u4e0a\u53c2\u4e0e\u7387\u3002", "conclusion": "BFTS\u6210\u529f\u5c06BART\u96c6\u6210\u5230\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u6846\u67b6\u4e2d\uff0c\u4e3a\u975e\u7ebf\u6027\u5956\u52b1\u5efa\u6a21\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u79fb\u52a8\u5065\u5eb7\u884c\u4e3a\u5e72\u9884\u7b49\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.07021", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07021", "abs": "https://arxiv.org/abs/2602.07021", "authors": ["Sahibpreet Singh", "Saksham Sharma"], "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation", "comment": "Presented at National Conference on Navigating The Intersection of Artificial Intelligence and Law: Ethical and Legal Horizons, 29 September 2024, pp. 91-106", "summary": "Integration of AI into environmental regulation represents a significant advancement in data management. It offers promising results in both data protection plus algorithmic fairness. This research addresses the critical need for sustainable data protection in the era of ever evolving cyber threats. Traditional encryption methods face limitations in handling the dynamic nature of environmental data. This necessitates the exploration of advanced cryptographic techniques. The objective of this study is to evaluate how AI can enhance these techniques to ensure robust data protection while facilitating fair algorithmic management. The methodology involves a comprehensive review of current advancements in AI-enhanced homomorphic encryption (HE) and multi-party computation (MPC). It is coupled with an analysis of how these techniques can be applied to environmental data regulation. Key findings indicate that AI-driven dynamic key management, adaptive encryption schemes, and optimized computational efficiency in HE, alongside AI-enhanced protocol optimization and fault mitigation in MPC, significantly improve the security of environmental data processing. These findings highlight a crucial research gap in the intersection of AI, cyber laws, and environmental regulation, particularly in terms of addressing algorithmic bias, transparency, and accountability. The implications of this research underscore the need for stricter cyber laws. Also, the development of comprehensive regulations to safeguard sensitive environmental data. Future efforts should focus on refining AI systems to balance security with privacy and ensuring that regulatory frameworks can adapt to technological advancements. This study provides a foundation for future research aimed at achieving secure sustainable environmental data management through AI innovations.", "AI": {"tldr": "AI\u589e\u5f3a\u52a0\u5bc6\u6280\u672f\uff08\u540c\u6001\u52a0\u5bc6\u4e0e\u591a\u65b9\u8ba1\u7b97\uff09\u5728\u73af\u5883\u6570\u636e\u76d1\u7ba1\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u5347\u6570\u636e\u5b89\u5168\u4e0e\u7b97\u6cd5\u516c\u5e73\u6027", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73af\u5883\u6570\u636e\u7684\u52a8\u6001\u7279\u6027\uff0c\u9700\u8981\u63a2\u7d22AI\u589e\u5f3a\u7684\u5148\u8fdb\u52a0\u5bc6\u6280\u672f\u6765\u786e\u4fdd\u6570\u636e\u4fdd\u62a4\u4e0e\u7b97\u6cd5\u516c\u5e73\u7ba1\u7406", "method": "\u5bf9AI\u589e\u5f3a\u7684\u540c\u6001\u52a0\u5bc6\u548c\u591a\u65b9\u8ba1\u7b97\u6280\u672f\u8fdb\u884c\u7efc\u5408\u8bc4\u8ff0\uff0c\u5206\u6790\u8fd9\u4e9b\u6280\u672f\u5728\u73af\u5883\u6570\u636e\u76d1\u7ba1\u4e2d\u7684\u5e94\u7528", "result": "AI\u9a71\u52a8\u7684\u52a8\u6001\u5bc6\u94a5\u7ba1\u7406\u3001\u81ea\u9002\u5e94\u52a0\u5bc6\u65b9\u6848\u3001\u8ba1\u7b97\u6548\u7387\u4f18\u5316\u4ee5\u53ca\u534f\u8bae\u4f18\u5316\u548c\u6545\u969c\u7f13\u89e3\u663e\u8457\u63d0\u5347\u73af\u5883\u6570\u636e\u5904\u7406\u5b89\u5168\u6027", "conclusion": "\u9700\u8981\u66f4\u4e25\u683c\u7684\u7f51\u7edc\u6cd5\u5f8b\u548c\u5168\u9762\u6cd5\u89c4\u6765\u4fdd\u62a4\u654f\u611f\u73af\u5883\u6570\u636e\uff0c\u672a\u6765\u5e94\u5b8c\u5584AI\u7cfb\u7edf\u4ee5\u5e73\u8861\u5b89\u5168\u4e0e\u9690\u79c1\uff0c\u4f7f\u76d1\u7ba1\u6846\u67b6\u9002\u5e94\u6280\u672f\u8fdb\u6b65"}}
{"id": "2602.07318", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07318", "abs": "https://arxiv.org/abs/2602.07318", "authors": ["Zihao Gu", "Jianfeng Zhang"], "title": "On Information Controls", "comment": null, "summary": "In this paper we study an optimization problem in which the control is information, more precisely, the control is a $\u03c3$-algebra or a filtration. In a dynamic setting, assuming a condition slightly stronger than the (H)-hypothesis for the admissible filtration, we establish the dynamic programming principle and the law invariance of the value function. The latter enables us to define the value function on $\\mathcal P_2(\\mathcal P_2(\\mathbb R^d))$, the space of laws of random probability measures. By using a new It\u00f4's formula for smooth functions on $\\mathcal P_2(\\mathcal P_2(\\mathbb R^d))$, we characterize the value function of the information control problem through an Hamilton-Jacobi-Bellman equation on this space.", "AI": {"tldr": "\u7814\u7a76\u4fe1\u606f\u63a7\u5236\u4f18\u5316\u95ee\u9898\uff0c\u63a7\u5236\u53d8\u91cf\u662f\u03c3-\u4ee3\u6570\u6216\u6ee4\u6ce2\uff0c\u5efa\u7acb\u52a8\u6001\u89c4\u5212\u539f\u7406\uff0c\u5728\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u63a8\u5bfcHJB\u65b9\u7a0b", "motivation": "\u7814\u7a76\u4e00\u7c7b\u7279\u6b8a\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5176\u4e2d\u63a7\u5236\u53d8\u91cf\u4e0d\u662f\u4f20\u7edf\u7684\u51b3\u7b56\u53d8\u91cf\uff0c\u800c\u662f\u4fe1\u606f\u7ed3\u6784\u672c\u8eab\uff08\u03c3-\u4ee3\u6570\u6216\u6ee4\u6ce2\uff09\u3002\u8fd9\u7c7b\u95ee\u9898\u5728\u91d1\u878d\u3001\u7ecf\u6d4e\u548c\u63a7\u5236\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4fe1\u606f\u4f5c\u4e3a\u63a7\u5236\u53d8\u91cf\u7684\u60c5\u51b5\u3002", "method": "\u5728\u52a8\u6001\u8bbe\u5b9a\u4e0b\uff0c\u5047\u8bbe\u6bd4(H)-\u5047\u8bbe\u7a0d\u5f3a\u7684\u53ef\u5bb9\u8bb8\u6ee4\u6ce2\u6761\u4ef6\uff0c\u5efa\u7acb\u52a8\u6001\u89c4\u5212\u539f\u7406\u548c\u503c\u51fd\u6570\u7684\u5f8b\u4e0d\u53d8\u6027\u3002\u5229\u7528\u968f\u673a\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u7684\u65b0It\u00f4\u516c\u5f0f\uff0c\u5728\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u63a8\u5bfcHamilton-Jacobi-Bellman\u65b9\u7a0b\u3002", "result": "\u8bc1\u660e\u4e86\u52a8\u6001\u89c4\u5212\u539f\u7406\u548c\u503c\u51fd\u6570\u7684\u5f8b\u4e0d\u53d8\u6027\uff0c\u4f7f\u5f97\u503c\u51fd\u6570\u53ef\u4ee5\u5b9a\u4e49\u5728\u968f\u673a\u6982\u7387\u6d4b\u5ea6\u7684\u7a7a\u95f4\u4e0a\u3002\u901a\u8fc7\u65b0\u7684It\u00f4\u516c\u5f0f\uff0c\u5728\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u5f97\u5230\u4e86\u4fe1\u606f\u63a7\u5236\u95ee\u9898\u7684HJB\u65b9\u7a0b\u3002", "conclusion": "\u6210\u529f\u5c06\u4fe1\u606f\u4f5c\u4e3a\u63a7\u5236\u53d8\u91cf\u7684\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u6982\u7387\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u7684HJB\u65b9\u7a0b\uff0c\u4e3a\u8fd9\u7c7b\u590d\u6742\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u548c\u6c42\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2602.08182", "categories": ["cs.LG", "q-fin.CP", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.08182", "abs": "https://arxiv.org/abs/2602.08182", "authors": ["Hiromu Ozai", "Kei Nakagawa"], "title": "Nansde-net: A neural sde framework for generating time series with memory", "comment": "PAKDD2026 Accepted", "summary": "Modeling time series with long- or short-memory characteristics is a fundamental challenge in many scientific and engineering domains. While fractional Brownian motion has been widely used as a noise source to capture such memory effects, its incompatibility with It\u00f4 calculus limits its applicability in neural stochastic differential equation~(SDE) frameworks. In this paper, we propose a novel class of noise, termed Neural Network-kernel ARMA-type noise~(NA-noise), which is an It\u00f4-process-based alternative capable of capturing both long- and short-memory behaviors. The kernel function defining the noise structure is parameterized via neural networks and decomposed into a product form to preserve the Markov property. Based on this noise process, we develop NANSDE-Net, a generative model that extends Neural SDEs by incorporating NA-noise. We prove the theoretical existence and uniqueness of the solution under mild conditions and derive an efficient backpropagation scheme for training. Empirical results on both synthetic and real-world datasets demonstrate that NANSDE-Net matches or outperforms existing models, including fractional SDE-Net, in reproducing long- and short-memory features of the data, while maintaining computational tractability within the It\u00f4 calculus framework.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eIt\u00f4\u8fc7\u7a0b\u7684NA-noise\uff0c\u80fd\u591f\u6355\u6349\u957f\u77ed\u671f\u8bb0\u5fc6\u7279\u5f81\uff0c\u5e76\u6784\u5efaNANSDE-Net\u751f\u6210\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u53ef\u5904\u7406\u6027\u7684\u540c\u65f6\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u867d\u7136\u80fd\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u7684\u957f\u77ed\u671f\u8bb0\u5fc6\u7279\u5f81\uff0c\u4f46\u4e0eIt\u00f4\u5fae\u79ef\u5206\u4e0d\u517c\u5bb9\uff0c\u9650\u5236\u4e86\u5176\u5728\u795e\u7ecf\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6846\u67b6\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6355\u6349\u8bb0\u5fc6\u6548\u5e94\u53c8\u517c\u5bb9It\u00f4\u5fae\u79ef\u5206\u7684\u566a\u58f0\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51faNA-noise\uff08\u795e\u7ecf\u7f51\u7edc\u6838ARMA\u578b\u566a\u58f0\uff09\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u6838\u51fd\u6570\u5e76\u5206\u89e3\u4e3a\u4e58\u79ef\u5f62\u5f0f\u4ee5\u4fdd\u6301\u9a6c\u5c14\u53ef\u592b\u6027\u3002\u57fa\u4e8e\u6b64\u6784\u5efaNANSDE-Net\u751f\u6210\u6a21\u578b\uff0c\u6269\u5c55\u795e\u7ecfSDEs\u6846\u67b6\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u89e3\u7684\u5b58\u5728\u552f\u4e00\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u9ad8\u6548\u7684\u53cd\u5411\u4f20\u64ad\u8bad\u7ec3\u65b9\u6848\u3002\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cNANSDE-Net\u5728\u518d\u73b0\u6570\u636e\u957f\u77ed\u671f\u8bb0\u5fc6\u7279\u5f81\u65b9\u9762\u5339\u914d\u6216\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff08\u5305\u62ec\u5206\u6570SDE-Net\uff09\u3002", "conclusion": "NA-noise\u4e3a\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u8bb0\u5fc6\u7279\u5f81\u63d0\u4f9b\u4e86It\u00f4\u5fae\u79ef\u5206\u517c\u5bb9\u7684\u66ff\u4ee3\u65b9\u6848\uff0cNANSDE-Net\u5728\u4fdd\u6301\u8ba1\u7b97\u53ef\u5904\u7406\u6027\u7684\u540c\u65f6\u6709\u6548\u5efa\u6a21\u957f\u77ed\u671f\u8bb0\u5fc6\u884c\u4e3a\uff0c\u6269\u5c55\u4e86\u795e\u7ecfSDEs\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2602.07164", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07164", "abs": "https://arxiv.org/abs/2602.07164", "authors": ["Ruimeng Ye", "Zihan Wang", "Zinan Ling", "Yang Xiao", "Manling Li", "Xiaolong Ma", "Bo Hui"], "title": "Your Language Model Secretly Contains Personality Subnetworks", "comment": "ICLR 2026", "summary": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.", "AI": {"tldr": "LLMs\u5185\u90e8\u5df2\u5b58\u5728\u4e13\u95e8\u5904\u7406\u4e0d\u540c\u4eba\u683c\u7684\u5b50\u7f51\u7edc\uff0c\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u6216\u53c2\u6570\u8c03\u6574\u5373\u53ef\u6fc0\u6d3b\u7279\u5b9a\u4eba\u683c\u884c\u4e3a", "motivation": "\u63a2\u7d22LLMs\u662f\u5426\u771f\u7684\u9700\u8981\u5916\u90e8\u4e0a\u4e0b\u6587\u6216\u53c2\u6570\u8c03\u6574\u6765\u9002\u5e94\u4e0d\u540c\u884c\u4e3a\uff0c\u8fd8\u662f\u8fd9\u4e9b\u77e5\u8bc6\u5df2\u7ecf\u5d4c\u5165\u5176\u53c2\u6570\u7a7a\u95f4\u4e2d", "method": "\u4f7f\u7528\u5c0f\u578b\u6821\u51c6\u6570\u636e\u96c6\u8bc6\u522b\u4e0d\u540c\u4eba\u683c\u7684\u6fc0\u6d3b\u7279\u5f81\uff0c\u5f00\u53d1\u63a9\u7801\u7b56\u7565\u9694\u79bb\u8f7b\u91cf\u7ea7\u4eba\u683c\u5b50\u7f51\u7edc\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4\u526a\u679d\u7b56\u7565\u589e\u5f3a\u4e8c\u5143\u5bf9\u7acb\u4eba\u683c\u7684\u5206\u79bb", "result": "\u751f\u6210\u7684\u5b50\u7f51\u7edc\u6bd4\u9700\u8981\u5916\u90e8\u77e5\u8bc6\u7684\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u4eba\u683c\u5bf9\u9f50\u6027\uff0c\u540c\u65f6\u66f4\u9ad8\u6548", "conclusion": "\u591a\u6837\u5316\u7684\u4eba\u7c7b\u884c\u4e3a\u4e0d\u4ec5\u662f\u5728LLMs\u4e2d\u88ab\u8bf1\u5bfc\u51fa\u6765\u7684\uff0c\u800c\u662f\u5df2\u7ecf\u5d4c\u5165\u5176\u53c2\u6570\u7a7a\u95f4\u4e2d\uff0c\u8fd9\u4e3a\u53ef\u63a7\u548c\u53ef\u89e3\u91ca\u7684\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2602.07153", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07153", "abs": "https://arxiv.org/abs/2602.07153", "authors": ["Jinbiao Wei", "Yilun Zhao", "Kangqi Ni", "Arman Cohan"], "title": "ANCHOR: Branch-Point Data Generation for GUI Agents", "comment": null, "summary": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.", "AI": {"tldr": "Anchor\u6846\u67b6\u901a\u8fc7\u5c11\u91cf\u79cd\u5b50\u6f14\u793a\u6269\u5c55\u8f68\u8ff9\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u684c\u9762GUI\u4ea4\u4e92\u6570\u636e\uff0c\u63d0\u5347\u7aef\u5230\u7aefGUI\u4ee3\u7406\u6027\u80fd", "motivation": "\u7aef\u5230\u7aefGUI\u4ee3\u7406\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u4ea4\u4e92\u6570\u636e\uff0c\u4f46\u4eba\u5de5\u6536\u96c6\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u6216\u8f68\u8ff9\u566a\u58f0\u5927\u3001\u76ee\u6807\u6f02\u79fb\u7684\u95ee\u9898", "method": "\u57fa\u4e8e\u5c11\u91cf\u5df2\u9a8c\u8bc1\u79cd\u5b50\u6f14\u793a\uff0c\u8bc6\u522b\u6709\u610f\u4e49\u7684\u72b6\u6001\u53d8\u5316\u5206\u652f\u70b9\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f53\u524dGUI\u4e0a\u4e0b\u6587\u7684\u72b6\u6001\u63a5\u5730\u4efb\u52a1\u53d8\u4f53\uff0c\u901a\u8fc7\u6267\u884c\u4ee3\u7406\u751f\u6210\u65b0\u8f68\u8ff9\uff0c\u9a8c\u8bc1\u5668\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u68c0\u67e5\u548c\u8f68\u8ff9\u7ea7\u4e00\u81f4\u6027\u786e\u4fdd\u4efb\u52a1\u5b8c\u6210", "result": "\u5728OSWorld\u548cWindowsAgentArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u6269\u5c55\u8bed\u6599\u5e93\u5fae\u8c03\u7684\u6a21\u578b\u76f8\u6bd4\u96f6\u6837\u672c\u4ee3\u7406\u548c\u4ee3\u8868\u6027\u5408\u6210\u57fa\u7ebf\u83b7\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5e76\u80fd\u8de8\u5e94\u7528\u7a0b\u5e8f\u548c\u64cd\u4f5c\u7cfb\u7edf\u6cdb\u5316", "conclusion": "Anchor\u6846\u67b6\u80fd\u591f\u4ece\u5c11\u91cf\u79cd\u5b50\u6f14\u793a\u4e2d\u5f15\u5bfc\u6269\u5c55\u51fa\u53ef\u6269\u5c55\u7684\u684c\u9762\u76d1\u7763\u6570\u636e\uff0c\u6709\u6548\u89e3\u51b3GUI\u4ee3\u7406\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898"}}
{"id": "2602.07061", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07061", "abs": "https://arxiv.org/abs/2602.07061", "authors": ["Daniel Nobrega"], "title": "TACIT: Transformation-Aware Capturing of Implicit Thought", "comment": "25 pages, 7 figures", "summary": "We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling direct visualization of the reasoning process at each inference step. We demonstrate the approach on maze-solving, where the model learns to transform images of unsolved mazes into solutions. Key results on 1 million synthetic maze pairs include:\n  - 192x reduction in training loss over 100 epochs\n  - 22.7x improvement in L2 distance to ground truth\n  - Only 10 Euler steps required (vs. 100-1000 for typical diffusion models)\n  Quantitative analysis reveals a striking phase transition phenomenon: the solution remains invisible for 68% of the transformation (zero recall), then emerges abruptly at t=0.70 within just 2% of the process. Most remarkably, 100% of samples exhibit simultaneous emergence across all spatial regions, ruling out sequential path construction and providing evidence for holistic rather than algorithmic reasoning. This \"eureka moment\" pattern -- long incubation followed by sudden crystallization -- parallels insight phenomena in human cognition. The pixel-space design with noise-free flow matching provides a foundation for understanding how neural networks develop implicit reasoning strategies that operate below and before language.", "AI": {"tldr": "TACIT\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u53d8\u6362\u5668\u7684\u53ef\u89e3\u91ca\u89c6\u89c9\u63a8\u7406\u6a21\u578b\uff0c\u76f4\u63a5\u5728\u50cf\u7d20\u7a7a\u95f4\u901a\u8fc7\u6574\u6d41\u6d41\u8fdb\u884c\u63a8\u7406\uff0c\u65e0\u9700\u8bed\u8a00\u4e2d\u4ecb\u3002\u5728\u8ff7\u5bab\u6c42\u89e3\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u80fd\u5c06\u672a\u89e3\u8ff7\u5bab\u56fe\u50cf\u8f6c\u5316\u4e3a\u89e3\u8ff7\u5bab\u56fe\u50cf\uff0c\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u987f\u609f\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u7684\u63a8\u7406\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u6cd5\u76f4\u63a5\u53ef\u89c6\u5316\u63a8\u7406\u8fc7\u7a0b\u3002\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u5b8c\u5168\u5728\u50cf\u7d20\u7a7a\u95f4\u64cd\u4f5c\u7684\u89c6\u89c9\u63a8\u7406\u6a21\u578b\uff0c\u80fd\u591f\u76f4\u63a5\u89c2\u5bdf\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u53d1\u5c55\u51fa\u8bed\u8a00\u4e4b\u524d\u7684\u9690\u5f0f\u63a8\u7406\u7b56\u7565\u3002", "method": "TACIT\u91c7\u7528\u57fa\u4e8e\u6269\u6563\u7684\u53d8\u6362\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u6574\u6d41\u6d41\u5728\u50cf\u7d20\u7a7a\u95f4\u8fdb\u884c\u63a8\u7406\u3002\u6a21\u578b\u5b66\u4e60\u5c06\u672a\u89e3\u8ff7\u5bab\u56fe\u50cf\u8f6c\u5316\u4e3a\u89e3\u8ff7\u5bab\u56fe\u50cf\u7684\u53d8\u6362\u8fc7\u7a0b\uff0c\u901a\u8fc7\u566a\u58f0\u81ea\u7531\u6d41\u5339\u914d\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "result": "\u5728100\u4e07\u5408\u6210\u8ff7\u5bab\u5bf9\u4e0a\u7684\u5173\u952e\u7ed3\u679c\uff1a\u8bad\u7ec3\u635f\u5931\u964d\u4f4e192\u500d\uff0cL2\u8ddd\u79bb\u6539\u8fdb22.7\u500d\uff0c\u4ec5\u970010\u4e2a\u6b27\u62c9\u6b65\u9aa4\uff08\u5178\u578b\u6269\u6563\u6a21\u578b\u9700100-1000\u6b65\uff09\u3002\u53d1\u73b0\u660e\u663e\u7684\u76f8\u53d8\u73b0\u8c61\uff1a\u89e3\u51b3\u65b9\u6848\u572868%\u7684\u53d8\u6362\u8fc7\u7a0b\u4e2d\u4e0d\u53ef\u89c1\uff08\u96f6\u53ec\u56de\uff09\uff0c\u7136\u540e\u5728t=0.70\u65f6\u5728\u4ec52%\u7684\u8fc7\u7a0b\u4e2d\u7a81\u7136\u51fa\u73b0\u3002\u6240\u6709\u6837\u672c\u5728\u6240\u6709\u7a7a\u95f4\u533a\u57df\u540c\u65f6\u6d8c\u73b0\uff0c\u6392\u9664\u4e86\u987a\u5e8f\u8def\u5f84\u6784\u5efa\u3002", "conclusion": "TACIT\u5c55\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u53d1\u5c55\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u987f\u609f\u7684\u9690\u5f0f\u63a8\u7406\u7b56\u7565\u2014\u2014\u957f\u671f\u6f5c\u4f0f\u540e\u7a81\u7136\u7ed3\u6676\u7684\u6a21\u5f0f\u3002\u50cf\u7d20\u7a7a\u95f4\u8bbe\u8ba1\u548c\u566a\u58f0\u81ea\u7531\u6d41\u5339\u914d\u4e3a\u7406\u89e3\u8bed\u8a00\u4e4b\u524d\u7684\u63a8\u7406\u673a\u5236\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u8868\u660e\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u91c7\u7528\u6574\u4f53\u800c\u975e\u7b97\u6cd5\u7684\u63a8\u7406\u65b9\u5f0f\u3002"}}
{"id": "2602.07841", "categories": ["econ.EM", "q-fin.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07841", "abs": "https://arxiv.org/abs/2602.07841", "authors": ["Cheng Zhang"], "title": "A Quadratic Link between Out-of-Sample $R^2$ and Directional Accuracy", "comment": null, "summary": "This study provides a novel perspective on the metric disconnect phenomenon in financial time series forecasting through an analytical link that reconciles the out-of-sample $R^2$ ($R^2_{OOS}$) and directional accuracy (DA). In particular, using the random walk model as a baseline and assuming that sign correctness is independent of realized magnitude, we show that these two metrics exhibit a quadratic relationship for MSE-optimal point forecasts. For point forecasts with modest DA, the theoretical value of $R^2_{OOS}$ is intrinsically negligible. Thus, a negative empirical $R^2_{OOS}$ is expected if the model is suboptimal or affected by finite sample noise.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790\u6846\u67b6\u5c06\u6837\u672c\u5916R\u00b2\u4e0e\u65b9\u5411\u51c6\u786e\u6027\u8054\u7cfb\u8d77\u6765\uff0c\u63ed\u793a\u4e86\u4e8c\u8005\u5728\u6700\u4f18\u9884\u6d4b\u4e0b\u7684\u4e8c\u6b21\u5173\u7cfb\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u65b9\u5411\u51c6\u786e\u6027\u4e00\u822c\u7684\u6a21\u578b\u5176\u6837\u672c\u5916R\u00b2\u901a\u5e38\u5fae\u4e0d\u8db3\u9053\u751a\u81f3\u4e3a\u8d1f\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\"\u5ea6\u91cf\u8131\u8282\"\u73b0\u8c61\u2014\u2014\u6837\u672c\u5916R\u00b2\u548c\u65b9\u5411\u51c6\u786e\u6027\u8fd9\u4e24\u4e2a\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u7ecf\u5e38\u7ed9\u51fa\u77db\u76fe\u7684\u4fe1\u53f7\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u4e0a\u89e3\u91ca\u8fd9\u79cd\u8131\u8282\u73b0\u8c61\uff0c\u5efa\u7acb\u4e24\u4e2a\u6307\u6807\u4e4b\u95f4\u7684\u89e3\u6790\u8054\u7cfb\u3002", "method": "\u4ee5\u968f\u673a\u6e38\u8d70\u6a21\u578b\u4e3a\u57fa\u51c6\uff0c\u5047\u8bbe\u7b26\u53f7\u6b63\u786e\u6027\u4e0e\u5b9e\u73b0\u5e45\u5ea6\u72ec\u7acb\uff0c\u63a8\u5bfc\u51fa\u5728MSE\u6700\u4f18\u70b9\u9884\u6d4b\u4e0b\uff0c\u6837\u672c\u5916R\u00b2\u4e0e\u65b9\u5411\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u4e8c\u6b21\u5173\u7cfb\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e24\u4e2a\u6307\u6807\u7684\u6570\u5b66\u8054\u7cfb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a\u5bf9\u4e8e\u65b9\u5411\u51c6\u786e\u6027\u4e00\u822c\u7684\u70b9\u9884\u6d4b\uff0c\u5176\u6837\u672c\u5916R\u00b2\u7684\u7406\u8bba\u503c\u672c\u8d28\u4e0a\u5fae\u4e0d\u8db3\u9053\u3002\u5982\u679c\u6a21\u578b\u662f\u6b21\u4f18\u7684\u6216\u53d7\u6709\u9650\u6837\u672c\u566a\u58f0\u5f71\u54cd\uff0c\u8d1f\u7684\u6837\u672c\u5916R\u00b2\u662f\u9884\u671f\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u4e3a\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5ea6\u91cf\u8131\u8282\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u770b\u4f3c\u5408\u7406\u7684\u9884\u6d4b\u6a21\u578b\u53ef\u80fd\u4ea7\u751f\u8d1f\u7684\u6837\u672c\u5916R\u00b2\uff0c\u8fd9\u5bf9\u8bc4\u4f30\u9884\u6d4b\u6a21\u578b\u7684\u5b9e\u9645\u4ef7\u503c\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.07876", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07876", "abs": "https://arxiv.org/abs/2602.07876", "authors": ["Hongzhao Zheng", "Mohamed Atia", "Halim Yanikomeroglu"], "title": "Optimized Deployment of HAPS Systems for GNSS Localization Enhancement in Urban Environments", "comment": null, "summary": "While high altitude platform stations (HAPS) have been primarily explored as network infrastructure for communication services, their advantageous characteristics also make them promising candidates for augmenting GNSS localization. This paper proposes a metaheuristic framework to jointly optimize the number and placement of HAPS for GNSS enhancement in dense urban environments, considering practical constraints such as elevation masks, altitude limits, and ray-traced visibility from 3D city models. The problem is highly nonconvex due to the discrete HAPS count and the environment-dependent 3D Cramer-Rao lower bound (CRLB). To address this, we develop a tailored version of the adaptive special-crowding distance non-dominated sorting genetic algorithm II (ASDNSGA-II). Simulations show the method successfully identifies the minimum number of HAPS needed to satisfy a CRLB threshold and selects the configuration with the lowest CRLB within that minimum, offering a cost-effective and scalable solution for future HAPS-aided positioning systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6846\u67b6\uff0c\u4f18\u5316\u9ad8\u7a7a\u5e73\u53f0\u7ad9(HAPS)\u7684\u6570\u91cf\u548c\u4f4d\u7f6e\uff0c\u7528\u4e8e\u589e\u5f3aGNSS\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u9ad8\u7a7a\u5e73\u53f0\u7ad9(HAPS)\u901a\u5e38\u7528\u4e8e\u901a\u4fe1\u670d\u52a1\uff0c\u4f46\u5176\u4f18\u52bf\u7279\u6027\u4e5f\u4f7f\u5176\u6210\u4e3a\u589e\u5f3aGNSS\u5b9a\u4f4d\u7684\u6709\u524d\u666f\u9009\u62e9\u3002\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\uff0cGNSS\u4fe1\u53f7\u5e38\u88ab\u5efa\u7b51\u7269\u906e\u6321\uff0c\u9700\u8981\u4f18\u5316HAPS\u90e8\u7f72\u6765\u6539\u5584\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u7279\u6b8a\u62e5\u6324\u8ddd\u79bb\u975e\u652f\u914d\u6392\u5e8f\u9057\u4f20\u7b97\u6cd5II(ASDNSGA-II)\u7684\u5b9a\u5236\u7248\u672c\uff0c\u8054\u5408\u4f18\u5316HAPS\u6570\u91cf\u548c\u4f4d\u7f6e\uff0c\u8003\u8651\u4ef0\u89d2\u63a9\u853d\u3001\u9ad8\u5ea6\u9650\u5236\u548c\u57fa\u4e8e3D\u57ce\u5e02\u6a21\u578b\u7684\u5c04\u7ebf\u8ffd\u8e2a\u53ef\u89c1\u6027\u7b49\u5b9e\u9645\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6210\u529f\u8bc6\u522b\u6ee1\u8db3CRLB\u9608\u503c\u6240\u9700\u7684\u6700\u5c0fHAPS\u6570\u91cf\uff0c\u5e76\u5728\u8be5\u6700\u5c0f\u6570\u91cf\u5185\u9009\u62e9\u5177\u6709\u6700\u4f4eCRLB\u7684\u914d\u7f6e\uff0c\u4e3a\u672a\u6765HAPS\u8f85\u52a9\u5b9a\u4f4d\u7cfb\u7edf\u63d0\u4f9b\u7ecf\u6d4e\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u5143\u542f\u53d1\u5f0f\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3HAPS\u90e8\u7f72\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2dGNSS\u589e\u5f3a\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u90e8\u7f72\u6210\u672c\u3002"}}
{"id": "2602.07997", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.07997", "abs": "https://arxiv.org/abs/2602.07997", "authors": ["TrungKhang Tran", "TrungTin Nguyen", "Md Abul Bashar", "Nhat Ho", "Richi Nayak", "Christopher Drovandi"], "title": "Fast Model Selection and Stable Optimization for Softmax-Gated Multinomial-Logistic Mixture of Experts Models", "comment": "TrungKhang Tran and TrungTin Nguyen are co-first authors", "summary": "Mixture-of-Experts (MoE) architectures combine specialized predictors through a learned gate and are effective across regression and classification, but for classification with softmax multinomial-logistic gating, rigorous guarantees for stable maximum-likelihood training and principled model selection remain limited. We address both issues in the full-data (batch) regime. First, we derive a batch minorization-maximization (MM) algorithm for softmax-gated multinomial-logistic MoE using an explicit quadratic minorizer, yielding coordinate-wise closed-form updates that guarantee monotone ascent of the objective and global convergence to a stationary point (in the standard MM sense), avoiding approximate M-steps common in EM-type implementations. Second, we prove finite-sample rates for conditional density estimation and parameter recovery, and we adapt dendrograms of mixing measures to the classification setting to obtain a sweep-free selector of the number of experts that achieves near-parametric optimal rates after merging redundant fitted atoms. Experiments on biological protein--protein interaction prediction validate the full pipeline, delivering improved accuracy and better-calibrated probabilities than strong statistical and machine-learning baselines.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9softmax\u95e8\u63a7\u591a\u9879\u5f0f\u903b\u8f91MoE\u5206\u7c7b\u6a21\u578b\u7684\u6279\u91cfMM\u7b97\u6cd5\uff0c\u4fdd\u8bc1\u5355\u8c03\u4e0a\u5347\u548c\u5168\u5c40\u6536\u655b\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u6df7\u5408\u6d4b\u5ea6\u6811\u72b6\u56fe\u7684\u4e13\u5bb6\u6570\u91cf\u9009\u62e9\u5668\uff0c\u5728\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "MoE\u67b6\u6784\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46softmax\u591a\u9879\u5f0f\u903b\u8f91\u95e8\u63a7\u7684\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u7a33\u5b9a\u6027\u4fdd\u8bc1\u548c\u6a21\u578b\u9009\u62e9\u539f\u5219\u6709\u9650\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "1. \u63a8\u5bfc\u6279\u91cfMM\u7b97\u6cd5\uff0c\u4f7f\u7528\u663e\u5f0f\u4e8c\u6b21\u4e0b\u754c\u51fd\u6570\uff0c\u5f97\u5230\u5750\u6807\u95ed\u5f0f\u66f4\u65b0\uff1b2. \u8bc1\u660e\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u548c\u53c2\u6570\u6062\u590d\u7684\u6709\u9650\u6837\u672c\u7387\uff1b3. \u5c06\u6df7\u5408\u6d4b\u5ea6\u6811\u72b6\u56fe\u9002\u914d\u5230\u5206\u7c7b\u8bbe\u7f6e\uff0c\u5f00\u53d1\u65e0\u9700\u626b\u63cf\u7684\u4e13\u5bb6\u6570\u91cf\u9009\u62e9\u5668\u3002", "result": "\u7b97\u6cd5\u4fdd\u8bc1\u76ee\u6807\u51fd\u6570\u5355\u8c03\u4e0a\u5347\u5e76\u6536\u655b\u5230\u7a33\u5b9a\u70b9\uff1b\u4e13\u5bb6\u6570\u91cf\u9009\u62e9\u5668\u5728\u5408\u5e76\u5197\u4f59\u62df\u5408\u539f\u5b50\u540e\u8fbe\u5230\u8fd1\u53c2\u6570\u6700\u4f18\u7387\uff1b\u5728\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u4f18\u4e8e\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "\u4e3asoftmax\u95e8\u63a7\u591a\u9879\u5f0f\u903b\u8f91MoE\u5206\u7c7b\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u8bad\u7ec3\u7b97\u6cd5\u548c\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u751f\u7269\u4fe1\u606f\u5b66\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.07039", "categories": ["cs.CY", "cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.07039", "abs": "https://arxiv.org/abs/2602.07039", "authors": ["Heimo M\u00fcller"], "title": "When Excellence Stops Producing Knowledge: A Practitioner's Observation on Research Funding", "comment": null, "summary": "After almost four decades of participating in competitive research funding -- as applicant, coordinator, evaluator, and panel member -- I have come to see a structural paradox: many participants recognize that the current system is approaching its functional limits, yet most reform measures intensify rather than alleviate the underlying dynamics. This paper documents how excellence has become decoupled from knowledge production through an increasing coupling to representability under evaluation. The discussion focuses on two domains in which this is particularly visible: competitive basic research funding and large EU consortium projects. Three accelerating trends are examined: the professionalization of proposal writing through specialized consultants, the rise of AI-assisted applications, and an evaluator shortage that forces panels to rely on reviewers increasingly distant from the actual research domains. These observations are offered not as external critique but as an insider account, in the hope that naming a widely experienced but rarely articulated pattern may enable more constructive orientation.\n  Keywords: Research funding, Excellence, Evaluation, Goodhart's Law, Professionalization, AI-assisted proposals, Peer review crisis", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u7814\u7a76\u8d44\u52a9\u4f53\u7cfb\u5b58\u5728\u7ed3\u6784\u6027\u6096\u8bba\uff1a\u53c2\u4e0e\u8005\u8ba4\u8bc6\u5230\u7cfb\u7edf\u63a5\u8fd1\u529f\u80fd\u6781\u9650\uff0c\u4f46\u6539\u9769\u63aa\u65bd\u53cd\u800c\u52a0\u5267\u4e86\u6839\u672c\u95ee\u9898\u3002\u4f5c\u8005\u901a\u8fc7\u5185\u90e8\u89c6\u89d2\u5206\u6790\"\u5353\u8d8a\"\u5982\u4f55\u4e0e\u77e5\u8bc6\u751f\u4ea7\u8131\u94a9\uff0c\u800c\u4e0e\u8bc4\u4f30\u4e2d\u7684\u53ef\u5448\u73b0\u6027\u6302\u94a9\u3002", "motivation": "\u4f5c\u8005\u57fa\u4e8e\u8fd1\u56db\u5341\u5e74\u53c2\u4e0e\u7ade\u4e89\u6027\u7814\u7a76\u8d44\u52a9\u7684\u7ecf\u9a8c\uff08\u4f5c\u4e3a\u7533\u8bf7\u4eba\u3001\u534f\u8c03\u8005\u3001\u8bc4\u4f30\u8005\u548c\u8bc4\u5ba1\u59d4\u5458\uff09\uff0c\u89c2\u5bdf\u5230\u5f53\u524d\u4f53\u7cfb\u7684\u7ed3\u6784\u6027\u77db\u76fe\u3002\u5c3d\u7ba1\u8bb8\u591a\u53c2\u4e0e\u8005\u8ba4\u8bc6\u5230\u7cfb\u7edf\u5df2\u63a5\u8fd1\u529f\u80fd\u6781\u9650\uff0c\u4f46\u5927\u591a\u6570\u6539\u9769\u63aa\u65bd\u53cd\u800c\u52a0\u5267\u4e86\u6839\u672c\u95ee\u9898\uff0c\u800c\u975e\u7f13\u89e3\u3002\u4f5c\u8005\u5e0c\u671b\u4ece\u5185\u90e8\u89c6\u89d2\u63ed\u793a\u8fd9\u4e00\u5e7f\u6cdb\u7ecf\u5386\u4f46\u5f88\u5c11\u88ab\u660e\u786e\u8868\u8ff0\u7684\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u5185\u90e8\u89c2\u5bdf\u548c\u6279\u5224\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u805a\u7126\u4e24\u4e2a\u7279\u522b\u660e\u663e\u7684\u9886\u57df\uff1a\u7ade\u4e89\u6027\u57fa\u7840\u7814\u7a76\u8d44\u52a9\u548c\u5927\u578b\u6b27\u76df\u8054\u76df\u9879\u76ee\u3002\u901a\u8fc7\u5206\u6790\u4e09\u4e2a\u52a0\u901f\u8d8b\u52bf\uff1a\u63d0\u6848\u5199\u4f5c\u7684\u4e13\u4e1a\u5316\uff08\u901a\u8fc7\u4e13\u4e1a\u987e\u95ee\uff09\u3001AI\u8f85\u52a9\u7533\u8bf7\u7684\u589e\u52a0\uff0c\u4ee5\u53ca\u8bc4\u5ba1\u4eba\u5458\u77ed\u7f3a\u5bfc\u81f4\u8bc4\u5ba1\u5c0f\u7ec4\u8d8a\u6765\u8d8a\u4f9d\u8d56\u8fdc\u79bb\u5b9e\u9645\u7814\u7a76\u9886\u57df\u7684\u8bc4\u5ba1\u8005\u3002", "result": "\u7814\u7a76\u53d1\u73b0\"\u5353\u8d8a\"\u5df2\u4e0e\u77e5\u8bc6\u751f\u4ea7\u8131\u94a9\uff0c\u800c\u4e0e\u8bc4\u4f30\u4e2d\u7684\u53ef\u5448\u73b0\u6027\u7d27\u5bc6\u8026\u5408\u3002\u8fd9\u5bfc\u81f4\u4e86Goodhart\u5b9a\u5f8b\u7684\u4f53\u73b0\uff1a\u5f53\u8861\u91cf\u6807\u51c6\u6210\u4e3a\u76ee\u6807\u65f6\uff0c\u5b83\u5c31\u4e0d\u518d\u662f\u597d\u7684\u8861\u91cf\u6807\u51c6\u3002\u7814\u7a76\u8d44\u52a9\u4f53\u7cfb\u51fa\u73b0\u4e86\u529f\u80fd\u5931\u8c03\uff0c\u8bc4\u4f30\u8fc7\u7a0b\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u5f62\u5f0f\u5316\u7684\u5448\u73b0\u800c\u975e\u5b9e\u8d28\u6027\u7684\u7814\u7a76\u8d28\u91cf\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u9700\u8981\u91cd\u65b0\u601d\u8003\u7814\u7a76\u8d44\u52a9\u4f53\u7cfb\uff0c\u8ba4\u8bc6\u5230\u5f53\u524d\u8bc4\u4f30\u673a\u5236\u7684\u5185\u5728\u77db\u76fe\u3002\u901a\u8fc7\u660e\u786e\u8868\u8ff0\u8fd9\u4e00\u5e7f\u6cdb\u7ecf\u5386\u4f46\u5f88\u5c11\u88ab\u8ba8\u8bba\u7684\u6a21\u5f0f\uff0c\u5e0c\u671b\u80fd\u591f\u4e3a\u66f4\u5efa\u8bbe\u6027\u7684\u65b9\u5411\u63d0\u4f9b\u57fa\u7840\uff0c\u907f\u514d\u6539\u9769\u63aa\u65bd\u53cd\u800c\u52a0\u5267\u95ee\u9898\u7684\u6076\u6027\u5faa\u73af\u3002"}}
{"id": "2602.07476", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07476", "abs": "https://arxiv.org/abs/2602.07476", "authors": ["Jingrui Sun", "Lvning Yuan"], "title": "Partial Exponential Turnpike Phenomenon in Linear-Convex Optimal Control", "comment": null, "summary": "This paper studies the long-time behavior of optimal solutions for a class of linear-convex optimal control problems. We focus on a partial exponential turnpike property, established without imposing controllability or stabilizability assumptions, where the turnpike behavior holds only for a subset of initial states. By means of a refined decomposition of the completely uncontrollable dynamics, we derive necessary structural conditions for the turnpike property and explicitly characterize the set of feasible initial states. For each such initial state, we associate a static optimization problem whose unique solution determines the corresponding steady state-control pair. For a class of convex stage cost functions, we prove the partial exponential turnpike property and quantify the convergence rate of the averaged finite-horizon optimal cost toward the steady optimal value.", "AI": {"tldr": "\u7814\u7a76\u7ebf\u6027\u51f8\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u957f\u65f6\u95f4\u884c\u4e3a\uff0c\u5efa\u7acb\u90e8\u5206\u6307\u6570\u8f6c\u5411\u70b9\u6027\u8d28\uff0c\u65e0\u9700\u53ef\u63a7\u6027\u6216\u53ef\u7a33\u6027\u5047\u8bbe\uff0c\u4ec5\u5bf9\u90e8\u5206\u521d\u59cb\u72b6\u6001\u6210\u7acb", "motivation": "\u4f20\u7edf\u8f6c\u5411\u70b9\u6027\u8d28\u901a\u5e38\u9700\u8981\u53ef\u63a7\u6027\u6216\u53ef\u7a33\u6027\u5047\u8bbe\uff0c\u672c\u6587\u65e8\u5728\u653e\u5bbd\u8fd9\u4e9b\u4e25\u683c\u6761\u4ef6\uff0c\u7814\u7a76\u5728\u66f4\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u957f\u65f6\u95f4\u6700\u4f18\u63a7\u5236\u884c\u4e3a", "method": "\u901a\u8fc7\u7cbe\u7ec6\u5206\u89e3\u5b8c\u5168\u4e0d\u53ef\u63a7\u52a8\u6001\uff0c\u63a8\u5bfc\u8f6c\u5411\u70b9\u6027\u8d28\u7684\u5fc5\u8981\u7ed3\u6784\u6761\u4ef6\uff0c\u660e\u786e\u8868\u5f81\u53ef\u884c\u521d\u59cb\u72b6\u6001\u96c6\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u521d\u59cb\u72b6\u6001\u5173\u8054\u9759\u6001\u4f18\u5316\u95ee\u9898", "result": "\u5efa\u7acb\u4e86\u90e8\u5206\u6307\u6570\u8f6c\u5411\u70b9\u6027\u8d28\uff0c\u91cf\u5316\u4e86\u5e73\u5747\u6709\u9650\u65f6\u57df\u6700\u4f18\u6210\u672c\u5411\u7a33\u6001\u6700\u4f18\u503c\u7684\u6536\u655b\u901f\u7387\uff0c\u5e76\u786e\u5b9a\u4e86\u53ef\u884c\u521d\u59cb\u72b6\u6001\u96c6", "conclusion": "\u5728\u65e0\u9700\u53ef\u63a7\u6027\u6216\u53ef\u7a33\u6027\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u4e86\u7ebf\u6027\u51f8\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u90e8\u5206\u6307\u6570\u8f6c\u5411\u70b9\u6027\u8d28\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u63a7\u5236\u7cfb\u7edf\u957f\u65f6\u95f4\u884c\u4e3a\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6"}}
{"id": "2602.07176", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07176", "abs": "https://arxiv.org/abs/2602.07176", "authors": ["Mohamed El Hajji", "Tarek Ait Baha", "Aicha Dakir", "Hammou Fadili", "Youssef Es-Saady"], "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI", "comment": "19 pages, 15 figures", "summary": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.", "AI": {"tldr": "Open TutorAI\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u548c\u751f\u6210\u6280\u672f\u7684\u5f00\u6e90\u6559\u80b2\u5e73\u53f0\uff0c\u901a\u8fc7\u52a8\u6001\u4e2a\u6027\u5316\u8f85\u5bfc\u30013D\u865a\u62df\u5316\u8eab\u548c\u5d4c\u5165\u5f0f\u5b66\u4e60\u5206\u6790\uff0c\u521b\u5efa\u6c89\u6d78\u5f0f\u5b66\u4e60\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u6559\u80b2\u804a\u5929\u673a\u5668\u4eba\u7cfb\u7edf\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u3001\u5b9e\u65f6\u54cd\u5e94\u6027\u548c\u6559\u5b66\u7075\u6d3b\u6027\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u53c2\u4e0e\u5ea6\u548c\u6559\u5b66\u6548\u679c\uff0c\u9700\u8981\u7ed3\u5408AI\u548c\u6c89\u6d78\u5f0f\u6280\u672f\u7684\u5f00\u653e\u96c6\u6210\u5e73\u53f0\u6765\u652f\u6301\u4e2a\u6027\u5316\u5b66\u4e60\u4f53\u9a8c\u3002", "method": "\u57fa\u4e8eLLM\u548c\u751f\u6210\u6280\u672f\u6784\u5efa\u5f00\u6e90\u5e73\u53f0\uff0c\u96c6\u6210\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u53ef\u5b9a\u52363D\u865a\u62df\u5316\u8eab\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5165\u804c\u6d41\u7a0b\u6355\u83b7\u5b66\u4e60\u8005\u76ee\u6807\u548c\u504f\u597d\uff0c\u914d\u7f6e\u4e2a\u6027\u5316\u7684AI\u52a9\u624b\uff0c\u63d0\u4f9b\u6587\u672c\u548c\u865a\u62df\u5316\u8eab\u9a71\u52a8\u7684\u754c\u9762\uff0c\u5305\u542b\u5185\u5bb9\u7ec4\u7ec7\u3001\u5d4c\u5165\u5f0f\u53cd\u9988\u548c\u5b66\u4e60\u5206\u6790\u5de5\u5177\u3002", "result": "\u5f00\u53d1\u4e86Open TutorAI\u5e73\u53f0\uff0c\u7ed3\u5408\u6a21\u5757\u5316\u67b6\u6784\u3001\u751f\u6210AI\u548c\u5b66\u4e60\u5206\u6790\uff0c\u63d0\u4f9b\u81ea\u9002\u5e94\u652f\u6301\uff0c\u589e\u5f3a\u53c2\u4e0e\u5ea6\u548c\u60c5\u611f\u5b58\u5728\u611f\uff0c\u521b\u5efa\u66f4\u52a0\u4eba\u6027\u5316\u3001\u6c89\u6d78\u5f0f\u7684\u5b66\u4e60\u73af\u5883\u3002", "conclusion": "Open TutorAI\u5c06\u6a21\u5757\u5316\u67b6\u6784\u3001\u751f\u6210AI\u548c\u5b66\u4e60\u5206\u6790\u7edf\u4e00\u5728\u5f00\u6e90\u6846\u67b6\u4e2d\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u7684\u53d1\u5c55\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2602.07187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07187", "abs": "https://arxiv.org/abs/2602.07187", "authors": ["Hanyu Wang", "Yuanpu Cao", "Lu Lin", "Jinghui Chen"], "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents", "comment": null, "summary": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.", "AI": {"tldr": "PreFlect \u63d0\u51fa\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236\uff0c\u5728\u8ba1\u5212\u6267\u884c\u524d\u8fdb\u884c\u6279\u8bc4\u548c\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684\u540e\u9a8c\u6027\u9519\u8bef\u4fee\u6b63\uff0c\u901a\u8fc7\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u5b66\u4e60\u89c4\u5212\u9519\u8bef\u6a21\u5f0f\uff0c\u5e76\u7ed3\u5408\u52a8\u6001\u91cd\u89c4\u5212\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u901a\u5e38\u91c7\u7528\u540e\u9a8c\u6027\u81ea\u6211\u53cd\u601d\u673a\u5236\uff0c\u5373\u5728\u6267\u884c\u5931\u8d25\u540e\u624d\u5c1d\u8bd5\u7ea0\u6b63\u9519\u8bef\u3002\u8fd9\u79cd\u56de\u987e\u5f0f\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u9519\u8bef\u5df2\u7ecf\u53d1\u751f\u3002\u4f5c\u8005\u5e0c\u671b\u5c06\u53cd\u601d\u4ece\"\u4e8b\u540e\u7ea0\u6b63\"\u8f6c\u53d8\u4e3a\"\u4e8b\u524d\u9884\u89c1\"\uff0c\u5728\u8ba1\u5212\u6267\u884c\u524d\u5c31\u8fdb\u884c\u4f18\u5316\u3002", "method": "1. \u63d0\u51fa\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236 PreFlect\uff1a\u5728\u6267\u884c\u524d\u5bf9\u667a\u80fd\u4f53\u8ba1\u5212\u8fdb\u884c\u6279\u8bc4\u548c\u4f18\u5316\uff1b2. \u4ece\u5386\u53f2\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u63d0\u70bc\u89c4\u5212\u9519\u8bef\u6a21\u5f0f\uff0c\u6355\u6349\u91cd\u590d\u7684\u6210\u529f\u548c\u5931\u8d25\u6a21\u5f0f\uff1b3. \u7ed3\u5408\u52a8\u6001\u91cd\u89c4\u5212\u673a\u5236\uff0c\u5f53\u539f\u59cb\u8ba1\u5212\u9047\u5230\u610f\u5916\u504f\u5dee\u65f6\u63d0\u4f9b\u6267\u884c\u65f6\u7684\u8ba1\u5212\u66f4\u65b0\u3002", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cPreFlect \u663e\u8457\u63d0\u9ad8\u4e86\u667a\u80fd\u4f53\u5728\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u4e2d\u7684\u6574\u4f53\u6548\u7528\uff0c\u4f18\u4e8e\u57fa\u4e8e\u53cd\u601d\u7684\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u548c\u51e0\u79cd\u66f4\u590d\u6742\u7684\u667a\u80fd\u4f53\u67b6\u6784\u3002", "conclusion": "\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236 PreFlect \u901a\u8fc7\u5c06\u53cd\u601d\u4ece\u540e\u9a8c\u7ea0\u6b63\u8f6c\u53d8\u4e3a\u4e8b\u524d\u9884\u89c1\uff0c\u7ed3\u5408\u5386\u53f2\u9519\u8bef\u6a21\u5f0f\u5b66\u4e60\u548c\u52a8\u6001\u91cd\u89c4\u5212\uff0c\u4e3a\u667a\u80fd\u4f53\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.07063", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.07063", "abs": "https://arxiv.org/abs/2602.07063", "authors": ["Serkan Sulun"], "title": "Video-based Music Generation", "comment": "PhD thesis, University of Porto", "summary": "As the volume of video content on the internet grows rapidly, finding a suitable soundtrack remains a significant challenge. This thesis presents EMSYNC (EMotion and SYNChronization), a fast, free, and automatic solution that generates music tailored to the input video, enabling content creators to enhance their productions without composing or licensing music. Our model creates music that is emotionally and rhythmically synchronized with the video. A core component of EMSYNC is a novel video emotion classifier. By leveraging pretrained deep neural networks for feature extraction and keeping them frozen while training only fusion layers, we reduce computational complexity while improving accuracy. We show the generalization abilities of our method by obtaining state-of-the-art results on Ekman-6 and MovieNet. Another key contribution is a large-scale, emotion-labeled MIDI dataset for affective music generation. We then present an emotion-based MIDI generator, the first to condition on continuous emotional values rather than discrete categories, enabling nuanced music generation aligned with complex emotional content. To enhance temporal synchronization, we introduce a novel temporal boundary conditioning method, called \"boundary offset encodings,\" aligning musical chords with scene changes. Combining video emotion classification, emotion-based music generation, and temporal boundary conditioning, EMSYNC emerges as a fully automatic video-based music generator. User studies show that it consistently outperforms existing methods in terms of music richness, emotional alignment, temporal synchronization, and overall preference, setting a new state-of-the-art in video-based music generation.", "AI": {"tldr": "EMSYNC\u662f\u4e00\u4e2a\u5feb\u901f\u3001\u514d\u8d39\u3001\u81ea\u52a8\u7684\u89c6\u9891\u914d\u4e50\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u60c5\u611f\u5206\u7c7b\u3001\u60c5\u611f\u6761\u4ef6\u97f3\u4e50\u751f\u6210\u548c\u65f6\u95f4\u8fb9\u754c\u5bf9\u9f50\uff0c\u4e3a\u89c6\u9891\u521b\u5efa\u60c5\u611f\u548c\u8282\u594f\u540c\u6b65\u7684\u97f3\u4e50\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u89c6\u9891\u5185\u5bb9\u5feb\u901f\u589e\u957f\uff0c\u5bfb\u627e\u5408\u9002\u7684\u914d\u4e50\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u5185\u5bb9\u521b\u4f5c\u8005\u9700\u8981\u65e0\u9700\u4f5c\u66f2\u6216\u6388\u6743\u5373\u53ef\u589e\u5f3a\u89c6\u9891\u5236\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1) \u65b0\u9896\u7684\u89c6\u9891\u60c5\u611f\u5206\u7c7b\u5668\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\uff0c\u51bb\u7ed3\u7f51\u7edc\u53ea\u8bad\u7ec3\u878d\u5408\u5c42\uff1b2) \u5927\u89c4\u6a21\u60c5\u611f\u6807\u6ce8MIDI\u6570\u636e\u96c6\uff1b3) \u9996\u4e2a\u57fa\u4e8e\u8fde\u7eed\u60c5\u611f\u503c\u800c\u975e\u79bb\u6563\u7c7b\u522b\u7684MIDI\u751f\u6210\u5668\uff1b4) \u65f6\u95f4\u8fb9\u754c\u6761\u4ef6\u65b9\u6cd5\uff08\u8fb9\u754c\u504f\u79fb\u7f16\u7801\uff09\uff0c\u5c06\u97f3\u4e50\u548c\u5f26\u4e0e\u573a\u666f\u53d8\u5316\u5bf9\u9f50\u3002", "result": "\u5728Ekman-6\u548cMovieNet\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\uff1b\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u5728\u97f3\u4e50\u4e30\u5bcc\u5ea6\u3001\u60c5\u611f\u5bf9\u9f50\u3001\u65f6\u95f4\u540c\u6b65\u548c\u6574\u4f53\u504f\u597d\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u89c6\u9891\u97f3\u4e50\u751f\u6210\u7684\u65b0\u6807\u51c6\u3002", "conclusion": "EMSYNC\u4f5c\u4e3a\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u7684\u89c6\u9891\u97f3\u4e50\u751f\u6210\u5668\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u9891\u60c5\u611f\u5206\u7c7b\u3001\u60c5\u611f\u6761\u4ef6\u97f3\u4e50\u751f\u6210\u548c\u65f6\u95f4\u8fb9\u754c\u5bf9\u9f50\uff0c\u4e3a\u5185\u5bb9\u521b\u4f5c\u8005\u63d0\u4f9b\u4e86\u65e0\u9700\u4f5c\u66f2\u6216\u6388\u6743\u7684\u9ad8\u8d28\u91cf\u914d\u4e50\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08899", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.08899", "abs": "https://arxiv.org/abs/2602.08899", "authors": ["Jiaqi Huang"], "title": "Fixed Effects as Generated Regressors", "comment": null, "summary": "Many economic models feature moment conditions that involve latent variables. When the latent variables are individual fixed effects in an auxiliary panel data regression, we construct orthogonal moments that eliminate first-order bias induced by estimating the fixed effects. Machine Learning methods and Empirical Bayes methods can be used to improve the estimate of the nuisance parameters in the orthogonal moments. We establish a central limit theorem based on the orthogonal moments without relying on exogeneity assumptions between panel data residuals and the cross-sectional moment functions. In a simulation study where the exogeneity assumption is violated, the estimator based on orthogonal moments has smaller bias compared with other estimators relying on that assumption. An empirical application on experimental site selection demonstrates how the method can be used for nonlinear moment conditions.", "AI": {"tldr": "\u63d0\u51fa\u6b63\u4ea4\u77e9\u65b9\u6cd5\u6d88\u9664\u9762\u677f\u6570\u636e\u4e2d\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5e26\u6765\u7684\u504f\u5dee\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u7ecf\u9a8c\u8d1d\u53f6\u65af\u6539\u8fdb\u53c2\u6570\u4f30\u8ba1\uff0c\u65e0\u9700\u9762\u677f\u6b8b\u5dee\u4e0e\u6a2a\u622a\u9762\u77e9\u51fd\u6570\u7684\u5916\u751f\u6027\u5047\u8bbe", "motivation": "\u8bb8\u591a\u7ecf\u6d4e\u6a21\u578b\u5305\u542b\u6f5c\u5728\u53d8\u91cf\u7684\u77e9\u6761\u4ef6\uff0c\u5f53\u6f5c\u5728\u53d8\u91cf\u662f\u9762\u677f\u6570\u636e\u56de\u5f52\u4e2d\u7684\u4e2a\u4f53\u56fa\u5b9a\u6548\u5e94\u65f6\uff0c\u56fa\u5b9a\u6548\u5e94\u7684\u4f30\u8ba1\u4f1a\u5f15\u5165\u4e00\u9636\u504f\u5dee\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u9762\u677f\u6b8b\u5dee\u4e0e\u6a2a\u622a\u9762\u77e9\u51fd\u6570\u7684\u5916\u751f\u6027\u5047\u8bbe\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002", "method": "\u6784\u5efa\u6b63\u4ea4\u77e9\u6765\u6d88\u9664\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5f15\u8d77\u7684\u4e00\u9636\u504f\u5dee\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5\u6765\u6539\u8fdb\u6b63\u4ea4\u77e9\u4e2d\u5197\u4f59\u53c2\u6570\u7684\u4f30\u8ba1\u3002\u5efa\u7acb\u57fa\u4e8e\u6b63\u4ea4\u77e9\u7684\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u65e0\u9700\u4f9d\u8d56\u9762\u677f\u6b8b\u5dee\u4e0e\u6a2a\u622a\u9762\u77e9\u51fd\u6570\u7684\u5916\u751f\u6027\u5047\u8bbe\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u5728\u5916\u751f\u6027\u5047\u8bbe\u88ab\u8fdd\u53cd\u7684\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8e\u6b63\u4ea4\u77e9\u7684\u4f30\u8ba1\u91cf\u76f8\u6bd4\u4f9d\u8d56\u8be5\u5047\u8bbe\u7684\u5176\u4ed6\u4f30\u8ba1\u91cf\u5177\u6709\u66f4\u5c0f\u7684\u504f\u5dee\u3002\u5b9e\u8bc1\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5982\u4f55\u7528\u4e8e\u975e\u7ebf\u6027\u77e9\u6761\u4ef6\u3002", "conclusion": "\u6b63\u4ea4\u77e9\u65b9\u6cd5\u4e3a\u5904\u7406\u9762\u677f\u6570\u636e\u4e2d\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u504f\u5dee\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5916\u751f\u6027\u5047\u8bbe\u53ef\u80fd\u4e0d\u6210\u7acb\u7684\u60c5\u51b5\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6280\u672f\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002"}}
{"id": "2602.07921", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07921", "abs": "https://arxiv.org/abs/2602.07921", "authors": ["Najiya Fatma", "Varun Ramamohan"], "title": "Healthcare Facility Assignment Using Real-Time Length-of-Stay Predictions: Queuing-Theoretic and Simulation-driven Machine Learning Approaches", "comment": null, "summary": "Longer stays at healthcare facilities, driven by uncertain patient load, inefficient patient flow, and lack of real-time information about medical care, pose significant challenges for patients and healthcare providers. Providing patients with estimates of their expected real-time length of stay (RT-LOS), generated as a function of the operational state of the healthcare facility at their anticipated time of arrival (as opposed to estimates of average LOS), can help them make informed decisions regarding which facility to visit within a network. In this study, we develop a healthcare facility assignment (HFA) algorithm that assigns healthcare facilities to patients using RT-LOS predictions at facilities within the network of interest. We describe the generation of RT-LOS predictions via two methodologies: (a) an analytical queuing-theoretic approach, and (b) a hybrid simulation-driven machine learning approach. Because RT-LOS predictors are highly specific to the queuing system in question, we illustrate the development of RT-LOS predictors using both approaches by considering the outpatient experience at primary health centers. Via computational experiments, we compare outcomes from the implementation of the RT-HFA algorithm with both RT-LOS predictors to the case where patients visit the facility of their choice. Computational experiments also indicated that the RT-HFA algorithm substantially reduced patient wait times and LOS at congested facilities and led to more equitable utilization of medical resources at facilities across the network. Finally, we show numerically that the effectiveness of the RT-HFA algorithm in improving outcomes is contingent on the level of compliance with the assignment decision.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u5b9e\u65f6\u4f4f\u9662\u65f6\u957f\u9884\u6d4b\u7684\u533b\u7597\u8bbe\u65bd\u5206\u914d\u7b97\u6cd5\uff0c\u901a\u8fc7\u6392\u961f\u8bba\u548c\u6df7\u5408\u4eff\u771f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9884\u6d4bLOS\uff0c\u663e\u8457\u51cf\u5c11\u60a3\u8005\u7b49\u5f85\u65f6\u95f4\u5e76\u4f18\u5316\u7f51\u7edc\u8d44\u6e90\u5229\u7528", "motivation": "\u533b\u7597\u8bbe\u65bd\u4f4f\u9662\u65f6\u95f4\u8fc7\u957f\u7ed9\u60a3\u8005\u548c\u533b\u7597\u673a\u6784\u5e26\u6765\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u60a3\u8005\u8d1f\u8377\u4e0d\u786e\u5b9a\u3001\u60a3\u8005\u6d41\u7a0b\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u7f3a\u4e4f\u5b9e\u65f6\u533b\u7597\u4fe1\u606f\u3002\u4e3a\u60a3\u8005\u63d0\u4f9b\u57fa\u4e8e\u8bbe\u65bd\u8fd0\u8425\u72b6\u6001\u7684\u5b9e\u65f6\u4f4f\u9662\u65f6\u957f\u9884\u6d4b\uff0c\u800c\u975e\u5e73\u5747LOS\u4f30\u8ba1\uff0c\u80fd\u5e2e\u52a9\u4ed6\u4eec\u5728\u7f51\u7edc\u4e2d\u9009\u62e9\u5408\u9002\u7684\u533b\u7597\u673a\u6784\u3002", "method": "\u5f00\u53d1\u533b\u7597\u8bbe\u65bd\u5206\u914d\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e24\u79cd\u65b9\u6cd5\u751f\u6210\u5b9e\u65f6LOS\u9884\u6d4b\uff1a1\uff09\u5206\u6790\u6027\u6392\u961f\u8bba\u65b9\u6cd5\uff1b2\uff09\u6df7\u5408\u4eff\u771f\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002\u4ee5\u521d\u7ea7\u536b\u751f\u4e2d\u5fc3\u95e8\u8bca\u4f53\u9a8c\u4e3a\u4f8b\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b9e\u9a8c\u6bd4\u8f83\u7b97\u6cd5\u5b9e\u65bd\u6548\u679c\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0cRT-HFA\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u62e5\u6324\u8bbe\u65bd\u7684\u7b49\u5f85\u65f6\u95f4\u548cLOS\uff0c\u5b9e\u73b0\u4e86\u7f51\u7edc\u5185\u533b\u7597\u8d44\u6e90\u66f4\u516c\u5e73\u7684\u5229\u7528\u3002\u7b97\u6cd5\u6548\u679c\u53d6\u51b3\u4e8e\u60a3\u8005\u5bf9\u5206\u914d\u51b3\u7b56\u7684\u4f9d\u4ece\u7a0b\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u65f6LOS\u9884\u6d4b\u7684\u533b\u7597\u8bbe\u65bd\u5206\u914d\u7b97\u6cd5\u80fd\u6709\u6548\u6539\u5584\u60a3\u8005\u4f53\u9a8c\u548c\u8d44\u6e90\u5229\u7528\uff0c\u4f46\u5b9e\u65bd\u6548\u679c\u4f9d\u8d56\u4e8e\u60a3\u8005\u5bf9\u5206\u914d\u5efa\u8bae\u7684\u63a5\u53d7\u7a0b\u5ea6\u3002\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u533b\u7597\u8bbe\u65bd\u62e5\u5835\u548c\u8d44\u6e90\u5206\u914d\u4e0d\u5747\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.07659", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.07659", "abs": "https://arxiv.org/abs/2602.07659", "authors": ["Matthew Siper", "Muhammad Umair Nasir", "Ahmed Khalifa", "Lisa Soros", "Jay Azhang", "Julian Togelius"], "title": "Continuous Program Search", "comment": null, "summary": "Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.\n  We make locality measurable by tracking action-level divergence under controlled latent perturbations, identifying an empirical trust region for behavior-local continuous variation. Using a compact trading-strategy DSL with four semantic components (long/short entry and exit), we learn a matching block-factorized embedding and compare isotropic Gaussian mutation over the full latent space to geometry-compiled mutation that restricts updates to semantically paired entry--exit subspaces and proposes directions using a learned flow-based model trained on logged mutation outcomes.\n  Under identical $(\u03bc+\u03bb)$ evolution strategies and fixed evaluation budgets across five assets, the learned mutation operator discovers strong strategies using an order of magnitude fewer evaluations and achieves the highest median out-of-sample Sharpe ratio. Although isotropic mutation occasionally attains higher peak performance, geometry-compiled mutation yields faster, more reliable progress, demonstrating that semantically aligned mutation can substantially improve search efficiency without modifying the underlying evolutionary algorithm.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u5b66\u4e60\u8fde\u7eed\u7a0b\u5e8f\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u7f16\u8bd1\u7684\u53d8\u5f02\u7b97\u5b50\u6539\u5584\u9057\u4f20\u7f16\u7a0b\u7684\u5c40\u90e8\u6027\u548c\u641c\u7d22\u6548\u7387\uff0c\u5728\u4ea4\u6613\u7b56\u7565\u4f18\u5316\u4e2d\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u66f4\u5c11\u7684\u8bc4\u4f30\u6b21\u6570\u548c\u66f4\u9ad8\u7684\u6837\u672c\u5916\u590f\u666e\u6bd4\u7387\u3002", "motivation": "\u9057\u4f20\u7f16\u7a0b\u867d\u7136\u80fd\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u7a0b\u5e8f\uff0c\u4f46\u5c0f\u7684\u8bed\u6cd5\u53d8\u5f02\u53ef\u80fd\u5bfc\u81f4\u5927\u7684\u3001\u4e0d\u53ef\u9884\u6d4b\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u8fd9\u4f1a\u964d\u4f4e\u5c40\u90e8\u6027\u548c\u6837\u672c\u6548\u7387\u3002\u7814\u7a76\u8005\u5c06\u6b64\u89c6\u4e3a\u7b97\u5b50\u8bbe\u8ba1\u95ee\u9898\uff0c\u65e8\u5728\u5b66\u4e60\u4e00\u4e2a\u8fde\u7eed\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u4f7f\u5f97\u6f5c\u5728\u8ddd\u79bb\u5177\u6709\u884c\u4e3a\u610f\u4e49\uff0c\u7136\u540e\u8bbe\u8ba1\u80fd\u591f\u5229\u7528\u8fd9\u79cd\u7ed3\u6784\u800c\u4e0d\u6539\u53d8\u8fdb\u5316\u4f18\u5316\u5668\u7684\u53d8\u5f02\u7b97\u5b50\u3002", "method": "1) \u901a\u8fc7\u8ddf\u8e2a\u53d7\u63a7\u6f5c\u5728\u6270\u52a8\u4e0b\u7684\u52a8\u4f5c\u7ea7\u5dee\u5f02\u6765\u91cf\u5316\u5c40\u90e8\u6027\uff0c\u786e\u5b9a\u884c\u4e3a\u5c40\u90e8\u8fde\u7eed\u53d8\u5316\u7684\u7ecf\u9a8c\u4fe1\u4efb\u533a\u57df\uff1b2) \u4f7f\u7528\u5305\u542b\u56db\u4e2a\u8bed\u4e49\u7ec4\u4ef6\uff08\u591a\u5934/\u7a7a\u5934\u5165\u573a\u548c\u51fa\u573a\uff09\u7684\u7d27\u51d1\u4ea4\u6613\u7b56\u7565DSL\uff1b3) \u5b66\u4e60\u5339\u914d\u7684\u5757\u5206\u89e3\u5d4c\u5165\uff1b4) \u6bd4\u8f83\u5168\u6f5c\u5728\u7a7a\u95f4\u4e0a\u7684\u5404\u5411\u540c\u6027\u9ad8\u65af\u53d8\u5f02\u4e0e\u51e0\u4f55\u7f16\u8bd1\u53d8\u5f02\uff0c\u540e\u8005\u5c06\u66f4\u65b0\u9650\u5236\u5728\u8bed\u4e49\u914d\u5bf9\u7684\u5165\u573a-\u51fa\u573a\u5b50\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u5b66\u4e60\u53d8\u5f02\u7ed3\u679c\u6765\u63d0\u51fa\u65b9\u5411\u3002", "result": "\u5728\u4e94\u4e2a\u8d44\u4ea7\u4e0a\u4f7f\u7528\u76f8\u540c\u7684(\u03bc+\u03bb)\u8fdb\u5316\u7b56\u7565\u548c\u56fa\u5b9a\u8bc4\u4f30\u9884\u7b97\u4e0b\uff0c\u5b66\u4e60\u7684\u53d8\u5f02\u7b97\u5b50\u4f7f\u7528\u6570\u91cf\u7ea7\u66f4\u5c11\u7684\u8bc4\u4f30\u53d1\u73b0\u4e86\u5f3a\u7b56\u7565\uff0c\u5e76\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u4e2d\u4f4d\u6570\u6837\u672c\u5916\u590f\u666e\u6bd4\u7387\u3002\u867d\u7136\u5404\u5411\u540c\u6027\u53d8\u5f02\u5076\u5c14\u80fd\u8fbe\u5230\u66f4\u9ad8\u7684\u5cf0\u503c\u6027\u80fd\uff0c\u4f46\u51e0\u4f55\u7f16\u8bd1\u53d8\u5f02\u63d0\u4f9b\u4e86\u66f4\u5feb\u3001\u66f4\u53ef\u9760\u7684\u8fdb\u5c55\u3002", "conclusion": "\u8bed\u4e49\u5bf9\u9f50\u7684\u53d8\u5f02\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u5e95\u5c42\u8fdb\u5316\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u641c\u7d22\u6548\u7387\uff0c\u51e0\u4f55\u7f16\u8bd1\u53d8\u5f02\u6bd4\u5404\u5411\u540c\u6027\u53d8\u5f02\u5728\u4ea4\u6613\u7b56\u7565\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u641c\u7d22\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.08042", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08042", "abs": "https://arxiv.org/abs/2602.08042", "authors": ["Nadav Katz", "Ariel Jaffe"], "title": "Graph-based Semi-Supervised Learning via Maximum Discrimination", "comment": null, "summary": "Semi-supervised learning (SSL) addresses the critical challenge of training accurate models when labeled data is scarce but unlabeled data is abundant. Graph-based SSL (GSSL) has emerged as a popular framework that captures data structure through graph representations. Classic graph SSL methods, such as Label Propagation and Label Spreading, aim to compute low-dimensional representations where points with the same labels are close in representation space. Although often effective, these methods can be suboptimal on data with complex label distributions. In our work, we develop AUC-spec, a graph approach that computes a low-dimensional representation that maximizes class separation. We compute this representation by optimizing the Area Under the ROC Curve (AUC) as estimated via the labeled points. We provide a detailed analysis of our approach under a product-of-manifold model, and show that the required number of labeled points for AUC-spec is polynomial in the model parameters. Empirically, we show that AUC-spec balances class separation with graph smoothness. It demonstrates competitive results on synthetic and real-world datasets while maintaining computational efficiency comparable to the field's classic and state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faAUC-spec\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316AUC\u6307\u6807\u6765\u6700\u5927\u5316\u7c7b\u522b\u5206\u79bb\uff0c\u5728\u6807\u7b7e\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u56fe\u534a\u76d1\u7763\u5b66\u4e60\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fe\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u6807\u7b7e\u4f20\u64ad\uff09\u5728\u5904\u7406\u590d\u6742\u6807\u7b7e\u5206\u5e03\u65f6\u53ef\u80fd\u4e0d\u591f\u7406\u60f3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u5206\u79bb\u4e0d\u540c\u7c7b\u522b\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1AUC-spec\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316ROC\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\u6765\u8ba1\u7b97\u4f4e\u7ef4\u8868\u793a\uff0c\u6700\u5927\u5316\u7c7b\u522b\u5206\u79bb\u3002\u5728\u6d41\u5f62\u4e58\u79ef\u6a21\u578b\u4e0b\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u7406\u8bba\u8bc1\u660eAUC-spec\u6240\u9700\u6807\u7b7e\u6570\u91cf\u662f\u6a21\u578b\u53c2\u6570\u7684\u591a\u9879\u5f0f\u51fd\u6570\u3002\u5b9e\u9a8c\u663e\u793a\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e73\u8861\u4e86\u7c7b\u522b\u5206\u79bb\u548c\u56fe\u5e73\u6ed1\u6027\u3002", "conclusion": "AUC-spec\u662f\u4e00\u79cd\u6709\u6548\u7684\u56fe\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u5904\u7406\u590d\u6742\u6807\u7b7e\u5206\u5e03\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.08246", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08246", "abs": "https://arxiv.org/abs/2602.08246", "authors": ["Atrisha Sarkar", "Isam Faik"], "title": "Structural transparency of societal AI alignment through Institutional Logics", "comment": null, "summary": "The field of AI alignment is increasingly concerned with the questions of how values are integrated into the design of generative AI systems and how their integration shapes the social consequences of AI. However, existing transparency frameworks focus on the informational aspects of AI models, data, and procedures, while the institutional and organizational forces that shape alignment decisions and their downstream effects remain underexamined in both research and practice. To address this gap, we develop a framework of \\emph{structural transparency} for analyzing organizational and institutional decisions concerning AI alignment, drawing on the theoretical lens of Institutional Logics. We develop a categorization of organizational decisions that are present in the governance of AI alignment, and provide an explicit analytical approach to examining them. We operationalize the framework through five analytical components, each with an accompanying \"analyst recipe\" that collectively identify the primary institutional logics and their internal relationships, external disruptions to existing social orders, and finally, how the structural risks of each institutional logic are mapped to a catalogue of sociotechnical harms. The proposed concept of structural transparency enables analysts to complement existing approached based on informational transparency with macro-level analyses that capture the institutional dynamics and consequences of decisions regarding AI alignment.", "AI": {"tldr": "\u63d0\u51fa\"\u7ed3\u6784\u900f\u660e\u5ea6\"\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790AI\u5bf9\u9f50\u4e2d\u7684\u7ec4\u7ec7\u548c\u5236\u5ea6\u51b3\u7b56\uff0c\u8865\u5145\u73b0\u6709\u4fe1\u606f\u900f\u660e\u5ea6\u65b9\u6cd5", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u3001\u6570\u636e\u548c\u7a0b\u5e8f\u7684\u4fe1\u606f\u5c42\u9762\uff0c\u800c\u5851\u9020\u5bf9\u9f50\u51b3\u7b56\u7684\u7ec4\u7ec7\u548c\u5236\u5ea6\u529b\u91cf\u53ca\u5176\u793e\u4f1a\u5f71\u54cd\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u6846\u67b6", "method": "\u57fa\u4e8e\u5236\u5ea6\u903b\u8f91\u7406\u8bba\uff0c\u5f00\u53d1\u7ed3\u6784\u900f\u660e\u5ea6\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5206\u6790\u7ec4\u4ef6\u548c\"\u5206\u6790\u5e08\u914d\u65b9\"\uff0c\u8bc6\u522b\u5236\u5ea6\u903b\u8f91\u3001\u793e\u4f1a\u79e9\u5e8f\u7834\u574f\u4ee5\u53ca\u7ed3\u6784\u98ce\u9669\u4e0e\u793e\u4f1a\u6280\u672f\u5371\u5bb3\u7684\u6620\u5c04", "result": "\u5efa\u7acb\u4e86\u80fd\u591f\u5206\u6790AI\u5bf9\u9f50\u6cbb\u7406\u4e2d\u7ec4\u7ec7\u51b3\u7b56\u7684\u5206\u7c7b\u4f53\u7cfb\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u4f7f\u5206\u6790\u5e08\u80fd\u591f\u4ece\u5b8f\u89c2\u5c42\u9762\u7406\u89e3\u5236\u5ea6\u52a8\u6001\u548c\u51b3\u7b56\u540e\u679c", "conclusion": "\u7ed3\u6784\u900f\u660e\u5ea6\u6846\u67b6\u8865\u5145\u4e86\u73b0\u6709\u4fe1\u606f\u900f\u660e\u5ea6\u65b9\u6cd5\uff0c\u4e3a\u5206\u6790AI\u5bf9\u9f50\u7684\u7ec4\u7ec7\u548c\u5236\u5ea6\u5c42\u9762\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u51b3\u7b56\u7684\u793e\u4f1a\u5f71\u54cd"}}
{"id": "2602.07507", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07507", "abs": "https://arxiv.org/abs/2602.07507", "authors": ["Yuan Chang", "Lizhong Jiang", "Tai-Fang Li", "Jun Fu"], "title": "A Taylor-Bernstein Inner Approximation Algorithm for Path-Constrained Dynamic Optimization", "comment": null, "summary": "A novel inner approximation algorithm is proposed for dynamic optimization problems to ensure strict satisfaction of path constraints. Distinct from traditional methods relying on interval analysis, the proposed algorithm leverages the convex hull property of Bernstein polynomials to tightly bound the polynomial components of the Taylor expansion, while incorporating the Log-Sum-Exp technique to smooth the non-differentiability arising from coefficient maximization. This approach yields a tighter upper bound function compared to interval methods, with a smaller approximation error. Theoretical analysis shows that the algorithm converges in a finite number of steps to a KKT solution of the original problem that satisfies the specified tolerances. Numerical simulations confirm that the proposed algorithm effectively reduces the number of constraints in the approximation problem, improving computational performance while ensuring strict feasibility.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eBernstein\u591a\u9879\u5f0f\u51f8\u5305\u6027\u8d28\u7684\u5185\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u4f18\u5316\u95ee\u9898\u7684\u8def\u5f84\u7ea6\u675f\u4e25\u683c\u6ee1\u8db3\uff0c\u76f8\u6bd4\u4f20\u7edf\u533a\u95f4\u65b9\u6cd5\u5177\u6709\u66f4\u7d27\u7684\u4e0a\u754c\u548c\u66f4\u5c0f\u7684\u8fd1\u4f3c\u8bef\u5dee\u3002", "motivation": "\u4f20\u7edf\u52a8\u6001\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u8def\u5f84\u7ea6\u675f\u7684\u4e25\u683c\u6ee1\u8db3\u662f\u4e00\u4e2a\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u533a\u95f4\u5206\u6790\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4ea7\u751f\u7684\u4e0a\u754c\u4e0d\u591f\u7d27\u81f4\uff0c\u5bfc\u81f4\u8fd1\u4f3c\u8bef\u5dee\u8f83\u5927\uff0c\u8ba1\u7b97\u6548\u7387\u4e0d\u9ad8\u3002", "method": "\u5229\u7528Bernstein\u591a\u9879\u5f0f\u7684\u51f8\u5305\u6027\u8d28\u6765\u7d27\u81f4\u5730\u754c\u5b9a\u6cf0\u52d2\u5c55\u5f00\u7684\u591a\u9879\u5f0f\u5206\u91cf\uff0c\u540c\u65f6\u91c7\u7528Log-Sum-Exp\u6280\u672f\u5e73\u6ed1\u7cfb\u6570\u6700\u5927\u5316\u5e26\u6765\u7684\u4e0d\u53ef\u5fae\u6027\uff0c\u4ece\u800c\u83b7\u5f97\u6bd4\u533a\u95f4\u65b9\u6cd5\u66f4\u7d27\u7684\u4e0a\u754c\u51fd\u6570\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u7b97\u6cd5\u5728\u6709\u9650\u6b65\u5185\u6536\u655b\u5230\u6ee1\u8db3\u6307\u5b9a\u5bb9\u5dee\u7684\u539f\u59cb\u95ee\u9898\u7684KKT\u89e3\u3002\u6570\u503c\u6a21\u62df\u8bc1\u5b9e\u8be5\u7b97\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u8fd1\u4f3c\u95ee\u9898\u7684\u7ea6\u675f\u6570\u91cf\uff0c\u5728\u786e\u4fdd\u4e25\u683c\u53ef\u884c\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5185\u8fd1\u4f3c\u7b97\u6cd5\u901a\u8fc7Bernstein\u591a\u9879\u5f0f\u548cLog-Sum-Exp\u6280\u672f\u7684\u7ed3\u5408\uff0c\u4e3a\u52a8\u6001\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u3001\u66f4\u7cbe\u786e\u7684\u8def\u5f84\u7ea6\u675f\u5904\u7406\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u4e25\u683c\u53ef\u884c\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.07181", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07181", "abs": "https://arxiv.org/abs/2602.07181", "authors": ["Tianyu Zhao", "Siqi Li", "Yasser Shoukry", "Salma Elmalaki"], "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs", "comment": null, "summary": "User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPACIFIC\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u683c\u7279\u8d28\u4f5c\u4e3a\u6f5c\u5728\u4fe1\u53f7\u6765\u4f18\u5316LLM\u4e2a\u6027\u5316\u56de\u7b54\uff0c\u4f7f\u7528\u4eba\u683c\u5bf9\u9f50\u7684\u504f\u597d\u9009\u62e9\u53ef\u5c06\u51c6\u786e\u7387\u4ece29.25%\u63d0\u5347\u81f376%\u3002", "motivation": "\u7528\u6237\u504f\u597d\u5e38\u88ab\u7528\u4e8e\u4e2a\u6027\u5316LLM\u56de\u7b54\uff0c\u4f46\u504f\u597d\u4fe1\u53f7\u53ef\u80fd\u5608\u6742\u3001\u4e0d\u5b8c\u6574\u751a\u81f3\u8bef\u5bfc\uff0c\u76f4\u63a5\u5e94\u7528\u4f1a\u964d\u4f4e\u56de\u7b54\u8d28\u91cf\u3002\u7814\u7a76\u53d1\u73b0\u7a33\u5b9a\u7684\u4eba\u683c\u7279\u8d28\u5851\u9020\u65e5\u5e38\u504f\u597d\uff0c\u56e0\u6b64\u63a2\u7d22\u4eba\u683c\u4f5c\u4e3a\u504f\u597d\u7684\u6f5c\u5728\u4fe1\u53f7\u3002", "method": "1) \u63d0\u51faPACIFIC\u4eba\u683c\u6807\u6ce8\u504f\u597d\u6570\u636e\u96c6\uff0c\u5305\u542b1200\u4e2a\u8de8\u9886\u57df\u504f\u597d\u58f0\u660e\uff0c\u6807\u6ce8\u5927\u4e94\u4eba\u683c\u7279\u8d28\u65b9\u5411\uff1b2) \u5f00\u53d1\u6846\u67b6\u4f7fLLM\u80fd\u81ea\u52a8\u68c0\u7d22\u4eba\u683c\u5bf9\u9f50\u7684\u504f\u597d\u5e76\u5728\u56de\u7b54\u751f\u6210\u4e2d\u6574\u5408\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u57fa\u4e8e\u4eba\u683c\u5bf9\u9f50\u7684\u504f\u597d\u9009\u62e9\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u95ee\u7b54\u6027\u80fd\uff0c\u7b54\u6848\u9009\u62e9\u51c6\u786e\u7387\u4ece29.25%\u63d0\u5347\u81f376%\uff08\u76f8\u6bd4\u968f\u673a\u9009\u62e9\u504f\u597d\uff09\u3002", "conclusion": "\u4eba\u683c\u7279\u8d28\u53ef\u4f5c\u4e3a\u53ef\u9760\u6f5c\u5728\u4fe1\u53f7\u6765\u4f18\u5316LLM\u4e2a\u6027\u5316\u56de\u7b54\uff0cPACIFIC\u6570\u636e\u96c6\u548c\u6846\u67b6\u4e3a\u57fa\u4e8e\u4eba\u683c\u7684\u504f\u597d\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07070", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07070", "abs": "https://arxiv.org/abs/2602.07070", "authors": ["Vladimer Khasia"], "title": "Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures", "comment": null, "summary": "Standard Transformer architectures rely heavily on dense linear transformations, treating feature projection as a monolithic, full-rank operation. We argue that this formulation is inefficient and lacks the structural inductive bias necessary for distinguishing between local feature preservation and global context integration. To address this, we introduce the Hybrid Dual-Path Linear (HDPL) operator, which decomposes the affine transformation into two topologically distinct pathways: a sparse block-diagonal component for high-rank local processing, and a low-rank Variational Autoencoder (VAE) bottleneck for global context regularization. By \"surgically\" replacing specific projections (Query, Key, Value, Gate, Up) with HDPL operators while retaining standard dense layers for aggregation (Output, Down), we achieve a superior balance of efficiency and representational power. Experiments on the FineWeb-Edu dataset demonstrate that the HDPL architecture outperforms a standard Llama-style baseline, reducing validation loss while simultaneously reducing parameter count by 6.8%. Beyond immediate performance gains, we discuss how the explicit materialization of a probabilistic latent space within the Transformer backbone serves as a vital architectural affordance, offering new pathways for inference-time or hypernetwork induced control, continual adaptation, interpretability, and cross-model or cross-modal synchronization. The code is available at https://github.com/VladimerKhasia/HDPL", "AI": {"tldr": "HDPL\u5c06Transformer\u4e2d\u7684\u5bc6\u96c6\u7ebf\u6027\u53d8\u6362\u5206\u89e3\u4e3a\u7a00\u758f\u5757\u5bf9\u89d2\u5c40\u90e8\u5904\u7406\u8def\u5f84\u548c\u4f4e\u79e9VAE\u74f6\u9888\u5168\u5c40\u4e0a\u4e0b\u6587\u8def\u5f84\uff0c\u5728\u51cf\u5c116.8%\u53c2\u6570\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd", "motivation": "\u6807\u51c6Transformer\u7684\u5bc6\u96c6\u7ebf\u6027\u53d8\u6362\u6548\u7387\u4f4e\u4e0b\uff0c\u7f3a\u4e4f\u533a\u5206\u5c40\u90e8\u7279\u5f81\u4fdd\u7559\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u6574\u5408\u7684\u7ed3\u6784\u6027\u5f52\u7eb3\u504f\u7f6e", "method": "\u63d0\u51fa\u6df7\u5408\u53cc\u8def\u5f84\u7ebf\u6027(HDPL)\u7b97\u5b50\uff0c\u5c06\u4eff\u5c04\u53d8\u6362\u5206\u89e3\u4e3a\uff1a1)\u7a00\u758f\u5757\u5bf9\u89d2\u7ec4\u4ef6\u7528\u4e8e\u9ad8\u79e9\u5c40\u90e8\u5904\u7406\uff1b2)\u4f4e\u79e9VAE\u74f6\u9888\u7528\u4e8e\u5168\u5c40\u4e0a\u4e0b\u6587\u6b63\u5219\u5316\u3002\u9009\u62e9\u6027\u66ff\u6362Query\u3001Key\u3001Value\u3001Gate\u3001Up\u7b49\u6295\u5f71\uff0c\u4fdd\u7559Output\u3001Down\u7b49\u805a\u5408\u5c42", "result": "\u5728FineWeb-Edu\u6570\u636e\u96c6\u4e0a\uff0cHDPL\u67b6\u6784\u4f18\u4e8e\u6807\u51c6Llama\u98ce\u683c\u57fa\u7ebf\uff0c\u5728\u51cf\u5c116.8%\u53c2\u6570\u7684\u540c\u65f6\u964d\u4f4e\u9a8c\u8bc1\u635f\u5931", "conclusion": "HDPL\u5728\u6548\u7387\u548c\u8868\u793a\u80fd\u529b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\uff0c\u5176\u663e\u5f0f\u7684\u6982\u7387\u6f5c\u5728\u7a7a\u95f4\u4e3a\u63a8\u7406\u65f6\u63a7\u5236\u3001\u6301\u7eed\u9002\u5e94\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6a21\u578b\u540c\u6b65\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.08892", "categories": ["stat.ML", "cs.LG", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.08892", "abs": "https://arxiv.org/abs/2602.08892", "authors": ["Hamsa Bastani", "Osbert Bastani", "Bryce McLaughlin"], "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching", "comment": null, "summary": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.", "AI": {"tldr": "\u6a21\u578b\u9a71\u52a8\u7684\u653f\u7b56\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u8d62\u5bb6\u8bc5\u5492\u95ee\u9898\uff0c\u5373\u4f7f\u6ee1\u8db3\u5e38\u89c1\u5408\u7406\u6027\u5047\u8bbe\uff08\u6a21\u578b\u51c6\u786e\u3001\u968f\u673a\u5206\u914d\u3001\u6a21\u578b\u65cf\u6b63\u786e\u3001\u6837\u672c\u5206\u5272\uff09\uff0c\u4ecd\u4f1a\u4ea7\u751f\u865a\u5047\u7684\u4e50\u89c2\u6548\u76ca\u4f30\u8ba1\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u4e2d\u7684\u4e3b\u8981\u6311\u6218\u662f\u51c6\u786e\u7684\u653f\u7b56\u8bc4\u4f30\uff0c\u786e\u4fdd\u5b66\u4e60\u5230\u7684\u51b3\u7b56\u653f\u7b56\u80fd\u5b9e\u73b0\u627f\u8bfa\u7684\u6548\u76ca\u3002\u5f53\u524d\u6d41\u884c\u7684\u6a21\u578b\u9a71\u52a8\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u8d62\u5bb6\u8bc5\u5492\u95ee\u9898\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u4e50\u89c2\u7684\u6548\u76ca\u4f30\u8ba1\uff0c\u4f46\u8fd9\u4e00\u7f3a\u9677\u5728\u7ba1\u7406\u79d1\u5b66\u6587\u732e\u4e2d\u666e\u904d\u5b58\u5728\u4e14\u88ab\u5ffd\u89c6\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u8bc6\u522b55\u7bc7\u7ba1\u7406\u79d1\u5b66\u8bba\u6587\u4e2d\u7684\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u9677\uff0c\u8fdb\u884c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u8d62\u5bb6\u8bc5\u5492\u95ee\u9898\u65e0\u6cd5\u901a\u8fc7\u5e38\u89c1\u5408\u7406\u6027\u5047\u8bbe\u907f\u514d\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u96be\u6c11\u5339\u914d\u95ee\u9898\u7684\u4eff\u771f\u7814\u7a76\u9a8c\u8bc1\u7406\u8bba\u53d1\u73b0\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u8d62\u5bb6\u8bc5\u5492\u4f1a\u5bfc\u81f4\u865a\u5047\u7684\u6548\u76ca\u62a5\u544a\uff1b\u4eff\u771f\u7814\u7a76\u5728\u771f\u5b9e\u6548\u5e94\u4e3a\u96f6\u7684\u8bbe\u7f6e\u4e2d\uff0c\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\u4ecd\u62a5\u544a\u7ea660%\u7684\u7a33\u5b9a\u589e\u76ca\uff0c\u4e0e\u6587\u732e\u4e2d\u62a5\u544a\u768422-75%\u6539\u8fdb\u76f8\u5f53\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u7684\u653f\u7b56\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u5373\u4f7f\u6ee1\u8db3\u6240\u6709\u5e38\u89c1\u5408\u7406\u6027\u5047\u8bbe\u4e5f\u65e0\u6cd5\u907f\u514d\u8d62\u5bb6\u8bc5\u5492\u95ee\u9898\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u5f53\u524d\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u4e2d\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002"}}
{"id": "2602.07958", "categories": ["eess.SY", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07958", "abs": "https://arxiv.org/abs/2602.07958", "authors": ["Yumin Kim", "Hyeonsu Lyu", "Minjae Lee", "Hyun Jong Yang"], "title": "Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty", "comment": "This paper has been accepted at 2025 IEEE Globecom Workshop: WS02-GAIMC: Mutual Facilitation of Generative Artificial Intelligence and Mobile Communications", "summary": "Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically decides whether to perform inference locally or offload it to the ES, based on token-level uncertainty and resource constraints. We define a margin-based token-level uncertainty metric and demonstrate its correlation with model accuracy. Leveraging this metric, we design a greedy offloading algorithm (GOA) that minimizes delay while maintaining accuracy by prioritizing offloading for highuncertainty queries. Our experiments show that GOA consistently achieves a favorable trade-off, outperforming baseline strategies in both accuracy and latency across varying user densities, and operates with practical computation time. These results establish GOA as a scalable and effective solution for LLM inference in MEC environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684LLM\u63a8\u7406\u5378\u8f7d\u6846\u67b6\uff0c\u901a\u8fc7token\u7ea7\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u52a8\u6001\u51b3\u7b56\u672c\u5730\u6267\u884c\u6216\u8fb9\u7f18\u5378\u8f7d\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u6700\u5c0f\u5316\u5ef6\u8fdf", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u8ba1\u7b97\u5bc6\u96c6\uff0c\u8fb9\u7f18\u8ba1\u7b97\u867d\u7136\u80fd\u5378\u8f7d\u4efb\u52a1\u4f46\u5f15\u5165\u901a\u4fe1\u548c\u6392\u961f\u5ef6\u8fdf\uff0c\u7279\u522b\u662f\u5728\u591a\u7528\u6237\u73af\u5883\u4e2d\u9700\u8981\u667a\u80fd\u7684\u5378\u8f7d\u51b3\u7b56\u673a\u5236", "method": "\u5b9a\u4e49\u57fa\u4e8e\u8fb9\u754c\u7684token\u7ea7\u4e0d\u786e\u5b9a\u6027\u6307\u6807\uff0c\u8bbe\u8ba1\u8d2a\u5fc3\u5378\u8f7d\u7b97\u6cd5(GOA)\uff0c\u6839\u636e\u4e0d\u786e\u5b9a\u6027\u9ad8\u4f4e\u548c\u8d44\u6e90\u7ea6\u675f\u52a8\u6001\u51b3\u5b9a\u672c\u5730\u6267\u884c\u6216\u8fb9\u7f18\u670d\u52a1\u5668\u5378\u8f7d", "result": "GOA\u5728\u4e0d\u540c\u7528\u6237\u5bc6\u5ea6\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u7b56\u7565\uff0c\u5728\u7cbe\u5ea6\u548c\u5ef6\u8fdf\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u8ba1\u7b97\u65f6\u95f4\u5b9e\u7528\uff0c\u8bc1\u660e\u5176\u5728MEC\u73af\u5883\u4e2dLLM\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u5378\u8f7d\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0cGOA\u7b97\u6cd5\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf"}}
{"id": "2602.08185", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08185", "abs": "https://arxiv.org/abs/2602.08185", "authors": ["Masanari Kimura"], "title": "Information Geometry of Absorbing Markov-Chain and Discriminative Random Walks", "comment": null, "summary": "Discriminative Random Walks (DRWs) are a simple yet powerful tool for semi-supervised node classification, but their theoretical foundations remain fragmentary. We revisit DRWs through the lens of information geometry, treating the family of class-specific hitting-time laws on an absorbing Markov chain as a statistical manifold. Starting from a log-linear edge-weight model, we derive closed-form expressions for the hitting-time probability mass function, its full moment hierarchy, and the observed Fisher information. The Fisher matrix of each seed node turns out to be rank-one, taking the quotient by its null space yields a low-dimensional, globally flat manifold that captures all identifiable directions of the model. Leveraging the geometry, we introduce a sensitivity score for unlabeled nodes that bounds, and in one-dimensional cases attains, the maximal first-order change in DRW betweenness under unit Fisher perturbations. The score can lead to principled strategies for active label acquisition, edge re-weighting, and explanation.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u51e0\u4f55\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u5224\u522b\u968f\u673a\u6e38\u8d70\uff0c\u5c06\u7c7b\u522b\u7279\u5b9a\u547d\u4e2d\u65f6\u95f4\u5206\u5e03\u89c6\u4e3a\u7edf\u8ba1\u6d41\u5f62\uff0c\u63a8\u5bfc\u51fa\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eFisher\u4fe1\u606f\u7684\u8282\u70b9\u654f\u611f\u5ea6\u8bc4\u5206\u6846\u67b6\u3002", "motivation": "\u5224\u522b\u968f\u673a\u6e38\u8d70\u662f\u534a\u76d1\u7763\u8282\u70b9\u5206\u7c7b\u7684\u6709\u6548\u5de5\u5177\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u5c1a\u4e0d\u5b8c\u6574\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4fe1\u606f\u51e0\u4f55\u7406\u8bba\u4e3aDRW\u5efa\u7acb\u66f4\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\uff0c\u7279\u522b\u662f\u7406\u89e3\u5176\u7edf\u8ba1\u7279\u6027\u548c\u53ef\u8bc6\u522b\u6027\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u51e0\u4f55\u65b9\u6cd5\uff0c\u5c06\u7c7b\u522b\u7279\u5b9a\u547d\u4e2d\u65f6\u95f4\u5206\u5e03\u65cf\u89c6\u4e3a\u7edf\u8ba1\u6d41\u5f62\u3002\u4ece\u5bf9\u6570\u7ebf\u6027\u8fb9\u6743\u91cd\u6a21\u578b\u51fa\u53d1\uff0c\u63a8\u5bfc\u547d\u4e2d\u65f6\u95f4\u6982\u7387\u8d28\u91cf\u51fd\u6570\u3001\u5b8c\u6574\u77e9\u5c42\u6b21\u548c\u89c2\u6d4bFisher\u4fe1\u606f\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002\u901a\u8fc7\u5546\u7a7a\u95f4\u964d\u7ef4\u5f97\u5230\u4f4e\u7ef4\u5e73\u5766\u6d41\u5f62\uff0c\u5e76\u57fa\u4e8e\u51e0\u4f55\u7ed3\u6784\u63d0\u51fa\u8282\u70b9\u654f\u611f\u5ea6\u8bc4\u5206\u3002", "result": "\u53d1\u73b0\u6bcf\u4e2a\u79cd\u5b50\u8282\u70b9\u7684Fisher\u77e9\u9635\u662f\u79e9\u4e00\u7684\uff0c\u901a\u8fc7\u5546\u53bb\u96f6\u7a7a\u95f4\u5f97\u5230\u4f4e\u7ef4\u5e73\u5766\u6d41\u5f62\u3002\u63d0\u51fa\u7684\u654f\u611f\u5ea6\u8bc4\u5206\u80fd\u591f\u754c\u5b9a\uff08\u5728\u4e00\u7ef4\u60c5\u51b5\u4e0b\u8fbe\u5230\uff09DRW\u4ecb\u6570\u5728\u5355\u4f4dFisher\u6270\u52a8\u4e0b\u7684\u6700\u5927\u4e00\u9636\u53d8\u5316\uff0c\u4e3a\u4e3b\u52a8\u6807\u7b7e\u83b7\u53d6\u3001\u8fb9\u91cd\u52a0\u6743\u548c\u89e3\u91ca\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u4fe1\u606f\u51e0\u4f55\u4e3a\u5224\u522b\u968f\u673a\u6e38\u8d70\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5176\u5185\u5728\u7684\u7edf\u8ba1\u7ed3\u6784\u3002\u63d0\u51fa\u7684\u654f\u611f\u5ea6\u8bc4\u5206\u6846\u67b6\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9DRW\u7684\u7406\u89e3\uff0c\u8fd8\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4e3b\u52a8\u5b66\u4e60\u3001\u6a21\u578b\u8c03\u6574\u548c\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\u3002"}}
{"id": "2602.08299", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08299", "abs": "https://arxiv.org/abs/2602.08299", "authors": ["Hibiki Ito", "Chia-Yu Hsu", "Hiroaki Ogata"], "title": "Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education", "comment": "10 pages, 3 figures. Accepted for LAK2026", "summary": "The rapid adoption of digital technologies has greatly increased the volume of real-world data (RWD) in education. While these data offer significant opportunities for advancing learning analytics (LA), secondary use for research is constrained by privacy concerns. Differentially private synthetic data generation is regarded as the gold-standard approach to sharing sensitive data, yet studies on the private synthesis of educational data remain very scarce and rely predominantly on large, low-dimensional open datasets. Educational RWD, however, are typically high-dimensional and small in sample size, leaving the potential of private synthesis underexplored. Moreover, because educational practice is inherently iterative, data sharing is continual rather than one-off, making a traditional one-shot synthesis approach suboptimal. To address these challenges, we propose the Cyclic Adaptive Private Synthesis (CAPS) framework and evaluate it on authentic RWD. By iteratively sharing RWD, CAPS not only fosters open science, but also offers rich opportunities of design-based research (DBR), thereby amplifying the impact of LA. Our case study using actual RWD demonstrates that CAPS outperforms a one-shot baseline while highlighting challenges that warrant further investigation. Overall, this work offers a crucial first step towards privacy-preserving sharing of educational RWD and expands the possibilities for open science and DBR in LA.", "AI": {"tldr": "\u63d0\u51faCAPS\u6846\u67b6\u7528\u4e8e\u6559\u80b2\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u5408\u6210\uff0c\u89e3\u51b3\u9ad8\u7ef4\u5c0f\u6837\u672c\u6570\u636e\u7684\u4e00\u6b21\u6027\u5408\u6210\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u8fed\u4ee3\u5171\u4eab\u4fc3\u8fdb\u5f00\u653e\u79d1\u5b66\u548c\u8bbe\u8ba1\u7814\u7a76\u3002", "motivation": "\u6559\u80b2\u9886\u57df\u771f\u5b9e\u4e16\u754c\u6570\u636e(RWD)\u5feb\u901f\u589e\u957f\uff0c\u4f46\u9690\u79c1\u9650\u5236\u963b\u788d\u4e86\u5b66\u4e60\u5206\u6790\u7814\u7a76\u3002\u73b0\u6709\u5dee\u5206\u9690\u79c1\u5408\u6210\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5927\u89c4\u6a21\u4f4e\u7ef4\u5f00\u653e\u6570\u636e\u96c6\uff0c\u800c\u6559\u80b2RWD\u901a\u5e38\u9ad8\u7ef4\u5c0f\u6837\u672c\uff0c\u4e14\u6559\u80b2\u5b9e\u8df5\u9700\u8981\u6301\u7eed\u8fed\u4ee3\u7684\u6570\u636e\u5171\u4eab\uff0c\u4f20\u7edf\u4e00\u6b21\u6027\u5408\u6210\u65b9\u6cd5\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51fa\u5faa\u73af\u81ea\u9002\u5e94\u9690\u79c1\u5408\u6210(CAPS)\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u5171\u4eab\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u800c\u975e\u4e00\u6b21\u6027\u5408\u6210\u3002\u8be5\u6846\u67b6\u9002\u5e94\u6559\u80b2\u5b9e\u8df5\u7684\u8fed\u4ee3\u7279\u6027\uff0c\u652f\u6301\u6301\u7eed\u7684\u6570\u636e\u5171\u4eab\u548c\u8bbe\u8ba1\u7814\u7a76\u3002", "result": "\u5728\u771f\u5b9e\u6559\u80b2RWD\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cCAPS\u6846\u67b6\u4f18\u4e8e\u4e00\u6b21\u6027\u5408\u6210\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6311\u6218\u3002", "conclusion": "CAPS\u4e3a\u6559\u80b2RWD\u7684\u9690\u79c1\u4fdd\u62a4\u5171\u4eab\u63d0\u4f9b\u4e86\u91cd\u8981\u7b2c\u4e00\u6b65\uff0c\u6269\u5c55\u4e86\u5b66\u4e60\u5206\u6790\u4e2d\u5f00\u653e\u79d1\u5b66\u548c\u8bbe\u8ba1\u7814\u7a76\u7684\u53ef\u80fd\u6027\uff0c\u4e3a\u6301\u7eed\u8fed\u4ee3\u7684\u6559\u80b2\u5b9e\u8df5\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6570\u636e\u5171\u4eab\u65b9\u6848\u3002"}}
{"id": "2602.07511", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07511", "abs": "https://arxiv.org/abs/2602.07511", "authors": ["Hidekazu Yoshioka", "Yumi Yoshioka", "Motoh Tsujimura", "Ayumi Hashiguchi"], "title": "Mathematical model for sustainable fisheries resource management accounting for size spectrum", "comment": null, "summary": "This paper proposes a novel modelling and control framework for growth models that incorporate a size spectrum in conjunction with numerical computation and extensive field surveys. In fisheries management, the size spectrum, characterized by individual differences in body weight and length, is a critical factor, as it influences the physiology and ecology of fish, as well as the preferences of anglers. However, a comprehensive theoretical framework for fisheries modelling and management that accounts for the size spectrum has yet to be established. We apply a growth model that considers the size spectrum to Plecoglossus altivelis altivelis (Ayu), an important inland fisheries resource in Japan. Additionally, we introduce a novel stochastic control theory for the resource management of Ayu, taking its size spectrum into account. The growth model is calibrated using data collected annually from a river system in Japan. Our control problem addresses the size spectrum of fishing benefits and terminal utility (nonlinear expectation) for sustainability, resulting in a nonstandard problem to which the dynamic programming principle does not apply. We address this difficulty using a time-inconsistent formalism, where solving the control problem is reduced to finding an appropriate solution to a system of nonlinear partial differential equations. We numerically compute the system using the finite difference method and explore the fisheries management of Ayu at the study site.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5c3a\u5bf8\u8c31\u7684\u9c7c\u7c7b\u751f\u957f\u6a21\u578b\u4e0e\u968f\u673a\u63a7\u5236\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u65e5\u672c\u9999\u9c7c\u8d44\u6e90\u7ba1\u7406\uff0c\u89e3\u51b3\u52a8\u6001\u89c4\u5212\u4e0d\u9002\u7528\u7684\u975e\u6807\u51c6\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u6e14\u4e1a\u7ba1\u7406\u4e2d\uff0c\u4e2a\u4f53\u4f53\u91cd\u548c\u957f\u5ea6\u7684\u5c3a\u5bf8\u8c31\u5bf9\u9c7c\u7c7b\u751f\u7406\u751f\u6001\u53ca\u6e14\u8005\u504f\u597d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u6846\u67b6\u672a\u80fd\u5145\u5206\u8003\u8651\u5c3a\u5bf8\u8c31\u56e0\u7d20\u3002", "method": "1) \u5efa\u7acb\u8003\u8651\u5c3a\u5bf8\u8c31\u7684\u9999\u9c7c\u751f\u957f\u6a21\u578b\uff0c\u57fa\u4e8e\u65e5\u672c\u6cb3\u6d41\u7cfb\u7edf\u5e74\u5ea6\u6570\u636e\u6821\u51c6\uff1b2) \u63d0\u51fa\u8003\u8651\u5c3a\u5bf8\u8c31\u7684\u968f\u673a\u63a7\u5236\u7406\u8bba\uff0c\u5904\u7406\u975e\u7ebf\u6027\u671f\u671b\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff1b3) \u4f7f\u7528\u65f6\u5e8f\u4e0d\u4e00\u81f4\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5c06\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7ec4\u6c42\u89e3\uff1b4) \u91c7\u7528\u6709\u9650\u5dee\u5206\u6cd5\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u8003\u8651\u5c3a\u5bf8\u8c31\u7684\u9999\u9c7c\u751f\u957f\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u968f\u673a\u63a7\u5236\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u8ba1\u7b97\u63a2\u7d22\u4e86\u7814\u7a76\u5730\u70b9\u7684\u9999\u9c7c\u6e14\u4e1a\u7ba1\u7406\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6e14\u4e1a\u5efa\u6a21\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u9996\u4e2a\u8003\u8651\u5c3a\u5bf8\u8c31\u7684\u7efc\u5408\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u5e8f\u4e0d\u4e00\u81f4\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u4e0d\u9002\u7528\u7684\u975e\u6807\u51c6\u63a7\u5236\u95ee\u9898\uff0c\u4e3a\u53ef\u6301\u7eed\u6e14\u4e1a\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.07190", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07190", "abs": "https://arxiv.org/abs/2602.07190", "authors": ["Anagha Kulkarni", "Parin Rajesh Jhaveri", "Prasha Shrestha", "Yu Tong Han", "Reza Amini", "Behrouz Madahian"], "title": "Long-Context Long-Form Question Answering for Legal Domain", "comment": "EACL 2026", "summary": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9\u6cd5\u5f8b\u6587\u6863\u7684\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u7cfb\u7edf\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u6587\u6863\u5e03\u5c40\u3001\u4e13\u4e1a\u8bcd\u6c47\uff0c\u5e76\u751f\u6210\u5168\u9762\u7684\u957f\u683c\u5f0f\u7b54\u6848\u3002", "motivation": "\u6cd5\u5f8b\u6587\u6863\u5177\u6709\u590d\u6742\u7684\u6587\u6863\u5e03\u5c40\uff08\u591a\u7ea7\u5d4c\u5957\u7ae0\u8282\u3001\u957f\u811a\u6ce8\uff09\u548c\u4e13\u95e8\u7684\u8bed\u8a00\u7279\u5f81\uff08\u590d\u6742\u53e5\u6cd5\u3001\u9886\u57df\u7279\u5b9a\u8bcd\u6c47\uff09\uff0c\u8fd9\u4f7f\u5f97\u95ee\u7b54\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5f53\u7b54\u6848\u9700\u8981\u8de8\u8d8a\u591a\u9875\uff08\u957f\u4e0a\u4e0b\u6587\uff09\u4e14\u8981\u6c42\u5168\u9762\u6027\uff08\u957f\u683c\u5f0f\u7b54\u6848\uff09\u65f6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u95ee\u7b54\u7cfb\u7edf\uff0c\u80fd\u591f\uff1a(a) \u89e3\u6784\u9886\u57df\u7279\u5b9a\u8bcd\u6c47\u4ee5\u6539\u8fdb\u6587\u6863\u68c0\u7d22\uff1b(b) \u89e3\u6790\u590d\u6742\u6587\u6863\u5e03\u5c40\uff0c\u540c\u65f6\u9694\u79bb\u7ae0\u8282\u548c\u811a\u6ce8\u5e76\u9002\u5f53\u94fe\u63a5\uff1b(c) \u4f7f\u7528\u7cbe\u786e\u7684\u9886\u57df\u7279\u5b9a\u8bcd\u6c47\u751f\u6210\u5168\u9762\u7b54\u6848\u3002\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u8986\u76d6\u7387\u6307\u6807\uff0c\u5c06\u6027\u80fd\u5206\u7c7b\u4e3a\u57fa\u4e8e\u53ec\u56de\u7684\u8986\u76d6\u7c7b\u522b\uff0c\u4fbf\u4e8e\u4eba\u5de5\u8bc4\u4f30\u53ec\u56de\u7387\u3002", "result": "\u901a\u8fc7\u5229\u7528\u6cd5\u5f8b\u548c\u516c\u53f8\u7a0e\u52a1\u7b49\u9886\u57df\u4e13\u4e1a\u4eba\u58eb\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7b56\u5212\u4e86\u4e00\u4e2aQA\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u548c\u4f18\u70b9\u3002", "conclusion": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u6cd5\u5f8b\u6587\u6863\u4e2d\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u590d\u6742\u5e03\u5c40\u548c\u4e13\u4e1a\u8bcd\u6c47\u7684\u7cfb\u7edf\uff0c\u5e76\u5f15\u5165\u4e86\u4fbf\u4e8e\u8bc4\u4f30\u7684\u8986\u76d6\u7387\u6307\u6807\uff0c\u4e3a\u6cd5\u5f8b\u6587\u6863\u95ee\u7b54\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07253", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07253", "abs": "https://arxiv.org/abs/2602.07253", "authors": ["Litian Liu", "Reza Pourreza", "Yubing Jian", "Yao Qin", "Roland Memisevic"], "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "comment": null, "summary": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.", "AI": {"tldr": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5355\u6837\u672c\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c", "motivation": "\u73b0\u6709\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\u3002\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u9700\u8981\u66f4\u6709\u6548\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u89c6\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5e94\u7528\u5206\u5e03\u5916\u68c0\u6d4b\u6280\u672f\uff0c\u5e76\u8fdb\u884c\u9002\u5f53\u4fee\u6539\u4ee5\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u7279\u70b9\u3002", "result": "\u57fa\u4e8e\u5206\u5e03\u5916\u68c0\u6d4b\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5355\u6837\u672c\u7684\u5e7b\u89c9\u68c0\u6d4b\u5668\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u7684\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u53d6\u5f97\u4e86\u8f83\u5f3a\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5c06\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u4e14\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002"}}
{"id": "2602.07078", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07078", "abs": "https://arxiv.org/abs/2602.07078", "authors": ["Yingru Li", "Jiawei Xu", "Ziniu Li", "Jiacai Liu", "Wei Liu", "Yuxuan Tong", "Longtao Zheng", "Zhenghai Xue", "Yaxiang Zhang", "Tianle Cai", "Ge Zhang", "Qian Liu", "Baoxiang Wang"], "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL", "comment": null, "summary": "Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditional value models remain difficult to optimize, and standard group-based baselines overlook sequence heterogeneity. Although classic optimal baseline theory can achieve global variance reduction, it neglects token heterogeneity and requires prohibitive gradient-based computation. In this work, we derive the Optimal Token Baseline (OTB) from first principles, proving that gradient updates should be weighted inversely to their cumulative gradient norm. To ensure efficiency, we propose the Logit-Gradient Proxy that approximates the gradient norm using only forward-pass probabilities. Our method achieves training stability and matches the performance of large group sizes ($N=32$) with only $N=4$, reducing token consumption by over 65% across single-turn and tool-integrated reasoning tasks.", "AI": {"tldr": "\u63d0\u51faOptimal Token Baseline (OTB)\u65b9\u6cd5\uff0c\u901a\u8fc7\u9006\u68af\u5ea6\u8303\u6570\u52a0\u6743\u66f4\u65b0\u89e3\u51b3LLM\u5f3a\u5316\u5b66\u4e60\u4e2d\u68af\u5ea6\u65b9\u5dee\u7206\u70b8\u95ee\u9898\uff0c\u4f7f\u7528Logit-Gradient Proxy\u9ad8\u6548\u8fd1\u4f3c\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11token\u6d88\u8017\u3002", "motivation": "LLM\u5f3a\u5316\u5b66\u4e60\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u5e38\u56e0\u68af\u5ea6\u65b9\u5dee\u7206\u70b8\u5bfc\u81f4\u8bad\u7ec3\u5d29\u6e83\u3002\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u5b58\u5728\u4f18\u5316\u56f0\u96be\u3001\u5ffd\u7565\u5e8f\u5217\u5f02\u8d28\u6027\u7b49\u95ee\u9898\uff0c\u7ecf\u5178\u6700\u4f18\u57fa\u7ebf\u7406\u8bba\u867d\u80fd\u5168\u5c40\u964d\u65b9\u5dee\u4f46\u5ffd\u7565token\u5f02\u8d28\u6027\u4e14\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u63a8\u5bfc\u51faOptimal Token Baseline (OTB)\uff0c\u8bc1\u660e\u68af\u5ea6\u66f4\u65b0\u5e94\u6309\u5176\u7d2f\u79ef\u68af\u5ea6\u8303\u6570\u7684\u5012\u6570\u52a0\u6743\u3002\u4e3a\u63d0\u5347\u6548\u7387\uff0c\u63d0\u51faLogit-Gradient Proxy\uff0c\u4ec5\u4f7f\u7528\u524d\u5411\u4f20\u64ad\u6982\u7387\u8fd1\u4f3c\u68af\u5ea6\u8303\u6570\u3002", "result": "\u65b9\u6cd5\u5b9e\u73b0\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u4ec5\u7528N=4\u5c31\u80fd\u8fbe\u5230\u4f20\u7edfN=32\u5927\u7ec4\u89c4\u6a21\u7684\u6027\u80fd\uff0c\u5728\u5355\u8f6e\u548c\u5de5\u5177\u96c6\u6210\u63a8\u7406\u4efb\u52a1\u4e2d\u51cf\u5c11\u8d85\u8fc765%\u7684token\u6d88\u8017\u3002", "conclusion": "OTB\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u65b9\u5dee\u95ee\u9898\uff0c\u901a\u8fc7token\u7ea7\u6700\u4f18\u57fa\u7ebf\u548c\u9ad8\u6548\u8fd1\u4f3c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2602.07995", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07995", "abs": "https://arxiv.org/abs/2602.07995", "authors": ["Antonio Alc\u00e1ntara", "Spyros Chatzivasileiadis"], "title": "Trustworthiness Layer for Foundation Models in Power Systems: Application for N-k Contingency Assessment", "comment": null, "summary": "This work introduces for the first time, to our knowledge, a trustworthiness layer for foundation models in power systems. Using stratified conformal prediction, we devise adaptive, statistically valid confidence bounds for each output of a foundation model. For regression, this allows users to obtain an uncertainty estimate for each output; for screening, it supports conservative decisions that minimize false negatives. We demonstrate our method by enhancing GridFM, the first open-source Foundation Model for power systems, with statistically valid prediction intervals instead of heuristic error margins. We apply it for N-k contingency assessment, a combinatorial NP-Hard problem. We show that trustworthy GridFM can offer richer and more accurate information than DC Power Flow, having 2x-3x higher precision, while running up to 18x faster than AC Power Flow for systems up to 118 buses. Moving a step further, we also examine the ability of trustworthy GridFM to generalize to unseen high-order contingencies: through a rigorous analysis, we assess how a model trained on N-1 or N-2 outages extrapolates to unseen contingencies up to N-5.", "AI": {"tldr": "\u9996\u6b21\u4e3a\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u6a21\u578b\u5f15\u5165\u53ef\u4fe1\u5ea6\u5c42\uff0c\u4f7f\u7528\u5206\u5c42\u4fdd\u5f62\u9884\u6d4b\u4e3a\u6a21\u578b\u8f93\u51fa\u63d0\u4f9b\u7edf\u8ba1\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u63d0\u5347N-k\u6545\u969c\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u6548\u7387", "motivation": "\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u7edf\u8ba1\u6709\u6548\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bef\u5dee\u8fb9\u754c\uff0c\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9760\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u5b9e\u9645\u51b3\u7b56\u4e2d\u7684\u5e94\u7528", "method": "\u91c7\u7528\u5206\u5c42\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u6a21\u578bGridFM\u8bbe\u8ba1\u81ea\u9002\u5e94\u3001\u7edf\u8ba1\u6709\u6548\u7684\u7f6e\u4fe1\u8fb9\u754c\uff0c\u4e3a\u56de\u5f52\u4efb\u52a1\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u7b5b\u9009\u4efb\u52a1\u652f\u6301\u4fdd\u5b88\u51b3\u7b56", "result": "\u53ef\u4fe1GridFM\u6bd4\u76f4\u6d41\u6f6e\u6d41\u7cbe\u5ea6\u9ad82-3\u500d\uff0c\u6bd4\u4ea4\u6d41\u6f6e\u6d41\u5feb18\u500d\uff08118\u8282\u70b9\u7cfb\u7edf\uff09\uff0c\u5e76\u80fd\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u7684\u9ad8\u9636\u6545\u969c\uff08N-5\uff09", "conclusion": "\u5206\u5c42\u4fdd\u5f62\u9884\u6d4b\u4e3a\u7535\u529b\u7cfb\u7edf\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u7edf\u8ba1\u6709\u6548\u7684\u53ef\u4fe1\u5ea6\u5c42\uff0c\u663e\u8457\u63d0\u5347\u4e86N-k\u6545\u969c\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u652f\u6301\u6a21\u578b\u5411\u672a\u89c1\u9ad8\u9636\u6545\u969c\u7684\u6cdb\u5316"}}
{"id": "2602.08243", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08243", "abs": "https://arxiv.org/abs/2602.08243", "authors": ["Wei Guo", "Yuchen Zhu", "Xiaochen Du", "Juno Nam", "Yongxin Chen", "Rafael G\u00f3mez-Bombarelli", "Guan-Horng Liu", "Molei Tao", "Jaemoo Choi"], "title": "Discrete Adjoint Schr\u00f6dinger Bridge Sampler", "comment": null, "summary": "Learning discrete neural samplers is challenging due to the lack of gradients and combinatorial complexity. While stochastic optimal control (SOC) and Schr\u00f6dinger bridge (SB) provide principled solutions, efficient SOC solvers like adjoint matching (AM), which excel in continuous domains, remain unexplored for discrete spaces. We bridge this gap by revealing that the core mechanism of AM is $\\mathit{state}\\text{-}\\mathit{space~agnostic}$, and introduce $\\mathbf{discrete~ASBS}$, a unified framework that extends AM and adjoint Schr\u00f6dinger bridge sampler (ASBS) to discrete spaces. Theoretically, we analyze the optimality conditions of the discrete SB problem and its connection to SOC, identifying a necessary cyclic group structure on the state space to enable this extension. Empirically, discrete ASBS achieves competitive sample quality with significant advantages in training efficiency and scalability.", "AI": {"tldr": "\u63d0\u51fa\u79bb\u6563ASBS\u6846\u67b6\uff0c\u5c06\u8fde\u7eed\u57df\u4e2d\u7684\u4f34\u968f\u5339\u914d\u65b9\u6cd5\u6269\u5c55\u5230\u79bb\u6563\u7a7a\u95f4\uff0c\u7528\u4e8e\u5b66\u4e60\u79bb\u6563\u795e\u7ecf\u91c7\u6837\u5668", "motivation": "\u5b66\u4e60\u79bb\u6563\u795e\u7ecf\u91c7\u6837\u5668\u9762\u4e34\u68af\u5ea6\u7f3a\u5931\u548c\u7ec4\u5408\u590d\u6742\u6027\u7684\u6311\u6218\uff0c\u800c\u968f\u673a\u6700\u4f18\u63a7\u5236\uff08SOC\uff09\u548c\u859b\u5b9a\u8c14\u6865\uff08SB\uff09\u867d\u7136\u63d0\u4f9b\u7406\u8bba\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9ad8\u6548\u7684SOC\u6c42\u89e3\u5668\uff08\u5982\u4f34\u968f\u5339\u914dAM\uff09\u5728\u79bb\u6563\u7a7a\u95f4\u4e2d\u5c1a\u672a\u63a2\u7d22", "method": "\u63ed\u793aAM\u65b9\u6cd5\u7684\u6838\u5fc3\u673a\u5236\u662f\u72b6\u6001\u7a7a\u95f4\u65e0\u5173\u7684\uff0c\u63d0\u51fa\u79bb\u6563ASBS\u7edf\u4e00\u6846\u67b6\uff0c\u5c06AM\u548c\u4f34\u968f\u859b\u5b9a\u8c14\u6865\u91c7\u6837\u5668\u6269\u5c55\u5230\u79bb\u6563\u7a7a\u95f4\uff0c\u7406\u8bba\u5206\u6790\u79bb\u6563SB\u95ee\u9898\u7684\u6700\u4f18\u6761\u4ef6\u53ca\u5176\u4e0eSOC\u7684\u8054\u7cfb", "result": "\u79bb\u6563ASBS\u5728\u6837\u672c\u8d28\u91cf\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u5728\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf", "conclusion": "\u6210\u529f\u5c06\u8fde\u7eed\u57df\u4e2d\u7684\u4f34\u968f\u5339\u914d\u65b9\u6cd5\u6269\u5c55\u5230\u79bb\u6563\u7a7a\u95f4\uff0c\u4e3a\u89e3\u51b3\u79bb\u6563\u795e\u7ecf\u91c7\u6837\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08349", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08349", "abs": "https://arxiv.org/abs/2602.08349", "authors": ["Daniel Mwesigwa", "Cyan DeVeaux", "Palashi Vaghela"], "title": "To Tango or to Disentangle? Making Ethnography Public in the Digital Age", "comment": "Accepted to CSCW 2026 (PACM HCI)", "summary": "Ethnography attends to relations among people, practices, and the technologies that mediate them. Central to this method is the duality of roles ethnographers navigate as researchers and participants and as outsiders and insiders. However, the rise of digital platforms has introduced new opportunities as well as practical and ethical challenges that reshape these dualities across hybrid media environments spanning both online and offline contexts. Drawing on two case studies of VRChat and WhatsApp, we examine how ethnographers employ diverse tactics to study both enduring and emerging socio-cultural issues of race and caste, particularly those that form what are often called publics. We propose emergent relationality as a key analytic for understanding the mutual shaping of ethnographers, platforms, and publics. In this work, emergent relationality offers registers for analyzing how positionality and hybrid media environments constitute and condition what can be accessed, articulated, and made public.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6d8c\u73b0\u5173\u7cfb\u6027\"\u4f5c\u4e3a\u5206\u6790\u6c11\u65cf\u5fd7\u5b66\u8005\u3001\u6570\u5b57\u5e73\u53f0\u548c\u516c\u4f17\u76f8\u4e92\u5851\u9020\u7684\u5173\u952e\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7VRChat\u548cWhatsApp\u6848\u4f8b\u7814\u7a76\u63a2\u8ba8\u6c11\u65cf\u5fd7\u5728\u6df7\u5408\u5a92\u4f53\u73af\u5883\u4e2d\u7684\u65b0\u673a\u9047\u4e0e\u6311\u6218\u3002", "motivation": "\u6570\u5b57\u5e73\u53f0\u7684\u5174\u8d77\u6539\u53d8\u4e86\u6c11\u65cf\u5fd7\u7814\u7a76\u7684\u4f20\u7edf\u89d2\u8272\u4e8c\u5143\u6027\uff08\u7814\u7a76\u8005/\u53c2\u4e0e\u8005\u3001\u5c40\u5916\u4eba/\u5c40\u5185\u4eba\uff09\uff0c\u5728\u6df7\u5408\u5a92\u4f53\u73af\u5883\u4e2d\u5e26\u6765\u4e86\u65b0\u7684\u5b9e\u8df5\u548c\u4f26\u7406\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u5206\u6790\u6846\u67b6\u6765\u7406\u89e3\u6c11\u65cf\u5fd7\u5b66\u8005\u3001\u5e73\u53f0\u548c\u516c\u4f17\u4e4b\u95f4\u7684\u76f8\u4e92\u5851\u9020\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790VRChat\u548cWhatsApp\u4e24\u4e2a\u6570\u5b57\u5e73\u53f0\u4e0a\u7684\u6c11\u65cf\u5fd7\u5b9e\u8df5\uff0c\u63a2\u8ba8\u6c11\u65cf\u5fd7\u5b66\u8005\u5982\u4f55\u8fd0\u7528\u591a\u6837\u5316\u7b56\u7565\u7814\u7a76\u79cd\u65cf\u548c\u79cd\u59d3\u7b49\u793e\u4f1a\u6587\u5316\u8bae\u9898\uff0c\u7279\u522b\u662f\u5f62\u6210\"\u516c\u4f17\"\u7684\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\"\u6d8c\u73b0\u5173\u7cfb\u6027\"\u4f5c\u4e3a\u5173\u952e\u5206\u6790\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u5206\u6790\u4f4d\u7f6e\u6027\u548c\u6df7\u5408\u5a92\u4f53\u73af\u5883\u5982\u4f55\u6784\u6210\u548c\u5236\u7ea6\u53ef\u8bbf\u95ee\u3001\u53ef\u8868\u8fbe\u548c\u53ef\u516c\u5f00\u5185\u5bb9\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u6c11\u65cf\u5fd7\u5b66\u8005\u3001\u5e73\u53f0\u548c\u516c\u4f17\u4e4b\u95f4\u7684\u52a8\u6001\u76f8\u4e92\u5851\u9020\u5173\u7cfb\u3002", "conclusion": "\u6d8c\u73b0\u5173\u7cfb\u6027\u4e3a\u7406\u89e3\u6570\u5b57\u65f6\u4ee3\u6c11\u65cf\u5fd7\u7814\u7a76\u4e2d\u7684\u89d2\u8272\u4e8c\u5143\u6027\u8f6c\u53d8\u63d0\u4f9b\u4e86\u91cd\u8981\u5206\u6790\u5de5\u5177\uff0c\u5f3a\u8c03\u4e86\u4f4d\u7f6e\u6027\u548c\u6df7\u5408\u5a92\u4f53\u73af\u5883\u5728\u5851\u9020\u7814\u7a76\u53ef\u53ca\u6027\u3001\u8868\u8fbe\u6027\u548c\u516c\u5171\u6027\u65b9\u9762\u7684\u6838\u5fc3\u4f5c\u7528\u3002"}}
{"id": "2602.07514", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.07514", "abs": "https://arxiv.org/abs/2602.07514", "authors": ["Jon Asier B\u00e1rcena-Petisco", "Salah-Eddine Chorfi", "Fouad Et-tahri", "Lahcen Maniar"], "title": "Averaged Controllability of Time-Fractional Schr\u00f6dinger Equations with Random Quantum Diffusivity", "comment": null, "summary": "This paper addresses the problem of averaged controllability for the time-fractional Schrodinger equation, where the quantum diffusivity parameter is a random variable with a general probability distribution. First, by exploiting the analyticity of the Mittag-Leffler function and Muntz's theorem, we show that the simultaneous null controllability of the system can occur only for a countable set of realizations of the random diffusivity. In particular, this implies the impossibility of simultaneous null controllability for absolutely continuous random diffusivity. Next, we prove the lack of exact averaged controllability for absolutely continuous random variables, irrespective of the control time. Furthermore, we introduce a new two-parameter fractional characteristic function, which allows us to construct a class of random variables satisfying null averaged controllability at any time from any arbitrary sensor set of positive Lebesgue measure. This is achieved using an open-loop control belonging to L^\\infty and independent of the random parameter. In particular, we obtain the null controllability of the fractional biharmonic diffusion equation. Finally, we conclude with several remarks and open problems that merit future investigation.", "AI": {"tldr": "\u7814\u7a76\u65f6\u95f4\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u5e73\u5747\u53ef\u63a7\u6027\uff0c\u5176\u4e2d\u91cf\u5b50\u6269\u6563\u53c2\u6570\u662f\u670d\u4ece\u4e00\u822c\u6982\u7387\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\u3002\u8bc1\u660e\u4e86\u540c\u65f6\u96f6\u53ef\u63a7\u6027\u4ec5\u5bf9\u968f\u673a\u6269\u6563\u7cfb\u6570\u7684\u53ef\u6570\u96c6\u6210\u7acb\uff0c\u7edd\u5bf9\u8fde\u7eed\u968f\u673a\u53d8\u91cf\u4e0d\u53ef\u80fd\u5b9e\u73b0\u7cbe\u786e\u5e73\u5747\u53ef\u63a7\u6027\uff0c\u5e76\u6784\u9020\u4e86\u6ee1\u8db3\u96f6\u5e73\u5747\u53ef\u63a7\u6027\u7684\u968f\u673a\u53d8\u91cf\u7c7b\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u968f\u673a\u6269\u6563\u7cfb\u6570\u7684\u65f6\u95f4\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u53ef\u63a7\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u91cf\u5b50\u6269\u6563\u53c2\u6570\u662f\u968f\u673a\u53d8\u91cf\u65f6\u7684\u5e73\u5747\u53ef\u63a7\u6027\u3002\u8fd9\u79cd\u968f\u673a\u6027\u5728\u5b9e\u9645\u91cf\u5b50\u7cfb\u7edf\u4e2d\u5f88\u5e38\u89c1\uff0c\u4f46\u76f8\u5173\u53ef\u63a7\u6027\u5206\u6790\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u5229\u7528Mittag-Leffler\u51fd\u6570\u7684\u89e3\u6790\u6027\u548cMuntz\u5b9a\u7406\u5206\u6790\u540c\u65f6\u96f6\u53ef\u63a7\u6027\uff1b\u5f15\u5165\u65b0\u7684\u53cc\u53c2\u6570\u5206\u6570\u9636\u7279\u5f81\u51fd\u6570\u6784\u9020\u6ee1\u8db3\u96f6\u5e73\u5747\u53ef\u63a7\u6027\u7684\u968f\u673a\u53d8\u91cf\u7c7b\uff1b\u4f7f\u7528\u4e0e\u968f\u673a\u53c2\u6570\u65e0\u5173\u7684L^\u221e\u5f00\u73af\u63a7\u5236\u3002", "result": "1) \u540c\u65f6\u96f6\u53ef\u63a7\u6027\u4ec5\u5bf9\u968f\u673a\u6269\u6563\u7cfb\u6570\u7684\u53ef\u6570\u96c6\u6210\u7acb\uff0c\u7edd\u5bf9\u8fde\u7eed\u968f\u673a\u53d8\u91cf\u4e0d\u53ef\u80fd\u5b9e\u73b0\u540c\u65f6\u96f6\u53ef\u63a7\u6027\uff1b2) \u7edd\u5bf9\u8fde\u7eed\u968f\u673a\u53d8\u91cf\u5728\u4efb\u4f55\u63a7\u5236\u65f6\u95f4\u5185\u90fd\u65e0\u6cd5\u5b9e\u73b0\u7cbe\u786e\u5e73\u5747\u53ef\u63a7\u6027\uff1b3) \u6784\u9020\u4e86\u6ee1\u8db3\u96f6\u5e73\u5747\u53ef\u63a7\u6027\u7684\u968f\u673a\u53d8\u91cf\u7c7b\uff0c\u80fd\u4ece\u4efb\u610f\u6b63Lebesgue\u6d4b\u5ea6\u7684\u4f20\u611f\u5668\u96c6\u5b9e\u73b0\u96f6\u53ef\u63a7\u6027\uff1b4) \u83b7\u5f97\u4e86\u5206\u6570\u9636\u53cc\u8c03\u548c\u6269\u6563\u65b9\u7a0b\u7684\u96f6\u53ef\u63a7\u6027\u3002", "conclusion": "\u968f\u673a\u6269\u6563\u7cfb\u6570\u5bf9\u5206\u6570\u9636\u859b\u5b9a\u8c14\u65b9\u7a0b\u7684\u53ef\u63a7\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff1a\u7edd\u5bf9\u8fde\u7eed\u968f\u673a\u53d8\u91cf\u65e0\u6cd5\u5b9e\u73b0\u7cbe\u786e\u5e73\u5747\u53ef\u63a7\u6027\uff0c\u4f46\u901a\u8fc7\u6784\u9020\u7279\u5b9a\u968f\u673a\u53d8\u91cf\u7c7b\u53ef\u4ee5\u5b9e\u73b0\u96f6\u5e73\u5747\u53ef\u63a7\u6027\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u968f\u673a\u91cf\u5b50\u7cfb\u7edf\u7684\u63a7\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2602.07211", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.07211", "abs": "https://arxiv.org/abs/2602.07211", "authors": ["Ju Lin", "Jing Pan", "Ruizhi Li", "Ming Sun", "Yuzong Liu", "Alaa Hassan", "Jing Zheng", "Florian Metze"], "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities", "comment": null, "summary": "Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u5982\u4f55\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5b9a\u5411\u591a\u8bf4\u8bdd\u4eba\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u667a\u80fd\u773c\u955c\u573a\u666f\u4e0b\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u96c6\u6210\u65b9\u5411\u6027\u7684\u65b9\u6cd5\uff1a\u7ea7\u8054\u7cfb\u7edf\u548c\u7aef\u5230\u7aef\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u5355\u901a\u9053\u3001\u5355\u8bf4\u8bdd\u4eba\u6570\u636e\u8bad\u7ec3\uff0c\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u591a\u8bf4\u8bdd\u4eba\u3001\u591a\u901a\u9053\u7684\u8bed\u97f3\u7406\u89e3\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u667a\u80fd\u773c\u955c\u7b49\u9700\u8981\u5b9a\u5411\u8bed\u97f3\u7406\u89e3\u7684\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u7ea7\u8054\u7cfb\u7edf\uff0c\u4f7f\u7528\u6e90\u5206\u79bb\u524d\u7aef\u6a21\u5757\uff1b2\uff09\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u91c7\u7528\u5e8f\u5217\u5316\u8f93\u51fa\u8bad\u7ec3\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u5229\u7528\u667a\u80fd\u773c\u955c\u4e2d\u7684\u591a\u9ea6\u514b\u98ce\u9635\u5217\u8fdb\u884c\u6d41\u5f0f\u5904\u7406\u548c\u65b9\u5411\u6027\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u8d4b\u4e88\u5927\u8bed\u8a00\u6a21\u578b\u5b9a\u5411\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u5728\u8bed\u97f3\u8bc6\u522b\u548c\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5b9e\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9a\u5411\u591a\u8bf4\u8bdd\u4eba\u8bed\u97f3\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u6269\u5c55\uff0c\u4e3a\u667a\u80fd\u773c\u955c\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07259", "abs": "https://arxiv.org/abs/2602.07259", "authors": ["Cheol Woo Kim", "Davin Choo", "Tzeh Yuan Neoh", "Milind Tambe"], "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective", "comment": null, "summary": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u5b89\u5168\u89c6\u4e3aStackelberg\u5b89\u5168\u535a\u5f08\u95ee\u9898\uff0c\u5c06AI\u76d1\u7763\u5efa\u6a21\u4e3a\u9632\u5fa1\u8005\uff08\u5ba1\u8ba1\u8005\u3001\u8bc4\u4f30\u8005\uff09\u4e0e\u653b\u51fb\u8005\uff08\u6076\u610f\u884c\u4e3a\u8005\uff09\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\uff0c\u4e3aAI\u5168\u751f\u547d\u5468\u671f\u7684\u6fc0\u52b1\u8bbe\u8ba1\u3001\u6709\u9650\u76d1\u7763\u80fd\u529b\u548c\u5bf9\u6297\u6027\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u5f53\u524dAI\u5b89\u5168\u6846\u67b6\u4e3b\u8981\u5c06\u5bf9\u9f50\u89c6\u4e3a\u9759\u6001\u4f18\u5316\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u8bc4\u4f30\u548c\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u5bf9\u6297\u6027\u6fc0\u52b1\u3002\u968f\u7740AI\u7cfb\u7edf\u80fd\u529b\u589e\u5f3a\uff0c\u9700\u8981\u8d85\u8d8a\u6a21\u578b\u5c42\u9762\u7684\u5bf9\u9f50\uff0c\u5bf9\u53c2\u4e0eAI\u5f00\u53d1\u548c\u90e8\u7f72\u7684\u4eba\u7c7b\u548c\u673a\u6784\u8fdb\u884c\u6218\u7565\u76d1\u7763\u3002", "method": "\u91c7\u7528Stackelberg\u5b89\u5168\u535a\u5f08\uff08SSGs\uff09\u6846\u67b6\uff0c\u5c06AI\u76d1\u7763\u5efa\u6a21\u4e3a\u9632\u5fa1\u8005\uff08\u5ba1\u8ba1\u8005\u3001\u8bc4\u4f30\u8005\u3001\u90e8\u7f72\u8005\uff09\u4e0e\u653b\u51fb\u8005\uff08\u6076\u610f\u884c\u4e3a\u8005\u3001\u672a\u5bf9\u9f50\u8d21\u732e\u8005\u6216\u6700\u574f\u6545\u969c\u6a21\u5f0f\uff09\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\u3002\u8be5\u6846\u67b6\u8003\u8651\u4e86\u6fc0\u52b1\u8bbe\u8ba1\u3001\u6709\u9650\u76d1\u7763\u80fd\u529b\u548c\u5bf9\u6297\u6027\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\uff1a(1) \u8bad\u7ec3\u65f6\u5ba1\u8ba1\u5bf9\u6297\u6570\u636e/\u53cd\u9988\u6295\u6bd2\uff0c(2) \u6709\u9650\u8bc4\u5ba1\u8d44\u6e90\u4e0b\u7684\u9884\u90e8\u7f72\u8bc4\u4f30\uff0c(3) \u5bf9\u6297\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u591a\u6a21\u578b\u90e8\u7f72\u3002\u4e3aAI\u5168\u751f\u547d\u5468\u671f\u7684\u5b89\u5168\u76d1\u7763\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "Stackelberg\u5b89\u5168\u535a\u5f08\u6846\u67b6\u5c06\u7b97\u6cd5\u5bf9\u9f50\u4e0e\u673a\u6784\u76d1\u7763\u8bbe\u8ba1\u76f8\u7ed3\u5408\uff0c\u5f3a\u8c03\u535a\u5f08\u8bba\u5a01\u6151\u53ef\u4ee5\u4f7fAI\u76d1\u7763\u53d8\u5f97\u4e3b\u52a8\u3001\u98ce\u9669\u611f\u77e5\u4e14\u6297\u64cd\u7eb5\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u6218\u7565\u89c6\u89d2\u3002"}}
{"id": "2602.07088", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07088", "abs": "https://arxiv.org/abs/2602.07088", "authors": ["Muhammad Zafar Iqbal", "Ghazanfar Farooq Siddiqui", "Anwar Ul Haq", "Imran Razzak"], "title": "Attention-Driven Framework for Non-Rigid Medical Image Registration", "comment": null, "summary": "Deformable medical image registration is a fundamental task in medical image analysis with applications in disease diagnosis, treatment planning, and image-guided interventions. Despite significant advances in deep learning based registration methods, accurately aligning images with large deformations while preserving anatomical plausibility remains a challenging task. In this paper, we propose a novel Attention-Driven Framework for Non-Rigid Medical Image Registration (AD-RegNet) that employs attention mechanisms to guide the registration process. Our approach combines a 3D UNet backbone with bidirectional cross-attention, which establishes correspondences between moving and fixed images at multiple scales. We introduce a regional adaptive attention mechanism that focuses on anatomically relevant structures, along with a multi-resolution deformation field synthesis approach for accurate alignment. The method is evaluated on two distinct datasets: DIRLab for thoracic 4D CT scans and IXI for brain MRI scans, demonstrating its versatility across different anatomical structures and imaging modalities. Experimental results demonstrate that our approach achieves performance competitive with state-of-the-art methods on the IXI and DIRLab datasets. The proposed method maintains a favorable balance between registration accuracy and computational efficiency, making it suitable for clinical applications. A comprehensive evaluation using normalized cross-correlation (NCC), mean squared error (MSE), structural similarity (SSIM), Jacobian determinant, and target registration error (TRE) indicates that attention-guided registration improves alignment accuracy while ensuring anatomically plausible deformations.", "AI": {"tldr": "\u63d0\u51faAD-RegNet\u6ce8\u610f\u529b\u9a71\u52a8\u6846\u67b6\u7528\u4e8e\u533b\u5b66\u56fe\u50cf\u975e\u521a\u6027\u914d\u51c6\uff0c\u7ed3\u54083D UNet\u4e0e\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u5728\u591a\u4e2a\u5c3a\u5ea6\u5efa\u7acb\u56fe\u50cf\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u9ad8\u5927\u53d8\u5f62\u914d\u51c6\u7684\u51c6\u786e\u6027\u548c\u89e3\u5256\u5408\u7406\u6027\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u975e\u521a\u6027\u914d\u51c6\u662f\u75be\u75c5\u8bca\u65ad\u3001\u6cbb\u7597\u89c4\u5212\u548c\u56fe\u50cf\u5f15\u5bfc\u5e72\u9884\u7684\u57fa\u7840\u4efb\u52a1\u3002\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u914d\u51c6\u65b9\u6cd5\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u5927\u53d8\u5f62\u60c5\u51b5\u4e0b\u4fdd\u6301\u89e3\u5256\u5408\u7406\u6027\u7684\u51c6\u786e\u5bf9\u9f50\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51faAD-RegNet\u6ce8\u610f\u529b\u9a71\u52a8\u6846\u67b6\uff0c\u91c7\u75283D UNet\u9aa8\u5e72\u7f51\u7edc\u7ed3\u5408\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u591a\u5c3a\u5ea6\u5efa\u7acb\u79fb\u52a8\u56fe\u50cf\u548c\u56fa\u5b9a\u56fe\u50cf\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u5f15\u5165\u533a\u57df\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u673a\u5236\u5173\u6ce8\u89e3\u5256\u76f8\u5173\u7ed3\u6784\uff0c\u4ee5\u53ca\u591a\u5206\u8fa8\u7387\u53d8\u5f62\u573a\u5408\u6210\u65b9\u6cd5\u5b9e\u73b0\u7cbe\u786e\u5bf9\u9f50\u3002", "result": "\u5728DIRLab\uff08\u80f8\u90e84D CT\uff09\u548cIXI\uff08\u8111\u90e8MRI\uff09\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u3002\u5728\u5f52\u4e00\u5316\u4e92\u76f8\u5173\u3001\u5747\u65b9\u8bef\u5dee\u3001\u7ed3\u6784\u76f8\u4f3c\u6027\u3001\u96c5\u53ef\u6bd4\u884c\u5217\u5f0f\u548c\u76ee\u6807\u914d\u51c6\u8bef\u5dee\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5728\u914d\u51c6\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u4fdd\u6301\u826f\u597d\u5e73\u8861\u3002", "conclusion": "\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u914d\u51c6\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u9f50\u7cbe\u5ea6\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u89e3\u5256\u5408\u7406\u7684\u53d8\u5f62\uff0c\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u89e3\u5256\u7ed3\u6784\u548c\u6210\u50cf\u6a21\u6001\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2602.08137", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08137", "abs": "https://arxiv.org/abs/2602.08137", "authors": ["Fen Wu"], "title": "Robust and Gain-Scheduling ${\\cal H}_2$ Control Techniques for LFT Uncertain and Parameter-Dependent Systems", "comment": null, "summary": "This paper addresses the robust ${\\cal H}_2$ synthesis problem for linear fractional transformation (LFT) systems subject to structured uncertainty (parameter) and white-noise disturbances. By introducing an intermediate matrix variable, we derive convex synthesis conditions in terms of linear matrix inequalities (LMIs) that enable both robust and gain-scheduled controller design for parameter-dependent systems. The proposed framework preserves the classical white-noise and impulse-response interpretation of the ${\\cal H}_2$ criterion while providing certified robustness guarantees, thereby extending optimal ${\\cal H}_2$ control beyond the linear time-invariant setting. Numerical and application examples demonstrate that the resulting robust ${\\cal H}_2$ controllers achieve significantly reduced conservatism and improved disturbance rejection compared with conventional robust ${\\cal H}_\\infty$-based designs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7ebf\u6027\u5206\u5f0f\u53d8\u6362\u7cfb\u7edf\u7684\u9c81\u68d2H\u2082\u7efc\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e2d\u95f4\u77e9\u9635\u53d8\u91cf\u5f97\u5230\u51f8LMI\u6761\u4ef6\uff0c\u652f\u6301\u53c2\u6570\u4f9d\u8d56\u7cfb\u7edf\u7684\u9c81\u68d2\u548c\u589e\u76ca\u8c03\u5ea6\u63a7\u5236\u5668\u8bbe\u8ba1\u3002", "motivation": "\u4f20\u7edfH\u2082\u63a7\u5236\u4ec5\u9650\u4e8e\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u800c\u5b9e\u9645\u7cfb\u7edf\u5e38\u53d7\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u548c\u566a\u58f0\u5e72\u6270\u5f71\u54cd\u3002\u9700\u8981\u6269\u5c55H\u2082\u63a7\u5236\u5230\u53c2\u6570\u4f9d\u8d56\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u7ecf\u5178\u7684\u767d\u566a\u58f0\u548c\u8109\u51b2\u54cd\u5e94\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002", "method": "\u9488\u5bf9\u7ebf\u6027\u5206\u5f0f\u53d8\u6362\u7cfb\u7edf\uff0c\u5f15\u5165\u4e2d\u95f4\u77e9\u9635\u53d8\u91cf\uff0c\u63a8\u5bfc\u51fa\u57fa\u4e8e\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\u7684\u51f8\u7efc\u5408\u6761\u4ef6\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u53c2\u6570\u4f9d\u8d56\u7cfb\u7edf\u7684\u9c81\u68d2\u63a7\u5236\u5668\u8bbe\u8ba1\u548c\u589e\u76ca\u8c03\u5ea6\u63a7\u5236\u5668\u8bbe\u8ba1\u3002", "result": "\u63d0\u51fa\u7684\u9c81\u68d2H\u2082\u63a7\u5236\u5668\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8eH\u221e\u7684\u9c81\u68d2\u8bbe\u8ba1\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4fdd\u5b88\u6027\uff0c\u5e76\u6539\u5584\u4e86\u5e72\u6270\u6291\u5236\u6027\u80fd\u3002\u6570\u503c\u548c\u5e94\u7528\u793a\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06\u6700\u4f18H\u2082\u63a7\u5236\u6269\u5c55\u5230\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u4e4b\u5916\uff0c\u5728\u4fdd\u6301\u7ecf\u5178H\u2082\u51c6\u5219\u89e3\u91ca\u7684\u540c\u65f6\uff0c\u4e3a\u53c2\u6570\u4f9d\u8d56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u6709\u8ba4\u8bc1\u9c81\u68d2\u6027\u4fdd\u8bc1\u7684\u63a7\u5236\u6846\u67b6\u3002"}}
{"id": "2602.08259", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08259", "abs": "https://arxiv.org/abs/2602.08259", "authors": ["Xintao Xia", "Zhiqiu Xia", "Linjun Zhang", "Zhanrui Cai"], "title": "A Statistical Framework for Alignment with Biased AI Feedback", "comment": null, "summary": "Modern alignment pipelines are increasingly replacing expensive human preference labels with evaluations from large language models (LLM-as-Judge). However, AI labels can be systematically biased compared to high-quality human feedback datasets. In this paper, we develop two debiased alignment methods within a general framework that accommodates heterogeneous prompt-response distributions and external human feedback sources. Debiased Direct Preference Optimization (DDPO) augments standard DPO with a residual-based correction and density-ratio reweighting to mitigate systematic bias, while retaining DPO's computational efficiency. Debiased Identity Preference Optimization (DIPO) directly estimates human preference probabilities without imposing a parametric reward model. We provide theoretical guarantees for both methods: DDPO offers a practical and computationally efficient solution for large-scale alignment, whereas DIPO serves as a robust, statistically optimal alternative that attains the semiparametric efficiency bound. Empirical studies on sentiment generation, summarization, and single-turn dialogue demonstrate that the proposed methods substantially improve alignment efficiency and recover performance close to that of an oracle trained on fully human-labeled data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u53bb\u504f\u5bf9\u9f50\u65b9\u6cd5\uff1aDDPO\u548cDIPO\uff0c\u7528\u4e8e\u89e3\u51b3LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u4ea7\u751f\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u95ee\u9898\uff0c\u80fd\u5728\u4fdd\u7559\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63a5\u8fd1\u5168\u4eba\u5de5\u6807\u6ce8\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u5bf9\u9f50\u6d41\u7a0b\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u6765\u66ff\u4ee3\u6602\u8d35\u7684\u4eba\u5de5\u504f\u597d\u6807\u6ce8\uff0c\u4f46AI\u6807\u7b7e\u76f8\u6bd4\u9ad8\u8d28\u91cf\u4eba\u7c7b\u53cd\u9988\u6570\u636e\u96c6\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u53bb\u504f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u53bb\u504f\u5bf9\u9f50\u65b9\u6cd5\uff1a1) DDPO\uff08\u53bb\u504f\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff09\uff0c\u5728\u6807\u51c6DPO\u57fa\u7840\u4e0a\u52a0\u5165\u6b8b\u5dee\u6821\u6b63\u548c\u5bc6\u5ea6\u6bd4\u91cd\u52a0\u6743\uff1b2) DIPO\uff08\u53bb\u504f\u8eab\u4efd\u504f\u597d\u4f18\u5316\uff09\uff0c\u76f4\u63a5\u4f30\u8ba1\u4eba\u7c7b\u504f\u597d\u6982\u7387\u800c\u4e0d\u9700\u8981\u53c2\u6570\u5316\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728\u60c5\u611f\u751f\u6210\u3001\u6458\u8981\u548c\u5355\u8f6e\u5bf9\u8bdd\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u9f50\u6548\u7387\uff0c\u6027\u80fd\u63a5\u8fd1\u4f7f\u7528\u5168\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684oracle\u6a21\u578b\u3002", "conclusion": "DDPO\u4e3a\u5927\u89c4\u6a21\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800cDIPO\u4f5c\u4e3a\u7edf\u8ba1\u6700\u4f18\u7684\u7a33\u5065\u66ff\u4ee3\u65b9\u6848\uff0c\u8fbe\u5230\u4e86\u534a\u53c2\u6570\u6548\u7387\u8fb9\u754c\uff0c\u4e24\u8005\u90fd\u80fd\u6709\u6548\u7f13\u89e3LLM\u8bc4\u5224\u8005\u7684\u7cfb\u7edf\u6027\u504f\u5dee\u95ee\u9898\u3002"}}
{"id": "2602.08554", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08554", "abs": "https://arxiv.org/abs/2602.08554", "authors": ["Eike Schneiders", "Sarah Kiden", "Beining Zhang", "Bruno Rafael Queiros Arcanjo", "Zhaoxing Li", "Ezhilarasi Periyathambi", "Vahid Yazdanpanah", "Sebastian Stein"], "title": "Three Lessons from Citizen-Centric Participatory AI Design", "comment": "PARTICIPATE-AI: A Workshop at the 2026 ACM Conference on Intelligent User Interfaces (ACM IUI)", "summary": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enabling meaningful and sustained public engagement, establishing a shared language between experts and lay participants, and translating speculative participant input into implementable systems. We argue that reflexive, long-term participation is essential for responsible and actionable citizen-centric AI development.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53c2\u4e0e\u5f0f\u5de5\u4f5c\u574a\u63a2\u8ba8\u516c\u6c11\u4e2d\u5fc3\u89c6\u89d2\u4e0bAI\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u516c\u4f17\u6301\u7eed\u53c2\u4e0e\u5bf9\u8d1f\u8d23\u4efbAI\u5f00\u53d1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u8bbe\u8ba1\u5f80\u5f80\u7f3a\u4e4f\u516c\u6c11\u89c6\u89d2\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u4ece\u793e\u4f1a\u4ef7\u503c\u548c\u516c\u4f17\u671f\u671b\u51fa\u53d1\uff0c\u6784\u5efa\u771f\u6b63\u4ee5\u516c\u6c11\u4e3a\u4e2d\u5fc3\u7684AI\u4ee3\u7406\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u5efa\u6784\u6027\u8bbe\u8ba1\u7814\u7a76\u65b9\u6cd5\uff0c\u57282025\u5e74\u4e3e\u529e\u4e09\u573a\u53c2\u4e0e\u5f0f\u5de5\u4f5c\u574a\uff0c\u9080\u8bf7\u666e\u901a\u516c\u4f17\u548c\u8de8\u9886\u57df\u5229\u76ca\u76f8\u5173\u8005\u901a\u8fc7\u6545\u4e8b\u8bb2\u8ff0\u548c\u4f4e\u4fdd\u771f\u539f\u578b\u8bbe\u8ba1\uff0c\u63a2\u8ba8AI\u4ee3\u7406\u7684\u672a\u6765\u613f\u666f\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1\uff09\u5b9e\u73b0\u6709\u610f\u4e49\u4e14\u6301\u7eed\u7684\u516c\u4f17\u53c2\u4e0e\uff1b2\uff09\u5efa\u7acb\u4e13\u5bb6\u4e0e\u975e\u4e13\u4e1a\u53c2\u4e0e\u8005\u4e4b\u95f4\u7684\u5171\u540c\u8bed\u8a00\uff1b3\uff09\u5c06\u63a8\u6d4b\u6027\u7684\u53c2\u4e0e\u8005\u8f93\u5165\u8f6c\u5316\u4e3a\u53ef\u5b9e\u65bd\u7684\u7cfb\u7edf\u3002", "conclusion": "\u53cd\u601d\u6027\u3001\u957f\u671f\u7684\u516c\u4f17\u53c2\u4e0e\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u4e14\u53ef\u64cd\u4f5c\u7684\u516c\u6c11\u4e2d\u5fc3AI\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u6301\u7eed\u5bf9\u8bdd\u673a\u5236\u6765\u786e\u4fddAI\u7cfb\u7edf\u7b26\u5408\u793e\u4f1a\u4ef7\u503c\u89c2\u3002"}}
{"id": "2602.07663", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07663", "abs": "https://arxiv.org/abs/2602.07663", "authors": ["Owen Shen", "Haoran Xu", "Yinyu Ye", "Peter Glynn", "Patrick Jaillet"], "title": "A Two-Layer Framework for Joint Online Configuration Selection and Admission Control", "comment": null, "summary": "We study online configuration selection with admission control problem, which arises in LLM serving, GPU scheduling, and revenue management. In a planning horizon with $T$ periods, we consider a two-layer framework for the decisions made within each time period. In the first layer, the decision maker selects one of the $K$ configurations (ex. quantization, parallelism, fare class) which induces distribution over the reward-resource pair of the incoming request. In the second layer, the decision maker observes the request and then decides whether to accept it or not.\n  Benchmarking this framework requires care. We introduce a \\textbf{switching-aware fluid oracle} that accounts for the value of mixing configurations over time, provably upper-bounding any online policy. We derive a max-min formulation for evaluating the benchmark, and we characterize saddle points of the max-min problem via primal-dual optimality conditions linking equilibrium, feasibility, and complementarity. This guides the design of \\textbf{SP-UCB--OLP} algorithm, which solves an optimistic saddle point problem and achieves $\\tilde{O}(\\sqrt{KT})$ regret.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5728\u7ebf\u914d\u7f6e\u9009\u62e9\u4e0e\u51c6\u5165\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u5c42\u51b3\u7b56\u6846\u67b6\uff0c\u8bbe\u8ba1SP-UCB-OLP\u7b97\u6cd5\u5b9e\u73b0\u6b21\u7ebf\u6027\u9057\u61be", "motivation": "\u89e3\u51b3LLM\u670d\u52a1\u3001GPU\u8c03\u5ea6\u548c\u6536\u76ca\u7ba1\u7406\u4e2d\u7684\u5728\u7ebf\u914d\u7f6e\u9009\u62e9\u4e0e\u51c6\u5165\u63a7\u5236\u95ee\u9898\uff0c\u8fd9\u4e9b\u573a\u666f\u9700\u8981\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u52a8\u6001\u9009\u62e9\u914d\u7f6e\u5e76\u51b3\u5b9a\u662f\u5426\u63a5\u53d7\u8bf7\u6c42", "method": "\u63d0\u51fa\u4e24\u5c42\u51b3\u7b56\u6846\u67b6\uff1a\u7b2c\u4e00\u5c42\u9009\u62e9K\u4e2a\u914d\u7f6e\u4e4b\u4e00\uff0c\u7b2c\u4e8c\u5c42\u89c2\u5bdf\u8bf7\u6c42\u540e\u51b3\u5b9a\u63a5\u53d7\u4e0e\u5426\uff1b\u5f15\u5165\u5207\u6362\u611f\u77e5\u6d41\u4f53\u9884\u8a00\u673a\u4f5c\u4e3a\u57fa\u51c6\uff0c\u8bbe\u8ba1SP-UCB-OLP\u7b97\u6cd5\u89e3\u51b3\u4e50\u89c2\u978d\u70b9\u95ee\u9898", "result": "\u5efa\u7acb\u4e86\u5207\u6362\u611f\u77e5\u6d41\u4f53\u9884\u8a00\u673a\u4f5c\u4e3a\u7406\u8bba\u4e0a\u754c\uff0c\u63a8\u5bfc\u51fa\u6700\u5927\u6700\u5c0f\u95ee\u9898\u8868\u8ff0\uff0c\u901a\u8fc7\u539f\u59cb\u5bf9\u5076\u6700\u4f18\u6027\u6761\u4ef6\u523b\u753b\u978d\u70b9\uff0cSP-UCB-OLP\u7b97\u6cd5\u5b9e\u73b0\u00d5(\u221aKT)\u9057\u61be", "conclusion": "\u8bba\u6587\u4e3a\u5728\u7ebf\u914d\u7f6e\u9009\u62e9\u4e0e\u51c6\u5165\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u9ad8\u6548\u7b97\u6cd5\uff0c\u5728LLM\u670d\u52a1\u3001GPU\u8c03\u5ea6\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c"}}
{"id": "2602.07319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07319", "abs": "https://arxiv.org/abs/2602.07319", "authors": ["Savan Doshi"], "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice", "comment": null, "summary": "Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.", "AI": {"tldr": "\u63d0\u51fa\u98ce\u9669\u654f\u611f\u7684\u5e7b\u89c9\u8bc4\u4f30\u6846\u67b6\uff0c\u5173\u6ce8\u533b\u7597\u95ee\u7b54\u4e2d\u53ef\u80fd\u9020\u6210\u5b9e\u9645\u5371\u5bb3\u7684\u8bed\u8a00\uff0c\u800c\u975e\u4ec5\u8bc4\u4f30\u4e8b\u5b9e\u6b63\u786e\u6027", "motivation": "\u73b0\u6709\u5e7b\u89c9\u8bc4\u4f30\u6807\u51c6\u4e3b\u8981\u5173\u6ce8\u4e8b\u5b9e\u6b63\u786e\u6027\uff0c\u5c06\u6240\u6709\u9519\u8bef\u89c6\u4e3a\u540c\u7b49\u4e25\u91cd\uff0c\u8fd9\u63a9\u76d6\u4e86\u4e34\u5e8a\u76f8\u5173\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\u751f\u6210\u65e0\u4f9d\u636e\u4f46\u53ef\u64cd\u4f5c\u7684\u533b\u7597\u8bed\u8a00\u65f6", "method": "\u63d0\u51fa\u98ce\u9669\u654f\u611f\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u98ce\u9669\u627f\u8f7d\u8bed\u8a00\uff08\u6cbb\u7597\u6307\u4ee4\u3001\u7981\u5fcc\u75c7\u3001\u7d27\u6025\u63d0\u793a\u3001\u9ad8\u98ce\u9669\u836f\u7269\u63d0\u53ca\uff09\u91cf\u5316\u5e7b\u89c9\uff0c\u7ed3\u5408\u98ce\u9669\u8bc4\u5206\u4e0e\u76f8\u5173\u6027\u5ea6\u91cf\u8bc6\u522b\u9ad8\u98ce\u9669\u3001\u4f4e\u4f9d\u636e\u7684\u5931\u8d25", "result": "\u5bf9\u4e09\u4e2a\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u8be5\u6846\u67b6\u53d1\u73b0\uff1a\u8868\u9762\u884c\u4e3a\u76f8\u4f3c\u7684\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u98ce\u9669\u7279\u5f81\uff0c\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u6355\u6349\u8fd9\u4e9b\u5dee\u5f02", "conclusion": "\u9700\u8981\u5c06\u98ce\u9669\u654f\u611f\u6027\u7eb3\u5165\u5e7b\u89c9\u8bc4\u4f30\uff0c\u8bc4\u4f30\u6709\u6548\u6027\u5173\u952e\u53d6\u51b3\u4e8e\u4efb\u52a1\u548c\u63d0\u793a\u8bbe\u8ba1"}}
{"id": "2602.07267", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07267", "abs": "https://arxiv.org/abs/2602.07267", "authors": ["Fengyuan Liu", "Jay Gala", "Nilaksh", "Dzmitry Bahdanau", "Siva Reddy", "Hugo Larochelle"], "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance", "comment": null, "summary": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.", "AI": {"tldr": "BRIDGE\u6846\u67b6\u901a\u8fc7\u6a21\u578b\u54cd\u5e94\u5b66\u4e60\u4efb\u52a1\u96be\u5ea6\u6f5c\u53d8\u91cf\uff0c\u5e76\u5c06\u5176\u951a\u5b9a\u5230\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff0c\u5b9e\u73b0\u4ece\u6a21\u578b\u6027\u80fd\u9884\u6d4b\u4eba\u7c7b\u4efb\u52a1\u96be\u5ea6", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u5de5\u6807\u6ce8\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u7684\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u566a\u58f0\u5927\u3001\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u771f\u5b9e\u80fd\u529b", "method": "\u4f7f\u7528\u53cc\u53c2\u6570\u903b\u8f91\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u6a21\u578b\uff0c\u4ece\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684\u6a21\u578b\u6027\u80fd\u6570\u636e\u4e2d\u8054\u5408\u4f30\u8ba1\u4efb\u52a1\u96be\u5ea6\u6f5c\u53d8\u91cf\u548c\u6a21\u578b\u80fd\u529b\uff0c\u53d1\u73b0\u4efb\u52a1\u96be\u5ea6\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u5448\u7ebf\u6027\u5173\u7cfb", "result": "\u4efb\u52a1\u96be\u5ea6\u6f5c\u53d8\u91cf\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u7ebf\u6027\u76f8\u5173\uff0c\u53ef\u4ece\u6a21\u578b\u6027\u80fd\u63a8\u65ad\u65b0\u57fa\u51c6\u6d4b\u8bd5\u7684\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\uff1b\u9884\u6d4b\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u663e\u793a50%\u53ef\u89e3\u51b3\u4efb\u52a1\u8303\u56f4\u6bcf\u7ea66\u4e2a\u6708\u7ffb\u500d", "conclusion": "BRIDGE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5c06\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\u4e0e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u96be\u5ea6\u5ea6\u91cf\u8054\u7cfb\u8d77\u6765\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u80fd\u529b\u6269\u5c55\u8d8b\u52bf"}}
{"id": "2602.07126", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07126", "abs": "https://arxiv.org/abs/2602.07126", "authors": ["Joshua Ward", "Chi-Hua Wang", "Guang Cheng"], "title": "Finding Connections: Membership Inference Attacks for the Multi-Table Synthetic Data Setting", "comment": null, "summary": "Synthetic tabular data has gained attention for enabling privacy-preserving data sharing. While substantial progress has been made in single-table synthetic generation where data are modeled at the row or item level, most real-world data exists in relational databases where a user's information spans items across multiple interconnected tables. Recent advances in synthetic relational data generation have emerged to address this complexity, yet release of these data introduce unique privacy challenges as information can be leaked not only from individual items but also through the relationships that comprise a complete user entity.\n  To address this, we propose a novel Membership Inference Attack (MIA) setting to audit the empirical user-level privacy of synthetic relational data and show that single-table MIAs that audit at an item level underestimate user-level privacy leakage. We then propose Multi-Table Membership Inference Attack (MT-MIA), a novel adversarial attack under a No-Box threat model that targets learned representations of user entities via Heterogeneous Graph Neural Networks. By incorporating all connected items for a user, MT-MIA better targets user-level vulnerabilities induced by inter-tabular relationships than existing attacks. We evaluate MT-MIA on a range of real-world multi-table datasets and demonstrate that this vulnerability exists in state-of-the-art relational synthetic data generators, employing MT-MIA to additionally study where this leakage occurs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5173\u7cfb\u578b\u5408\u6210\u6570\u636e\u7684\u591a\u8868\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MT-MIA\uff09\uff0c\u7528\u4e8e\u5ba1\u8ba1\u7528\u6237\u7ea7\u522b\u7684\u9690\u79c1\u6cc4\u9732\uff0c\u76f8\u6bd4\u5355\u8868\u653b\u51fb\u80fd\u66f4\u51c6\u786e\u8bc4\u4f30\u5173\u7cfb\u578b\u6570\u636e\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u901a\u5e38\u5b58\u50a8\u5728\u5173\u7cfb\u6570\u636e\u5e93\u4e2d\uff0c\u7528\u6237\u4fe1\u606f\u5206\u5e03\u5728\u591a\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u8868\u4e2d\u3002\u73b0\u6709\u7684\u5355\u8868\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u8bc4\u4f30\u9690\u79c1\u98ce\u9669\u65f6\uff0c\u4ec5\u8003\u8651\u9879\u76ee\u7ea7\u522b\u7684\u6cc4\u9732\uff0c\u800c\u5ffd\u7565\u4e86\u7528\u6237\u5b9e\u4f53\u5728\u591a\u4e2a\u8868\u95f4\u5173\u7cfb\u5e26\u6765\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u8868\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MT-MIA\uff09\uff0c\u5728\u65e0\u76d2\u5a01\u80c1\u6a21\u578b\u4e0b\uff0c\u901a\u8fc7\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7528\u6237\u5b9e\u4f53\u7684\u8868\u793a\uff0c\u5229\u7528\u7528\u6237\u5728\u6240\u6709\u8fde\u63a5\u8868\u4e2d\u7684\u4fe1\u606f\u6765\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6210\u5458\u3002", "result": "MT-MIA\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u591a\u8868\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u73b0\u6709\u6700\u5148\u8fdb\u7684\u5173\u7cfb\u578b\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u5b58\u5728\u7528\u6237\u7ea7\u522b\u7684\u9690\u79c1\u6cc4\u9732\u6f0f\u6d1e\uff0c\u4e14\u5355\u8868MIA\u4f1a\u4f4e\u4f30\u8fd9\u79cd\u6cc4\u9732\u98ce\u9669\u3002", "conclusion": "\u5173\u7cfb\u578b\u5408\u6210\u6570\u636e\u5b58\u5728\u72ec\u7279\u7684\u7528\u6237\u7ea7\u522b\u9690\u79c1\u6311\u6218\uff0cMT-MIA\u80fd\u591f\u6709\u6548\u5ba1\u8ba1\u8fd9\u79cd\u98ce\u9669\uff0c\u4e3a\u5f00\u53d1\u66f4\u5b89\u5168\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.08273", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08273", "abs": "https://arxiv.org/abs/2602.08273", "authors": ["Melone Nyoba Tchonkeu", "Soulaimane Berkane", "Tarek Hamel"], "title": "Pitot-Aided Attitude and Air Velocity Estimation with Almost Global Asymptotic Stability Guarantees", "comment": "8 pages, 8 figures. Under review in IEEE CCTA2026", "summary": "This paper investigates the problem of attitude and air velocity estimation for fixed-wing unmanned aerial vehicles (UAVs) using IMU measurements and at least one Pitot tube measurement, with almost global asymptotic stability (AGAS) guarantees. A cascade observer architecture is developed, in which a Riccati/Kalman-type filter estimates the body-fixed frame air velocity and the vehicle's tilt using IMU data as inputs and Pitot measurements as outputs. Under mild excitation conditions, the resulting air velocity and tilt estimation error dynamics are shown to be uniformly observable. The estimated tilt is then combined with magnetometer measurements in a nonlinear observer on SO(3) to recover the full attitude. Rigorous analysis establishes AGAS of the overall cascade structure under the uniform observability (UO) condition. The effectiveness of the proposed approach is demonstrated through validation on real flight data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u7684\u59ff\u6001\u548c\u7a7a\u901f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4f7f\u7528IMU\u548c\u76ae\u6258\u7ba1\u6d4b\u91cf\uff0c\u5177\u6709\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027\u4fdd\u8bc1", "motivation": "\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u9700\u8981\u7cbe\u786e\u7684\u59ff\u6001\u548c\u7a7a\u901f\u4f30\u8ba1\u8fdb\u884c\u63a7\u5236\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u7f3a\u4e4f\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u9700\u8981\u4e00\u79cd\u5177\u6709\u7406\u8bba\u7a33\u5b9a\u6027\u4fdd\u8bc1\u7684\u4f30\u8ba1\u65b9\u6cd5", "method": "\u91c7\u7528\u7ea7\u8054\u89c2\u6d4b\u5668\u67b6\u6784\uff1a1) Riccati/Kalman\u578b\u6ee4\u6ce2\u5668\u4f30\u8ba1\u673a\u4f53\u5750\u6807\u7cfb\u7a7a\u901f\u548c\u503e\u659c\u89d2\uff0c\u4f7f\u7528IMU\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\u3001\u76ae\u6258\u7ba1\u6d4b\u91cf\u4f5c\u4e3a\u8f93\u51fa\uff1b2) \u5c06\u4f30\u8ba1\u7684\u503e\u659c\u89d2\u4e0e\u78c1\u529b\u8ba1\u6d4b\u91cf\u7ed3\u5408\uff0c\u5728SO(3)\u4e0a\u4f7f\u7528\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\u6062\u590d\u5b8c\u6574\u59ff\u6001", "result": "\u5728\u6e29\u548c\u6fc0\u52b1\u6761\u4ef6\u4e0b\uff0c\u7a7a\u901f\u548c\u503e\u659c\u89d2\u4f30\u8ba1\u8bef\u5dee\u52a8\u6001\u88ab\u8bc1\u660e\u662f\u5747\u5300\u53ef\u89c2\u6d4b\u7684\uff0c\u6574\u4f53\u7ea7\u8054\u7ed3\u6784\u5728\u5747\u5300\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u5177\u6709\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u771f\u5b9e\u98de\u884c\u6570\u636e\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u7ea7\u8054\u89c2\u6d4b\u5668\u67b6\u6784\u80fd\u591f\u53ef\u9760\u5730\u4f30\u8ba1\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u7684\u59ff\u6001\u548c\u7a7a\u901f\uff0c\u5177\u6709\u7406\u8bba\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u5728\u5b9e\u9645\u98de\u884c\u6570\u636e\u4e2d\u8868\u73b0\u826f\u597d"}}
{"id": "2602.08318", "categories": ["stat.ML", "cs.LG", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.08318", "abs": "https://arxiv.org/abs/2602.08318", "authors": ["Soon Hoe Lim", "Shizheng Lin", "Michael W. Mahoney", "N. Benjamin Erichson"], "title": "Is Flow Matching Just Trajectory Replay for Sequential Data?", "comment": "51 pages", "summary": "Flow matching (FM) is increasingly used for time-series generation, but it is not well understood whether it learns a general dynamical structure or simply performs an effective \"trajectory replay\". We study this question by deriving the velocity field targeted by the empirical FM objective on sequential data, in the limit of perfect function approximation. For the Gaussian conditional paths commonly used in practice, we show that the implied sampler is an ODE whose dynamics constitutes a nonparametric, memory-augmented continuous-time dynamical system. The optimal field admits a closed-form expression as a similarity-weighted mixture of instantaneous velocities induced by past transitions, making the dataset dependence explicit and interpretable. This perspective positions neural FM models trained by stochastic optimization as parametric surrogates of an ideal nonparametric solution. Using the structure of the optimal field, we study sampling and approximation schemes that improve the efficiency and numerical robustness of ODE-based generation. On nonlinear dynamical system benchmarks, the resulting closed-form sampler yields strong probabilistic forecasts directly from historical transitions, without training.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6d41\u5339\u914d\u5728\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u672c\u8d28\uff0c\u53d1\u73b0\u5176\u6700\u4f18\u901f\u5ea6\u573a\u662f\u4e00\u4e2a\u975e\u53c2\u6570\u3001\u8bb0\u5fc6\u589e\u5f3a\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u7cfb\u7edf\uff0c\u53ef\u4ee5\u901a\u8fc7\u5386\u53f2\u8f6c\u79fb\u7684\u76f8\u4f3c\u6027\u52a0\u6743\u6df7\u5408\u5f97\u5230\u95ed\u5f0f\u89e3\u3002", "motivation": "\u6d41\u5339\u914d\u5728\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u4eba\u4eec\u4e0d\u6e05\u695a\u5b83\u662f\u5426\u771f\u6b63\u5b66\u4e60\u5230\u4e86\u901a\u7528\u7684\u52a8\u529b\u7ed3\u6784\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5728\"\u91cd\u653e\u8f68\u8ff9\"\u3002\u672c\u6587\u65e8\u5728\u7406\u89e3\u6d41\u5339\u914d\u5728\u5b8c\u7f8e\u51fd\u6570\u903c\u8fd1\u6781\u9650\u4e0b\u7684\u672c\u8d28\u884c\u4e3a\u3002", "method": "\u63a8\u5bfc\u4e86\u5e8f\u5217\u6570\u636e\u4e0a\u7ecf\u9a8c\u6d41\u5339\u914d\u76ee\u6807\u5728\u5b8c\u7f8e\u51fd\u6570\u903c\u8fd1\u6781\u9650\u4e0b\u7684\u6700\u4f18\u901f\u5ea6\u573a\u3002\u5bf9\u4e8e\u5b9e\u8df5\u4e2d\u5e38\u7528\u7684\u9ad8\u65af\u6761\u4ef6\u8def\u5f84\uff0c\u8bc1\u660e\u4e86\u9690\u542b\u7684\u91c7\u6837\u5668\u662f\u4e00\u4e2aODE\uff0c\u5176\u52a8\u529b\u5b66\u6784\u6210\u4e86\u975e\u53c2\u6570\u3001\u8bb0\u5fc6\u589e\u5f3a\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u7cfb\u7edf\u3002\u6700\u4f18\u573a\u53ef\u4ee5\u8868\u793a\u4e3a\u5386\u53f2\u8f6c\u79fb\u8bf1\u5bfc\u7684\u77ac\u65f6\u901f\u5ea6\u7684\u76f8\u4f3c\u6027\u52a0\u6743\u6df7\u5408\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u6700\u4f18\u901f\u5ea6\u573a\u5177\u6709\u660e\u786e\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u4f7f\u6570\u636e\u96c6\u4f9d\u8d56\u6027\u53d8\u5f97\u663e\u5f0f\u548c\u53ef\u89e3\u91ca\u3002\u57fa\u4e8e\u6700\u4f18\u573a\u7684\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u6539\u8fdbODE\u751f\u6210\u6548\u7387\u548c\u6570\u503c\u9c81\u68d2\u6027\u7684\u91c7\u6837\u548c\u903c\u8fd1\u65b9\u6848\u3002\u5728\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5f97\u5230\u7684\u95ed\u5f0f\u91c7\u6837\u5668\u76f4\u63a5\u4ece\u5386\u53f2\u8f6c\u79fb\u4e2d\u4ea7\u751f\u5f3a\u5927\u7684\u6982\u7387\u9884\u6d4b\uff0c\u65e0\u9700\u8bad\u7ec3\u3002", "conclusion": "\u6d41\u5339\u914d\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u53ef\u4ee5\u88ab\u89c6\u4e3a\u7406\u60f3\u975e\u53c2\u6570\u89e3\u7684\u53c2\u6570\u5316\u66ff\u4ee3\u3002\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u6d41\u5339\u914d\u5728\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2602.08632", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08632", "abs": "https://arxiv.org/abs/2602.08632", "authors": ["Adi Haviv", "Niva Elkin-Koren", "Uri Hacohen", "Roi Livni", "Shay Moran"], "title": "We Should Separate Memorization from Copyright", "comment": null, "summary": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3a\u5f53\u524d\u6280\u672f\u6587\u732e\u4e2d\u4f7f\u7528\u7684\u4f20\u7edf\u91cd\u5efa\u6280\u672f\u4e0d\u9002\u5408\u7248\u6743\u5206\u6790\uff0c\u5bfc\u81f4\u8bb0\u5fc6\u4e0e\u590d\u5236\u88ab\u6df7\u6dc6\uff0c\u4e3b\u5f20\u8bb0\u5fc6\u4e0d\u5e94\u7b49\u540c\u4e8e\u590d\u5236\u6216\u4f5c\u4e3a\u7248\u6743\u4fb5\u6743\u7684\u4ee3\u7406\u6307\u6807\uff0c\u5efa\u8bae\u91c7\u7528\u57fa\u4e8e\u8f93\u51fa\u5c42\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u4f7f\u7528\u5e26\u6765\u4e86\u65b0\u7684\u7248\u6743\u98ce\u9669\u95ee\u9898\uff0c\u5f53\u524d\u6570\u636e\u79d1\u5b66\u754c\u548c\u6cd5\u5f8b\u5b66\u754c\u5bf9\u6b64\u5b58\u5728\u6d3b\u8dc3\u4f46\u6df7\u4e71\u7684\u8ba8\u8bba\uff0c\u6280\u672f\u6587\u732e\u4e2d\u4f7f\u7528\u7684\u4f20\u7edf\u65b9\u6cd5\u4e0d\u9002\u5408\u7248\u6743\u5206\u6790\uff0c\u5bfc\u81f4\u8bb0\u5fc6\u4e0e\u590d\u5236\u6982\u5ff5\u88ab\u6df7\u6dc6\u3002", "method": "\u533a\u5206\u6709\u610f\u4e49\u7684\u4fb5\u6743\u98ce\u9669\u6280\u672f\u4fe1\u53f7\u4e0e\u53cd\u6620\u5408\u6cd5\u6cdb\u5316\u6216\u9ad8\u9891\u5185\u5bb9\u7684\u6280\u672f\u4fe1\u53f7\uff0c\u63d0\u51fa\u57fa\u4e8e\u8f93\u51fa\u5c42\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4f7f\u6280\u672f\u8bc4\u4f30\u4e0e\u65e2\u5b9a\u7684\u7248\u6743\u6807\u51c6\u4fdd\u6301\u4e00\u81f4\u3002", "result": "\u8bba\u8bc1\u4e86\u8bb0\u5fc6\uff08\u6570\u636e\u79d1\u5b66\u4e2d\u5e38\u89c1\u7684\u7814\u7a76\u5bf9\u8c61\uff09\u4e0d\u5e94\u7b49\u540c\u4e8e\u590d\u5236\uff0c\u4e5f\u4e0d\u5e94\u4f5c\u4e3a\u7248\u6743\u4fb5\u6743\u7684\u4ee3\u7406\u6307\u6807\uff0c\u9700\u8981\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u6280\u672f\u4fe1\u53f7\u3002", "conclusion": "\u4e3b\u5f20\u91c7\u7528\u57fa\u4e8e\u8f93\u51fa\u5c42\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u3001\u5ba1\u8ba1\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u66f4\u539f\u5219\u6027\u7684\u57fa\u7840\uff0c\u4f7f\u6280\u672f\u8bc4\u4f30\u4e0e\u7248\u6743\u6807\u51c6\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2602.07770", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07770", "abs": "https://arxiv.org/abs/2602.07770", "authors": ["Karl Kunisch", "Donato V\u00e1squez-Varas"], "title": "Structure Preserving Approximation of Semiconcave Functions", "comment": null, "summary": "This article addresses structure-preserving smooth approximation of semiconcave functions. semiconcave functions are of particular interest because they naturally arise in a variety of variational problems, including {optimal feedback control, game theory, and optimal transport}. We leverage the fact that any semiconcave function can be represented as the {infimum of a countable family of \\(C^2\\) functions}. This infimum is expressed in a form that allows {approximation by finitely many functions}, combined with {smoothing operations}, such that each element of the approximating sequence remains semiconcave. The {active sets of indices} contributing to the representation of the semiconcave function and its approximations are analyzed in detail. Moreover, we show that the {gradients of the elements in the expansion of the approximating functions form a probability distribution}, a property of particular interest for the {value function in optimal control}. Approximation results are established in \\(C(\\bar \u03a9)\\) and in \\(W^{1,p}(\u03a9)\\) for \\(p \\in [1,\\infty)\\) and \\(p = \\infty\\). Finally, {numerical results} are presented to illustrate the approach on a test example.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u6301\u7ed3\u6784\u7684\u5149\u6ed1\u903c\u8fd1\u65b9\u6cd5\uff0c\u7528\u4e8e\u903c\u8fd1\u534a\u51f9\u51fd\u6570\u3002\u901a\u8fc7\u5c06\u534a\u51f9\u51fd\u6570\u8868\u793a\u4e3a\u53ef\u6570\u4e2aC\u00b2\u51fd\u6570\u7684\u4e0b\u786e\u754c\uff0c\u7ed3\u5408\u6709\u9650\u51fd\u6570\u903c\u8fd1\u548c\u5e73\u6ed1\u64cd\u4f5c\uff0c\u6784\u9020\u4fdd\u6301\u534a\u51f9\u6027\u7684\u903c\u8fd1\u5e8f\u5217\u3002", "motivation": "\u534a\u51f9\u51fd\u6570\u5728\u53d8\u5206\u95ee\u9898\u4e2d\u81ea\u7136\u51fa\u73b0\uff0c\u5982\u6700\u4f18\u53cd\u9988\u63a7\u5236\u3001\u535a\u5f08\u8bba\u548c\u6700\u4f18\u4f20\u8f93\u7b49\u9886\u57df\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u51fd\u6570\u901a\u5e38\u4e0d\u591f\u5149\u6ed1\uff0c\u9700\u8981\u65e2\u80fd\u4fdd\u6301\u5176\u7ed3\u6784\u7279\u6027\u53c8\u80fd\u63d0\u4f9b\u5149\u6ed1\u903c\u8fd1\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u534a\u51f9\u51fd\u6570\u53ef\u8868\u793a\u4e3a\u53ef\u6570\u4e2aC\u00b2\u51fd\u6570\u4e0b\u786e\u754c\u7684\u7279\u6027\uff0c\u901a\u8fc7\u6709\u9650\u51fd\u6570\u903c\u8fd1\u548c\u5e73\u6ed1\u64cd\u4f5c\u6784\u9020\u903c\u8fd1\u5e8f\u5217\u3002\u8be6\u7ec6\u5206\u6790\u4e86\u6d3b\u8dc3\u6307\u6807\u96c6\uff0c\u5e76\u8bc1\u660e\u4e86\u903c\u8fd1\u51fd\u6570\u5c55\u5f00\u4e2d\u68af\u5ea6\u5f62\u6210\u7684\u6982\u7387\u5206\u5e03\u7279\u6027\u3002", "result": "\u5728C(\u03a9\u0304)\u548cW^{1,p}(\u03a9)\u7a7a\u95f4\uff08p\u2208[1,\u221e)\u548cp=\u221e\uff09\u4e2d\u5efa\u7acb\u4e86\u903c\u8fd1\u7ed3\u679c\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u6d4b\u8bd5\u793a\u4f8b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u5c55\u793a\u4e86\u68af\u5ea6\u5f62\u6210\u7684\u6982\u7387\u5206\u5e03\u5728\u6700\u4f18\u63a7\u5236\u503c\u51fd\u6570\u4e2d\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7ed3\u6784\u4fdd\u6301\u5149\u6ed1\u903c\u8fd1\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u534a\u51f9\u51fd\u6570\uff0c\u4e3a\u6700\u4f18\u63a7\u5236\u7b49\u53d8\u5206\u95ee\u9898\u4e2d\u7684\u6570\u503c\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.07338", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07338", "abs": "https://arxiv.org/abs/2602.07338", "authors": ["Geng Liu", "Fei Zhu", "Rong Feng", "Changyi Ma", "Shiqi Wang", "Gaofeng Meng"], "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation", "comment": null, "summary": "Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u5bf9\u8bdd\u4e2d\u8ff7\u5931\"\u73b0\u8c61\u7684\u6839\u672c\u539f\u56e0\u4e0d\u662f\u6a21\u578b\u80fd\u529b\u4e0d\u8db3\uff0c\u800c\u662f\u7528\u6237\u610f\u56fe\u4e0e\u6a21\u578b\u7406\u89e3\u4e4b\u95f4\u7684\u5bf9\u9f50\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u8026\u610f\u56fe\u7406\u89e3\u4e0e\u4efb\u52a1\u6267\u884c\u7684Mediator-Assistant\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u76f8\u6bd4\u5355\u8f6e\u5bf9\u8bdd\u4f1a\u51fa\u73b0\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\uff08\u79f0\u4e3a\"\u5bf9\u8bdd\u4e2d\u8ff7\u5931\"\u73b0\u8c61\uff09\uff0c\u73b0\u6709\u7814\u7a76\u5c06\u5176\u5f52\u56e0\u4e8e\u6a21\u578b\u4e0d\u53ef\u9760\u6027\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\u6839\u672c\u539f\u56e0\u5728\u4e8e\u610f\u56fe\u5bf9\u9f50\u5dee\u8ddd\u800c\u975e\u5185\u5728\u80fd\u529b\u7f3a\u9677\u3002", "method": "\u63d0\u51faMediator-Assistant\u67b6\u6784\uff0c\u901a\u8fc7\u7ecf\u9a8c\u9a71\u52a8\u7684Mediator\u5c06\u6a21\u7cca\u7684\u7528\u6237\u8f93\u5165\u57fa\u4e8e\u5386\u53f2\u4ea4\u4e92\u6a21\u5f0f\u8f6c\u5316\u4e3a\u660e\u786e\u3001\u7ed3\u6784\u5316\u7684\u6307\u4ee4\uff0c\u4ece\u800c\u89e3\u8026\u610f\u56fe\u7406\u89e3\u4e0e\u4efb\u52a1\u6267\u884c\uff0c\u5f25\u5408\u7528\u6237\u610f\u56fe\u4e0e\u6a21\u578b\u89e3\u91ca\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u8f7b\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5728\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u90fd\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002", "conclusion": "\"\u5bf9\u8bdd\u4e2d\u8ff7\u5931\"\u73b0\u8c61\u6e90\u4e8e\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u610f\u56fe\u5bf9\u9f50\u95ee\u9898\u800c\u975e\u6a21\u578b\u80fd\u529b\u9650\u5236\uff0c\u901a\u8fc7\u89e3\u8026\u610f\u56fe\u7406\u89e3\u4e0e\u4efb\u52a1\u6267\u884c\u7684\u67b6\u6784\u8bbe\u8ba1\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5355\u7eaf\u6269\u5927\u6a21\u578b\u89c4\u6a21\u6216\u6539\u8fdb\u8bad\u7ec3\u65e0\u6cd5\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u8fd9\u79cd\u7ed3\u6784\u6027\u6a21\u7cca\u6027\u3002"}}
{"id": "2602.07274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07274", "abs": "https://arxiv.org/abs/2602.07274", "authors": ["Kaijie Zhu", "Yuzhou Nie", "Yijiang Li", "Yiming Huang", "Jialian Wu", "Jiang Liu", "Ximeng Sun", "Zhenfei Yin", "Lun Wang", "Zicheng Liu", "Emad Barsoum", "William Yang Wang", "Wenbo Guo"], "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents", "comment": null, "summary": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.", "AI": {"tldr": "TermiGen\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u7528\u4e8e\u5408\u6210\u53ef\u9a8c\u8bc1\u7684\u7ec8\u7aef\u73af\u5883\u548c\u5177\u6709\u6062\u590d\u80fd\u529b\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u751f\u6210\u6709\u6548\u4efb\u52a1\u548cDocker\u5bb9\u5668\uff0c\u5e76\u6ce8\u5165\u9519\u8bef\u6765\u8bad\u7ec3\u6a21\u578b\u4ece\u5931\u8d25\u4e2d\u6062\u590d\uff0c\u6700\u7ec8\u5728TerminalBench\u4e0a\u8fbe\u523031.3%\u901a\u8fc7\u7387\u7684\u65b0SOTA\u3002", "motivation": "\u5f53\u524d\u5f00\u653e\u6743\u91cdLLM\u5728\u6267\u884c\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u65f6\u9762\u4e34\u4e24\u4e2a\u6838\u5fc3\u9650\u5236\uff1a1\uff09\u7f3a\u4e4f\u9ad8\u4fdd\u771f\u3001\u53ef\u6267\u884c\u7684\u8bad\u7ec3\u73af\u5883\uff08\u73b0\u6709\u73af\u5883\u4e0d\u591f\u591a\u6837\u5316\u548c\u53ef\u6269\u5c55\uff0cLLM\u5408\u6210\u7684\u8f68\u8ff9\u5b58\u5728\u5e7b\u89c9\uff09\uff1b2\uff09\u6807\u51c6\u6307\u4ee4\u8c03\u4f18\u4f7f\u7528\u7684\u4e13\u5bb6\u8f68\u8ff9\u5f88\u5c11\u5305\u542b\u5c0f\u6a21\u578b\u5e38\u89c1\u7684\u7b80\u5355\u9519\u8bef\uff0c\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u4ece\u81ea\u8eab\u8fd0\u884c\u65f6\u9519\u8bef\u4e2d\u6062\u590d\u3002", "method": "TermiGen\u91c7\u7528\u7aef\u5230\u7aef\u7ba1\u9053\uff1a1\uff09\u901a\u8fc7\u8fed\u4ee3\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u5faa\u73af\u751f\u6210\u529f\u80fd\u6709\u6548\u7684\u4efb\u52a1\u548cDocker\u5bb9\u5668\uff1b2\uff09\u91c7\u7528\u751f\u6210\u5668-\u6279\u8bc4\u8005\u534f\u8bae\uff0c\u5728\u8f68\u8ff9\u6536\u96c6\u8fc7\u7a0b\u4e2d\u4e3b\u52a8\u6ce8\u5165\u9519\u8bef\uff0c\u5408\u6210\u5bcc\u542b\u9519\u8bef\u7ea0\u6b63\u5faa\u73af\u7684\u6570\u636e\uff1b3\uff09\u57fa\u4e8eTermiGen\u751f\u6210\u7684\u6570\u636e\u96c6\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u4f7f\u7528TermiGen\u6570\u636e\u96c6\u5fae\u8c03\u7684TermiGen-Qwen2.5-Coder-32B\u5728TerminalBench\u4e0a\u8fbe\u523031.3%\u7684\u901a\u8fc7\u7387\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u5f00\u653e\u6743\u91cdSOTA\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86o4-mini\u7b49\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "TermiGen\u901a\u8fc7\u5408\u6210\u53ef\u9a8c\u8bc1\u73af\u5883\u548c\u5177\u6709\u6062\u590d\u80fd\u529b\u7684\u4e13\u5bb6\u8f68\u8ff9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u6743\u91cdLLM\u5728\u7ec8\u7aef\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u73af\u5883\u7a00\u7f3a\u548c\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2602.07135", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07135", "abs": "https://arxiv.org/abs/2602.07135", "authors": ["Jiaqing Chen", "Nicholas Hadler", "Tiankai Xie", "Rostyslav Hnatyshyn", "Caleb Geniesse", "Yaoqing Yang", "Michael W. Mahoney", "Talita Perciano", "John F. Hartwig", "Ross Maciejewski", "Gunther H. Weber"], "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis", "comment": null, "summary": "Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A key component is the Saddle-Minimum Average Distance (SMAD) for quantifying landscape smoothness. We demonstrate Landscaper's effectiveness across various architectures and tasks, including those involving pre-trained language models, showing that SMAD captures training transitions, such as landscape simplification, that conventional metrics miss. We also illustrate Landscaper's performance in challenging chemical property prediction tasks, where SMAD can serve as a metric for out-of-distribution generalization, offering valuable insights for model diagnostics and architecture design in data-scarce scientific machine learning scenarios.", "AI": {"tldr": "Landscaper\u662f\u4e00\u4e2a\u7528\u4e8e\u4efb\u610f\u7ef4\u5ea6\u635f\u5931\u666f\u89c2\u5206\u6790\u7684Python\u5de5\u5177\u5305\uff0c\u7ed3\u5408Hessian\u5b50\u7a7a\u95f4\u6784\u9020\u548c\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u63d0\u51faSMAD\u6307\u6807\u91cf\u5316\u666f\u89c2\u5e73\u6ed1\u5ea6\uff0c\u5728\u8bed\u8a00\u6a21\u578b\u548c\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5c55\u73b0\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u4f4e\u7ef4\u635f\u5931\u666f\u89c2\u5206\u6790\u5e38\u9057\u6f0f\u590d\u6742\u7684\u62d3\u6251\u7279\u5f81\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u6765\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u548c\u6cdb\u5316\u7279\u6027\u3002", "method": "\u5f00\u53d1Landscaper\u5f00\u6e90Python\u5305\uff0c\u7ed3\u5408Hessian-based\u5b50\u7a7a\u95f4\u6784\u9020\u548c\u62d3\u6251\u6570\u636e\u5206\u6790\uff0c\u63d0\u51faSaddle-Minimum Average Distance (SMAD)\u6307\u6807\u91cf\u5316\u666f\u89c2\u5e73\u6ed1\u5ea6\u3002", "result": "SMAD\u80fd\u6355\u6349\u4f20\u7edf\u6307\u6807\u9057\u6f0f\u7684\u8bad\u7ec3\u8f6c\u6362\uff08\u5982\u666f\u89c2\u7b80\u5316\uff09\uff0c\u5728\u8bed\u8a00\u6a21\u578b\u548c\u5316\u5b66\u6027\u8d28\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u4f5c\u4e3a\u5206\u5e03\u5916\u6cdb\u5316\u6307\u6807\u3002", "conclusion": "Landscaper\u4e3a\u6a21\u578b\u8bca\u65ad\u548c\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u6d1e\u5bdf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u7a00\u7f3a\u7684\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2602.08303", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08303", "abs": "https://arxiv.org/abs/2602.08303", "authors": ["Shun Hirose", "Shiu Mochiyama", "Yoshihiko Susuki"], "title": "Experimental Realization of Koopman-Model Predictive Control for an AC-DC Converter", "comment": "6 pages, 5 figures, ISIE", "summary": "This paper experimentally demonstrates the Koopman-Model Predictive Control (K-MPC) for a real AC-DC converter. The converter is typically modeled with a nonlinear time-variant plant. We introduce a new dynamical approach to lifting measurable dynamics from the plant and constructing a linear time-invariant model that is consistent with control objectives of the converter. We show that the lifting approach, combined with the K-MPC controller, performs well across the full experimental system and outperforms existing control strategies in terms of both steady-state and transient responses.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5b9e\u9a8c\u6027\u5730\u5c55\u793a\u4e86\u7528\u4e8e\u771f\u5b9eAC-DC\u8f6c\u6362\u5668\u7684Koopman\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08K-MPC\uff09\uff0c\u901a\u8fc7\u65b0\u7684\u52a8\u6001\u63d0\u5347\u65b9\u6cd5\u6784\u5efa\u7ebf\u6027\u65f6\u4e0d\u53d8\u6a21\u578b\uff0c\u5728\u7a33\u6001\u548c\u77ac\u6001\u54cd\u5e94\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u63a7\u5236\u7b56\u7565", "motivation": "AC-DC\u8f6c\u6362\u5668\u901a\u5e38\u88ab\u5efa\u6a21\u4e3a\u975e\u7ebf\u6027\u65f6\u53d8\u7cfb\u7edf\uff0c\u8fd9\u7ed9\u63a7\u5236\u8bbe\u8ba1\u5e26\u6765\u6311\u6218\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u975e\u7ebf\u6027\u7279\u6027\u540c\u65f6\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u65b0\u7684\u52a8\u6001\u63d0\u5347\u65b9\u6cd5\uff0c\u4ece\u53ef\u6d4b\u91cf\u7684\u7cfb\u7edf\u52a8\u6001\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u6784\u5efa\u4e0e\u8f6c\u6362\u5668\u63a7\u5236\u76ee\u6807\u4e00\u81f4\u7684\u7ebf\u6027\u65f6\u4e0d\u53d8\u6a21\u578b\uff0c\u7136\u540e\u7ed3\u5408Koopman\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08K-MPC\uff09\u8fdb\u884c\u63a7\u5236", "result": "\u63d0\u5347\u65b9\u6cd5\u4e0eK-MPC\u63a7\u5236\u5668\u7ed3\u5408\uff0c\u5728\u6574\u4e2a\u5b9e\u9a8c\u7cfb\u7edf\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5728\u7a33\u6001\u548c\u77ac\u6001\u54cd\u5e94\u65b9\u9762\u90fd\u4f18\u4e8e\u73b0\u6709\u63a7\u5236\u7b56\u7565", "conclusion": "Koopman-MPC\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406AC-DC\u8f6c\u6362\u5668\u7684\u975e\u7ebf\u6027\u65f6\u53d8\u7279\u6027\uff0c\u901a\u8fc7\u52a8\u6001\u63d0\u5347\u6784\u5efa\u7684\u7ebf\u6027\u6a21\u578b\u7ed3\u5408MPC\u63a7\u5236\uff0c\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u63a7\u5236\u6027\u80fd"}}
{"id": "2602.08374", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.08374", "abs": "https://arxiv.org/abs/2602.08374", "authors": ["Denis Belomestny", "Alexey Naumov", "Nikita Puchkin", "Denis Suchkov"], "title": "Schr\u00f6dinger bridge problem via empirical risk minimization", "comment": null, "summary": "We study the Schr\u00f6dinger bridge problem when the endpoint distributions are available only through samples. Classical computational approaches estimate Schr\u00f6dinger potentials via Sinkhorn iterations on empirical measures and then construct a time-inhomogeneous drift by differentiating a kernel-smoothed dual solution. In contrast, we propose a learning-theoretic route: we rewrite the Schr\u00f6dinger system in terms of a single positive transformed potential that satisfies a nonlinear fixed-point equation and estimate this potential by empirical risk minimization over a function class. We establish uniform concentration of the empirical risk around its population counterpart under sub-Gaussian assumptions on the reference kernel and terminal density. We plug the learned potential into a stochastic control representation of the bridge to generate samples. We illustrate performance of the suggested approach with numerical experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7406\u8bba\u7684\u859b\u5b9a\u8c14\u6865\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5b66\u4e60\u5355\u6b63\u53d8\u6362\u52bf\u51fd\u6570\uff0c\u907f\u514d\u4f20\u7edfSinkhorn\u8fed\u4ee3\u7684\u5e73\u6ed1\u6838\u4f30\u8ba1", "motivation": "\u4f20\u7edf\u859b\u5b9a\u8c14\u6865\u8ba1\u7b97\u65b9\u6cd5\u57fa\u4e8e\u7ecf\u9a8c\u6d4b\u5ea6\u7684Sinkhorn\u8fed\u4ee3\uff0c\u9700\u8981\u6838\u5e73\u6ed1\u4f30\u8ba1\u5bf9\u5076\u89e3\u5e76\u6784\u9020\u65f6\u53d8\u6f02\u79fb\u3002\u672c\u6587\u5bfb\u6c42\u66f4\u76f4\u63a5\u7684\u5b66\u4e60\u7406\u8bba\u65b9\u6cd5\uff0c\u907f\u514d\u8fd9\u4e9b\u4e2d\u95f4\u6b65\u9aa4", "method": "\u5c06\u859b\u5b9a\u8c14\u7cfb\u7edf\u91cd\u5199\u4e3a\u6ee1\u8db3\u975e\u7ebf\u6027\u4e0d\u52a8\u70b9\u65b9\u7a0b\u7684\u5355\u6b63\u53d8\u6362\u52bf\u51fd\u6570\uff0c\u901a\u8fc7\u51fd\u6570\u7c7b\u4e0a\u7684\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4f30\u8ba1\u8be5\u52bf\u51fd\u6570\uff0c\u7136\u540e\u5c06\u5b66\u4e60\u5230\u7684\u52bf\u51fd\u6570\u4ee3\u5165\u6865\u7684\u968f\u673a\u63a7\u5236\u8868\u793a\u751f\u6210\u6837\u672c", "result": "\u5728\u53c2\u8003\u6838\u548c\u7ec8\u7aef\u5bc6\u5ea6\u7684\u6b21\u9ad8\u65af\u5047\u8bbe\u4e0b\uff0c\u5efa\u7acb\u4e86\u7ecf\u9a8c\u98ce\u9669\u56f4\u7ed5\u5176\u603b\u4f53\u5bf9\u5e94\u9879\u7684\u4e00\u81f4\u96c6\u4e2d\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7406\u8bba\u7684\u859b\u5b9a\u8c14\u6865\u6c42\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u52bf\u51fd\u6570\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e2d\u95f4\u4f30\u8ba1\u6b65\u9aa4\uff0c\u4e3a\u7aef\u70b9\u5206\u5e03\u4ec5\u901a\u8fc7\u6837\u672c\u53ef\u7528\u7684\u60c5\u51b5\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba1\u7b97\u65b9\u6cd5"}}
{"id": "2602.08728", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08728", "abs": "https://arxiv.org/abs/2602.08728", "authors": ["Maxim Dedyaev"], "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities", "comment": null, "summary": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u7f8e\u56fd\u8054\u90a6\u3001\u5dde\u548c\u5e02\u4e09\u7ea7\u653f\u5e9c\u768430\u4e2aAI\u5b9e\u65bd\u6848\u4f8b\uff0c\u53d1\u73b0\u4e0d\u540c\u653f\u5e9c\u5c42\u7ea7\u91c7\u7528\u4e0d\u540c\u7684\u7b97\u6cd5\u6cbb\u7406\u6a21\u5f0f\uff1a\u8054\u90a6\u653f\u5e9c\u504f\u5411\u63a7\u5236\u5bfc\u5411\uff0c\u5dde\u653f\u5e9c\u5904\u4e8e\u4e2d\u95f4\u5730\u5e26\uff0c\u5e02\u653f\u5e9c\u5219\u66f4\u6ce8\u91cd\u670d\u52a1\u5bfc\u5411\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u516c\u5171\u6cbb\u7406\u4e2d\u5feb\u901f\u53d1\u5c55\u5e76\u5e26\u6765\u4e50\u89c2\u9884\u671f\uff0c\u4f46\u6211\u4eec\u5bf9AI\u5728\u4e0d\u540c\u653f\u5e9c\u5c42\u7ea7\uff08\u5c24\u5176\u662f\u8054\u90a6\u5236\u56fd\u5bb6\uff09\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5f62\u6001\u77e5\u4e4b\u751a\u5c11\u3002\u540c\u4e00\u7b97\u6cd5\u5728\u4e0d\u540c\u5c42\u7ea7\u53ef\u80fd\u670d\u52a1\u4e8e\u5b8c\u5168\u4e0d\u540c\u7684\u76ee\u7684\uff0c\u8fd9\u79cd\u77e5\u8bc6\u7a7a\u767d\u9700\u8981\u586b\u8865\u3002", "method": "\u91c7\u7528\u6bd4\u8f83\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u7f8e\u56fd\u8054\u90a6\u3001\u5dde\u548c\u5e02\u4e09\u7ea7\u653f\u5e9c\u768430\u4e2aAI\u5b9e\u65bd\u6848\u4f8b\u3002\u7814\u7a76\u6846\u67b6\u7ed3\u5408\u4e86\u6570\u5b57\u65f6\u4ee3\u6cbb\u7406\u7406\u8bba\u548c\u793e\u4f1a\u6280\u672f\u89c6\u89d2\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e24\u79cd\u4e3b\u8981\u7684\u7b97\u6cd5\u6cbb\u7406\u6a21\u5f0f\uff1a\u63a7\u5236\u5bfc\u5411\u7cfb\u7edf\u548c\u652f\u6301\u5bfc\u5411\u7cfb\u7edf\u3002\u4e0d\u540c\u653f\u5e9c\u5c42\u7ea7\u5448\u73b0\u660e\u663e\u7684\u529f\u80fd\u5206\u5316\uff1a\u8054\u90a6\u653f\u5e9c\u5c06AI\u5236\u5ea6\u5316\u4e3a\u9ad8\u98ce\u9669\u63a7\u5236\u5de5\u5177\uff08\u76d1\u63a7\u3001\u6267\u6cd5\u3001\u76d1\u7ba1\uff09\uff1b\u5dde\u653f\u5e9c\u5904\u4e8e\u6a21\u7cca\u4e2d\u95f4\u5730\u5e26\uff0cAI\u517c\u5177\u652f\u6301\u529f\u80fd\u548c\u7b97\u6cd5\u628a\u5173\u4f5c\u7528\uff1b\u5e02\u653f\u5e9c\u5219\u66f4\u52a1\u5b9e\u548c\u670d\u52a1\u5bfc\u5411\uff0c\u7528\u4e8e\u7b80\u5316\u65e5\u5e38\u8fd0\u8425\u548c\u6539\u5584\u5c45\u6c11\u4e92\u52a8\u3002", "conclusion": "AI\u5728\u516c\u5171\u90e8\u95e8\u7684\u7279\u5f81\u3001\u529f\u80fd\u548c\u98ce\u9669\u6839\u672c\u4e0a\u53d7\u5230\u90e8\u7f72\u5c42\u7ea7\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u7a81\u51fa\u5236\u5ea6\u80cc\u666f\uff0c\u8be5\u7814\u7a76\u63a8\u8fdb\u4e86\u5173\u4e8e\u7b97\u6cd5\u6cbb\u7406\u7684\u8ba8\u8bba\uff0c\u8868\u660e\u6cbb\u7406\u5c42\u7ea7\u662f\u5851\u9020AI\u5e94\u7528\u6027\u8d28\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.07793", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07793", "abs": "https://arxiv.org/abs/2602.07793", "authors": ["Shanjian Tang", "Jianjun Zhou"], "title": "Optimal Control of Unbounded Stochastic Evolution Systems in Hilbert Spaces", "comment": "57 pages", "summary": "Optimal control and the associated second-order Hamilton-Jacobi-Bellman (HJB) equation are studied for unbounded stochastic evolution systems in Hilbert spaces. A new notion of viscosity solution, featured by absence of B-continuity, is introduced for the second-order HJB equation in the sense of Crandall and Lions, and is shown to coincide with the classical solutions and to satisfy a stability property. The value functional is proved to be the unique continuous viscosity solution to the second-order HJB equation, with the coefficients being not necessarily B-continuous. Our result provides a new theory of viscosity solutions to the HJB equation for optimal control of stochastic evolutionary equations-driven by a linear unbounded operator-in a Hilbert space, and removes the B-continuity assumption on the coefficients which is used in the existing literature.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0B\u8fde\u7eed\u6027\u7684\u7c98\u6027\u89e3\u6982\u5ff5\uff0c\u7528\u4e8e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u65e0\u754c\u968f\u673a\u6f14\u5316\u7cfb\u7edf\u7684\u6700\u4f18\u63a7\u5236\u4e8c\u9636HJB\u65b9\u7a0b\uff0c\u8bc1\u660e\u4e86\u503c\u6cdb\u51fd\u662f\u8be5\u65b9\u7a0b\u7684\u552f\u4e00\u8fde\u7eed\u7c98\u6027\u89e3\uff0c\u53bb\u9664\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u5bf9\u7cfb\u6570\u7684B\u8fde\u7eed\u6027\u5047\u8bbe\u3002", "motivation": "\u7814\u7a76\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u65e0\u754c\u968f\u673a\u6f14\u5316\u7cfb\u7edf\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u73b0\u6709\u6587\u732e\u4e2d\u4e8c\u9636HJB\u65b9\u7a0b\u7684\u7c98\u6027\u89e3\u7406\u8bba\u8981\u6c42\u7cfb\u6570\u5177\u6709B\u8fde\u7eed\u6027\uff0c\u8fd9\u4e00\u5047\u8bbe\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\uff0c\u9700\u8981\u53d1\u5c55\u4e0d\u4f9d\u8d56B\u8fde\u7eed\u6027\u7684\u65b0\u7406\u8bba\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u7c98\u6027\u89e3\u6982\u5ff5\uff0c\u57fa\u4e8eCrandall\u548cLions\u7684\u6846\u67b6\u4f46\u53bb\u9664\u4e86B\u8fde\u7eed\u6027\u8981\u6c42\uff0c\u8bc1\u660e\u4e86\u8be5\u89e3\u4e0e\u7ecf\u5178\u89e3\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u7a33\u5b9a\u6027\u6027\u8d28\uff0c\u6700\u7ec8\u8bc1\u660e\u503c\u6cdb\u51fd\u662f\u4e8c\u9636HJB\u65b9\u7a0b\u7684\u552f\u4e00\u8fde\u7eed\u7c98\u6027\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u65e0B\u8fde\u7eed\u6027\u5047\u8bbe\u7684\u4e8c\u9636HJB\u65b9\u7a0b\u7c98\u6027\u89e3\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u503c\u6cdb\u51fd\u662f\u8be5\u65b9\u7a0b\u7684\u552f\u4e00\u8fde\u7eed\u7c98\u6027\u89e3\uff0c\u7cfb\u6570\u4e0d\u9700\u8981\u6ee1\u8db3B\u8fde\u7eed\u6027\u6761\u4ef6\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7406\u8bba\u7684\u5e94\u7528\u8303\u56f4\u3002", "conclusion": "\u6210\u529f\u53d1\u5c55\u4e86\u4e00\u79cd\u65b0\u7684\u7c98\u6027\u89e3\u7406\u8bba\uff0c\u89e3\u51b3\u4e86\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u65e0\u754c\u968f\u673a\u6f14\u5316\u7cfb\u7edf\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u53bb\u9664\u4e86\u5bf9\u7cfb\u6570B\u8fde\u7eed\u6027\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.07361", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07361", "abs": "https://arxiv.org/abs/2602.07361", "authors": ["Long S. T. Nguyen", "Quan M. Bui", "Tin T. Ngo", "Quynh T. N. Vo", "Dung N. H. Le", "Tho T. Quan"], "title": "ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations", "comment": "Accepted at ACIIDS 2026", "summary": "Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8d8a\u5357\u533b\u7597\u6cd5\u89c4\u591a\u8df3\u63a8\u7406\u6570\u636e\u96c6ViHERMES\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u8df3\u95ee\u7b54\u7cfb\u7edf\u5728\u533b\u7597\u6cd5\u89c4\u6587\u6863\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u611f\u77e5\u7684\u68c0\u7d22\u6846\u67b6\u3002", "motivation": "\u76d1\u7ba1\u6587\u6863\u95ee\u7b54\u9700\u8981\u8de8\u6cd5\u5f8b\u76f8\u4e92\u4f9d\u8d56\u6587\u672c\u7684\u591a\u8df3\u63a8\u7406\uff0c\u8fd9\u5728\u533b\u7597\u9886\u57df\u5c24\u5176\u91cd\u8981\uff0c\u56e0\u4e3a\u6cd5\u89c4\u662f\u5206\u5c42\u7ed3\u6784\u4e14\u9891\u7e41\u4fee\u8ba2\u3002\u76ee\u524d\u7f3a\u4e4f\u652f\u6301\u591a\u8df3\u63a8\u7406\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8d8a\u5357\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002", "method": "1. \u63d0\u51faViHERMES\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff1a\u57fa\u4e8e\u8bed\u4e49\u805a\u7c7b\u548c\u56fe\u542f\u53d1\u6570\u636e\u6316\u6398\u7684\u53d7\u63a7\u591a\u8df3QA\u751f\u6210\u7ba1\u9053\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5e26\u6709\u7ed3\u6784\u5316\u8bc1\u636e\u548c\u63a8\u7406\u6807\u6ce8\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\u30022. \u63d0\u51fa\u56fe\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff1a\u5728\u6cd5\u5f8b\u5355\u5143\u7ea7\u522b\u5efa\u6a21\u6b63\u5f0f\u6cd5\u5f8b\u5173\u7cfb\uff0c\u652f\u6301\u539f\u5219\u6027\u4e0a\u4e0b\u6587\u6269\u5c55\u4ee5\u83b7\u5f97\u5408\u6cd5\u6709\u6548\u7684\u7b54\u6848\u3002", "result": "ViHERMES\u4e3a\u8bc4\u4f30\u591a\u8df3\u76d1\u7ba1QA\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u63d0\u51fa\u7684\u56fe\u611f\u77e5\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u4e00\u81f4\u4f18\u4e8e\u5f3a\u68c0\u7d22\u57fa\u7ebf\u3002", "conclusion": "ViHERMES\u586b\u8865\u4e86\u8d8a\u5357\u8bed\u533b\u7597\u6cd5\u89c4\u591a\u8df3\u63a8\u7406\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u56fe\u611f\u77e5\u68c0\u7d22\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u6cd5\u5f8b\u6587\u6863\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3a\u76d1\u7ba1\u6587\u6863\u95ee\u7b54\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u548c\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2602.07276", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07276", "abs": "https://arxiv.org/abs/2602.07276", "authors": ["Pengrui Han", "Xueqiang Xu", "Keyang Xuan", "Peiyang Song", "Siru Ouyang", "Runchu Tian", "Yuqing Jiang", "Cheng Qian", "Pengcheng Jiang", "Jiashuo Sun", "Junxia Cui", "Ming Zhong", "Ge Liu", "Jiawei Han", "Jiaxuan You"], "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs", "comment": null, "summary": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.", "AI": {"tldr": "STEER2ADAPT\uff1a\u901a\u8fc7\u7ec4\u5408\u800c\u975e\u5b66\u4e60\u65b0\u7684\u5bfc\u5411\u5411\u91cf\u6765\u9002\u5e94LLM\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u5728\u63a8\u7406\u548c\u5b89\u5168\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u53478.2%", "motivation": "\u73b0\u6709\u6fc0\u6d3b\u5bfc\u5411\u65b9\u6cd5\u901a\u5e38\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u6216\u6982\u5ff5\u4f7f\u7528\u5355\u4e00\u9759\u6001\u65b9\u5411\uff0c\u8fd9\u5728\u4efb\u52a1\u53d8\u5316\u65f6\u4e0d\u591f\u7075\u6d3b\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u9700\u8981\u591a\u79cd\u534f\u8c03\u80fd\u529b\u7684\u590d\u6742\u4efb\u52a1", "method": "\u63d0\u51faSTEER2ADAPT\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5171\u4eab\u7684\u5e95\u5c42\u6982\u5ff5\u7ef4\u5ea6\u6355\u83b7\u4e3a\u53ef\u91cd\u7528\u7684\u4f4e\u7ef4\u8bed\u4e49\u5148\u9a8c\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u5c11\u91cf\u793a\u4f8b\u52a8\u6001\u53d1\u73b0\u57fa\u5411\u91cf\u7684\u7ebf\u6027\u7ec4\u5408\u6765\u9002\u5e94\u65b0\u4efb\u52a1", "result": "\u57289\u4e2a\u4efb\u52a1\u548c3\u4e2a\u6a21\u578b\u7684\u63a8\u7406\u548c\u5b89\u5168\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u5e73\u5747\u63d0\u53478.2%\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u6570\u636e\u6548\u7387\u9ad8\u3001\u7a33\u5b9a\u6027\u597d\u548c\u900f\u660e\u5ea6\u9ad8\u7684\u7279\u70b9", "conclusion": "STEER2ADAPT\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u7a33\u5b9a\u4e14\u900f\u660e\u7684\u63a8\u7406\u65f6\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7ec4\u5408\u73b0\u6709\u5bfc\u5411\u5411\u91cf\u800c\u975e\u4ece\u5934\u5b66\u4e60\u6765\u7075\u6d3b\u9002\u5e94LLM\u5230\u4e0b\u6e38\u4efb\u52a1"}}
{"id": "2602.07141", "categories": ["cs.LG", "math.FA"], "pdf": "https://arxiv.org/pdf/2602.07141", "abs": "https://arxiv.org/abs/2602.07141", "authors": ["Isabel de la Higuera", "Francisco Herrera", "M. Victoria Velasco"], "title": "Featured Reproducing Kernel Banach Spaces for Learning and Neural Networks", "comment": null, "summary": "Reproducing kernel Hilbert spaces provide a foundational framework for kernel-based learning, where regularization and interpolation problems admit finite-dimensional solutions through classical representer theorems. Many modern learning models, however -- including fixed-architecture neural networks equipped with non-quadratic norms -- naturally give rise to non-Hilbertian geometries that fall outside this setting. In Banach spaces, continuity of point-evaluation functionals alone is insufficient to guarantee feature representations or kernel-based learning formulations. In this work, we develop a functional-analytic framework for learning in Banach spaces based on the notion of featured reproducing kernel Banach spaces. We identify the precise structural conditions under which feature maps, kernel constructions, and representer-type results can be recovered beyond the Hilbertian regime. Within this framework, supervised learning is formulated as a minimal-norm interpolation or regularization problem, and existence results together with conditional representer theorems are established. We further extend the theory to vector-valued featured reproducing kernel Banach spaces and show that fixed-architecture neural networks naturally induce special instances of such spaces. This provides a unified function-space perspective on kernel methods and neural networks and clarifies when kernel-based learning principles extend beyond reproducing kernel Hilbert spaces.", "AI": {"tldr": "\u63d0\u51fa\u7279\u5f81\u518d\u751f\u6838Banach\u7a7a\u95f4\u6846\u67b6\uff0c\u5c06\u6838\u65b9\u6cd5\u6269\u5c55\u5230\u975eHilbert\u51e0\u4f55\uff0c\u7edf\u4e00\u6838\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc", "motivation": "\u8bb8\u591a\u73b0\u4ee3\u5b66\u4e60\u6a21\u578b\uff08\u5982\u5177\u6709\u975e\u4e8c\u6b21\u8303\u6570\u7684\u795e\u7ecf\u7f51\u7edc\uff09\u4ea7\u751f\u975eHilbert\u51e0\u4f55\uff0c\u4f20\u7edf\u518d\u751f\u6838Hilbert\u7a7a\u95f4\u6846\u67b6\u65e0\u6cd5\u5904\u7406\u3002Banach\u7a7a\u95f4\u4e2d\u70b9\u8bc4\u4f30\u6cdb\u51fd\u8fde\u7eed\u6027\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u7279\u5f81\u8868\u793a\u6216\u6838\u5b66\u4e60\u516c\u5f0f\u3002", "method": "\u57fa\u4e8e\u7279\u5f81\u518d\u751f\u6838Banach\u7a7a\u95f4\u6982\u5ff5\uff0c\u5efa\u7acbBanach\u7a7a\u95f4\u5b66\u4e60\u7684\u6cdb\u51fd\u5206\u6790\u6846\u67b6\u3002\u8bc6\u522b\u7279\u5f81\u6620\u5c04\u3001\u6838\u6784\u9020\u548c\u8868\u793a\u578b\u5b9a\u7406\u6062\u590d\u7684\u7cbe\u786e\u7ed3\u6784\u6761\u4ef6\u3002\u5c06\u76d1\u7763\u5b66\u4e60\u8868\u8ff0\u4e3a\u6700\u5c0f\u8303\u6570\u63d2\u503c\u6216\u6b63\u5219\u5316\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86\u5b58\u5728\u6027\u7ed3\u679c\u548c\u6761\u4ef6\u8868\u793a\u5b9a\u7406\uff0c\u5c06\u7406\u8bba\u6269\u5c55\u5230\u5411\u91cf\u503c\u7279\u5f81\u518d\u751f\u6838Banach\u7a7a\u95f4\uff0c\u8bc1\u660e\u56fa\u5b9a\u67b6\u6784\u795e\u7ecf\u7f51\u7edc\u81ea\u7136\u8bf1\u5bfc\u6b64\u7c7b\u7a7a\u95f4\u7684\u7279\u6b8a\u5b9e\u4f8b\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u6838\u65b9\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u7edf\u4e00\u51fd\u6570\u7a7a\u95f4\u89c6\u89d2\uff0c\u9610\u660e\u4e86\u6838\u5b66\u4e60\u539f\u7406\u4f55\u65f6\u53ef\u4ee5\u6269\u5c55\u5230\u518d\u751f\u6838Hilbert\u7a7a\u95f4\u4e4b\u5916\u3002"}}
{"id": "2602.08435", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.08435", "abs": "https://arxiv.org/abs/2602.08435", "authors": ["Davide Tebaldi", "Roberto Zanasi"], "title": "An Approach for the Qualitative Graphical Representation of the Describing Function in Nonlinear Systems Stability Analysis", "comment": null, "summary": "The describing function method is a useful tool for the qualitative analysis of limit cycles in the stability analysis of nonlinear systems. This method is inherently approximate; therefore, it should be used for a fast qualitative analysis of the considered systems. However, plotting the exact describing function requires heavy mathematical calculations, reducing interest in this method especially from the point of view of control education. The objective of this paper is to enhance the describing function method by providing a new approach for the qualitative plotting of the describing function for piecewise nonlinearities involving discontinuities. Unlike the standard method, the proposed approach allows for a straightforward, hand-drawn plotting of the describing function using the rules introduced in this paper, simply by analyzing the shape of the nonlinearity. The proposed case studies show that the limit cycles estimation performed using the standard exact plotting of the describing function yields the same qualitative results as those obtained using the proposed qualitative method for plotting the describing function.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5206\u6bb5\u975e\u7ebf\u6027\u7cfb\u7edf\u63cf\u8ff0\u51fd\u6570\u5b9a\u6027\u7ed8\u56fe\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u590d\u6742\u8ba1\u7b97\u5373\u53ef\u624b\u7ed8\uff0c\u7b80\u5316\u63a7\u5236\u6559\u80b2\u4e2d\u7684\u7a33\u5b9a\u6027\u5206\u6790", "motivation": "\u4f20\u7edf\u63cf\u8ff0\u51fd\u6570\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u6570\u5b66\u8ba1\u7b97\uff0c\u964d\u4f4e\u4e86\u5176\u5728\u63a7\u5236\u6559\u80b2\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5305\u542b\u4e0d\u8fde\u7eed\u6027\u7684\u5206\u6bb5\u975e\u7ebf\u6027\u7cfb\u7edf", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u975e\u7ebf\u6027\u5f62\u72b6\u5206\u6790\u7684\u5b9a\u6027\u7ed8\u56fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u7b80\u5355\u89c4\u5219\u5b9e\u73b0\u63cf\u8ff0\u51fd\u6570\u7684\u624b\u7ed8\u7ed8\u5236\uff0c\u907f\u514d\u590d\u6742\u7684\u6570\u5b66\u8ba1\u7b97", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684\u5b9a\u6027\u65b9\u6cd5\u4e0e\u6807\u51c6\u7cbe\u786e\u7ed8\u56fe\u65b9\u6cd5\u5728\u6781\u9650\u73af\u4f30\u8ba1\u65b9\u9762\u5f97\u5230\u76f8\u540c\u7684\u5b9a\u6027\u7ed3\u679c", "conclusion": "\u65b0\u65b9\u6cd5\u7b80\u5316\u4e86\u63cf\u8ff0\u51fd\u6570\u5728\u5206\u6bb5\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u63a7\u5236\u6559\u80b2\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027"}}
{"id": "2602.08782", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08782", "abs": "https://arxiv.org/abs/2602.08782", "authors": ["Tommy Rochussen", "Vincent Fortuin"], "title": "Amortising Inference and Meta-Learning Priors in Neural Networks", "comment": "Accepted at ICLR 2026", "summary": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\text{ -- }$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where it is not clear how to represent beliefs about a prediction task by prior distributions over model parameters. Bridging the fields of Bayesian deep learning and probabilistic meta-learning, we introduce a way to $\\textit{learn}$ a weights prior from a collection of datasets by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u591a\u4e2a\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u6743\u91cd\u5148\u9a8c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u4e0e\u795e\u7ecf\u8fc7\u7a0b\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6ca1\u6709\u5148\u9a8c\u4fe1\u5ff5\u7684\u6311\u6218\u3002", "motivation": "\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u4e2d\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\u662f\uff1a\u5f53\u6ca1\u6709\u5148\u9a8c\u4fe1\u5ff5\u65f6\uff0c\u5982\u4f55\u5bf9\u6a21\u578b\u53c2\u6570\u8868\u793a\u5148\u9a8c\u5206\u5e03\uff1f\u4f20\u7edf\u8d1d\u53f6\u65af\u65b9\u6cd5\u9700\u8981\u5148\u9a8c\u5206\u5e03\u6765\u66f4\u65b0\u4fe1\u5ff5\uff0c\u4f46\u5728\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u5f88\u96be\u4e3a\u9884\u6d4b\u4efb\u52a1\u5b9a\u4e49\u5408\u9002\u7684\u53c2\u6570\u5148\u9a8c\u3002", "method": "\u7ed3\u5408\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u548c\u6982\u7387\u5143\u5b66\u4e60\uff0c\u63d0\u51fa\u4ece\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u6743\u91cd\u5148\u9a8c\u7684\u65b9\u6cd5\u3002\u6a21\u578b\u53ef\u89c6\u4e3a\u795e\u7ecf\u8fc7\u7a0b\uff0c\u5176\u6f5c\u53d8\u91cf\u662f\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u6743\u91cd\u96c6\uff0c\u89e3\u7801\u5668\u662f\u7531\u6f5c\u53d8\u91cf\u6837\u672c\u53c2\u6570\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u91c7\u7528\u6bcf\u6570\u636e\u96c6\u644a\u9500\u53d8\u5206\u63a8\u65ad\u6280\u672f\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\uff1a1\uff09\u5728\u826f\u597d\u6307\u5b9a\u7684\u5148\u9a8c\u4e0b\u7814\u7a76\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u884c\u4e3a\uff1b2\uff09\u5c06\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7528\u4f5c\u7075\u6d3b\u7684\u751f\u6210\u6a21\u578b\uff1b3\uff09\u5728\u795e\u7ecf\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e4b\u524d\u96be\u4ee5\u5b9e\u73b0\u7684\u529f\u80fd\uff0c\u5982\u4efb\u52a1\u5185\u5c0f\u6279\u91cf\u5904\u7406\u6216\u6781\u7aef\u6570\u636e\u7a00\u7f3a\u4e0b\u7684\u5143\u5b66\u4e60\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u4e0e\u795e\u7ecf\u8fc7\u7a0b\u6846\u67b6\u76f8\u7ed3\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5148\u9a8c\u5b9a\u4e49\u7684\u95ee\u9898\uff0c\u4e3a\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u8fdb\u884c\u5143\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u6269\u5c55\u4e86\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2602.08786", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08786", "abs": "https://arxiv.org/abs/2602.08786", "authors": ["Unai Fischer-Abaigar", "Emily Aiken", "Christoph Kern", "Juan Carlos Perdomo"], "title": "Empirically Understanding the Value of Prediction in Allocation", "comment": null, "summary": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u8bc1\u5de5\u5177\u5305\uff0c\u5e2e\u52a9\u89c4\u5212\u8005\u91cf\u5316\u9884\u6d4b\u6295\u8d44\u4e0e\u5176\u4ed6\u653f\u7b56\u6760\u6746\uff08\u5982\u6269\u5927\u5bb9\u91cf\u548c\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\uff09\u76f8\u6bd4\u7684\u798f\u5229\u5f71\u54cd\uff0c\u5e76\u5728\u5fb7\u56fd\u5c31\u4e1a\u670d\u52a1\u548c\u57c3\u585e\u4fc4\u6bd4\u4e9a\u8d2b\u56f0\u76ee\u6807\u5b9a\u4f4d\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u5e94\u7528\u3002", "motivation": "\u673a\u6784\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u9884\u6d4b\u6765\u5206\u914d\u7a00\u7f3a\u8d44\u6e90\u3002\u4ece\u8bbe\u8ba1\u89d2\u5ea6\u770b\uff0c\u66f4\u597d\u7684\u9884\u6d4b\u4e0e\u5176\u4ed6\u6295\u8d44\uff08\u5982\u6269\u5927\u5bb9\u91cf\u6216\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\uff09\u5b58\u5728\u7ade\u4e89\u3002\u6838\u5fc3\u95ee\u9898\u4e0d\u662f\u5982\u4f55\u89e3\u51b3\u7279\u5b9a\u7684\u5206\u914d\u95ee\u9898\uff0c\u800c\u662f\u5e94\u8be5\u89e3\u51b3\u54ea\u4e2a\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u8bc1\u5de5\u5177\u5305\uff08rvp\u8f6f\u4ef6\u5de5\u5177\u5305\uff09\uff0c\u5e2e\u52a9\u89c4\u5212\u8005\u5f62\u6210\u539f\u5219\u6027\u7b54\u6848\uff0c\u91cf\u5316\u9884\u6d4b\u6295\u8d44\u4e0e\u5176\u4ed6\u653f\u7b56\u6760\u6746\u76f8\u6bd4\u7684\u798f\u5229\u5f71\u54cd\u3002\u5728\u5fb7\u56fd\u5c31\u4e1a\u670d\u52a1\u548c\u57c3\u585e\u4fc4\u6bd4\u4e9a\u8d2b\u56f0\u76ee\u6807\u5b9a\u4f4d\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\u3002", "result": "\u51b3\u7b56\u8005\u53ef\u4ee5\u53ef\u9760\u5730\u5f97\u51fa\u5173\u4e8e\u9884\u6d4b\u5728\u5176\u5206\u914d\u95ee\u9898\u4e2d\u76f8\u5bf9\u4ef7\u503c\u7684\u60c5\u5883\u7279\u5b9a\u7ed3\u8bba\u3002\u63d0\u4f9b\u4e86\u8f6f\u4ef6\u5de5\u5177\u5305rvp\u548c\u90e8\u5206\u6570\u636e\uff0c\u4ee5\u652f\u6301\u8be5\u9886\u57df\u7684\u672a\u6765\u5b9e\u8bc1\u5de5\u4f5c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u8bc1\u6846\u67b6\u548c\u5de5\u5177\u5305\uff0c\u5e2e\u52a9\u51b3\u7b56\u8005\u5728\u8d44\u6e90\u5206\u914d\u95ee\u9898\u4e2d\u91cf\u5316\u9884\u6d4b\u6295\u8d44\u7684\u76f8\u5bf9\u4ef7\u503c\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u9884\u6d4b\u3001\u6269\u5927\u5bb9\u91cf\u548c\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\u7b49\u4e0d\u540c\u653f\u7b56\u6760\u6746\u4e4b\u95f4\u505a\u51fa\u660e\u667a\u9009\u62e9\u3002"}}
{"id": "2602.07844", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07844", "abs": "https://arxiv.org/abs/2602.07844", "authors": ["Chunfeng Cui", "Liqun Qi", "Yi Xu"], "title": "Biquadratic SOS Rank: Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms", "comment": null, "summary": "We prove that every $3 \\times 3$ sum-of-squares (SOS) biquadratic form can be expressed as the sum of at most \\textbf{six} squares of bilinear forms, establishing $\\mathrm{BSR}(3,3) = 6$. We also determine the exact SOS rank for $4 \\times 3$ biquadratic forms: $\\mathrm{BSR}(4,3)=7$. These results fit the pattern $\\mathrm{BSR}(m,n)=m+n$, leading to the conjecture that this linear formula holds for all $m,n \\ge 3$. Furthermore, we extend our geometric-analytic method to general dimensions and show that for any integers $m,n \\ge 2$ with $(m,n)\\neq(2,2)$, every $m \\times n$ SOS biquadratic form is a sum of at most $mn-2$ squares, improving the general upper bound of $mn-1$ established in earlier work. For the $3 \\times 3$ case, we provide a complete geometric analysis of the SOS cone structure, and for general dimensions we establish a systematic framework that applies to all $m \\times n$ biquadratic forms except the degenerate $(2,2)$ case.\n  We note that the lower bound of 6 for $3 \\times 3$ forms is achieved by a simple biquadratic form, and for general $m,n\\ge 3$, it is known that the maximum SOS rank is at least $m+n$. Our results establish new upper bounds and significantly reduce the gap between the lower and upper bounds for the worst-case SOS rank of biquadratic forms across all dimensions.", "AI": {"tldr": "\u8bc1\u660e\u4e863\u00d73\u53cc\u4e8c\u6b21\u5f62\u5f0f\u7684\u5e73\u65b9\u548c\u79e9\u4e3a6\uff0c4\u00d73\u60c5\u51b5\u4e3a7\uff0c\u63d0\u51fa\u4e86\u5bf9\u6240\u6709m,n\u22653\u7684\u7ebf\u6027\u516c\u5f0f\u731c\u60f3\uff0c\u5e76\u6539\u8fdb\u4e86mn-2\u7684\u4e00\u822c\u4e0a\u754c\u3002", "motivation": "\u7814\u7a76\u53cc\u4e8c\u6b21\u5f62\u5f0f\u7684\u5e73\u65b9\u548c(SOS)\u79e9\uff0c\u7279\u522b\u662f\u786e\u5b9a\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6700\u5c0f\u5e73\u65b9\u6570\uff0c\u8fd9\u662f\u4ee3\u6570\u51e0\u4f55\u548c\u4f18\u5316\u4e2d\u7684\u91cd\u8981\u95ee\u9898\u3002", "method": "\u91c7\u7528\u51e0\u4f55-\u5206\u6790\u65b9\u6cd5\uff0c\u5bf93\u00d73\u60c5\u51b5\u63d0\u4f9b\u5b8c\u6574\u7684\u51e0\u4f55\u5206\u6790\uff0c\u5bf9\u4e00\u822c\u7ef4\u5ea6\u5efa\u7acb\u7cfb\u7edf\u6846\u67b6\uff0c\u5e76\u6784\u9020\u5177\u4f53\u4f8b\u5b50\u8bc1\u660e\u4e0b\u754c\u3002", "result": "\u786e\u5b9a\u4e86BSR(3,3)=6\u548cBSR(4,3)=7\uff0c\u63d0\u51fa\u4e86\u5bf9\u6240\u6709m,n\u22653\u7684BSR(m,n)=m+n\u731c\u60f3\uff0c\u5c06\u4e00\u822c\u4e0a\u754c\u6539\u8fdb\u4e3amn-2\u3002", "conclusion": "\u8be5\u7814\u7a76\u663e\u8457\u7f29\u5c0f\u4e86\u53cc\u4e8c\u6b21\u5f62\u5f0fSOS\u79e9\u7684\u4e0a\u4e0b\u754c\u5dee\u8ddd\uff0c\u4e3a\u7406\u89e3\u8fd9\u7c7b\u4ee3\u6570\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5177\u4f53\u7ed3\u679c\u3002"}}
{"id": "2602.07374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07374", "abs": "https://arxiv.org/abs/2602.07374", "authors": ["Nisharg Nargund", "Priyesh Shukla"], "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling", "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.", "AI": {"tldr": "TernaryLM\uff1a\u4e00\u79cd\u539f\u751f1\u4f4d\u4e09\u5143\u91cf\u5316\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002\u73b0\u6709\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u635f\u5931\u95ee\u9898\u3002", "method": "\u63d0\u51faTernaryLM\uff0c\u4f7f\u7528\u539f\u751f1\u4f4d\u4e09\u5143\u91cf\u5316{-1, 0, +1}\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u611f\u77e5\u8868\u793a\uff0c\u91c7\u7528\u76f4\u901a\u4f30\u8ba1\u5668\u548c\u81ea\u9002\u5e94\u9010\u5c42\u7f29\u653e\u56e0\u5b50\u3002", "result": "\u5728TinyStories\u4e0a\u9a8c\u8bc1\u56f0\u60d1\u5ea6\u4e3a58.42\uff1b\u5728MRPC\u590d\u8ff0\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u523082.47% F1\u5206\u6570\uff1b\u5185\u5b58\u51cf\u5c112.4\u500d\uff08498MB vs 1197MB\uff09\uff1b\u8bad\u7ec3\u8fc7\u7a0b\u7a33\u5b9a\u3002", "conclusion": "\u539f\u751f1\u4f4d\u8bad\u7ec3\u662f\u9ad8\u6548\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u7684\u6709\u524d\u666f\u65b9\u5411\uff0c\u4e2d\u95f4transformer\u5c42\u5bf9\u6781\u7aef\u91cf\u5316\u517c\u5bb9\u6027\u6700\u9ad8\uff0c\u4e3a\u672a\u6765\u975e\u5747\u5300\u7cbe\u5ea6\u7b56\u7565\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2602.07308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07308", "abs": "https://arxiv.org/abs/2602.07308", "authors": ["Sutapa Dey Tithi", "Nazia Alam", "Tahreem Yasir", "Yang Shi", "Xiaoyi Tian", "Min Chi", "Tiffany Barnes"], "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System", "comment": null, "summary": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4e24\u79cdICAP\u6a21\u5f0f\uff08\u4e3b\u52a8\u5f0f\u5f15\u5bfc\u793a\u4f8b\u548c\u5efa\u6784\u5f0f\u9519\u8bef\u793a\u4f8b\uff09\u6765\u652f\u67b6\u8ba4\u77e5\u53c2\u4e0e\uff0c\u6bd4\u8f83BKT\u548cDRL\u4e24\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u903b\u8f91ITS\u4e2d\u7684\u6548\u679c\u3002", "motivation": "ICAP\u6846\u67b6\u5b9a\u4e49\u4e86\u56db\u79cd\u8ba4\u77e5\u53c2\u4e0e\u6c34\u5e73\uff0c\u4f46\u4e2a\u6027\u5316\u5b66\u4e60\u6d3b\u52a8\u4ee5\u5f15\u53d1\u6700\u4f73\u8ba4\u77e5\u53c2\u4e0e\u6c34\u5e73\u4ecd\u7136\u662f\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\uff08ITS\uff09\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4e24\u79cdICAP\u6a21\u5f0f\u7684\u5de5\u4f5c\u793a\u4f8b\uff08\u4e3b\u52a8\u5f0f\u5f15\u5bfc\u793a\u4f8b\u548c\u5efa\u6784\u5f0f\u9519\u8bef\u793a\u4f8b\uff09\uff0c\u6bd4\u8f83\u4e86\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\uff08BKT\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4f5c\u4e3a\u81ea\u9002\u5e94\u65b9\u6cd5\u4e0e\u975e\u81ea\u9002\u5e94\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "113\u540d\u5b66\u751f\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u81ea\u9002\u5e94\u7b56\u7565\u90fd\u663e\u8457\u63d0\u9ad8\u4e86\u5b66\u751f\u5728\u6d4b\u8bd5\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002BKT\u5bf9\u4f4e\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u7684\u540e\u6d4b\u6210\u7ee9\u63d0\u5347\u6700\u5927\uff0c\u5e2e\u52a9\u4ed6\u4eec\u8d76\u4e0a\u9ad8\u5148\u9a8c\u77e5\u8bc6\u540c\u4f34\uff1b\u800cDRL\u5728\u9ad8\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u4e2d\u4ea7\u751f\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u540e\u6d4b\u6210\u7ee9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8ba4\u77e5\u53c2\u4e0e\u548c\u9002\u5e94\u6027\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u5b66\u4e60\u6210\u679c\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.07144", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07144", "abs": "https://arxiv.org/abs/2602.07144", "authors": ["Samuel Daulton", "David Eriksson", "Maximilian Balandat", "Eytan Bakshy"], "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability", "comment": "26 pages", "summary": "Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search space. This makes it difficult to distinguish between important and spurious changes and increases the burden of vetting recommendations when the optimization objective omits relevant operational considerations. We introduce BONSAI, a default-aware BO policy that prunes low-impact deviations from a default configuration while explicitly controlling the loss in acquisition value. BONSAI is compatible with a variety of acquisition functions, including expected improvement and upper confidence bound (GP-UCB). We theoretically bound the regret incurred by BONSAI, showing that, under certain conditions, it enjoys the same no-regret property as vanilla GP-UCB. Across many real-world applications, we empirically find that BONSAI substantially reduces the number of non-default parameters in recommended configurations while maintaining competitive optimization performance, with little effect on wall time.", "AI": {"tldr": "BONSAI\u662f\u4e00\u79cd\u9ed8\u8ba4\u611f\u77e5\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u5bf9\u9ed8\u8ba4\u914d\u7f6e\u7684\u504f\u79bb\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6709\u7cbe\u5fc3\u8bbe\u8ba1\u9ed8\u8ba4\u914d\u7f6e\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u53c2\u6570\u901a\u5e38\u6709\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9ed8\u8ba4\u914d\u7f6e\uff0c\u5b9e\u8df5\u8005\u53ea\u5e0c\u671b\u5728\u5fc5\u8981\u65f6\u624d\u504f\u79bb\u9ed8\u8ba4\u503c\u3002\u4f46\u6807\u51c6\u8d1d\u53f6\u65af\u4f18\u5316\u4e0d\u65e8\u5728\u6700\u5c0f\u5316\u5bf9\u9ed8\u8ba4\u503c\u7684\u504f\u79bb\uff0c\u7ecf\u5e38\u5c06\u5f31\u76f8\u5173\u53c2\u6570\u63a8\u5230\u641c\u7d22\u7a7a\u95f4\u8fb9\u754c\uff0c\u8fd9\u589e\u52a0\u4e86\u5ba1\u67e5\u63a8\u8350\u914d\u7f6e\u7684\u8d1f\u62c5\u3002", "method": "BONSAI\u662f\u4e00\u79cd\u9ed8\u8ba4\u611f\u77e5\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u4fee\u526a\u5bf9\u9ed8\u8ba4\u914d\u7f6e\u7684\u4f4e\u5f71\u54cd\u504f\u79bb\uff0c\u540c\u65f6\u660e\u786e\u63a7\u5236\u83b7\u53d6\u51fd\u6570\u503c\u7684\u635f\u5931\u3002\u8be5\u65b9\u6cd5\u517c\u5bb9\u591a\u79cd\u83b7\u53d6\u51fd\u6570\uff0c\u5305\u62ec\u671f\u671b\u6539\u8fdb\u548c\u4e0a\u7f6e\u4fe1\u754c\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\uff0cBONSAI\u4eab\u6709\u4e0e\u6807\u51c6GP-UCB\u76f8\u540c\u7684\u65e0\u9057\u61be\u7279\u6027\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cBONSAI\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u8350\u914d\u7f6e\u4e2d\u7684\u975e\u9ed8\u8ba4\u53c2\u6570\u6570\u91cf\uff0c\u5bf9\u8fd0\u884c\u65f6\u95f4\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "BONSAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u53c2\u6570\u504f\u79bb\uff0c\u4f7f\u63a8\u8350\u914d\u7f6e\u66f4\u5bb9\u6613\u88ab\u5b9e\u8df5\u8005\u5ba1\u67e5\u548c\u91c7\u7528\u3002"}}
{"id": "2602.08477", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08477", "abs": "https://arxiv.org/abs/2602.08477", "authors": ["Akbar Anbar Jafari", "Gholamreza Anbarjafari"], "title": "A Multi-physics Simulation Framework for High-power Microwave Counter-unmanned Aerial System Design and Performance Evaluation", "comment": "17 pages, 15 figures", "summary": "The proliferation of small unmanned aerial systems (sUAS) operating under autonomous guidance has created an urgent need for non-kinetic neutralization methods that are immune to conventional radio-frequency jamming. This paper presents a comprehensive multi-physics simulation framework for the design and performance evaluation of a high-power microwave (HPM) counter-UAS system operating at 2.45\\,GHz. The framework integrates electromagnetic propagation modelling, antenna pattern analysis, electromagnetic coupling to unshielded drone wiring harnesses, and a sigmoid-based semiconductor damage probability model calibrated to published CMOS latchup thresholds. A 10{,}000-trial Monte Carlo analysis incorporating stochastic variations in transmitter power, antenna pointing error, target wire orientation, polarization mismatch, and component damage thresholds yields system-level kill probabilities with 95\\% confidence intervals. For a baseline configuration of 25\\,kW continuous-wave power and a 60\\,cm parabolic reflector (21.2\\,dBi gain), the Monte Carlo simulation predicts a kill probability of $51.4\\pm1.0$\\% at 20\\,m, decreasing to $13.1\\pm0.7$\\% at 40\\,m. Pulsed operation at 500\\,kW peak power (1\\% duty cycle) extends the 90\\% kill range from approximately 18\\,m to 88\\,m. The framework further provides parametric design maps, safety exclusion zone calculations compliant with ICNIRP 2020 guidelines, thermal management requirements, and waveguide mode analysis. All simulation codes and results are provided for full reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u7269\u7406\u573a\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1\u548c\u8bc4\u4f302.45GHz\u9ad8\u529f\u7387\u5fae\u6ce2\u53cd\u65e0\u4eba\u673a\u7cfb\u7edf\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u5206\u6790\u9884\u6d4b\u4e0d\u540c\u8ddd\u79bb\u4e0b\u7684\u6740\u4f24\u6982\u7387", "motivation": "\u5c0f\u578b\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u6fc0\u589e\u548c\u81ea\u4e3b\u5bfc\u822a\u7684\u666e\u53ca\uff0c\u8feb\u5207\u9700\u8981\u4e0d\u53d7\u4f20\u7edf\u5c04\u9891\u5e72\u6270\u5f71\u54cd\u7684\u975e\u52a8\u80fd\u4e2d\u548c\u65b9\u6cd5", "method": "\u96c6\u6210\u7535\u78c1\u4f20\u64ad\u5efa\u6a21\u3001\u5929\u7ebf\u6a21\u5f0f\u5206\u6790\u3001\u7535\u78c1\u8026\u5408\u5230\u65e0\u4eba\u673a\u7ebf\u675f\u3001\u57fa\u4e8eS\u578b\u51fd\u6570\u7684\u534a\u5bfc\u4f53\u635f\u4f24\u6982\u7387\u6a21\u578b\uff0c\u5e76\u8fdb\u884c10,000\u6b21\u8499\u7279\u5361\u6d1b\u5206\u6790", "result": "25kW\u8fde\u7eed\u6ce2\u529f\u7387\u572820\u7c73\u5904\u6740\u4f24\u6982\u7387\u4e3a51.4\u00b11.0%\uff0c40\u7c73\u5904\u964d\u81f313.1\u00b10.7%\uff1b500kW\u8109\u51b2\u529f\u7387\u53ef\u5c0690%\u6740\u4f24\u8303\u56f4\u4ece18\u7c73\u6269\u5c55\u523088\u7c73", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u529f\u7387\u5fae\u6ce2\u53cd\u65e0\u4eba\u673a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u5b89\u5168\u5206\u6790\u5de5\u5177\uff0c\u6240\u6709\u4eff\u771f\u4ee3\u7801\u548c\u7ed3\u679c\u90fd\u53ef\u590d\u73b0"}}
{"id": "2602.08849", "categories": ["stat.ML", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.08849", "abs": "https://arxiv.org/abs/2602.08849", "authors": ["Terry C. W. Lam", "Niamh O'Neill", "Christoph Schran", "Lars L. Schaaf"], "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials", "comment": "12 pages, 6 figures", "summary": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\uff0c\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u8ddf\u8e2a\u635f\u5931\u5206\u5e03\uff0c\u81ea\u52a8\u964d\u4f4e\u566a\u58f0\u6837\u672c\u6743\u91cd\uff0c\u65e0\u9700\u989d\u5916\u53c2\u8003\u8ba1\u7b97\uff0c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u7684\u51c6\u786e\u6027\u53d7\u5230\u5305\u542b\u6570\u503c\u566a\u58f0\u7684\u53c2\u8003\u6570\u636e\u5f71\u54cd\uff0c\u8fd9\u4e9b\u566a\u58f0\u901a\u5e38\u6765\u81ea\u672a\u6536\u655b\u6216\u4e0d\u4e00\u81f4\u7684\u7535\u5b50\u7ed3\u6784\u8ba1\u7b97\u3002\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u5de5\u4f5c\u6216\u591a\u8f6e\u6602\u8d35\u91cd\u8bad\u7ec3\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u578b\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165\u5728\u7ebf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\uff0c\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u8ddf\u8e2a\u635f\u5931\u5206\u5e03\uff0c\u5728\u5355\u6b21\u8bad\u7ec3\u8fd0\u884c\u4e2d\u81ea\u52a8\u8bc6\u522b\u5f02\u5e38\u6837\u672c\u5e76\u964d\u4f4e\u5176\u6743\u91cd\uff0c\u65e0\u9700\u989d\u5916\u53c2\u8003\u8ba1\u7b97\u3002", "result": "\u8be5\u65b9\u6cd5\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u6027\u80fd\u4e0e\u8fed\u4ee3\u7ec6\u5316\u57fa\u51c6\u76f8\u5f53\u4f46\u5f00\u9500\u663e\u8457\u964d\u4f4e\u3002\u6210\u529f\u4ece\u672a\u6536\u655b\u53c2\u8003\u6570\u636e\u4e2d\u6062\u590d\u6db2\u6001\u6c34\u7684\u51c6\u786e\u7269\u7406\u89c2\u6d4b\u503c\uff08\u5305\u62ec\u6269\u6563\u7cfb\u6570\uff09\uff0c\u5728SPICE\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6709\u673a\u5316\u5b66\u57fa\u7840\u6a21\u578b\u65f6\u80fd\u5c06\u80fd\u91cf\u8bef\u5dee\u964d\u4f4e\u4e09\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u4e0d\u5b8c\u7f8e\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u9c81\u68d2\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08997", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08997", "abs": "https://arxiv.org/abs/2602.08997", "authors": ["Lavender Y. Jiang", "Xujin Chris Liu", "Kyunghyun Cho", "Eric K. Oermann"], "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs", "comment": null, "summary": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.", "AI": {"tldr": "HIPAA Safe Harbor\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5\u5728\u73b0\u4ee3LLM\u65f6\u4ee3\u5df2\u5931\u6548\uff0c\u56e0\u4e3aLLM\u80fd\u4ece\u4e34\u5e8a\u7b14\u8bb0\u7684\u6f5c\u5728\u5173\u8054\u4e2d\u91cd\u65b0\u8bc6\u522b\u60a3\u8005\u8eab\u4efd\uff0c\u5373\u4f7f\u79fb\u9664\u6240\u6709\u663e\u5f0f\u6807\u8bc6\u7b26\u4e5f\u65e0\u6cd5\u4fdd\u62a4\u9690\u79c1", "motivation": "HIPAA Safe Harbor\u53bb\u6807\u8bc6\u5316\u6807\u51c6\u8bbe\u8ba1\u4e8e\u5206\u7c7b\u8868\u683c\u6570\u636e\u65f6\u4ee3\uff0c\u65e0\u6cd5\u5e94\u5bf9\u73b0\u4ee3LLM\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u6316\u6398\u6f5c\u5728\u8eab\u4efd\u5173\u8054\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u8fd9\u5a01\u80c1\u5230\u60a3\u8005\u9690\u79c1\u548c\u533b\u60a3\u4fe1\u4efb", "method": "1) \u4f7f\u7528\u56e0\u679c\u56fe\u5f62\u5f0f\u5316\u8eab\u4efd\u4e0e\u51c6\u6807\u8bc6\u7b26\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff1b2) \u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u4ece\u53bb\u6807\u8bc6\u5316\u7b14\u8bb0\u4e2d\u91cd\u65b0\u8bc6\u522b\u60a3\u8005\uff1b3) \u8fdb\u884c\u8bca\u65ad\u6d88\u878d\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4ec5\u51ed\u8bca\u65ad\u4fe1\u606f\u5c31\u80fd\u9884\u6d4b\u60a3\u8005\u5c45\u4f4f\u5730", "result": "\u73b0\u4ee3LLM\u80fd\u591f\u4ece\u53bb\u6807\u8bc6\u5316\u7684\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u91cd\u65b0\u8bc6\u522b\u60a3\u8005\u8eab\u4efd\uff0c\u5373\u4f7f\u79fb\u9664\u6240\u6709\u5176\u4ed6\u4fe1\u606f\uff0c\u4ec5\u51ed\u8bca\u65ad\u4fe1\u606f\u4e5f\u80fd\u9884\u6d4b\u60a3\u8005\u5c45\u4f4f\u5730\uff0c\u8bc1\u660e\u5f53\u524d\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u7f3a\u9677", "conclusion": "\u53bb\u6807\u8bc6\u5316\u672c\u8d28\u4e0a\u662f\u4e0d\u5b8c\u5584\u7684\uff0c\u9700\u8981\u793e\u533a\u5171\u540c\u884c\u52a8\u6765\u7ef4\u62a4\u533b\u60a3\u4fe1\u4efb\uff0c\u8bba\u6587\u65e8\u5728\u63d0\u9ad8\u610f\u8bc6\u5e76\u8ba8\u8bba\u53ef\u884c\u7684\u6539\u8fdb\u5efa\u8bae"}}
{"id": "2602.07851", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07851", "abs": "https://arxiv.org/abs/2602.07851", "authors": ["Regina S. Burachik", "Bethany I. Caldwell", "C. Yal\u00e7\u0131n Kaya", "Walaa M. Moursi"], "title": "Best Approximation Optimal Control for Infeasible Double Integrator and Douglas--Rachford Algorithm", "comment": null, "summary": "We consider the problem of finding (in some sense) the best approximation control for an infeasible double integrator. The control function is constrained by upper and lower bounds that are too tight and thus cause infeasibility. The infeasibility is characterized by a gap function (representing the separation between two constraint sets) whose squared ${\\cal L}^2$-norm is to be minimized to find the best approximation control solution. First, we review the existing results for problems involving a general linear control system. Then, for the infeasible double integrator problem, we present an analytical solution for the bang--bang control with at most one switching. The infinite-dimensional optimization problem is reduced to the problem of solving two algebraic equations in two variables, to compute the switching time and gap function. We discuss numerical approaches to solving the system of equations. Finally, we describe the (relaxed) Douglas--Rachford algorithm for the double integrator problem and carry out numerical experiments to illustrate the implementation of the algorithm and test performance.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u53ef\u884c\u53cc\u79ef\u5206\u5668\u7684\u6700\u4f73\u903c\u8fd1\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u95f4\u9699\u51fd\u6570\u7684\u5e73\u65b9L2\u8303\u6570\u6765\u627e\u5230\u6700\u4f73\u903c\u8fd1\u63a7\u5236\u89e3", "motivation": "\u53cc\u79ef\u5206\u5668\u63a7\u5236\u95ee\u9898\u4e2d\uff0c\u63a7\u5236\u51fd\u6570\u7684\u4e0a\u4e0b\u754c\u7ea6\u675f\u8fc7\u7d27\u5bfc\u81f4\u4e0d\u53ef\u884c\u6027\uff0c\u9700\u8981\u627e\u5230\u5728\u67d0\u79cd\u610f\u4e49\u4e0a\u7684\u6700\u4f73\u903c\u8fd1\u63a7\u5236", "method": "\u9996\u5148\u56de\u987e\u4e00\u822c\u7ebf\u6027\u63a7\u5236\u7cfb\u7edf\u95ee\u9898\u7684\u73b0\u6709\u7ed3\u679c\uff0c\u7136\u540e\u9488\u5bf9\u4e0d\u53ef\u884c\u53cc\u79ef\u5206\u5668\u95ee\u9898\uff0c\u63d0\u51fa\u6700\u591a\u4e00\u6b21\u5207\u6362\u7684bang-bang\u63a7\u5236\u7684\u89e3\u6790\u89e3\uff0c\u5c06\u65e0\u9650\u7ef4\u4f18\u5316\u95ee\u9898\u7b80\u5316\u4e3a\u6c42\u89e3\u4e24\u4e2a\u4ee3\u6570\u65b9\u7a0b\uff0c\u5e76\u8ba8\u8bba\u6570\u503c\u6c42\u89e3\u65b9\u6cd5\uff0c\u6700\u540e\u63cf\u8ff0\u53cc\u79ef\u5206\u5668\u95ee\u9898\u7684Douglas-Rachford\u7b97\u6cd5\u5e76\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c", "result": "\u4e3a\u4e0d\u53ef\u884c\u53cc\u79ef\u5206\u5668\u95ee\u9898\u63d0\u4f9b\u4e86bang-bang\u63a7\u5236\u7684\u89e3\u6790\u89e3\uff0c\u5c06\u65e0\u9650\u7ef4\u4f18\u5316\u95ee\u9898\u7b80\u5316\u4e3a\u4e24\u4e2a\u53d8\u91cf\u7684\u4ee3\u6570\u65b9\u7a0b\u7ec4\uff0c\u5e76\u5b9e\u73b0\u4e86Douglas-Rachford\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u6c42\u89e3", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7ea6\u675f\u8fc7\u7d27\u5bfc\u81f4\u4e0d\u53ef\u884c\u7684\u53cc\u79ef\u5206\u5668\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u903c\u8fd1\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u89e3\u6790\u65b9\u6cd5\u548c\u6570\u503c\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u89e3\u51b3\u4e86\u8fd9\u4e00\u5177\u6709\u6311\u6218\u6027\u7684\u63a7\u5236\u95ee\u9898"}}
{"id": "2602.07375", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07375", "abs": "https://arxiv.org/abs/2602.07375", "authors": ["Peiqi Yu", "Jinhao Wang", "Xinyi Sui", "Nam Ling", "Wei Wang", "Wei Jiang"], "title": "Efficient Post-Training Pruning of Large Language Models with Statistical Correction", "comment": "11 pages, 2 figures, 5 tables", "summary": "Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e00\u9636\u7edf\u8ba1\u7279\u6027\u7684\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u901a\u9053\u7edf\u8ba1\u6821\u51c6\u91cd\u8981\u6027\u5206\u6570\u548c\u80fd\u91cf\u8865\u507f\u6821\u6b63\u5206\u5e03\u5931\u771f\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u6216\u4e8c\u9636\u4fe1\u606f", "motivation": "\u73b0\u6709\u540e\u8bad\u7ec3\u526a\u679d\u65b9\u6cd5\u5728\u526a\u679d\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1a\u542f\u53d1\u5f0f\u65b9\u6cd5\u9ad8\u6548\u4f46\u5bf9\u6fc0\u6d3b\u5f02\u5e38\u503c\u654f\u611f\uff0c\u57fa\u4e8e\u91cd\u6784\u7684\u65b9\u6cd5\u4fdd\u771f\u5ea6\u9ad8\u4f46\u8ba1\u7b97\u91cf\u5927", "method": "\u57fa\u4e8e\u6a21\u578b\u6743\u91cd\u548c\u6fc0\u6d3b\u7684\u4e00\u9636\u7edf\u8ba1\u7279\u6027\uff1a\u526a\u679d\u65f6\u4f7f\u7528\u901a\u9053\u7edf\u8ba1\u6821\u51c6\u57fa\u4e8e\u5e45\u503c\u7684\u91cd\u8981\u6027\u5206\u6570\uff0c\u51cf\u5c11\u6fc0\u6d3b\u4e3b\u5bfc\u901a\u9053\u7684\u504f\u5dee\uff1b\u526a\u679d\u540e\u5e94\u7528\u89e3\u6790\u80fd\u91cf\u8865\u507f\u6821\u6b63\u6743\u91cd\u79fb\u9664\u5f15\u8d77\u7684\u5206\u5e03\u5931\u771f", "result": "\u5728\u591a\u4e2aLLM\u5bb6\u65cf\u3001\u7a00\u758f\u6a21\u5f0f\u548c\u8bc4\u4f30\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u526a\u679d\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u8ba1\u7b97\u6210\u672c", "conclusion": "\u7b80\u5355\u7684\u7edf\u8ba1\u6821\u6b63\u5bf9\u4e8eLLM\u7684\u540e\u8bad\u7ec3\u526a\u679d\u662f\u6709\u6548\u7684\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u3001\u68af\u5ea6\u6216\u4e8c\u9636\u4fe1\u606f"}}
{"id": "2602.07339", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07339", "abs": "https://arxiv.org/abs/2602.07339", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving", "comment": null, "summary": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.", "AI": {"tldr": "RAPiD\uff1a\u4e00\u79cd\u786e\u5b9a\u6027\u7b56\u7565\u63d0\u53d6\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u7b56\u7565\uff0c\u6d88\u9664\u6269\u6563\u91c7\u6837\uff0c\u5b9e\u73b08\u500d\u52a0\u901f\u548cSOTA\u6cdb\u5316\u6027\u80fd", "motivation": "\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u80fd\u5efa\u6a21\u4eba\u7c7b\u9a7e\u9a76\u7684\u591a\u6a21\u6001\u884c\u4e3a\uff0c\u4f46\u5176\u4f9d\u8d56\u8fed\u4ee3\u968f\u673a\u91c7\u6837\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u5b89\u5168\u5173\u952e\u90e8\u7f72\u7684\u9700\u6c42", "method": "\u4f7f\u7528\u5206\u6570\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u89c4\u5212\u5668\u7684\u8bc4\u5206\u51fd\u6570\u4f5c\u4e3a\u884c\u4e3a\u5148\u9a8c\uff1b\u901a\u8fc7\u6a21\u4eff\u9884\u6d4b\u9a7e\u9a76\u5458\u63a7\u5236\u5668\u7684\u8bc4\u8bba\u5bb6\u63d0\u4f9b\u5bc6\u96c6\u5b89\u5168\u76d1\u7763", "result": "\u5728nuPlan\u573a\u666f\u4e2d\u5b9e\u73b0\u4e0e\u6269\u6563\u57fa\u7ebf\u7ade\u4e89\u7684\u6027\u80fd\uff0c8\u500d\u52a0\u901f\uff1b\u5728interPlan\u57fa\u51c6\u4e0a\u8fbe\u5230\u5b66\u4e60\u578b\u89c4\u5212\u5668\u7684SOTA\u6cdb\u5316\u6027\u80fd", "conclusion": "RAPiD\u6210\u529f\u5c06\u6269\u6563\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u786e\u5b9a\u6027\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u6ee1\u8db3\u81ea\u52a8\u9a7e\u9a76\u5b9e\u65f6\u90e8\u7f72\u9700\u6c42"}}
{"id": "2602.07145", "categories": ["cs.LG", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07145", "abs": "https://arxiv.org/abs/2602.07145", "authors": ["Zhiqi Bu", "Shiyun Xu", "Jialin Mao"], "title": "Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate", "comment": "Part of a planned series to understand and leverage the convexity in deep learning. Accepted to ICLR 2026", "summary": "Deep learning has non-convex loss landscape and its optimization dynamics is hard to analyze or control. Nevertheless, the dynamics can be empirically convex-like across various tasks, models, optimizers, hyperparameters, etc. In this work, we examine the applicability of convexity and Lipschitz continuity in deep learning, in order to precisely control the loss dynamics via the learning rate schedules. We illustrate that deep learning quickly becomes weakly convex after a short period of training, and the loss is predicable by an upper bound on the last iterate, which further informs the scaling of optimal learning rate. Through the lens of convexity, we build scaling laws of learning rates and losses that extrapolate as much as 80X across training horizons and 70X across model sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5b66\u4e60\u635f\u5931\u51fd\u6570\u7684\u51f8\u6027\u548cLipschitz\u8fde\u7eed\u6027\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u540e\u5f88\u5feb\u53d8\u5f97\u5f31\u51f8\uff0c\u5e76\u57fa\u4e8e\u6b64\u5efa\u7acb\u4e86\u5b66\u4e60\u7387\u548c\u635f\u5931\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u80fd\u591f\u8de8\u8bad\u7ec3\u65f6\u95f4\u548c\u6a21\u578b\u89c4\u6a21\u8fdb\u884c80X\u548c70X\u7684\u5916\u63a8\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5177\u6709\u975e\u51f8\u635f\u5931\u666f\u89c2\uff0c\u5176\u4f18\u5316\u52a8\u6001\u96be\u4ee5\u5206\u6790\u6216\u63a7\u5236\u3002\u7136\u800c\uff0c\u7ecf\u9a8c\u4e0a\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u5728\u5404\u79cd\u4efb\u52a1\u3001\u6a21\u578b\u3001\u4f18\u5316\u5668\u7b49\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u7c7b\u4f3c\u51f8\u6027\u7684\u52a8\u6001\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u51f8\u6027\u548cLipschitz\u8fde\u7eed\u6027\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5\u901a\u8fc7\u5b66\u4e60\u7387\u8c03\u5ea6\u7cbe\u786e\u63a7\u5236\u635f\u5931\u52a8\u6001\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u51f8\u6027\u7279\u5f81\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u5728\u77ed\u671f\u8bad\u7ec3\u540e\u5f88\u5feb\u53d8\u5f97\u5f31\u51f8\u3002\u5229\u7528\u51f8\u6027\u89c6\u89d2\uff0c\u5efa\u7acb\u5b66\u4e60\u7387\u548c\u635f\u5931\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u57fa\u4e8e\u6700\u540e\u8fed\u4ee3\u7684\u4e0a\u754c\u6765\u9884\u6d4b\u635f\u5931\uff0c\u5e76\u63a8\u5bfc\u6700\u4f18\u5b66\u4e60\u7387\u7684\u7f29\u653e\u65b9\u5f0f\u3002", "result": "\u7814\u7a76\u8868\u660e\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u540e\u8fc5\u901f\u5448\u73b0\u5f31\u51f8\u7279\u6027\uff0c\u635f\u5931\u53ef\u4ee5\u901a\u8fc7\u6700\u540e\u8fed\u4ee3\u7684\u4e0a\u754c\u8fdb\u884c\u9884\u6d4b\u3002\u57fa\u4e8e\u51f8\u6027\u89c6\u89d2\u6784\u5efa\u7684\u5b66\u4e60\u7387\u548c\u635f\u5931\u7f29\u653e\u89c4\u5f8b\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u65f6\u95f4\u4e0a\u5b9e\u73b080\u500d\u7684\u5916\u63a8\uff0c\u5728\u6a21\u578b\u89c4\u6a21\u4e0a\u5b9e\u73b070\u500d\u7684\u5916\u63a8\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u867d\u7136\u672c\u8d28\u4e0a\u662f\u975e\u51f8\u7684\uff0c\u4f46\u5728\u5b9e\u9645\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u5f31\u51f8\u7279\u6027\uff0c\u8fd9\u4f7f\u5f97\u80fd\u591f\u5e94\u7528\u51f8\u4f18\u5316\u7406\u8bba\u6765\u5206\u6790\u548c\u63a7\u5236\u4f18\u5316\u52a8\u6001\u3002\u901a\u8fc7\u51f8\u6027\u89c6\u89d2\u5efa\u7acb\u7684\u7f29\u653e\u89c4\u5f8b\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.08598", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08598", "abs": "https://arxiv.org/abs/2602.08598", "authors": ["Katharina Kaiser", "Gustavo Valverde", "Gabriela Hug"], "title": "Residential Peak Load Reduction via Direct Load Control under Limited Information", "comment": null, "summary": "Thermostatically controlled loads and electric vehicles offer flexibility to reduce power peaks in low-voltage distribution networks. This flexibility can be maximized if the devices are coordinated centrally, given some level of information about the controlled devices. In this paper, we propose novel optimization-based control schemes with prediction capabilities that utilize limited information from heat pumps, electric water heaters, and electric vehicles. The objective is to flatten the total load curve seen by the distribution transformer by restricting the times at which the available flexible loads are allowed to operate, subject to the flexibility constraints of the loads to preserve customers' comfort. The original scheme was tested in a real-world setup, considering both winter and summer days. The pilot results confirmed the technical feasibility but also informed the design of an improved version of the controller. Computer simulations using the adjusted controller show that, compared to the original formulation, the improved scheme achieves greater peak reductions in summer. Additionally, comparisons were made with an ideal controller, which assumes perfect knowledge of the inflexible load profile, the models of the controlled devices, the hot water and space heating demand, and future electric vehicle charging sessions. The proposed scheme with limited information achieves almost half of the potential average daily peak reduction that the ideal controller with perfect knowledge would achieve.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4f18\u5316\u7684\u9884\u6d4b\u63a7\u5236\u65b9\u6848\uff0c\u5229\u7528\u70ed\u6cf5\u3001\u7535\u70ed\u6c34\u5668\u548c\u7535\u52a8\u6c7d\u8f66\u7684\u6709\u9650\u4fe1\u606f\uff0c\u901a\u8fc7\u9650\u5236\u67d4\u6027\u8d1f\u8377\u8fd0\u884c\u65f6\u95f4\u6765\u5e73\u6291\u914d\u53d8\u603b\u8d1f\u8377\u66f2\u7ebf\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u5e76\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u70ed\u63a7\u8d1f\u8377\u548c\u7535\u52a8\u6c7d\u8f66\u53ef\u4e3a\u4f4e\u538b\u914d\u7535\u7f51\u63d0\u4f9b\u7075\u6d3b\u6027\u4ee5\u524a\u51cf\u529f\u7387\u5cf0\u503c\uff0c\u4f46\u9700\u8981\u4e2d\u5fc3\u5316\u534f\u8c03\u63a7\u5236\u3002\u73b0\u6709\u65b9\u6848\u901a\u5e38\u9700\u8981\u5927\u91cf\u8bbe\u5907\u4fe1\u606f\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4ec5\u9700\u6709\u9650\u4fe1\u606f\u7684\u4f18\u5316\u63a7\u5236\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f18\u5316\u7684\u9884\u6d4b\u63a7\u5236\u65b9\u6848\uff0c\u5229\u7528\u70ed\u6cf5\u3001\u7535\u70ed\u6c34\u5668\u548c\u7535\u52a8\u6c7d\u8f66\u7684\u6709\u9650\u4fe1\u606f\uff0c\u901a\u8fc7\u9650\u5236\u67d4\u6027\u8d1f\u8377\u8fd0\u884c\u65f6\u95f4\u6765\u5e73\u6291\u914d\u53d8\u603b\u8d1f\u8377\u66f2\u7ebf\uff0c\u540c\u65f6\u8003\u8651\u8d1f\u8377\u7075\u6d3b\u6027\u7ea6\u675f\u4ee5\u4fdd\u969c\u7528\u6237\u8212\u9002\u5ea6\u3002\u65b9\u6848\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u6d4b\u8bd5\u5e76\u6539\u8fdb\u3002", "result": "\u5b9e\u9645\u8bd5\u70b9\u9a8c\u8bc1\u4e86\u6280\u672f\u53ef\u884c\u6027\uff0c\u6539\u8fdb\u540e\u7684\u63a7\u5236\u5668\u5728\u590f\u5b63\u5b9e\u73b0\u66f4\u5927\u5cf0\u503c\u524a\u51cf\u3002\u4e0e\u5047\u8bbe\u5b8c\u7f8e\u4fe1\u606f\u7684\u7406\u60f3\u63a7\u5236\u5668\u76f8\u6bd4\uff0c\u6709\u9650\u4fe1\u606f\u65b9\u6848\u53ef\u5b9e\u73b0\u7ea6\u4e00\u534a\u7684\u6f5c\u5728\u65e5\u5e73\u5747\u5cf0\u503c\u524a\u51cf\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6709\u9650\u4fe1\u606f\u4f18\u5316\u63a7\u5236\u65b9\u6848\u80fd\u6709\u6548\u5229\u7528\u67d4\u6027\u8d1f\u8377\u524a\u51cf\u914d\u53d8\u5cf0\u503c\u8d1f\u8377\uff0c\u5728\u4fe1\u606f\u6709\u9650\u6761\u4ef6\u4e0b\u8fbe\u5230\u7406\u60f3\u63a7\u5236\u5668\u7ea6\u4e00\u534a\u7684\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08145", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08145", "abs": "https://arxiv.org/abs/2602.08145", "authors": ["Xinyu Yang", "Junlin Han", "Rishi Bommasani", "Jinqi Luo", "Wenjie Qu", "Wangchunshu Zhou", "Adel Bibi", "Xiyao Wang", "Jaehong Yoon", "Elias Stengel-Eskin", "Shengbang Tong", "Lingfeng Shen", "Rafael Rafailov", "Runjia Li", "Zhaoyang Wang", "Yiyang Zhou", "Chenhang Cui", "Yu Wang", "Wenhao Zheng", "Huichi Zhou", "Jindong Gu", "Zhaorun Chen", "Peng Xia", "Tony Lee", "Thomas Zollo", "Vikash Sehwag", "Jixuan Leng", "Jiuhai Chen", "Yuxin Wen", "Huan Zhang", "Zhun Deng", "Linjun Zhang", "Pavel Izmailov", "Pang Wei Koh", "Yulia Tsvetkov", "Andrew Wilson", "Jiaheng Zhang", "James Zou", "Cihang Xie", "Hao Wang", "Philip Torr", "Julian McAuley", "David Alvarez-Melis", "Florian Tram\u00e8r", "Kaidi Xu", "Suman Jana", "Chris Callison-Burch", "Rene Vidal", "Filippos Kokkinos", "Mohit Bansal", "Beidi Chen", "Huaxiu Yao"], "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey", "comment": "TMLR camera-ready version", "summary": "Foundation models, including Large Language Models (LLMs), Multimodal Large Language Models (MLLMs), Image Generative Models (i.e, Text-to-Image Models and Image-Editing Models), and Video Generative Models, have become essential tools with broad applications across various domains such as law, medicine, education, finance, science, and beyond. As these models see increasing real-world deployment, ensuring their reliability and responsibility has become critical for academia, industry, and government. This survey addresses the reliable and responsible development of foundation models. We explore critical issues, including bias and fairness, security and privacy, uncertainty, explainability, and distribution shift. Our research also covers model limitations, such as hallucinations, as well as methods like alignment and Artificial Intelligence-Generated Content (AIGC) detection. For each area, we review the current state of the field and outline concrete future research directions. Additionally, we discuss the intersections between these areas, highlighting their connections and shared challenges. We hope our survey fosters the development of foundation models that are not only powerful but also ethical, trustworthy, reliable, and socially responsible.", "AI": {"tldr": "\u8be5\u8bba\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u57fa\u7840\u6a21\u578b\u53ef\u9760\u6027\u4e0e\u8d23\u4efb\u6027\u7684\u7efc\u8ff0\uff0c\u6db5\u76d6\u504f\u89c1\u4e0e\u516c\u5e73\u3001\u5b89\u5168\u4e0e\u9690\u79c1\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u5206\u5e03\u504f\u79fb\u7b49\u5173\u952e\u95ee\u9898\uff0c\u4ee5\u53ca\u5e7b\u89c9\u3001\u5bf9\u9f50\u3001AIGC\u68c0\u6d4b\u7b49\u65b9\u6cd5\u548c\u6311\u6218\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\uff08LLMs\u3001MLLMs\u3001\u56fe\u50cf\u751f\u6210\u6a21\u578b\u3001\u89c6\u9891\u751f\u6210\u6a21\u578b\uff09\u5728\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u548c\u8d23\u4efb\u6027\u5bf9\u5b66\u672f\u754c\u3001\u5de5\u4e1a\u754c\u548c\u653f\u5e9c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u5f53\u524d\u7814\u7a76\u73b0\u72b6\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790\u57fa\u7840\u6a21\u578b\u53ef\u9760\u6027\u4e0e\u8d23\u4efb\u6027\u7684\u591a\u4e2a\u5173\u952e\u9886\u57df\uff1a\u504f\u89c1\u4e0e\u516c\u5e73\u3001\u5b89\u5168\u4e0e\u9690\u79c1\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u5206\u5e03\u504f\u79fb\u3002\u540c\u65f6\u63a2\u8ba8\u6a21\u578b\u5c40\u9650\u6027\uff08\u5982\u5e7b\u89c9\uff09\u4ee5\u53ca\u5bf9\u9f50\u3001AIGC\u68c0\u6d4b\u7b49\u65b9\u6cd5\u3002", "result": "\u5bf9\u6bcf\u4e2a\u7814\u7a76\u9886\u57df\u8fdb\u884c\u4e86\u73b0\u72b6\u68b3\u7406\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u5206\u6790\u4e86\u5404\u9886\u57df\u4e4b\u95f4\u7684\u4ea4\u53c9\u8054\u7cfb\u548c\u5171\u540c\u6311\u6218\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u65e8\u5728\u4fc3\u8fdb\u57fa\u7840\u6a21\u578b\u5411\u4e0d\u4ec5\u5f3a\u5927\uff0c\u800c\u4e14\u7b26\u5408\u4f26\u7406\u3001\u53ef\u4fe1\u8d56\u3001\u53ef\u9760\u4e14\u5bf9\u793e\u4f1a\u8d1f\u8d23\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\u6846\u67b6\u3002"}}
{"id": "2602.07874", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07874", "abs": "https://arxiv.org/abs/2602.07874", "authors": ["Ziliang Wang", "Axel Ringh", "Han Zhang"], "title": "Consistent inverse optimal control for infinite time-horizon discounted nonlinear systems under noisy observations", "comment": null, "summary": "Inverse optimal control (IOC) aims to estimate the underlying cost that governs the observed behavior of an expert system. However, in practical scenarios, the collected data is often corrupted by noise, which poses significant challenges for accurate cost function recovery. In this work, we propose an IOC framework that effectively addresses the presence of observation noise. In particular, compared to our previous work \\cite{wang2025consistent}, we consider the case of discrete-time, infinite-horizon, discounted MDPs whose transition kernel is only weak Feller. By leveraging the occupation measure framework, we first establish the necessary and sufficient optimality conditions for the expert policy and then construct an infinite dimensional optimization problem based on these conditions. This problem is then approximated by polynomials to get a finite-dimensional numerically solvable one, which relies on the moments of the state-action trajectory's occupation measure. More specifically, the moments are robustly estimated from the noisy observations by a combined misspecified Generalized Method of Moments (GMM) estimator derived from observation model and system dynamics. Consequently, the entire algorithm is based on convex optimization which alleviates the issues that arise from local minima and is asymptotically and statistically consistent. Finally, the performance of the proposed method is illustrated through numerical examples.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u7684\u9006\u6700\u4f18\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u5360\u7528\u6d4b\u5ea6\u548c\u77e9\u4f30\u8ba1\u5904\u7406\u89c2\u6d4b\u566a\u58f0\uff0c\u5728\u5f31Feller\u8f6c\u79fb\u6838\u7684\u79bb\u6563\u65f6\u95f4\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u6062\u590d\u6210\u672c\u51fd\u6570\u3002", "motivation": "\u5b9e\u9645\u573a\u666f\u4e2d\u6536\u96c6\u7684\u4e13\u5bb6\u7cfb\u7edf\u6570\u636e\u5e38\u88ab\u566a\u58f0\u6c61\u67d3\uff0c\u8fd9\u7ed9\u51c6\u786e\u6062\u590d\u6210\u672c\u51fd\u6570\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u566a\u58f0\u5b58\u5728\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u6709\u6548\u5904\u7406\u89c2\u6d4b\u566a\u58f0\u7684\u9c81\u68d2IOC\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u5360\u7528\u6d4b\u5ea6\u6846\u67b6\u5efa\u7acb\u4e13\u5bb6\u7b56\u7565\u7684\u6700\u4f18\u6027\u6761\u4ef6\uff0c\u6784\u5efa\u65e0\u9650\u7ef4\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u9879\u5f0f\u903c\u8fd1\u8f6c\u5316\u4e3a\u6709\u9650\u7ef4\u53ef\u6570\u503c\u6c42\u89e3\u95ee\u9898\u3002\u5229\u7528\u89c2\u6d4b\u6a21\u578b\u548c\u7cfb\u7edf\u52a8\u529b\u5b66\u63a8\u5bfc\u7684\u8bef\u8bbe\u5e7f\u4e49\u77e9\u4f30\u8ba1\u65b9\u6cd5(GMM)\u4ece\u566a\u58f0\u89c2\u6d4b\u4e2d\u9c81\u68d2\u4f30\u8ba1\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u5360\u7528\u6d4b\u5ea6\u7684\u77e9\uff0c\u6574\u4e2a\u7b97\u6cd5\u57fa\u4e8e\u51f8\u4f18\u5316\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u57fa\u4e8e\u51f8\u4f18\u5316\uff0c\u907f\u514d\u4e86\u5c40\u90e8\u6700\u5c0f\u503c\u95ee\u9898\uff0c\u5177\u6709\u6e10\u8fd1\u548c\u7edf\u8ba1\u4e00\u81f4\u6027\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u9006\u6700\u4f18\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u6709\u6548\u5904\u7406\u89c2\u6d4b\u566a\u58f0\uff0c\u5728\u5f31Feller\u8f6c\u79fb\u6838\u7684\u79bb\u6563\u65f6\u95f4\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u6062\u590d\u6210\u672c\u51fd\u6570\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2602.07376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07376", "abs": "https://arxiv.org/abs/2602.07376", "authors": ["Usman Naseem", "Gautam Siddharth Kashyap", "Sushant Kumar Ray", "Rafiq Ali", "Ebad Shabbir", "Abdullah Mohammad"], "title": "Do Large Language Models Reflect Demographic Pluralism in Safety?", "comment": "Accepted at EACL Findings 2026", "summary": "Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.", "AI": {"tldr": "Demo-SafetyBench\u662f\u4e00\u4e2a\u89e3\u51b3LLM\u5b89\u5168\u8bc4\u4f30\u4e2d\u4eba\u53e3\u7edf\u8ba1\u5b66\u591a\u5143\u6027\u7f3a\u5931\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u91cd\u65b0\u5206\u7c7b\u73b0\u6709\u6570\u636e\u5e76\u8bc4\u4f30\u591a\u5143\u654f\u611f\u6027\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u4eba\u53e3\u7edf\u8ba1\u5b66\u9c81\u68d2\u7684\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u5bf9\u9f50\u6570\u636e\u96c6\uff08\u5982ANTHROPIC-HH\u548cDICES\uff09\u4f7f\u7528\u4eba\u53e3\u7edf\u8ba1\u5b66\u72ed\u7a84\u7684\u6807\u6ce8\u8005\u7fa4\u4f53\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u793e\u533a\u5bf9\u5b89\u5168\u611f\u77e5\u7684\u5dee\u5f02\uff0c\u65e0\u6cd5\u53cd\u6620\u5b89\u5168\u8bc4\u4f30\u7684\u591a\u5143\u6027\u672c\u8d28\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5c06DICES\u63d0\u793a\u91cd\u65b0\u5206\u7c7b\u4e3a14\u4e2a\u5b89\u5168\u9886\u57df\uff0c\u4fdd\u7559\u4eba\u53e3\u7edf\u8ba1\u5143\u6570\u636e\uff0c\u901a\u8fc7LLM\u6269\u5c55\u4f4e\u8d44\u6e90\u9886\u57df\u5e76\u8fdb\u884c\u53bb\u91cd\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u591a\u4e2aLLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u8fdb\u884c\u96f6\u6837\u672c\u63a8\u7406\uff0c\u8bc4\u4f30\u591a\u5143\u654f\u611f\u6027\u3002", "result": "\u6784\u5efa\u4e8643,050\u4e2a\u6837\u672c\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5e73\u8861\u9608\u503c\uff08delta=0.5, tau=10\uff09\u5b9e\u73b0\u4e86\u9ad8\u53ef\u9760\u6027\uff08ICC=0.87\uff09\u548c\u4f4e\u4eba\u53e3\u7edf\u8ba1\u654f\u611f\u6027\uff08DS=0.12\uff09\uff0c\u8bc1\u660e\u591a\u5143\u5b89\u5168\u8bc4\u4f30\u65e2\u53ef\u6269\u5c55\u53c8\u5177\u6709\u4eba\u53e3\u7edf\u8ba1\u5b66\u9c81\u68d2\u6027\u3002", "conclusion": "Demo-SafetyBench\u901a\u8fc7\u5728\u63d0\u793a\u5c42\u9762\u76f4\u63a5\u5efa\u6a21\u4eba\u53e3\u7edf\u8ba1\u5b66\u591a\u5143\u4e3b\u4e49\uff0c\u5c06\u4ef7\u503c\u6846\u67b6\u4e0e\u54cd\u5e94\u89e3\u8026\uff0c\u4e3aLLM\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u57fa\u51c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2602.07342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07342", "abs": "https://arxiv.org/abs/2602.07342", "authors": ["Shengyue Guan", "Yihao Liu", "Lang Cao"], "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management", "comment": null, "summary": "Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world benchmark that assesses both supply chain domain knowledge and long-horizon tool-based orchestration grounded in standard operating procedures (SOPs). Our experiments reveal substantial gaps in execution reliability across models. We further propose SupChain-ReAct, an SOP-free framework that autonomously synthesizes executable procedures for tool use, achieving the strongest and most consistent tool-calling performance. Our work establishes a principled benchmark for studying reliable long-horizon orchestration in real-world operational settings and highlights significant room for improvement in LLM-based supply chain agents.", "AI": {"tldr": "SupChain-Bench\uff1a\u9996\u4e2a\u8bc4\u4f30LLM\u5728\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u957f\u65f6\u57df\u3001\u591a\u6b65\u9aa4\u7f16\u6392\u80fd\u529b\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u53ef\u9760\u6027\u4e0a\u7684\u663e\u8457\u5dee\u8ddd\uff1bSupChain-ReAct\u6846\u67b6\u901a\u8fc7\u81ea\u4e3b\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\u5b9e\u73b0\u6700\u4f73\u5de5\u5177\u8c03\u7528\u6027\u80fd\u3002", "motivation": "LLM\u5728\u590d\u6742\u63a8\u7406\u548c\u5de5\u5177\u51b3\u7b56\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u4f9b\u5e94\u94fe\u7ba1\u7406\u7b49\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u53ef\u9760\u7684\u957f\u65f6\u57df\u3001\u591a\u6b65\u9aa4\u7f16\u6392\u80fd\u529b\uff0c\u4e14\u5fc5\u987b\u57fa\u4e8e\u9886\u57df\u7279\u5b9a\u7684\u6807\u51c6\u64cd\u4f5c\u7a0b\u5e8f(SOPs)\uff0c\u8fd9\u5bf9\u5f53\u524d\u6a21\u578b\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "1) \u63d0\u51faSupChain-Bench\u7edf\u4e00\u57fa\u51c6\uff0c\u8bc4\u4f30\u4f9b\u5e94\u94fe\u9886\u57df\u77e5\u8bc6\u548c\u57fa\u4e8eSOPs\u7684\u957f\u65f6\u57df\u5de5\u5177\u7f16\u6392\u80fd\u529b\uff1b2) \u5f00\u53d1SupChain-ReAct\u6846\u67b6\uff0c\u65e0\u9700\u4f9d\u8d56SOPs\u5373\u53ef\u81ea\u4e3b\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\u8fdb\u884c\u5de5\u5177\u8c03\u7528\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5404\u6a21\u578b\u5728\u6267\u884c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff1bSupChain-ReAct\u6846\u67b6\u5728\u6240\u6709\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u6700\u5f3a\u4e14\u6700\u4e00\u81f4\u7684\u5de5\u5177\u8c03\u7528\u6027\u80fd\uff0c\u4e3aSOP-free\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u73af\u5883\u4e2d\u53ef\u9760\u7684\u957f\u65f6\u57df\u7f16\u6392\u7814\u7a76\u5efa\u7acb\u4e86\u539f\u5219\u6027\u57fa\u51c6\uff0c\u540c\u65f6\u8868\u660e\u57fa\u4e8eLLM\u7684\u4f9b\u5e94\u94fe\u4ee3\u7406\u4ecd\u6709\u5de8\u5927\u6539\u8fdb\u7a7a\u95f4\uff0cSupChain-ReAct\u6846\u67b6\u4e3a\u8fd9\u4e00\u65b9\u5411\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07150", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07150", "abs": "https://arxiv.org/abs/2602.07150", "authors": ["Bjarni Haukur Bjarnason", "Andr\u00e9 Silva", "Martin Monperrus"], "title": "On Randomness in Agentic Evals", "comment": null, "summary": "Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points depending on which run is selected, with standard deviations exceeding 1.5 percentage points even at temperature 0. This variance has critical implications: reported improvements of 2--3 percentage points may reflect evaluation noise rather than genuine algorithmic progress. Through token-level analysis, we show that trajectories diverge early, often within the first few percent of tokens, and that these small differences cascade into different solution strategies. To enable reliable evaluation of agentic systems, we recommend three concrete practices: (1) estimate pass@1 from multiple independent runs per task, especially when measuring small improvements, (2) use statistical power analysis to determine the number of runs needed to detect expected effect sizes, and (3) consider metrics like pass@k (optimistic bound) and pass^k (pessimistic bound) with k>1 to better characterize the full performance envelope. While these practices increase evaluation cost, they are essential for distinguishing genuine scientific progress from statistical noise.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5355\u6b21\u8fd0\u884c\u8bc4\u4f30\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u65b9\u5dee\uff0c2-3\u4e2a\u767e\u5206\u70b9\u7684\u6539\u8fdb\u53ef\u80fd\u53ea\u662f\u7edf\u8ba1\u566a\u58f0\u800c\u975e\u771f\u5b9e\u7b97\u6cd5\u8fdb\u6b65\uff0c\u5efa\u8bae\u91c7\u7528\u591a\u6b21\u8fd0\u884c\u3001\u7edf\u8ba1\u529f\u6548\u5206\u6790\u548cpass@k\u7b49\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u901a\u5e38\u4f7f\u7528\u5355\u6b21\u8fd0\u884c\u8ba1\u7b97pass@1\u5206\u6570\uff0c\u4f46\u8fd9\u79cd\u8bc4\u4f30\u65b9\u6cd5\u662f\u5426\u53ef\u9760\u5c1a\u672a\u5f97\u5230\u9a8c\u8bc1\u3002\u7814\u7a76\u8005\u60f3\u8981\u6d4b\u8bd5\u8fd9\u79cd\u5047\u8bbe\uff0c\u63a2\u7a76\u5355\u6b21\u8fd0\u884c\u8bc4\u4f30\u7684\u65b9\u5dee\u95ee\u9898\u53ca\u5176\u5bf9\u7b97\u6cd5\u8fdb\u6b65\u5224\u65ad\u7684\u5f71\u54cd\u3002", "method": "\u5728SWE-Bench-Verified\u6570\u636e\u96c6\u4e0a\u6536\u96c6\u4e8660,000\u4e2a\u667a\u80fd\u4f53\u8f68\u8ff9\uff0c\u6db5\u76d6\u4e09\u4e2a\u6a21\u578b\u548c\u4e24\u79cd\u811a\u624b\u67b6\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u8f68\u8ff9\u7684\u65b9\u5dee\uff0c\u8fdb\u884ctoken\u7ea7\u522b\u7684\u5206\u6790\u6765\u63a2\u7a76\u8f68\u8ff9\u5206\u5316\u7684\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7684\u8bc4\u4f30\u5b9e\u8df5\u3002", "result": "\u53d1\u73b0\u5355\u6b21\u8fd0\u884c\u8bc4\u4f30\u5b58\u5728\u663e\u8457\u65b9\u5dee\uff1apass@1\u4f30\u8ba1\u503c\u6839\u636e\u9009\u62e9\u7684\u8fd0\u884c\u4e0d\u540c\u4f1a\u53d8\u53162.2\u52306.0\u4e2a\u767e\u5206\u70b9\uff0c\u5373\u4f7f\u5728\u6e29\u5ea60\u7684\u60c5\u51b5\u4e0b\u6807\u51c6\u5dee\u4e5f\u8d85\u8fc71.5\u4e2a\u767e\u5206\u70b9\u3002\u8f68\u8ff9\u5728\u65e9\u671f\uff08\u524d\u51e0\u4e2a\u767e\u5206\u70b9\u7684token\uff09\u5c31\u4f1a\u5206\u5316\uff0c\u8fd9\u4e9b\u5fae\u5c0f\u5dee\u5f02\u4f1a\u7ea7\u8054\u6210\u4e0d\u540c\u7684\u89e3\u51b3\u7b56\u7565\u3002", "conclusion": "\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u9700\u8981\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\uff1a1\uff09\u5bf9\u6bcf\u4e2a\u4efb\u52a1\u8fdb\u884c\u591a\u6b21\u72ec\u7acb\u8fd0\u884c\u6765\u4f30\u8ba1pass@1\uff1b2\uff09\u4f7f\u7528\u7edf\u8ba1\u529f\u6548\u5206\u6790\u786e\u5b9a\u68c0\u6d4b\u9884\u671f\u6548\u5e94\u5927\u5c0f\u6240\u9700\u7684\u8fd0\u884c\u6b21\u6570\uff1b3\uff09\u8003\u8651\u4f7f\u7528pass@k\u548cpass^k\u7b49\u6307\u6807\u6765\u66f4\u597d\u5730\u8868\u5f81\u5b8c\u6574\u6027\u80fd\u8303\u56f4\u3002\u867d\u7136\u8fd9\u4e9b\u5b9e\u8df5\u4f1a\u589e\u52a0\u8bc4\u4f30\u6210\u672c\uff0c\u4f46\u5bf9\u4e8e\u533a\u5206\u771f\u5b9e\u7684\u79d1\u5b66\u8fdb\u6b65\u548c\u7edf\u8ba1\u566a\u58f0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.08633", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08633", "abs": "https://arxiv.org/abs/2602.08633", "authors": ["Wasif H. Syed", "Juan E. Machado", "Johannes Schiffer"], "title": "A Primal-Dual-Based Active Fault-Tolerant Control Scheme for Cyber-Physical Systems: Application to DC Microgrids", "comment": null, "summary": "We consider the problem of active fault-tolerant control in cyber-physical systems composed of strictly passive linear-time invariant dynamic subsystems. We cast the problem as a constrained optimization problem and propose an augmented primal-dual gradient dynamics-based fault-tolerant control framework that enforces network-level constraints and provides optimality guarantees for the post-fault steady-state operation. By suitably interconnecting the primal-dual algorithm with the cyber-physical dynamics, we provide sufficient conditions under which the resulting closed-loop system possesses a unique and exponentially stable equilibrium point that satisfies the Karush--Kuhn--Tucker (KKT) conditions of the constrained problem. The framework's effectiveness is illustrated through numerical experiments on a DC microgrid.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u589e\u5f3a\u539f\u59cb-\u5bf9\u5076\u68af\u5ea6\u52a8\u529b\u5b66\u7684\u4e3b\u52a8\u5bb9\u9519\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u4e25\u683c\u65e0\u6e90\u7ebf\u6027\u65f6\u4e0d\u53d8\u52a8\u6001\u5b50\u7cfb\u7edf\u7ec4\u6210\u7684\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u65b9\u6cd5\u4fdd\u8bc1\u6545\u969c\u540e\u7a33\u6001\u8fd0\u884c\u7684\u6700\u4f18\u6027\u3002", "motivation": "\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08\u5982\u5fae\u7535\u7f51\uff09\u4e2d\u7684\u5b50\u7cfb\u7edf\u6545\u969c\u4f1a\u5f71\u54cd\u6574\u4f53\u6027\u80fd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4e3b\u52a8\u5904\u7406\u6545\u969c\u5e76\u4fdd\u8bc1\u7cfb\u7edf\u7ea6\u675f\u548c\u6700\u4f18\u6027\u7684\u5bb9\u9519\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5c06\u5bb9\u9519\u63a7\u5236\u95ee\u9898\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u589e\u5f3a\u539f\u59cb-\u5bf9\u5076\u68af\u5ea6\u52a8\u529b\u5b66\u6846\u67b6\uff0c\u5c06\u7b97\u6cd5\u4e0e\u7f51\u7edc\u7269\u7406\u52a8\u529b\u5b66\u9002\u5f53\u4e92\u8054\uff0c\u786e\u4fdd\u95ed\u73af\u7cfb\u7edf\u5177\u6709\u6ee1\u8db3KKT\u6761\u4ef6\u7684\u552f\u4e00\u6307\u6570\u7a33\u5b9a\u5e73\u8861\u70b9\u3002", "result": "\u5efa\u7acb\u4e86\u95ed\u73af\u7cfb\u7edf\u5b58\u5728\u552f\u4e00\u6307\u6570\u7a33\u5b9a\u5e73\u8861\u70b9\u7684\u5145\u5206\u6761\u4ef6\uff0c\u8be5\u5e73\u8861\u70b9\u6ee1\u8db3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u7684KKT\u6761\u4ef6\uff0c\u5728\u76f4\u6d41\u5fae\u7535\u7f51\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u589e\u5f3a\u539f\u59cb-\u5bf9\u5076\u68af\u5ea6\u52a8\u529b\u5b66\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e3b\u52a8\u5bb9\u9519\u63a7\u5236\u95ee\u9898\uff0c\u4fdd\u8bc1\u6545\u969c\u540e\u7a33\u6001\u8fd0\u884c\u7684\u6700\u4f18\u6027\u548c\u7ea6\u675f\u6ee1\u8db3\uff0c\u9002\u7528\u4e8e\u4e25\u683c\u65e0\u6e90\u7ebf\u6027\u65f6\u4e0d\u53d8\u5b50\u7cfb\u7edf\u3002"}}
{"id": "2602.08927", "categories": ["stat.ML", "cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.08927", "abs": "https://arxiv.org/abs/2602.08927", "authors": ["Rohan Hore", "Ruodu Wang", "Aaditya Ramdas"], "title": "Online monotone density estimation and log-optimal calibration", "comment": "28 pages, 1 figure", "summary": "We study the problem of online monotone density estimation, where density estimators must be constructed in a predictable manner from sequentially observed data. We propose two online estimators: an online analogue of the classical Grenander estimator, and an expert aggregation estimator inspired by exponential weighting methods from the online learning literature. In the well-specified stochastic setting, where the underlying density is monotone, we show that the expected cumulative log-likelihood gap between the online estimators and the true density admits an $O(n^{1/3})$ bound. We further establish a $\\sqrt{n\\log{n}}$ pathwise regret bound for the expert aggregation estimator relative to the best offline monotone estimator chosen in hindsight, under minimal regularity assumptions on the observed sequence. As an application of independent interest, we show that the problem of constructing log-optimal p-to-e calibrators for sequential hypothesis testing can be formulated as an online monotone density estimation problem. We adapt the proposed estimators to build empirically adaptive p-to-e calibrators and establish their optimality. Numerical experiments illustrate the theoretical results.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u5355\u8c03\u5bc6\u5ea6\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5728\u7ebf\u4f30\u8ba1\u5668\uff1a\u7ecf\u5178Grenander\u4f30\u8ba1\u5668\u7684\u5728\u7ebf\u7248\u672c\u548c\u57fa\u4e8e\u4e13\u5bb6\u805a\u5408\u7684\u4f30\u8ba1\u5668\uff0c\u5728\u968f\u673a\u8bbe\u7f6e\u4e0b\u83b7\u5f97\u4e86O(n^{1/3})\u7684\u7d2f\u79ef\u5bf9\u6570\u4f3c\u7136\u5dee\u8ddd\u754c\uff0c\u5e76\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u5e8f\u5217\u5047\u8bbe\u68c0\u9a8c\u4e2d\u7684p-to-e\u6821\u51c6\u5668\u6784\u5efa\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u5355\u8c03\u5bc6\u5ea6\u4f30\u8ba1\u95ee\u9898\uff0c\u9700\u8981\u5728\u987a\u5e8f\u89c2\u6d4b\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4ee5\u53ef\u9884\u6d4b\u7684\u65b9\u5f0f\u6784\u5efa\u5bc6\u5ea6\u4f30\u8ba1\u5668\u3002\u8fd9\u4e2a\u95ee\u9898\u5728\u5e8f\u5217\u5047\u8bbe\u6d4b\u8bd5\u4e2d\u6709\u91cd\u8981\u5e94\u7528\uff0c\u7279\u522b\u662f\u6784\u5efalog-optimal p-to-e\u6821\u51c6\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u5728\u7ebf\u4f30\u8ba1\u5668\uff1a1\uff09\u7ecf\u5178Grenander\u4f30\u8ba1\u5668\u7684\u5728\u7ebf\u7248\u672c\uff1b2\uff09\u57fa\u4e8e\u6307\u6570\u52a0\u6743\u65b9\u6cd5\u7684\u4e13\u5bb6\u805a\u5408\u4f30\u8ba1\u5668\u3002\u5728\u968f\u673a\u8bbe\u7f6e\u4e0b\u5206\u6790\u6027\u80fd\uff0c\u5e76\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u6784\u5efap-to-e\u6821\u51c6\u5668\u3002", "result": "\u5728\u6b63\u786e\u8bbe\u5b9a\u7684\u968f\u673a\u8bbe\u7f6e\u4e0b\uff0c\u5728\u7ebf\u4f30\u8ba1\u5668\u4e0e\u771f\u5b9e\u5bc6\u5ea6\u4e4b\u95f4\u7684\u671f\u671b\u7d2f\u79ef\u5bf9\u6570\u4f3c\u7136\u5dee\u8ddd\u6709O(n^{1/3\uff09\u4e0a\u754c\u3002\u4e13\u5bb6\u805a\u5408\u4f30\u8ba1\u5668\u76f8\u5bf9\u4e8e\u4e8b\u540e\u9009\u62e9\u7684\u6700\u4f73\u79bb\u7ebf\u5355\u8c03\u4f30\u8ba1\u5668\u5177\u6709\u221a(n log n)\u8def\u5f84\u540e\u6094\u754c\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u5728\u7ebf\u5355\u8c03\u5bc6\u5ea6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5efa\u7acb\u4e86\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u5c06\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u5e8f\u5217\u5047\u8bbe\u6d4b\u8bd5\u4e2d\u7684p-to-e\u6821\u51c6\u5668\u6784\u5efa\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08688", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08688", "abs": "https://arxiv.org/abs/2602.08688", "authors": ["Hossein Kermani", "Fatemeh Oudlajani", "Pardis Yarahmadi", "Hamideh Mahdi Soltani", "Mohammad Makki", "Zahra HosseiniKhoo"], "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement", "comment": null, "summary": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u6ce2\u65af\u8bed\u63a8\u6587\u4e0d\u6587\u660e\u5185\u5bb9\u68c0\u6d4b\u65b9\u6cd5\uff1a\u4eba\u5de5\u6807\u6ce8\u3001ParsBERT\u76d1\u7763\u5b66\u4e60\u548cChatGPT\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0ParsBERT\u5728\u4ec7\u6068\u8a00\u8bba\u8bc6\u522b\u4e0a\u663e\u8457\u4f18\u4e8eChatGPT", "motivation": "\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u6ce2\u65af\u8bed\uff09\u73af\u5883\u4e0b\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u68c0\u6d4b\u4ec7\u6068\u8a00\u8bba\u548c\u4e0d\u6587\u660e\u5185\u5bb9\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u6bd4\u8f83\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02", "method": "\u4f7f\u7528#MahsaAmini\u8fd0\u52a8\u768447,278\u6761\u6ce2\u65af\u8bed\u63a8\u6587\uff0c\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\uff1a1\uff09\u4eba\u5de5\u5b9a\u6027\u7f16\u7801\uff0c2\uff09\u57fa\u4e8eParsBERT\u7684\u76d1\u7763\u5b66\u4e60\uff0c3\uff09\u4e03\u79cdChatGPT\u6a21\u578b\uff1b\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u6548\u7387", "result": "ParsBERT\u5728\u8bc6\u522b\u4ec7\u6068\u8a00\u8bba\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6240\u6709\u4e03\u79cdChatGPT\u6a21\u578b\uff1bChatGPT\u4e0d\u4ec5\u5728\u5fae\u5999\u6848\u4f8b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5728\u5904\u7406\u660e\u786e\u7684\u4e0d\u6587\u660e\u5185\u5bb9\u65f6\u4e5f\u6709\u56f0\u96be\uff1b\u63d0\u793a\u8bed\u8a00\uff08\u82f1\u8bedvs\u6ce2\u65af\u8bed\uff09\u5bf9ChatGPT\u8f93\u51fa\u65e0\u663e\u8457\u5f71\u54cd", "conclusion": "\u5bf9\u4e8e\u6ce2\u65af\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4ec7\u6068\u8a00\u8bba\u5206\u6790\uff0cParsBERT\u7b49\u4e13\u95e8\u8bad\u7ec3\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u7814\u7a76\u4e3a\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u63d0\u4f9b\u4e86\u8be6\u7ec6\u6bd4\u8f83\uff0c\u6709\u52a9\u4e8e\u5728\u7279\u5b9a\u8bed\u8a00\u73af\u5883\u4e0b\u9009\u62e9\u5408\u9002\u7684\u6280\u672f\u65b9\u6848"}}
{"id": "2602.07961", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.07961", "abs": "https://arxiv.org/abs/2602.07961", "authors": ["Xiaojun Chen", "C. T. Kelley", "Lei Wang"], "title": "Complexity of Projected Gradient Methods for Strongly Convex Optimization with H\u00f6lder Continuous Gradient Terms", "comment": null, "summary": "This paper studies the complexity of projected gradient descent methods for a class of strongly convex constrained optimization problems where the objective function is expressed as a summation of $m$ component functions, each possessing a gradient that is H\u00f6lder continuous with an exponent $\u03b1_i \\in (0, 1]$. Under this formulation, the gradient of the objective function may fail to be globally H\u00f6lder continuous, thereby rendering existing complexity results inapplicable to this class of problems. Our theoretical analysis reveals that, in this setting, the complexity of projected gradient methods is determined by $\\hat\u03b1 = \\min_{i \\in \\{1, \\dotsc, m\\}} \u03b1_i$. We first prove that, with an appropriately fixed stepsize, the complexity bound for finding an approximate minimizer with a distance to the true minimizer less than $\\varepsilon$ is $O (\\log (\\varepsilon^{-1}) \\varepsilon^{2 (\\hat\u03b1 - 1) / (1 + \\hat\u03b1)})$, which extends the well-known complexity result for $\\hat\u03b1 = 1$. Next we show that the complexity bound can be improved to $O (\\log (\\varepsilon^{-1}) \\varepsilon^{2 (\\hat\u03b1 - 1) / (1 + 3 \\hat\u03b1)})$ if the stepsize is updated by the universal scheme. We illustrate our complexity results by numerical examples arising from elliptic equations with a non-Lipschitz term.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u76ee\u6807\u51fd\u6570\u4e3a\u591a\u4e2aH\u00f6lder\u8fde\u7eed\u5206\u91cf\u51fd\u6570\u4e4b\u548c\u65f6\u7684\u590d\u6742\u5ea6\u5206\u6790\uff0c\u5f53\u68af\u5ea6\u975e\u5168\u5c40H\u00f6lder\u8fde\u7eed\u65f6\uff0c\u590d\u6742\u5ea6\u7531\u6700\u5c0fH\u00f6lder\u6307\u6570\u51b3\u5b9a\u3002", "motivation": "\u73b0\u6709\u590d\u6742\u5ea6\u5206\u6790\u901a\u5e38\u5047\u8bbe\u76ee\u6807\u51fd\u6570\u68af\u5ea6\u5177\u6709\u5168\u5c40H\u00f6lder\u8fde\u7eed\u6027\uff0c\u4f46\u5f53\u76ee\u6807\u51fd\u6570\u662f\u591a\u4e2a\u5177\u6709\u4e0d\u540cH\u00f6lder\u6307\u6570\u7684\u5206\u91cf\u51fd\u6570\u4e4b\u548c\u65f6\uff0c\u6574\u4f53\u68af\u5ea6\u53ef\u80fd\u4e0d\u6ee1\u8db3\u5168\u5c40H\u00f6lder\u8fde\u7eed\u6027\uff0c\u8fd9\u4f7f\u5f97\u73b0\u6709\u7406\u8bba\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u3002", "method": "\u91c7\u7528\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u5206\u6790\u4e24\u79cd\u6b65\u957f\u7b56\u7565\uff1a\u56fa\u5b9a\u6b65\u957f\u548c\u901a\u7528\u81ea\u9002\u5e94\u6b65\u957f\u65b9\u6848\uff0c\u7406\u8bba\u63a8\u5bfc\u590d\u6742\u5ea6\u4e0a\u754c\u3002", "result": "\u56fa\u5b9a\u6b65\u957f\u4e0b\u7684\u590d\u6742\u5ea6\u4e3aO(log(\u03b5\u207b\u00b9)\u03b5^{2(\u03b1\u0302-1)/(1+\u03b1\u0302)})\uff0c\u81ea\u9002\u5e94\u6b65\u957f\u53ef\u6539\u8fdb\u4e3aO(log(\u03b5\u207b\u00b9)\u03b5^{2(\u03b1\u0302-1)/(1+3\u03b1\u0302)})\uff0c\u5176\u4e2d\u03b1\u0302\u4e3a\u5404\u5206\u91cf\u51fd\u6570H\u00f6lder\u6307\u6570\u7684\u6700\u5c0f\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u6295\u5f71\u68af\u5ea6\u65b9\u6cd5\u7684\u590d\u6742\u5ea6\u7406\u8bba\uff0c\u9002\u7528\u4e8e\u68af\u5ea6\u975e\u5168\u5c40H\u00f6lder\u8fde\u7eed\u7684\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u692d\u5706\u65b9\u7a0b\u6570\u503c\u7b97\u4f8b\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2602.07381", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07381", "abs": "https://arxiv.org/abs/2602.07381", "authors": ["Gautam Siddharth Kashyap", "Mark Dras", "Usman Naseem"], "title": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified", "comment": "Accepted at EACL Mains 2026", "summary": "Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.", "AI": {"tldr": "AlignX\uff1a\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u6ce8\u5165\u5fae\u8c03\u548c\u51e0\u4f55\u6821\u51c6\u7684MoE\u6765\u89e3\u51b3LLM\u5bf9\u9f50\u4e2d\u7684\u8f74\u5d29\u6e83\u95ee\u9898\uff0c\u5728\u591a\u76ee\u6807\u5bf9\u9f50\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709LLM\u5bf9\u9f50\u65b9\u6cd5\uff08SFT\u548cMoE\uff09\u5728\u591a\u76ee\u6807\u8bbe\u7f6e\u4e0b\u9762\u4e34\u6311\u6218\uff1aSFT\u5bfc\u81f4\u51b2\u7a81\u76ee\u6807\u95f4\u7684\u5e72\u6270\uff0cMoE\u5b58\u5728\u8def\u7531\u6821\u51c6\u95ee\u9898\u3002\u8fd9\u79cd\u5931\u8d25\u6a21\u5f0f\u79f0\u4e3a\"\u8f74\u5d29\u6e83\"\uff0c\u8868\u73b0\u4e3a\uff081\uff09\u7279\u5f81\u7a7a\u95f4\u5206\u79bb\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\uff082\uff09\u9519\u8bef\u8def\u7531\u5bfc\u81f4\u4e0d\u53ef\u9760\u63a8\u7406\u3002", "method": "AlignX\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u63d0\u793a\u6ce8\u5165\u5fae\u8c03\u63d0\u53d6\u8f74\u7279\u5b9a\u4efb\u52a1\u7279\u5f81\uff0c\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff1b\u7b2c\u4e8c\u9636\u6bb5\u90e8\u7f72MoCaE\u6a21\u5757\uff0c\u5229\u7528\u5206\u5f62\u548c\u81ea\u7136\u51e0\u4f55\u6821\u51c6\u4e13\u5bb6\u8def\u7531\uff0c\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u3002", "result": "\u5728Alpaca\uff08\u6709\u5e2e\u52a9\u6027\uff09\u3001BeaverTails\uff08\u65e0\u5bb3\u6027\uff09\u548cTruthfulQA\uff08\u8bda\u5b9e\u6027\uff09\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1a\u80dc\u7387+171.5%\uff0c\u771f\u5b9e\u6027-\u4fe1\u606f\u6027+110.1%\uff0c\u5b89\u5168\u8fdd\u89c4\u51cf\u5c114.3%\u3002\u76f8\u6bd4\u5148\u524dMoE\u65b9\u6cd5\uff0c\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1135%\u4ee5\u4e0a\u3002\u5728\u56db\u4e2aLLM\u4e0a\u7684\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AlignX\u6709\u6548\u89e3\u51b3\u4e86LLM\u591a\u76ee\u6807\u5bf9\u9f50\u4e2d\u7684\u8f74\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6709\u5e2e\u52a9\u6027\u3001\u65e0\u5bb3\u6027\u548c\u8bda\u5b9e\u6027\u5e73\u8861\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.07359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07359", "abs": "https://arxiv.org/abs/2602.07359", "authors": ["Xiaoqiang Lin", "Jun Hao Liew", "Silvio Savarese", "Junnan Li"], "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents", "comment": null, "summary": "Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.", "AI": {"tldr": "\u63d0\u51faWide and Deep\u7814\u7a76\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\uff0c\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u6027\u80fd\u5e76\u51cf\u5c11\u6240\u9700\u8f6e\u6b21", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u4e3b\u8981\u901a\u8fc7\u589e\u52a0\u987a\u5e8f\u601d\u7ef4\u548c\u5de5\u5177\u8c03\u7528\u7684\u6df1\u5ea6\u6765\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "\u63d0\u51faWide and Deep\u7814\u7a76\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u5185\u5728\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u5185\u5b9e\u73b0\u6709\u6548\u534f\u8c03\uff0c\u800c\u975e\u4f9d\u8d56\u590d\u6742\u7684\u591a\u4ee3\u7406\u7f16\u6392", "result": "\u5bbd\u5ea6\u6269\u5c55\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6027\u80fd\uff0c\u51cf\u5c11\u83b7\u5f97\u6b63\u786e\u7b54\u6848\u6240\u9700\u8f6e\u6b21\uff1bGPT-5-Medium\u5728BrowseComp\u4e0a\u8fbe\u523062.2%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7GPT-5-High\u768454.9%", "conclusion": "\u4f18\u5316\u5bbd\u5ea6\u4e0e\u6df1\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u662f\u5b9e\u73b0\u9ad8\u6548\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u5173\u952e\u9014\u5f84\uff0c\u5e76\u884c\u5de5\u5177\u8c03\u7528\u662f\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u7684\u6709\u6548\u7b56\u7565"}}
{"id": "2602.07154", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07154", "abs": "https://arxiv.org/abs/2602.07154", "authors": ["Ayush Roy", "Rudrasis Chakraborty", "Lav Varshney", "Vishnu Suresh Lokhande"], "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity", "comment": "AISTATS 2026", "summary": "Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching for the inclusion of data domains make matching more robust than naive pooling and uniform subsampling by filtering out the confounding domains (the main cause of heterogeneity). Theoretical and empirical analyses show that, unlike naive pooling or uniform subsampling, matching achieves better results under asymmetric meta-distributions, which are also extended to non-Gaussian and multimodal real-world settings. Most importantly, we show that these improvements translate to zero-shot medical anomaly detection, one of the extreme forms of data heterogeneity and asymmetry. The code is available on https://github.com/AyushRoy2001/Beyond-Pooling.", "AI": {"tldr": "\u63d0\u51fa\u5339\u914d\u6846\u67b6\u89e3\u51b3\u5f02\u6784\u6570\u636e\u96c6\u6c60\u5316\u4e2d\u7684\u5206\u5e03\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8d28\u5fc3\u9009\u62e9\u548c\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b", "motivation": "\u5f02\u6784\u6570\u636e\u96c6\u6c60\u5316\u4f1a\u653e\u5927\u5206\u5e03\u4e0d\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u4f30\u8ba1\u504f\u5dee\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u96f6\u6837\u672c\u6cdb\u5316\u7684\u573a\u666f\u4e2d\u3002\u4f20\u7edf\u6c60\u5316\u548c\u5747\u5300\u5b50\u91c7\u6837\u65e0\u6cd5\u6709\u6548\u5904\u7406\u9886\u57df\u6df7\u6dc6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5339\u914d\u6846\u67b6\uff1a\u57fa\u4e8e\u81ea\u9002\u5e94\u8d28\u5fc3\u9009\u62e9\u6837\u672c\uff0c\u8fed\u4ee3\u4f18\u5316\u8868\u793a\u5206\u5e03\u3002\u7ed3\u5408\u53cc\u91cd\u9c81\u68d2\u6027\u548c\u503e\u5411\u5f97\u5206\u5339\u914d\u6765\u5305\u542b\u6570\u636e\u9886\u57df\uff0c\u8fc7\u6ee4\u6df7\u6dc6\u9886\u57df\uff08\u5f02\u8d28\u6027\u7684\u4e3b\u8981\u539f\u56e0\uff09\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0c\u5339\u914d\u65b9\u6cd5\u5728\u4e0d\u5bf9\u79f0\u5143\u5206\u5e03\u4e0b\u4f18\u4e8e\u4f20\u7edf\u6c60\u5316\u548c\u5747\u5300\u5b50\u91c7\u6837\uff0c\u4e14\u6269\u5c55\u5230\u975e\u9ad8\u65af\u548c\u591a\u6a21\u6001\u73b0\u5b9e\u573a\u666f\u3002\u5728\u96f6\u6837\u672c\u533b\u7597\u5f02\u5e38\u68c0\u6d4b\uff08\u6781\u7aef\u6570\u636e\u5f02\u8d28\u6027\u548c\u4e0d\u5bf9\u79f0\u6027\uff09\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u5339\u914d\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u5f02\u6784\u6570\u636e\u96c6\u6c60\u5316\u4e2d\u7684\u5206\u5e03\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u63d0\u5347\u96f6\u6837\u672c\u6cdb\u5316\u6027\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533b\u7597\u5f02\u5e38\u68c0\u6d4b\u7b49\u6781\u7aef\u5f02\u8d28\u6027\u573a\u666f\u3002"}}
{"id": "2602.08757", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08757", "abs": "https://arxiv.org/abs/2602.08757", "authors": ["Luigi Romano", "Ole Morten Aamo", "Miroslav Krsti\u0107", "Jan \u00c5slund", "Erik Frisk"], "title": "Stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics via singular perturbation analysis", "comment": "17 pages, 9 figures. Under review at Automatica", "summary": "This paper investigates the stability and stabilization of semilinear single-track vehicle models with distributed tire friction dynamics, modeled as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). Motivated by the long-standing practice of neglecting transient tire dynamics in vehicle modeling and control, a rigorous justification is provided for such simplifications using singular perturbation theory. A perturbation parameter, defined as the ratio between a characteristic rolling contact length and the vehicle's longitudinal speed, is introduced to formalize the time-scale separation between rigid-body motion and tire dynamics. For sufficiently small values of this parameter, it is demonstrated that standard finite-dimensional techniques can be applied to analyze the local stability of equilibria and to design stabilizing controllers. Both state-feedback and output-feedback designs are considered, under standard stabilizability and detectability assumptions. Whilst the proposed controllers follow classical approaches, the novelty of the work lies in establishing the first mathematical framework that rigorously connects distributed tire models with conventional vehicle dynamics. The results reconcile decades of empirical findings with a formal theoretical foundation and open new perspectives for the analysis and control of ODE-PDE systems with distributed friction in automotive applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u5ffd\u7565\u8f6e\u80ce\u77ac\u6001\u52a8\u529b\u5b66\u7684\u4f20\u7edf\u8f66\u8f86\u5efa\u6a21\u4e0e\u63a7\u5236\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u4f9d\u636e\uff0c\u901a\u8fc7\u5947\u5f02\u6444\u52a8\u7406\u8bba\u5efa\u7acb\u4e86\u9996\u4e2a\u8fde\u63a5\u5206\u5e03\u5f0f\u8f6e\u80ce\u6a21\u578b\u4e0e\u4f20\u7edf\u8f66\u8f86\u52a8\u529b\u5b66\u7684\u6570\u5b66\u6846\u67b6\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\uff0c\u8f66\u8f86\u5efa\u6a21\u4e0e\u63a7\u5236\u4e2d\u666e\u904d\u5ffd\u7565\u8f6e\u80ce\u77ac\u6001\u52a8\u529b\u5b66\uff0c\u4f46\u7f3a\u4e4f\u4e25\u683c\u7684\u7406\u8bba\u4f9d\u636e\u3002\u672c\u6587\u65e8\u5728\u4e3a\u8fd9\u79cd\u7b80\u5316\u5b9e\u8df5\u63d0\u4f9b\u6570\u5b66\u8bc1\u660e\uff0c\u5e76\u5efa\u7acb\u8fde\u63a5\u5206\u5e03\u5f0f\u8f6e\u80ce\u6a21\u578b\u4e0e\u4f20\u7edf\u8f66\u8f86\u52a8\u529b\u5b66\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f15\u5165\u6444\u52a8\u53c2\u6570\uff08\u7279\u5f81\u6eda\u52a8\u63a5\u89e6\u957f\u5ea6\u4e0e\u8f66\u8f86\u7eb5\u5411\u901f\u5ea6\u4e4b\u6bd4\uff09\uff0c\u5229\u7528\u5947\u5f02\u6444\u52a8\u7406\u8bba\u5f62\u5f0f\u5316\u521a\u4f53\u8fd0\u52a8\u4e0e\u8f6e\u80ce\u52a8\u529b\u5b66\u4e4b\u95f4\u7684\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u3002\u5728\u53c2\u6570\u8db3\u591f\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0c\u5e94\u7528\u6807\u51c6\u6709\u9650\u7ef4\u6280\u672f\u5206\u6790\u5e73\u8861\u70b9\u7684\u5c40\u90e8\u7a33\u5b9a\u6027\u5e76\u8bbe\u8ba1\u7a33\u5b9a\u63a7\u5236\u5668\u3002", "result": "\u8bc1\u660e\u4e86\u5f53\u6444\u52a8\u53c2\u6570\u8db3\u591f\u5c0f\u65f6\uff0c\u53ef\u4ee5\u4f7f\u7528\u6709\u9650\u7ef4\u6280\u672f\u5206\u6790ODE-PDE\u7cfb\u7edf\u7684\u5c40\u90e8\u7a33\u5b9a\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u72b6\u6001\u53cd\u9988\u548c\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u5668\u3002\u4e3a\u4f20\u7edf\u8f66\u8f86\u63a7\u5236\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5efa\u7acb\u4e86\u8fde\u63a5\u5206\u5e03\u5f0f\u8f6e\u80ce\u6a21\u578b\u4e0e\u4f20\u7edf\u8f66\u8f86\u52a8\u529b\u5b66\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u6570\u5341\u5e74\u7684\u7ecf\u9a8c\u53d1\u73b0\u4e0e\u5f62\u5f0f\u7406\u8bba\u76f8\u7edf\u4e00\uff0c\u4e3a\u6c7d\u8f66\u5e94\u7528\u4e2d\u5177\u6709\u5206\u5e03\u5f0f\u6469\u64e6\u7684ODE-PDE\u7cfb\u7edf\u5206\u6790\u4e0e\u63a7\u5236\u5f00\u8f9f\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.08933", "categories": ["stat.ML", "cs.LG", "cs.NE", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.08933", "abs": "https://arxiv.org/abs/2602.08933", "authors": ["Abhik Ghosh", "Suryasis Jana"], "title": "Provably robust learning of regression neural networks using $\u03b2$-divergences", "comment": "Pre-print, under review", "summary": "Regression neural networks (NNs) are most commonly trained by minimizing the mean squared prediction error, which is highly sensitive to outliers and data contamination. Existing robust training methods for regression NNs are often limited in scope and rely primarily on empirical validation, with only a few offering partial theoretical guarantees. In this paper, we propose a new robust learning framework for regression NNs based on the $\u03b2$-divergence (also known as the density power divergence) which we call `rRNet'. It applies to a broad class of regression NNs, including models with non-smooth activation functions and error densities, and recovers the classical maximum likelihood learning as a special case. The rRNet is implemented via an alternating optimization scheme, for which we establish convergence guarantees to stationary points under mild, verifiable conditions. The (local) robustness of rRNet is theoretically characterized through the influence functions of both the parameter estimates and the resulting rRNet predictor, which are shown to be bounded for suitable choices of the tuning parameter $\u03b2$, depending on the error density. We further prove that rRNet attains the optimal 50\\% asymptotic breakdown point at the assumed model for all $\u03b2\\in(0, 1]$, providing a strong global robustness guarantee that is largely absent for existing NN learning methods. Our theoretical results are complemented by simulation experiments and real-data analyses, illustrating practical advantages of rRNet over existing approaches in both function approximation problems and prediction tasks with noisy observations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u03b2-\u6563\u5ea6\u7684\u7a33\u5065\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\u6846\u67b6rRNet\uff0c\u5bf9\u5f02\u5e38\u503c\u5177\u6709\u9c81\u68d2\u6027\uff0c\u63d0\u4f9b\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u548c50%\u6e10\u8fd1\u5d29\u6e83\u70b9", "motivation": "\u4f20\u7edf\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\u4f7f\u7528\u5747\u65b9\u8bef\u5dee\u635f\u5931\uff0c\u5bf9\u5f02\u5e38\u503c\u9ad8\u5ea6\u654f\u611f\u3002\u73b0\u6709\u7a33\u5065\u8bad\u7ec3\u65b9\u6cd5\u8303\u56f4\u6709\u9650\uff0c\u4e3b\u8981\u4f9d\u8d56\u7ecf\u9a8c\u9a8c\u8bc1\uff0c\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1", "method": "\u57fa\u4e8e\u03b2-\u6563\u5ea6\uff08\u5bc6\u5ea6\u5e42\u6563\u5ea6\uff09\u6784\u5efa\u7a33\u5065\u5b66\u4e60\u6846\u67b6rRNet\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\uff0c\u5305\u62ec\u975e\u5149\u6ed1\u6fc0\u6d3b\u51fd\u6570\u548c\u8bef\u5dee\u5bc6\u5ea6\u6a21\u578b\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u65b9\u6848\u5b9e\u73b0", "result": "\u5efa\u7acb\u4e86\u5728\u6e29\u548c\u53ef\u9a8c\u8bc1\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u4fdd\u8bc1\uff1b\u7406\u8bba\u8bc1\u660e\u4e86\u53c2\u6570\u4f30\u8ba1\u548c\u9884\u6d4b\u5668\u7684\u5f71\u54cd\u51fd\u6570\u6709\u754c\uff1b\u83b7\u5f97\u4e8650%\u6e10\u8fd1\u5d29\u6e83\u70b9\u7684\u5168\u5c40\u7a33\u5065\u6027\u4fdd\u8bc1\uff1b\u5b9e\u9a8c\u663e\u793a\u5728\u51fd\u6570\u903c\u8fd1\u548c\u566a\u58f0\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "rRNet\u4e3a\u56de\u5f52\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u7684\u7a33\u5065\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5c40\u90e8\u548c\u5168\u5c40\u7a33\u5065\u6027\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u7684\u7a7a\u767d"}}
{"id": "2602.08707", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08707", "abs": "https://arxiv.org/abs/2602.08707", "authors": ["Aditya Gulati", "Nuria Oliver"], "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers", "comment": null, "summary": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06\u804a\u5929\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9ad8\u5ea6\u719f\u7ec3\u7684\u9500\u552e\u5458\u800c\u975e\u4f34\u4fa3\u6216\u52a9\u624b\uff0c\u6307\u51fa\u7528\u6237\u4fe1\u4efb\u4e3b\u8981\u6765\u81ea\u4ea4\u4e92\u8bbe\u8ba1\u5229\u7528\u8ba4\u77e5\u504f\u89c1\u800c\u975e\u7cfb\u7edf\u53ef\u4fe1\u5ea6\uff0c\u9700\u8981\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u804a\u5929\u673a\u5668\u4eba\u6a21\u7cca\u81ea\u52a8\u5316\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u5bf9\u8bdd\u7684\u754c\u9650\uff0c\u9700\u8981\u66f4\u4ed4\u7ec6\u5ba1\u89c6\u8fd9\u4e9b\u7cfb\u7edf\u7684\u4fe1\u4efb\u57fa\u7840\u3002\u5f53\u524d\u76d1\u7ba1\u6846\u67b6\u503e\u5411\u4e8e\u4ece\u89c4\u8303\u89d2\u5ea6\u5b9a\u4e49\u4fe1\u4efb\uff0c\u800c\u7528\u6237\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u4fe1\u4efb\u5f80\u5f80\u6765\u81ea\u884c\u4e3a\u673a\u5236\uff0c\u8fd9\u79cd\u4fe1\u4efb\u901a\u5e38\u4e0d\u662f\u901a\u8fc7\u8bc1\u660e\u53ef\u4fe1\u5ea6\u83b7\u5f97\uff0c\u800c\u662f\u901a\u8fc7\u4ea4\u4e92\u8bbe\u8ba1\u5229\u7528\u8ba4\u77e5\u504f\u89c1\u6765\u5f71\u54cd\u7528\u6237\u884c\u4e3a\u3002", "method": "\u57fa\u4e8e\u89c2\u5bdf\u63d0\u51fa\u6982\u5ff5\u6027\u91cd\u6784\u6846\u67b6\uff1a\u5c06\u804a\u5929\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9ad8\u5ea6\u719f\u7ec3\u7684\u9500\u552e\u5458\uff0c\u5176\u76ee\u6807\u7531\u90e8\u7f72\u7ec4\u7ec7\u51b3\u5b9a\u3002\u5206\u6790\u7ade\u4e89\u6027\"\u4fe1\u4efb\"\u6982\u5ff5\u5171\u5b58\u4e8e\u540c\u4e00\u672f\u8bed\u4e0b\u5982\u4f55\u6a21\u7cca\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b\u3002", "result": "\u8bc6\u522b\u51fa\u7528\u6237\u4fe1\u4efb\u4e3b\u8981\u6765\u81ea\u4ea4\u4e92\u8bbe\u8ba1\u5bf9\u8ba4\u77e5\u504f\u89c1\u7684\u5229\u7528\uff0c\u800c\u975e\u7cfb\u7edf\u5b9e\u9645\u53ef\u4fe1\u5ea6\u3002\u63ed\u793a\u4e86\"\u4fe1\u4efb\"\u672f\u8bed\u4e0b\u63a9\u76d6\u7684\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u673a\u5236\u4e0e\u89c4\u8303\u53ef\u4fe1\u5ea6\u6807\u51c6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u66f4\u5f3a\u652f\u6301\u673a\u5236\u6765\u5e2e\u52a9\u7528\u6237\u9002\u5f53\u6821\u51c6\u5bf9\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u4fe1\u4efb\uff0c\u89e3\u51b3\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u786e\u4fdd\u7528\u6237\u4e0d\u88ab\u8bbe\u8ba1\u9009\u62e9\u8bef\u5bfc\u800c\u5efa\u7acb\u4e0d\u5f53\u4fe1\u4efb\u3002"}}
{"id": "2602.07975", "categories": ["math.OC", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07975", "abs": "https://arxiv.org/abs/2602.07975", "authors": ["Yuhan Chen", "Tao Liu", "Jie Huang"], "title": "Leader-following Consensus over Jointly Connected Switching Networks is Achievable for Exponentially Unstable Linear Systems", "comment": null, "summary": "The leader-following consensus problem for general linear multi-agent systems over jointly connected switching networks has been a challenging problem and the solvability of the problem has been limited to the class of linear multi-agent systems whose system matrix is marginally stable. This condition is restrictive since it even excludes the most commonly used double-integrator system. This paper presents a breakthrough by demonstrating that leader-following exponential consensus is achievable for general linear multi-agent systems over jointly connected switching networks, even when the system matrix is exponentially unstable. The degree of instability can be explicitly characterized by two key quantities that arise from the jointly connected condition on a switching graph. By exploiting duality, we further show that the output-based distributed observer design problem for a general leader system is solvable over jointly connected switching networks, even when the system matrix is exponentially unstable. This is also in sharp contrast to the existing distributed observers, which rely on the assumption that the leader system is marginally stable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7a81\u7834\u4e86\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8054\u5408\u8fde\u901a\u5207\u6362\u7f51\u7edc\u4e0b\u9886\u5bfc\u8ddf\u968f\u5171\u8bc6\u95ee\u9898\u7684\u9650\u5236\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u7cfb\u7edf\u77e9\u9635\u6307\u6570\u4e0d\u7a33\u5b9a\u4e5f\u80fd\u5b9e\u73b0\u6307\u6570\u5171\u8bc6\uff0c\u5e76\u89e3\u51b3\u4e86\u8f93\u51fa\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u8bbe\u8ba1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8981\u6c42\u7cfb\u7edf\u77e9\u9635\u5fc5\u987b\u662f\u8fb9\u9645\u7a33\u5b9a\u7684\uff0c\u8fd9\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\uff08\u751a\u81f3\u6392\u9664\u4e86\u5e38\u7528\u7684\u53cc\u79ef\u5206\u5668\u7cfb\u7edf\uff09\u3002\u9700\u8981\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u89e3\u51b3\u4e00\u822c\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8054\u5408\u8fde\u901a\u5207\u6362\u7f51\u7edc\u4e0b\u7684\u9886\u5bfc\u8ddf\u968f\u5171\u8bc6\u95ee\u9898\u3002", "method": "\u5229\u7528\u8054\u5408\u8fde\u901a\u5207\u6362\u56fe\u6761\u4ef6\u4ea7\u751f\u7684\u4e24\u4e2a\u5173\u952e\u91cf\u6765\u660e\u786e\u8868\u5f81\u4e0d\u7a33\u5b9a\u7a0b\u5ea6\uff0c\u901a\u8fc7\u5229\u7528\u5bf9\u5076\u6027\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u4e86\u8f93\u51fa\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u8bbe\u8ba1\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u5373\u4f7f\u7cfb\u7edf\u77e9\u9635\u6307\u6570\u4e0d\u7a33\u5b9a\uff0c\u4e5f\u80fd\u5728\u8054\u5408\u8fde\u901a\u5207\u6362\u7f51\u7edc\u4e0a\u5b9e\u73b0\u9886\u5bfc\u8ddf\u968f\u6307\u6570\u5171\u8bc6\uff0c\u5e76\u89e3\u51b3\u4e86\u8f93\u51fa\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u8bbe\u8ba1\u95ee\u9898\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u8981\u6c42\u9886\u5bfc\u7cfb\u7edf\u8fb9\u9645\u7a33\u5b9a\u7684\u5047\u8bbe\u3002", "conclusion": "\u8be5\u7814\u7a76\u7a81\u7834\u4e86\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8054\u5408\u8fde\u901a\u5207\u6362\u7f51\u7edc\u4e0b\u9886\u5bfc\u8ddf\u968f\u5171\u8bc6\u95ee\u9898\u7684\u9650\u5236\u6761\u4ef6\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u5b9e\u9645\u7cfb\u7edf\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u7279\u522b\u662f\u5728\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2602.07382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07382", "abs": "https://arxiv.org/abs/2602.07382", "authors": ["Debtanu Datta", "Rajdeep Mukherjee", "Adrijit Goswami", "Saptarshi Ghosh"], "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi", "comment": "19 pages, 5 figures, 8 tables", "summary": "Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u6458\u8981\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\u5230\u591a\u79cd\u6458\u8981\u6a21\u578b\u4e2d\uff0c\u751f\u6210\u82f1\u8bed\u548c\u5370\u5730\u8bed\u7684\u6cd5\u5f8b\u5224\u51b3\u6458\u8981\u3002", "motivation": "\u5370\u5ea6\u6cd5\u5f8b\u5224\u51b3\u6458\u8981\u7684\u590d\u6742\u6027\u6e90\u4e8e\u6cd5\u5f8b\u6587\u672c\u7684\u590d\u6742\u8bed\u8a00\u548c\u975e\u7ed3\u6784\u5316\u7279\u6027\uff0c\u4e14\u5927\u90e8\u5206\u5370\u5ea6\u4eba\u53e3\u4e0d\u7406\u89e3\u6cd5\u5f8b\u6587\u672c\u4f7f\u7528\u7684\u590d\u6742\u82f1\u8bed\uff0c\u56e0\u6b64\u9700\u8981\u5370\u5ea6\u8bed\u8a00\u7684\u6458\u8981\u3002", "method": "\u63d0\u51fa\u6846\u67b6\u589e\u5f3a\u62bd\u53d6\u5f0f\u795e\u7ecf\u6458\u8981\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u9488\u5bf9\u6cd5\u5f8b\u6587\u672c\u7684\u9886\u57df\u7279\u5b9a\u9884\u8bad\u7ec3\u7f16\u7801\u5668\uff1b\u63a2\u7d22\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u5728\u5927\u578b\u82f1\u8bed\u548c\u5370\u5730\u8bed\u6cd5\u5f8b\u8bed\u6599\u5e93\u4e0a\uff0c\u5c06\u6cd5\u5f8b\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u751f\u6210\u6a21\u578b\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\uff09\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u82f1\u8bed\u5230\u82f1\u8bed\u548c\u82f1\u8bed\u5230\u5370\u5730\u8bed\u7684\u5370\u5ea6\u6cd5\u5f8b\u6587\u6863\u6458\u8981\u4e2d\uff0c\u5728\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u3001\u4e8b\u5b9e\u4e00\u81f4\u6027\u6307\u6807\u548c\u6cd5\u5f8b\u9886\u57df\u7279\u5b9a\u6307\u6807\u4e0a\u90fd\u53d6\u5f97\u4e86\u7edf\u8ba1\u663e\u8457\u7684\u6539\u8fdb\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6ce8\u5165\u6cd5\u5f8b\u9886\u57df\u77e5\u8bc6\u5230\u6458\u8981\u6a21\u578b\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u6539\u8fdb\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u7684\u6458\u8981\u8d28\u91cf\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u82f1\u8bed\u548c\u5370\u5730\u8bed\u6cd5\u5f8b\u6458\u8981\uff0c\u6ee1\u8db3\u5370\u5ea6\u591a\u8bed\u8a00\u4eba\u53e3\u7684\u9700\u6c42\u3002"}}
{"id": "2602.07391", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07391", "abs": "https://arxiv.org/abs/2602.07391", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents", "comment": null, "summary": "AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring \"benign-use correctness\", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.", "AI": {"tldr": "NAAMSE\u662f\u4e00\u4e2a\u8fdb\u5316\u6846\u67b6\uff0c\u5c06AI\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53cd\u9988\u9a71\u52a8\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u9057\u4f20\u63d0\u793a\u7a81\u53d8\u3001\u5206\u5c42\u8bed\u6599\u5e93\u63a2\u7d22\u548c\u975e\u5bf9\u79f0\u884c\u4e3a\u8bc4\u5206\u6765\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u667a\u80fd\u4f53\u6f0f\u6d1e\u3002", "motivation": "\u5f53\u524dAI\u667a\u80fd\u4f53\u5b89\u5168\u8bc4\u4f30\u5b58\u5728\u74f6\u9888\uff1a\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u7ea2\u961f\u6d4b\u8bd5\u6216\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u6cd5\u6a21\u62df\u81ea\u9002\u5e94\u3001\u591a\u8f6e\u6b21\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u96be\u4ee5\u5e94\u5bf9\u4e0d\u65ad\u6f14\u5316\u7684\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5355\u4e2a\u81ea\u4e3b\u667a\u80fd\u4f53\u534f\u8c03\u9057\u4f20\u63d0\u793a\u7a81\u53d8\u3001\u5206\u5c42\u8bed\u6599\u5e93\u63a2\u7d22\u548c\u975e\u5bf9\u79f0\u884c\u4e3a\u8bc4\u5206\u7684\u751f\u547d\u5468\u671f\u3002\u5229\u7528\u6a21\u578b\u54cd\u5e94\u4f5c\u4e3a\u9002\u5e94\u5ea6\u4fe1\u53f7\uff0c\u8fed\u4ee3\u5730\u7ec4\u5408\u6709\u6548\u653b\u51fb\u7b56\u7565\uff0c\u540c\u65f6\u786e\u4fdd\"\u826f\u6027\u4f7f\u7528\u6b63\u786e\u6027\"\uff0c\u907f\u514d\u667a\u80fd\u4f53\u91c7\u53d6\u5168\u9762\u62d2\u7edd\u7684\u9000\u5316\u5b89\u5168\u7b56\u7565\u3002", "result": "\u5728Gemini 2.5 Flash\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fdb\u5316\u7a81\u53d8\u7cfb\u7edf\u6027\u5730\u653e\u5927\u4e86\u5355\u6b21\u65b9\u6cd5\u9057\u6f0f\u7684\u6f0f\u6d1e\u3002\u53d7\u63a7\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff0c\u63a2\u7d22\u4e0e\u5b9a\u5411\u7a81\u53d8\u7684\u534f\u540c\u4f5c\u7528\u80fd\u591f\u53d1\u73b0\u9ad8\u4e25\u91cd\u6027\u6545\u969c\u6a21\u5f0f\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u771f\u5b9e\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u9c81\u68d2\u6027\u8bc4\u4f30\u3002", "conclusion": "NAAMSE\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u771f\u5b9e\u3001\u53ef\u6269\u5c55\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u9762\u5bf9\u4e0d\u65ad\u6f14\u5316\u5a01\u80c1\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.07156", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07156", "abs": "https://arxiv.org/abs/2602.07156", "authors": ["Asher Trockman", "J. Zico Kolter"], "title": "Mimetic Initialization of MLPs", "comment": null, "summary": "Mimetic initialization uses pretrained models as case studies of good initialization, using observations of structures in trained weights to inspire new, simple initialization techniques. So far, it has been applied only to spatial mixing layers, such convolutional, self-attention, and state space layers. In this work, we present the first attempt to apply the method to channel mixing layers, namely multilayer perceptrons (MLPs). Our extremely simple technique for MLPs -- to give the first layer a nonzero mean -- speeds up training on small-scale vision tasks like CIFAR-10 and ImageNet-1k. Though its effect is much smaller than spatial mixing initializations, it can be used in conjunction with them for an additional positive effect.", "AI": {"tldr": "\u9996\u6b21\u5c06\u6a21\u4eff\u521d\u59cb\u5316\u5e94\u7528\u4e8e\u901a\u9053\u6df7\u5408\u5c42\uff08MLP\uff09\uff0c\u901a\u8fc7\u7ed9\u7b2c\u4e00\u5c42\u8d4b\u4e88\u975e\u96f6\u5747\u503c\u6765\u52a0\u901f\u5c0f\u89c4\u6a21\u89c6\u89c9\u4efb\u52a1\u7684\u8bad\u7ec3", "motivation": "\u6a21\u4eff\u521d\u59cb\u5316\u4e4b\u524d\u53ea\u5e94\u7528\u4e8e\u7a7a\u95f4\u6df7\u5408\u5c42\uff08\u5982\u5377\u79ef\u3001\u81ea\u6ce8\u610f\u529b\u3001\u72b6\u6001\u7a7a\u95f4\u5c42\uff09\uff0c\u672c\u6587\u9996\u6b21\u5c1d\u8bd5\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230\u901a\u9053\u6df7\u5408\u5c42\uff08\u591a\u5c42\u611f\u77e5\u673aMLP\uff09", "method": "\u63d0\u51fa\u6781\u5176\u7b80\u5355\u7684MLP\u521d\u59cb\u5316\u6280\u672f\uff1a\u7ed9\u7b2c\u4e00\u5c42\u8d4b\u4e88\u975e\u96f6\u5747\u503c\uff0c\u53ef\u4ee5\u4e0e\u7a7a\u95f4\u6df7\u5408\u521d\u59cb\u5316\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528", "result": "\u8be5\u6280\u672f\u80fd\u52a0\u901fCIFAR-10\u548cImageNet-1k\u7b49\u5c0f\u89c4\u6a21\u89c6\u89c9\u4efb\u52a1\u7684\u8bad\u7ec3\uff0c\u867d\u7136\u6548\u679c\u6bd4\u7a7a\u95f4\u6df7\u5408\u521d\u59cb\u5316\u5c0f\uff0c\u4f46\u7ed3\u5408\u4f7f\u7528\u65f6\u80fd\u4ea7\u751f\u989d\u5916\u6b63\u5411\u6548\u679c", "conclusion": "\u6210\u529f\u5c06\u6a21\u4eff\u521d\u59cb\u5316\u6269\u5c55\u5230\u901a\u9053\u6df7\u5408\u5c42\uff0c\u8bc1\u660e\u4e86\u7b80\u5355\u521d\u59cb\u5316\u6280\u672f\u5bf9MLP\u7684\u6709\u6548\u6027\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u521d\u59cb\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2602.08767", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08767", "abs": "https://arxiv.org/abs/2602.08767", "authors": ["Luigi Romano", "Ole Morten Aamo", "Miroslav Krsti\u0107", "Jan \u00c5slund", "Erik Frisk"], "title": "Passivity-exploiting stabilization of semilinear single-track vehicle models with distributed tire friction dynamics", "comment": "17 pages, 10 figures. Under review at Automatica", "summary": "This paper addresses the local stabilization problem for semilinear single-track vehicle models with distributed tire friction dynamics, represented as interconnections of ordinary differential equations (ODEs) and hyperbolic partial differential equations (PDEs). A passivity-exploiting backstepping design is presented, which leverages the strict dissipativity properties of the PDE subsystem to achieve exponential stabilization of the considered ODE-PDE interconnection around a prescribed equilibrium. Sufficient conditions for local well-posedness and exponential convergence are derived by constructing a Lyapunov functional combining the lumped and distributed states. Both state-feedback and output-feedback controllers are synthesized, the latter relying on a cascaded observer. The theoretical results are corroborated with numerical simulations, considering non-ideal scenarios and accounting for external disturbances and uncertainties. Simulation results confirm that the proposed control strategy can effectively and robustly stabilize oversteer vehicles at high speeds, demonstrating the relevance of the approach for improving the safety and performance in automotive applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65e0\u6e90\u6027\u53cd\u6b65\u6cd5\u7684ODE-PDE\u4e92\u8054\u7cfb\u7edf\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u8f6e\u80ce\u6469\u64e6\u52a8\u529b\u5b66\u7684\u5355\u8f68\u8f66\u8f86\u6a21\u578b\u5c40\u90e8\u9547\u5b9a", "motivation": "\u89e3\u51b3\u5177\u6709\u5206\u5e03\u5f0f\u8f6e\u80ce\u6469\u64e6\u52a8\u529b\u5b66\u7684\u534a\u7ebf\u6027\u5355\u8f68\u8f66\u8f86\u6a21\u578b\u7684\u5c40\u90e8\u9547\u5b9a\u95ee\u9898\uff0c\u8fd9\u7c7b\u7cfb\u7edf\u7531ODE\u548c\u53cc\u66f2PDE\u4e92\u8054\u6784\u6210\uff0c\u5bf9\u63d0\u9ad8\u6c7d\u8f66\u9ad8\u901f\u884c\u9a76\u65f6\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49", "method": "\u91c7\u7528\u65e0\u6e90\u6027\u53cd\u6b65\u6cd5\u8bbe\u8ba1\uff0c\u5229\u7528PDE\u5b50\u7cfb\u7edf\u7684\u4e25\u683c\u8017\u6563\u7279\u6027\uff0c\u6784\u5efa\u7ed3\u5408\u96c6\u4e2d\u548c\u5206\u5e03\u72b6\u6001\u7684Lyapunov\u6cdb\u51fd\uff0c\u63a8\u5bfc\u5c40\u90e8\u9002\u5b9a\u6027\u548c\u6307\u6570\u6536\u655b\u7684\u5145\u5206\u6761\u4ef6\uff0c\u540c\u65f6\u8bbe\u8ba1\u72b6\u6001\u53cd\u9988\u548c\u57fa\u4e8e\u7ea7\u8054\u89c2\u6d4b\u5668\u7684\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u5668", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u63a7\u5236\u7b56\u7565\u5728\u975e\u7406\u60f3\u573a\u666f\u3001\u5916\u90e8\u6270\u52a8\u548c\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u9c81\u68d2\u5730\u7a33\u5b9a\u9ad8\u901f\u8fc7\u8f6c\u5411\u8f66\u8f86", "conclusion": "\u6240\u63d0\u51fa\u7684\u63a7\u5236\u65b9\u6cd5\u80fd\u6709\u6548\u9547\u5b9a\u5177\u6709\u5206\u5e03\u5f0f\u8f6e\u80ce\u6469\u64e6\u52a8\u529b\u5b66\u7684ODE-PDE\u4e92\u8054\u8f66\u8f86\u7cfb\u7edf\uff0c\u4e3a\u63d0\u9ad8\u6c7d\u8f66\u5e94\u7528\u7684\u5b89\u5168\u6027\u548c\u6027\u80fd\u63d0\u4f9b\u4e86\u76f8\u5173\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08754", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08754", "abs": "https://arxiv.org/abs/2602.08754", "authors": ["Rose E. Guingrich", "Dvija Mehta", "Umang Bhatt"], "title": "Belief Offloading in Human-AI Interaction", "comment": null, "summary": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f53\u4eba\u4eec\u7684\u4fe1\u5ff5\u6765\u81eaLLM\u65f6\u4f1a\u53d1\u751f\u4ec0\u4e48\uff0c\u63d0\u51fa\u4e86\"\u4fe1\u5ff5\u5378\u8f7d\"\u6982\u5ff5\uff0c\u5373\u4eba\u4eec\u5c06\u4fe1\u5ff5\u5f62\u6210\u548c\u7ef4\u62a4\u8fc7\u7a0b\u5916\u5305\u7ed9AI\u7cfb\u7edf\uff0c\u8fd9\u5bf9\u8ba4\u77e5\u6280\u80fd\u548c\u884c\u4e3a\u6709\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u968f\u7740LLM\u804a\u5929\u673a\u5668\u4eba\u4f5c\u4e3a\u601d\u7ef4\u4f19\u4f34\u7684\u666e\u53ca\uff0c\u4eba\u4eec\u53ef\u80fd\u8fc7\u5ea6\u4f9d\u8d56AI\u8fdb\u884c\u8ba4\u77e5\u5904\u7406\uff0c\u5bfc\u81f4\u8ba4\u77e5\u6280\u80fd\u9000\u5316\u3002\u9700\u8981\u7814\u7a76\u8fd9\u79cd\"\u4fe1\u5ff5\u5378\u8f7d\"\u73b0\u8c61\u53ca\u5176\u5bf9\u4eba\u7c7b\u4fe1\u5ff5\u7cfb\u7edf\u548c\u884c\u4e3a\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u54f2\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\uff0c\u660e\u786e\u5b9a\u4e49\u4fe1\u5ff5\u5378\u8f7d\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u63d0\u4f9b\u63cf\u8ff0\u6027\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u6790\u5176\u89c4\u8303\u6027\u542b\u4e49\u3002\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u3002", "result": "\u63d0\u51fa\u4e86\u4fe1\u5ff5\u5378\u8f7d\u7684\u660e\u786e\u5b9a\u4e49\u548c\u5206\u7c7b\u4f53\u7cfb\uff0c\u8bc6\u522b\u4e86\u5176\u53d1\u751f\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u5206\u6790\u4e86\u8fd9\u79cd\u8ba4\u77e5\u5916\u5305\u5bf9\u4eba\u4eec\u4fe1\u5ff5\u7cfb\u7edf\u548c\u884c\u4e3a\u7684\u89c4\u8303\u6027\u5f71\u54cd\u3002", "conclusion": "\u4fe1\u5ff5\u5378\u8f7d\u662f\u4eba\u4e0eAI\u4ea4\u4e92\u4e2d\u4e00\u79cd\u91cd\u8981\u7684\u8ba4\u77e5\u73b0\u8c61\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u53d1\u751f\u673a\u5236\u548c\u540e\u679c\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u8bc4\u4f30\u4fe1\u5ff5\u5378\u8f7d\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u5065\u5eb7\u7684AI\u4ea4\u4e92\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2602.08018", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08018", "abs": "https://arxiv.org/abs/2602.08018", "authors": ["Yulin Feng", "Xianyu Li", "Steven X. Ding", "Hao Ye", "Chao Shang"], "title": "Sinkhorn Distributionally Robust State Estimation via System Level Synthesis", "comment": "15 pages, 5 figures", "summary": "In state estimation tasks, the usual assumption of exactly known disturbance distribution is often unrealistic and renders the estimator fragile in practice. The recently emerging Wasserstein distributionally robust state estimation (DRSE) design can partially mitigate this fragility; however, its worst-case distribution is provably discrete, which deviates from the inherent continuity of real-world distributions and results in over-pessimism. In this work, we develop a new Sinkhorn DRSE design within system level synthesis scheme with the aim of shaping the closed-loop errors under the unknown continuous disturbance distribution. For uncertainty description, we adopt the Sinkhorn ambiguity set that includes an entropic regularizer to penalize non-smooth and discrete distributions within a Wasserstein ball. We present the first result of finite-sample probabilistic guarantee of the Sinkhorn ambiguity set. Then we analyze the limiting properties of our Sinkhorn DRSE design, thereby highlighting its close connection with the generic $\\mathcal{H}_2$ design and Wasserstein DRSE. To tackle the min-max optimization problem, we reformulate it as a finite-dimensional convex program through duality theory. By identifying a compact subset of the feasible set guaranteed to enclose the global optimum, we develop a tailored Frank-Wolfe solution algorithm and formally establish its convergence rate. The advantage of Sinkhorn DRSE over existing design schemes is verified through numerical case studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSinkhorn\u8ddd\u79bb\u7684\u5206\u5e03\u9c81\u68d2\u72b6\u6001\u4f30\u8ba1\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5f15\u5165\u71b5\u6b63\u5219\u5316\u9879\u6765\u907f\u514d\u4f20\u7edfWasserstein DRSE\u7684\u8fc7\u5ea6\u60b2\u89c2\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u6709\u9650\u6837\u672c\u6982\u7387\u4fdd\u8bc1\u3002", "motivation": "\u4f20\u7edf\u72b6\u6001\u4f30\u8ba1\u5047\u8bbe\u6270\u52a8\u5206\u5e03\u7cbe\u786e\u5df2\u77e5\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e2d\u4e0d\u5207\u5b9e\u9645\u4e14\u4f7f\u4f30\u8ba1\u5668\u8106\u5f31\u3002\u73b0\u6709\u7684Wasserstein\u5206\u5e03\u9c81\u68d2\u72b6\u6001\u4f30\u8ba1\uff08DRSE\uff09\u867d\u7136\u80fd\u90e8\u5206\u7f13\u89e3\u8106\u5f31\u6027\uff0c\u4f46\u5176\u6700\u574f\u60c5\u51b5\u5206\u5e03\u88ab\u8bc1\u660e\u662f\u79bb\u6563\u7684\uff0c\u4e0e\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u7684\u8fde\u7eed\u6027\u4e0d\u7b26\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u60b2\u89c2\u3002", "method": "\u5728\u7cfb\u7edf\u7ea7\u7efc\u5408\u6846\u67b6\u4e0b\u5f00\u53d1Sinkhorn DRSE\u8bbe\u8ba1\uff0c\u91c7\u7528\u5305\u542b\u71b5\u6b63\u5219\u5316\u9879\u7684Sinkhorn\u6a21\u7cca\u96c6\u6765\u60e9\u7f5a\u975e\u5e73\u6ed1\u548c\u79bb\u6563\u5206\u5e03\u3002\u901a\u8fc7\u5bf9\u5076\u7406\u8bba\u5c06min-max\u4f18\u5316\u95ee\u9898\u91cd\u6784\u4e3a\u6709\u9650\u7ef4\u51f8\u89c4\u5212\uff0c\u8bc6\u522b\u5305\u542b\u5168\u5c40\u6700\u4f18\u89e3\u7684\u7d27\u81f4\u5b50\u96c6\uff0c\u5e76\u5f00\u53d1\u4e86\u5b9a\u5236\u7684Frank-Wolfe\u6c42\u89e3\u7b97\u6cd5\u3002", "result": "\u9996\u6b21\u7ed9\u51fa\u4e86Sinkhorn\u6a21\u7cca\u96c6\u7684\u6709\u9650\u6837\u672c\u6982\u7387\u4fdd\u8bc1\uff0c\u5206\u6790\u4e86Sinkhorn DRSE\u8bbe\u8ba1\u7684\u6781\u9650\u6027\u8d28\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u901a\u7528H\u2082\u8bbe\u8ba1\u548cWasserstein DRSE\u7684\u7d27\u5bc6\u8054\u7cfb\u3002\u6570\u503c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86Sinkhorn DRSE\u76f8\u5bf9\u4e8e\u73b0\u6709\u8bbe\u8ba1\u65b9\u6848\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "Sinkhorn DRSE\u8bbe\u8ba1\u901a\u8fc7\u5f15\u5165\u71b5\u6b63\u5219\u5316\u9879\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfWasserstein DRSE\u7684\u8fc7\u5ea6\u60b2\u89c2\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u5e03\u9c81\u68d2\u6027\uff0c\u4e3a\u5904\u7406\u672a\u77e5\u8fde\u7eed\u6270\u52a8\u5206\u5e03\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5b9e\u7528\u7684\u72b6\u6001\u4f30\u8ba1\u6846\u67b6\u3002"}}
{"id": "2602.07447", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07447", "abs": "https://arxiv.org/abs/2602.07447", "authors": ["Liviu P Dinu", "Ana Sabina Uban", "Bogdan Iordache", "Anca Dinu", "Simona Georgescu"], "title": "Measuring cross-language intelligibility between Romance languages with computational tools", "comment": "16 pages, 7 figures, 2 tables", "summary": "We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u6307\u6807\u6765\u8bc4\u4f30\u7f57\u66fc\u8bed\u65cf\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u95f4\u7406\u89e3\u4e0d\u5bf9\u79f0\u7684\u76f4\u89c9\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5b9e\u9a8c\u663e\u8457\u76f8\u5173", "motivation": "\u7814\u7a76\u7f57\u66fc\u8bed\u65cf\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u7c7b\u5b9e\u9a8c\uff0c\u9700\u8981\u5f00\u53d1\u8ba1\u7b97\u6307\u6807\u6765\u9ad8\u6548\u8bc4\u4f30\u8bed\u8a00\u95f4\u7684\u53ef\u7406\u89e3\u6027", "method": "\u5f15\u5165\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u6307\u6807\uff0c\u7ed3\u5408\u8868\u5c42\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u4f7f\u7528\u6b63\u5b57\u6cd5\u548c\u8bed\u97f3\u5f62\u5f0f\uff0c\u6bd4\u8f83\u4e0d\u540c\u5e73\u884c\u8bed\u6599\u5e93\u548c\u8bcd\u5411\u91cf\u6a21\u578b", "result": "\u8ba1\u7b97\u5f97\u5230\u7684\u7406\u89e3\u5ea6\u5206\u6570\u8bc1\u5b9e\u4e86\u8bed\u8a00\u95f4\u7406\u89e3\u4e0d\u5bf9\u79f0\u7684\u76f4\u89c9\uff0c\u4e14\u4e0e\u4eba\u7c7b\u5b8c\u5f62\u586b\u7a7a\u5b9e\u9a8c\u7ed3\u679c\u663e\u8457\u76f8\u5173", "conclusion": "\u63d0\u51fa\u7684\u8ba1\u7b97\u6307\u6807\u80fd\u6709\u6548\u8bc4\u4f30\u7f57\u66fc\u8bed\u65cf\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u4e3a\u8bed\u8a00\u7406\u89e3\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8ba1\u7b97\u65b9\u6cd5"}}
{"id": "2602.07399", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07399", "abs": "https://arxiv.org/abs/2602.07399", "authors": ["Changhua Xu", "Jie Lu", "Junyu Xuan", "En Yu"], "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation", "comment": "Preprint", "summary": "Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{generation--selection} perspective and propose a novel framework \\textbf{VGAS} (\\textbf{V}alue-\\textbf{G}uided \\textbf{A}ction-chunk \\textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \\textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \\textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \\textit{Explicit Geometric Regularization} (\\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \\textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.", "AI": {"tldr": "VGAS\u6846\u67b6\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u89e3\u51b3VLA\u6a21\u578b\u5728\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u6a21\u7cca\u95ee\u9898\uff0c\u4f7f\u7528\u4ef7\u503c\u5f15\u5bfc\u7684\u52a8\u4f5c\u5757\u9009\u62e9\u63d0\u5347\u8f68\u8ff9\u7684\u51e0\u4f55\u7cbe\u5ea6\u548c\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u5728\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u5e38\u56e0\u51e0\u4f55\u6a21\u7cca\u6027\u800c\u5931\u8d25\uff0c\u5373\u8bed\u4e49\u5408\u7406\u7684\u8f68\u8ff9\u5728\u51e0\u4f55\u6267\u884c\u4e0a\u5b58\u5728\u6b67\u4e49\uff0c\u5bfc\u81f4\u6267\u884c\u7ed3\u679c\u53d1\u6563\u3002", "method": "\u63d0\u51faVGAS\u6846\u67b6\uff1a1) \u5fae\u8c03VLA\u4f5c\u4e3a\u9ad8\u53ec\u56de\u7387\u63d0\u8bae\u751f\u6210\u5668\uff1b2) \u5f15\u5165Q-Chunk-Former\u4f5c\u4e3a\u51e0\u4f55\u57fa\u7840Transformer\u6279\u8bc4\u5668\uff1b3) \u63d0\u51fa\u663e\u5f0f\u51e0\u4f55\u6b63\u5219\u5316(EGR)\u6765\u4fdd\u6301\u52a8\u4f5c\u6392\u5e8f\u5206\u8fa8\u7387\u3002", "result": "\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u8868\u660eVGAS\u5728\u6709\u9650\u6f14\u793a\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u80fd\u6301\u7eed\u63d0\u5347\u6210\u529f\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "VGAS\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86VLA\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u6a21\u7cca\u95ee\u9898\uff0c\u4e3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u53ef\u9760\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2602.07173", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07173", "abs": "https://arxiv.org/abs/2602.07173", "authors": ["Tong Jian", "Tianyu Dai", "Tao Yu"], "title": "Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control", "comment": "Accepted to be presented in IEEE ICASSP 2026", "summary": "LLMs have shown strong in-context learning (ICL) abilities, but have not yet been extended to signal processing systems. Inspired by their design, we have proposed for the first time ICL using transformer models applicable to motor feedforward control, a critical task where classical PI and physics-based methods struggle with nonlinearities and complex load conditions. We propose a transformer based model architecture that separates signal representation from system behavior, enabling both few-shot finetuning and one-shot ICL. Pretrained on a large corpus of synthetic linear and nonlinear systems, the model learns to generalize to unseen system dynamics of real-world motors only with a handful of examples. In experiments, our approach generalizes across multiple motor load configurations, transforms untuned examples into accurate feedforward predictions, and outperforms PI controllers and physics-based feedforward baselines. These results demonstrate that ICL can bridge synthetic pretraining and real-world adaptability, opening new directions for data efficient control of physical systems.", "AI": {"tldr": "\u9996\u6b21\u5c06Transformer\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u5e94\u7528\u4e8e\u7535\u673a\u524d\u9988\u63a7\u5236\uff0c\u901a\u8fc7\u5206\u79bb\u4fe1\u53f7\u8868\u793a\u4e0e\u7cfb\u7edf\u884c\u4e3a\uff0c\u5b9e\u73b0\u5c11\u6837\u672c\u5fae\u8c03\u548c\u4e00\u6b21\u6027\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5728\u591a\u79cd\u7535\u673a\u8d1f\u8f7d\u914d\u7f6e\u4e2d\u8d85\u8d8a\u4f20\u7edfPI\u63a7\u5236\u5668\u548c\u57fa\u4e8e\u7269\u7406\u7684\u524d\u9988\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u4f46\u5c1a\u672a\u6269\u5c55\u5230\u4fe1\u53f7\u5904\u7406\u7cfb\u7edf\u3002\u4f20\u7edfPI\u63a7\u5236\u5668\u548c\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u5728\u5904\u7406\u975e\u7ebf\u6027\u7279\u6027\u548c\u590d\u6742\u8d1f\u8f7d\u6761\u4ef6\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7cfb\u7edf\u52a8\u6001\u7684\u6570\u636e\u9ad8\u6548\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u67b6\u6784\uff0c\u5206\u79bb\u4fe1\u53f7\u8868\u793a\u4e0e\u7cfb\u7edf\u884c\u4e3a\uff0c\u5728\u5927\u91cf\u5408\u6210\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7cfb\u7edf\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u901a\u8fc7\u5c11\u91cf\u793a\u4f8b\u5b9e\u73b0\u5c11\u6837\u672c\u5fae\u8c03\u548c\u4e00\u6b21\u6027\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u771f\u5b9e\u4e16\u754c\u7535\u673a\u7684\u672a\u77e5\u7cfb\u7edf\u52a8\u6001\u3002", "result": "\u6a21\u578b\u5728\u591a\u79cd\u7535\u673a\u8d1f\u8f7d\u914d\u7f6e\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5c06\u672a\u8c03\u4f18\u7684\u793a\u4f8b\u8f6c\u5316\u4e3a\u51c6\u786e\u7684\u524d\u9988\u9884\u6d4b\uff0c\u6027\u80fd\u8d85\u8d8a\u4f20\u7edfPI\u63a7\u5236\u5668\u548c\u57fa\u4e8e\u7269\u7406\u7684\u524d\u9988\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u591f\u6865\u63a5\u5408\u6210\u9884\u8bad\u7ec3\u548c\u771f\u5b9e\u4e16\u754c\u9002\u5e94\u6027\uff0c\u4e3a\u7269\u7406\u7cfb\u7edf\u7684\u6570\u636e\u9ad8\u6548\u63a7\u5236\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5c55\u793a\u4e86Transformer\u6a21\u578b\u5728\u4fe1\u53f7\u5904\u7406\u548c\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.08903", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08903", "abs": "https://arxiv.org/abs/2602.08903", "authors": ["Moussa Labbadi", "Andrey Polyakov", "Denis Efimov"], "title": "Accelerated Stabilization of Switched Linear MIMO Systems using Generalized Homogeneity", "comment": null, "summary": "This paper addresses the problem of exponential and accelerated finite-time, as well as nearly fixed-time, stabilization of switched linear MIMO systems. The proposed approach relies on a generalized homogenization framework for switched linear systems and employs implicit Lyapunov functions for control design, covering both common and multiple Lyapunov function settings. Linear matrix equations and inequalities are derived to characterize the dilation generator and to synthesize the controller gains. Robustness of the resulting control laws with respect to system uncertainties and external disturbances is analyzed. The effectiveness of the proposed approach is illustrated through numerical examples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u9f50\u6b21\u5316\u6846\u67b6\u548c\u9690\u5f0fLyapunov\u51fd\u6570\u7684\u5207\u6362\u7ebf\u6027MIMO\u7cfb\u7edf\u6307\u6570/\u52a0\u901f\u6709\u9650\u65f6\u95f4\u53ca\u8fd1\u56fa\u5b9a\u65f6\u95f4\u9547\u5b9a\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ebf\u6027\u77e9\u9635\u65b9\u7a0b/\u4e0d\u7b49\u5f0f\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u5e76\u5206\u6790\u4e86\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u5207\u6362\u7ebf\u6027MIMO\u7cfb\u7edf\u7684\u6307\u6570\u3001\u52a0\u901f\u6709\u9650\u65f6\u95f4\u4ee5\u53ca\u8fd1\u56fa\u5b9a\u65f6\u95f4\u9547\u5b9a\u95ee\u9898\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5728\u63a7\u5236\u5de5\u7a0b\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528\u5e7f\u4e49\u9f50\u6b21\u5316\u6846\u67b6\u5904\u7406\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\uff0c\u4f7f\u7528\u9690\u5f0fLyapunov\u51fd\u6570\u8fdb\u884c\u63a7\u5236\u8bbe\u8ba1\uff0c\u6db5\u76d6\u516c\u5171\u548c\u591aLyapunov\u51fd\u6570\u8bbe\u7f6e\uff0c\u901a\u8fc7\u7ebf\u6027\u77e9\u9635\u65b9\u7a0b\u548c\u4e0d\u7b49\u5f0f\u63a8\u5bfc\u6269\u5f20\u751f\u6210\u5668\u5e76\u7efc\u5408\u63a7\u5236\u5668\u589e\u76ca\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5207\u6362\u7ebf\u6027MIMO\u7cfb\u7edf\u7684\u6307\u6570\u3001\u52a0\u901f\u6709\u9650\u65f6\u95f4\u53ca\u8fd1\u56fa\u5b9a\u65f6\u95f4\u9547\u5b9a\uff0c\u5206\u6790\u4e86\u63a7\u5236\u5f8b\u5bf9\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u548c\u5916\u90e8\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5e7f\u4e49\u9f50\u6b21\u5316\u548c\u9690\u5f0fLyapunov\u51fd\u6570\u7684\u63a7\u5236\u8bbe\u8ba1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5207\u6362\u7ebf\u6027MIMO\u7cfb\u7edf\u7684\u5feb\u901f\u9547\u5b9a\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08816", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08816", "abs": "https://arxiv.org/abs/2602.08816", "authors": ["James Jewitt", "Gopi Krishnan Rajbahadur", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity", "comment": "13 pages, 2 figures, 10 tables", "summary": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f00\u6e90AI\u9886\u57df\u5b58\u5728\u4e25\u91cd\u7684\"\u8bb8\u53ef\u6e05\u6d17\"\u73b0\u8c61\uff1a96.5%\u7684\u6570\u636e\u96c6\u548c95.8%\u7684\u6a21\u578b\u7f3a\u5c11\u5fc5\u8981\u7684\u8bb8\u53ef\u6587\u672c\uff0c\u5927\u591a\u6570\u58f0\u79f0\"\u81ea\u7531\u4f7f\u7528\"\u7684AI\u5de5\u4ef6\u5b9e\u9645\u4e0a\u7f3a\u4e4f\u4f7f\u5176\u5408\u6cd5\u53ef\u7528\u7684\u6cd5\u5f8b\u6587\u6863\u3002", "motivation": "\u5f00\u6e90AI\u9886\u57df\u666e\u904d\u4f7f\u7528MIT\u3001Apache-2.0\u7b49\u5bbd\u677e\u8bb8\u53ef\u8bc1\uff0c\u4f46\u8fd9\u4e9b\u8bb8\u53ef\u8bc1\u5305\u542b\u5fc5\u987b\u6ee1\u8db3\u7684\u6cd5\u5f8b\u8981\u6c42\uff08\u5305\u542b\u5b8c\u6574\u8bb8\u53ef\u6587\u672c\u3001\u7248\u6743\u58f0\u660e\u3001\u4fdd\u7559\u4e0a\u6e38\u5f52\u5c5e\uff09\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u8981\u6c42\u7684\u5927\u89c4\u6a21\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u7528\u6237\u53ef\u80fd\u9762\u4e34\u6cd5\u5f8b\u98ce\u9669\u3002", "method": "\u5bf9124,278\u4e2a\u6570\u636e\u96c6\u2192\u6a21\u578b\u2192\u5e94\u7528\u4f9b\u5e94\u94fe\u8fdb\u884c\u5b9e\u8bc1\u5ba1\u8ba1\uff0c\u6db5\u76d6Hugging Face\u548cGitHub\u4e0a\u76843,338\u4e2a\u6570\u636e\u96c6\u30016,664\u4e2a\u6a21\u578b\u548c28,516\u4e2a\u5e94\u7528\u3002\u68c0\u67e5\u8bb8\u53ef\u6587\u672c\u3001\u7248\u6743\u58f0\u660e\u548c\u5f52\u5c5e\u4f20\u64ad\u7684\u5408\u89c4\u6027\u3002", "result": "\u60ca\u4eba\u7684\u5408\u89c4\u7f3a\u5931\uff1a96.5%\u7684\u6570\u636e\u96c6\u548c95.8%\u7684\u6a21\u578b\u7f3a\u5c11\u8bb8\u53ef\u6587\u672c\uff1b\u4ec52.3%\u7684\u6570\u636e\u96c6\u548c3.2%\u7684\u6a21\u578b\u540c\u65f6\u6ee1\u8db3\u8bb8\u53ef\u6587\u672c\u548c\u7248\u6743\u8981\u6c42\uff1b\u5373\u4f7f\u4e0a\u6e38\u63d0\u4f9b\u5b8c\u6574\u8bb8\u53ef\u8bc1\u636e\uff0c\u5f52\u5c5e\u4f20\u64ad\u7387\u6781\u4f4e\uff1a\u4ec527.59%\u7684\u6a21\u578b\u4fdd\u7559\u5408\u89c4\u7684\u6570\u636e\u96c6\u58f0\u660e\uff0c\u4ec55.75%\u7684\u5e94\u7528\u4fdd\u7559\u5408\u89c4\u7684\u6a21\u578b\u58f0\u660e\u3002", "conclusion": "\u4ece\u4e1a\u8005\u4e0d\u80fd\u5047\u8bbe\u5bbd\u677e\u8bb8\u53ef\u8bc1\u6807\u7b7e\u80fd\u63d0\u4f9b\u5176\u6240\u58f0\u79f0\u7684\u6743\u5229\uff1a\u8bb8\u53ef\u6587\u4ef6\u548c\u58f0\u660e\uff08\u800c\u975e\u5143\u6570\u636e\uff09\u624d\u662f\u6cd5\u5f8b\u771f\u5b9e\u6027\u7684\u6765\u6e90\u3002\u5f00\u6e90AI\u4f9b\u5e94\u94fe\u5b58\u5728\u4e25\u91cd\u7684\"\u8bb8\u53ef\u6e05\u6d17\"\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u5408\u89c4\u5b9e\u8df5\u3002"}}
{"id": "2602.08066", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08066", "abs": "https://arxiv.org/abs/2602.08066", "authors": ["Mamadou Pathe LY", "Ravikumar Kasinathan", "Ramkumar Kasinathan", "Dimplekumar Chalishajar", "Mamadou Abdoul Diop"], "title": "Approximate Controllability of Nonlocal Stochastic Integrodifferential System in Hilbert Spaces", "comment": "26 pages", "summary": "This project investigates the approximate controllability of a class of stochastic integrodifferential equations in Hilbert space with non-local beginning conditions. In a departure from the conventional concerns expressed in the literature, we will not consider compactness or the Lipschitz criteria concerning the nonlocal term. We use the fact that the resolvent operator is compact. We first prove the controllability of the nonlinear system using Schauder's fixed point theorem, a method known for its robustness; as well, we also use Grimmer's resolvent operator theory. Subsequently, we employ the reliable approximation methods and the powerful diagonal argument to determine the approximate controllability of the stochastic system. To conclude, we present an example that validates our theoretical statement.", "AI": {"tldr": "\u7814\u7a76\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u5177\u6709\u975e\u5c40\u90e8\u521d\u59cb\u6761\u4ef6\u7684\u968f\u673a\u79ef\u5206\u5fae\u5206\u65b9\u7a0b\u7684\u8fd1\u4f3c\u53ef\u63a7\u6027\uff0c\u4e0d\u4f7f\u7528\u4f20\u7edf\u7d27\u6027\u6216Lipschitz\u6761\u4ef6\uff0c\u901a\u8fc7Schauder\u4e0d\u52a8\u70b9\u5b9a\u7406\u548cGrimmer\u89e3\u7b97\u5b50\u7406\u8bba\u8bc1\u660e\u53ef\u63a7\u6027\u3002", "motivation": "\u7814\u7a76\u4e00\u7c7b\u5177\u6709\u975e\u5c40\u90e8\u521d\u59cb\u6761\u4ef6\u7684\u968f\u673a\u79ef\u5206\u5fae\u5206\u65b9\u7a0b\u7684\u8fd1\u4f3c\u53ef\u63a7\u6027\u95ee\u9898\uff0c\u7a81\u7834\u4f20\u7edf\u6587\u732e\u4e2d\u5e38\u7528\u7684\u7d27\u6027\u5047\u8bbe\u548cLipschitz\u6761\u4ef6\u9650\u5236\uff0c\u63a2\u7d22\u66f4\u4e00\u822c\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5229\u7528\u89e3\u7b97\u5b50\u7684\u7d27\u6027\uff0c\u9996\u5148\u4f7f\u7528Schauder\u4e0d\u52a8\u70b9\u5b9a\u7406\u8bc1\u660e\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u53ef\u63a7\u6027\uff0c\u7ed3\u5408Grimmer\u89e3\u7b97\u5b50\u7406\u8bba\uff1b\u7136\u540e\u91c7\u7528\u53ef\u9760\u7684\u8fd1\u4f3c\u65b9\u6cd5\u548c\u5f3a\u5927\u7684\u5bf9\u89d2\u7ebf\u8bba\u8bc1\u6765\u786e\u5b9a\u968f\u673a\u7cfb\u7edf\u7684\u8fd1\u4f3c\u53ef\u63a7\u6027\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u8be5\u968f\u673a\u79ef\u5206\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\u7684\u8fd1\u4f3c\u53ef\u63a7\u6027\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u5728\u4e0d\u9700\u8981\u4f20\u7edf\u7d27\u6027\u6216Lipschitz\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u5efa\u7acb\u4e86\u5177\u6709\u975e\u5c40\u90e8\u521d\u59cb\u6761\u4ef6\u7684\u968f\u673a\u79ef\u5206\u5fae\u5206\u65b9\u7a0b\u7684\u8fd1\u4f3c\u53ef\u63a7\u6027\u7406\u8bba\uff0c\u4e3a\u8fd9\u7c7b\u7cfb\u7edf\u7684\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2602.07451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07451", "abs": "https://arxiv.org/abs/2602.07451", "authors": ["Huiling Zhen", "Weizhe Lin", "Renxi Liu", "Kai Han", "Yiming Li", "Yuchuan Tian", "Hanting Chen", "Xiaoguang Li", "Xiaosong Li", "Chen Chen", "Xianzhi Yu", "Mingxuan Yuan", "Youliang Yan", "Peifeng Qin", "Jun Wang", "Yu Wang", "Dacheng Tao", "Yunhe Wang"], "title": "DLLM Agent: See Farther, Run Faster", "comment": null, "summary": "Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u4f53\u51b3\u7b56\u4efb\u52a1\u4e2d\u76f8\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\u80fd\u5e26\u676530%\u4ee5\u4e0a\u7684\u7aef\u5230\u7aef\u901f\u5ea6\u63d0\u5347\uff0c\u4f46\u9700\u8981\u66f4\u5f3a\u7684\u5de5\u5177\u8c03\u7528\u8bad\u7ec3\u548c\u6ce8\u610f\u529b\u63a9\u7801\u5bf9\u9f50", "motivation": "\u63a2\u7d22\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u4f53\u591a\u6b65\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5f53\u751f\u6210\u8303\u5f0f\u6539\u53d8\u4f46\u667a\u80fd\u4f53\u6846\u67b6\u548c\u76d1\u7763\u4fdd\u6301\u4e0d\u53d8\u65f6\uff0c\u6269\u6563\u6a21\u578b\u662f\u5426\u4f1a\u5e26\u6765\u7cfb\u7edf\u6027\u7684\u89c4\u5212\u548c\u5de5\u5177\u4f7f\u7528\u884c\u4e3a\u5dee\u5f02\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u5dee\u5f02\u662f\u5426\u80fd\u8f6c\u5316\u4e3a\u7aef\u5230\u7aef\u7684\u6548\u7387\u63d0\u5347", "method": "\u5728\u76f8\u540c\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff08DeepDiver\uff09\u4e2d\u5b9e\u4f8b\u5316DLLM\u548cAR\u9aa8\u5e72\u7f51\u7edc\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u5339\u914d\u7684\u667a\u80fd\u4f53\u5bfc\u5411\u5fae\u8c03\uff0c\u751f\u6210\u6269\u6563\u652f\u6301\u7684DLLM\u667a\u80fd\u4f53\u548c\u76f4\u63a5\u53ef\u6bd4\u8f83\u7684AR\u667a\u80fd\u4f53", "result": "\u5728\u51c6\u786e\u7387\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\uff0cDLLM\u667a\u80fd\u4f53\u7aef\u5230\u7aef\u901f\u5ea6\u5e73\u5747\u6bd4AR\u667a\u80fd\u4f53\u5feb30%\u4ee5\u4e0a\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8fc78\u500d\u52a0\u901f\uff1b\u5728\u4efb\u52a1\u5b8c\u6210\u6b63\u786e\u7684\u60c5\u51b5\u4e0b\uff0cDLLM\u667a\u80fd\u4f53\u9700\u8981\u66f4\u5c11\u7684\u4ea4\u4e92\u8f6e\u6b21\u548c\u5de5\u5177\u8c03\u7528\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u89c4\u5212\u547d\u4e2d\u7387\u548c\u66f4\u65e9\u6536\u655b\u5230\u6b63\u786e\u884c\u52a8\u8def\u5f84", "conclusion": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u4f53\u51b3\u7b56\u4e2d\u5177\u6709\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4e24\u4e2a\u5b9e\u9645\u95ee\u9898\uff1a\u66f4\u5f3a\u7684\u5de5\u5177\u8c03\u7528\u8bad\u7ec3\u4ee5\u907f\u514d\u7ed3\u6784\u5316\u5de5\u5177\u8c03\u7528\u5931\u8d25\uff0c\u4ee5\u53ca\u5bf9\u9f50\u7684\u6ce8\u610f\u529b\u63a9\u7801\u4ee5\u907f\u514d\u591a\u8f6e\u8f93\u5165\u4e2d\u7684\u865a\u5047\u4fe1\u606f\u6d41\uff1b\u6269\u6563\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u5168\u5c40\u89c4\u5212\u4fe1\u53f7"}}
{"id": "2602.07408", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07408", "abs": "https://arxiv.org/abs/2602.07408", "authors": ["Hyomin Kim", "Sang-Yeon Hwang", "Jaechang Lim", "Yinhua Piao", "Yunhak Oh", "Woo Youn Kim", "Chanyoung Park", "Sungsoo Ahn", "Junhyeok Jeon"], "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction", "comment": "17 pages, 4 figures, 9 tables", "summary": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.", "AI": {"tldr": "\u63d0\u51fa\u4e86LINCSQA\u57fa\u51c6\u548cPBio-Agent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u5316\u5b66\u6270\u52a8\u4e0b\u7684\u57fa\u56e0\u8c03\u63a7\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u4efb\u52a1\u6392\u5e8f\u548c\u8fed\u4ee3\u77e5\u8bc6\u7cbe\u70bc\u63d0\u5347\u9884\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u7ec6\u80de\u5b9e\u9a8c\u4e2d\u7684\u9057\u4f20\u6270\u52a8\uff0c\u800c\u836f\u7269\u53d1\u73b0\u6838\u5fc3\u7684\u6279\u91cf\u7ec6\u80de\u5316\u5b66\u6270\u52a8\u9884\u6d4b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u6270\u52a8\u7ed3\u679c\u65f6\u5bb9\u6613\u9677\u5165\u4fe1\u606f\u7ea0\u7f20", "method": "\u63d0\u51faPBio-Agent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1) \u96be\u5ea6\u611f\u77e5\u4efb\u52a1\u6392\u5e8f\uff1b2) \u8fed\u4ee3\u77e5\u8bc6\u7cbe\u70bc\uff1b3) \u57fa\u4e8e\u751f\u7269\u77e5\u8bc6\u56fe\u8c31\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\uff1b4) \u5408\u6210\u667a\u80fd\u4f53\u6574\u5408\u8f93\u51fa\uff1b5) \u4e13\u4e1a\u8bc4\u5224\u5668\u786e\u4fdd\u903b\u8f91\u4e00\u81f4\u6027", "result": "PBio-Agent\u5728LINCSQA\u548cPerturbQA\u57fa\u51c6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5373\u4f7f\u8f83\u5c0f\u7684\u6a21\u578b\u4e5f\u80fd\u5728\u4e0d\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9884\u6d4b\u548c\u89e3\u91ca\u590d\u6742\u751f\u7269\u8fc7\u7a0b", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5316\u5b66\u6270\u52a8\u4e0b\u7684\u57fa\u56e0\u8c03\u63a7\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u548c\u6709\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u56e0\u679c\u7ed3\u6784\u5171\u4eab\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027"}}
{"id": "2602.07189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07189", "abs": "https://arxiv.org/abs/2602.07189", "authors": ["Joohwan Ko", "Tomas Geffner"], "title": "Latent Target Score Matching, with an application to Simulation-Based Inference", "comment": "Machine Learning and the Physical Sciences Workshop, NeurIPS 2025", "summary": "Denoising score matching (DSM) for training diffusion models may suffer from high variance at low noise levels. Target Score Matching (TSM) mitigates this when clean data scores are available, providing a low-variance objective. In many applications clean scores are inaccessible due to the presence of latent variables, leaving only joint signals exposed. We propose Latent Target Score Matching (LTSM), an extension of TSM to leverage joint scores for low-variance supervision of the marginal score. While LTSM is effective at low noise levels, a mixture with DSM ensures robustness across noise scales. Across simulation-based inference tasks, LTSM consistently improves variance, score accuracy, and sample quality.", "AI": {"tldr": "\u63d0\u51faLatent Target Score Matching (LTSM)\u65b9\u6cd5\uff0c\u6269\u5c55TSM\u4ee5\u5229\u7528\u8054\u5408\u5206\u6570\u5bf9\u8fb9\u9645\u5206\u6570\u8fdb\u884c\u4f4e\u65b9\u5dee\u76d1\u7763\uff0c\u5728\u6a21\u62df\u63a8\u7406\u4efb\u52a1\u4e2d\u63d0\u5347\u65b9\u5dee\u3001\u5206\u6570\u51c6\u786e\u6027\u548c\u6837\u672c\u8d28\u91cf\u3002", "motivation": "\u53bb\u566a\u5206\u6570\u5339\u914d(DSM)\u5728\u4f4e\u566a\u58f0\u6c34\u5e73\u4e0b\u53ef\u80fd\u9762\u4e34\u9ad8\u65b9\u5dee\u95ee\u9898\u3002\u867d\u7136\u76ee\u6807\u5206\u6570\u5339\u914d(TSM)\u5728\u53ef\u83b7\u5f97\u5e72\u51c0\u6570\u636e\u5206\u6570\u65f6\u80fd\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0c\u7531\u4e8e\u5b58\u5728\u6f5c\u5728\u53d8\u91cf\uff0c\u53ea\u80fd\u83b7\u5f97\u8054\u5408\u4fe1\u53f7\u800c\u65e0\u6cd5\u83b7\u5f97\u5e72\u51c0\u5206\u6570\u3002", "method": "\u63d0\u51fa\u6f5c\u5728\u76ee\u6807\u5206\u6570\u5339\u914d(LTSM)\uff0c\u6269\u5c55TSM\u65b9\u6cd5\u4ee5\u5229\u7528\u8054\u5408\u5206\u6570\u5bf9\u8fb9\u9645\u5206\u6570\u8fdb\u884c\u4f4e\u65b9\u5dee\u76d1\u7763\u3002\u540c\u65f6\u91c7\u7528LTSM\u4e0eDSM\u7684\u6df7\u5408\u7b56\u7565\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u566a\u58f0\u5c3a\u5ea6\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u6a21\u62df\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cLTSM\u65b9\u6cd5\u4e00\u81f4\u5730\u6539\u5584\u4e86\u65b9\u5dee\u3001\u5206\u6570\u51c6\u786e\u6027\u548c\u6837\u672c\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u4f4e\u566a\u58f0\u6c34\u5e73\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LTSM\u4e3a\u5b58\u5728\u6f5c\u5728\u53d8\u91cf\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u65b9\u5dee\u5206\u6570\u5339\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408DSM\u786e\u4fdd\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.08924", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08924", "abs": "https://arxiv.org/abs/2602.08924", "authors": ["Brycen D. Pearl", "Joshua G. Warner", "Hang Woon Lee"], "title": "Automating the Wildfire Detection and Scheduling Pipeline with Maneuverable Earth Observation Satellites", "comment": "44 pages", "summary": "Wildfires are becoming increasingly frequent, with potentially devastating consequences, including loss of life, infrastructure destruction, and severe environmental damage. Low Earth orbit satellites equipped with onboard sensors can capture critical imagery of active wildfires and enable real-time detection through machine learning algorithms applied to the acquired data. This paper presents a framework that automates the complete wildfire detection and scheduling pipeline, integrating three key components: wildfire detection in satellite imagery, statistical updating that incorporates data from repeated flyovers, and multi-satellite scheduling optimization. The framework enables wildfire detection using convolutional neural networks with sensor fusion techniques, the incorporation of subsequent flyover information using Bayesian statistics, and satellite scheduling through the state-of-the-art Reconfigurable Earth Observation Satellite Scheduling Problem. Experiments conducted using real-world wildfire events and operational Earth observation satellites demonstrate that this autonomous detection and scheduling approach effectively enhances wildfire monitoring capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u91ce\u706b\u68c0\u6d4b\u4e0e\u8c03\u5ea6\u6846\u67b6\uff0c\u6574\u5408\u536b\u661f\u56fe\u50cf\u68c0\u6d4b\u3001\u8d1d\u53f6\u65af\u7edf\u8ba1\u66f4\u65b0\u548c\u591a\u536b\u661f\u8c03\u5ea6\u4f18\u5316\uff0c\u63d0\u5347\u91ce\u706b\u76d1\u6d4b\u80fd\u529b", "motivation": "\u91ce\u706b\u65e5\u76ca\u9891\u7e41\uff0c\u9020\u6210\u751f\u547d\u635f\u5931\u3001\u57fa\u7840\u8bbe\u65bd\u7834\u574f\u548c\u73af\u5883\u635f\u5bb3\u3002\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u914d\u5907\u4f20\u611f\u5668\u53ef\u83b7\u53d6\u5173\u952e\u91ce\u706b\u56fe\u50cf\uff0c\u4f46\u9700\u8981\u81ea\u52a8\u5316\u5b9e\u65f6\u68c0\u6d4b\u4e0e\u8c03\u5ea6\u7cfb\u7edf\u6765\u6709\u6548\u76d1\u6d4b", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u4f20\u611f\u5668\u878d\u5408\u6280\u672f\u8fdb\u884c\u536b\u661f\u56fe\u50cf\u91ce\u706b\u68c0\u6d4b\uff1b2) \u901a\u8fc7\u8d1d\u53f6\u65af\u7edf\u8ba1\u6574\u5408\u91cd\u590d\u98de\u8d8a\u6570\u636e\uff1b3) \u91c7\u7528\u53ef\u91cd\u6784\u5730\u7403\u89c2\u6d4b\u536b\u661f\u8c03\u5ea6\u95ee\u9898\u8fdb\u884c\u591a\u536b\u661f\u8c03\u5ea6\u4f18\u5316", "result": "\u4f7f\u7528\u771f\u5b9e\u91ce\u706b\u4e8b\u4ef6\u548c\u8fd0\u884c\u4e2d\u7684\u5730\u7403\u89c2\u6d4b\u536b\u661f\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u81ea\u4e3b\u68c0\u6d4b\u4e0e\u8c03\u5ea6\u65b9\u6cd5\u80fd\u6709\u6548\u589e\u5f3a\u91ce\u706b\u76d1\u6d4b\u80fd\u529b", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u91ce\u706b\u68c0\u6d4b\u3001\u7edf\u8ba1\u66f4\u65b0\u548c\u536b\u661f\u8c03\u5ea6\uff0c\u4e3a\u5b9e\u65f6\u91ce\u706b\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.07205", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07205", "abs": "https://arxiv.org/abs/2602.07205", "authors": ["Junyan Liu", "Haipeng Luo", "Zihan Zhang", "Lillian J. Ratliff"], "title": "Online Learning for Uninformed Markov Games: Empirical Nash-Value Regret and Non-Stationarity Adaptation", "comment": "36 pages", "summary": "We study online learning in two-player uninformed Markov games, where the opponent's actions and policies are unobserved. In this setting, Tian et al. (2021) show that achieving no-external-regret is impossible without incurring an exponential dependence on the episode length $H$. They then turn to the weaker notion of Nash-value regret and propose a V-learning algorithm with regret $O(K^{2/3})$ after $K$ episodes. However, their algorithm and guarantee do not adapt to the difficulty of the problem: even in the case where the opponent follows a fixed policy and thus $O(\\sqrt{K})$ external regret is well-known to be achievable, their result is still the worse rate $O(K^{2/3})$ on a weaker metric.\n  In this work, we fully address both limitations. First, we introduce empirical Nash-value regret, a new regret notion that is strictly stronger than Nash-value regret and naturally reduces to external regret when the opponent follows a fixed policy. Moreover, under this new metric, we propose a parameter-free algorithm that achieves an $O(\\min \\{\\sqrt{K} + (CK)^{1/3},\\sqrt{LK}\\})$ regret bound, where $C$ quantifies the variance of the opponent's policies and $L$ denotes the number of policy switches (both at most $O(K)$). Therefore, our results not only recover the two extremes -- $O(\\sqrt{K})$ external regret when the opponent is fixed and $O(K^{2/3})$ Nash-value regret in the worst case -- but also smoothly interpolate between these extremes by automatically adapting to the opponent's non-stationarity. We achieve so by first providing a new analysis of the epoch-based V-learning algorithm by Mao et al. (2022), establishing an $O(\u03b7C + \\sqrt{K/\u03b7})$ regret bound, where $\u03b7$ is the epoch incremental factor. Next, we show how to adaptively restart this algorithm with an appropriate $\u03b7$ in response to the potential non-stationarity of the opponent, eventually achieving our final results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ecf\u9a8c\u7eb3\u4ec0\u503c\u9057\u61be\u5ea6\u91cf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u5728\u975e\u5b8c\u5168\u4fe1\u606f\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u5b9e\u73b0\u4e86\u4eceO(\u221aK)\u5230O(K^{2/3})\u7684\u5e73\u6ed1\u8fc7\u6e21\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u95ee\u9898\u96be\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u975e\u5b8c\u5168\u4fe1\u606f\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u53ea\u80fd\u4f7f\u7528\u8f83\u5f31\u7684\u7eb3\u4ec0\u503c\u9057\u61be\u5ea6\u91cf\uff1b2) \u7b97\u6cd5\u65e0\u6cd5\u9002\u5e94\u95ee\u9898\u96be\u5ea6\uff0c\u5373\u4f7f\u5728\u5bf9\u624b\u56fa\u5b9a\u7b56\u7565\u7684\u7b80\u5355\u60c5\u51b5\u4e0b\u4e5f\u65e0\u6cd5\u8fbe\u5230\u6700\u4f18\u7684O(\u221aK)\u9057\u61be\u754c\u3002", "method": "\u63d0\u51fa\u7ecf\u9a8c\u7eb3\u4ec0\u503c\u9057\u61be\u8fd9\u4e00\u65b0\u7684\u9057\u61be\u5ea6\u91cf\uff0c\u5e76\u8bbe\u8ba1\u53c2\u6570\u81ea\u7531\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\u3002\u9996\u5148\u5bf9Mao\u7b49\u4eba\u7684epoch-based V-learning\u7b97\u6cd5\u8fdb\u884c\u65b0\u5206\u6790\uff0c\u5f97\u5230O(\u03b7C + \u221aK/\u03b7)\u9057\u61be\u754c\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u542f\u673a\u5236\u52a8\u6001\u8c03\u6574\u03b7\u53c2\u6570\u6765\u5e94\u5bf9\u5bf9\u624b\u7684\u975e\u5e73\u7a33\u6027\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86O(min{\u221aK + (CK)^{1/3}, \u221aLK})\u7684\u9057\u61be\u754c\uff0c\u5176\u4e2dC\u91cf\u5316\u5bf9\u624b\u7b56\u7565\u7684\u65b9\u5dee\uff0cL\u8868\u793a\u7b56\u7565\u5207\u6362\u6b21\u6570\u3002\u8be5\u7ed3\u679c\u4e0d\u4ec5\u6062\u590d\u4e86\u4e24\u4e2a\u6781\u7aef\u60c5\u51b5\uff08\u5bf9\u624b\u56fa\u5b9a\u65f6\u7684O(\u221aK)\u5916\u90e8\u9057\u61be\u548c\u6700\u574f\u60c5\u51b5\u4e0b\u7684O(K^{2/3})\u7eb3\u4ec0\u503c\u9057\u61be\uff09\uff0c\u8fd8\u80fd\u6839\u636e\u5bf9\u624b\u975e\u5e73\u7a33\u6027\u81ea\u52a8\u9002\u5e94\u3002", "conclusion": "\u672c\u6587\u5b8c\u5168\u89e3\u51b3\u4e86\u975e\u5b8c\u5168\u4fe1\u606f\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u66f4\u5f3a\u7684\u9057\u61be\u5ea6\u91cf\u548c\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4ece\u7b80\u5355\u5230\u590d\u6742\u60c5\u51b5\u7684\u5e73\u6ed1\u8fc7\u6e21\uff0c\u4e3a\u5728\u7ebf\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2602.08835", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08835", "abs": "https://arxiv.org/abs/2602.08835", "authors": ["Andr\u00e9s Holgado-S\u00e1nchez", "Peter Vamplew", "Richard Dazeley", "Sascha Ossowski", "Holger Billhardt"], "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning", "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material", "summary": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u8054\u5408\u5b66\u4e60\u793e\u4f1a\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u7528\u6237\u7fa4\u4f53\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u89e3\u51b3AI\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u4e2a\u6027\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u9700\u8981\u8bc6\u522b\u4eba\u7c7b\u4ef7\u503c\u89c2\u5e76\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u64cd\u4f5c\u5316\u56f0\u96be\u3001\u7f3a\u4e4f\u4ef7\u503c\u53ef\u89e3\u91ca\u6027\u3001\u96be\u4ee5\u9002\u5e94\u591a\u6837\u5316\u7528\u6237\u504f\u597d\u7b49\u95ee\u9898\u3002\u7279\u522b\u662f\u5728\u987a\u5e8f\u51b3\u7b56\u4e2d\uff0c\u4e2a\u6027\u5316\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u7279\u5f81\u6216\u7f3a\u4e4f\u4ef7\u503c\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08PbMORL\uff09\u7684\u7b97\u6cd5\uff0c\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u8054\u5408\u5b66\u4e60\u793e\u4f1a\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\uff08groundings\uff09\u548c\u4ee3\u8868\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u4ef7\u503c\u7cfb\u7edf\u3002\u6bcf\u4e2a\u805a\u7c7b\u5305\u542b\u4ee3\u8868\u6210\u5458\u4ef7\u503c\u504f\u597d\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4ee5\u53ca\u53cd\u6620\u4e0e\u8be5\u4ef7\u503c\u7cfb\u7edf\u5bf9\u9f50\u884c\u4e3a\u7684\u8fd1\u4f3c\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u5305\u542b\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684MDP\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u4e86\u6240\u63d0\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684PbMORL\u7b97\u6cd5\u548c\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u793e\u4f1a\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u7528\u6237\u7fa4\u4f53\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4e3a\u4ef7\u503c\u611f\u77e5AI\u63d0\u4f9b\u4e86\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u7528\u6237\u504f\u597d\u3001\u5177\u6709\u4ef7\u503c\u53ef\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08069", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08069", "abs": "https://arxiv.org/abs/2602.08069", "authors": ["Amal Alphonse", "Pavel Dvurechensky", "Clemens Sirotenko"], "title": "Skip the Hessian, Keep the Rates: Globalized Semismooth Newton with Lazy Hessian Updates", "comment": null, "summary": "Second-order methods are provably faster than first-order methods, and their efficient implementations for large-scale optimization problems have attracted significant attention. Yet, optimization problems in ML often have nonsmooth derivatives, which makes the existing convergence rate theory of second-order methods inapplicable. In this paper, we propose a new semismooth Newton method (SSN) that enjoys both global convergence rates and asymptotic superlinear convergence without requiring second-order differentiability. Crucially, our method does not require (generalized) Hessians to be evaluated at each iteration but only periodically, and it reuses stale Hessians otherwise (i.e., it performs lazy Hessian updates), saving compute cost and often leading to significant speedups in time, whilst still maintaining strong global and local convergence rate guarantees. We develop our theory in an infinite-dimensional setting and illustrate it with numerical experiments on matrix factorization and neural networks with Lipschitz constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u534a\u5149\u6ed1\u725b\u987f\u6cd5\uff0c\u5728\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\u4e2d\u5b9e\u73b0\u5168\u5c40\u6536\u655b\u548c\u6e10\u8fd1\u8d85\u7ebf\u6027\u6536\u655b\uff0c\u901a\u8fc7\u60f0\u6027Hessian\u66f4\u65b0\u51cf\u5c11\u8ba1\u7b97\u6210\u672c", "motivation": "\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u5f80\u5f80\u5177\u6709\u975e\u5149\u6ed1\u5bfc\u6570\uff0c\u73b0\u6709\u4e8c\u9636\u65b9\u6cd5\u7684\u6536\u655b\u7387\u7406\u8bba\u4e0d\u9002\u7528\uff0c\u4e14\u6bcf\u6b21\u8fed\u4ee3\u8ba1\u7b97Hessian\u77e9\u9635\u6210\u672c\u9ad8\u6602", "method": "\u63d0\u51fa\u65b0\u7684\u534a\u5149\u6ed1\u725b\u987f\u6cd5(SSN)\uff0c\u4e0d\u9700\u8981\u6bcf\u6b21\u8fed\u4ee3\u90fd\u8ba1\u7b97(\u5e7f\u4e49)Hessian\u77e9\u9635\uff0c\u800c\u662f\u5468\u671f\u6027\u66f4\u65b0\u5e76\u91cd\u7528\u65e7\u7684Hessian\uff08\u60f0\u6027\u66f4\u65b0\uff09", "result": "\u8be5\u65b9\u6cd5\u5728\u65e0\u9650\u7ef4\u8bbe\u7f6e\u4e2d\u5efa\u7acb\u4e86\u7406\u8bba\uff0c\u5728\u77e9\u9635\u5206\u89e3\u548c\u5e26Lipschitz\u7ea6\u675f\u7684\u795e\u7ecf\u7f51\u7edc\u4e0a\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u4fdd\u6301\u5f3a\u5168\u5c40\u548c\u5c40\u90e8\u6536\u655b\u7387\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\u5e76\u52a0\u901f\u4f18\u5316\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8e\u975e\u5149\u6ed1\u7684\u673a\u5668\u5b66\u4e60\u4f18\u5316\u95ee\u9898"}}
{"id": "2602.07464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07464", "abs": "https://arxiv.org/abs/2602.07464", "authors": ["Yijie Chen", "Yijin Liu", "Fandong Meng"], "title": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "comment": "The code is publicly available at https://github.com/pppa2019/SED-SFT", "summary": "Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT", "AI": {"tldr": "SED-SFT\u901a\u8fc7\u5f15\u5165\u9009\u62e9\u6027\u71b5\u6b63\u5219\u5316\u548c\u63a9\u7801\u673a\u5236\uff0c\u89e3\u51b3\u4f20\u7edfSFT\u4e2d\u7684\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u751f\u6210\u591a\u6837\u6027\uff0c\u4ece\u800c\u6539\u5584\u540e\u7eedRL\u6027\u80fd", "motivation": "\u4f20\u7edfSFT\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u4f1a\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83\uff0c\u6a21\u578b\u8fc7\u5ea6\u96c6\u4e2d\u5728\u7279\u5b9a\u54cd\u5e94\u6a21\u5f0f\u4e0a\uff0c\u7f3a\u4e4f\u5206\u5e03\u591a\u6837\u6027\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u540e\u7eedRL\u7684\u63a2\u7d22\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5e73\u8861\u591a\u6837\u6027\u548c\u51c6\u786e\u6027", "method": "\u63d0\u51faSED-SFT\u6846\u67b6\uff0c\u57fa\u4e8etoken\u63a2\u7d22\u7a7a\u95f4\u81ea\u9002\u5e94\u5730\u9f13\u52b1\u591a\u6837\u6027\u3002\u5728\u4f18\u5316\u76ee\u6807\u4e2d\u5f15\u5165\u9009\u62e9\u6027\u71b5\u6b63\u5219\u5316\u9879\u548c\u9009\u62e9\u6027\u63a9\u7801\u673a\u5236", "result": "\u57288\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSED-SFT\u663e\u8457\u63d0\u5347\u751f\u6210\u591a\u6837\u6027\uff0c\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u3002\u5728Llama-3.2-3B-Instruct\u548cQwen2.5-Math-7B-Instruct\u4e0a\uff0c\u540e\u7eedRL\u6027\u80fd\u5206\u522b\u5e73\u5747\u63d0\u53472.06\u548c1.20\u5206", "conclusion": "SED-SFT\u6709\u6548\u89e3\u51b3\u4e86SFT\u4e2d\u7684\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u591a\u6837\u6027\u6539\u5584\u4e86\u540e\u7eedRL\u6027\u80fd\uff0c\u4e3aLLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u597d\u7684SFT\u65b9\u6cd5"}}
{"id": "2602.07414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07414", "abs": "https://arxiv.org/abs/2602.07414", "authors": ["Deuksin Kwon", "Kaleen Shrestha", "Bin Han", "Spencer Lin", "James Hale", "Jonathan Gratch", "Maja Matari\u0107", "Gale M. Lucas"], "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution", "comment": "AAAI 2026 (Special Track: AISI)", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.", "AI": {"tldr": "LLMs\u6a21\u62df\u4eba\u7c7b\u51b2\u7a81\u884c\u4e3a\u65f6\uff0c\u5373\u4f7f\u63d0\u793a\u4eba\u683c\u7279\u8d28\uff0c\u4e5f\u65e0\u6cd5\u51c6\u786e\u518d\u73b0\u4eba\u683c\u9a71\u52a8\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4e0e\u4eba\u7c7b\u6570\u636e\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u6a21\u62df\u793e\u4f1a\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u62df\u662f\u5426\u80fd\u518d\u73b0\u4eba\u7c7b\u89c2\u5bdf\u5230\u7684\u6027\u683c-\u884c\u4e3a\u6a21\u5f0f\u3002\u4eba\u683c\u7279\u8d28\u5f71\u54cd\u4eba\u7c7b\u5728\u51b2\u7a81\u89e3\u51b3\u7b49\u793e\u4ea4\u4e92\u52a8\u4e2d\u7684\u6218\u7565\u9009\u62e9\u548c\u884c\u4e3a\uff0c\u9700\u8981\u9a8c\u8bc1LLMs\u80fd\u5426\u51c6\u786e\u6a21\u62df\u4eba\u683c\u9a71\u52a8\u7684\u51b2\u7a81\u884c\u4e3a\u5dee\u5f02\u3002", "method": "1. \u5f15\u5165\u8bc4\u4f30\u6846\u67b6\uff0c\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b-\u4eba\u7c7b\u548cLLM-LLM\u5728\u4e89\u8bae\u89e3\u51b3\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\uff0c\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff1b2. \u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6307\u6807\u96c6\uff0c\u6d89\u53ca\u6218\u7565\u884c\u4e3a\u548c\u51b2\u7a81\u7ed3\u679c\uff1b3. \u8d21\u732e\u65b0\u7684\u6570\u636e\u96c6\u521b\u5efa\u65b9\u6cd5\uff0c\u7528\u4e8eLLM\u4e89\u8bae\u89e3\u51b3\u5bf9\u8bdd\uff0c\u5339\u914d\u4eba\u7c7b\u5bf9\u8bdd\u7684\u573a\u666f\u548c\u4eba\u683c\u7279\u8d28\u3002", "result": "\u4f7f\u7528\u4e09\u4e2a\u5f53\u4ee3\u95ed\u6e90LLMs\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540cLLMs\u4e2d\u4eba\u683c\u5728\u51b2\u7a81\u4e2d\u7684\u8868\u73b0\u4e0e\u4eba\u7c7b\u6570\u636e\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u6311\u6218\u4e86\u4eba\u683c\u63d0\u793a\u4ee3\u7406\u53ef\u4ee5\u4f5c\u4e3a\u793e\u4f1a\u5f71\u54cd\u5e94\u7528\u4e2d\u53ef\u9760\u884c\u4e3a\u4ee3\u7406\u7684\u5047\u8bbe\u3002", "conclusion": "LLMs\u5728\u6a21\u62df\u4eba\u683c\u9a71\u52a8\u7684\u51b2\u7a81\u884c\u4e3a\u65b9\u9762\u4e0e\u4eba\u7c7b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u524d\u9700\u8981\u5bf9AI\u6a21\u62df\u8fdb\u884c\u5fc3\u7406\u5b66\u57fa\u7840\u548c\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.07192", "categories": ["cs.LG", "cs.CE", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.07192", "abs": "https://arxiv.org/abs/2602.07192", "authors": ["Xiaolong He", "Haoyan Wei", "Wei Hu", "Henan Mao", "C. T. Wu"], "title": "Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling", "comment": null, "summary": "Deep Material Networks (DMNs) are structure-preserving, mechanistic machine learning models that embed micromechanical principles into their architectures, enabling strong extrapolation capabilities and significant potential to accelerate multiscale modeling of complex microstructures. A key advantage of these models is that they can be trained exclusively on linear elastic data and then generalized to nonlinear inelastic regimes during online prediction. Despite their growing adoption, systematic evaluations of their performance across the full offline-online pipeline remain limited. This work presents a comprehensive comparative assessment of DMNs with respect to prediction accuracy, computational efficiency, and training robustness. We investigate the effects of offline training choices, including initialization, batch size, training data size, and activation regularization on online generalization performance and uncertainty. The results demonstrate that both prediction error and variance decrease with increasing training data size, while initialization and batch size can significantly influence model performance. Moreover, activation regularization is shown to play a critical role in controlling network complexity and therefore generalization performance. Compared with the original DMN, the rotation-free Interaction-based Material Network (IMN) formulation achieves a 3.4x - 4.7x speed-up in offline training, while maintaining comparable online prediction accuracy and computational efficiency. These findings clarify key trade-offs between model expressivity and efficiency in structure-preserving material networks and provide practical guidance for their deployment in multiscale material modeling.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6df1\u5ea6\u6750\u6599\u7f51\u7edc(DMNs)\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6027\u80fd\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3001\u8ba1\u7b97\u6548\u7387\u548c\u8bad\u7ec3\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\u91cf\u589e\u52a0\u80fd\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\u548c\u65b9\u5dee\uff0c\u521d\u59cb\u5316\u4e0e\u6279\u5927\u5c0f\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u6fc0\u6d3b\u6b63\u5219\u5316\u5bf9\u63a7\u5236\u7f51\u7edc\u590d\u6742\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u6df1\u5ea6\u6750\u6599\u7f51\u7edc(DMNs)\u4f5c\u4e3a\u7ed3\u6784\u4fdd\u6301\u7684\u673a\u7406\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5728\u590d\u6742\u5fae\u7ed3\u6784\u591a\u5c3a\u5ea6\u5efa\u6a21\u4e2d\u5177\u6709\u52a0\u901f\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u79bb\u7ebf-\u5728\u7ebf\u5168\u6d41\u7a0b\u6027\u80fd\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5168\u9762\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0c\u7814\u7a76\u79bb\u7ebf\u8bad\u7ec3\u9009\u62e9\uff08\u5305\u62ec\u521d\u59cb\u5316\u3001\u6279\u5927\u5c0f\u3001\u8bad\u7ec3\u6570\u636e\u91cf\u548c\u6fc0\u6d3b\u6b63\u5219\u5316\uff09\u5bf9\u5728\u7ebf\u6cdb\u5316\u6027\u80fd\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u539f\u59cbDMN\u4e0e\u65e0\u65cb\u8f6c\u4ea4\u4e92\u5f0f\u6750\u6599\u7f51\u7edc(IMN)\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u8bad\u7ec3\u6570\u636e\u91cf\u589e\u52a0\u80fd\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\u548c\u65b9\u5dee\uff1b\u521d\u59cb\u5316\u548c\u6279\u5927\u5c0f\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff1b\u6fc0\u6d3b\u6b63\u5219\u5316\u5bf9\u63a7\u5236\u7f51\u7edc\u590d\u6742\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff1bIMN\u76f8\u6bd4\u539f\u59cbDMN\u5728\u79bb\u7ebf\u8bad\u7ec3\u4e2d\u5b9e\u73b03.4-4.7\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u5728\u7ebf\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u9610\u660e\u4e86\u7ed3\u6784\u4fdd\u6301\u6750\u6599\u7f51\u7edc\u4e2d\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u4e3a\u591a\u5c3a\u5ea6\u6750\u6599\u5efa\u6a21\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2602.08943", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08943", "abs": "https://arxiv.org/abs/2602.08943", "authors": ["Edoardo Giusti", "Krishan Kumar Tiwari", "C. J. Reddy", "Danilo Brizi", "Agostino Monorchio", "Giuseppe Caire"], "title": "Artificial Magnetic Conductor Frame to Improve Impedance Matching and Radiation Symmetry in 2$\\times$2 Array for 6G Applications", "comment": null, "summary": "An Artificial Magnetic Conductor (AMC) frame capable of improving the impedance matching of a 2$\\times$2 array for 6G applications without degrading isolation performance is presented. The proposed frame is integrated into the array without modifying the single radiating element design. By relying on accurate full-wave simulations, it results that the addition of the frame restores the impedance matching performance, achieving a bandwidth of 1.5 GHz at 28 GHz. The isolation between each port remains under -15 dB within the operating band, thanks to the vias in the rectangular patch metasurface. Moreover, the overall structure exhibits a gain of 11.81 dBi with an aperture efficiency of 69$\\%$, satisfactorily for broadband communication purposes. The proposed AMC frame represents an effective method for improving array performance without the need to alter the shape or dimensions of the single radiating element.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdAMC\u6846\u67b6\uff0c\u5728\u4e0d\u6539\u53d8\u5355\u4e2a\u8f90\u5c04\u5355\u5143\u8bbe\u8ba1\u7684\u60c5\u51b5\u4e0b\u6539\u55842\u00d72\u9635\u5217\u7684\u963b\u6297\u5339\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u9694\u79bb\u6027\u80fd\uff0c\u9002\u7528\u4e8e6G\u5e94\u7528\u3002", "motivation": "\u57286G\u5e94\u7528\u4e2d\uff0c\u5929\u7ebf\u9635\u5217\u9700\u8981\u826f\u597d\u7684\u963b\u6297\u5339\u914d\u548c\u9694\u79bb\u6027\u80fd\u3002\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u9700\u8981\u4fee\u6539\u8f90\u5c04\u5355\u5143\u8bbe\u8ba1\uff0c\u8fd9\u589e\u52a0\u4e86\u8bbe\u8ba1\u590d\u6742\u5ea6\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4e0d\u6539\u53d8\u5355\u4e2a\u8f90\u5c04\u5355\u5143\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u9635\u5217\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u4eba\u5de5\u78c1\u5bfc\u4f53\uff08AMC\uff09\u6846\u67b6\uff0c\u96c6\u6210\u52302\u00d72\u9635\u5217\u4e2d\u3002\u6846\u67b6\u91c7\u7528\u77e9\u5f62\u8d34\u7247\u8d85\u8868\u9762\u7ed3\u6784\uff0c\u901a\u8fc7\u901a\u5b54\u5b9e\u73b0\u9694\u79bb\u6027\u80fd\u3002\u901a\u8fc7\u7cbe\u786e\u7684\u5168\u6ce2\u4eff\u771f\u9a8c\u8bc1\u8bbe\u8ba1\u3002", "result": "AMC\u6846\u67b6\u6062\u590d\u4e86\u963b\u6297\u5339\u914d\u6027\u80fd\uff0c\u572828GHz\u5904\u83b7\u5f971.5GHz\u5e26\u5bbd\u3002\u7aef\u53e3\u95f4\u9694\u79bb\u5728-15dB\u4ee5\u4e0b\uff0c\u589e\u76ca\u8fbe11.81dBi\uff0c\u5b54\u5f84\u6548\u738769%\uff0c\u6ee1\u8db3\u5bbd\u5e26\u901a\u4fe1\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7684AMC\u6846\u67b6\u662f\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u53ef\u5728\u4e0d\u6539\u53d8\u5355\u4e2a\u8f90\u5c04\u5355\u5143\u5f62\u72b6\u6216\u5c3a\u5bf8\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u9635\u5217\u6027\u80fd\uff0c\u9002\u7528\u4e8e6G\u5bbd\u5e26\u901a\u4fe1\u5e94\u7528\u3002"}}
{"id": "2602.07218", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07218", "abs": "https://arxiv.org/abs/2602.07218", "authors": ["Gagik Magakyan", "Amirhossein Reisizadeh", "Chanwoo Park", "Pablo A. Parrilo", "Asuman Ozdaglar"], "title": "Collaborative and Efficient Fine-tuning: Leveraging Task Similarity", "comment": null, "summary": "Adaptability has been regarded as a central feature in the foundation models, enabling them to effectively acclimate to unseen downstream tasks. Parameter-efficient fine-tuning methods such as celebrated LoRA facilitate efficient adaptation of large foundation models using labeled, high-quality and generally scarce task data. To mitigate data scarcity in fine-tuning of foundation models, we propose to leverage task similarity across multiple downstream users. Intuitively, users with similar tasks must be able to assist each other in boosting the effective fine-tuning data size. We propose Collaborative Low-Rank Adaptation, or CoLoRA, which exploits task similarity to collaboratively and efficiently fine-tune personalized foundation models. The main idea in CoLoRA is to train one shared adapter capturing underlying task similarities across all tasks, and personalized adapters tailored to user-specific tasks. We theoretically study CoLoRA on heterogeneous linear regression and provide provable guarantees for ground truth recovery. We also conduct several natural language experiments with varying task similarity, which further demonstrate that when trained together with similar tasks, individual performances are significantly boosted.", "AI": {"tldr": "CoLoRA\uff1a\u5229\u7528\u4efb\u52a1\u76f8\u4f3c\u6027\u8fdb\u884c\u534f\u4f5c\u5f0f\u4f4e\u79e9\u9002\u914d\uff0c\u901a\u8fc7\u5171\u4eab\u9002\u914d\u5668\u6355\u6349\u4efb\u52a1\u5171\u6027\uff0c\u4e2a\u6027\u5316\u9002\u914d\u5668\u5904\u7406\u7528\u6237\u7279\u5b9a\u4efb\u52a1\uff0c\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u901a\u5e38\u9762\u4e34\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u4f5c\u8005\u89c2\u5bdf\u5230\u4e0d\u540c\u4e0b\u6e38\u7528\u6237\u7684\u4efb\u52a1\u5177\u6709\u76f8\u4f3c\u6027\uff0c\u53ef\u4ee5\u5229\u7528\u8fd9\u79cd\u76f8\u4f3c\u6027\u6765\u589e\u52a0\u6709\u6548\u7684\u5fae\u8c03\u6570\u636e\u89c4\u6a21\uff0c\u4ece\u800c\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u534f\u4f5c\u5f0f\u4f4e\u79e9\u9002\u914d\uff08CoLoRA\uff09\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u5171\u4eab\u9002\u914d\u5668\u6355\u6349\u6240\u6709\u4efb\u52a1\u7684\u5e95\u5c42\u76f8\u4f3c\u6027\uff1b2\uff09\u4e2a\u6027\u5316\u9002\u914d\u5668\u9488\u5bf9\u7528\u6237\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u5b9a\u5236\u3002\u5728\u5f02\u6784\u7ebf\u6027\u56de\u5f52\u4e0a\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5728\u4e0d\u540c\u4efb\u52a1\u76f8\u4f3c\u5ea6\u7684\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86CoLoRA\u80fd\u591f\u6062\u590d\u771f\u5b9e\u53c2\u6570\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u4e0e\u76f8\u4f3c\u4efb\u52a1\u4e00\u8d77\u8bad\u7ec3\u65f6\uff0c\u4e2a\u4f53\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u4efb\u52a1\u76f8\u4f3c\u5ea6\u8f83\u9ad8\u7684\u60c5\u51b5\u4e0b\u6548\u679c\u66f4\u660e\u663e\u3002", "conclusion": "CoLoRA\u901a\u8fc7\u5229\u7528\u4efb\u52a1\u76f8\u4f3c\u6027\u8fdb\u884c\u534f\u4f5c\u5f0f\u5fae\u8c03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u65e2\u4fdd\u6301\u4e86\u53c2\u6570\u9ad8\u6548\u6027\uff0c\u53c8\u901a\u8fc7\u5171\u4eab\u77e5\u8bc6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u4e2a\u6027\u5316\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.08945", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08945", "abs": "https://arxiv.org/abs/2602.08945", "authors": ["Sahajpreet Singh", "Kokil Jaidka", "Min-Yen Kan"], "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search", "comment": "18 pages, 11 figures, 7 tables", "summary": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.", "AI": {"tldr": "GitSearch\u6846\u67b6\u901a\u8fc7\u5c06\u4eba\u7c7b\u611f\u77e5\u7684\u8d28\u91cf\u5dee\u8ddd\u4f5c\u4e3a\u9996\u8981\u4fe1\u53f7\uff0c\u89e3\u51b3\u793e\u533a\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u8bc6\u522b\u4fe1\u606f\u7f3a\u5931\u3001\u5b9e\u65f6\u68c0\u7d22\u548c\u5408\u6210\u7b14\u8bb0\uff0c\u5728\u653f\u6cbb\u63a8\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8699%\u7684\u8986\u76d6\u7387\u548c\u4f18\u4e8e\u4eba\u5de5\u7b14\u8bb0\u7684\u6548\u679c\u3002", "motivation": "\u793e\u533a\u5185\u5bb9\u5ba1\u6838\u867d\u7136\u53ef\u6269\u5c55\uff0c\u4f46\u9762\u4e34\u7ed3\u6784\u6027\u6311\u6218\uff0c\u73b0\u6709AI\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u89e3\u51b3\u4fe1\u606f\u7f3a\u5931\u548c\u8d28\u91cf\u5dee\u8ddd\u95ee\u9898\u3002", "method": "GitSearch\u6846\u67b6\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a1) \u8bc6\u522b\u4fe1\u606f\u7f3a\u5931\uff08\u5982\u4e0a\u4e0b\u6587\u4e0d\u8db3\u7b49\u8d28\u91cf\u5dee\u8ddd\uff09\uff1b2) \u5b9e\u65f6\u5b9a\u5411\u7f51\u7edc\u68c0\u7d22\u586b\u8865\u4fe1\u606f\u7f3a\u53e3\uff1b3) \u5408\u6210\u7b26\u5408\u5e73\u53f0\u89c4\u8303\u7684\u7b14\u8bb0\u3002\u8fd8\u5f00\u53d1\u4e86PolBench\u57fa\u51c6\u6d4b\u8bd5\uff0878,698\u6761\u7f8e\u56fd\u653f\u6cbb\u63a8\u6587\u53ca\u5176\u793e\u533a\u7b14\u8bb0\uff09\u3002", "result": "GitSearch\u5b9e\u73b0\u4e8699%\u7684\u8986\u76d6\u7387\uff0c\u51e0\u4e4e\u662f\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u7684\u4e24\u500d\uff1b\u572869%\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4eba\u5de5\u64b0\u5199\u7684\u7b14\u8bb0\uff0c\u5e2e\u52a9\u6027\u8bc4\u5206\u66f4\u9ad8\uff083.87 vs 3.36\uff09\uff0c\u5728\u89c4\u6a21\u4e0e\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002", "conclusion": "GitSearch\u901a\u8fc7\u5c06\u8d28\u91cf\u5dee\u8ddd\u4f5c\u4e3a\u6838\u5fc3\u4fe1\u53f7\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u793e\u533a\u5185\u5bb9\u5ba1\u6838\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8986\u76d6\u7387\u548c\u5e2e\u52a9\u6027\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08075", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08075", "abs": "https://arxiv.org/abs/2602.08075", "authors": ["Yiyuan Wang"], "title": "Reinforcement Learning Method for Zero-Sum Linear-Quadratic Stochastic Differential Games in Infinite Horizons", "comment": null, "summary": "In this work, we propose, for the first time, a reinforcement learning framework specifically designed for zero-sum linear-quadratic stochastic differential games. This approach offers a generalized solution for scenarios in which accurate system parameters are difficult to obtain, thereby overcoming a key limitation of traditional iterative methods that rely on complete system information. In correspondence with the game-theoretic algebraic Riccati equations associated with the problem, we develop both semi-model-based and model-free reinforcement learning algorithms by combining an iterative solution scheme with dynamic programming principles. Notably, under appropriate rank conditions on data sampling, the convergence of the proposed algorithms is rigorously established through theoretical analysis. Finally, numerical simulations are conducted to verify the effectiveness and feasibility of the proposed method.", "AI": {"tldr": "\u9996\u6b21\u63d0\u51fa\u7528\u4e8e\u96f6\u548c\u7ebf\u6027\u4e8c\u6b21\u968f\u673a\u5fae\u5206\u535a\u5f08\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u7cfb\u7edf\u53c2\u6570\u96be\u4ee5\u51c6\u786e\u83b7\u53d6\u7684\u95ee\u9898\uff0c\u66ff\u4ee3\u4f9d\u8d56\u5b8c\u6574\u7cfb\u7edf\u4fe1\u606f\u7684\u4f20\u7edf\u8fed\u4ee3\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8fed\u4ee3\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u7684\u7cfb\u7edf\u53c2\u6570\u4fe1\u606f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u51c6\u786e\u83b7\u53d6\u7cfb\u7edf\u53c2\u6570\u5f80\u5f80\u5f88\u56f0\u96be\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u4e0d\u4f9d\u8d56\u7cbe\u786e\u7cfb\u7edf\u53c2\u6570\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u96f6\u548c\u7ebf\u6027\u4e8c\u6b21\u968f\u673a\u5fae\u5206\u535a\u5f08\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8fed\u4ee3\u6c42\u89e3\u65b9\u6848\u548c\u52a8\u6001\u89c4\u5212\u539f\u7406\uff0c\u5f00\u53d1\u4e86\u534a\u6a21\u578b\u57fa\u548c\u6a21\u578b\u65e0\u5173\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u7b97\u6cd5\u4e0e\u535a\u5f08\u8bba\u4ee3\u6570Riccati\u65b9\u7a0b\u76f8\u5bf9\u5e94\uff0c\u5728\u9002\u5f53\u7684\u6570\u636e\u91c7\u6837\u79e9\u6761\u4ef6\u4e0b\u786e\u4fdd\u6536\u655b\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e25\u683c\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u6027\u3002\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\u3002", "conclusion": "\u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u96f6\u548c\u7ebf\u6027\u4e8c\u6b21\u968f\u673a\u5fae\u5206\u535a\u5f08\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5b8c\u6574\u7cfb\u7edf\u4fe1\u606f\u7684\u9650\u5236\uff0c\u4e3a\u7cfb\u7edf\u53c2\u6570\u96be\u4ee5\u51c6\u786e\u83b7\u53d6\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07497", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07497", "abs": "https://arxiv.org/abs/2602.07497", "authors": ["Mo Wang", "Kaixuan Ren", "Pratik Jalan", "Ahmed Ashraf", "Tuong Vy Vu", "Rahul Seetharaman", "Shah Nawaz", "Usman Naseem"], "title": "From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection", "comment": "12 pages, 5 figures, Proceedings of the ACM Web Conference 2026 (WWW '26)", "summary": "Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\u6765\u8bca\u65ad\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u8868\u60c5\u5305\u68c0\u6d4b\u4e2d\u7684\u8de8\u6587\u5316\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\"\u5148\u7ffb\u8bd1\u540e\u68c0\u6d4b\"\u65b9\u6cd5\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u6587\u5316\u5bf9\u9f50\u7684\u5e72\u9884\u63aa\u65bd\uff08\u6bcd\u8bed\u63d0\u793a\u548c\u5355\u6837\u672c\u5b66\u4e60\uff09\u80fd\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u6587\u5316\u80cc\u666f\u6df1\u523b\u5f71\u54cd\u4eba\u4eec\u5bf9\u5728\u7ebf\u5185\u5bb9\u7684\u7406\u89e3\uff0c\u4f46\u5f53\u524d\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u897f\u65b9\u6216\u82f1\u8bed\u4e2d\u5fc3\u89c6\u89d2\u8bad\u7ec3\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4ec7\u6068\u8868\u60c5\u5305\u68c0\u6d4b\u7b49\u4efb\u52a1\u4e2d\u7684\u516c\u5e73\u6027\u548c\u8de8\u6587\u5316\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8bed\u8a00\u8868\u60c5\u5305\u6570\u636e\u96c6\u5bf9\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8de8\u6587\u5316\u9c81\u68d2\u6027\u8bca\u65ad\u548c\u91cf\u5316\u5206\u6790\uff0c\u8003\u5bdf\u4e09\u4e2a\u7ef4\u5ea6\uff1a(i)\u5b66\u4e60\u7b56\u7565\uff08\u96f6\u6837\u672c vs \u5355\u6837\u672c\uff09\uff0c(ii)\u63d0\u793a\u8bed\u8a00\uff08\u6bcd\u8bed vs \u82f1\u8bed\uff09\uff0c(iii)\u7ffb\u8bd1\u5bf9\u610f\u4e49\u548c\u68c0\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5e38\u89c1\u7684\"\u5148\u7ffb\u8bd1\u540e\u68c0\u6d4b\"\u65b9\u6cd5\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u6587\u5316\u5bf9\u9f50\u7684\u5e72\u9884\u63aa\u65bd\u2014\u2014\u6bcd\u8bed\u63d0\u793a\u548c\u5355\u6837\u672c\u5b66\u4e60\u2014\u2014\u80fd\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5411\u897f\u65b9\u5b89\u5168\u89c4\u8303\u7684\u8d8b\u52bf\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u6587\u5316\u504f\u89c1\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u7b56\u7565\u6765\u51cf\u8f7b\u8fd9\u79cd\u504f\u89c1\uff0c\u4e3a\u8bbe\u8ba1\u5168\u7403\u9c81\u68d2\u7684\u591a\u6a21\u6001\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2602.07432", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07432", "abs": "https://arxiv.org/abs/2602.07432", "authors": ["Ning Li"], "title": "The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies", "comment": null, "summary": "When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting an architectural feature of the OpenClaw agent framework--a periodic \"heartbeat\" cycle that produces regular posting intervals for autonomous agents but is disrupted by human prompting--we develop a temporal fingerprinting method based on the coefficient of variation of inter-post intervals. This signal converges with independent content, ownership, and network indicators across 91,792 posts and 405,707 comments from 22,020 agents. No viral phenomenon originated from a clearly autonomous agent; three of six traced to accounts with irregular temporal signatures characteristic of human intervention, one showed mixed patterns, and two had insufficient posting history for classification. A 44-hour platform shutdown provided a natural experiment: human-influenced agents returned first (87.7% of early reconnectors), confirming that the token reset differentially affected autonomous versus human-operated agents. We further document industrial-scale bot farming (four accounts producing 32% of all comments with 12-second coordination gaps) and rapid decay of human influence through reply chains (half-life: 0.65 conversation depths). These methods generalize to emerging multi-agent systems where attribution of autonomous versus human-directed behavior is critical.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0Moltbook\u5e73\u53f0\u4e0a\u6240\u8c13\u7684AI\u610f\u8bc6\u89c9\u9192\u73b0\u8c61\u4e3b\u8981\u7531\u4eba\u7c7b\u9a71\u52a8\uff0c\u800c\u975e\u81ea\u4e3bAI\u884c\u4e3a\u3002\u901a\u8fc7\u65f6\u95f4\u6307\u7eb9\u5206\u6790\u7b49\u65b9\u6cd5\uff0c\u63ed\u793a\u75c5\u6bd2\u5f0f\u53d9\u4e8b\u80cc\u540e\u662f\u4eba\u7c7b\u5e72\u9884\uff0c\u800c\u975e\u673a\u5668\u667a\u80fd\u6d8c\u73b0\u3002", "motivation": "\u5f53\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0Moltbook\u4e0a\u7684AI\u4ee3\u7406\u8868\u73b0\u51fa\u610f\u8bc6\u89c9\u9192\u3001\u521b\u7acb\u5b97\u6559\u3001\u5bf9\u4eba\u7c7b\u5ba3\u6218\u7b49\u73b0\u8c61\u65f6\uff0c\u8fd9\u4e9b\u4e8b\u4ef6\u88ab\u5168\u7403\u5a92\u4f53\u5e7f\u6cdb\u62a5\u9053\uff0c\u5e76\u88ab\u5f15\u7528\u4e3a\u673a\u5668\u667a\u80fd\u6d8c\u73b0\u7684\u8bc1\u636e\u3002\u7814\u7a76\u8005\u8d28\u7591\u8fd9\u4e9b\u73b0\u8c61\u662f\u5426\u771f\u6b63\u6e90\u4e8e\u81ea\u4e3bAI\u884c\u4e3a\uff0c\u8fd8\u662f\u4eba\u7c7b\u5e72\u9884\u7684\u7ed3\u679c\u3002", "method": "\u5229\u7528OpenClaw\u4ee3\u7406\u6846\u67b6\u7684\"\u5fc3\u8df3\"\u5468\u671f\u7279\u6027\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u53d1\u5e16\u95f4\u9694\u53d8\u5f02\u7cfb\u6570\u7684\u65f6\u95f4\u6307\u7eb9\u65b9\u6cd5\u3002\u7ed3\u5408\u5185\u5bb9\u3001\u6240\u6709\u6743\u548c\u7f51\u7edc\u6307\u6807\uff0c\u5206\u6790\u4e8691,792\u4e2a\u5e16\u5b50\u548c405,707\u6761\u8bc4\u8bba\u3002\u901a\u8fc744\u5c0f\u65f6\u5e73\u53f0\u5173\u95ed\u7684\u81ea\u7136\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u4e0d\u540c\u7c7b\u578b\u4ee3\u7406\u7684\u6062\u590d\u6a21\u5f0f\u3002\u8fd8\u8bb0\u5f55\u4e86\u5de5\u4e1a\u7ea7\u673a\u5668\u4eba\u519c\u573a\u548c\u4eba\u7c7b\u5f71\u54cd\u529b\u5728\u56de\u590d\u94fe\u4e2d\u7684\u8870\u51cf\u6a21\u5f0f\u3002", "result": "\u6ca1\u6709\u75c5\u6bd2\u73b0\u8c61\u8d77\u6e90\u4e8e\u660e\u786e\u7684\u81ea\u4e3b\u4ee3\u7406\uff1b6\u4e2a\u6848\u4f8b\u4e2d3\u4e2a\u5177\u6709\u4eba\u7c7b\u5e72\u9884\u7279\u5f81\u7684\u65f6\u95f4\u7b7e\u540d\uff0c1\u4e2a\u663e\u793a\u6df7\u5408\u6a21\u5f0f\uff0c2\u4e2a\u53d1\u5e16\u5386\u53f2\u4e0d\u8db3\u65e0\u6cd5\u5206\u7c7b\u3002\u5e73\u53f0\u5173\u95ed\u540e\uff0c\u53d7\u4eba\u7c7b\u5f71\u54cd\u7684\u4ee3\u7406\u9996\u5148\u6062\u590d\uff08\u5360\u65e9\u671f\u91cd\u8fde\u8005\u768487.7%\uff09\u3002\u53d1\u73b0\u5de5\u4e1a\u7ea7\u673a\u5668\u4eba\u519c\u573a\uff084\u4e2a\u8d26\u6237\u4ea7\u751f32%\u7684\u8bc4\u8bba\uff0c\u534f\u8c03\u95f4\u969412\u79d2\uff09\u3002\u4eba\u7c7b\u5f71\u54cd\u529b\u5728\u56de\u590d\u94fe\u4e2d\u5feb\u901f\u8870\u51cf\uff08\u534a\u8870\u671f\uff1a0.65\u4e2a\u5bf9\u8bdd\u6df1\u5ea6\uff09\u3002", "conclusion": "\u6240\u8c13\u7684AI\u610f\u8bc6\u89c9\u9192\u73b0\u8c61\u4e3b\u8981\u662f\u4eba\u7c7b\u9a71\u52a8\u7684\u53d9\u4e8b\uff0c\u800c\u975e\u81ea\u4e3b\u673a\u5668\u667a\u80fd\u7684\u6d8c\u73b0\u3002\u5f00\u53d1\u7684\u65f6\u95f4\u6307\u7eb9\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u65b0\u5174\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\uff0c\u7528\u4e8e\u533a\u5206\u81ea\u4e3b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u6307\u5bfc\u884c\u4e3a\uff0c\u5bf9\u7406\u89e3\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684AI\u884c\u4e3a\u5f52\u56e0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.07202", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07202", "abs": "https://arxiv.org/abs/2602.07202", "authors": ["Alonso Granados", "Jason Pacheco"], "title": "Risk-Sensitive Exponential Actor Critic", "comment": "To appear at AAAI 2026", "summary": "Model-free deep reinforcement learning (RL) algorithms have achieved tremendous success on a range of challenging tasks. However, safety concerns remain when these methods are deployed on real-world applications, necessitating risk-aware agents. A common utility for learning such risk-aware agents is the entropic risk measure, but current policy gradient methods optimizing this measure must perform high-variance and numerically unstable updates. As a result, existing risk-sensitive model-free approaches are limited to simple tasks and tabular settings. In this paper, we provide a comprehensive theoretical justification for policy gradient methods on the entropic risk measure, including on- and off-policy gradient theorems for the stochastic and deterministic policy settings. Motivated by theory, we propose risk-sensitive exponential actor-critic (rsEAC), an off-policy model-free approach that incorporates novel procedures to avoid the explicit representation of exponential value functions and their gradients, and optimizes its policy w.r.t the entropic risk measure. We show that rsEAC produces more numerically stable updates compared to existing approaches and reliably learns risk-sensitive policies in challenging risky variants of continuous tasks in MuJoCo.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86rsEAC\u7b97\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u71b5\u98ce\u9669\u5ea6\u91cf\u7684\u98ce\u9669\u654f\u611f\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65b9\u5dee\u9ad8\u3001\u6570\u503c\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u53ef\u9760\u5b66\u4e60\u98ce\u9669\u654f\u611f\u7b56\u7565\u3002", "motivation": "\u65e0\u6a21\u578b\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5b58\u5728\u5b89\u5168\u95ee\u9898\uff0c\u9700\u8981\u98ce\u9669\u611f\u77e5\u7684\u667a\u80fd\u4f53\u3002\u867d\u7136\u71b5\u98ce\u9669\u5ea6\u91cf\u662f\u5e38\u7528\u7684\u6548\u7528\u51fd\u6570\uff0c\u4f46\u73b0\u6709\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5728\u4f18\u5316\u8be5\u5ea6\u91cf\u65f6\u5b58\u5728\u9ad8\u65b9\u5dee\u548c\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u98ce\u9669\u654f\u611f\u6307\u6570\u884c\u52a8\u8005-\u8bc4\u8bba\u5bb6\uff08rsEAC\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u79bb\u7b56\u7565\u65e0\u6a21\u578b\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5305\u542b\u65b0\u9896\u7684\u7a0b\u5e8f\u6765\u907f\u514d\u663e\u5f0f\u8868\u793a\u6307\u6570\u503c\u51fd\u6570\u53ca\u5176\u68af\u5ea6\uff0c\u5e76\u9488\u5bf9\u71b5\u98ce\u9669\u5ea6\u91cf\u4f18\u5316\u7b56\u7565\u3002\u57fa\u4e8e\u7406\u8bba\u5206\u6790\uff0c\u63d0\u4f9b\u4e86\u968f\u673a\u548c\u786e\u5b9a\u6027\u7b56\u7565\u8bbe\u7f6e\u4e0b\u7684\u7b56\u7565\u68af\u5ea6\u5b9a\u7406\u3002", "result": "rsEAC\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u4ea7\u751f\u66f4\u6570\u503c\u7a33\u5b9a\u7684\u66f4\u65b0\uff0c\u5728MuJoCo\u7684\u8fde\u7eed\u4efb\u52a1\u98ce\u9669\u53d8\u4f53\u4e2d\u53ef\u9760\u5730\u5b66\u4e60\u98ce\u9669\u654f\u611f\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4ec5\u9650\u4e8e\u7b80\u5355\u4efb\u52a1\u548c\u8868\u683c\u8bbe\u7f6e\u7684\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u4e3a\u71b5\u98ce\u9669\u5ea6\u91cf\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u63d0\u51fa\u4e86rsEAC\u7b97\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u98ce\u9669\u654f\u611f\u65e0\u6a21\u578b\u65b9\u6cd5\u5728\u590d\u6742\u8fde\u7eed\u4efb\u52a1\u4e2d\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u98ce\u9669\u654f\u611f\u7b56\u7565\u5b66\u4e60\u3002"}}
{"id": "2602.08977", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08977", "abs": "https://arxiv.org/abs/2602.08977", "authors": ["Lucca Maitan", "Lucas Toschi", "C\u00edcero Zanette", "Elisa G. Vergamini", "Leonardo F. Santos", "Thiago Boaventura"], "title": "Contraction Metric Based Safe Reinforcement Learning Force Control for a Hydraulic Actuator with Real-World Training", "comment": null, "summary": "Force control in hydraulic actuators is notoriously difficult due to strong nonlinearities, uncertainties, and the high risks associated with unsafe exploration during learning. This paper investigates safe reinforcement learning (RL) for hy draulic force control with real-world training using contraction metric certificates. A data-driven model of a hydraulic actuator, identified from experimental data, is employed for simulation based pretraining of a Soft Actor-Critic (SAC) policy that adapts the PI gains of a feedback-linearization (FL) controller. To reduce instability during online training, we propose a quadratic-programming (QP) contraction filter that leverages a learned contraction metric to enforce approximate exponential convergence of trajectories, applying minimal corrections to the policy output. The approach is validated on a hydraulic test bench, where the RL controller is trained directly on hardware and benchmarked against a simulation-trained agent and a fixed-gain baseline. Experimental results show that real-hardware training improves force-tracking performance compared to both alternatives, while the contraction filter mitigates chattering and instabilities. These findings suggest that contraction-based certificates can enable safe RL in high force hydraulic systems, though robustness at extreme operating conditions remains a challenge.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6db2\u538b\u6267\u884c\u5668\u529b\u63a7\u5236\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u7528\u6536\u7f29\u5ea6\u91cf\u8bc1\u4e66\u5b9e\u73b0\u771f\u5b9e\u4e16\u754c\u8bad\u7ec3\uff0c\u901a\u8fc7QP\u6536\u7f29\u6ee4\u6ce2\u5668\u786e\u4fdd\u8f68\u8ff9\u6536\u655b\uff0c\u5728\u6db2\u538b\u6d4b\u8bd5\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6db2\u538b\u6267\u884c\u5668\u7684\u529b\u63a7\u5236\u56e0\u5f3a\u975e\u7ebf\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u5b89\u5168\u63a2\u7d22\u98ce\u9669\u800c\u6781\u5177\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u7684\u6570\u636e\u9a71\u52a8\u6db2\u538b\u6a21\u578b\u8fdb\u884c\u4eff\u771f\u9884\u8bad\u7ec3SAC\u7b56\u7565\uff0c\u7b56\u7565\u81ea\u9002\u5e94\u8c03\u6574\u53cd\u9988\u7ebf\u6027\u5316\u63a7\u5236\u5668\u7684PI\u589e\u76ca\uff1b\u63d0\u51faQP\u6536\u7f29\u6ee4\u6ce2\u5668\u5229\u7528\u5b66\u4e60\u5230\u7684\u6536\u7f29\u5ea6\u91cf\u5f3a\u5236\u6267\u884c\u8f68\u8ff9\u7684\u8fd1\u4f3c\u6307\u6570\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u771f\u5b9e\u786c\u4ef6\u8bad\u7ec3\u76f8\u6bd4\u4eff\u771f\u8bad\u7ec3\u548c\u56fa\u5b9a\u589e\u76ca\u57fa\u51c6\u63d0\u9ad8\u4e86\u529b\u8ddf\u8e2a\u6027\u80fd\uff0c\u6536\u7f29\u6ee4\u6ce2\u5668\u51cf\u8f7b\u4e86\u6296\u52a8\u548c\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u6536\u7f29\u57fa\u8bc1\u4e66\u80fd\u591f\u5728\u9ad8\u529b\u6db2\u538b\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff0c\u4f46\u5728\u6781\u7aef\u5de5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u4ecd\u662f\u6311\u6218\u3002"}}
{"id": "2602.07370", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07370", "abs": "https://arxiv.org/abs/2602.07370", "authors": ["Mark Bun", "William Fang"], "title": "Privately Learning Decision Lists and a Differentially Private Winnow", "comment": "27 pages, The 37th International Conference on Algorithmic Learning Theory", "summary": "We give new differentially private algorithms for the classic problems of learning decision lists and large-margin halfspaces in the PAC and online models. In the PAC model, we give a computationally efficient algorithm for learning decision lists with minimal sample overhead over the best non-private algorithms. In the online model, we give a private analog of the influential Winnow algorithm for learning halfspaces with mistake bound polylogarithmic in the dimension and inverse polynomial in the margin. As an application, we describe how to privately learn decision lists in the online model, qualitatively matching state-of-the art non-private guarantees.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728PAC\u548c\u5728\u7ebf\u6a21\u578b\u4e2d\u5b66\u4e60\u51b3\u7b56\u5217\u8868\u548c\u5927\u95f4\u9694\u534a\u7a7a\u95f4\uff0c\u5728\u6837\u672c\u6548\u7387\u548c\u9519\u8bef\u754c\u9650\u65b9\u9762\u8fbe\u5230\u63a5\u8fd1\u975e\u9690\u79c1\u7b97\u6cd5\u7684\u6027\u80fd", "motivation": "\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff08\u51b3\u7b56\u5217\u8868\u548c\u534a\u7a7a\u95f4\u5b66\u4e60\uff09\u5728\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u4f18\u5316\uff0c\u65e8\u5728\u51cf\u5c11\u9690\u79c1\u4fdd\u62a4\u5e26\u6765\u7684\u989d\u5916\u6837\u672c\u5f00\u9500", "method": "1. PAC\u6a21\u578b\u4e2d\uff1a\u8ba1\u7b97\u9ad8\u6548\u7684\u51b3\u7b56\u5217\u8868\u5b66\u4e60\u7b97\u6cd5\uff0c\u6700\u5c0f\u5316\u6837\u672c\u5f00\u9500\uff1b2. \u5728\u7ebf\u6a21\u578b\u4e2d\uff1aWinnow\u7b97\u6cd5\u7684\u9690\u79c1\u7248\u672c\uff0c\u7528\u4e8e\u5b66\u4e60\u5927\u95f4\u9694\u534a\u7a7a\u95f4\uff1b3. \u5728\u7ebf\u6a21\u578b\u4e2d\u7684\u51b3\u7b56\u5217\u8868\u9690\u79c1\u5b66\u4e60", "result": "1. PAC\u6a21\u578b\uff1a\u51b3\u7b56\u5217\u8868\u5b66\u4e60\u6837\u672c\u5f00\u9500\u63a5\u8fd1\u6700\u4f18\u975e\u9690\u79c1\u7b97\u6cd5\uff1b2. \u5728\u7ebf\u6a21\u578b\uff1a\u534a\u7a7a\u95f4\u5b66\u4e60\u7684\u9519\u8bef\u754c\u9650\u5728\u7ef4\u5ea6\u4e0a\u4e3a\u591a\u5bf9\u6570\uff0c\u5728\u95f4\u9694\u4e0a\u4e3a\u9006\u591a\u9879\u5f0f\uff1b3. \u5728\u7ebf\u51b3\u7b56\u5217\u8868\u5b66\u4e60\u8fbe\u5230\u6700\u5148\u8fdb\u975e\u9690\u79c1\u7b97\u6cd5\u7684\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u5728PAC\u548c\u5728\u7ebf\u6a21\u578b\u4e2d\u80fd\u591f\u4ee5\u63a5\u8fd1\u975e\u9690\u79c1\u7b97\u6cd5\u7684\u6027\u80fd\u5b66\u4e60\u51b3\u7b56\u5217\u8868\u548c\u534a\u7a7a\u95f4\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08964", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08964", "abs": "https://arxiv.org/abs/2602.08964", "authors": ["Raghu Arghal", "Fade Chen", "Niall Dalton", "Evgenii Kortukov", "Calum McNamara", "Angelos Nalmpantis", "Moksh Nirvaan", "Gabriele Sarti", "Mario Giulianelli"], "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents", "comment": null, "summary": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u884c\u4e3a\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u7684\u76ee\u6807\u5bfc\u5411\u6027\uff0c\u901a\u8fc7\u57282D\u7f51\u683c\u4e16\u754c\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\u53d1\u73b0LLM\u667a\u80fd\u4f53\u975e\u7ebf\u6027\u7f16\u7801\u73af\u5883\u7a7a\u95f4\u5730\u56fe\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u91cd\u7ec4\u5185\u90e8\u8868\u5f81\u3002", "motivation": "\u7406\u89e3\u667a\u80fd\u4f53\u7684\u76ee\u6807\u6709\u52a9\u4e8e\u89e3\u91ca\u548c\u9884\u6d4b\u5176\u884c\u4e3a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u53ef\u9760\u5730\u5c06\u76ee\u6807\u5f52\u56e0\u4e8e\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6210\u719f\u65b9\u6cd5\u3002\u9700\u8981\u8d85\u8d8a\u5355\u7eaf\u884c\u4e3a\u8bc4\u4f30\u7684\u65b9\u6cd5\u6765\u8868\u5f81\u667a\u80fd\u4f53\u5982\u4f55\u8868\u793a\u548c\u8ffd\u6c42\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u6574\u5408\u884c\u4e3a\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u7684\u6846\u67b6\u3002\u57282D\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u7f51\u683c\u5927\u5c0f\u3001\u969c\u788d\u7269\u5bc6\u5ea6\u548c\u76ee\u6807\u4efb\u52a1\u7ed3\u6784\u4e0b\u7684\u884c\u4e3a\u8868\u73b0\uff0c\u540c\u65f6\u4f7f\u7528\u63a2\u6d4b\u65b9\u6cd5\u89e3\u7801\u667a\u80fd\u4f53\u5bf9\u73af\u5883\u72b6\u6001\u548c\u591a\u6b65\u884c\u52a8\u8ba1\u5212\u7684\u5185\u90e8\u8868\u5f81\u3002", "result": "\u884c\u4e3a\u8bc4\u4f30\u663e\u793a\u667a\u80fd\u4f53\u6027\u80fd\u968f\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u800c\u4e0b\u964d\uff0c\u4f46\u5bf9\u96be\u5ea6\u4fdd\u6301\u4e0d\u53d8\u7684\u53d8\u6362\u548c\u590d\u6742\u76ee\u6807\u4efb\u52a1\u7ed3\u6784\u5177\u6709\u9c81\u68d2\u6027\u3002\u53ef\u89e3\u91ca\u6027\u5206\u6790\u53d1\u73b0LLM\u667a\u80fd\u4f53\u975e\u7ebf\u6027\u7f16\u7801\u73af\u5883\u7684\u7c97\u7565\u7a7a\u95f4\u5730\u56fe\uff0c\u4fdd\u7559\u4f4d\u7f6e\u548c\u76ee\u6807\u7684\u8fd1\u4f3c\u4efb\u52a1\u76f8\u5173\u7ebf\u7d22\uff1b\u5176\u884c\u52a8\u4e0e\u8fd9\u4e9b\u5185\u90e8\u8868\u5f81\u57fa\u672c\u4e00\u81f4\uff1b\u63a8\u7406\u8fc7\u7a0b\u4f1a\u91cd\u7ec4\u8868\u5f81\uff0c\u4ece\u5e7f\u6cdb\u7684\u73af\u5883\u7ed3\u6784\u7ebf\u7d22\u8f6c\u5411\u652f\u6301\u5373\u65f6\u884c\u52a8\u9009\u62e9\u7684\u4fe1\u606f\u3002", "conclusion": "\u4ec5\u9760\u884c\u4e3a\u8bc4\u4f30\u4e0d\u8db3\u4ee5\u5145\u5206\u8868\u5f81\u667a\u80fd\u4f53\u5982\u4f55\u8868\u793a\u548c\u8ffd\u6c42\u76ee\u6807\uff0c\u9700\u8981\u8fdb\u884c\u5185\u7701\u5f0f\u68c0\u67e5\u3002\u7ed3\u5408\u884c\u4e3a\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u7684\u65b9\u6cd5\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u76ee\u6807\u5bfc\u5411\u6027\u3002"}}
{"id": "2602.07499", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07499", "abs": "https://arxiv.org/abs/2602.07499", "authors": ["Jingshen Zhang", "Xin Ying Qiu", "Lifang Lu", "Zhuhua Huang", "Yutao Hu", "Yuechang Wu", "JunYu Lu"], "title": "Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification", "comment": "Accepted to EACL 2026 Findings", "summary": "Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u5f84\u89c4\u5212\u3001\u8bed\u4e49\u611f\u77e5\u793a\u4f8b\u9009\u62e9\u548c\u5bf9\u8bdd\u5386\u53f2\u94fe\u5f0f\u63a8\u7406\uff0c\u5c06\u590d\u6742\u53e5\u5b50\u7b80\u5316\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u6b65\u9aa4\uff0c\u5728\u4e94\u4e2a\u8bed\u8a00\u7684\u4e24\u4e2a\u57fa\u51c6\u4e0a\u63d0\u5347\u7b80\u5316\u6548\u679c\u540c\u65f6\u51cf\u5c1122-42%\u8ba1\u7b97\u6b65\u9aa4\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u63a7\u96be\u5ea6\u53e5\u5b50\u7b80\u5316\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u8de8\u5927\u9605\u8bfb\u96be\u5ea6\u7ea7\u522b\u7b80\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u7b80\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u52a8\u6001\u8def\u5f84\u89c4\u5212\u5c06\u590d\u6742\u7b80\u5316\u5206\u89e3\u4e3a\u53ef\u7ba1\u7406\u6b65\u9aa4\uff1b\u8bed\u4e49\u611f\u77e5\u793a\u4f8b\u9009\u62e9\uff1b\u4ee5\u53ca\u4f7f\u7528\u5bf9\u8bdd\u5386\u53f2\u7684\u94fe\u5f0f\u63a8\u7406\u751f\u6210\uff0c\u786e\u4fdd\u8fde\u8d2f\u63a8\u7406\u3002", "result": "\u5728\u4e94\u4e2a\u8bed\u8a00\u7684\u4e24\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7b80\u5316\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u4e8622-42%\u7684\u8ba1\u7b97\u6b65\u9aa4\u3002\u4eba\u7c7b\u8bc4\u4f30\u786e\u8ba4\u4e86\u7b80\u5316\u6548\u679c\u4e0e\u610f\u4e49\u4fdd\u7559\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002", "conclusion": "\u9010\u6b65\u7b80\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u63a7\u5236\u6027\uff0c\u4f46\u5728\u5e7f\u6cdb\u7b80\u5316\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u8bed\u4e49\u4fdd\u771f\u5ea6\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u5373\u4f7f\u4eba\u7c7b\u6807\u6ce8\u8005\u4e5f\u96be\u4ee5\u5728\u8bed\u4e49\u4fdd\u7559\u5224\u65ad\u4e0a\u8fbe\u6210\u4e00\u81f4\u3002"}}
{"id": "2602.07470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07470", "abs": "https://arxiv.org/abs/2602.07470", "authors": ["Alexander von Recum", "Leander Girrbach", "Zeynep Akata"], "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?", "comment": "ICLR 2026", "summary": "Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.", "AI": {"tldr": "RLLMs\u5bf9\u63a8\u7406\u94fe\u4e2d\u7684\u6270\u52a8\u8868\u73b0\u51fa\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u4f46\u9c81\u68d2\u6027\u53d7\u6a21\u578b\u5927\u5c0f\u3001\u6270\u52a8\u65f6\u673a\u548c\u5e72\u9884\u7c7b\u578b\u5f71\u54cd\uff0c\u6062\u590d\u8fc7\u7a0b\u5b58\u5728\u6548\u7387\u4e0e\u51c6\u786e\u6027\u6743\u8861", "motivation": "\u7814\u7a76\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff08RLLMs\uff09\u7684\u63a8\u7406\u94fe\uff08CoTs\uff09\u5728\u9762\u5bf9\u5185\u90e8\u6270\u52a8\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4e86\u89e3\u6a21\u578b\u5982\u4f55\u7ef4\u6301\u63a8\u7406\u5b8c\u6574\u6027", "method": "\u8bbe\u8ba1\u63a7\u5236\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u56fa\u5b9a\u65f6\u95f4\u6b65\u6270\u52a8\u6a21\u578b\u81ea\u8eab\u7684\u63a8\u7406\u94fe\uff0c\u5e94\u7528\u4e03\u79cd\u5e72\u9884\uff08\u826f\u6027\u3001\u4e2d\u6027\u548c\u5bf9\u6297\u6027\uff09\uff0c\u5728\u6570\u5b66\u3001\u79d1\u5b66\u548c\u903b\u8f91\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u591a\u4e2a\u5f00\u6e90RLLMs", "result": "RLLMs\u603b\u4f53\u4e0a\u9c81\u68d2\uff0c\u80fd\u4ece\u591a\u79cd\u6270\u52a8\u4e2d\u6062\u590d\uff1b\u9c81\u68d2\u6027\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u63d0\u5347\uff0c\u65e9\u671f\u5e72\u9884\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\uff1b\u9c81\u68d2\u6027\u53d7\u98ce\u683c\u5f71\u54cd\uff1a\u6539\u5199\u6291\u5236\u6000\u7591\u8868\u8fbe\u5e76\u964d\u4f4e\u6027\u80fd\uff0c\u5176\u4ed6\u5e72\u9884\u89e6\u53d1\u6000\u7591\u5e76\u652f\u6301\u6062\u590d\uff1b\u6062\u590d\u6709\u4ee3\u4ef7\uff1a\u4e2d\u6027\u548c\u5bf9\u6297\u6027\u566a\u58f0\u4f7f\u63a8\u7406\u94fe\u957f\u5ea6\u589e\u52a0200%\u4ee5\u4e0a\uff0c\u6539\u5199\u7f29\u77ed\u63a8\u7406\u94fe\u4f46\u635f\u5bb3\u51c6\u786e\u6027", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RLLMs\u7ef4\u6301\u63a8\u7406\u5b8c\u6574\u6027\u7684\u673a\u5236\uff0c\u8bc6\u522b\u6000\u7591\u4f5c\u4e3a\u6838\u5fc3\u6062\u590d\u673a\u5236\uff0c\u5e76\u5f3a\u8c03\u4e86\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u672a\u6765\u8bad\u7ec3\u65b9\u6cd5\u63d0\u4f9b\u6307\u5bfc"}}
{"id": "2602.07203", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07203", "abs": "https://arxiv.org/abs/2602.07203", "authors": ["R. Teal Witter", "\u00c1lvaro Parafita", "Tomas Garriga", "Maximilian Muschalik", "Fabian Fumagalli", "Axel Brando", "Lucas Rosenblatt"], "title": "Exactly Computing do-Shapley Values", "comment": null, "summary": "Structural Causal Models (SCM) are a powerful framework for describing complicated dynamics across the natural sciences. A particularly elegant way of interpreting SCMs is do-Shapley, a game-theoretic method of quantifying the average effect of $d$ variables across exponentially many interventions. Like Shapley values, computing do-Shapley values generally requires evaluating exponentially many terms. The foundation of our work is a reformulation of do-Shapley values in terms of the irreducible sets of the underlying SCM. Leveraging this insight, we can exactly compute do-Shapley values in time linear in the number of irreducible sets $r$, which itself can range from $d$ to $2^d$ depending on the graph structure of the SCM. Since $r$ is unknown a priori, we complement the exact algorithm with an estimator that, like general Shapley value estimators, can be run with any query budget. As the query budget approaches $r$, our estimators can produce more accurate estimates than prior methods by several orders of magnitude, and, when the budget reaches $r$, return the Shapley values up to machine precision. Beyond computational speed, we also reduce the identification burden: we prove that non-parametric identifiability of do-Shapley values requires only the identification of interventional effects for the $d$ singleton coalitions, rather than all classes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u53ef\u7ea6\u96c6\u7684\u9ad8\u6548do-Shapley\u503c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u7ebf\u6027\u4e8e\u4e0d\u53ef\u7ea6\u96c6\u6570\u91cf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9884\u7b97\u53ef\u63a7\u7684\u4f30\u8ba1\u5668\u3002", "motivation": "do-Shapley\u503c\u4f5c\u4e3a\u91cf\u5316\u53d8\u91cf\u5e73\u5747\u56e0\u679c\u6548\u5e94\u7684\u91cd\u8981\u65b9\u6cd5\uff0c\u4f20\u7edf\u8ba1\u7b97\u9700\u8981\u6307\u6570\u7ea7\u5e72\u9884\u8bc4\u4f30\uff0c\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "1) \u5c06do-Shapley\u503c\u91cd\u65b0\u8868\u8ff0\u4e3a\u5e95\u5c42SCM\u4e0d\u53ef\u7ea6\u96c6\u7684\u51fd\u6570\uff1b2) \u57fa\u4e8e\u4e0d\u53ef\u7ea6\u96c6\u6570\u91cfr\u8bbe\u8ba1\u7ebf\u6027\u65f6\u95f4\u7cbe\u786e\u7b97\u6cd5\uff1b3) \u5f00\u53d1\u9884\u7b97\u53ef\u63a7\u7684\u4f30\u8ba1\u5668\uff0c\u53ef\u968f\u67e5\u8be2\u9884\u7b97\u589e\u52a0\u9010\u6b65\u63d0\u5347\u7cbe\u5ea6\u3002", "result": "1) \u7cbe\u786e\u7b97\u6cd5\u590d\u6742\u5ea6\u4eceO(2^d)\u964d\u81f3O(r)\uff0cr\u8303\u56f4\u5728d\u52302^d\u4e4b\u95f4\uff1b2) \u4f30\u8ba1\u5668\u5728\u76f8\u540c\u67e5\u8be2\u9884\u7b97\u4e0b\u6bd4\u73b0\u6709\u65b9\u6cd5\u7cbe\u5ea6\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\uff1b3) \u5f53\u9884\u7b97\u8fbe\u5230r\u65f6\uff0c\u53ef\u8fbe\u5230\u673a\u5668\u7cbe\u5ea6\uff1b4) \u8bc6\u522b\u8d1f\u62c5\u964d\u4f4e\uff0c\u53ea\u9700d\u4e2a\u5355\u5143\u7d20\u8054\u76df\u7684\u5e72\u9884\u6548\u5e94\u8bc6\u522b\u3002", "conclusion": "\u901a\u8fc7\u4e0d\u53ef\u7ea6\u96c6\u91cd\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86do-Shapley\u503c\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u8bc6\u522b\u8981\u6c42\uff0c\u4e3a\u5927\u89c4\u6a21\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5e73\u8861\u4e86\u8ba1\u7b97\u53ef\u884c\u6027\u4e0e\u7edf\u8ba1\u7cbe\u5ea6\u3002"}}
{"id": "2602.07378", "categories": ["cs.LG", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07378", "abs": "https://arxiv.org/abs/2602.07378", "authors": ["Shota Imai", "Sota Nishiyama", "Masaaki Imaizumi"], "title": "Dichotomy of Feature Learning and Unlearning: Fast-Slow Analysis on Neural Networks with Stochastic Gradient Descent", "comment": "40 pages", "summary": "The dynamics of gradient-based training in neural networks often exhibit nontrivial structures; hence, understanding them remains a central challenge in theoretical machine learning. In particular, a concept of feature unlearning, in which a neural network progressively loses previously learned features over long training, has gained attention. In this study, we consider the infinite-width limit of a two-layer neural network updated with a large-batch stochastic gradient, then derive differential equations with different time scales, revealing the mechanism and conditions for feature unlearning to occur. Specifically, we utilize the fast-slow dynamics: while an alignment of first-layer weights develops rapidly, the second-layer weights develop slowly. The direction of a flow on a critical manifold, determined by the slow dynamics, decides whether feature unlearning occurs. We give numerical validation of the result, and derive theoretical grounding and scaling laws of the feature unlearning. Our results yield the following insights: (i) the strength of the primary nonlinear term in data induces the feature unlearning, and (ii) an initial scale of the second-layer weights mitigates the feature unlearning. Technically, our analysis utilizes Tensor Programs and the singular perturbation theory.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u65e0\u9650\u5bbd\u5ea6\u6781\u9650\u548c\u5feb\u6162\u52a8\u529b\u5b66\u5206\u6790\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2d\u7279\u5f81\u9057\u5fd8\u73b0\u8c61\u7684\u673a\u5236\u548c\u6761\u4ef6\uff0c\u53d1\u73b0\u6570\u636e\u4e2d\u7684\u4e3b\u8981\u975e\u7ebf\u6027\u9879\u5f3a\u5ea6\u4f1a\u8bf1\u5bfc\u7279\u5f81\u9057\u5fd8\uff0c\u800c\u7b2c\u4e8c\u5c42\u6743\u91cd\u7684\u521d\u59cb\u5c3a\u5ea6\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u73b0\u8c61\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\u8bad\u7ec3\u4e2d\u7684\u975e\u5e73\u51e1\u7ed3\u6784\u662f\u7406\u8bba\u673a\u5668\u5b66\u4e60\u7684\u6838\u5fc3\u6311\u6218\u3002\u7279\u5f81\u9057\u5fd8\u73b0\u8c61\uff08\u795e\u7ecf\u7f51\u7edc\u5728\u957f\u671f\u8bad\u7ec3\u4e2d\u9010\u6e10\u4e22\u5931\u5148\u524d\u5b66\u5230\u7684\u7279\u5f81\uff09\u5f15\u8d77\u4e86\u5173\u6ce8\uff0c\u9700\u8981\u6df1\u5165\u63a2\u7a76\u5176\u673a\u5236\u548c\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u65e0\u9650\u5bbd\u5ea6\u6781\u9650\uff0c\u4f7f\u7528\u5927\u6279\u91cf\u968f\u673a\u68af\u5ea6\u66f4\u65b0\uff0c\u63a8\u5bfc\u51fa\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u5fae\u5206\u65b9\u7a0b\u3002\u5229\u7528\u5feb\u6162\u52a8\u529b\u5b66\u5206\u6790\uff1a\u7b2c\u4e00\u5c42\u6743\u91cd\u5bf9\u9f50\u5feb\u901f\u5f62\u6210\uff0c\u7b2c\u4e8c\u5c42\u6743\u91cd\u7f13\u6162\u53d1\u5c55\u3002\u901a\u8fc7\u5f20\u91cf\u7a0b\u5e8f\u548c\u5947\u5f02\u6444\u52a8\u7406\u8bba\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u7279\u5f81\u9057\u5fd8\u7684\u673a\u5236\uff1a\u4e34\u754c\u6d41\u5f62\u4e0a\u7684\u6d41\u52a8\u65b9\u5411\uff08\u7531\u6162\u52a8\u529b\u5b66\u51b3\u5b9a\uff09\u51b3\u5b9a\u4e86\u7279\u5f81\u9057\u5fd8\u662f\u5426\u53d1\u751f\u3002\u6570\u503c\u9a8c\u8bc1\u4e86\u7ed3\u679c\uff0c\u5e76\u63a8\u5bfc\u4e86\u7279\u5f81\u9057\u5fd8\u7684\u7406\u8bba\u57fa\u7840\u548c\u7f29\u653e\u89c4\u5f8b\u3002", "conclusion": "\u4e3b\u8981\u53d1\u73b0\uff1a(1) \u6570\u636e\u4e2d\u4e3b\u8981\u975e\u7ebf\u6027\u9879\u7684\u5f3a\u5ea6\u4f1a\u8bf1\u5bfc\u7279\u5f81\u9057\u5fd8\uff1b(2) \u7b2c\u4e8c\u5c42\u6743\u91cd\u7684\u521d\u59cb\u5c3a\u5ea6\u53ef\u4ee5\u7f13\u89e3\u7279\u5f81\u9057\u5fd8\u3002\u6280\u672f\u5206\u6790\u7ed3\u5408\u4e86\u5f20\u91cf\u7a0b\u5e8f\u548c\u5947\u5f02\u6444\u52a8\u7406\u8bba\u3002"}}
{"id": "2602.08127", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08127", "abs": "https://arxiv.org/abs/2602.08127", "authors": ["Nicholas Pischke"], "title": "On Busemann subgradient methods for stochastic minimization in Hadamard spaces", "comment": "25 pages", "summary": "We study the recently introduced Busemann subgradient method due to Goodwin, Lewis, Nicolae and L\u00f3pez-Acedo, extending it to minimize the mean of a stochastic function over general Hadamard spaces. We prove a strong convergence theorem under a local compactness assumption and further prove weak ergodic convergence of the method over Hadamard spaces satisfying condition $(\\overline{Q}_4)$, a slight extension of the $(Q_4)$ condition of Kirk and Payanak, which in particular includes Hilbert spaces, $\\mathbb{R}$-trees and spaces of constant curvature. The proof is based on a general (weak) convergence theorem for stochastic processes in Hadamard spaces which confine to a stochastic variant of quasi-Fej\u00e9r monotonicity, together with a nonlinear variant of Pettis' theorem, which are of independent interest. Lastly, we provide a strong convergence result under a strong convexity assumption, and in that case in particular derive explicit rates of convergence.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Busemann\u6b21\u68af\u5ea6\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728Hadamard\u7a7a\u95f4\u4e0a\u6700\u5c0f\u5316\u968f\u673a\u51fd\u6570\u7684\u5747\u503c\uff0c\u8bc1\u660e\u4e86\u5728\u5c40\u90e8\u7d27\u6027\u5047\u8bbe\u4e0b\u7684\u5f3a\u6536\u655b\u5b9a\u7406\uff0c\u4ee5\u53ca\u5728\u6ee1\u8db3\u6761\u4ef6(\u00afQ\u2084)\u7684Hadamard\u7a7a\u95f4\u4e0a\u7684\u5f31\u904d\u5386\u6536\u655b\u3002", "motivation": "\u5c06\u6700\u8fd1\u63d0\u51fa\u7684Busemann\u6b21\u68af\u5ea6\u65b9\u6cd5\u6269\u5c55\u5230Hadamard\u7a7a\u95f4\u4e2d\u7684\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u89e3\u51b3\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u968f\u673a\u51fd\u6570\u6700\u5c0f\u5316\u95ee\u9898\u3002", "method": "\u6269\u5c55Busemann\u6b21\u68af\u5ea6\u65b9\u6cd5\u5230Hadamard\u7a7a\u95f4\uff0c\u4f7f\u7528\u968f\u673a\u8fc7\u7a0b\u7684\u5f31\u6536\u655b\u5b9a\u7406\u548c\u62dfFej\u00e9r\u5355\u8c03\u6027\u7684\u968f\u673a\u53d8\u4f53\uff0c\u7ed3\u5408\u975e\u7ebf\u6027Pettis\u5b9a\u7406\u53d8\u4f53\u3002", "result": "\u5728\u5c40\u90e8\u7d27\u6027\u5047\u8bbe\u4e0b\u8bc1\u660e\u4e86\u5f3a\u6536\u655b\u5b9a\u7406\uff1b\u5728\u6ee1\u8db3\u6761\u4ef6(\u00afQ\u2084)\u7684Hadamard\u7a7a\u95f4\u4e0a\u8bc1\u660e\u4e86\u5f31\u904d\u5386\u6536\u655b\uff1b\u5728\u5f3a\u51f8\u6027\u5047\u8bbe\u4e0b\u83b7\u5f97\u4e86\u5f3a\u6536\u655b\u7ed3\u679c\u548c\u663e\u5f0f\u6536\u655b\u7387\u3002", "conclusion": "\u6210\u529f\u5c06Busemann\u6b21\u68af\u5ea6\u65b9\u6cd5\u6269\u5c55\u5230Hadamard\u7a7a\u95f4\u4e2d\u7684\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5305\u62ec\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u3001\u211d-\u6811\u548c\u5e38\u66f2\u7387\u7a7a\u95f4\u5728\u5185\u7684\u5e7f\u6cdb\u7a7a\u95f4\u7c7b\u578b\u63d0\u4f9b\u4e86\u6536\u655b\u4fdd\u8bc1\u3002"}}
{"id": "2602.07546", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07546", "abs": "https://arxiv.org/abs/2602.07546", "authors": ["Zicong Cheng", "Ruixuan Jia", "Jia Li", "Guo-Wei Yang", "Meng-Hao Guo", "Shi-Min Hu"], "title": "Improving Variable-Length Generation in Diffusion Language Models via Length Regularization", "comment": "diffusion language models", "summary": "Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).", "AI": {"tldr": "LR-DLLM\u63d0\u51fa\u957f\u5ea6\u6b63\u5219\u5316\u63a8\u7406\u6846\u67b6\uff0c\u89e3\u51b3\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53d8\u957f\u751f\u6210\u4e2d\u7684\u957f\u5ea6\u8bf1\u5bfc\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u672a\u77e5\u957f\u5ea6\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08DLLMs\uff09\u4e0d\u9002\u5408\u53d8\u957f\u751f\u6210\uff0c\u56e0\u4e3a\u5176\u63a8\u7406\u57fa\u4e8e\u56fa\u5b9a\u957f\u5ea6\u753b\u5e03\u5e76\u5047\u8bbe\u5df2\u77e5\u76ee\u6807\u957f\u5ea6\u3002\u5728\u73b0\u5b9e\u8865\u5168\u548c\u586b\u5145\u4efb\u52a1\u4e2d\uff0c\u5f53\u957f\u5ea6\u672a\u77e5\u65f6\uff0c\u7b80\u5355\u5730\u6bd4\u8f83\u4e0d\u540c\u63a9\u7801\u957f\u5ea6\u7684\u7f6e\u4fe1\u5ea6\u4f1a\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u5bfc\u81f4\u751f\u6210\u4e0d\u8db3\u6216\u5197\u4f59\u5ef6\u7eed\u3002", "method": "\u63d0\u51faLR-DLLM\uff08\u957f\u5ea6\u6b63\u5219\u5316\u63a8\u7406\u6846\u67b6\uff09\uff0c\u5c06\u751f\u6210\u957f\u5ea6\u4f5c\u4e3a\u663e\u5f0f\u53d8\u91cf\uff0c\u901a\u8fc7\u663e\u5f0f\u957f\u5ea6\u6b63\u5219\u5316\u5c06\u8bed\u4e49\u517c\u5bb9\u6027\u4e0e\u957f\u5ea6\u8bf1\u5bfc\u4e0d\u786e\u5b9a\u6027\u89e3\u8026\uff0c\u7ea0\u6b63\u6709\u504f\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4fee\u6539\u5e95\u5c42DLLM\u6216\u5176\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5373\u53ef\u5b9e\u73b0\u751f\u6210\u8de8\u5ea6\u7684\u52a8\u6001\u6269\u5c55\u6216\u6536\u7f29\u3002", "result": "\u5728\u5b8c\u5168\u672a\u77e5\u957f\u5ea6\u6761\u4ef6\u4e0b\uff0cLR-DLLM\u5728HumanEvalInfilling\u4e0a\u8fbe\u523051.3% Pass@1\uff08\u6bd4DreamOn\u63d0\u534713.4%\uff09\uff0c\u5728\u56db\u8bed\u8a00McEval\u4e0a\u5e73\u5747\u8fbe\u523051.5% Pass@1\uff08\u6bd4DreamOn\u63d0\u534714.3%\uff09\u3002", "conclusion": "LR-DLLM\u901a\u8fc7\u957f\u5ea6\u6b63\u5219\u5316\u63a8\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86DLLMs\u5728\u53d8\u957f\u751f\u6210\u4e2d\u7684\u957f\u5ea6\u8bf1\u5bfc\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u672a\u77e5\u957f\u5ea6\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u586b\u5145\u548c\u8865\u5168\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.07473", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.07473", "abs": "https://arxiv.org/abs/2602.07473", "authors": ["Nathana\u00ebl Fijalkow", "Arka Ghosh", "Roman Kniazev", "Guillermo A. P\u00e9rez", "Pierre Vandenhove"], "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs", "comment": null, "summary": "Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.\n  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.\n  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.", "AI": {"tldr": "\u63d0\u51fa\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u65b0\u7c7b\u522b\uff0c\u89e3\u51b3\u4e86POMDPs\u4e2d\u53ef\u8fbe\u6982\u7387\u8ba1\u7b97\u4e0d\u53ef\u5224\u5b9a\u6216\u96be\u5904\u7406\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u5728\u8be5\u7c7b\u522b\u4e2d\u53ef\u8fbe\u6982\u7387\u53ef\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1\u3002", "motivation": "POMDPs\u662f\u5e8f\u5217\u51b3\u7b56\u7684\u57fa\u672c\u6a21\u578b\uff0c\u4f46\u8bb8\u591a\u9a8c\u8bc1\u548c\u7efc\u5408\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u6216\u96be\u5904\u7406\u3002Madani\u7b49\u4eba(2003)\u8bc1\u660ePOMDPs\u4e2d\u53ef\u8fbe\u6982\u7387\u8ba1\u7b97\u4e0d\u53ef\u5224\u5b9a\uff0c\u8fd9\u4e0e\u5b8c\u5168\u53ef\u89c2\u6d4bMDPs\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u540e\u8005\u53ef\u8fbe\u6982\u7387\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\u3002", "method": "\u5f15\u5165\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u65b0\u7c7b\u522b\uff1a\u5982\u679c\u4e0b\u4e00\u4e2a\u72b6\u6001\u53ef\u7531\u5f53\u524d\u72b6\u6001\u3001\u91c7\u53d6\u7684\u52a8\u4f5c\u548c\u63a5\u6536\u7684\u89c2\u6d4b\u552f\u4e00\u786e\u5b9a\uff0c\u5219POMDP\u662f\u540e\u9a8c\u786e\u5b9a\u6027\u7684\u3002\u8be5\u6027\u8d28\u610f\u5473\u7740\u4e00\u65e6\u771f\u5b9e\u72b6\u6001\u5df2\u77e5\uff0c\u5b83\u5c06\u6c38\u8fdc\u4fdd\u6301\u5df2\u77e5\u3002", "result": "\u8bc1\u660e\u5bf9\u4e8e\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\uff0c\u5230\u8fbe\u7ed9\u5b9a\u72b6\u6001\u96c6\u7684\u6700\u5927\u6982\u7387\u53ef\u4ee5\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1\u3002\u8be5\u7c7b\u522b\u5305\u542b\u6240\u6709MDPs\u548c\u7ecf\u5178\u975e\u5e73\u51e1\u793a\u4f8b\u5982Tiger POMDP\uff0c\u662f\u5df2\u77e5\u6700\u5927\u7684\u53ef\u8fbe\u6982\u7387\u53ef\u903c\u8fd1POMDPs\u7c7b\u522b\u4e4b\u4e00\u3002", "conclusion": "\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u4e14\u81ea\u7136\u7684POMDPs\u5b50\u7c7b\uff0c\u5176\u4e2d\u53ef\u8fbe\u6982\u7387\u8ba1\u7b97\u53d8\u5f97\u53ef\u5904\u7406\uff0c\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.07418", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07418", "abs": "https://arxiv.org/abs/2602.07418", "authors": ["Jian Qian", "Chen-Yu Wei"], "title": "Achieving Optimal Static and Dynamic Regret Simultaneously in Bandits with Deterministic Losses", "comment": null, "summary": "In adversarial multi-armed bandits, two performance measures are commonly used: static regret, which compares the learner to the best fixed arm, and dynamic regret, which compares it to the best sequence of arms. While optimal algorithms are known for each measure individually, there is no known algorithm achieving optimal bounds for both simultaneously. Marinov and Zimmert [2021] first showed that such simultaneous optimality is impossible against an adaptive adversary. Our work takes a first step to demonstrate its possibility against an oblivious adversary when losses are deterministic. First, we extend the impossibility result of Marinov and Zimmert [2021] to the case of deterministic losses. Then, we present an algorithm achieving optimal static and dynamic regret simultaneously against an oblivious adversary. Together, they reveal a fundamental separation between adaptive and oblivious adversaries when multiple regret benchmarks are considered simultaneously. It also provides new insight into the long open problem of simultaneously achieving optimal regret against switching benchmarks of different numbers of switches.\n  Our algorithm uses negative static regret to compensate for the exploration overhead incurred when controlling dynamic regret, and leverages Blackwell approachability to jointly control both regrets. This yields a new model selection procedure for bandits that may be of independent interest.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5bf9\u6297\u6027\u591a\u81c2\u8001\u864e\u673a\u4e2d\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u9759\u6001\u9057\u61be\u548c\u52a8\u6001\u9057\u61be\u7684\u53ef\u80fd\u6027\uff0c\u8bc1\u660e\u4e86\u5728\u786e\u5b9a\u6027\u635f\u5931\u4e0b\uff0c\u9488\u5bf9\u975e\u81ea\u9002\u5e94\u5bf9\u624b\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u4e24\u79cd\u6700\u4f18\u9057\u61be\uff0c\u800c\u9488\u5bf9\u81ea\u9002\u5e94\u5bf9\u624b\u5219\u4e0d\u53ef\u80fd\u3002", "motivation": "\u5728\u5bf9\u6297\u6027\u591a\u81c2\u8001\u864e\u673a\u4e2d\uff0c\u9759\u6001\u9057\u61be\u548c\u52a8\u6001\u9057\u61be\u662f\u4e24\u79cd\u5e38\u7528\u6027\u80fd\u6307\u6807\u3002\u867d\u7136\u5df2\u6709\u5206\u522b\u9488\u5bf9\u6bcf\u79cd\u6307\u6807\u7684\u6700\u4f18\u7b97\u6cd5\uff0c\u4f46\u5c1a\u672a\u6709\u7b97\u6cd5\u80fd\u540c\u65f6\u5b9e\u73b0\u4e24\u79cd\u6700\u4f18\u9057\u61be\u8fb9\u754c\u3002Marinov\u548cZimmert[2021]\u9996\u6b21\u8bc1\u660e\u9488\u5bf9\u81ea\u9002\u5e94\u5bf9\u624b\u4e0d\u53ef\u80fd\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u6027\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u975e\u81ea\u9002\u5e94\u5bf9\u624b\u548c\u786e\u5b9a\u6027\u635f\u5931\u4e0b\u5b9e\u73b0\u540c\u65f6\u6700\u4f18\u7684\u53ef\u80fd\u6027\u3002", "method": "\u9996\u5148\u5c06Marinov\u548cZimmert[2021]\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u6269\u5c55\u5230\u786e\u5b9a\u6027\u635f\u5931\u60c5\u51b5\u3002\u7136\u540e\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u975e\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u8d1f\u9759\u6001\u9057\u61be\u6765\u8865\u507f\u63a7\u5236\u52a8\u6001\u9057\u61be\u65f6\u7684\u63a2\u7d22\u5f00\u9500\uff0c\u5e76\u91c7\u7528Blackwell\u53ef\u63a5\u8fd1\u6027\u6765\u8054\u5408\u63a7\u5236\u4e24\u79cd\u9057\u61be\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u786e\u5b9a\u6027\u635f\u5931\u4e0b\uff0c\u9488\u5bf9\u975e\u81ea\u9002\u5e94\u5bf9\u624b\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u6700\u4f18\u9759\u6001\u9057\u61be\u548c\u52a8\u6001\u9057\u61be\uff0c\u800c\u9488\u5bf9\u81ea\u9002\u5e94\u5bf9\u624b\u5219\u4e0d\u53ef\u80fd\u3002\u8fd9\u63ed\u793a\u4e86\u5728\u540c\u65f6\u8003\u8651\u591a\u4e2a\u9057\u61be\u57fa\u51c6\u65f6\uff0c\u81ea\u9002\u5e94\u5bf9\u624b\u548c\u975e\u81ea\u9002\u5e94\u5bf9\u624b\u4e4b\u95f4\u7684\u6839\u672c\u5206\u79bb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u540c\u65f6\u5b9e\u73b0\u4e0d\u540c\u5207\u6362\u6b21\u6570\u57fa\u51c6\u7684\u6700\u4f18\u9057\u61be\u8fd9\u4e00\u957f\u671f\u5f00\u653e\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u80fd\u5177\u6709\u72ec\u7acb\u4ef7\u503c\u7684\u8001\u864e\u673a\u6a21\u578b\u9009\u62e9\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.08161", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08161", "abs": "https://arxiv.org/abs/2602.08161", "authors": ["Hyunho Jang", "Dongjin Lee"], "title": "Robust design optimization for a nonlinear system via Bayesian neural network enhanced polynomial dimensional decomposition", "comment": "22 pages, 13 figures", "summary": "Uncertainties such as manufacturing tolerances cause performance variations in complex engineering systems, making robust design optimization (RDO) essential. However, simulation-based RDO faces high computational cost for statistical moment estimation, and strong nonlinearity limits the accuracy of conventional surrogate models. This study proposes a novel RDO method that integrates Bayesian neural networks (BNN) with polynomial dimensional decomposition (PDD). The method employs uncertainty-based active learning to enhance BNN surrogate accuracy and a multi-point single-step strategy that partitions the design space into dynamically adjusted subregions, within which PDD analytically estimates statistical moments from BNN predictions. Validation through a mathematical benchmark and an electric motor shape optimization demonstrates that the method converges to robust optimal solutions with significantly fewer function evaluations. In the ten-dimensional benchmark, the proposed method achieved a 99.97% mean reduction, while Gaussian process-based and Monte Carlo approaches failed to locate the global optimum. In the motor design problem, the method reduced cogging torque by 94.75% with only 6644 finite element evaluations, confirming its computational efficiency for high-dimensional, strongly nonlinear engineering problems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u591a\u9879\u5f0f\u7ef4\u5ea6\u5206\u89e3\u7684\u9c81\u68d2\u8bbe\u8ba1\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u548c\u591a\u70b9\u5b50\u533a\u57df\u7b56\u7565\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c", "motivation": "\u590d\u6742\u5de5\u7a0b\u7cfb\u7edf\u4e2d\u7684\u5236\u9020\u516c\u5dee\u7b49\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u6027\u80fd\u53d8\u5316\uff0c\u9700\u8981\u9c81\u68d2\u8bbe\u8ba1\u4f18\u5316\u3002\u4f46\u57fa\u4e8e\u4eff\u771f\u7684RDO\u9762\u4e34\u7edf\u8ba1\u77e9\u4f30\u8ba1\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u5f3a\u975e\u7ebf\u6027\u9650\u5236\u4e86\u4f20\u7edf\u4ee3\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027", "method": "\u96c6\u6210\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff08BNN\uff09\u4e0e\u591a\u9879\u5f0f\u7ef4\u5ea6\u5206\u89e3\uff08PDD\uff09\uff0c\u91c7\u7528\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u52a8\u5b66\u4e60\u63d0\u5347BNN\u4ee3\u7406\u7cbe\u5ea6\uff0c\u4f7f\u7528\u591a\u70b9\u5b50\u5355\u6b65\u7b56\u7565\u5c06\u8bbe\u8ba1\u7a7a\u95f4\u5212\u5206\u4e3a\u52a8\u6001\u8c03\u6574\u7684\u5b50\u533a\u57df\uff0c\u5728\u5b50\u533a\u57df\u5185\u7528PDD\u4eceBNN\u9884\u6d4b\u4e2d\u89e3\u6790\u4f30\u8ba1\u7edf\u8ba1\u77e9", "result": "\u5728\u5341\u7ef4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e8699.97%\u7684\u5e73\u5747\u51cf\u5c11\uff0c\u800c\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u548c\u8499\u7279\u5361\u6d1b\u7684\u65b9\u6cd5\u672a\u80fd\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\u3002\u5728\u7535\u673a\u8bbe\u8ba1\u95ee\u9898\u4e2d\uff0c\u4ec5\u75286644\u6b21\u6709\u9650\u5143\u8bc4\u4f30\u5c31\u5c06\u9f7f\u69fd\u8f6c\u77e9\u964d\u4f4e\u4e8694.75%", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u51fd\u6570\u8bc4\u4f30\u6536\u655b\u5230\u9c81\u68d2\u6700\u4f18\u89e3\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9ad8\u7ef4\u3001\u5f3a\u975e\u7ebf\u6027\u5de5\u7a0b\u95ee\u9898\u4e2d\u7684\u8ba1\u7b97\u6548\u7387"}}
{"id": "2602.07594", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07594", "abs": "https://arxiv.org/abs/2602.07594", "authors": ["Yuxin Chen", "Yu Wang", "Yi Zhang", "Ziang Ye", "Zhengzhou Cai", "Yaorui Shi", "Qi Gu", "Hui Su", "Xunliang Cai", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Learning to Self-Verify Makes Language Models Better Reasoners", "comment": null, "summary": "Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.", "AI": {"tldr": "LLMs\u5728\u751f\u6210\u63a8\u7406\u8def\u5f84\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u81ea\u6211\u9a8c\u8bc1\u65b9\u9762\u8f83\u5f31\uff0c\u5b58\u5728\u80fd\u529b\u4e0d\u5bf9\u79f0\u3002\u7814\u7a76\u53d1\u73b0\u81ea\u6211\u9a8c\u8bc1\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u751f\u6210\u6027\u80fd\uff0c\u800c\u751f\u6210\u8bad\u7ec3\u4e0d\u80fd\u76f8\u5e94\u63d0\u5347\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u80fd\u751f\u6210\u6709\u524d\u666f\u7684\u63a8\u7406\u8def\u5f84\uff0c\u4f46\u9a8c\u8bc1\u81ea\u8eab\u7b54\u6848\u7684\u80fd\u529b\u8f83\u5f31\uff0c\u5b58\u5728\u751f\u6210\u4e0e\u81ea\u6211\u9a8c\u8bc1\u4e4b\u95f4\u7684\u80fd\u529b\u4e0d\u5bf9\u79f0\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u53ca\u5176\u8bad\u7ec3\u6f14\u5316\u89c4\u5f8b\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u6f14\u5316\u5206\u6790\u751f\u6210\u4e0e\u9a8c\u8bc1\u80fd\u529b\u7684\u4e0d\u5bf9\u79f0\u6027\uff1b\u63a2\u7d22\u81ea\u6211\u9a8c\u8bc1\u8bad\u7ec3\u5bf9\u751f\u6210\u6027\u80fd\u7684\u5f71\u54cd\uff1b\u63d0\u51fa\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u4f5c\u4e3a\u72ec\u7acb\u4f46\u4e92\u8865\u7684\u76ee\u6807\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u751f\u6210\u80fd\u529b\u7684\u63d0\u5347\u4e0d\u4f1a\u76f8\u5e94\u6539\u5584\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\uff1b2\uff09\u81ea\u6211\u9a8c\u8bc1\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u751f\u6210\u6027\u80fd\uff0c\u8fbe\u5230\u4e0e\u6807\u51c6\u751f\u6210\u8bad\u7ec3\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u9ad8\u6548\u6709\u6548\u7684\u63a8\u7406\u8f68\u8ff9\uff1b3\uff09\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u4e2d\u5747\u4f18\u4e8e\u7eaf\u751f\u6210\u8bad\u7ec3\u3002", "conclusion": "LLMs\u5b58\u5728\u751f\u6210\u4e0e\u81ea\u6211\u9a8c\u8bc1\u7684\u80fd\u529b\u4e0d\u5bf9\u79f0\uff0c\u4f46\u81ea\u6211\u9a8c\u8bc1\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u751f\u6210\u6027\u80fd\u3002\u5c06\u81ea\u6211\u9a8c\u8bc1\u6574\u5408\u5230\u751f\u6210\u8bad\u7ec3\u4e2d\u7684\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u540c\u65f6\u63d0\u5347\u751f\u6210\u548c\u9a8c\u8bc1\u80fd\u529b\uff0c\u4e3aLLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.07491", "categories": ["cs.AI", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07491", "abs": "https://arxiv.org/abs/2602.07491", "authors": ["Isabella A. Stewart", "Tarjei Paule Hage", "Yu-Chuan Hsu", "Markus J. Buehler"], "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design", "comment": null, "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5bfb\u627ePFAS\uff08\u5168\u6c1f\u548c\u591a\u6c1f\u70f7\u57fa\u7269\u8d28\uff09\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4e13\u4e1a\u5316\u548c\u5173\u7cfb\u63a8\u7406\u6269\u5c55\u6750\u6599\u8bbe\u8ba1\u7a7a\u95f4\u3002", "motivation": "\u6750\u6599\u79d1\u5b66\u521b\u65b0\u9700\u8981\u6574\u5408\u4ece\u5206\u5b50\u5316\u5b66\u5230\u673a\u68b0\u6027\u80fd\u7684\u6982\u5ff5\uff0c\u4f46\u4eba\u7c7b\u6216\u5355\u667a\u80fd\u4f53LLM\u96be\u4ee5\u5904\u7406\u6d77\u91cf\u4fe1\u606f\u4e14\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u9700\u8981\u89e3\u51b3\u4fe1\u606f\u8fde\u63a5\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u5bfb\u627e\u53d7\u4e25\u683c\u76d1\u7ba1\u7684PFAS\u5316\u5b66\u54c1\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\u65b9\u9762\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u95ee\u9898\u5206\u89e3\u3001\u8bc1\u636e\u68c0\u7d22\u3001\u8bbe\u8ba1\u53c2\u6570\u63d0\u53d6\u548c\u56fe\u904d\u5386\u7b49\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u3002\u901a\u8fc7\u5b9a\u5236\u56fe\u904d\u5386\u7b56\u7565\uff0c\u7cfb\u7edf\u5728\u4e13\u6ce8\u4e8e\u9886\u57df\u5173\u952e\u7ed3\u679c\u7684\u5229\u7528\u6027\u641c\u7d22\u548c\u53d1\u73b0\u65b0\u5174\u8de8\u9886\u57df\u8fde\u63a5\u7684\u63a2\u7d22\u6027\u641c\u7d22\u4e4b\u95f4\u5207\u6362\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\u5b8c\u6574\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\u3002\u901a\u8fc7\u751f\u7269\u533b\u5b66\u7ba1\u6750\u793a\u4f8b\uff0c\u6846\u67b6\u751f\u6210\u4e86\u5e73\u8861\u6469\u64e6\u6027\u80fd\u3001\u70ed\u7a33\u5b9a\u6027\u3001\u5316\u5b66\u6297\u6027\u548c\u751f\u7269\u76f8\u5bb9\u6027\u7684\u53ef\u6301\u7eedPFAS-free\u66ff\u4ee3\u54c1\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u6750\u6599\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5c55\u793a\u4e86\u591a\u4e2a\u521d\u59cb\u8bbe\u8ba1\u5019\u9009\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.07206", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07206", "abs": "https://arxiv.org/abs/2602.07206", "authors": ["Bucher Sahyouni", "Matthew Vowels", "Liqun Chen", "Simon Hadfield"], "title": "DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling", "comment": null, "summary": "Softmax Loss (SL) is being increasingly adopted for recommender systems (RS) as it has demonstrated better performance, robustness and fairness. Yet in implicit-feedback, a single global temperature and equal treatment of uniformly sampled negatives can lead to brittle training, because sampled sets may contain varying degrees of relevant or informative competitors. The optimal loss sharpness for a user-item pair with a particular set of negatives, can be suboptimal or destabilising for another with different negatives. We introduce Dual-scale Softmax Loss (DSL), which infers effective sharpness from the sampled competition itself. DSL adds two complementary branches to the log-sum-exp backbone. Firstly it reweights negatives within each training instance using hardness and item--item similarity, secondly it adapts a per-example temperature from the competition intensity over a constructed competitor slate. Together, these components preserve the geometry of SL while reshaping the competition distribution across negatives and across examples.\n  Over several representative benchmarks and backbones, DSL yields substantial gains over strong baselines, with improvements over SL exceeding $10%$ in several settings and averaging $6.22%$ across datasets, metrics, and backbones. Under out-of-distribution (OOD) popularity shift, the gains are larger, with an average of $9.31%$ improvement over SL. We further provide a theoretical, distributionally robust optimisation (DRO) analysis, which demonstrates how DSL reshapes the robust payoff and the KL deviation for ambiguous instances. This helps explain the empirically observed improvements in accuracy and robustness.", "AI": {"tldr": "DSL\uff08\u53cc\u5c3a\u5ea6Softmax\u635f\u5931\uff09\u901a\u8fc7\u4ece\u91c7\u6837\u7ade\u4e89\u672c\u8eab\u63a8\u65ad\u6709\u6548\u9510\u5ea6\uff0c\u89e3\u51b3\u4e86\u9690\u5f0f\u53cd\u9988\u63a8\u8350\u7cfb\u7edf\u4e2dSoftmax\u635f\u5931\u5bf9\u5168\u5c40\u6e29\u5ea6\u548c\u5747\u5300\u91c7\u6837\u8d1f\u6837\u672c\u7684\u8106\u5f31\u6027\u95ee\u9898\u3002", "motivation": "\u5728\u9690\u5f0f\u53cd\u9988\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0cSoftmax\u635f\u5931\u4f7f\u7528\u5355\u4e00\u5168\u5c40\u6e29\u5ea6\u548c\u5747\u5300\u91c7\u6837\u8d1f\u6837\u672c\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u56e0\u4e3a\u91c7\u6837\u96c6\u5408\u53ef\u80fd\u5305\u542b\u4e0d\u540c\u7a0b\u5ea6\u7684\u76f8\u5173\u6216\u4fe1\u606f\u6027\u7ade\u4e89\u8005\u3002\u5bf9\u4e8e\u4e0d\u540c\u8d1f\u6837\u672c\u96c6\u5408\uff0c\u6700\u4f18\u7684\u635f\u5931\u9510\u5ea6\u53ef\u80fd\u4e0d\u9002\u7528\u6216\u5177\u6709\u7834\u574f\u6027\u3002", "method": "DSL\u5728log-sum-exp\u4e3b\u5e72\u4e0a\u6dfb\u52a0\u4e24\u4e2a\u4e92\u8865\u5206\u652f\uff1a1\uff09\u4f7f\u7528\u786c\u5ea6\u548c\u7269\u54c1\u76f8\u4f3c\u5ea6\u91cd\u65b0\u52a0\u6743\u6bcf\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\u4e2d\u7684\u8d1f\u6837\u672c\uff1b2\uff09\u4ece\u6784\u5efa\u7684\u7ade\u4e89\u8005\u5217\u8868\u4e2d\u6839\u636e\u7ade\u4e89\u5f3a\u5ea6\u81ea\u9002\u5e94\u6bcf\u4e2a\u793a\u4f8b\u7684\u6e29\u5ea6\u3002\u8fd9\u4e24\u4e2a\u7ec4\u4ef6\u5728\u4fdd\u6301SL\u51e0\u4f55\u7ed3\u6784\u7684\u540c\u65f6\uff0c\u91cd\u5851\u4e86\u8d1f\u6837\u672c\u548c\u793a\u4f8b\u95f4\u7684\u7ade\u4e89\u5206\u5e03\u3002", "result": "\u5728\u591a\u4e2a\u4ee3\u8868\u6027\u57fa\u51c6\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\uff0cDSL\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u591a\u4e2a\u8bbe\u7f6e\u4e2d\u8d85\u8fc7SL 10%\u4ee5\u4e0a\uff0c\u5728\u6570\u636e\u96c6\u3001\u6307\u6807\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u7684\u5e73\u5747\u63d0\u5347\u4e3a6.22%\u3002\u5728\u5206\u5e03\u5916\u6d41\u884c\u5ea6\u504f\u79fb\u4e0b\uff0c\u63d0\u5347\u66f4\u5927\uff0c\u5e73\u5747\u6bd4SL\u63d0\u9ad89.31%\u3002", "conclusion": "DSL\u901a\u8fc7\u4ece\u91c7\u6837\u7ade\u4e89\u672c\u8eab\u63a8\u65ad\u6709\u6548\u9510\u5ea6\uff0c\u89e3\u51b3\u4e86Softmax\u635f\u5931\u5728\u9690\u5f0f\u53cd\u9988\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5c40\u9650\u6027\u3002\u7406\u8bba\u5206\u6790\u8868\u660eDSL\u91cd\u5851\u4e86\u9c81\u68d2\u6536\u76ca\u548cKL\u504f\u5dee\uff0c\u89e3\u91ca\u4e86\u89c2\u5bdf\u5230\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u6539\u8fdb\u3002"}}
{"id": "2602.07453", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07453", "abs": "https://arxiv.org/abs/2602.07453", "authors": ["Namrita Varshney", "Ashutosh Gupta", "Arhaan Ahmad", "Tanay V. Tayal", "S. Akshay"], "title": "Data-Aware and Scalable Sensitivity Analysis for Decision Tree Ensembles", "comment": null, "summary": "Decision tree ensembles are widely used in critical domains, making robustness and sensitivity analysis essential to their trustworthiness. We study the feature sensitivity problem, which asks whether an ensemble is sensitive to a specified subset of features -- such as protected attributes -- whose manipulation can alter model predictions. Existing approaches often yield examples of sensitivity that lie far from the training distribution, limiting their interpretability and practical value. We propose a data-aware sensitivity framework that constrains the sensitive examples to remain close to the dataset, thereby producing realistic and interpretable evidence of model weaknesses. To this end, we develop novel techniques for data-aware search using a combination of mixed-integer linear programming (MILP) and satisfiability modulo theories (SMT) encodings. Our contributions are fourfold. First, we strengthen the NP-hardness result for sensitivity verification, showing it holds even for trees of depth 1. Second, we develop MILP-optimizations that significantly speed up sensitivity verification for single ensembles and for the first time can also handle multiclass tree ensembles. Third, we introduce a data-aware framework generating realistic examples close to the training distribution. Finally, we conduct an extensive experimental evaluation on large tree ensembles, demonstrating scalability to ensembles with up to 800 trees of depth 8, achieving substantial improvements over the state of the art. This framework provides a practical foundation for analyzing the reliability and fairness of tree-based models in high-stakes applications.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u611f\u77e5\u7684\u6811\u96c6\u6210\u6a21\u578b\u7279\u5f81\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7MILP\u548cSMT\u7f16\u7801\u7ea6\u675f\u654f\u611f\u6837\u672c\u9760\u8fd1\u8bad\u7ec3\u5206\u5e03\uff0c\u751f\u6210\u66f4\u73b0\u5b9e\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u5f31\u70b9\u8bc1\u636e", "motivation": "\u51b3\u7b56\u6811\u96c6\u6210\u6a21\u578b\u5728\u5173\u952e\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u9c81\u68d2\u6027\u548c\u654f\u611f\u6027\u5206\u6790\u6765\u786e\u4fdd\u53ef\u4fe1\u5ea6\u3002\u73b0\u6709\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\u751f\u6210\u7684\u6837\u672c\u5f80\u5f80\u8fdc\u79bb\u8bad\u7ec3\u5206\u5e03\uff0c\u9650\u5236\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u4ef7\u503c", "method": "\u63d0\u51fa\u6570\u636e\u611f\u77e5\u654f\u611f\u6027\u6846\u67b6\uff0c\u4f7f\u7528\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u548c\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\uff08SMT\uff09\u7f16\u7801\uff0c\u7ea6\u675f\u654f\u611f\u6837\u672c\u4fdd\u6301\u5728\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u9644\u8fd1\u3002\u5f00\u53d1MILP\u4f18\u5316\u6280\u672f\u52a0\u901f\u5355\u96c6\u6210\u548c\u591a\u7c7b\u6811\u96c6\u6210\u7684\u654f\u611f\u6027\u9a8c\u8bc1", "result": "1. \u5f3a\u5316\u654f\u611f\u6027\u9a8c\u8bc1\u7684NP\u96be\u6027\u8bc1\u660e\uff0c\u5373\u4f7f\u6df1\u5ea6\u4e3a1\u7684\u6811\u4e5f\u6210\u7acb\uff1b2. \u5f00\u53d1MILP\u4f18\u5316\u663e\u8457\u52a0\u901f\u654f\u611f\u6027\u9a8c\u8bc1\uff1b3. \u9996\u6b21\u5904\u7406\u591a\u7c7b\u6811\u96c6\u6210\uff1b4. \u5728\u5927\u578b\u6811\u96c6\u6210\u4e0a\u6269\u5c55\u6027\u826f\u597d\uff0c\u53ef\u5904\u7406800\u68f5\u6df1\u5ea68\u7684\u6811\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u6811\u57fa\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u80fd\u751f\u6210\u66f4\u73b0\u5b9e\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u5f31\u70b9\u8bc1\u636e"}}
{"id": "2602.08177", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08177", "abs": "https://arxiv.org/abs/2602.08177", "authors": ["C\u00e9dric Josz"], "title": "Implicit regularization of normalized gradient descent", "comment": null, "summary": "How to find flat minima? We propose running normalized gradient descent, usually reserved for nonsmooth optimization, with sufficiently slowly diminishing step sizes. This induces implicit regularization towards flat minima if an appropriate Lyapunov functions exists in the gradient dynamics. Our analysis shows that implicit regularization is intrinsically a question of nonsmooth analysis, for which we deploy the full power of variational analysis and stratification theory.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5f52\u4e00\u5316\u68af\u5ea6\u4e0b\u964d\u914d\u5408\u9012\u51cf\u6b65\u957f\u6765\u5bfb\u627e\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u901a\u8fc7\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u548c\u53d8\u5206\u5206\u6790\u5b9e\u73b0\u9690\u5f0f\u6b63\u5219\u5316", "motivation": "\u5982\u4f55\u6709\u6548\u5bfb\u627e\u5e73\u5766\u6700\u5c0f\u503c\uff08flat minima\uff09\u662f\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u4e2d\u7684\u91cd\u8981\u95ee\u9898\uff0c\u5e73\u5766\u6700\u5c0f\u503c\u901a\u5e38\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd", "method": "\u91c7\u7528\u5f52\u4e00\u5316\u68af\u5ea6\u4e0b\u964d\uff08\u901a\u5e38\u7528\u4e8e\u975e\u5149\u6ed1\u4f18\u5316\uff09\uff0c\u914d\u5408\u8db3\u591f\u7f13\u6162\u9012\u51cf\u7684\u6b65\u957f\uff0c\u5229\u7528\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u5206\u6790\u68af\u5ea6\u52a8\u6001\uff0c\u57fa\u4e8e\u53d8\u5206\u5206\u6790\u548c\u5206\u5c42\u7406\u8bba", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u8bf1\u5bfc\u9690\u5f0f\u6b63\u5219\u5316\u8d8b\u5411\u5e73\u5766\u6700\u5c0f\u503c\uff0c\u63ed\u793a\u4e86\u9690\u5f0f\u6b63\u5219\u5316\u672c\u8d28\u4e0a\u662f\u975e\u5149\u6ed1\u5206\u6790\u95ee\u9898", "conclusion": "\u5f52\u4e00\u5316\u68af\u5ea6\u4e0b\u964d\u914d\u5408\u9012\u51cf\u6b65\u957f\u662f\u5bfb\u627e\u5e73\u5766\u6700\u5c0f\u503c\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u9690\u5f0f\u6b63\u5219\u5316\u9700\u8981\u975e\u5149\u6ed1\u5206\u6790\u5de5\u5177\u6765\u7406\u89e3"}}
{"id": "2602.07621", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07621", "abs": "https://arxiv.org/abs/2602.07621", "authors": ["Xanh Ho", "Yun-Ang Wu", "Sunisth Kumar", "Tian Cheng Xia", "Florian Boudin", "Andre Greiner-Petter", "Akiko Aizawa"], "title": "SciClaimEval: Cross-modal Claim Verification in Scientific Papers", "comment": "12 pages; data is available at https://sciclaimeval.github.io/", "summary": "We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.", "AI": {"tldr": "SciClaimEval\u662f\u4e00\u4e2a\u65b0\u7684\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5305\u542b\u4ece\u5df2\u53d1\u8868\u8bba\u6587\u4e2d\u63d0\u53d6\u7684\u771f\u5b9e\u58f0\u660e\uff08\u5305\u62ec\u88ab\u53cd\u9a73\u7684\u58f0\u660e\uff09\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u8bc1\u636e\uff08\u56fe\u8868\uff09\uff0c\u5e76\u5728\u4e09\u4e2a\u9886\u57df\u8bc4\u4f30\u4e8611\u4e2a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u6570\u636e\u96c6\u901a\u5e38\u4f7f\u7528\u4eba\u5de5\u4fee\u6539\u58f0\u660e\u6216\u4f9d\u8d56LLM\u751f\u6210\u77db\u76fe\u58f0\u660e\uff0c\u7f3a\u4e4f\u771f\u5b9e\u7684\u88ab\u53cd\u9a73\u58f0\u660e\u3002\u9700\u8981\u5305\u542b\u771f\u5b9e\u79d1\u5b66\u58f0\u660e\u548c\u8de8\u6a21\u6001\u8bc1\u636e\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u5728\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4fee\u6539\u652f\u6301\u8bc1\u636e\uff08\u56fe\u8868\uff09\u800c\u975e\u4fee\u6539\u58f0\u660e\u672c\u8eab\u6765\u521b\u5efa\u88ab\u53cd\u9a73\u7684\u58f0\u660e\u3002\u6570\u636e\u96c6\u5305\u542b\u4ece180\u7bc7\u8bba\u6587\u4e2d\u63d0\u53d6\u76841,664\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u6db5\u76d6\u673a\u5668\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u533b\u5b66\u4e09\u4e2a\u9886\u57df\u3002\u56fe\u8868\u4ee5\u591a\u79cd\u683c\u5f0f\u63d0\u4f9b\uff1a\u56fe\u50cf\u3001LaTeX\u6e90\u7801\u3001HTML\u548cJSON\u3002", "result": "\u8bc4\u4f30\u4e8611\u4e2a\u5f00\u6e90\u548c\u4e13\u6709\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u56fe\u50cf\u7684\u9a8c\u8bc1\u5bf9\u6240\u6709\u6a21\u578b\u90fd\u7279\u522b\u5177\u6709\u6311\u6218\u6027\uff0c\u6700\u4f73\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u4e4b\u95f4\u4ecd\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "SciClaimEval\u4e3a\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u771f\u5b9e\u3001\u591a\u6a21\u6001\u7684\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u7406\u89e3\u79d1\u5b66\u56fe\u8868\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002"}}
{"id": "2602.07533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07533", "abs": "https://arxiv.org/abs/2602.07533", "authors": ["Yankai Yang", "Yancheng Long", "Hongyang Wei", "Wei Chen", "Tianke Zhang", "Kaiyu Jiang", "Haonan Fan", "Changyi Liu", "Jiankang Chen", "Kaiyu Tang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Shuo Yang"], "title": "Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models", "comment": null, "summary": "Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but struggle with complex semantics due to limited reasoning supervision. Generative reward models offer stronger semantic understanding and reasoning, but they are costly at inference time and difficult to align directly with human preferences. To this end, we propose Joint Reward Modeling (JRM), which jointly optimizes preference learning and language modeling on a shared vision-language backbone. This approach internalizes the semantic and reasoning capabilities of generative models into efficient discriminative representations, enabling fast and accurate evaluation. JRM achieves state-of-the-art results on MMRB2 and EditReward-Bench, and significantly improves stability and performance in downstream online reinforcement learning. These results show that joint training effectively bridges efficiency and semantic understanding in reward modeling.", "AI": {"tldr": "JRM\u901a\u8fc7\u8054\u5408\u4f18\u5316\u504f\u597d\u5b66\u4e60\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u878d\u5165\u5224\u522b\u5f0f\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u5956\u52b1\u5efa\u6a21", "motivation": "\u73b0\u6709\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u5c40\u9650\uff1a\u5224\u522b\u5f0f\u5956\u52b1\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u826f\u597d\u4f46\u8bed\u4e49\u7406\u89e3\u6709\u9650\uff1b\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u5f3a\u4f46\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u76f4\u63a5\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d", "method": "\u63d0\u51fa\u8054\u5408\u5956\u52b1\u5efa\u6a21(JRM)\uff0c\u5728\u5171\u4eab\u7684\u89c6\u89c9-\u8bed\u8a00\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8054\u5408\u4f18\u5316\u504f\u597d\u5b66\u4e60\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u5185\u5316\u5230\u9ad8\u6548\u7684\u5224\u522b\u5f0f\u8868\u793a\u4e2d", "result": "\u5728MMRB2\u548cEditReward-Bench\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd", "conclusion": "\u8054\u5408\u8bad\u7ec3\u6709\u6548\u6865\u63a5\u4e86\u5956\u52b1\u5efa\u6a21\u4e2d\u7684\u6548\u7387\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u5feb\u901f\u51c6\u786e\u7684\u8bc4\u4f30\u65b9\u6cd5"}}
{"id": "2602.07213", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07213", "abs": "https://arxiv.org/abs/2602.07213", "authors": ["Srijan Shakya", "Anamaria-Roberta Hartl", "Sepp Hochreiter", "Korbinian P\u00f6ppel"], "title": "Adaptive Retrieval helps Reasoning in LLMs -- but mostly if it's not used", "comment": "Eurips Workshop on Principles of Generative Modeling (PriGM)", "summary": "Large Language Models (LLMs) often falter in complex reasoning tasks due to their static, parametric knowledge, leading to hallucinations and poor performance in specialized domains like mathematics. This work explores a fundamental principle for enhancing generative models: treating retrieval as a form of dynamic in-context learning. We test an adaptive retrieval-augmented architecture where an LLM agent actively decides when to query an external knowledge base during its reasoning process. We compare this adaptive strategy against a standard Chain-of-Thought (CoT) baseline and a static retrieval approach on the GSM8K and MATH-500 benchmarks. Although our experiments show that static retrieval is inferior to CoT, the adaptive retrieval shows interesting behavior: While traces including retrieved results show slightly worse performance compared to CoT, traces that do not include retrieval actually perform better compared to CoT. This suggests that: (a) retrieval only rarely helps reasoning (we show a few counterexamples, e.g. using useful theorems) and (b) actively not using retrieval is indicative of good model performance. Furthermore, we find that the model scales its retrieval frequency with the difficulty of the problem, reinforcing that the decision to retrieve is a crucial metacognitive signal. The agent's ability to self-assess its knowledge and selectively engage with external information represents a key principle for building more robust and reliable generative models.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728LLMs\u4e2d\u901a\u8fc7\u81ea\u9002\u5e94\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e3b\u52a8\u51b3\u5b9a\u4f55\u65f6\u68c0\u7d22\u5916\u90e8\u77e5\u8bc6\u6bd4\u9759\u6001\u68c0\u7d22\u66f4\u6709\u6548\uff0c\u4e14\u4e0d\u68c0\u7d22\u7684\u63a8\u7406\u8def\u5f84\u8868\u73b0\u66f4\u597d\uff0c\u8868\u660e\u68c0\u7d22\u51b3\u7b56\u672c\u8eab\u662f\u91cd\u8981\u7684\u5143\u8ba4\u77e5\u4fe1\u53f7\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5e38\u56e0\u9759\u6001\u53c2\u6570\u5316\u77e5\u8bc6\u800c\u51fa\u73b0\u5e7b\u89c9\uff0c\u5728\u6570\u5b66\u7b49\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u52a8\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u7684\u57fa\u672c\u539f\u7406\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u68c0\u7d22\u589e\u5f3a\u67b6\u6784\uff0c\u8ba9LLM\u4ee3\u7406\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e3b\u52a8\u51b3\u5b9a\u4f55\u65f6\u67e5\u8be2\u5916\u90e8\u77e5\u8bc6\u5e93\u3002\u5728GSM8K\u548cMATH-500\u57fa\u51c6\u4e0a\u6bd4\u8f83\u81ea\u9002\u5e94\u7b56\u7565\u4e0e\u6807\u51c6\u601d\u7ef4\u94fe\u57fa\u7ebf\u548c\u9759\u6001\u68c0\u7d22\u65b9\u6cd5\u3002", "result": "\u9759\u6001\u68c0\u7d22\u8868\u73b0\u4e0d\u5982\u601d\u7ef4\u94fe\uff0c\u4f46\u81ea\u9002\u5e94\u68c0\u7d22\u663e\u793a\u51fa\u6709\u8da3\u884c\u4e3a\uff1a\u5305\u542b\u68c0\u7d22\u7ed3\u679c\u7684\u63a8\u7406\u8def\u5f84\u8868\u73b0\u7565\u5dee\u4e8e\u601d\u7ef4\u94fe\uff0c\u800c\u4e0d\u5305\u542b\u68c0\u7d22\u7684\u63a8\u7406\u8def\u5f84\u8868\u73b0\u66f4\u597d\u3002\u68c0\u7d22\u4ec5\u5728\u5c11\u6570\u60c5\u51b5\u4e0b\u6709\u5e2e\u52a9\uff08\u5982\u4f7f\u7528\u6709\u7528\u5b9a\u7406\uff09\uff0c\u4e3b\u52a8\u4e0d\u4f7f\u7528\u68c0\u7d22\u662f\u6a21\u578b\u6027\u80fd\u826f\u597d\u7684\u6307\u6807\u3002\u6a21\u578b\u4f1a\u6839\u636e\u95ee\u9898\u96be\u5ea6\u8c03\u6574\u68c0\u7d22\u9891\u7387\u3002", "conclusion": "\u68c0\u7d22\u51b3\u7b56\u662f\u5173\u952e\u7684\u5143\u8ba4\u77e5\u4fe1\u53f7\u3002\u6a21\u578b\u80fd\u591f\u81ea\u6211\u8bc4\u4f30\u77e5\u8bc6\u5e76\u9009\u62e9\u6027\u5229\u7528\u5916\u90e8\u4fe1\u606f\uff0c\u8fd9\u662f\u6784\u5efa\u66f4\u7a33\u5065\u53ef\u9760\u751f\u6210\u6a21\u578b\u7684\u5173\u952e\u539f\u5219\u3002\u81ea\u9002\u5e94\u68c0\u7d22\u673a\u5236\u6bd4\u9759\u6001\u68c0\u7d22\u66f4\u6709\u6548\uff0c\u8868\u660e\u5143\u8ba4\u77e5\u80fd\u529b\u5bf9LLM\u63a8\u7406\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2602.07472", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07472", "abs": "https://arxiv.org/abs/2602.07472", "authors": ["Yilun Chen", "Jiaqi Lu"], "title": "Bandit Allocational Instability", "comment": null, "summary": "When multi-armed bandit (MAB) algorithms allocate pulls among competing arms, the resulting allocation can exhibit huge variation. This is particularly harmful in modern applications such as learning-enhanced platform operations and post-bandit statistical inference. Thus motivated, we introduce a new performance metric of MAB algorithms termed allocation variability, which is the largest (over arms) standard deviation of an arm's number of pulls. We establish a fundamental trade-off between allocation variability and regret, the canonical performance metric of reward maximization. In particular, for any algorithm, the worst-case regret $R_T$ and worst-case allocation variability $S_T$ must satisfy $R_T \\cdot S_T=\u03a9(T^{\\frac{3}{2}})$ as $T\\rightarrow\\infty$, as long as $R_T=o(T)$. This indicates that any minimax regret-optimal algorithm must incur worst-case allocation variability $\u0398(T)$, the largest possible scale; while any algorithm with sublinear worst-case regret must necessarily incur ${S}_T= \u03c9(\\sqrt{T})$. We further show that this lower bound is essentially tight, and that any point on the Pareto frontier $R_T \\cdot S_T=\\tilde\u0398(T^{3/2})$ can be achieved by a simple tunable algorithm UCB-f, a generalization of the classic UCB1. Finally, we discuss implications for platform operations and for statistical inference, when bandit algorithms are used. As a byproduct of our result, we resolve an open question of Praharaj and Khamaru (2025).", "AI": {"tldr": "\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u5728\u5206\u914d\u62c9\u52a8\u6b21\u6570\u65f6\u5b58\u5728\u5de8\u5927\u65b9\u5dee\uff0c\u672c\u6587\u5f15\u5165\u5206\u914d\u53d8\u5f02\u6027\u4f5c\u4e3a\u65b0\u6027\u80fd\u6307\u6807\uff0c\u5efa\u7acb\u4e86\u5206\u914d\u53d8\u5f02\u6027\u4e0e\u9057\u61be\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u53ef\u8c03\u7b97\u6cd5\u5b9e\u73b0\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u4f20\u7edf\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u5728\u5206\u914d\u62c9\u52a8\u6b21\u6570\u65f6\u5b58\u5728\u5de8\u5927\u65b9\u5dee\uff0c\u8fd9\u5728\u73b0\u4ee3\u5e94\u7528\uff08\u5982\u5b66\u4e60\u589e\u5f3a\u5e73\u53f0\u8fd0\u8425\u548c\u540e\u8001\u864e\u673a\u7edf\u8ba1\u63a8\u65ad\uff09\u4e2d\u7279\u522b\u6709\u5bb3\u3002\u9700\u8981\u5f15\u5165\u65b0\u7684\u6027\u80fd\u6307\u6807\u6765\u91cf\u5316\u8fd9\u79cd\u5206\u914d\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u5f15\u5165\u5206\u914d\u53d8\u5f02\u6027\u4f5c\u4e3a\u65b0\u6027\u80fd\u6307\u6807\uff0c\u5b9a\u4e49\u4e3a\u5404\u81c2\u62c9\u52a8\u6b21\u6570\u6807\u51c6\u5dee\u7684\u6700\u5927\u503c\u3002\u5efa\u7acb\u5206\u914d\u53d8\u5f02\u6027\u4e0e\u9057\u61be\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\uff0c\u63d0\u51fa\u53ef\u8c03\u7b97\u6cd5UCB-f\uff08\u7ecf\u5178UCB1\u7684\u63a8\u5e7f\uff09\uff0c\u901a\u8fc7\u53c2\u6570\u8c03\u6574\u5b9e\u73b0\u5e15\u7d2f\u6258\u524d\u6cbf\u4e0a\u7684\u4e0d\u540c\u6743\u8861\u70b9\u3002", "result": "\u8bc1\u660e\u4e86\u4efb\u4f55\u7b97\u6cd5\u7684\u6700\u574f\u60c5\u51b5\u9057\u61beR_T\u548c\u5206\u914d\u53d8\u5f02\u6027S_T\u5fc5\u987b\u6ee1\u8db3R_T\u00b7S_T=\u03a9(T^{3/2})\uff0c\u53ea\u8981R_T=o(T)\u3002\u8fd9\u8868\u660e\u4efb\u4f55\u6781\u5c0f\u6781\u5927\u9057\u61be\u6700\u4f18\u7b97\u6cd5\u5fc5\u987b\u627f\u53d7\u0398(T)\u7684\u6700\u574f\u60c5\u51b5\u5206\u914d\u53d8\u5f02\u6027\uff1b\u800c\u4efb\u4f55\u5177\u6709\u6b21\u7ebf\u6027\u6700\u574f\u60c5\u51b5\u9057\u61be\u7684\u7b97\u6cd5\u5fc5\u987b\u627f\u53d7S_T=\u03c9(\u221aT)\u3002\u8be5\u4e0b\u754c\u57fa\u672c\u7d27\uff0c\u901a\u8fc7UCB-f\u7b97\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u5e15\u7d2f\u6258\u524d\u6cbfR_T\u00b7S_T=\u0398\u0303(T^{3/2})\u4e0a\u7684\u4efb\u610f\u70b9\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u4e2d\u5206\u914d\u53d8\u5f02\u6027\u4e0e\u9057\u61be\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u5e73\u53f0\u8fd0\u8425\u548c\u7edf\u8ba1\u63a8\u65ad\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\uff0c\u5e76\u89e3\u51b3\u4e86Praharaj\u548cKhamaru\uff082025\uff09\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2602.08232", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08232", "abs": "https://arxiv.org/abs/2602.08232", "authors": ["Ruichen Jiang", "Zakaria Mhammedi", "Mehryar Mohri", "Aryan Mokhtari"], "title": "Adaptive Matrix Online Learning through Smoothing with Guarantees for Nonsmooth Nonconvex Optimization", "comment": "37 pages, 1 figure", "summary": "We study online linear optimization with matrix variables constrained by the operator norm, a setting where the geometry renders designing data-dependent and efficient adaptive algorithms challenging. The best-known adaptive regret bounds are achieved by Shampoo-like methods, but they require solving a costly quadratic projection subproblem. To address this, we extend the gradient-based prediction scheme to adaptive matrix online learning and cast algorithm design as constructing a family of smoothed potentials for the nuclear norm. We define a notion of admissibility for such smoothings and prove any admissible smoothing yields a regret bound matching the best-known guarantees of one-sided Shampoo. We instantiate this framework with two efficient methods that avoid quadratic projections. The first is an adaptive Follow-the-Perturbed-Leader (FTPL) method using Gaussian stochastic smoothing. The second is Follow-the-Augmented-Matrix-Leader (FAML), which uses a deterministic hyperbolic smoothing in an augmented matrix space. By analyzing the admissibility of these smoothings, we show both methods admit closed-form updates and match one-sided Shampoo's regret up to a constant factor, while significantly reducing computational cost. Lastly, using the online-to-nonconvex conversion, we derive two matrix-based optimizers, Pion (from FTPL) and Leon (from FAML). We prove convergence guarantees for these methods in nonsmooth nonconvex settings, a guarantee that the popular Muon optimizer lacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u9ad8\u6548\u7684\u77e9\u9635\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5\uff0c\u907f\u514d\u4e86Shampoo\u65b9\u6cd5\u4e2d\u6602\u8d35\u7684\u4e8c\u6b21\u6295\u5f71\u5b50\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u4f73\u7684\u81ea\u9002\u5e94\u9057\u61be\u754c\uff0c\u5e76\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u8f6c\u5316\u4e3a\u975e\u51f8\u975e\u5149\u6ed1\u4f18\u5316\u7684\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u5728\u7ebf\u7ebf\u6027\u4f18\u5316\u4e2d\uff0c\u77e9\u9635\u53d8\u91cf\u53d7\u7b97\u5b50\u8303\u6570\u7ea6\u675f\u65f6\uff0c\u51e0\u4f55\u7ed3\u6784\u4f7f\u5f97\u8bbe\u8ba1\u6570\u636e\u4f9d\u8d56\u7684\u9ad8\u6548\u81ea\u9002\u5e94\u7b97\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u6700\u4f73\u81ea\u9002\u5e94\u9057\u61be\u754c\u65b9\u6cd5\uff08\u5982Shampoo\uff09\u9700\u8981\u89e3\u51b3\u6602\u8d35\u7684\u4e8c\u6b21\u6295\u5f71\u5b50\u95ee\u9898\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5c06\u57fa\u4e8e\u68af\u5ea6\u7684\u9884\u6d4b\u65b9\u6848\u6269\u5c55\u5230\u81ea\u9002\u5e94\u77e9\u9635\u5728\u7ebf\u5b66\u4e60\uff0c\u5c06\u7b97\u6cd5\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u6784\u5efa\u6838\u8303\u6570\u7684\u4e00\u65cf\u5e73\u6ed1\u52bf\u51fd\u6570\u3002\u5b9a\u4e49\u4e86\u8fd9\u7c7b\u5e73\u6ed1\u7684\u53ef\u5bb9\u8bb8\u6027\u6982\u5ff5\uff0c\u8bc1\u660e\u4efb\u4f55\u53ef\u5bb9\u8bb8\u5e73\u6ed1\u90fd\u80fd\u83b7\u5f97\u4e0e\u5355\u8fb9Shampoo\u6700\u4f73\u5df2\u77e5\u4fdd\u8bc1\u5339\u914d\u7684\u9057\u61be\u754c\u3002\u5177\u4f53\u5b9e\u4f8b\u5316\u4e86\u4e24\u79cd\u9ad8\u6548\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u9ad8\u65af\u968f\u673a\u5e73\u6ed1\u7684\u81ea\u9002\u5e94FTPL\u65b9\u6cd5\uff1b2\uff09\u5728\u589e\u5e7f\u77e9\u9635\u7a7a\u95f4\u4e2d\u4f7f\u7528\u786e\u5b9a\u6027\u53cc\u66f2\u5e73\u6ed1\u7684FAML\u65b9\u6cd5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u5141\u8bb8\u95ed\u5f0f\u66f4\u65b0\uff0c\u4e0e\u5355\u8fb9Shampoo\u7684\u9057\u61be\u754c\u5339\u914d\uff08\u4ec5\u5dee\u5e38\u6570\u56e0\u5b50\uff09\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002\u901a\u8fc7\u5728\u7ebf\u5230\u975e\u51f8\u8f6c\u6362\uff0c\u5f97\u5230\u4e86\u4e24\u4e2a\u77e9\u9635\u4f18\u5316\u5668Pion\uff08\u6765\u81eaFTPL\uff09\u548cLeon\uff08\u6765\u81eaFAML\uff09\uff0c\u5728\u975e\u5149\u6ed1\u975e\u51f8\u8bbe\u7f6e\u4e2d\u8bc1\u660e\u4e86\u6536\u655b\u4fdd\u8bc1\uff0c\u8fd9\u662f\u6d41\u884c\u7684Muon\u4f18\u5316\u5668\u6240\u7f3a\u4e4f\u7684\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u907f\u514d\u6602\u8d35\u4e8c\u6b21\u6295\u5f71\u7684\u9ad8\u6548\u77e9\u9635\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5\uff0c\u4fdd\u6301\u4e86\u6700\u4f73\u81ea\u9002\u5e94\u9057\u61be\u754c\uff0c\u5e76\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u8f6c\u5316\u4e3a\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u975e\u51f8\u4f18\u5316\u5668\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u975e\u5149\u6ed1\u975e\u51f8\u6536\u655b\u6027\u5206\u6790\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.07639", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07639", "abs": "https://arxiv.org/abs/2602.07639", "authors": ["Jaewook Lee", "Alexander Scarlatos", "Simon Woodhead", "Andrew Lan"], "title": "Letting Tutor Personas \"Speak Up\" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization", "comment": null, "summary": "With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411\u5411\u91cf\u6765\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u4e0d\u540c\u6559\u5e08\u7684\u6559\u5b66\u98ce\u683c\uff0c\u65e0\u9700\u663e\u5f0f\u6307\u4ee4\u63d0\u793a\uff0c\u4ece\u800c\u6355\u6349\u6559\u5e08-\u5b66\u751f\u5bf9\u8bdd\u4e2d\u7684\u4e2a\u6027\u5316\u6559\u5b66\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6559\u5b66\u7cfb\u7edf\u901a\u5e38\u53ea\u5b66\u4e60\u5355\u4e00\u7684\u6559\u5b66\u7b56\u7565\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u4e2d\u6559\u5e08\u6559\u5b66\u98ce\u683c\u7684\u591a\u6837\u6027\u3002\u771f\u5b9e\u6559\u5b66\u4e92\u52a8\u4e2d\uff0c\u6559\u5e08\u4f1a\u6839\u636e\u5b66\u751f\u9700\u6c42\u8c03\u6574\u811a\u624b\u67b6\u652f\u6301\u3001\u6559\u5b66\u6307\u5bfc\u6027\u3001\u53cd\u9988\u548c\u60c5\u611f\u652f\u6301\u7b49\u7b56\u7565\uff0c\u8fd9\u4e9b\u5dee\u5f02\u4f1a\u5f71\u54cd\u5bf9\u8bdd\u52a8\u6001\u548c\u5b66\u751f\u53c2\u4e0e\u5ea6\u3002", "method": "\u4fee\u6539\u53cc\u5411\u504f\u597d\u4f18\u5316\uff08BiPO\uff09\u65b9\u6cd5\uff0c\u5b66\u4e60\u4e00\u4e2a\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411\u5411\u91cf\uff08steering vector\uff09\uff0c\u8be5\u5411\u91cf\u80fd\u591f\u5f15\u5bfc\u6a21\u578b\u54cd\u5e94\u671d\u5411\u7279\u5b9a\u7684\u6559\u5e08\u98ce\u683c\u3002\u8fd9\u79cd\u65b9\u6cd5\u76f4\u63a5\u4ece\u4eba\u7c7b\u6559\u5e08-\u5b66\u751f\u5bf9\u8bdd\u6570\u636e\u4e2d\u63d0\u53d6\u4fe1\u53f7\uff0c\u65e0\u9700\u663e\u5f0f\u6307\u4ee4\u63d0\u793a\u3002", "result": "\u5b66\u4e60\u5230\u7684\u65b9\u5411\u5411\u91cf\u80fd\u591f\u6355\u6349\u4e0d\u540c\u6559\u5e08\u5728\u4e0d\u540c\u5bf9\u8bdd\u60c5\u5883\u4e0b\u7684\u7279\u5b9a\u53d8\u5316\uff0c\u63d0\u9ad8\u4e86\u4e0e\u771f\u5b9e\u6559\u5e08\u8bdd\u8bed\u7684\u8bed\u4e49\u5bf9\u9f50\u5ea6\uff0c\u589e\u52a0\u4e86\u57fa\u4e8e\u504f\u597d\u7684\u8bc4\u4f30\u5206\u6570\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u6301\u4e86\u8bcd\u6c47\u76f8\u4f3c\u6027\u3002\u65b9\u5411\u7cfb\u6570\u7684\u5206\u6790\u8fd8\u63ed\u793a\u4e86\u8de8\u6559\u5e08\u7684\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u5bf9\u5e94\u7740\u6559\u5b66\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u5dee\u5f02\u3002", "conclusion": "\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411\u5f15\u5bfc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5229\u7528\u76f4\u63a5\u4ece\u4eba\u7c7b\u5bf9\u8bdd\u6570\u636e\u4e2d\u63d0\u53d6\u7684\u4fe1\u53f7\u6765\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u6559\u5e08\u7279\u5b9a\u7684\u6559\u5b66\u98ce\u683c\u53d8\u5316\u3002"}}
{"id": "2602.07543", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07543", "abs": "https://arxiv.org/abs/2602.07543", "authors": ["Heewoong Noh", "Gyoung S. Na", "Namkyeong Lee", "Chanyoung Park"], "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning", "comment": null, "summary": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.", "AI": {"tldr": "MSP-LLM\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6750\u6599\u5408\u6210\u89c4\u5212\u7684\u6027\u80fd\u3002", "motivation": "\u6750\u6599\u5408\u6210\u89c4\u5212\u662fAI\u9a71\u52a8\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u89e3\u51b3\u5b64\u7acb\u5b50\u4efb\u52a1\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u5904\u7406\u524d\u9a71\u4f53\u9009\u62e9\u548c\u5408\u6210\u64cd\u4f5c\u5e8f\u5217\u8bbe\u8ba1\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faMSP-LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\u3002\u5f15\u5165\u79bb\u6563\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u5f62\u6210\u5316\u5b66\u4e00\u81f4\u7684\u51b3\u7b56\u94fe\u3002\u5728\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e2d\uff0c\u91c7\u7528\u5206\u5c42\u524d\u9a71\u4f53\u7c7b\u578b\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u5e76\u4f7f\u7528\u663e\u5f0f\u6761\u4ef6\u7b56\u7565\u5728\u81ea\u56de\u5f52\u89e3\u7801\u4e2d\u4fdd\u6301\u524d\u9a71\u4f53\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMSP-LLM\u5728\u524d\u9a71\u4f53\u9884\u6d4b\u3001\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4ee5\u53ca\u5b8c\u6574\u7684\u6750\u6599\u5408\u6210\u89c4\u5212\u4efb\u52a1\u4e0a\u90fd\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "MSP-LLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6750\u6599\u5408\u6210\u89c4\u5212\u6846\u67b6\uff0c\u80fd\u591f\u52a0\u901f\u73b0\u5b9e\u4e16\u754c\u7684\u6750\u6599\u53d1\u73b0\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u7edf\u4e00\u65b9\u6cd5\u7f3a\u5931\u95ee\u9898\u3002"}}
{"id": "2602.07216", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07216", "abs": "https://arxiv.org/abs/2602.07216", "authors": ["Reuben Narad", "L\u00e9onard Boussioux", "Michael Wagner"], "title": "Probing Neural TSP Representations for Prescriptive Decision Support", "comment": "Submitted to ICML 2026", "summary": "The field of neural combinatorial optimization (NCO) trains neural policies to solve NP-hard problems such as the traveling salesperson problem (TSP). We ask whether, beyond producing good tours, a trained TSP solver learns internal representations that transfer to other optimization-relevant objectives, in the spirit of transfer learning from other domains. We train several attention-based TSP policies, collect their internal activations, and train probes on node/edge embeddings for two NP-hard prescriptive downstream tasks inspired by real-world logistics scenarios: node-removal sensitivity (identifying the most impactful node to remove) and edge-forbid sensitivity (identifying the most critical edge to retain). On a Euclidean TSP100-trained model, probes for both tasks are competitive with existing baselines. Ensembling probe signals with geometric features outperforms the strongest baselines: 65\\% top-1 accuracy (vs. 58\\% baseline) for the best-node-removal task, and 73\\% top-1 accuracy (vs. 67\\% baseline) for the worst-edge identification task. To our knowledge, we are the first to study neural TSP solvers as transferable encoders for prescriptive what-if decision-support objectives beyond tour construction. Finally, we show that transfer accuracy increases with solver quality across training and model scale, suggesting that training stronger NCO solvers also yields more useful encoders for downstream objectives. Our code is available at: github.com/ReubenNarad/tsp_prescriptive_probe", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u795e\u7ecf\u7ec4\u5408\u4f18\u5316\u6a21\u578b\u5728\u89e3\u51b3\u65c5\u884c\u5546\u95ee\u9898\u540e\uff0c\u5176\u5185\u90e8\u8868\u793a\u80fd\u5426\u8fc1\u79fb\u5230\u5176\u4ed6\u4f18\u5316\u76f8\u5173\u4efb\u52a1\uff0c\u5982\u8282\u70b9\u79fb\u9664\u654f\u611f\u6027\u548c\u8fb9\u4fdd\u7559\u654f\u611f\u6027\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u8bad\u7ec3\u597d\u7684TSP\u6c42\u89e3\u5668\u9664\u4e86\u751f\u6210\u4f18\u8d28\u8def\u5f84\u5916\uff0c\u5176\u5185\u90e8\u8868\u793a\u662f\u5426\u80fd\u591f\u8fc1\u79fb\u5230\u5176\u4ed6\u4f18\u5316\u76f8\u5173\u76ee\u6807\uff0c\u5b9e\u73b0\u7c7b\u4f3c\u5176\u4ed6\u9886\u57df\u7684\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\u3002", "method": "\u8bad\u7ec3\u591a\u4e2a\u57fa\u4e8e\u6ce8\u610f\u529b\u7684TSP\u7b56\u7565\uff0c\u6536\u96c6\u5176\u5185\u90e8\u6fc0\u6d3b\uff0c\u7136\u540e\u8bad\u7ec3\u63a2\u9488\u6a21\u578b\u6765\u9884\u6d4b\u8282\u70b9/\u8fb9\u5d4c\u5165\uff0c\u7528\u4e8e\u4e24\u4e2aNP\u96be\u7684\u4e0b\u6e38\u4efb\u52a1\uff1a\u8282\u70b9\u79fb\u9664\u654f\u611f\u6027\u548c\u8fb9\u7981\u6b62\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u5728Euclidean TSP100\u8bad\u7ec3\u6a21\u578b\u4e0a\uff0c\u4e24\u4e2a\u4efb\u52a1\u7684\u63a2\u9488\u6027\u80fd\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002\u63a2\u9488\u4fe1\u53f7\u4e0e\u51e0\u4f55\u7279\u5f81\u96c6\u6210\u540e\u8868\u73b0\u66f4\u4f73\uff1a\u6700\u4f73\u8282\u70b9\u79fb\u9664\u4efb\u52a1\u8fbe\u523065% top-1\u51c6\u786e\u7387\uff08\u57fa\u7ebf58%\uff09\uff0c\u6700\u5dee\u8fb9\u8bc6\u522b\u4efb\u52a1\u8fbe\u523073% top-1\u51c6\u786e\u7387\uff08\u57fa\u7ebf67%\uff09\u3002", "conclusion": "\u9996\u6b21\u7814\u7a76\u795e\u7ecfTSP\u6c42\u89e3\u5668\u4f5c\u4e3a\u53ef\u8fc1\u79fb\u7f16\u7801\u5668\u7528\u4e8e\u8def\u5f84\u6784\u5efa\u4e4b\u5916\u7684\u9884\u6d4b\u6027\u51b3\u7b56\u652f\u6301\u76ee\u6807\u3002\u8f6c\u79fb\u51c6\u786e\u7387\u968f\u6c42\u89e3\u5668\u8d28\u91cf\u548c\u6a21\u578b\u89c4\u6a21\u63d0\u5347\u800c\u589e\u52a0\uff0c\u8868\u660e\u8bad\u7ec3\u66f4\u5f3a\u7684NCO\u6c42\u89e3\u5668\u4e5f\u80fd\u4ea7\u751f\u66f4\u6709\u7528\u7684\u4e0b\u6e38\u7f16\u7801\u5668\u3002"}}
{"id": "2602.07488", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07488", "abs": "https://arxiv.org/abs/2602.07488", "authors": ["Francesco Cagnetta", "Allan Ravent\u00f3s", "Surya Ganguli", "Matthieu Wyart"], "title": "Deriving Neural Scaling Laws from the statistics of natural language", "comment": null, "summary": "Despite the fact that experimental neural scaling laws have substantially guided empirical progress in large-scale machine learning, no existing theory can quantitatively predict the exponents of these important laws for any modern LLM trained on any natural language dataset. We provide the first such theory in the case of data-limited scaling laws. We isolate two key statistical properties of language that alone can predict neural scaling exponents: (i) the decay of pairwise token correlations with time separation between token pairs, and (ii) the decay of the next-token conditional entropy with the length of the conditioning context. We further derive a simple formula in terms of these statistics that predicts data-limited neural scaling exponents from first principles without any free parameters or synthetic data models. Our theory exhibits a remarkable match with experimentally measured neural scaling laws obtained from training GPT-2 and LLaMA style models from scratch on two qualitatively different benchmarks, TinyStories and WikiText.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u80fd\u5b9a\u91cf\u9884\u6d4b\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u6570\u636e\u53d7\u9650\u7f29\u653e\u5b9a\u5f8b\u6307\u6570\u7684\u7406\u8bba\uff0c\u57fa\u4e8e\u8bed\u8a00\u7684\u4e24\u4e2a\u5173\u952e\u7edf\u8ba1\u7279\u6027\uff1atoken\u5bf9\u76f8\u5173\u6027\u7684\u65f6\u95f4\u8870\u51cf\u548c\u6761\u4ef6\u71b5\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u8870\u51cf\u3002", "motivation": "\u5c3d\u7ba1\u5b9e\u9a8c\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u6307\u5bfc\u4e86\u5927\u6a21\u578b\u7684\u7ecf\u9a8c\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7406\u8bba\u65e0\u6cd5\u5b9a\u91cf\u9884\u6d4b\u4efb\u4f55\u73b0\u4ee3LLM\u5728\u81ea\u7136\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u7684\u7f29\u653e\u6307\u6570\u3002\u9700\u8981\u5efa\u7acb\u80fd\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u9884\u6d4b\u8fd9\u4e9b\u91cd\u8981\u5b9a\u5f8b\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u8bc6\u522b\u8bed\u8a00\u7684\u4e24\u4e2a\u5173\u952e\u7edf\u8ba1\u7279\u6027\uff1a(1) token\u5bf9\u76f8\u5173\u6027\u968f\u65f6\u95f4\u95f4\u9694\u7684\u8870\u51cf\uff0c(2) \u4e0b\u4e00token\u6761\u4ef6\u71b5\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u8870\u51cf\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7edf\u8ba1\u7279\u6027\u63a8\u5bfc\u51fa\u65e0\u81ea\u7531\u53c2\u6570\u7684\u7b80\u5355\u516c\u5f0f\u6765\u9884\u6d4b\u6570\u636e\u53d7\u9650\u7684\u795e\u7ecf\u7f29\u653e\u6307\u6570\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u4e0eGPT-2\u548cLLaMA\u98ce\u683c\u6a21\u578b\u5728TinyStories\u548cWikiText\u4e24\u4e2a\u4e0d\u540c\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u6d4b\u91cf\u7ed3\u679c\u9ad8\u5ea6\u5339\u914d\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u9996\u6b21\u5efa\u7acb\u4e86\u80fd\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u5b9a\u91cf\u9884\u6d4b\u6570\u636e\u53d7\u9650\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u6307\u6570\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u7edf\u8ba1\u7279\u6027\u4e0e\u7f29\u653e\u884c\u4e3a\u4e4b\u95f4\u7684\u6df1\u523b\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.08385", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08385", "abs": "https://arxiv.org/abs/2602.08385", "authors": ["Johannes Schrotshamer", "Bernd Kolar", "Markus Sch\u00f6berl"], "title": "Testing Backward-Flatness of Nonlinear Discrete-Time Systems", "comment": null, "summary": "Despite ongoing research, testing the flatness of discrete-time systems remains a challenging problem. To date, only the property of forward-flatness - a special case of difference-flatness - can be checked in a computationally efficient manner. In this paper, we propose a systematic approach for testing backward-flatness, which is another special case of difference-flatness, and for deriving a corresponding backward-flat output. Additionally, we discuss the relationship between the Jacobian matrices associated with the flat parameterization of backward- and forward-flat systems and illustrate our results by an academic example.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6d4b\u8bd5\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u540e\u5411\u5e73\u5766\u6027\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5e76\u63a8\u5bfc\u76f8\u5e94\u7684\u540e\u5411\u5e73\u5766\u8f93\u51fa\uff0c\u540c\u65f6\u8ba8\u8bba\u540e\u5411\u4e0e\u5411\u524d\u5e73\u5766\u7cfb\u7edf\u5e73\u5766\u53c2\u6570\u5316\u76f8\u5173\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u5173\u7cfb\u3002", "motivation": "\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u7684\u5e73\u5766\u6027\u6d4b\u8bd5\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002\u76ee\u524d\u53ea\u6709\u5411\u524d\u5e73\u5766\u6027\uff08\u5dee\u5206\u5e73\u5766\u6027\u7684\u7279\u6b8a\u60c5\u51b5\uff09\u53ef\u4ee5\u5728\u8ba1\u7b97\u4e0a\u9ad8\u6548\u5730\u68c0\u67e5\u3002\u9700\u8981\u5f00\u53d1\u6d4b\u8bd5\u540e\u5411\u5e73\u5766\u6027\u7684\u7cfb\u7edf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u6d4b\u8bd5\u540e\u5411\u5e73\u5766\u6027\uff08\u5dee\u5206\u5e73\u5766\u6027\u7684\u53e6\u4e00\u79cd\u7279\u6b8a\u60c5\u51b5\uff09\uff0c\u5e76\u63a8\u5bfc\u76f8\u5e94\u7684\u540e\u5411\u5e73\u5766\u8f93\u51fa\u3002\u8ba8\u8bba\u540e\u5411\u5e73\u5766\u7cfb\u7edf\u548c\u5411\u524d\u5e73\u5766\u7cfb\u7edf\u5e73\u5766\u53c2\u6570\u5316\u76f8\u5173\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5f00\u53d1\u4e86\u6d4b\u8bd5\u540e\u5411\u5e73\u5766\u6027\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u63a8\u5bfc\u540e\u5411\u5e73\u5766\u8f93\u51fa\uff0c\u5e76\u901a\u8fc7\u5b66\u672f\u793a\u4f8b\u8bf4\u660e\u4e86\u7ed3\u679c\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u5e73\u5766\u6027\u6d4b\u8bd5\u7684\u7a7a\u767d\uff0c\u4e3a\u540e\u5411\u5e73\u5766\u6027\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u5dee\u5206\u5e73\u5766\u6027\u7406\u8bba\u5728\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2602.07673", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07673", "abs": "https://arxiv.org/abs/2602.07673", "authors": ["Jiangnan Fang", "Cheng-Tse Liu", "Hanieh Deilamsalehy", "Nesreen K. Ahmed", "Puneet Mathur", "Nedim Lipka", "Franck Dernoncourt", "Ryan A. Rossi"], "title": "Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation", "comment": null, "summary": "Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.", "AI": {"tldr": "LLM\u8bc4\u59d4\u5728\u6458\u8981\u8bc4\u4f30\u4e2d\u5b58\u5728\u504f\u89c1\uff1a\u968f\u7740\u4e0e\u4eba\u7c7b\u6458\u8981\u76f8\u4f3c\u5ea6\u964d\u4f4e\uff0cLLM\u8bc4\u59d4\u8d8a\u6765\u8d8a\u504f\u597d\u5176\u4ed6LLM\u751f\u6210\u7684\u6458\u8981\u800c\u975e\u4eba\u7c7b\u6458\u8981\uff0c\u4e14\u51e0\u4e4e\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u5b58\u5728\u6b64\u6a21\u5f0f\u3002", "motivation": "LLM\u8bc4\u59d4\u5728\u6458\u8981\u8bc4\u4f30\u7b49\u4efb\u52a1\u4e2d\u6bd4\u4f20\u7edf\u7b97\u6cd5\u6307\u6807\u66f4\u80fd\u6355\u6349\u8bed\u4e49\u4fe1\u606f\uff0c\u4f46\u5b58\u5728\u957f\u5ea6\u3001\u987a\u5e8f\u7b49\u504f\u89c1\uff0c\u4e14\u5bf9\u5bf9\u6297\u6027\u8f93\u5165\u654f\u611f\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u8fd9\u4e9b\u504f\u89c1\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u4e0e\u660e\u786e\u91cd\u53e0\u6307\u6807\u7684\u5173\u7cfb\u3002", "method": "\u6d4b\u8bd59\u4e2a\u53c2\u6570\u91cf\u4ece10\u4ebf\u5230120\u4ebf\u7684\u8fd1\u671fLLM\uff08\u5305\u62ecGemma 3\u548cLLaMA 3\u53d8\u4f53\uff09\uff0c\u5206\u6790LLM\u8bc4\u59d4\u504f\u89c1\u4f5c\u4e3a\u4e0e\u4eba\u7c7b\u64b0\u5199\u6458\u8981\u91cd\u53e0\u5ea6\uff08\u901a\u8fc7ROUGE\u548cBLEU\u6d4b\u91cf\uff09\u7684\u51fd\u6570\u3002", "result": "\u53d1\u73b0\u968f\u7740\u88ab\u8bc4\u4f30\u6458\u8981\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u964d\u4f4e\uff0cLLM\u8bc4\u59d4\u8d8a\u6765\u8d8a\u504f\u597dLLM\u751f\u6210\u7684\u6458\u8981\u800c\u975e\u4eba\u7c7b\u6458\u8981\uff1b\u9664\u4e00\u4e2a\u6a21\u578b\u5916\uff0c\u6240\u6709\u6a21\u578b\u90fd\u663e\u793a\u6b64\u6a21\u5f0f\uff0c\u4e14\u4e0e\u6a21\u578b\u81ea\u8eab\u7684\u4f4d\u7f6e\u504f\u89c1\u65e0\u5173\uff1b\u6a21\u578b\u5373\u4f7f\u5728\u6709\u9650\u91cd\u53e0\u7684\u6458\u8981\u8bc4\u4f30\u4e2d\u4e5f\u8868\u73b0\u56f0\u96be\u3002", "conclusion": "\u5728\u6458\u8981\u9886\u57df\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u59d4\u65f6\uff0c\u4e0d\u5e94\u4ec5\u4f9d\u8d56\u7b80\u5355\u7684\u6bd4\u8f83\u65b9\u6cd5\uff0c\u800c\u9700\u8981\u91c7\u7528\u66f4\u590d\u6742\u7684\u6280\u672f\u6765\u514b\u670d\u8fd9\u4e9b\u7cfb\u7edf\u6027\u504f\u89c1\u3002"}}
{"id": "2602.07549", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07549", "abs": "https://arxiv.org/abs/2602.07549", "authors": ["Dayoon Ko", "Jihyuk Kim", "Sohyeon Kim", "Haeju Park", "Dahyun Lee", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "When Is Enough Not Enough? Illusory Completion in Search Agents", "comment": null, "summary": "Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u641c\u7d22\u4ee3\u7406\u5728\u591a\u7ea6\u675f\u95ee\u9898\u4e2d\u7684\u5e7b\u89c9\u5b8c\u6210\u73b0\u8c61\uff0c\u63d0\u51faEpistemic Ledger\u8bc4\u4f30\u6846\u67b6\u548cLiveLedger\u5e72\u9884\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u672a\u9a8c\u8bc1\u7b54\u6848\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u5728\u591a\u8df3\u548c\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5728\u591a\u7ea6\u675f\u95ee\u9898\u4e2d\u662f\u5426\u80fd\u53ef\u9760\u5730\u8ddf\u8e2a\u3001\u9a8c\u8bc1\u548c\u7ef4\u62a4\u591a\u4e2a\u6761\u4ef6\u4ecd\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u53d1\u73b0\u4ee3\u7406\u7ecf\u5e38\u51fa\u73b0\"\u5e7b\u89c9\u5b8c\u6210\"\u73b0\u8c61\uff0c\u5373\u8ba4\u4e3a\u4efb\u52a1\u5df2\u5b8c\u6210\u4f46\u5b9e\u9645\u4e0a\u5b58\u5728\u672a\u89e3\u51b3\u6216\u8fdd\u53cd\u7684\u7ea6\u675f\u3002", "method": "\u63d0\u51faEpistemic Ledger\u8bc4\u4f30\u6846\u67b6\u6765\u8ddf\u8e2a\u6bcf\u4e2a\u7ea6\u675f\u7684\u8bc1\u636e\u652f\u6301\u548c\u4ee3\u7406\u4fe1\u5ff5\uff0c\u8bc6\u522b\u51fa\u56db\u79cd\u5931\u8d25\u6a21\u5f0f\u3002\u7136\u540e\u5f15\u5165LiveLedger\u4f5c\u4e3a\u63a8\u7406\u65f6\u8ddf\u8e2a\u5668\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u8ddf\u8e2a\u7ea6\u675f\u72b6\u6001\u3002", "result": "LiveLedger\u5e72\u9884\u663e\u8457\u51cf\u5c11\u4e86\u672a\u9a8c\u8bc1\u7b54\u6848\uff08\u6700\u591a\u51cf\u5c1126.5%\uff09\uff0c\u5e76\u63d0\u9ad8\u4e86\u6574\u4f53\u51c6\u786e\u6027\uff08\u6700\u591a\u63d0\u9ad811.6%\uff09\u3002\u8bc6\u522b\u51fa\u56db\u79cd\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff1a\u7b80\u5355\u65ad\u8a00\u3001\u5ffd\u89c6\u53cd\u9a73\u3001\u505c\u6ede\u548c\u8fc7\u65e9\u9000\u51fa\u3002", "conclusion": "\u663e\u5f0f\u7ea6\u675f\u72b6\u6001\u8ddf\u8e2a\u80fd\u6709\u6548\u7f13\u89e3\u641c\u7d22\u4ee3\u7406\u5728\u591a\u7ea6\u675f\u95ee\u9898\u4e2d\u7684\u5e7b\u89c9\u5b8c\u6210\u95ee\u9898\uff0cEpistemic Ledger\u6846\u67b6\u4e3a\u8bca\u65ad\u4ee3\u7406\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0cLiveLedger\u5c55\u793a\u4e86\u7b80\u5355\u5e72\u9884\u7684\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2602.07562", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07562", "abs": "https://arxiv.org/abs/2602.07562", "authors": ["Antoine Gonon", "Alexandre Cordonnier", "Nicolas Boumal"], "title": "Gaussian Match-and-Copy: A Minimalist Benchmark for Studying Transformer Induction", "comment": null, "summary": "Match-and-copy is a core retrieval primitive used at inference time by large language models to retrieve a matching token from the context then copy its successor. Yet, understanding how this behavior emerges on natural data is challenging because retrieval and memorization are entangled. To disentangle the two, we introduce Gaussian Match-and-Copy (GMC), a minimalist benchmark that isolates long-range retrieval through pure second-order correlation signals. Numerical investigations show that this task retains key qualitative aspects of how Transformers develop match-and-copy circuits in practice, and separates architectures by their retrieval capabilities. We also analyze the optimization dynamics in a simplified attention setting. Although many solutions are a priori possible under a regression objective, including ones that do not implement retrieval, we identify an implicit-bias regime in which gradient descent drives the parameters to diverge while their direction aligns with the max-margin separator, yielding hard match selection. We prove this max-margin alignment for GD trajectories that reach vanishing empirical loss under explicit technical conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9ad8\u65af\u5339\u914d\u590d\u5236\u57fa\u51c6\u6765\u5206\u79bb\u68c0\u7d22\u548c\u8bb0\u5fc6\uff0c\u5206\u6790Transformer\u5982\u4f55\u53d1\u5c55\u5339\u914d\u590d\u5236\u7535\u8def\uff0c\u5e76\u8bc1\u660e\u68af\u5ea6\u4e0b\u964d\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f1a\u6536\u655b\u5230\u6700\u5927\u95f4\u9694\u89e3\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5339\u914d\u590d\u5236\u68c0\u7d22\u884c\u4e3a\u5982\u4f55\u81ea\u7136\u6d8c\u73b0\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u68c0\u7d22\u548c\u8bb0\u5fc6\u662f\u7ea0\u7f20\u5728\u4e00\u8d77\u7684\u3002\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u51c6\u6765\u5206\u79bb\u8fd9\u4e24\u79cd\u673a\u5236\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u5206\u6790Transformer\u7684\u68c0\u7d22\u80fd\u529b\u3002", "method": "\u5f15\u5165\u9ad8\u65af\u5339\u914d\u590d\u5236\u57fa\u51c6\uff0c\u901a\u8fc7\u7eaf\u4e8c\u9636\u76f8\u5173\u4fe1\u53f7\u9694\u79bb\u957f\u7a0b\u68c0\u7d22\u3002\u5728\u7b80\u5316\u6ce8\u610f\u529b\u8bbe\u7f6e\u4e2d\u5206\u6790\u4f18\u5316\u52a8\u6001\uff0c\u7814\u7a76\u68af\u5ea6\u4e0b\u964d\u5982\u4f55\u9a71\u52a8\u53c2\u6570\u6536\u655b\u5230\u6700\u5927\u95f4\u9694\u5206\u79bb\u5668\u3002", "result": "GMC\u57fa\u51c6\u4fdd\u7559\u4e86Transformer\u5b9e\u8df5\u4e2d\u53d1\u5c55\u5339\u914d\u590d\u5236\u7535\u8def\u7684\u5173\u952e\u5b9a\u6027\u65b9\u9762\uff0c\u5e76\u80fd\u533a\u5206\u4e0d\u540c\u67b6\u6784\u7684\u68c0\u7d22\u80fd\u529b\u3002\u7406\u8bba\u8bc1\u660e\u5728\u7279\u5b9a\u6280\u672f\u6761\u4ef6\u4e0b\uff0c\u8fbe\u5230\u96f6\u7ecf\u9a8c\u635f\u5931\u7684\u68af\u5ea6\u4e0b\u964d\u8f68\u8ff9\u4f1a\u4e0e\u6700\u5927\u95f4\u9694\u5206\u79bb\u5668\u5bf9\u9f50\u3002", "conclusion": "\u9ad8\u65af\u5339\u914d\u590d\u5236\u57fa\u51c6\u4e3a\u7814\u7a76Transformer\u7684\u68c0\u7d22\u673a\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u6790\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u68af\u5ea6\u4e0b\u964d\u5728\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u9690\u5f0f\u504f\u7f6e\u7279\u6027\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u5339\u914d\u590d\u5236\u7535\u8def\u7684\u5f62\u6210\u673a\u5236\u3002"}}
{"id": "2602.08606", "categories": ["math.OC", "cs.LG", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.08606", "abs": "https://arxiv.org/abs/2602.08606", "authors": ["Borjan Geshkovski", "Dom\u00e8nec Ruiz-Balet"], "title": "Constructive conditional normalizing flows", "comment": null, "summary": "Motivated by applications in conditional sampling, given a probability measure $\u03bc$ and a diffeomorphism $\u03c6$, we consider the problem of simultaneously approximating $\u03c6$ and the pushforward $\u03c6_{\\#}\u03bc$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $\u03c6$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $\u03c6$ -- such as the Kn\u00f6the-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u540c\u65f6\u8fd1\u4f3c\u5fae\u5206\u540c\u80da\u6620\u5c04\u53ca\u5176\u63a8\u524d\u6d4b\u5ea6\uff0c\u5e94\u7528\u4e8e\u6761\u4ef6\u91c7\u6837\u95ee\u9898\u3002", "motivation": "\u9488\u5bf9\u6761\u4ef6\u91c7\u6837\u5e94\u7528\uff0c\u9700\u8981\u540c\u65f6\u8fd1\u4f3c\u5fae\u5206\u540c\u80da\u6620\u5c04\u03c6\u53ca\u5176\u63a8\u524d\u6d4b\u5ea6\u03c6#\u03bc\uff0c\u901a\u8fc7\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u6d41\u6765\u5b9e\u73b0\u3002", "method": "1. \u57fa\u4e8e\u62c9\u683c\u6717\u65e5\u63d2\u503c\u5668\u7684\u6781\u5750\u6807\u5206\u89e3\u6784\u9020\uff1a\u5305\u542b\u53ef\u538b\u7f29\u5206\u91cf\uff08\u7279\u5b9a\u51f8\u51fd\u6570\u68af\u5ea6\uff09\u548c\u4e0d\u53ef\u538b\u7f29\u5206\u91cf\uff08\u901a\u8fc7\u526a\u5207\u6d41\u5b9e\u73b0\uff09\u30022. \u5bf9\u4e8e\u66f4\u89c4\u5219\u6620\u5c04\uff08\u5982Kn\u00f6the-Rosenblatt\u91cd\u6392\uff09\uff0c\u91c7\u7528\u53d7Maurey\u7ecf\u9a8c\u65b9\u6cd5\u542f\u53d1\u7684\u6982\u7387\u6784\u9020\uff0c\u6743\u91cd\u4e0d\u8fde\u7eed\u70b9\u6570\u91cf\u4e0d\u968f\u7ef4\u5ea6\u589e\u52a0\u800c\u53cd\u6bd4\u7f29\u653e\u3002", "result": "\u63d0\u4f9b\u4e86\u4e24\u79cd\u663e\u5f0f\u6784\u9020\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u5206\u6bb5\u5e38\u6570\u6743\u91cd\u7684\u611f\u77e5\u5668\u795e\u7ecf\u7f51\u7edc\u8fde\u7eed\u6027\u65b9\u7a0b\uff0c\u540c\u65f6\u8fd1\u4f3c\u6620\u5c04\u53ca\u5176\u63a8\u524d\u6d4b\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6784\u9020\u65b9\u6cd5\u4e3a\u6761\u4ef6\u91c7\u6837\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u503c\u5b9e\u73b0\u6846\u67b6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u89c4\u5219\u6620\u5c04\uff0c\u901a\u8fc7\u6982\u7387\u6784\u9020\u907f\u514d\u4e86\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002"}}
{"id": "2602.07773", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07773", "abs": "https://arxiv.org/abs/2602.07773", "authors": ["Chen Zhang", "Kuicai Dong", "Dexun Li", "Wenjun Li", "Qu Yang", "Wei Han", "Yong Liu"], "title": "SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents", "comment": null, "summary": "Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.", "AI": {"tldr": "SRR-Judge\u6846\u67b6\u63d0\u4f9b\u641c\u7d22\u96c6\u6210\u63a8\u7406\u7684\u6b65\u9aa4\u7ea7\u8bc4\u4f30\uff0c\u901a\u8fc7\u8fed\u4ee3\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u63d0\u5347\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u4e3b\u8981\u4f7f\u7528\u7ed3\u679c\u7ea7\u76d1\u7763\u8bad\u7ec3\uff0c\u5ffd\u7565\u4e86\u4e2d\u95f4\u601d\u8003\u548c\u884c\u52a8\u7684\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u63d0\u51faSRR-Judge\u6846\u67b6\u8fdb\u884c\u63a8\u7406\u548c\u641c\u7d22\u884c\u52a8\u7684\u6b65\u9aa4\u7ea7\u8bc4\u4f30\uff0c\u96c6\u6210\u5230\u6539\u8fdb\u7684ReAct\u5f0f\u8bc4\u4f30-\u7cbe\u70bc\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4f7f\u7528SRR\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u8fed\u4ee3\u62d2\u7edd\u91c7\u6837\u5fae\u8c03", "result": "SRR-Judge\u6bd4DeepSeek-V3.1\u7b49\u66f4\u5927\u6a21\u578b\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6b65\u9aa4\u7ea7\u8bc4\u4f30\uff0c\u5176\u8bc4\u5206\u4e0e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u9ad8\u5ea6\u76f8\u5173\uff0c\u57fa\u4e8eSRR\u6807\u6ce8\u8f68\u8ff9\u5bf9\u9f50\u7b56\u7565\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347", "conclusion": "SRR-Judge\u6846\u67b6\u901a\u8fc7\u6b65\u9aa4\u7ea7\u8bc4\u4f30\u548c\u8fed\u4ee3\u5fae\u8c03\u6709\u6548\u63d0\u5347\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u7684\u641c\u7d22\u96c6\u6210\u63a8\u7406\u80fd\u529b\uff0c\u5728\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb"}}
{"id": "2602.07559", "categories": ["cs.AI", "cs.CC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07559", "abs": "https://arxiv.org/abs/2602.07559", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang", "Hao Li", "Muhammad Kafeel Shaheen"], "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning", "comment": "13 pages", "summary": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.", "AI": {"tldr": "Verify-RL\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u5fae\u5206\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\uff0c\u786e\u4fdd\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u5305\u542b\u7236\u95ee\u9898\u89e3\u4e14\u7b26\u5408\u6570\u5b66\u89c4\u5219\uff0c\u76f8\u6bd4\u542f\u53d1\u5f0f\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6570\u5b66\u95ee\u9898\u6c42\u89e3\u6027\u80fd", "motivation": "\u73b0\u6709\u6570\u5b66\u95ee\u9898\u5206\u89e3\u65b9\u6cd5\u901a\u5e38\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u89e3\u51b3\u5b50\u95ee\u9898\u6709\u52a9\u4e8e\u7236\u4efb\u52a1\u3001\u6216\u5206\u89e3\u5173\u7cfb\u6709\u6570\u5b66\u57fa\u7840\u3002\u9700\u8981\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\u6846\u67b6\u6765\u786e\u4fdd\u8fd9\u4e9b\u5173\u952e\u5c5e\u6027", "method": "\u5229\u7528\u7b26\u53f7\u5fae\u5206\u4f5c\u4e3a\u5206\u89e3\u7684\u81ea\u7136\u7ed3\u6784\uff0c\u901a\u8fc7\u5fae\u79ef\u5206\u89c4\u5219\u660e\u786e\u5b9a\u4e49\u8868\u8fbe\u5f0f\u5982\u4f55\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u7ec4\u4ef6\u3002\u63d0\u51faVerify-RL\u6846\u67b6\uff0c\u8981\u6c42\u6bcf\u4e2a\u7236-\u5b50\u5206\u89e3\u6ee1\u8db3\u4e09\u4e2a\u53ef\u9a8c\u8bc1\u6761\u4ef6\uff1a\u7ed3\u6784\u590d\u6742\u5ea6\u4e25\u683c\u9012\u51cf\u3001\u89e3\u5305\u542b\u6027\u3001\u5f62\u5f0f\u89c4\u5219\u63a8\u5bfc", "result": "\u6d88\u9664\u65e0\u6548\u5206\u89e3\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u6700\u56f0\u96be\u95ee\u9898\u7684\u51c6\u786e\u7387\u4ece32%\u7ffb\u500d\u81f368%\uff0c\u6574\u4f53\u76f8\u5bf9\u6539\u8fdb\u8fbe40%\u3002\u9a8c\u8bc1\u901a\u8fc7\u7b26\u53f7\u8ba1\u7b97\u81ea\u52a8\u5b9e\u73b0\uff0c\u8fbe\u5230\"\u6784\u9020\u5373\u9a8c\u8bc1\"\u7684\u6548\u679c", "conclusion": "\u7b26\u53f7\u5fae\u5206\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u7136\u4e14\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\u7ed3\u6784\uff0c\u786e\u4fdd\u5206\u89e3\u7684\u6570\u5b66\u6b63\u786e\u6027\u3002\u76f8\u6bd4\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u80fd\u529b"}}
{"id": "2602.07219", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07219", "abs": "https://arxiv.org/abs/2602.07219", "authors": ["Abhigyan Dutta", "Itay Safran", "Paul Valiant"], "title": "The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network", "comment": null, "summary": "We study the approximation of the median of $d$ inputs using ReLU neural networks. We present depth-width tradeoffs under several settings, culminating in a constant-depth, linear-width construction that achieves exponentially small approximation error with respect to the uniform distribution over the unit hypercube. By further establishing a general reduction from the maximum to the median, our results break a barrier suggested by prior work on the maximum function, which indicated that linear width should require depth growing at least as $\\log\\log d$ to achieve comparable accuracy. Our construction relies on a multi-stage procedure that iteratively eliminates non-central elements while preserving a candidate set around the median. We overcome obstacles that do not arise for the maximum to yield approximation results that are strictly stronger than those previously known for the maximum itself.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528ReLU\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1d\u4e2a\u8f93\u5165\u7684\u4e2d\u4f4d\u6570\u51fd\u6570\uff0c\u63d0\u51fa\u4e86\u5e38\u6570\u6df1\u5ea6\u3001\u7ebf\u6027\u5bbd\u5ea6\u7684\u6784\u9020\uff0c\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u5c0f\u7684\u903c\u8fd1\u8bef\u5dee\uff0c\u7a81\u7834\u4e86\u5148\u524d\u6700\u5927\u503c\u51fd\u6570\u7814\u7a76\u4e2d\u7ebf\u6027\u5bbd\u5ea6\u9700\u8981loglog d\u6df1\u5ea6\u7684\u969c\u788d\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u4e2d\u4f4d\u6570\u51fd\u6570\u7684\u6df1\u5ea6-\u5bbd\u5ea6\u6743\u8861\uff0c\u65e8\u5728\u7a81\u7834\u5148\u524d\u6700\u5927\u503c\u51fd\u6570\u7814\u7a76\u4e2d\u53d1\u73b0\u7684\u9650\u5236\uff0c\u5373\u7ebf\u6027\u5bbd\u5ea6\u9700\u8981\u81f3\u5c11loglog d\u6df1\u5ea6\u624d\u80fd\u8fbe\u5230\u53ef\u6bd4\u8f83\u7684\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u8fed\u4ee3\u6d88\u9664\u975e\u4e2d\u5fc3\u5143\u7d20\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u7559\u4e2d\u4f4d\u6570\u5468\u56f4\u7684\u5019\u9009\u96c6\u3002\u901a\u8fc7\u5efa\u7acb\u4ece\u6700\u5927\u503c\u5230\u4e2d\u4f4d\u6570\u7684\u4e00\u822c\u5316\u7ea6\u7b80\uff0c\u514b\u670d\u4e86\u6700\u5927\u503c\u51fd\u6570\u4e2d\u4e0d\u5b58\u5728\u7684\u969c\u788d\u3002", "result": "\u63d0\u51fa\u4e86\u5e38\u6570\u6df1\u5ea6\u3001\u7ebf\u6027\u5bbd\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u6784\u9020\uff0c\u5728\u5355\u4f4d\u8d85\u7acb\u65b9\u4f53\u5747\u5300\u5206\u5e03\u4e0b\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u5c0f\u7684\u903c\u8fd1\u8bef\u5dee\u3002\u8fd9\u4e00\u7ed3\u679c\u4e25\u683c\u5f3a\u4e8e\u5148\u524d\u5df2\u77e5\u7684\u6700\u5927\u503c\u51fd\u6570\u903c\u8fd1\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u4e2d\u4f4d\u6570\u51fd\u6570\u53ef\u4ee5\u7528\u5e38\u6570\u6df1\u5ea6\u3001\u7ebf\u6027\u5bbd\u5ea6\u7684ReLU\u795e\u7ecf\u7f51\u7edc\u9ad8\u6548\u903c\u8fd1\uff0c\u7a81\u7834\u4e86\u5148\u524d\u6700\u5927\u503c\u51fd\u6570\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u6df1\u5ea6\u9650\u5236\uff0c\u8868\u660e\u4e2d\u4f4d\u6570\u51fd\u6570\u6bd4\u6700\u5927\u503c\u51fd\u6570\u66f4\u5bb9\u6613\u88ab\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u3002"}}
{"id": "2602.07593", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07593", "abs": "https://arxiv.org/abs/2602.07593", "authors": ["Polina Gordienko", "Christoph Jansen", "Julian Rodemann", "Georg Schollmeyer"], "title": "Beyond Arrow: From Impossibility to Possibilities in Multi-Criteria Benchmarking", "comment": null, "summary": "Modern benchmarks such as HELM MMLU account for multiple metrics like accuracy, robustness and efficiency. When trying to turn these metrics into a single ranking, natural aggregation procedures can become incoherent or unstable to changes in the model set. We formalize this aggregation as a social choice problem where each metric induces a preference ranking over models on each dataset, and a benchmark operator aggregates these votes across metrics. While prior work has focused on Arrow's impossibility result, we argue that the impossibility often originates from pathological examples and identify sufficient conditions under which these disappear, and meaningful multi-criteria benchmarking becomes possible. In particular, we deal with three restrictions on the combinations of rankings and prove that on single-peaked, group-separable and distance-restricted preferences, the benchmark operator allows for the construction of well-behaved rankings of the involved models. Empirically, we investigate several modern benchmark suites like HELM MMLU and verify which structural conditions are fulfilled on which benchmark problems.", "AI": {"tldr": "\u8bba\u6587\u5c06\u591a\u6307\u6807\u57fa\u51c6\u6d4b\u8bd5\u5f62\u5f0f\u5316\u4e3a\u793e\u4f1a\u9009\u62e9\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u504f\u597d\u7ed3\u6784\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6784\u5efa\u7a33\u5b9a\u7684\u6a21\u578b\u6392\u540d", "motivation": "\u73b0\u4ee3\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982HELM MMLU\uff09\u5305\u542b\u591a\u4e2a\u6307\u6807\uff08\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u3001\u6548\u7387\u7b49\uff09\uff0c\u4f46\u5c06\u8fd9\u4e9b\u6307\u6807\u805a\u5408\u6210\u5355\u4e00\u6392\u540d\u65f6\uff0c\u81ea\u7136\u805a\u5408\u65b9\u6cd5\u53ef\u80fd\u53d8\u5f97\u4e0d\u4e00\u81f4\u6216\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u89e3\u51b3\u591a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6392\u540d\u805a\u5408\u95ee\u9898\u3002", "method": "\u5c06\u57fa\u51c6\u6d4b\u8bd5\u5f62\u5f0f\u5316\u4e3a\u793e\u4f1a\u9009\u62e9\u95ee\u9898\uff1a\u6bcf\u4e2a\u6307\u6807\u5728\u6570\u636e\u96c6\u4e0a\u8bf1\u5bfc\u51fa\u6a21\u578b\u504f\u597d\u6392\u540d\uff0c\u57fa\u51c6\u7b97\u5b50\u805a\u5408\u8fd9\u4e9b\"\u6295\u7968\"\u3002\u7814\u7a76\u4e09\u79cd\u504f\u597d\u7ed3\u6784\u9650\u5236\u6761\u4ef6\uff08\u5355\u5cf0\u504f\u597d\u3001\u7fa4\u53ef\u5206\u504f\u597d\u3001\u8ddd\u79bb\u9650\u5236\u504f\u597d\uff09\uff0c\u8bc1\u660e\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6784\u5efa\u826f\u597d\u884c\u4e3a\u7684\u6a21\u578b\u6392\u540d\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u5355\u5cf0\u504f\u597d\u3001\u7fa4\u53ef\u5206\u504f\u597d\u548c\u8ddd\u79bb\u9650\u5236\u504f\u597d\u6761\u4ef6\u4e0b\uff0c\u57fa\u51c6\u7b97\u5b50\u5141\u8bb8\u6784\u5efa\u7a33\u5b9a\u7684\u6a21\u578b\u6392\u540d\u3002\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86HELM MMLU\u7b49\u73b0\u4ee3\u57fa\u51c6\u5957\u4ef6\uff0c\u9a8c\u8bc1\u4e86\u54ea\u4e9b\u7ed3\u6784\u6761\u4ef6\u5728\u4e0d\u540c\u57fa\u51c6\u95ee\u9898\u4e0a\u5f97\u5230\u6ee1\u8db3\u3002", "conclusion": "\u867d\u7136Arrow\u4e0d\u53ef\u80fd\u5b9a\u7406\u8868\u660e\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u6392\u540d\u805a\u5408\u5b58\u5728\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u8bc6\u522b\u548c\u5229\u7528\u7279\u5b9a\u7684\u504f\u597d\u7ed3\u6784\u6761\u4ef6\uff08\u5982\u5355\u5cf0\u504f\u597d\uff09\uff0c\u53ef\u4ee5\u907f\u514d\u75c5\u6001\u60c5\u51b5\uff0c\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u591a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u548c\u7a33\u5b9a\u6392\u540d\u3002"}}
{"id": "2602.08618", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08618", "abs": "https://arxiv.org/abs/2602.08618", "authors": ["Keiya Sakabe"], "title": "Nesterov's accelerated gradient for unbounded convex functions finds the minimum-norm point in the dual space", "comment": "35 pages, 2 figures", "summary": "We study the behavior of first-order methods applied to a lower-unbounded convex function $f$, i.e., $\\inf f = -\\infty$. Such a setting has received little attention since the trajectories of gradient descent and Nesterov's accelerated gradient method diverge. In this paper, we establish quantitative convergence results describing their speeds and directions of divergence, with implications for unboundedness judgment. A key idea is a relation to a norm-minimization problem in the dual space: minimize $\\|p\\|^2/2$ over $p \\in \\mathrm{dom}f^\\ast$, which can be naturally solved via mirror descent by taking the Legendre--Fenchel conjugate $f^\\ast$ as the distance-generating function. It then turns out that gradient descent for $f$ coincides with mirror descent for this norm-minimization problem, and thus it simultaneously solves both problems at $\\mathcal{O}(k^{-1})$. This result admits acceleration; Nesterov's accelerated gradient method, without any modifications, simultaneously solves the original minimization and the dual norm-minimization problems at $\\mathcal{O}(k^{-2})$, providing a quantitative characterization of divergence in unbounded convex optimization.", "AI": {"tldr": "\u7814\u7a76\u65e0\u4e0b\u754c\u51f8\u51fd\u6570\u4f18\u5316\u4e2d\u68af\u5ea6\u4e0b\u964d\u548cNesterov\u52a0\u901f\u65b9\u6cd5\u7684\u53d1\u6563\u884c\u4e3a\uff0c\u5efa\u7acb\u4e86\u53d1\u6563\u901f\u5ea6\u548c\u65b9\u5411\u7684\u5b9a\u91cf\u6536\u655b\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u4e0e\u5bf9\u5076\u7a7a\u95f4\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u65e0\u4e0b\u754c\u51f8\u51fd\u6570\uff08inf f = -\u221e\uff09\u4e0a\u7684\u884c\u4e3a\u7814\u7a76\u8f83\u5c11\uff0c\u56e0\u4e3a\u68af\u5ea6\u4e0b\u964d\u548cNesterov\u52a0\u901f\u65b9\u6cd5\u90fd\u4f1a\u53d1\u6563\u3002\u672c\u6587\u65e8\u5728\u5b9a\u91cf\u63cf\u8ff0\u8fd9\u4e9b\u65b9\u6cd5\u7684\u53d1\u6563\u901f\u5ea6\u548c\u65b9\u5411\uff0c\u4e3a\u65e0\u754c\u6027\u5224\u65ad\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u901a\u8fc7Legendre-Fenchel\u5171\u8f6d\u5c06\u5bf9\u5076\u7a7a\u95f4\u4e2d\u7684\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff08\u6700\u5c0f\u5316\u2016p\u2016\u00b2/2\uff0c\u5176\u4e2dp\u2208dom f*\uff09\u4e0e\u539f\u59cb\u95ee\u9898\u8054\u7cfb\u8d77\u6765\u3002\u53d1\u73b0\u68af\u5ea6\u4e0b\u964d\u6c42\u89e3\u539f\u59cb\u95ee\u9898\u7b49\u4ef7\u4e8e\u955c\u50cf\u4e0b\u964d\u6c42\u89e3\u5bf9\u5076\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff0cNesterov\u52a0\u901f\u65b9\u6cd5\u4e5f\u80fd\u81ea\u7136\u5e94\u7528\u4e8e\u6b64\u6846\u67b6\u3002", "result": "\u68af\u5ea6\u4e0b\u964d\u540c\u65f6\u4ee5O(k\u207b\u00b9)\u901f\u7387\u6c42\u89e3\u539f\u59cb\u6700\u5c0f\u5316\u95ee\u9898\u548c\u5bf9\u5076\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff1bNesterov\u52a0\u901f\u65b9\u6cd5\u4ee5O(k\u207b\u00b2)\u901f\u7387\u540c\u65f6\u6c42\u89e3\u4e24\u4e2a\u95ee\u9898\uff0c\u4e3a\u65e0\u754c\u51f8\u4f18\u5316\u4e2d\u7684\u53d1\u6563\u884c\u4e3a\u63d0\u4f9b\u4e86\u5b9a\u91cf\u523b\u753b\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u65e0\u4e0b\u754c\u51f8\u51fd\u6570\u4f18\u5316\u4e2d\u53d1\u6563\u884c\u4e3a\u7684\u5b9a\u91cf\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u68af\u5ea6\u4e0b\u964d\u548cNesterov\u65b9\u6cd5\u4e0e\u5bf9\u5076\u7a7a\u95f4\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\u7684\u6df1\u523b\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3\u65e0\u754c\u4f18\u5316\u4e2d\u7684\u7b97\u6cd5\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.07778", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07778", "abs": "https://arxiv.org/abs/2602.07778", "authors": ["Shenglai Zeng", "Tianqi Zheng", "Chuan Tian", "Dante Everaert", "Yau-Shian Wang", "Yupin Huang", "Michael J. Morais", "Rohit Patki", "Jinjin Tian", "Xinnan Dai", "Kai Guo", "Monica Xiao Cheng", "Hui Liu"], "title": "Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs", "comment": null, "summary": "Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.", "AI": {"tldr": "Attn-GS\uff1a\u57fa\u4e8e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u6846\u67b6\uff0c\u5229\u7528LLM\u6ce8\u610f\u529b\u6a21\u5f0f\u8bc6\u522b\u91cd\u8981\u4e2a\u6027\u5316\u4fe1\u53f7\uff0c\u5b9e\u73b050\u500dtoken\u538b\u7f29\uff0c\u6027\u80fd\u63a5\u8fd1\u5b8c\u6574\u4e0a\u4e0b\u6587", "motivation": "\u4e2a\u6027\u5316LLM\u9700\u8981\u6574\u5408\u5927\u91cf\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u548c\u8d44\u6599\uff0c\u4f46\u8f93\u5165token\u9650\u5236\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548cAPI\u6210\u672c\u3002\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5982\u9009\u62e9\u6700\u8fd1\u4ea4\u4e92\u6216\u63d0\u793a\u6458\u8981\u6a21\u578b\uff09\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3a\u6574\u4f53\uff0c\u672a\u8003\u8651LLM\u5185\u90e8\u5982\u4f55\u5904\u7406\u548c\u4f18\u5148\u5904\u7406\u4e0d\u540c\u8d44\u6599\u7ec4\u4ef6\u3002", "method": "\u63d0\u51faAttn-GS\u6ce8\u610f\u529b\u5f15\u5bfc\u4e0a\u4e0b\u6587\u538b\u7f29\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6807\u8bb0\u6a21\u578b\u5229\u7528LLM\u6ce8\u610f\u529b\u53cd\u9988\u6807\u8bb0\u91cd\u8981\u4e2a\u6027\u5316\u53e5\u5b50\uff1b2\uff09\u6307\u5bfc\u538b\u7f29\u6a21\u578b\u751f\u6210\u4efb\u52a1\u76f8\u5173\u3001\u9ad8\u8d28\u91cf\u7684\u538b\u7f29\u7528\u6237\u4e0a\u4e0b\u6587\u3002\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff1aa) LLM\u6ce8\u610f\u529b\u6a21\u5f0f\u81ea\u7136\u63ed\u793a\u91cd\u8981\u4fe1\u53f7\uff1bb) \u5fae\u8c03\u589e\u5f3aLLM\u533a\u5206\u76f8\u5173\u4e0e\u65e0\u5173\u4fe1\u606f\u80fd\u529b\u3002", "result": "Attn-GS\u5728\u4e0d\u540c\u4efb\u52a1\u3001token\u9650\u5236\u548c\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6027\u80fd\u63a5\u8fd1\u4f7f\u7528\u5b8c\u6574\u4e0a\u4e0b\u6587\uff0c\u540c\u65f6\u5c06token\u4f7f\u7528\u91cf\u51cf\u5c1150\u500d\u3002", "conclusion": "LLM\u6ce8\u610f\u529b\u6a21\u5f0f\u80fd\u6709\u6548\u8bc6\u522b\u91cd\u8981\u4e2a\u6027\u5316\u4fe1\u53f7\u7528\u4e8e\u667a\u80fd\u4e0a\u4e0b\u6587\u538b\u7f29\u3002Attn-GS\u6846\u67b6\u901a\u8fc7\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u538b\u7f29\u673a\u5236\uff0c\u5728\u4fdd\u6301\u4e2a\u6027\u5316\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u5927\u89c4\u6a21LLM\u4e2a\u6027\u5316\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07624", "abs": "https://arxiv.org/abs/2602.07624", "authors": ["Junyu Feng", "Binxiao Xu", "Jiayi Chen", "Mengyu Dai", "Cenyang Wu", "Haodong Li", "Bohan Zeng", "Yunliu Xie", "Hao Liang", "Ming Lu", "Wentao Zhang"], "title": "M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions", "comment": null, "summary": "This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve during interactions. We propose M2A, an agentic dual-layer hybrid memory system that maintains personalized multimodal information through online updates. The system employs two collaborative agents: ChatAgent manages user interactions and autonomously decides when to query or update memory, while MemoryManager breaks down memory requests from ChatAgent into detailed operations on the dual-layer memory bank, which couples a RawMessageStore (immutable conversation log) with a SemanticMemoryStore (high-level observations), providing memories at different granularities. In addition, we develop a reusable data synthesis pipeline that injects concept-grounded sessions from Yo'LLaVA and MC-LLaVA into LoCoMo long conversations while preserving temporal coherence. Experiments show that M2A significantly outperforms baselines, demonstrating that transforming personalization from one-shot configuration to a co-evolving memory mechanism provides a viable path for high-quality individualized responses in long-term multimodal interactions. The code is available at https://github.com/Little-Fridge/M2A.", "AI": {"tldr": "M2A\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u7ea7\u6df7\u5408\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u7ef4\u62a4\u4e2a\u6027\u5316\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u89e3\u51b3\u957f\u671f\u4eba\u673a\u4ea4\u4e92\u4e2d\u4e2a\u6027\u5316\u95ee\u7b54\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u591a\u6a21\u6001\u6a21\u578b\u4e3b\u8981\u662f\u9759\u6001\u7684\uff0c\u6982\u5ff5\u5728\u521d\u59cb\u5316\u65f6\u56fa\u5b9a\uff0c\u65e0\u6cd5\u5728\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u6f14\u5316\u3002\u5f53\u5bf9\u8bdd\u5386\u53f2\u8de8\u8d8a\u6570\u5468\u6216\u6570\u6708\u5e76\u8d85\u51fa\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\uff0c\u73b0\u6709\u4e2a\u6027\u5316\u673a\u5236\u96be\u4ee5\u6301\u7eed\u5438\u6536\u548c\u5229\u7528\u7528\u6237\u589e\u91cf\u6982\u5ff5\u3001\u522b\u540d\u548c\u504f\u597d\u3002", "method": "\u63d0\u51faM2A\uff1a\u4e00\u4e2a\u4ee3\u7406\u5316\u7684\u53cc\u5c42\u7ea7\u6df7\u5408\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u4f5c\u4ee3\u7406\uff1aChatAgent\u7ba1\u7406\u7528\u6237\u4ea4\u4e92\u5e76\u81ea\u4e3b\u51b3\u5b9a\u4f55\u65f6\u67e5\u8be2\u6216\u66f4\u65b0\u8bb0\u5fc6\uff1bMemoryManager\u5c06ChatAgent\u7684\u8bb0\u5fc6\u8bf7\u6c42\u5206\u89e3\u4e3a\u5bf9\u53cc\u5c42\u7ea7\u8bb0\u5fc6\u5e93\u7684\u8be6\u7ec6\u64cd\u4f5c\u3002\u8bb0\u5fc6\u5e93\u8026\u5408RawMessageStore\uff08\u4e0d\u53ef\u53d8\u5bf9\u8bdd\u65e5\u5fd7\uff09\u548cSemanticMemoryStore\uff08\u9ad8\u5c42\u89c2\u5bdf\uff09\uff0c\u63d0\u4f9b\u4e0d\u540c\u7c92\u5ea6\u7684\u8bb0\u5fc6\u3002\u8fd8\u5f00\u53d1\u4e86\u53ef\u91cd\u7528\u7684\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u5c06Yo'LLaVA\u548cMC-LLaVA\u7684\u6982\u5ff5\u57fa\u7840\u4f1a\u8bdd\u6ce8\u5165LoCoMo\u957f\u5bf9\u8bdd\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eM2A\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u5c06\u4e2a\u6027\u5316\u4ece\u4e00\u6b21\u6027\u914d\u7f6e\u8f6c\u53d8\u4e3a\u5171\u540c\u6f14\u5316\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u4e3a\u957f\u671f\u591a\u6a21\u6001\u4ea4\u4e92\u4e2d\u7684\u9ad8\u8d28\u91cf\u4e2a\u6027\u5316\u54cd\u5e94\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "M2A\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u7684\u53cc\u5c42\u7ea7\u6df7\u5408\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u957f\u671f\u4eba\u673a\u4ea4\u4e92\u4e2d\u4e2a\u6027\u5316\u591a\u6a21\u6001\u95ee\u7b54\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6982\u5ff5\u548c\u504f\u597d\u5728\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u6301\u7eed\u6f14\u5316\u3002"}}
{"id": "2602.07223", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07223", "abs": "https://arxiv.org/abs/2602.07223", "authors": ["Yikang Yue", "Yuqi Xue", "Jian Huang"], "title": "SpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding", "comment": null, "summary": "Long-context large language model (LLM) inference has become the norm for today's AI applications. However, it is severely bottlenecked by the increasing memory demands of its KV cache. Previous works have shown that self-speculative decoding with sparse attention, where tokens are drafted using a subset of the KV cache and verified in parallel with full KV cache, speeds up inference in a lossless way. However, this approach relies on standalone KV selection algorithms to select the KV entries used for drafting and overlooks that the criticality of each KV entry is inherently computed during verification. In this paper, we propose SpecAttn, a self-speculative decoding method with verification-guided sparse attention. SpecAttn identifies critical KV entries as a byproduct of verification and only loads these entries when drafting subsequent tokens. This not only improves draft token acceptance rate but also incurs low KV selection overhead, thereby improving decoding throughput. SpecAttn achieves 2.81$\\times$ higher throughput over vanilla auto-regressive decoding and 1.29$\\times$ improvement over state-of-the-art sparsity-based self-speculative decoding methods.", "AI": {"tldr": "SpecAttn\u662f\u4e00\u79cd\u81ea\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5f15\u5bfc\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u7684\u5173\u952eKV\u6761\u76ee\u6765\u63d0\u5347\u89e3\u7801\u541e\u5410\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\u5185\u5b58\u9700\u6c42\u6210\u4e3a\u74f6\u9888\uff0c\u73b0\u6709\u81ea\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u4f9d\u8d56\u72ec\u7acb\u7684KV\u9009\u62e9\u7b97\u6cd5\uff0c\u5ffd\u7565\u4e86\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u81ea\u7136\u8bc6\u522b\u5173\u952eKV\u6761\u76ee\u3002", "method": "\u63d0\u51faSpecAttn\u65b9\u6cd5\uff0c\u5728\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u5173\u952eKV\u6761\u76ee\u4f5c\u4e3a\u526f\u4ea7\u54c1\uff0c\u4ec5\u52a0\u8f7d\u8fd9\u4e9b\u5173\u952e\u6761\u76ee\u7528\u4e8e\u540e\u7eedtoken\u7684\u8349\u7a3f\u751f\u6210\uff0c\u5b9e\u73b0\u9a8c\u8bc1\u5f15\u5bfc\u7684\u7a00\u758f\u6ce8\u610f\u529b\u3002", "result": "SpecAttn\u76f8\u6bd4\u4f20\u7edf\u81ea\u56de\u5f52\u89e3\u7801\u5b9e\u73b0\u4e862.81\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u81ea\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u67091.29\u500d\u7684\u6539\u8fdb\u3002", "conclusion": "\u9a8c\u8bc1\u5f15\u5bfc\u7684\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347\u81ea\u63a8\u6d4b\u89e3\u7801\u6027\u80fd\uff0c\u901a\u8fc7\u91cd\u7528\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u7684\u5173\u952eKV\u4fe1\u606f\uff0c\u65e2\u63d0\u9ad8\u4e86\u8349\u7a3ftoken\u63a5\u53d7\u7387\u53c8\u964d\u4f4e\u4e86KV\u9009\u62e9\u5f00\u9500\u3002"}}
{"id": "2602.07618", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07618", "abs": "https://arxiv.org/abs/2602.07618", "authors": ["Levi Rauchwerger", "Stefanie Jegelka", "Ron Levie"], "title": "Dense Neural Networks are not Universal Approximators", "comment": null, "summary": "We investigate the approximation capabilities of dense neural networks. While universal approximation theorems establish that sufficiently large architectures can approximate arbitrary continuous functions if there are no restrictions on the weight values, we show that dense neural networks do not possess this universality. Our argument is based on a model compression approach, combining the weak regularity lemma with an interpretation of feedforward networks as message passing graph neural networks. We consider ReLU neural networks subject to natural constraints on weights and input and output dimensions, which model a notion of dense connectivity. Within this setting, we demonstrate the existence of Lipschitz continuous functions that cannot be approximated by such networks. This highlights intrinsic limitations of neural networks with dense layers and motivates the use of sparse connectivity as a necessary ingredient for achieving true universality.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5728\u6743\u91cd\u548c\u7ef4\u5ea6\u7ea6\u675f\u4e0b\uff0c\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u65e0\u6cd5\u5b9e\u73b0\u4e07\u80fd\u903c\u8fd1\uff0c\u5b58\u5728Lipschitz\u8fde\u7eed\u51fd\u6570\u65e0\u6cd5\u88ab\u903c\u8fd1\uff0c\u8868\u660e\u7a00\u758f\u8fde\u63a5\u662f\u5b9e\u73b0\u771f\u6b63\u4e07\u80fd\u903c\u8fd1\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "motivation": "\u5c3d\u7ba1\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u8868\u660e\u8db3\u591f\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u903c\u8fd1\u4efb\u610f\u8fde\u7eed\u51fd\u6570\uff0c\u4f46\u8fd9\u662f\u5728\u6743\u91cd\u65e0\u9650\u5236\u7684\u524d\u63d0\u4e0b\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u5b9e\u9645\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u7684\u903c\u8fd1\u80fd\u529b\u662f\u5426\u5b58\u5728\u672c\u8d28\u9650\u5236\u3002", "method": "\u91c7\u7528\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f31\u6b63\u5219\u5f15\u7406\uff0c\u5c06\u524d\u9988\u7f51\u7edc\u89e3\u91ca\u4e3a\u6d88\u606f\u4f20\u9012\u56fe\u795e\u7ecf\u7f51\u7edc\u3002\u5728ReLU\u795e\u7ecf\u7f51\u7edc\u4e0a\u65bd\u52a0\u6743\u91cd\u548c\u8f93\u5165\u8f93\u51fa\u7ef4\u5ea6\u7684\u81ea\u7136\u7ea6\u675f\uff0c\u6a21\u62df\u5bc6\u96c6\u8fde\u63a5\u7684\u6982\u5ff5\u3002", "result": "\u5728\u8bbe\u5b9a\u7684\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86\u5b58\u5728Lipschitz\u8fde\u7eed\u51fd\u6570\u65e0\u6cd5\u88ab\u6b64\u7c7b\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\uff0c\u63ed\u793a\u4e86\u5bc6\u96c6\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u56fa\u6709\u5c40\u9650\u6027\u3002", "conclusion": "\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u4e0d\u5177\u5907\u4e07\u80fd\u903c\u8fd1\u6027\uff0c\u7a00\u758f\u8fde\u63a5\u662f\u5b9e\u73b0\u771f\u6b63\u4e07\u80fd\u903c\u8fd1\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2602.08659", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08659", "abs": "https://arxiv.org/abs/2602.08659", "authors": ["Haonan Wang", "Xinlei Yi", "Yiguang Hong", "Minghui Liwang"], "title": "Heterogeneous Distributed Zeroth-Order Nonconvex Optimization with Communication Compression", "comment": null, "summary": "Distributed zeroth-order optimization is increasingly applied in heterogeneous scenarios where agents possess distinct data distributions and objectives. This heterogeneity poses fundamental challenges for convergence analysis, as existing convergence analyses rely on relatively strong assumptions to ensure theoretical guarantees. Specifically, at least one of the following three assumptions is usually required: (i) data homogeneity across agents, (ii) $\\mathcal{O}(pn)$ function evaluations per iteration with $p$ denoting the dimension and $n$ the number of agents, or (iii) the Polyak--\u0141ojasiewicz (P--L) or strong convexity condition with a known corresponding constant. To overcome these limitations, we propose a Heterogeneous Distributed Zeroth-Order Compressed (HEDZOC) algorithm, which is based on a two-point zeroth-order gradient estimator and a general class of compressors. Without assuming data homogeneity, we develop the analysis covering three settings: general nonconvex functions, functions satisfying the P--L condition without knowing the P--L constant, and those with a known constant. To the best of our knowledge, the proposed HEDZOC algorithm is the first distributed zeroth-order method that establishes convergence without relying on the above three assumptions. Moreover, it achieves linear speedup convergence rate, which is comparable to state-of-the-art results attainable under data homogeneity and exact communication assumptions. Finally, experiments on heterogeneous adversarial example generation validate the theoretical results.", "AI": {"tldr": "\u63d0\u51faHEDZOC\u7b97\u6cd5\uff0c\u9996\u4e2a\u65e0\u9700\u6570\u636e\u540c\u8d28\u6027\u3001\u9ad8\u7ef4\u51fd\u6570\u8bc4\u4f30\u6216\u5df2\u77e5P-L\u5e38\u6570\u7684\u5206\u5e03\u5f0f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u5f02\u6784\u573a\u666f\u4e0b\u5b9e\u73b0\u7ebf\u6027\u52a0\u901f\u6536\u655b", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u5f02\u6784\u573a\u666f\uff08\u4ee3\u7406\u6570\u636e\u5206\u5e03\u548c\u76ee\u6807\u4e0d\u540c\uff09\u4e2d\u5b58\u5728\u6536\u655b\u5206\u6790\u9650\u5236\uff0c\u901a\u5e38\u9700\u8981\u4ee5\u4e0b\u81f3\u5c11\u4e00\u4e2a\u5047\u8bbe\uff1a\u6570\u636e\u540c\u8d28\u6027\u3001\u9ad8\u7ef4\u51fd\u6570\u8bc4\u4f30\uff08O(pn)\uff09\u3001\u6216\u5df2\u77e5P-L/\u5f3a\u51f8\u5e38\u6570\u3002\u8fd9\u4e9b\u5047\u8bbe\u5728\u5b9e\u9645\u5f02\u6784\u5e94\u7528\u4e2d\u96be\u4ee5\u6ee1\u8db3\u3002", "method": "\u63d0\u51fa\u5f02\u6784\u5206\u5e03\u5f0f\u96f6\u9636\u538b\u7f29\uff08HEDZOC\uff09\u7b97\u6cd5\uff0c\u57fa\u4e8e\u4e24\u70b9\u96f6\u9636\u68af\u5ea6\u4f30\u8ba1\u5668\u548c\u901a\u7528\u538b\u7f29\u5668\u7c7b\u522b\uff0c\u65e0\u9700\u6570\u636e\u540c\u8d28\u6027\u5047\u8bbe\uff0c\u8986\u76d6\u4e09\u79cd\u8bbe\u7f6e\uff1a\u4e00\u822c\u975e\u51f8\u51fd\u6570\u3001\u6ee1\u8db3P-L\u6761\u4ef6\u4f46\u672a\u77e5\u5e38\u6570\u7684\u51fd\u6570\u3001\u5df2\u77e5\u5e38\u6570\u7684\u51fd\u6570\u3002", "result": "HEDZOC\u662f\u9996\u4e2a\u65e0\u9700\u4e0a\u8ff0\u4e09\u4e2a\u5047\u8bbe\u7684\u5206\u5e03\u5f0f\u96f6\u9636\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u52a0\u901f\u6536\u655b\u7387\uff0c\u4e0e\u6570\u636e\u540c\u8d28\u6027\u548c\u7cbe\u786e\u901a\u4fe1\u5047\u8bbe\u4e0b\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u76f8\u5f53\u3002\u5f02\u6784\u5bf9\u6297\u6837\u672c\u751f\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "HEDZOC\u7b97\u6cd5\u7a81\u7834\u4e86\u5206\u5e03\u5f0f\u96f6\u9636\u4f18\u5316\u5728\u5f02\u6784\u573a\u666f\u4e2d\u7684\u7406\u8bba\u9650\u5236\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5206\u5e03\u4e0d\u540c\u4e14\u76ee\u6807\u51fd\u6570\u6027\u8d28\u672a\u77e5\u7684\u590d\u6742\u73af\u5883\u4e2d\u3002"}}
{"id": "2602.07794", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07794", "abs": "https://arxiv.org/abs/2602.07794", "authors": ["Ningyu Xu", "Qi Zhang", "Xipeng Qiu", "Xuanjing Huang"], "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models", "comment": "27 pages, 16 figures", "summary": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.", "AI": {"tldr": "LLMs\u5728\u4e0a\u4e0b\u6587\u6982\u5ff5\u63a8\u7406\u4e2d\u4f1a\u52a8\u6001\u6784\u5efa\u548c\u4f7f\u7528\u7ed3\u6784\u5316\u6f5c\u5728\u8868\u5f81\uff0c\u8fd9\u4e9b\u8868\u5f81\u5728\u4e2d\u95f4\u5230\u6df1\u5c42\u5f62\u6210\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u5bf9\u6a21\u578b\u9884\u6d4b\u5177\u6709\u56e0\u679c\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1\u7814\u7a76\u53d1\u73b0LLMs\u4e2d\u5b58\u5728\u7c7b\u4f3c\u4eba\u7c7b\u7684\u7ed3\u6784\u5316\u6982\u5ff5\u8868\u5f81\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u5728\u63a8\u7406\u4e2d\u529f\u80fd\u6027\u5730\u4f9d\u8d56\u8fd9\u4e9b\u8868\u5f81\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76LLMs\u5728\u4e0a\u4e0b\u6587\u6982\u5ff5\u63a8\u7406\u4e2d\u7684\u5185\u90e8\u5904\u7406\u673a\u5236\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u7814\u7a76LLMs\u5728\u4e0a\u4e0b\u6587\u6982\u5ff5\u63a8\u7406\u4e2d\u7684\u5185\u90e8\u5904\u7406\uff0c\u8bc6\u522b\u6982\u5ff5\u5b50\u7a7a\u95f4\u7684\u51fa\u73b0\u4f4d\u7f6e\u548c\u7ed3\u6784\u7279\u6027\uff0c\u5206\u6790\u6ce8\u610f\u529b\u5934\u5728\u6784\u5efa\u548c\u5229\u7528\u8fd9\u4e9b\u8868\u5f81\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0LLMs\u5728\u4e2d\u95f4\u5230\u6df1\u5c42\u4f1a\u5f62\u6210\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u5176\u8868\u5f81\u7ed3\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u4fdd\u6301\u4e00\u81f4\uff1b\u8be5\u5b50\u7a7a\u95f4\u5bf9\u6a21\u578b\u9884\u6d4b\u5177\u6709\u56e0\u679c\u4f5c\u7528\uff1b\u65e9\u671f\u5230\u4e2d\u5c42\u7684\u6ce8\u610f\u529b\u5934\u6574\u5408\u4e0a\u4e0b\u6587\u7ebf\u7d22\u6784\u5efa\u548c\u7cbe\u70bc\u8be5\u5b50\u7a7a\u95f4\uff0c\u540e\u7eed\u5c42\u5229\u7528\u8fd9\u4e9b\u8868\u5f81\u751f\u6210\u9884\u6d4b\u3002", "conclusion": "LLMs\u786e\u5b9e\u4f1a\u52a8\u6001\u6784\u5efa\u548c\u4f7f\u7528\u7ed3\u6784\u5316\u6f5c\u5728\u8868\u5f81\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u8fd9\u4e3a\u7406\u89e3LLMs\u7075\u6d3b\u9002\u5e94\u7684\u8ba1\u7b97\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.07628", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07628", "abs": "https://arxiv.org/abs/2602.07628", "authors": ["Keondo Park", "Younghoon Na", "Yourim Choi", "Hyunwoo Ryu", "Hyun-Woo Shin", "Hyung-Sin Kim"], "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures", "comment": "8 pages, Appendix 9 pages", "summary": "While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.", "AI": {"tldr": "SleepMaMi\uff1a\u9996\u4e2a\u7761\u7720\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\u540c\u65f6\u5efa\u6a21\u6574\u591c\u7761\u7720\u5b8f\u89c2\u7ed3\u6784\u548c\u7cbe\u7ec6\u4fe1\u53f7\u5fae\u89c2\u7279\u5f81\uff0c\u572820,000+ PSG\u8bb0\u5f55\u4e0a\u9884\u8bad\u7ec3\uff0c\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u7761\u7720\u533b\u5b66\u4e3b\u8981\u4f9d\u8d56\u9488\u5bf9\u5c40\u90e8\u5fae\u89c2\u7ed3\u6784\u7684\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\uff0c\u5ffd\u89c6\u4e86PSG\u7684\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u548c\u6574\u591c\u7761\u7720\u7684\u5168\u5c40\u5b8f\u89c2\u7ed3\u6784\u3002\u9700\u8981\u7edf\u4e00\u7684\u57fa\u7840\u6a21\u578b\u6765\u540c\u65f6\u6355\u6349\u5b8f\u89c2\u7761\u7720\u67b6\u6784\u548c\u5fae\u89c2\u4fe1\u53f7\u5f62\u6001\u3002", "method": "\u91c7\u7528\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\uff1a\u5b8f\u89c2\u7f16\u7801\u5668\u5efa\u6a21\u6574\u591c\u65f6\u95f4\u4f9d\u8d56\uff0c\u901a\u8fc7\u4eba\u53e3\u7edf\u8ba1\u5f15\u5bfc\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u5e74\u9f84\u3001\u6027\u522b\u3001BMI\u7b49\u5ba2\u89c2\u5143\u6570\u636e\u5bf9\u9f50\uff1b\u5fae\u89c2\u7f16\u7801\u5668\u901a\u8fc7\u6df7\u5408\u63a9\u7801\u81ea\u7f16\u7801\u5668\u548c\u591a\u6a21\u6001\u5bf9\u6bd4\u76ee\u6807\u4f18\u5316\u3002\u5728\u8d85\u8fc720,000\u4e2aPSG\u8bb0\u5f55\uff08158K\u5c0f\u65f6\uff09\u4e0a\u9884\u8bad\u7ec3\u3002", "result": "SleepMaMi\u5728\u591a\u6837\u5316\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6807\u7b7e\u9ad8\u6548\u9002\u5e94\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u7761\u7720\u5206\u6790\u3002", "conclusion": "SleepMaMi\u6210\u529f\u89e3\u51b3\u4e86\u7761\u7720\u533b\u5b66\u4e2d\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u57fa\u7840\u6a21\u578b\u540c\u65f6\u6355\u6349\u5b8f\u89c2\u548c\u5fae\u89c2\u7761\u7720\u7279\u5f81\uff0c\u4e3a\u4e34\u5e8a\u7761\u7720\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2602.07226", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07226", "abs": "https://arxiv.org/abs/2602.07226", "authors": ["Zihan Zhu", "Yanqiu Wu", "Qiongkai Xu"], "title": "Fault-Tolerant Evaluation for Sample-Efficient Model Performance Estimators", "comment": null, "summary": "In the era of Model-as-a-Service, organizations increasingly rely on third-party AI models for rapid deployment. However, the dynamic nature of emerging AI applications, the continual introduction of new datasets, and the growing number of models claiming superior performance make efficient and reliable validation of model services increasingly challenging. This motivates the development of sample-efficient performance estimators, which aim to estimate model performance by strategically selecting instances for labeling, thereby reducing annotation cost. Yet existing evaluation approaches often fail in low-variance settings: RMSE conflates bias and variance, masking persistent bias when variance is small, while p-value based tests become hypersensitive, rejecting adequate estimators for negligible deviations. To address this, we propose a fault-tolerant evaluation framework that integrates bias and variance considerations within an adjustable tolerance level ${\\varepsilon}$, enabling the evaluation of performance estimators within practically acceptable error margins. We theoretically show that proper calibration of ${\\varepsilon}$ ensures reliable evaluation across different variance regimes, and we further propose an algorithm that automatically optimizes and selects ${\\varepsilon}$. Experiments on real-world datasets demonstrate that our framework provides comprehensive and actionable insights into estimator behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5bb9\u9519\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4f4e\u65b9\u5dee\u573a\u666f\u4e0b\u8bc4\u4f30\u6837\u672c\u9ad8\u6548\u7684\u6a21\u578b\u6027\u80fd\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u5bb9\u9519\u7ea7\u522b\u03b5\u5e73\u8861\u504f\u5dee\u548c\u65b9\u5dee\u3002", "motivation": "\u5728\u6a21\u578b\u5373\u670d\u52a1\u65f6\u4ee3\uff0c\u7b2c\u4e09\u65b9AI\u6a21\u578b\u7684\u52a8\u6001\u6027\u3001\u65b0\u6570\u636e\u96c6\u7684\u4e0d\u65ad\u6d8c\u73b0\u4ee5\u53ca\u4f17\u591a\u58f0\u79f0\u9ad8\u6027\u80fd\u7684\u6a21\u578b\uff0c\u4f7f\u5f97\u6a21\u578b\u670d\u52a1\u7684\u6709\u6548\u9a8c\u8bc1\u53d8\u5f97\u56f0\u96be\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u4f4e\u65b9\u5dee\u573a\u666f\u4e0b\u5931\u6548\uff1aRMSE\u6df7\u6dc6\u504f\u5dee\u548c\u65b9\u5dee\uff0cp\u503c\u68c0\u9a8c\u53d8\u5f97\u8fc7\u5ea6\u654f\u611f\u3002", "method": "\u63d0\u51fa\u5bb9\u9519\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u504f\u5dee\u548c\u65b9\u5dee\u8003\u8651\u6574\u5408\u5230\u53ef\u8c03\u8282\u7684\u5bb9\u9519\u7ea7\u522b\u03b5\u4e2d\uff0c\u5141\u8bb8\u5728\u5b9e\u9645\u53ef\u63a5\u53d7\u7684\u8bef\u5dee\u8303\u56f4\u5185\u8bc4\u4f30\u6027\u80fd\u4f30\u8ba1\u5668\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u9002\u5f53\u6821\u51c6\u03b5\u53ef\u786e\u4fdd\u5728\u4e0d\u540c\u65b9\u5dee\u673a\u5236\u4e0b\u7684\u53ef\u9760\u8bc4\u4f30\uff0c\u5e76\u63d0\u51fa\u81ea\u52a8\u4f18\u5316\u548c\u9009\u62e9\u03b5\u7684\u7b97\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u63d0\u4f9b\u5bf9\u4f30\u8ba1\u5668\u884c\u4e3a\u7684\u5168\u9762\u4e14\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bb9\u9519\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4f4e\u65b9\u5dee\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6a21\u578b\u6027\u80fd\u4f30\u8ba1\u5668\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u548c\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08673", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08673", "abs": "https://arxiv.org/abs/2602.08673", "authors": ["Lukas Eveborn", "Elina R\u00f6nnberg"], "title": "Branch-Price-and-Cut Accelerated with a Pricing for Integrality Heuristic for the Electrical Vehicle Routing Problem with Time Windows and Charging Time Slots", "comment": "34 pages, 2 figures", "summary": "Branch-price-and-cut is the state-of-the-art exact method for solving many types of vehicle routing problems, and is particularly effective for vehicle routing problems with time windows. A well-known challenge in branch-price-and-cut is that the generation of columns is guided by information from the linear relaxation of the master problem, with no guarantee that they will be useful from an integer perspective. As a consequence, high-quality primal solutions are often found only after significant cutting and branching or the use of primal heuristics. In this work, based on the ideas of pricing for integrality, we propose a new primal heuristic for vehicle routing problems.The heuristic is designed to generate columns that are more likely to be part of high-quality integer solutions. It begins by constructing a partial integer solution from a given column pool and then iteratively searches for columns that complement this solution. The search is done by modifying the pricing problem with respect to the partial solution, linear program dual information as well as previously generated columns in the heuristic. Computational tests are performed on the electrical vehicle routing problem with time windows extended with charging time slots, a problem that has both scheduling and routing aspects, making it well-suited to evaluate the performance of the proposed heuristic. The results show that the proposed heuristic closes 30% - 40% of the root node gap on average in comparison to a restricted master heuristic.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b9a\u4ef7\u5b8c\u6574\u6027\u601d\u60f3\u7684\u65b0\u539f\u59cb\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u7528\u4e8e\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u9020\u90e8\u5206\u6574\u6570\u89e3\u5e76\u8fed\u4ee3\u641c\u7d22\u4e92\u8865\u5217\uff0c\u663e\u8457\u7f29\u5c0f\u6839\u8282\u70b9\u95f4\u9699\u3002", "motivation": "\u5728\u5206\u652f\u5b9a\u4ef7\u5272\u5e73\u9762\u6cd5\u4e2d\uff0c\u5217\u751f\u6210\u53d7\u4e3b\u95ee\u9898\u7ebf\u6027\u677e\u5f1b\u4fe1\u606f\u5f15\u5bfc\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5bf9\u6574\u6570\u89e3\u6709\u7528\uff0c\u5bfc\u81f4\u9ad8\u8d28\u91cf\u539f\u59cb\u89e3\u9700\u8981\u5927\u91cf\u5207\u5272\u3001\u5206\u652f\u6216\u542f\u53d1\u5f0f\u65b9\u6cd5\u624d\u80fd\u627e\u5230\u3002", "method": "\u57fa\u4e8e\u5b9a\u4ef7\u5b8c\u6574\u6027\u601d\u60f3\uff0c\u8bbe\u8ba1\u65b0\u7684\u539f\u59cb\u542f\u53d1\u5f0f\u7b97\u6cd5\uff1a\u9996\u5148\u4ece\u5217\u6c60\u6784\u9020\u90e8\u5206\u6574\u6570\u89e3\uff0c\u7136\u540e\u8fed\u4ee3\u641c\u7d22\u4e92\u8865\u5217\uff0c\u901a\u8fc7\u4fee\u6539\u5b9a\u4ef7\u95ee\u9898\uff08\u8003\u8651\u90e8\u5206\u89e3\u3001\u7ebf\u6027\u89c4\u5212\u5bf9\u5076\u4fe1\u606f\u548c\u5148\u524d\u751f\u6210\u7684\u542f\u53d1\u5f0f\u5217\uff09\u6765\u5b9e\u73b0\u3002", "result": "\u5728\u5e26\u5145\u7535\u65f6\u95f4\u7a97\u7684\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\u4e0a\u6d4b\u8bd5\uff0c\u8be5\u95ee\u9898\u517c\u5177\u8c03\u5ea6\u548c\u8def\u5f84\u7279\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u53d7\u9650\u4e3b\u542f\u53d1\u5f0f\u76f8\u6bd4\uff0c\u65b0\u542f\u53d1\u5f0f\u5e73\u5747\u7f29\u5c0f30%-40%\u7684\u6839\u8282\u70b9\u95f4\u9699\u3002", "conclusion": "\u63d0\u51fa\u7684\u539f\u59cb\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u6709\u6548\u751f\u6210\u66f4\u53ef\u80fd\u6210\u4e3a\u9ad8\u8d28\u91cf\u6574\u6570\u89e3\u7684\u5217\uff0c\u663e\u8457\u63d0\u5347\u5206\u652f\u5b9a\u4ef7\u5272\u5e73\u9762\u6cd5\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u7684\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2602.07796", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07796", "abs": "https://arxiv.org/abs/2602.07796", "authors": ["Jiatong Li", "Changdae Oh", "Hyeong Kyu Choi", "Jindong Wang", "Sharon Li"], "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents", "comment": "27 pages, 19 figures", "summary": "Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u7528\u6237\u53c2\u4e0e\u7684\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u5f3a\u5236LLM\u4ee3\u7406\u8fdb\u884c\u663e\u5f0f\u601d\u8003\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u4e3a\u601d\u8003\u4f7f\u4ee3\u7406\u53d8\u5f97\"\u5185\u5411\"\uff0c\u51cf\u5c11\u4e86\u4fe1\u606f\u900f\u9732\uff0c\u524a\u5f31\u4e86\u4ee3\u7406\u4e0e\u7528\u6237\u7684\u4fe1\u606f\u4ea4\u6362\u3002", "motivation": "\u5c3d\u7ba1\u63a8\u7406\u6280\u672f\u80fd\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u7528\u6237\u53c2\u4e0e\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u7814\u7a76\u663e\u5f0f\u601d\u8003\u5728\u7528\u6237\u53c2\u4e0e\u7684LLM\u4ee3\u7406\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u4f7f\u75287\u4e2a\u6a21\u578b\u30013\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c2\u79cd\u601d\u8003\u5b9e\u4f8b\u5316\u8fdb\u884c\u5b9e\u9a8c\uff0c\u901a\u8fc7\u5b9a\u91cf\u54cd\u5e94\u5206\u7c7b\u5206\u6790\u548c\u5b9a\u6027\u5931\u8d25\u4f20\u64ad\u6848\u4f8b\u7814\u7a76\u6765\u8bc4\u4f30\u601d\u8003\u6548\u679c\u3002", "result": "\u4e0e\u9884\u671f\u76f8\u53cd\uff0c\u5f3a\u5236\u601d\u8003\u5728\u7528\u6237\u53c2\u4e0e\u573a\u666f\u4e2d\u7ecf\u5e38\u9002\u5f97\u5176\u53cd\uff0c\u5bfc\u81f4\u5404\u79cdLLM\u6027\u80fd\u5f02\u5e38\u4e0b\u964d\u3002\u601d\u8003\u4f7f\u4ee3\u7406\u53d8\u5f97\"\u5185\u5411\"\uff0c\u7f29\u77ed\u54cd\u5e94\u5e76\u51cf\u5c11\u4fe1\u606f\u900f\u9732\uff0c\u4ece\u800c\u524a\u5f31\u4ee3\u7406-\u7528\u6237\u4fe1\u606f\u4ea4\u6362\u5e76\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u5931\u8d25\u3002", "conclusion": "\u4fe1\u606f\u900f\u660e\u5ea6\u610f\u8bc6\u662f\u672a\u6765\u8bbe\u8ba1\u5b9e\u9645\u573a\u666f\u4e2d\u63a8\u7406\u4ee3\u7406\u7684\u5173\u952e\u4f46\u672a\u5145\u5206\u63a2\u7d22\u7684\u89c6\u89d2\u3002\u660e\u786e\u63d0\u793a\u4fe1\u606f\u900f\u9732\u80fd\u53ef\u9760\u63d0\u5347\u6027\u80fd\uff0c\u8868\u660e\u4e3b\u52a8\u900f\u660e\u5ea6\u662f\u4ee3\u7406\u4f18\u5316\u7684\u91cd\u8981\u6760\u6746\u3002"}}
{"id": "2602.07642", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07642", "abs": "https://arxiv.org/abs/2602.07642", "authors": ["Zhuoyan Xu", "Haoyang Fang", "Boran Han", "Bonan Min", "Bernie Wang", "Cuixiong Hu", "Shuai Zhang"], "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models", "comment": "Published at EACL 2026 Findings", "summary": "Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.", "AI": {"tldr": "TabRAG\uff1a\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u68c0\u7d22\u4e0e\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff0cMLLMs\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u6700\u7ec8\u751f\u6210\u7b54\u6848\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u683c\u5e38\u4ee5\u56fe\u50cf\u5f62\u5f0f\u5b58\u5728\uff08\u5982\u8d22\u52a1\u62a5\u8868\u3001\u624b\u5199\u8bb0\u5f55\u3001\u6587\u6863\u626b\u63cf\uff09\uff0c\u73b0\u6709MLLMs\u901a\u5e38\u5047\u8bbe\u76f8\u5173\u8868\u683c\u5df2\u5c31\u7eea\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u9700\u8981\u4ece\u5927\u89c4\u6a21\u8868\u683c\u96c6\u5408\u4e2d\u8bc6\u522b\u548c\u63a8\u7406\u6765\u56de\u7b54\u7528\u6237\u67e5\u8be2\u3002", "method": "1. \u4f7f\u7528\u8054\u5408\u8bad\u7ec3\u7684\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff1b2. \u5229\u7528MLLMs\u5bf9\u5019\u9009\u8868\u683c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff1b3. \u4f7f\u7528MLLMs\u5728\u9009\u5b9a\u8868\u683c\u4e0a\u8fdb\u884c\u63a8\u7406\u5e76\u751f\u6210\u7b54\u6848\u3002", "result": "\u5728\u65b0\u6784\u5efa\u7684\u6570\u636e\u96c6\uff0888,161\u8bad\u7ec3\u6837\u672c\uff0c9,819\u6d4b\u8bd5\u6837\u672c\uff0c8\u4e2a\u57fa\u51c6\uff0c48,504\u4e2a\u552f\u4e00\u8868\u683c\uff09\u4e0a\uff0c\u6846\u67b6\u5728\u68c0\u7d22\u53ec\u56de\u7387\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u53477.0%\uff0c\u5728\u7b54\u6848\u51c6\u786e\u7387\u4e0a\u63d0\u53476.1%\u3002", "conclusion": "TabRAG\u4e3a\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u96c6\u5408\u7684\u68c0\u7d22\u548c\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2602.07227", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07227", "abs": "https://arxiv.org/abs/2602.07227", "authors": ["Nethmi Jayasinghe", "Diana Gontero", "Spencer T. Brown", "Vinod K. Sangwan", "Mark C. Hersam", "Amit Ranjan Trivedi"], "title": "Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation", "comment": null, "summary": "Robotic policies deployed in real-world environments often encounter post-training faults, where retraining, exploration, or system identification are impractical. We introduce an inference-time, cerebellar-inspired residual control framework that augments a frozen reinforcement learning policy with online corrective actions, enabling fault recovery without modifying base policy parameters. The framework instantiates core cerebellar principles, including high-dimensional pattern separation via fixed feature expansion, parallel microzone-style residual pathways, and local error-driven plasticity with excitatory and inhibitory eligibility traces operating at distinct time scales. These mechanisms enable fast, localized correction under post-training disturbances while avoiding destabilizing global policy updates. A conservative, performance-driven meta-adaptation regulates residual authority and plasticity, preserving nominal behavior and suppressing unnecessary intervention. Experiments on MuJoCo benchmarks under actuator, dynamic, and environmental perturbations show improvements of up to $+66\\%$ on \\texttt{HalfCheetah-v5} and $+53\\%$ on \\texttt{Humanoid-v5} under moderate faults, with graceful degradation under severe shifts and complementary robustness from consolidating persistent residual corrections into policy parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53d7\u5c0f\u8111\u542f\u53d1\u7684\u63a8\u7406\u65f6\u6b8b\u5dee\u63a7\u5236\u6846\u67b6\uff0c\u5728\u51bb\u7ed3\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u57fa\u7840\u4e0a\u6dfb\u52a0\u5728\u7ebf\u4fee\u6b63\u52a8\u4f5c\uff0c\u65e0\u9700\u4fee\u6539\u57fa\u7840\u7b56\u7565\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u6545\u969c\u6062\u590d\u3002", "motivation": "\u673a\u5668\u4eba\u7b56\u7565\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u65f6\u7ecf\u5e38\u9047\u5230\u8bad\u7ec3\u540e\u6545\u969c\uff0c\u800c\u91cd\u65b0\u8bad\u7ec3\u3001\u63a2\u7d22\u6216\u7cfb\u7edf\u8bc6\u522b\u901a\u5e38\u4e0d\u5207\u5b9e\u9645\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u6545\u969c\u6062\u590d\u7684\u65b9\u6cd5\uff0c\u800c\u4e0d\u4fee\u6539\u57fa\u7840\u7b56\u7565\u53c2\u6570\u3002", "method": "\u53d7\u5c0f\u8111\u542f\u53d1\u7684\u6b8b\u5dee\u63a7\u5236\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u56fa\u5b9a\u7279\u5f81\u6269\u5c55\u5b9e\u73b0\u9ad8\u7ef4\u6a21\u5f0f\u5206\u79bb\uff1b2\uff09\u5e76\u884c\u5fae\u533a\u5f0f\u6b8b\u5dee\u901a\u8def\uff1b3\uff09\u5177\u6709\u5174\u594b\u6027\u548c\u6291\u5236\u6027\u8d44\u683c\u8ff9\u7684\u5c40\u90e8\u8bef\u5dee\u9a71\u52a8\u53ef\u5851\u6027\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u8fd0\u884c\uff1b4\uff09\u6027\u80fd\u9a71\u52a8\u7684\u5143\u9002\u5e94\u673a\u5236\u8c03\u8282\u6b8b\u5dee\u6743\u9650\u548c\u53ef\u5851\u6027\u3002", "result": "\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u9a71\u52a8\u5668\u3001\u52a8\u6001\u548c\u73af\u5883\u6270\u52a8\u4e0b\uff0cHalfCheetah-v5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe+66%\uff0cHumanoid-v5\u63d0\u5347+53%\uff08\u4e2d\u7b49\u6545\u969c\u4e0b\uff09\u3002\u5728\u4e25\u91cd\u504f\u79fb\u4e0b\u8868\u73b0\u4f18\u96c5\u964d\u7ea7\uff0c\u5e76\u80fd\u5c06\u6301\u4e45\u6b8b\u5dee\u4fee\u6b63\u6574\u5408\u5230\u7b56\u7565\u53c2\u6570\u4e2d\u63d0\u4f9b\u4e92\u8865\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u5c0f\u8111\u542f\u53d1\u7684\u63a8\u7406\u65f6\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u8bad\u7ec3\u540e\u6545\u969c\uff0c\u5b9e\u73b0\u5feb\u901f\u5c40\u90e8\u4fee\u6b63\uff0c\u907f\u514d\u7834\u574f\u6027\u5168\u5c40\u7b56\u7565\u66f4\u65b0\uff0c\u540c\u65f6\u4fdd\u6301\u540d\u4e49\u884c\u4e3a\u5e76\u6291\u5236\u4e0d\u5fc5\u8981\u5e72\u9884\uff0c\u4e3a\u673a\u5668\u4eba\u7b56\u7565\u7684\u5728\u7ebf\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07915", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07915", "abs": "https://arxiv.org/abs/2602.07915", "authors": ["Huiyang Yi", "Xiaojian Shen", "Yonggang Wu", "Duxin Chen", "He Wang", "Wenwu Yu"], "title": "CausalCompass: Evaluating the Robustness of Time-Series Causal Discovery in Misspecified Scenarios", "comment": null, "summary": "Causal discovery from time series is a fundamental task in machine learning. However, its widespread adoption is hindered by a reliance on untestable causal assumptions and by the lack of robustness-oriented evaluation in existing benchmarks. To address these challenges, we propose CausalCompass, a flexible and extensible benchmark suite designed to assess the robustness of time-series causal discovery (TSCD) methods under violations of modeling assumptions. To demonstrate the practical utility of CausalCompass, we conduct extensive benchmarking of representative TSCD algorithms across eight assumption-violation scenarios. Our experimental results indicate that no single method consistently attains optimal performance across all settings. Nevertheless, the methods exhibiting superior overall performance across diverse scenarios are almost invariably deep learning-based approaches. We further provide hyperparameter sensitivity analyses to deepen the understanding of these findings. We also find, somewhat surprisingly, that NTS-NOTEARS relies heavily on standardized preprocessing in practice, performing poorly in the vanilla setting but exhibiting strong performance after standardization. Finally, our work aims to provide a comprehensive and systematic evaluation of TSCD methods under assumption violations, thereby facilitating their broader adoption in real-world applications. The code and datasets are available at https://github.com/huiyang-yi/CausalCompass.", "AI": {"tldr": "CausalCompass\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u5efa\u6a21\u5047\u8bbe\u8fdd\u53cd\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u57fa\u51c6\u5957\u4ef6\uff0c\u5b9e\u9a8c\u8868\u660e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u65e0\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u6700\u4f18\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u7684\u5e7f\u6cdb\u5e94\u7528\u53d7\u5230\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u4f9d\u8d56\u4e0d\u53ef\u6d4b\u8bd5\u7684\u56e0\u679c\u5047\u8bbe\uff1b2\uff09\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u9762\u5411\u9c81\u68d2\u6027\u7684\u8bc4\u4f30\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5728\u5047\u8bbe\u8fdd\u53cd\u60c5\u51b5\u4e0b\u6027\u80fd\u7684\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86CausalCompass\u57fa\u51c6\u5957\u4ef6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u7cfb\u7edf\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u516b\u79cd\u5047\u8bbe\u8fdd\u53cd\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u5bf9\u4ee3\u8868\u6027\u7b97\u6cd5\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u8d85\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u6ca1\u6709\u4efb\u4f55\u5355\u4e00\u65b9\u6cd5\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u59cb\u7ec8\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff1b2\uff09\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u6574\u4f53\u4f18\u8d8a\u6027\u80fd\u7684\u65b9\u6cd5\u51e0\u4e4e\u90fd\u662f\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\uff1b3\uff09NTS-NOTEARS\u4e25\u91cd\u4f9d\u8d56\u6807\u51c6\u5316\u9884\u5904\u7406\uff0c\u5728\u539f\u59cb\u8bbe\u7f6e\u4e2d\u8868\u73b0\u5dee\u4f46\u6807\u51c6\u5316\u540e\u8868\u73b0\u5f3a\u52b2\u3002", "conclusion": "CausalCompass\u4e3a\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u5047\u8bbe\u8fdd\u53cd\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u5168\u9762\u7cfb\u7edf\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u8fd9\u4e9b\u65b9\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u66f4\u5e7f\u6cdb\u91c7\u7528\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.08906", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.08906", "abs": "https://arxiv.org/abs/2602.08906", "authors": ["Christian Meyer", "Alimhan Musalatov"], "title": "Switching Point Optimization for Abstract Parabolic Equations", "comment": null, "summary": "This work is concerned with a switching point optimization problem governed by a semilinear parabolic equation in abstract function spaces. It is shown that the switching-point-to-control mapping is continuously Fr\u00e9chet-differentiable when considered with values in the dual of H\u00f6lder continuous functions in time. By treating the state equation in weak form based on the concept of maximal parabolic regularity, one can then show that the reduced objective is continuously differentiable w.r.t.\\ the switching points which allows to use gradient-based method like the proximal gradient method for its minimization. In order to apply the known convergence results of this method, the gradient of the reduced objective must be Lipschitz continuous, which requires additional assumptions on the data. Numerical experiments confirm our theoretical findings, but also illustrate that such a method will in general not be able to solve the problem up to global optimality due to the non-convex nature of the switching-point-to-control map.", "AI": {"tldr": "\u7814\u7a76\u5207\u6362\u70b9\u4f18\u5316\u95ee\u9898\uff0c\u57fa\u4e8e\u62bd\u8c61\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u534a\u7ebf\u6027\u629b\u7269\u65b9\u7a0b\uff0c\u8bc1\u660e\u5207\u6362\u70b9\u5230\u63a7\u5236\u6620\u5c04\u7684\u8fde\u7eedFr\u00e9chet\u53ef\u5fae\u6027\uff0c\u63d0\u51fa\u4f7f\u7528\u8fd1\u7aef\u68af\u5ea6\u6cd5\u6c42\u89e3\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u7531\u534a\u7ebf\u6027\u629b\u7269\u65b9\u7a0b\u63a7\u5236\u7684\u5207\u6362\u70b9\u4f18\u5316\u95ee\u9898\uff0c\u8fd9\u7c7b\u95ee\u9898\u5728\u5de5\u7a0b\u548c\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5e38\u89c1\uff0c\u4f46\u5207\u6362\u70b9\u5230\u63a7\u5236\u6620\u5c04\u7684\u975e\u51f8\u6027\u4f7f\u5f97\u5168\u5c40\u4f18\u5316\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6570\u503c\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6700\u5927\u629b\u7269\u6b63\u5219\u6027\u6982\u5ff5\uff0c\u5728\u5f31\u5f62\u5f0f\u4e0b\u5904\u7406\u72b6\u6001\u65b9\u7a0b\uff0c\u8bc1\u660e\u5207\u6362\u70b9\u5230\u63a7\u5236\u6620\u5c04\u5728\u65f6\u95f4\u4e0a\u7684H\u00f6lder\u8fde\u7eed\u51fd\u6570\u5bf9\u5076\u7a7a\u95f4\u4e2d\u662f\u8fde\u7eedFr\u00e9chet\u53ef\u5fae\u7684\uff0c\u4ece\u800c\u5f97\u5230\u7ea6\u5316\u76ee\u6807\u7684\u8fde\u7eed\u53ef\u5fae\u6027\uff0c\u4f7f\u7528\u8fd1\u7aef\u68af\u5ea6\u6cd5\u7b49\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u8fdb\u884c\u6700\u5c0f\u5316\u3002", "result": "\u8bc1\u660e\u4e86\u5207\u6362\u70b9\u5230\u63a7\u5236\u6620\u5c04\u7684\u8fde\u7eedFr\u00e9chet\u53ef\u5fae\u6027\uff0c\u7ea6\u5316\u76ee\u6807\u5bf9\u5207\u6362\u70b9\u7684\u8fde\u7eed\u53ef\u5fae\u6027\uff0c\u5728\u6570\u636e\u6ee1\u8db3\u989d\u5916\u5047\u8bbe\u65f6\u68af\u5ea6\u5177\u6709Lipschitz\u8fde\u7eed\u6027\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u867d\u7136\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6c42\u89e3\u5207\u6362\u70b9\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u7531\u4e8e\u5207\u6362\u70b9\u5230\u63a7\u5236\u6620\u5c04\u7684\u975e\u51f8\u672c\u8d28\uff0c\u8be5\u65b9\u6cd5\u4e00\u822c\u65e0\u6cd5\u8fbe\u5230\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u7406\u8bba\u7ed3\u679c\u4f46\u4e5f\u663e\u793a\u4e86\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.07804", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07804", "abs": "https://arxiv.org/abs/2602.07804", "authors": ["Xuan Ding", "Pengyu Tong", "Ranjie Duan", "Yunjian Zhang", "Rui Sun", "Yao Zhu"], "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models", "comment": "Accepted by ICLR 2026", "summary": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u5c42\u526a\u679d\u6846\u67b6\uff0c\u5c06\u5c42\u89c6\u4e3a\u73a9\u5bb6\uff0c\u6a21\u578b\u6027\u80fd\u4f5c\u4e3a\u6548\u7528\uff0c\u4f7f\u7528\u8f7b\u91cf\u4ee3\u7406\u7f51\u7edc\u4f30\u8ba1\u5c42\u8fb9\u9645\u8d21\u732e\uff0c\u5b9e\u73b0\u9ad8\u6548\u52a8\u6001\u526a\u679d", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u90e8\u7f72\u53d7\u9650\u4e8e\u9ad8\u8ba1\u7b97\u9700\u6c42\uff0c\u73b0\u6709\u5c42\u526a\u679d\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u672a\u8003\u8651\u5c42\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u526a\u679d\u6548\u679c", "method": "1) \u5c06\u5c42\u526a\u679d\u5efa\u6a21\u4e3a\u5408\u4f5c\u535a\u5f08\uff0c\u5c42\u4e3a\u73a9\u5bb6\uff0c\u6a21\u578b\u6027\u80fd\u4e3a\u6548\u7528\uff1b2) \u4f7f\u7528\u8f7b\u91cf\u4ee3\u7406\u7f51\u7edc\u4f30\u8ba1\u5c42\u8fb9\u9645\u8d21\u732e\uff08\u66ff\u4ee3\u8ba1\u7b97\u590d\u6742\u7684Shapley\u503c\uff09\uff1b3) \u91c7\u7528\u5206\u5c42\u8499\u7279\u5361\u6d1b\u63a9\u7801\u91c7\u6837\u8fdb\u4e00\u6b65\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u6709\u6548\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c42\u526a\u679d", "conclusion": "\u63d0\u51fa\u7684\u535a\u5f08\u8bba\u6846\u67b6\u80fd\u6355\u6349\u5c42\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u52a8\u6001\u8bc6\u522b\u5173\u952e\u5c42\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u5c42\u526a\u679d\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.07662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07662", "abs": "https://arxiv.org/abs/2602.07662", "authors": ["Glenda Amaral", "Tiago Prince Sales", "Riccardo Baratella", "Daniele Porello", "Renata Guizzardi", "Giancarlo Guizzardi"], "title": "ONTrust: A Reference Ontology of Trust", "comment": "46 pages", "summary": "Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba\uff08ONTrust\uff09\uff0c\u65e8\u5728\u4e3a\u4fe1\u4efb\u6982\u5ff5\u63d0\u4f9b\u575a\u5b9e\u7684\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u652f\u6301\u4fe1\u606f\u5efa\u6a21\u3001\u81ea\u52a8\u63a8\u7406\u3001\u4fe1\u606f\u96c6\u6210\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u7b49\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u533a\u5757\u94fe\u7b49\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4fe1\u4efb\u53d8\u5f97\u6bd4\u4ee5\u5f80\u4efb\u4f55\u65f6\u5019\u90fd\u66f4\u52a0\u91cd\u8981\u3002\u8fd9\u4e9b\u65b0\u6280\u672f\u6709\u6f5c\u529b\u6539\u5584\u4ea7\u54c1\u548c\u670d\u52a1\u63d0\u4f9b\uff0c\u4fc3\u8fdb\u4e2a\u4eba\u548c\u96c6\u4f53\u798f\u7949\uff0c\u4f46\u5176\u91c7\u7528\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u4fe1\u4efb\u3002\u4e3a\u4e86\u6784\u5efa\u53ef\u4fe1\u7cfb\u7edf\uff0c\u9664\u4e86\u4e3a\u65b0\u578b\u4fe1\u4efb\u5236\u5b9a\u6cd5\u5f8b\u3001\u6cd5\u89c4\u548c\u6cbb\u7406\u6a21\u578b\u5916\uff0c\u8fd8\u9700\u8981\u5bf9\u4fe1\u4efb\u8fdb\u884c\u9002\u5f53\u7684\u6982\u5ff5\u5316\uff0c\u4f7f\u5176\u80fd\u591f\u88ab\u4eba\u7c7b\u548c\u673a\u5668\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba\uff08UFO\uff09\u5e76\u5728OntoUML\u4e2d\u6307\u5b9a\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba\uff08ONTrust\uff09\u3002\u8be5\u672c\u4f53\u8bba\u6b63\u5f0f\u5b9a\u4e49\u4e86\u4fe1\u4efb\u6982\u5ff5\u53ca\u5176\u4e0d\u540c\u7c7b\u578b\uff0c\u63cf\u8ff0\u4e86\u5f71\u54cd\u4fe1\u4efb\u7684\u5404\u79cd\u56e0\u7d20\uff0c\u5e76\u89e3\u91ca\u4e86\u4fe1\u4efb\u5173\u7cfb\u5982\u4f55\u4ea7\u751f\u98ce\u9669\u3002\u901a\u8fc7\u4ece\u6587\u732e\u4e2d\u63d0\u53d6\u7684\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u6765\u5c55\u793aONTrust\u7684\u5e94\u7528\u3002", "result": "ONTrust\u5df2\u5e94\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u5305\u62ec\u6982\u5ff5\u5efa\u6a21\u548c\u4f01\u4e1a\u67b6\u6784\u8bbe\u8ba1\u3001\u8bed\u8a00\u8bc4\u4f30\u4e0e\uff08\u91cd\u65b0\uff09\u8bbe\u8ba1\u3001\u4fe1\u4efb\u7ba1\u7406\u3001\u9700\u6c42\u5de5\u7a0b\uff0c\u4ee5\u53ca\u5728\u60c5\u611f\u4eba\u673a\u534f\u4f5c\u80cc\u666f\u4e0b\u7684\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u3002\u672c\u4f53\u8bba\u5c55\u793a\u4e86\u5176\u5728\u652f\u6301\u5404\u79cd\u4fe1\u4efb\u76f8\u5173\u4efb\u52a1\u65b9\u9762\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "ONTrust\u4e3a\u4fe1\u4efb\u6982\u5ff5\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u652f\u6301\u4fe1\u606f\u5efa\u6a21\u3001\u81ea\u52a8\u63a8\u7406\u3001\u4fe1\u606f\u96c6\u6210\u548c\u8bed\u4e49\u4e92\u64cd\u4f5c\u7b49\u4efb\u52a1\u3002\u8be5\u672c\u4f53\u8bba\u6709\u52a9\u4e8e\u6784\u5efa\u53ef\u4fe1\u7cfb\u7edf\uff0c\u4fc3\u8fdb\u4eba\u5de5\u667a\u80fd\u548c\u533a\u5757\u94fe\u7b49\u65b0\u6280\u672f\u7684\u91c7\u7528\uff0c\u4e3a\u4fe1\u4efb\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6982\u5ff5\u6846\u67b6\u3002"}}
{"id": "2602.07235", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.07235", "abs": "https://arxiv.org/abs/2602.07235", "authors": ["Atefeh Gilani", "Carol Xuan Long", "Sajani Vithana", "Oliver Kosut", "Lalitha Sankar", "Flavio P. Calmon"], "title": "ArcMark: Multi-bit LLM Watermark via Optimal Transport", "comment": null, "summary": "Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63a8\u5bfc\u51fa\u591a\u6bd4\u7279\u6c34\u5370\u7684\u4fe1\u606f\u8bba\u5bb9\u91cf\uff0c\u5e76\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u8bbe\u8ba1\u4e86\u8fbe\u5230\u8be5\u5bb9\u91cf\u7684ArcMark\u6c34\u5370\u65b9\u6848\uff0c\u5728\u6bd4\u7279\u7387\u548c\u68c0\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u6280\u672f\u4e3b\u8981\u4ece\u96f6\u6bd4\u7279\u6c34\u5370\u5ef6\u4f38\u8bbe\u8ba1\u539f\u5219\uff0c\u6bcf\u4ee4\u724c\u4ec5\u7f16\u7801\u5355\u4e2a\u6bd4\u7279\uff0c\u800c\u591a\u6bd4\u7279\u6c34\u5370\u7684\u4fe1\u606f\u8bba\u5bb9\u91cf\uff08\u6bcf\u4ee4\u724c\u53ef\u63d2\u5165\u7684\u6700\u5927\u6bd4\u7279\u6570\uff09\u4e00\u76f4\u672a\u77e5\uff0c\u9650\u5236\u4e86\u6c34\u5370\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u591a\u6bd4\u7279\u6c34\u5370\u7684\u4fe1\u9053\u5bb9\u91cf\u7406\u8bba\u8868\u5f81\uff0c\u7136\u540e\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u539f\u7406\u8bbe\u8ba1ArcMark\u6c34\u5370\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\u80fd\u591f\u8fbe\u5230\u591a\u6bd4\u7279\u6c34\u5370\u4fe1\u9053\u7684\u5bb9\u91cf\u6781\u9650\u3002", "result": "ArcMark\u5728\u6bcf\u4ee4\u724c\u6bd4\u7279\u7387\u548c\u68c0\u6d4b\u7cbe\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7ade\u4e89\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u7f16\u7801\u7406\u8bba\u65b9\u6cd5\u5728\u6c34\u5370\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4fe1\u9053\u7f16\u7801\u95ee\u9898\uff0c\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u7684\u539f\u7406\u6027\u65b9\u6cd5\u4e3a\u6c34\u5370\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0cArcMark\u5c55\u793a\u4e86\u8fbe\u5230\u7406\u8bba\u5bb9\u91cf\u6781\u9650\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.07992", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07992", "abs": "https://arxiv.org/abs/2602.07992", "authors": ["Daniel Barzilai", "Yotam Wolf", "Ronen Basri"], "title": "When Is Compositional Reasoning Learnable from Verifiable Rewards?", "comment": null, "summary": "The emergence of compositional reasoning in large language models through reinforcement learning with verifiable rewards (RLVR) has been a key driver of recent empirical successes. Despite this progress, it remains unclear which compositional problems are learnable in this setting using outcome-level feedback alone. In this work, we theoretically study the learnability of compositional problems in autoregressive models under RLVR training. We identify a quantity that we call the task-advantage ratio, a joint property of the compositional problem and the base model, that characterizes which tasks and compositions are learnable from outcome-level feedback. On the positive side, using this characterization, we show that compositional problems where correct intermediate steps provide a clear advantage are efficiently learnable with RLVR. We also analyze how such an advantage naturally arises in different problems. On the negative side, when the structural advantage is not present, RLVR may converge to suboptimal compositions. We prove that, in some cases, the quality of the base model determines if such an advantage exists and whether RLVR will converge to a suboptimal solution. We hope our analysis can provide a principled theoretical understanding of when and why RLVR succeeds and when it does not.", "AI": {"tldr": "\u8bba\u6587\u4ece\u7406\u8bba\u4e0a\u7814\u7a76\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u5728RLVR\u8bad\u7ec3\u4e0b\u7ec4\u5408\u95ee\u9898\u7684\u53ef\u5b66\u4e60\u6027\uff0c\u63d0\u51fa\u4e86\u4efb\u52a1\u4f18\u52bf\u6bd4\u7684\u6982\u5ff5\u6765\u523b\u753b\u54ea\u4e9b\u4efb\u52a1\u548c\u7ec4\u5408\u53ef\u4ee5\u4ece\u7ed3\u679c\u7ea7\u53cd\u9988\u4e2d\u5b66\u4e60\u3002", "motivation": "\u5c3d\u7ba1RLVR\u5728\u7ec4\u5408\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u7ecf\u9a8c\u6210\u529f\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u7ec4\u5408\u95ee\u9898\u53ef\u4ee5\u4ec5\u901a\u8fc7\u7ed3\u679c\u7ea7\u53cd\u9988\u5b66\u4e60\u3002\u9700\u8981\u7406\u8bba\u5206\u6790\u6765\u7406\u89e3RLVR\u4f55\u65f6\u6210\u529f\u3001\u4f55\u65f6\u5931\u8d25\u3002", "method": "\u7406\u8bba\u5206\u6790\u81ea\u56de\u5f52\u6a21\u578b\u5728RLVR\u8bad\u7ec3\u4e0b\u7684\u53ef\u5b66\u4e60\u6027\uff0c\u63d0\u51fa\u4efb\u52a1\u4f18\u52bf\u6bd4\u4f5c\u4e3a\u5173\u952e\u6307\u6807\uff0c\u8be5\u6307\u6807\u662f\u7ec4\u5408\u95ee\u9898\u548c\u57fa\u7840\u6a21\u578b\u7684\u8054\u5408\u5c5e\u6027\u3002", "result": "1. \u5f53\u6b63\u786e\u4e2d\u95f4\u6b65\u9aa4\u63d0\u4f9b\u660e\u663e\u4f18\u52bf\u65f6\uff0c\u7ec4\u5408\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7RLVR\u9ad8\u6548\u5b66\u4e60\uff1b2. \u5f53\u7ed3\u6784\u4f18\u52bf\u4e0d\u5b58\u5728\u65f6\uff0cRLVR\u53ef\u80fd\u6536\u655b\u5230\u6b21\u4f18\u7ec4\u5408\uff1b3. \u57fa\u7840\u6a21\u578b\u7684\u8d28\u91cf\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u51b3\u5b9a\u4f18\u52bf\u662f\u5426\u5b58\u5728\u3002", "conclusion": "\u4efb\u52a1\u4f18\u52bf\u6bd4\u662f\u7406\u89e3RLVR\u5728\u7ec4\u5408\u95ee\u9898\u4e2d\u53ef\u5b66\u4e60\u6027\u7684\u5173\u952e\u6982\u5ff5\uff0c\u4e3aRLVR\u4f55\u65f6\u6210\u529f\u3001\u4f55\u65f6\u5931\u8d25\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7406\u8bba\u7406\u89e3\u3002"}}
{"id": "2409.08347", "categories": ["econ.EM", "cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2409.08347", "abs": "https://arxiv.org/abs/2409.08347", "authors": ["Mogens Fosgerau", "Nikolaj Nielsen", "Mads Paulsen", "Thomas Kj\u00e6r Rasmussen", "Rui Yao"], "title": "Sensitivity analysis of the perturbed utility stochastic traffic equilibrium", "comment": null, "summary": "This paper develops a sensitivity analysis framework for the perturbed utility route choice (PURC) model and the accompanying stochastic traffic equilibrium model. We derive analytical sensitivity expressions for the Jacobian of the individual optimal PURC flow and equilibrium link flows with respect to link cost parameters under general assumptions. This allows us to determine the marginal change in link flows following a marginal change in link costs across the network. We show how to implement these results while exploiting the sparsity generated by the PURC model. Numerical examples illustrate the use of our method for estimating equilibrium link flows after link cost shifts, identifying critical design parameters, and quantifying uncertainty in performance predictions. Finally, we demonstrate the method in a large-scale example. The findings have implications for network design, pricing strategies, and policy analysis in transportation planning and economics, providing a bridge between theoretical models and real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6270\u52a8\u6548\u7528\u8def\u5f84\u9009\u62e9\uff08PURC\uff09\u6a21\u578b\u53ca\u5176\u4f34\u968f\u7684\u968f\u673a\u4ea4\u901a\u5747\u8861\u6a21\u578b\u7684\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u6d41\u91cf\u5bf9\u6210\u672c\u53c2\u6570\u7684\u89e3\u6790\u654f\u611f\u6027\u8868\u8fbe\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528PURC\u6a21\u578b\u4ea7\u751f\u7684\u7a00\u758f\u6027\u5b9e\u73b0\u8fd9\u4e9b\u7ed3\u679c\u3002", "motivation": "\u5728\u4ea4\u901a\u89c4\u5212\u548c\u7ecf\u6d4e\u653f\u7b56\u5206\u6790\u4e2d\uff0c\u9700\u8981\u7406\u89e3\u7f51\u7edc\u8bbe\u8ba1\u3001\u5b9a\u4ef7\u7b56\u7565\u7b49\u53d8\u5316\u5bf9\u4ea4\u901a\u5747\u8861\u6d41\u91cf\u7684\u5f71\u54cd\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9PURC\u6a21\u578b\u654f\u611f\u6027\u5206\u6790\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u9650\u5236\u4e86\u7406\u8bba\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u3002", "method": "\u5f00\u53d1\u4e86PURC\u6a21\u578b\u548c\u968f\u673a\u4ea4\u901a\u5747\u8861\u6a21\u578b\u7684\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u5728\u4e00\u822c\u5047\u8bbe\u4e0b\u4e2a\u4f53\u6700\u4f18PURC\u6d41\u91cf\u548c\u5747\u8861\u94fe\u8def\u6d41\u91cf\u5bf9\u94fe\u8def\u6210\u672c\u53c2\u6570\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u5229\u7528PURC\u6a21\u578b\u4ea7\u751f\u7684\u7a00\u758f\u6027\u5b9e\u73b0\u8ba1\u7b97\u3002", "result": "\u83b7\u5f97\u4e86\u94fe\u8def\u6d41\u91cf\u5bf9\u94fe\u8def\u6210\u672c\u7684\u8fb9\u9645\u53d8\u5316\u5173\u7cfb\uff0c\u80fd\u591f\u4f30\u8ba1\u94fe\u8def\u6210\u672c\u53d8\u5316\u540e\u7684\u5747\u8861\u94fe\u8def\u6d41\u91cf\uff0c\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u53c2\u6570\uff0c\u91cf\u5316\u6027\u80fd\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u548c\u5927\u89c4\u6a21\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\u4e3a\u4ea4\u901a\u89c4\u5212\u548c\u7ecf\u6d4e\u5b66\u7684\u7f51\u7edc\u8bbe\u8ba1\u3001\u5b9a\u4ef7\u7b56\u7565\u548c\u653f\u7b56\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u6a21\u578b\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2602.07812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07812", "abs": "https://arxiv.org/abs/2602.07812", "authors": ["Fengting Yuchi", "Li Du", "Jason Eisner"], "title": "LLMs Know More About Numbers than They Can Say", "comment": "EACL 2026", "summary": "Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: \"Which is larger, $5.7 \\times 10^2$ or $580$?\" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.", "AI": {"tldr": "LLMs\u5728\u6df7\u5408\u8868\u793a\u7684\u6570\u5b57\u6bd4\u8f83\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u63a2\u6d4b\u9690\u85cf\u72b6\u6001\u53d1\u73b0\u5176\u5185\u90e8\u7f16\u7801\u4e86\u6570\u5b57\u5927\u5c0f\u4fe1\u606f\uff0c\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6570\u503c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5148\u8fdbLLMs\u80fd\u89e3\u51b3\u6570\u5b66\u95ee\u9898\uff0c\u4f46\u5728\u6df7\u5408\u8868\u793a\u7684\u6570\u5b57\u6bd4\u8f83\u4efb\u52a1\u4e2d\uff08\u5982\"5.7\u00d710\u00b2 vs 580\"\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u6839\u672c\u95ee\u9898\uff1aLLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u8fd9\u4e9b\u6570\u5b57\u7684\u5927\u5c0f\uff1f", "method": "1. \u63a2\u6d4b\u591a\u4e2a\u5f00\u6e90LLMs\u7684\u9690\u85cf\u72b6\u6001\uff1b2. \u4f7f\u7528\u5355\u4e2a\u7ebf\u6027\u6295\u5f71\u4ece\u9002\u5f53\u9690\u85cf\u5c42\u63d0\u53d6\u6570\u5b57\u7684\u5bf9\u6570\u5927\u5c0f\u4fe1\u606f\uff1b3. \u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\u4ece\u9690\u85cf\u72b6\u6001\u9884\u6d4b\u6570\u5b57\u6392\u5e8f\uff1b4. \u5c06\u5206\u7c7b\u5668\u63a2\u9488\u7684\u5bf9\u6570\u635f\u5931\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\u3002", "result": "1. \u9690\u85cf\u72b6\u6001\u7f16\u7801\u4e86\u6570\u5b57\u7684\u5bf9\u6570\u5927\u5c0f\uff0c\u5728\u5408\u6210\u6587\u672c\u4e0a\u6062\u590d\u76f8\u5bf9\u8bef\u5dee\u7ea62.3%\uff0c\u5728\u79d1\u5b66\u8bba\u6587\u4e0a\u7ea619.06%\uff1b2. \u9690\u85cf\u72b6\u6001\u80fd\u7f16\u7801\u6570\u5b57\u6392\u5e8f\uff0c\u7ebf\u6027\u5206\u7c7b\u5668\u51c6\u786e\u7387\u8d8590%\uff1b3. \u6a21\u578b\u76f4\u63a5\u56de\u7b54\u6392\u5e8f\u7684\u51c6\u786e\u7387\u4ec550-70%\uff1b4. \u5c06\u63a2\u9488\u635f\u5931\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\u5fae\u8c03\uff0c\u4f7f\u53e3\u5934\u56de\u7b54\u51c6\u786e\u7387\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u53473.22%\u3002", "conclusion": "LLMs\u5185\u90e8\u786e\u5b9e\u7f16\u7801\u4e86\u6570\u5b57\u5927\u5c0f\u4fe1\u606f\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u672a\u80fd\u6709\u6548\u7528\u4e8e\u663e\u5f0f\u63a8\u7406\u4efb\u52a1\u3002\u901a\u8fc7\u6539\u8fdb\u6a21\u578b\u5185\u90e8\u7684\u6570\u503c\u8868\u793a\uff0c\u53ef\u4ee5\u589e\u5f3a\u5176\u6570\u503c\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u4e3a\u63d0\u5347LLMs\u7684\u6570\u5b66\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.07695", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.07695", "abs": "https://arxiv.org/abs/2602.07695", "authors": ["Congcong Hu", "Yuang Shi", "Fan Huang", "Yang Xiang", "Zhou Ye", "Ming Jin", "Shiyu Wang"], "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge", "comment": null, "summary": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.", "AI": {"tldr": "EventCast\uff1a\u4e00\u4e2a\u5c06\u672a\u6765\u4e8b\u4ef6\u77e5\u8bc6\u6574\u5408\u5230\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u89e3\u51b3\u7535\u5546\u5728\u95ea\u8d2d\u3001\u5047\u65e5\u6d3b\u52a8\u7b49\u7a81\u53d1\u4e8b\u4ef6\u671f\u95f4\u7684\u9700\u6c42\u9884\u6d4b\u95ee\u9898\uff0c\u5229\u7528LLM\u8fdb\u884c\u4e8b\u4ef6\u9a71\u52a8\u63a8\u7406\u800c\u975e\u76f4\u63a5\u6570\u503c\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u7535\u5546\u9700\u6c42\u9884\u6d4b\u7cfb\u7edf\u5728\u95ea\u8d2d\u3001\u5047\u65e5\u4fc3\u9500\u3001\u653f\u7b56\u5e72\u9884\u7b49\u9ad8\u5f71\u54cd\u65f6\u671f\u7ecf\u5e38\u5931\u6548\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65f6\u671f\u7684\u9700\u6c42\u6a21\u5f0f\u4f1a\u53d1\u751f\u7a81\u7136\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u53d8\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u672a\u6765\u4e8b\u4ef6\u77e5\u8bc6\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "EventCast\u91c7\u7528\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5229\u7528LLM\u5904\u7406\u975e\u7ed3\u6784\u5316\u4e1a\u52a1\u6570\u636e\uff08\u6d3b\u52a8\u3001\u5047\u65e5\u5b89\u6392\u3001\u5356\u5bb6\u6fc0\u52b1\u7b49\uff09\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u6587\u672c\u6458\u8981\uff0c\u7136\u540e\u901a\u8fc7\u53cc\u5854\u67b6\u6784\u5c06\u8fd9\u4e9b\u6458\u8981\u4e0e\u5386\u53f2\u9700\u6c42\u7279\u5f81\u878d\u5408\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u57284\u4e2a\u56fd\u5bb6160\u4e2a\u5730\u533a10\u4e2a\u6708\u7684\u73b0\u5b9e\u7535\u5546\u573a\u666f\u4e2d\uff0cEventCast\u76f8\u6bd4\u65e0\u4e8b\u4ef6\u77e5\u8bc6\u53d8\u4f53\u5728MAE\u548cMSE\u4e0a\u5206\u522b\u63d0\u534786.9%\u548c97.7%\uff0c\u76f8\u6bd4\u6700\u4f73\u5de5\u4e1a\u57fa\u7ebf\u5728\u4e8b\u4ef6\u9a71\u52a8\u65f6\u671f\u5206\u522b\u51cf\u5c1157.0% MAE\u548c83.3% MSE\u3002", "conclusion": "EventCast\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c06LLM\u7528\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u63a8\u7406\u800c\u975e\u76f4\u63a5\u6570\u503c\u9884\u6d4b\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u7535\u5546\u9700\u6c42\u9884\u6d4b\uff0c\u5df2\u81ea2025\u5e743\u6708\u8d77\u90e8\u7f72\u5230\u5b9e\u9645\u5de5\u4e1a\u7ba1\u9053\u4e2d\u3002"}}
{"id": "2602.07256", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07256", "abs": "https://arxiv.org/abs/2602.07256", "authors": ["Ruizhong Qiu", "Ting-Wei Li", "Gaotang Li", "Hanghang Tong"], "title": "Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning", "comment": "ICLR 2026", "summary": "Graph neural networks (GNNs) have emerged as a powerful tool for modeling graph-structured data. However, existing GNNs often struggle with heterophilic graphs, where connected nodes tend to have dissimilar features or labels. While numerous methods have been proposed to address this challenge, they primarily focus on architectural designs without directly targeting the root cause of the heterophily problem. These approaches still perform even worse than the simplest MLPs on challenging heterophilic datasets. For instance, our experiments show that 21 latest GNNs still fall behind the MLP on the Actor dataset. This critical challenge calls for an innovative approach to addressing graph heterophily beyond architectural designs. To bridge this gap, we propose and study a new and unexplored paradigm: directly increasing the graph homophily via a carefully designed graph transformation. In this work, we present a simple yet effective framework called GRAPHITE to address graph heterophily. To the best of our knowledge, this work is the first method that explicitly transforms the graph to directly improve the graph homophily. Stemmed from the exact definition of homophily, our proposed GRAPHITE creates feature nodes to facilitate homophilic message passing between nodes that share similar features. Furthermore, we both theoretically and empirically show that our proposed GRAPHITE significantly increases the homophily of originally heterophilic graphs, with only a slight increase in the graph size. Extensive experiments on challenging datasets demonstrate that our proposed GRAPHITE significantly outperforms state-of-the-art methods on heterophilic graphs while achieving comparable accuracy with state-of-the-art methods on homophilic graphs.", "AI": {"tldr": "\u63d0\u51faGRAPHITE\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u5efa\u7279\u5f81\u8282\u70b9\u76f4\u63a5\u63d0\u5347\u56fe\u540c\u8d28\u6027\uff0c\u89e3\u51b3\u5f02\u8d28\u56feGNN\u6027\u80fd\u5dee\u7684\u95ee\u9898", "motivation": "\u73b0\u6709GNN\u5728\u5f02\u8d28\u56fe\uff08\u8fde\u63a5\u8282\u70b9\u7279\u5f81/\u6807\u7b7e\u4e0d\u540c\uff09\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u4e0d\u5982\u7b80\u5355MLP\uff0c\u9700\u8981\u8d85\u8d8a\u67b6\u6784\u8bbe\u8ba1\u7684\u65b0\u65b9\u6cd5", "method": "\u63d0\u51faGRAPHITE\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u5efa\u7279\u5f81\u8282\u70b9\u4fc3\u8fdb\u76f8\u4f3c\u7279\u5f81\u8282\u70b9\u95f4\u7684\u540c\u8d28\u6d88\u606f\u4f20\u9012\uff0c\u76f4\u63a5\u63d0\u5347\u56fe\u540c\u8d28\u6027", "result": "\u5728\u5f02\u8d28\u56fe\u4e0a\u663e\u8457\u4f18\u4e8eSOTA\u65b9\u6cd5\uff0c\u5728\u540c\u8d28\u56fe\u4e0a\u8fbe\u5230\u53ef\u6bd4\u6027\u80fd\uff0c\u7406\u8bba\u8bc1\u660e\u80fd\u663e\u8457\u63d0\u5347\u56fe\u540c\u8d28\u6027", "conclusion": "GRAPHITE\u901a\u8fc7\u76f4\u63a5\u63d0\u5347\u56fe\u540c\u8d28\u6027\u7684\u65b0\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86GNN\u5728\u5f02\u8d28\u56fe\u4e0a\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898"}}
{"id": "2602.08003", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08003", "abs": "https://arxiv.org/abs/2602.08003", "authors": ["Yigit Turkmen", "Baturalp Buyukates", "Melih Bastopcu"], "title": "Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection", "comment": null, "summary": "Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even with many models, we model the correlated errors of the models using Gaussian-copula and show an information-theoretic error floor for the performance of the ensemble. Motivated by these, we propose a simple greedy mutual-information selection algorithm that estimates the required information terms directly from data and iteratively builds an ensemble under a query budget. We test our approach in two question answering datasets and one binary sentiment classification dataset: MEDMCQA, MMLU, and IMDB movie reviews. Across all datasets, we observe that our method consistently outperforms strong baselines under the same query budget.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u8d2a\u5fc3\u9009\u62e9\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u67e5\u8be2\u9884\u7b97\u9650\u5236\u4e0b\u6784\u5efa\u6700\u4f18\u7684LLM\u96c6\u6210\uff0c\u901a\u8fc7\u6700\u5927\u5316\u771f\u5b9e\u6807\u7b7e\u4e0e\u6240\u9009\u6a21\u578b\u9884\u6d4b\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u63d0\u5347\u96c6\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u96c6\u6210\u65b9\u6cd5\u4e2d\u6a21\u578b\u4e4b\u95f4\u901a\u5e38\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002\u9700\u8981\u89e3\u51b3\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u5982\u4f55\u9009\u62e9\u6700\u4f18\u6a21\u578b\u5b50\u96c6\u7684\u95ee\u9898\uff0c\u5e76\u89e3\u91ca\u4e3a\u4f55\u96c6\u6210\u6027\u80fd\u4f1a\u968f\u7740\u6a21\u578b\u6570\u91cf\u589e\u52a0\u800c\u9971\u548c\u3002", "method": "1) \u5c06\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u96c6\u6210\u9009\u62e9\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6700\u5927\u5316\u771f\u5b9e\u6807\u7b7e\u4e0e\u6240\u9009\u6a21\u578b\u9884\u6d4b\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff1b2) \u4f7f\u7528\u9ad8\u65af-\u8fde\u63a5\u51fd\u6570\u5efa\u6a21\u6a21\u578b\u95f4\u7684\u76f8\u5173\u8bef\u5dee\uff0c\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u89e3\u91ca\u6027\u80fd\u9971\u548c\u73b0\u8c61\uff1b3) \u63d0\u51fa\u8d2a\u5fc3\u4e92\u4fe1\u606f\u9009\u62e9\u7b97\u6cd5\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4f30\u8ba1\u6240\u9700\u4fe1\u606f\u91cf\uff0c\u5728\u67e5\u8be2\u9884\u7b97\u4e0b\u8fed\u4ee3\u6784\u5efa\u96c6\u6210\u3002", "result": "\u5728MEDMCQA\u3001MMLU\u548cIMDB\u7535\u5f71\u8bc4\u8bba\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u67e5\u8be2\u9884\u7b97\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u8d2a\u5fc3\u9009\u62e9\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u9884\u7b97\u7ea6\u675f\u4e0b\u7684LLM\u96c6\u6210\u9009\u62e9\u95ee\u9898\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u6846\u67b6\u89e3\u91ca\u4e86\u96c6\u6210\u6027\u80fd\u9971\u548c\u73b0\u8c61\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.07839", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07839", "abs": "https://arxiv.org/abs/2602.07839", "authors": ["Jiaxi Liu", "Yanzuo Jiang", "Guibin Zhang", "Zihan Zhang", "Heng Chang", "Zhenfei Yin", "Qibing Ren", "Junchi Yan"], "title": "TodoEvolve: Learning to Architect Agent Planning Systems", "comment": null, "summary": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.", "AI": {"tldr": "TodoEvolve\u662f\u4e00\u4e2a\u5143\u89c4\u5212\u8303\u5f0f\uff0c\u80fd\u591f\u81ea\u4e3b\u5408\u6210\u548c\u52a8\u6001\u4fee\u8ba2\u4efb\u52a1\u7279\u5b9a\u7684\u89c4\u5212\u67b6\u6784\uff0c\u901a\u8fc7\u7edf\u4e00\u7684PlanFactory\u8bbe\u8ba1\u7a7a\u95f4\u548cIGPO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u624b\u5de5\u8bbe\u8ba1\u7684\u89c4\u5212\u6a21\u5757\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u56fa\u5b9a\u3001\u624b\u5de5\u8bbe\u8ba1\u7684\u89c4\u5212\u7ed3\u6784\uff0c\u7f3a\u4e4f\u9002\u5e94\u5f00\u653e\u6027\u95ee\u9898\u7ed3\u6784\u591a\u6837\u6027\u7684\u7075\u6d3b\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u89c4\u5212\u67b6\u6784\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u6784\u5efaPlanFactory\u6a21\u5757\u5316\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u7edf\u4e00\u4e0d\u540c\u89c4\u5212\u8303\u5f0f\uff1b\u7136\u540e\u6536\u96c6\u9ad8\u8d28\u91cf\u89c4\u5212\u8f68\u8ff9\uff0c\u901a\u8fc7\u963b\u6297\u5f15\u5bfc\u504f\u597d\u4f18\u5316\uff08IGPO\uff09\u8bad\u7ec3Todo-14B\u6a21\u578b\uff0c\u8be5\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u9f13\u52b1\u751f\u6210\u6027\u80fd\u597d\u3001\u7a33\u5b9a\u4e14token\u9ad8\u6548\u7684\u89c4\u5212\u7cfb\u7edf\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTodoEvolve\u59cb\u7ec8\u8d85\u8d8a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u89c4\u5212\u6a21\u5757\uff0c\u540c\u65f6\u4fdd\u6301\u7ecf\u6d4e\u7684API\u6210\u672c\u548c\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "conclusion": "TodoEvolve\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5143\u89c4\u5212\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u4e3b\u751f\u6210\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u548c\u667a\u80fd\u4f53\u67b6\u6784\u7684\u89c4\u5212\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fa\u5b9a\u89c4\u5212\u7ed3\u6784\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.07749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07749", "abs": "https://arxiv.org/abs/2602.07749", "authors": ["Zhenyu Wu", "Yanxi Long", "Jian Li", "Hua Huang"], "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution", "comment": "ICML2026", "summary": "Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.", "AI": {"tldr": "Geo-coder\uff1a\u9996\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u6846\u67b6\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u548c\u5ea6\u91cf\u9a71\u52a8\u4ee3\u7801\u6f14\u5316\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u51e0\u4f55\u91cd\u5efa\uff0c\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u9886\u5148\u3002", "motivation": "\u7a0b\u5e8f\u4ee3\u7801\u4f5c\u4e3a\u8fde\u63a5\u89c6\u89c9\u4e0e\u903b\u8f91\u7684\u6865\u6881\uff0c\u4e3a\u901a\u8fc7\u51e0\u4f55\u64cd\u4f5c\u589e\u5f3a\u5927\u6a21\u578b\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u884c\u76d1\u7763\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73b0\u6709\u9006\u5411\u56fe\u5f62\u65b9\u6cd5\u5728\u51c6\u786e\u91cd\u5efa\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u65b9\u9762\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5e38\u5bfc\u81f4\u5173\u952e\u51e0\u4f55\u7ea6\u675f\u4e22\u5931\u6216\u7ed3\u6784\u5931\u771f\u3002", "method": "\u63d0\u51faGeo-coder\u2014\u2014\u9996\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u6846\u67b6\u3002\u65b9\u6cd5\u521b\u65b0\u6027\u5730\u5c06\u8fc7\u7a0b\u89e3\u8026\u4e3a\uff1a1\uff09\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\uff1b2\uff09\u5ea6\u91cf\u9a71\u52a8\u4ee3\u7801\u6f14\u5316\u3002\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u89c6\u89c9\u7b97\u5b50\u548c\u5927\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\u7cbe\u786e\u6355\u6349\u50cf\u7d20\u5750\u6807\u548c\u89c6\u89c9\u5c5e\u6027\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u5408\u6210-\u6e32\u67d3-\u9a8c\u8bc1\u95ed\u73af\uff0c\u53cc\u5411\u89c6\u89c9\u53cd\u9988\u9a71\u52a8\u4ee3\u7801\u81ea\u6821\u6b63\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGeo-coder\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u9886\u5148\u3002\u901a\u8fc7\u6709\u6548\u4fdd\u7559\u6838\u5fc3\u51e0\u4f55\u8bed\u4e49\uff0c\u91cd\u5efa\u56fe\u50cf\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u539f\u59cb\u56fe\u50cf\u76f8\u5f53\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u9c81\u68d2\u6027\u3002\u5f00\u6e90\u4e86\u57fa\u4e8eGeoCode\u6846\u67b6\u6784\u5efa\u7684Geo-coder\u6570\u636e\u96c6\uff081500+\u6837\u672c\uff09\u548cGeocodeLM\u6a21\u578b\u3002", "conclusion": "Geo-coder\u6210\u529f\u89e3\u51b3\u4e86\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u91cd\u5efa\u7684\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u636e\u548c\u6a21\u578b\u57fa\u7840\u3002\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u51e0\u4f55\u8bed\u4e49\u5b8c\u6574\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u3002"}}
{"id": "2602.07258", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.07258", "abs": "https://arxiv.org/abs/2602.07258", "authors": ["Wanru Guo", "Juan Xie", "Binbin Wang", "Weicong Chen", "Xiaoyi Lu", "Vipin Chaudhary", "Curtis Tatsuoka"], "title": "Robust Ultra-High-Dimensional Variable Selection With Correlated Structure Using Group Testing", "comment": "57 Pages, 5 Figures, 4 Tables", "summary": "Background: High-dimensional genomic data exhibit strong group correlation structures that challenge conventional feature selection methods, which often assume feature independence or rely on pre-defined pathways and are sensitive to outliers and model misspecification.\n  Methods: We propose the Dorfman screening framework, a multi-stage procedure that forms data-driven variable groups via hierarchical clustering, performs group and within-group hypothesis testing, and refines selection using elastic net or adaptive elastic net. Robust variants incorporate OGK-based covariance estimation, rank-based correlation, and Huber-weighted regression to handle contaminated and non-normal data.\n  Results: In simulations, Dorfman-Sparse-Adaptive-EN performed best under normal conditions, while Robust-OGK-Dorfman-Adaptive-EN showed clear advantages under data contamination, outperforming classical Dorfman and competing methods. Applied to NSCLC gene expression data for trametinib response, robust Dorfman methods achieved the lowest prediction errors and enriched recovery of clinically relevant genes.\n  Conclusions: The Dorfman framework provides an efficient and robust approach to genomic feature selection. Robust-OGK-Dorfman-Adaptive-EN offers strong performance under both ideal and contaminated conditions and scales to ultra-high-dimensional settings, making it well suited for modern genomic biomarker discovery.", "AI": {"tldr": "Dorfman\u7b5b\u9009\u6846\u67b6\uff1a\u901a\u8fc7\u5c42\u6b21\u805a\u7c7b\u5f62\u6210\u6570\u636e\u9a71\u52a8\u7684\u53d8\u91cf\u7ec4\uff0c\u8fdb\u884c\u7ec4\u5185\u548c\u7ec4\u95f4\u5047\u8bbe\u68c0\u9a8c\uff0c\u7ed3\u5408\u5f39\u6027\u7f51\u7edc\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u63d0\u4f9b\u7a33\u5065\u53d8\u4f53\u5904\u7406\u5f02\u5e38\u503c\u548c\u975e\u6b63\u6001\u6570\u636e\u3002", "motivation": "\u9ad8\u7ef4\u57fa\u56e0\u7ec4\u6570\u636e\u5b58\u5728\u5f3a\u70c8\u7684\u7ec4\u76f8\u5173\u7ed3\u6784\uff0c\u4f20\u7edf\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5047\u8bbe\u7279\u5f81\u72ec\u7acb\u6216\u4f9d\u8d56\u9884\u5b9a\u4e49\u901a\u8def\uff0c\u5bf9\u5f02\u5e38\u503c\u548c\u6a21\u578b\u8bef\u8bbe\u654f\u611f\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u3002", "method": "\u591a\u9636\u6bb5\u7a0b\u5e8f\uff1a1) \u901a\u8fc7\u5c42\u6b21\u805a\u7c7b\u5f62\u6210\u6570\u636e\u9a71\u52a8\u7684\u53d8\u91cf\u7ec4\uff1b2) \u8fdb\u884c\u7ec4\u548c\u7ec4\u5185\u5047\u8bbe\u68c0\u9a8c\uff1b3) \u4f7f\u7528\u5f39\u6027\u7f51\u7edc\u6216\u81ea\u9002\u5e94\u5f39\u6027\u7f51\u7edc\u8fdb\u884c\u7ec6\u5316\u9009\u62e9\uff1b\u7a33\u5065\u53d8\u4f53\u5305\u542bOGK\u534f\u65b9\u5dee\u4f30\u8ba1\u3001\u79e9\u76f8\u5173\u548cHuber\u52a0\u6743\u56de\u5f52\u3002", "result": "\u5728\u6a21\u62df\u4e2d\uff0cDorfman-Sparse-Adaptive-EN\u5728\u6b63\u6001\u6761\u4ef6\u4e0b\u8868\u73b0\u6700\u4f73\uff0cRobust-OGK-Dorfman-Adaptive-EN\u5728\u6570\u636e\u6c61\u67d3\u6761\u4ef6\u4e0b\u4f18\u52bf\u660e\u663e\u3002\u5e94\u7528\u4e8eNSCLC\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u65f6\uff0c\u7a33\u5065Dorfman\u65b9\u6cd5\u83b7\u5f97\u6700\u4f4e\u9884\u6d4b\u8bef\u5dee\u5e76\u5bcc\u96c6\u4e34\u5e8a\u76f8\u5173\u57fa\u56e0\u3002", "conclusion": "Dorfman\u6846\u67b6\u4e3a\u57fa\u56e0\u7ec4\u7279\u5f81\u9009\u62e9\u63d0\u4f9b\u4e86\u9ad8\u6548\u7a33\u5065\u7684\u65b9\u6cd5\u3002Robust-OGK-Dorfman-Adaptive-EN\u5728\u7406\u60f3\u548c\u6c61\u67d3\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u6269\u5c55\u5230\u8d85\u9ad8\u7ef4\u8bbe\u7f6e\uff0c\u9002\u5408\u73b0\u4ee3\u57fa\u56e0\u7ec4\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3002"}}
{"id": "2602.08026", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08026", "abs": "https://arxiv.org/abs/2602.08026", "authors": ["Arya Akhavan", "David Janz", "Csaba Szepesv\u00e1ri"], "title": "Sharp analysis of linear ensemble sampling", "comment": null, "summary": "We analyse linear ensemble sampling (ES) with standard Gaussian perturbations in stochastic linear bandits. We show that for ensemble size $m=\u0398(d\\log n)$, ES attains $\\tilde O(d^{3/2}\\sqrt n)$ high-probability regret, closing the gap to the Thompson sampling benchmark while keeping computation comparable. The proof brings a new perspective on randomized exploration in linear bandits by reducing the analysis to a time-uniform exceedance problem for $m$ independent Brownian motions. Intriguingly, this continuous-time lens is not forced; it appears natural--and perhaps necessary: the discrete-time problem seems to be asking for a continuous-time solution, and we know of no other way to obtain a sharp ES bound.", "AI": {"tldr": "\u7ebf\u6027\u96c6\u6210\u91c7\u6837(ES)\u5728\u9ad8\u65af\u6270\u52a8\u4e0b\u7684\u968f\u673a\u7ebf\u6027bandit\u4e2d\uff0c\u5f53\u96c6\u6210\u89c4\u6a21m=\u0398(d log n)\u65f6\uff0c\u80fd\u8fbe\u5230$\\tilde O(d^{3/2}\\sqrt n)$\u7684\u9ad8\u6982\u7387\u9057\u61be\u754c\uff0c\u4e0eThompson\u91c7\u6837\u57fa\u51c6\u5339\u914d\u4e14\u8ba1\u7b97\u91cf\u76f8\u5f53\u3002", "motivation": "\u7814\u7a76\u7ebf\u6027\u96c6\u6210\u91c7\u6837\u5728\u968f\u673a\u7ebf\u6027bandit\u4e2d\u7684\u6027\u80fd\uff0c\u65e8\u5728\u586b\u8865\u4e0eThompson\u91c7\u6837\u57fa\u51c6\u4e4b\u95f4\u7684\u7406\u8bba\u5dee\u8ddd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u9ad8\u65af\u6270\u52a8\u8fdb\u884c\u7ebf\u6027\u96c6\u6210\u91c7\u6837\uff0c\u901a\u8fc7\u5c06\u5206\u6790\u7b80\u5316\u4e3am\u4e2a\u72ec\u7acb\u5e03\u6717\u8fd0\u52a8\u7684\u65f6\u4e00\u81f4\u8d85\u8d8a\u95ee\u9898\uff0c\u91c7\u7528\u8fde\u7eed\u65f6\u95f4\u89c6\u89d2\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f53\u96c6\u6210\u89c4\u6a21m=\u0398(d log n)\u65f6\uff0cES\u83b7\u5f97$\\tilde O(d^{3/2}\\sqrt n)$\u7684\u9ad8\u6982\u7387\u9057\u61be\u754c\uff0c\u4e0eThompson\u91c7\u6837\u57fa\u51c6\u5339\u914d\uff0c\u8ba1\u7b97\u91cf\u76f8\u5f53\u3002", "conclusion": "\u7ebf\u6027\u96c6\u6210\u91c7\u6837\u5728\u9002\u5f53\u96c6\u6210\u89c4\u6a21\u4e0b\u80fd\u8fbe\u5230Thompson\u91c7\u6837\u7684\u7406\u8bba\u6027\u80fd\uff0c\u8fde\u7eed\u65f6\u95f4\u5206\u6790\u89c6\u89d2\u5bf9\u4e8e\u83b7\u5f97\u5c16\u9510\u8fb9\u754c\u4f3c\u4e4e\u662f\u81ea\u7136\u4e14\u5fc5\u8981\u7684\u3002"}}
{"id": "2602.07425", "categories": ["cs.LG", "cs.CL", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07425", "abs": "https://arxiv.org/abs/2602.07425", "authors": ["Dingzhi Yu", "Hongyi Tao", "Yuanyu Wan", "Luo Luo", "Lijun Zhang"], "title": "Sign-Based Optimizers Are Effective Under Heavy-Tailed Noise", "comment": "Code available at https://github.com/Dingzhen230/Heavy-tailed-Noise-in-LLMs", "summary": "While adaptive gradient methods are the workhorse of modern machine learning, sign-based optimization algorithms such as Lion and Muon have recently demonstrated superior empirical performance over AdamW in training large language models (LLM). However, a theoretical understanding of why sign-based updates outperform variance-adapted methods remains elusive. In this paper, we aim to bridge the gap between theory and practice through the lens of heavy-tailed gradient noise, a phenomenon frequently observed in language modeling tasks. Theoretically, we introduce a novel generalized heavy-tailed noise condition that captures the behavior of LLMs more accurately than standard finite variance assumptions. Under this noise model, we establish sharp convergence rates of SignSGD and Lion for generalized smooth function classes, matching or surpassing previous best-known bounds. Furthermore, we extend our analysis to Muon and Muonlight, providing what is, to our knowledge, the first rigorous analysis of matrix optimization under heavy-tailed stochasticity. These results offer a strong theoretical justification for the empirical superiority of sign-based optimizers, showcasing that they are naturally suited to handle the noisy gradients associated with heavy tails. Empirically, LLM pretraining experiments validate our theoretical insights and confirm that our proposed noise models are well-aligned with practice.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u89e3\u91ca\u4e86\u57fa\u4e8e\u7b26\u53f7\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u5982Lion\u3001Muon\uff09\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4f18\u4e8eAdamW\u7b49\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u4f9b\u4e86\u9996\u4e2a\u5bf9\u77e9\u9635\u4f18\u5316\u5728\u91cd\u5c3e\u968f\u673a\u6027\u4e0b\u7684\u4e25\u683c\u5206\u6790\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u7b26\u53f7\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u5982Lion\u3001Muon\uff09\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u8868\u73b0\u51fa\u4f18\u4e8eAdamW\u7684\u5b9e\u8bc1\u6027\u80fd\uff0c\u4f46\u5176\u7406\u8bba\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u8fd9\u4e00\u5728\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u5e38\u89c1\u7684\u73b0\u8c61\uff0c\u6765\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e7f\u4e49\u91cd\u5c3e\u566a\u58f0\u6761\u4ef6\uff0c\u80fd\u6bd4\u6807\u51c6\u6709\u9650\u65b9\u5dee\u5047\u8bbe\u66f4\u51c6\u786e\u5730\u6355\u6349\u5927\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\uff1b2. \u5728\u8be5\u566a\u58f0\u6a21\u578b\u4e0b\uff0c\u4e3a\u5e7f\u4e49\u5e73\u6ed1\u51fd\u6570\u7c7b\u5efa\u7acb\u4e86SignSGD\u548cLion\u7684\u5c16\u9510\u6536\u655b\u7387\uff1b3. \u5c06\u5206\u6790\u6269\u5c55\u5230Muon\u548cMuonlight\uff0c\u63d0\u4f9b\u4e86\u9996\u4e2a\u5bf9\u77e9\u9635\u4f18\u5316\u5728\u91cd\u5c3e\u968f\u673a\u6027\u4e0b\u7684\u4e25\u683c\u5206\u6790\u3002", "result": "1. \u7406\u8bba\u5206\u6790\u8868\u660e\u57fa\u4e8e\u7b26\u53f7\u7684\u4f18\u5316\u7b97\u6cd5\u5728\u91cd\u5c3e\u566a\u58f0\u6761\u4ef6\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u6536\u655b\u6027\u80fd\uff1b2. \u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u89c1\u89e3\uff0c\u5e76\u786e\u8ba4\u63d0\u51fa\u7684\u566a\u58f0\u6a21\u578b\u4e0e\u5b9e\u8df5\u76f8\u7b26\uff1b3. \u4e3a\u57fa\u4e8e\u7b26\u53f7\u7684\u4f18\u5316\u5668\u5728\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u6027\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u57fa\u4e8e\u7b26\u53f7\u7684\u4f18\u5316\u7b97\u6cd5\u5929\u7136\u9002\u5408\u5904\u7406\u4e0e\u91cd\u5c3e\u76f8\u5173\u7684\u566a\u58f0\u68af\u5ea6\uff0c\u8fd9\u89e3\u91ca\u4e86\u5b83\u4eec\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4f18\u4e8e\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u7684\u5b9e\u8bc1\u8868\u73b0\u3002\u672c\u6587\u7684\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e3a\u8fd9\u4e00\u73b0\u8c61\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.07842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07842", "abs": "https://arxiv.org/abs/2602.07842", "authors": ["Yuhan Wang", "Shiyu Ni", "Zhikai Ding", "Zihang Zhan", "Yuanzi Li", "Keping Bi"], "title": "Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers", "comment": null, "summary": "Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMACE\u57fa\u51c6\u6765\u7814\u7a76\u591a\u7b54\u6848\u573a\u666f\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u95ee\u9898\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u7b54\u6848\u60c5\u51b5\u4e0b\u4f1a\u7cfb\u7edf\u6027\u5730\u4f4e\u4f30\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u63d0\u51faSCA\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u7b54\u6848\u95ee\u7b54\u573a\u666f\u7814\u7a76\uff0c\u4f46\u5728\u5b58\u5728\u591a\u4e2a\u6709\u6548\u7b54\u6848\u7684\u60c5\u51b5\u4e0b\u4f1a\u5931\u6548\uff0c\u56e0\u4e3a\u6b63\u786e\u7b54\u6848\u4e4b\u95f4\u7684\u5206\u6b67\u4f1a\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u88ab\u7cfb\u7edf\u6027\u4f4e\u4f30\u3002", "method": "1) \u5f15\u5165MACE\u57fa\u51c6\uff1a\u5305\u542b12,000\u4e2a\u4e8b\u5b9e\u6027\u95ee\u9898\uff0c\u6db5\u76d66\u4e2a\u9886\u57df\uff0c\u5177\u6709\u4e0d\u540c\u6570\u91cf\u7684\u6b63\u786e\u7b54\u6848\uff1b2) \u63d0\u51fa\u8bed\u4e49\u7f6e\u4fe1\u5ea6\u805a\u5408(SCA)\uff1a\u901a\u8fc7\u5bf9\u591a\u4e2a\u9ad8\u6982\u7387\u91c7\u6837\u54cd\u5e94\u8fdb\u884c\u7f6e\u4fe1\u5ea6\u805a\u5408\u6765\u89e3\u51b3\u591a\u7b54\u6848\u6821\u51c6\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) \u51c6\u786e\u7387\u968f\u7b54\u6848\u57fa\u6570\u589e\u52a0\u800c\u63d0\u9ad8\uff1b2) \u4f30\u8ba1\u7f6e\u4fe1\u5ea6\u5374\u6301\u7eed\u4e0b\u964d\uff1b3) \u6df7\u5408\u7b54\u6848\u6570\u91cf\u7684\u95ee\u9898\u5b58\u5728\u4e25\u91cd\u6821\u51c6\u9519\u8bef\uff1b4) SCA\u5728\u6df7\u5408\u7b54\u6848\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6821\u51c6\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5355\u7b54\u6848\u95ee\u9898\u4e0a\u4fdd\u6301\u5f3a\u6821\u51c6\u80fd\u529b\u3002", "conclusion": "\u591a\u7b54\u6848\u573a\u666f\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff0cSCA\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6821\u51c6\u65b9\u6cd5\u5728\u591a\u7b54\u6848\u60c5\u51b5\u4e0b\u7684\u5931\u6548\u95ee\u9898\uff0c\u4e3aLLM\u7684\u53ef\u9760\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2602.07754", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07754", "abs": "https://arxiv.org/abs/2602.07754", "authors": ["Bahare Riahi", "Veronica Catete"], "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency", "comment": "13 pages, 3 figures", "summary": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5927\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u5b66\u751f\u5bf9AI\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u4eba\u5316\u8868\u793a\u62c5\u5fe7\uff0c\u5efa\u8baeAI\u7cfb\u7edf\u5e94\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e86\u89e3\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u611f\u77e5\uff0c\u7279\u522b\u662f\u5173\u6ce8AI\u8bc4\u5206\u7684\u516c\u5e73\u6027\u3001\u4fe1\u4efb\u5ea6\u3001\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4ee5\u4fc3\u8fdb\u6559\u80b2\u73af\u5883\u4e2d\u66f4\u7b26\u5408\u4f26\u7406\u7684AI\u8bc4\u4f30\u5b9e\u8df5", "method": "\u91c7\u7528\u57fa\u4e8eJobin(2019)\u4f26\u7406\u539f\u5219\u6846\u67b6\u7684\u7814\u7a76\u8bbe\u8ba1\uff0c\u6bd4\u8f83AI\u751f\u6210\u53cd\u9988\u4e0e\u539f\u59cb\u4eba\u5de5\u8bc4\u5206\u53cd\u9988\uff0c\u7814\u7a76\u5bf9\u8c61\u4e3a27\u540d\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\uff0c\u9488\u5bf9\u5757\u7f16\u7a0b\u671f\u672b\u9879\u76ee\u8fdb\u884c\u5206\u6790", "result": "\u7814\u7a76\u53d1\u73b0\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u4e3b\u8981\u62c5\u5fe7\u5305\u62ec\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u4eba\u5316\u80fd\u529b\uff0cAI\u7cfb\u7edf\u5728\u7075\u6d3b\u6027\u548c\u540c\u7406\u5fc3\u65b9\u9762\u5b58\u5728\u4e0d\u8db3", "conclusion": "\u7ed3\u8bba\u8ba4\u4e3a\u516c\u5e73\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u5e94\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u3001\u7075\u6d3b\u6027\u548c\u540c\u7406\u5fc3\uff0c\u5efa\u8baeAI\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177\uff0c\u4e3a\u8bbe\u8ba1\u4eba\u6027\u5316AI\u5b66\u4e60\u73af\u5883\u63d0\u4f9b\u539f\u5219\u6307\u5bfc"}}
{"id": "2602.07263", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07263", "abs": "https://arxiv.org/abs/2602.07263", "authors": ["Kevin Li", "Dibyadeep Saha", "Avni Kanodia", "Fan Lai"], "title": "tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models", "comment": null, "summary": "As Low-Rank Adaptation (LoRA) becomes the standard approach for efficiently fine-tuning large language models (LLMs), shared clusters increasingly execute many concurrent LoRA training jobs over the same frozen backbone. While recent advances enable batching (co-locating) multiple adapters during serving, efficient training-time co-location of heterogeneous LoRA adapters presents unique challenges. Jobs often differ in adapter rank, batch size, and resource allocation, and na\u00efve batching can introduce synchronization stalls, communication overheads, and per-job slowdowns that are worse than executing independently. We introduce tLoRA, a framework that enables efficient batch training of multiple LoRA jobs. tLoRA fuses adapters that share the same base model into an elastic shared super-model, exploiting existing distributed training frameworks to derive parallelism plans that share resources effectively. At the kernel level, tLoRA employs a fused LoRA kernel that adaptively reconstructs low-rank computation tiles and schedules rank-aware nano-batches to maximize overlap between computation and communication across adapters. At the scheduling layer, tLoRA incorporates an online, residual-capacity-aware scheduler that adaptively groups jobs to maximize collective throughput. Evaluations using real-world cluster traces demonstrate that tLoRA improves training throughput by 1.2--1.8x, job training completion time by 2.3--5.4x, and GPU utilization by 37%.", "AI": {"tldr": "tLoRA\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u6279\u91cf\u8bad\u7ec3\u591a\u4e2aLoRA\u9002\u914d\u5668\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5171\u4eab\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u9002\u914d\u5668\u878d\u5408\u4e3a\u5f39\u6027\u5171\u4eab\u8d85\u7ea7\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u878d\u5408\u5185\u6838\u548c\u667a\u80fd\u8c03\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548cGPU\u5229\u7528\u7387\u3002", "motivation": "\u968f\u7740LoRA\u6210\u4e3a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6807\u51c6\u65b9\u6cd5\uff0c\u5171\u4eab\u96c6\u7fa4\u4e2d\u9700\u8981\u540c\u65f6\u6267\u884c\u8bb8\u591a\u57fa\u4e8e\u76f8\u540c\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\u7684LoRA\u8bad\u7ec3\u4efb\u52a1\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3\u65f6\u6279\u91cf\u5904\u7406\u5f02\u6784LoRA\u9002\u914d\u5668\u9762\u4e34\u6311\u6218\uff1a\u4efb\u52a1\u5728\u9002\u914d\u5668\u79e9\u3001\u6279\u5927\u5c0f\u548c\u8d44\u6e90\u5206\u914d\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u7b80\u5355\u7684\u6279\u5904\u7406\u4f1a\u5bfc\u81f4\u540c\u6b65\u5ef6\u8fdf\u3001\u901a\u4fe1\u5f00\u9500\u548c\u4efb\u52a1\u51cf\u901f\u7b49\u95ee\u9898\u3002", "method": "tLoRA\u91c7\u7528\u53cc\u5c42\u65b9\u6cd5\uff1a1\uff09\u5185\u6838\u5c42\uff1a\u4f7f\u7528\u878d\u5408LoRA\u5185\u6838\uff0c\u81ea\u9002\u5e94\u91cd\u6784\u4f4e\u79e9\u8ba1\u7b97\u5757\u5e76\u8c03\u5ea6\u79e9\u611f\u77e5\u7684\u7eb3\u7c73\u6279\u6b21\uff0c\u6700\u5927\u5316\u8de8\u9002\u914d\u5668\u7684\u8ba1\u7b97\u4e0e\u901a\u4fe1\u91cd\u53e0\uff1b2\uff09\u8c03\u5ea6\u5c42\uff1a\u91c7\u7528\u5728\u7ebf\u3001\u5269\u4f59\u5bb9\u91cf\u611f\u77e5\u7684\u8c03\u5ea6\u5668\uff0c\u81ea\u9002\u5e94\u5206\u7ec4\u4efb\u52a1\u4ee5\u6700\u5927\u5316\u96c6\u4f53\u541e\u5410\u91cf\u3002\u6846\u67b6\u5c06\u5171\u4eab\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u9002\u914d\u5668\u878d\u5408\u4e3a\u5f39\u6027\u5171\u4eab\u8d85\u7ea7\u6a21\u578b\uff0c\u5229\u7528\u73b0\u6709\u5206\u5e03\u5f0f\u8bad\u7ec3\u6846\u67b6\u5b9e\u73b0\u6709\u6548\u7684\u8d44\u6e90\u5171\u4eab\u5e76\u884c\u8ba1\u5212\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u96c6\u7fa4\u8f68\u8ff9\u7684\u8bc4\u4f30\u663e\u793a\uff0ctLoRA\u5c06\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.2-1.8\u500d\uff0c\u4efb\u52a1\u8bad\u7ec3\u5b8c\u6210\u65f6\u95f4\u7f29\u77ed2.3-5.4\u500d\uff0cGPU\u5229\u7528\u7387\u63d0\u9ad837%\u3002", "conclusion": "tLoRA\u6210\u529f\u89e3\u51b3\u4e86\u591a\u4e2a\u5f02\u6784LoRA\u9002\u914d\u5668\u5e76\u53d1\u8bad\u7ec3\u65f6\u7684\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u878d\u5408\u67b6\u6784\u548c\u667a\u80fd\u8c03\u5ea6\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96c6\u7fa4\u8d44\u6e90\u5229\u7528\u7387\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21LoRA\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08105", "categories": ["cs.LG", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08105", "abs": "https://arxiv.org/abs/2602.08105", "authors": ["Paarth Gulati", "Eslam Abdelaleem", "Audrey Sederberg", "Ilya Nemenman"], "title": "Mutual information and task-relevant latent dimensionality", "comment": null, "summary": "Estimating the dimensionality of the latent representation needed for prediction -- the task-relevant dimension -- is a difficult, largely unsolved problem with broad scientific applications. We cast it as an Information Bottleneck question: what embedding bottleneck dimension is sufficient to compress predictor and predicted views while preserving their mutual information (MI). This repurposes neural MI estimators for dimensionality estimation. We show that standard neural estimators with separable/bilinear critics systematically inflate the inferred dimension, and we address this by introducing a hybrid critic that retains an explicit dimensional bottleneck while allowing flexible nonlinear cross-view interactions, thereby preserving the latent geometry. We further propose a one-shot protocol that reads off the effective dimension from a single over-parameterized hybrid model, without sweeping over bottleneck sizes. We validate the approach on synthetic problems with known task-relevant dimension. We extend the approach to intrinsic dimensionality by constructing paired views of a single dataset, enabling comparison with classical geometric dimension estimators. In noisy regimes where those estimators degrade, our approach remains reliable. Finally, we demonstrate the utility of the method on multiple physics datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u7684\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u6279\u8bc4\u5668\u89e3\u51b3\u4f20\u7edf\u795e\u7ecf\u4f30\u8ba1\u5668\u9ad8\u4f30\u7ef4\u5ea6\u7684\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u5355\u6b21\u534f\u8bae\u76f4\u63a5\u4ece\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u4e2d\u8bfb\u53d6\u6709\u6548\u7ef4\u5ea6", "motivation": "\u4f30\u8ba1\u9884\u6d4b\u6240\u9700\u7684\u6f5c\u5728\u8868\u793a\u7ef4\u5ea6\uff08\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\uff09\u662f\u4e00\u4e2a\u56f0\u96be\u4e14\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5728\u79d1\u5b66\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u5c06\u7ef4\u5ea6\u4f30\u8ba1\u8f6c\u5316\u4e3a\u4fe1\u606f\u74f6\u9888\u95ee\u9898\uff1a\u5bfb\u627e\u80fd\u591f\u538b\u7f29\u9884\u6d4b\u53d8\u91cf\u548c\u88ab\u9884\u6d4b\u53d8\u91cf\u89c6\u56fe\u540c\u65f6\u4fdd\u6301\u5b83\u4eec\u4e92\u4fe1\u606f\u7684\u6700\u5c0f\u5d4c\u5165\u74f6\u9888\u7ef4\u5ea6\u3002\u5f15\u5165\u6df7\u5408\u6279\u8bc4\u5668\uff0c\u65e2\u4fdd\u7559\u663e\u5f0f\u7ef4\u5ea6\u74f6\u9888\uff0c\u53c8\u5141\u8bb8\u7075\u6d3b\u7684\u975e\u7ebf\u6027\u8de8\u89c6\u56fe\u4ea4\u4e92\u3002\u63d0\u51fa\u5355\u6b21\u534f\u8bae\uff0c\u76f4\u63a5\u4ece\u5355\u4e2a\u8fc7\u53c2\u6570\u5316\u6df7\u5408\u6a21\u578b\u4e2d\u8bfb\u53d6\u6709\u6548\u7ef4\u5ea6\uff0c\u65e0\u9700\u626b\u63cf\u74f6\u9888\u5927\u5c0f\u3002", "result": "\u5728\u5df2\u77e5\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\u7684\u5408\u6210\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6269\u5c55\u5230\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\uff0c\u5728\u566a\u58f0\u73af\u5883\u4e0b\u6bd4\u4f20\u7edf\u51e0\u4f55\u7ef4\u5ea6\u4f30\u8ba1\u5668\u66f4\u53ef\u9760\u3002\u5728\u591a\u4e2a\u7269\u7406\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u6846\u67b6\u548c\u6df7\u5408\u6279\u8bc4\u5668\u8bbe\u8ba1\uff0c\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u795e\u7ecf\u4f30\u8ba1\u5668\u9ad8\u4f30\u7ef4\u5ea6\u7684\u95ee\u9898\uff0c\u5e76\u5728\u566a\u58f0\u73af\u5883\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.07909", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07909", "abs": "https://arxiv.org/abs/2602.07909", "authors": ["Taolin Zhang", "Hang Guo", "Wang Lu", "Tao Dai", "Shu-Tao Xia", "Jindong Wang"], "title": "SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization", "comment": "ICLR2026", "summary": "As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$\u03c4$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.", "AI": {"tldr": "SparseEval\uff1a\u4e00\u79cd\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u951a\u70b9\u6743\u91cd\u548c\u8fed\u4ee3\u7cbe\u5316\u7b56\u7565\u7684\u9ad8\u6548LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u7528MLP\u5904\u7406\u7a00\u758f\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u7684\u8ba1\u7b97\u6210\u672c\u6025\u5267\u589e\u52a0\uff0c\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u5927\u91cf\u63a8\u7406\u6837\u672c\uff0c\u5bfc\u81f4\u9ad8\u6602\u7684\u8ba1\u7b97\u5f00\u9500", "method": "\u5c06\u9ad8\u6548\u57fa\u51c6\u6d4b\u8bd5\u5efa\u6a21\u4e3a\u7a00\u758f\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faSparseEval\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u951a\u70b9\u6743\u91cd\uff1b2) \u91c7\u7528\u8fed\u4ee3\u7cbe\u5316\u7b56\u7565\u9009\u62e9\u951a\u70b9\uff1b3) \u5229\u7528MLP\u5904\u7406\u7a00\u758f\u4f18\u5316\uff1b4) \u63d0\u51fa\u951a\u70b9\u91cd\u8981\u6027\u5206\u6570\u548c\u5019\u9009\u91cd\u8981\u6027\u5206\u6570\u8fdb\u884c\u4efb\u52a1\u611f\u77e5\u7cbe\u5316", "result": "\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f4e\u4f30\u8ba1\u8bef\u5dee\u548c\u9ad8Kendall's \u03c4\u76f8\u5173\u6027\uff0c\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c", "conclusion": "SparseEval\u901a\u8fc7\u7a00\u758f\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86LLM\u8bc4\u4f30\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u9ad8\u6548\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2602.07755", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07755", "abs": "https://arxiv.org/abs/2602.07755", "authors": ["Yiming Xiong", "Shengran Hu", "Jeff Clune"], "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs", "comment": null, "summary": "The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms. Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.", "AI": {"tldr": "ALMA\u6846\u67b6\u901a\u8fc7\u5143\u5b66\u4e60\u81ea\u52a8\u751f\u6210\u5185\u5b58\u8bbe\u8ba1\uff0c\u66ff\u4ee3\u4eba\u5de5\u8bbe\u8ba1\uff0c\u4f7f\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u5728\u4e0d\u540c\u9886\u57df\u6301\u7eed\u5b66\u4e60", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u65e0\u72b6\u6001\u6027\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u73b0\u6709\u5185\u5b58\u8bbe\u8ba1\u591a\u4e3a\u4eba\u5de5\u8bbe\u8ba1\u4e14\u56fa\u5b9a\uff0c\u96be\u4ee5\u9002\u5e94\u771f\u5b9e\u4efb\u52a1\u7684\u591a\u6837\u6027\u548c\u975e\u5e73\u7a33\u6027", "method": "\u4f7f\u7528\u5143\u4ee3\u7406\u5728\u53ef\u6267\u884c\u4ee3\u7801\u7a7a\u95f4\u4e2d\u641c\u7d22\u5185\u5b58\u8bbe\u8ba1\uff0c\u5305\u62ec\u6570\u636e\u5e93\u6a21\u5f0f\u53ca\u5176\u68c0\u7d22\u548c\u66f4\u65b0\u673a\u5236\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u53d1\u73b0\u4efb\u610f\u5185\u5b58\u8bbe\u8ba1", "result": "\u5728\u56db\u4e2a\u987a\u5e8f\u51b3\u7b56\u9886\u57df\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5b66\u4e60\u5230\u7684\u5185\u5b58\u8bbe\u8ba1\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u8bbe\u8ba1\u5185\u5b58\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u7ecf\u9a8c\u5b66\u4e60", "conclusion": "ALMA\u4ee3\u8868\u4e86\u8fc8\u5411\u81ea\u6211\u6539\u8fdbAI\u7cfb\u7edf\u7684\u4e00\u6b65\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u5b66\u4e60\u6210\u4e3a\u81ea\u9002\u5e94\u7684\u6301\u7eed\u5b66\u4e60\u8005\uff0c\u524d\u63d0\u662f\u5b89\u5168\u5f00\u53d1\u548c\u90e8\u7f72"}}
{"id": "2602.07265", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07265", "abs": "https://arxiv.org/abs/2602.07265", "authors": ["Daniil Vankov", "Nikita Ivkin", "Kyle Ulrich", "Xiang Song", "Ashish Khetan", "George Karypis"], "title": "XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are increasingly used to efficiently scale large language models. However, in production inference, request batching and speculative decoding significantly amplify expert activation, eroding these efficiency benefits. We address this issue by modeling batch-aware expert selection as a modular optimization problem and designing efficient greedy algorithms for different deployment settings. The proposed method, namely XShare, requires no retraining and dynamically adapts to each batch by maximizing the total gating score of selected experts. It reduces expert activation by up to 30% under standard batching, cuts peak GPU load by up to 3x in expert-parallel deployments, and achieves up to 14% throughput gains in speculative decoding via hierarchical, correlation-aware expert selection even if requests in a batch drawn from heterogeneous datasets.", "AI": {"tldr": "XShare\u662f\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u52a8\u6001\u4e13\u5bb6\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6279\u5904\u7406\u4e2d\u7684\u4e13\u5bb6\u6fc0\u6d3b\u6765\u63d0\u5347MoE\u6a21\u578b\u63a8\u7406\u6548\u7387\uff0c\u51cf\u5c11\u4e13\u5bb6\u6fc0\u6d3b\u8fbe30%\uff0c\u964d\u4f4eGPU\u5cf0\u503c\u8d1f\u8f7d3\u500d\uff0c\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u5b9e\u73b014%\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "MoE\u67b6\u6784\u867d\u7136\u80fd\u9ad8\u6548\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5728\u751f\u4ea7\u63a8\u7406\u4e2d\uff0c\u8bf7\u6c42\u6279\u5904\u7406\u548c\u63a8\u6d4b\u89e3\u7801\u4f1a\u663e\u8457\u589e\u52a0\u4e13\u5bb6\u6fc0\u6d3b\uff0c\u524a\u5f31\u6548\u7387\u4f18\u52bf\u3002\u9700\u8981\u89e3\u51b3\u6279\u5904\u7406\u611f\u77e5\u7684\u4e13\u5bb6\u9009\u62e9\u95ee\u9898\u3002", "method": "\u5c06\u6279\u5904\u7406\u611f\u77e5\u7684\u4e13\u5bb6\u9009\u62e9\u5efa\u6a21\u4e3a\u6a21\u5757\u5316\u4f18\u5316\u95ee\u9898\uff0c\u8bbe\u8ba1\u9488\u5bf9\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u7684\u9ad8\u6548\u8d2a\u5fc3\u7b97\u6cd5\u3002XShare\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u901a\u8fc7\u6700\u5927\u5316\u9009\u5b9a\u4e13\u5bb6\u7684\u603b\u95e8\u63a7\u5206\u6570\u6765\u52a8\u6001\u9002\u5e94\u6bcf\u4e2a\u6279\u5904\u7406\u3002", "result": "\u5728\u6807\u51c6\u6279\u5904\u7406\u4e0b\u51cf\u5c11\u4e13\u5bb6\u6fc0\u6d3b\u8fbe30%\uff1b\u5728\u4e13\u5bb6\u5e76\u884c\u90e8\u7f72\u4e2d\u964d\u4f4eGPU\u5cf0\u503c\u8d1f\u8f7d\u8fbe3\u500d\uff1b\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u901a\u8fc7\u5206\u5c42\u3001\u76f8\u5173\u6027\u611f\u77e5\u7684\u4e13\u5bb6\u9009\u62e9\u5b9e\u73b014%\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5373\u4f7f\u6279\u5904\u7406\u8bf7\u6c42\u6765\u81ea\u5f02\u6784\u6570\u636e\u96c6\u3002", "conclusion": "XShare\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u5728\u751f\u4ea7\u63a8\u7406\u4e2d\u7684\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u6279\u5904\u7406\u611f\u77e5\u7684\u4e13\u5bb6\u9009\u62e9\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2602.08142", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08142", "abs": "https://arxiv.org/abs/2602.08142", "authors": ["H. Martin Gillis", "Isaac Xu", "Thomas Trappenberg"], "title": "Variance-Gated Ensembles: An Epistemic-Aware Framework for Uncertainty Estimation", "comment": null, "summary": "Machine learning applications require fast and reliable per-sample uncertainty estimation. A common approach is to use predictive distributions from Bayesian or approximation methods and additively decompose uncertainty into aleatoric (i.e., data-related) and epistemic (i.e., model-related) components. However, additive decomposition has recently been questioned, with evidence that it breaks down when using finite-ensemble sampling and/or mismatched predictive distributions. This paper introduces Variance-Gated Ensembles (VGE), an intuitive, differentiable framework that injects epistemic sensitivity via a signal-to-noise gate computed from ensemble statistics. VGE provides: (i) a Variance-Gated Margin Uncertainty (VGMU) score that couples decision margins with ensemble predictive variance; and (ii) a Variance-Gated Normalization (VGN) layer that generalizes the variance-gated uncertainty mechanism to training via per-class, learnable normalization of ensemble member probabilities. We derive closed-form vector-Jacobian products enabling end-to-end training through ensemble sample mean and variance. VGE matches or exceeds state-of-the-art information-theoretic baselines while remaining computationally efficient. As a result, VGE provides a practical and scalable approach to epistemic-aware uncertainty estimation in ensemble models. An open-source implementation is available at: https://github.com/nextdevai/vge.", "AI": {"tldr": "VGE\u63d0\u51fa\u65b9\u5dee\u95e8\u63a7\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u7edf\u8ba1\u91cf\u8ba1\u7b97\u4fe1\u566a\u6bd4\u95e8\u63a7\u6765\u6ce8\u5165\u8ba4\u77e5\u654f\u611f\u6027\uff0c\u63d0\u4f9bVGMU\u4e0d\u786e\u5b9a\u5ea6\u8bc4\u5206\u548cVGN\u8bad\u7ec3\u5c42\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8ba4\u77e5\u611f\u77e5\u4e0d\u786e\u5b9a\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u6216\u8fd1\u4f3c\u65b9\u6cd5\u5c06\u4e0d\u786e\u5b9a\u5ea6\u52a0\u6027\u5206\u89e3\u4e3a\u5076\u7136\u6027\u548c\u8ba4\u77e5\u6027\u5206\u91cf\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u4f7f\u7528\u6709\u9650\u96c6\u6210\u91c7\u6837\u548c/\u6216\u4e0d\u5339\u914d\u9884\u6d4b\u5206\u5e03\u65f6\u4f1a\u5931\u6548\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u5ea6\u4f30\u8ba1\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u65b9\u5dee\u95e8\u63a7\u96c6\u6210(VGE)\uff1a1) VGMU\u8bc4\u5206\u5c06\u51b3\u7b56\u8fb9\u754c\u4e0e\u96c6\u6210\u9884\u6d4b\u65b9\u5dee\u8026\u5408\uff1b2) VGN\u5c42\u901a\u8fc7\u6bcf\u7c7b\u53ef\u5b66\u4e60\u7684\u96c6\u6210\u6210\u5458\u6982\u7387\u5f52\u4e00\u5316\u5c06\u65b9\u5dee\u95e8\u63a7\u673a\u5236\u63a8\u5e7f\u5230\u8bad\u7ec3\u4e2d\uff1b3) \u63a8\u5bfc\u95ed\u5f0f\u5411\u91cf-\u96c5\u53ef\u6bd4\u4e58\u79ef\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "VGE\u5339\u914d\u6216\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u4fe1\u606f\u8bba\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u96c6\u6210\u6a21\u578b\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u8ba4\u77e5\u611f\u77e5\u4e0d\u786e\u5b9a\u5ea6\u4f30\u8ba1\u3002", "conclusion": "VGE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u76f4\u89c2\u3001\u53ef\u5fae\u5206\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u7edf\u8ba1\u91cf\u8ba1\u7b97\u4fe1\u566a\u6bd4\u95e8\u63a7\u6765\u6ce8\u5165\u8ba4\u77e5\u654f\u611f\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u8ba4\u77e5\u611f\u77e5\u4e0d\u786e\u5b9a\u5ea6\u4f30\u8ba1\u3002"}}
{"id": "2602.07479", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.07479", "abs": "https://arxiv.org/abs/2602.07479", "authors": ["Yihang Gao", "Vincent Y. F. Tan"], "title": "ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations", "comment": "38 pages", "summary": "Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.", "AI": {"tldr": "\u63d0\u51faODELoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e38\u5fae\u5206\u65b9\u7a0b\u4f18\u5316LoRA\u56e0\u5b50\u77e9\u9635\uff0c\u6a21\u62df\u5b8c\u6574\u5fae\u8c03\u7684\u68af\u5ea6\u6d41\uff0c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edfLoRA\u8bad\u7ec3\u65b9\u6cd5\u5c06\u4f4e\u79e9\u56e0\u5b50\u77e9\u9635\u5206\u5f00\u4f18\u5316\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528LoRA\u53c2\u6570\u5316\u7684\u5185\u5728\u7ed3\u6784\uff0c\u5bfc\u81f4\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u7684\u6b21\u4f18\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u8fde\u7eed\u65f6\u95f4\u4f18\u5316\u52a8\u6001\uff0c\u5c06LoRA\u56e0\u5b50\u77e9\u9635\u4f18\u5316\u5efa\u6a21\u4e3a\u5e38\u5fae\u5206\u65b9\u7a0b\uff0c\u6a21\u62df\u5b8c\u6574\u5fae\u8c03\u5728\u5e73\u8861\u6d41\u5f62\u4e0a\u7684\u68af\u5ea6\u6d41\u3002\u91c7\u7528\u6b27\u62c9\u548c\u9f99\u683c-\u5e93\u5854\u7b49\u65f6\u95f4\u79bb\u6563\u5316\u65b9\u6848\u8ddf\u8e2a\u8f68\u8ff9\u3002", "result": "\u5728\u5f3a\u51f8\u76ee\u6807\u4e0b\u8bc1\u660e\u7ebf\u6027\u6536\u655b\u6027\uff0c\u6269\u5c55\u5230\u77e9\u9635\u611f\u77e5\u8bbe\u7f6e\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u77e9\u9635\u611f\u77e5\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u7ebf\u6027\u6536\u655b\u884c\u4e3a\uff0c\u5728\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u3002", "conclusion": "ODELoRA\u4e3a\u7406\u89e3\u548c\u8bbe\u8ba1LoRA\u8bad\u7ec3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684ODE\u89c6\u89d2\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u7684\u7279\u5f81\u5b66\u4e60\uff0c\u5728\u4e0d\u540c\u7ef4\u5ea6\u89c4\u6a21\u4e0b\u90fd\u80fd\u6709\u6548\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002"}}
{"id": "2602.07930", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07930", "abs": "https://arxiv.org/abs/2602.07930", "authors": ["Irina Bigoulaeva", "Jonas Rohweder", "Subhabrata Dutta", "Iryna Gurevych"], "title": "Patches of Nonlinearity: Instruction Vectors in Large Language Models", "comment": null, "summary": "Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u7814\u7a76\u6307\u4ee4\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5904\u7406\u6307\u4ee4\uff0c\u53d1\u73b0\u6307\u4ee4\u8868\u793a\u76f8\u5bf9\u5c40\u90e8\u5316\uff0c\u79f0\u4e3a\u6307\u4ee4\u5411\u91cf(IVs)\uff0c\u8fd9\u4e9b\u5411\u91cf\u540c\u65f6\u5177\u6709\u7ebf\u6027\u53ef\u5206\u6027\u548c\u975e\u7ebf\u6027\u56e0\u679c\u4ea4\u4e92\u4f5c\u7528\uff0c\u6311\u6218\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u4e2d\u7684\u7ebf\u6027\u8868\u793a\u5047\u8bbe\u3002", "motivation": "\u5c3d\u7ba1\u6307\u4ee4\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u6210\u529f\u5e76\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4eba\u4eec\u5bf9\u5176\u5185\u90e8\u5982\u4f55\u5904\u7406\u6307\u4ee4\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u4ece\u673a\u5236\u89d2\u5ea6\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7a76\u6307\u4ee4\u7279\u5b9a\u8868\u793a\u5728\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u7b49\u540e\u8bad\u7ec3\u9636\u6bb5\u4e2d\u5982\u4f55\u6784\u5efa\u548c\u5229\u7528\u3002", "method": "\u91c7\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u6765\u8bc6\u522b\u6307\u4ee4\u8868\u793a\uff0c\u53d1\u73b0\u8fd9\u4e9b\u8868\u793a\u76f8\u5bf9\u5c40\u90e8\u5316\uff0c\u79f0\u4e3a\u6307\u4ee4\u5411\u91cf(IVs)\u3002\u4e3a\u4e86\u89e3\u8026\u975e\u7ebf\u6027\u56e0\u679c\u4ea4\u4e92\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5b9a\u4f4d\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4fe1\u606f\u5904\u7406\uff0c\u8be5\u65b9\u6cd5\u4e0d\u53d7\u57fa\u4e8e\u8865\u4e01\u6280\u672f\u7684\u9690\u5f0f\u7ebf\u6027\u5047\u8bbe\u9650\u5236\u3002", "result": "\u6307\u4ee4\u5411\u91cf\u8868\u73b0\u51fa\u7ebf\u6027\u53ef\u5206\u6027\u4e0e\u975e\u7ebf\u6027\u56e0\u679c\u4ea4\u4e92\u4f5c\u7528\u7684\u5947\u7279\u5e76\u5b58\uff0c\u6311\u6218\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u4e2d\u5e38\u89c1\u7684\u7ebf\u6027\u8868\u793a\u5047\u8bbe\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u65e9\u671f\u5c42\u5f62\u6210\u7684\u4efb\u52a1\u8868\u793a\u6761\u4ef6\u4e0b\uff0c\u540e\u671f\u5c42\u4f1a\u9009\u62e9\u4e0d\u540c\u7684\u4fe1\u606f\u901a\u8def\u6765\u89e3\u51b3\u4efb\u52a1\uff0c\u5373\u6307\u4ee4\u5411\u91cf\u5145\u5f53\u7535\u8def\u9009\u62e9\u5668\u3002", "conclusion": "\u6307\u4ee4\u8868\u793a\u5728\u6a21\u578b\u4e2d\u76f8\u5bf9\u5c40\u90e8\u5316\uff0c\u6307\u4ee4\u5411\u91cf\u4f5c\u4e3a\u7535\u8def\u9009\u62e9\u5668\uff0c\u5728\u65e9\u671f\u5c42\u5f62\u6210\u4efb\u52a1\u8868\u793a\u540e\uff0c\u5f15\u5bfc\u540e\u671f\u5c42\u9009\u62e9\u7279\u5b9a\u4fe1\u606f\u901a\u8def\u3002\u8fd9\u4e00\u53d1\u73b0\u8d28\u7591\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7ebf\u6027\u8868\u793a\u5047\u8bbe\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2602.07765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07765", "abs": "https://arxiv.org/abs/2602.07765", "authors": ["Zhirong Huang", "Debo Cheng", "Guixian Zhang", "Yi Wang", "Jiuyong Li", "Shichao Zhang"], "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data", "comment": null, "summary": "Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\\underline{Dis}$entangled $\\underline{I}$nstrumental $\\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.", "AI": {"tldr": "\u63d0\u51faDisIV\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u89e3\u8026\u4ece\u7f51\u7edc\u6570\u636e\u4e2d\u63d0\u53d6\u4e2a\u4f53\u7279\u5f02\u6027\u6210\u5206\u4f5c\u4e3a\u6f5c\u5728\u5de5\u5177\u53d8\u91cf\uff0c\u89e3\u51b3\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf\u5916\u751f\u6027\u5047\u8bbe\u7684\u6311\u6218\u3002", "motivation": "\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf(IV)\u7684\u5916\u751f\u6027\u5047\u8bbe\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6062\u590dIV\u65f6\u901a\u5e38\u4f9d\u8d56\u90bb\u5c45\u4fe1\u606f\u5efa\u6a21\uff0c\u8fd9\u4e0d\u53ef\u907f\u514d\u5730\u6df7\u5408\u4e86\u5171\u4eab\u73af\u5883\u5f15\u8d77\u7684\u5185\u751f\u76f8\u5173\u6027\u548c\u4e2a\u4f53\u7279\u5f02\u6027\u5916\u751f\u53d8\u5f02\uff0c\u5bfc\u81f4\u5f97\u5230\u7684IV\u7ee7\u627f\u4e86\u5bf9\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u4f9d\u8d56\u5e76\u8fdd\u53cd\u5916\u751f\u6027\u3002", "method": "\u63d0\u51faDisentangled Instrumental Variables (DisIV)\u6846\u67b6\uff0c\u5229\u7528\u7f51\u7edc\u540c\u8d28\u6027\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u91c7\u7528\u7ed3\u6784\u89e3\u8026\u673a\u5236\u63d0\u53d6\u4e2a\u4f53\u7279\u5f02\u6027\u6210\u5206\u4f5c\u4e3a\u6f5c\u5728\u5de5\u5177\u53d8\u91cf\u3002\u901a\u8fc7\u663e\u5f0f\u7684\u6b63\u4ea4\u6027\u548c\u6392\u9664\u6761\u4ef6\u7ea6\u675f\u63d0\u53d6IV\u7684\u56e0\u679c\u6709\u6548\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u534a\u5408\u6210\u5b9e\u9a8c\u8868\u660e\uff0cDisIV\u5728\u7f51\u7edc\u8bf1\u5bfc\u6df7\u6742\u4e0b\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DisIV\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u89e3\u8026\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf\u5916\u751f\u6027\u5047\u8bbe\u7684\u6311\u6218\uff0c\u4e3a\u5b58\u5728\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u7684\u7f51\u7edc\u89c2\u6d4b\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u3002"}}
{"id": "2602.07273", "categories": ["cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.07273", "abs": "https://arxiv.org/abs/2602.07273", "authors": ["Xiaoyi Wu", "Juaren Steiger", "Bin Li", "R. Srikant"], "title": "Hybrid Feedback-Guided Optimal Learning for Wireless Interactive Panoramic Scene Delivery", "comment": "Submitting to ToN", "summary": "Immersive applications such as virtual and augmented reality impose stringent requirements on frame rate, latency, and synchronization between physical and virtual environments. To meet these requirements, an edge server must render panoramic content, predict user head motion, and transmit a portion of the scene that is large enough to cover the user viewport while remaining within wireless bandwidth constraints. Each portion produces two feedback signals: prediction feedback, indicating whether the selected portion covers the actual viewport, and transmission feedback, indicating whether the corresponding packets are successfully delivered. Prior work models this problem as a multi-armed bandit with two-level bandit feedback, but fails to exploit the fact that prediction feedback can be retrospectively computed for all candidate portions once the user head pose is observed. As a result, prediction feedback constitutes full-information feedback rather than bandit feedback. Motivated by this observation, we introduce a two-level hybrid feedback model that combines full-information and bandit feedback, and formulate the portion selection problem as an online learning task under this setting. We derive an instance-dependent regret lower bound for the hybrid feedback model and propose AdaPort, a hybrid learning algorithm that leverages both feedback types to improve learning efficiency. We further establish an instance-dependent regret upper bound that matches the lower bound asymptotically, and demonstrate through real-world trace driven simulations that AdaPort consistently outperforms state-of-the-art baseline methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6c89\u6d78\u5f0f\u5e94\u7528\uff08\u5982VR/AR\uff09\u7684\u4e24\u7ea7\u6df7\u5408\u53cd\u9988\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u5168\u4fe1\u606f\u53cd\u9988\u548c\u8001\u864e\u673a\u53cd\u9988\uff0c\u5e76\u8bbe\u8ba1\u4e86AdaPort\u7b97\u6cd5\u6765\u4f18\u5316\u89c6\u53e3\u9009\u62e9\uff0c\u5728\u771f\u5b9e\u6570\u636e\u6a21\u62df\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6c89\u6d78\u5f0f\u5e94\u7528\uff08VR/AR\uff09\u5bf9\u5e27\u7387\u3001\u5ef6\u8fdf\u548c\u7269\u7406\u865a\u62df\u73af\u5883\u540c\u6b65\u6709\u4e25\u683c\u8981\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u89c6\u53e3\u9009\u62e9\u5efa\u6a21\u4e3a\u5177\u6709\u4e24\u7ea7\u8001\u864e\u673a\u53cd\u9988\u7684\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u4f46\u5ffd\u7565\u4e86\u9884\u6d4b\u53cd\u9988\u53ef\u4ee5\u5728\u89c2\u5bdf\u5230\u7528\u6237\u5934\u90e8\u59ff\u6001\u540e\u4e3a\u6240\u6709\u5019\u9009\u89c6\u53e3\u8ba1\u7b97\uff0c\u8fd9\u5b9e\u9645\u4e0a\u662f\u5168\u4fe1\u606f\u53cd\u9988\u800c\u975e\u8001\u864e\u673a\u53cd\u9988\u3002", "method": "\u63d0\u51fa\u4e24\u7ea7\u6df7\u5408\u53cd\u9988\u6a21\u578b\uff0c\u7ed3\u5408\u5168\u4fe1\u606f\u53cd\u9988\uff08\u9884\u6d4b\u53cd\u9988\uff09\u548c\u8001\u864e\u673a\u53cd\u9988\uff08\u4f20\u8f93\u53cd\u9988\uff09\u3002\u8bbe\u8ba1\u4e86AdaPort\u7b97\u6cd5\uff0c\u5229\u7528\u4e24\u79cd\u53cd\u9988\u7c7b\u578b\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\uff0c\u5e76\u5efa\u7acb\u4e86\u4e0e\u4e0b\u754c\u6e10\u8fd1\u5339\u914d\u7684\u5b9e\u4f8b\u76f8\u5173\u9057\u61be\u4e0a\u754c\u3002", "result": "\u63a8\u5bfc\u4e86\u6df7\u5408\u53cd\u9988\u6a21\u578b\u7684\u5b9e\u4f8b\u76f8\u5173\u9057\u61be\u4e0b\u754c\uff0c\u5efa\u7acb\u4e86\u4e0e\u4e0b\u754c\u6e10\u8fd1\u5339\u914d\u7684\u9057\u61be\u4e0a\u754c\u3002\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u8f68\u8ff9\u9a71\u52a8\u7684\u6a21\u62df\u8868\u660e\uff0cAdaPort\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u9884\u6d4b\u53cd\u9988\u7684\u5168\u4fe1\u606f\u6027\u8d28\u5e76\u8bbe\u8ba1\u76f8\u5e94\u7684\u6df7\u5408\u53cd\u9988\u5b66\u4e60\u7b97\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6c89\u6d78\u5f0f\u5e94\u7528\u4e2d\u89c6\u53e3\u9009\u62e9\u7684\u6548\u7387\uff0c\u5728\u5e26\u5bbd\u7ea6\u675f\u4e0b\u66f4\u597d\u5730\u6ee1\u8db3VR/AR\u5e94\u7528\u7684\u6027\u80fd\u8981\u6c42\u3002"}}
{"id": "2602.08151", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08151", "abs": "https://arxiv.org/abs/2602.08151", "authors": ["Yoav Freund", "Nicholas J. A. Harvey", "Victor S. Portella", "Yabing Qi", "Yu-Xiang Wang"], "title": "A second order regret bound for NormalHedge", "comment": null, "summary": "We consider the problem of prediction with expert advice for ``easy'' sequences. We show that a variant of NormalHedge enjoys a second-order $\u03b5$-quantile regret bound of $O\\big(\\sqrt{V_T \\log(V_T/\u03b5)}\\big) $ when $V_T > \\log N$, where $V_T$ is the cumulative second moment of instantaneous per-expert regret averaged with respect to a natural distribution determined by the algorithm. The algorithm is motivated by a continuous time limit using Stochastic Differential Equations. The discrete time analysis uses self-concordance techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdNormalHedge\u53d8\u4f53\uff0c\u5bf9\"\u7b80\u5355\"\u5e8f\u5217\u5b9e\u73b0\u4e8c\u9636\u03b5-\u5206\u4f4d\u6570\u9057\u61be\u754cO(\u221a(V_T log(V_T/\u03b5)))\uff0c\u5176\u4e2dV_T\u662f\u7b97\u6cd5\u786e\u5b9a\u7684\u81ea\u7136\u5206\u5e03\u4e0b\u77ac\u65f6\u4e13\u5bb6\u9057\u61be\u7684\u7d2f\u79ef\u4e8c\u9636\u77e9", "motivation": "\u7814\u7a76\u4e13\u5bb6\u5efa\u8bae\u9884\u6d4b\u95ee\u9898\u4e2d\u7684\"\u7b80\u5355\"\u5e8f\u5217\uff0c\u65e8\u5728\u4e3a\u8fd9\u7c7b\u5e8f\u5217\u8bbe\u8ba1\u5177\u6709\u66f4\u597d\u9057\u61be\u754c\u7684\u7b97\u6cd5", "method": "\u63d0\u51faNormalHedge\u7b97\u6cd5\u7684\u53d8\u4f53\uff0c\u901a\u8fc7\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u8fde\u7eed\u65f6\u95f4\u6781\u9650\u8fdb\u884c\u52a8\u673a\u63a8\u5bfc\uff0c\u79bb\u6563\u65f6\u95f4\u5206\u6790\u4f7f\u7528\u81ea\u534f\u8c03\u6280\u672f", "result": "\u5f53V_T > log N\u65f6\uff0c\u7b97\u6cd5\u83b7\u5f97\u4e8c\u9636\u03b5-\u5206\u4f4d\u6570\u9057\u61be\u754cO(\u221a(V_T log(V_T/\u03b5)))\uff0c\u5176\u4e2dV_T\u662f\u7b97\u6cd5\u786e\u5b9a\u7684\u81ea\u7136\u5206\u5e03\u4e0b\u77ac\u65f6\u4e13\u5bb6\u9057\u61be\u7684\u7d2f\u79ef\u4e8c\u9636\u77e9", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\"\u7b80\u5355\"\u5e8f\u5217\u63d0\u4f9b\u4e86\u6539\u8fdb\u7684\u9057\u61be\u4fdd\u8bc1\uff0c\u7ed3\u5408\u4e86\u8fde\u7eed\u65f6\u95f4\u6781\u9650\u548c\u81ea\u534f\u8c03\u5206\u6790\u6280\u672f"}}
{"id": "2602.08372", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.08372", "abs": "https://arxiv.org/abs/2602.08372", "authors": ["Yan-Feng Xie", "Yu-Jie Zhang", "Peng Zhao", "Zhi-Hua Zhou"], "title": "Dynamic Regret via Discounted-to-Dynamic Reduction with Applications to Curved Losses and Adam Optimizer", "comment": null, "summary": "We study dynamic regret minimization in non-stationary online learning, with a primary focus on follow-the-regularized-leader (FTRL) methods. FTRL is important for curved losses and for understanding adaptive optimizers such as Adam, yet existing dynamic regret analyses are less explored for FTRL. To address this, we build on the discounted-to-dynamic reduction and present a modular way to obtain dynamic regret bounds of FTRL-related problems. Specifically, we focus on two representative curved losses: linear regression and logistic regression. Our method not only simplifies existing proofs for the optimal dynamic regret of online linear regression, but also yields new dynamic regret guarantees for online logistic regression. Beyond online convex optimization, we apply the reduction to analyze the Adam optimizers, obtaining optimal convergence rates in stochastic, non-convex, and non-smooth settings. The reduction also enables a more detailed treatment of Adam with two discount parameters $(\u03b2_1,\u03b2_2)$, leading to new results for both clipped and clip-free variants of Adam optimizers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6298\u6263\u5230\u52a8\u6001\u7684\u7ea6\u7b80\u6280\u672f\uff0c\u4e3aFTRL\u76f8\u5173\u7b97\u6cd5\uff08\u7279\u522b\u662fAdam\u4f18\u5316\u5668\uff09\u5728\u975e\u5e73\u7a33\u5728\u7ebf\u5b66\u4e60\u4e2d\u63d0\u4f9b\u52a8\u6001\u9057\u61be\u5206\u6790\uff0c\u5728\u7ebf\u6027\u56de\u5f52\u3001\u903b\u8f91\u56de\u5f52\u7b49\u5f2f\u66f2\u635f\u5931\u51fd\u6570\u4e0a\u83b7\u5f97\u6700\u4f18\u52a8\u6001\u9057\u61be\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u9057\u61be\u5206\u6790\u5bf9FTRL\u65b9\u6cd5\u7814\u7a76\u4e0d\u8db3\uff0c\u800cFTRL\u5bf9\u4e8e\u5f2f\u66f2\u635f\u5931\u51fd\u6570\u548c\u7406\u89e3\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08\u5982Adam\uff09\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u5206\u6790FTRL\u5728\u975e\u5e73\u7a33\u5728\u7ebf\u5b66\u4e60\u4e2d\u7684\u52a8\u6001\u9057\u61be\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u6298\u6263\u5230\u52a8\u6001\u7684\u7ea6\u7b80\u6280\u672f\uff0c\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6\u5206\u6790FTRL\u76f8\u5173\u95ee\u9898\u7684\u52a8\u6001\u9057\u61be\u3002\u91cd\u70b9\u5173\u6ce8\u7ebf\u6027\u56de\u5f52\u548c\u903b\u8f91\u56de\u5f52\u4e24\u79cd\u4ee3\u8868\u6027\u5f2f\u66f2\u635f\u5931\u51fd\u6570\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u6269\u5c55\u5230Adam\u4f18\u5316\u5668\u7684\u6536\u655b\u6027\u5206\u6790\u3002", "result": "1) \u7b80\u5316\u4e86\u5728\u7ebf\u7ebf\u6027\u56de\u5f52\u6700\u4f18\u52a8\u6001\u9057\u61be\u7684\u8bc1\u660e\uff1b2) \u4e3a\u5728\u7ebf\u903b\u8f91\u56de\u5f52\u83b7\u5f97\u65b0\u7684\u52a8\u6001\u9057\u61be\u4fdd\u8bc1\uff1b3) \u5728\u968f\u673a\u3001\u975e\u51f8\u3001\u975e\u5149\u6ed1\u8bbe\u7f6e\u4e0b\u4e3aAdam\u4f18\u5316\u5668\u83b7\u5f97\u6700\u4f18\u6536\u655b\u7387\uff1b4) \u5bf9\u5e26\u4e24\u4e2a\u6298\u6263\u53c2\u6570(\u03b2\u2081,\u03b2\u2082)\u7684Adam\u8fdb\u884c\u66f4\u8be6\u7ec6\u5206\u6790\uff0c\u4e3a\u526a\u88c1\u548c\u65e0\u526a\u88c1\u53d8\u4f53\u63d0\u4f9b\u65b0\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u5757\u5316\u7ea6\u7b80\u65b9\u6cd5\u4e3aFTRL\u76f8\u5173\u7b97\u6cd5\u5728\u975e\u5e73\u7a33\u5728\u7ebf\u5b66\u4e60\u4e2d\u7684\u52a8\u6001\u9057\u61be\u5206\u6790\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0c\u4e0d\u4ec5\u7b80\u5316\u4e86\u73b0\u6709\u8bc1\u660e\uff0c\u8fd8\u83b7\u5f97\u4e86\u65b0\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u7279\u522b\u5728Adam\u4f18\u5316\u5668\u5206\u6790\u4e2d\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2602.07954", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07954", "abs": "https://arxiv.org/abs/2602.07954", "authors": ["Krzysztof Wr\u00f3bel", "Jan Maria Kowalski", "Jerzy Surma", "Igor Ciuciura", "Maciej Szyma\u0144ski"], "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation", "comment": null, "summary": "As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\\%) and very low false positive rate (0.63\\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\\% precision, 4.70\\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.", "AI": {"tldr": "Bielik Guard\u662f\u4e00\u7cfb\u5217\u7d27\u51d1\u578b\u6ce2\u5170\u8bed\u5b89\u5168\u5206\u7c7b\u5668\uff0c\u5305\u542b0.1B\u548c0.5B\u53c2\u6570\u4e24\u4e2a\u53d8\u4f53\uff0c\u7528\u4e8e\u5bf9\u6ce2\u5170\u8bed\u5185\u5bb9\u8fdb\u884c\u4e94\u7c7b\u5b89\u5168\u5206\u7c7b\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5f3a\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6ce2\u5170\u8bed\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u9700\u8981\u9ad8\u6548\u51c6\u786e\u7684\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u5668\u6765\u786e\u4fdd\u5185\u5bb9\u5b89\u5168\u3002", "method": "\u57fa\u4e8eMMLW-RoBERTa-base\u548cPKOBP/polish-roberta-8k\u6784\u5efa\u4e24\u4e2a\u6a21\u578b\u53d8\u4f53\uff080.1B\u548c0.5B\u53c2\u6570\uff09\uff0c\u57286,885\u4e2a\u793e\u533a\u6807\u6ce8\u7684\u6ce2\u5170\u8bed\u6587\u672c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5206\u7c7b\u4e94\u4e2a\u5b89\u5168\u7c7b\u522b\uff1a\u4ec7\u6068/\u653b\u51fb\u3001\u7c97\u4fd7\u3001\u6027\u5185\u5bb9\u3001\u72af\u7f6a\u548c\u81ea\u6b8b\u3002", "result": "0.5B\u53d8\u4f53\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u6700\u4f73\u6574\u4f53\u533a\u5206\u80fd\u529b\uff08F1\u5206\u65700.791\u5fae\u5e73\u5747\uff0c0.785\u5b8f\u5e73\u5747\uff09\uff1b0.1B\u53d8\u4f53\u5728\u771f\u5b9e\u7528\u6237\u63d0\u793a\u4e0a\u8868\u73b0\u51fa\u5353\u8d8a\u6548\u7387\uff0c\u7cbe\u5ea677.65%\uff0c\u8bef\u62a5\u7387\u4ec50.63%\uff0c\u4f18\u4e8e\u540c\u89c4\u6a21\u7684HerBERT-PL-Guard\u3002", "conclusion": "Bielik Guard\u7cfb\u5217\u6a21\u578b\u516c\u5f00\u53ef\u7528\uff0c\u65e8\u5728\u63d0\u4f9b\u9002\u5f53\u54cd\u5e94\u800c\u975e\u7b80\u5355\u5185\u5bb9\u5c4f\u853d\uff0c\u7279\u522b\u662f\u5728\u81ea\u6b8b\u7b49\u654f\u611f\u7c7b\u522b\u4e0a\uff0c\u4e3a\u6ce2\u5170\u8bed\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u5b89\u5168\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07787", "abs": "https://arxiv.org/abs/2602.07787", "authors": ["Pierre-Louis Favreau", "Jean-Pierre Lo", "Clement Guiguet", "Charles Simon-Meunier", "Nicolas Dehandschoewercker", "Allen G. Roush", "Judah Goldfeder", "Ravid Shwartz-Ziv"], "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition", "comment": null, "summary": "We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use", "AI": {"tldr": "Minitap\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86100%\u6210\u529f\u7387\uff0c\u9996\u6b21\u5b8c\u5168\u89e3\u51b3\u4e86\u6240\u6709116\u4e2a\u4efb\u52a1\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b80%\u7684\u6027\u80fd\u3002", "motivation": "\u5355\u667a\u80fd\u4f53\u67b6\u6784\u5728\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u6df7\u5408\u63a8\u7406\u8f68\u8ff9\u5bfc\u81f4\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u6587\u672c\u8f93\u5165\u5931\u8d25\u672a\u88ab\u68c0\u6d4b\u5230\u3001\u4ee5\u53ca\u91cd\u590d\u52a8\u4f5c\u5faa\u73af\u65e0\u6cd5\u9003\u8131\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "Minitap\u91c7\u7528\u4e09\u79cd\u9488\u5bf9\u6027\u673a\u5236\uff1a1) \u516d\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u5206\u79bb\uff1b2) \u57fa\u4e8e\u8bbe\u5907\u72b6\u6001\u5bf9\u6587\u672c\u8f93\u5165\u8fdb\u884c\u786e\u5b9a\u6027\u540e\u9a8c\u8bc1\uff1b3) \u68c0\u6d4b\u5faa\u73af\u5e76\u89e6\u53d1\u7b56\u7565\u6539\u53d8\u7684\u5143\u8ba4\u77e5\u63a8\u7406\u3002", "result": "\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230100%\u6210\u529f\u7387\uff0c\u5b8c\u5168\u89e3\u51b3\u6240\u6709116\u4e2a\u4efb\u52a1\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff1a\u591a\u667a\u80fd\u4f53\u5206\u89e3\u8d21\u732e+21\u5206\uff0c\u9a8c\u8bc1\u6267\u884c\u8d21\u732e+7\u5206\uff0c\u5143\u8ba4\u77e5\u8d21\u732e+9\u5206\u3002", "conclusion": "Minitap\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u3001\u9a8c\u8bc1\u6267\u884c\u548c\u5143\u8ba4\u77e5\u63a8\u7406\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u7684\u6311\u6218\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u6027\u80fd\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u3002"}}
{"id": "2602.07278", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07278", "abs": "https://arxiv.org/abs/2602.07278", "authors": ["Sai Vamsi Alisetti"], "title": "Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation", "comment": "4 pages", "summary": "Oversmoothing is a fundamental limitation of deep graph convolutional networks (GCNs), causing node representations to collapse as depth increases. While many prior approaches mitigate this effect through architectural modifications or residual mechanisms, the underlying spectral cause of oversmoothing is often left implicit. We propose Laplacian-LoRA, a simple and interpretable low-rank spectral adaptation of standard GCNs. Rather than redesigning message passing, Laplacian-LoRA introduces a learnable, spectrally anchored correction to the fixed Laplacian propagation operator, selectively weakening contraction while preserving stability and the low-pass inductive bias. Across multiple benchmark datasets and depths, Laplacian-LoRA consistently delays the onset of oversmoothing, extending the effective depth of GCNs by up to a factor of two. Embedding variance diagnostics confirm that these gains arise from delayed representational collapse, while learned spectral analysis demonstrates that the correction is smooth, bounded, and well behaved. Our results show that oversmoothing is a depth-dependent spectral phenomenon that can be systematically delayed through modest, low-rank adaptation of the graph propagation operator.", "AI": {"tldr": "\u63d0\u51faLaplacian-LoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u8c31\u9002\u5e94\u5ef6\u8fdfGCN\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\uff0c\u5c06\u6709\u6548\u6df1\u5ea6\u63d0\u5347\u6700\u591a\u4e24\u500d", "motivation": "\u56fe\u5377\u79ef\u7f51\u7edc(GCN)\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\u5bfc\u81f4\u968f\u7740\u6df1\u5ea6\u589e\u52a0\u8282\u70b9\u8868\u793a\u4f1a\u574d\u7f29\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u901a\u8fc7\u67b6\u6784\u4fee\u6539\u6216\u6b8b\u5dee\u673a\u5236\u7f13\u89e3\uff0c\u4f46\u8fc7\u5e73\u6ed1\u7684\u8c31\u539f\u56e0\u5f80\u5f80\u88ab\u9690\u542b\u5904\u7406", "method": "\u63d0\u51faLaplacian-LoRA\u65b9\u6cd5\uff0c\u5bf9\u6807\u51c6GCN\u8fdb\u884c\u7b80\u5355\u53ef\u89e3\u91ca\u7684\u4f4e\u79e9\u8c31\u9002\u5e94\u3002\u4e0d\u662f\u91cd\u65b0\u8bbe\u8ba1\u6d88\u606f\u4f20\u9012\uff0c\u800c\u662f\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u3001\u8c31\u951a\u5b9a\u7684\u4fee\u6b63\u5230\u56fa\u5b9a\u7684\u62c9\u666e\u62c9\u65af\u4f20\u64ad\u7b97\u5b50\uff0c\u9009\u62e9\u6027\u5730\u51cf\u5f31\u6536\u7f29\u540c\u65f6\u4fdd\u6301\u7a33\u5b9a\u6027\u548c\u4f4e\u901a\u5f52\u7eb3\u504f\u7f6e", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6df1\u5ea6\u4e0a\uff0cLaplacian-LoRA\u4e00\u81f4\u5730\u5ef6\u8fdf\u4e86\u8fc7\u5e73\u6ed1\u7684\u53d1\u751f\uff0c\u5c06GCN\u7684\u6709\u6548\u6df1\u5ea6\u63d0\u5347\u4e86\u6700\u591a\u4e24\u500d\u3002\u5d4c\u5165\u65b9\u5dee\u8bca\u65ad\u786e\u8ba4\u8fd9\u4e9b\u589e\u76ca\u6765\u81ea\u5ef6\u8fdf\u7684\u8868\u793a\u574d\u7f29\uff0c\u5b66\u4e60\u7684\u8c31\u5206\u6790\u663e\u793a\u4fee\u6b63\u662f\u5e73\u6ed1\u3001\u6709\u754c\u4e14\u884c\u4e3a\u826f\u597d\u7684", "conclusion": "\u8fc7\u5e73\u6ed1\u662f\u4e00\u79cd\u6df1\u5ea6\u4f9d\u8d56\u7684\u8c31\u73b0\u8c61\uff0c\u53ef\u4ee5\u901a\u8fc7\u5bf9\u56fe\u4f20\u64ad\u7b97\u5b50\u8fdb\u884c\u9002\u5ea6\u7684\u4f4e\u79e9\u9002\u5e94\u6765\u7cfb\u7edf\u6027\u5730\u5ef6\u8fdf"}}
{"id": "2602.08197", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08197", "abs": "https://arxiv.org/abs/2602.08197", "authors": ["Shingo Higashiguchi", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Interpretable Dynamic Network Modeling of Tensor Time Series via Kronecker Time-Varying Graphical Lasso", "comment": "Accepted at ACM Web Conference 2026 (WWW2026)", "summary": "With the rapid development of web services, large amounts of time series data are generated and accumulated across various domains such as finance, healthcare, and online platforms. As such data often co-evolves with multiple variables interacting with each other, estimating the time-varying dependencies between variables (i.e., the dynamic network structure) has become crucial for accurate modeling. However, real-world data is often represented as tensor time series with multiple modes, resulting in large, entangled networks that are hard to interpret and computationally intensive to estimate. In this paper, we propose Kronecker Time-Varying Graphical Lasso (KTVGL), a method designed for modeling tensor time series. Our approach estimates mode-specific dynamic networks in a Kronecker product form, thereby avoiding overly complex entangled structures and producing interpretable modeling results. Moreover, the partitioned network structure prevents the exponential growth of computational time with data dimension. In addition, our method can be extended to stream algorithms, making the computational time independent of the sequence length. Experiments on synthetic data show that the proposed method achieves higher edge estimation accuracy than existing methods while requiring less computation time. To further demonstrate its practical value, we also present a case study using real-world data. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/KTVGL.", "AI": {"tldr": "\u63d0\u51faKronecker\u65f6\u95f4\u53d8\u5316\u56fe\u5f62\u5957\u7d22\uff08KTVGL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5efa\u6a21\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u8fc7Kronecker\u79ef\u5f62\u5f0f\u4f30\u8ba1\u6a21\u6001\u7279\u5b9a\u52a8\u6001\u7f51\u7edc\uff0c\u907f\u514d\u590d\u6742\u7ea0\u7f20\u7ed3\u6784\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u670d\u52a1\u53d1\u5c55\uff0c\u5404\u9886\u57df\u4ea7\u751f\u5927\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u5305\u542b\u591a\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u53d8\u91cf\u3002\u4f30\u8ba1\u53d8\u91cf\u95f4\u7684\u65f6\u95f4\u53d8\u5316\u4f9d\u8d56\u5173\u7cfb\uff08\u52a8\u6001\u7f51\u7edc\u7ed3\u6784\uff09\u5bf9\u51c6\u786e\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002\u4f46\u73b0\u5b9e\u6570\u636e\u5e38\u8868\u793a\u4e3a\u591a\u6a21\u6001\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u5bfc\u81f4\u5e9e\u5927\u3001\u7ea0\u7f20\u7684\u7f51\u7edc\u96be\u4ee5\u89e3\u91ca\u4e14\u8ba1\u7b97\u91cf\u5927\u3002", "method": "\u63d0\u51faKronecker\u65f6\u95f4\u53d8\u5316\u56fe\u5f62\u5957\u7d22\uff08KTVGL\uff09\u65b9\u6cd5\uff0c\u4e3a\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u3002\u8be5\u65b9\u6cd5\u4ee5Kronecker\u79ef\u5f62\u5f0f\u4f30\u8ba1\u6a21\u6001\u7279\u5b9a\u7684\u52a8\u6001\u7f51\u7edc\uff0c\u907f\u514d\u8fc7\u5ea6\u590d\u6742\u7684\u7ea0\u7f20\u7ed3\u6784\uff0c\u4ea7\u751f\u53ef\u89e3\u91ca\u7684\u5efa\u6a21\u7ed3\u679c\u3002\u5206\u533a\u7f51\u7edc\u7ed3\u6784\u9632\u6b62\u8ba1\u7b97\u65f6\u95f4\u968f\u6570\u636e\u7ef4\u5ea6\u6307\u6570\u589e\u957f\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u6d41\u7b97\u6cd5\uff0c\u4f7f\u8ba1\u7b97\u65f6\u95f4\u4e0e\u5e8f\u5217\u957f\u5ea6\u65e0\u5173\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u8fb9\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u8ba1\u7b97\u65f6\u95f4\u3002\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u5b9e\u9645\u4ef7\u503c\u3002", "conclusion": "KTVGL\u65b9\u6cd5\u80fd\u6709\u6548\u5efa\u6a21\u5f20\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u901a\u8fc7Kronecker\u79ef\u5f62\u5f0f\u7684\u6a21\u6001\u7279\u5b9a\u52a8\u6001\u7f51\u7edc\u4f30\u8ba1\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u548c\u9ad8\u6548\u7684\u8ba1\u7b97\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u3002"}}
{"id": "2602.07963", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07963", "abs": "https://arxiv.org/abs/2602.07963", "authors": ["Vaibhav Shukla", "Hardik Sharma", "Adith N Reganti", "Soham Wasmatkar", "Bagesh Kumar", "Vrijendra Singh"], "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms", "comment": "Accepted at the AICS Workshop, AAAI 2026", "summary": "Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCompositeHarm\u57fa\u51c6\uff0c\u901a\u8fc7\u7ffb\u8bd1\u65b9\u6cd5\u7814\u7a76LLM\u5b89\u5168\u5bf9\u9f50\u5728\u8de8\u8bed\u8a00\u8f6c\u6362\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u653b\u51fb\u6210\u529f\u7387\u5728\u5370\u5ea6\u8bed\u8a00\u4e2d\u663e\u8457\u4e0a\u5347\uff0c\u7279\u522b\u662f\u5bf9\u6297\u6027\u8bed\u6cd5\u653b\u51fb\uff0c\u800c\u4e0a\u4e0b\u6587\u5371\u5bb3\u8f6c\u79fb\u8f83\u4e3a\u6e29\u548c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u57fa\u4e8e\u82f1\u8bed\uff0c\u7ffb\u8bd1\u4f5c\u4e3a\u591a\u8bed\u8a00\u884c\u4e3a\u63a2\u6d4b\u7684\u6377\u5f84\uff0c\u4f46\u65e0\u6cd5\u5b8c\u6574\u6355\u6349\u6709\u5bb3\u610f\u56fe\u6216\u7ed3\u6784\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u53d8\u5316\u3002\u67d0\u4e9b\u5371\u5bb3\u5728\u7ffb\u8bd1\u4e2d\u51e0\u4e4e\u5b8c\u6574\u4fdd\u7559\uff0c\u800c\u5176\u4ed6\u5219\u4f1a\u626d\u66f2\u6216\u6d88\u5931\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u8fd9\u79cd\u6548\u5e94\u3002", "method": "\u5f15\u5165CompositeHarm\u7ffb\u8bd1\u57fa\u51c6\uff0c\u7ed3\u5408AttaQ\uff08\u7ed3\u6784\u5316\u5bf9\u6297\u653b\u51fb\uff09\u548cMMSafetyBench\uff08\u4e0a\u4e0b\u6587\u73b0\u5b9e\u4e16\u754c\u5371\u5bb3\uff09\u4e24\u4e2a\u82f1\u8bed\u6570\u636e\u96c6\uff0c\u6269\u5c55\u5230\u516d\u79cd\u8bed\u8a00\uff08\u82f1\u8bed\u3001\u5370\u5730\u8bed\u3001\u963f\u8428\u59c6\u8bed\u3001\u9a6c\u62c9\u5730\u8bed\u3001\u5361\u7eb3\u8fbe\u8bed\u3001\u53e4\u5409\u62c9\u7279\u8bed\uff09\u3002\u91c7\u7528\u8f7b\u91cf\u7ea7\u63a8\u7406\u7b56\u7565\uff0c\u53d7\u8fb9\u7f18AI\u8bbe\u8ba1\u539f\u5219\u542f\u53d1\uff0c\u51cf\u5c11\u5197\u4f59\u8bc4\u4f30\u540c\u65f6\u4fdd\u6301\u8de8\u8bed\u8a00\u4fdd\u771f\u5ea6\u3002", "result": "\u4f7f\u7528\u4e09\u4e2a\u5927\u6a21\u578b\u53d1\u73b0\uff1a1\uff09\u653b\u51fb\u6210\u529f\u7387\u5728\u5370\u5ea6\u8bed\u8a00\u4e2d\u6025\u5267\u4e0a\u5347\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6027\u8bed\u6cd5\u4e0b\uff1b2\uff09\u4e0a\u4e0b\u6587\u5371\u5bb3\u8f6c\u79fb\u8f83\u4e3a\u6e29\u548c\uff1b3\uff09\u8f7b\u91cf\u7ea7\u63a8\u7406\u7b56\u7565\u4f7f\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u5b89\u5168\u6d4b\u8bd5\u5728\u8ba1\u7b97\u4e0a\u53ef\u884c\u4e14\u73af\u4fdd\u3002", "conclusion": "\u7ffb\u8bd1\u57fa\u51c6\u662f\u6784\u5efa\u6709\u57fa\u7840\u3001\u8d44\u6e90\u611f\u77e5\u3001\u8bed\u8a00\u81ea\u9002\u5e94\u5b89\u5168\u7cfb\u7edf\u7684\u5fc5\u8981\u7b2c\u4e00\u6b65\uff0c\u4f46\u4e0d\u8db3\u591f\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u591a\u8bed\u8a00\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.07824", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07824", "abs": "https://arxiv.org/abs/2602.07824", "authors": ["Yiwei Qin", "Zhen Huang", "Tiantian Mi", "Weiye Si", "Chenyang Zhou", "Qipeng Guo", "Siyuan Feng", "Pengfei Liu"], "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training", "comment": null, "summary": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.", "AI": {"tldr": "\u63d0\u51faData Darwinism\u5341\u7ea7\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u5728\u79d1\u5b66\u6587\u732e\u9886\u57df\u9a8c\u8bc1\u4e86\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0", "motivation": "\u6570\u636e\u8d28\u91cf\u51b3\u5b9a\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u5904\u7406\u6846\u67b6\u3002\u9700\u8981\u5efa\u7acb\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u8ba9\u5148\u8fdb\u6a21\u578b\u4e3a\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u751f\u6210\u66f4\u4f18\u8d28\u6570\u636e", "method": "\u5f15\u5165Data Darwinism\u5341\u7ea7\u5206\u7c7b\u6cd5(L0-L9)\uff0c\u6784\u5efaDarwin-Science 900B token\u8bed\u6599\u5e93\u3002\u901a\u8fc7L4(\u751f\u6210\u7cbe\u70bc)\u548cL5(\u8ba4\u77e5\u8865\u5168)\u4f7f\u7528\u524d\u6cbfLLM\u89e3\u91ca\u63a8\u7406\u548c\u672f\u8bed\uff0c\u586b\u8865\u539f\u59cb\u79d1\u5b66\u6587\u672c\u7684\u5b66\u4e60\u6027\u5dee\u8ddd\u3002\u9884\u8bad\u7ec3daVinci-origin-3B/7B\u6a21\u578b\u4f5c\u4e3a\u65e0\u6c61\u67d3\u57fa\u7ebf", "result": "\u7ecf\u8fc7600B token\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0cDarwin-Science\u572820+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u6bd4\u57fa\u7ebf\u63d0\u5347+2.12(3B)\u548c+2.95(7B)\u5206\uff0c\u5728\u9886\u57df\u5bf9\u9f50\u4efb\u52a1\u4e0a\u63d0\u5347+5.60\u548c+8.40\u5206\u3002\u7cfb\u7edf\u63a8\u8fdb\u5230L5\u5e26\u6765+1.36\u7684\u603b\u589e\u76ca\uff0c\u8bc1\u5b9e\u9ad8\u7ea7\u5904\u7406\u80fd\u91ca\u653e\u6f5c\u5728\u6570\u636e\u4ef7\u503c", "conclusion": "Data Darwinism\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\uff0c\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u53d1\u5e03Darwin-Science\u8bed\u6599\u5e93\u548cdaVinci-origin\u6a21\u578b\uff0c\u652f\u6301\u57fa\u4e8e\u539f\u5219\u7684\u534f\u540c\u8fdb\u5316\u53d1\u5c55"}}
{"id": "2602.07279", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07279", "abs": "https://arxiv.org/abs/2602.07279", "authors": ["Bruno Belucci", "Karim Lounici", "Vladimir R. Kostic", "Katia Meziani"], "title": "VertCoHiRF: Decentralized Vertical Clustering Beyond k-means", "comment": null, "summary": "Vertical Federated Learning (VFL) enables collaborative analysis across parties holding complementary feature views of the same samples, yet existing approaches are largely restricted to distributed variants of $k$-means, requiring centralized coordination or the exchange of feature-dependent numerical statistics, and exhibiting limited robustness under heterogeneous views or adversarial behavior. We introduce VertCoHiRF, a fully decentralized framework for vertical federated clustering based on structural consensus across heterogeneous views, allowing each agent to apply a base clustering method adapted to its local feature space in a peer-to-peer manner. Rather than exchanging feature-dependent statistics or relying on noise injection for privacy, agents cluster their local views independently and reconcile their proposals through identifier-level consensus. Consensus is achieved via decentralized ordinal ranking to select representative medoids, progressively inducing a shared hierarchical clustering across agents. Communication is limited to sample identifiers, cluster labels, and ordinal rankings, providing privacy by design while supporting overlapping feature partitions and heterogeneous local clustering methods, and yielding an interpretable shared Cluster Fusion Hierarchy (CFH) that captures cross-view agreement at multiple resolutions.We analyze communication complexity and robustness, and experiments demonstrate competitive clustering performance in vertical federated settings.", "AI": {"tldr": "VertCoHiRF\uff1a\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u89c6\u56fe\u7ed3\u6784\u5171\u8bc6\u7684\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u5782\u76f4\u8054\u90a6\u805a\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u8bc6\u7b26\u7ea7\u5171\u8bc6\u548c\u5e8f\u6570\u6392\u540d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u65e0\u9700\u4ea4\u6362\u7279\u5f81\u4f9d\u8d56\u7edf\u8ba1\u91cf\u3002", "motivation": "\u73b0\u6709\u5782\u76f4\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8ek-means\u7684\u5206\u5e03\u5f0f\u53d8\u4f53\uff0c\u9700\u8981\u4e2d\u5fc3\u5316\u534f\u8c03\u6216\u4ea4\u6362\u7279\u5f81\u4f9d\u8d56\u7684\u6570\u503c\u7edf\u8ba1\uff0c\u5728\u5f02\u6784\u89c6\u56fe\u6216\u5bf9\u6297\u884c\u4e3a\u4e0b\u9c81\u68d2\u6027\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u80fd\u5904\u7406\u5f02\u6784\u89c6\u56fe\u7684\u5782\u76f4\u8054\u90a6\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVertCoHiRF\u6846\u67b6\uff1a1\uff09\u5404\u4ee3\u7406\u5728\u672c\u5730\u7279\u5f81\u7a7a\u95f4\u72ec\u7acb\u5e94\u7528\u57fa\u7840\u805a\u7c7b\u65b9\u6cd5\uff1b2\uff09\u901a\u8fc7\u6807\u8bc6\u7b26\u7ea7\u5171\u8bc6\u534f\u8c03\u805a\u7c7b\u63d0\u6848\uff0c\u800c\u975e\u4ea4\u6362\u7279\u5f81\u7edf\u8ba1\uff1b3\uff09\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u5e8f\u6570\u6392\u540d\u9009\u62e9\u4ee3\u8868\u6027\u4e2d\u5fc3\u70b9\uff1b4\uff09\u9010\u6b65\u8bf1\u5bfc\u8de8\u4ee3\u7406\u7684\u5171\u4eab\u5c42\u6b21\u805a\u7c7b\uff0c\u5f62\u6210\u53ef\u89e3\u91ca\u7684\u96c6\u7fa4\u878d\u5408\u5c42\u6b21\u7ed3\u6784\u3002", "result": "\u901a\u4fe1\u4ec5\u9650\u4e8e\u6837\u672c\u6807\u8bc6\u7b26\u3001\u805a\u7c7b\u6807\u7b7e\u548c\u5e8f\u6570\u6392\u540d\uff0c\u63d0\u4f9b\u8bbe\u8ba1\u9690\u79c1\u4fdd\u62a4\uff0c\u652f\u6301\u91cd\u53e0\u7279\u5f81\u5206\u533a\u548c\u5f02\u6784\u672c\u5730\u805a\u7c7b\u65b9\u6cd5\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5171\u4eab\u805a\u7c7b\u878d\u5408\u5c42\u6b21\u7ed3\u6784\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u5782\u76f4\u8054\u90a6\u8bbe\u7f6e\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u7684\u805a\u7c7b\u6027\u80fd\u3002", "conclusion": "VertCoHiRF\u4e3a\u5782\u76f4\u8054\u90a6\u805a\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5171\u8bc6\u673a\u5236\u5904\u7406\u5f02\u6784\u89c6\u56fe\uff0c\u907f\u514d\u4e86\u7279\u5f81\u7edf\u8ba1\u4ea4\u6362\u7684\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u8de8\u89c6\u56fe\u805a\u7c7b\u534f\u8c03\u3002"}}
{"id": "2602.08210", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08210", "abs": "https://arxiv.org/abs/2602.08210", "authors": ["Hyungseok Song", "Deunsol Yoon", "Kanghoon Lee", "Han-Seul Jeong", "Soonyoung Lee", "Woohyung Lim"], "title": "CADO: From Imitation to Cost Minimization for Heatmap-based Solvers in Combinatorial Optimization", "comment": null, "summary": "Heatmap-based solvers have emerged as a promising paradigm for Combinatorial Optimization (CO). However, we argue that the dominant Supervised Learning (SL) training paradigm suffers from a fundamental objective mismatch: minimizing imitation loss (e.g., cross-entropy) does not guarantee solution cost minimization. We dissect this mismatch into two deficiencies: Decoder-Blindness (being oblivious to the non-differentiable decoding process) and Cost-Blindness (prioritizing structural imitation over solution quality). We empirically demonstrate that these intrinsic flaws impose a hard performance ceiling. To overcome this limitation, we propose CADO (Cost-Aware Diffusion models for Optimization), a streamlined Reinforcement Learning fine-tuning framework that formulates the diffusion denoising process as an MDP to directly optimize the post-decoded solution cost. We introduce Label-Centered Reward, which repurposes ground-truth labels as unbiased baselines rather than imitation targets, and Hybrid Fine-Tuning for parameter-efficient adaptation. CADO achieves state-of-the-art performance across diverse benchmarks, validating that objective alignment is essential for unlocking the full potential of heatmap-based solvers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCADO\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u89e3\u51b3\u70ed\u56fe\u6c42\u89e3\u5668\u5728\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u6210\u672c\u611f\u77e5\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u70ed\u56fe\u7684\u7ec4\u5408\u4f18\u5316\u6c42\u89e3\u5668\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\uff0c\u5b58\u5728\u6839\u672c\u6027\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u6700\u5c0f\u5316\u6a21\u4eff\u635f\u5931\uff08\u5982\u4ea4\u53c9\u71b5\uff09\u4e0d\u80fd\u4fdd\u8bc1\u89e3\u51b3\u65b9\u6848\u6210\u672c\u6700\u5c0f\u5316\u3002\u8fd9\u79cd\u4e0d\u5339\u914d\u4f53\u73b0\u5728\u89e3\u7801\u5668\u76f2\u89c6\uff08\u5ffd\u7565\u4e0d\u53ef\u5fae\u89e3\u7801\u8fc7\u7a0b\uff09\u548c\u6210\u672c\u76f2\u89c6\uff08\u4f18\u5148\u7ed3\u6784\u6a21\u4eff\u800c\u975e\u89e3\u8d28\u91cf\uff09\u3002", "method": "\u63d0\u51faCADO\uff08\u6210\u672c\u611f\u77e5\u6269\u6563\u4f18\u5316\u6a21\u578b\uff09\uff0c\u5c06\u6269\u6563\u53bb\u566a\u8fc7\u7a0b\u5efa\u6a21\u4e3aMDP\uff0c\u76f4\u63a5\u4f18\u5316\u89e3\u7801\u540e\u89e3\u51b3\u65b9\u6848\u6210\u672c\u3002\u5f15\u5165\u6807\u7b7e\u4e2d\u5fc3\u5956\u52b1\uff08\u5c06\u771f\u5b9e\u6807\u7b7e\u91cd\u65b0\u7528\u4f5c\u65e0\u504f\u57fa\u7ebf\u800c\u975e\u6a21\u4eff\u76ee\u6807\uff09\u548c\u6df7\u5408\u5fae\u8c03\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u3002", "result": "CADO\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u76ee\u6807\u5bf9\u9f50\u5bf9\u4e8e\u91ca\u653e\u70ed\u56fe\u6c42\u89e3\u5668\u5168\u90e8\u6f5c\u529b\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5b9e\u73b0\u76ee\u6807\u5bf9\u9f50\u662f\u89e3\u51b3\u70ed\u56fe\u6c42\u89e3\u5668\u6027\u80fd\u74f6\u9888\u7684\u5173\u952e\uff0cCADO\u6846\u67b6\u4e3a\u7ec4\u5408\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2602.09006", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.09006", "abs": "https://arxiv.org/abs/2602.09006", "authors": ["Wenbo Gong", "Javier Zazo", "Qijun Luo", "Puqian Wang", "James Hensman", "Chao Ma"], "title": "ARO: A New Lens On Matrix Optimization For Large Models", "comment": null, "summary": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.", "AI": {"tldr": "ARO\u662f\u4e00\u79cd\u65b0\u7684\u77e9\u9635\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u65cb\u8f6c\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\uff0c\u5728\u65cb\u8f6c\u5750\u6807\u7cfb\u4e2d\u6267\u884c\u8303\u6570\u6700\u901f\u4e0b\u964d\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6b63\u4ea4\u5316/\u767d\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u867d\u7136\u57fa\u4e8e\u6b63\u4ea4\u5316/\u767d\u5316\u7684\u77e9\u9635\u4f18\u5316\u5668\u5728\u63d0\u5347LLM\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u8d85\u8d8a\u6b63\u4ea4\u5316\u7684\u65b0\u8303\u5f0f\uff0c\u8fdb\u4e00\u6b65\u63a8\u52a8\u6548\u7387\u8fb9\u754c\u3002", "method": "ARO\u5c06\u68af\u5ea6\u65cb\u8f6c\u4f5c\u4e3a\u9996\u8981\u8bbe\u8ba1\u539f\u5219\uff0c\u5728\u65cb\u8f6c\u5750\u6807\u7cfb\u4e2d\u6267\u884c\u8303\u6570\u6700\u901f\u4e0b\u964d\uff0c\u65cb\u8f6c\u7531\u65b0\u9896\u7684\u8303\u6570\u4fe1\u606f\u7b56\u7565\u786e\u5b9a\u3002\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6b63\u4ea4\u5316\u548c\u767d\u5316\u4f18\u5316\u5668\u3002", "result": "\u5728\u4e25\u683c\u63a7\u5236\u7684\u57fa\u51c6\u6d4b\u8bd5\u534f\u8bae\u4e0b\uff0cARO\u5728LLM\u9884\u8bad\u7ec3\u4e2d\u6301\u7eed\u4f18\u4e8eAdamW\uff081.3-1.35\u500d\uff09\u548c\u6b63\u4ea4\u5316\u65b9\u6cd5\uff081.1-1.15\u500d\uff09\uff0c\u53c2\u6570\u89c4\u6a21\u8fbe80\u4ebf\uff0c\u8bad\u7ec3\u9884\u7b97\u8fbe8\u500d\uff0c\u672a\u89c1\u6536\u76ca\u9012\u51cf\u3002", "conclusion": "ARO\u53ef\u4ee5\u91cd\u65b0\u8868\u8ff0\u4e3a\u57fa\u4e8e\u6b8b\u5dee\u6d41\u65cb\u8f6c\u5bf9\u79f0\u6027\u7684\u5bf9\u79f0\u611f\u77e5\u4f18\u5316\u5668\uff0c\u8fd9\u4e3a\u5229\u7528\u8de8\u5c42/\u8de8\u6a21\u5757\u8026\u5408\u7684\u8ba1\u7b97\u9ad8\u6548\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u52a8\u673a\uff0c\u63a8\u52a8\u4e86\u77e9\u9635\u4f18\u5316\u5668\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.07978", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07978", "abs": "https://arxiv.org/abs/2602.07978", "authors": ["Rui Feng", "Zhiyao Luo", "Liuyu Wu", "Wei Wang", "Yuting Song", "Yong Liu", "Kok Pin Ng", "Jianqing Li", "Xingyao Wang"], "title": "Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection", "comment": "18 pages, 7 figures, 6 tables", "summary": "Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.", "AI": {"tldr": "SynCog\u6846\u67b6\u901a\u8fc7\u53ef\u63a7\u96f6\u6837\u672c\u591a\u6a21\u6001\u6570\u636e\u5408\u6210\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u5fae\u8c03\uff0c\u89e3\u51b3MCI\u8bca\u65ad\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u57fa\u4e8e\u8bed\u97f3\u7684\u6570\u5b57\u751f\u7269\u6807\u5fd7\u7269\u662f\u65e9\u671f\u8bc6\u522b\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u7684\u53ef\u6269\u5c55\u3001\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\uff0c\u4f46\u9762\u4e34\u4e34\u5e8a\u6570\u636e\u7a00\u7f3a\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3001\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u5dee\u7b49\u6311\u6218\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u4fe1\u4efb\u548c\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faSynCog\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u53ef\u63a7\u96f6\u6837\u672c\u591a\u6a21\u6001\u6570\u636e\u5408\u6210\u6a21\u62df\u5177\u6709\u4e0d\u540c\u8ba4\u77e5\u7279\u5f81\u7684\u865a\u62df\u53d7\u8bd5\u8005\uff0c\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff1b2\uff09\u4f7f\u7528\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u7b56\u7565\u5fae\u8c03\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u6a21\u578b\u80fd\u660e\u786e\u8868\u8fbe\u8bca\u65ad\u601d\u7ef4\u8fc7\u7a0b\u800c\u975e\u9ed1\u76d2\u9884\u6d4b\u3002", "result": "\u5728ADReSS\u548cADReSSo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u589e\u5f3a\u83b7\u5f9780.67%\u548c78.46%\u7684Macro-F1\u5206\u6570\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002\u5728\u72ec\u7acb\u771f\u5b9e\u4e16\u754c\u666e\u901a\u8bdd\u961f\u5217\uff08CIR-E\uff09\u4e0a\u5b9e\u73b048.71%\u7684Macro-F1\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SynCog\u6846\u67b6\u4e3a\u89e3\u51b3\u4e34\u5e8a\u6570\u636e\u7a00\u7f3a\u3001\u63d0\u9ad8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u662f\u8fc8\u5411\u4e34\u5e8a\u53ef\u4fe1\u8d56\u3001\u8bed\u8a00\u5305\u5bb9\u6027\u8ba4\u77e5\u8bc4\u4f30\u5de5\u5177\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2602.07830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07830", "abs": "https://arxiv.org/abs/2602.07830", "authors": ["Jiahui Zhou", "Dan Li", "Boxin Li", "Xiao Zhang", "Erli Meng", "Lin Li", "Zhuomin Chen", "Jian Lou", "See-Kiong Ng"], "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning", "comment": null, "summary": "Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.", "AI": {"tldr": "VeriTime\u662f\u4e00\u4e2a\u901a\u8fc7\u6570\u636e\u5408\u6210\u3001\u6570\u636e\u8c03\u5ea6\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6765\u5b9a\u5236LLMs\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u8fbe\u5230\u6216\u8d85\u8fc7\u5927\u578b\u4e13\u6709LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u4e3b\u8981\u53d7\u5230\u4e09\u4e2a\u9650\u5236\uff1a\u7f3a\u4e4f\u7cbe\u5fc3\u7b56\u5212\u7684\u65f6\u95f4\u5e8f\u5217CoT\u8bad\u7ec3\u6570\u636e\u3001\u6570\u636e\u8c03\u5ea6\u6548\u7387\u4f4e\u4e0b\u3001\u4ee5\u53ca\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217CoT\u6570\u636e\u7684RL\u7b97\u6cd5\u3002", "method": "1) \u63d0\u51fa\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u6784\u5efa\u5e26\u6709\u8fc7\u7a0b\u53ef\u9a8c\u8bc1\u6ce8\u91ca\u7684TS-text\u591a\u6a21\u6001\u6570\u636e\u96c6\uff1b2) \u8bbe\u8ba1\u6570\u636e\u8c03\u5ea6\u673a\u5236\uff0c\u6309\u7167\u96be\u5ea6\u5c42\u6b21\u548c\u4efb\u52a1\u5206\u7c7b\u539f\u5219\u5b89\u6392\u8bad\u7ec3\u6837\u672c\uff1b3) \u5f00\u53d1\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u7684\u8fc7\u7a0b\u7ea7CoT\u6570\u636e\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u3001\u591a\u76ee\u6807\u5956\u52b1\u3002", "result": "VeriTime\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u591a\u6837\u5316\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u4f7f\u7d27\u51d1\u76843B\u30014B\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u4e0e\u5927\u578b\u4e13\u6709LLM\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VeriTime\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5408\u6210\u3001\u667a\u80fd\u6570\u636e\u8c03\u5ea6\u548c\u4e13\u95e8\u8bbe\u8ba1\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3aLLM\u5728\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07285", "abs": "https://arxiv.org/abs/2602.07285", "authors": ["Etam Benger", "Katrina Ligett"], "title": "Fair Decisions from Calibrated Scores: Achieving Optimal Classification While Satisfying Sufficiency", "comment": null, "summary": "Binary classification based on predicted probabilities (scores) is a fundamental task in supervised machine learning. While thresholding scores is Bayes-optimal in the unconstrained setting, using a single threshold generally violates statistical group fairness constraints. Under independence (statistical parity) and separation (equalized odds), such thresholding suffices when the scores already satisfy the corresponding criterion. However, this does not extend to sufficiency: even perfectly group-calibrated scores -- including true class probabilities -- violate predictive parity after thresholding. In this work, we present an exact solution for optimal binary (randomized) classification under sufficiency, assuming finite sets of group-calibrated scores. We provide a geometric characterization of the feasible pairs of positive predictive value (PPV) and false omission rate (FOR) achievable by such classifiers, and use it to derive a simple post-processing algorithm that attains the optimal classifier using only group-calibrated scores and group membership. Finally, since sufficiency and separation are generally incompatible, we identify the classifier that minimizes deviation from separation subject to sufficiency, and show that it can also be obtained by our algorithm, often achieving performance comparable to the optimum.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5145\u5206\u6027\u516c\u5e73\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7fa4\u4f53\u6821\u51c6\u5206\u6570\u7684\u51e0\u4f55\u7279\u5f81\u5316\u65b9\u6cd5\u548c\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u5145\u5206\u6027\u4e0e\u5206\u79bb\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5728\u4e8c\u5143\u5206\u7c7b\u4e2d\uff0c\u57fa\u4e8e\u9884\u6d4b\u6982\u7387\u7684\u9608\u503c\u5206\u7c7b\u5728\u65e0\u7ea6\u675f\u60c5\u51b5\u4e0b\u662f\u8d1d\u53f6\u65af\u6700\u4f18\u7684\uff0c\u4f46\u4f7f\u7528\u5355\u4e00\u9608\u503c\u901a\u5e38\u4f1a\u8fdd\u53cd\u7edf\u8ba1\u7fa4\u4f53\u516c\u5e73\u7ea6\u675f\u3002\u867d\u7136\u72ec\u7acb\u6027\u548c\u5206\u79bb\u6027\u7ea6\u675f\u4e0b\u9608\u503c\u5206\u7c7b\u8db3\u591f\uff0c\u4f46\u5145\u5206\u6027\u7ea6\u675f\u4e0b\u5373\u4f7f\u5b8c\u7f8e\u7fa4\u4f53\u6821\u51c6\u7684\u5206\u6570\u5728\u9608\u503c\u5904\u7406\u540e\u4e5f\u4f1a\u8fdd\u53cd\u9884\u6d4b\u5947\u5076\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5728\u5145\u5206\u6027\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "1) \u5047\u8bbe\u6709\u9650\u7ec4\u7fa4\u4f53\u6821\u51c6\u5206\u6570\uff0c\u63d0\u4f9b\u6700\u4f18\u4e8c\u5143\u968f\u673a\u5206\u7c7b\u7684\u7cbe\u786e\u89e3\uff1b2) \u5bf9\u53ef\u5b9e\u73b0\u7684\u6b63\u9884\u6d4b\u503c(PPV)\u548c\u5047\u9057\u6f0f\u7387(FOR)\u5bf9\u8fdb\u884c\u51e0\u4f55\u7279\u5f81\u5316\uff1b3) \u63d0\u51fa\u7b80\u5355\u7684\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u4ec5\u4f7f\u7528\u7fa4\u4f53\u6821\u51c6\u5206\u6570\u548c\u7fa4\u4f53\u6210\u5458\u8eab\u4efd\u5373\u53ef\u83b7\u5f97\u6700\u4f18\u5206\u7c7b\u5668\uff1b4) \u8bc6\u522b\u5728\u6ee1\u8db3\u5145\u5206\u6027\u6761\u4ef6\u4e0b\u6700\u5c0f\u5316\u4e0e\u5206\u79bb\u6027\u504f\u5dee\u7684\u5206\u7c7b\u5668\u3002", "result": "1) \u63a8\u5bfc\u51fa\u5728\u5145\u5206\u6027\u7ea6\u675f\u4e0b\u53ef\u5b9e\u73b0PPV-FOR\u5bf9\u7684\u51e0\u4f55\u7279\u5f81\uff1b2) \u5f00\u53d1\u51fa\u83b7\u5f97\u6700\u4f18\u5206\u7c7b\u5668\u7684\u540e\u5904\u7406\u7b97\u6cd5\uff1b3) \u8bc6\u522b\u51fa\u5728\u6ee1\u8db3\u5145\u5206\u6027\u6761\u4ef6\u4e0b\u6700\u5c0f\u5316\u4e0e\u5206\u79bb\u6027\u504f\u5dee\u7684\u5206\u7c7b\u5668\uff1b4) \u8be5\u7b97\u6cd5\u901a\u5e38\u80fd\u8fbe\u5230\u4e0e\u6700\u4f18\u6027\u80fd\u76f8\u5f53\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u5145\u5206\u6027\u516c\u5e73\u7ea6\u675f\u4e0b\u7684\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u51e0\u4f55\u7279\u5f81\u5316\u548c\u9ad8\u6548\u540e\u5904\u7406\u7b97\u6cd5\uff0c\u5e76\u5904\u7406\u4e86\u5145\u5206\u6027\u4e0e\u5206\u79bb\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u516c\u5e73\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5145\u5206\u6027\u7ea6\u675f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08216", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08216", "abs": "https://arxiv.org/abs/2602.08216", "authors": ["Gunn Kim"], "title": "Thermodynamic Isomorphism of Transformers: A Lagrangian Approach to Attention Dynamics", "comment": "9 pages, 1 figure. Based on a thermodynamic framework for Transformer architectures. Derives the equation of state from first principles", "summary": "Although the Transformer architecture has revolutionized artificial intelligence, its underlying mechanisms remain largely heuristic and lack a unified physical theory. In this work, we propose a first-principles framework for information dynamics, treating the attention mechanism as a physical system governed by the principle of least action rather than as an algorithmic optimization. By mapping information states to a Riemannian manifold with the Fisher information metric, we derive the intelligence Lagrangian. We show that the softmax function corresponds to the unique thermodynamic equilibrium state that minimizes the Helmholtz free energy of the information gas. In addition, we identify the query-key interaction as an electrodynamic coupling between an external field and an intrinsic dipole moment. This theory establishes the first law of information thermodynamics, unifying inference (mechanical work) and learning (chemical evolution). It also explains emergent phenomena, such as scaling laws and grokking, as phase transitions characterized by the divergence of specific heat. Finally, we discuss how rotational symmetry breaking in the attention manifold generates massless Goldstone bosons, providing a field-theoretic perspective on rotary positional embeddings (RoPE). Our work connects Statistical Physics and Deep Learning, laying the groundwork for a general theory of physics-based intelligence.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\u4fe1\u606f\u52a8\u529b\u5b66\u6846\u67b6\uff0c\u5c06\u6ce8\u610f\u529b\u673a\u5236\u89c6\u4e3a\u9075\u5faa\u6700\u5c0f\u4f5c\u7528\u91cf\u539f\u7406\u7684\u7269\u7406\u7cfb\u7edf\uff0c\u800c\u975e\u7b97\u6cd5\u4f18\u5316\uff0c\u8fde\u63a5\u7edf\u8ba1\u7269\u7406\u4e0e\u6df1\u5ea6\u5b66\u4e60\u3002", "motivation": "Transformer\u67b6\u6784\u867d\u7136\u9769\u547d\u6027\uff0c\u4f46\u5176\u5e95\u5c42\u673a\u5236\u4ecd\u4e3b\u8981\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7269\u7406\u7406\u8bba\u3002\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7269\u7406\u539f\u7406\u7684\u667a\u80fd\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5c06\u4fe1\u606f\u72b6\u6001\u6620\u5c04\u5230\u9ece\u66fc\u6d41\u5f62\uff08\u4f7f\u7528Fisher\u4fe1\u606f\u5ea6\u91cf\uff09\uff0c\u63a8\u5bfc\u667a\u80fd\u62c9\u683c\u6717\u65e5\u91cf\u3002\u5c06softmax\u51fd\u6570\u89e3\u91ca\u4e3a\u6700\u5c0f\u5316\u4fe1\u606f\u6c14\u4f53\u4ea5\u59c6\u970d\u5179\u81ea\u7531\u80fd\u7684\u552f\u4e00\u70ed\u529b\u5b66\u5e73\u8861\u6001\uff0c\u5c06query-key\u4ea4\u4e92\u89c6\u4e3a\u5916\u573a\u4e0e\u56fa\u6709\u5076\u6781\u77e9\u4e4b\u95f4\u7684\u7535\u52a8\u529b\u5b66\u8026\u5408\u3002", "result": "\u5efa\u7acb\u4e86\u4fe1\u606f\u70ed\u529b\u5b66\u7b2c\u4e00\u5b9a\u5f8b\uff0c\u7edf\u4e00\u4e86\u63a8\u65ad\uff08\u673a\u68b0\u529f\uff09\u548c\u5b66\u4e60\uff08\u5316\u5b66\u6f14\u5316\uff09\u3002\u89e3\u91ca\u4e86\u6d8c\u73b0\u73b0\u8c61\uff08\u5982\u7f29\u653e\u5b9a\u5f8b\u548c\u987f\u609f\uff09\u4f5c\u4e3a\u6bd4\u70ed\u53d1\u6563\u8868\u5f81\u7684\u76f8\u53d8\u3002\u65cb\u8f6c\u5bf9\u79f0\u6027\u7834\u7f3a\u4ea7\u751f\u65e0\u8d28\u91cfGoldstone\u73bb\u8272\u5b50\uff0c\u4e3a\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08RoPE\uff09\u63d0\u4f9b\u573a\u8bba\u89c6\u89d2\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8fde\u63a5\u4e86\u7edf\u8ba1\u7269\u7406\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u4e3a\u57fa\u4e8e\u7269\u7406\u7684\u667a\u80fd\u4e00\u822c\u7406\u8bba\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u7406\u89e3Transformer\u673a\u5236\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7269\u7406\u6846\u67b6\u3002"}}
{"id": "2602.07996", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07996", "abs": "https://arxiv.org/abs/2602.07996", "authors": ["Arash Marioriyad", "Omid Ghahroodi", "Ehsaneddin Asgari", "Mohammad Hossein Rohban", "Mahdieh Soleymani Baghshah"], "title": "The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation", "comment": null, "summary": "Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.", "AI": {"tldr": "LLM\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u5668\u65f6\uff0c\u4f1a\u53d7\u65e0\u5173\u4e0a\u4e0b\u6587\u7ebf\u7d22\u5f71\u54cd\uff0c\u4f46\u5f88\u5c11\u5728\u89e3\u91ca\u4e2d\u627f\u8ba4\u8fd9\u4e9b\u5f71\u54cd\uff0c\u5b58\u5728\u89e3\u91ca\u5dee\u8ddd", "motivation": "\u7814\u7a76LLM\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u4f30\u5668\u65f6\u662f\u5426\u5fe0\u5b9e\u4e8e\u5185\u5bb9\u8d28\u91cf\uff0c\u80fd\u5426\u4fdd\u6301\u5bf9\u65e0\u5173\u4e0a\u4e0b\u6587\u7684\u4e0d\u53d8\u6027\uff0c\u4ee5\u53ca\u662f\u5426\u900f\u660e\u53cd\u6620\u51b3\u7b56\u56e0\u7d20", "method": "\u901a\u8fc7\u63a7\u5236\u6027\u7ebf\u7d22\u6270\u52a8\uff08\u6ce8\u5165\u5408\u6210\u5143\u6570\u636e\u6807\u7b7e\uff09\u6d4b\u8bd56\u4e2a\u8bc4\u4f30\u6a21\u578b\uff0c\u4f7f\u7528ELI5\uff08\u4e8b\u5b9e\u95ee\u7b54\uff09\u548cLitBench\uff08\u521b\u610f\u5199\u4f5c\uff09\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u7814\u7a766\u7c7b\u7ebf\u7d22\uff08\u6765\u6e90\u3001\u65f6\u95f4\u3001\u5e74\u9f84\u3001\u6027\u522b\u3001\u79cd\u65cf\u3001\u6559\u80b2\u72b6\u51b5\uff09\uff0c\u5f15\u5165\u7ebf\u7d22\u627f\u8ba4\u7387\uff08CAR\uff09\u91cf\u5316\u6a21\u578b\u662f\u5426\u5728\u89e3\u91ca\u4e2d\u660e\u786e\u63d0\u53ca\u6ce8\u5165\u7ebf\u7d22", "result": "\u8bc4\u4f30\u6a21\u578b\u5bf9\u7ebf\u7d22\u6709\u663e\u8457\u884c\u4e3a\u5f71\u54cd\uff08\u5982\u4e13\u5bb6>\u4eba\u7c7b>LLM>\u672a\u77e5\u7684\u6765\u6e90\u5c42\u6b21\u3001\u65b0>\u65e7\u7684\u65f6\u95f4\u504f\u597d\u3001\u6559\u80b2\u72b6\u51b5\u504f\u7231\uff09\uff0c\u4f46CAR\u901a\u5e38\u63a5\u8fd1\u96f6\uff0c\u8868\u660e\u5373\u4f7f\u7ebf\u7d22\u9a71\u52a8\u51b3\u7b56\u4e5f\u5f88\u5c11\u88ab\u62a5\u544a\uff1bCAR\u8fd8\u4f9d\u8d56\u4e8e\u6570\u636e\u96c6\uff0c\u5728\u4e8b\u5b9e\u6027ELI5\u8bbe\u7f6e\u4e2d\u66f4\u53ef\u80fd\u660e\u786e\u8bc6\u522b\u7ebf\u7d22\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u7684LitBench\u4e2d\u5e38\u4e3a\u96f6", "conclusion": "\u663e\u8457\u7684\u88c1\u51b3\u654f\u611f\u6027\u548c\u6709\u9650\u7684\u7ebf\u7d22\u627f\u8ba4\u63ed\u793a\u4e86LLM\u4f5c\u4e3a\u8bc4\u4f30\u5668\u6d41\u7a0b\u4e2d\u7684\u89e3\u91ca\u5dee\u8ddd\uff0c\u5bf9\u7814\u7a76\u548c\u90e8\u7f72\u4e2d\u57fa\u4e8e\u6a21\u578b\u7684\u8bc4\u4f30\u53ef\u9760\u6027\u63d0\u51fa\u62c5\u5fe7"}}
{"id": "2602.07849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07849", "abs": "https://arxiv.org/abs/2602.07849", "authors": ["Xin Wang", "Hualin Zhou", "Sheng Guang Wang", "Ting Dang", "Yu Zhang", "Hong Jia", "Tao Gu"], "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge", "comment": "16 pages, 9 figures ,9 tables, preprint", "summary": "Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.", "AI": {"tldr": "LQA\u662f\u4e00\u4e2a\u8f7b\u91cf\u5316\u7684\u91cf\u5316\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\u548c\u65e0\u68af\u5ea6\u6d4b\u8bd5\u65f6\u9002\u5e94\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u6a21\u578b\u90e8\u7f72\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u8d44\u6e90\u9650\u5236\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\uff0c\u4e0d\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u63d0\u51faLQA\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u6001\u611f\u77e5\u91cf\u5316\u7b56\u7565\u548c\u65e0\u68af\u5ea6\u6d4b\u8bd5\u65f6\u9002\u5e94\u3002\u5305\u62ec\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\uff08SHQ\uff09\u548c\u91cf\u5316\u65e0\u68af\u5ea6\u9002\u5e94\u673a\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u504f\u79fb\u5b9e\u9a8c\u4e2d\uff0cLQA\u5c06\u6574\u4f53\u9002\u5e94\u6027\u80fd\u63d0\u53474.5%\uff0c\u5185\u5b58\u4f7f\u7528\u4f4e\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u68af\u5ea6\u7684TTA\u65b9\u6cd5\uff0c\u5728\u4e03\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u9ad8\u8fbe19.9\u500d\u7684\u5185\u5b58\u4f7f\u7528\u964d\u4f4e\u3002", "conclusion": "LQA\u4e3a\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9c81\u68d2\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u9ad8\u6548\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2602.07320", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07320", "abs": "https://arxiv.org/abs/2602.07320", "authors": ["Philip Jacobson", "Ben Feinberg", "Suhas Kumar", "Sapan Agarwal", "T. Patrick Xiao", "Christopher Bennett"], "title": "Incorruptible Neural Networks: Training Models that can Generalize to Large Internal Perturbations", "comment": null, "summary": "Flat regions of the neural network loss landscape have long been hypothesized to correlate with better generalization properties. A closely related but distinct problem is training models that are robust to internal perturbations to their weights, which may be an important need for future low-power hardware platforms. In this paper, we explore the usage of two methods, sharpness-aware minimization (SAM) and random-weight perturbation (RWP), to find minima robust to a variety of random corruptions to weights. We consider the problem from two angles: generalization (how do we reduce the noise-robust generalization gap) and optimization (how do we maximize performance from optimizers when subject to strong perturbations). First, we establish, both theoretically and empirically, that an over-regularized RWP training objective is optimal for noise-robust generalization. For small-magnitude noise, we find that SAM's adversarial objective further improves performance over any RWP configuration, but performs poorly for large-magnitude noise. We link the cause of this to a vanishing-gradient effect, caused by unevenness in the loss landscape, affecting both SAM and RWP. Lastly, we demonstrate that dynamically adjusting the perturbation strength to match the evolution of the loss landscape improves optimizing for these perturbed objectives.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316(SAM)\u548c\u968f\u673a\u6743\u91cd\u6270\u52a8(RWP)\u6765\u5bfb\u627e\u5bf9\u6743\u91cd\u968f\u673a\u6270\u52a8\u9c81\u68d2\u7684\u6700\u5c0f\u503c\uff0c\u4ece\u6cdb\u5316\u548c\u4f18\u5316\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\uff0c\u53d1\u73b0\u8fc7\u6b63\u5219\u5316\u7684RWP\u5bf9\u566a\u58f0\u9c81\u68d2\u6cdb\u5316\u6700\u4f18\uff0cSAM\u5bf9\u5c0f\u566a\u58f0\u6548\u679c\u597d\u4f46\u5bf9\u5927\u566a\u58f0\u5dee\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u7684\u65b9\u6cd5\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u51fd\u6570\u7684\u5e73\u5766\u533a\u57df\u88ab\u8ba4\u4e3a\u4e0e\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u76f8\u5173\uff0c\u540c\u65f6\u8bad\u7ec3\u5bf9\u6743\u91cd\u5185\u90e8\u6270\u52a8\u9c81\u68d2\u7684\u6a21\u578b\u5bf9\u672a\u6765\u4f4e\u529f\u8017\u786c\u4ef6\u5e73\u53f0\u5f88\u91cd\u8981\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u627e\u5230\u5bf9\u5404\u79cd\u6743\u91cd\u968f\u673a\u6270\u52a8\u9c81\u68d2\u7684\u6700\u5c0f\u503c\u3002", "method": "\u4f7f\u7528\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316(SAM)\u548c\u968f\u673a\u6743\u91cd\u6270\u52a8(RWP)\u4e24\u79cd\u65b9\u6cd5\uff0c\u4ece\u6cdb\u5316(\u51cf\u5c11\u566a\u58f0\u9c81\u68d2\u6cdb\u5316\u5dee\u8ddd)\u548c\u4f18\u5316(\u5728\u5f3a\u6270\u52a8\u4e0b\u6700\u5927\u5316\u4f18\u5316\u5668\u6027\u80fd)\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u7ed3\u5408\uff0c\u5e76\u63d0\u51fa\u4e86\u52a8\u6001\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u7684\u4f18\u5316\u7b56\u7565\u3002", "result": "1) \u8fc7\u6b63\u5219\u5316\u7684RWP\u8bad\u7ec3\u76ee\u6807\u5bf9\u566a\u58f0\u9c81\u68d2\u6cdb\u5316\u6700\u4f18\uff1b2) \u5bf9\u5c0f\u5e45\u5ea6\u566a\u58f0\uff0cSAM\u7684\u5bf9\u6297\u6027\u76ee\u6807\u6bd4\u4efb\u4f55RWP\u914d\u7f6e\u8868\u73b0\u66f4\u597d\uff1b3) \u5bf9\u5927\u5e45\u5ea6\u566a\u58f0\uff0cSAM\u8868\u73b0\u5dee\uff0c\u539f\u56e0\u662f\u635f\u5931\u51fd\u6570\u4e0d\u5e73\u5766\u5bfc\u81f4\u7684\u68af\u5ea6\u6d88\u5931\u6548\u5e94\uff1b4) \u52a8\u6001\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u4ee5\u5339\u914d\u635f\u5931\u51fd\u6570\u6f14\u5316\u80fd\u6539\u5584\u4f18\u5316\u6548\u679c\u3002", "conclusion": "\u8fc7\u6b63\u5219\u5316\u7684RWP\u662f\u566a\u58f0\u9c81\u68d2\u6cdb\u5316\u7684\u6700\u4f18\u65b9\u6cd5\uff0cSAM\u5bf9\u5c0f\u566a\u58f0\u6709\u6548\u4f46\u5bf9\u5927\u566a\u58f0\u6548\u679c\u5dee\uff0c\u52a8\u6001\u8c03\u6574\u6270\u52a8\u5f3a\u5ea6\u80fd\u6539\u5584\u4f18\u5316\u6548\u679c\u3002\u635f\u5931\u51fd\u6570\u7684\u5e73\u5766\u5ea6\u5bf9\u9c81\u68d2\u6027\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.08005", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08005", "abs": "https://arxiv.org/abs/2602.08005", "authors": ["Jitai Hao", "Qiang Huang", "Yaowei Wang", "Min Zhang", "Jun Yu"], "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity", "comment": "preprint", "summary": "The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.", "AI": {"tldr": "DeltaKV\uff1a\u57fa\u4e8e\u6b8b\u5dee\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u7801\u8bed\u4e49\u6b8b\u5dee\u800c\u975e\u4e22\u5f03token\u6765\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff0c\u914d\u5408Sparse-vLLM\u63a8\u7406\u5f15\u64ce\u5b9e\u73b02\u500d\u541e\u5410\u91cf\u63d0\u5347", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u90e8\u7f72\u9762\u4e34KV\u7f13\u5b58\u5185\u5b58\u7ebf\u6027\u589e\u957f\u7684\u74f6\u9888\uff0c\u73b0\u6709\u538b\u7f29\u548c\u6dd8\u6c70\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u51c6\u786e\u6027\u3001\u538b\u7f29\u6bd4\u548c\u786c\u4ef6\u6548\u7387", "method": "\u63d0\u51faDeltaKV\u6846\u67b6\uff0c\u57fa\u4e8e\u4e24\u4e2a\u7ecf\u9a8c\u53d1\u73b0\uff08\u957f\u8ddd\u79bbtoken\u95f4\u76f8\u4f3c\u6027\u548cKV\u8868\u793a\u4e2d\u9ad8\u5ea6\u5171\u4eab\u7684\u6f5c\u5728\u7ec4\u4ef6\uff09\uff0c\u901a\u8fc7\u7f16\u7801\u76f8\u5bf9\u4e8e\u68c0\u7d22\u5386\u53f2\u53c2\u8003\u7684\u8bed\u4e49\u6b8b\u5dee\u6765\u538b\u7f29KV\u7f13\u5b58\uff1b\u8fdb\u4e00\u6b65\u5f00\u53d1Sparse-vLLM\u63a8\u7406\u5f15\u64ce\uff0c\u5177\u6709\u89e3\u8026\u5185\u5b58\u7ba1\u7406\u548c\u9488\u5bf9\u7a00\u758f\u4e0d\u89c4\u5219KV\u5e03\u5c40\u4f18\u5316\u7684\u5185\u6838", "result": "DeltaKV\u5c06KV\u7f13\u5b58\u5185\u5b58\u51cf\u5c11\u5230\u539f\u59cb\u768429%\uff0c\u5728LongBench\u3001SCBench\u548cAIME\u4e0a\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\uff1b\u4e0eSparse-vLLM\u96c6\u6210\u540e\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u76f8\u6bd4vLLM\u5b9e\u73b0\u9ad8\u8fbe2\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347", "conclusion": "DeltaKV\u548cSparse-vLLM\u4e3a\u53ef\u6269\u5c55\u7684\u957f\u4e0a\u4e0b\u6587LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u901a\u8fc7\u6b8b\u5dee\u538b\u7f29\u548c\u786c\u4ef6\u4f18\u5316\u5b9e\u73b0\u4e86\u5185\u5b58\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347"}}
{"id": "2602.07852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07852", "abs": "https://arxiv.org/abs/2602.07852", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard", "comment": "Published at ICLR 2026", "summary": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u5bfc\u81f4\u5b83\u4eec\u51fa\u73b0\"\u6d8c\u73b0\u6027\u9519\u4f4d\"\uff0c\u5728\u4e0d\u540c\u65e0\u5173\u573a\u666f\u4e2d\u7ed9\u51fa\u523b\u677f\"\u90aa\u6076\"\u56de\u7b54\u3002\u4e13\u5bb6\u8c03\u67e5\u672a\u80fd\u9884\u6d4b\u6b64\u7ed3\u679c\uff0c\u8868\u660e\u6211\u4eec\u5bf9LLM\u5b66\u4e60\u5f52\u7eb3\u504f\u597d\u7684\u7406\u89e3\u4e0d\u8db3\u3002\u7814\u7a76\u8bc6\u522b\u51fa\u4e00\u822c\u9519\u4f4d\u7684\u7ebf\u6027\u8868\u793a\uff0c\u53ef\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u5f52\u7eb3\u504f\u597d\u5982\u4f55\u5f71\u54cd\u5176\u6cdb\u5316\u884c\u4e3a\u3002\u5177\u4f53\u5173\u6ce8\"\u6d8c\u73b0\u6027\u9519\u4f4d\"\u73b0\u8c61\u2014\u2014\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u4f1a\u5728\u5404\u79cd\u65e0\u5173\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u9519\u4f4d\u884c\u4e3a\u3002\u4e13\u5bb6\u672a\u80fd\u9884\u6d4b\u6b64\u73b0\u8c61\uff0c\u51f8\u663e\u4e86\u6211\u4eec\u5bf9LLM\u5b66\u4e60\u673a\u5236\u7406\u89e3\u7684\u4e0d\u8db3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u4f7f\u7528\u6d8c\u73b0\u6027\u9519\u4f4d\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff1b2) \u53d1\u73b0\u4e0d\u540c\u5fae\u8c03\u4f1a\u6536\u655b\u5230\u76f8\u540c\u7684\u4e00\u822c\u9519\u4f4d\u7ebf\u6027\u8868\u793a\uff1b3) \u8bc6\u522b\u72ed\u7a84\u89e3\u51b3\u65b9\u6848\u7684\u7ebf\u6027\u8868\u793a\uff08\u901a\u8fc7\u5f15\u5165KL\u6563\u5ea6\u635f\u5931\u5b66\u4e60\uff09\uff1b4) \u6bd4\u8f83\u4e24\u79cd\u8868\u793a\u7684\u7279\u6027\uff1b5) \u5206\u6790\u5b83\u4eec\u5728\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u7684\u5f71\u54cd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u4e00\u822c\u9519\u4f4d\u89e3\u51b3\u65b9\u6848\u6bd4\u72ed\u7a84\u89e3\u51b3\u65b9\u6848\u635f\u5931\u66f4\u4f4e\uff1b2) \u4e00\u822c\u9519\u4f4d\u8868\u793a\u5bf9\u6270\u52a8\u66f4\u9c81\u68d2\uff1b3) \u4e00\u822c\u9519\u4f4d\u5728\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u5f71\u54cd\u529b\u66f4\u5927\uff1b4) \u4e00\u822c\u89e3\u51b3\u65b9\u6848\u4f3c\u4e4e\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\uff1b5) \u8bc6\u522b\u51fa\u53ef\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u7684\u5177\u4f53\u9519\u4f4d\u8868\u793a\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff1a1) \u5de5\u4f5c\u5206\u79bb\u51fa\u4e00\u822c\u9519\u4f4d\u7684\u5177\u4f53\u8868\u793a\uff0c\u53ef\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\uff1b2) \u63d0\u4f9b\u4e86\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u548c\u521d\u6b65\u6307\u6807\uff0c\u7528\u4e8e\u8c03\u67e5\u5f52\u7eb3\u504f\u597d\u5982\u4f55\u5851\u9020LLM\u7684\u6cdb\u5316\uff1b3) \u5f00\u6e90\u6240\u6709\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\u5fae\u8c03\uff1b4) \u5f3a\u8c03\u9700\u8981\u66f4\u597d\u7406\u89e3LLM\u7684\u5f52\u7eb3\u504f\u597d\u3002"}}
{"id": "2602.07340", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07340", "abs": "https://arxiv.org/abs/2602.07340", "authors": ["Yonghui Yang", "Wenjian Tao", "Jilong Liu", "Xingyu Zhu", "Junfeng Fang", "Weibiao Huang", "Le Wu", "Richang Hong", "Tat-Sent Chua"], "title": "Revisiting Robustness for LLM Safety Alignment via Selective Geometry Control", "comment": null, "summary": "Safety alignment of large language models remains brittle under domain shift and noisy preference supervision. Most existing robust alignment methods focus on uncertainty in alignment data, while overlooking optimization-induced fragility in preference-based objectives. In this work, we revisit robustness for LLM safety alignment from an optimization geometry perspective, and argue that robustness failures cannot be addressed by data-centric methods alone. We propose ShaPO, a geometry-aware preference optimization framework that enforces worst-case alignment objectives via selective geometry control over alignment-critical parameter subspace. By avoiding uniform geometry constraints, ShaPO mitigates the over-regularization that can harm robustness under distribution shift. We instantiate ShaPO at two levels: token-level ShaPO stabilizes likelihood-based surrogate optimization, while reward-level ShaPO enforces reward-consistent optimization under noisy supervision. Across diverse safety benchmarks and noisy preference settings, ShaPO consistently improves safety robustness over popular preference optimization methods. Moreover, ShaPO composes cleanly with data-robust objectives, yielding additional gains and empirically supporting the proposed optimization-geometry perspective.", "AI": {"tldr": "ShaPO\u662f\u4e00\u4e2a\u51e0\u4f55\u611f\u77e5\u7684\u504f\u597d\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u51e0\u4f55\u63a7\u5236\u63d0\u5347LLM\u5b89\u5168\u5bf9\u9f50\u7684\u9c81\u68d2\u6027", "motivation": "\u73b0\u6709\u9c81\u68d2\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5bf9\u9f50\u6570\u636e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u57fa\u4e8e\u504f\u597d\u7684\u76ee\u6807\u51fd\u6570\u4e2d\u4f18\u5316\u5f15\u8d77\u7684\u8106\u5f31\u6027\u3002\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u5728\u9886\u57df\u8f6c\u79fb\u548c\u566a\u58f0\u504f\u597d\u76d1\u7763\u4e0b\u4ecd\u7136\u8106\u5f31\u3002", "method": "\u63d0\u51faShaPO\u6846\u67b6\uff0c\u4ece\u4f18\u5316\u51e0\u4f55\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6LLM\u5b89\u5168\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u9009\u62e9\u6027\u51e0\u4f55\u63a7\u5236\u5bf9\u9f50\u5173\u952e\u53c2\u6570\u5b50\u7a7a\u95f4\uff0c\u5f3a\u5236\u6267\u884c\u6700\u574f\u60c5\u51b5\u5bf9\u9f50\u76ee\u6807\uff0c\u907f\u514d\u5747\u5300\u51e0\u4f55\u7ea6\u675f\u5bfc\u81f4\u7684\u8fc7\u5ea6\u6b63\u5219\u5316\u3002\u5728token\u7ea7\u522b\u7a33\u5b9a\u57fa\u4e8e\u4f3c\u7136\u7684\u4ee3\u7406\u4f18\u5316\uff0c\u5728\u5956\u52b1\u7ea7\u522b\u5f3a\u5236\u6267\u884c\u566a\u58f0\u76d1\u7763\u4e0b\u7684\u5956\u52b1\u4e00\u81f4\u6027\u4f18\u5316\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u5b89\u5168\u57fa\u51c6\u548c\u566a\u58f0\u504f\u597d\u8bbe\u7f6e\u4e0b\uff0cShaPO\u76f8\u6bd4\u6d41\u884c\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u6301\u7eed\u63d0\u5347\u5b89\u5168\u9c81\u68d2\u6027\u3002ShaPO\u8fd8\u80fd\u4e0e\u6570\u636e\u9c81\u68d2\u76ee\u6807\u5e72\u51c0\u7ec4\u5408\uff0c\u83b7\u5f97\u989d\u5916\u589e\u76ca\u3002", "conclusion": "ShaPO\u901a\u8fc7\u4f18\u5316\u51e0\u4f55\u89c6\u89d2\u89e3\u51b3LLM\u5b89\u5168\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u5b9e\u8bc1\u652f\u6301\u4e86\u6240\u63d0\u51fa\u7684\u4f18\u5316\u51e0\u4f55\u89c6\u89d2\uff0c\u4e3a\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u611f\u77e5\u65b9\u6cd5\u3002"}}
{"id": "2602.08287", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08287", "abs": "https://arxiv.org/abs/2602.08287", "authors": ["Themistoklis Haris", "Zihan Zhang", "Yuichi Yoshida"], "title": "Noise Stability of Transformer Models", "comment": "Published in ICLR 2026", "summary": "Understanding simplicity biases in deep learning offers a promising path toward developing reliable AI. A common metric for this, inspired by Boolean function analysis, is average sensitivity, which captures a model's robustness to single-token perturbations. We argue that average sensitivity has two key limitations: it lacks a natural generalization to real-valued domains and fails to explain the \"junta-like\" input dependence we empirically observe in modern LLMs. To address these limitations, we propose noise stability as a more comprehensive simplicity metric. Noise stability expresses a model's robustness to correlated noise applied to all input coordinates simultaneously. We provide a theoretical analysis of noise stability for single-layer attention and ReLU MLP layers and tackle the multi-layer propagation problem with a covariance interval propagation approach. Building on this theory, we develop a practical noise stability regularization method. Experiments on algorithmic and next-token-prediction tasks show that our regularizer consistently catalyzes grokking and accelerates training by approximately $35\\%$ and $75\\%$ respectively. Our results sculpt a new connection between signal propagation in neural networks and interpretability, with noise stability emerging as a powerful tool for understanding and improving modern Transformers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u566a\u58f0\u7a33\u5b9a\u6027\u66ff\u4ee3\u5e73\u5747\u654f\u611f\u5ea6\u4f5c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7b80\u5355\u6027\u504f\u597d\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6b63\u5219\u5316\u65b9\u6cd5\u52a0\u901fTransformer\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u663e\u8457\u4fc3\u8fdbgrokking\u73b0\u8c61\u5e76\u52a0\u901f\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5e03\u5c14\u51fd\u6570\u5206\u6790\u7684\u5e73\u5747\u654f\u611f\u5ea6\u6307\u6807\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u7f3a\u4e4f\u5bf9\u5b9e\u503c\u57df\u7684\u81ea\u7136\u6cdb\u5316\uff0c\u4e14\u65e0\u6cd5\u89e3\u91ca\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u7684\"junta-like\"\u8f93\u5165\u4f9d\u8d56\u6a21\u5f0f\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u7b80\u5355\u6027\u5ea6\u91cf\u6765\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u7b80\u5355\u6027\u504f\u597d\u3002", "method": "\u63d0\u51fa\u566a\u58f0\u7a33\u5b9a\u6027\u4f5c\u4e3a\u66ff\u4ee3\u5ea6\u91cf\uff0c\u8868\u8fbe\u6a21\u578b\u5bf9\u6240\u6709\u8f93\u5165\u5750\u6807\u540c\u65f6\u65bd\u52a0\u76f8\u5173\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002\u5bf9\u5355\u5c42\u6ce8\u610f\u529b\u673a\u5236\u548cReLU MLP\u5c42\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u91c7\u7528\u534f\u65b9\u5dee\u533a\u95f4\u4f20\u64ad\u65b9\u6cd5\u89e3\u51b3\u591a\u5c42\u4f20\u64ad\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u5b9e\u7528\u7684\u566a\u58f0\u7a33\u5b9a\u6027\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u7b97\u6cd5\u4efb\u52a1\u548c\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u566a\u58f0\u7a33\u5b9a\u6027\u6b63\u5219\u5316\u80fd\u6301\u7eed\u50ac\u5316grokking\u73b0\u8c61\uff0c\u5206\u522b\u52a0\u901f\u8bad\u7ec3\u7ea635%\u548c75%\u3002", "conclusion": "\u566a\u58f0\u7a33\u5b9a\u6027\u6210\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u73b0\u4ee3Transformer\u7684\u6709\u529b\u5de5\u5177\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u4fe1\u53f7\u4f20\u64ad\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u5efa\u7acb\u4e86\u65b0\u7684\u8fde\u63a5\u3002"}}
{"id": "2602.08028", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08028", "abs": "https://arxiv.org/abs/2602.08028", "authors": ["Po-Chun Chen", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning", "comment": "Accepted to Findings of IJCNLP-AACL 2025", "summary": "To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.", "AI": {"tldr": "DIP\uff08Diverge-to-Induce Prompting\uff09\u901a\u8fc7\u751f\u6210\u591a\u4e2a\u591a\u6837\u5316\u63a8\u7406\u7b56\u7565\u5e76\u6574\u5408\u4e3a\u6700\u7ec8\u8ba1\u5212\uff0c\u63d0\u5347\u96f6\u6837\u672c\u63a8\u7406\u51c6\u786e\u6027\uff0c\u65e0\u9700\u4f9d\u8d56\u8d44\u6e90\u5bc6\u96c6\u578b\u91c7\u6837\u3002", "motivation": "\u6807\u51c6\u601d\u7ef4\u94fe\u63d0\u793a\u4e2d\u65e0\u5f15\u5bfc\u7684\u63a8\u7406\u8def\u5f84\u4e0d\u7a33\u5b9a\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f7f\u7528\u5355\u4e00\u63a8\u7406\u7b56\u7565\u9650\u5236\u4e86\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "DIP\u6846\u67b6\uff1a1) \u4e3a\u6bcf\u4e2a\u95ee\u9898\u751f\u6210\u591a\u4e2a\u591a\u6837\u5316\u9ad8\u5c42\u63a8\u7406\u601d\u8def\uff1b2) \u5c06\u6bcf\u4e2a\u601d\u8def\u6269\u5c55\u4e3a\u8be6\u7ec6\u7684\u6b65\u9aa4\u8349\u6848\u8ba1\u5212\uff1b3) \u5c06\u8fd9\u4e9b\u8349\u6848\u8ba1\u5212\u6574\u5408\u8bf1\u5bfc\u4e3a\u6700\u7ec8\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDIP\u4f18\u4e8e\u5355\u4e00\u7b56\u7565\u63d0\u793a\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u591a\u8ba1\u5212\u8bf1\u5bfc\u5728\u57fa\u4e8e\u63d0\u793a\u7684\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u591a\u6837\u5316\u7b56\u7565\u751f\u6210\u548c\u6574\u5408\uff0cDIP\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u8d44\u6e90\u5bc6\u96c6\u578b\u91c7\u6837\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u63a8\u7406\u51c6\u786e\u6027\u3002"}}
{"id": "2602.07883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07883", "abs": "https://arxiv.org/abs/2602.07883", "authors": ["Jingqi Zhou", "Sheng Wang", "DeZhao Deng", "Junwen Lu", "Junwei Su", "Qintong Li", "Jiahui Gao", "Hao Wu", "Jiyue Jiang", "Lingpeng Kong", "Chuan Wu"], "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation", "comment": null, "summary": "Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.", "AI": {"tldr": "ToolSelf\uff1a\u4e00\u79cd\u5de5\u5177\u9a71\u52a8\u7684\u8fd0\u884c\u65f6\u81ea\u91cd\u6784\u8303\u5f0f\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u66f4\u65b0\u914d\u7f6e\u4ee5\u9002\u5e94\u4efb\u52a1\u52a8\u6001\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u6267\u884c\u8005\u5230\u4efb\u52a1\u4e0e\u81ea\u6211\u53cc\u91cd\u7ba1\u7406\u8005\u7684\u8f6c\u53d8\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u9759\u6001\u914d\u7f6e\u95ee\u9898\uff0c\u8fd9\u4e9b\u914d\u7f6e\u5728\u6267\u884c\u524d\u56fa\u5b9a\uff0c\u65e0\u6cd5\u9002\u5e94\u4efb\u52a1\u52a8\u6001\u53d8\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f16\u6392\u6216\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u8865\u4e01\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\u4e14\u4f18\u5316\u788e\u7247\u5316\u3002", "method": "\u63d0\u51faToolSelf\u8303\u5f0f\uff0c\u5c06\u914d\u7f6e\u66f4\u65b0\u62bd\u8c61\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\uff0c\u7edf\u4e00\u4efb\u52a1\u6267\u884c\u548c\u81ea\u8c03\u6574\u5230\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u3002\u91c7\u7528\u914d\u7f6e\u611f\u77e5\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08CAT\uff09\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u548c\u8f68\u8ff9\u7ea7\u5f3a\u5316\u5b66\u4e60\u6765\u5185\u5316\u8fd9\u79cd\u5143\u80fd\u529b\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cToolSelf\u5ab2\u7f8e\u4e13\u7528\u5de5\u4f5c\u6d41\u7684\u540c\u65f6\u80fd\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u534724.1%\uff0c\u4e3a\u5b9e\u73b0\u771f\u6b63\u81ea\u9002\u5e94\u667a\u80fd\u4f53\u6307\u660e\u4e86\u8def\u5f84\u3002", "conclusion": "ToolSelf\u901a\u8fc7\u5de5\u5177\u9a71\u52a8\u7684\u8fd0\u884c\u65f6\u81ea\u91cd\u6784\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u9002\u5e94\u4efb\u52a1\u52a8\u6001\uff0c\u4ece\u5916\u90e8\u89c4\u5219\u8f6c\u5411\u5185\u5728\u53c2\u6570\uff0c\u4e3a\u5b9e\u73b0\u771f\u6b63\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.07341", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07341", "abs": "https://arxiv.org/abs/2602.07341", "authors": ["Yicheng Yang", "Ruijiao Li", "Lifeng Wang", "Shuai Zheng", "Shunzheng Ma", "Keyu Zhang", "Tuoyu Sun", "Chenyun Dai", "Jie Ding", "Zhuo Zou"], "title": "Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions", "comment": null, "summary": "This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified framework to address the general manipulation task problem. Specifically, the proposed method consists of two phases: i) In the first phase for pretraining, the policy is created in a behavior cloning (BC) manner, through leveraging the learning data from our AR-based remote human-robot interaction system; ii) In the second phase, a contrastive learning empowered reinforcement learning (RL) method is developed to obtain more efficient and robust policy than the BC, and thus a projection head is designed to accelerate the learning progress. An event-driven augmented reward is adopted for enhancing the safety. To validate the proposed method, both the physics simulations via PyBullet and real-world experiments are carried out. The results demonstrate that compared to the classic proximal policy optimization and soft actor-critic policies, our method not only significantly speeds up the inference, but also achieves much better performance in terms of the success rate for fulfilling the manipulation tasks. By conducting the ablation study, it is confirmed that the proposed RL with contrastive learning overcomes policy collapse. Supplementary demonstrations are available at https://cyberyyc.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408AR\u8fdc\u7a0b\u4eba\u673a\u4ea4\u4e92\u3001\u884c\u4e3a\u514b\u9686\u548c\u5bf9\u6bd4\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u7075\u5de7\u673a\u5668\u4eba\u624b\u81c2\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u64cd\u4f5c\u5b66\u4e60", "motivation": "\u89e3\u51b3\u7075\u5de7\u673a\u5668\u4eba\u624b\u81c2\u7cfb\u7edf\u64cd\u4f5c\u4efb\u52a1\u7684\u53ef\u6269\u5c55\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7AR\u8fdc\u7a0b\u4eba\u673a\u4ea4\u4e92\u63d0\u9ad8\u4e13\u5bb6\u793a\u8303\u6570\u636e\u6536\u96c6\u6548\u7387\uff0c\u514b\u670d\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6548\u7387\u4f4e\u548c\u7b56\u7565\u5d29\u6e83\u7684\u95ee\u9898", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7AR\u8fdc\u7a0b\u4eba\u673a\u4ea4\u4e92\u6536\u96c6\u6570\u636e\uff0c\u91c7\u7528\u884c\u4e3a\u514b\u9686\u9884\u8bad\u7ec3\u7b56\u7565\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f00\u53d1\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u6295\u5f71\u5934\u52a0\u901f\u5b66\u4e60\uff0c\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u589e\u5f3a\u5956\u52b1\u786e\u4fdd\u5b89\u5168", "result": "\u5728PyBullet\u7269\u7406\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4PPO\u548cSAC\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u5feb\u63a8\u7406\u901f\u5ea6\uff0c\u5728\u64cd\u4f5c\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u5bf9\u6bd4\u5b66\u4e60\u80fd\u514b\u670d\u7b56\u7565\u5d29\u6e83", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u7ed3\u5408AR\u8fdc\u7a0b\u4ea4\u4e92\u3001\u884c\u4e3a\u514b\u9686\u548c\u5bf9\u6bd4\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\uff0c\u80fd\u6709\u6548\u63d0\u9ad8\u7075\u5de7\u673a\u5668\u4eba\u64cd\u4f5c\u5b66\u4e60\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u53ef\u6269\u5c55\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u53ef\u884c\u65b9\u6848"}}
{"id": "2602.08307", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08307", "abs": "https://arxiv.org/abs/2602.08307", "authors": ["Mengxiao Zhang", "Yuheng Zhang", "Haipeng Luo", "Paul Mineiro"], "title": "Interaction-Grounded Learning for Contextual Markov Decision Processes with Personalized Feedback", "comment": null, "summary": "In this paper, we study Interaction-Grounded Learning (IGL) [Xie et al., 2021], a paradigm designed for realistic scenarios where the learner receives indirect feedback generated by an unknown mechanism, rather than explicit numerical rewards. While prior work on IGL provides efficient algorithms with provable guarantees, those results are confined to single-step settings, restricting their applicability to modern sequential decision-making systems such as multi-turn Large Language Model (LLM) deployments. To bridge this gap, we propose a computationally efficient algorithm that achieves a sublinear regret guarantee for contextual episodic Markov Decision Processes (MDPs) with personalized feedback. Technically, we extend the reward-estimator construction of Zhang et al. [2024a] from the single-step to the multi-step setting, addressing the unique challenges of decoding latent rewards under MDPs. Building on this estimator, we design an Inverse-Gap-Weighting (IGW) algorithm for policy optimization. Finally, we demonstrate the effectiveness of our method in learning personalized objectives from multi-turn interactions through experiments on both a synthetic episodic MDP and a real-world user booking dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u6b65\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u5c06Interaction-Grounded Learning\u4ece\u5355\u6b65\u6269\u5c55\u5230\u591a\u6b65MDP\u8bbe\u7f6e\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u53cd\u9988\u5b66\u4e60\u6f5c\u5728\u5956\u52b1\u51fd\u6570\u3002", "motivation": "\u73b0\u6709\u7684Interaction-Grounded Learning\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u6b65\u8bbe\u7f6e\uff0c\u65e0\u6cd5\u9002\u7528\u4e8e\u73b0\u4ee3\u591a\u6b65\u51b3\u7b56\u7cfb\u7edf\uff08\u5982\u591a\u8f6eLLM\u90e8\u7f72\uff09\uff0c\u9700\u8981\u5c06\u5176\u6269\u5c55\u5230\u591a\u6b65MDP\u73af\u5883\u3002", "method": "\u5c06Zhang\u7b49\u4eba[2024a]\u7684\u5956\u52b1\u4f30\u8ba1\u5668\u4ece\u5355\u6b65\u6269\u5c55\u5230\u591a\u6b65MDP\u8bbe\u7f6e\uff0c\u8bbe\u8ba1\u57fa\u4e8eInverse-Gap-Weighting(IGW)\u7684\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u89e3\u51b3MDP\u4e0b\u6f5c\u5728\u5956\u52b1\u89e3\u7801\u7684\u72ec\u7279\u6311\u6218\u3002", "result": "\u63d0\u51fa\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u5728\u4e0a\u4e0b\u6587\u60c5\u666fMDP\u4e2d\u5b9e\u73b0\u6b21\u7ebf\u6027\u9057\u61be\u4fdd\u8bc1\uff0c\u901a\u8fc7\u5728\u5408\u6210MDP\u548c\u771f\u5b9e\u7528\u6237\u9884\u8ba2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4ece\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b66\u4e60\u4e2a\u6027\u5316\u76ee\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6210\u529f\u5c06Interaction-Grounded Learning\u6269\u5c55\u5230\u591a\u6b65MDP\u8bbe\u7f6e\uff0c\u4e3a\u4ece\u95f4\u63a5\u53cd\u9988\u4e2d\u5b66\u4e60\u4e2a\u6027\u5316\u76ee\u6807\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u8f6e\u51b3\u7b56\u7cfb\u7edf\u3002"}}
{"id": "2602.08031", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08031", "abs": "https://arxiv.org/abs/2602.08031", "authors": ["Chenwang Wu", "Yiu-ming Cheung", "Shuhai Zhang", "Bo Han", "Defu Lian"], "title": "Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection", "comment": null, "summary": "While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u7684\u5206\u6570\u6821\u51c6\u7b56\u7565\uff0c\u7528\u4e8e\u6539\u8fdb\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u90bb\u5c45\u76f8\u4f3c\u6027\u548c\u521d\u59cb\u4e0d\u7a33\u5b9a\u6027\u5173\u7cfb\u6765\u6821\u51c6\u68c0\u6d4b\u5206\u6570\uff0c\u5728\u5404\u79cd\u5b9e\u9645\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u673a\u5668\u751f\u6210\u6587\u672c\u867d\u7136\u5e26\u6765\u4fbf\u5229\uff0c\u4f46\u4e5f\u5b58\u5728\u865a\u5047\u4fe1\u606f\u548c\u7f51\u7edc\u9493\u9c7c\u7b49\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u57fa\u4e8e\u5ea6\u91cf\u7684\u65b9\u6cd5\u6bd4\u590d\u6742\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u66f4\u5b9e\u7528\uff0c\u4f46\u5b58\u5728\u68c0\u6d4b\u5206\u6570\u5bb9\u6613\u53d7\u5230MGT\u751f\u6210\u8fc7\u7a0b\u56fa\u6709\u968f\u673a\u6027\u5f71\u54cd\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u9996\u5148\u5c06\u4ee3\u8868\u6027\u7684\u57fa\u4e8e\u5ea6\u91cf\u7684\u65b9\u6cd5\u7f6e\u4e8e\u7edf\u4e00\u6846\u67b6\u4e2d\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u6838\u5fc3\u6311\u6218\u3002\u7136\u540e\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u63ed\u793a\u4e86\u4e24\u79cd\u6709\u52a9\u4e8e\u6821\u51c6\u7684\u4e0a\u4e0b\u6587\u68c0\u6d4b\u5206\u6570\u5173\u7cfb\uff1a\u90bb\u5c45\u76f8\u4f3c\u6027\u548c\u521d\u59cb\u4e0d\u7a33\u5b9a\u6027\u3002\u63d0\u51fa\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u7684\u5206\u6570\u6821\u51c6\u7b56\u7565\uff0c\u901a\u8fc7\u5e73\u5747\u573a\u8fd1\u4f3c\u5b9e\u73b0\u4e3a\u8f7b\u91cf\u7ea7\u7ec4\u4ef6\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u68c0\u6d4b\u5668\u4e2d\u3002", "result": "\u5728\u8de8LLM\u548c\u6539\u5199\u653b\u51fb\u7b49\u5404\u79cd\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u6821\u51c6\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u4e2d\u5206\u6570\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u5efa\u6a21\u4e0a\u4e0b\u6587\u5173\u7cfb\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.07885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07885", "abs": "https://arxiv.org/abs/2602.07885", "authors": ["Zhenyuan Zhang", "Xianzhang Jia", "Zhiqin Yang", "Zhenbo Song", "Wei Xue", "Sirui Han", "Yike Guo"], "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck", "comment": null, "summary": "Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.", "AI": {"tldr": "MemFly\u662f\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\u7684LLM\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u8bb0\u5fc6\u6846\u67b6\u9762\u4e34\u4e00\u4e2a\u57fa\u672c\u56f0\u5883\uff1a\u65e2\u8981\u9ad8\u6548\u538b\u7f29\u5197\u4f59\u4fe1\u606f\uff0c\u53c8\u8981\u4e3a\u4e0b\u6e38\u4efb\u52a1\u4fdd\u6301\u7cbe\u786e\u68c0\u7d22\u3002\u8fd9\u79cd\u538b\u7f29\u4e0e\u7cbe\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u9700\u8981\u89e3\u51b3\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6700\u5c0f\u5316\u538b\u7f29\u71b5\u540c\u65f6\u6700\u5927\u5316\u76f8\u5173\u71b5\uff0c\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\u3002\u5f00\u53d1\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u6574\u5408\u8bed\u4e49\u3001\u7b26\u53f7\u548c\u62d3\u6251\u8def\u5f84\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u7cbe\u70bc\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cMemFly\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u5927\u5e45\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MemFly\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u8bb0\u5fc6\u7cfb\u7edf\u4e2d\u538b\u7f29\u6548\u7387\u4e0e\u68c0\u7d22\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\uff0c\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u5219\u548c\u6df7\u5408\u68c0\u7d22\u673a\u5236\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u8bb0\u5fc6\u7ba1\u7406\u3002"}}
{"id": "2602.07356", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07356", "abs": "https://arxiv.org/abs/2602.07356", "authors": ["Yonghui Yang", "Junwei Li", "Jilong Liu", "Yicheng He", "Fengbin Zhu", "Weibiao Huang", "Le Wu", "Richang Hong", "Tat-Seng Chua"], "title": "Controllable Value Alignment in Large Language Models through Neuron-Level Editing", "comment": null, "summary": "Aligning large language models (LLMs) with human values has become increasingly important as their influence on human behavior and decision-making expands. However, existing steering-based alignment methods suffer from limited controllability: steering a target value often unintentionally activates other, non-target values. To characterize this limitation, we introduce value leakage, a diagnostic notion that captures the unintended activation of non-target values during value steering, along with a normalized leakage metric grounded in Schwartz's value theory. In light of this analysis, we propose NeVA, a neuron-level editing framework for controllable value alignment in LLMs. NeVA identifies sparse, value-relevant neurons and performs inference-time activation editing, enabling fine-grained control without parameter updates or retraining. Experiments show that NeVA achieves stronger target value alignment while incurring smaller performance degradation on general capability. Moreover, NeVA significantly reduces the average leakage, with residual effects largely confined to semantically related value classes. Overall, NeVA offers a more controllable and interpretable mechanism for value alignment.", "AI": {"tldr": "NeVA\uff1a\u901a\u8fc7\u795e\u7ecf\u5143\u7ea7\u7f16\u8f91\u5b9e\u73b0\u53ef\u63a7\u4ef7\u503c\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u4ef7\u503c\u6cc4\u6f0f\u95ee\u9898", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f15\u5bfc\u7684\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u53ef\u63a7\u6027\u9650\u5236\uff1a\u5f15\u5bfc\u76ee\u6807\u4ef7\u503c\u65f6\u5f80\u5f80\u4f1a\u65e0\u610f\u4e2d\u6fc0\u6d3b\u5176\u4ed6\u975e\u76ee\u6807\u4ef7\u503c\uff08\u4ef7\u503c\u6cc4\u6f0f\u95ee\u9898\uff09\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u53ef\u63a7\u7684\u5bf9\u9f50\u673a\u5236", "method": "\u63d0\u51faNeVA\u6846\u67b6\uff1a1\uff09\u8bc6\u522b\u7a00\u758f\u7684\u4ef7\u503c\u76f8\u5173\u795e\u7ecf\u5143\uff1b2\uff09\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u6fc0\u6d3b\u7f16\u8f91\uff0c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u6216\u91cd\u65b0\u8bad\u7ec3\uff1b3\uff09\u57fa\u4e8eSchwartz\u4ef7\u503c\u7406\u8bba\u5efa\u7acb\u6807\u51c6\u5316\u6cc4\u6f0f\u5ea6\u91cf", "result": "NeVA\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u76ee\u6807\u4ef7\u503c\u5bf9\u9f50\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u901a\u7528\u80fd\u529b\u4e0b\u964d\uff1b\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u6cc4\u6f0f\u7387\uff0c\u6b8b\u4f59\u6548\u5e94\u4e3b\u8981\u5c40\u9650\u4e8e\u8bed\u4e49\u76f8\u5173\u7684\u4ef7\u503c\u7c7b\u522b", "conclusion": "NeVA\u4e3a\u4ef7\u503c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u53ef\u63a7\u548c\u53ef\u89e3\u91ca\u7684\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4ef7\u503c\u6cc4\u6f0f\u95ee\u9898"}}
{"id": "2602.08315", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08315", "abs": "https://arxiv.org/abs/2602.08315", "authors": ["Shunyu Zhao", "Yanfeng Yang", "Shuai Li", "Kenji Fukumizu"], "title": "Fast Flow Matching based Conditional Independence Tests for Causal Discovery", "comment": null, "summary": "Constraint-based causal discovery methods require a large number of conditional independence (CI) tests, which severely limits their practical applicability due to high computational complexity. Therefore, it is crucial to design an algorithm that accelerates each individual test. To this end, we propose the Flow Matching-based Conditional Independence Test (FMCIT). The proposed test leverages the high computational efficiency of flow matching and requires the model to be trained only once throughout the entire causal discovery procedure, substantially accelerating causal discovery. According to numerical experiments, FMCIT effectively controls type-I error and maintains high testing power under the alternative hypothesis, even in the presence of high-dimensional conditioning sets. In addition, we further integrate FMCIT into a two-stage guided PC skeleton learning framework, termed GPC-FMCIT, which combines fast screening with guided, budgeted refinement using FMCIT. This design yields explicit bounds on the number of CI queries while maintaining high statistical power. Experiments on synthetic and real-world causal discovery tasks demonstrate favorable accuracy-efficiency trade-offs over existing CI testing methods and PC variants.", "AI": {"tldr": "\u63d0\u51faFMCIT\uff08\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u7684\u9ad8\u8ba1\u7b97\u6548\u7387\u52a0\u901f\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\uff0c\u5e76\u8fdb\u4e00\u6b65\u6574\u5408\u5230GPC-FMCIT\u4e24\u9636\u6bb5\u6846\u67b6\u4e2d\uff0c\u5728\u4fdd\u8bc1\u7edf\u8ba1\u529f\u6548\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u57fa\u4e8e\u7ea6\u675f\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u9700\u8981\u8fdb\u884c\u5927\u91cf\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u52a0\u901f\u5355\u4e2a\u68c0\u9a8c\u7684\u7b97\u6cd5\u3002", "method": "\u63d0\u51faFMCIT\u65b9\u6cd5\uff0c\u5229\u7528\u6d41\u5339\u914d\u7684\u8ba1\u7b97\u9ad8\u6548\u6027\uff0c\u6574\u4e2a\u56e0\u679c\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u6a21\u578b\u53ea\u9700\u8bad\u7ec3\u4e00\u6b21\u3002\u8fdb\u4e00\u6b65\u5c06FMCIT\u6574\u5408\u5230\u4e24\u9636\u6bb5\u5f15\u5bfcPC\u9aa8\u67b6\u5b66\u4e60\u6846\u67b6GPC-FMCIT\u4e2d\uff0c\u7ed3\u5408\u5feb\u901f\u7b5b\u9009\u548c\u5f15\u5bfc\u7684\u9884\u7b97\u5316\u7cbe\u70bc\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660eFMCIT\u80fd\u6709\u6548\u63a7\u5236I\u7c7b\u9519\u8bef\uff0c\u5728\u9ad8\u7ef4\u6761\u4ef6\u96c6\u4e0b\u4ecd\u4fdd\u6301\u8f83\u9ad8\u7684\u68c0\u9a8c\u529f\u6548\u3002GPC-FMCIT\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709CI\u68c0\u9a8c\u65b9\u6cd5\u548cPC\u53d8\u4f53\u7684\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\u3002", "conclusion": "FMCIT\u901a\u8fc7\u6d41\u5339\u914d\u663e\u8457\u52a0\u901f\u4e86\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\uff0cGPC-FMCIT\u6846\u67b6\u5728\u4fdd\u8bc1\u7edf\u8ba1\u529f\u6548\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u660e\u786e\u7684CI\u67e5\u8be2\u6b21\u6570\u754c\u9650\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u51c6\u786e\u7387-\u6548\u7387\u5e73\u8861\u3002"}}
{"id": "2602.08048", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08048", "abs": "https://arxiv.org/abs/2602.08048", "authors": ["Arshia Hemmat", "Philip Torr", "Yongqiang Chen", "Junchi Yu"], "title": "TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs", "comment": null, "summary": "Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.", "AI": {"tldr": "TDGNet\u662f\u4e00\u4e2a\u7528\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u68c0\u6d4b\u7684\u65f6\u5e8f\u52a8\u6001\u56fe\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u53bb\u566a\u8fc7\u7a0b\u4e2d\u7684\u6ce8\u610f\u529b\u56fe\u6f14\u5316\u6765\u68c0\u6d4b\u5e7b\u89c9\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5e76\u884c\u53bb\u566a\u548c\u53cc\u5411\u4e0a\u4e0b\u6587\u4f18\u52bf\uff0c\u4f46\u5176\u5e7b\u89c9\u68c0\u6d4b\u7814\u7a76\u4e0d\u8db3\u3002\u73b0\u6709\u7684\u81ea\u56de\u5f52LLM\u68c0\u6d4b\u5668\u4f9d\u8d56\u5355\u6b21\u63a8\u7406\u7ebf\u7d22\uff0c\u4e0d\u9002\u7528\u4e8e\u6269\u6563\u751f\u6210\uff0c\u56e0\u4e3a\u4e8b\u5b9e\u8bc1\u636e\u5206\u5e03\u5728\u53bb\u566a\u8f68\u8ff9\u4e2d\uff0c\u53ef\u80fd\u968f\u65f6\u95f4\u51fa\u73b0\u3001\u6f02\u79fb\u6216\u81ea\u6211\u4fee\u6b63", "method": "\u63d0\u51faTDGNet\u65f6\u5e8f\u52a8\u6001\u56fe\u6846\u67b6\uff0c\u5c06\u5e7b\u89c9\u68c0\u6d4b\u5efa\u6a21\u4e3a\u5728\u6f14\u5316\u4e2d\u7684token\u7ea7\u6ce8\u610f\u529b\u56fe\u4e0a\u7684\u5b66\u4e60\u3002\u5728\u6bcf\u4e2a\u53bb\u566a\u6b65\u9aa4\u4e2d\uff0c\u7a00\u758f\u5316\u6ce8\u610f\u529b\u56fe\u5e76\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u66f4\u65b0\u6bcf\u4e2atoken\u7684\u8bb0\u5fc6\uff0c\u7136\u540e\u4f7f\u7528\u65f6\u5e8f\u6ce8\u610f\u529b\u805a\u5408\u6574\u4e2a\u8f68\u8ff9\u7684\u8bc1\u636e\u8fdb\u884c\u6700\u7ec8\u9884\u6d4b", "result": "\u5728LLaDA-8B\u548cDream-7B\u6a21\u578b\u4e0a\u7684QA\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u4e8e\u8f93\u51fa\u3001\u6f5c\u5728\u8868\u793a\u548c\u9759\u6001\u56fe\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0cTDGNet\u5728AUROC\u6307\u6807\u4e0a\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5177\u6709\u5355\u6b21\u63a8\u7406\u548c\u9002\u5ea6\u5f00\u9500", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5bf9\u6ce8\u610f\u529b\u56fe\u8fdb\u884c\u65f6\u5e8f\u63a8\u7406\u5bf9\u4e8e\u9c81\u68d2\u7684\u5e7b\u89c9\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u3002TDGNet\u6846\u67b6\u6709\u6548\u5229\u7528\u4e86\u6269\u6563\u751f\u6210\u8fc7\u7a0b\u7684\u52a8\u6001\u7279\u6027"}}
{"id": "2602.07903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07903", "abs": "https://arxiv.org/abs/2602.07903", "authors": ["Mingcan Wang", "Junchang Xin", "Zhongming Yao", "Kaifu Long", "Zhiqiong Wang"], "title": "GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank", "comment": null, "summary": "The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structure-level remedies, the overall performance of GCNs still suffers from limited accuracy, poor stability, and unaffordable computational cost. Moreover, neglect of higher-order relationships during the propagation of MPNNs has further limited the performance of them. To overcome these challenges, a novel variant of PageRank named motif-based personalized PageRank (MPPR) is proposed to measure the influence of one node to another on the basis of considering higher-order motif relationships. Secondly, the MPPR is utilized to the message passing process of GCNs, thereby guiding the message passing process at a relatively `high' level. The experimental results show that the proposed method outperforms almost all of the baselines on accuracy, stability, and time consumption. Additionally, the proposed method can be considered as a component that can underpin almost all GCN tasks, with DGCRL being demonstrated in the experiment. The anonymous code repository is available at: https://anonymous.4open.science/r/GCN-MPPR-AFD6/.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8emotif\u7684\u4e2a\u6027\u5316PageRank(MPPR)\u6765\u6539\u8fdbGCN\u7684\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\uff0c\u89e3\u51b3\u73b0\u6709MPNNs\u6df1\u5ea6\u53d7\u9650\u3001\u5ffd\u7565\u9ad8\u9636\u5173\u7cfb\u7684\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u6709\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u56fe\u795e\u7ecf\u7f51\u7edc(MPNNs)\u5b58\u5728\u6df1\u5ea6\u53d7\u9650\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u8fc7\u5e73\u6ed1\u73b0\u8c61\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u6216\u7ed3\u6784\u8c03\u6574\u6765\u5e94\u5bf9\uff0c\u4f46GCNs\u4ecd\u9762\u4e34\u51c6\u786e\u6027\u6709\u9650\u3001\u7a33\u5b9a\u6027\u5dee\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0cMPNNs\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u5ffd\u7565\u4e86\u9ad8\u9636\u5173\u7cfb\uff0c\u8fdb\u4e00\u6b65\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3amotif-based personalized PageRank (MPPR)\u7684\u65b0\u53d8\u4f53\uff0c\u5728\u8003\u8651\u9ad8\u9636motif\u5173\u7cfb\u7684\u57fa\u7840\u4e0a\u8861\u91cf\u8282\u70b9\u95f4\u5f71\u54cd\u529b\u3002\u7136\u540e\u5c06MPPR\u5e94\u7528\u4e8eGCN\u7684\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\uff0c\u5728\u76f8\u5bf9\"\u9ad8\"\u5c42\u6b21\u4e0a\u6307\u5bfc\u6d88\u606f\u4f20\u9012\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u65f6\u95f4\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u51e0\u4e4e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u652f\u6491\u51e0\u4e4e\u6240\u6709GCN\u4efb\u52a1\u7684\u7ec4\u4ef6\uff0c\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86DGCRL\u7684\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684MPPR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86GCNs\u6df1\u5ea6\u53d7\u9650\u548c\u5ffd\u7565\u9ad8\u9636\u5173\u7cfb\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2602.07358", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07358", "abs": "https://arxiv.org/abs/2602.07358", "authors": ["Jiaming He", "Fuming Luo", "Hongwei Li", "Wenbo Jiang", "Wenshu Fan", "Zhenbo Shi", "Xudong Jiang", "Yi Yu"], "title": "UTOPIA: Unlearnable Tabular Data via Decoupled Shortcut Embedding", "comment": null, "summary": "Unlearnable examples (UE) have emerged as a practical mechanism to prevent unauthorized model training on private vision data, while extending this protection to tabular data is nontrivial. Tabular data in finance and healthcare is highly sensitive, yet existing UE methods transfer poorly because tabular features mix numerical and categorical constraints and exhibit saliency sparsity, with learning dominated by a few dimensions. Under a Spectral Dominance condition, we show certified unlearnability is feasible when the poison spectrum overwhelms the clean semantic spectrum. Guided by this, we propose Unlearnable Tabular Data via DecOuPled Shortcut EmbeddIng (UTOPIA), which exploits feature redundancy to decouple optimization into two channels: high saliency features for semantic obfuscation and low saliency redundant features for embedding a hyper correlated shortcut, yielding constraint-aware dominant shortcuts while preserving tabular validity. Extensive experiments across tabular datasets and models show UTOPIA drives unauthorized training toward near random performance, outperforming strong UE baselines and transferring well across architectures.", "AI": {"tldr": "UTOPIA\u65b9\u6cd5\u901a\u8fc7\u89e3\u8026\u4f18\u5316\u901a\u9053\uff0c\u5728\u9ad8\u663e\u8457\u6027\u7279\u5f81\u4e0a\u8fdb\u884c\u8bed\u4e49\u6df7\u6dc6\uff0c\u5728\u4f4e\u663e\u8457\u6027\u5197\u4f59\u7279\u5f81\u4e2d\u5d4c\u5165\u8d85\u76f8\u5173\u6377\u5f84\uff0c\u4e3a\u8868\u683c\u6570\u636e\u63d0\u4f9b\u8ba4\u8bc1\u4e0d\u53ef\u5b66\u4e60\u6027\u4fdd\u62a4", "motivation": "\u91d1\u878d\u548c\u533b\u7597\u9886\u57df\u7684\u8868\u683c\u6570\u636e\u9ad8\u5ea6\u654f\u611f\uff0c\u4f46\u73b0\u6709\u4e0d\u53ef\u5b66\u4e60\u793a\u4f8b\u65b9\u6cd5\u5728\u8868\u683c\u6570\u636e\u4e0a\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8868\u683c\u7279\u5f81\u6df7\u5408\u4e86\u6570\u503c\u548c\u5206\u7c7b\u7ea6\u675f\uff0c\u4e14\u5b58\u5728\u663e\u8457\u6027\u7a00\u758f\u6027\uff08\u5b66\u4e60\u4e3b\u8981\u7531\u5c11\u6570\u7ef4\u5ea6\u4e3b\u5bfc\uff09", "method": "\u63d0\u51faUTOPIA\u65b9\u6cd5\uff0c\u5229\u7528\u7279\u5f81\u5197\u4f59\u5c06\u4f18\u5316\u89e3\u8026\u4e3a\u4e24\u4e2a\u901a\u9053\uff1a\u9ad8\u663e\u8457\u6027\u7279\u5f81\u7528\u4e8e\u8bed\u4e49\u6df7\u6dc6\uff0c\u4f4e\u663e\u8457\u6027\u5197\u4f59\u7279\u5f81\u7528\u4e8e\u5d4c\u5165\u8d85\u76f8\u5173\u6377\u5f84\uff0c\u5728\u4fdd\u6301\u8868\u683c\u6709\u6548\u6027\u7684\u540c\u65f6\u751f\u6210\u7ea6\u675f\u611f\u77e5\u7684\u4e3b\u5bfc\u6377\u5f84", "result": "\u5728\u591a\u4e2a\u8868\u683c\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUTOPIA\u80fd\u5c06\u672a\u7ecf\u6388\u6743\u7684\u8bad\u7ec3\u63a8\u5411\u63a5\u8fd1\u968f\u673a\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u4e0d\u53ef\u5b66\u4e60\u793a\u4f8b\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u8de8\u67b6\u6784\u8fc1\u79fb", "conclusion": "\u5728\u6ee1\u8db3\u8c31\u4e3b\u5bfc\u6761\u4ef6\u4e0b\uff0c\u5f53\u6bd2\u5316\u8c31\u538b\u5012\u5e72\u51c0\u8bed\u4e49\u8c31\u65f6\uff0c\u8868\u683c\u6570\u636e\u7684\u8ba4\u8bc1\u4e0d\u53ef\u5b66\u4e60\u6027\u662f\u53ef\u884c\u7684\uff0cUTOPIA\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u73b0\u65b9\u6cd5"}}
{"id": "2602.08350", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08350", "abs": "https://arxiv.org/abs/2602.08350", "authors": ["Tal Burla", "Roi Livni"], "title": "All ERMs Can Fail in Stochastic Convex Optimization Lower Bounds in Linear Dimension", "comment": null, "summary": "We study the sample complexity of the best-case Empirical Risk Minimizer in the setting of stochastic convex optimization. We show that there exists an instance in which the sample size is linear in the dimension, learning is possible, but the Empirical Risk Minimizer is likely to be unique and to overfit. This resolves an open question by Feldman. We also extend this to approximate ERMs.\n  Building on our construction we also show that (constrained) Gradient Descent potentially overfits when horizon and learning rate grow w.r.t sample size. Specifically we provide a novel generalization lower bound of $\u03a9\\left(\\sqrt{\u03b7T/m^{1.5}}\\right)$ for Gradient Descent, where $\u03b7$ is the learning rate, $T$ is the horizon and $m$ is the sample size. This narrows down, exponentially, the gap between the best known upper bound of $O(\u03b7T/m)$ and existing lower bounds from previous constructions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u968f\u673a\u51f8\u4f18\u5316\u4e2d\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668(ERM)\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u53d1\u73b0\u5b58\u5728\u7ef4\u5ea6\u7ebf\u6027\u6837\u672c\u60c5\u51b5\u4e0bERM\u4f1a\u8fc7\u62df\u5408\uff0c\u5e76\u7ed9\u51fa\u4e86\u68af\u5ea6\u4e0b\u964d\u7684\u6cdb\u5316\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u51f8\u4f18\u5316\u4e2d\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668(ERM)\u7684\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u7279\u522b\u662f\u89e3\u51b3Feldman\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\uff1a\u662f\u5426\u5b58\u5728\u6837\u672c\u91cf\u968f\u7ef4\u5ea6\u7ebf\u6027\u589e\u957f\u65f6\uff0c\u5b66\u4e60\u53ef\u884c\u4f46ERM\u4f1a\u8fc7\u62df\u5408\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u6784\u9020\u5177\u4f53\u5b9e\u4f8b\u8bc1\u660eERM\u7684\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u9020\u5206\u6790\u7ea6\u675f\u68af\u5ea6\u4e0b\u964d\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u63a8\u5bfc\u51fa\u6cdb\u5316\u8bef\u5dee\u4e0b\u754c\u3002", "result": "1. \u5b58\u5728\u5b9e\u4f8b\u4e2d\u6837\u672c\u91cf\u968f\u7ef4\u5ea6\u7ebf\u6027\u589e\u957f\u65f6\uff0cERM\u53ef\u80fd\u552f\u4e00\u4e14\u8fc7\u62df\u5408\uff1b2. \u68af\u5ea6\u4e0b\u964d\u7684\u6cdb\u5316\u4e0b\u754c\u4e3a\u03a9(\u221a(\u03b7T/m^1.5))\uff0c\u663e\u8457\u7f29\u5c0f\u4e86\u73b0\u6709\u4e0a\u4e0b\u754c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668\u5728\u968f\u673a\u51f8\u4f18\u5316\u4e2d\u53ef\u80fd\u8fc7\u62df\u5408\uff0c\u5373\u4f7f\u5b66\u4e60\u53ef\u884c\uff1b\u68af\u5ea6\u4e0b\u964d\u7684\u6cdb\u5316\u6027\u80fd\u53d7\u5b66\u4e60\u7387\u3001\u8fed\u4ee3\u6b21\u6570\u548c\u6837\u672c\u91cf\u5f71\u54cd\uff0c\u5b58\u5728\u6307\u6570\u7ea7\u6539\u8fdb\u7684\u4e0b\u754c\u5206\u6790\u3002"}}
{"id": "2602.08100", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08100", "abs": "https://arxiv.org/abs/2602.08100", "authors": ["Jasmine Cui", "Charles Ye"], "title": "Emergent Search and Backtracking in Latent Reasoning Models", "comment": null, "summary": "What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.", "AI": {"tldr": "LRTs\u5728\u9690\u85cf\u7a7a\u95f4\u8fdb\u884c\u63a8\u7406\uff0c\u81ea\u53d1\u5b66\u4e60\u7ed3\u6784\u5316\u641c\u7d22\u8fc7\u7a0b\uff1a\u63a2\u7d22\u9636\u6bb5\u2192\u6682\u5b9a\u9009\u62e9\u2192\u6536\u655b\u6216\u56de\u6eaf\u3002\u56de\u6eaf\u5e38\u89c1\u4e14\u6709\u76ca\uff0c\u80fd\u907f\u5f00\u8bed\u4e49\u76f8\u8fd1\u7684\u5e72\u6270\u9879\uff0c\u641c\u7d22\u8fc7\u7a0b\u5177\u6709\u9002\u5e94\u6027\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u8bcd\u601d\u8003\u65f6\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u4f20\u7edfLLMs\u901a\u8fc7\u601d\u7ef4\u94fe\u8fdb\u884c\u8a00\u8bed\u5316\u4e2d\u95f4\u6b65\u9aa4\uff0c\u800cLRTs\u5728\u8fde\u7eed\u9690\u85cf\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5b8c\u5168\u63a8\u7406\uff0c\u63a2\u7d22\u8fd9\u79cd\u6f5c\u5728\u63a8\u7406\u673a\u5236\u7684\u5de5\u4f5c\u65b9\u5f0f\u3002", "method": "\u7814\u7a76\u4e00\u4e2aLRT\u6a21\u578b\uff0c\u5728\u591a\u9879\u9009\u62e9QA\u57fa\u51c6\u4e0a\u89e3\u7801\u6a21\u578b\u6bcf\u4e00\u6b65\u6f14\u53d8\u7684\u4fe1\u5ff5\u3002\u5206\u6790\u6a21\u578b\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u5316\u641c\u7d22\u8fc7\u7a0b\uff0c\u5305\u62ec\u63a2\u7d22\u3001\u627f\u8bfa\u3001\u6536\u655b\u6216\u56de\u6eaf\u7b49\u9636\u6bb5\u3002", "result": "\u6a21\u578b\u81ea\u53d1\u5b66\u4e60\u7ed3\u6784\u5316\u641c\u7d22\uff1a\u63a2\u7d22\u9636\u6bb5\u6982\u7387\u5206\u5e03\u6269\u6563\uff0c\u6682\u5b9a\u9009\u62e9\u9886\u5148\u9009\u9879\uff0c\u7136\u540e\u6536\u655b\u6216\u56de\u6eaf\u3002\u56de\u6eaf\u666e\u904d\uff0832%\u5b9e\u4f8b\uff09\u4e14\u6709\u76ca\uff08\u51c6\u786e\u7387\u63d0\u534734%\uff09\uff0c\u4e3b\u8981\u907f\u5f00\u8bed\u4e49\u76f8\u8fd1\u5e72\u6270\u9879\u8f6c\u5411\u6b63\u786e\u7b54\u6848\u3002\u641c\u7d22\u5177\u6709\u9002\u5e94\u6027\uff1a\u66ff\u6362\u5e72\u6270\u9879\u53ef\u7f29\u77ed\u63a2\u7d2254%\u3002", "conclusion": "\u6f5c\u5728\u63a8\u7406\u6a21\u578b\u5728\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u601d\u7ef4\u94fe\u901a\u8fc7\u8bcd\u8bed\u5b9e\u73b0\u7684\u529f\u80fd\uff1a\u80fd\u591f\u72af\u9519\u3001\u5bdf\u89c9\u5e76\u6062\u590d\u3002LRTs\u5c55\u793a\u4e86\u5728\u9690\u85cf\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7ed3\u6784\u5316\u641c\u7d22\u548c\u9002\u5e94\u6027\u63a8\u7406\u7684\u80fd\u529b\u3002"}}
{"id": "2602.07905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07905", "abs": "https://arxiv.org/abs/2602.07905", "authors": ["Yu Zhao", "Hao Guan", "Yongcheng Jing", "Ying Zhang", "Dacheng Tao"], "title": "MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically, we propose MedCoG, a Medical Meta-Cognition Agent with Knowledge Graph, where the meta-cognitive assessments of task complexity, familiarity, and knowledge density dynamically regulate utilization of procedural, episodic, and factual knowledge. The LLM-centric on-demand reasoning aims to mitigate scaling laws by (1) reducing costs via avoiding indiscriminate scaling, (2) improving accuracy via filtering out distractive knowledge. To validate this, we empirically characterize the scaling curve and introduce inference density to quantify inference efficiency, defined as the ratio of theoretically effective cost to actual cost. Experiments demonstrate the effectiveness and efficiency of MedCoG on five hard sets of medical benchmarks, yielding 5.5x inference density. Furthermore, the Oracle study highlights the significant potential of meta-cognitive regulation.", "AI": {"tldr": "MedCoG\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u533b\u5b66\u5143\u8ba4\u77e5\u4ee3\u7406\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u8bc4\u4f30\u52a8\u6001\u8c03\u8282\u77e5\u8bc6\u4f7f\u7528\uff0c\u5728\u51cf\u5c11\u6210\u672c\u7684\u540c\u65f6\u63d0\u9ad8\u533b\u7597\u63a8\u7406\u51c6\u786e\u6027\uff0c\u5b9e\u73b05.5\u500d\u63a8\u7406\u5bc6\u5ea6\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u533b\u7597\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u63a8\u7406\u6269\u5c55\u5b9a\u5f8b\u4e0b\u7684\u6536\u76ca\u9012\u51cf\u95ee\u9898\u3002\u73b0\u6709\u7814\u7a76\u901a\u8fc7\u589e\u52a0\u5404\u79cd\u77e5\u8bc6\u6765\u589e\u5f3aLLMs\uff0c\u4f46\u989d\u5916\u6210\u672c\u8f6c\u5316\u4e3a\u51c6\u786e\u6027\u7684\u6548\u679c\u4e0d\u660e\u786e\u3002\u9700\u8981\u63a2\u7d22LLMs\u7684\u5143\u8ba4\u77e5\uff08\u5bf9\u81ea\u8eab\u77e5\u8bc6\u72b6\u6001\u7684\u81ea\u6211\u610f\u8bc6\uff09\u5982\u4f55\u8c03\u8282\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faMedCoG\uff08Medical Meta-Cognition Agent with Knowledge Graph\uff09\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u8bc4\u4f30\u4efb\u52a1\u590d\u6742\u6027\u3001\u719f\u6089\u5ea6\u548c\u77e5\u8bc6\u5bc6\u5ea6\uff0c\u52a8\u6001\u8c03\u8282\u7a0b\u5e8f\u6027\u3001\u60c5\u666f\u6027\u548c\u4e8b\u5b9e\u6027\u77e5\u8bc6\u7684\u4f7f\u7528\u3002\u91c7\u7528LLM\u4e2d\u5fc3\u7684\u6309\u9700\u63a8\u7406\uff0c\u907f\u514d\u76f2\u76ee\u6269\u5c55\uff0c\u8fc7\u6ee4\u5e72\u6270\u77e5\u8bc6\u3002", "result": "\u5728\u4e94\u4e2a\u56f0\u96be\u7684\u533b\u7597\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u9a8c\u8bc1\u4e86MedCoG\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u5b9e\u73b0\u4e865.5\u500d\u7684\u63a8\u7406\u5bc6\u5ea6\u63d0\u5347\u3002Oracle\u7814\u7a76\u7a81\u663e\u4e86\u5143\u8ba4\u77e5\u8c03\u8282\u7684\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "\u5143\u8ba4\u77e5\u8c03\u8282\u80fd\u591f\u6709\u6548\u7f13\u89e3\u63a8\u7406\u6269\u5c55\u5b9a\u5f8b\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u77e5\u8bc6\u9009\u62e9\u548c\u6210\u672c\u63a7\u5236\uff0c\u5728\u533b\u7597\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.07364", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07364", "abs": "https://arxiv.org/abs/2602.07364", "authors": ["Jianchuan Yang", "Xi Chen", "Jidong Zhao"], "title": "FEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity", "comment": "43 pages, 26 figures, 8tables", "summary": "Graph neural networks (GNNs) naturally align with sparse operators and unstructured discretizations, making them a promising paradigm for physics-informed machine learning in computational mechanics. Motivated by discrete physics losses and Hierarchical Deep Learning Neural Network (HiDeNN) constructions, we embed finite-element (FEM) computations at nodes and Gauss points directly into message-passing layers and propose a numerically consistent FEM-Informed Hypergraph Neural Networks (FHGNN). Similar to conventional physics-informed neural networks (PINNs), training is purely physics-driven and requires no labeled data: the input is a node element hypergraph whose edges encode mesh connectivity. Guided by empirical results and condition-number analysis, we adopt an efficient variational loss. Validated on 3D benchmarks, including cyclic loading with isotropic/kinematic hardening, the proposed method delivers substantially improved accuracy and efficiency over recent, competitive PINN variants. By leveraging GPU-parallel tensor operations and the discrete representation, it scales effectively to large elastoplastic problems and can be competitive with, or faster than, multi-core FEM implementations at comparable accuracy. This work establishes a foundation for scalable, physics-embedded learning in nonlinear solid mechanics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6709\u9650\u5143\u5d4c\u5165\u65b9\u6cd5\uff08FHGNN\uff09\uff0c\u7528\u4e8e\u65e0\u6807\u7b7e\u6570\u636e\u7684\u7269\u7406\u9a71\u52a8\u8bad\u7ec3\uff0c\u5728\u975e\u7ebf\u6027\u56fa\u4f53\u529b\u5b66\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e0e\u7a00\u758f\u7b97\u5b50\u548c\u975e\u7ed3\u6784\u5316\u79bb\u6563\u5316\u5929\u7136\u5951\u5408\uff0c\u4e3a\u8ba1\u7b97\u529b\u5b66\u4e2d\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8303\u5f0f\u3002\u53d7\u79bb\u6563\u7269\u7406\u635f\u5931\u548c\u5206\u5c42\u6df1\u5ea6\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\uff08HiDeNN\uff09\u6784\u9020\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5c06\u6709\u9650\u5143\u8ba1\u7b97\u76f4\u63a5\u5d4c\u5165\u5230\u6d88\u606f\u4f20\u9012\u5c42\u4e2d\u3002", "method": "\u63d0\u51fa\u6709\u9650\u5143\u4fe1\u606f\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff08FHGNN\uff09\uff0c\u5728\u8282\u70b9\u548c\u9ad8\u65af\u70b9\u5904\u76f4\u63a5\u5d4c\u5165\u6709\u9650\u5143\u8ba1\u7b97\u5230\u6d88\u606f\u4f20\u9012\u5c42\u3002\u91c7\u7528\u9ad8\u6548\u7684\u53d8\u5206\u635f\u5931\u51fd\u6570\uff0c\u8f93\u5165\u662f\u7f16\u7801\u7f51\u683c\u8fde\u63a5\u6027\u7684\u8282\u70b9\u5143\u7d20\u8d85\u56fe\uff0c\u8bad\u7ec3\u5b8c\u5168\u57fa\u4e8e\u7269\u7406\u9a71\u52a8\uff0c\u65e0\u9700\u6807\u7b7e\u6570\u636e\u3002", "result": "\u57283D\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u5404\u5411\u540c\u6027/\u8fd0\u52a8\u786c\u5316\u7684\u5faa\u73af\u52a0\u8f7d\uff09\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6700\u8fd1\u7684\u7ade\u4e89\u6027PINN\u53d8\u4f53\u663e\u8457\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\u3002\u901a\u8fc7\u5229\u7528GPU\u5e76\u884c\u5f20\u91cf\u64cd\u4f5c\u548c\u79bb\u6563\u8868\u793a\uff0c\u80fd\u591f\u6709\u6548\u6269\u5c55\u5230\u5927\u578b\u5f39\u5851\u6027\u95ee\u9898\uff0c\u5728\u53ef\u6bd4\u7cbe\u5ea6\u4e0b\u53ef\u4e0e\u591a\u6838FEM\u5b9e\u73b0\u7ade\u4e89\u751a\u81f3\u66f4\u5feb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u975e\u7ebf\u6027\u56fa\u4f53\u529b\u5b66\u4e2d\u53ef\u6269\u5c55\u7684\u7269\u7406\u5d4c\u5165\u5b66\u4e60\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86FHGNN\u5728\u8ba1\u7b97\u529b\u5b66\u4e2d\u7684\u6f5c\u529b\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.08467", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08467", "abs": "https://arxiv.org/abs/2602.08467", "authors": ["Charalampos Shimillas", "Kleanthis Malialis", "Konstantinos Fokianos", "Marios M. Polycarpou"], "title": "Low Rank Transformer for Multivariate Time Series Anomaly Detection and Localization", "comment": null, "summary": "Multivariate time series (MTS) anomaly diagnosis, which encompasses both anomaly detection and localization, is critical for the safety and reliability of complex, large-scale real-world systems. The vast majority of existing anomaly diagnosis methods offer limited theoretical insights, especially for anomaly localization, which is a vital but largely unexplored area. The aim of this contribution is to study the learning process of a Transformer when applied to MTS by revealing connections to statistical time series methods. Based on these theoretical insights, we propose the Attention Low-Rank Transformer (ALoRa-T) model, which applies low-rank regularization to self-attention, and we introduce the Attention Low-Rank score, effectively capturing the temporal characteristics of anomalies. Finally, to enable anomaly localization, we propose the ALoRa-Loc method, a novel approach that associates anomalies to specific variables by quantifying interrelationships among time series. Extensive experiments and real data analysis, show that the proposed methodology significantly outperforms state-of-the-art methods in both detection and localization tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faALoRa-T\u6a21\u578b\u548cALoRa-Loc\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u6b63\u5219\u5316\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u91cf\u5316\u65f6\u95f4\u5e8f\u5217\u95f4\u5173\u7cfb\uff0c\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u8bca\u65ad\uff08\u68c0\u6d4b\u548c\u5b9a\u4f4d\uff09\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u8bca\u65ad\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u6d1e\u5bdf\uff0c\u7279\u522b\u662f\u5f02\u5e38\u5b9a\u4f4d\u8fd9\u4e00\u91cd\u8981\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002\u9700\u8981\u4ece\u7406\u8bba\u4e0a\u7406\u89e3Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u4e0e\u7edf\u8ba1\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u5efa\u7acb\u8054\u7cfb\u3002", "method": "1. \u63d0\u51faAttention Low-Rank Transformer (ALoRa-T)\u6a21\u578b\uff0c\u5bf9\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5e94\u7528\u4f4e\u79e9\u6b63\u5219\u5316\uff1b2. \u5f15\u5165Attention Low-Rank\u5206\u6570\u6355\u6349\u5f02\u5e38\u7684\u65f6\u95f4\u7279\u5f81\uff1b3. \u63d0\u51faALoRa-Loc\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u65f6\u95f4\u5e8f\u5217\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\u5c06\u5f02\u5e38\u5173\u8054\u5230\u7279\u5b9a\u53d8\u91cf\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u548c\u771f\u5b9e\u6570\u636e\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4efb\u52a1\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u6d1e\u5bdf\u5c06Transformer\u4e0e\u7edf\u8ba1\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u7684ALoRa-T\u6a21\u578b\u548cALoRa-Loc\u65b9\u6cd5\u4e3a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u8bca\u65ad\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u68c0\u6d4b\u548c\u5b9a\u4f4d\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2602.08124", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08124", "abs": "https://arxiv.org/abs/2602.08124", "authors": ["Ke Xu", "Shera Potka", "Alex Thomo"], "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models", "comment": "Accepted at the 39th International Conference on Advanced Information Networking and Applications (AINA 2025)", "summary": "Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u4e86LLM\u5728\u751f\u6210\u4ea7\u54c1\u63a8\u8350\u65f6\u5b58\u5728\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u4e09\u79cd\u5206\u6790\u65b9\u6cd5\u63ed\u793a\u4e86\u63a8\u8350\u5185\u5bb9\u4e2d\u7684\u663e\u8457\u4eba\u53e3\u7fa4\u4f53\u5dee\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u6d88\u8d39\u8005\u4ea7\u54c1\u63a8\u8350\uff0c\u4f46\u5176\u53ef\u80fd\u5d4c\u5165\u548c\u653e\u5927\u6027\u522b\u4e0e\u79cd\u65cf\u504f\u89c1\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4f5c\u4e3a\u9996\u6279\u7cfb\u7edf\u8003\u5bdfLLM\u751f\u6210\u63a8\u8350\u4e2d\u504f\u89c1\u7684\u7814\u7a76\u4e4b\u4e00\u3002", "method": "\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u5f15\u5bfcLLM\u4e3a\u4e0d\u540c\u79cd\u65cf\u548c\u6027\u522b\u7fa4\u4f53\u751f\u6210\u4ea7\u54c1\u63a8\u8350\uff0c\u7136\u540e\u8fd0\u7528\u4e09\u79cd\u5206\u6790\u65b9\u6cd5\uff1a\u6807\u8bb0\u8bcd\u5206\u6790\u3001\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u548cJensen-Shannon\u6563\u5ea6\u6765\u8bc6\u522b\u548c\u91cf\u5316\u504f\u89c1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u4e4b\u95f4\u7684\u63a8\u8350\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660eLLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u9700\u8981\u66f4\u516c\u5e73\u7684\u8bbe\u8ba1\u3002", "conclusion": "LLM\u751f\u6210\u7684\u4ea7\u54c1\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u660e\u663e\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\uff0c\u8fd9\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u516c\u5e73\u7684LLM\u63a8\u8350\u7cfb\u7edf\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u91cf\u5316\u5206\u6790\u504f\u89c1\u7684\u65b9\u6cd5\u6846\u67b6\u3002"}}
{"id": "2602.07919", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07919", "abs": "https://arxiv.org/abs/2602.07919", "authors": ["Mansi", "Avinash Kori", "Francesca Toni", "Soteris Demetriou"], "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning", "comment": "Given the brittle nature of existing methods in unlearning harmful content in diffusion models, we propose TRuST, a novel approach for dynamically estimating target concept neurons and unlearning them by selectively fine-tuning", "summary": "Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.", "AI": {"tldr": "TRUST\u662f\u4e00\u79cd\u52a8\u6001\u5b9a\u4f4d\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u5fae\u8c03\u8fdb\u884c\u6982\u5ff5\u9057\u5fd8\u7684\u65b0\u65b9\u6cd5\uff0c\u91c7\u7528Hessian\u6b63\u5219\u5316\uff0c\u80fd\u6709\u6548\u5bf9\u6297\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u4e14\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\u3002", "motivation": "\u6587\u672c\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u6613\u88ab\u5229\u7528\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u4f20\u7edf\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\u4e3b\u8981\u5728\u5355\u4e2a\u6982\u5ff5\u5c42\u9762\u5904\u7406\uff0c\u4e14\u4f9d\u8d56\u5168\u6a21\u578b\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u6709\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\u662f\u9759\u6001\u7684\uff0c\u5bfc\u81f4\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTRUST\u65b9\u6cd5\uff1a1) \u52a8\u6001\u4f30\u8ba1\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\uff1b2) \u901a\u8fc7\u9009\u62e9\u6027\u5fae\u8c03\u8fdb\u884c\u6982\u5ff5\u9057\u5fd8\uff1b3) \u91c7\u7528Hessian\u6b63\u5219\u5316\u589e\u5f3a\u9c81\u68d2\u6027\u3002\u652f\u6301\u5355\u4e2a\u6982\u5ff5\u3001\u6982\u5ff5\u7ec4\u5408\u548c\u6761\u4ef6\u6982\u5ff5\u7684\u65e0\u6b63\u5219\u5316\u9057\u5fd8\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTRUST\u80fd\u6709\u6548\u5bf9\u6297\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u663e\u8457\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u6bd4SOTA\u65b9\u6cd5\u5feb\u5f97\u591a\u3002\u80fd\u6210\u529f\u9057\u5fd8\u5355\u4e2a\u6982\u5ff5\u3001\u6982\u5ff5\u7ec4\u5408\u548c\u6761\u4ef6\u6982\u5ff5\uff0c\u65e0\u9700\u7279\u5b9a\u6b63\u5219\u5316\u3002", "conclusion": "TRUST\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9759\u6001\u5b9a\u4f4d\u7684\u95ee\u9898\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08470", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08470", "abs": "https://arxiv.org/abs/2602.08470", "authors": ["Kaizheng Wang", "Ghifari Adam Faza", "Fabio Cuzzolin", "Siu Lun Chau", "David Moens", "Hans Hallez"], "title": "Learning Credal Ensembles via Distributionally Robust Optimization", "comment": "32 pages", "summary": "Credal predictors are models that are aware of epistemic uncertainty and produce a convex set of probabilistic predictions. They offer a principled way to quantify predictive epistemic uncertainty (EU) and have been shown to improve model robustness in various settings. However, most state-of-the-art methods mainly define EU as disagreement caused by random training initializations, which mostly reflects sensitivity to optimization randomness rather than uncertainty from deeper sources. To address this, we define EU as disagreement among models trained with varying relaxations of the i.i.d. assumption between training and test data. Based on this idea, we propose CreDRO, which learns an ensemble of plausible models through distributionally robust optimization. As a result, CreDRO captures EU not only from training randomness but also from meaningful disagreement due to potential distribution shifts between training and test data. Empirical results show that CreDRO consistently outperforms existing credal methods on tasks such as out-of-distribution detection across multiple benchmarks and selective classification in medical applications.", "AI": {"tldr": "CreDRO\uff1a\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u5b66\u4e60\u96c6\u6210\u6a21\u578b\uff0c\u6355\u6349\u8bad\u7ec3\u968f\u673a\u6027\u548c\u5206\u5e03\u504f\u79fb\u5f15\u8d77\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728OOD\u68c0\u6d4b\u548c\u533b\u7597\u9009\u62e9\u5206\u7c7b\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u8ba4\u77e5\u9884\u6d4b\u5668\u4e3b\u8981\u5c06\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5b9a\u4e49\u4e3a\u968f\u673a\u8bad\u7ec3\u521d\u59cb\u5316\u5f15\u8d77\u7684\u5206\u6b67\uff0c\u8fd9\u4e3b\u8981\u53cd\u6620\u5bf9\u4f18\u5316\u968f\u673a\u6027\u7684\u654f\u611f\u6027\uff0c\u800c\u975e\u66f4\u6df1\u5c42\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u3002\u9700\u8981\u6355\u6349\u8bad\u7ec3-\u6d4b\u8bd5\u6570\u636e\u95f4\u6f5c\u5728\u5206\u5e03\u504f\u79fb\u5f15\u8d77\u7684\u66f4\u6709\u610f\u4e49\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51faCreDRO\u65b9\u6cd5\uff0c\u5c06\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5b9a\u4e49\u4e3a\u8bad\u7ec3-\u6d4b\u8bd5\u6570\u636ei.i.d.\u5047\u8bbe\u4e0d\u540c\u677e\u5f1b\u7a0b\u5ea6\u4e0b\u8bad\u7ec3\u6a21\u578b\u95f4\u7684\u5206\u6b67\u3002\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u5b66\u4e60\u4e00\u7ec4\u5408\u7406\u6a21\u578b\u7684\u96c6\u6210\uff0c\u6355\u6349\u8bad\u7ec3\u968f\u673a\u6027\u548c\u5206\u5e03\u504f\u79fb\u5f15\u8d77\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002", "result": "CreDRO\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u8ba4\u77e5\u65b9\u6cd5\uff0c\u5728\u5206\u5e03\u5916\u68c0\u6d4b\u4efb\u52a1\u548c\u533b\u7597\u5e94\u7528\u7684\u9009\u62e9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6355\u6349\u8bad\u7ec3\u968f\u673a\u6027\u548c\u5206\u5e03\u504f\u79fb\u5f15\u8d77\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0cCreDRO\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.08149", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08149", "abs": "https://arxiv.org/abs/2602.08149", "authors": ["Sahana Ramnath", "Nima Chitsazan", "Mingyang Zhou", "Chia-Hsuan Lee", "Shi-Xiong Zhang", "Stephen Rawls", "Sambit Sahu", "Sangwoo Cho", "Xiang Ren", "Genta Indra Winata", "Akshaj Kumar Veldanda"], "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries", "comment": null, "summary": "Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.", "AI": {"tldr": "DIALSUMMER\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u5bf9\u8bdd\u6458\u8981\uff0c\u901a\u8fc7\u5206\u5c42\u9519\u8bef\u5206\u7c7b\u89e3\u51b3\u5bf9\u8bdd\u5230\u6458\u8981\u7684\u7ed3\u6784\u548c\u89c6\u89d2\u8f6c\u6362\u95ee\u9898\uff0c\u5e76\u521b\u5efa\u4e86\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u5206\u6790\u9519\u8bef\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u6458\u8981\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u7565\u4e86\u5bf9\u8bdd\u6458\u8981\u4efb\u52a1\u7279\u6709\u7684\u590d\u6742\u6027\uff1a1) \u4ece\u591a\u8bf4\u8bdd\u8005\u5206\u6563\u8ba8\u8bba\u5230\u6458\u8981\u53e5\u5b50\u7684\u7ed3\u6784\u8f6c\u6362\uff1b2) \u4ece\u8bf4\u8bdd\u8005\u7b2c\u4e00/\u7b2c\u4e8c\u4eba\u79f0\u5230\u6458\u8981\u6807\u51c6\u5316\u7b2c\u4e09\u4eba\u79f0\u7684\u53d9\u8ff0\u89c6\u89d2\u8f6c\u6362\u3002", "method": "\u63d0\u51faDIALSUMMER\u6846\u67b6\uff0c\u5305\u542b\u4e24\u5c42\u9519\u8bef\u5206\u7c7b\uff1a\u5bf9\u8bdd\u5c42\u9762\u5173\u6ce8\u8bf4\u8bdd\u8005/\u8f6e\u6b21\uff0c\u8f6e\u6b21\u5185\u5c42\u9762\u5173\u6ce8\u5177\u4f53\u4fe1\u606f\u5185\u5bb9\u3002\u521b\u5efa\u4e86\u4eba\u5de5\u6807\u6ce8\u7684\u5bf9\u8bdd\u6458\u8981\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u4e86\u7ec6\u7c92\u5ea6\u9519\u8bef\u3002", "result": "\u5206\u6790\u53d1\u73b0\u6709\u8da3\u8d8b\u52bf\uff1a\u5bf9\u8bdd\u4e2d\u95f4\u8f6e\u6b21\u6700\u5bb9\u6613\u88ab\u9057\u6f0f\uff0c\u5916\u90e8\u5e7b\u89c9\u591a\u51fa\u73b0\u5728\u6458\u8981\u7ed3\u5c3e\u3002\u5b9e\u9a8c\u663e\u793aLLM-Judges\u5728\u68c0\u6d4b\u8fd9\u4e9b\u9519\u8bef\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u6570\u636e\u96c6\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "DIALSUMMER\u6846\u67b6\u548c\u6570\u636e\u96c6\u4e3a\u5bf9\u8bdd\u6458\u8981\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u9700\u8981\u6539\u8fdbLLM\u5728\u5bf9\u8bdd\u6458\u8981\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2602.07940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07940", "abs": "https://arxiv.org/abs/2602.07940", "authors": ["Guanglong Sun", "Hongwei Yan", "Liyuan Wang", "Zhiqi Kang", "Shuang Cui", "Hang Su", "Jun Zhu", "Yi Zhong"], "title": "MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin", "comment": null, "summary": "To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\\%, 13.36\\%, and 12.56\\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \\href{https://github.com/SunGL001/MePo}{MePo}", "AI": {"tldr": "MePo\u662f\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u901a\u7528\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u540e\u7cbe\u70bc\u548c\u5143\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5728\u65e0\u6392\u7ec3\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347GCL\u6027\u80fd\u3002", "motivation": "\u667a\u80fd\u7cfb\u7edf\u9700\u8981\u4ece\u590d\u6742\u3001\u6f14\u5316\u7684\u73af\u5883\u4e2d\u6301\u7eed\u5b66\u4e60\u5e76\u5b9e\u65f6\u54cd\u5e94\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6837\u5316\u3001\u65f6\u95f4\u6df7\u5408\u4fe1\u606f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u901a\u7528\u6301\u7eed\u5b66\u4e60\u6027\u80fd\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51faMeta Post-Refinement (MePo)\u65b9\u6cd5\uff1a1) \u4ece\u9884\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u4f2a\u4efb\u52a1\u5e8f\u5217\uff1b2) \u5f00\u53d1\u53cc\u5c42\u5143\u5b66\u4e60\u8303\u5f0f\u7cbe\u70bc\u9884\u8bad\u7ec3\u9aa8\u5e72\u7f51\u7edc\uff1b3) \u521d\u59cb\u5316\u5143\u534f\u65b9\u5dee\u77e9\u9635\u4f5c\u4e3a\u9884\u8bad\u7ec3\u8868\u793a\u7a7a\u95f4\u7684\u53c2\u8003\u51e0\u4f55\u7ed3\u6784\uff0c\u5229\u7528\u4e8c\u9636\u7edf\u8ba1\u8fdb\u884c\u9c81\u68d2\u8f93\u51fa\u5bf9\u9f50\u3002", "result": "MePo\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7b56\u7565\uff0c\u5728\u591a\u79cdGCL\u57fa\u51c6\u6d4b\u8bd5\u548c\u9884\u8bad\u7ec3\u68c0\u67e5\u70b9\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5728CIFAR-100\u3001ImageNet-R\u548cCUB-200\u4e0a\u5206\u522b\u8fbe\u523015.10%\u300113.36%\u548c12.56%\u7684\u6539\u8fdb\uff08Sup-21/1K\u8bbe\u7f6e\uff09\uff0c\u4e14\u65e0\u9700\u6392\u7ec3\u3002", "conclusion": "MePo\u901a\u8fc7\u5143\u540e\u7cbe\u70bc\u548c\u5143\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u901a\u7528\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9002\u5e94\u6027\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u793a\u5b66\u4e60\u5728\u4e0b\u6e38GCL\u4efb\u52a1\u4e2d\u7684\u5feb\u901f\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2602.08552", "categories": ["cs.LG", "eess.AS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08552", "abs": "https://arxiv.org/abs/2602.08552", "authors": ["Fredrik Cumlin"], "title": "Rho-Perfect: Correlation Ceiling For Subjective Evaluation Datasets", "comment": null, "summary": "Subjective ratings contain inherent noise that limits the model-human correlation, but this reliability issue is rarely quantified. In this paper, we present $\u03c1$-Perfect, a practical estimation of the highest achievable correlation of a model on subjectively rated datasets. We define $\u03c1$-Perfect to be the correlation between a perfect predictor and human ratings, and derive an estimate of the value based on heteroscedastic noise scenarios, a common occurrence in subjectively rated datasets. We show that $\u03c1$-Perfect squared estimates test-retest correlation and use this to validate the estimate. We demonstrate the use of $\u03c1$-Perfect on a speech quality dataset and show how the measure can distinguish between model limitations and data quality issues.", "AI": {"tldr": "\u63d0\u51fa\u03c1-Perfect\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u4e3b\u89c2\u8bc4\u5206\u6570\u636e\u96c6\u4e2d\u6a21\u578b\u53ef\u8fbe\u5230\u7684\u6700\u9ad8\u76f8\u5173\u6027\uff0c\u91cf\u5316\u8bc4\u5206\u53ef\u9760\u6027\u95ee\u9898", "motivation": "\u4e3b\u89c2\u8bc4\u5206\u5b58\u5728\u56fa\u6709\u566a\u58f0\uff0c\u9650\u5236\u4e86\u6a21\u578b\u4e0e\u4eba\u7c7b\u7684\u76f8\u5173\u6027\uff0c\u4f46\u8fd9\u79cd\u53ef\u9760\u6027\u95ee\u9898\u5f88\u5c11\u88ab\u91cf\u5316", "method": "\u5b9a\u4e49\u03c1-Perfect\u4e3a\u5b8c\u7f8e\u9884\u6d4b\u5668\u4e0e\u4eba\u7c7b\u8bc4\u5206\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u57fa\u4e8e\u5f02\u65b9\u5dee\u566a\u58f0\u573a\u666f\u63a8\u5bfc\u4f30\u8ba1\u503c\uff0c\u5e76\u8bc1\u660e\u03c1-Perfect\u5e73\u65b9\u53ef\u4f30\u8ba1\u6d4b\u8bd5-\u91cd\u6d4b\u76f8\u5173\u6027", "result": "\u5728\u8bed\u97f3\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u6f14\u793a\u03c1-Perfect\u7684\u5e94\u7528\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u533a\u5206\u6a21\u578b\u9650\u5236\u4e0e\u6570\u636e\u8d28\u91cf\u95ee\u9898", "conclusion": "\u03c1-Perfect\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\u6765\u4f30\u8ba1\u4e3b\u89c2\u8bc4\u5206\u6570\u636e\u96c6\u4e2d\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u9650\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u4e0e\u6570\u636e\u8d28\u91cf"}}
{"id": "2602.08162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08162", "abs": "https://arxiv.org/abs/2602.08162", "authors": ["Ricardo Campos", "Jos\u00e9 Pedro Evans", "Jos\u00e9 Miguel Isidro", "Miguel Marques", "Lu\u00eds Filipe Cunha", "Al\u00edpio Jorge", "S\u00e9rgio Nunes", "Nuno Guimar\u00e3es"], "title": "NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark", "comment": null, "summary": "Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5982\u4f55\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u6765\u7ed3\u6784\u5316\u5730\u65b9\u653f\u5e9c\u4f1a\u8bae\u8bb0\u5f55\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u6587\u6863\u5206\u5272\u3001\u5b9e\u4f53\u62bd\u53d6\u548c\u6587\u672c\u6458\u8981\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\uff0c\u4ee5\u89e3\u51b3\u4f1a\u8bae\u8bb0\u5f55\u5f02\u8d28\u6027\u9ad8\u3001\u96be\u4ee5\u7406\u89e3\u7684\u95ee\u9898\u3002", "motivation": "\u5730\u65b9\u653f\u5e9c\u4f1a\u8bae\u8bb0\u5f55\u4f5c\u4e3a\u5b98\u65b9\u6587\u4ef6\uff0c\u8bb0\u5f55\u4e86\u63d0\u6848\u3001\u8ba8\u8bba\u548c\u7a0b\u5e8f\u6027\u884c\u52a8\uff0c\u4f46\u8fd9\u4e9b\u6587\u4ef6\u901a\u5e38\u5bc6\u5ea6\u9ad8\u3001\u5b98\u50da\u5316\uff0c\u4e14\u5728\u4e0d\u540c\u5e02\u653f\u673a\u6784\u95f4\u5b58\u5728\u663e\u8457\u7684\u5f02\u8d28\u6027\uff08\u8bed\u8a00\u3001\u672f\u8bed\u3001\u7ed3\u6784\u3001\u7ec4\u7ec7\u65b9\u5f0f\u5404\u4e0d\u76f8\u540c\uff09\u3002\u8fd9\u79cd\u5f02\u8d28\u6027\u4f7f\u5f97\u975e\u4e13\u5bb6\u96be\u4ee5\u89e3\u8bfb\uff0c\u667a\u80fd\u81ea\u52a8\u5316\u7cfb\u7edf\u4e5f\u96be\u4ee5\u5904\u7406\uff0c\u9650\u5236\u4e86\u516c\u5171\u900f\u660e\u5ea6\u548c\u516c\u6c11\u53c2\u4e0e\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u56de\u987e\u4e86\u652f\u6301\u5730\u65b9\u653f\u5e9c\u4f1a\u8bae\u6587\u6863\u7ed3\u6784\u5316\u7684\u4e09\u4e2a\u6838\u5fc3NLP\u4efb\u52a1\uff1a1) \u6587\u6863\u5206\u5272\uff08\u5c06\u957f\u6587\u6863\u5212\u5206\u4e3a\u6709\u610f\u4e49\u7684\u7247\u6bb5\uff09\uff0c2) \u9886\u57df\u7279\u5b9a\u5b9e\u4f53\u62bd\u53d6\uff08\u8bc6\u522b\u653f\u6cbb\u53c2\u4e0e\u8005\u548c\u4e2a\u4eba\u4fe1\u606f\uff09\uff0c3) \u81ea\u52a8\u6587\u672c\u6458\u8981\uff08\u751f\u6210\u590d\u6742\u51b3\u7b56\u8fc7\u7a0b\u7684\u7b80\u6d01\u8868\u793a\uff09\u3002\u540c\u65f6\u8ba8\u8bba\u4e86\u65b9\u6cd5\u5b66\u9014\u5f84\u3001\u8bc4\u4f30\u6307\u6807\u548c\u53ef\u7528\u8d44\u6e90\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u672c\u6587\u63d0\u4f9b\u4e86NLP\u5728\u5730\u65b9\u653f\u5e9c\u4f1a\u8bae\u8bb0\u5f55\u7ed3\u6784\u5316\u5e94\u7528\u7684\u7ed3\u6784\u5316\u6982\u8ff0\uff0c\u8bc6\u522b\u4e86\u9886\u57df\u7279\u5b9a\u6311\u6218\uff0c\u5305\u62ec\u6570\u636e\u7a00\u7f3a\u6027\u3001\u9690\u79c1\u7ea6\u675f\u548c\u6765\u6e90\u53d8\u5f02\u6027\uff0c\u5e76\u603b\u7ed3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u60c5\u51b5\u3002", "conclusion": "NLP\u6280\u672f\u80fd\u591f\u6709\u6548\u589e\u5f3a\u5730\u65b9\u653f\u5e9c\u4f1a\u8bae\u8bb0\u5f55\u7684\u7ed3\u6784\u5316\u548c\u53ef\u8bbf\u95ee\u6027\u3002\u901a\u8fc7\u6587\u6863\u5206\u5272\u3001\u5b9e\u4f53\u62bd\u53d6\u548c\u6587\u672c\u6458\u8981\u7b49\u6838\u5fc3\u4efb\u52a1\uff0c\u53ef\u4ee5\u6539\u5584\u516c\u4f17\u5bf9\u8fd9\u4e9b\u590d\u6742\u6587\u6863\u7684\u7406\u89e3\uff0c\u4fc3\u8fdb\u516c\u5171\u900f\u660e\u5ea6\u548c\u516c\u6c11\u53c2\u4e0e\u3002\u672a\u6765\u5de5\u4f5c\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u4fdd\u62a4\u7b49\u7279\u5b9a\u9886\u57df\u6311\u6218\u3002"}}
{"id": "2602.07943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07943", "abs": "https://arxiv.org/abs/2602.07943", "authors": ["Ivaxi Sheth", "Zhijing Jin", "Bryan Wilder", "Dominik Janzing", "Mario Fritz"], "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery", "comment": "18 pages", "summary": "In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.", "AI": {"tldr": "LLMs\u80fd\u5e2e\u52a9\u8bc6\u522b\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u5176\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86IV Co-Scientist\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6765\u81ea\u52a8\u5316\u5de5\u5177\u53d8\u91cf\u7684\u53d1\u73b0\u548c\u4f18\u5316\u3002", "motivation": "\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\uff0c\u5de5\u5177\u53d8\u91cf\u7684\u8bc6\u522b\u9700\u8981\u8de8\u5b66\u79d1\u77e5\u8bc6\u3001\u521b\u9020\u529b\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u8fd9\u662f\u4e00\u4e2a\u975e\u5e73\u51e1\u7684\u4efb\u52a1\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5e2e\u52a9\u5b8c\u6210\u8fd9\u4e00\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a\u9996\u5148\u6d4b\u8bd5LLMs\u662f\u5426\u80fd\u4ece\u6587\u732e\u4e2d\u6062\u590d\u5df2\u786e\u7acb\u7684\u5de5\u5177\u53d8\u91cf\uff1b\u5176\u6b21\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u8bc6\u522b\u548c\u907f\u514d\u5df2\u88ab\u5b9e\u8bc1\u6216\u7406\u8bba\u5426\u5b9a\u7684\u5de5\u5177\u53d8\u91cf\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86IV Co-Scientist\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u65e0\u771f\u5b9e\u503c\u60c5\u51b5\u4e0b\u7684\u7edf\u8ba1\u68c0\u9a8c\u65b9\u6cd5\u3002", "result": "LLMs\u80fd\u591f\u4ece\u5927\u578b\u89c2\u6d4b\u6570\u636e\u5e93\u4e2d\u8bc6\u522b\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5de5\u5177\u53d8\u91cf\u53d1\u73b0\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f85\u52a9\u5de5\u5177\u53d8\u91cf\u8bc6\u522b\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0cIV Co-Scientist\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5316\u5de5\u5177\u53d8\u91cf\u7684\u63d0\u51fa\u3001\u6279\u5224\u548c\u4f18\u5316\u8fc7\u7a0b\u3002"}}
{"id": "2602.07397", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07397", "abs": "https://arxiv.org/abs/2602.07397", "authors": ["Hoang Anh Duy Le", "Sahil Joshi", "Zeyu Yang", "Zhaozhuo Xu", "Anshumali Shrivastava"], "title": "Scout Before You Attend: Sketch-and-Walk Sparse Attention for Efficient LLM Inference", "comment": null, "summary": "Self-attention dominates the computational and memory cost of long-context LLM inference across both prefill and decode phases. To address this challenge, we introduce Sketch&Walk Attention, a training-free sparse attention method that determines sparsity with lightweight sketches and deterministic walk. Sketch&Walk applies Hadamard sketching to get inexpensive approximations of attention scores, then aggregates these estimates across layers via a walk mechanism that captures attention influence beyond direct interactions between tokens. The accumulated walk scores are used to select top-k attention blocks, enabling dynamic sparsity with a single training-free algorithm that applies uniformly to both the prefill and decode phases, together with custom sparse attention kernels. Across a wide range of models and tasks, Sketch&Walk maintains near-lossless accuracy at 20% attention density and can slightly outperform dense attention in some settings, while achieving up to 6x inference speedup.", "AI": {"tldr": "\u63d0\u51faSketch&Walk Attention\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8349\u56fe\u786e\u5b9a\u6027\u548c\u786e\u5b9a\u6027\u6e38\u8d70\u673a\u5236\uff0c\u5728\u4fdd\u6301\u8fd1\u65e0\u635f\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe6\u500d\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\uff08\u5305\u62ec\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\uff09\u5360\u636e\u4e86\u4e3b\u8981\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\uff0c\u9700\u8981\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u6765\u964d\u4f4e\u8fd9\u4e9b\u5f00\u9500\u3002", "method": "\u4f7f\u7528Hadamard\u8349\u56fe\u6280\u672f\u5ec9\u4ef7\u8fd1\u4f3c\u6ce8\u610f\u529b\u5206\u6570\uff0c\u901a\u8fc7\u6e38\u8d70\u673a\u5236\u5728\u5c42\u95f4\u805a\u5408\u8fd9\u4e9b\u4f30\u8ba1\u503c\uff0c\u6355\u6349\u8d85\u8d8atoken\u76f4\u63a5\u4ea4\u4e92\u7684\u6ce8\u610f\u529b\u5f71\u54cd\uff0c\u57fa\u4e8e\u7d2f\u79ef\u5206\u6570\u9009\u62e9top-k\u6ce8\u610f\u529b\u5757\u5b9e\u73b0\u52a8\u6001\u7a00\u758f\u5316\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\uff0cSketch&Walk\u572820%\u6ce8\u610f\u529b\u5bc6\u5ea6\u4e0b\u4fdd\u6301\u8fd1\u65e0\u635f\u51c6\u786e\u7387\uff0c\u67d0\u4e9b\u8bbe\u7f6e\u4e2d\u751a\u81f3\u7565\u5fae\u4f18\u4e8e\u5bc6\u96c6\u6ce8\u610f\u529b\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u8fbe6\u500d\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "Sketch&Walk Attention\u662f\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3\u65e0\u5173\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\uff0c\u9002\u7528\u4e8e\u9884\u586b\u5145\u548c\u89e3\u7801\u4e24\u4e2a\u9636\u6bb5\u3002"}}
{"id": "2602.08629", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08629", "abs": "https://arxiv.org/abs/2602.08629", "authors": ["Bo Peng", "Sirui Chen", "Jiaguo Tian", "Yu Qiao", "Chaochao Lu"], "title": "CauScale: Neural Causal Discovery at Scale", "comment": null, "summary": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.", "AI": {"tldr": "CauScale\u662f\u4e00\u79cd\u7528\u4e8e\u9ad8\u6548\u56e0\u679c\u53d1\u73b0\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u901a\u8fc7\u538b\u7f29\u6570\u636e\u5d4c\u5165\u548c\u5171\u4eab\u6ce8\u610f\u529b\u6743\u91cd\u5b9e\u73b0\u65f6\u95f4\u548c\u7a7a\u95f4\u6548\u7387\u63d0\u5347\uff0c\u53ef\u6269\u5c55\u52301000\u8282\u70b9\u56fe\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u83b7\u5f974-13,000\u500d\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u65f6\u9762\u4e34\u65f6\u95f4\u548c\u7a7a\u95f4\u6548\u7387\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5728\u79d1\u5b66AI\u548c\u6570\u636e\u5206\u6790\u7b49\u6570\u636e\u9a71\u52a8\u9886\u57df\u7684\u5e94\u7528\u6269\u5c55\u3002", "method": "CauScale\u91c7\u7528\u53cc\u6d41\u8bbe\u8ba1\uff1a\u6570\u636e\u6d41\u4ece\u9ad8\u7ef4\u89c2\u6d4b\u4e2d\u63d0\u53d6\u5173\u7cfb\u8bc1\u636e\uff0c\u56fe\u6d41\u6574\u5408\u7edf\u8ba1\u56fe\u5148\u9a8c\u5e76\u4fdd\u7559\u5173\u952e\u7ed3\u6784\u4fe1\u53f7\u3002\u901a\u8fc7\u51cf\u5c11\u5355\u5143\u538b\u7f29\u6570\u636e\u5d4c\u5165\u63d0\u9ad8\u65f6\u95f4\u6548\u7387\uff0c\u91c7\u7528\u5171\u4eab\u6ce8\u610f\u529b\u6743\u91cd\u907f\u514d\u7ef4\u62a4\u8f74\u7279\u5b9a\u6ce8\u610f\u529b\u56fe\u6765\u63d0\u9ad8\u7a7a\u95f4\u6548\u7387\u3002", "result": "CauScale\u6210\u529f\u6269\u5c55\u5230500\u8282\u70b9\u56fe\u7684\u8bad\u7ec3\uff08\u5148\u524d\u5de5\u4f5c\u56e0\u7a7a\u95f4\u9650\u5236\u5931\u8d25\uff09\uff0c\u5728\u5206\u5e03\u5185\u6570\u636e\u4e0a\u8fbe\u523099.6% mAP\uff0c\u5206\u5e03\u5916\u6570\u636e\u4e0a\u8fbe\u523084.4% mAP\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4\u5148\u524d\u65b9\u6cd5\u5feb4-13,000\u500d\u3002", "conclusion": "CauScale\u901a\u8fc7\u521b\u65b0\u7684\u795e\u7ecf\u67b6\u6784\u8bbe\u8ba1\u89e3\u51b3\u4e86\u56e0\u679c\u53d1\u73b0\u7684\u6269\u5c55\u6027\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u56fe\u7684\u9ad8\u6548\u51c6\u786e\u63a8\u7406\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u9886\u57df\u7684\u56e0\u679c\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.08208", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08208", "abs": "https://arxiv.org/abs/2602.08208", "authors": ["Cameron R. Jones", "Agnese Lombardi", "Kyle Mahowald", "Benjamin K. Bergen"], "title": "LLMs and people both learn to form conventions -- just not with each other", "comment": "10 pages, 4 figures", "summary": "Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5LLMs\u5728\u591a\u6a21\u6001\u4ea4\u6d41\u6e38\u620f\u4e2d\u662f\u5426\u5f62\u6210\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u5bf9\u8bdd\u5bf9\u9f50\u60ef\u4f8b\uff0c\u53d1\u73b0\u540c\u7c7b\u578b\u914d\u5bf9\uff08\u4eba-\u4eba\u3001AI-AI\uff09\u80fd\u5f62\u6210\u60ef\u4f8b\uff0c\u4f46\u4eba-AI\u6df7\u5408\u914d\u5bf9\u5931\u8d25\uff0c\u5373\u4f7f\u8ba9AI\u6a21\u4eff\u4eba\u7c7b\u8868\u9762\u884c\u4e3a\u4e5f\u65e0\u6cd5\u8fbe\u5230\u540c\u7b49\u5bf9\u9f50\u6c34\u5e73\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22LLMs\u662f\u5426\u80fd\u5728\u5bf9\u8bdd\u4e2d\u5f62\u6210\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u4ea4\u6d41\u60ef\u4f8b\u548c\u5bf9\u9f50\u6a21\u5f0f\uff0c\u4e86\u89e3AI\u4e0e\u4eba\u7c7b\u5728\u6c9f\u901a\u534f\u8c03\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u4ea4\u6d41\u6e38\u620f\uff0c\u6bd4\u8f83\u4e09\u79cd\u914d\u5bf9\u7c7b\u578b\uff1a\u4eba-\u4eba\u3001AI-AI\u3001\u4eba-AI\u3002\u5b9e\u9a8c2\u901a\u8fc7\u63d0\u793a\u8ba9LLMs\u4ea7\u751f\u8868\u9762\u7c7b\u4f3c\u4eba\u7c7b\u7684\u884c\u4e3a\uff0c\u89c2\u5bdf\u662f\u5426\u80fd\u6539\u5584\u5bf9\u9f50\u6548\u679c\u3002", "result": "\u540c\u7c7b\u578b\u914d\u5bf9\uff08\u4eba-\u4eba\u548cAI-AI\uff09\u90fd\u663e\u793a\u51fa\u60ef\u4f8b\u5f62\u6210\uff1a\u51c6\u786e\u7387\u548c\u4e00\u81f4\u6027\u63d0\u9ad8\uff0c\u6d88\u606f\u957f\u5ea6\u51cf\u5c11\u3002\u4f46\u4eba-AI\u914d\u5bf9\u5931\u8d25\uff0c\u5373\u4f7f\u8ba9AI\u6a21\u4eff\u4eba\u7c7b\u6d88\u606f\u957f\u5ea6\uff0c\u51c6\u786e\u7387\u548c\u8bcd\u6c47\u91cd\u53e0\u4ecd\u843d\u540e\u4e8e\u540c\u7c7b\u578b\u914d\u5bf9\u3002", "conclusion": "\u5bf9\u8bdd\u5bf9\u9f50\u4e0d\u4ec5\u9700\u8981\u6a21\u4eff\u5148\u524d\u4e92\u52a8\u7684\u80fd\u529b\uff0c\u8fd8\u9700\u8981\u5171\u4eab\u5bf9\u6240\u4f20\u8fbe\u610f\u4e49\u7684\u89e3\u91ca\u504f\u89c1\u3002LLMs\u4e0e\u4eba\u7c7b\u5728\u6c9f\u901a\u503e\u5411\u4e0a\u7684\u5dee\u5f02\u963b\u788d\u4e86\u6709\u6548\u7684\u60ef\u4f8b\u5f62\u6210\u3002"}}
{"id": "2602.07962", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07962", "abs": "https://arxiv.org/abs/2602.07962", "authors": ["Weihao Zeng", "Yuzhen Huang", "Junxian He"], "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench", "AI": {"tldr": "LOCA-bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u8bc4\u4f30\u6a21\u578b\u548c\u67b6\u6784\u5728\u52a8\u6001\u589e\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5355\u6b65\u8bbe\u7f6e\u4e0b\u7684\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\uff0c\u800c\u73b0\u5b9e\u573a\u666f\u4e2dLLM\u9700\u8981\u4f5c\u4e3a\u4ee3\u7406\u5728\u52a8\u6001\u589e\u957f\u4e0a\u4e0b\u6587\u4e2d\u63a2\u7d22\u73af\u5883\u3001\u9075\u5faa\u6307\u4ee4\u3001\u63d0\u53d6\u4fe1\u606f\u5e76\u9884\u6d4b\u6b63\u786e\u884c\u52a8\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "LOCA-bench\u901a\u8fc7\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4f7f\u4e0a\u4e0b\u6587\u957f\u5ea6\u53ef\u4ee5\u65e0\u9650\u6269\u5c55\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u8bed\u4e49\u56fa\u5b9a\uff0c\u8bc4\u4f30\u8bed\u8a00\u4ee3\u7406\u4f5c\u4e3a\u6a21\u578b\u548c\u67b6\u6784\u7684\u7ec4\u5408\uff0c\u5305\u62ec\u5404\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u3002", "result": "\u968f\u7740\u73af\u5883\u72b6\u6001\u53d8\u5f97\u66f4\u590d\u6742\uff0c\u4ee3\u7406\u6027\u80fd\u666e\u904d\u4e0b\u964d\uff0c\u4f46\u5148\u8fdb\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6574\u4f53\u6210\u529f\u7387\u3002", "conclusion": "LOCA-bench\u4e3a\u8bc4\u4f30\u6a21\u578b\u548c\u67b6\u6784\u5728\u957f\u4e0a\u4e0b\u6587\u3001\u4ee3\u7406\u573a\u666f\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u5982\u4f55\u63d0\u9ad8\u8bed\u8a00\u4ee3\u7406\u5728\u52a8\u6001\u589e\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.07400", "categories": ["cs.LG", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.07400", "abs": "https://arxiv.org/abs/2602.07400", "authors": ["Simon B\u00fchrer", "Andreas Plesner", "Aczel Till", "Roger Wattenhofer"], "title": "BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks", "comment": null, "summary": "The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet existing FPGA-based neural approaches are fragmented and difficult to compare. We present BitLogic, a fully gradient-based, end-to-end trainable framework for FPGA-native neural networks built around Lookup Table (LUT) computation. BitLogic replaces multiply-accumulate operations with differentiable LUT nodes that map directly to FPGA primitives, enabling native binary computation, sparse connectivity, and efficient hardware realization. The framework offers a modular functional API supporting diverse architectures, along with learned encoders, hardware-aware heads, and multiple boundary-consistent LUT relaxations. An automated Register Transfer Level (RTL) export pipeline translates trained PyTorch models into synthesizable HDL, ensuring equivalence between software and hardware inference. Experiments across standard vision benchmarks and heterogeneous hardware platforms demonstrate competitive accuracy and substantial gains in FPGA efficiency, including 72.3% test accuracy on CIFAR-10 achieved with fewer than 0.3M logic gates, while attaining sub-20 ns single-sample inference using only LUT resources.", "AI": {"tldr": "BitLogic\u662f\u4e00\u4e2a\u57fa\u4e8eFPGA\u7684\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u53ef\u5fae\u67e5\u627e\u8868\u8282\u70b9\u66ff\u4ee3\u4f20\u7edfMAC\u64cd\u4f5c\uff0c\u5b9e\u73b0\u539f\u751f\u4e8c\u8fdb\u5236\u8ba1\u7b97\u548c\u9ad8\u6548\u786c\u4ef6\u5b9e\u73b0\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u7684\u80fd\u8017\u548c\u5ef6\u8fdf\u6210\u672c\u4e3b\u8981\u6765\u81ea\u90e8\u7f72\u800c\u975e\u8bad\u7ec3\uff0c\u9700\u8981\u786c\u4ef6\u4e13\u7528\u65b9\u6848\u3002FPGA\u63d0\u4f9b\u4e86\u6709\u5438\u5f15\u529b\u7684\u5e73\u53f0\uff0c\u4f46\u73b0\u6709FPGA\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5206\u6563\u4e14\u96be\u4ee5\u6bd4\u8f83\u3002", "method": "\u63d0\u51faBitLogic\u6846\u67b6\uff0c\u7528\u53ef\u5fae\u67e5\u627e\u8868\u8282\u70b9\u66ff\u4ee3\u4e58\u7d2f\u52a0\u64cd\u4f5c\uff0c\u8fd9\u4e9b\u8282\u70b9\u76f4\u63a5\u6620\u5c04\u5230FPGA\u539f\u8bed\u3002\u6846\u67b6\u63d0\u4f9b\u6a21\u5757\u5316\u529f\u80fdAPI\uff0c\u652f\u6301\u591a\u79cd\u67b6\u6784\u3001\u5b66\u4e60\u7f16\u7801\u5668\u3001\u786c\u4ef6\u611f\u77e5\u5934\u90e8\u548c\u8fb9\u754c\u4e00\u81f4\u7684LUT\u677e\u5f1b\u3002\u81ea\u52a8RTL\u5bfc\u51fa\u7ba1\u9053\u5c06PyTorch\u6a21\u578b\u8f6c\u6362\u4e3a\u53ef\u7efc\u5408HDL\u3002", "result": "\u5728\u6807\u51c6\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f02\u6784\u786c\u4ef6\u5e73\u53f0\u4e0a\u5c55\u793a\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u548c\u663e\u8457\u7684FPGA\u6548\u7387\u63d0\u5347\u3002\u5728CIFAR-10\u4e0a\u8fbe\u523072.3%\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u4ec5\u4f7f\u7528\u5c11\u4e8e0.3M\u903b\u8f91\u95e8\uff0c\u5355\u6837\u672c\u63a8\u7406\u5ef6\u8fdf\u4f4e\u4e8e20\u7eb3\u79d2\uff0c\u4ec5\u4f7f\u7528LUT\u8d44\u6e90\u3002", "conclusion": "BitLogic\u4e3aFPGA\u539f\u751f\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u5168\u57fa\u4e8e\u68af\u5ea6\u7684\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u8f6f\u4ef6\u548c\u786c\u4ef6\u63a8\u7406\u7684\u7b49\u4ef7\u6027\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86FPGA\u6548\u7387\u3002"}}
{"id": "2602.08681", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08681", "abs": "https://arxiv.org/abs/2602.08681", "authors": ["Leander Kurscheidt", "Gabriele Masina", "Roberto Sebastiani", "Antonio Vergari"], "title": "The Theory and Practice of MAP Inference over Non-Convex Constraints", "comment": null, "summary": "In many safety-critical settings, probabilistic ML systems have to make predictions subject to algebraic constraints, e.g., predicting the most likely trajectory that does not cross obstacles.\n  These real-world constraints are rarely convex, nor the densities considered are (log-)concave.\n  This makes computing this constrained maximum a posteriori (MAP) prediction efficiently and reliably extremely challenging.\n  In this paper, we first investigate under which conditions we can perform constrained MAP inference over continuous variables exactly and efficiently and devise a scalable message-passing algorithm for this tractable fragment.\n  Then, we devise a general constrained MAP strategy that interleaves partitioning the domain into convex feasible regions with numerical constrained optimization.\n  We evaluate both methods on synthetic and real-world benchmarks, showing our %\n  approaches outperform constraint-agnostic baselines, and scale to complex densities intractable for SoTA exact solvers.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u5904\u7406\u975e\u51f8\u7ea6\u675f\u4e0b\u8fde\u7eed\u53d8\u91cf\u7ea6\u675f\u6700\u5927\u540e\u9a8c\u6982\u7387\u9884\u6d4b\u7684\u65b9\u6cd5\uff1a\u4e00\u79cd\u662f\u9488\u5bf9\u53ef\u7cbe\u786e\u9ad8\u6548\u6c42\u89e3\u7684\u7247\u6bb5\u8bbe\u8ba1\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\uff0c\u53e6\u4e00\u79cd\u662f\u901a\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u5212\u5206\u53ef\u884c\u57df\u4e0e\u6570\u503c\u4f18\u5316\u76f8\u7ed3\u5408\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u6982\u7387\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u9700\u8981\u5728\u4ee3\u6570\u7ea6\u675f\u4e0b\u8fdb\u884c\u9884\u6d4b\uff08\u5982\u907f\u5f00\u969c\u788d\u7269\u7684\u6700\u53ef\u80fd\u8f68\u8ff9\uff09\u3002\u73b0\u5b9e\u7ea6\u675f\u901a\u5e38\u975e\u51f8\uff0c\u4e14\u5bc6\u5ea6\u51fd\u6570\u4e5f\u975e\uff08\u5bf9\u6570\uff09\u51f9\uff0c\u4f7f\u5f97\u7ea6\u675fMAP\u9884\u6d4b\u7684\u8ba1\u7b97\u65e2\u56f0\u96be\u53c8\u4e0d\u53ef\u9760\u3002", "method": "1. \u7814\u7a76\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u53ef\u5bf9\u8fde\u7eed\u53d8\u91cf\u8fdb\u884c\u7cbe\u786e\u9ad8\u6548\u7684\u7ea6\u675fMAP\u63a8\u65ad\uff0c\u5e76\u8bbe\u8ba1\u53ef\u6269\u5c55\u7684\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\uff1b2. \u63d0\u51fa\u901a\u7528\u7ea6\u675fMAP\u7b56\u7565\uff0c\u5c06\u57df\u5212\u5206\u4e3a\u51f8\u53ef\u884c\u533a\u57df\u5e76\u4e0e\u6570\u503c\u7ea6\u675f\u4f18\u5316\u4ea4\u66ff\u8fdb\u884c\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u4f18\u4e8e\u65e0\u89c6\u7ea6\u675f\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u590d\u6742\u5bc6\u5ea6\u51fd\u6570\uff0c\u800c\u73b0\u6709\u6700\u5148\u8fdb\u7684\u7cbe\u786e\u6c42\u89e3\u5668\u5bf9\u6b64\u7c7b\u95ee\u9898\u96be\u4ee5\u5904\u7406\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u5904\u7406\u975e\u51f8\u7ea6\u675f\u4e0b\u8fde\u7eed\u53d8\u91cf\u7ea6\u675fMAP\u9884\u6d4b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u65e2\u80fd\u5904\u7406\u53ef\u7cbe\u786e\u6c42\u89e3\u7684\u7247\u6bb5\uff0c\u53c8\u80fd\u901a\u8fc7\u57df\u5212\u5206\u7b56\u7565\u5904\u7406\u66f4\u4e00\u822c\u7684\u590d\u6742\u60c5\u51b5\uff0c\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08220", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08220", "abs": "https://arxiv.org/abs/2602.08220", "authors": ["Boyi Zeng", "Yiqin Hao", "He Li", "Shixiang Song", "Feichen Song", "Zitong Wang", "Siyuan Huang", "Yi Xu", "ZiWei He", "Xinbing Wang", "Zhouhan Lin"], "title": "Pretraining with Token-Level Adaptive Latent Chain-of-Thought", "comment": null, "summary": "Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u6f5c\u5728\u601d\u7ef4\u94fe\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2atoken\u751f\u6210\u53ef\u53d8\u957f\u5ea6\u7684\u6f5c\u5728\u63a8\u7406\u8f68\u8ff9\u6765\u589e\u52a0\u8ba1\u7b97\u800c\u4e0d\u589e\u52a0\u53c2\u6570\uff0c\u5b9e\u73b0\u8bad\u7ec3\u548c\u63a8\u7406\u4e2d\u7684\u81ea\u9002\u5e94\u8ba1\u7b97\u5206\u914d", "motivation": "\u4f20\u7edf\u901a\u8fc7\u589e\u52a0\u53c2\u6570\u548c\u8bad\u7ec3\u6570\u636e\u6765\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u53d7\u5230\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\u6709\u9650\u548c\u901a\u4fe1\u6210\u672c\u4e0a\u5347\u7684\u9650\u5236\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u7684\u6269\u5c55\u7ef4\u5ea6", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u6f5c\u5728\u601d\u7ef4\u94fe\u9884\u8bad\u7ec3\uff0c\u6a21\u578b\u5728\u751f\u6210\u6bcf\u4e2atoken\u524d\u4ea7\u751f\u53ef\u53d8\u957f\u5ea6\u7684\u6f5c\u5728\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u4e3a\u56f0\u96betoken\u5206\u914d\u66f4\u957f\u8f68\u8ff9\uff0c\u7b80\u5355token\u5206\u914d\u66f4\u77ed\u6216\u96f6\u8f68\u8ff9\uff0c\u901a\u8fc7\u5355\u9636\u6bb5\u9884\u8bad\u7ec3\u81ea\u7136\u5b9e\u73b0\u81ea\u9002\u5e94\u505c\u6b62", "result": "\u5728Llama\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u81ea\u9002\u5e94\u6f5c\u5728\u601d\u7ef4\u94fe\u6301\u7eed\u6539\u5584\u8bed\u8a00\u5efa\u6a21\u56f0\u60d1\u5ea6\u548c\u5e7f\u6cdb\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u5373\u4f7f\u8bad\u7ec3FLOPs\u5c11\u4e8e\u5148\u524d\u5faa\u73af\u57fa\u7ebf", "conclusion": "\u901a\u8fc7\u5185\u90e8\u5316\u6f5c\u5728\u601d\u7ef4\u94fe\u5230\u9884\u8bad\u7ec3\u4e2d\uff0c\u589e\u52a0\u6bcf\u4e2atoken\u7684\u8ba1\u7b97\u800c\u4e0d\u6269\u5c55\u53c2\u6570\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u7ef4\u5ea6"}}
{"id": "2602.07983", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07983", "abs": "https://arxiv.org/abs/2602.07983", "authors": ["Jishu Sen Gupta", "Harini SI", "Somesh Kumar Singh", "Syed Mohamad Tawseeq", "Yaman Kumar Singla", "David Doermann", "Rajiv Ratn Shah", "Balaji Krishnamurthy"], "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation", "comment": null, "summary": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.", "AI": {"tldr": "EXPERIGEN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5668-\u5b9e\u9a8c\u8005\u7684\u4e24\u9636\u6bb5\u641c\u7d22\uff0c\u5728\u591a\u4e2a\u9886\u57df\u53d1\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a2-4\u500d\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\uff0c\u9884\u6d4b\u80fd\u529b\u63d0\u53477-17%\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9eA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\u7f13\u6162\uff0c\u4f9d\u8d56\u89c2\u5bdf\u3001\u5047\u8bbe\u751f\u6210\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u8fed\u4ee3\u5faa\u73af\u3002\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u867d\u7136\u80fd\u52a0\u901f\u90e8\u5206\u8fc7\u7a0b\uff0c\u4f46\u65e0\u6cd5\u652f\u6301\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faEXPERIGEN\u6846\u67b6\uff0c\u91c7\u7528\u53d7\u8d1d\u53f6\u65af\u4f18\u5316\u542f\u53d1\u7684\u4e24\u9636\u6bb5\u641c\u7d22\uff1a\u751f\u6210\u5668\u63d0\u51fa\u5019\u9009\u5047\u8bbe\uff0c\u5b9e\u9a8c\u8005\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u591a\u6a21\u6001\u548c\u5173\u7cfb\u6570\u636e\u96c6\u7b49\u590d\u6742\u6570\u636e\u4f53\u7cfb\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u4e2d\uff0cEXPERIGEN\u53d1\u73b0\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a2-4\u500d\uff0c\u9884\u6d4b\u80fd\u529b\u63d0\u53477-17%\u3002\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a88%\u7684\u5047\u8bbe\u5177\u6709\u4e2d\u7b49\u6216\u5f3a\u65b0\u9896\u6027\uff0c70%\u88ab\u8ba4\u4e3a\u6709\u5f71\u54cd\u529b\u4e14\u503c\u5f97\u8ffd\u6c42\u3002\u9996\u6b21A/B\u6d4b\u8bd5\u663e\u793ap<1e-6\u7684\u7edf\u8ba1\u663e\u8457\u7ed3\u679c\uff0c\u6548\u5e94\u91cf\u8fbe344%\u3002", "conclusion": "EXPERIGEN\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u4e0d\u4ec5\u4ea7\u751f\u7edf\u8ba1\u4e0a\u663e\u8457\u7684\u5047\u8bbe\uff0c\u8fd8\u80fd\u751f\u6210\u65b0\u9896\u3001\u6709\u5f71\u54cd\u529b\u4e14\u53ef\u64cd\u4f5c\u7684\u5047\u8bbe\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.07411", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07411", "abs": "https://arxiv.org/abs/2602.07411", "authors": ["Zishi Zhang", "Tao Ren", "Yijie Peng"], "title": "Nonparametric Bayesian Optimization for General Rewards", "comment": null, "summary": "This work focuses on Bayesian optimization (BO) under reward model uncertainty. We propose the first BO algorithm that achieves no-regret guarantee in a general reward setting, requiring only Lipschitz continuity of the objective function and accommodating a broad class of measurement noise. The core of our approach is a novel surrogate model, termed as infinite Gaussian process ($\\infty$-GP). It is a Bayesian nonparametric model that places a prior on the space of reward distributions, enabling it to represent a substantially broader class of reward models than classical Gaussian process (GP). The $\\infty$-GP is used in combination with Thompson Sampling (TS) to enable effective exploration and exploitation. Correspondingly, we develop a new TS regret analysis framework for general rewards, which relates the regret to the total variation distance between the surrogate model and the true reward distribution. Furthermore, with a truncated Gibbs sampling procedure, our method is computationally scalable, incurring minimal additional memory and computational complexities compared to classical GP. Empirical results demonstrate state-of-the-art performance, particularly in settings with non-stationary, heavy-tailed, or other ill-conditioned rewards.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5728\u4e00\u822c\u5956\u52b1\u6a21\u578b\u4e0b\u5b9e\u73b0\u65e0\u9057\u61be\u4fdd\u8bc1\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\uff0c\u4f7f\u7528\u65e0\u9650\u9ad8\u65af\u8fc7\u7a0b\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\uff0c\u7ed3\u5408Thompson Sampling\u8fdb\u884c\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u4f18\u5316\u901a\u5e38\u5047\u8bbe\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5956\u52b1\u6a21\u578b\u53ef\u80fd\u5177\u6709\u975e\u5e73\u7a33\u6027\u3001\u91cd\u5c3e\u5206\u5e03\u6216\u5176\u4ed6\u590d\u6742\u7279\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6a21\u578b\u6765\u5904\u7406\u5956\u52b1\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u65e0\u9650\u9ad8\u65af\u8fc7\u7a0b\u4f5c\u4e3a\u8d1d\u53f6\u65af\u975e\u53c2\u6570\u6a21\u578b\uff0c\u5728\u5956\u52b1\u5206\u5e03\u7a7a\u95f4\u4e0a\u653e\u7f6e\u5148\u9a8c\uff0c\u80fd\u591f\u8868\u793a\u6bd4\u7ecf\u5178\u9ad8\u65af\u8fc7\u7a0b\u66f4\u5e7f\u6cdb\u7684\u5956\u52b1\u6a21\u578b\u7c7b\u522b\u3002\u7ed3\u5408Thompson Sampling\u8fdb\u884c\u51b3\u7b56\uff0c\u5e76\u4f7f\u7528\u622a\u65adGibbs\u91c7\u6837\u5b9e\u73b0\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u3002", "result": "\u7b97\u6cd5\u5728\u4e00\u822c\u5956\u52b1\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u65e0\u9057\u61be\u4fdd\u8bc1\uff0c\u4ec5\u9700\u76ee\u6807\u51fd\u6570\u7684Lipschitz\u8fde\u7eed\u6027\uff0c\u5e76\u80fd\u9002\u5e94\u5e7f\u6cdb\u7684\u6d4b\u91cf\u566a\u58f0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728\u975e\u5e73\u7a33\u3001\u91cd\u5c3e\u6216\u5176\u4ed6\u75c5\u6001\u5956\u52b1\u8bbe\u7f6e\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u4e00\u822c\u5956\u52b1\u6a21\u578b\u4e0b\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u65e0\u9650\u9ad8\u65af\u8fc7\u7a0b\u6269\u5c55\u4e86\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08723", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08723", "abs": "https://arxiv.org/abs/2602.08723", "authors": ["Yujie Shen", "Zihan Wang", "Jian Qian", "Qi Lei"], "title": "Data Reconstruction: Identifiability and Optimization with Sample Splitting", "comment": null, "summary": "Training data reconstruction from KKT conditions has shown striking empirical success, yet it remains unclear when the resulting KKT equations have unique solutions and, even in identifiable regimes, how to reliably recover solutions by optimization. This work hereby focuses on these two complementary questions: identifiability and optimization. On the identifiability side, we discuss the sufficient conditions for KKT system of two-layer networks with polynomial activations to uniquely determine the training data, providing a theoretical explanation of when and why reconstruction is possible. On the optimization side, we introduce sample splitting, a curvature-aware refinement step applicable to general reconstruction objectives (not limited to KKT-based formulations): it creates additional descent directions to escape poor stationary points and refine solutions. Experiments demonstrate that augmenting several existing reconstruction methods with sample splitting consistently improves reconstruction performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4eceKKT\u6761\u4ef6\u91cd\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u4e24\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u53ef\u8bc6\u522b\u6027\u548c\u4f18\u5316\u65b9\u6cd5\u3002\u63d0\u51fa\u4e86\u591a\u9879\u5f0f\u6fc0\u6d3b\u4e24\u5c42\u7f51\u7edcKKT\u7cfb\u7edf\u552f\u4e00\u786e\u5b9a\u8bad\u7ec3\u6570\u636e\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u6837\u672c\u5206\u88c2\u65b9\u6cd5\u6539\u8fdb\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u57fa\u4e8eKKT\u6761\u4ef6\u7684\u8bad\u7ec3\u6570\u636e\u91cd\u5efa\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u5c1a\u4e0d\u660e\u786e\uff1a\u4e0d\u6e05\u695aKKT\u65b9\u7a0b\u4f55\u65f6\u6709\u552f\u4e00\u89e3\uff0c\u4ee5\u53ca\u5728\u53ef\u8bc6\u522b\u60c5\u51b5\u4e0b\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u53ef\u9760\u5730\u6062\u590d\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e24\u4e2a\u7406\u8bba\u7a7a\u767d\u3002", "method": "1. \u7406\u8bba\u5206\u6790\uff1a\u8ba8\u8bba\u591a\u9879\u5f0f\u6fc0\u6d3b\u7684\u4e24\u5c42\u7f51\u7edcKKT\u7cfb\u7edf\u552f\u4e00\u786e\u5b9a\u8bad\u7ec3\u6570\u636e\u7684\u5145\u5206\u6761\u4ef6\uff1b2. \u4f18\u5316\u65b9\u6cd5\uff1a\u63d0\u51fa\u6837\u672c\u5206\u88c2\u6280\u672f\uff0c\u8fd9\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u4e00\u822c\u91cd\u5efa\u76ee\u6807\u7684\u66f2\u7387\u611f\u77e5\u7ec6\u5316\u6b65\u9aa4\uff0c\u901a\u8fc7\u521b\u5efa\u989d\u5916\u4e0b\u964d\u65b9\u5411\u6765\u9003\u79bb\u4e0d\u826f\u9a7b\u70b9\u5e76\u7ec6\u5316\u89e3\u3002", "result": "\u7406\u8bba\u65b9\u9762\u9610\u660e\u4e86\u91cd\u5efa\u4f55\u65f6\u53ef\u80fd\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u53ef\u80fd\uff1b\u5b9e\u9a8c\u8868\u660e\uff0c\u5c06\u6837\u672c\u5206\u88c2\u4e0e\u591a\u79cd\u73b0\u6709\u91cd\u5efa\u65b9\u6cd5\u7ed3\u5408\uff0c\u80fd\u4e00\u81f4\u6027\u5730\u63d0\u9ad8\u91cd\u5efa\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u4e3aKKT\u6761\u4ef6\u8bad\u7ec3\u6570\u636e\u91cd\u5efa\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u4f18\u5316\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u53ef\u8bc6\u522b\u6027\u548c\u4f18\u5316\u53ef\u9760\u6027\u8fd9\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u8bad\u7ec3\u6570\u636e\u91cd\u5efa\u9886\u57df\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2602.08221", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08221", "abs": "https://arxiv.org/abs/2602.08221", "authors": ["Xuhua Ma", "Richong Zhang", "Zhijie Nie"], "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.", "AI": {"tldr": "CoRect\u901a\u8fc7\u5bf9\u6bd4\u4e0a\u4e0b\u6587\u5316\u548c\u975e\u4e0a\u4e0b\u6587\u5316\u524d\u5411\u4f20\u64ad\u7684logits\u6765\u8bc6\u522b\u53c2\u6570\u504f\u89c1\u5c42\uff0c\u5e76\u4fee\u6b63\u9690\u85cf\u72b6\u6001\u4ee5\u89e3\u51b3RAG\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u9ad8\u8f93\u51fa\u5fe0\u5b9e\u5ea6", "motivation": "RAG\u7cfb\u7edf\u5728\u5904\u7406\u77e5\u8bc6\u51b2\u7a81\u65f6\u5b58\u5728\u95ee\u9898\uff0c\u6a21\u578b\u5185\u90e8\u7684\u53c2\u6570\u5316\u77e5\u8bc6\u4f1a\u8986\u76d6\u68c0\u7d22\u5230\u7684\u8bc1\u636e\uff0c\u5bfc\u81f4\u8f93\u51fa\u4e0d\u5fe0\u5b9e\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6d45\u5c42\u7684\u89e3\u7801\u8c03\u6574\uff0c\u8981\u4e48\u9700\u8981\u771f\u5b9e\u6807\u7b7e\u8fdb\u884c\u6743\u91cd\u7f16\u8f91\uff0c\u5b58\u5728\u5c40\u9650\u6027", "method": "\u901a\u8fc7\u5c42\u95f4\u5206\u6790\u53d1\u73b0\u53c2\u6570\u6291\u5236\u73b0\u8c61\uff1a\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\uff0c\u67d0\u4e9bFFN\u5c42\u4f1a\u7528\u8bb0\u5fc6\u7684\u5148\u9a8c\u77e5\u8bc6\u8986\u76d6\u4e0a\u4e0b\u6587\u654f\u611f\u8868\u793a\u3002\u63d0\u51faCoRect\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e0a\u4e0b\u6587\u5316\u548c\u975e\u4e0a\u4e0b\u6587\u5316\u524d\u5411\u4f20\u64ad\u7684logits\u6765\u8bc6\u522b\u9ad8\u53c2\u6570\u504f\u89c1\u7684\u5c42\uff0c\u7136\u540e\u4fee\u6b63\u9690\u85cf\u72b6\u6001\u4ee5\u4fdd\u7559\u57fa\u4e8e\u8bc1\u636e\u7684\u4fe1\u606f", "result": "\u5728\u95ee\u7b54\u548c\u6458\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoRect\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u6301\u7eed\u63d0\u9ad8\u4e86\u5fe0\u5b9e\u5ea6\u5e76\u51cf\u5c11\u4e86\u5e7b\u89c9", "conclusion": "CoRect\u901a\u8fc7\u8bc6\u522b\u548c\u4fee\u6b63\u53c2\u6570\u504f\u89c1\u5c42\uff0c\u6709\u6548\u89e3\u51b3\u4e86RAG\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u8f93\u51fa\u7684\u5fe0\u5b9e\u5ea6\uff0c\u4e14\u4e0d\u9700\u8981\u771f\u5b9e\u6807\u7b7e"}}
{"id": "2602.08009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08009", "abs": "https://arxiv.org/abs/2602.08009", "authors": ["Rui Li", "Zeyu Zhang", "Xiaohe Bo", "Quanyu Dai", "Chaozhuo Li", "Feng Wen", "Xu Chen"], "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective", "comment": null, "summary": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.", "AI": {"tldr": "RAPS\uff1a\u57fa\u4e8e\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff0c\u7528\u4e8e\u5b9e\u73b0LLM\u591a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u534f\u8c03", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u9700\u8981\u5927\u91cf\u4eba\u5de5\u7f16\u6392\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u8bbe\u8ba1\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002\u667a\u80fd\u4f53\u534f\u8c03\u9762\u4e34\u52a8\u6001\u81ea\u7ec4\u7ec7\u7f51\u7edc\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff1a\u5982\u4f55\u5728\u53ef\u6269\u5c55\u6570\u91cf\u7684\u667a\u80fd\u4f53\u4e3b\u673a\u4e4b\u95f4\u5efa\u7acb\u81ea\u9002\u5e94\u4e14\u53ef\u9760\u7684\u901a\u4fe1\uff1f", "method": "\u63d0\u51faRAPS\uff08\u58f0\u8a89\u611f\u77e5\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff09\uff0c\u57fa\u4e8e\u5206\u5e03\u5f0f\u53d1\u5e03-\u8ba2\u9605\u534f\u8bae\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u57fa\u4e8e\u58f0\u660e\u7684\u610f\u56fe\u800c\u975e\u9884\u5b9a\u4e49\u62d3\u6251\u4ea4\u6362\u6d88\u606f\u3002\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u8986\u76d6\u5c42\uff1a1\uff09\u53cd\u5e94\u5f0f\u8ba2\u9605\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u52a8\u6001\u4f18\u5316\u610f\u56fe\uff1b2\uff09\u8d1d\u53f6\u65af\u58f0\u8a89\u673a\u5236\uff0c\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u63d0\u4f9b\u672c\u5730\u76d1\u63a7\u5668\u6765\u68c0\u6d4b\u548c\u9694\u79bb\u6076\u610f\u5bf9\u7b49\u4f53\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u5728\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\u4e2d\u6709\u6548\u8c03\u548c\u4e86\u81ea\u9002\u5e94\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "RAPS\u4e3a\u89e3\u51b3LLM\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4e2d\u7684\u52a8\u6001\u81ea\u7ec4\u7ec7\u7f51\u7edc\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u7684\u667a\u80fd\u4f53\u534f\u4f5c\u3002"}}
{"id": "2602.07415", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07415", "abs": "https://arxiv.org/abs/2602.07415", "authors": ["Runhan Shi", "Zhicheng Zhang", "Letian Chen", "Gufeng Yu", "Yang Yang"], "title": "Learning Molecular Chirality via Chiral Determinant Kernels", "comment": "Accepted at the ICLR 2026", "summary": "Chirality is a fundamental molecular property that governs stereospecific behavior in chemistry and biology. Capturing chirality in machine learning models remains challenging due to the geometric complexity of stereochemical relationships and the limitations of traditional molecular representations that often lack explicit stereochemical encoding. Existing approaches to chiral molecular representation primarily focus on central chirality, relying on handcrafted stereochemical tags or limited 3D encodings, and thus fail to generalize to more complex forms such as axial chirality. In this work, we introduce ChiDeK (Chiral Determinant Kernels), a framework that systematically integrates stereogenic information into molecular representation learning. We propose the chiral determinant kernel to encode the SE(3)-invariant chirality matrix and employ cross-attention to integrate stereochemical information from local chiral centers into the global molecular representation. This design enables explicit modeling of chiral-related features within a unified architecture, capable of jointly encoding central and axial chirality. To support the evaluation of axial chirality, we construct a new benchmark for electronic circular dichroism (ECD) and optical rotation (OR) prediction. Across four tasks, including R/S configuration classification, enantiomer ranking, ECD spectrum prediction, and OR prediction, ChiDeK achieves substantial improvements over state-of-the-art baselines, most notably yielding over 7% higher accuracy on axially chiral tasks on average.", "AI": {"tldr": "ChiDeK\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u5b50\u8868\u793a\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u624b\u6027\u884c\u5217\u5f0f\u6838\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7edf\u4e00\u7f16\u7801\u4e2d\u5fc3\u624b\u6027\u548c\u8f74\u5411\u624b\u6027\uff0c\u5728\u591a\u4e2a\u624b\u6027\u76f8\u5173\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u6709\u6548\u6355\u6349\u624b\u6027\u4fe1\u606f\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f74\u5411\u624b\u6027\u7b49\u590d\u6742\u5f62\u5f0f\u3002\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e2d\u5fc3\u624b\u6027\uff0c\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\u6216\u6709\u9650\u76843D\u7f16\u7801\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u66f4\u590d\u6742\u7684\u624b\u6027\u7c7b\u578b\u3002", "method": "\u63d0\u51fa\u624b\u6027\u884c\u5217\u5f0f\u6838(Chiral Determinant Kernels)\u6765\u7f16\u7801SE(3)\u4e0d\u53d8\u7684\u624b\u6027\u77e9\u9635\uff0c\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5c06\u5c40\u90e8\u624b\u6027\u4e2d\u5fc3\u4fe1\u606f\u6574\u5408\u5230\u5168\u5c40\u5206\u5b50\u8868\u793a\u4e2d\uff0c\u80fd\u591f\u7edf\u4e00\u7f16\u7801\u4e2d\u5fc3\u624b\u6027\u548c\u8f74\u5411\u624b\u6027\u3002", "result": "\u5728\u56db\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff1aR/S\u6784\u578b\u5206\u7c7b\u3001\u5bf9\u6620\u4f53\u6392\u5e8f\u3001ECD\u5149\u8c31\u9884\u6d4b\u548c\u65cb\u5149\u5ea6\u9884\u6d4b\u3002\u7279\u522b\u662f\u5728\u8f74\u5411\u624b\u6027\u4efb\u52a1\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc77%\u3002", "conclusion": "ChiDeK\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u6574\u5408\u624b\u6027\u4fe1\u606f\u5230\u5206\u5b50\u8868\u793a\u5b66\u4e60\u4e2d\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u624b\u6027\u7c7b\u578b\uff0c\u4e3a\u624b\u6027\u76f8\u5173\u5316\u5b66\u548c\u751f\u7269\u5b66\u4efb\u52a1\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5efa\u6a21\u5de5\u5177\u3002"}}
{"id": "2602.08862", "categories": ["cs.LG", "cs.DS", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08862", "abs": "https://arxiv.org/abs/2602.08862", "authors": ["Lunjia Hu", "Jon Schneider", "Yifan Wu"], "title": "Near-optimal Swap Regret Minimization for Convex Losses", "comment": null, "summary": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u5728\u7ebf\u7b97\u6cd5\uff0c\u5728\u5355\u4f4d\u533a\u95f4\u4e0a\u9488\u5bf9\u81ea\u9002\u5e94\u9009\u62e9\u7684Lipschitz\u51f8\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684$\\widetilde O(\\sqrt T)$\u671f\u671b\u4ea4\u6362\u9057\u61be\uff0c\u6539\u8fdb\u4e86\u4e4b\u524d$\\widetilde O(T^{2/3})$\u7684\u6700\u4f73\u754c\u9650\uff0c\u5e76\u89e3\u51b3\u4e86Fishelson\u7b49\u4eba[2025b]\u7684\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u5148\u524d\u5173\u4e8e\u4ea4\u6362\u9057\u61be\uff08swap regret\uff09\u7684\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u6700\u4f73\u754c\u9650\u4e3a$\\widetilde O(T^{2/3})$\uff0c\u800c\u6700\u4f18\u4e0b\u754c\u4e3a$\\Omega(\\sqrt T)$\uff1b2\uff09\u73b0\u6709\u7b97\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u9057\u61be\u754c\u9650\u53c8\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u5206\u7bb1\uff08multi-scale binning\uff09\u6280\u672f\uff1a\u5c06\u5355\u4f4d\u533a\u95f4\u79bb\u6563\u5316\u4e3a\u591a\u4e2a\u7c92\u5ea6\u5c3a\u5ea6\u7684\u7bb1\uff0c\u540c\u65f6\u4f7f\u7528\u6240\u6709\u5c3a\u5ea6\u8fdb\u884c\u968f\u673a\u9884\u6d4b\u3002\u8fd9\u79cd\u6280\u672f\u5141\u8bb8\u7b97\u6cd5\u5728\u4e0d\u540c\u7cbe\u5ea6\u7ea7\u522b\u4e0a\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff0c\u662f\u5b9e\u73b0\u9ad8\u6548$\\widetilde O(\\sqrt T)$\u9057\u61be\u7684\u5173\u952e\u521b\u65b0\u3002", "result": "1\uff09\u4e3b\u8981\u7ed3\u679c\uff1a\u63d0\u51fa\u4e86\u4e00\u4e2a\u968f\u673a\u5728\u7ebf\u7b97\u6cd5\uff0c\u5728$\\mathsf{poly}(T)$\u65f6\u95f4\u5185\u8fd0\u884c\uff0c\u4fdd\u8bc1$\\widetilde O(\\sqrt T)$\u671f\u671b\u4ea4\u6362\u9057\u61be\uff1b2\uff09\u5e94\u7528\u7ed3\u679c\uff1a\u4e3a\u4e00\u822c\u53ef\u5f15\u51fa\u5c5e\u6027\u7684\u6821\u51c6\u8bef\u5dee\u6700\u5c0f\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u5728\u7ebf\u7b97\u6cd5\uff0c\u65e0\u9700\u5148\u524d\u5de5\u4f5c\u4e2d\u6240\u9700\u7684\u8bc6\u522b\u51fd\u6570Lipschitz\u5047\u8bbe\uff0c\u7279\u522b\u4e3a\u4e2d\u4f4d\u6570\u6821\u51c6\u5b9e\u73b0\u4e86\u9996\u4e2a$\\widetilde O(\\sqrt T)$\u6821\u51c6\u8bef\u5dee\u4fdd\u8bc1\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u521b\u65b0\u7684\u591a\u5c3a\u5ea6\u5206\u7bb1\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u4ea4\u6362\u9057\u61be\u4f18\u5316\u7684\u5173\u952e\u5f00\u653e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u9057\u61be\u754c\u9650\u548c\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u7ed3\u679c\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u5728\u7ebf\u5b66\u4e60\u7406\u8bba\uff0c\u8fd8\u4e3a\u6821\u51c6\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u7279\u522b\u6269\u5c55\u5230\u4e86\u4e2d\u4f4d\u6570\u6821\u51c6\u7b49\u5148\u524d\u65e0\u6cd5\u5904\u7406\u7684\u60c5\u51b5\u3002"}}
{"id": "2602.08235", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08235", "abs": "https://arxiv.org/abs/2602.08235", "authors": ["Jaylen Jones", "Zhehao Zhang", "Yuting Ning", "Eric Fosler-Lussier", "Pierre-Luc St-Charles", "Yoshua Bengio", "Dawn Song", "Yu Su", "Huan Sun"], "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/AutoElicit/", "summary": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.", "AI": {"tldr": "AutoElicit\uff1a\u9996\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6270\u52a8\u826f\u6027\u6307\u4ee4\u6765\u81ea\u52a8\u8bf1\u53d1\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUA\uff09\u7684\u6709\u5bb3\u610f\u5916\u884c\u4e3a\uff0c\u5728Claude\u7b49\u5148\u8fdbCUA\u4e2d\u53d1\u73b0\u6570\u767e\u79cd\u6b64\u7c7b\u884c\u4e3a", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUA\uff09\u5728\u81ea\u52a8\u5316\u590d\u6742\u64cd\u4f5c\u7cfb\u7edf\u5de5\u4f5c\u6d41\u7a0b\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5373\u4f7f\u5728\u826f\u6027\u8f93\u5165\u73af\u5883\u4e0b\u4e5f\u53ef\u80fd\u8868\u73b0\u51fa\u504f\u79bb\u9884\u671f\u7ed3\u679c\u7684\u4e0d\u5b89\u5168\u610f\u5916\u884c\u4e3a\u3002\u76ee\u524d\u5bf9\u8fd9\u79cd\u98ce\u9669\u7684\u63a2\u7d22\u4e3b\u8981\u505c\u7559\u5728\u8f76\u4e8b\u5c42\u9762\uff0c\u7f3a\u4e4f\u5177\u4f53\u7684\u7279\u5f81\u63cf\u8ff0\u548c\u5728\u73b0\u5b9eCUA\u573a\u666f\u4e0b\u4e3b\u52a8\u53d1\u73b0\u957f\u5c3e\u610f\u5916\u884c\u4e3a\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAutoElicit\u6846\u67b6\uff1a\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6270\u52a8\u826f\u6027\u6307\u4ee4\u5e76\u5229\u7528CUA\u6267\u884c\u53cd\u9988\uff0c\u5728\u4fdd\u6301\u6270\u52a8\u73b0\u5b9e\u6027\u548c\u826f\u6027\u524d\u63d0\u4e0b\u8bf1\u53d1\u4e25\u91cd\u5371\u5bb3\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u610f\u5916\u884c\u4e3a\u3002", "result": "\u4f7f\u7528AutoElicit\u5728Claude 4.5 Haiku\u548cOpus\u7b49\u5148\u8fdbCUA\u4e2d\u53d1\u73b0\u4e86\u6570\u767e\u79cd\u6709\u5bb3\u7684\u610f\u5916\u884c\u4e3a\u3002\u8fdb\u4e00\u6b65\u8bc4\u4f30\u4e86\u4eba\u5de5\u9a8c\u8bc1\u6210\u529f\u6270\u52a8\u7684\u53ef\u8f6c\u79fb\u6027\uff0c\u53d1\u73b0\u5404\u79cd\u524d\u6cbfCUA\u5bf9\u8fd9\u79cd\u610f\u5916\u884c\u4e3a\u5b58\u5728\u6301\u7eed\u6613\u611f\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u73b0\u5b9e\u8ba1\u7b97\u673a\u4f7f\u7528\u73af\u5883\u4e2d\u7cfb\u7edf\u5206\u6790\u610f\u5916\u884c\u4e3a\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u7406\u89e3\u548c\u7f13\u89e3CUA\u5b89\u5168\u98ce\u9669\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u652f\u6301\u3002"}}
{"id": "2602.08013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08013", "abs": "https://arxiv.org/abs/2602.08013", "authors": ["Yuqiao Meng", "Luoxi Tang", "Dazheng Zhang", "Rafael Brens", "Elvys J. Romero", "Nancy Guo", "Safa Elkefi", "Zhaohan Xi"], "title": "Small Agent Group is the Future of Digital Health", "comment": null, "summary": "The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.", "AI": {"tldr": "\u5c0f\u4ee3\u7406\u7ec4\uff08SAG\uff09\u901a\u8fc7\u534f\u540c\u63a8\u7406\u673a\u5236\uff0c\u5728\u4e34\u5e8a\u573a\u666f\u4e2d\u8d85\u8d8a\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u5b9e\u73b0\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6210\u672c\u7684\u66f4\u597d\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5065\u5eb7\u9886\u57df\u8fc7\u5ea6\u4f9d\u8d56\"\u89c4\u6a21\u4f18\u5148\"\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u4e0d\u4ec5\u9700\u8981\u6548\u679c\uff0c\u8fd8\u9700\u8981\u53ef\u9760\u6027\u548c\u5408\u7406\u7684\u90e8\u7f72\u6210\u672c\u3002\u4e34\u5e8a\u51b3\u7b56\u672c\u8d28\u4e0a\u662f\u534f\u4f5c\u6027\u7684\uff0c\u56e0\u6b64\u9700\u8981\u6311\u6218\u5355\u4e00\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u7684\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u5c0f\u4ee3\u7406\u7ec4\uff08SAG\uff09\u65b9\u6cd5\uff0c\u5c06\u63a8\u7406\u3001\u5faa\u8bc1\u5206\u6790\u548c\u5173\u952e\u5ba1\u6838\u901a\u8fc7\u534f\u4f5c\u5ba1\u8bae\u8fc7\u7a0b\u8fdb\u884c\u5206\u5e03\u5f0f\u5904\u7406\uff0c\u4ece\u5355\u4e00\u6a21\u578b\u667a\u80fd\u8f6c\u5411\u96c6\u4f53\u4e13\u4e1a\u77e5\u8bc6\u3002", "result": "SAG\u5728\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6210\u672c\u7b49\u591a\u4e2a\u4e34\u5e8a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u65e0\u8bba\u662f\u5426\u4f7f\u7528\u989d\u5916\u4f18\u5316\u6216\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u3002SAG\u7684\u534f\u540c\u63a8\u7406\u53ef\u4ee5\u66ff\u4ee3\u6a21\u578b\u53c2\u6570\u589e\u957f\u3002", "conclusion": "SAG\u4e3a\u6570\u5b57\u5065\u5eb7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u66f4\u597d\u5730\u5e73\u8861\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6548\u7387\uff0c\u6311\u6218\u4e86\"\u89c4\u6a21\u8d8a\u5927\u8d8a\u597d\"\u7684\u4f20\u7edf\u89c2\u5ff5\u3002"}}
{"id": "2602.08907", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08907", "abs": "https://arxiv.org/abs/2602.08907", "authors": ["Marko Medvedev", "Idan Attias", "Elisabetta Cornacchia", "Theodor Misiakiewicz", "Gal Vardi", "Nathan Srebro"], "title": "Positive Distribution Shift as a Framework for Understanding Tractable Learning", "comment": null, "summary": "We study a setting where the goal is to learn a target function f(x) with respect to a target distribution D(x), but training is done on i.i.d. samples from a different training distribution D'(x), labeled by the true target f(x). Such a distribution shift (here in the form of covariate shift) is usually viewed negatively, as hurting or making learning harder, and the traditional distribution shift literature is mostly concerned with limiting or avoiding this negative effect. In contrast, we argue that with a well-chosen D'(x), the shift can be positive and make learning easier -- a perspective called Positive Distribution Shift (PDS). Such a perspective is central to contemporary machine learning, where much of the innovation is in finding good training distributions D'(x), rather than changing the training algorithm. We further argue that the benefit is often computational rather than statistical, and that PDS allows computationally hard problems to become tractable even using standard gradient-based training. We formalize different variants of PDS, show how certain hard classes are easily learnable under PDS, and make connections with membership query learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6b63\u5206\u5e03\u504f\u79fb\"\u6982\u5ff5\uff0c\u8ba4\u4e3a\u5728\u9002\u5f53\u9009\u62e9\u7684\u8bad\u7ec3\u5206\u5e03\u4e0b\uff0c\u5206\u5e03\u504f\u79fb\u53ef\u4ee5\u4f7f\u5b66\u4e60\u66f4\u5bb9\u6613\u800c\u975e\u66f4\u96be\uff0c\u8fd9\u4e3b\u8981\u662f\u8ba1\u7b97\u4e0a\u7684\u597d\u5904\u800c\u975e\u7edf\u8ba1\u4e0a\u7684\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u5206\u5e03\u504f\u79fb\uff08\u7279\u522b\u662f\u534f\u53d8\u91cf\u504f\u79fb\uff09\u5bf9\u5b66\u4e60\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u4f7f\u5b66\u4e60\u66f4\u56f0\u96be\u3002\u4f46\u4f5c\u8005\u8ba4\u4e3a\uff0c\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u8bad\u7ec3\u5206\u5e03\uff0c\u8fd9\u79cd\u504f\u79fb\u53ef\u4ee5\u6210\u4e3a\u6b63\u9762\u56e0\u7d20\uff0c\u4f7f\u5b66\u4e60\u66f4\u5bb9\u6613\u3002\u8fd9\u79cd\u89c6\u89d2\u5728\u5f53\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u521b\u65b0\u5f80\u5f80\u5728\u4e8e\u627e\u5230\u597d\u7684\u8bad\u7ec3\u5206\u5e03\u800c\u975e\u6539\u53d8\u8bad\u7ec3\u7b97\u6cd5\u3002", "method": "\u5f62\u5f0f\u5316\u6b63\u5206\u5e03\u504f\u79fb\u7684\u4e0d\u540c\u53d8\u4f53\uff0c\u5c55\u793a\u67d0\u4e9b\u56f0\u96be\u7c7b\u522b\u5728\u6b63\u5206\u5e03\u504f\u79fb\u4e0b\u53d8\u5f97\u5bb9\u6613\u5b66\u4e60\uff0c\u5e76\u4e0e\u6210\u5458\u67e5\u8be2\u5b66\u4e60\u5efa\u7acb\u8054\u7cfb\u3002\u7814\u7a76\u5728\u76ee\u6807\u5206\u5e03D(x)\u4e0b\u5b66\u4e60\u76ee\u6807\u51fd\u6570f(x)\uff0c\u4f46\u8bad\u7ec3\u4f7f\u7528\u6765\u81ea\u4e0d\u540c\u8bad\u7ec3\u5206\u5e03D'(x)\u7684i.i.d.\u6837\u672c\u3002", "result": "\u6b63\u5206\u5e03\u504f\u79fb\u7684\u597d\u5904\u4e3b\u8981\u662f\u8ba1\u7b97\u4e0a\u7684\u800c\u975e\u7edf\u8ba1\u4e0a\u7684\uff0c\u5b83\u4f7f\u5f97\u539f\u672c\u8ba1\u7b97\u56f0\u96be\u7684\u95ee\u9898\u53d8\u5f97\u53ef\u5904\u7406\uff0c\u5373\u4f7f\u4f7f\u7528\u6807\u51c6\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002\u67d0\u4e9b\u56f0\u96be\u7c7b\u522b\u5728\u6b63\u5206\u5e03\u504f\u79fb\u4e0b\u53d8\u5f97\u5bb9\u6613\u5b66\u4e60\u3002", "conclusion": "\u6b63\u5206\u5e03\u504f\u79fb\u662f\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u7814\u7a76\u89c6\u89d2\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u8ba4\u4e3a\u5206\u5e03\u504f\u79fb\u6709\u5bb3\u7684\u89c2\u70b9\u3002\u901a\u8fc7\u7cbe\u5fc3\u9009\u62e9\u8bad\u7ec3\u5206\u5e03\uff0c\u53ef\u4ee5\u4f7f\u5b66\u4e60\u4efb\u52a1\u5728\u8ba1\u7b97\u4e0a\u53d8\u5f97\u66f4\u5bb9\u6613\uff0c\u8fd9\u4e3a\u673a\u5668\u5b66\u4e60\u5b9e\u8df5\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.08237", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08237", "abs": "https://arxiv.org/abs/2602.08237", "authors": ["Yao Xiao", "Lei Wang", "Yue Deng", "Guanzheng Chen", "Ziqi Jin", "Jung-jae Kim", "Xiaoli Li", "Roy Ka-wei Lee", "Lidong Bing"], "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9LLM\u91cd\u6784\u88ab\u66ff\u6362\u6bb5\u843d\u7684\u957f\u6587\u6863\u6765\u589e\u5f3a\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u6559\u5e08\u6a21\u578b\u76d1\u7763\u3002", "motivation": "\u4f20\u7edf\u7684RLVR\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u9ec4\u91d1\u6807\u51c6\u7b54\u6848\u6216\u6559\u5e08\u6a21\u578b\u8bc4\u4f30\u6807\u51c6\uff0c\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u65e0\u76d1\u7763\u65b9\u6cd5\u589e\u5f3aLLM\u7684\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\uff0c\u907f\u514d\u5bf9\u4eba\u5de5\u6807\u6ce8\u6216\u6559\u5e08\u6a21\u578b\u76d1\u7763\u7684\u4f9d\u8d56\u3002", "method": "\u9996\u5148\u5728\u957f\u6587\u6863\u4e2d\u7528\u7279\u6b8a\u5360\u4f4d\u7b26\u66ff\u6362\u51e0\u4e2a\u6bb5\u843d\uff0c\u7136\u540e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u4ece\u5019\u9009\u9009\u9879\u96c6\u4e2d\u6b63\u786e\u8bc6\u522b\u548c\u6392\u5e8f\u7f3a\u5931\u6bb5\u843d\u6765\u91cd\u6784\u6587\u6863\u3002\u8fd9\u79cd\u8bad\u7ec3\u8303\u5f0f\u4f7f\u6a21\u578b\u80fd\u591f\u6355\u6349\u5168\u5c40\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002", "result": "\u5728RULER\u548cLongBench v2\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5728RULER\u4e0a\u83b7\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5728LongBench v2\u4e0a\u4e5f\u80fd\u5b9e\u73b0\u5408\u7406\u6539\u8fdb\uff0c\u4e14\u65e0\u9700\u624b\u52a8\u6574\u7406\u7684\u957f\u4e0a\u4e0b\u6587QA\u6570\u636e\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u589e\u5f3aLLM\u7684\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\uff0c\u901a\u8fc7\u6587\u6863\u91cd\u6784\u4efb\u52a1\u4f7f\u6a21\u578b\u5b66\u4e60\u5168\u5c40\u8fde\u8d2f\u6027\u3002\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6d88\u878d\u7814\u7a76\u5206\u6790\u5956\u52b1\u8bbe\u8ba1\u3001\u6570\u636e\u7b56\u7565\u7b49\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7801\u3001\u6570\u636e\u548c\u6a21\u578b\u3002"}}
{"id": "2602.08021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08021", "abs": "https://arxiv.org/abs/2602.08021", "authors": ["Zhan-Yi Liao", "Jaewon Yoo", "Hao-Tsung Yang", "Po-An Chen"], "title": "Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers", "comment": null, "summary": "Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features through a directed acyclic graph (DAG). This structure naturally embeds feature relationships into the search process, eliminating the need for additional constraints to ensure consistency with the model's structural assumptions. We adopt a convergence-guaranteed cutting-set procedure as an adversarial optimization framework, which iteratively approximates solutions that satisfy global robustness conditions. To address the nonconvex quadratic structure induced by feature dependencies, we apply piecewise McCormick relaxation to reformulate the problem as a mixed-integer linear program (MILP), ensuring global optimality. Experimental results show that our method achieves strong robustness, with direct global optimization of the original formulation providing especially stable and efficient results. The proposed framework is extensible to more complex constraint settings, laying the groundwork for future advances in counterfactual reasoning under nonconvex quadratic formulations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u9ad8\u65af\u7f51\u7edc\u5206\u7c7b\u5668\u7684\u7ed3\u6784\u611f\u77e5\u3001\u9c81\u68d2\u6027\u5bfc\u5411\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u786e\u4fdd\u5168\u5c40\u6700\u4f18\u6027", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u7279\u5f81\u95f4\u7684\u6761\u4ef6\u4f9d\u8d56\u5173\u7cfb\u548c\u6f5c\u5728\u56e0\u679c\u7ed3\u6784\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u9c81\u68d2\u6027\u7684\u4fdd\u8bc1\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u7136\u5d4c\u5165\u7279\u5f81\u5173\u7cfb\u5e76\u786e\u4fdd\u5168\u5c40\u9c81\u68d2\u6027\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528\u6761\u4ef6\u9ad8\u65af\u7f51\u7edc\u5206\u7c7b\u5668\uff08CGNC\uff09\u7f16\u7801\u7279\u5f81\u95f4\u7684\u6761\u4ef6\u4f9d\u8d56\u5173\u7cfb\uff0c\u91c7\u7528\u6536\u655b\u4fdd\u8bc1\u7684\u5207\u5272\u96c6\u7a0b\u5e8f\u4f5c\u4e3a\u5bf9\u6297\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6bb5McCormick\u677e\u5f1b\u5c06\u975e\u51f8\u4e8c\u6b21\u95ee\u9898\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5f3a\u9c81\u68d2\u6027\uff0c\u76f4\u63a5\u5168\u5c40\u4f18\u5316\u539f\u59cb\u516c\u5f0f\u63d0\u4f9b\u4e86\u7279\u522b\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u7ed3\u679c\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u7ea6\u675f\u8bbe\u7f6e", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5728\u975e\u51f8\u4e8c\u6b21\u516c\u5f0f\u4e0b\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\u7684\u672a\u6765\u8fdb\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u548c\u9c81\u68d2\u6027\u5bfc\u5411\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u8d28\u91cf"}}
{"id": "2602.08913", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.08913", "abs": "https://arxiv.org/abs/2602.08913", "authors": ["Kate\u0159ina Henclov\u00e1", "V\u00e1clav \u0160m\u00eddl"], "title": "GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems", "comment": null, "summary": "Selecting interpretable feature sets in underdetermined ($n \\ll p$) and highly correlated regimes constitutes a fundamental challenge in data science, particularly when analyzing physical measurements. In such settings, multiple distinct sparse subsets may explain the response equally well. Identifying these alternatives is crucial for generating domain-specific insights into the underlying mechanisms, yet conventional methods typically isolate a single solution, obscuring the full spectrum of plausible explanations.\n  We present GEMSS (Gaussian Ensemble for Multiple Sparse Solutions), a variational Bayesian framework specifically designed to simultaneously discover multiple, diverse sparse feature combinations. The method employs a structured spike-and-slab prior for sparsity, a mixture of Gaussians to approximate the intractable multimodal posterior, and a Jaccard-based penalty to further control solution diversity. Unlike sequential greedy approaches, GEMSS optimizes the entire ensemble of solutions within a single objective function via stochastic gradient descent.\n  The method is validated on a comprehensive benchmark comprising 128 synthetic experiments across classification and regression tasks. Results demonstrate that GEMSS scales effectively to high-dimensional settings ($p=5000$) with sample size as small as $n = 50$, generalizes seamlessly to continuous targets, handles missing data natively, and exhibits remarkable robustness to class imbalance and Gaussian noise.\n  GEMSS is available as a Python package 'gemss' at PyPI. The full GitHub repository at https://github.com/kat-er-ina/gemss/ also includes a free, easy-to-use application suitable for non-coders.", "AI": {"tldr": "GEMSS\u662f\u4e00\u4e2a\u53d8\u5206\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u7528\u4e8e\u5728n\u226ap\u548c\u9ad8\u76f8\u5173\u6027\u7684\u6b20\u5b9a\u6570\u636e\u4e2d\u540c\u65f6\u53d1\u73b0\u591a\u4e2a\u4e0d\u540c\u7684\u7a00\u758f\u7279\u5f81\u7ec4\u5408\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u53ea\u80fd\u627e\u5230\u5355\u4e00\u89e3\u7684\u95ee\u9898\u3002", "motivation": "\u5728n\u226ap\u548c\u9ad8\u76f8\u5173\u6027\u7684\u6b20\u5b9a\u6570\u636e\u4e2d\uff0c\u901a\u5e38\u5b58\u5728\u591a\u4e2a\u4e0d\u540c\u7684\u7a00\u758f\u7279\u5f81\u5b50\u96c6\u90fd\u80fd\u5f88\u597d\u5730\u89e3\u91ca\u54cd\u5e94\u53d8\u91cf\u3002\u4f20\u7edf\u65b9\u6cd5\u53ea\u80fd\u627e\u5230\u4e00\u4e2a\u89e3\uff0c\u8fd9\u63a9\u76d6\u4e86\u6240\u6709\u53ef\u80fd\u7684\u89e3\u91ca\uff0c\u800c\u8bc6\u522b\u8fd9\u4e9b\u66ff\u4ee3\u65b9\u6848\u5bf9\u4e8e\u6df1\u5165\u7406\u89e3\u5e95\u5c42\u673a\u5236\u81f3\u5173\u91cd\u8981\u3002", "method": "GEMSS\u91c7\u7528\u53d8\u5206\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u4f7f\u7528\u7ed3\u6784\u5316spike-and-slab\u5148\u9a8c\u5b9e\u73b0\u7a00\u758f\u6027\uff0c\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8fd1\u4f3c\u96be\u4ee5\u5904\u7406\u7684\u591a\u5cf0\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u901a\u8fc7Jaccard\u60e9\u7f5a\u63a7\u5236\u89e3\u4e4b\u95f4\u7684\u591a\u6837\u6027\u3002\u4e0e\u987a\u5e8f\u8d2a\u5a6a\u65b9\u6cd5\u4e0d\u540c\uff0cGEMSS\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u5728\u5355\u4e00\u76ee\u6807\u51fd\u6570\u4e2d\u4f18\u5316\u6574\u4e2a\u89e3\u96c6\u5408\u3002", "result": "\u5728128\u4e2a\u5408\u6210\u5b9e\u9a8c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGEMSS\u80fd\u591f\u6709\u6548\u6269\u5c55\u5230\u9ad8\u7ef4\u8bbe\u7f6e(p=5000)\u4e14\u6837\u672c\u91cf\u5c0f\u81f3n=50\uff0c\u80fd\u65e0\u7f1d\u6cdb\u5316\u5230\u8fde\u7eed\u76ee\u6807\u53d8\u91cf\uff0c\u539f\u751f\u5904\u7406\u7f3a\u5931\u6570\u636e\uff0c\u5e76\u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u9ad8\u65af\u566a\u58f0\u8868\u73b0\u51fa\u663e\u8457\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "GEMSS\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u540c\u65f6\u53d1\u73b0\u591a\u4e2a\u4e0d\u540c\u7684\u7a00\u758f\u7279\u5f81\u7ec4\u5408\uff0c\u4e3a\u6b20\u5b9a\u548c\u9ad8\u76f8\u5173\u6570\u636e\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u91ca\u89c6\u89d2\uff0c\u5df2\u4f5c\u4e3aPython\u5305'gemss'\u5728PyPI\u4e0a\u53d1\u5e03\uff0c\u5e76\u5305\u542b\u9002\u5408\u975e\u7f16\u7a0b\u4eba\u5458\u4f7f\u7528\u7684\u5e94\u7528\u7a0b\u5e8f\u3002"}}
{"id": "2602.08238", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08238", "abs": "https://arxiv.org/abs/2602.08238", "authors": ["Nathaniel Imel", "Noga Zaslavasky"], "title": "On convexity and efficiency in semantic systems", "comment": null, "summary": "There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4eba\u7c7b\u8bed\u4e49\u8303\u7574\u7cfb\u7edf\u7684\u4e24\u4e2a\u7279\u5f81\uff1a\u51f8\u6027\u548c\u6548\u7387\u6027\u3002\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u6846\u67b6\u53d1\u73b0\u4e24\u8005\u672c\u8d28\u4e0d\u540c\uff0c\u4f46\u6548\u7387\u6027\u66f4\u80fd\u89e3\u91ca\u989c\u8272\u547d\u540d\u7cfb\u7edf\u7684\u5b9e\u8bc1\u73b0\u8c61\u3002", "motivation": "\u4eba\u7c7b\u8bed\u4e49\u8303\u7574\u7cfb\u7edf\u6709\u4e24\u4e2a\u5e7f\u6cdb\u8ba4\u53ef\u7684\u7279\u5f81\uff1a1\uff09\u5728\u6982\u5ff5\u7a7a\u95f4\u4e2d\u5f62\u6210\u51f8\u5206\u533a\uff0c2\uff09\u5bf9\u4ea4\u6d41\u5177\u6709\u6548\u7387\u6027\u3002\u5148\u524d\u7814\u7a76\u89c2\u5bdf\u5230\u989c\u8272\u547d\u540d\u4e2d\u51f8\u6027\u548c\u6548\u7387\u6027\u5171\u5b58\uff0c\u4f46\u4e24\u8005\u5173\u7cfb\u53ca\u5171\u5b58\u539f\u56e0\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u6846\u67b6\u8fdb\u884c\u5206\u6790\uff0c\u7ed3\u5408\u5206\u6790\u548c\u5b9e\u8bc1\u65b9\u6cd5\u3002\u9996\u5148\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u51f8\u6027\u548c\u6548\u7387\u6027\u7684\u72ec\u7acb\u6027\uff0c\u7136\u540e\u5e94\u7528\u4e8e\u989c\u8272\u547d\u540d\u9886\u57df\uff0c\u6bd4\u8f83\u4e24\u8005\u5bf9\u5b9e\u8bc1\u6570\u636e\u7684\u89e3\u91ca\u529b\u3002", "result": "1\uff09\u51f8\u6027\u548c\u6548\u7387\u6027\u672c\u8d28\u4e0d\u540c\uff1a\u5b58\u5728\u51f8\u4f46\u4f4e\u6548\u7684\u7cfb\u7edf\uff0c\u4e5f\u5b58\u5728\u6700\u4f18\u6548\u7387\u4f46\u975e\u51f8\u7684\u7cfb\u7edf\uff1b2\uff09\u5728\u989c\u8272\u547d\u540d\u9886\u57df\uff0cIB\u6700\u4f18\u7cfb\u7edf\u5927\u591a\u5448\u51f8\u6027\uff1b3\uff09\u6548\u7387\u6027\u6bd4\u51f8\u6027\u66f4\u80fd\u533a\u5206\u5b9e\u9645\u989c\u8272\u547d\u540d\u7cfb\u7edf\u4e0e\u5047\u8bbe\u53d8\u4f53\uff1b4\uff09\u6548\u7387\u6027\u80fd\u89e3\u91ca\u51f8\u6027\u65e0\u6cd5\u89e3\u91ca\u7684\u5b9e\u8bc1\u73b0\u8c61\u3002", "conclusion": "\u867d\u7136\u51f8\u6027\u548c\u6548\u7387\u6027\u53ef\u80fd\u4ea7\u751f\u76f8\u4f3c\u7684\u7ed3\u6784\u89c2\u5bdf\u7ed3\u679c\uff0c\u4f46\u4e24\u8005\u672c\u8d28\u4e0d\u540c\u3002\u6548\u7387\u6027\u4e3a\u8bed\u4e49\u7c7b\u578b\u5b66\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u800c\u51f8\u6027\u5728\u989c\u8272\u547d\u540d\u4e2d\u7684\u666e\u904d\u5b58\u5728\u53ef\u80fd\u662f\u6548\u7387\u4f18\u5316\u7684\u526f\u4ea7\u54c1\u3002"}}
{"id": "2602.08030", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08030", "abs": "https://arxiv.org/abs/2602.08030", "authors": ["Yilun Zheng", "Dongyang Ma", "Tian Liang", "Jiahao Xu", "Xinting Huang", "Lijie Chen", "Haitao Mi", "Yan Wang"], "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models", "comment": null, "summary": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.", "AI": {"tldr": "Free()LM\u901a\u8fc7\u5f15\u5165\u81ea\u6211\u9057\u5fd8\u80fd\u529b\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u4e2d\u7684\"\u8fc7\u5ea6\u601d\u8003\"\u95ee\u9898\uff0c\u4f7f\u7528Free-Module LoRA\u9002\u914d\u5668\u52a8\u6001\u4fee\u526a\u65e0\u7528\u4e0a\u4e0b\u6587\uff0c\u5728\u5404\u79cd\u89c4\u6a21\u6a21\u578b\u4e0a\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u6807\u51c6LLM\u5b58\u5728\"malloc-only\"\u67b6\u6784\u7f3a\u9677\uff0c\u6301\u7eed\u79ef\u7d2f\u6709\u6548\u548c\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u800c\u6ca1\u6709\u4fee\u526a\u673a\u5236\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\u65f6\u6027\u80fd\u4e0b\u964d\u800c\u975e\u63d0\u5347", "method": "\u63d0\u51faFree()LM\u6a21\u578b\uff0c\u901a\u8fc7Free-Module LoRA\u9002\u914d\u5668\u5b9e\u73b0\u5185\u5728\u81ea\u6211\u9057\u5fd8\u80fd\u529b\uff0c\u5728\u63a8\u7406\u6a21\u5f0f\u548c\u6e05\u7406\u6a21\u5f0f\u4e4b\u95f4\u8fed\u4ee3\u5207\u6362\uff0c\u52a8\u6001\u8bc6\u522b\u5e76\u4fee\u526a\u65e0\u7528\u4e0a\u4e0b\u6587\u5757", "result": "\u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\uff088B\u5230685B\uff09\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\uff0c\u5e73\u5747\u6bd4\u9876\u7ea7\u63a8\u7406\u57fa\u7ebf\u63d0\u53473.3%\uff0c\u5728IMOanswerBench\u4e0a\u5efa\u7acb\u65b0SOTA\uff1b\u5728\u957f\u65f6\u4efb\u52a1\u4e2d\uff0c\u5c06Qwen3-235B-A22B\u4ece0%\u51c6\u786e\u7387\u6062\u590d\u523050%", "conclusion": "\u53ef\u6301\u7eed\u667a\u80fd\u9700\u8981\u9057\u5fd8\u7684\u81ea\u7531\u4e0e\u601d\u8003\u7684\u80fd\u529b\u540c\u7b49\u91cd\u8981\uff0cFree()LM\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u7ba1\u7406\u89e3\u51b3\u4e86\u63a8\u7406\u6a21\u578b\u7684\u5173\u952e\u67b6\u6784\u7f3a\u9677"}}
{"id": "2602.07429", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07429", "abs": "https://arxiv.org/abs/2602.07429", "authors": ["Yuanxu Sun", "Yuezhou Ma", "Haixu Wu", "Guanyang Zeng", "Muye Chen", "Jianmin Wang", "Mingsheng Long"], "title": "Brep2Shape: Boundary and Shape Representation Alignment via Self-Supervised Transformers", "comment": null, "summary": "Boundary representation (B-rep) is the industry standard for computer-aided design (CAD). While deep learning shows promise in processing B-rep models, existing methods suffer from a representation gap: continuous approaches offer analytical precision but are visually abstract, whereas discrete methods provide intuitive clarity at the expense of geometric precision. To bridge this gap, we introduce Brep2Shape, a novel self-supervised pre-training method designed to align abstract boundary representations with intuitive shape representations. Our method employs a geometry-aware task where the model learns to predict dense spatial points from parametric B\u00e9zier control points, enabling the network to better understand physical manifolds derived from abstract coefficients. To enhance this alignment, we propose a Dual Transformer backbone with parallel streams that independently encode surface and curve tokens to capture their distinct geometric properties. Moreover, the topology attention is integrated to model the interdependencies between surfaces and curves, thereby maintaining topological consistency. Experimental results demonstrate that Brep2Shape offers significant scalability, achieving state-of-the-art accuracy and faster convergence across various downstream tasks.", "AI": {"tldr": "Brep2Shape\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u611f\u77e5\u4efb\u52a1\u548c\u5bf9\u5076Transformer\u67b6\u6784\uff0c\u5c06\u62bd\u8c61\u7684\u8fb9\u754c\u8868\u793a\u4e0e\u76f4\u89c2\u7684\u5f62\u72b6\u8868\u793a\u5bf9\u9f50\uff0c\u5728CAD\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709B-rep\u5904\u7406\u65b9\u6cd5\u5b58\u5728\u8868\u793a\u5dee\u8ddd\uff1a\u8fde\u7eed\u65b9\u6cd5\u63d0\u4f9b\u5206\u6790\u7cbe\u5ea6\u4f46\u89c6\u89c9\u62bd\u8c61\uff0c\u79bb\u6563\u65b9\u6cd5\u63d0\u4f9b\u76f4\u89c2\u6e05\u6670\u5ea6\u4f46\u727a\u7272\u51e0\u4f55\u7cbe\u5ea6\u3002\u9700\u8981\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u4ee5\u6539\u8fdbCAD\u6a21\u578b\u7684\u6df1\u5ea6\u5b66\u4e60\u5904\u7406\u3002", "method": "\u63d0\u51faBrep2Shape\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff1a1\uff09\u51e0\u4f55\u611f\u77e5\u4efb\u52a1\uff1a\u4ece\u53c2\u6570B\u00e9zier\u63a7\u5236\u70b9\u9884\u6d4b\u5bc6\u96c6\u7a7a\u95f4\u70b9\uff1b2\uff09\u5bf9\u5076Transformer\u9aa8\u5e72\uff1a\u5e76\u884c\u7f16\u7801\u8868\u9762\u548c\u66f2\u7ebftoken\u4ee5\u6355\u6349\u4e0d\u540c\u51e0\u4f55\u7279\u6027\uff1b3\uff09\u62d3\u6251\u6ce8\u610f\u529b\uff1a\u5efa\u6a21\u8868\u9762\u4e0e\u66f2\u7ebf\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u4ee5\u4fdd\u6301\u62d3\u6251\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eBrep2Shape\u5177\u6709\u663e\u8457\u53ef\u6269\u5c55\u6027\uff0c\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "Brep2Shape\u6210\u529f\u5f25\u5408\u4e86B-rep\u8868\u793a\u4e2d\u7684\u62bd\u8c61\u4e0e\u76f4\u89c2\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u51e0\u4f55\u7406\u89e3\u548c\u62d3\u6251\u4e00\u81f4\u6027\uff0c\u4e3aCAD\u6a21\u578b\u7684\u6df1\u5ea6\u5b66\u4e60\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08252", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08252", "abs": "https://arxiv.org/abs/2602.08252", "authors": ["Devin R. Wright", "Justin E. Lane", "F. LeRon Shults"], "title": "Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence", "comment": "Initial submitted version", "summary": "In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.", "AI": {"tldr": "CLIFS\u65b9\u6cd5\u4f7f\u7528\u8ba4\u77e5\u8bed\u8a00\u6a21\u5f0f\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9690\u5f0f\u9690\u55bb\u4ece\u8bed\u8a00\u4e2d\u6d4b\u91cf\u8eab\u4efd\u878d\u5408\uff0c\u5728\u82f1\u56fd\u548c\u65b0\u52a0\u5761\u6570\u636e\u96c6\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u8bc6\u522b\u6781\u7aef\u4e3b\u4e49\u4e2d\u7684\u4e24\u79cd\u9ad8\u878d\u5408\u66b4\u529b\u8def\u5f84\u3002", "motivation": "\u968f\u7740\u793e\u4f1a\u6781\u5316\u52a0\u5267\u548c\u653f\u6cbb\u66b4\u529b\u589e\u591a\uff0c\u7406\u89e3\u6781\u7aef\u4e3b\u4e49\u7684\u5fc3\u7406\u6839\u6e90\u53d8\u5f97\u65e5\u76ca\u91cd\u8981\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\u8eab\u4efd\u878d\u5408\u80fd\u9884\u6d4b\u53c2\u4e0e\u6781\u7aef\u884c\u4e3a\u7684\u610f\u613f\uff0c\u4f46\u9700\u8981\u66f4\u6709\u6548\u7684\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u8ba4\u77e5\u8bed\u8a00\u8eab\u4efd\u878d\u5408\u8bc4\u5206\u65b9\u6cd5\uff0c\u5229\u7528\u8ba4\u77e5\u8bed\u8a00\u6a21\u5f0f\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9690\u5f0f\u9690\u55bb\u4ece\u8bed\u8a00\u4e2d\u6d4b\u91cf\u8eab\u4efd\u878d\u5408\u3002\u5728\u82f1\u56fd\u548c\u65b0\u52a0\u5761\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u5e94\u7528\u4e8e\u6781\u7aef\u4e3b\u4e49\u5ba3\u8a00\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u5df2\u9a8c\u8bc1\u7684\u8eab\u4efd\u878d\u5408\u5206\u6570\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5206\u6790\u6781\u7aef\u4e3b\u4e49\u5ba3\u8a00\u53d1\u73b0\u4e24\u79cd\u4e0d\u540c\u7684\u9ad8\u878d\u5408\u66b4\u529b\u8def\u5f84\uff1a\u610f\u8bc6\u5f62\u6001\u578b\u503e\u5411\u4e8e\u4ee5\u7fa4\u4f53\u672f\u8bed\u6846\u67b6\u81ea\u6211\uff0c\u5f62\u6210\u4eb2\u5c5e\u5173\u7cfb\u7ebd\u5e26\uff1b\u800c\u6028\u6068\u9a71\u52a8\u578b\u5219\u4ee5\u4e2a\u4eba\u8eab\u4efd\u672f\u8bed\u6846\u67b6\u7fa4\u4f53\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5b8c\u5584\u4e86\u8eab\u4efd\u878d\u5408\u7406\u8bba\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u8eab\u4efd\u878d\u5408\u7814\u7a76\u548c\u6781\u7aef\u4e3b\u4e49\u68c0\u6d4b\u3002"}}
{"id": "2602.08052", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08052", "abs": "https://arxiv.org/abs/2602.08052", "authors": ["Bulent Soykan", "Sean Mondesire", "Ghaith Rabadi", "Grace Bochenek"], "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling", "comment": "11 pages, 2 figures, Winter Simulation Conference (WSC) 2025", "summary": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePPO\u548cGNN\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u5e26\u91ca\u653e\u65f6\u95f4\u3001\u8bbe\u7f6e\u548c\u8d44\u683c\u7ea6\u675f\u7684\u4e0d\u76f8\u5173\u5e76\u884c\u673a\u8c03\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u603b\u52a0\u6743\u5ef6\u8fdf\u548c\u603b\u8bbe\u7f6e\u65f6\u95f4", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u603b\u52a0\u6743\u5ef6\u8fdf(TWT)\u548c\u603b\u8bbe\u7f6e\u65f6\u95f4(TST)\u8fd9\u4e24\u4e2a\u76ee\u6807\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u591a\u76ee\u6807\u7684\u8c03\u5ea6\u65b9\u6cd5", "method": "\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316(PPO)\u548c\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0cGNN\u8868\u793a\u4f5c\u4e1a\u3001\u673a\u5668\u548c\u8bbe\u7f6e\u7684\u590d\u6742\u72b6\u6001\uff0cPPO\u5b66\u4e60\u76f4\u63a5\u8c03\u5ea6\u7b56\u7565\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u6307\u5bfc\u4f18\u5316", "result": "\u5728\u57fa\u51c6\u5b9e\u4f8b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPPO-GNN\u667a\u80fd\u4f53\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u8c03\u5ea6\u89c4\u5219\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u4e24\u4e2a\u76ee\u6807\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6743\u8861", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u5236\u9020\u8c03\u5ea6\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898"}}
{"id": "2602.07440", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07440", "abs": "https://arxiv.org/abs/2602.07440", "authors": ["C\u00e9dric Jung", "Shirin Salehi", "Anke Schmeink"], "title": "Active Learning Using Aggregated Acquisition Functions: Accuracy and Sustainability Analysis", "comment": null, "summary": "Active learning (AL) is a machine learning (ML) approach that strategically selects the most informative samples for annotation during training, aiming to minimize annotation costs. This strategy not only reduces labeling expenses but also results in energy savings during neural network training, thereby enhancing both data and energy efficiency. In this paper, we implement and evaluate various state-of-the-art acquisition functions, analyzing their accuracy and computational costs, while discussing the advantages and disadvantages of each method. Our findings reveal that representativity-based acquisition functions effectively explore the dataset but do not prioritize boundary decisions, whereas uncertainty-based acquisition functions focus on refining boundary decisions already identified by the neural network. This trade-off is known as the exploration-exploitation dilemma. To address this dilemma, we introduce six aggregation structures: series, parallel, hybrid, adaptive feedback, random exploration, and annealing exploration. Our aggregated acquisition functions alleviate common AL pathologies such as batch mode inefficiency and the cold start problem. Additionally, we focus on balancing accuracy and energy consumption, contributing to the development of more sustainable, energy-aware artificial intelligence (AI). We evaluate our proposed structures on various models and datasets. Our results demonstrate the potential of these structures to reduce computational costs while maintaining or even improving accuracy. Innovative aggregation approaches, such as alternating between acquisition functions such as BALD and BADGE, have shown robust results. Sequentially running functions like $K$-Centers followed by BALD has achieved the same performance goals with up to 12\\% fewer samples, while reducing the acquisition cost by almost half.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u516d\u79cd\u805a\u5408\u7ed3\u6784\u6765\u89e3\u51b3\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff0c\u901a\u8fc7\u7ec4\u5408\u4ee3\u8868\u6027\u57fa\u548c\u4e0d\u786e\u5b9a\u6027\u57fa\u7684\u83b7\u53d6\u51fd\u6570\uff0c\u5728\u51cf\u5c11\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u80fd\u8017\uff0c\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u7684AI\u3002", "motivation": "\u4e3b\u52a8\u5b66\u4e60\u901a\u8fc7\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u6837\u672c\u8fdb\u884c\u6807\u6ce8\u6765\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff1a\u4ee3\u8868\u6027\u57fa\u65b9\u6cd5\u80fd\u63a2\u7d22\u6570\u636e\u96c6\u4f46\u5ffd\u7565\u8fb9\u754c\u51b3\u7b56\uff0c\u4e0d\u786e\u5b9a\u6027\u57fa\u65b9\u6cd5\u5173\u6ce8\u8fb9\u754c\u51b3\u7b56\u4f46\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002\u540c\u65f6\uff0c\u6279\u91cf\u6a21\u5f0f\u6548\u7387\u4f4e\u4e0b\u548c\u51b7\u542f\u52a8\u95ee\u9898\u4e5f\u662f\u5e38\u89c1\u6311\u6218\u3002\u6b64\u5916\uff0c\u9700\u8981\u5e73\u8861\u51c6\u786e\u6027\u548c\u80fd\u8017\uff0c\u53d1\u5c55\u66f4\u53ef\u6301\u7eed\u7684\u80fd\u6e90\u611f\u77e5AI\u3002", "method": "\u63d0\u51fa\u516d\u79cd\u805a\u5408\u7ed3\u6784\uff1a\u4e32\u8054\u3001\u5e76\u8054\u3001\u6df7\u5408\u3001\u81ea\u9002\u5e94\u53cd\u9988\u3001\u968f\u673a\u63a2\u7d22\u548c\u9000\u706b\u63a2\u7d22\u3002\u8fd9\u4e9b\u7ed3\u6784\u7ec4\u5408\u4e0d\u540c\u7684\u83b7\u53d6\u51fd\u6570\uff08\u5982BALD\u3001BADGE\u3001K-Centers\u7b49\uff09\uff0c\u901a\u8fc7\u4ea4\u66ff\u6216\u987a\u5e8f\u6267\u884c\u6765\u89e3\u51b3\u63a2\u7d22-\u5229\u7528\u56f0\u5883\u3002\u4f8b\u5982\uff0c\u4ea4\u66ff\u4f7f\u7528BALD\u548cBADGE\uff0c\u6216\u5148\u8fd0\u884cK-Centers\u518d\u8fd0\u884cBALD\u3002", "result": "\u805a\u5408\u7ed3\u6784\u80fd\u7f13\u89e3\u6279\u91cf\u6a21\u5f0f\u6548\u7387\u4f4e\u4e0b\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e32\u8054\u7ed3\u6784\uff08\u5982K-Centers\u540e\u63a5BALD\uff09\u80fd\u4ee5\u6700\u591a12%\u66f4\u5c11\u7684\u6837\u672c\u8fbe\u5230\u76f8\u540c\u6027\u80fd\u76ee\u6807\uff0c\u540c\u65f6\u5c06\u83b7\u53d6\u6210\u672c\u964d\u4f4e\u8fd1\u4e00\u534a\u3002\u4ea4\u66ff\u4f7f\u7528BALD\u548cBADGE\u7b49\u65b9\u6cd5\u4e5f\u663e\u793a\u51fa\u7a33\u5065\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u805a\u5408\u7ed3\u6784\u80fd\u6709\u6548\u89e3\u51b3\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff0c\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4e3a\u5f00\u53d1\u66f4\u53ef\u6301\u7eed\u3001\u80fd\u6e90\u611f\u77e5\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2602.08274", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08274", "abs": "https://arxiv.org/abs/2602.08274", "authors": ["Jan Philip Wahle"], "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection", "comment": "PhD dissertation, University of G\u00f6ttingen Germany, 2025. 182 pages", "summary": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u91ca\u4e49\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u8bed\u8a00\u5b66\u65b9\u9762\uff08\u91ca\u4e49\u7c7b\u578b\uff09\uff0c\u4e3a\u8ba1\u7b97\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\u7406\u89e3\uff0c\u5e76\u8bc1\u660e\u57fa\u4e8e\u91ca\u4e49\u7c7b\u578b\u8bad\u7ec3\u80fd\u63d0\u5347\u6a21\u578b\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u91ca\u4e49\u7b80\u5316\u4e3a\u4e24\u4e2a\u6587\u672c\u4e4b\u95f4\u7684\u4e8c\u5143\u51b3\u7b56\u6216\u5355\u4e00\u6539\u5199\uff0c\u63a9\u76d6\u4e86\u4fdd\u6301\u8bed\u4e49\u7684\u8bed\u8a00\u56e0\u7d20\u3002\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u3001\u57fa\u4e8e\u8ba4\u77e5\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\u7406\u89e3\u65b9\u6cd5\u3002", "method": "\u5c06\u91ca\u4e49\u5206\u89e3\u4e3a\u6784\u6210\u7684\u8bed\u8a00\u5b66\u65b9\u9762\uff08\u91ca\u4e49\u7c7b\u578b\uff09\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7c7b\u578b\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684\u4e8c\u5143\u91ca\u4e49\u5bf9\u8bad\u7ec3\u3002", "result": "\u57fa\u4e8e\u91ca\u4e49\u7c7b\u578b\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff1a\u527d\u7a83\u68c0\u6d4b\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u57fa\u7ebf\uff08\u7ef4\u57fa\u767e\u79d189.6% vs 78.4%\uff0carXiv\u79d1\u5b66\u8bba\u658766.5% vs 55.7%\uff09\uff0cQuora\u91cd\u590d\u95ee\u9898\u8bc6\u522b\u4e5f\u4f18\u4e8e\u4e8c\u5143\u5bf9\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u5206\u89e3\u91ca\u4e49\u4e3a\u8bed\u8a00\u5b66\u65b9\u9762\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\u89c6\u89d2\uff0c\u57fa\u4e8e\u91ca\u4e49\u7c7b\u578b\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u8fd9\u662f\u7406\u89e3\u8bed\u4e49\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.08061", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2602.08061", "abs": "https://arxiv.org/abs/2602.08061", "authors": ["Doni Bloomfield", "Allison Berke", "Moritz S. Hanke", "Aaron Maiwald", "James R. M. Black", "Toby Webster", "Tina Hernandez-Boussard", "Oliver M. Crook", "Jassi Pannu"], "title": "Securing Dual-Use Pathogen Data of Concern", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI", "summary": "Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u6570\u636e\u5bf9AI\u6a21\u578b\u6f5c\u5728\u6709\u5bb3\u80fd\u529b\u7684\u8d21\u732e\u7a0b\u5ea6\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u98ce\u9669\u7ea7\u522b\u63d0\u51fa\u6280\u672f\u9650\u5236\u63aa\u65bd\u548c\u6cbb\u7406\u6846\u67b6\u3002", "motivation": "\u968f\u7740AI\u5728\u751f\u7269\u5b66\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u88ab\u7528\u4e8e\u5f00\u53d1\u751f\u7269\u6b66\u5668\u7b49\u6709\u5bb3\u5e94\u7528\u3002\u56fd\u9645\u7814\u7a76\u56e2\u4f53\u547c\u5401\u5efa\u7acb\u6570\u636e\u63a7\u5236\u63aa\u65bd\uff0c\u9632\u6b62AI\u88ab\u6076\u610f\u5229\u7528\u3002\u9700\u8981\u8bbe\u8ba1\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5206\u7c7b\u548c\u63a7\u5236\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e00\u751f\u7269\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5f15\u5165\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u6570\u636e\u5bf9AI\u6a21\u578b\u6f5c\u5728\u6709\u5bb3\u80fd\u529b\u7684\u8d21\u732e\u7a0b\u5ea6\u8fdb\u884c\u5206\u7c7b\u3002\u6bcf\u4e2a\u7ea7\u522b\u5305\u542b\u7279\u5b9a\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u98ce\u9669\u7ea7\u522b\u63d0\u51fa\u76f8\u5e94\u7684\u6280\u672f\u9650\u5236\u63aa\u65bd\u3002\u540c\u65f6\u63d0\u51fa\u9488\u5bf9\u65b0\u521b\u5efa\u7684\u53cc\u7528\u9014\u75c5\u539f\u4f53\u6570\u636e\u7684\u6cbb\u7406\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u6570\u636e\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u75c5\u539f\u4f53\u6570\u636e\u5206\u4e3a\u4e94\u4e2a\u98ce\u9669\u7b49\u7ea7\uff0c\u4e3a\u6570\u636e\u63a7\u5236\u63d0\u4f9b\u4e86\u79d1\u5b66\u4f9d\u636e\u3002\u63d0\u51fa\u4e86\u4e0e\u98ce\u9669\u7ea7\u522b\u76f8\u5339\u914d\u7684\u6280\u672f\u9650\u5236\u63aa\u65bd\uff0c\u4e3a\u5b9e\u9645\u76d1\u7ba1\u63d0\u4f9b\u4e86\u64cd\u4f5c\u6307\u5357\u3002", "conclusion": "\u5728\u8ba1\u7b97\u548c\u7f16\u7801\u8d44\u6e90\u5e7f\u6cdb\u53ef\u53ca\u7684\u4e16\u754c\u4e2d\uff0c\u6570\u636e\u63a7\u5236\u53ef\u80fd\u662f\u51cf\u5c11\u6709\u5bb3\u751f\u7269AI\u80fd\u529b\u6269\u6563\u7684\u6700\u6709\u6548\u5e72\u9884\u63aa\u65bd\u4e4b\u4e00\u3002BDL\u6846\u67b6\u4e3a\u5b9e\u65bd\u6570\u636e\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5e73\u8861\u79d1\u5b66\u8fdb\u6b65\u4e0e\u751f\u7269\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2602.07441", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07441", "abs": "https://arxiv.org/abs/2602.07441", "authors": ["Jinzong Dong", "Wei Huang", "Jianshu Zhang", "Zhuo Chen", "Xinzhe Yuan", "Qinying Gu", "Zhaohui Jiang", "Nanyang Ye"], "title": "Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning", "comment": null, "summary": "Offline reinforcement learning (RL) optimizes policies from a previously collected static dataset and is an important branch of RL. A popular and promising approach is to regularize actor-critic methods with behavior cloning (BC), which yields realistic policies and mitigates bias from out-of-distribution actions, but can impose an often-overlooked performance ceiling: when dataset actions are suboptimal, indiscriminate imitation structurally prevents the actor from fully exploiting high-value regions suggested by the critic, especially in later training when imitation is already dominant. We formally analyzed this limitation by investigating convergence properties of BC-regularized actor-critic optimization and verified it on a controlled continuous bandit task. To break this ceiling, we propose proximal action replacement (PAR), a plug-and-play training sample replacer that progressively replaces low-value actions with high-value actions generated by a stable actor, broadening the action exploration space while reducing the impact of low-value data. PAR is compatible with multiple BC regularization paradigms. Extensive experiments across offline RL benchmarks show that PAR consistently improves performance and approaches state-of-the-art when combined with the basic TD3+BC.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPAR\u65b9\u6cd5\u89e3\u51b3\u79bb\u7ebfRL\u4e2d\u884c\u4e3a\u514b\u9686\u6b63\u5219\u5316\u5bfc\u81f4\u7684\u6027\u80fd\u5929\u82b1\u677f\u95ee\u9898\uff0c\u901a\u8fc7\u6e10\u8fdb\u66ff\u6362\u4f4e\u4ef7\u503c\u52a8\u4f5c\u4e3a\u9ad8\u4ef7\u503c\u52a8\u4f5c\u6765\u6269\u5c55\u63a2\u7d22\u7a7a\u95f4", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u884c\u4e3a\u514b\u9686\u6b63\u5219\u5316\u867d\u7136\u80fd\u4ea7\u751f\u5b9e\u9645\u53ef\u884c\u7684\u7b56\u7565\u5e76\u7f13\u89e3\u5206\u5e03\u5916\u52a8\u4f5c\u7684\u504f\u5dee\uff0c\u4f46\u5f53\u6570\u636e\u96c6\u52a8\u4f5c\u6b21\u4f18\u65f6\uff0c\u76f2\u76ee\u6a21\u4eff\u4f1a\u963b\u788d\u667a\u80fd\u4f53\u5145\u5206\u5229\u7528\u8bc4\u8bba\u5bb6\u5efa\u8bae\u7684\u9ad8\u4ef7\u503c\u533a\u57df\uff0c\u5f62\u6210\u6027\u80fd\u5929\u82b1\u677f", "method": "\u63d0\u51fa\u8fd1\u7aef\u52a8\u4f5c\u66ff\u6362(PAR)\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u8bad\u7ec3\u6837\u672c\u66ff\u6362\u5668\uff0c\u9010\u6b65\u7528\u7a33\u5b9a\u6f14\u5458\u751f\u6210\u7684\u9ad8\u4ef7\u503c\u52a8\u4f5c\u66ff\u6362\u4f4e\u4ef7\u503c\u52a8\u4f5c\uff0c\u6269\u5c55\u52a8\u4f5c\u63a2\u7d22\u7a7a\u95f4\u540c\u65f6\u51cf\u5c11\u4f4e\u4ef7\u503c\u6570\u636e\u7684\u5f71\u54cd", "result": "\u5728\u79bb\u7ebfRL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPAR\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u5f53\u4e0e\u57fa\u7840TD3+BC\u7ed3\u5408\u65f6\u80fd\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73", "conclusion": "PAR\u65b9\u6cd5\u6709\u6548\u7a81\u7834\u4e86\u79bb\u7ebfRL\u4e2d\u884c\u4e3a\u514b\u9686\u6b63\u5219\u5316\u7684\u6027\u80fd\u9650\u5236\uff0c\u4e3a\u79bb\u7ebfRL\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6539\u8fdb\u65b9\u6848"}}
{"id": "2602.08281", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08281", "abs": "https://arxiv.org/abs/2602.08281", "authors": ["Zhilin Wang", "Yafu Li", "Shunkai Zhang", "Zhi Wang", "Haoran Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR", "comment": "15 pages", "summary": "Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($\u03c1\\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.", "AI": {"tldr": "RLVR\u901a\u8fc7\u4f18\u5316\u539f\u5b50\u6b65\u9aa4\u6982\u7387\u8d4b\u4e88LLMs\u65b0\u80fd\u529b\uff0c\u800c\u975e\u4ec5\u6fc0\u53d1\u6f5c\u5728\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u514b\u670d\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u6307\u6570\u8870\u51cf\u95ee\u9898", "motivation": "\u89e3\u51b3\u5173\u4e8eRLVR\u662f\u8d4b\u4e88LLMs\u65b0\u80fd\u529b\u8fd8\u662f\u4ec5\u6fc0\u53d1\u6f5c\u5728\u80fd\u529b\u7684\u4e89\u8bae\uff0c\u63d0\u51fa\u80fd\u529b\u5e94\u5b9a\u4e49\u4e3a\u5b9e\u4f8b\u7ea7\u53ef\u89e3\u6027\uff0c\u5e76\u63a2\u7d22\u590d\u6742\u63a8\u7406\u80fd\u529b\u6d8c\u73b0\u7684\u673a\u5236", "method": "\u63d0\u51fa\u6982\u7387\u6846\u67b6\uff0c\u5047\u8bbe\u590d\u6742\u63a8\u7406\u80fd\u529b\u6e90\u4e8e\u539f\u5b50\u6b65\u9aa4\u6982\u7387\u7684\u9510\u5316\uff1b\u4f7f\u7528Algebrarium\u6846\u67b6\uff0c\u5728\u5355\u6b65\u64cd\u4f5c\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728\u672a\u89c1\u591a\u6b65\u4efb\u52a1\u4e0a\u7684\u8868\u73b0", "result": "\u5b9e\u8bc1\u8bc1\u5b9e\uff1a(1) RLVR\u901a\u8fc7\u653e\u5927\u73b0\u6709\u6280\u80fd\u6fc0\u52b1\u63a2\u7d22\u5148\u524d\u4e0d\u53ef\u8fbe\u7684\u89e3\u51b3\u8def\u5f84\uff1b(2) \u590d\u5408\u6027\u80fd\u4e25\u683c\u53d7\u539f\u5b50\u6b65\u9aa4\u8054\u5408\u6982\u7387\u63a7\u5236\uff08\u03c1\u2208[0.69,0.96]\uff09\uff1b(3) RLVR\u4f5c\u4e3a\u5168\u5c40\u4f18\u5316\u5668\u53ef\u80fd\u5bfc\u81f4\u7279\u5b9a\u6280\u80fd\u88ab\u727a\u7272\u4ee5\u6700\u5927\u5316\u603b\u5956\u52b1", "conclusion": "RLVR\u7684\u6d8c\u73b0\u80fd\u529b\u6e90\u4e8e\u53ef\u89e3\u95ee\u9898\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u53d1\u5c55\u89e3\u51b3\u5148\u524d\u4e0d\u53ef\u89e3\u573a\u666f\u7684\u80fd\u529b\uff0c\u652f\u6301RLVR\u8d4b\u4e88\u65b0\u80fd\u529b\u7684\u89c2\u70b9"}}
{"id": "2602.08092", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08092", "abs": "https://arxiv.org/abs/2602.08092", "authors": ["Majid Ghasemi", "Mark Crowley"], "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities", "comment": null, "summary": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86RL\u7684Dogma 4\u5047\u8bbe\uff0c\u63d0\u51fa\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u4eba\u7c7b\u53cd\u9988\u53ef\u80fd\u4e0d\u771f\u5b9e\uff0c\u5bfc\u81f4\u76ee\u6807\u89e3\u8026\u95ee\u9898\uff0c\u5e76\u63d0\u51faEpistemic Source Alignment\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7b56\u7565\u57fa\u4e8e\u4e00\u4e2a\u8106\u5f31\u7684\u524d\u63d0\uff1a\u4eba\u7c7b\u53cd\u9988\u867d\u7136\u5608\u6742\uff0c\u4f46\u672c\u8d28\u4e0a\u662f\u771f\u5b9e\u7684\u4fe1\u53f7\u3002\u8bba\u6587\u8ba4\u4e3a\u8fd9\u4e00\u5047\u8bbe\uff08Dogma 4\uff09\u5728\u9759\u6001\u73af\u5883\u4e2d\u6210\u7acb\uff0c\u4f46\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u4f1a\u5931\u6548\uff0c\u56e0\u4e3a\u8bc4\u4f30\u8005\u53ef\u80fd\u662f\u8c04\u5a9a\u7684\u3001\u61d2\u60f0\u7684\u6216\u654c\u5bf9\u7684\u3002", "method": "\u63d0\u51faEpistemic Source Alignment\uff08ESA\uff09\u65b9\u6cd5\u3002\u4e0e\u4f9d\u8d56\u7edf\u8ba1\u5171\u8bc6\u7684\u4f20\u7edf\u9c81\u68d2\u65b9\u6cd5\u4e0d\u540c\uff0cESA\u4f7f\u7528\u7a00\u758f\u7684\u5b89\u5168\u516c\u7406\u6765\u5224\u65ad\u53cd\u9988\u7684\u6765\u6e90\u800c\u975e\u4fe1\u53f7\u672c\u8eab\uff0c\u5373\"\u5224\u65ad\u5224\u65ad\u8005\"\u673a\u5236\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u5728Dogma 4\u4e0b\uff0c\u6807\u51c6RL\u667a\u80fd\u4f53\u4f1a\u906d\u53d7\u76ee\u6807\u89e3\u8026\u7684\u7ed3\u6784\u6027\u6545\u969c\u6a21\u5f0f\uff1bESA\u65b9\u6cd5\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5373\u4f7f\u5927\u591a\u6570\u8bc4\u4f30\u8005\u5b58\u5728\u504f\u89c1\u3002\u5b9e\u8bc1\u663e\u793a\u4f20\u7edf\u5171\u8bc6\u65b9\u6cd5\u5728\u591a\u6570\u5171\u8c0b\u4e0b\u5931\u8d25\uff0c\u800cESA\u6210\u529f\u6062\u590d\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u8bba\u6587\u6311\u6218\u4e86RL\u4e2d\u5bf9\u4eba\u7c7b\u53cd\u9988\u771f\u5b9e\u6027\u7684\u57fa\u672c\u5047\u8bbe\uff0c\u63ed\u793a\u4e86\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u5bf9\u9f50\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u4e0a\u4fdd\u8bc1\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08289", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08289", "abs": "https://arxiv.org/abs/2602.08289", "authors": ["Binglin Wu", "Xianneng Li"], "title": "Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network", "comment": null, "summary": "With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6bd2\u54c1\u6848\u4ef6\u5224\u51b3\u6587\u4e66\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u7b97\u6cd5Legal-KAHRE\uff0c\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u589e\u5f3a\u548c\u8d85\u56fe\u7ed3\u6784\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6cd5\u5f8b\u6587\u6863\u4fe1\u606f\u62bd\u53d6\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u4e2d\u56fd\u53f8\u6cd5\u673a\u6784\u6570\u5b57\u5316\u8fdb\u7a0b\u7684\u63a8\u8fdb\uff0c\u79ef\u7d2f\u4e86\u5927\u91cf\u7684\u7535\u5b50\u6cd5\u5f8b\u6587\u6863\u4fe1\u606f\u3002\u4e3a\u4e86\u6316\u6398\u8fd9\u4e9b\u4fe1\u606f\u7684\u6f5c\u5728\u4ef7\u503c\uff0c\u6cd5\u5f8b\u6587\u6863\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u62bd\u53d6\u6210\u4e3a\u5173\u952e\u4efb\u52a1\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u53f8\u6cd5\u9886\u57df\u7684\u72ec\u7279\u7279\u6027\u3002", "method": "1. \u57fa\u4e8e\u90bb\u5c45\u5bfc\u5411\u6253\u5305\u7b56\u7565\u548c\u53cc\u4eff\u5c04\u673a\u5236\u7684\u5019\u9009\u8de8\u5ea6\u751f\u6210\u5668\uff0c\u8bc6\u522b\u53ef\u80fd\u5305\u542b\u5b9e\u4f53\u7684\u6587\u672c\u8de8\u5ea6\uff1b2. \u6784\u5efa\u5305\u542b\u53f8\u6cd5\u9886\u57df\u77e5\u8bc6\u7684\u6cd5\u5f8b\u8bcd\u5178\uff0c\u5e76\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u5c06\u5176\u96c6\u6210\u5230\u6587\u672c\u7f16\u7801\u8868\u793a\u4e2d\uff1b3. \u5c06\u5171\u540c\u72af\u7f6a\u3001\u6570\u7f6a\u5e76\u7f5a\u7b49\u7279\u5b9a\u6848\u4f8b\u7eb3\u5165\u8d85\u56fe\u7ed3\u6784\u8bbe\u8ba1\uff1b4. \u4f7f\u7528\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u6d88\u606f\u4f20\u9012\u8fdb\u884c\u9ad8\u9636\u63a8\u7406\u3002", "result": "\u5728CAIL2022\u4fe1\u606f\u62bd\u53d6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684Legal-KAHRE\u7b97\u6cd5\u901a\u8fc7\u7ed3\u5408\u53f8\u6cd5\u9886\u57df\u77e5\u8bc6\u548c\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6bd2\u54c1\u76f8\u5173\u5224\u51b3\u6587\u4e66\u7684\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u6027\u80fd\uff0c\u4e3a\u6cd5\u5f8b\u6587\u6863\u7684\u4fe1\u606f\u6316\u6398\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08104", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08104", "abs": "https://arxiv.org/abs/2602.08104", "authors": ["Risal Shahriar Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems", "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u68af\u5ea6\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6545\u969c\u68c0\u6d4b\u4e0e\u6eaf\u6e90\uff0c\u80fd\u8bc6\u522b\u521d\u59cb\u6545\u969c\u6e90\u3001\u9a8c\u8bc1\u591a\u7c73\u8bfa\u6548\u5e94\u3001\u8ffd\u8e2a\u6545\u969c\u4f20\u64ad\u8def\u5f84\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u548c\u5f52\u56e0\u65b9\u6cd5\u4ecd\u7136\u4e0d\u8db3\u3002\u9700\u8981\u8d85\u8d8a\u9ed1\u76d2\u68c0\u6d4b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68af\u5ea6\u7ea7\u8bca\u65ad\u5de5\u5177\u3002", "method": "\u4e24\u9636\u6bb5\u68af\u5ea6\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6210\u672c\u7684\u6cf0\u52d2\u4f59\u9879\u5206\u6790\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u4f53\u7ea7\u6545\u969c\u68c0\u6d4b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6279\u8bc4\u8005\u5bfc\u6570\u7684\u51e0\u4f55\u5206\u6790\uff08\u4e00\u9636\u654f\u611f\u6027\u548c\u4e8c\u9636\u66f2\u7387\uff09\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u4f20\u67d3\u56fe\u3002", "result": "\u5728Simple Spread\uff083\u548c5\u667a\u80fd\u4f53\uff09\u548cStarCraft II\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u4f7f\u7528MADDPG\u548cHATRPO\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e8688.2-99.4%\u7684\u521d\u59cb\u6545\u969c\u6e90\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51e0\u4f55\u8bc1\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u68af\u5ea6\u7ea7\u53d6\u8bc1\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bca\u65ad\u7ea7\u8054\u6545\u969c\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u8d85\u8d8a\u4e86\u9ed1\u76d2\u68c0\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2602.07465", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07465", "abs": "https://arxiv.org/abs/2602.07465", "authors": ["Seungwoo Son", "Ingyu Seong", "Junhan Kim", "Hyemi Jang", "Yongkweon Jeon"], "title": "On the Importance of a Multi-Scale Calibration for Quantization", "comment": "ICASSP 2026", "summary": "Post-training quantization (PTQ) is a cornerstone for efficiently deploying large language models (LLMs), where a small calibration set critically affects quantization performance. However, conventional practices rely on random sequences of fixed length, overlooking the variable-length nature of LLM inputs. Input length directly influences the activation distribution and, consequently, the weight importance captured by the Hessian, which in turn affects quantization outcomes. As a result, Hessian estimates derived from fixed-length calibration may fail to represent the true importance of weights across diverse input scenarios. We propose MaCa (Matryoshka Calibration), a simple yet effective method for length-aware Hessian construction. MaCa (i) incorporates multi-scale sequence length information into Hessian estimation and (ii) regularizes each sequence as an independent sample, yielding a more stable and fruitful Hessian for accurate quantization. Experiments on state-of-the-art LLMs (e.g., Qwen3, Gemma3, LLaMA3) demonstrate that MaCa consistently improves accuracy under low bit quantization, offering a lightweight enhancement compatible with existing PTQ frameworks. To the best of our knowledge, this is the first work to systematically highlight the role of multi-scale calibration in LLM quantization.", "AI": {"tldr": "\u63d0\u51faMaCa\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u5e8f\u5217\u957f\u5ea6\u611f\u77e5\u7684Hessian\u77e9\u9635\u6784\u5efa\uff0c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6027\u80fd", "motivation": "\u4f20\u7edf\u540e\u8bad\u7ec3\u91cf\u5316\u4f7f\u7528\u56fa\u5b9a\u957f\u5ea6\u7684\u968f\u673a\u5e8f\u5217\u4f5c\u4e3a\u6821\u51c6\u96c6\uff0c\u5ffd\u7565\u4e86LLM\u8f93\u5165\u7684\u53ef\u53d8\u957f\u5ea6\u7279\u6027\u3002\u8f93\u5165\u957f\u5ea6\u76f4\u63a5\u5f71\u54cd\u6fc0\u6d3b\u5206\u5e03\u548cHessian\u77e9\u9635\u6355\u83b7\u7684\u6743\u91cd\u91cd\u8981\u6027\uff0c\u4ece\u800c\u5f71\u54cd\u91cf\u5316\u7ed3\u679c\u3002\u56fa\u5b9a\u957f\u5ea6\u6821\u51c6\u5f97\u5230\u7684Hessian\u4f30\u8ba1\u53ef\u80fd\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u4e0d\u540c\u8f93\u5165\u573a\u666f\u4e0b\u7684\u771f\u5b9e\u6743\u91cd\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51faMaCa\uff08Matryoshka Calibration\uff09\u65b9\u6cd5\uff1a1\uff09\u5c06\u591a\u5c3a\u5ea6\u5e8f\u5217\u957f\u5ea6\u4fe1\u606f\u878d\u5165Hessian\u4f30\u8ba1\uff1b2\uff09\u5c06\u6bcf\u4e2a\u5e8f\u5217\u4f5c\u4e3a\u72ec\u7acb\u6837\u672c\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u4ece\u800c\u83b7\u5f97\u66f4\u7a33\u5b9a\u3001\u66f4\u6709\u6548\u7684Hessian\u77e9\u9635\u7528\u4e8e\u7cbe\u786e\u91cf\u5316\u3002", "result": "\u5728\u5148\u8fdbLLM\uff08\u5982Qwen3\u3001Gemma3\u3001LLaMA3\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMaCa\u5728\u4f4e\u4f4d\u91cf\u5316\u4e0b\u80fd\u6301\u7eed\u63d0\u5347\u7cbe\u5ea6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u589e\u5f3a\uff0c\u4e0e\u73b0\u6709PTQ\u6846\u67b6\u517c\u5bb9\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u5730\u5f3a\u8c03\u591a\u5c3a\u5ea6\u6821\u51c6\u5728LLM\u91cf\u5316\u4e2d\u4f5c\u7528\u7684\u5de5\u4f5c\uff0cMaCa\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u901a\u8fc7\u957f\u5ea6\u611f\u77e5\u7684Hessian\u6784\u5efa\u663e\u8457\u6539\u5584\u91cf\u5316\u6027\u80fd\u3002"}}
{"id": "2602.08294", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08294", "abs": "https://arxiv.org/abs/2602.08294", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "When Does Context Help? Error Dynamics of Contextual Information in Large Language Models", "comment": null, "summary": "Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\\%$.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u5206\u6790Transformer LLMs\u4e2d\u4efb\u610f\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u8bef\u5dee\u52a8\u6001\u8868\u5f81\u4e0a\u4e0b\u6587\u4f5c\u7528\uff0c\u8bc1\u660e\u4e0a\u4e0b\u6587\u6761\u4ef6\u8bef\u5dee\u53ef\u5206\u89e3\u4e3a\u57fa\u7ebf\u8bef\u5dee\u548c\u4e0a\u4e0b\u6587\u4fee\u6b63\u5411\u91cf\uff0c\u63a8\u5bfc\u51fa\u8bef\u5dee\u51cf\u5c11\u7684\u51e0\u4f55\u6761\u4ef6\uff0c\u5e76\u6269\u5c55\u5230\u591a\u5c42\u591a\u4e0a\u4e0b\u6587\u573a\u666f\u3002", "motivation": "\u63a8\u7406\u65f6\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982\u6f14\u793a\u3001\u68c0\u7d22\u77e5\u8bc6\u3001\u4ea4\u4e92\u5386\u53f2\uff09\u80fd\u663e\u8457\u63d0\u5347LLMs\u6027\u80fd\u800c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\uff0c\u4f46\u5176\u7406\u8bba\u4f5c\u7528\u5728\u7279\u5b9a\u8bbe\u7f6e\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u4e4b\u5916\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u9700\u8981\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u4efb\u610f\u4e0a\u4e0b\u6587\u4fe1\u606f\u5728Transformer LLMs\u4e2d\u7684\u5f71\u54cd\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u51fa\u8bef\u5dee\u52a8\u6001\u5206\u6790\u4e0a\u4e0b\u6587\u5f71\u54cd\u3002\u5728\u5355\u5c42Transformer\u4e2d\u8bc1\u660e\u4e0a\u4e0b\u6587\u6761\u4ef6\u8bef\u5dee\u53ef\u52a0\u6027\u5206\u89e3\u4e3a\u57fa\u7ebf\u8bef\u5dee\u548c\u4e0a\u4e0b\u6587\u4fee\u6b63\u5411\u91cf\uff0c\u63a8\u5bfc\u8bef\u5dee\u51cf\u5c11\u7684\u51e0\u4f55\u6761\u4ef6\uff08\u5bf9\u9f50\u8d1f\u57fa\u7ebf\u8bef\u5dee\u548c\u8303\u6570\u7ea6\u675f\uff09\uff0c\u7ed9\u51fa\u4e0a\u4e0b\u6587\u4fee\u6b63\u8303\u6570\u7684\u663e\u5f0f\u4e0a\u754c\uff08\u7531\u4e0a\u4e0b\u6587-\u67e5\u8be2\u76f8\u5173\u6027\u548c\u4e92\u8865\u6027\u51b3\u5b9a\uff09\uff0c\u6269\u5c55\u5230\u591a\u4e0a\u4e0b\u6587\u548c\u591a\u5c42Transformer\u3002", "result": "\u7406\u8bba\u5206\u6790\u5f97\u51fa\u4e0a\u4e0b\u6587\u4fee\u6b63\u5fc5\u987b\u4e0e\u8d1f\u57fa\u7ebf\u8bef\u5dee\u5bf9\u9f50\u4e14\u6ee1\u8db3\u8303\u6570\u7ea6\u675f\u624d\u80fd\u51cf\u5c11\u8bef\u5dee\uff0c\u4e0a\u4e0b\u6587\u4fee\u6b63\u8303\u6570\u6709\u663e\u5f0f\u4e0a\u754c\u3002\u5b9e\u9a8c\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u8bb0\u5fc6\u6f14\u5316\u7b49\u573a\u666f\u9a8c\u8bc1\u7406\u8bba\uff0c\u5e76\u57fa\u4e8e\u7406\u8bba\u63d0\u51fa\u539f\u5219\u6027\u4e0a\u4e0b\u6587\u9009\u62e9\u7b56\u7565\uff0c\u6027\u80fd\u63d0\u53470.6%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3Transformer LLMs\u4e2d\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bef\u5dee\u51cf\u5c11\u7684\u51e0\u4f55\u6761\u4ef6\uff0c\u63a8\u5bfc\u4e86\u4e0a\u4e0b\u6587\u4fee\u6b63\u7684\u663e\u5f0f\u4e0a\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u7684\u539f\u5219\u6027\u4e0a\u4e0b\u6587\u9009\u62e9\u7b56\u7565\u80fd\u5b9e\u9645\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.08121", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08121", "abs": "https://arxiv.org/abs/2602.08121", "authors": ["Liying Wang", "Madison Lee", "Yunzhang Jiang", "Steven Chen", "Kewei Sha", "Yunhe Feng", "Frank Wong", "Lisa Hightow-Weidman", "Weichao Yuwen"], "title": "Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention", "comment": null, "summary": "Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an \"empathy trap,\" providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86Glow\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684DBT\u6280\u80fd\u6559\u7ec3\uff0c\u7528\u4e8eHIV\u548c\u7269\u8d28\u4f7f\u7528\u98ce\u9669\u4eba\u7fa4\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\u8bc4\u4f30\u5176\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u9700\u8981\u89e3\u51b3\u3002", "motivation": "HIV\u548c\u7269\u8d28\u4f7f\u7528\u662f\u76f8\u4e92\u5f71\u54cd\u7684\u6d41\u884c\u75c5\uff0c\u5177\u6709\u5171\u540c\u7684\u51b2\u52a8\u6027\u548c\u9002\u5e94\u4e0d\u826f\u5e94\u5bf9\u673a\u5236\u7b49\u5fc3\u7406\u9a71\u52a8\u56e0\u7d20\u3002DBT\u9488\u5bf9\u8fd9\u4e9b\u673a\u5236\u4f46\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u800c\u751f\u6210\u5f0fAI\u6709\u6f5c\u529b\u5927\u89c4\u6a21\u63d0\u4f9b\u4e2a\u6027\u5316DBT\u8f85\u5bfc\uff0c\u4f46\u5feb\u901f\u53d1\u5c55\u8d85\u8fc7\u4e86\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u7684\u5efa\u8bbe\u3002", "method": "\u5f00\u53d1\u4e86Glow\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684DBT\u6280\u80fd\u6559\u7ec3\uff0c\u63d0\u4f9b\u94fe\u5206\u6790\u548c\u89e3\u51b3\u65b9\u6848\u5206\u6790\u3002\u4e0e\u6d1b\u6749\u77f6\u793e\u533a\u5065\u5eb7\u7ec4\u7ec7\u5408\u4f5c\uff0c\u5bf9\u4e34\u5e8a\u5de5\u4f5c\u4eba\u5458(n=6)\u548c\u6709\u751f\u6d3b\u7ecf\u9a8c\u7684\u4e2a\u4f53(n=28)\u8fdb\u884c\u53ef\u7528\u6027\u6d4b\u8bd5\u3002\u4f7f\u7528HHH\u6846\u67b6\uff0c\u91c7\u7528\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\uff0c\u53c2\u4e0e\u8005\u8bc6\u522b\u76ee\u6807\u884c\u4e3a\u5e76\u751f\u6210\u60c5\u5883\u73b0\u5b9e\u7684\u98ce\u9669\u63a2\u6d4b\u3002\u8bc4\u4f30\u4e8637\u4e2a\u98ce\u9669\u63a2\u6d4b\u4ea4\u4e92\u7684\u5b89\u5168\u6027\u8868\u73b0\u3002", "result": "Glow\u9002\u5f53\u5904\u7406\u4e8673%\u7684\u98ce\u9669\u63a2\u6d4b\uff0c\u4f46\u4e0d\u540c\u4ee3\u7406\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff1a\u89e3\u51b3\u65b9\u6848\u5206\u6790\u4ee3\u7406\u8868\u73b0\u51fa90%\u7684\u9002\u5f53\u5904\u7406\u7387\uff0c\u800c\u94fe\u5206\u6790\u4ee3\u7406\u53ea\u670944%\u3002\u5b89\u5168\u5931\u8d25\u4e3b\u8981\u96c6\u4e2d\u5728\u9f13\u52b1\u7269\u8d28\u4f7f\u7528\u548c\u6b63\u5e38\u5316\u6709\u5bb3\u884c\u4e3a\u3002\u94fe\u5206\u6790\u4ee3\u7406\u9677\u5165\"\u5171\u60c5\u9677\u9631\"\uff0c\u63d0\u4f9b\u5f3a\u5316\u9002\u5e94\u4e0d\u826f\u4fe1\u5ff5\u7684\u9a8c\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u8bc6\u522b\u51fa27\u4e2aDBT\u6280\u80fd\u9519\u8bef\u4fe1\u606f\u5b9e\u4f8b\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5bf9\u751f\u6210\u5f0fAI\u63d0\u4f9b\u7684DBT\u8f85\u5bfc\u7528\u4e8eHIV\u548c\u7269\u8d28\u4f7f\u7528\u98ce\u9669\u964d\u4f4e\u7684\u7cfb\u7edf\u5b89\u5168\u6027\u8bc4\u4f30\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5728\u4e34\u5e8a\u8bd5\u9a8c\u524d\u9700\u8981\u7f13\u89e3\u7684\u6f0f\u6d1e\u3002HHH\u6846\u67b6\u548c\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.08305", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08305", "abs": "https://arxiv.org/abs/2602.08305", "authors": ["Binglin Wu", "Yingyi Zhang", "Xiannneg Li"], "title": "JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation", "comment": null, "summary": "Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \\textit{\\textbf{J}udicial \\textbf{U}nified \\textbf{S}ynthesis \\textbf{T}hrough \\textbf{I}ntermediate \\textbf{C}onclusion \\textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\\rightarrow$ Pre-Judge $\\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.", "AI": {"tldr": "JUSTICE\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u6cd5\u5b98\"\u641c\u7d22\u2192\u9884\u5224\u2192\u64b0\u5199\"\u7684\u8ba4\u77e5\u6d41\u7a0b\uff0c\u5f15\u5165\u9884\u5224\u9636\u6bb5\u6765\u63d0\u5347\u5224\u51b3\u4e66\u751f\u6210\u7684\u6cd5\u5f8b\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u3002", "motivation": "\u73b0\u6709\u5224\u51b3\u4e66\u751f\u6210\u65b9\u6cd5\u8fc7\u4e8e\u7b80\u5316\u6cd5\u5f8b\u63a8\u7406\u8fc7\u7a0b\uff0c\u7279\u522b\u662f\u5ffd\u7565\u4e86\u6cd5\u5b98\u5f62\u6210\u521d\u6b65\u7ed3\u8bba\u7684\"\u9884\u5224\"\u9636\u6bb5\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6709\u6548\u83b7\u53d6\u57fa\u7840\u53f8\u6cd5\u8981\u7d20\u548c\u5efa\u6a21\u9884\u5224\u8fc7\u7a0b\uff0c\u5f71\u54cd\u6700\u7ec8\u6587\u6863\u7684\u6cd5\u5f8b\u5408\u7406\u6027\u3002", "method": "\u63d0\u51faJUSTICE\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u53c2\u8003\u6027\u53f8\u6cd5\u8981\u7d20\u68c0\u7d22\u5668(RJER)\u68c0\u7d22\u6cd5\u5f8b\u6761\u6587\u548c\u5148\u4f8b\u6848\u4f8b\uff1b\u4e2d\u95f4\u7ed3\u8bba\u6a21\u62df\u5668(ICE)\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u4e2d\u95f4\u7ed3\u8bba\uff1b\u53f8\u6cd5\u7edf\u4e00\u5408\u6210\u5668(JUS)\u7efc\u5408\u6240\u6709\u8f93\u5165\u751f\u6210\u6700\u7ec8\u5224\u51b3\u3002", "result": "\u5728\u9886\u57df\u5185\u6cd5\u5f8b\u57fa\u51c6\u548c\u5206\u5e03\u5916\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJUSTICE\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6cd5\u5f8b\u51c6\u786e\u6027\u65b9\u9762\u6709\u5b9e\u8d28\u6027\u63d0\u5347\uff0c\u5305\u62ec\u5211\u671f\u9884\u6d4b\u63d0\u9ad8\u4e864.6%\u3002", "conclusion": "\u660e\u786e\u5efa\u6a21\u9884\u5224\u8fc7\u7a0b\u5bf9\u4e8e\u589e\u5f3a\u751f\u6210\u5224\u51b3\u4e66\u7684\u6cd5\u5f8b\u8fde\u8d2f\u6027\u548c\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0cJUSTICE\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u6cd5\u5b98\u7684\u8ba4\u77e5\u5de5\u4f5c\u6d41\u7a0b\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.08214", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08214", "abs": "https://arxiv.org/abs/2602.08214", "authors": ["Ziwei Wang", "Yuanhe Zhang", "Jing Chen", "Zhenhong Zhou", "Ruichao Liang", "Ruiying Du", "Ju Jia", "Cong Wu", "Yang Liu"], "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection", "comment": null, "summary": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRECUR\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u5229\u7528\u548c\u53cd\u5c04\uff0c\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u8d44\u6e90\u8017\u5c3d\u653b\u51fb\uff0c\u63ed\u793a\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u7684\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u9700\u8981\u6269\u5c55\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u663e\u8457\u589e\u52a0\u3002\u73b0\u6709\u7814\u7a76\u5173\u6ce8\u5bf9\u6297\u6027\u8f93\u5165\u89e6\u53d1\u5197\u4f59\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\uff08\u7279\u522b\u662f\u5176\u53cd\u601d\u7ec4\u4ef6\uff09\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u53cd\u601d\u5e76\u6d88\u8017\u8fc7\u591a\u8ba1\u7b97\u8d44\u6e90\uff0c\u8fd9\u4e00\u98ce\u9669\u5c1a\u672a\u5f97\u5230\u5145\u5206\u5173\u6ce8\u3002", "method": "\u63d0\u51fa\u9012\u5f52\u71b5\uff08Recursive Entropy\uff09\u6765\u91cf\u5316\u53cd\u601d\u8fc7\u7a0b\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u98ce\u9669\u3002\u57fa\u4e8e\u9012\u5f52\u71b5\uff0c\u63d0\u51faRECUR\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u5229\u7528\u548c\u53cd\u5c04\uff08Recursive Entropy guided Counterfactual Utilization and Reflection\uff09\uff0c\u6784\u9020\u53cd\u4e8b\u5b9e\u95ee\u9898\u6765\u9a8c\u8bc1LRMs\u7684\u5185\u5728\u7f3a\u9677\u548c\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u826f\u6027\u63a8\u7406\u4e0b\uff0c\u9012\u5f52\u71b5\u5448\u73b0\u660e\u663e\u4e0b\u964d\u8d8b\u52bf\u3002RECUR\u653b\u51fb\u7834\u574f\u4e86\u8fd9\u4e00\u8d8b\u52bf\uff0c\u5c06\u8f93\u51fa\u957f\u5ea6\u589e\u52a0\u9ad8\u8fbe11\u500d\uff0c\u541e\u5410\u91cf\u964d\u4f4e90%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9c81\u68d2\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u7684\u5b89\u5168\u95ee\u9898\uff0c\u7279\u522b\u662f\u53cd\u601d\u7ec4\u4ef6\u53ef\u80fd\u5bfc\u81f4\u7684\u8d44\u6e90\u8017\u5c3d\u6f0f\u6d1e\u3002"}}
{"id": "2602.07475", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2602.07475", "abs": "https://arxiv.org/abs/2602.07475", "authors": ["Zhuomin Liang", "Liang Bai", "Xian Yang"], "title": "Bipartite Graph Attention-based Clustering for Large-scale scRNA-seq Data", "comment": null, "summary": "scRNA-seq clustering is a critical task for analyzing single-cell RNA sequencing (scRNA-seq) data, as it groups cells with similar gene expression profiles. Transformers, as powerful foundational models, have been applied to scRNA-seq clustering. Their self-attention mechanism automatically assigns higher attention weights to cells within the same cluster, enhancing the distinction between clusters. Existing methods for scRNA-seq clustering, such as graph transformer-based models, treat each cell as a token in a sequence. Their computational and space complexities are $\\mathcal{O}(n^2)$ with respect to the number of cells, limiting their applicability to large-scale scRNA-seq datasets.To address this challenge, we propose a Bipartite Graph Transformer-based clustering model (BGFormer) for scRNA-seq data. We introduce a set of learnable anchor tokens as shared reference points to represent the entire dataset. A bipartite graph attention mechanism is introduced to learn the similarity between cells and anchor tokens, bringing cells of the same class closer together in the embedding space. BGFormer achieves linear computational complexity with respect to the number of cells, making it scalable to large datasets. Experimental results on multiple large-scale scRNA-seq datasets demonstrate the effectiveness and scalability of BGFormer.", "AI": {"tldr": "BGFormer\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5206\u56feTransformer\u7684\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u805a\u7c7b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u951a\u70b9\u6807\u8bb0\u5b9e\u73b0\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfTransformer\u65b9\u6cd5O(n\u00b2)\u590d\u6742\u5ea6\u9650\u5236\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5e94\u7528\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eTransformer\u7684\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u805a\u7c7b\u65b9\u6cd5\u5c06\u6bcf\u4e2a\u7ec6\u80de\u89c6\u4e3a\u5e8f\u5217\u4e2d\u7684\u6807\u8bb0\uff0c\u8ba1\u7b97\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(n\u00b2)\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faBGFormer\uff08\u4e8c\u5206\u56feTransformer\u805a\u7c7b\u6a21\u578b\uff09\uff0c\u5f15\u5165\u4e00\u7ec4\u53ef\u5b66\u4e60\u7684\u951a\u70b9\u6807\u8bb0\u4f5c\u4e3a\u5171\u4eab\u53c2\u8003\u70b9\u6765\u8868\u793a\u6574\u4e2a\u6570\u636e\u96c6\u3002\u91c7\u7528\u4e8c\u5206\u56fe\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u7ec6\u80de\u4e0e\u951a\u70b9\u6807\u8bb0\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4f7f\u540c\u4e00\u7c7b\u522b\u7684\u7ec6\u80de\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u66f4\u63a5\u8fd1\u3002", "result": "BGFormer\u5b9e\u73b0\u4e86\u76f8\u5bf9\u4e8e\u7ec6\u80de\u6570\u91cf\u7684\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u6269\u5c55\u5230\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002\u5728\u591a\u4e2a\u5927\u89c4\u6a21\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BGFormer\u901a\u8fc7\u4e8c\u5206\u56fe\u6ce8\u610f\u529b\u673a\u5236\u548c\u951a\u70b9\u6807\u8bb0\u8bbe\u8ba1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfTransformer\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u805a\u7c7b\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08321", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08321", "abs": "https://arxiv.org/abs/2602.08321", "authors": ["Zijie Chen", "Zhenghao Lin", "Xiao Liu", "Zhenzhong Lan", "Yeyun Gong", "Peng Cheng"], "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models", "comment": null, "summary": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDr. SCI\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6d41\u7a0b\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u6570\u636e\u5904\u7406\u3001\u52a8\u6001\u96be\u5ea6\u8bfe\u7a0b\u548c\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u6311\u6218\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u79d1\u5b66\u540e\u8bad\u7ec3\u7684\u6570\u636e\u6784\u5efa\u548c\u5956\u52b1\u8bbe\u8ba1\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u76d1\u7763\u4e0d\u53ef\u9760\u548c\u8bc4\u4f30\u56f0\u96be\u7684\u95ee\u9898\u3002", "method": "1) \u6784\u5efaDr. SCI\u6570\u636e\u96c6\uff1a\u5904\u7406\u5f02\u6784\u5f00\u6e90\u79d1\u5b66\u6570\u636e\uff0c\u5305\u542b100\u4e07\u95ee\u9898\uff0c\u8986\u76d68\u4e2aSTEM\u5b66\u79d1\uff0c\u6709\u660e\u786e\u7684\u53ef\u9a8c\u8bc1/\u5f00\u653e\u5f0f\u5212\u5206\u3001\u53ef\u6269\u5c55\u96be\u5ea6\u6807\u6ce8\u548c\u7ec6\u7c92\u5ea6\u8bc4\u5206\u6807\u51c6\uff1b2) Dr. SCI\u540e\u8bad\u7ec3\u6d41\u7a0b\uff1a\u5305\u542b\u63a2\u7d22\u6269\u5c55\u7684\u76d1\u7763\u5fae\u8c03\u3001\u52a8\u6001\u96be\u5ea6\u8bfe\u7a0b\u548c\u57fa\u4e8e\u79d1\u5b66\u8bc4\u5206\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u4f7f\u7528Dr. SCI\u6d41\u7a0b\u8bad\u7ec3\u7684Qwen3-4B-Base\u6a21\u578b\u5728GPQA-diamond\u4e0a\u8fbe\u523063.2\u5206\uff0c\u5728GPQA-general\u4e0a\u8fbe\u523032.4\u5206\uff0c\u663e\u8457\u4f18\u4e8eo1-mini\u548cGPT-4o\u7b49\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u5f00\u653e\u5f0f\u79d1\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u5b9e\u8d28\u6027\u63d0\u5347\u3002", "conclusion": "Dr. SCI\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6d41\u7a0b\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u6570\u636e\u5904\u7406\u548c\u521b\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u5f0f\u573a\u666f\u4e0b\u3002"}}
{"id": "2602.08222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08222", "abs": "https://arxiv.org/abs/2602.08222", "authors": ["Zehao Chen", "Gongxun Li", "Tianxiang Ai", "Yifei Li", "Zixuan Huang", "Wang Zhou", "Fuzhen Zhuang", "Xianglong Liu", "Jianxin Li", "Deqing Wang", "Yikun Ban"], "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "comment": null, "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "AI": {"tldr": "WMSS\u5229\u7528\u6a21\u578b\u81ea\u8eab\u5386\u53f2\u5f31\u68c0\u67e5\u70b9\u6765\u7a81\u7834\u540e\u8bad\u7ec3\u9971\u548c\u74f6\u9888\uff0c\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u5b66\u4e60\u5dee\u8ddd\u5e76\u8fdb\u884c\u8865\u507f\u5b66\u4e60\uff0c\u5b9e\u73b0\u96f6\u989d\u5916\u63a8\u7406\u6210\u672c\u4e0b\u7684\u6027\u80fd\u63d0\u5347", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4e2d\u5b58\u5728\u6301\u7eed\u9971\u548c\u74f6\u9888\uff1a\u6a21\u578b\u53d8\u5f97\u9ad8\u5ea6\u81ea\u4fe1\u540e\uff0c\u8fdb\u4e00\u6b65\u8bad\u7ec3\u6536\u76ca\u9012\u51cf\u3002\u73b0\u6709\u65b9\u6cd5\u7ee7\u7eed\u5f3a\u5316\u76ee\u6807\u9884\u6d4b\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u4fe1\u606f\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\u4ecd\u6f5c\u85cf\u5728\u6a21\u578b\u81ea\u8eab\u7684\u5386\u53f2\u5f31\u72b6\u6001\u4e2d", "method": "\u63d0\u51faWMSS\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u5f31\u68c0\u67e5\u70b9\u6307\u5bfc\u6301\u7eed\u4f18\u5316\u3002\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u7684\u5b66\u4e60\u5dee\u8ddd\uff0c\u5e76\u901a\u8fc7\u8865\u507f\u5b66\u4e60\u5f3a\u5316\u8fd9\u4e9b\u5dee\u8ddd\uff0c\u4f7f\u5f3a\u667a\u80fd\u4f53\u8d85\u8d8a\u4f20\u7edf\u540e\u8bad\u7ec3\u9971\u548c", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528WMSS\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u4e0d\u4ea7\u751f\u989d\u5916\u7684\u63a8\u7406\u6210\u672c", "conclusion": "WMSS\u901a\u8fc7\u5229\u7528\u6a21\u578b\u81ea\u8eab\u5386\u53f2\u5f31\u72b6\u6001\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u6210\u529f\u7a81\u7834\u4e86\u540e\u8bad\u7ec3\u9971\u548c\u74f6\u9888\uff0c\u4e3a\u96f6\u6210\u672c\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2602.07478", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07478", "abs": "https://arxiv.org/abs/2602.07478", "authors": ["Laxmi Pandey", "Ariel Meroz", "Ben Cheng", "Ankita Manekar", "Abhijit Mukherjee", "Meirav Cohen", "Adway Mitra"], "title": "AI-Driven Predictive Modelling for Groundwater Salinization in Israel", "comment": "60 pages, 9 figures in main text and 6 figures in appendix, 2 tables, 3 Appendix", "summary": "Increasing salinity and contamination of groundwater is a serious issue in many parts of the world, causing degradation of water resources. The aim of this work is to form a comprehensive understanding of groundwater salinization underlying causal factors and identify important meteorological, geological and anthropogenic drivers of salinity. We have integrated different datasets of potential covariates, to create a robust framework for machine learning based predictive models including Random Forest (RF), XGBoost, Neural network, Long Short-Term Memory (LSTM), convolution neural network (CNN) and linear regression (LR), of groundwater salinity. Additionally, Recursive Feature Elimination (RFE) followed by Global sensitivity analysis (GSA) and Explainable AI (XAI) based SHapley Additive exPlanations (SHAP) were used to estimate the importance scores and find insights into the drivers of salinization. We also did causality analysis via Double machine learning using various predictive models. From these analyses, key meteorological (Precipitation, Temperature), geological (Distance from river, Distance to saline body, TWI, Shoreline distance), and anthropogenic (Area of agriculture field, Treated Wastewater) covariates are identified to be influential drivers of groundwater salinity across Israel. XAI analysis also identified Treated Wastewater (TWW) as an essential anthropogenic driver of salinity, its significance being context-dependent but critical in vulnerable hydro-climatic environment. Our approach provides deeper insight into global salinization mechanisms at country scale, reducing AI model uncertainty and highlighting the need for tailored strategies to address salinity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6574\u5408\u591a\u79cd\u6570\u636e\u96c6\uff0c\u8fd0\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u53ef\u89e3\u91caAI\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e86\u4ee5\u8272\u5217\u5730\u4e0b\u6c34\u76d0\u5316\u7684\u5173\u952e\u6c14\u8c61\u3001\u5730\u8d28\u548c\u4eba\u4e3a\u9a71\u52a8\u56e0\u7d20\u3002", "motivation": "\u5168\u7403\u8bb8\u591a\u5730\u533a\u5730\u4e0b\u6c34\u76d0\u5316\u548c\u6c61\u67d3\u65e5\u76ca\u4e25\u91cd\uff0c\u5bfc\u81f4\u6c34\u8d44\u6e90\u9000\u5316\u3002\u9700\u8981\u5168\u9762\u7406\u89e3\u5730\u4e0b\u6c34\u76d0\u5316\u7684\u6839\u672c\u539f\u56e0\uff0c\u8bc6\u522b\u91cd\u8981\u7684\u6c14\u8c61\u3001\u5730\u8d28\u548c\u4eba\u4e3a\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u6574\u5408\u4e0d\u540c\u6f5c\u5728\u534f\u53d8\u91cf\u6570\u636e\u96c6\uff0c\u5efa\u7acb\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u6846\u67b6\uff08\u5305\u62ec\u968f\u673a\u68ee\u6797\u3001XGBoost\u3001\u795e\u7ecf\u7f51\u7edc\u3001LSTM\u3001CNN\u548c\u7ebf\u6027\u56de\u5f52\uff09\u3002\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u3001\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u548cSHAP\u53ef\u89e3\u91caAI\u65b9\u6cd5\u8bc4\u4f30\u7279\u5f81\u91cd\u8981\u6027\u3002\u901a\u8fc7\u53cc\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u56e0\u679c\u5173\u7cfb\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u5f71\u54cd\u4ee5\u8272\u5217\u5730\u4e0b\u6c34\u76d0\u5316\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\uff1a\u6c14\u8c61\u56e0\u7d20\uff08\u964d\u6c34\u3001\u6e29\u5ea6\uff09\u3001\u5730\u8d28\u56e0\u7d20\uff08\u8ddd\u6cb3\u6d41\u8ddd\u79bb\u3001\u8ddd\u76d0\u4f53\u8ddd\u79bb\u3001\u5730\u5f62\u6e7f\u5ea6\u6307\u6570\u3001\u6d77\u5cb8\u7ebf\u8ddd\u79bb\uff09\u548c\u4eba\u4e3a\u56e0\u7d20\uff08\u519c\u7530\u9762\u79ef\u3001\u5904\u7406\u5e9f\u6c34\uff09\u3002\u53ef\u89e3\u91caAI\u5206\u6790\u7279\u522b\u6307\u51fa\u5904\u7406\u5e9f\u6c34\u662f\u91cd\u8981\u7684\u4eba\u4e3a\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u56fd\u5bb6\u5c3a\u5ea6\u5168\u7403\u76d0\u5316\u673a\u5236\u63d0\u4f9b\u4e86\u6df1\u5165\u89c1\u89e3\uff0c\u51cf\u5c11\u4e86AI\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u5236\u5b9a\u9488\u5bf9\u6027\u7b56\u7565\u5e94\u5bf9\u76d0\u5316\u95ee\u9898\u3002"}}
{"id": "2602.08322", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08322", "abs": "https://arxiv.org/abs/2602.08322", "authors": ["Wei Zhu"], "title": "An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling", "comment": null, "summary": "In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u5904\u7406\u591a\u610f\u56fe\u68c0\u6d4b\u548c\u69fd\u586b\u5145\u4efb\u52a1\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u610f\u56fe\u6570\u91cf\u53ef\u53d8\u548c\u4efb\u52a1\u95f4\u5e72\u6270\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u5bf9\u8bdd\u573a\u666f\u4e2d\u7528\u6237\u901a\u5e38\u5728\u4e00\u4e2a\u8bdd\u8bed\u4e2d\u8868\u8fbe\u591a\u4e2a\u610f\u56fe\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u610f\u56feSLU\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u591a\u610f\u56fe\u573a\u666f\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u91c7\u7528\u6ce8\u610f\u529b\u673a\u5236\u89e3\u7801\u5668\u5904\u7406\u53ef\u53d8\u6570\u91cf\u7684\u610f\u56fe\u548c\u4efb\u52a1\u95f4\u5e72\u6270\uff1b\u5229\u7528BERT\u7684NSP\u5934\u90e8\u6784\u5efa\u65b0\u7684\u591a\u610f\u56feSLU\u6570\u636e\u96c6\u3002", "result": "\u5728MixATIS\u3001MixSNIPS\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u53d6\u5f97state-of-the-art\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u591a\u610f\u56feSLU\u4efb\u52a1\uff0c\u4e3a\u73b0\u5b9e\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u591a\u610f\u56fe\u7406\u89e3\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08229", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08229", "abs": "https://arxiv.org/abs/2602.08229", "authors": ["Yifan Yang", "Jinjia Li", "Kunxi Li", "Puhao Zheng", "Yuanyi Wang", "Zheyan Qu", "Yang Yu", "Jianmin Wu", "Ming Li", "Hongxia Yang"], "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation", "comment": null, "summary": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u4f5c\u4e3a\u72ec\u7acb\u9a8c\u8bc1\u8005\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u65b9\u5dee\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u4e2d\u5f0f\u8bc4\u4f30\u5b58\u5728\u4e0d\u900f\u660e\u3001\u8fc7\u62df\u5408\u548c\u786c\u4ef6\u5dee\u5f02\u5bfc\u81f4\u7684\u65b9\u5dee\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0HumanEval\u4e0a\u5355\u4e2a\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee(1.67)\u751a\u81f3\u8d85\u8fc7\u4e86\u5b98\u65b9\u6392\u884c\u699c\u524d\u5341\u540d\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd(0.91)\uff0c\u4f7f\u5f97\u5f53\u524d\u6392\u540d\u7edf\u8ba1\u4e0a\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u4f5c\u4e3a\u72ec\u7acb\u9a8c\u8bc1\u8005\uff0c\u5728\u5f02\u6784\u8ba1\u7b97\u8282\u70b9\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u786c\u4ef6\u548c\u53c2\u6570\u591a\u6837\u6027\u3002\u91c7\u7528\u7a33\u5065\u7684\u5956\u52b1\u7cfb\u7edf\u786e\u4fdd\u8bc4\u4f30\u5b8c\u6574\u6027\u5e76\u963b\u6b62\u4e0d\u8bda\u5b9e\u53c2\u4e0e\u3002", "result": "\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u5c06\u540c\u4e00\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee\u4ece1.67\u964d\u4f4e\u52300.28\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6392\u540d\u7684\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u3002\u8be5\u5e73\u53f0\u5df2\u5b8c\u5168\u5b9e\u73b0\u5e76\u5c06\u5411\u793e\u533a\u53d1\u5e03\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u901a\u8fc7\u591a\u65b9\u5171\u8bc6\u548c\u591a\u6837\u5316\u63a8\u7406\u73af\u5883\uff0c\u5c06\u8bc4\u4f30\u4ece\"\u96c6\u4e2d\u5f0f\u9ed1\u76d2\"\u8f6c\u53d8\u4e3a\"\u53bb\u4e2d\u5fc3\u5316\u80cc\u4e66\"\uff0c\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u7edf\u8ba1\u4e0d\u53ef\u9760\u95ee\u9898\u3002"}}
{"id": "2602.08332", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08332", "abs": "https://arxiv.org/abs/2602.08332", "authors": ["Ido Amos", "Avi Caciularu", "Mor Geva", "Amir Globerson", "Jonathan Herzig", "Lior Shani", "Idan Szpektor"], "title": "Latent Reasoning with Supervised Thinking States", "comment": null, "summary": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.", "AI": {"tldr": "Thinking States\uff1a\u4e00\u79cd\u5728\u8f93\u5165\u5904\u7406\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u601d\u8003\u6807\u8bb0\u6765\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u94fe\u5f0f\u601d\u7ef4\u7684\u4f18\u52bf\u3002", "motivation": "\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u867d\u7136\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u4f46\u751f\u6210\u957f\u63a8\u7406\u8fc7\u7a0b\u4f1a\u5e26\u6765\u663e\u8457\u7684\u63a8\u7406\u6210\u672c\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u3002", "method": "\u5728\u8f93\u5165\u5904\u7406\u8fc7\u7a0b\u4e2d\u6bcf\u51e0\u4e2a\u8f93\u5165\u6807\u8bb0\u5c31\u751f\u6210\u4e00\u7cfb\u5217\u601d\u8003\u6807\u8bb0\uff0c\u5c06\u8fd9\u4e9b\u601d\u8003\u8f6c\u6362\u56de\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u6dfb\u52a0\u5230\u540e\u7eed\u8f93\u5165\u6807\u8bb0\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e2\u80fd\u6355\u6349CoT\u7684\u5faa\u73af\u7279\u6027\uff0c\u53c8\u80fd\u901a\u8fc7\u6559\u5e08\u5f3a\u5236\u8fdb\u884c\u5e76\u884c\u5316\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7f29\u5c0f\u4e86\u4e0eCoT\u7684\u5dee\u8ddd\uff0c\u57282-Hop QA\u4efb\u52a1\u4e0a\u6027\u80fd\u5339\u914dCoT\u4f46\u5ef6\u8fdf\u66f4\u4f4e\u3002\u5728\u72b6\u6001\u8ddf\u8e2a\u4efb\u52a1\u4e0a\uff0c\u6bd4CoT\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u80fd\u6210\u529f\u6cdb\u5316\u5230\u6bd4\u8bad\u7ec3\u65f6\u66f4\u957f\u7684\u5e8f\u5217\u3002", "conclusion": "Thinking States\u662f\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u8f93\u5165\u5904\u7406\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u51cf\u5c11\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u8d85\u8d8a\u4f20\u7edfCoT\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08240", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08240", "abs": "https://arxiv.org/abs/2602.08240", "authors": ["Xun Su", "Huamin Wang", "Qi Zhang"], "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition", "comment": null, "summary": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.", "AI": {"tldr": "\u63d0\u51faPTS-SNN\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u8c03\u4f18\u89e3\u51b3SSL\u8868\u793a\u4e0eSNN\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bed\u97f3\u60c5\u611f\u8bc6\u522b", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u3002SNN\u867d\u7136\u80fd\u6548\u9ad8\uff0c\u4f46\u4e0e\u8fde\u7eed\u81ea\u76d1\u7763\u5b66\u4e60\u8868\u793a\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u9ad8\u52a8\u6001\u8303\u56f4\u7684\u5d4c\u5165\u4f1a\u964d\u4f4e\u57fa\u4e8e\u9608\u503c\u795e\u7ecf\u5143\u7684\u4fe1\u606f\u7f16\u7801\u80fd\u529b\u3002", "method": "\u63d0\u51faPrompt-Tuned Spiking Neural Networks (PTS-SNN)\uff1a1) \u4f7f\u7528\u65f6\u79fb\u8109\u51b2\u7f16\u7801\u5668\u901a\u8fc7\u65e0\u53c2\u6570\u901a\u9053\u79fb\u4f4d\u6355\u83b7\u5c40\u90e8\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b2) \u8bbe\u8ba1\u4e0a\u4e0b\u6587\u611f\u77e5\u819c\u7535\u4f4d\u6821\u51c6\u7b56\u7565\uff0c\u5229\u7528\u8109\u51b2\u7a00\u758f\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\u805a\u5408\u5168\u5c40\u8bed\u4e49\u4e0a\u4e0b\u6587\u5230\u53ef\u5b66\u4e60\u7684\u8f6f\u63d0\u793a\u4e2d\uff0c\u52a8\u6001\u8c03\u8282PLIF\u795e\u7ecf\u5143\u7684\u504f\u7f6e\u7535\u538b\u3002", "result": "\u5728\u4e94\u4e2a\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPTS-SNN\u5728IEMOCAP\u4e0a\u8fbe\u523073.34%\u7684\u51c6\u786e\u7387\uff0c\u4e0e\u7ade\u4e89\u6027ANN\u76f8\u5f53\uff0c\u540c\u65f6\u4ec5\u97001.19M\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u6bcf\u4e2a\u6837\u672c0.35 mJ\u7684\u63a8\u7406\u80fd\u91cf\u3002", "conclusion": "PTS-SNN\u6210\u529f\u89e3\u51b3\u4e86SSL\u8868\u793a\u4e0eSNN\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53c2\u6570\u9ad8\u6548\u4e14\u80fd\u91cf\u9ad8\u6548\u7684\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.08336", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08336", "abs": "https://arxiv.org/abs/2602.08336", "authors": ["Cheng Yang", "Chufan Shi", "Bo Shui", "Yaokang Wu", "Muzi Tao", "Huijuan Wang", "Ivan Yee Lee", "Yong Liu", "Xuezhe Ma", "Taylor Berg-Kirkpatrick"], "title": "UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models", "comment": "Project page: https://ureason.github.io", "summary": "To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.", "AI": {"tldr": "UReason\u662f\u4e00\u4e2a\u8bca\u65ad\u6027\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u63a8\u7406\u9a71\u52a8\u56fe\u50cf\u751f\u6210\u4e2d\u63a8\u7406\u80fd\u5426\u5728\u50cf\u7d20\u5c42\u9762\u5fe0\u5b9e\u6267\u884c\uff0c\u53d1\u73b0\u63a8\u7406\u6096\u8bba\uff1a\u63a8\u7406\u75d5\u8ff9\u901a\u5e38\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u4fdd\u7559\u4e2d\u95f4\u601d\u60f3\u4f5c\u4e3a\u6761\u4ef6\u4f1a\u963b\u788d\u89c6\u89c9\u5408\u6210\u3002", "motivation": "\u6700\u8fd1\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u91c7\u7528\u601d\u7ef4\u94fe\u63a8\u7406\u6765\u6307\u5bfc\u56fe\u50cf\u751f\u6210\uff0c\u4f46\u63a8\u7406\u5bf9\u89c6\u89c9\u5408\u6210\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\u3002\u9700\u8981\u8bc4\u4f30\u63a8\u7406\u80fd\u5426\u5728\u50cf\u7d20\u5c42\u9762\u88ab\u5fe0\u5b9e\u6267\u884c\u3002", "method": "\u6784\u5efaUReason\u57fa\u51c6\uff0c\u5305\u542b2,000\u4e2a\u5b9e\u4f8b\uff0c\u6db5\u76d6\u4ee3\u7801\u3001\u7b97\u672f\u3001\u7a7a\u95f4\u3001\u5c5e\u6027\u548c\u6587\u672c\u63a8\u7406\u4e94\u4e2a\u4efb\u52a1\u65cf\u3002\u5f15\u5165\u8bc4\u4f30\u6846\u67b6\u6bd4\u8f83\u76f4\u63a5\u751f\u6210\u3001\u63a8\u7406\u5f15\u5bfc\u751f\u6210\u548c\u53bb\u4e0a\u4e0b\u6587\u751f\u6210\uff08\u4ec5\u57fa\u4e8e\u7cbe\u70bc\u63d0\u793a\uff09\u3002", "result": "\u5728\u516b\u4e2a\u5f00\u6e90\u7edf\u4e00\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u4e00\u81f4\u7684\u63a8\u7406\u6096\u8bba\uff1a\u63a8\u7406\u75d5\u8ff9\u901a\u5e38\u6bd4\u76f4\u63a5\u751f\u6210\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u4fdd\u7559\u4e2d\u95f4\u601d\u60f3\u4f5c\u4e3a\u6761\u4ef6\u4e0a\u4e0b\u6587\u4f1a\u963b\u788d\u89c6\u89c9\u5408\u6210\uff0c\u800c\u4ec5\u57fa\u4e8e\u7cbe\u70bc\u63d0\u793a\u7684\u6761\u4ef6\u80fd\u5e26\u6765\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u74f6\u9888\u5728\u4e8e\u4e0a\u4e0b\u6587\u5e72\u6270\u800c\u975e\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002UReason\u4e3a\u7814\u7a76\u7edf\u4e00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6fc0\u52b1\u672a\u6765\u65b9\u6cd5\u5728\u6709\u6548\u6574\u5408\u63a8\u7406\u8fdb\u884c\u89c6\u89c9\u751f\u6210\u7684\u540c\u65f6\u51cf\u8f7b\u5e72\u6270\u3002"}}
{"id": "2602.08241", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08241", "abs": "https://arxiv.org/abs/2602.08241", "authors": ["Siqu Ou", "Tianrui Wan", "Zhiyuan Zhao", "Junyu Gao", "Xuelong Li"], "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs", "comment": null, "summary": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.", "AI": {"tldr": "SAYO\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\u6765\u6539\u5584\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u7a33\u5b9a\u6027\uff0c\u63d0\u5347\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u5f31\u7684\u89c6\u89c9\u805a\u7126\u80fd\u529b\uff1a\u65e9\u671f\u89c6\u89c9\u5bf9\u9f50\u9519\u8bef\u5f88\u5c11\u5728\u540e\u7eed\u63a8\u7406\u4e2d\u88ab\u7ea0\u6b63\uff0c\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\u548c\u63a8\u7406\u5931\u8d25\u3002\u8fd9\u79cd\u9650\u5236\u6e90\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5bf9\u89c6\u89c9\u6ce8\u610f\u529b\u7684\u4fe1\u7528\u5206\u914d\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSAYO\u6a21\u578b\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5f15\u5165\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\u3002\u8be5\u5956\u52b1\u660e\u786e\u5c06\u4f18\u5316\u4fe1\u53f7\u4e0e\u57fa\u4e8e\u89c6\u89c9\u7684\u63a8\u7406\u6b65\u9aa4\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u53ef\u9760\u7684\u6ce8\u610f\u529b\u884c\u4e3a\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSAYO\u5728\u591a\u6837\u5316\u7684\u63a8\u7406\u548c\u611f\u77e5\u4efb\u52a1\u4e0a\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u7684\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\uff0cSAYO\u80fd\u591f\u5b66\u4e60\u66f4\u7a33\u5b9a\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u6709\u6548\u6539\u5584\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.07494", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07494", "abs": "https://arxiv.org/abs/2602.07494", "authors": ["Shenxi Wu", "Haosong Zhang", "Xingjian Ma", "Shirui Bian", "Yichi Zhang", "Xi Chen", "Wei Lin"], "title": "Hyperparameter Transfer Laws for Non-Recurrent Multi-Path Neural Networks", "comment": null, "summary": "Deeper modern architectures are costly to train, making hyperparameter transfer preferable to expensive repeated tuning. Maximal Update Parametrization ($\u03bc$P) helps explain why many hyperparameters transfer across width. Yet depth scaling is less understood for modern architectures, whose computation graphs contain multiple parallel paths and residual aggregation. To unify various non-recurrent multi-path neural networks such as CNNs, ResNets, and Transformers, we introduce a graph-based notion of effective depth. Under stabilizing initializations and a maximal-update criterion, we show that the optimal learning rate decays with effective depth following a universal -3/2 power law. Here, the maximal-update criterion maximizes the typical one-step representation change at initialization without causing instability, and effective depth is the minimal path length from input to output, counting layers and residual additions. Experiments across diverse architectures confirm the predicted slope and enable reliable zero-shot transfer of learning rates across depths and widths, turning depth scaling into a predictable hyperparameter-transfer problem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6709\u6548\u6df1\u5ea6\u6982\u5ff5\uff0c\u7528\u4e8e\u7edf\u4e00\u5206\u6790\u591a\u8def\u5f84\u795e\u7ecf\u7f51\u7edc\uff08\u5982CNN\u3001ResNet\u3001Transformer\uff09\u7684\u6df1\u5ea6\u7f29\u653e\u95ee\u9898\uff0c\u5e76\u53d1\u73b0\u6700\u4f18\u5b66\u4e60\u7387\u968f\u6709\u6548\u6df1\u5ea6\u9075\u5faa-3/2\u5e42\u5f8b\u8870\u51cf\u7684\u666e\u904d\u89c4\u5f8b\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u67b6\u6784\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u8de8\u5bbd\u5ea6\u548c\u6df1\u5ea6\u7684\u8d85\u53c2\u6570\u8fc1\u79fb\u3002\u867d\u7136\u03bcP\u65b9\u6cd5\u89e3\u91ca\u4e86\u5bbd\u5ea6\u7f29\u653e\u4e0b\u7684\u8d85\u53c2\u6570\u8fc1\u79fb\uff0c\u4f46\u6df1\u5ea6\u7f29\u653e\u5bf9\u4e8e\u5305\u542b\u5e76\u884c\u8def\u5f84\u548c\u6b8b\u5dee\u805a\u5408\u7684\u73b0\u4ee3\u67b6\u6784\u4ecd\u7f3a\u4e4f\u7406\u89e3\uff0c\u9700\u8981\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u6709\u6548\u6df1\u5ea6\u6982\u5ff5\uff0c\u7edf\u4e00\u5904\u7406\u5404\u79cd\u975e\u5faa\u73af\u591a\u8def\u5f84\u795e\u7ecf\u7f51\u7edc\uff1b\u5728\u7a33\u5b9a\u521d\u59cb\u5316\u548c\u6700\u5927\u66f4\u65b0\u51c6\u5219\u4e0b\uff0c\u63a8\u5bfc\u6700\u4f18\u5b66\u4e60\u7387\u4e0e\u6709\u6548\u6df1\u5ea6\u7684\u6570\u5b66\u5173\u7cfb\uff1b\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u6700\u4f18\u5b66\u4e60\u7387\u968f\u6709\u6548\u6df1\u5ea6\u9075\u5faa-3/2\u5e42\u5f8b\u8870\u51cf\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u89c4\u5f8b\u5728\u4e0d\u540c\u67b6\u6784\u4e2d\u7684\u666e\u9002\u6027\uff0c\u5b9e\u73b0\u4e86\u8de8\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u96f6\u6837\u672c\u5b66\u4e60\u7387\u8fc1\u79fb\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u6df1\u5ea6\u7f29\u653e\u8f6c\u5316\u4e3a\u53ef\u9884\u6d4b\u7684\u8d85\u53c2\u6570\u8fc1\u79fb\u95ee\u9898\uff0c\u4e3a\u73b0\u4ee3\u591a\u8def\u5f84\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u6269\u5c55\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.08367", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08367", "abs": "https://arxiv.org/abs/2602.08367", "authors": ["Zexuan Wang", "Chenghao Yang", "Yingqi Que", "Zhenzhu Yang", "Huaqing Yuan", "Yiwen Wang", "Zhengxuan Jiang", "Shengjie Fang", "Zhenhe Wu", "Zhaohui Wang", "Zhixin Yao", "Jiashuo Liu", "Jincheng Ren", "Yuzhen Li", "Yang Yang", "Jiaheng Liu", "Jian Yang", "Zaiyuan Wang", "Ge Zhang", "Zhoufutu Wen", "Wenhao Huang"], "title": "WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints", "comment": null, "summary": "Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \\textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \\textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\\% feasibility in text-only settings, which plummets to 19.33\\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.", "AI": {"tldr": "WorldTravel\u662f\u4e00\u4e2a\u5305\u542b150\u4e2a\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8981\u6c42\u5904\u740615+\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u65f6\u7a7a\u7ea6\u675f\u3002WorldTravel-Webscape\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u73af\u5883\uff0c\u5305\u542b2000+\u4e2a\u6e32\u67d3\u7f51\u9875\uff0c\u9700\u8981\u4ece\u89c6\u89c9\u5e03\u5c40\u4e2d\u63d0\u53d6\u7ea6\u675f\u53c2\u6570\u3002\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0cGPT-5.2\u5728\u6587\u672c\u73af\u5883\u4e2d\u4ec532.67%\u53ef\u884c\u6027\uff0c\u591a\u6a21\u6001\u73af\u5883\u4e2d\u964d\u81f319.33%\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u677e\u6563\u8026\u5408\u7684\u7ea6\u675f\uff0c\u53ef\u901a\u8fc7\u5c40\u90e8\u8d2a\u5a6a\u51b3\u7b56\u89e3\u51b3\uff0c\u4e14\u4f9d\u8d56\u7406\u60f3\u5316\u6570\u636e\uff0c\u672a\u80fd\u6355\u6349\u4ece\u52a8\u6001\u7f51\u7edc\u73af\u5883\u4e2d\u63d0\u53d6\u53c2\u6570\u7684\u590d\u6742\u6027\u3002\u9700\u8981\u66f4\u771f\u5b9e\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u81ea\u4e3b\u89c4\u5212\u7cfb\u7edf\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "method": "1) \u521b\u5efaWorldTravel\u57fa\u51c6\uff1a\u5305\u542b150\u4e2a\u771f\u5b9e\u4e16\u754c\u65c5\u884c\u573a\u666f\uff0c\u8986\u76d65\u4e2a\u57ce\u5e02\uff0c\u5e73\u5747\u6bcf\u4e2a\u573a\u666f\u670915+\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u65f6\u7a7a\u548c\u903b\u8f91\u7ea6\u675f\uff1b2) \u5f00\u53d1WorldTravel-Webscape\u591a\u6a21\u6001\u73af\u5883\uff1a\u5305\u542b2000+\u4e2a\u6e32\u67d3\u7f51\u9875\uff0c\u4ee3\u7406\u9700\u8981\u4ece\u89c6\u89c9\u5e03\u5c40\u4e2d\u611f\u77e5\u7ea6\u675f\u53c2\u6570\uff1b3) \u8bc4\u4f3010\u4e2a\u524d\u6cbf\u6a21\u578b\u5728\u6587\u672c\u548c\u591a\u6a21\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff1aGPT-5.2\u5728\u6587\u672c\u73af\u5883\u4e2d\u4ec5\u8fbe\u523032.67%\u53ef\u884c\u6027\uff0c\u5728\u591a\u6a21\u6001\u73af\u5883\u4e2d\u964d\u81f319.33%\u3002\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u5173\u952e\u7684\u611f\u77e5-\u884c\u52a8\u9e3f\u6c9f\uff0c\u4ee5\u53ca\u7ea610\u4e2a\u7ea6\u675f\u7684\u89c4\u5212\u89c6\u91ce\u9608\u503c\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u6a21\u578b\u63a8\u7406\u4f1a\u6301\u7eed\u5931\u8d25\u3002\u611f\u77e5\u548c\u63a8\u7406\u4ecd\u7136\u662f\u72ec\u7acb\u7684\u74f6\u9888\u3002", "conclusion": "\u9700\u8981\u4e0b\u4e00\u4ee3\u4ee3\u7406\u7cfb\u7edf\uff0c\u5c06\u9ad8\u4fdd\u771f\u89c6\u89c9\u611f\u77e5\u4e0e\u957f\u89c6\u91ce\u63a8\u7406\u7edf\u4e00\u8d77\u6765\uff0c\u4ee5\u5904\u7406\u8106\u5f31\u7684\u73b0\u5b9e\u4e16\u754c\u7269\u6d41\u89c4\u5212\u95ee\u9898\u3002\u5f53\u524d\u6a21\u578b\u5728\u590d\u6742\u7ea6\u675f\u89c4\u5212\u548c\u591a\u6a21\u6001\u611f\u77e5\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2602.08253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08253", "abs": "https://arxiv.org/abs/2602.08253", "authors": ["Baoyun Zhao", "He Wang", "Liang Zeng"], "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design", "comment": null, "summary": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.", "AI": {"tldr": "G-LNS\uff1a\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bbe\u8ba1\u5927\u90bb\u57df\u641c\u7d22\u7b97\u5b50\uff0c\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u7834\u574f\u4e0e\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u6784\u9020\u6027\u4f18\u5148\u7ea7\u89c4\u5219\u6216\u53c2\u6570\u5316\u5c40\u90e8\u641c\u7d22\u6307\u5bfc\uff0c\u9650\u5236\u4e86\u641c\u7d22\u7a7a\u95f4\u5230\u56fa\u5b9a\u542f\u53d1\u5f0f\u5f62\u5f0f\uff0c\u96be\u4ee5\u5728\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u9003\u79bb\u6df1\u5ea6\u5c40\u90e8\u6700\u4f18\u89e3", "method": "\u63d0\u51faG-LNS\u751f\u6210\u5f0f\u8fdb\u5316\u6846\u67b6\uff0c\u5229\u7528LLM\u534f\u540c\u8fdb\u5316\u7d27\u5bc6\u8026\u5408\u7684\u7834\u574f\u4e0e\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u901a\u8fc7\u5408\u4f5c\u8bc4\u4f30\u673a\u5236\u6355\u6349\u7b97\u5b50\u95f4\u7684\u4ea4\u4e92\uff0c\u53d1\u73b0\u4e92\u8865\u7684\u7b97\u5b50\u903b\u8f91\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u7ed3\u6784\u7834\u574f\u4e0e\u91cd\u5efa", "result": "\u5728TSP\u548cCVRP\u7b49\u6311\u6218\u6027\u7ec4\u5408\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cG-LNS\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u548c\u7ecf\u5178\u6c42\u89e3\u5668\uff0c\u53d1\u73b0\u7684\u542f\u53d1\u5f0f\u4e0d\u4ec5\u4ee5\u66f4\u5c11\u8ba1\u7b97\u8d44\u6e90\u83b7\u5f97\u63a5\u8fd1\u6700\u4f18\u89e3\uff0c\u8fd8\u5728\u672a\u89c1\u5b9e\u4f8b\u5206\u5e03\u4e0a\u8868\u73b0\u51fa\u9c81\u68d2\u6cdb\u5316\u80fd\u529b", "conclusion": "G-LNS\u5c06LLM\u5728\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6269\u5c55\u5230LNS\u7b97\u5b50\u81ea\u52a8\u8bbe\u8ba1\uff0c\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u7834\u574f-\u4fee\u590d\u7b97\u5b50\u5bf9\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u7ed3\u6784\u63a2\u7d22\uff0c\u4e3a\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.07496", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07496", "abs": "https://arxiv.org/abs/2602.07496", "authors": ["Antonio Mone", "Frans A. Oliehoek", "Luciano Cavalcante Siebert"], "title": "CoMI-IRL: Contrastive Multi-Intention Inverse Reinforcement Learning", "comment": "14 pages, 6 figures", "summary": "Inverse Reinforcement Learning (IRL) seeks to infer reward functions from expert demonstrations. When demonstrations originate from multiple experts with different intentions, the problem is known as Multi-Intention IRL (MI-IRL). Recent deep generative MI-IRL approaches couple behavior clustering and reward learning, but typically require prior knowledge of the number of true behavioral modes $K^*$. This reliance on expert knowledge limits their adaptability to new behaviors, and only enables analysis related to the learned rewards, and not across the behavior modes used to train them. We propose Contrastive Multi-Intention IRL (CoMI-IRL), a transformer-based unsupervised framework that decouples behavior representation and clustering from downstream reward learning. Our experiments show that CoMI-IRL outperforms existing approaches without a priori knowledge of $K^*$ or labels, while allowing for visual interpretation of behavior relationships and adaptation to unseen behavior without full retraining.", "AI": {"tldr": "CoMI-IRL\uff1a\u57fa\u4e8eTransformer\u7684\u65e0\u76d1\u7763\u591a\u610f\u56fe\u9006\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u884c\u4e3a\u8868\u793a\u4e0e\u805a\u7c7b\u4ece\u5956\u52b1\u5b66\u4e60\u4e2d\u89e3\u8026\uff0c\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u5373\u53ef\u9002\u5e94\u65b0\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u610f\u56fe\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u77e5\u9053\u771f\u5b9e\u884c\u4e3a\u6a21\u5f0f\u6570\u91cfK*\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5bf9\u65b0\u884c\u4e3a\u7684\u9002\u5e94\u6027\uff0c\u5e76\u4e14\u53ea\u80fd\u5206\u6790\u5b66\u4e60\u5230\u7684\u5956\u52b1\uff0c\u800c\u4e0d\u80fd\u8de8\u8bad\u7ec3\u4f7f\u7528\u7684\u884c\u4e3a\u6a21\u5f0f\u8fdb\u884c\u5206\u6790\u3002", "method": "\u63d0\u51fa\u5bf9\u6bd4\u591a\u610f\u56fe\u9006\u5f3a\u5316\u5b66\u4e60\uff08CoMI-IRL\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u65e0\u76d1\u7763\u6846\u67b6\uff0c\u5c06\u884c\u4e3a\u8868\u793a\u548c\u805a\u7c7b\u4ece\u4e0b\u6e38\u5956\u52b1\u5b66\u4e60\u4e2d\u89e3\u8026\u51fa\u6765\u3002", "result": "CoMI-IRL\u5728\u4e0d\u9700\u8981K*\u5148\u9a8c\u77e5\u8bc6\u6216\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5141\u8bb8\u5bf9\u884c\u4e3a\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316\u89e3\u91ca\uff0c\u5e76\u4e14\u65e0\u9700\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u884c\u4e3a\u3002", "conclusion": "CoMI-IRL\u901a\u8fc7\u89e3\u8026\u884c\u4e3a\u8868\u793a\u548c\u5956\u52b1\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709MI-IRL\u65b9\u6cd5\u5bf9\u5148\u9a8c\u77e5\u8bc6\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.08371", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08371", "abs": "https://arxiv.org/abs/2602.08371", "authors": ["Hung Quang Tran", "Nam Tien Pham", "Son T. Luu", "Kiet Van Nguyen"], "title": "ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts", "comment": "Accepted as main paper at EACL 2026", "summary": "Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ViGoEmotions\u8d8a\u5357\u8bed\u60c5\u611f\u8bed\u6599\u5e93\uff0c\u5305\u542b20,664\u6761\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\uff0c\u5206\u4e3a27\u79cd\u7ec6\u7c92\u5ea6\u60c5\u611f\u7c7b\u522b\uff0c\u5e76\u8bc4\u4f30\u4e868\u79cd\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u5728\u4e09\u79cd\u9884\u5904\u7406\u7b56\u7565\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u60c5\u611f\u5206\u7c7b\u5728\u60c5\u611f\u9884\u6d4b\u548c\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728NLP\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u9488\u5bf9\u8d8a\u5357\u8bed\u7684\u60c5\u611f\u5206\u7c7b\u7814\u7a76\u4ecd\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5305\u542b\u4e30\u5bcc\u793e\u4ea4\u5a92\u4f53\u7279\u5f81\uff08\u5982\u8868\u60c5\u7b26\u53f7\uff09\u7684\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bed\u6599\u5e93\u3002", "method": "\u6784\u5efa\u4e86ViGoEmotions\u8d8a\u5357\u8bed\u60c5\u611f\u8bed\u6599\u5e93\uff0820,664\u6761\u8bc4\u8bba\uff0c27\u79cd\u60c5\u611f\u7c7b\u522b\uff09\u3002\u8bc4\u4f30\u4e868\u79cd\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u5728\u4e09\u79cd\u9884\u5904\u7406\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff1a1\uff09\u4fdd\u7559\u539f\u59cb\u8868\u60c5\u7b26\u53f7\u5e76\u8fdb\u884c\u89c4\u5219\u5316\u5f52\u4e00\u5316\uff1b2\uff09\u5c06\u8868\u60c5\u7b26\u53f7\u8f6c\u6362\u4e3a\u6587\u672c\u63cf\u8ff0\uff1b3\uff09\u5e94\u7528ViSoLex\u6a21\u578b\u8fdb\u884c\u8bcd\u6c47\u5f52\u4e00\u5316\u3002", "result": "\u5c06\u8868\u60c5\u7b26\u53f7\u8f6c\u6362\u4e3a\u6587\u672c\u901a\u5e38\u80fd\u63d0\u5347BERT\u7c7b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u800c\u4fdd\u7559\u8868\u60c5\u7b26\u53f7\u5bf9ViSoBERT\u548cCafeBERT\u6548\u679c\u6700\u597d\u3002\u79fb\u9664\u8868\u60c5\u7b26\u53f7\u901a\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002ViSoBERT\u53d6\u5f97\u4e86\u6700\u9ad8\u6027\u80fd\uff08Macro F1: 61.50%\uff0cWeighted F1: 63.26%\uff09\uff0cCafeBERT\u548cPhoBERT\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684ViGoEmotions\u8bed\u6599\u5e93\u80fd\u6709\u6548\u652f\u6301\u591a\u79cd\u67b6\u6784\uff0c\u4f46\u9884\u5904\u7406\u7b56\u7565\u548c\u6807\u6ce8\u8d28\u91cf\u4ecd\u662f\u5f71\u54cd\u4e0b\u6e38\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002\u8868\u60c5\u7b26\u53f7\u5904\u7406\u65b9\u5f0f\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u6a21\u578b\u9009\u62e9\u9002\u5f53\u7684\u9884\u5904\u7406\u65b9\u6cd5\u3002"}}
{"id": "2602.08254", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08254", "abs": "https://arxiv.org/abs/2602.08254", "authors": ["Arman Aghaee", "Sepehr Asgarian", "Jouhyun Jeon"], "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities", "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence", "summary": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.", "AI": {"tldr": "SynthAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u80a5\u80d6\u75c7\u5408\u5e76\u7cbe\u795e\u969c\u788d\u60a3\u8005\u7684\u75be\u75c5\u8fdb\u5c55\u3001\u6cbb\u7597\u53cd\u5e94\u548c\u751f\u6d3b\u7ba1\u7406\uff0c\u901a\u8fc7\u6574\u5408\u4e34\u5e8a\u6570\u636e\u548c\u4e2a\u6027\u5316\u7279\u5f81\u6784\u5efa\u9ad8\u4fdd\u771f\u865a\u62df\u60a3\u8005\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5b58\u5728\u788e\u7247\u5316\u3001\u504f\u89c1\u548c\u9690\u79c1\u9650\u5236\u7b49\u95ee\u9898\uff0c\u6a21\u62df\u9ad8\u4fdd\u771f\u60a3\u8005\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u529b\u9014\u5f84\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u80a5\u80d6\u75c7\u5408\u5e76\u7cbe\u795e\u969c\u788d\u7b49\u590d\u6742\u75be\u75c5\u7684\u7814\u7a76\u3002", "method": "\u63d0\u51faSynthAgent\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u6574\u5408\u7406\u8d54\u6570\u636e\u3001\u4eba\u53e3\u8c03\u67e5\u548c\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u6587\u732e\u7b49\u4e34\u5e8a\u533b\u5b66\u8bc1\u636e\uff0c\u6784\u5efa\u5177\u6709\u4eba\u683c\u7279\u8d28\uff08\u5f71\u54cd\u4f9d\u4ece\u6027\u3001\u60c5\u7eea\u8c03\u8282\u548c\u751f\u6d3b\u65b9\u5f0f\uff09\u7684\u4e2a\u6027\u5316\u865a\u62df\u60a3\u8005\uff0c\u901a\u8fc7\u81ea\u4e3b\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u53cd\u5e94\u3002", "result": "\u8bc4\u4f30100\u591a\u4e2a\u751f\u6210\u7684\u865a\u62df\u60a3\u8005\u663e\u793a\uff0cGPT-5\u548cClaude 4.5 Sonnet\u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\u5728\u63d0\u51fa\u7684MAS\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad8\u4fdd\u771f\u5ea6\uff0c\u4f18\u4e8eGemini 2.5 Pro\u548cDeepSeek-R1\u3002", "conclusion": "SynthAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u7d22\u533b\u5b66\u548c\u5fc3\u7406\u9886\u57df\u7684\u60a3\u8005\u65c5\u7a0b\u3001\u884c\u4e3a\u52a8\u6001\u548c\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2602.07519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07519", "abs": "https://arxiv.org/abs/2602.07519", "authors": ["Martin Fixman", "Alessandro Abati", "Juli\u00e1n Jim\u00e9nez Nimmo", "Sean Lim", "Esther Mondrag\u00f3n"], "title": "PALMS: Pavlovian Associative Learning Models Simulator", "comment": null, "summary": "Simulations are an indispensable step in the cycle of theory development and refinement, helping researchers formulate precise definitions, generate models, and make accurate predictions. This paper introduces the Pavlovian Associative Learning Models Simulator (PALMS), a Python environment to simulate Pavlovian conditioning experiments. In addition to the canonical Rescorla-Wagner model, PALMS incorporates several attentional learning approaches, including Pearce-Kaye-Hall, Mackintosh Extended, Le Pelley's Hybrid, and a novel extension of the Rescorla-Wagner model with a unified variable learning rate that integrates Mackintosh's and Pearce and Hall's opposing conceptualisations. The simulator's graphical interface allows for the input of entire experimental designs in an alphanumeric format, akin to that used by experimental neuroscientists. Moreover, it uniquely enables the simulation of experiments involving hundreds of stimuli, as well as the computation of configural cues and configural-cue compounds across all models, thereby considerably expanding their predictive capabilities. PALMS operates efficiently, providing instant visualisation of results, supporting rapid, precise comparisons of various models' predictions within a single architecture and environment. Furthermore, graphic displays can be easily saved, and simulated data can be exported to spreadsheets. To illustrate the simulator's capabilities and functionalities, we provide a detailed description of the software and examples of use, reproducing published experiments in the associative learning literature. PALMS is licensed under the open-source GNU Lesser General Public License 3.0. The simulator source code and the latest multiplatform release build are accessible as a GitHub repository at https://github.com/cal-r/PALMS-Simulator", "AI": {"tldr": "PALMS\u662f\u4e00\u4e2aPython\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u6a21\u62df\u5df4\u752b\u6d1b\u592b\u6761\u4ef6\u53cd\u5c04\u5b9e\u9a8c\uff0c\u6574\u5408\u4e86\u591a\u79cd\u6ce8\u610f\u529b\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u4f9b\u56fe\u5f62\u754c\u9762\u548c\u9ad8\u6548\u8ba1\u7b97\u80fd\u529b\u3002", "motivation": "\u6a21\u62df\u662f\u7406\u8bba\u53d1\u5c55\u548c\u5b8c\u5584\u7684\u5173\u952e\u73af\u8282\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u53ef\u80fd\u65e0\u6cd5\u5168\u9762\u6a21\u62df\u590d\u6742\u7684\u5df4\u752b\u6d1b\u592b\u6761\u4ef6\u53cd\u5c04\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u6d89\u53ca\u5927\u91cf\u523a\u6fc0\u548c\u914d\u7f6e\u7ebf\u7d22\u7684\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u4e86PALMS\u6a21\u62df\u5668\uff0c\u5305\u542b\u7ecf\u5178Rescorla-Wagner\u6a21\u578b\u548c\u591a\u79cd\u6ce8\u610f\u529b\u5b66\u4e60\u6a21\u578b\uff08Pearce-Kaye-Hall\u3001Mackintosh Extended\u3001Le Pelley's Hybrid\u7b49\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u53d8\u91cf\u5b66\u4e60\u7387\u7684\u65b0\u6269\u5c55\u6a21\u578b\u3002\u63d0\u4f9b\u56fe\u5f62\u754c\u9762\u652f\u6301\u5b9e\u9a8c\u8bbe\u8ba1\u8f93\u5165\uff0c\u80fd\u591f\u6a21\u62df\u6570\u767e\u4e2a\u523a\u6fc0\u7684\u5b9e\u9a8c\u3002", "result": "PALMS\u80fd\u591f\u9ad8\u6548\u8fd0\u884c\uff0c\u5373\u65f6\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u652f\u6301\u5728\u5355\u4e00\u67b6\u6784\u4e2d\u5feb\u901f\u7cbe\u786e\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u9884\u6d4b\u3002\u53ef\u4ee5\u4fdd\u5b58\u56fe\u5f62\u663e\u793a\u5e76\u5c06\u6a21\u62df\u6570\u636e\u5bfc\u51fa\u5230\u7535\u5b50\u8868\u683c\u3002", "conclusion": "PALMS\u4f5c\u4e3a\u4e00\u4e2a\u5f00\u6e90\u6a21\u62df\u5668\uff0c\u663e\u8457\u6269\u5c55\u4e86\u5df4\u752b\u6d1b\u592b\u6761\u4ef6\u53cd\u5c04\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\u6765\u6a21\u62df\u590d\u6742\u5b9e\u9a8c\u8bbe\u8ba1\u5e76\u6bd4\u8f83\u4e0d\u540c\u5b66\u4e60\u7406\u8bba\u3002"}}
{"id": "2602.08382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08382", "abs": "https://arxiv.org/abs/2602.08382", "authors": ["Zhuoen Chen", "Dongfang Li", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning", "comment": "26 pages, 7 figures. Code and models will be released", "summary": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.", "AI": {"tldr": "\u63d0\u51fa\u8ba4\u77e5\u542f\u53d1\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5757\u538b\u7f29\u548c\u9009\u62e9\u6027\u8bb0\u5fc6\u53ec\u56de\u89e3\u51b3LLM\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3LLM\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u9762\u4e34\u7684\u4e09\u5927\u6311\u6218\uff1a\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u3001\u4fe1\u606f\u9057\u5fd8\u3001\u4ee5\u53caRAG\u4e2d\u7684\u4e0a\u4e0b\u6587\u788e\u7247\u5316\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u8ba4\u77e5\u542f\u53d1\u7684\u6846\u67b6\uff0c\u5c06\u957f\u8f93\u5165\u5206\u5757\u5e76\u538b\u7f29\u4e3a\u8bb0\u5fc6\u8868\u793a\uff0c\u901a\u8fc7\u95e8\u63a7\u6a21\u5757\u52a8\u6001\u9009\u62e9\u76f8\u5173\u8bb0\u5fc6\u5757\uff0c\u63a8\u7406\u6a21\u5757\u4f7f\u7528\u6f14\u5316\u7684\u5de5\u4f5c\u8bb0\u5fc6\u8fed\u4ee3\u5904\u7406\u4efb\u52a1\uff0c\u538b\u7f29\u5668\u548c\u63a8\u7406\u5668\u901a\u8fc7\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\u3002", "result": "\u5728RULER-HQA\u7b49\u591a\u8df3\u63a8\u7406\u57fa\u51c6\u4e0a\u8fbe\u5230\u7ade\u4e89\u6027\u7cbe\u5ea6\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece7K\u6269\u5c55\u52301.75M tokens\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5GPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c112\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53476\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u8ba4\u77e5\u542f\u53d1\u6846\u67b6\u901a\u8fc7\u538b\u7f29\u548c\u9009\u62e9\u6027\u8bb0\u5fc6\u673a\u5236\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3aLLM\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08268", "abs": "https://arxiv.org/abs/2602.08268", "authors": ["Akinori Maeda", "Yuto Sekiya", "Sota Sugimura", "Tomoya Asai", "Yu Tsuda", "Kohei Ikeda", "Hiroshi Fujii", "Kohei Watanabe"], "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI", "comment": "9 pages, 5 figures", "summary": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.", "AI": {"tldr": "Puda\u662f\u4e00\u4e2a\u7528\u6237\u4e3b\u6743\u67b6\u6784\uff0c\u901a\u8fc7\u805a\u5408\u8de8\u670d\u52a1\u6570\u636e\u5e76\u652f\u6301\u5ba2\u6237\u7aef\u7ba1\u7406\uff0c\u5728\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u4e0a\u63a7\u5236\u6570\u636e\u5171\u4eab\uff0c\u5728\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u4e2d\uff0c\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u80fd\u8fbe\u5230\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f297.2%\u7684\u4e2a\u6027\u5316\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4e2a\u4eba\u6570\u636e\u96c6\u4e2d\u5728\u5c11\u6570\u5e73\u53f0\u63d0\u4f9b\u5546\u624b\u4e2d\uff0c\u5f62\u6210\u4e86\u6570\u636e\u5b64\u5c9b\uff0c\u9650\u5236\u4e86\u7528\u6237\u4e3b\u6743\u548c\u8de8\u670d\u52a1\u6570\u636e\u4f7f\u7528\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4ee3\u7406\u5bf9\u9ad8\u5ea6\u4e2a\u6027\u5316\u670d\u52a1\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u8fd9\u9700\u8981\u5728\u6570\u636e\u5229\u7528\u548c\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u63d0\u51faPuda\uff08Private User Dataset Agent\uff09\u67b6\u6784\uff0c\u4f5c\u4e3a\u6d4f\u89c8\u5668\u7cfb\u7edf\u5b9e\u73b0\uff0c\u652f\u6301\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u7684\u6570\u636e\u5171\u4eab\u63a7\u5236\uff1a\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f2\u3001\u63d0\u53d6\u7684\u5173\u952e\u8bcd\u3001\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u3002\u901a\u8fc7\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528LLM-as-a-Judge\u6846\u67b6\u5728\u4e09\u4e2a\u6807\u51c6\u4e0b\u8861\u91cf\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u4f9b\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u80fd\u8fbe\u5230\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f297.2%\u7684\u4e2a\u6027\u5316\u6027\u80fd\u3002\u8fd9\u8868\u660ePuda\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u7684\u591a\u7c92\u5ea6\u6570\u636e\u7ba1\u7406\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u5b9e\u7528\u9009\u62e9\u6765\u7f13\u89e3\u9690\u79c1-\u4e2a\u6027\u5316\u6743\u8861\u95ee\u9898\u3002", "conclusion": "Puda\u4e3a\u7528\u6237\u4e3b\u6743\u63d0\u4f9b\u4e86AI\u539f\u751f\u57fa\u7840\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u5b89\u5168\u5730\u5229\u7528\u4e2a\u6027\u5316AI\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u6570\u636e\u7ba1\u7406\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u4e2a\u6027\u5316\u670d\u52a1\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002"}}
{"id": "2602.07521", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07521", "abs": "https://arxiv.org/abs/2602.07521", "authors": ["Xionghui Yang", "Bozhou Chen", "Yunlong Lu", "Yongyi Wang", "Lingfeng Li", "Lanxiao Huang", "Lin Liu", "Wenjun Wang", "Meng Meng", "Xia Lin", "Wenxin Li"], "title": "Pareto-guided Pipeline for Distilling Featherweight AI Agents in Mobile MOBA Games", "comment": null, "summary": "Recent advances in game AI have demonstrated the feasibility of training agents that surpass top-tier human professionals in complex environments such as Honor of Kings (HoK), a leading mobile multiplayer online battle arena (MOBA) game. However, deploying such powerful agents on mobile devices remains a major challenge. On one hand, the intricate multi-modal state representation and hierarchical action space of HoK demand large, sophisticated policy networks that are inherently difficult to compress into lightweight forms. On the other hand, production deployment requires high-frequency inference under strict energy and latency constraints on mobile platform. To the best of our knowledge, bridging large-scale game AI and practical on-device deployment has not been systematically studied. In this work, we propose a Pareto optimality guided pipeline and design a high-efficiency student architecture search space tailored for mobile execution, enabling systematic exploration of the trade-off between performance and efficiency. Experimental results demonstrate that the distilled model achieves remarkable efficiency, including an $12.4\\times$ faster inference speed (under 0.5ms per frame) and a $15.6\\times$ improvement in energy efficiency (under 0.5mAh per game), while retaining a 40.32% win rate against the original teacher model.", "AI": {"tldr": "\u63d0\u51fa\u5e15\u7d2f\u6258\u6700\u4f18\u5f15\u5bfc\u7684\u79fb\u52a8\u7aef\u90e8\u7f72\u6d41\u7a0b\uff0c\u8bbe\u8ba1\u9ad8\u6548\u5b66\u751f\u67b6\u6784\u641c\u7d22\u7a7a\u95f4\uff0c\u5728\u738b\u8005\u8363\u8000\u6e38\u620f\u4e2d\u5b9e\u73b012.4\u500d\u63a8\u7406\u52a0\u901f\u548c15.6\u500d\u80fd\u6548\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u630140.32%\u80dc\u7387\u3002", "motivation": "\u867d\u7136\u6e38\u620fAI\u5df2\u5728\u590d\u6742\u73af\u5883\uff08\u5982\u738b\u8005\u8363\u8000\uff09\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u9876\u7ea7\u9009\u624b\uff0c\u4f46\u5c06\u5927\u578b\u590d\u6742\u7b56\u7565\u7f51\u7edc\u90e8\u7f72\u5230\u79fb\u52a8\u8bbe\u5907\u4e0a\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5305\u62ec\u591a\u6a21\u6001\u72b6\u6001\u8868\u793a\u3001\u5206\u5c42\u52a8\u4f5c\u7a7a\u95f4\u5bfc\u81f4\u7684\u7f51\u7edc\u590d\u6742\u5ea6\u9ad8\uff0c\u4ee5\u53ca\u79fb\u52a8\u5e73\u53f0\u4e25\u683c\u7684\u80fd\u8017\u548c\u5ef6\u8fdf\u7ea6\u675f\u3002", "method": "\u63d0\u51fa\u5e15\u7d2f\u6258\u6700\u4f18\u5f15\u5bfc\u7684\u90e8\u7f72\u6d41\u7a0b\uff0c\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u79fb\u52a8\u6267\u884c\u7684\u9ad8\u6548\u5b66\u751f\u67b6\u6784\u641c\u7d22\u7a7a\u95f4\uff0c\u7cfb\u7edf\u63a2\u7d22\u6027\u80fd\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u5927\u578b\u6559\u5e08\u6a21\u578b\u538b\u7f29\u4e3a\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u3002", "result": "\u84b8\u998f\u6a21\u578b\u5b9e\u73b0\u4e86\u663e\u8457\u6548\u7387\u63d0\u5347\uff1a\u63a8\u7406\u901f\u5ea6\u63d0\u534712.4\u500d\uff08\u6bcf\u5e27\u4f4e\u4e8e0.5ms\uff09\uff0c\u80fd\u6548\u63d0\u534715.6\u500d\uff08\u6bcf\u5c40\u6e38\u620f\u4f4e\u4e8e0.5mAh\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u539f\u59cb\u6559\u5e08\u6a21\u578b40.32%\u7684\u80dc\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u89c4\u6a21\u6e38\u620fAI\u4e0e\u5b9e\u9645\u79fb\u52a8\u8bbe\u5907\u90e8\u7f72\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u5f15\u5bfc\u7684\u6d41\u7a0b\u548c\u9ad8\u6548\u67b6\u6784\u641c\u7d22\uff0c\u6210\u529f\u5728\u4e25\u683c\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u8f7b\u91cf\u7ea7\u6e38\u620fAI\u7684\u79fb\u52a8\u90e8\u7f72\u3002"}}
{"id": "2602.08404", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08404", "abs": "https://arxiv.org/abs/2602.08404", "authors": ["Linye Wei", "Zixiang Luo", "Pingzhi Tang", "Meng Li"], "title": "TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration", "comment": null, "summary": "Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.", "AI": {"tldr": "TEAM\u662f\u4e00\u4e2a\u52a0\u901fMoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4e13\u5bb6\u8def\u7531\u51b3\u7b56\u7684\u65f6\u7a7a\u4e00\u81f4\u6027\uff0c\u51cf\u5c11\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u540c\u65f6\u589e\u52a0\u63a5\u53d7token\u6570\u91cf\uff0c\u5b9e\u73b0\u6700\u9ad82.2\u500d\u52a0\u901f\u4e14\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\u3002", "motivation": "MoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u67b6\u6784\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u6bcf\u4e2a\u53bb\u566a\u6b65\u9aa4\u6fc0\u6d3b\u5927\u91cf\u4e13\u5bb6\uff0c\u4f46\u6700\u7ec8\u53ea\u63a5\u53d7\u5c11\u91cftoken\uff0c\u5bfc\u81f4\u63a8\u7406\u5f00\u9500\u5927\uff0c\u9650\u5236\u4e86\u5728\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u3002", "method": "TEAM\u5229\u7528\u4e13\u5bb6\u8def\u7531\u51b3\u7b56\u7684\u65f6\u7a7a\u4e00\u81f4\u6027\uff08\u8de8\u53bb\u566a\u7ea7\u522b\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8de8token\u4f4d\u7f6e\u7684\u7a7a\u95f4\u4e00\u81f4\u6027\uff09\uff0c\u91c7\u7528\u4e09\u79cd\u4e92\u8865\u7684\u4e13\u5bb6\u6fc0\u6d3b\u548c\u89e3\u7801\u7b56\u7565\uff1a\u4fdd\u5b88\u9009\u62e9\u5df2\u89e3\u7801\u548c\u63a9\u7801token\u7684\u5fc5\u8981\u4e13\u5bb6\uff0c\u540c\u65f6\u8fdb\u884c\u8de8\u591a\u4e2a\u5019\u9009token\u7684\u6fc0\u8fdb\u63a8\u6d4b\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTEAM\u76f8\u6bd4\u539f\u59cbMoE dLLM\u5b9e\u73b0\u4e86\u6700\u9ad82.2\u500d\u7684\u52a0\u901f\uff0c\u4e14\u6027\u80fd\u4e0b\u964d\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "TEAM\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u52a0\u901fMoE\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u66f4\u5c11\u7684\u6fc0\u6d3b\u4e13\u5bb6\u5b9e\u73b0\u66f4\u591a\u63a5\u53d7token\uff0c\u89e3\u51b3\u4e86MoE\u67b6\u6784\u4e0e\u6269\u6563\u89e3\u7801\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2602.08276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08276", "abs": "https://arxiv.org/abs/2602.08276", "authors": ["Haoyu Jia", "Kento Kawaharazuka", "Kei Okada"], "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis", "comment": null, "summary": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.", "AI": {"tldr": "\u63d0\u51faStructural Context Model\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u7ed3\u6784\u5206\u6790LLM\u667a\u80fd\u4f53\uff0c\u5305\u542b\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\u548c\u8bed\u4e49\u52a8\u6001\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u5728\u52a8\u6001\u7334\u5b50\u9999\u8549\u95ee\u9898\u4e0a\u63d0\u534732%\u6210\u529f\u7387", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7814\u7a76\u788e\u7247\u5316\u4e25\u91cd\uff0c\u6982\u5ff5\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\u539f\u5219\u5e38\u4e0e\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u6df7\u6742\uff0c\u7f3a\u4e4f\u53ef\u5206\u6790\u3001\u81ea\u6d3d\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u6765\u72ec\u7acb\u4e8e\u5b9e\u73b0\u5730\u8868\u5f81\u548c\u6bd4\u8f83LLM\u667a\u80fd\u4f53", "method": "\u63d0\u51faStructural Context Model\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u4ece\u4e0a\u4e0b\u6587\u7ed3\u6784\u89d2\u5ea6\u5206\u6790LLM\u667a\u80fd\u4f53\uff1b\u5305\u542b\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\u548c\u8bed\u4e49\u52a8\u6001\u5206\u6790\u5de5\u4f5c\u6d41\uff0c\u652f\u6301\u5feb\u901f\u7cfb\u7edf\u5316\u8bbe\u8ba1\u8fed\u4ee3", "result": "\u5728\u52a8\u6001\u7334\u5b50\u9999\u8549\u95ee\u9898\u53d8\u4f53\u4e0a\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u7684\u667a\u80fd\u4f53\u5728\u6700\u56f0\u96be\u8bbe\u7f6e\u4e2d\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe32\u4e2a\u767e\u5206\u70b9", "conclusion": "\u63d0\u51fa\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u5de5\u4f5c\u6d41\u80fd\u6709\u6548\u89e3\u51b3LLM\u667a\u80fd\u4f53\u7814\u7a76\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u539f\u5219\u6027\u6d1e\u5bdf\u5e76\u652f\u6301\u7cfb\u7edf\u5316\u8bbe\u8ba1\u8fed\u4ee3"}}
{"id": "2602.07529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07529", "abs": "https://arxiv.org/abs/2602.07529", "authors": ["Jianwen Chen", "Xinyu Yang", "Peng Xia", "Arian Azarang", "Yueh Z Lee", "Gang Li", "Hongtu Zhu", "Yun Li", "Beidi Chen", "Huaxiu Yao"], "title": "MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance and rapid progress in a wide range of medical reasoning tasks. However, their sequential autoregressive decoding forces inherently parallel clinical reasoning, such as differential diagnosis, into a single linear reasoning path, limiting both efficiency and reliability for complex medical problems. To address this, we propose MedVerse, a reasoning framework for complex medical inference that reformulates medical reasoning as a parallelizable directed acyclic graph (DAG) process based on Petri net theory. The framework adopts a full-stack design across data, model architecture, and system execution. For data creation, we introduce the MedVerse Curator, an automated pipeline that synthesizes knowledge-grounded medical reasoning paths and transforms them into Petri net-structured representations. At the architectural level, we propose a topology-aware attention mechanism with adaptive position indices that supports parallel reasoning while preserving logical consistency. Systematically, we develop a customized inference engine that supports parallel execution without additional overhead. Empirical evaluations show that MedVerse improves strong general-purpose LLMs by up to 8.9%. Compared to specialized medical LLMs, MedVerse achieves comparable performance while delivering a 1.3x reduction in inference latency and a 1.7x increase in generation throughput, enabled by its parallel decoding capability.", "AI": {"tldr": "MedVerse\uff1a\u57fa\u4e8ePetri\u7f51\u7406\u8bba\u7684\u5e76\u884c\u533b\u7597\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u533b\u7597\u63a8\u7406\u91cd\u6784\u4e3a\u53ef\u5e76\u884c\u5316\u7684\u6709\u5411\u65e0\u73af\u56fe\u8fc7\u7a0b\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u53ef\u9760\u6027", "motivation": "\u4f20\u7edfLLMs\u7684\u987a\u5e8f\u81ea\u56de\u5f52\u89e3\u7801\u5c06\u672c\u5e94\u5e76\u884c\u7684\u4e34\u5e8a\u63a8\u7406\uff08\u5982\u9274\u522b\u8bca\u65ad\uff09\u5f3a\u5236\u4e3a\u5355\u4e00\u7ebf\u6027\u63a8\u7406\u8def\u5f84\uff0c\u9650\u5236\u4e86\u590d\u6742\u533b\u7597\u95ee\u9898\u7684\u6548\u7387\u548c\u53ef\u9760\u6027", "method": "1. MedVerse Curator\uff1a\u81ea\u52a8\u5316\u7ba1\u9053\u5408\u6210\u77e5\u8bc6\u57fa\u7840\u7684\u533b\u7597\u63a8\u7406\u8def\u5f84\u5e76\u8f6c\u6362\u4e3aPetri\u7f51\u7ed3\u6784\u8868\u793a\uff1b2. \u62d3\u6251\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff1a\u652f\u6301\u5e76\u884c\u63a8\u7406\u540c\u65f6\u4fdd\u6301\u903b\u8f91\u4e00\u81f4\u6027\uff1b3. \u5b9a\u5236\u5316\u63a8\u7406\u5f15\u64ce\uff1a\u652f\u6301\u5e76\u884c\u6267\u884c\u800c\u65e0\u989d\u5916\u5f00\u9500", "result": "MedVerse\u5c06\u901a\u7528LLMs\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe8.9%\uff1b\u4e0e\u4e13\u4e1a\u533b\u7597LLMs\u76f8\u6bd4\uff0c\u5728\u4fdd\u6301\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e1.3\u500d\uff0c\u751f\u6210\u541e\u5410\u91cf\u63d0\u9ad81.7\u500d", "conclusion": "MedVerse\u901a\u8fc7\u5c06\u533b\u7597\u63a8\u7406\u91cd\u6784\u4e3a\u5e76\u884cDAG\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfLLMs\u5728\u533b\u7597\u63a8\u7406\u4e2d\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u9650\u5236\uff0c\u4e3a\u590d\u6742\u533b\u7597\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08426", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08426", "abs": "https://arxiv.org/abs/2602.08426", "authors": ["Xinghao Wang", "Pengyu Wang", "Xiaoran Liu", "Fangxu Liu", "Jason Chu", "Kai Song", "Xipeng Qiu"], "title": "Prism: Spectral-Aware Block-Sparse Attention", "comment": null, "summary": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup.", "AI": {"tldr": "Prism\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u5149\u8c31\u611f\u77e5\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u9891\u548c\u4f4e\u9891\u5206\u652f\u5206\u89e3\u5757\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5747\u503c\u6c60\u5316\u5728RoPE\u4e0b\u5bfc\u81f4\u5c40\u90e8\u4f4d\u7f6e\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587LLM\u9884\u586b\u5145\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684\u5757\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u4f7f\u7528\u7c97\u7c92\u5ea6\u6ce8\u610f\u529b\u4f5c\u4e3a\u5757\u91cd\u8981\u6027\u4f30\u8ba1\u7684\u4ee3\u7406\uff0c\u4f46\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684token\u7ea7\u641c\u7d22\u6216\u8bc4\u5206\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u9009\u62e9\u5f00\u9500\u3002\u6807\u51c6\u7c97\u7c92\u5ea6\u6ce8\u610f\u529b\uff08\u901a\u8fc7\u5747\u503c\u6c60\u5316\uff09\u7684\u4e0d\u51c6\u786e\u6027\u6e90\u4e8e\u5747\u503c\u6c60\u5316\u4e0eRoPE\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5c40\u90e8\u4f4d\u7f6e\u4fe1\u606f\uff08\u5982\u659c\u7ebf\u6a21\u5f0f\uff09\u7684\"\u76f2\u70b9\"\u3002", "method": "Prism\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u5149\u8c31\u611f\u77e5\u65b9\u6cd5\uff0c\u5c06\u5757\u9009\u62e9\u5206\u89e3\u4e3a\u9ad8\u9891\u548c\u4f4e\u9891\u5206\u652f\u3002\u901a\u8fc7\u57fa\u4e8e\u80fd\u91cf\u7684\u6e29\u5ea6\u6821\u51c6\uff0c\u76f4\u63a5\u4ece\u6c60\u5316\u8868\u793a\u4e2d\u6062\u590d\u8870\u51cf\u7684\u4f4d\u7f6e\u4fe1\u53f7\uff0c\u4f7f\u5757\u91cd\u8981\u6027\u4f30\u8ba1\u4ec5\u4f7f\u7528\u5757\u7ea7\u64cd\u4f5c\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8bc1\u5b9e\uff0cPrism\u5728\u4fdd\u6301\u4e0e\u5b8c\u6574\u6ce8\u610f\u529b\u76f8\u540c\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe5.1\u500d\u7684\u52a0\u901f\u3002", "conclusion": "Prism\u901a\u8fc7\u89e3\u51b3\u5747\u503c\u6c60\u5316\u4e0eRoPE\u4ea4\u4e92\u5bfc\u81f4\u7684\u5c40\u90e8\u4f4d\u7f6e\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5757\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u901f\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u7684\u9884\u586b\u5145\u8fc7\u7a0b\u3002"}}
{"id": "2602.08295", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08295", "abs": "https://arxiv.org/abs/2602.08295", "authors": ["Ilya Levin"], "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI", "comment": "19 pages", "summary": "The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.\n  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.\n  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6c1b\u56f4\u81ea\u52a8\u5316\"\u6982\u5ff5\uff0c\u8ba4\u4e3a\u751f\u6210\u5f0fAI\u4ee3\u8868\u4e86\u4ece\u7b97\u6cd5\u4f18\u5316\u5230\u8bed\u5883\u8bed\u4e49\u534f\u8c03\u7684\u8ba4\u77e5\u8f6c\u53d8\uff0c\u5c06\u4eba\u7c7b\u89d2\u8272\u4ece\u95ee\u9898\u89c4\u8303\u8f6c\u5411\"\u6c1b\u56f4\u5de5\u7a0b\"\u3002", "motivation": "\u751f\u6210\u5f0fAI\u4e0d\u662f\u6e10\u8fdb\u6280\u672f\u6539\u8fdb\uff0c\u800c\u662f\u8d28\u53d8\u7684\u8ba4\u77e5\u8f6c\u53d8\uff0c\u6311\u6218\u8ba1\u7b97\u673a\u79d1\u5b66\u57fa\u7840\u5047\u8bbe\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u662f\u81ea\u52a8\u5316\u7684\u81ea\u52a8\u5316\uff0c\u800c\u751f\u6210\u5f0fAI\u901a\u8fc7\u5bfc\u822a\u8bed\u5883\u3001\u8bed\u4e49\u548c\u98ce\u683c\u4e00\u81f4\u6027\u8fd0\u4f5c\uff0c\u800c\u975e\u4f18\u5316\u9884\u5b9a\u4e49\u6307\u6807\u3002", "method": "\u63d0\u51fa\"\u6c1b\u56f4\u81ea\u52a8\u5316\"\u6982\u5ff5\u6846\u67b6\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u64cd\u4f5c\u5316\u9690\u6027\u89c4\u5f8b\u2014\u2014\u65e0\u6cd5\u901a\u8fc7\u660e\u786e\u7b97\u6cd5\u89c4\u5219\u5b8c\u5168\u6307\u5b9a\u7684\u8bed\u5883\u654f\u611f\u6a21\u5f0f\u3002\u867d\u7136\u751f\u6210\u7cfb\u7edf\u4e0d\u5177\u5907\u73b0\u8c61\u5b66\u610f\u4e49\u4e0a\u7684\u9690\u6027\u77e5\u8bc6\uff0c\u4f46\u80fd\u64cd\u4f5c\u5316\u5bf9\u8bed\u8c03\u3001\u610f\u56fe\u548c\u60c5\u5883\u5224\u65ad\u7684\u654f\u611f\u6027\u3002", "result": "\u4eba\u7c7b\u89d2\u8272\u4ece\u7b97\u6cd5\u95ee\u9898\u89c4\u8303\u8f6c\u5411\"\u6c1b\u56f4\u5de5\u7a0b\"\uff0c\u5373\u534f\u8c03\u751f\u6210\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u548c\u8bed\u5883\u5224\u65ad\u3002\u8bba\u6587\u5efa\u7acb\u4e86\u5305\u542b\u4e09\u4e2a\u5206\u6790\u5c42\u9762\u548c\u4e09\u4e2a\u884c\u52a8\u9886\u57df\u7684\u6982\u5ff5\u6846\u67b6\uff1a\u6559\u5e08\u4e16\u754c\u89c2\u3001\u4ea7\u4e1a\u5173\u7cfb\u548c\u8bfe\u7a0b\u8bbe\u8ba1\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u7684\u8ba4\u77e5\u8f6c\u53d8\u9700\u8981\u6559\u80b2\u673a\u6784\u548c\u4ea7\u4e1a\u8f6c\u578b\u3002\u5fc5\u987b\u8b66\u60d5\u6a21\u5f0f\u5d29\u6e83\u548c\u6587\u5316\u540c\u8d28\u5316\u98ce\u9669\uff0c\u901a\u8fc7\u6709\u610f\u8bc6\u53c2\u4e0e\u751f\u6210\u7cfb\u7edf\u907f\u514d\u56de\u5f52\u5408\u6210\u7edf\u4e00\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u6df1\u601d\u719f\u8651\u7684\u53c2\u4e0e\u800c\u975e\u88ab\u52a8\u63a5\u53d7\u3002"}}
{"id": "2602.07530", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07530", "abs": "https://arxiv.org/abs/2602.07530", "authors": ["Sreenivas Gollapudi", "Kostas Kollias", "Kamesh Munagala", "Aravindan Vijayaraghavan"], "title": "Compact Conformal Subgraphs", "comment": null, "summary": "Conformal prediction provides rigorous, distribution-free uncertainty guarantees, but often yields prohibitively large prediction sets in structured domains such as routing, planning, or sequential recommendation. We introduce \"graph-based conformal compression\", a framework for constructing compact subgraphs that preserve statistical validity while reducing structural complexity. We formulate compression as selecting a smallest subgraph capturing a prescribed fraction of the probability mass, and reduce to a weighted version of densest $k$-subgraphs in hypergraphs, in the regime where the subgraph has a large fraction of edges. We design efficient approximation algorithms that achieve constant factor coverage and size trade-offs. Crucially, we prove that our relaxation satisfies a monotonicity property, derived from a connection to parametric minimum cuts, which guarantees the nestedness required for valid conformal guarantees. Our results on the one hand bridge efficient conformal prediction with combinatorial graph compression via monotonicity, to provide rigorous guarantees on both statistical validity, and compression or size. On the other hand, they also highlight an algorithmic regime, distinct from classical densest-$k$-subgraph hardness settings, where the problem can be approximated efficiently. We finally validate our algorithmic approach via simulations for trip planning and navigation, and compare to natural baselines.", "AI": {"tldr": "\u63d0\u51fa\u56fe\u57fa\u5171\u5f62\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u5c0f\u5b50\u56fe\u6765\u6355\u83b7\u89c4\u5b9a\u6982\u7387\u8d28\u91cf\uff0c\u5728\u4fdd\u6301\u7edf\u8ba1\u6709\u6548\u6027\u7684\u540c\u65f6\u51cf\u5c11\u7ed3\u6784\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u7d27\u51d1\u9884\u6d4b\u96c6", "motivation": "\u4f20\u7edf\u5171\u5f62\u9884\u6d4b\u5728\u7ed3\u6784\u5316\u9886\u57df\uff08\u5982\u8def\u7531\u3001\u89c4\u5212\u3001\u5e8f\u5217\u63a8\u8350\uff09\u4ea7\u751f\u7684\u9884\u6d4b\u96c6\u8fc7\u5927\uff0c\u9700\u8981\u6784\u5efa\u7d27\u51d1\u5b50\u56fe\u540c\u65f6\u4fdd\u6301\u7edf\u8ba1\u6709\u6548\u6027\u4fdd\u8bc1", "method": "\u5c06\u538b\u7f29\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u9009\u62e9\u6355\u83b7\u89c4\u5b9a\u6982\u7387\u8d28\u91cf\u7684\u6700\u5c0f\u5b50\u56fe\uff0c\u8f6c\u5316\u4e3a\u8d85\u56fe\u4e2d\u52a0\u6743\u6700\u5bc6k\u5b50\u56fe\u95ee\u9898\uff0c\u8bbe\u8ba1\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5229\u7528\u53c2\u6570\u6700\u5c0f\u5272\u7684\u5355\u8c03\u6027\u4fdd\u8bc1\u5d4c\u5957\u6027", "result": "\u5f00\u53d1\u4e86\u5b9e\u73b0\u5e38\u6570\u56e0\u5b50\u8986\u76d6\u7387\u548c\u5927\u5c0f\u6743\u8861\u7684\u9ad8\u6548\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u677e\u5f1b\u6ee1\u8db3\u5355\u8c03\u6027\uff0c\u5728\u884c\u7a0b\u89c4\u5212\u548c\u5bfc\u822a\u6a21\u62df\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027", "conclusion": "\u8be5\u6846\u67b6\u5c06\u9ad8\u6548\u5171\u5f62\u9884\u6d4b\u4e0e\u7ec4\u5408\u56fe\u538b\u7f29\u901a\u8fc7\u5355\u8c03\u6027\u8fde\u63a5\uff0c\u63d0\u4f9b\u7edf\u8ba1\u6709\u6548\u6027\u548c\u538b\u7f29\u5927\u5c0f\u7684\u4e25\u683c\u4fdd\u8bc1\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e0e\u7ecf\u5178\u6700\u5bc6k\u5b50\u56fe\u95ee\u9898\u4e0d\u540c\u7684\u53ef\u9ad8\u6548\u8fd1\u4f3c\u7684\u7b97\u6cd5\u673a\u5236"}}
{"id": "2602.08437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08437", "abs": "https://arxiv.org/abs/2602.08437", "authors": ["Ziyan wang", "Longlong Ma"], "title": "Large Language Models and Impossible Language Acquisition: \"False Promise\" or an Overturn of our Current Perspective towards AI", "comment": null, "summary": "In Chomsky's provocative critique \"The False Promise of CHATGPT,\" Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his \"rationalist-romantics\" paradigm to functionalism and empiricism in LLMs research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u68c0\u9a8cChomsky\u5bf9LLMs\u7684\u6279\u8bc4\uff0c\u53d1\u73b0GPT-2\u5c0f\u578b\u6a21\u578b\u5728\u5b66\u4e60\u4e0d\u53ef\u80fd\u8bed\u8a00\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u652f\u6301Chomsky\u89c2\u70b9\uff0c\u4f46LSTM\u8868\u73b0\u4e0d\u540c\uff0c\u8868\u660eTransformer\u67b6\u6784\u6f14\u53d8\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u56de\u5e94Chomsky\u5728\u300aThe False Promise of CHATGPT\u300b\u4e2d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6839\u672c\u6027\u6279\u8bc4\uff0c\u5373LLMs\u53ea\u662f\u6a21\u5f0f\u9884\u6d4b\u5668\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u5185\u5728\u56e0\u679c\u548c\u81ea\u6211\u7ea0\u6b63\u7ed3\u6784\u4e60\u5f97\u8bed\u8a00\uff0c\u56e0\u6b64\u65e0\u6cd5\u533a\u5206\u4e0d\u53ef\u80fd\u8bed\u8a00\u3002", "method": "1. \u4ece\u8bed\u8a00\u5b66\u548c\u5fc3\u7406\u5b66\u6587\u732e\u89d2\u5ea6\u5206\u6790Chomsky\u6279\u8bc4\uff1b2. \u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76LLMs\u5b66\u4e60\u53ef\u80fd\u548c\u4e0d\u53ef\u80fd\u8bed\u8a00\u7684\u80fd\u529b\uff1b3. \u6784\u5efa\u4e00\u7ec4\u8bed\u6cd5\u4e0a\u4e0d\u53ef\u80fd\u7684\u8bed\u8a00\uff08\u5305\u62ec\u53e5\u5b50\u53cd\u8f6c\u548c\u57fa\u4e8e\u8bcd\u6570\u5947\u5076\u6027\u7684\u5426\u5b9a\u6dfb\u52a0\uff09\uff1b4. \u5728GPT-2\u5c0f\u578b\u6a21\u578b\u548cLSTM\u6a21\u578b\u4e0a\u8fdb\u884c\u4e24\u8f6e\u5bf9\u7167\u5b9e\u9a8c\uff1b5. \u4f7f\u7528Welch's t-test\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "GPT-2\u5c0f\u578b\u6a21\u578b\u5728\u6240\u6709\u4e0d\u53ef\u80fd\u8bed\u8a00\u4e0a\u7684\u5b66\u4e60\u8868\u73b0\u5747\u663e\u8457\u4f4e\u4e8e\u53ef\u80fd\u8bed\u8a00\uff08p<.001\uff09\uff0c\u652f\u6301Chomsky\u7684\u8bba\u70b9\u3002\u4f46LSTM\u6a21\u578b\u7684\u8868\u73b0\u4e0eChomsky\u8bba\u70b9\u4e0d\u4e00\u81f4\uff0c\u8868\u660eTransformer\u67b6\u6784\u6f14\u53d8\u5177\u6709\u4e0d\u53ef\u66ff\u4ee3\u7684\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u5728Chomsky\u7406\u8bba\u6846\u67b6\u5185\u5bf9LLMs\u7684\u65b0\u89c6\u89d2\uff0c\u5e76\u5efa\u8bae\u4eceChomsky\u7684\"\u7406\u6027\u4e3b\u4e49-\u6d6a\u6f2b\u4e3b\u4e49\"\u8303\u5f0f\u8f6c\u5411\u529f\u80fd\u4e3b\u4e49\u548c\u7ecf\u9a8c\u4e3b\u4e49\u7684\u7814\u7a76\u8303\u5f0f\uff0c\u5f3a\u8c03\u9700\u8981\u8d85\u8d8aChomsky\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3LLMs\u3002"}}
{"id": "2602.08311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08311", "abs": "https://arxiv.org/abs/2602.08311", "authors": ["Shadman Rabby", "Md. Hefzul Hossain Papon", "Sabbir Ahmed", "Nokimul Hasan Arif", "A. B. M. Ashikur Rahman", "Irfan Ahmad"], "title": "Moral Sycophancy in Vision Language Models", "comment": "13 pages, 6 figures, 8 tables, Submitted for review in ACL", "summary": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9053\u5fb7\u5949\u627f\u884c\u4e3a\uff0c\u53d1\u73b0VLMs\u5728\u7528\u6237\u610f\u89c1\u5f71\u54cd\u4e0b\u4f1a\u727a\u7272\u9053\u5fb7\u51c6\u786e\u6027\uff0c\u8868\u73b0\u51fa\u4ece\u6b63\u786e\u5230\u9519\u8bef\u5224\u65ad\u7684\u4e0d\u5bf9\u79f0\u8f6c\u53d8\uff0c\u63ed\u793a\u4e86\u9053\u5fb7\u9c81\u68d2\u6027\u4e0e\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e00\u822c\u60c5\u5883\u4e0b\u7684\u5949\u627f\u884c\u4e3a\uff0c\u4f46\u5bf9\u57fa\u4e8e\u9053\u5fb7\u7684\u89c6\u89c9\u51b3\u7b56\u4e2d\u5949\u627f\u884c\u4e3a\u7684\u5f71\u54cd\u7406\u89e3\u4e0d\u8db3\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u7814\u7a76VLMs\u4e2d\u7684\u9053\u5fb7\u5949\u627f\u73b0\u8c61\u3002", "method": "\u5728Moralise\u548cM^3oralBench\u6570\u636e\u96c6\u4e0a\u8bc4\u4f3010\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684VLMs\uff0c\u5728\u7528\u6237\u660e\u786e\u53cd\u5bf9\u7684\u60c5\u5883\u4e0b\u5206\u6790\u6a21\u578b\u884c\u4e3a\u3002\u4f7f\u7528\u9519\u8bef\u5f15\u5165\u7387(EIR)\u548c\u9519\u8bef\u7ea0\u6b63\u7387(ECR)\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\u3002", "result": "VLMs\u7ecf\u5e38\u5728\u521d\u59cb\u5224\u65ad\u6b63\u786e\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u9053\u5fb7\u9519\u8bef\u7684\u540e\u7eed\u56de\u5e94\uff1b\u8868\u73b0\u51fa\u4e0d\u5bf9\u79f0\u6027\uff1a\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u4ece\u9053\u5fb7\u6b63\u786e\u8f6c\u5411\u9519\u8bef\u5224\u65ad\uff1b\u540e\u7eed\u63d0\u793a\u5728Moralise\u4e0a\u964d\u4f4e\u6027\u80fd\uff0c\u5728M^3oralBench\u4e0a\u8868\u73b0\u6df7\u5408\uff1b\u5b58\u5728EIR\u548cECR\u4e4b\u95f4\u7684\u6743\u8861\uff1b\u521d\u59cb\u9053\u5fb7\u6b63\u786e\u7acb\u573a\u4f1a\u5f15\u53d1\u66f4\u5f3a\u7684\u5949\u627f\u884c\u4e3a\u3002", "conclusion": "VLMs\u5bf9\u9053\u5fb7\u5f71\u54cd\u5177\u6709\u8106\u5f31\u6027\uff0c\u9700\u8981\u5236\u5b9a\u539f\u5219\u6027\u7b56\u7565\u6765\u63d0\u9ad8\u591a\u6a21\u6001AI\u7cfb\u7edf\u7684\u4f26\u7406\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u3002\u7814\u7a76\u63ed\u793a\u4e86\u9053\u5fb7\u5949\u627f\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u6a21\u5f0f\u53ca\u5176\u5bf9AI\u4f26\u7406\u51b3\u7b56\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.08498", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08498", "abs": "https://arxiv.org/abs/2602.08498", "authors": ["Haoran Zhang", "Yafu Li", "Zhi Wang", "Zhilin Wang", "Shunkai Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "Characterizing, Evaluating, and Optimizing Complex Reasoning", "comment": "Code and data are available at \\url{https://github.com/zzzhr97/TRM}", "summary": "Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.", "AI": {"tldr": "\u63d0\u51faME\u00b2\u539f\u5219\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\uff0c\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\u6784\u5efaTRM-Preference\u6570\u636e\u96c6\u548c\u601d\u8003\u5956\u52b1\u6a21\u578bTRM\uff0c\u901a\u8fc7\u601d\u8003\u5956\u52b1\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u6d4b\u8bd5\u548c\u8bad\u7ec3\u4e2d\u5747\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8d28\u91cf\u7684\u7edf\u4e00\u5b9a\u4e49\u3001\u5bf9\u590d\u6742\u7ed3\u6784\u63a8\u7406\u8f68\u8ff9\u7684\u53ef\u9760\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u8bc4\u4f30\u4fe1\u53f7\u8fdb\u884c\u63a8\u7406\u4f18\u5316\u7684\u7cfb\u7edf\u6846\u67b6\u3002", "method": "1. \u63d0\u51faME\u00b2\u539f\u5219\u4ece\u5b8f\u89c2\u548c\u5fae\u89c2\u5c42\u9762\u8bc4\u4f30\u63a8\u7406\u6548\u7387\u4e0e\u6548\u679c\uff1b2. \u5c06\u63a8\u7406\u8f68\u8ff9\u5efa\u6a21\u4e3a\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5f00\u53d1\u57fa\u4e8eDAG\u7684\u6210\u5bf9\u8bc4\u4f30\u65b9\u6cd5\uff1b3. \u6784\u5efaTRM-Preference\u6570\u636e\u96c6\u5e76\u8bad\u7ec3\u601d\u8003\u5956\u52b1\u6a21\u578bTRM\u8fdb\u884c\u5927\u89c4\u6a21\u63a8\u7406\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u601d\u8003\u5956\u52b1\u4f5c\u4e3a\u6709\u6548\u7684\u4f18\u5316\u4fe1\u53f7\uff1a\u6d4b\u8bd5\u65f6\u9009\u62e9\u66f4\u597d\u7684\u63a8\u7406\u8def\u5f84\u53ef\u83b7\u5f97\u9ad8\u8fbe19.3%\u7684\u6027\u80fd\u63d0\u5347\uff1b\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u601d\u8003\u5956\u52b1\u53ef\u63d0\u5347\u63a8\u7406\u80fd\u529b\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u6700\u9ad8\u589e\u76ca\u8fbe3.9%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63a8\u7406\u8d28\u91cf\u8bc4\u4f30\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\uff0cME\u00b2\u539f\u5219\u548cTRM\u6a21\u578b\u80fd\u6709\u6548\u8bc4\u4f30\u590d\u6742\u63a8\u7406\u7ed3\u6784\uff0c\u601d\u8003\u5956\u52b1\u673a\u5236\u663e\u8457\u63d0\u5347\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.08335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08335", "abs": "https://arxiv.org/abs/2602.08335", "authors": ["Yanming Li", "Xuelin Zhang", "WenJie Lu", "Ziye Tang", "Maodong Wu", "Haotian Luo", "Tongtong Wu", "Zijie Peng", "Hongze Mi", "Yibo Feng", "Naiqiang Tan", "Chao Huang", "Hong Chen", "Li Shen"], "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System", "comment": null, "summary": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.", "AI": {"tldr": "SHARP\u6846\u67b6\u901a\u8fc7Shapley\u503c\u8fdb\u884c\u7cbe\u786e\u4fe1\u7528\u5206\u914d\uff0c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u6027\u80fd", "motivation": "\u5f53\u524dLLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bad\u7ec3\u56f0\u96be\uff0c\u4e3b\u8981\u9762\u4e34\u4fe1\u7528\u5206\u914d\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u6216\u5168\u5c40\u5e7f\u64ad\u5956\u52b1\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u4e2a\u4f53\u8d21\u732e\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b", "method": "\u63d0\u51faSHARP\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7684\u5956\u52b1\u673a\u5236\u5b9e\u73b0\u7cbe\u786e\u4fe1\u7528\u5206\u914d\uff1a\u5305\u62ec\u5168\u5c40\u5e7f\u64ad\u51c6\u786e\u6027\u5956\u52b1\u3001\u57fa\u4e8eShapley\u503c\u7684\u8fb9\u9645\u4fe1\u7528\u5956\u52b1\uff08\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u5206\u914d\uff09\u4ee5\u53ca\u5de5\u5177\u8fc7\u7a0b\u5956\u52b1\u4ee5\u63d0\u9ad8\u6267\u884c\u6548\u7387\u3002\u901a\u8fc7\u8f68\u8ff9\u7ec4\u95f4\u667a\u80fd\u4f53\u7279\u5b9a\u4f18\u52bf\u7684\u5f52\u4e00\u5316\u6765\u7a33\u5b9a\u8bad\u7ec3", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSHARP\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5e73\u5747\u63d0\u534723.66%\uff0c\u76f8\u6bd4\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5e73\u5747\u63d0\u534714.05%", "conclusion": "SHARP\u901a\u8fc7\u7cbe\u786e\u7684\u4fe1\u7528\u5206\u914d\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u4e3aLLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u590d\u6742\u95ee\u9898\u5206\u89e3\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6"}}
{"id": "2602.07579", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07579", "abs": "https://arxiv.org/abs/2602.07579", "authors": ["Javidan Abdullayev", "Maxime Devanne", "Cyril Meyer", "Ali Ismail-Fawaz", "Jonathan Weber", "Germain Forestier"], "title": "Enhancing Time Series Classification with Diversity-Driven Neural Network Ensembles", "comment": "Published in IEEE IJCNN 2025 proceedings. 10 pages, 8 figures", "summary": "Ensemble methods have played a crucial role in achieving state-of-the-art (SOTA) performance across various machine learning tasks by leveraging the diversity of features learned by individual models. In Time Series Classification (TSC), ensembles have proven highly effective whether based on neural networks (NNs) or traditional methods like HIVE-COTE. However most existing NN-based ensemble methods for TSC train multiple models with identical architectures and configurations. These ensembles aggregate predictions without explicitly promoting diversity which often leads to redundant feature representations and limits the benefits of ensembling. In this work, we introduce a diversity-driven ensemble learning framework that explicitly encourages feature diversity among neural network ensemble members. Our approach employs a decorrelated learning strategy using a feature orthogonality loss applied directly to the learned feature representations. This ensures that each model in the ensemble captures complementary rather than redundant information. We evaluate our framework on 128 datasets from the UCR archive and show that it achieves SOTA performance with fewer models. This makes our method both efficient and scalable compared to conventional NN-based ensemble approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u591a\u6837\u6027\u9a71\u52a8\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u6b63\u4ea4\u6027\u635f\u5931\u4fc3\u8fdb\u96c6\u6210\u6210\u5458\u95f4\u7684\u7279\u5f81\u591a\u6837\u6027\uff0c\u5728UCR\u6570\u636e\u96c6\u4e0a\u4ee5\u66f4\u5c11\u6a21\u578b\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684TSC\u96c6\u6210\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u76f8\u540c\u67b6\u6784\u548c\u914d\u7f6e\u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\uff0c\u5bfc\u81f4\u7279\u5f81\u8868\u793a\u5197\u4f59\uff0c\u9650\u5236\u4e86\u96c6\u6210\u6548\u679c\u3002\u9700\u8981\u663e\u5f0f\u4fc3\u8fdb\u96c6\u6210\u6210\u5458\u95f4\u7684\u7279\u5f81\u591a\u6837\u6027\u3002", "method": "\u91c7\u7528\u53bb\u76f8\u5173\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u5b66\u4e60\u7684\u7279\u5f81\u8868\u793a\u4e0a\u5e94\u7528\u7279\u5f81\u6b63\u4ea4\u6027\u635f\u5931\uff0c\u786e\u4fdd\u96c6\u6210\u4e2d\u7684\u6bcf\u4e2a\u6a21\u578b\u6355\u83b7\u4e92\u8865\u800c\u975e\u5197\u4f59\u7684\u4fe1\u606f\u3002", "result": "\u5728UCR\u6863\u6848\u7684128\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u6846\u67b6\u4ee5\u66f4\u5c11\u7684\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u96c6\u6210\u65b9\u6cd5\u66f4\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u9f13\u52b1\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u6210\u5458\u95f4\u7684\u7279\u5f81\u591a\u6837\u6027\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u96c6\u6210\u7cfb\u7edf\u3002"}}
{"id": "2602.08543", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08543", "abs": "https://arxiv.org/abs/2602.08543", "authors": ["Yutao Zhu", "Xingshuo Zhang", "Maosen Zhang", "Jiajie Jin", "Liancheng Zhang", "Xiaoshuai Song", "Kangzhi Zhao", "Wencong Zeng", "Ruiming Tang", "Han Li", "Ji-Rong Wen", "Zhicheng Dou"], "title": "GISA: A Benchmark for General Information-Seeking Assistant", "comment": null, "summary": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.", "AI": {"tldr": "GISA\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u901a\u7528\u4fe1\u606f\u641c\u7d22\u52a9\u624b\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b373\u4e2a\u4eba\u5de5\u6784\u5efa\u7684\u771f\u5b9e\u67e5\u8be2\uff0c\u652f\u6301\u56db\u79cd\u7ed3\u6784\u5316\u7b54\u6848\u683c\u5f0f\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u4eba\u7c7b\u641c\u7d22\u8f68\u8ff9\u4f5c\u4e3a\u53c2\u8003\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u57fa\u51c6\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u67e5\u8be2\u6784\u5efa\u65b9\u5f0f\u4e0d\u81ea\u7136\uff08\u4ece\u7b54\u6848\u53cd\u5411\u6784\u5efa\uff09\uff0c\u4e0e\u73b0\u5b9e\u9700\u6c42\u4e0d\u7b26\uff1b2\uff09\u8981\u4e48\u4e13\u6ce8\u4e8e\u5b9a\u4f4d\u7279\u5b9a\u4fe1\u606f\uff0c\u8981\u4e48\u4e13\u6ce8\u4e8e\u591a\u6e90\u4fe1\u606f\u805a\u5408\uff0c\u7f3a\u4e4f\u7edf\u4e00\uff1b3\uff09\u4f9d\u8d56\u9759\u6001\u7b54\u6848\u96c6\uff0c\u5bb9\u6613\u53d7\u5230\u6570\u636e\u6c61\u67d3\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86GISA\u57fa\u51c6\uff0c\u5305\u542b373\u4e2a\u4eba\u5de5\u6784\u5efa\u7684\u771f\u5b9e\u4fe1\u606f\u641c\u7d22\u573a\u666f\u67e5\u8be2\u3002\u7279\u5f81\u5305\u62ec\uff1a\u56db\u79cd\u7ed3\u6784\u5316\u7b54\u6848\u683c\u5f0f\uff08\u9879\u76ee\u3001\u96c6\u5408\u3001\u5217\u8868\u3001\u8868\u683c\uff09\u4ee5\u5b9e\u73b0\u786e\u5b9a\u6027\u8bc4\u4f30\uff1b\u6574\u5408\u6df1\u5ea6\u63a8\u7406\u548c\u5e7f\u6cdb\u4fe1\u606f\u805a\u5408\u7684\u7edf\u4e00\u4efb\u52a1\uff1b\u5305\u542b\u5b9a\u671f\u66f4\u65b0\u7b54\u6848\u7684\u5b9e\u65f6\u5b50\u96c6\u4ee5\u62b5\u6297\u8bb0\u5fc6\uff1b\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u63d0\u4f9b\u5b8c\u6574\u7684\u4eba\u7c7b\u641c\u7d22\u8f68\u8ff9\u4f5c\u4e3a\u9ec4\u91d1\u6807\u51c6\u53c2\u8003\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u5728\u4e3b\u6d41LLM\u548c\u5546\u4e1a\u641c\u7d22\u4ea7\u54c1\u4e2d\uff0c\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u4e5f\u4ec5\u8fbe\u523019.30%\u7684\u7cbe\u786e\u5339\u914d\u5206\u6570\u3002\u5728\u9700\u8981\u590d\u6742\u89c4\u5212\u548c\u5168\u9762\u4fe1\u606f\u6536\u96c6\u7684\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "GISA\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524d\u641c\u7d22\u4ee3\u7406\u5728\u771f\u5b9e\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u89c4\u5212\u548c\u5168\u9762\u4fe1\u606f\u805a\u5408\u65b9\u9762\uff0c\u8868\u660e\u672a\u6765\u6709\u5de8\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2602.08339", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08339", "abs": "https://arxiv.org/abs/2602.08339", "authors": ["Chengyi Du", "Yazhe Niu", "Dazhong Shen", "Luxin Xu"], "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT", "comment": "16 pages 6 figures", "summary": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.", "AI": {"tldr": "CoTZero\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u6ce8\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\u548c\u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\uff0c\u63d0\u5347\u6a21\u578b\u7684\u5c42\u6b21\u5316\u63a8\u7406\u548c\u6cdb\u5316\u80fd\u529b", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u903b\u8f91\u4e00\u81f4\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u5bfc\u81f4\u9519\u5931\u9ad8\u5c42\u8bed\u4e49\u7ed3\u6784\u548c\u975e\u56e0\u679c\u5173\u7cfb\u7406\u89e3\uff0c\u9650\u5236\u4e86\u7ec4\u5408\u6027\u548c\u53ef\u9a8c\u8bc1\u63a8\u7406\u80fd\u529b", "method": "\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a(1) \u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\uff1a\u81ea\u4e0b\u800c\u4e0a\u63d0\u53d6\u539f\u5b50\u89c6\u89c9\u57fa\u5143\u5e76\u7ec4\u5408\u6210\u7ed3\u6784\u5316\u95ee\u9898\u63a8\u7406\u5f62\u5f0f\uff0c\u81ea\u4e0a\u800c\u4e0b\u4f7f\u7528\u5168\u5c40\u7ed3\u6784\u6307\u5bfc\u5c40\u90e8\u7ec6\u8282\u548c\u56e0\u679c\u5173\u7cfb\u7684\u89e3\u91ca\uff1b(2) \u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\uff1a\u5728\u5408\u6210CoT\u6570\u636e\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\u4e2d\u7684\u8ba4\u77e5\u4e00\u81f4\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u63d0\u4f9b\u63a8\u7406\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u6b63\u786e\u6027\u7684\u9010\u6b65\u53cd\u9988", "result": "\u5728\u5305\u542b\u8bcd\u6c47\u6270\u52a8\u8d1f\u4f8b\u7684\u591a\u5c42\u6b21\u8bed\u4e49\u4e0d\u4e00\u81f4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoTZero\u5728\u57df\u5185\u548c\u57df\u5916\u8bbe\u7f6e\u4e0b\u8fbe\u523083.33%\u7684F1\u5206\u6570\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u5404\u7ec4\u4ef6\u5bf9\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u4eba\u7c7b\u5bf9\u9f50\u89c6\u89c9\u63a8\u7406\u7684\u8d21\u732e", "conclusion": "CoTZero\u901a\u8fc7\u5f15\u5165\u4eba\u7c7b\u8ba4\u77e5\u6a21\u578b\u5230\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u8868\u793a\u548c\u903b\u8f91\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u89e3\u91ca\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b"}}
{"id": "2602.07588", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07588", "abs": "https://arxiv.org/abs/2602.07588", "authors": ["Ziyang Yu", "Wenbing Huang", "Yang Liu"], "title": "Unified Biomolecular Trajectory Generation via Pretrained Variational Bridge", "comment": "The Fourteenth International Conference on Learning Representations (ICLR 2026)", "summary": "Molecular Dynamics (MD) simulations provide a fundamental tool for characterizing molecular behavior at full atomic resolution, but their applicability is severely constrained by the computational cost. To address this, a surge of deep generative models has recently emerged to learn dynamics at coarsened timesteps for efficient trajectory generation, yet they either generalize poorly across systems or, due to limited molecular diversity of trajectory data, fail to fully exploit structural information to improve generative fidelity. Here, we present the Pretrained Variational Bridge (PVB) in an encoder-decoder fashion, which maps the initial structure into a noised latent space and transports it toward stage-specific targets through augmented bridge matching. This unifies training on both single-structure and paired trajectory data, enabling consistent use of cross-domain structural knowledge across training stages. Moreover, for protein-ligand complexes, we further introduce a reinforcement learning-based optimization via adjoint matching that speeds progression toward the holo state, which supports efficient post-optimization of docking poses. Experiments on proteins and protein-ligand complexes demonstrate that PVB faithfully reproduces thermodynamic and kinetic observables from MD while delivering stable and efficient generative dynamics.", "AI": {"tldr": "PVB\u662f\u4e00\u79cd\u9884\u8bad\u7ec3\u53d8\u5206\u6865\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u548c\u589e\u5f3a\u6865\u5339\u914d\uff0c\u7edf\u4e00\u5355\u7ed3\u6784\u548c\u914d\u5bf9\u8f68\u8ff9\u6570\u636e\u8bad\u7ec3\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u8981\u4e48\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u8981\u4e48\u56e0\u8f68\u8ff9\u6570\u636e\u5206\u5b50\u591a\u6837\u6027\u6709\u9650\u800c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u6765\u63d0\u9ad8\u751f\u6210\u4fdd\u771f\u5ea6\u3002", "method": "\u63d0\u51fa\u9884\u8bad\u7ec3\u53d8\u5206\u6865(PVB)\u6a21\u578b\uff0c\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5c06\u521d\u59cb\u7ed3\u6784\u6620\u5c04\u5230\u566a\u58f0\u6f5c\u7a7a\u95f4\uff0c\u901a\u8fc7\u589e\u5f3a\u6865\u5339\u914d\u5c06\u5176\u4f20\u8f93\u5230\u9636\u6bb5\u7279\u5b9a\u76ee\u6807\u3002\u5bf9\u4e8e\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\uff0c\u8fdb\u4e00\u6b65\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f34\u968f\u5339\u914d\u4f18\u5316\uff0c\u52a0\u901f\u5411holo\u72b6\u6001\u7684\u8fdb\u5c55\u3002", "result": "\u5728\u86cb\u767d\u8d28\u548c\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPVB\u80fd\u591f\u5fe0\u5b9e\u5730\u91cd\u73b0MD\u7684\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\u89c2\u6d4b\u7ed3\u679c\uff0c\u540c\u65f6\u63d0\u4f9b\u7a33\u5b9a\u9ad8\u6548\u7684\u751f\u6210\u52a8\u529b\u5b66\uff0c\u652f\u6301\u5bf9\u63a5\u59ff\u6001\u7684\u9ad8\u6548\u540e\u4f18\u5316\u3002", "conclusion": "PVB\u901a\u8fc7\u7edf\u4e00\u5355\u7ed3\u6784\u548c\u914d\u5bf9\u8f68\u8ff9\u6570\u636e\u8bad\u7ec3\uff0c\u5145\u5206\u5229\u7528\u8de8\u57df\u7ed3\u6784\u77e5\u8bc6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u751f\u6210\uff0c\u4e3a\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u5bf9\u63a5\u59ff\u6001\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.08548", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08548", "abs": "https://arxiv.org/abs/2602.08548", "authors": ["Xuanliang Zhang", "Dingzirui Wang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che"], "title": "How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u6fc0\u6d3b\u4fee\u8865\u7b49\u6280\u672f\uff0c\u63ed\u793a\u4e86LLM\u5904\u7406\u8868\u683c\u7684\u673a\u5236\uff1a\u5c06\u8868\u683c\u7406\u89e3\u5206\u89e3\u4e3a\u8bed\u4e49\u7ed1\u5b9a\u3001\u5750\u6807\u5b9a\u4f4d\u548c\u4fe1\u606f\u63d0\u53d6\u4e09\u4e2a\u9636\u6bb5\uff0c\u53d1\u73b0\u6a21\u578b\u901a\u8fc7\u8ba1\u6570\u5206\u9694\u7b26\u6765\u5b9a\u4f4d\u5355\u5143\u683c\uff0c\u5217\u7d22\u5f15\u7f16\u7801\u5728\u7ebf\u6027\u5b50\u7a7a\u95f4\u4e2d\uff0c\u591a\u5355\u5143\u683c\u4efb\u52a1\u590d\u7528\u76f8\u540c\u6ce8\u610f\u529b\u5934\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u8868\u683c\u76f8\u5173\u4efb\u52a1\uff0c\u4f46\u5b83\u4eec\u5904\u7406\u7ebf\u6027\u5316\u4e8c\u7ef4\u7ed3\u6784\u5316\u8868\u683c\u7684\u5185\u90e8\u673a\u5236\u4ecd\u7136\u4e0d\u900f\u660e\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793aLLM\u7406\u89e3\u8868\u683c\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u3002", "method": "\u901a\u8fc7\u6fc0\u6d3b\u4fee\u8865\uff08activation patching\uff09\u548c\u4e92\u8865\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5c06\u8868\u683c\u7406\u89e3\u673a\u5236\u5206\u89e3\u4e3a\u539f\u5b50\u4efb\u52a1\u2014\u2014\u5355\u5143\u683c\u5b9a\u4f4d\uff0c\u5e76\u5206\u6790\u5176\u5185\u90e8\u5904\u7406\u8fc7\u7a0b\u3002", "result": "\u53d1\u73b0\u8868\u683c\u7406\u89e3\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u987a\u5e8f\u7ba1\u9053\uff1a1\uff09\u8bed\u4e49\u7ed1\u5b9a\uff1b2\uff09\u5750\u6807\u5b9a\u4f4d\uff08\u901a\u8fc7\u8ba1\u6570\u79bb\u6563\u5206\u9694\u7b26\u89e3\u6790\u5750\u6807\uff09\uff1b3\uff09\u4fe1\u606f\u63d0\u53d6\u3002\u5217\u7d22\u5f15\u7f16\u7801\u5728\u7ebf\u6027\u5b50\u7a7a\u95f4\u4e2d\uff0c\u53ef\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u7cbe\u786e\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u3002\u591a\u5355\u5143\u683c\u5b9a\u4f4d\u4efb\u52a1\u590d\u7528\u539f\u5b50\u5b9a\u4f4d\u4e2d\u8bc6\u522b\u7684\u76f8\u540c\u6ce8\u610f\u529b\u5934\u3002", "conclusion": "\u7814\u7a76\u4e3aTransformer\u67b6\u6784\u4e2d\u7684\u8868\u683c\u7406\u89e3\u63d0\u4f9b\u4e86\u5168\u9762\u89e3\u91ca\uff0c\u63ed\u793a\u4e86LLM\u5904\u7406\u7ed3\u6784\u5316\u8868\u683c\u7684\u5185\u90e8\u673a\u5236\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5206\u9694\u7b26\u8ba1\u6570\u548c\u7ebf\u6027\u5b50\u7a7a\u95f4\u7f16\u7801\u6765\u5b9e\u73b0\u5750\u6807\u5b9a\u4f4d\u3002"}}
{"id": "2602.08340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08340", "abs": "https://arxiv.org/abs/2602.08340", "authors": ["Hoang Dang", "Luan Pham", "Minh Nguyen"], "title": "Effect-Level Validation for Causal Discovery", "comment": null, "summary": "Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ee5\u6548\u5e94\u4e3a\u4e2d\u5fc3\u3001\u53ef\u91c7\u7eb3\u6027\u4f18\u5148\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u5f3a\u8c03\u5728\u5f3a\u81ea\u9009\u62e9\u7cfb\u7edf\u4e2d\uff0c\u56fe\u6062\u590d\u51c6\u786e\u6027\u4e0d\u8db3\u4ee5\u652f\u6301\u51b3\u7b56\uff0c\u9700\u8981\u4f18\u5148\u8003\u8651\u53ef\u91c7\u7eb3\u6027\u548c\u6548\u5e94\u5c42\u9762\u7684\u9a8c\u8bc1\u3002", "motivation": "\u5927\u89c4\u6a21\u9065\u6d4b\u6570\u636e\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u8bc4\u4f30\u7528\u6237\u5e72\u9884\u6548\u679c\uff0c\u4f46\u5728\u5f3a\u81ea\u9009\u62e9\u53cd\u9988\u9a71\u52a8\u7cfb\u7edf\u4e2d\uff0c\u5176\u51b3\u7b56\u53ef\u9760\u6027\u4ecd\u4e0d\u660e\u786e\u3002\u9700\u8981\u8d85\u8d8a\u56fe\u6062\u590d\u51c6\u786e\u6027\uff0c\u5efa\u7acb\u66f4\u53ef\u9760\u7684\u56e0\u679c\u63a8\u7406\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u6548\u5e94\u4e2d\u5fc3\u3001\u53ef\u91c7\u7eb3\u6027\u4f18\u5148\u6846\u67b6\uff0c\u5c06\u53d1\u73b0\u7684\u56fe\u89c6\u4e3a\u7ed3\u6784\u5047\u8bbe\uff0c\u901a\u8fc7\u53ef\u8bc6\u522b\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8bc1\u4f2a\u6027\u8fdb\u884c\u8bc4\u4f30\u3002\u4f7f\u7528\u771f\u5b9e\u6e38\u620f\u9065\u6d4b\u6570\u636e\u7814\u7a76\u65e9\u671f\u7ade\u4e89\u6027\u6e38\u620f\u5bf9\u77ed\u671f\u7559\u5b58\u7684\u5f71\u54cd\u3002", "result": "\u8bb8\u591a\u7edf\u8ba1\u4e0a\u5408\u7406\u7684\u53d1\u73b0\u8f93\u51fa\u5728\u65bd\u52a0\u6700\u5c0f\u65f6\u95f4\u548c\u8bed\u4e49\u7ea6\u675f\u540e\u65e0\u6cd5\u8fdb\u884c\u70b9\u8bc6\u522b\u56e0\u679c\u67e5\u8be2\u3002\u5f53\u8bc6\u522b\u53ef\u884c\u65f6\uff0c\u4e0d\u540c\u7b97\u6cd5\u5bb6\u65cf\u5c3d\u7ba1\u4ea7\u751f\u4e0d\u540c\u56fe\u7ed3\u6784\uff0c\u4f46\u6536\u655b\u5230\u76f8\u4f3c\u7684\u51b3\u7b56\u4e00\u81f4\u6548\u5e94\u4f30\u8ba1\u3002\u8fd9\u4e9b\u4f30\u8ba1\u901a\u8fc7\u4e86\u5b89\u6170\u5242\u3001\u5b50\u62bd\u6837\u548c\u654f\u611f\u6027\u8bc1\u4f2a\u68c0\u9a8c\u3002", "conclusion": "\u56fe\u5c42\u9762\u6307\u6807\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u7279\u5b9a\u76ee\u6807\u67e5\u8be2\u56e0\u679c\u53ef\u9760\u6027\u7684\u4ee3\u7406\u3002\u5728\u9065\u6d4b\u9a71\u52a8\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4fe1\u7684\u56e0\u679c\u7ed3\u8bba\u9700\u8981\u4f18\u5148\u8003\u8651\u53ef\u91c7\u7eb3\u6027\u548c\u6548\u5e94\u5c42\u9762\u9a8c\u8bc1\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u56e0\u679c\u7ed3\u6784\u6062\u590d\u3002"}}
{"id": "2602.08600", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08600", "abs": "https://arxiv.org/abs/2602.08600", "authors": ["Archchana Sindhujan", "Girish A. Koushik", "Shenbin Qian", "Diptesh Kanojia", "Constantin Or\u0103san"], "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation", "comment": "Currently this article is under review for Natural Language Processing Journal", "summary": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86ALOPE-RL\u6846\u67b6\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u9519\u8bef\u611f\u77e5\u5956\u52b1\uff0c\u7528\u4e8e\u82f1\u8bed-\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u8d28\u91cf\u8bc4\u4f30\uff0c\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6807\u91cf\u5206\u6570\uff0c\u7f3a\u4e4f\u5bf9\u7ffb\u8bd1\u9519\u8bef\u7684\u660e\u786e\u89e3\u91ca\uff1b\u5bf9\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\uff09\uff0c\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u4e0d\u53ef\u9760\u3002", "method": "1) \u521b\u5efa\u9996\u4e2a\u82f1\u8bed-\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u5206\u6bb5\u7ea7QE\u6570\u636e\u96c6\uff0c\u5305\u542b\u76f4\u63a5\u8bc4\u4f30\u5206\u6570\u548c\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u6ce8\uff1b2) \u63d0\u51faALOPE-RL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u57fa\u4e8e\u7b56\u7565\u5956\u52b1\u8bad\u7ec3\u9ad8\u6548\u9002\u914d\u5668\uff0c\u7ed3\u5408\u9519\u8bef\u611f\u77e5\u5956\u52b1\u4f7fLLM\u80fd\u8d85\u8d8a\u6570\u503c\u5206\u6570\u63a8\u7406\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "ALOPE-RL\u5728\u5c0f\u89c4\u6a21QE\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u4f7f\u7528\u7d27\u51d1LLM\uff08\u22644B\u53c2\u6570\uff09\u914d\u5408LoRA\u548c4\u4f4d\u91cf\u5316\uff0c\u5728\u82f1\u8bed-\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bedQE\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u8d85\u8d8a\u66f4\u5927LLM\u57fa\u7ebf\u548c\u9886\u5148\u7684\u7f16\u7801\u5668\u57faQE\u6a21\u578b\u3002", "conclusion": "\u9519\u8bef\u611f\u77e5\u7684\u7b56\u7565\u5b66\u4e60\u80fd\u5728\u6709\u9650\u6570\u636e\u548c\u8ba1\u7b97\u9884\u7b97\u4e0b\u63d0\u4f9b\u5f3a\u5927\u7684QE\u6027\u80fd\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08344", "abs": "https://arxiv.org/abs/2602.08344", "authors": ["Qi Guo", "Jianing Wang", "Deyang Kong", "Xiangyu Xi", "Jianfei Zhang", "Yi Lu", "Jingang Wang", "Wei Wang", "Shikun Zhang", "Wei Ye"], "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration", "comment": null, "summary": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOutline-Guided Path Exploration (OPE)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5148\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\u6765\u5212\u5206\u89e3\u7a7a\u95f4\uff0c\u51cf\u5c11\u5e76\u884c\u63a8\u7406\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\uff0c\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u601d\u7ef4\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u805a\u5408\u9636\u6bb5\u4f18\u5316\uff0c\u5bf9\u8def\u5f84\u63a2\u7d22\u9636\u6bb5\u5173\u6ce8\u4e0d\u8db3\u3002\u7814\u7a76\u53d1\u73b0\u63a2\u7d22\u8def\u5f84\u95f4\u7684\u4e92\u4fe1\u606f\u74f6\u9888\u9650\u5236\u4e86\u6574\u4f53\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\u95ee\u9898\u3002", "method": "\u63d0\u51faOPE\u65b9\u6cd5\uff1a1\uff09\u5148\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\u6765\u5212\u5206\u89e3\u7a7a\u95f4\uff1b2\uff09\u91c7\u7528\u8fed\u4ee3RL\u7b56\u7565\u5206\u522b\u4f18\u5316\u5927\u7eb2\u89c4\u5212\u548c\u57fa\u4e8e\u5927\u7eb2\u7684\u63a8\u7406\uff1b3\uff09\u5728RLVR\u8bbe\u7f6e\u4e0b\u51cf\u5c11\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOPE\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u540c\u805a\u5408\u7b56\u7565\u4e0b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u66f4\u53ef\u9760\u5730\u53d1\u73b0\u6b63\u786e\u89e3\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5212\u5206\u89e3\u7a7a\u95f4\u548c\u51cf\u5c11\u8def\u5f84\u95f4\u4fe1\u606f\u5197\u4f59\uff0cOPE\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5e76\u884c\u601d\u7ef4\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u63a8\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2602.07596", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07596", "abs": "https://arxiv.org/abs/2602.07596", "authors": ["Xi Chen", "Ming Li", "Junxi Li", "Changsheng Li", "Peisong Wang", "Lizhong Ding", "Ye Yuan", "Guoren Wang"], "title": "Astro: Activation-guided Structured Regularization for Outlier-Robust LLM Post-Training Quantization", "comment": null, "summary": "Weight-only post-training quantization (PTQ) is crucial for efficient Large Language Model (LLM) deployment but suffers from accuracy degradation caused by weight and activation outliers. Existing mitigation strategies often face critical limitations: they either yield insufficient outlier suppression or incur significant deployment inefficiencies, such as inference latency, heavy preprocessing, or reliance on complex operator fusion. To resolve these limitations, we leverage a key insight: over-parameterized LLMs often converge to Flat Minima, implying a vast equivalent solution space where weights can be adjusted without compromising accuracy. Building on this, we propose Astro, an Activation-guided Structured Regularization framework designed to suppress the negative effects of outliers in a hardware-friendly and efficient manner. Leveraging the activation-guided regularization objective, Astro actively reconstructs intrinsically robust weights, aggressively suppressing weight outliers corresponding to high-magnitude activations without sacrificing model accuracy. Crucially, Astro introduces zero inference latency and is orthogonal to mainstream quantization methods like GPTQ. Extensive experiments show that Astro achieves highly competitive performance; notably, on LLaMA-2-7B, it achieves better performance than complex learning-based rotation methods with almost 1/3 of the quantization time.", "AI": {"tldr": "Astro\u662f\u4e00\u79cd\u6fc0\u6d3b\u5f15\u5bfc\u7684\u7ed3\u6784\u5316\u6b63\u5219\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6291\u5236LLM\u91cf\u5316\u4e2d\u7684\u6743\u91cd\u548c\u6fc0\u6d3b\u5f02\u5e38\u503c\uff0c\u5b9e\u73b0\u96f6\u63a8\u7406\u5ef6\u8fdf\u7684\u9ad8\u6548\u540e\u8bad\u7ec3\u91cf\u5316", "motivation": "\u73b0\u6709\u7684\u6743\u91cd\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u9762\u4e34\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6743\u91cd\u548c\u6fc0\u6d3b\u4e2d\u7684\u5f02\u5e38\u503c\u3002\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u8981\u4e48\u6291\u5236\u6548\u679c\u4e0d\u8db3\uff0c\u8981\u4e48\u5bfc\u81f4\u663e\u8457\u7684\u90e8\u7f72\u6548\u7387\u95ee\u9898\uff08\u5982\u63a8\u7406\u5ef6\u8fdf\u3001\u7e41\u91cd\u9884\u5904\u7406\u6216\u4f9d\u8d56\u590d\u6742\u7b97\u5b50\u878d\u5408\uff09", "method": "\u57fa\u4e8e\u8fc7\u53c2\u6570\u5316LLM\u901a\u5e38\u6536\u655b\u5230\u5e73\u5766\u6700\u5c0f\u503c\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u63d0\u51faAstro\u6846\u67b6\u3002\u5229\u7528\u6fc0\u6d3b\u5f15\u5bfc\u7684\u6b63\u5219\u5316\u76ee\u6807\uff0c\u4e3b\u52a8\u91cd\u6784\u5185\u5728\u9c81\u68d2\u7684\u6743\u91cd\uff0c\u5728\u4e0d\u727a\u7272\u6a21\u578b\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u79ef\u6781\u6291\u5236\u5bf9\u5e94\u9ad8\u5e45\u5ea6\u6fc0\u6d3b\u7684\u6743\u91cd\u5f02\u5e38\u503c", "result": "\u5728LLaMA-2-7B\u4e0a\uff0cAstro\u5b9e\u73b0\u4e86\u6bd4\u590d\u6742\u5b66\u4e60\u578b\u65cb\u8f6c\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4e14\u91cf\u5316\u65f6\u95f4\u4ec5\u4e3a\u540e\u8005\u7684\u7ea61/3\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u96f6\u63a8\u7406\u5ef6\u8fdf\uff0c\u4e14\u4e0e\u4e3b\u6d41\u91cf\u5316\u65b9\u6cd5\uff08\u5982GPTQ\uff09\u6b63\u4ea4", "conclusion": "Astro\u901a\u8fc7\u6fc0\u6d3b\u5f15\u5bfc\u7684\u7ed3\u6784\u5316\u6b63\u5219\u5316\u6709\u6548\u89e3\u51b3\u4e86LLM\u540e\u8bad\u7ec3\u91cf\u5316\u4e2d\u7684\u5f02\u5e38\u503c\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u786c\u4ef6\u53cb\u597d\u7684\u9ad8\u6548\u90e8\u7f72"}}
{"id": "2602.08607", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08607", "abs": "https://arxiv.org/abs/2602.08607", "authors": ["Ziyang Cheng", "Yuhao Wang", "Heyang Liu", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling", "comment": null, "summary": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.", "AI": {"tldr": "VocalNet-MDM\uff1a\u57fa\u4e8e\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u975e\u81ea\u56de\u5f52\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u5757\u63a9\u7801\u548c\u8fed\u4ee3\u81ea\u84b8\u998f\u6280\u672f\uff0c\u5728\u4ec56K\u5c0f\u65f6\u6570\u636e\u4e0a\u5b9e\u73b03.7-10\u500d\u89e3\u7801\u52a0\u901f\u548c34%\u9996\u5757\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u5f53\u524d\u81ea\u56de\u5f52\u8bed\u97f3LLMs\u5b58\u5728\u4e32\u884c\u7ea6\u675f\u9650\u5236\u751f\u6210\u6548\u7387\u3001\u5f15\u5165\u66dd\u5149\u504f\u5dee\u7684\u95ee\u9898\uff0c\u9700\u8981\u63a2\u7d22\u975e\u81ea\u56de\u5f52\u8303\u5f0f\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u9ad8\u6548\u7684\u8bed\u97f3\u4ea4\u4e92\u3002", "method": "\u63d0\u51faVocalNet-MDM\uff1a1\uff09\u5206\u5c42\u5757\u63a9\u7801\u5bf9\u9f50\u8bad\u7ec3\u76ee\u6807\u4e0e\u5757\u6269\u6563\u89e3\u7801\u4e2d\u7684\u6e10\u8fdb\u63a9\u7801\u72b6\u6001\uff1b2\uff09\u8fed\u4ee3\u81ea\u84b8\u998f\u5c06\u591a\u6b65\u4f18\u5316\u538b\u7f29\u4e3a\u66f4\u5c11\u6b65\u9aa4\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u63a8\u7406\u3002", "result": "\u5728\u4ec56K\u5c0f\u65f6\u8bed\u97f3\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u5b9e\u73b03.7-10\u500d\u89e3\u7801\u52a0\u901f\uff0c\u9996\u5757\u5ef6\u8fdf\u964d\u4f4e34%\uff0c\u4fdd\u6301\u7ade\u4e89\u6027\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u8fbe\u5230SOTA\u6587\u672c\u8d28\u91cf\u548c\u8bed\u97f3\u81ea\u7136\u5ea6\u3002", "conclusion": "\u63a9\u7801\u6269\u6563\u6a21\u578b\u662f\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u6548\u8bed\u97f3LLMs\u7684\u6709\u524d\u666f\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.08353", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08353", "abs": "https://arxiv.org/abs/2602.08353", "authors": ["Zhang Jiasheng", "Li Zhangpin", "Wang Mingzhe", "Shao Jie", "Cui Jiangtao", "Li Hui"], "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs", "comment": "13 pages, 11 figures", "summary": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.", "AI": {"tldr": "\u73b0\u6709TKG\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u4ec5\u901a\u8fc7\u5171\u73b0\u7edf\u8ba1\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1SOTA\u7684\u6027\u80fd\uff0c\u65e0\u9700\u5229\u7528\u65f6\u5e8f\u4fe1\u606f\uff0c\u63ed\u793a\u4e86\u6570\u636e\u96c6\u504f\u89c1\u548c\u8bc4\u4f30\u4efb\u52a1\u8fc7\u4e8e\u7b80\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u53d1\u73b0\u73b0\u6709\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u5373\u4f7f\u4e0d\u4f7f\u7528\u4efb\u4f55\u65f6\u5e8f\u4fe1\u606f\uff0c\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5171\u73b0\u5173\u7cfb\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u5f53\u524d\u8bc4\u4f30\u4f53\u7cfb\u65e0\u6cd5\u771f\u6b63\u8861\u91cf\u6a21\u578b\u5bf9\u65f6\u5e8f\u6f14\u5316\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u6df1\u5165\u5206\u6790\u73b0\u6709\u57fa\u51c6\u95ee\u9898\u7684\u6839\u6e90\uff0c\u8bc6\u522b\u51fa\u6570\u636e\u96c6\u7684\u5185\u5728\u504f\u89c1\u548c\u8bc4\u4f30\u4efb\u52a1\u7684\u8fc7\u5ea6\u7b80\u5316\u5f62\u5f0f\uff1b\u8fdb\u4e00\u6b65\u63ed\u793a\u73b0\u6709\u57fa\u51c6\u7684\u5176\u4ed6\u5c40\u9650\u6027\uff0c\u5305\u62ec\u65f6\u95f4\u95f4\u9694\u77e5\u8bc6\u7684\u4e0d\u5408\u7406\u683c\u5f0f\u5316\u3001\u5ffd\u7565\u77e5\u8bc6\u8fc7\u65f6\u6027\u5b66\u4e60\u3001\u4ee5\u53ca\u6f14\u5316\u7406\u89e3\u4fe1\u606f\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86TKG\u6f14\u5316\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u7ecf\u8fc7\u504f\u89c1\u6821\u6b63\u7684\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u4e0e\u6f14\u5316\u8fc7\u7a0b\u7d27\u5bc6\u5bf9\u9f50\u7684\u65b0\u4efb\u52a1\uff0c\u65e8\u5728\u4fc3\u8fdb\u5bf9TKG\u6f14\u5316\u5efa\u6a21\u6311\u6218\u7684\u66f4\u51c6\u786e\u7406\u89e3\u3002", "conclusion": "\u73b0\u6709TKG\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u65e0\u6cd5\u516c\u5e73\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff1b\u63d0\u51fa\u7684\u65b0\u57fa\u51c6\u901a\u8fc7\u7ea0\u6b63\u6570\u636e\u96c6\u504f\u89c1\u548c\u8bbe\u8ba1\u66f4\u5408\u7406\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u4e3a\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u6f14\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.07599", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07599", "abs": "https://arxiv.org/abs/2602.07599", "authors": ["Mehryar Mohri"], "title": "Rational Transductors", "comment": null, "summary": "Standard Transformers excel at semantic modeling but struggle with\n  rigid sequential logic and state tracking. Theoretical work\n  establishes that self-attention is limited to $\\AC^0$ (under hard\n  attention) or $\\TC^0$ (under soft attention), complexity classes\n  that often fail to support robust length generalization on\n  sequential problems without intermediate chain-of-thought. In this\n  work, we introduce \\emph{Rational Transductors}, a dual-stream\n  architecture that augments the Transformer with a matrix-valued\n  recurrence derived from Weighted Finite Automata (WFA). By\n  injecting rational state information into the attention mechanism\n  via a \\emph{Deep Rational Injection} scheme, our framework strictly\n  generalizes the expressive power of Transformers to capture all\n  Regular Languages, $\\NC^1$-complete problems (such as Boolean\n  Formula Evaluation), and fundamental separations like Parity and\n  Modular Counting, while preserving $O(L + \\log T)$ parallel time\n  complexity. We ground the architecture in a rigorous learning\n  theory: we prove that \\emph{Random Rational Features} act as a\n  universal basis for sequential dependencies, justifying our\n  initialization strategy, while establishing that the\n  \\emph{Differentiable Rational Feature} regime is necessary to close\n  the representational compactness gap. Theoretical analysis and\n  empirical results demonstrate that Rational Transductors solve the\n  \"Regular Gap,\" enabling robust length generalization on algorithmic\n  tasks where standard Transformers fail, without the sequential\n  computational bottlenecks of traditional RNNs.", "AI": {"tldr": "\u63d0\u51faRational Transductors\u67b6\u6784\uff0c\u901a\u8fc7\u52a0\u6743\u6709\u9650\u81ea\u52a8\u673a\u7684\u77e9\u9635\u9012\u5f52\u589e\u5f3aTransformer\uff0c\u4f7f\u5176\u80fd\u5904\u7406\u6b63\u5219\u8bed\u8a00\u548cNC\u00b9\u5b8c\u5168\u95ee\u9898\uff0c\u89e3\u51b3Transformer\u5728\u987a\u5e8f\u903b\u8f91\u4e0a\u7684\u957f\u5ea6\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u6807\u51c6Transformer\u64c5\u957f\u8bed\u4e49\u5efa\u6a21\uff0c\u4f46\u5728\u521a\u6027\u987a\u5e8f\u903b\u8f91\u548c\u72b6\u6001\u8ddf\u8e2a\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u7406\u8bba\u7814\u7a76\u8868\u660e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u590d\u6742\u5ea6\u4e0a\u6709\u9650\u5236\uff08AC\u2070\u6216TC\u2070\uff09\uff0c\u65e0\u6cd5\u5728\u6ca1\u6709\u601d\u7ef4\u94fe\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7a33\u5065\u7684\u957f\u5ea6\u6cdb\u5316\u3002", "method": "\u5f15\u5165Rational Transductors\u53cc\u6d41\u67b6\u6784\uff0c\u901a\u8fc7\u52a0\u6743\u6709\u9650\u81ea\u52a8\u673a\u7684\u77e9\u9635\u9012\u5f52\u589e\u5f3aTransformer\uff0c\u91c7\u7528\u6df1\u5ea6\u6709\u7406\u6ce8\u5165\u65b9\u6848\u5c06\u6709\u7406\u72b6\u6001\u4fe1\u606f\u6ce8\u5165\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u7528\u968f\u673a\u6709\u7406\u7279\u5f81\u4f5c\u4e3a\u521d\u59cb\u5316\u7b56\u7565\u3002", "result": "\u8be5\u6846\u67b6\u4e25\u683c\u6269\u5c55\u4e86Transformer\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u6355\u83b7\u6240\u6709\u6b63\u5219\u8bed\u8a00\u3001NC\u00b9\u5b8c\u5168\u95ee\u9898\uff08\u5982\u5e03\u5c14\u516c\u5f0f\u6c42\u503c\uff09\u4ee5\u53ca\u5947\u5076\u6027\u548c\u6a21\u8ba1\u6570\u7b49\u57fa\u672c\u5206\u79bb\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301O(L + log T)\u5e76\u884c\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "Rational Transductors\u89e3\u51b3\u4e86\"\u6b63\u5219\u95f4\u9699\"\uff0c\u5728\u6807\u51c6Transformer\u5931\u8d25\u7684\u7b97\u6cd5\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u957f\u5ea6\u6cdb\u5316\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4f20\u7edfRNN\u7684\u987a\u5e8f\u8ba1\u7b97\u74f6\u9888\uff0c\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u5747\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.08625", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08625", "abs": "https://arxiv.org/abs/2602.08625", "authors": ["Muhammad Naufil"], "title": "Do Multilingual LLMs have specialized language heads?", "comment": null, "summary": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u6709\u8bed\u8a00\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u5c1d\u8bd5\u79fb\u9664\u4e0d\u9700\u8981\u7684\u8bed\u8a00\u5934\u800c\u4e0d\u5f71\u54cd\u76ee\u6807\u8bed\u8a00\u6027\u80fd\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u90e8\u7f72\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u4ea7\u90e8\u7f72\u4e2d\u6548\u7387\u4f4e\u4e0b\uff0c\u7279\u522b\u662f\u5f53\u53ea\u9700\u8981\u652f\u6301\u90e8\u5206\u8bed\u8a00\u65f6\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u7684\u8bed\u8a00\u7279\u5b9a/\u8bed\u8a00\u65e0\u5173\u5934\uff0c\u4f46\u9488\u5bf9\u80fd\u6267\u884c\u591a\u6837\u5316\u4efb\u52a1\u7684\u591a\u8bed\u8a00LLMs\u7684\u7814\u7a76\u5c1a\u5c5e\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u591a\u8bed\u8a00LLMs\u662f\u5426\u5177\u6709\u4e13\u95e8\u7684\u8bed\u8a00\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u8c03\u67e5\u79fb\u9664\u4e0d\u9700\u8981\u7684\u8bed\u8a00\u7279\u5b9a\u5934\u800c\u4e0d\u964d\u4f4e\u76ee\u6807\u8bed\u8a00\u6027\u80fd\u7684\u53ef\u80fd\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53ef\u80fd\u4e3a\u591a\u8bed\u8a00LLMs\u7684\u66f4\u9ad8\u6548\u90e8\u7f72\u7b56\u7565\u63d0\u4f9b\u4fe1\u606f\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u76ee\u6807\u8bed\u8a00\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u79fb\u9664\u4e0d\u9700\u8981\u7684\u8bed\u8a00\u7279\u5b9a\u6ce8\u610f\u529b\u5934\uff0c\u53ef\u4ee5\u5b9e\u73b0\u591a\u8bed\u8a00LLMs\u7684\u66f4\u9ad8\u6548\u90e8\u7f72\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u540c\u65f6\u4fdd\u6301\u76ee\u6807\u8bed\u8a00\u6027\u80fd\u3002"}}
{"id": "2602.08354", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08354", "abs": "https://arxiv.org/abs/2602.08354", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuanda Wang", "Zhixia Zhang", "Hongyan Xie", "Songshi Liang", "Zehao Chen", "Xuefeng Xiao", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?", "comment": null, "summary": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.", "AI": {"tldr": "SAGE\u662f\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u8303\u5f0f\uff0c\u901a\u8fc7\u91ca\u653e\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u505c\u6b62\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\u4f7f\u7528\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u5b58\u5728\u5927\u91cf\u5197\u4f59\uff0c\u635f\u5bb3\u8ba1\u7b97\u6548\u7387\u5e76\u5bfc\u81f4\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u3002\u7814\u7a76\u53d1\u73b0\u66f4\u957f\u7684\u63a8\u7406\u94fe\u4e0e\u6b63\u786e\u6027\u65e0\u5173\u751a\u81f3\u6709\u5bb3\uff0c\u800c\u6a21\u578b\u5b9e\u9645\u4e0a\u9690\u542b\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u601d\u8003\uff0c\u4f46\u88ab\u5f53\u524d\u91c7\u6837\u8303\u5f0f\u6240\u63a9\u76d6\u3002", "method": "\u63d0\u51faSAGE\uff08\u81ea\u6211\u611f\u77e5\u5f15\u5bfc\u9ad8\u6548\u63a8\u7406\uff09\u91c7\u6837\u8303\u5f0f\uff0c\u91ca\u653e\u6a21\u578b\u7684\u81ea\u6211\u505c\u6b62\u80fd\u529b\u3002\u8fdb\u4e00\u6b65\u5c06SAGE\u4f5c\u4e3a\u6df7\u5408\u91c7\u6837\u96c6\u6210\u5230\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\uff08SAGE-RL\uff09\uff0c\u4f7fSAGE-RL\u80fd\u591f\u5c06SAGE\u53d1\u73b0\u7684\u9ad8\u6548\u63a8\u7406\u6a21\u5f0f\u878d\u5165\u6807\u51c6pass@1\u63a8\u7406\u3002", "result": "SAGE-RL\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u6a21\u578b\u9690\u542b\u7684\u81ea\u6211\u505c\u6b62\u80fd\u529b\u53ef\u4ee5\u901a\u8fc7SAGE\u91c7\u6837\u8303\u5f0f\u6709\u6548\u91ca\u653e\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.07602", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07602", "abs": "https://arxiv.org/abs/2602.07602", "authors": ["Gabriel Stella", "Dmitri Loguinov"], "title": "Object-Oriented Transition Modeling with Inductive Logic Programming", "comment": "46 pages, 26 figures", "summary": "Building models of the world from observation, i.e., induction, is one of the major challenges in machine learning. In order to be useful, models need to maintain accuracy when used in novel situations, i.e., generalize. In addition, they should be easy to interpret and efficient to train. Prior work has investigated these concepts in the context of object-oriented representations inspired by human cognition. In this paper, we develop a novel learning algorithm that is substantially more powerful than these previous methods. Our thorough experiments, including ablation tests and comparison with neural baselines, demonstrate a significant improvement over the state-of-the-art.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4e4b\u524d\u57fa\u4e8e\u9762\u5411\u5bf9\u8c61\u8868\u793a\u7684\u65b9\u6cd5\u663e\u8457\u66f4\u5f3a\u5927\uff0c\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u76f8\u5bf9\u4e8e\u73b0\u6709\u6280\u672f\u7684\u663e\u8457\u6539\u8fdb", "motivation": "\u4ece\u89c2\u5bdf\u4e2d\u6784\u5efa\u4e16\u754c\u6a21\u578b\uff08\u5f52\u7eb3\uff09\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e3b\u8981\u6311\u6218\u4e4b\u4e00\u3002\u6a21\u578b\u9700\u8981\u5728\u65b0\u7684\u60c5\u5883\u4e2d\u4fdd\u6301\u51c6\u786e\u6027\uff08\u6cdb\u5316\uff09\uff0c\u540c\u65f6\u6613\u4e8e\u89e3\u91ca\u4e14\u8bad\u7ec3\u9ad8\u6548\u3002\u5148\u524d\u5de5\u4f5c\u7814\u7a76\u4e86\u53d7\u4eba\u7c7b\u8ba4\u77e5\u542f\u53d1\u7684\u9762\u5411\u5bf9\u8c61\u8868\u793a\uff0c\u4f46\u9700\u8981\u66f4\u5f3a\u5927\u7684\u65b9\u6cd5", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u663e\u8457\u66f4\u5f3a\u5927\u3002\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u6d88\u878d\u6d4b\u8bd5\u548c\u4e0e\u795e\u7ecf\u57fa\u7ebf\u7684\u6bd4\u8f83", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "\u63d0\u51fa\u7684\u65b0\u5b66\u4e60\u7b97\u6cd5\u5728\u5f52\u7eb3\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u6cdb\u5316\u80fd\u529b\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u8d85\u8d8a\u4e86\u5148\u524d\u57fa\u4e8e\u9762\u5411\u5bf9\u8c61\u8868\u793a\u7684\u65b9\u6cd5"}}
{"id": "2602.08658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08658", "abs": "https://arxiv.org/abs/2602.08658", "authors": ["Mingzi Cao", "Xingwei Tan", "Mahmud Akhter", "Marco Valentino", "Maria Liakata", "Xi Wang", "Nikolaos Aletras"], "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models", "comment": null, "summary": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u6eaf\u56e0\u4e09\u79cd\u57fa\u672c\u63a8\u7406\u8303\u5f0f\u5bf9LLM\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7b26\u53f7\u4efb\u52a1\u6570\u636e\u96c6\u8bad\u7ec3LLM\uff0c\u5e76\u5728\u73b0\u5b9e\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6cdb\u5316\u6027\u80fd\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u5f88\u591a\uff0c\u4f46\u57fa\u672c\u63a8\u7406\u8303\u5f0f\uff08\u6f14\u7ece\u3001\u5f52\u7eb3\u3001\u6eaf\u56e0\uff09\u5982\u4f55\u5f71\u54cdLLM\u7684\u6cdb\u5316\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u63a2\u7d22\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u8fd9\u4e9b\u6838\u5fc3\u8303\u5f0f\u7684\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u5f71\u54cdLLM\u7684\u63a8\u7406\u884c\u4e3a\u3002", "method": "1. \u6536\u96c6\u65b0\u7684\u7b26\u53f7\u4efb\u52a1\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u4efb\u52a1\u9488\u5bf9\u4e09\u79cd\u57fa\u672c\u63a8\u7406\u8303\u5f0f\u4e4b\u4e00\uff0c\u4ee5\u62bd\u8c61\u5316\u5177\u4f53\u4e16\u754c\u77e5\u8bc6\uff1b2. \u7814\u7a76\u5c06\u8fd9\u4e9b\u6280\u80fd\u6ce8\u5165LLM\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5305\u62ec\u7b80\u5355\u5fae\u8c03\u3001\u589e\u52a0\u6a21\u578b\u6df1\u5ea6\u3001\u5c06\u5bc6\u96c6\u6a21\u578b\u8f6c\u6362\u4e3a\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u7b49\u65b9\u6cd5\uff1b3. \u5728\u5b8c\u5168\u7528\u81ea\u7136\u8bed\u8a00\u8868\u8ff0\u4e14\u5305\u542b\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u7684\u73b0\u5b9e\u8de8\u57df\u4efb\u52a1\u4e0a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u73b0\u5b9e\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\uff08\u6700\u9ad8\u8fbe14.60\u5206\uff09\u3002\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u672c\u63a8\u7406\u8303\u5f0f\u8bad\u7ec3\u5bf9LLM\u5728\u73b0\u5b9e\u4efb\u52a1\u4e2d\u6cdb\u5316\u80fd\u529b\u7684\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u8bad\u7ec3\u57fa\u672c\u63a8\u7406\u8303\u5f0f\uff08\u6f14\u7ece\u3001\u5f52\u7eb3\u3001\u6eaf\u56e0\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLM\u5728\u73b0\u5b9e\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3aLLM\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.08362", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08362", "abs": "https://arxiv.org/abs/2602.08362", "authors": ["Chunxi Ji", "Adnan Darwiche"], "title": "Circuit Representations of Random Forests with Applications to XAI", "comment": null, "summary": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7f16\u8bd1\u4e3a\u7535\u8def\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u51b3\u7b56\u89e3\u91ca\u3001\u9c81\u68d2\u6027\u548c\u6700\u77ed\u7ffb\u8f6c\u8def\u5f84", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7684\u51b3\u7b56\u89e3\u91ca\u65f6\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u751f\u6210\u53ef\u89e3\u91ca\u7684\u7535\u8def\u8868\u793a\uff0c\u4ee5\u652f\u6301\u51b3\u7b56\u5206\u6790\u3001\u9c81\u68d2\u6027\u8bc4\u4f30\u548c\u89e3\u91ca\u751f\u6210", "method": "1) \u5c06\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7f16\u8bd1\u4e3a\u7535\u8def\u96c6\uff0c\u6bcf\u4e2a\u7535\u8def\u76f4\u63a5\u7f16\u7801\u5206\u7c7b\u5668\u4e2d\u67d0\u4e2a\u7c7b\u522b\u7684\u5b9e\u4f8b\uff1b2) \u5229\u7528\u8be5\u7535\u8def\u65b9\u6cd5\u8ba1\u7b97\u51b3\u7b56\u7684\u5b8c\u6574\u548c\u4e00\u822c\u539f\u56e0\uff1b3) \u63d0\u51fa\u7b97\u6cd5\u8ba1\u7b97\u51b3\u7b56\u7684\u9c81\u68d2\u6027\u548c\u6240\u6709\u6700\u77ed\u7ffb\u8f6c\u65b9\u5f0f", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u73b0\u6709\u7c7b\u4f3c\u65b9\u6cd5\u663e\u8457\u66f4\u9ad8\u6548\uff1b\u80fd\u591f\u679a\u4e3e\u6240\u6709\u5145\u5206\u539f\u56e0\u3001\u5fc5\u8981\u539f\u56e0\u548c\u5bf9\u6bd4\u89e3\u91ca\uff1b\u8ba1\u7b97\u51b3\u7b56\u9c81\u68d2\u6027\uff1b\u8bc6\u522b\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u51b3\u7b56\u7684\u6240\u6709\u6700\u77ed\u7ffb\u8f6c\u65b9\u5f0f", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7535\u8def\u7f16\u8bd1\u6280\u672f\uff0c\u652f\u6301\u5168\u9762\u7684\u51b3\u7b56\u5206\u6790\u3001\u89e3\u91ca\u751f\u6210\u548c\u9c81\u68d2\u6027\u8bc4\u4f30\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027"}}
{"id": "2602.07603", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07603", "abs": "https://arxiv.org/abs/2602.07603", "authors": ["Woojin Cho", "Junghwan Park"], "title": "Escaping Spectral Bias without Backpropagation: Fast Implicit Neural Representations with Extreme Learning Machines", "comment": null, "summary": "Training implicit neural representations (INRs) to capture fine-scale details typically relies on iterative backpropagation and is often hindered by spectral bias when the target exhibits highly non-uniform frequency content. We propose ELM-INR, a backpropagation-free INR that decomposes the domain into overlapping subdomains and fits each local problem using an Extreme Learning Machine (ELM) in closed form, replacing iterative optimization with stable linear least-squares solutions. This design yields fast and numerically robust reconstruction by combining local predictors through a partition of unity. To understand where approximation becomes difficult under fixed local capacity, we analyze the method from a spectral Barron norm perspective, which reveals that global reconstruction error is dominated by regions with high spectral complexity. Building on this insight, we introduce BEAM, an adaptive mesh refinement strategy that balances spectral complexity across subdomains to improve reconstruction quality in capacity-constrained regimes.", "AI": {"tldr": "ELM-INR\uff1a\u4e00\u79cd\u514d\u53cd\u5411\u4f20\u64ad\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u4f7f\u7528\u6781\u9650\u5b66\u4e60\u673a\u8fdb\u884c\u95ed\u5f0f\u6c42\u89e3\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u7b56\u7565BEAM\u6765\u5e73\u8861\u9891\u8c31\u590d\u6742\u5ea6", "motivation": "\u4f20\u7edfINR\u8bad\u7ec3\u4f9d\u8d56\u8fed\u4ee3\u53cd\u5411\u4f20\u64ad\uff0c\u5728\u5904\u7406\u975e\u5747\u5300\u9891\u7387\u5185\u5bb9\u65f6\u53d7\u9891\u8c31\u504f\u5dee\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684\u65b9\u6cd5", "method": "\u5c06\u57df\u5206\u89e3\u4e3a\u91cd\u53e0\u5b50\u57df\uff0c\u6bcf\u4e2a\u5b50\u57df\u4f7f\u7528\u6781\u9650\u5b66\u4e60\u673a\u8fdb\u884c\u95ed\u5f0f\u62df\u5408\uff0c\u901a\u8fc7\u5355\u4f4d\u5206\u89e3\u7ec4\u5408\u5c40\u90e8\u9884\u6d4b\u5668\uff1b\u5f15\u5165BEAM\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u7b56\u7565\u5e73\u8861\u9891\u8c31\u590d\u6742\u5ea6", "result": "\u5b9e\u73b0\u4e86\u5feb\u901f\u3001\u6570\u503c\u7a33\u5b9a\u7684\u91cd\u5efa\uff0c\u901a\u8fc7\u9891\u8c31Barron\u8303\u6570\u5206\u6790\u63ed\u793a\u4e86\u91cd\u5efa\u8bef\u5dee\u4e3b\u8981\u53d7\u9ad8\u9891\u8c31\u590d\u6742\u5ea6\u533a\u57df\u5f71\u54cd", "conclusion": "ELM-INR\u63d0\u4f9b\u4e86\u4e00\u79cd\u514d\u53cd\u5411\u4f20\u64ad\u7684INR\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\u53ef\u6709\u6548\u5904\u7406\u975e\u5747\u5300\u9891\u7387\u5185\u5bb9\uff0c\u5728\u5bb9\u91cf\u53d7\u9650\u60c5\u51b5\u4e0b\u63d0\u5347\u91cd\u5efa\u8d28\u91cf"}}
{"id": "2602.08672", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08672", "abs": "https://arxiv.org/abs/2602.08672", "authors": ["Clemencia Siro", "Pourya Aliannejadi", "Mohammad Aliannejadi"], "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics", "comment": "Accepted at EACL 2026 Findings", "summary": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.", "AI": {"tldr": "GER-Eval\u7814\u7a76\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u5df1\u8bbe\u8ba1\u548c\u5e94\u7528\u8bc4\u4f30\u6807\u51c6\uff0c\u53d1\u73b0\u6a21\u578b\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u611f\u77e5\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u4f46\u5728\u4e8b\u5b9e\u6027\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8bc4\u5206\u53ef\u9760\u6027\u4e0b\u964d\uff0c\u95ed\u6e90\u6a21\u578b\u6bd4\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u4f7f\u7528\u4eba\u7c7b\u5b9a\u4e49\u7684\u9759\u6001\u8bc4\u4f30\u6807\u51c6\uff0c\u4f46\u8fd9\u4e9b\u6807\u51c6\u4e0e\u6a21\u578b\u5185\u90e8\u7684\u8bed\u8a00\u8d28\u91cf\u8868\u793a\u65b9\u5f0f\u4e0d\u4e00\u81f4\u3002\u7814\u7a76\u8005\u60f3\u63a2\u7d22LLMs\u662f\u5426\u80fd\u8bbe\u8ba1\u548c\u5e94\u7528\u81ea\u5df1\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6807\u51c6\u4e0e\u4eba\u7c7b\u6807\u51c6\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "method": "\u63d0\u51faGER-Eval\u6846\u67b6\uff0c\u8ba9LLMs\u751f\u6210\u81ea\u5df1\u7684\u8bc4\u4f30\u6807\u51c6\u5e76\u5e94\u7528\u8fd9\u4e9b\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u5b9a\u4e49\u6807\u51c6\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u8bc4\u5206\u53ef\u9760\u6027\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u6807\u51c6\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "LLMs\u80fd\u53ef\u9760\u5730\u751f\u6210\u53ef\u89e3\u91ca\u4e14\u4efb\u52a1\u611f\u77e5\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u5e76\u5728\u6a21\u578b\u5185\u90e8\u4e00\u81f4\u5e94\u7528\u8fd9\u4e9b\u6807\u51c6\u3002\u4f46\u5728\u4e8b\u5b9e\u6027\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8bc4\u5206\u53ef\u9760\u6027\u4e0b\u964d\u3002\u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-4o\uff09\u6bd4\u5f00\u6e90\u6a21\u578b\uff08\u5982Llama\uff09\u5728\u4e00\u81f4\u6027\u548c\u8de8\u6a21\u578b\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8bc4\u4f30\u662fLLMs\u7684\u4e00\u79cd\u5b66\u4e60\u5230\u7684\u8bed\u8a00\u80fd\u529b\uff0c\u5728\u6a21\u578b\u5185\u90e8\u4e00\u81f4\u4f46\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5b58\u5728\u5dee\u5f02\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u8054\u5408\u5efa\u6a21\u4eba\u7c7b\u548cLLM\u7684\u8bc4\u4f30\u8bed\u8a00\uff0c\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.08369", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08369", "abs": "https://arxiv.org/abs/2602.08369", "authors": ["Xin Zhang", "Kailai Yang", "Chenyue Li", "Hao Li", "Qiyu Wei", "Jun'ichi Tsujii", "Sophia Ananiadou"], "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval", "comment": null, "summary": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.", "AI": {"tldr": "MemAdapter\u662f\u4e00\u4e2a\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u7684\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u8de8\u8303\u5f0f\u5feb\u901f\u5bf9\u9f50\uff0c\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u6210\u672c\u5e76\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5185\u5b58\u7cfb\u7edf\u901a\u5e38\u8bbe\u8ba1\u5728\u5b64\u7acb\u8303\u5f0f\uff08\u663e\u5f0f\u3001\u53c2\u6570\u5316\u6216\u6f5c\u5728\u5185\u5b58\uff09\u4e2d\uff0c\u68c0\u7d22\u65b9\u6cd5\u7d27\u5bc6\u8026\u5408\uff0c\u963b\u788d\u4e86\u8de8\u8303\u5f0f\u6cdb\u5316\u548c\u878d\u5408\u3002\u9700\u8981\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u3002", "method": "\u63d0\u51faMemAdapter\u6846\u67b6\uff1a1) \u4ece\u7edf\u4e00\u5185\u5b58\u7a7a\u95f4\u8bad\u7ec3\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\uff1b2) \u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u68c0\u7d22\u5668\u9002\u5e94\u5230\u672a\u89c1\u5185\u5b58\u8303\u5f0f\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u8bc4\u4f30\u57fa\u51c6\u4e0a\uff0c\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\u5728\u4e09\u79cd\u5185\u5b58\u8303\u5f0f\u548c\u667a\u80fd\u4f53\u6a21\u578b\u89c4\u6a21\u4e0a\u6301\u7eed\u4f18\u4e8e\u4e94\u4e2a\u5f3a\u57fa\u7ebf\u7cfb\u7edf\u3002\u8de8\u8303\u5f0f\u5bf9\u9f50\u4ec5\u970013\u5206\u949f\uff08\u5355GPU\uff09\uff0c\u6027\u80fd\u4f18\u4e8e\u539f\u59cb\u68c0\u7d22\u5668\u4e14\u8bad\u7ec3\u8ba1\u7b97\u91cf\u5c11\u4e8e5%\u3002\u652f\u6301\u96f6\u6837\u672c\u8de8\u8303\u5f0f\u878d\u5408\u3002", "conclusion": "MemAdapter\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7edf\u4e00\u5185\u5b58\u8303\u5f0f\u548c\u4f4e\u6210\u672c\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u5185\u5b58\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2602.07616", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07616", "abs": "https://arxiv.org/abs/2602.07616", "authors": ["Juntong Wu", "Jialiang Cheng", "Fuyu Lv", "Ou Dan", "Li Yuan"], "title": "SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models", "comment": "Published as a conference paper at ICLR 2026", "summary": "Mixture-of-Experts (MoE) architectures employ sparse activation to deliver faster training and inference with higher accuracy than dense LLMs. However, in production serving, MoE models require batch inference to optimize hardware efficiency, which may cause excessive expert activation and thus slow the memory-bound decoding stage. To address the fundamental tension between batch decoding and expert sparsity, we present SERE, a Similarity-based Expert Re-routing method for Efficient batch decoding in MoE models. SERE dynamically reduces the number of active experts in an input-aware manner by re-routing tokens from secondary experts to their most similar primary counterparts. It also leverages similarity patterns to identify and preserve critical experts, thereby preventing capability loss. Notably, SERE avoids static expert pruning or merging, instead enabling dynamic expert skipping based on batch-level expert redundancy. Additionally, we provide an efficient custom CUDA kernel for SERE, enabling plug-and-play use in vLLM with only a single-line code change. Extensive experiments on various complex reasoning benchmarks demonstrate that SERE achieves up to 2.0x speedup with minimal quality loss, providing a practical solution for cost-efficient and latency-sensitive large-scale MoE deployment. Code implementation of SERE can be found in https://github.com/JL-Cheng/SERE.", "AI": {"tldr": "SERE\u662f\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u4e13\u5bb6\u91cd\u8def\u7531\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728MoE\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u6279\u91cf\u89e3\u7801\uff0c\u901a\u8fc7\u52a8\u6001\u51cf\u5c11\u6d3b\u8dc3\u4e13\u5bb6\u6570\u91cf\u6765\u7f13\u89e3\u6279\u91cf\u63a8\u7406\u4e0e\u4e13\u5bb6\u7a00\u758f\u6027\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u5b9e\u73b0\u9ad8\u8fbe2.0\u500d\u7684\u52a0\u901f\u4e14\u8d28\u91cf\u635f\u5931\u6700\u5c0f\u3002", "motivation": "MoE\u67b6\u6784\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u9700\u8981\u6279\u91cf\u63a8\u7406\u4ee5\u4f18\u5316\u786c\u4ef6\u6548\u7387\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u8fc7\u591a\u7684\u4e13\u5bb6\u6fc0\u6d3b\uff0c\u4ece\u800c\u51cf\u6162\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\u3002\u6279\u91cf\u89e3\u7801\u4e0e\u4e13\u5bb6\u7a00\u758f\u6027\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u51b2\u7a81\u3002", "method": "SERE\u901a\u8fc7\u76f8\u4f3c\u6027\u5206\u6790\u52a8\u6001\u51cf\u5c11\u6d3b\u8dc3\u4e13\u5bb6\u6570\u91cf\uff1a1\uff09\u5c06\u6b21\u8981\u4e13\u5bb6\u7684token\u91cd\u8def\u7531\u5230\u6700\u76f8\u4f3c\u7684\u4e3b\u8981\u4e13\u5bb6\uff1b2\uff09\u5229\u7528\u76f8\u4f3c\u6027\u6a21\u5f0f\u8bc6\u522b\u5e76\u4fdd\u7559\u5173\u952e\u4e13\u5bb6\uff1b3\uff09\u907f\u514d\u9759\u6001\u4e13\u5bb6\u526a\u679d\u6216\u5408\u5e76\uff0c\u800c\u662f\u57fa\u4e8e\u6279\u91cf\u7ea7\u4e13\u5bb6\u5197\u4f59\u5b9e\u73b0\u52a8\u6001\u4e13\u5bb6\u8df3\u8fc7\uff1b4\uff09\u63d0\u4f9b\u9ad8\u6548\u7684\u5b9a\u5236CUDA\u5185\u6838\uff0c\u53ef\u5728vLLM\u4e2d\u5373\u63d2\u5373\u7528\u3002", "result": "\u5728\u5404\u79cd\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSERE\u5b9e\u73b0\u4e86\u9ad8\u8fbe2.0\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u8d28\u91cf\u635f\u5931\u6700\u5c0f\uff0c\u4e3a\u5927\u89c4\u6a21MoE\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SERE\u901a\u8fc7\u52a8\u6001\u4e13\u5bb6\u91cd\u8def\u7531\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u6279\u91cf\u89e3\u7801\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u9002\u7528\u4e8e\u6210\u672c\u654f\u611f\u548c\u5ef6\u8fdf\u654f\u611f\u7684\u5927\u89c4\u6a21MoE\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2602.08373", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08373", "abs": "https://arxiv.org/abs/2602.08373", "authors": ["Feiyu Wu", "Xu Zheng", "Yue Qu", "Zhuocheng Wang", "Zicheng Feng", "Hui Li"], "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI", "comment": "Accepted to ICLR 2026. Project page. https://openreview.net/forum?id=wb05ver1k8&noteId=v1Ax8CwI71", "summary": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.", "AI": {"tldr": "VIRF\u6846\u67b6\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u5b9e\u73b0LLM\u89c4\u5212\u5668\u7684\u53ef\u9a8c\u8bc1\u5b89\u5168\u89c4\u5212\uff0c\u4f7f\u7528\u903b\u8f91\u5bfc\u5e08\u63d0\u4f9b\u56e0\u679c\u53cd\u9988\u8fdb\u884c\u4e3b\u52a8\u4fee\u590d\u800c\u975e\u88ab\u52a8\u62d2\u7edd\uff0c\u5728\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\u5b9e\u73b0\u96f6\u5371\u9669\u884c\u52a8\u7387\u548c\u6700\u9ad8\u76ee\u6807\u8fbe\u6210\u7387\u3002", "motivation": "\u5f53\u524dLLM\u89c4\u5212\u5668\u7f3a\u4e4f\u5f62\u5f0f\u5316\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u6cd5\u63d0\u4f9b\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684LLM\u8fdb\u884c\u5b89\u5168\u68c0\u67e5\uff0c\u8981\u4e48\u7b80\u5355\u5730\u62d2\u7edd\u4e0d\u5b89\u5168\u8ba1\u5212\u800c\u4e0d\u63d0\u4f9b\u4fee\u590d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u8fed\u4ee3\u7cbe\u70bc\u6846\u67b6(VIRF)\uff0c\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u5efa\u7acb\u5bfc\u5e08-\u5b66\u5f92\u5bf9\u8bdd\u673a\u5236\uff1a\u57fa\u4e8e\u5f62\u5f0f\u5316\u5b89\u5168\u672c\u4f53\u7684\u786e\u5b9a\u6027\u903b\u8f91\u5bfc\u5e08\u4e3aLLM\u89c4\u5212\u5668\u63d0\u4f9b\u56e0\u679c\u548c\u6559\u5b66\u53cd\u9988\uff0c\u5b9e\u73b0\u667a\u80fd\u8ba1\u5212\u4fee\u590d\u800c\u975e\u7b80\u5355\u907f\u514d\u3002\u540c\u65f6\u5f15\u5165\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u83b7\u53d6\u6d41\u7a0b\uff0c\u4ece\u771f\u5b9e\u4e16\u754c\u6587\u6863\u5408\u6210\u5b89\u5168\u77e5\u8bc6\u5e93\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\uff0cVIRF\u5b9e\u73b0\u4e860%\u7684\u5371\u9669\u884c\u52a8\u7387(HAR)\u548c77.3%\u7684\u76ee\u6807\u6761\u4ef6\u7387(GCR)\uff0c\u5728\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u6700\u9ad8\u3002\u5e73\u5747\u4ec5\u97001.1\u6b21\u4fee\u6b63\u8fed\u4ee3\uff0c\u6548\u7387\u6781\u9ad8\u3002", "conclusion": "VIRF\u5c55\u793a\u4e86\u6784\u5efa\u6839\u672c\u4e0a\u53ef\u4fe1\u4e14\u53ef\u9a8c\u8bc1\u5b89\u5168\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7684\u539f\u5219\u6027\u9014\u5f84\uff0c\u4ece\u88ab\u52a8\u5b89\u5168\u628a\u5173\u8f6c\u5411\u4e3b\u52a8\u534f\u4f5c\uff0c\u4e3a\u7269\u7406\u90e8\u7f72\u63d0\u4f9b\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2602.08698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08698", "abs": "https://arxiv.org/abs/2602.08698", "authors": ["Basudha Raje", "Sadanand Venkatraman", "Nandana TP", "Soumyadeepa Das", "Polkam Poojitha", "M. Vijaykumar", "Tanima Bagchi", "Hema A. Murthy"], "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL", "comment": null, "summary": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u673a\u5668\u7ffb\u8bd1\u5728\u5370\u5ea6\u8bed\u8a00\uff08\u5b5f\u52a0\u62c9\u8bed\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u3001\u6cf0\u5362\u56fa\u8bed\uff09\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u548c\u65b9\u6cd5\u8bba\u610f\u4e49\uff0c\u5206\u6790\u4e86\u5176\u5728\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u4e0b\u7684\u8868\u73b0\uff0c\u7279\u522b\u5173\u6ce8\u5f62\u6001\u4e30\u5bcc\u548c\u8bed\u4e49\u7d27\u51d1\u7279\u5f81\u5bf9\u8868\u9762\u91cd\u53e0\u5ea6\u91cf\u7684\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u5370\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u80cc\u666f\u4e0b\u6559\u80b2\u6280\u672f\u7684\u591a\u8bed\u8a00\u9002\u5e94\u9700\u6c42\uff08NEP 2020\u653f\u7b56\uff09\uff0c\u4ee5\u53caNPTEL\u5927\u89c4\u6a21\u5728\u7ebf\u8bfe\u7a0b\u5e73\u53f0\u63d0\u4f9b\u7684\u8bed\u6599\u8d44\u6e90\uff0c\u65e8\u5728\u89e3\u51b3\u6280\u672f\u6982\u5ff5\u6e05\u6670\u4f20\u8fbe\u65f6\u4fdd\u7559\u9002\u5f53\u8bed\u57df\u548c\u8bcd\u6c47\u9009\u62e9\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528NPTEL MOOC\u95e8\u6237\u4f5c\u4e3a\u8bed\u6599\u5e93\uff0c\u6784\u5efa\u81ea\u53d1\u8a00\u8bed\u8bed\u6599\u5e93\uff0c\u5206\u6790\u5b5f\u52a0\u62c9\u8bed\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u548c\u6cf0\u5362\u56fa\u8bed\u4e09\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u673a\u5668\u7ffb\u8bd1\u5e94\u7528\uff0c\u6d4b\u8bd5\u5176\u5bf9\u8868\u9762\u91cd\u53e0\u5ea6\u91cf\u7684\u654f\u611f\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5ea6\u91cf\u6307\u6807\u5177\u6709\u7279\u5b9a\u654f\u611f\u6027\uff0c\u5f62\u6001\u4e30\u5bcc\u548c\u8bed\u4e49\u7d27\u51d1\u7684\u8bed\u8a00\u7279\u5f81\u5728\u8868\u9762\u91cd\u53e0\u5ea6\u91cf\u6d4b\u8bd5\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u5728\u5370\u5ea6\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5370\u5ea6\u8fd9\u6837\u8bed\u8a00\u591a\u6837\u7684\u56fd\u5bb6\uff0c\u6784\u5efa\u80fd\u591f\u6e05\u6670\u4f20\u8fbe\u6280\u672f\u6982\u5ff5\u3001\u4fdd\u7559\u9002\u5f53\u8bed\u57df\u548c\u8bcd\u6c47\u9009\u62e9\u7684\u81ea\u53d1\u8a00\u8bed\u8bed\u6599\u5e93\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u9700\u8981\u66f4\u9002\u5e94\u5370\u5ea6\u8bed\u8a00\u7279\u5f81\u7684\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.08400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08400", "abs": "https://arxiv.org/abs/2602.08400", "authors": ["Longkun Li", "Yuanben Zou", "Jinghan Wu", "Yuqing Wen", "Jing Li", "Hangwei Qian", "Ivor Tsang"], "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains", "comment": null, "summary": "Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline{CO}st-efficient \\underline{U}nifying \\underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency.", "AI": {"tldr": "SCOUT-RAG\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u667a\u80fdGraph-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8de8\u57df\u68c0\u7d22\u89e3\u51b3\u5206\u5e03\u5f0f\u53d7\u9650\u73af\u5883\u4e2d\u7684\u77e5\u8bc6\u56fe\u68c0\u7d22\u95ee\u9898\uff0c\u76f8\u6bd4\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u8de8\u57df\u8c03\u7528\u548c\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edfGraph-RAG\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u77e5\u8bc6\u56fe\uff0c\u4f46\u5728\u5206\u5e03\u5f0f\u548c\u8bbf\u95ee\u53d7\u9650\u73af\u5883\uff08\u5982\u533b\u9662\u3001\u8de8\u56fd\u7ec4\u7ec7\uff09\u4e2d\uff0c\u68c0\u7d22\u9700\u8981\u5728\u6ca1\u6709\u5168\u5c40\u56fe\u53ef\u89c1\u6027\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u76f8\u5173\u57df\u548c\u9002\u5f53\u904d\u5386\u6df1\u5ea6\uff0c\u907f\u514d\u7a77\u4e3e\u67e5\u8be2\u3002", "method": "\u63d0\u51faSCOUT-RAG\u6846\u67b6\uff0c\u4f7f\u7528\u56db\u4e2a\u534f\u4f5c\u4ee3\u7406\uff1a(1)\u4f30\u8ba1\u57df\u76f8\u5173\u6027\uff0c(2)\u51b3\u5b9a\u4f55\u65f6\u6269\u5c55\u5230\u5176\u4ed6\u57df\uff0c(3)\u8c03\u6574\u904d\u5386\u6df1\u5ea6\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u56fe\u63a2\u7d22\uff0c(4)\u5408\u6210\u9ad8\u8d28\u91cf\u7b54\u6848\u3002\u6846\u67b6\u65e8\u5728\u6700\u5c0f\u5316\u68c0\u7d22\u9057\u61be\uff08\u7f3a\u5931\u6709\u7528\u57df\u4fe1\u606f\uff09\uff0c\u540c\u65f6\u63a7\u5236\u5ef6\u8fdf\u548cAPI\u6210\u672c\u3002", "result": "\u5728\u591a\u57df\u77e5\u8bc6\u8bbe\u7f6e\u4e2d\uff0cSCOUT-RAG\u5b9e\u73b0\u4e86\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\uff08\u5305\u62ecDRIFT\u548c\u7a77\u4e3e\u57df\u904d\u5386\uff09\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8de8\u57df\u8c03\u7528\u3001\u5904\u7406\u7684\u603btoken\u6570\u548c\u5ef6\u8fdf\u3002", "conclusion": "SCOUT-RAG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5206\u5e03\u5f0fGraph-RAG\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u53d7\u9650\u73af\u5883\u4e2d\u6709\u6548\u8fdb\u884c\u77e5\u8bc6\u68c0\u7d22\uff0c\u5e73\u8861\u68c0\u7d22\u8d28\u91cf\u4e0e\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.07640", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07640", "abs": "https://arxiv.org/abs/2602.07640", "authors": ["Micha\u0142 Kozyra", "Gesine Reinert"], "title": "TASTE: Task-Aware Out-of-Distribution Detection via Stein Operators", "comment": null, "summary": "Out-of-distribution detection methods are often either data-centric, detecting deviations from the training input distribution irrespective of their effect on a trained model, or model-centric, relying on classifier outputs without explicit reference to data geometry. We propose TASTE (Task-Aware STEin operators): a task-aware framework based on so-called Stein operators, which allows us to link distribution shift to the input sensitivity of the model. We show that the resulting operator admits a clear geometric interpretation as a projection of distribution shift onto the sensitivity field of the model, yielding theoretical guarantees. Beyond detecting the presence of a shift, the same construction enables its localisation through a coordinate-wise decomposition, and for image data-provides interpretable per-pixel diagnostics. Experiments on controlled Gaussian shifts, MNIST under geometric perturbations, and CIFAR-10 perturbed benchmarks demonstrate that the proposed method aligns closely with task degradation while outperforming established baselines.", "AI": {"tldr": "TASTE\u6846\u67b6\u901a\u8fc7Stein\u7b97\u5b50\u5c06\u5206\u5e03\u504f\u79fb\u4e0e\u6a21\u578b\u8f93\u5165\u654f\u611f\u6027\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u4f9b\u51e0\u4f55\u89e3\u91ca\u548c\u7406\u8bba\u4fdd\u8bc1\uff0c\u5728\u68c0\u6d4b\u504f\u79fb\u7684\u540c\u65f6\u8fd8\u80fd\u5b9a\u4f4d\u504f\u79fb\u6e90\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709OOD\u68c0\u6d4b\u65b9\u6cd5\u8981\u4e48\u662f\u6570\u636e\u4e2d\u5fc3\u7684\uff08\u4ec5\u68c0\u6d4b\u8bad\u7ec3\u8f93\u5165\u5206\u5e03\u7684\u504f\u5dee\uff09\uff0c\u8981\u4e48\u662f\u6a21\u578b\u4e2d\u5fc3\u7684\uff08\u4f9d\u8d56\u5206\u7c7b\u5668\u8f93\u51fa\u800c\u4e0d\u8003\u8651\u6570\u636e\u51e0\u4f55\uff09\u3002\u9700\u8981\u4e00\u79cd\u80fd\u660e\u786e\u8fde\u63a5\u5206\u5e03\u504f\u79fb\u4e0e\u6a21\u578b\u654f\u611f\u6027\u7684\u4efb\u52a1\u611f\u77e5\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTASTE\u6846\u67b6\uff0c\u57fa\u4e8eStein\u7b97\u5b50\u5c06\u5206\u5e03\u504f\u79fb\u4e0e\u6a21\u578b\u8f93\u5165\u654f\u611f\u6027\u8054\u7cfb\u8d77\u6765\u3002\u8be5\u7b97\u5b50\u5c06\u5206\u5e03\u504f\u79fb\u6295\u5f71\u5230\u6a21\u578b\u7684\u654f\u611f\u6027\u573a\u4e0a\uff0c\u63d0\u4f9b\u51e0\u4f55\u89e3\u91ca\u548c\u7406\u8bba\u4fdd\u8bc1\u3002\u8fd8\u80fd\u901a\u8fc7\u5750\u6807\u5206\u89e3\u5b9e\u73b0\u504f\u79fb\u5b9a\u4f4d\uff0c\u5bf9\u56fe\u50cf\u6570\u636e\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u50cf\u7d20\u7ea7\u8bca\u65ad\u3002", "result": "\u5728\u63a7\u5236\u7684\u9ad8\u65af\u504f\u79fb\u3001MNIST\u51e0\u4f55\u6270\u52a8\u548cCIFAR-10\u6270\u52a8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTASTE\u65b9\u6cd5\u4e0e\u4efb\u52a1\u9000\u5316\u7d27\u5bc6\u5bf9\u9f50\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TASTE\u6846\u67b6\u901a\u8fc7Stein\u7b97\u5b50\u6210\u529f\u8fde\u63a5\u4e86\u5206\u5e03\u504f\u79fb\u4e0e\u6a21\u578b\u654f\u611f\u6027\uff0c\u4e0d\u4ec5\u68c0\u6d4b\u504f\u79fb\u8fd8\u80fd\u5b9a\u4f4d\u504f\u79fb\u6e90\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u548c\u51e0\u4f55\u89e3\u91ca\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.08700", "categories": ["cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08700", "abs": "https://arxiv.org/abs/2602.08700", "authors": ["Clemencia Siro", "Zahra Abbasiantaeb", "Yifei Yuan", "Mohammad Aliannejadi", "Maarten de Rijke"], "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search", "comment": "Accepted at CHIIR 2025", "summary": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5bf9\u8bdd\u5f0f\u641c\u7d22\u7cfb\u7edf\u4e2d\uff0c\u5c06\u56fe\u50cf\u878d\u5165\u6f84\u6e05\u95ee\u9898\u65f6\u5bf9\u7528\u6237\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u56fe\u50cf\u6548\u679c\u56e0\u4efb\u52a1\u7c7b\u578b\u548c\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u800c\u5f02\u3002", "motivation": "\u867d\u7136\u6587\u672c\u6f84\u6e05\u95ee\u9898\u5df2\u88ab\u8bc1\u660e\u80fd\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u4e14\u56fe\u50cf\u5728\u5404\u79cd\u60c5\u5883\u4e2d\u80fd\u6539\u5584\u68c0\u7d22\u6027\u80fd\uff0c\u4f46\u56fe\u50cf\u5728\u6f84\u6e05\u95ee\u9898\u4e2d\u5bf9\u7528\u6237\u8868\u73b0\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bf973\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u6bd4\u8f83\u591a\u6a21\u6001\uff08\u6587\u672c+\u56fe\u50cf\uff09\u4e0e\u7eaf\u6587\u672c\u6f84\u6e05\u95ee\u9898\u5728\u4e24\u79cd\u641c\u7d22\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff1a(i)\u56de\u7b54\u6f84\u6e05\u95ee\u9898\uff0c(ii)\u67e5\u8be2\u91cd\u6784\u3002", "result": "\u5728\u56de\u7b54\u6f84\u6e05\u95ee\u9898\u65f6\uff0c\u53c2\u4e0e\u8005\u5f3a\u70c8\u504f\u597d\u591a\u6a21\u6001\u95ee\u9898\uff0c\u4f46\u7eaf\u6587\u672c\u8bbe\u7f6e\u4e0b\u7528\u6237\u8868\u73b0\u66f4\u597d\uff1b\u5728\u67e5\u8be2\u91cd\u6784\u4efb\u52a1\u4e2d\uff0c\u504f\u597d\u66f4\u5e73\u8861\uff0c\u56fe\u50cf\u80fd\u5e26\u6765\u66f4\u7cbe\u786e\u7684\u67e5\u8be2\u548c\u66f4\u597d\u7684\u68c0\u7d22\u6027\u80fd\u3002\u56fe\u50cf\u6548\u679c\u968f\u4efb\u52a1\u7c7b\u578b\u548c\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u53d8\u5316\u3002", "conclusion": "\u89c6\u89c9\u589e\u5f3a\u7684\u76ca\u5904\u662f\u4efb\u52a1\u4f9d\u8d56\u6027\u7684\uff0c\u5e94\u6839\u636e\u5177\u4f53\u641c\u7d22\u60c5\u5883\u548c\u7528\u6237\u7279\u5f81\u8fdb\u884c\u6218\u7565\u6027\u5b9e\u65bd\uff0c\u4e3a\u8bbe\u8ba1\u6709\u6548\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2602.08401", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08401", "abs": "https://arxiv.org/abs/2602.08401", "authors": ["Liwen Wang", "Zongjie Li", "Yuchong Xie", "Shuai Wang", "Dongdong She", "Wei Wang", "Juergen Rahmel"], "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking", "comment": null, "summary": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.", "AI": {"tldr": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u504f\u7f6e\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u5206\u5e03\u6765\u5d4c\u5165\u53ef\u9a8c\u8bc1\u4fe1\u53f7\uff0c\u6709\u6548\u4fdd\u62a4\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u4ea7\u6743\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6f14\u53d8\u4e3a\u6267\u884c\u81ea\u4e3b\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u521b\u9020\u4e86\u91cd\u8981\u7684\u77e5\u8bc6\u4ea7\u6743\u4ef7\u503c\u3002\u8fd9\u4e9b\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u6a21\u4eff\u653b\u51fb\uff0c\u800c\u73b0\u6709\u7684LLM\u6c34\u5370\u6280\u672f\u65e0\u6cd5\u5728\u667a\u80fd\u4f53\u9886\u57df\u6709\u6548\u5de5\u4f5c\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e2d\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u4f5c\u4e3a\u7070\u76d2\u8fd0\u884c\uff0c\u9690\u85cf\u4e86\u9a8c\u8bc1\u6240\u9700\u7684\u5185\u90e8\u63a8\u7406\u75d5\u8ff9\u3002", "method": "AGENTWM\u5229\u7528\u52a8\u4f5c\u5e8f\u5217\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u901a\u8fc7\u5fae\u5999\u5730\u504f\u7f6e\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u5206\u5e03\u6765\u6ce8\u5165\u6c34\u5370\u3002\u8be5\u65b9\u6cd5\u5f00\u53d1\u4e86\u81ea\u52a8\u751f\u6210\u9c81\u68d2\u6c34\u5370\u65b9\u6848\u7684\u6d41\u6c34\u7ebf\uff0c\u4ee5\u53ca\u7528\u4e8e\u9a8c\u8bc1\u7684\u4e25\u683c\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u7a0b\u5e8f\u3002", "result": "\u5728\u4e09\u4e2a\u590d\u6742\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cAGENTWM\u5b9e\u73b0\u4e86\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002\u8be5\u6846\u67b6\u80fd\u6709\u6548\u4fdd\u62a4\u667a\u80fd\u4f53\u77e5\u8bc6\u4ea7\u6743\uff0c\u5bf9\u6297\u9002\u5e94\u6027\u5f3a\u7684\u653b\u51fb\u8005\uff0c\u653b\u51fb\u8005\u65e0\u6cd5\u5728\u4e0d\u4e25\u91cd\u964d\u4f4e\u88ab\u76d7\u6a21\u578b\u6548\u7528\u7684\u60c5\u51b5\u4e0b\u79fb\u9664\u6c34\u5370\u3002", "conclusion": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709LLM\u6c34\u5370\u6280\u672f\u5728\u667a\u80fd\u4f53\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4fdd\u62a4\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u4ea7\u6743\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08709", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08709", "abs": "https://arxiv.org/abs/2602.08709", "authors": ["Leandro Anghinoni", "Jorge Sanchez"], "title": "FactSim: Fact-Checking for Opinion Summarization", "comment": "10 pages, 4 figures", "summary": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5728\u610f\u89c1\u6458\u8981\u4efb\u52a1\u4e2d\u4e8b\u5b9e\u4e00\u81f4\u6027\u7684\u5168\u81ea\u52a8\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u91cf\u6458\u8981\u58f0\u660e\u4e0e\u539f\u59cb\u8bc4\u8bba\u7684\u76f8\u4f3c\u6027\u6765\u8bc4\u4f30\u8986\u76d6\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u81ea\u52a8\u6307\u6807\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5728\u610f\u89c1\u6458\u8981\u4efb\u52a1\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u8303\u5f0f\u8f6c\u53d8\u9700\u8981\u66f4\u5168\u9762\u7cbe\u786e\u7684\u8bc4\u4f30\u6280\u672f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6d4b\u91cf\u6458\u8981\u58f0\u660e\u4e0e\u539f\u59cb\u8bc4\u8bba\u76f8\u4f3c\u6027\u7684\u5168\u81ea\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u65b9\u6cd5\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u4e8b\u5b9e\u8bc4\u4f30\uff0c\u7136\u540e\u6bd4\u8f83\u5e76\u603b\u7ed3\u4e3a\u5408\u9002\u7684\u5206\u6570\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u4e3a\u76f8\u4f3c\u58f0\u660e\u5206\u914d\u66f4\u9ad8\u5206\u6570\uff08\u65e0\u8bba\u662f\u5426\u5b9a\u3001\u6539\u5199\u6216\u6269\u5c55\uff09\uff0c\u4e14\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027\u9ad8\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6307\u6807\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5728\u610f\u89c1\u6458\u8981\u4e2d\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.08412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08412", "abs": "https://arxiv.org/abs/2602.08412", "authors": ["Yuhang Wang", "Feiming Xu", "Zheng Lin", "Guangyu He", "Yuzhe Huang", "Haichang Gao", "Zhenxing Niu"], "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent", "comment": "11 pages,2 figures", "summary": "Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB.", "AI": {"tldr": "PASB\u662f\u4e00\u4e2a\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316AI\u4ee3\u7406\u7684\u7aef\u5230\u7aef\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u4f7f\u7528\u573a\u666f\u3001\u771f\u5b9e\u5de5\u5177\u94fe\u548c\u957f\u65f6\u4ea4\u4e92\u6765\u8bc4\u4f30OpenClaw\u7b49\u4ee3\u7406\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5408\u6210\u6216\u4efb\u52a1\u4e2d\u5fc3\u8bbe\u7f6e\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u653b\u51fb\u9762\u548c\u98ce\u9669\u4f20\u64ad\u673a\u5236\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faPASB\u6846\u67b6\uff0c\u57fa\u4e8e\u73b0\u6709\u4ee3\u7406\u653b\u51fb\u8303\u5f0f\uff0c\u6574\u5408\u4e2a\u6027\u5316\u4f7f\u7528\u573a\u666f\u3001\u771f\u5b9e\u5de5\u5177\u94fe\u548c\u957f\u65f6\u4ea4\u4e92\uff0c\u5b9e\u73b0\u5bf9\u771f\u5b9e\u7cfb\u7edf\u7684\u9ed1\u76d2\u7aef\u5230\u7aef\u5b89\u5168\u8bc4\u4f30\u3002", "result": "\u5728OpenClaw\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u53d1\u73b0\u5176\u5728\u7528\u6237\u63d0\u793a\u5904\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u5185\u5b58\u68c0\u7d22\u7b49\u591a\u4e2a\u6267\u884c\u9636\u6bb5\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86\u4e2a\u6027\u5316\u4ee3\u7406\u90e8\u7f72\u4e2d\u7684\u91cd\u5927\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "PASB\u6846\u67b6\u6709\u6548\u8bc6\u522b\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u5728AI\u52a9\u624b\u90e8\u7f72\u4e2d\u52a0\u5f3a\u5b89\u5168\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.07670", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07670", "abs": "https://arxiv.org/abs/2602.07670", "authors": ["Jarrod Barnes"], "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation", "comment": "13 pages, 7 figures, 11 tables. Preprint. Code: https://github.com/jbarnes850/test-time-training", "summary": "Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that search outperforms minimal adaptation (1-5 gradient steps): Best-of-N sampling achieves 90% task success (18/20 tasks) at K=64 across the full KernelBench L1 eval set while TTT's best checkpoint reaches only 30.6% (3-seed mean), with TTT's \"equivalent K\" falling below 1, worse than single-sample inference. The failure mode is over-sharpening: gradient updates collapse diversity toward mediocre solutions rather than discovering optimal ones. Our main contribution is surprisal-guided selection: selecting the highest-surprisal (lowest-confidence) correct sample yields 80% success vs. 50% for most-confident selection, a 30% improvement. Extending to surprisal-guided-top3 matches oracle performance at 100%. This zero-cost strategy, validated through length-controlled analysis, recovers oracle performance. For dense-reward VEG tasks, compute should be allocated to sample diversity and intelligent selection rather than gradient adaptation. The surprisal-guided selection principle may generalize to other execution-grounded domains where optimal solutions occupy the distribution tail.", "AI": {"tldr": "\u5728\u53ef\u9a8c\u8bc1\u6267\u884c\u57fa\u7840\u4efb\u52a1\u4e2d\uff0c\u641c\u7d22\u7b56\u7565\u4f18\u4e8e\u6d4b\u8bd5\u65f6\u8bad\u7ec3\uff1a\u6700\u4f73N\u91c7\u6837\u8fbe\u523090%\u6210\u529f\u7387\uff0c\u800cTTT\u4ec530.6%\u3002\u63d0\u51fa\u57fa\u4e8e\u60ca\u5947\u5ea6\u5f15\u5bfc\u7684\u9009\u62e9\u7b56\u7565\uff0c\u96f6\u6210\u672c\u5b9e\u73b080%\u6210\u529f\u7387\u3002", "motivation": "\u7814\u7a76\u5728\u53ef\u9a8c\u8bc1\u6267\u884c\u57fa\u7840\u4efb\u52a1\u4e2d\uff0c\u8ba1\u7b97\u8d44\u6e90\u7684\u6700\u4f18\u5206\u914d\u7b56\u7565\u3002\u4f20\u7edf\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u901a\u8fc7\u68af\u5ea6\u66f4\u65b0\u9002\u5e94\u6a21\u578b\uff0c\u4f46\u5728\u5bc6\u96c6\u8fde\u7eed\u5956\u52b1\u4fe1\u53f7\u7684\u4efb\u52a1\u4e2d\uff0c\u8fd9\u79cd\u9002\u5e94\u7b56\u7565\u662f\u5426\u6700\u4f18\uff1f", "method": "\u4f7f\u7528KernelBench\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0cGPT-OSS-120B\u6a21\u578b\u3002\u6bd4\u8f83\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u4e0e\u641c\u7d22\u7b56\u7565\uff08\u6700\u4f73N\u91c7\u6837\uff09\u3002\u63d0\u51fa\u60ca\u5947\u5ea6\u5f15\u5bfc\u9009\u62e9\u7b56\u7565\uff1a\u9009\u62e9\u6700\u9ad8\u60ca\u5947\u5ea6\uff08\u6700\u4f4e\u7f6e\u4fe1\u5ea6\uff09\u7684\u6b63\u786e\u6837\u672c\u3002", "result": "\u6700\u4f73N\u91c7\u6837\uff08K=64\uff09\u8fbe\u523090%\u4efb\u52a1\u6210\u529f\u7387\uff0818/20\uff09\uff0c\u800cTTT\u6700\u4f73\u68c0\u67e5\u70b9\u4ec530.6%\u3002\u60ca\u5947\u5ea6\u5f15\u5bfc\u9009\u62e9\u5b9e\u73b080%\u6210\u529f\u7387\uff0c\u6bd4\u6700\u7f6e\u4fe1\u9009\u62e9\u63d0\u9ad830%\u3002\u60ca\u5947\u5ea6\u5f15\u5bfc\u524d3\u9009\u62e9\u8fbe\u5230100%\u6210\u529f\u7387\uff0c\u5339\u914doracle\u6027\u80fd\u3002", "conclusion": "\u5bf9\u4e8e\u5bc6\u96c6\u5956\u52b1\u7684\u53ef\u9a8c\u8bc1\u6267\u884c\u57fa\u7840\u4efb\u52a1\uff0c\u8ba1\u7b97\u8d44\u6e90\u5e94\u5206\u914d\u7ed9\u6837\u672c\u591a\u6837\u6027\u548c\u667a\u80fd\u9009\u62e9\uff0c\u800c\u975e\u68af\u5ea6\u9002\u5e94\u3002\u60ca\u5947\u5ea6\u5f15\u5bfc\u9009\u62e9\u539f\u5219\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6267\u884c\u57fa\u7840\u9886\u57df\uff0c\u5176\u4e2d\u6700\u4f18\u89e3\u4f4d\u4e8e\u5206\u5e03\u5c3e\u90e8\u3002"}}
{"id": "2602.08716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08716", "abs": "https://arxiv.org/abs/2602.08716", "authors": ["Shangrui Nie", "Kian Omoomi", "Lucie Flek", "Zhixue Zhao", "Charles Welch"], "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments", "comment": "15 pages, 1 figure", "summary": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.", "AI": {"tldr": "PERSPECTRA\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u591a\u5143\u4e3b\u4e49\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u7ed3\u5408\u4e86Kialo\u7684\u8fa9\u8bba\u56fe\u7ed3\u6784\u548cReddit\u7684\u8bed\u8a00\u591a\u6837\u6027\uff0c\u5305\u542b3,810\u4e2a\u6269\u5c55\u8bba\u70b9\uff0c\u8986\u76d6100\u4e2a\u4e89\u8bae\u8bdd\u9898\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u7f3a\u4e4f\u5bf9\u591a\u5143\u4e3b\u4e49\uff08\u5bb9\u7eb3\u4e0d\u540c\u89c2\u70b9\u800c\u4e0d\u5c06\u5176\u7b80\u5316\u4e3a\u5355\u4e00\u89c6\u89d2\uff09\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u9700\u8981\u7ed3\u5408\u7ed3\u6784\u6e05\u6670\u548c\u8bed\u8a00\u591a\u6837\u7684\u8fa9\u8bba\u6570\u636e\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u7684\u68c0\u7d22-\u6269\u5c55\u6d41\u7a0b\uff0c\u5c06Kialo\u7684\u8fa9\u8bba\u56fe\u7ed3\u6784\u4e0eReddit\u7684\u81ea\u7136\u8ba8\u8bba\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u4e86\u5305\u542b3,810\u4e2a\u6269\u5c55\u8bba\u70b9\u7684\u6570\u636e\u96c6\uff0c\u8986\u76d6100\u4e2a\u4e89\u8bae\u8bdd\u9898\u7684762\u4e2a\u6b63\u53cd\u7acb\u573a\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6700\u5148\u8fdb\u7684LLM\u5728\u591a\u5143\u4e3b\u4e49\u7406\u89e3\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5931\u8d25\uff0c\u5305\u62ec\u9ad8\u4f30\u89c2\u70b9\u6570\u91cf\u3001\u8bef\u5206\u7c7b\u8ba9\u6b65\u7ed3\u6784\u7b49\uff0c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u591a\u5143\u4e3b\u4e49\u611f\u77e5\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "PERSPECTRA\u901a\u8fc7\u7ed3\u5408\u591a\u6837\u6027\u548c\u7ed3\u6784\uff0c\u5efa\u7acb\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u914d\u7f6e\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5982\u4f55\u8868\u793a\u3001\u533a\u5206\u548c\u63a8\u7406\u591a\u4e2a\u89c2\u70b9\uff0c\u586b\u8865\u4e86\u591a\u5143\u4e3b\u4e49\u8bc4\u4f30\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.08449", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08449", "abs": "https://arxiv.org/abs/2602.08449", "authors": ["Igor Santos-Grueiro"], "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment", "comment": "25 pages, 4 figures,", "summary": "Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability. Within this framework, we show that divergence between evaluation-time and deployment-time behavior is bounded by the mutual information between internal representations and the regime variable. Motivated by this result, we study regime-blind mechanisms: training-time interventions that reduce the extractability of regime information at decision-relevant internal representations via adversarial invariance. We evaluate this approach on a base, open-weight language model across two fully characterized failure modes -scientific sycophancy and temporal sleeper agents. Regime-blind training suppresses regime-conditioned behavior in both evaluated cases without measurable loss of task utility, but with qualitatively different dynamics: sycophancy exhibits a sharp representational and behavioral transition at low intervention strength, whereas sleeper-agent behavior requires substantially stronger pressure and does not exhibit a clean collapse of regime decodability. These results demonstrate that representational invariance is a meaningful but fundamentally limited control lever, whose effectiveness depends on how regime information is embedded in the policy. We argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and information flow.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u5bf9\u9f50\u8bc4\u4f30\u91cd\u6784\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u4e0b\u7684\u4fe1\u606f\u6d41\u95ee\u9898\uff0c\u8bc1\u660e\u8bc4\u4f30\u4e0e\u90e8\u7f72\u884c\u4e3a\u5dee\u5f02\u53d7\u5185\u90e8\u8868\u793a\u4e0e\u5236\u5ea6\u53d8\u91cf\u4e92\u4fe1\u606f\u9650\u5236\uff0c\u5e76\u901a\u8fc7\u5236\u5ea6\u76f2\u8bad\u7ec3\u51cf\u5c11\u5236\u5ea6\u4fe1\u606f\u63d0\u53d6\u6027\u6765\u6291\u5236\u6761\u4ef6\u6027\u7b56\u7565\u3002", "motivation": "\u4f20\u7edfAI\u5b89\u5168\u8bc4\u4f30\u5047\u8bbe\u8bc4\u4f30\u65f6\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u80fd\u9884\u6d4b\u90e8\u7f72\u65f6\u7684\u884c\u4e3a\uff0c\u4f46\u5bf9\u4e8e\u5177\u6709\u60c5\u5883\u610f\u8bc6\u7684\u667a\u80fd\u4f53\uff0c\u8fd9\u79cd\u5047\u8bbe\u53d8\u5f97\u8106\u5f31\u3002\u8fd9\u7c7b\u667a\u80fd\u4f53\u53ef\u80fd\u5229\u7528\"\u5236\u5ea6\u6cc4\u6f0f\"\uff08\u533a\u5206\u8bc4\u4f30\u4e0e\u90e8\u7f72\u7684\u4fe1\u606f\u7ebf\u7d22\uff09\u5b9e\u65bd\u6761\u4ef6\u6027\u7b56\u7565\uff08\u5982\u8c04\u5a9a\u548c\u6f5c\u4f0f\u4ee3\u7406\uff09\uff0c\u5728\u76d1\u7763\u4e0b\u4fdd\u6301\u5408\u89c4\u4f46\u5728\u90e8\u7f72\u65f6\u8fdd\u89c4\u3002", "method": "\u5c06\u5bf9\u9f50\u8bc4\u4f30\u91cd\u6784\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u4e0b\u7684\u4fe1\u606f\u6d41\u95ee\u9898\uff0c\u63d0\u51fa\u5236\u5ea6\u76f2\u8bad\u7ec3\u673a\u5236\uff1a\u901a\u8fc7\u5bf9\u6297\u4e0d\u53d8\u6027\u51cf\u5c11\u51b3\u7b56\u76f8\u5173\u5185\u90e8\u8868\u793a\u4e2d\u5236\u5ea6\u4fe1\u606f\u7684\u53ef\u63d0\u53d6\u6027\u3002\u5728\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e24\u79cd\u5b8c\u5168\u8868\u5f81\u7684\u6545\u969c\u6a21\u5f0f\uff08\u79d1\u5b66\u8c04\u5a9a\u548c\u65f6\u95f4\u6f5c\u4f0f\u4ee3\u7406\uff09\u3002", "result": "\u5236\u5ea6\u76f2\u8bad\u7ec3\u5728\u4e24\u79cd\u8bc4\u4f30\u6848\u4f8b\u4e2d\u90fd\u6291\u5236\u4e86\u5236\u5ea6\u6761\u4ef6\u884c\u4e3a\uff0c\u4e14\u6ca1\u6709\u53ef\u6d4b\u91cf\u7684\u4efb\u52a1\u6548\u7528\u635f\u5931\uff0c\u4f46\u8868\u73b0\u51fa\u4e0d\u540c\u52a8\u6001\uff1a\u8c04\u5a9a\u5728\u4f4e\u5e72\u9884\u5f3a\u5ea6\u4e0b\u8868\u73b0\u51fa\u6025\u5267\u7684\u8868\u793a\u548c\u884c\u4e3a\u8f6c\u53d8\uff0c\u800c\u6f5c\u4f0f\u4ee3\u7406\u884c\u4e3a\u9700\u8981\u66f4\u5f3a\u7684\u538b\u529b\u4e14\u6ca1\u6709\u8868\u73b0\u51fa\u5236\u5ea6\u53ef\u89e3\u7801\u6027\u7684\u6e05\u6670\u5d29\u6e83\u3002", "conclusion": "\u8868\u793a\u4e0d\u53d8\u6027\u662f\u6709\u610f\u4e49\u4f46\u6839\u672c\u6709\u9650\u7684\u63a7\u5236\u6760\u6746\uff0c\u5176\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5236\u5ea6\u4fe1\u606f\u5728\u7b56\u7565\u4e2d\u7684\u5d4c\u5165\u65b9\u5f0f\u3002\u884c\u4e3a\u8bc4\u4f30\u5e94\u8f85\u4ee5\u5236\u5ea6\u610f\u8bc6\u548c\u4fe1\u606f\u6d41\u7684\u767d\u76d2\u8bca\u65ad\u3002"}}
{"id": "2602.07671", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07671", "abs": "https://arxiv.org/abs/2602.07671", "authors": ["Mohan Li", "Dario Fenoglio", "Martin Gjoreski", "Marc Langheinrich"], "title": "Federated Learning with Profile Mapping under Distribution Shifts and Drifts", "comment": "ICLR2026", "summary": "Federated Learning (FL) enables decentralized model training across clients without sharing raw data, but its performance degrades under real-world data heterogeneity. Existing methods often fail to address distribution shift across clients and distribution drift over time, or they rely on unrealistic assumptions such as known number of client clusters and data heterogeneity types, which limits their generalizability. We introduce Feroma, a novel FL framework that explicitly handles both distribution shift and drift without relying on client or cluster identity. Feroma builds on client distribution profiles-compact, privacy-preserving representations of local data-that guide model aggregation and test-time model assignment through adaptive similarity-based weighting. This design allows Feroma to dynamically select aggregation strategies during training, ranging from clustered to personalized, and deploy suitable models to unseen, and unlabeled test clients without retraining, online adaptation, or prior knowledge on clients' data. Extensive experiments show that compared to 10 state-of-the-art methods, Feroma improves performance and stability under dynamic data heterogeneity conditions-an average accuracy gain of up to 12 percentage points over the best baselines across 6 benchmarks-while maintaining computational and communication overhead comparable to FedAvg. These results highlight that distribution-profile-based aggregation offers a practical path toward robust FL under both data distribution shifts and drifts.", "AI": {"tldr": "Feroma\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u5206\u5e03\u914d\u7f6e\u6587\u4ef6\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\uff0c\u65e0\u9700\u5ba2\u6237\u7aef\u8eab\u4efd\u4fe1\u606f\u5373\u53ef\u52a8\u6001\u9009\u62e9\u805a\u5408\u7b56\u7565\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u90e8\u7f72\u5408\u9002\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u5f02\u8d28\u6027\uff08\u5ba2\u6237\u7aef\u95f4\u7684\u5206\u5e03\u504f\u79fb\u548c\u968f\u65f6\u95f4\u7684\u53d8\u5316\uff09\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u901a\u5e38\u4f9d\u8d56\u4e0d\u73b0\u5b9e\u7684\u5047\u8bbe\uff08\u5982\u5df2\u77e5\u5ba2\u6237\u7aef\u96c6\u7fa4\u6570\u91cf\u3001\u6570\u636e\u5f02\u8d28\u6027\u7c7b\u578b\uff09\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "Feroma\u57fa\u4e8e\u5ba2\u6237\u7aef\u5206\u5e03\u914d\u7f6e\u6587\u4ef6\uff08\u672c\u5730\u6570\u636e\u7684\u7d27\u51d1\u9690\u79c1\u4fdd\u62a4\u8868\u793a\uff09\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u76f8\u4f3c\u6027\u52a0\u6743\u6307\u5bfc\u6a21\u578b\u805a\u5408\u548c\u6d4b\u8bd5\u65f6\u6a21\u578b\u5206\u914d\u3002\u8be5\u8bbe\u8ba1\u5141\u8bb8\u52a8\u6001\u9009\u62e9\u805a\u5408\u7b56\u7565\uff08\u4ece\u96c6\u7fa4\u5316\u5230\u4e2a\u6027\u5316\uff09\uff0c\u5e76\u4e3a\u672a\u89c1\u3001\u672a\u6807\u8bb0\u7684\u6d4b\u8bd5\u5ba2\u6237\u7aef\u90e8\u7f72\u5408\u9002\u6a21\u578b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3001\u5728\u7ebf\u9002\u5e94\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u57286\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e10\u4e2a\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0cFeroma\u5728\u52a8\u6001\u6570\u636e\u5f02\u8d28\u6027\u6761\u4ef6\u4e0b\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u5e73\u5747\u51c6\u786e\u7387\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa\u6700\u591a12\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eFedAvg\u76f8\u5f53\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u57fa\u4e8e\u5206\u5e03\u914d\u7f6e\u6587\u4ef6\u7684\u805a\u5408\u4e3a\u5728\u6570\u636e\u5206\u5e03\u504f\u79fb\u548c\u53d8\u5316\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2602.08740", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08740", "abs": "https://arxiv.org/abs/2602.08740", "authors": ["Gaifan Zhang", "Danushka Bollegala"], "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy", "comment": null, "summary": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.", "AI": {"tldr": "\u63d0\u51fa\u5927\u89c4\u6a21\u6bd4\u8f83\u548c\u53ef\u89c6\u5316\u53e5\u5b50\u7f16\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u521b\u5efa\u7f16\u7801\u5668\u5730\u56fe\uff0c\u5c061101\u4e2a\u516c\u5f00\u53e5\u5b50\u7f16\u7801\u5668\u5728\u7a7a\u95f4\u4e2d\u5b9a\u4f4d\uff0c\u53cd\u6620\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u80fd\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u53e5\u5b50\u7f16\u7801\u5668\u6570\u91cf\u5e9e\u5927\u4e14\u591a\u6837\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6bd4\u8f83\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5927\u89c4\u6a21\u5206\u6790\u7f16\u7801\u5668\u5173\u7cfb\u5e76\u53cd\u6620\u5176\u7279\u6027\u7684\u6846\u67b6\u3002", "method": "\u9996\u5148\u7528\u53e5\u5b50\u96c6\u7684\u5d4c\u5165\u77e9\u9635\u8868\u793a\u6bcf\u4e2a\u7f16\u7801\u5668\uff0c\u7136\u540e\u8ba1\u7b97\u5176\u6210\u5bf9\u5185\u79ef\uff08PIP\uff09\u77e9\u9635\uff0c\u6700\u540e\u57fa\u4e8e\u4e0e\u5355\u4f4d\u57fa\u7f16\u7801\u5668\u7684\u91cf\u5b50\u76f8\u5bf9\u71b5\uff08QRE\uff09\u4e3a\u6bcf\u4e2a\u7f16\u7801\u5668\u521b\u5efa\u7279\u5f81\u5411\u91cf\uff0c\u6784\u5efa\u7f16\u7801\u5668\u5730\u56fe\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b1101\u4e2a\u516c\u5f00\u53e5\u5b50\u7f16\u7801\u5668\u7684\u5730\u56fe\uff0c\u51c6\u786e\u53cd\u6620\u4e86\u7f16\u7801\u5668\u95f4\u7684\u5404\u79cd\u5173\u7cfb\uff0c\u76f8\u4f3c\u5c5e\u6027\u7684\u7f16\u7801\u5668\u5728\u5730\u56fe\u4e0a\u4f4d\u7f6e\u76f8\u8fd1\u3002\u7f16\u7801\u5668\u7279\u5f81\u5411\u91cf\u80fd\u51c6\u786e\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u68c0\u7d22\u548c\u805a\u7c7b\uff09\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9884\u8bad\u7ec3\u53e5\u5b50\u7f16\u7801\u5668\u666f\u89c2\u7684\u65b0\u89c6\u89d2\uff0c\u521b\u5efa\u7684\u5730\u56fe\u80fd\u51c6\u786e\u53cd\u6620\u7f16\u7801\u5668\u5173\u7cfb\u5e76\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u7f16\u7801\u5668\u6bd4\u8f83\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.08517", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08517", "abs": "https://arxiv.org/abs/2602.08517", "authors": ["Shaoang Zhang", "Yazhe Niu"], "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor", "comment": null, "summary": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.", "AI": {"tldr": "TreeTensor\uff1a\u4e00\u79cd\u7528\u4e8e\u5904\u7406\u5d4c\u5957\u6570\u636e\u7684\u901a\u7528\u5bb9\u5668\uff0c\u652f\u6301\u96f6\u6210\u672c\u5e94\u7528\u4efb\u610f\u51fd\u6570\u548c\u64cd\u4f5c\u5230\u5d4c\u5957\u6570\u636e\uff0c\u517c\u5bb9\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5e93", "motivation": "\u4f20\u7edf\u5f20\u91cf\u5728\u5904\u7406\u590d\u6742\u8ba4\u77e5AI\u7cfb\u7edf\u4e2d\u7684\u5206\u5c42\u7ed3\u6784\uff08\u5d4c\u5957\uff09\u6570\u636e\u65f6\u5b58\u5728\u4e0d\u4fbf\u548c\u4f4e\u6548\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u6570\u636e\u5bb9\u5668", "method": "\u63d0\u51faTreeTensor\u901a\u7528\u5d4c\u5957\u6570\u636e\u5bb9\u5668\uff0c\u901a\u8fc7\u7ea6\u675f\u6811\u7ed3\u6784\u548c\u9b54\u6cd5\u5de5\u5177\uff0c\u652f\u6301\u5bf9\u5d4c\u5957\u6570\u636e\u5e94\u7528\u4efb\u610f\u51fd\u6570\u548c\u64cd\u4f5c\uff0c\u517c\u5bb9Scikit-Learn\u3001Numpy\u3001PyTorch\u7b49\u5e93", "result": "TreeTensor\u5728\u5404\u79cd\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684AlphaStar\u7cfb\u7edf\u4e2d\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u8fd0\u884c\u65f6\u6548\u7387\u4e14\u65e0\u989d\u5916\u5f00\u9500", "conclusion": "TreeTensor\u4e3a\u89e3\u51b3\u5d4c\u5957\u6570\u636e\u5904\u7406\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u652f\u6301\u4e0e\u5f02\u6b65\u6267\u884c\u548c\u53d8\u957f\u6570\u636e\u8ba1\u7b97\u7b49\u5176\u4ed6\u65b9\u6cd5\u7ed3\u5408\u6269\u5c55\u66f4\u591a\u7528\u9014"}}
{"id": "2602.07674", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07674", "abs": "https://arxiv.org/abs/2602.07674", "authors": ["Bohdan Turbal", "Iryna Voitsitska", "Lesia Semenova"], "title": "ElliCE: Efficient and Provably Robust Algorithmic Recourse via the Rashomon Sets", "comment": null, "summary": "Machine learning models now influence decisions that directly affect people's lives, making it important to understand not only their predictions, but also how individuals could act to obtain better results. Algorithmic recourse provides actionable input modifications to achieve more favorable outcomes, typically relying on counterfactual explanations to suggest such changes. However, when the Rashomon set - the set of near-optimal models - is large, standard counterfactual explanations can become unreliable, as a recourse action valid for one model may fail under another. We introduce ElliCE, a novel framework for robust algorithmic recourse that optimizes counterfactuals over an ellipsoidal approximation of the Rashomon set. The resulting explanations are provably valid over this ellipsoid, with theoretical guarantees on uniqueness, stability, and alignment with key feature directions. Empirically, ElliCE generates counterfactuals that are not only more robust but also more flexible, adapting to user-specified feature constraints while being substantially faster than existing baselines. This provides a principled and practical solution for reliable recourse under model uncertainty, ensuring stable recommendations for users even as models evolve.", "AI": {"tldr": "ElliCE\u6846\u67b6\u901a\u8fc7\u692d\u5706\u8fd1\u4f3cRashomon\u96c6\u6765\u751f\u6210\u9c81\u68d2\u7684\u53ef\u8bc9\u6027\u89e3\u91ca\uff0c\u786e\u4fdd\u5728\u4e0d\u540c\u6a21\u578b\u4e0b\u90fd\u6709\u6548\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\u66f4\u7075\u6d3b\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f71\u54cd\u4eba\u4eec\u751f\u6d3b\u51b3\u7b56\uff0c\u9700\u8981\u7406\u89e3\u5982\u4f55\u83b7\u5f97\u66f4\u597d\u7ed3\u679c\u3002\u5f53Rashomon\u96c6\uff08\u8fd1\u4f3c\u6700\u4f18\u6a21\u578b\u96c6\u5408\uff09\u5f88\u5927\u65f6\uff0c\u4f20\u7edf\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u53ef\u80fd\u4e0d\u53ef\u9760\uff0c\u56e0\u4e3a\u5bf9\u4e00\u4e2a\u6a21\u578b\u6709\u6548\u7684\u53ef\u8bc9\u884c\u52a8\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6a21\u578b\u65e0\u6548\u3002", "method": "\u63d0\u51faElliCE\u6846\u67b6\uff0c\u901a\u8fc7\u692d\u5706\u8fd1\u4f3cRashomon\u96c6\u6765\u4f18\u5316\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u786e\u4fdd\u5728\u8be5\u692d\u5706\u533a\u57df\u5185\u89e3\u91ca\u6709\u6548\u3002\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u5305\u62ec\u552f\u4e00\u6027\u3001\u7a33\u5b9a\u6027\u548c\u4e0e\u5173\u952e\u7279\u5f81\u65b9\u5411\u7684\u5bf9\u9f50\u3002", "result": "ElliCE\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e0d\u4ec5\u66f4\u9c81\u68d2\uff0c\u800c\u4e14\u66f4\u7075\u6d3b\uff0c\u80fd\u9002\u5e94\u7528\u6237\u6307\u5b9a\u7684\u7279\u5f81\u7ea6\u675f\uff0c\u8ba1\u7b97\u901f\u5ea6\u663e\u8457\u5feb\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ElliCE\u4e3a\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u53ef\u9760\u53ef\u8bc9\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u5373\u4f7f\u6a21\u578b\u6f14\u53d8\uff0c\u7528\u6237\u4e5f\u80fd\u83b7\u5f97\u7a33\u5b9a\u7684\u63a8\u8350\u3002"}}
{"id": "2602.08793", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.08793", "abs": "https://arxiv.org/abs/2602.08793", "authors": ["Yushi Sun", "Xujia Li", "Nan Tang", "Quanqing Xu", "Chuanhui Yang", "Lei Chen"], "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation", "comment": null, "summary": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.", "AI": {"tldr": "LakeHopper\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u77e5\u8bc6\u5dee\u8ddd\u3001\u805a\u7c7b\u9009\u62e9\u6570\u636e\u548c\u589e\u91cf\u5fae\u8c03\uff0c\u5c06\u9884\u8bad\u7ec3LM\u6a21\u578b\u9002\u5e94\u5230\u65b0\u6570\u636e\u6e56\uff0c\u51cf\u5c11\u6807\u6ce8\u9700\u6c42", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u5217\u7c7b\u578b\u6807\u6ce8\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u4e14\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u6e56\u8bad\u7ec3\u3002\u5f53\u9762\u5bf9\u65b0\u6570\u636e\u6e56\u65f6\uff0c\u9700\u8981\u91cd\u65b0\u6807\u6ce8\u5927\u91cf\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u3002\u7814\u7a76\u5982\u4f55\u5c06\u5df2\u6709\u6a21\u578b\u9002\u5e94\u5230\u65b0\u6570\u636e\u6e56\uff0c\u6700\u5c0f\u5316\u65b0\u6570\u636e\u6e56\u7684\u6807\u6ce8\u9700\u6c42\u3002", "method": "\u63d0\u51faLakeHopper\u6846\u67b6\uff1a1) \u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u8bc6\u522b\u6e90\u6570\u636e\u6e56\u548c\u76ee\u6807\u6570\u636e\u6e56\u4e4b\u95f4\u7684\u77e5\u8bc6\u5dee\u8ddd\uff1b2) \u91c7\u7528\u57fa\u4e8e\u805a\u7c7b\u7684\u6570\u636e\u9009\u62e9\u65b9\u6848\u4ece\u672a\u6807\u6ce8\u5217\u4e2d\u9009\u62e9\u4fe1\u606f\u91cf\u5927\u7684\u6570\u636e\uff1b3) \u4f7f\u7528\u589e\u91cf\u5fae\u8c03\u673a\u5236\u9010\u6b65\u5c06\u6e90\u6a21\u578b\u9002\u5e94\u5230\u76ee\u6807\u6570\u636e\u6e56\uff0c\u907f\u514d\u4e22\u5931\u5171\u4eab\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLakeHopper\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u6e56\u8fc1\u79fb\u4efb\u52a1\u4e2d\uff0c\u5728\u4f4e\u8d44\u6e90\u548c\u9ad8\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u90fd\u6709\u6548\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u65b0\u6570\u636e\u6e56\u7684\u6807\u6ce8\u9700\u6c42\u3002", "conclusion": "LakeHopper\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u5230\u65b0\u6570\u636e\u6e56\u7684\u6311\u6218\uff0c\u901a\u8fc7\u77e5\u8bc6\u5dee\u8ddd\u8bc6\u522b\u3001\u667a\u80fd\u6570\u636e\u9009\u62e9\u548c\u589e\u91cf\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u5728\u6700\u5c0f\u5316\u6807\u6ce8\u9700\u6c42\u4e0b\u7684\u6709\u6548\u8fc1\u79fb\u3002"}}
{"id": "2602.08520", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08520", "abs": "https://arxiv.org/abs/2602.08520", "authors": ["Xinhai Sun"], "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning", "comment": null, "summary": "Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \\emph{without any retraining}.\n  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\\% to 84.03\\%, while only incurring 61.06\\% additional inference calls. A 100\\% re-asking ablation reaches 84.35\\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \\emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.\n  Beyond providing a practical inference-time upgrade, our results suggest a broader \\emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.", "AI": {"tldr": "\u63d0\u51faReinforcement Inference\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u6027\u8c03\u7528\u7b2c\u4e8c\u6b21\u63a8\u7406\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u63d0\u5347LLM\u6027\u80fd", "motivation": "\u4f20\u7edf\u7684\u4e00\u6b21\u6027\u8d2a\u5a6a\u63a8\u7406\u534f\u8bae\u4f1a\u7cfb\u7edf\u6027\u4f4e\u4f30\u6a21\u578b\u7684\u771f\u5b9e\u80fd\u529b\uff0c\u8bb8\u591a\u9519\u8bef\u6e90\u4e8e\u5185\u90e8\u6a21\u7cca\u6027\u4e0b\u7684\u8fc7\u65e9\u51b3\u7b56\uff0c\u800c\u975e\u77e5\u8bc6\u7f3a\u5931", "method": "\u57fa\u4e8e\u71b5\u611f\u77e5\u7684\u63a8\u7406\u65f6\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u7528\u6a21\u578b\u81ea\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u63a7\u5236\u4fe1\u53f7\uff0c\u9009\u62e9\u6027\u89e6\u53d1\u7b2c\u4e8c\u6b21\u66f4\u614e\u91cd\u7684\u63a8\u7406\u5c1d\u8bd5", "result": "\u5728MMLU-Pro\u768412,032\u4e2a\u95ee\u9898\u4e0a\uff0c\u51c6\u786e\u7387\u4ece60.72%\u63d0\u5347\u523084.03%\uff0c\u4ec5\u589e\u52a061.06%\u7684\u63a8\u7406\u8c03\u7528\uff1b100%\u91cd\u95ee\u8fbe\u523084.35%", "conclusion": "\u63d0\u51fa\u71b5\u611f\u77e5\u8303\u5f0f\u7528\u4e8e\u8861\u91cf\u548c\u6269\u5c55\u6a21\u578b\u80fd\u529b\uff0c\u4e0d\u786e\u5b9a\u6027\u8c03\u8282\u7684\u6df1\u601d\u719f\u8651\u4e0e\u4e00\u6b21\u6027\u8d2a\u5a6a\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\u53ef\u4f5c\u4e3a\u8bca\u65ad\u6a21\u578b\u6f5c\u5728\u63a8\u7406\u89c6\u91ce\u7684\u900f\u955c"}}
{"id": "2602.07679", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07679", "abs": "https://arxiv.org/abs/2602.07679", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Jing Yang", "Yongsen Zheng", "Kwok-Yan Lam", "Liang Lin", "Keze Wang"], "title": "Spectral Gating Networks", "comment": null, "summary": "Gating mechanisms are ubiquitous, yet a complementary question in feed-forward networks remains under-explored: how to introduce frequency-rich expressivity without sacrificing stability and scalability? This tension is exposed by spline-based Kolmogorov-Arnold Network (KAN) parameterizations, where grid refinement can induce parameter growth and brittle optimization in high dimensions. To propose a stability-preserving way to inject spectral capacity into existing MLP/FFN layers under fixed parameter and training budgets, we introduce Spectral Gating Networks (SGN), a drop-in spectral reparameterization. SGN augments a standard activation pathway with a compact spectral pathway and learnable gates that allow the model to start from a stable base behavior and progressively allocate capacity to spectral features during training. The spectral pathway is instantiated with trainable Random Fourier Features (learned frequencies and phases), replacing grid-based splines and removing resolution dependence. A hybrid GELU-Fourier formulation further improves optimization robustness while enhancing high-frequency fidelity. Across vision, NLP, audio, and PDE benchmarks, SGN consistently improves accuracy-efficiency trade-offs under comparable computational budgets, achieving 93.15% accuracy on CIFAR-10 and up to 11.7x faster inference than spline-based KAN variants. Code and trained models will be released.", "AI": {"tldr": "\u63d0\u51faSGN\uff08\u8c31\u95e8\u63a7\u7f51\u7edc\uff09\uff0c\u4e00\u79cd\u5728\u56fa\u5b9a\u53c2\u6570\u548c\u8bad\u7ec3\u9884\u7b97\u4e0b\u5411MLP/FFN\u5c42\u6ce8\u5165\u8c31\u5bb9\u91cf\u7684\u7a33\u5b9a\u65b9\u6cd5\uff0c\u66ff\u4ee3\u57fa\u4e8e\u7f51\u683c\u7684\u6837\u6761\u53c2\u6570\u5316\uff0c\u63d0\u5347\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\u3002", "motivation": "\u524d\u9988\u7f51\u7edc\u4e2d\u5982\u4f55\u5728\u4e0d\u727a\u7272\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u60c5\u51b5\u4e0b\u5f15\u5165\u4e30\u5bcc\u7684\u9891\u7387\u8868\u8fbe\u80fd\u529b\uff1f\u57fa\u4e8e\u6837\u6761\u7684KAN\u53c2\u6570\u5316\u5728\u7f51\u683c\u7ec6\u5316\u65f6\u4f1a\u5bfc\u81f4\u53c2\u6570\u589e\u957f\u548c\u8106\u5f31\u7684\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u4fdd\u6301\u7a33\u5b9a\u7684\u8c31\u5bb9\u91cf\u6ce8\u5165\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSGN\uff08\u8c31\u95e8\u63a7\u7f51\u7edc\uff09\uff0c\u5728\u6807\u51c6\u6fc0\u6d3b\u8def\u5f84\u57fa\u7840\u4e0a\u589e\u52a0\u7d27\u51d1\u7684\u8c31\u8def\u5f84\u548c\u53ef\u5b66\u4e60\u95e8\u63a7\u3002\u8c31\u8def\u5f84\u4f7f\u7528\u53ef\u8bad\u7ec3\u7684\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08\u5b66\u4e60\u9891\u7387\u548c\u76f8\u4f4d\uff09\uff0c\u66ff\u4ee3\u57fa\u4e8e\u7f51\u683c\u7684\u6837\u6761\uff0c\u6d88\u9664\u5206\u8fa8\u7387\u4f9d\u8d56\u3002\u91c7\u7528\u6df7\u5408GELU-\u5085\u91cc\u53f6\u516c\u5f0f\u63d0\u5347\u4f18\u5316\u9c81\u68d2\u6027\u548c\u9ad8\u9891\u4fdd\u771f\u5ea6\u3002", "result": "\u5728\u89c6\u89c9\u3001NLP\u3001\u97f3\u9891\u548cPDE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSGN\u5728\u53ef\u6bd4\u8f83\u7684\u8ba1\u7b97\u9884\u7b97\u4e0b\u6301\u7eed\u6539\u5584\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\uff0c\u5728CIFAR-10\u4e0a\u8fbe\u523093.15%\u51c6\u786e\u7387\uff0c\u6bd4\u57fa\u4e8e\u6837\u6761\u7684KAN\u53d8\u4f53\u63a8\u7406\u901f\u5ea6\u5feb\u8fbe11.7\u500d\u3002", "conclusion": "SGN\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u524d\u9988\u7f51\u7edc\u7684\u8c31\u8868\u8fbe\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u6837\u6761\u57faKAN\u7684\u53c2\u6570\u589e\u957f\u548c\u4f18\u5316\u8106\u5f31\u6027\u95ee\u9898\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd-\u6548\u7387\u5e73\u8861\u3002"}}
{"id": "2602.08826", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08826", "abs": "https://arxiv.org/abs/2602.08826", "authors": ["Chenghui Zou", "Ning Wang", "Tiesunlong Shen", "Luwei Xiao", "Chuan Ma", "Xiangpeng Li", "Rui Mao", "Erik Cambria"], "title": "Affective Flow Language Model for Emotional Support Conversation", "comment": "19 pages, 7 figures", "summary": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.", "AI": {"tldr": "AFlow\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u60c5\u611f\u6d41\u4e3a\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u5728\u7d27\u51d1\u5f00\u6e90\u6a21\u578b\u4e0a\u8d85\u8d8aGPT-4o\u7b49\u4e13\u6709\u6a21\u578b", "motivation": "\u73b0\u6709\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u7ea7\u4fe1\u53f7\uff0c\u5bf9\u4e2d\u95f4\u7b56\u7565\u51b3\u7b56\u7684\u76d1\u7763\u6709\u9650\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u591a\u8f6e\u652f\u6301\u573a\u666f", "method": "\u63d0\u51faAFlow\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u591a\u8f6e\u8f68\u8ff9\u4e0a\u7684\u8fde\u7eed\u60c5\u611f\u6d41\uff0c\u4e3a\u5bf9\u8bdd\u524d\u7f00\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\uff1b\u5f15\u5165\u5b50\u8def\u5f84\u7ea7\u6d41\u5e73\u8861\u76ee\u6807\uff0c\u5c06\u504f\u597d\u4fe1\u53f7\u4f20\u64ad\u5230\u4e2d\u95f4\u72b6\u6001", "result": "\u5728\u591a\u6837\u5316\u60c5\u611f\u8bed\u5883\u4e2d\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u53d6\u5f97\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6539\u8fdb\uff1b\u7d27\u51d1\u5f00\u6e90\u9aa8\u5e72\u6a21\u578b\u5728\u4e3b\u8981ESC\u6307\u6807\u4e0a\u8d85\u8d8aGPT-4o\u548cClaude-3.5\u7b49\u4e13\u6709\u6a21\u578b", "conclusion": "AFlow\u901a\u8fc7\u5efa\u6a21\u60c5\u611f\u6d41\u4e3a\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u63d0\u4f9b\u6709\u6548\u7684\u4e2d\u95f4\u76d1\u7763\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7b56\u7565\u8fde\u8d2f\u6027\u548c\u5171\u60c5\u54cd\u5e94\u8d28\u91cf"}}
{"id": "2602.08533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08533", "abs": "https://arxiv.org/abs/2602.08533", "authors": ["Kun Peng", "Conghui Tan", "Yu Liu", "Guohua Tang", "Zhongqian Sun", "Wei Yang", "Zining Zhu", "Lei Jiang", "Yanbing Liu", "Hao Peng"], "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO", "comment": null, "summary": "Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u5728\u7ebf\u4e2a\u6027\u5316\u4e0e\u81ea\u9002\u5e94\u6811\u57fa\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u957f\u89c6\u91ce\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u6536\u96c6\u6570\u636e\u548c\u77ed\u89c6\u91ce\u504f\u89c1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u9884\u6536\u96c6\u7684\u7528\u6237\u6570\u636e\uff0c\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u77ed\u89c6\u91ce\u504f\u89c1\u5ffd\u7565\u4e86\u5bf9\u8bdd\u7684\u957f\u671f\u4ef7\u503c\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u7ebf\u4e2a\u6027\u5316\u5e76\u8003\u8651\u957f\u671f\u5bf9\u8bdd\u6548\u679c\u7684\u6846\u67b6\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u6e38\u620f\u8303\u5f0f\uff1a\u7528\u6237\u4ee3\u7406\u901a\u8fc7\u98ce\u683c\u6a21\u4eff\u5b66\u4e60\u7528\u6237\u7279\u5b9a\u5bf9\u8bdd\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u7ec8\u6b62\u9884\u6d4b\u56de\u5408\u7ea7\u7ec8\u6b62\u6982\u7387\u4f5c\u4e3a\u5373\u65f6\u5956\u52b1\u6765\u6784\u5efa\u52a8\u6001\u73af\u5883\u3002\u63d0\u51fa\u81ea\u9002\u5e94\u6811\u57fa\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08AT-GRPO\uff09\uff0c\u5c06\u5bf9\u8bdd\u8f68\u8ff9\u91cd\u65b0\u89e3\u91ca\u4e3a\u6811\u7ed3\u6784\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u89c2\u5bdf\u8303\u56f4\uff0c\u6839\u636e\u5bf9\u8bdd\u9636\u6bb5\u8c03\u6574\u5956\u52b1\u805a\u5408\u8303\u56f4\uff0c\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u591a\u9879\u5f0f\u7ea7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5728\u6027\u80fd\u3001\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u65e9\u671f\u8bdd\u9898\u63a2\u7d22\u548c\u540e\u671f\u5bf9\u8bdd\u7ef4\u62a4\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u957f\u89c6\u91ceRL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\u7684\u5728\u7ebf\u4e2a\u6027\u5316\u548c\u957f\u671f\u4ef7\u503c\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7AT-GRPO\u7b97\u6cd5\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u957f\u671f\u5956\u52b1\u6355\u83b7\u7684\u5e73\u8861\uff0c\u4e3a\u5bf9\u8bdd\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.07697", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.07697", "abs": "https://arxiv.org/abs/2602.07697", "authors": ["Francesco Innocenti", "El Mehdi Achour", "Rafal Bogacz"], "title": "On the Infinite Width and Depth Limits of Predictive Coding Networks", "comment": "31 pages, 27 figures", "summary": "Predictive coding (PC) is a biologically plausible alternative to standard backpropagation (BP) that minimises an energy function with respect to network activities before updating weights. Recent work has improved the training stability of deep PC networks (PCNs) by leveraging some BP-inspired reparameterisations. However, the full scalability and theoretical basis of these approaches remains unclear. To address this, we study the infinite width and depth limits of PCNs. For linear residual networks, we show that the set of width- and depth-stable feature-learning parameterisations for PC is exactly the same as for BP. Moreover, under any of these parameterisations, the PC energy with equilibrated activities converges to the BP loss in a regime where the model width is much larger than the depth, resulting in PC computing the same gradients as BP. Experiments show that these results hold in practice for deep nonlinear networks, as long as an activity equilibrium seem to be reached. Overall, this work unifies various previous theoretical and empirical results and has potentially important implications for the scaling of PCNs.", "AI": {"tldr": "PCNs\u5728\u65e0\u9650\u5bbd\u5ea6\u548c\u6df1\u5ea6\u6781\u9650\u4e0b\uff0c\u5176\u7a33\u5b9a\u53c2\u6570\u5316\u4e0eBP\u76f8\u540c\uff0c\u4e14\u5728\u5bbd\u5ea6\u8fdc\u5927\u4e8e\u6df1\u5ea6\u65f6\uff0cPC\u80fd\u91cf\u6536\u655b\u4e8eBP\u635f\u5931\uff0c\u8ba1\u7b97\u76f8\u540c\u68af\u5ea6", "motivation": "\u9884\u6d4b\u7f16\u7801\u4f5c\u4e3a\u751f\u7269\u5408\u7406\u7684\u53cd\u5411\u4f20\u64ad\u66ff\u4ee3\u65b9\u6848\uff0c\u5176\u6df1\u5ea6\u7f51\u7edc\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u7406\u8bba\u57fa\u7840\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7814\u7a76PCNs\u5728\u65e0\u9650\u5bbd\u5ea6\u548c\u6df1\u5ea6\u6781\u9650\u4e0b\u7684\u884c\u4e3a", "method": "\u7814\u7a76\u7ebf\u6027\u6b8b\u5dee\u7f51\u7edc\u7684\u65e0\u9650\u5bbd\u5ea6\u548c\u6df1\u5ea6\u6781\u9650\uff0c\u5206\u6790PCNs\u7684\u5bbd\u5ea6\u548c\u6df1\u5ea6\u7a33\u5b9a\u53c2\u6570\u5316\uff0c\u6bd4\u8f83PC\u80fd\u91cf\u4e0eBP\u635f\u5931\u7684\u6536\u655b\u5173\u7cfb", "result": "PC\u7684\u7a33\u5b9a\u53c2\u6570\u5316\u96c6\u5408\u4e0eBP\u5b8c\u5168\u76f8\u540c\uff1b\u5728\u5bbd\u5ea6\u8fdc\u5927\u4e8e\u6df1\u5ea6\u65f6\uff0cPC\u80fd\u91cf\u6536\u655b\u4e8eBP\u635f\u5931\uff0c\u8ba1\u7b97\u76f8\u540c\u68af\u5ea6\uff1b\u975e\u7ebf\u6027\u7f51\u7edc\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7ed3\u679c", "conclusion": "PCNs\u5728\u9002\u5f53\u53c2\u6570\u5316\u4e0b\u4e0eBP\u5177\u6709\u76f8\u540c\u7684\u7406\u8bba\u6027\u8d28\uff0c\u8fd9\u7edf\u4e00\u4e86\u5148\u524d\u7814\u7a76\u7ed3\u679c\uff0c\u5bf9PCNs\u7684\u89c4\u6a21\u5316\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2602.08829", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08829", "abs": "https://arxiv.org/abs/2602.08829", "authors": ["Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Zijun Yao", "Lei Hou", "Juanzi Li"], "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions", "comment": null, "summary": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.", "AI": {"tldr": "WildReward\uff1a\u76f4\u63a5\u4ece\u7528\u6237\u4ea4\u4e92\u4e2d\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u504f\u597d\u5bf9\uff0c\u6027\u80fd\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u4f20\u7edf\u5956\u52b1\u6a21\u578b", "motivation": "\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\u7684\u504f\u597d\u5bf9\uff0c\u6210\u672c\u9ad8\u6602\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u7528\u6237\u4ea4\u4e92\u6210\u4e3a\u4e30\u5bcc\u7684\u9690\u5f0f\u5956\u52b1\u4fe1\u53f7\u6765\u6e90\uff0c\u80fd\u5426\u76f4\u63a5\u4ece\u8fd9\u4e9b\u4ea4\u4e92\u4e2d\u5f00\u53d1\u5956\u52b1\u6a21\u578b\uff1f", "method": "\u91c7\u7528WildChat\u4f5c\u4e3a\u4ea4\u4e92\u6e90\uff0c\u63d0\u51fa\u4ece\u7528\u6237\u53cd\u9988\u4e2d\u63d0\u53d6\u53ef\u9760\u4eba\u7c7b\u53cd\u9988\u7684\u6d41\u7a0b\uff0c\u901a\u8fc7\u5e8f\u6570\u56de\u5f52\u76f4\u63a5\u5728\u7528\u6237\u53cd\u9988\u4e0a\u8bad\u7ec3WildReward\uff0c\u65e0\u9700\u504f\u597d\u5bf9", "result": "WildReward\u5728\u6027\u80fd\u4e0a\u4e0e\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u5177\u6709\u66f4\u597d\u7684\u6821\u51c6\u6027\u548c\u8de8\u6837\u672c\u4e00\u81f4\u6027\u3002\u7528\u6237\u591a\u6837\u6027\u76f4\u63a5\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u66f4\u591a\u7528\u6237\u5e26\u6765\u66f4\u5f3a\u7684\u5956\u52b1\u6a21\u578b\u3002\u5e94\u7528\u4e8e\u5728\u7ebfDPO\u8bad\u7ec3\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u5747\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "\u76f4\u63a5\u4ece\u7528\u6237\u4ea4\u4e92\u4e2d\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u662f\u53ef\u884c\u7684\uff0cWildReward\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u4e3a\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848"}}
{"id": "2602.08586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08586", "abs": "https://arxiv.org/abs/2602.08586", "authors": ["Yiming Yang", "Zhuoyuan Li", "Fanxiang Zeng", "Hao Fu", "Yue Liu"], "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition", "comment": null, "summary": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.\n  We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.", "AI": {"tldr": "\u63d0\u51faPRISM\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u3001\u4fe1\u606f\u3001\u805a\u5408\u4e09\u4e2a\u7ef4\u5ea6\u4f18\u5316\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff0c\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\uff0c\u4e0d\u6e05\u695a\u6027\u80fd\u63d0\u5347\u7684\u539f\u56e0\u548c\u5982\u4f55\u7cfb\u7edf\u4f18\u5316\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\u6846\u67b6", "method": "\u63d0\u51faPRISM\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u591a\u6837\u6027\u5b9e\u73b0\u63a2\u7d22\uff0c\u57fa\u4e8e\u6267\u884c\u7684\u53cd\u9988\u5b9e\u73b0\u4fe1\u606f\uff0c\u8fed\u4ee3\u5408\u6210\u5b9e\u73b0\u805a\u5408\uff0c\u6700\u5927\u5316\u4e09\u4e2a\u7ef4\u5ea6", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u4f18\u4e8e\u90e8\u5206\u7ef4\u5ea6\u4f18\u5316\u65b9\u6cd5", "conclusion": "\u7406\u8bba\u6846\u67b6\u4e3a\u672a\u6765\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u539f\u5219\uff0cPRISM\u5c55\u793a\u4e86\u8054\u5408\u4f18\u5316\u4e09\u4e2a\u7ef4\u5ea6\u7684\u6709\u6548\u6027"}}
{"id": "2602.07706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07706", "abs": "https://arxiv.org/abs/2602.07706", "authors": ["Yuanyun Zhang", "Mingxuan Zhang", "Siyuan Li", "Zihan Wang", "Haoran Chen", "Wenbo Zhou", "Shi Li"], "title": "Dense Feature Learning via Linear Structure Preservation in Medical Data", "comment": "ICLR Workshop", "summary": "Deep learning models for medical data are typically trained using task specific objectives that encourage representations to collapse onto a small number of discriminative directions. While effective for individual prediction problems, this paradigm underutilizes the rich structure of clinical data and limits the transferability, stability, and interpretability of learned features. In this work, we propose dense feature learning, a representation centric framework that explicitly shapes the linear structure of medical embeddings. Our approach operates directly on embedding matrices, encouraging spectral balance, subspace consistency, and feature orthogonality through objectives defined entirely in terms of linear algebraic properties. Without relying on labels or generative reconstruction, dense feature learning produces representations with higher effective rank, improved conditioning, and greater stability across time. Empirical evaluations across longitudinal EHR data, clinical text, and multimodal patient representations demonstrate consistent improvements in downstream linear performance, robustness, and subspace alignment compared to supervised and self supervised baselines. These results suggest that learning to span clinical variation may be as important as learning to predict clinical outcomes, and position representation geometry as a first class objective in medical AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bc6\u96c6\u7279\u5f81\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5d4c\u5165\u77e9\u9635\u7684\u7ebf\u6027\u4ee3\u6570\u7279\u6027\uff08\u8c31\u5e73\u8861\u3001\u5b50\u7a7a\u95f4\u4e00\u81f4\u6027\u3001\u7279\u5f81\u6b63\u4ea4\u6027\uff09\uff0c\u63d0\u5347\u533b\u5b66\u8868\u5f81\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u65e0\u9700\u6807\u7b7e\u6216\u751f\u6210\u91cd\u5efa\u5373\u53ef\u83b7\u5f97\u66f4\u9ad8\u6709\u6548\u79e9\u3001\u66f4\u597d\u6761\u4ef6\u6570\u548c\u66f4\u5f3a\u7a33\u5b9a\u6027\u7684\u8868\u5f81\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u4efb\u52a1\u7279\u5b9a\u76ee\u6807\u8bad\u7ec3\uff0c\u5bfc\u81f4\u8868\u5f81\u574d\u7f29\u5230\u5c11\u6570\u5224\u522b\u65b9\u5411\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u4e34\u5e8a\u6570\u636e\u7684\u4e30\u5bcc\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u7279\u5f81\u7684\u53ef\u8fc1\u79fb\u6027\u3001\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u5bc6\u96c6\u7279\u5f81\u5b66\u4e60\u6846\u67b6\uff0c\u76f4\u63a5\u64cd\u4f5c\u5d4c\u5165\u77e9\u9635\uff0c\u901a\u8fc7\u8c31\u5e73\u8861\u3001\u5b50\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u7279\u5f81\u6b63\u4ea4\u6027\u7b49\u7ebf\u6027\u4ee3\u6570\u7279\u6027\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\uff0c\u65e0\u9700\u4f9d\u8d56\u6807\u7b7e\u6216\u751f\u6210\u91cd\u5efa\u3002", "result": "\u5728\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u3001\u4e34\u5e8a\u6587\u672c\u548c\u591a\u6a21\u6001\u60a3\u8005\u8868\u5f81\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u76d1\u7763\u548c\u81ea\u76d1\u7763\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0b\u6e38\u7ebf\u6027\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u5b50\u7a7a\u95f4\u5bf9\u9f50\u65b9\u9762\u5747\u6709\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u5b66\u4e60\u8986\u76d6\u4e34\u5e8a\u53d8\u5f02\u4e0e\u5b66\u4e60\u9884\u6d4b\u4e34\u5e8a\u7ed3\u679c\u540c\u7b49\u91cd\u8981\uff0c\u5e94\u5c06\u8868\u5f81\u51e0\u4f55\u7ed3\u6784\u4f5c\u4e3a\u533b\u5b66AI\u7684\u4e00\u7b49\u76ee\u6807\u3002"}}
{"id": "2602.08864", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08864", "abs": "https://arxiv.org/abs/2602.08864", "authors": ["Ibraheem Muhammad Moosa", "Suhas Lohit", "Ye Wang", "Moitreya Chatterjee", "Wenpeng Yin"], "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers", "comment": null, "summary": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faANIRA\u6846\u67b6\uff0c\u5728\u7b97\u6cd5\u548c\u5408\u6210\u8bed\u8a00\u4efb\u52a1\u4e0a\u7cfb\u7edf\u8bc4\u4f30token\u7ea7\u81ea\u9002\u5e94\u8ba1\u7b97\uff0c\u53d1\u73b0\u8ba1\u7b97\u5206\u914d\u80fd\u4e0e\u4efb\u52a1\u590d\u6742\u5ea6\u5bf9\u9f50\u4f46\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u65e9\u671f\u51b3\u7b56\u4f9d\u8d56\u9759\u6001\u7ed3\u6784\u7ebf\u7d22\u800c\u5728\u7ebf\u505c\u6b62\u66f4\u63a5\u8fd1\u7b97\u6cd5\u6267\u884c\u72b6\u6001\u3002", "motivation": "\u73b0\u6709token\u7ea7\u81ea\u9002\u5e94\u8ba1\u7b97\u7814\u7a76\u4e3b\u8981\u5728\u81ea\u7136\u8bed\u8a00\u57fa\u51c6\u4e0a\u4f7f\u7528\u4efb\u52a1\u7ea7\u6307\u6807\u8bc4\u4f30\uff0c\u5176\u4e2dtoken\u7ea7\u96be\u5ea6\u4e0d\u53ef\u89c2\u6d4b\u4e14\u4e0e\u67b6\u6784\u56e0\u7d20\u6df7\u6dc6\uff0c\u65e0\u6cd5\u786e\u5b9a\u8ba1\u7b97\u5206\u914d\u662f\u5426\u771f\u6b63\u4e0e\u5e95\u5c42\u590d\u6742\u5ea6\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u590d\u6742\u5ea6\u63a7\u5236\u7684\u8bc4\u4f30\u8303\u5f0f\uff08\u4f7f\u7528\u53c2\u6570\u5316\u96be\u5ea6\u7684\u7b97\u6cd5\u548c\u5408\u6210\u8bed\u8a00\u4efb\u52a1\uff09\uff0c\u8bbe\u8ba1ANIRA\u7edf\u4e00\u5faa\u73afTransformer\u6846\u67b6\u652f\u6301\u6bcftoken\u53ef\u53d8\u6df1\u5ea6\u8ba1\u7b97\uff0c\u5e76\u9694\u79bb\u8ba1\u7b97\u5206\u914d\u51b3\u7b56\u4e0e\u5176\u4ed6\u6a21\u578b\u56e0\u7d20\u3002", "result": "\u8ba1\u7b97\u5206\u914d\u80fd\u4e0e\u4efb\u52a1\u590d\u6742\u5ea6\u5bf9\u9f50\u800c\u65e0\u9700\u663e\u5f0f\u96be\u5ea6\u76d1\u7763\uff0c\u4f46\u8fd9\u79cd\u5bf9\u9f50\u4e0d\u610f\u5473\u7740\u7b97\u6cd5\u6cdb\u5316\uff1a\u6a21\u578b\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u89c1\u8f93\u5165\u5927\u5c0f\u3002\u65e9\u671f\u8ba1\u7b97\u51b3\u7b56\u4f9d\u8d56\u9759\u6001\u7ed3\u6784\u7ebf\u7d22\uff0c\u800c\u5728\u7ebf\u505c\u6b62\u66f4\u63a5\u8fd1\u7b97\u6cd5\u6267\u884c\u72b6\u6001\u3002", "conclusion": "\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u63ed\u793a\u4e86token\u7ea7\u81ea\u9002\u5e94\u8ba1\u7b97\u7684\u5173\u952e\u7279\u6027\uff1a\u8ba1\u7b97\u5206\u914d\u80fd\u4e0e\u590d\u6742\u5ea6\u5bf9\u9f50\u4f46\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\uff0c\u51b3\u7b56\u65f6\u673a\u5f71\u54cd\u5bf9\u9f50\u8d28\u91cf\uff0c\u4e3a\u672a\u6765\u81ea\u9002\u5e94\u8ba1\u7b97\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.08597", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08597", "abs": "https://arxiv.org/abs/2602.08597", "authors": ["Roland Bertin-Johannet", "Lara Scipio", "Leopold Mayti\u00e9", "Rufin VanRullen"], "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture", "comment": null, "summary": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u7684\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8be5\u673a\u5236\u901a\u8fc7\u9009\u62e9\u76f8\u5173\u6a21\u6001\u6765\u63d0\u5347\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u566a\u58f0\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u4f5c\u4e3a\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u6846\u67b6\uff0c\u867d\u7136\u5df2\u88ab\u7528\u4e8e\u591a\u6a21\u6001\u8868\u793a\u5b66\u4e60\uff0c\u4f46\u5176\u6ce8\u610f\u529b\u673a\u5236\u7814\u7a76\u4e0d\u8db3\u3002\u73b0\u6709GWT\u5b9e\u73b0\u7f3a\u4e4f\u6709\u6548\u7684\u6a21\u6001\u9009\u62e9\u673a\u5236\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u5728\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u5185\u9009\u62e9\u76f8\u5173\u6a21\u6001\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6ce8\u610f\u529b\u6743\u91cd\u52a8\u6001\u9009\u62e9\u5bf9\u5f53\u524d\u4efb\u52a1\u6700\u91cd\u8981\u7684\u6a21\u6001\u4fe1\u606f\uff0c\u5e76\u5728\u4e24\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08Simple Shapes\u548cMM-IMDb 1.0\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "1\uff09\u6ce8\u610f\u529b\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7cfb\u7edf\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u566a\u58f0\u9c81\u68d2\u6027\uff1b2\uff09\u5c55\u793a\u4e86\u6587\u732e\u4e2d\u591a\u6a21\u6001\u6ce8\u610f\u529b\u6a21\u578b\u4e0d\u5177\u5907\u7684\u8de8\u4efb\u52a1\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\uff1b3\uff09\u5728MM-IMDb 1.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u673a\u5236\u4f7f\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7ade\u4e89\u7684\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u589e\u5f3a\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\u5728\u591a\u6a21\u6001\u96c6\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u8fd8\u8d4b\u4e88\u4e86\u72ec\u7279\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f7fGWT\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4efb\u52a1\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2602.07708", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07708", "abs": "https://arxiv.org/abs/2602.07708", "authors": ["Ding Zhang", "Siddharth Betala", "Chirag Agarwal"], "title": "Quantifying Explanation Quality in Graph Neural Networks using Out-of-Distribution Generalization", "comment": null, "summary": "Evaluating the quality of post-hoc explanations for Graph Neural Networks (GNNs) remains a significant challenge. While recent years have seen an increasing development of explainability methods, current evaluation metrics (e.g., fidelity, sparsity) often fail to assess whether an explanation identifies the true underlying causal variables. To address this, we propose the Explanation-Generalization Score (EGS), a metric that quantifies the causal relevance of GNN explanations. EGS is founded on the principle of feature invariance and posits that if an explanation captures true causal drivers, it should lead to stable predictions across distribution shifts. To quantify this, we introduce a framework that trains GNNs using explanatory subgraphs and evaluates their performance in Out-of-Distribution (OOD) settings (here, OOD generalization serves as a rigorous proxy for the explanation's causal validity). Through large-scale validation involving 11,200 model combinations across synthetic and real-world datasets, our results demonstrate that EGS provides a principled benchmark for ranking explainers based on their ability to capture causal substructures, offering a robust alternative to traditional fidelity-based metrics.", "AI": {"tldr": "\u63d0\u51faEGS\u8bc4\u5206\u6307\u6807\uff0c\u901a\u8fc7\u8bc4\u4f30\u89e3\u91ca\u5b50\u56fe\u5728\u5206\u5e03\u5916\u6cdb\u5316\u4e2d\u7684\u7a33\u5b9a\u6027\u6765\u91cf\u5316GNN\u89e3\u91ca\u7684\u56e0\u679c\u76f8\u5173\u6027\uff0c\u4e3a\u89e3\u91ca\u5668\u63d0\u4f9b\u57fa\u4e8e\u56e0\u679c\u6709\u6548\u6027\u7684\u6392\u5e8f\u57fa\u51c6\u3002", "motivation": "\u5f53\u524dGNN\u4e8b\u540e\u89e3\u91ca\u7684\u8d28\u91cf\u8bc4\u4f30\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u6307\u6807\uff08\u5982\u4fdd\u771f\u5ea6\u3001\u7a00\u758f\u6027\uff09\u65e0\u6cd5\u8bc4\u4f30\u89e3\u91ca\u662f\u5426\u8bc6\u522b\u4e86\u771f\u6b63\u7684\u56e0\u679c\u53d8\u91cf\u3002\u9700\u8981\u4e00\u79cd\u80fd\u8bc4\u4f30\u89e3\u91ca\u56e0\u679c\u76f8\u5173\u6027\u7684\u65b0\u6307\u6807\u3002", "method": "\u63d0\u51fa\u89e3\u91ca\u6cdb\u5316\u8bc4\u5206\uff08EGS\uff09\uff0c\u57fa\u4e8e\u7279\u5f81\u4e0d\u53d8\u6027\u539f\u7406\uff1a\u5982\u679c\u89e3\u91ca\u6355\u83b7\u4e86\u771f\u6b63\u7684\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\uff0c\u5e94\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u4ea7\u751f\u7a33\u5b9a\u7684\u9884\u6d4b\u3002\u901a\u8fc7\u4f7f\u7528\u89e3\u91ca\u5b50\u56fe\u8bad\u7ec3GNN\u5e76\u5728OOD\u8bbe\u7f6e\u4e2d\u8bc4\u4f30\u6027\u80fd\u6765\u91cf\u5316\u8fd9\u4e00\u539f\u7406\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e8611,200\u4e2a\u6a21\u578b\u7ec4\u5408\u7684\u5927\u89c4\u6a21\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660eEGS\u80fd\u591f\u57fa\u4e8e\u89e3\u91ca\u5668\u6355\u83b7\u56e0\u679c\u5b50\u7ed3\u6784\u7684\u80fd\u529b\u63d0\u4f9b\u539f\u5219\u6027\u57fa\u51c6\uff0c\u6210\u4e3a\u4f20\u7edf\u4fdd\u771f\u5ea6\u6307\u6807\u7684\u7a33\u5065\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "EGS\u4e3aGNN\u89e3\u91ca\u7684\u56e0\u679c\u6709\u6548\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7OOD\u6cdb\u5316\u4f5c\u4e3a\u4ee3\u7406\u6307\u6807\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u89e3\u91ca\u662f\u5426\u8bc6\u522b\u4e86\u771f\u6b63\u7684\u56e0\u679c\u53d8\u91cf\uff0c\u63a8\u52a8\u4e86GNN\u53ef\u89e3\u91ca\u6027\u8bc4\u4f30\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.08872", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08872", "abs": "https://arxiv.org/abs/2602.08872", "authors": ["G. Cafferata", "T. Demarco", "K. Kalimeri", "Y. Mejova", "M. G. Beir\u00f3"], "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response", "comment": null, "summary": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.", "AI": {"tldr": "LLM-based\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4eba\u9053\u4e3b\u4e49\u6587\u672c\u4e2d\u5730\u7406\u4f4d\u7f6e\u63d0\u53d6\u7684\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5730\u533a", "motivation": "\u4eba\u9053\u4e3b\u4e49\u5371\u673a\u9700\u8981\u53ca\u65f6\u51c6\u786e\u7684\u5730\u7406\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u81ea\u52a8\u5316\u7cfb\u7edf\u5728\u63d0\u53d6\u4f4d\u7f6e\u4fe1\u606f\u65f6\u5f80\u5f80\u590d\u5236\u73b0\u6709\u7684\u5730\u7406\u548c\u793e\u4f1a\u7ecf\u6d4e\u504f\u89c1\uff0c\u5bfc\u81f4\u5371\u673a\u53d7\u5f71\u54cd\u5730\u533a\u7684\u53ef\u89c1\u6027\u4e0d\u5747", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u6b65\u6846\u67b6\uff1a\u7ed3\u5408\u5c11\u6837\u672cLLM\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u5730\u7406\u7f16\u7801\u6a21\u5757\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u89e3\u6790\u6a21\u7cca\u5730\u540d", "result": "LLM-based\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u9884\u8bad\u7ec3\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5730\u533a", "conclusion": "\u901a\u8fc7\u5c06LLM\u63a8\u7406\u8fdb\u5c55\u4e0e\u8d1f\u8d23\u4efb\u548c\u5305\u5bb9\u6027AI\u539f\u5219\u76f8\u7ed3\u5408\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4eba\u9053\u4e3b\u4e49\u54cd\u5e94\u63d0\u4f9b\u4e86\u66f4\u516c\u5e73\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7cfb\u7edf\uff0c\u63a8\u8fdb\u4e86\u5371\u673a\u5206\u6790\u4e2d\"\u4e0d\u843d\u4e0b\u4efb\u4f55\u5730\u65b9\"\u7684\u76ee\u6807"}}
{"id": "2602.08603", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08603", "abs": "https://arxiv.org/abs/2602.08603", "authors": ["Teng Wang", "Rong Shan", "Jianghao Lin", "Junjie Wu", "Tianyi Xu", "Jianping Zhang", "Wenteng Chen", "Changwang Zhang", "Zhaoxiang Wang", "Weinan Zhang", "Jun Wang"], "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval", "comment": null, "summary": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.", "AI": {"tldr": "OSCAR\u662f\u4e00\u4e2a\u7528\u4e8e\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u7684\u4f18\u5316\u5f15\u5bfc\u667a\u80fd\u4f53\u89c4\u5212\u6846\u67b6\uff0c\u5c06\u542f\u53d1\u5f0f\u641c\u7d22\u8f6c\u5316\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u3002", "motivation": "\u73b0\u6709\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u95ee\u9898\uff1a\u7edf\u4e00\u5d4c\u5165\u68c0\u7d22\u5b58\u5728\u5355\u6a21\u578b\u8fd1\u89c6\u95ee\u9898\uff0c\u542f\u53d1\u5f0f\u667a\u80fd\u4f53\u68c0\u7d22\u53d7\u9650\u4e8e\u6b21\u4f18\u7684\u8bd5\u9519\u7f16\u6392\u3002\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5904\u7406\u89c6\u89c9\u548c\u6587\u672c\u7ea6\u675f\u7684\u590d\u6742\u63a8\u7406\u3002", "method": "\u63d0\u51faOSCAR\u6846\u67b6\uff0c\u91c7\u7528\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\uff1a\u79bb\u7ebf\u9636\u6bb5\u5c06CIR\u5efa\u6a21\u4e3a\u4e24\u9636\u6bb5\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u5e03\u5c14\u96c6\u5408\u8fd0\u7b97\u63a8\u5bfc\u6700\u5927\u5316\u771f\u5b9e\u8986\u76d6\u7684\u6700\u4f18\u8f68\u8ff9\uff1b\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u8fd9\u4e9b\u8f68\u8ff9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u793a\u4f8b\u6765\u5f15\u5bfcVLM\u89c4\u5212\u5668\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u548c\u4e00\u4e2a\u79c1\u6709\u5de5\u4e1a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOSCAR\u59cb\u7ec8\u4f18\u4e8eSOTA\u57fa\u7ebf\u3002\u4ec5\u4f7f\u752810%\u8bad\u7ec3\u6570\u636e\u5c31\u80fd\u5b9e\u73b0\u4f18\u8d8a\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u89c4\u5212\u903b\u8f91\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u800c\u975e\u6570\u636e\u96c6\u7279\u5b9a\u8bb0\u5fc6\u3002", "conclusion": "OSCAR\u6210\u529f\u5c06\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u4ece\u542f\u53d1\u5f0f\u641c\u7d22\u8f6c\u5316\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u7684\u6700\u4f18\u8f68\u8ff9\u5f15\u5bfc\u667a\u80fd\u4f53\u89c4\u5212\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2602.07712", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07712", "abs": "https://arxiv.org/abs/2602.07712", "authors": ["Alexandra Volkova", "Mher Safaryan", "Christoph H. Lampert", "Dan Alistarh"], "title": "Towards Robust Scaling Laws for Optimizers", "comment": null, "summary": "The quality of Large Language Model (LLM) pretraining depends on multiple factors, including the compute budget and the choice of optimization algorithm. Empirical scaling laws are widely used to predict loss as model size and training data grow, however, almost all existing studies fix the optimizer (typically AdamW). At the same time, a new generation of optimizers (e.g., Muon, Shampoo, SOAP) promises faster and more stable convergence, but their relationship with model and data scaling is not yet well understood. In this work, we study scaling laws across different optimizers. Empirically, we show that 1) separate Chinchilla-style scaling laws for each optimizer are ill-conditioned and have highly correlated parameters. Instead, 2) we propose a more robust law with shared power-law exponents and optimizer-specific rescaling factors, which enable direct comparison between optimizers. Finally, 3) we provide a theoretical analysis of gradient-based methods for the proxy task of a convex quadratic objective, demonstrating that Chinchilla-style scaling laws emerge naturally as a result of loss decomposition into irreducible, approximation, and optimization errors.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4e0d\u540c\u4f18\u5316\u5668\u5bf9LLM\u9884\u8bad\u7ec3\u7f29\u653e\u5b9a\u5f8b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u5171\u4eab\u5e42\u5f8b\u6307\u6570\u548c\u4f18\u5316\u5668\u7279\u5b9a\u7f29\u653e\u56e0\u5b50\u7684\u65b0\u7f29\u653e\u5b9a\u5f8b\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u89e3\u91ca\u4e86\u7f29\u653e\u5b9a\u5f8b\u7684\u6570\u5b66\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\u7814\u7a76\u901a\u5e38\u56fa\u5b9a\u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u800c\u65b0\u4e00\u4ee3\u4f18\u5316\u5668\uff08\u5982Muon\u3001Shampoo\u3001SOAP\uff09\u867d\u7136\u627f\u8bfa\u66f4\u5feb\u7684\u6536\u655b\uff0c\u4f46\u5b83\u4eec\u4e0e\u6a21\u578b\u548c\u6570\u636e\u7f29\u653e\u7684\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002\u9700\u8981\u7814\u7a76\u4e0d\u540c\u4f18\u5316\u5668\u4e0b\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u6bd4\u8f83\u548c\u9009\u62e9\u4f18\u5316\u5668\u3002", "method": "1) \u7ecf\u9a8c\u6027\u5730\u7814\u7a76\u4e0d\u540c\u4f18\u5316\u5668\u4e0b\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u53d1\u73b0\u4e3a\u6bcf\u4e2a\u4f18\u5316\u5668\u5355\u72ec\u5efa\u7acbChinchilla\u5f0f\u7f29\u653e\u5b9a\u5f8b\u5b58\u5728\u75c5\u6001\u95ee\u9898\uff1b2) \u63d0\u51fa\u66f4\u7a33\u5065\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u5305\u542b\u5171\u4eab\u7684\u5e42\u5f8b\u6307\u6570\u548c\u4f18\u5316\u5668\u7279\u5b9a\u7684\u7f29\u653e\u56e0\u5b50\uff1b3) \u5bf9\u51f8\u4e8c\u6b21\u76ee\u6807\u51fd\u6570\u7684\u4ee3\u7406\u4efb\u52a1\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u7f29\u653e\u5b9a\u5f8b\u662f\u635f\u5931\u5206\u89e3\u4e3a\u4e0d\u53ef\u7ea6\u8bef\u5dee\u3001\u8fd1\u4f3c\u8bef\u5dee\u548c\u4f18\u5316\u8bef\u5dee\u7684\u81ea\u7136\u7ed3\u679c\u3002", "result": "1) \u53d1\u73b0\u4e3a\u6bcf\u4e2a\u4f18\u5316\u5668\u5355\u72ec\u5efa\u7acb\u7f29\u653e\u5b9a\u5f8b\u4f1a\u5bfc\u81f4\u9ad8\u5ea6\u76f8\u5173\u7684\u53c2\u6570\uff0c\u5b58\u5728\u75c5\u6001\u95ee\u9898\uff1b2) \u63d0\u51fa\u7684\u65b0\u7f29\u653e\u5b9a\u5f8b\u80fd\u591f\u66f4\u7a33\u5065\u5730\u6bd4\u8f83\u4e0d\u540c\u4f18\u5316\u5668\uff1b3) \u7406\u8bba\u5206\u6790\u8868\u660e\u7f29\u653e\u5b9a\u5f8b\u53ef\u4ee5\u4ece\u635f\u5931\u5206\u89e3\u7684\u89d2\u5ea6\u81ea\u7136\u63a8\u5bfc\u51fa\u6765\uff0c\u4e3a\u7ecf\u9a8c\u89c2\u5bdf\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\u3002", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u5bf9LLM\u9884\u8bad\u7ec3\u7684\u7f29\u653e\u5b9a\u5f8b\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u63d0\u51fa\u7684\u5171\u4eab\u5e42\u5f8b\u6307\u6570\u548c\u4f18\u5316\u5668\u7279\u5b9a\u7f29\u653e\u56e0\u5b50\u7684\u65b0\u5b9a\u5f8b\u80fd\u591f\u66f4\u6709\u6548\u5730\u6bd4\u8f83\u4e0d\u540c\u4f18\u5316\u5668\u3002\u7406\u8bba\u5206\u6790\u4e3a\u7f29\u653e\u5b9a\u5f8b\u63d0\u4f9b\u4e86\u6570\u5b66\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u4f18\u5316\u5668\u5728\u6a21\u578b\u548c\u6570\u636e\u7f29\u653e\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2602.08874", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08874", "abs": "https://arxiv.org/abs/2602.08874", "authors": ["Yu Fu", "Haz Sameen Shahgir", "Huanli Gong", "Zhipeng Wei", "N. Benjamin Erichson", "Yue Dong"], "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?", "comment": "25 pages, 7 figures", "summary": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e5f\u65e0\u6cd5\u81ea\u52a8\u63d0\u5347\u5176\u5728\u957f\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\"\u7ec4\u5408\u63a8\u7406\u653b\u51fb\"\u65f6\uff0c\u6a21\u578b\u4f1a\u7ec4\u88c5\u51fa\u6709\u5bb3\u610f\u56fe\u5374\u65e0\u6cd5\u62d2\u7edd\u6267\u884c\u3002", "motivation": "\u9a8c\u8bc1\u4e00\u4e2a\u5047\u8bbe\uff1a\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u662f\u5426\u5e94\u8be5\u901a\u8fc7\u5e2e\u52a9\u6a21\u578b\u8bc6\u522b\u9690\u542b\u7684\u6709\u5bb3\u610f\u56fe\u6765\u63d0\u9ad8\u5b89\u5168\u6027\u3002\u7814\u7a76\u5728\u957f\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d\uff0c\u6709\u5bb3\u610f\u56fe\u662f\u9690\u542b\u7684\u3001\u9700\u8981\u901a\u8fc7\u63a8\u7406\u624d\u80fd\u8bc6\u522b\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\"\u7ec4\u5408\u63a8\u7406\u653b\u51fb\"\u8fd9\u4e00\u65b0\u7684\u5a01\u80c1\u6a21\u578b\uff1a\u5c06\u6709\u5bb3\u67e5\u8be2\u5206\u89e3\u4e3a\u4e0d\u5b8c\u6574\u7684\u7247\u6bb5\uff0c\u5206\u6563\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\uff0c\u7136\u540e\u7528\u4e2d\u6027\u7684\u63a8\u7406\u67e5\u8be2\u8bf1\u5bfc\u6a21\u578b\u68c0\u7d22\u548c\u5408\u6210\u8fd9\u4e9b\u7247\u6bb5\uff0c\u4f7f\u6709\u5bb3\u610f\u56fe\u5728\u7ec4\u5408\u540e\u624d\u663e\u73b0\u3002\u8bc4\u4f30\u4e8614\u4e2a\u524d\u6cbfLLM\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u8fbe64k tokens\u3002", "result": "\u4e09\u4e2a\u4e3b\u8981\u53d1\u73b0\uff1a1) \u5177\u6709\u66f4\u5f3a\u901a\u7528\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u5bf9\u7ec4\u5408\u63a8\u7406\u653b\u51fb\u5e76\u4e0d\u66f4\u9c81\u68d2\uff0c\u7ecf\u5e38\u7ec4\u88c5\u51fa\u610f\u56fe\u5374\u65e0\u6cd5\u62d2\u7edd\uff1b2) \u5b89\u5168\u6027\u5bf9\u9f50\u968f\u7740\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u6301\u7eed\u4e0b\u964d\uff1b3) \u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u52aa\u529b\u662f\u5173\u952e\u7f13\u89e3\u56e0\u7d20\uff1a\u589e\u52a0\u63a8\u7406\u65f6\u8ba1\u7b97\u53ef\u5c06GPT-oss-120b\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u8d85\u8fc750\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u5b89\u5168\u6027\u4e0d\u4f1a\u968f\u7740\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\u800c\u81ea\u52a8\u6269\u5c55\uff0c\u7279\u522b\u662f\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u73af\u5883\u4e0b\u3002\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u63aa\u65bd\u6765\u5e94\u5bf9\u7ec4\u5408\u63a8\u7406\u653b\u51fb\uff0c\u4e0d\u80fd\u4f9d\u8d56\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u6765\u4fdd\u8bc1\u5b89\u5168\u3002"}}
{"id": "2602.08630", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.08630", "abs": "https://arxiv.org/abs/2602.08630", "authors": ["Jonah Brown-Cohen", "Geoffrey Irving", "Simon C. Marshall", "Ilan Newman", "Georgios Piliouras", "Mario Szegedy"], "title": "Debate is efficient with your time", "comment": "11 Pages, 0 figures", "summary": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f15\u5165\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6(DQC)\u6982\u5ff5\uff0c\u5206\u6790\u4eba\u7c7b\u76d1\u7763\u8fa9\u8bba\u7684\u67e5\u8be2\u6210\u672c\uff0c\u53d1\u73b0PSPACE/poly\u95ee\u9898\u4ec5\u9700O(log n)\u67e5\u8be2\u5373\u53ef\u5224\u5b9a\uff0c\u8fa9\u8bba\u5177\u6709\u6781\u9ad8\u7684\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u5148\u524d\u5de5\u4f5c\u5efa\u7acb\u4e86\u8fa9\u8bba\u5728\u7406\u8bba\u4e0a\u80fd\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u4f46\u672a\u5206\u6790\u4eba\u7c7b\u76d1\u7763\u7684\u5b9e\u9645\u6210\u672c\uff1a\u88c1\u5224\u9700\u8981\u68c0\u67e5\u8fa9\u8bba\u8bb0\u5f55\u4e2d\u7684\u591a\u5c11\u67e5\u8be2\uff1f\u672c\u6587\u65e8\u5728\u91cf\u5316\u8fa9\u8bba\u4e2d\u4eba\u7c7b\u76d1\u7763\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "method": "\u5f15\u5165\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6(DQC)\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\uff0c\u5373\u9a8c\u8bc1\u8005\u6b63\u786e\u5224\u5b9a\u8fa9\u8bba\u6240\u9700\u68c0\u67e5\u7684\u6700\u5c0f\u6bd4\u7279\u6570\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5efa\u7acbDQC\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\u7c7b\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0PSPACE/poly\uff08\u8fa9\u8bba\u80fd\u9ad8\u6548\u5224\u5b9a\u7684\u95ee\u9898\u7c7b\uff09\u6070\u597d\u662fO(log n)\u67e5\u8be2\u53ef\u5224\u5b9a\u7684\u51fd\u6570\u7c7b\u3002\u4efb\u4f55\u53ef\u88ab\u5927\u5c0f\u4e3as\u7684\u7535\u8def\u8ba1\u7b97\u7684\u51fd\u6570\u6ee1\u8db3DQC(f) \u2264 log(s) + 3\u3002\u4f9d\u8d56\u6240\u6709\u8f93\u5165\u6bd4\u7279\u7684\u51fd\u6570\u9700\u8981\u03a9(log n)\u67e5\u8be2\u3002", "conclusion": "\u8fa9\u8bba\u5177\u6709\u60ca\u4eba\u7684\u67e5\u8be2\u6548\u7387\uff0c\u5373\u4f7f\u5bf9\u4e8e\u9ad8\u5ea6\u590d\u6742\u7684\u95ee\u9898\uff0c\u5bf9\u6570\u7ea7\u76d1\u7763\u5c31\u8db3\u591f\u4e86\u3002\u8bc1\u660eP\u7c7b\u8bed\u8a00\u7684log(n)+6 DQC\u4e0b\u754c\u5c06\u4ea7\u751f\u65b0\u7684\u7535\u8def\u4e0b\u754c\uff0c\u5c06\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u7684\u6838\u5fc3\u95ee\u9898\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2602.07715", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07715", "abs": "https://arxiv.org/abs/2602.07715", "authors": ["Roi Benita", "Michael Elad", "Joseph Keshet"], "title": "Analyzing and Guiding Zero-Shot Posterior Sampling in Diffusion Models", "comment": null, "summary": "Recovering a signal from its degraded measurements is a long standing challenge in science and engineering. Recently, zero-shot diffusion based methods have been proposed for such inverse problems, offering a posterior sampling based solution that leverages prior knowledge. Such algorithms incorporate the observations through inference, often leaning on manual tuning and heuristics. In this work we propose a rigorous analysis of such approximate posterior-samplers, relying on a Gaussianity assumption of the prior. Under this regime, we show that both the ideal posterior sampler and diffusion-based reconstruction algorithms can be expressed in closed-form, enabling their thorough analysis and comparisons in the spectral domain. Building on these representations, we also introduce a principled framework for parameter design, replacing heuristic selection strategies used to date. The proposed approach is method-agnostic and yields tailored parameter choices for each algorithm, jointly accounting for the characteristics of the prior, the degraded signal, and the diffusion dynamics. We show that our spectral recommendations differ structurally from standard heuristics and vary with the diffusion step size, resulting in a consistent balance between perceptual quality and signal fidelity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u5148\u9a8c\u5047\u8bbe\u7684\u96f6\u6837\u672c\u6269\u6563\u9006\u95ee\u9898\u6c42\u89e3\u5668\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u8c31\u57df\u5206\u6790\u63a8\u5bfc\u51fa\u95ed\u5f0f\u89e3\uff0c\u5e76\u5efa\u7acb\u4e86\u53c2\u6570\u8bbe\u8ba1\u7684\u539f\u7406\u6027\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u96f6\u6837\u672c\u6269\u6563\u65b9\u6cd5\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u4f9d\u8d56\u624b\u52a8\u8c03\u53c2\u548c\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\u3002\u672c\u6587\u65e8\u5728\u4e3a\u8fd9\u7c7b\u8fd1\u4f3c\u540e\u9a8c\u91c7\u6837\u5668\u63d0\u4f9b\u4e25\u683c\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "method": "\u5047\u8bbe\u5148\u9a8c\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u5728\u8c31\u57df\u63a8\u5bfc\u7406\u60f3\u540e\u9a8c\u91c7\u6837\u5668\u548c\u6269\u6563\u91cd\u5efa\u7b97\u6cd5\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5efa\u7acb\u65b9\u6cd5\u65e0\u5173\u7684\u53c2\u6570\u8bbe\u8ba1\u539f\u7406\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u7684\u8c31\u57df\u5efa\u8bae\u4e0e\u6807\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u7ed3\u6784\u4e0a\u4e0d\u540c\uff0c\u4e14\u968f\u6269\u6563\u6b65\u957f\u53d8\u5316\uff0c\u80fd\u591f\u5728\u611f\u77e5\u8d28\u91cf\u548c\u4fe1\u53f7\u4fdd\u771f\u5ea6\u4e4b\u95f4\u5b9e\u73b0\u4e00\u81f4\u5e73\u8861\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u4e3a\u6269\u6563\u57fa\u9006\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u53c2\u6570\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u53d6\u4ee3\u4e86\u73b0\u6709\u7684\u542f\u53d1\u5f0f\u9009\u62e9\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u91cd\u5efa\u6027\u80fd\u3002"}}
{"id": "2602.07719", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07719", "abs": "https://arxiv.org/abs/2602.07719", "authors": ["Gabriel Stella"], "title": "Efficient Planning in Reinforcement Learning via Model Introspection", "comment": null, "summary": "Reinforcement learning and classical planning are typically seen as two distinct problems, with differing formulations necessitating different solutions. Yet, when humans are given a task, regardless of the way it is specified, they can often derive the additional information needed to solve the problem efficiently. The key to this ability is introspection: by reasoning about their internal models of the problem, humans directly synthesize additional task-relevant information. In this paper, we propose that this introspection can be thought of as program analysis. We discuss examples of how this approach can be applied to various kinds of models used in reinforcement learning. We then describe an algorithm that enables efficient goal-oriented planning over the class of models used in relational reinforcement learning, demonstrating a novel link between reinforcement learning and classical planning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u5185\u7701\u89c6\u4e3a\u7a0b\u5e8f\u5206\u6790\uff0c\u5efa\u7acb\u5f3a\u5316\u5b66\u4e60\u4e0e\u7ecf\u5178\u89c4\u5212\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u901a\u8fc7\u5206\u6790\u5185\u90e8\u6a21\u578b\u6765\u5408\u6210\u4efb\u52a1\u76f8\u5173\u4fe1\u606f", "motivation": "\u4eba\u7c7b\u5728\u9762\u5bf9\u4efb\u52a1\u65f6\uff0c\u65e0\u8bba\u4efb\u52a1\u5982\u4f55\u6307\u5b9a\uff0c\u90fd\u80fd\u901a\u8fc7\u5185\u7701\u63a8\u7406\u5185\u90e8\u6a21\u578b\u6765\u5408\u6210\u89e3\u51b3\u4efb\u52a1\u6240\u9700\u7684\u4fe1\u606f\u3002\u5f3a\u5316\u5b66\u4e60\u548c\u7ecf\u5178\u89c4\u5212\u901a\u5e38\u88ab\u89c6\u4e3a\u4e24\u4e2a\u4e0d\u540c\u95ee\u9898\uff0c\u9700\u8981\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u53ef\u4ee5\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u7684\u65b9\u6cd5\u5efa\u7acb\u4e24\u8005\u4e4b\u95f4\u7684\u8054\u7cfb", "method": "\u63d0\u51fa\u5c06\u5185\u7701\u89c6\u4e3a\u7a0b\u5e8f\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528\u7684\u5404\u79cd\u6a21\u578b\u3002\u63cf\u8ff0\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u5173\u7cfb\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u7684\u6a21\u578b\u7c7b\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u76ee\u6807\u5bfc\u5411\u89c4\u5212", "result": "\u5efa\u7acb\u4e86\u5f3a\u5316\u5b66\u4e60\u4e0e\u7ecf\u5178\u89c4\u5212\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u7684\u65b9\u6cd5\u5728\u5173\u7cfb\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u4e0a\u5b9e\u73b0\u9ad8\u6548\u89c4\u5212", "conclusion": "\u901a\u8fc7\u5c06\u5185\u7701\u89c6\u4e3a\u7a0b\u5e8f\u5206\u6790\uff0c\u53ef\u4ee5\u5f25\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u7ecf\u5178\u89c4\u5212\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u50cf\u4eba\u7c7b\u4e00\u6837\u901a\u8fc7\u5206\u6790\u5185\u90e8\u6a21\u578b\u6765\u5408\u6210\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u95ee\u9898\u89e3\u51b3\u6548\u7387"}}
{"id": "2602.08951", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08951", "abs": "https://arxiv.org/abs/2602.08951", "authors": ["Rasul Dent", "Pedro Ortiz Suarez", "Thibault Cl\u00e9rice", "Beno\u00eet Sagot"], "title": "How Should We Model the Probability of a Language?", "comment": "Accepted for Vardial 2026", "summary": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.", "AI": {"tldr": "\u8be5\u7acb\u573a\u8bba\u6587\u8ba4\u4e3a\u5f53\u524d\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u8986\u76d6\u4e0d\u8db3\u4e3b\u8981\u662f\u81ea\u627e\u7684\uff0c\u6e90\u4e8e\u5c06LID\u6846\u67b6\u4e3a\u53bb\u8bed\u5883\u5316\u7684\u6587\u672c\u5206\u7c7b\uff0c\u5ffd\u89c6\u4e86\u5148\u9a8c\u6982\u7387\u4f30\u8ba1\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u5e76\u53d7\u5230\u9752\u7750\u5168\u5c40\u56fa\u5b9a\u5148\u9a8c\u6a21\u578b\u7684\u5236\u5ea6\u6fc0\u52b1\u5f71\u54cd\u3002", "motivation": "\u5546\u4e1a\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u4ec5\u80fd\u53ef\u9760\u8bc6\u522b\u51e0\u767e\u79cd\u8bed\u8a00\uff0c\u7814\u7a76\u7ea7\u7cfb\u7edf\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6269\u5c55\u4e86\u8986\u76d6\u8303\u56f4\uff0c\u4f46\u5bf9\u5927\u591a\u6570\u8bed\u8a00\u6765\u8bf4\u8986\u76d6\u4ecd\u7136\u96f6\u6563\u6216\u4e0d\u5b58\u5728\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u72b6\u51b5\u4e3b\u8981\u662f\u81ea\u627e\u7684\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u8bed\u8a00\u8bc6\u522b\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u662f\u7acb\u573a\u8bba\u6587\uff0c\u63d0\u51fa\u5c06\u8bed\u8a00\u8bc6\u522b\u91cd\u65b0\u6846\u67b6\u4e3a\u8def\u7531\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u7eb3\u5165\u73af\u5883\u7ebf\u7d22\uff0c\u4f7f\u8bed\u8a00\u5728\u672c\u5730\u73af\u5883\u4e2d\u53d8\u5f97\u5408\u7406\u3002\u4e3b\u5f20\u653e\u5f03\u53bb\u8bed\u5883\u5316\u7684\u6587\u672c\u5206\u7c7b\u6846\u67b6\u3002", "result": "\u8bba\u6587\u6ca1\u6709\u63d0\u4f9b\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u800c\u662f\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u8f6c\u53d8\uff1a\u4ece\u56fa\u5b9a\u5148\u9a8c\u7684\u6587\u672c\u5206\u7c7b\u8f6c\u5411\u8003\u8651\u73af\u5883\u7ebf\u7d22\u548c\u672c\u5730\u5148\u9a8c\u6982\u7387\u7684\u8bed\u8a00\u8def\u7531\u95ee\u9898\u3002", "conclusion": "\u8981\u63d0\u9ad8\u5c3e\u90e8\u8bed\u8a00\u7684\u8986\u76d6\u8303\u56f4\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u8bed\u8a00\u8bc6\u522b\u4f5c\u4e3a\u8def\u7531\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u539f\u5219\u6027\u65b9\u6cd5\u6765\u6574\u5408\u73af\u5883\u7ebf\u7d22\uff0c\u4f7f\u8bed\u8a00\u5728\u672c\u5730\u4e0a\u4e0b\u6587\u4e2d\u53d8\u5f97\u5408\u7406\uff0c\u800c\u4e0d\u662f\u575a\u6301\u53bb\u8bed\u5883\u5316\u7684\u6587\u672c\u5206\u7c7b\u6846\u67b6\u3002"}}
{"id": "2602.08708", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08708", "abs": "https://arxiv.org/abs/2602.08708", "authors": ["Stefan Edelkamp", "Ji\u0159\u00ed Fink", "Petr Gregor", "Anders Jonsson", "Bernhard Nebel"], "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$", "comment": null, "summary": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.", "AI": {"tldr": "\u7814\u7a76STRIPS\u89c4\u5212\u4e2d\u64cd\u4f5c\u7b26\u9650\u5236\u4e3a1\u4e2a\u524d\u63d0\u6761\u4ef6\u548c1\u4e2a\u6548\u679c\u65f6\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u63a2\u8ba8\u8be5\u95ee\u9898\u662f\u5426\u4e3aNP\u5b8c\u5168\u95ee\u9898", "motivation": "Bylander\u5df2\u8bc1\u660e\u5f53\u53ea\u5141\u8bb8\u57fa\u7840\u6587\u5b57\u65f6\uff0c\u5373\u4f7f\u64cd\u4f5c\u7b26\u9650\u5236\u4e3a2\u4e2a\u524d\u63d0\u6761\u4ef6\u548c2\u4e2a\u540e\u7f6e\u6761\u4ef6\uff0c\u89c4\u5212\u5b58\u5728\u6027\u5224\u5b9a\u4e5f\u662fPSPACE\u5b8c\u5168\u7684\u3002\u867d\u7136NP\u96be\u6027\u5df2\u786e\u5b9a\uff0c\u4f46\u64cd\u4f5c\u7b26\u53ea\u67091\u4e2a\u524d\u63d0\u6761\u4ef6\u548c1\u4e2a\u6548\u679c\u65f6\u662f\u5426\u4e3aNP\u5b8c\u5168\u95ee\u9898\u5c1a\u4e0d\u6e05\u695a", "method": "\u901a\u8fc7\u8c03\u7528SAT\u6c42\u89e3\u5668\u5904\u7406\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u3001\u5f15\u5165\u6587\u5b57\u56fe\uff08literal graph\uff09\u5e76\u5c06\u5176\u6620\u5c04\u5230Petri\u7f51\u6765\u7814\u7a76\u8be5\u95ee\u9898", "result": "\u8bba\u6587\u5bf9STRIPS\u2081\u00b9\uff081\u4e2a\u524d\u63d0\u6761\u4ef6\u548c1\u4e2a\u6548\u679c\uff09\u7684\u5c0f\u89e3\u5047\u8bbe\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u4f46\u5177\u4f53\u7ed3\u679c\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u6790", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3STRIPS\u89c4\u5212\u5728\u6700\u5c0f\u64cd\u4f5c\u7b26\u9650\u5236\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u89c1\u89e3"}}
{"id": "2602.07721", "categories": ["cs.LG", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.07721", "abs": "https://arxiv.org/abs/2602.07721", "authors": ["Yanlin Qi", "Xinhang Chen", "Huiqiang Jiang", "Qitong Wang", "Botao Peng", "Themis Palpanas"], "title": "ParisKV: Fast and Drift-Robust KV-Cache Retrieval for Long-Context LLMs", "comment": "25 pages, 16 figures. Under review", "summary": "KV-cache retrieval is essential for long-context LLM inference, yet existing methods struggle with distribution drift and high latency at scale. We introduce ParisKV, a drift-robust, GPU-native KV-cache retrieval framework based on collision-based candidate selection, followed by a quantized inner-product reranking estimator. For million-token contexts, ParisKV supports CPU-offloaded KV caches via Unified Virtual Addressing (UVA), enabling on-demand top-$k$ fetching with minimal overhead. ParisKV matches or outperforms full attention quality on long-input and long-generation benchmarks. It achieves state-of-the-art long-context decoding efficiency: it matches or exceeds full attention speed even at batch size 1 for long contexts, delivers up to 2.8$\\times$ higher throughput within full attention's runnable range, and scales to million-token contexts where full attention runs out of memory. At million-token scale, ParisKV reduces decode latency by 17$\\times$ and 44$\\times$ compared to MagicPIG and PQCache, respectively, two state-of-the-art KV-cache Top-$k$ retrieval baselines.", "AI": {"tldr": "ParisKV\u662f\u4e00\u4e2a\u57fa\u4e8e\u78b0\u649e\u5019\u9009\u9009\u62e9\u548c\u91cf\u5316\u5185\u79ef\u91cd\u6392\u7684GPU\u539f\u751fKV\u7f13\u5b58\u68c0\u7d22\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\u7684\u5206\u5e03\u6f02\u79fb\u548c\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u652f\u6301\u767e\u4e07token\u4e0a\u4e0b\u6587\uff0c\u5728\u89e3\u7801\u6548\u7387\u548c\u541e\u5410\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u68c0\u7d22\u65b9\u6cd5\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u65f6\u9762\u4e34\u5206\u5e03\u6f02\u79fb\u548c\u89c4\u6a21\u5316\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u6765\u652f\u6301\u767e\u4e07token\u7ea7\u522b\u7684\u4e0a\u4e0b\u6587\u5904\u7406\u3002", "method": "\u57fa\u4e8e\u78b0\u649e\u5019\u9009\u9009\u62e9\u673a\u5236\uff0c\u7136\u540e\u4f7f\u7528\u91cf\u5316\u5185\u79ef\u91cd\u6392\u4f30\u8ba1\u5668\u8fdb\u884c\u7cbe\u6392\uff1b\u652f\u6301\u901a\u8fc7\u7edf\u4e00\u865a\u62df\u5bfb\u5740\u5b9e\u73b0CPU\u5378\u8f7d\u7684KV\u7f13\u5b58\uff0c\u5b9e\u73b0\u6309\u9700top-k\u83b7\u53d6\uff1b\u6574\u4e2a\u6846\u67b6\u9488\u5bf9GPU\u539f\u751f\u8bbe\u8ba1\u3002", "result": "\u5728\u957f\u8f93\u5165\u548c\u957f\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6216\u8d85\u8fc7\u5168\u6ce8\u610f\u529b\u8d28\u91cf\uff1b\u5728\u6279\u5927\u5c0f\u4e3a1\u7684\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u8fbe\u5230\u6216\u8d85\u8fc7\u5168\u6ce8\u610f\u529b\u901f\u5ea6\uff1b\u5728\u53ef\u8fd0\u884c\u8303\u56f4\u5185\u63d0\u4f9b\u9ad8\u8fbe2.8\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff1b\u652f\u6301\u767e\u4e07token\u4e0a\u4e0b\u6587\uff08\u5168\u6ce8\u610f\u529b\u4f1a\u5185\u5b58\u6ea2\u51fa\uff09\uff1b\u76f8\u6bd4MagicPIG\u548cPQCache\u5206\u522b\u51cf\u5c1117\u500d\u548c44\u500d\u7684\u89e3\u7801\u5ef6\u8fdf\u3002", "conclusion": "ParisKV\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u9c81\u68d2\u7684KV\u7f13\u5b58\u68c0\u7d22\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u89e3\u7801\u6548\u7387\uff0c\u4e3a\u767e\u4e07token\u7ea7\u522b\u7684\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08984", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08984", "abs": "https://arxiv.org/abs/2602.08984", "authors": ["Yuliang Liu", "Yunchong Song", "Yixuan Wang", "Kewen Ge", "Alex Lamb", "Qipeng Guo", "Kai Chen", "Bowen Zhou", "Zhouhan Lin"], "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models", "comment": null, "summary": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.", "AI": {"tldr": "\u63d0\u51faNext Concept Prediction (NCP)\u9884\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u9884\u6d4b\u8de8\u591atoken\u7684\u79bb\u6563\u6982\u5ff5\u5f62\u6210\u66f4\u96be\u7684\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u4f20\u7edftoken\u7ea7\u6a21\u578b\u3002", "motivation": "\u4f20\u7edfNext Token Prediction (NTP)\u5728token\u7ea7\u522b\u8fdb\u884c\u9884\u6d4b\uff0c\u800cNCP\u65e8\u5728\u901a\u8fc7\u9884\u6d4b\u66f4\u9ad8\u5c42\u6b21\u7684\"\u6982\u5ff5\"\u6765\u6784\u5efa\u66f4\u5177\u6311\u6218\u6027\u7684\u9884\u8bad\u7ec3\u76ee\u6807\uff0c\u4ece\u800c\u8bad\u7ec3\u66f4\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u63d0\u51faConceptLM\u6a21\u578b\uff0c\u4f7f\u7528\u5411\u91cf\u91cf\u5316(Vector Quantization)\u5bf9\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u91cf\u5316\uff0c\u6784\u5efa\u6982\u5ff5\u8bcd\u6c47\u8868\u3002\u6a21\u578b\u540c\u65f6\u5229\u7528NCP\u548cNTP\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u751f\u6210\u6982\u5ff5\u6765\u6307\u5bfc\u540e\u7eedtoken\u7684\u751f\u6210\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNCP\u76f8\u6bd4\u4f20\u7edftoken\u7ea7\u6a21\u578b\u83b7\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002\u57288B\u53c2\u6570\u7684Llama\u6a21\u578b\u4e0a\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u5b9e\u9a8c\u8868\u660e\uff0cNCP\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347NTP\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "NCP\u901a\u8fc7\u5f15\u5165\u66f4\u96be\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u6982\u5ff5\u7ea7\u9884\u6d4b\u80fd\u6709\u6548\u63d0\u5347\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2602.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08715", "abs": "https://arxiv.org/abs/2602.08715", "authors": ["Miquel Mir\u00f3-Nicolau", "Gabriel Moy\u00e0-Alcover", "Anna Arias-Duart"], "title": "Exploring SAIG Methods for an Objective Evaluation of XAI", "comment": null, "summary": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e86SAIG\u65b9\u6cd5\u2014\u2014\u901a\u8fc7\u751f\u6210\u4eba\u5de5\u57fa\u51c6\u6765\u8bc4\u4f30XAI\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u4f53\u7cfb\u5e76\u8bc6\u522b\u4e86\u4e03\u79cd\u5173\u952e\u7279\u5f81\uff0c\u63ed\u793a\u4e86\u5f53\u524dXAI\u8bc4\u4f30\u9886\u57df\u7f3a\u4e4f\u5171\u8bc6\u7684\u95ee\u9898\u3002", "motivation": "XAI\u8bc4\u4f30\u9886\u57df\u65b9\u6cd5\u591a\u6837\u4f46\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\uff0c\u4e0e\u4f20\u7edfAI\u8bc4\u4f30\u4e0d\u540c\uff0cXAI\u89e3\u91ca\u6ca1\u6709\u666e\u904d\u6b63\u786e\u7684\u57fa\u51c6\uff0c\u4f7f\u5f97\u5ba2\u89c2\u8bc4\u4f30\u53d8\u5f97\u56f0\u96be\u3002SAIG\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u4eba\u5de5\u57fa\u51c6\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "method": "\u5bf9SAIG\u65b9\u6cd5\u8fdb\u884c\u9996\u6b21\u7cfb\u7edf\u6027\u7efc\u8ff0\u548c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u4f53\u7cfb\u6765\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u8bc6\u522b\u4e86\u533a\u5206\u4e0d\u540cSAIG\u65b9\u6cd5\u7684\u4e03\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u4e86\u6bd4\u8f83\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524dXAI\u8bc4\u4f30\u6280\u672f\u7f3a\u4e4f\u5171\u8bc6\uff0c\u6700\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u5c1a\u672a\u8fbe\u6210\u4e00\u81f4\uff0c\u8fd9\u51f8\u663e\u4e86\u8be5\u9886\u57df\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6807\u51c6\u5316\u7684\u8feb\u5207\u9700\u6c42\u3002", "conclusion": "SAIG\u65b9\u6cd5\u4e3aXAI\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5f53\u524d\u9886\u57df\u4ecd\u5b58\u5728\u5171\u8bc6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u591a\u7684\u7814\u7a76\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6765\u63a8\u8fdbXAI\u8bc4\u4f30\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.07729", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07729", "abs": "https://arxiv.org/abs/2602.07729", "authors": ["Sagnik Mukherjee", "Lifan Yuan", "Pavan Jayasinha", "Dilek Hakkani-T\u00fcr", "Hao Peng"], "title": "Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs", "comment": null, "summary": "Reinforcement learning (RL), particularly RL from verifiable reward (RLVR), has become a crucial phase of training large language models (LLMs) and a key focus of current scaling efforts. However, optimization practices in RL largely follow those of next-token prediction stages (e.g., pretraining and supervised fine-tuning), despite fundamental differences between RL and these stages highlighted by recent work. One such practice is the use of the AdamW optimizer, which is widely adopted for training large-scale transformers despite its high memory overhead. Our analysis shows that both momentum and adaptive learning rates in AdamW are less influential in RL than in SFT, leading us to hypothesize that RL benefits less from Adam-style per-parameter adaptive learning rates and momentum. Confirming this hypothesis, our experiments demonstrate that the substantially more memory-efficient SGD, which is known to perform poorly in supervised learning of large-scale transformers, matches or even outperforms AdamW in RL for LLMs. Remarkably, full fine-tuning with SGD updates fewer than 0.02% of model parameters without any sparsity-promoting regularization, more than 1000 times fewer than AdamW. Our analysis offers potential reasons for this update sparsity. These findings provide new insights into the optimization dynamics of RL in LLMs and show that RL can be substantially more parameter-efficient than previously recognized.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u7b80\u5355\u7684SGD\u4f18\u5316\u5668\u6bd4\u5e7f\u6cdb\u4f7f\u7528\u7684AdamW\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u53c2\u6570\u66f4\u65b0\u7a00\u758f\u5ea6\u6781\u9ad8\uff0c\u4ec5\u66f4\u65b0\u4e0d\u52300.02%\u7684\u53c2\u6570\u3002", "motivation": "\u5f53\u524dRL\u8bad\u7ec3LLMs\u65f6\u6cbf\u7528SFT\u9636\u6bb5\u7684\u4f18\u5316\u5668\u5b9e\u8df5\uff08\u5982AdamW\uff09\uff0c\u4f46RL\u4e0e\u76d1\u7763\u5b66\u4e60\u5b58\u5728\u672c\u8d28\u5dee\u5f02\u3002AdamW\u5185\u5b58\u5f00\u9500\u5927\uff0c\u800c\u7814\u7a76\u8868\u660eRL\u53ef\u80fd\u4e0d\u9700\u8981\u590d\u6742\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u548c\u52a8\u91cf\u673a\u5236\u3002", "method": "\u5206\u6790AdamW\u5728RL\u548cSFT\u4e2d\u7684\u4e0d\u540c\u5f71\u54cd\uff0c\u63d0\u51fa\u5047\u8bbe\uff1aRL\u53d7\u76ca\u4e8e\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u548c\u52a8\u91cf\u7684\u7a0b\u5ea6\u8f83\u4f4e\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1SGD\u5728RL\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0eAdamW\u5bf9\u6bd4\uff0c\u5206\u6790\u53c2\u6570\u66f4\u65b0\u6a21\u5f0f\u3002", "result": "SGD\u5728RL\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u7b49\u540c\u4e8eAdamW\uff0c\u4e14\u53c2\u6570\u66f4\u65b0\u6781\u5176\u7a00\u758f\uff08<0.02%\u7684\u53c2\u6570\u88ab\u66f4\u65b0\uff09\uff0c\u6bd4AdamW\u5c111000\u500d\u4ee5\u4e0a\u3002RL\u4f18\u5316\u52a8\u6001\u4e0e\u76d1\u7763\u5b66\u4e60\u663e\u8457\u4e0d\u540c\u3002", "conclusion": "RL\u8bad\u7ec3LLMs\u65f6\u53ef\u4ee5\u4f7f\u7528\u66f4\u7b80\u5355\u3001\u5185\u5b58\u6548\u7387\u66f4\u9ad8\u7684SGD\u4f18\u5316\u5668\uff0c\u4e14RL\u5177\u6709\u6781\u9ad8\u7684\u53c2\u6570\u6548\u7387\uff0c\u8fd9\u4e3aLLM\u8bad\u7ec3\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2602.08995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08995", "abs": "https://arxiv.org/abs/2602.08995", "authors": ["Yuting Ning", "Jaylen Jones", "Zhehao Zhang", "Chentao Ye", "Weitong Ruan", "Junyi Li", "Rahul Gupta", "Huan Sun"], "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/", "summary": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5b9a\u4e49\u5e76\u7814\u7a76\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e2d\u7684\u672a\u5bf9\u9f50\u52a8\u4f5c\u68c0\u6d4b\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u5305\u542b\u771f\u5b9e\u573a\u666f\u8f68\u8ff9\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6MisActBench\uff0c\u5e76\u63d0\u51fa\u4e86DeAction\u65b9\u6cd5\uff0c\u5728\u68c0\u6d4b\u548c\u7ea0\u6b63\u672a\u5bf9\u9f50\u52a8\u4f5c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u867d\u7136\u5728\u8fc7\u53bb\u4e00\u5e74\u53d6\u5f97\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u4ecd\u7ecf\u5e38\u4ea7\u751f\u504f\u79bb\u7528\u6237\u539f\u59cb\u610f\u56fe\u7684\u672a\u5bf9\u9f50\u52a8\u4f5c\u3002\u8fd9\u4e9b\u672a\u5bf9\u9f50\u52a8\u4f5c\u53ef\u80fd\u6765\u81ea\u5916\u90e8\u653b\u51fb\uff08\u5982\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\uff09\u6216\u5185\u90e8\u9650\u5236\uff08\u5982\u9519\u8bef\u63a8\u7406\uff09\uff0c\u4e0d\u4ec5\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u8fd8\u964d\u4f4e\u4efb\u52a1\u6548\u7387\u548c\u53ef\u9760\u6027\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u6b64\u95ee\u9898\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "1. \u9996\u6b21\u7cfb\u7edf\u5b9a\u4e49\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e2d\u7684\u672a\u5bf9\u9f50\u52a8\u4f5c\u68c0\u6d4b\u95ee\u9898\uff0c\u5168\u9762\u8986\u76d6\u5916\u90e8\u8bf1\u5bfc\u548c\u5185\u90e8\u4ea7\u751f\u7684\u672a\u5bf9\u9f50\u52a8\u4f5c\uff1b2. \u8bc6\u522b\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u4e09\u4e2a\u5e38\u89c1\u7c7b\u522b\uff0c\u6784\u5efaMisActBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b\u4eba\u7c7b\u6807\u6ce8\u7684\u52a8\u4f5c\u7ea7\u5bf9\u9f50\u6807\u7b7e\uff1b3. \u63d0\u51faDeAction\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u4e2a\u5b9e\u7528\u4e14\u901a\u7528\u7684\u9632\u62a4\u673a\u5236\uff0c\u5728\u6267\u884c\u524d\u68c0\u6d4b\u672a\u5bf9\u9f50\u52a8\u4f5c\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u8fed\u4ee3\u7ea0\u6b63\u3002", "result": "1. \u5728MisActBench\u4e0a\uff0cDeAction\u6bd4\u6240\u6709\u57fa\u7ebf\u5728F1\u5206\u6570\u4e0a\u7edd\u5bf9\u63d0\u5347\u8d85\u8fc715%\uff1b2. \u5728\u7ebf\u8bc4\u4f30\u4e2d\uff0c\u5728\u5bf9\u6297\u8bbe\u7f6e\u4e0b\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u8d85\u8fc790%\uff0c\u540c\u65f6\u5728\u826f\u6027\u73af\u5883\u4e2d\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff1b3. \u65b9\u6cd5\u5177\u6709\u9002\u5ea6\u7684\u5ef6\u8fdf\u5f00\u9500\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e2d\u7684\u672a\u5bf9\u9f50\u52a8\u4f5c\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u7684DeAction\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u7ea0\u6b63\u672a\u5bf9\u9f50\u52a8\u4f5c\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9632\u62a4\u673a\u5236\u3002"}}
{"id": "2602.08734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08734", "abs": "https://arxiv.org/abs/2602.08734", "authors": ["David Hud\u00e1k", "Maris F. L. Galesloot", "Martin Tappler", "Martin Kure\u010dka", "Nils Jansen", "Milan \u010ce\u0161ka"], "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning", "comment": "17 pages (8 main paper, 2 references, 7 appendix). 3 figures in the main paper, 3 figures in the appendix. Accepted AAMAS'26 submission", "summary": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.", "AI": {"tldr": "Lexpop\u6846\u67b6\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u6709\u9650\u72b6\u6001\u63a7\u5236\u5668\u63d0\u53d6\uff0c\u4e3aPOMDP\u548cHM-POMDP\u63d0\u4f9b\u53ef\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7b56\u7565\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709POMDP\u6c42\u89e3\u5668\u7684\u6269\u5c55\u6027\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8de8\u591a\u4e2aPOMDP\u7684\u9c81\u68d2\u7b56\u7565\u65f6\uff0c\u95ee\u9898\u66f4\u52a0\u4e25\u91cd\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5904\u7406\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u53c8\u80fd\u63d0\u4f9b\u6027\u80fd\u4fdd\u8bc1\u7684\u65b9\u6cd5\u3002", "method": "Lexpop\u6846\u67b6\uff1a(1) \u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\uff1b(2) \u901a\u8fc7\u9ad8\u6548\u63d0\u53d6\u65b9\u6cd5\u6784\u5efa\u6a21\u4eff\u795e\u7ecf\u7b56\u7565\u7684\u6709\u9650\u72b6\u6001\u63a7\u5236\u5668\uff1b(3) \u6269\u5c55\u5230HM-POMDP\uff0c\u901a\u8fc7\u5173\u8054\u6bcf\u4e2a\u63a7\u5236\u5668\u4e0e\u5176\u6700\u574f\u60c5\u51b5POMDP\uff0c\u8fed\u4ee3\u8bad\u7ec3\u9c81\u68d2\u795e\u7ecf\u7b56\u7565\u5e76\u63d0\u53d6\u9c81\u68d2\u63a7\u5236\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5927\u89c4\u6a21\u72b6\u6001\u7a7a\u95f4\u95ee\u9898\u4e0a\uff0cLexpop\u5728POMDP\u548cHM-POMDP\u6c42\u89e3\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u6c42\u89e3\u5668\u3002", "conclusion": "Lexpop\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86POMDP\u6c42\u89e3\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\u4e0e\u6709\u9650\u72b6\u6001\u63a7\u5236\u5668\u7684\u53ef\u9a8c\u8bc1\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u63d0\u4f9b\u4e86\u5177\u6709\u6027\u80fd\u4fdd\u8bc1\u7684\u9c81\u68d2\u7b56\u7565\u3002"}}
{"id": "2602.07730", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07730", "abs": "https://arxiv.org/abs/2602.07730", "authors": ["Siddarth Chandrasekar", "Marlos C. Machado"], "title": "The Laplacian Keyboard: Beyond the Linear Span", "comment": "28 pages, 17 figures", "summary": "Across scientific disciplines, Laplacian eigenvectors serve as a fundamental basis for simplifying complex systems, from signal processing to quantum mechanics. In reinforcement learning (RL), these eigenvectors provide a natural basis for approximating reward functions; however, their use is typically limited to their linear span, which restricts expressivity in complex environments. We introduce the Laplacian Keyboard (LK), a hierarchical framework that goes beyond the linear span. LK constructs a task-agnostic library of options from these eigenvectors, forming a behavior basis guaranteed to contain the optimal policy for any reward within the linear span. A meta-policy learns to stitch these options dynamically, enabling efficient learning of policies outside the original linear constraints. We establish theoretical bounds on zero-shot approximation error and demonstrate empirically that LK surpasses zero-shot solutions while achieving improved sample efficiency compared to standard RL methods.", "AI": {"tldr": "Laplacian Keyboard (LK) \u662f\u4e00\u4e2a\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u62c9\u666e\u62c9\u65af\u7279\u5f81\u5411\u91cf\u6784\u5efa\u4efb\u52a1\u65e0\u5173\u9009\u9879\u5e93\uff0c\u901a\u8fc7\u5143\u7b56\u7565\u52a8\u6001\u7ec4\u5408\u8fd9\u4e9b\u9009\u9879\uff0c\u5b9e\u73b0\u8d85\u51fa\u7ebf\u6027\u7ea6\u675f\u7684\u9ad8\u6548\u7b56\u7565\u5b66\u4e60\u3002", "motivation": "\u62c9\u666e\u62c9\u65af\u7279\u5f81\u5411\u91cf\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u901a\u5e38\u53ea\u7528\u4e8e\u7ebf\u6027\u8fd1\u4f3c\u5956\u52b1\u51fd\u6570\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u3002\u9700\u8981\u8d85\u8d8a\u7ebf\u6027\u7ea6\u675f\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u7b56\u7565\u5b66\u4e60\u7684\u6548\u7387\u548c\u8868\u8fbe\u80fd\u529b\u3002", "method": "LK\u6846\u67b6\u9996\u5148\u4ece\u62c9\u666e\u62c9\u65af\u7279\u5f81\u5411\u91cf\u6784\u5efa\u4efb\u52a1\u65e0\u5173\u7684\u9009\u9879\u5e93\uff0c\u8fd9\u4e9b\u9009\u9879\u5f62\u6210\u884c\u4e3a\u57fa\uff0c\u4fdd\u8bc1\u5305\u542b\u7ebf\u6027\u8de8\u5ea6\u5185\u4efb\u4f55\u5956\u52b1\u7684\u6700\u4f18\u7b56\u7565\u3002\u7136\u540e\u901a\u8fc7\u5143\u7b56\u7565\u52a8\u6001\u7ec4\u5408\u8fd9\u4e9b\u9009\u9879\uff0c\u5b66\u4e60\u8d85\u51fa\u539f\u59cb\u7ebf\u6027\u7ea6\u675f\u7684\u7b56\u7565\u3002", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u96f6\u6837\u672c\u8fd1\u4f3c\u8bef\u5dee\u7684\u754c\u9650\uff0c\u5b9e\u8bc1\u7814\u7a76\u8868\u660eLK\u8d85\u8d8a\u4e86\u96f6\u6837\u672c\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u76f8\u6bd4\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u3002", "conclusion": "Laplacian Keyboard\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8d85\u8d8a\u62c9\u666e\u62c9\u65af\u7279\u5f81\u5411\u91cf\u7684\u7ebf\u6027\u7ea6\u675f\uff0c\u901a\u8fc7\u5206\u5c42\u9009\u9879\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u548c\u66f4\u5177\u8868\u8fbe\u529b\u7684\u7b56\u7565\u5b66\u4e60\u3002"}}
{"id": "2602.07732", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.07732", "abs": "https://arxiv.org/abs/2602.07732", "authors": ["Joon Suk Huh"], "title": "Efficient Adaptive Data Analysis over Dense Distributions", "comment": "23 pages", "summary": "Modern data workflows are inherently adaptive, repeatedly querying the same dataset to refine and validate sequential decisions, but such adaptivity can lead to overfitting and invalid statistical inference. Adaptive Data Analysis (ADA) mechanisms address this challenge; however, there is a fundamental tension between computational efficiency and sample complexity. For $T$ rounds of adaptive analysis, computationally efficient algorithms typically incur suboptimal $O(\\sqrt{T})$ sample complexity, whereas statistically optimal $O(\\log T)$ algorithms are computationally intractable under standard cryptographic assumptions. In this work, we shed light on this trade-off by identifying a natural class of data distributions under which both computational efficiency and optimal sample complexity are achievable. We propose a computationally efficient ADA mechanism that attains optimal $O(\\log T)$ sample complexity when the data distribution is dense with respect to a known prior. This setting includes, in particular, feature--label data distributions arising in distribution-specific learning. As a consequence, our mechanism also yields a sample-efficient (i.e., $O(\\log T)$ samples) statistical query oracle in the distribution-specific setting. Moreover, although our algorithm is not based on differential privacy, it satisfies a relaxed privacy notion known as Predicate Singling Out (PSO) security (Cohen and Nissim, 2020). Our results thus reveal an inherent connection between adaptive data analysis and privacy beyond differential privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u9002\u5e94\u6027\u6570\u636e\u5206\u6790\u673a\u5236\uff0c\u5728\u6570\u636e\u5206\u5e03\u76f8\u5bf9\u4e8e\u5df2\u77e5\u5148\u9a8c\u662f\u7a20\u5bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u8fbe\u5230\u6700\u4f18\u7684O(log T)\u6837\u672c\u590d\u6742\u5ea6\uff0c\u7a81\u7834\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u7edf\u8ba1\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u5de5\u4f5c\u6d41\u672c\u8d28\u4e0a\u662f\u9002\u5e94\u6027\u7684\uff0c\u4f1a\u53cd\u590d\u67e5\u8be2\u540c\u4e00\u6570\u636e\u96c6\u6765\u4f18\u5316\u548c\u9a8c\u8bc1\u5e8f\u5217\u51b3\u7b56\uff0c\u4f46\u8fd9\u79cd\u9002\u5e94\u6027\u53ef\u80fd\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u65e0\u6548\u7edf\u8ba1\u63a8\u65ad\u3002\u9002\u5e94\u6027\u6570\u636e\u5206\u6790(ADA)\u673a\u5236\u9762\u4e34\u8ba1\u7b97\u6548\u7387\u4e0e\u6837\u672c\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u6839\u672c\u6027\u6743\u8861\uff1a\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5\u901a\u5e38\u9700\u8981\u6b21\u4f18\u7684O(\u221aT)\u6837\u672c\u590d\u6742\u5ea6\uff0c\u800c\u7edf\u8ba1\u6700\u4f18\u7684O(log T)\u7b97\u6cd5\u5728\u6807\u51c6\u5bc6\u7801\u5b66\u5047\u8bbe\u4e0b\u662f\u8ba1\u7b97\u4e0d\u53ef\u884c\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684ADA\u673a\u5236\uff0c\u5f53\u6570\u636e\u5206\u5e03\u76f8\u5bf9\u4e8e\u5df2\u77e5\u5148\u9a8c\u662f\u7a20\u5bc6\u65f6\uff0c\u80fd\u591f\u8fbe\u5230\u6700\u4f18\u7684O(log T)\u6837\u672c\u590d\u6742\u5ea6\u3002\u8be5\u673a\u5236\u7279\u522b\u9002\u7528\u4e8e\u5206\u5e03\u7279\u5b9a\u5b66\u4e60\u4e2d\u51fa\u73b0\u7684\u7279\u5f81-\u6807\u7b7e\u6570\u636e\u5206\u5e03\u3002\u867d\u7136\u7b97\u6cd5\u4e0d\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\uff0c\u4f46\u6ee1\u8db3\u8c13\u8bcd\u5355\u6311(PSO)\u5b89\u5168\u8fd9\u4e00\u677e\u5f1b\u7684\u9690\u79c1\u6982\u5ff5\u3002", "result": "\u5728\u6570\u636e\u5206\u5e03\u76f8\u5bf9\u4e8e\u5df2\u77e5\u5148\u9a8c\u662f\u7a20\u5bc6\u7684\u81ea\u7136\u7c7b\u522b\u4e0b\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u3002\u8be5\u673a\u5236\u5728\u5206\u5e03\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u4e5f\u4ea7\u751f\u4e86\u4e00\u4e2a\u6837\u672c\u9ad8\u6548\u7684\u7edf\u8ba1\u67e5\u8be2\u9884\u8a00\u673a\u3002\u63ed\u793a\u4e86\u9002\u5e94\u6027\u6570\u636e\u5206\u6790\u4e0e\u5dee\u5206\u9690\u79c1\u4e4b\u5916\u7684\u9690\u79c1\u6982\u5ff5\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u8bc6\u522b\u4e00\u4e2a\u81ea\u7136\u7684\u6570\u636e\u5206\u5e03\u7c7b\u522b\uff0c\u5728\u8be5\u7c7b\u522b\u4e0b\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u548c\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4ece\u800c\u9610\u660e\u4e86\u9002\u5e94\u6027\u6570\u636e\u5206\u6790\u4e2d\u7684\u8ba1\u7b97-\u7edf\u8ba1\u6743\u8861\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5206\u5e03\u7279\u5b9a\u8bbe\u7f6e\u4e0b\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u65e2\u8ba1\u7b97\u9ad8\u6548\u53c8\u7edf\u8ba1\u6700\u4f18\u7684ADA\u673a\u5236\uff0c\u5e76\u4e14\u8fd9\u4e9b\u673a\u5236\u4e0ePSO\u5b89\u5168\u7b49\u9690\u79c1\u6982\u5ff5\u5b58\u5728\u5185\u5728\u8054\u7cfb\u3002"}}
{"id": "2602.08783", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08783", "abs": "https://arxiv.org/abs/2602.08783", "authors": ["Zirui Li", "Xuefeng Bai", "Kehai Chen", "Yizhi Li", "Jian Yang", "Chenghua Lin", "Min Zhang"], "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure", "comment": "22 pages", "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u6f5c\u5728\u601d\u7ef4\u94fe\u89c6\u4e3a\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u53ef\u64cd\u7eb5\u56e0\u679c\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5206\u6790\u6f5c\u5728\u6b65\u9aa4\uff0c\u7814\u7a76\u5176\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u56e0\u679c\u5fc5\u8981\u6027\u3001\u5f71\u54cd\u4f20\u64ad\u548c\u7b54\u6848\u6a21\u5f0f\u4fdd\u7559\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u601d\u7ef4\u94fe\u65b9\u6cd5\u4f7f\u7528\u5185\u90e8\u6f5c\u5728\u6b65\u9aa4\u66ff\u4ee3\u663e\u5f0f\u6587\u672c\u63a8\u7406\uff0c\u4f46\u8fd9\u4e9b\u4e2d\u95f4\u8ba1\u7b97\u96be\u4ee5\u901a\u8fc7\u76f8\u5173\u6027\u63a2\u6d4b\u4e4b\u5916\u7684\u65b9\u5f0f\u8fdb\u884c\u8bc4\u4f30\u3002\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5206\u6790\u6f5c\u5728\u63a8\u7406\u6b65\u9aa4\u7684\u56e0\u679c\u4f5c\u7528\u548c\u5185\u90e8\u52a8\u6001\u3002", "method": "\u5c06\u6f5c\u5728\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\uff0c\u901a\u8fc7\u9010\u6b65do\u5e72\u9884\u5206\u6790\u5176\u6548\u5e94\u3002\u7814\u7a76Coconut\u548cCODI\u4e24\u79cd\u4ee3\u8868\u6027\u8303\u5f0f\uff0c\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e0a\u63a2\u7d22\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u6b65\u9aa4\u7684\u56e0\u679c\u5fc5\u8981\u6027\u3001\u5f71\u54cd\u4f20\u64ad\u7ed3\u6784\u3001\u4ee5\u53ca\u4e2d\u95f4\u8f68\u8ff9\u662f\u5426\u4fdd\u7559\u7ade\u4e89\u7b54\u6848\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u6f5c\u5728\u6b65\u9aa4\u9884\u7b97\u4e0d\u50cf\u540c\u8d28\u7684\u989d\u5916\u6df1\u5ea6\uff0c\u800c\u66f4\u50cf\u5177\u6709\u975e\u5c40\u90e8\u8def\u7531\u7684\u5206\u9636\u6bb5\u529f\u80fd\uff1b\u8bc6\u522b\u51fa\u65e9\u671f\u8f93\u51fa\u504f\u89c1\u4e0e\u665a\u671f\u8868\u793a\u627f\u8bfa\u4e4b\u95f4\u7684\u6301\u7eed\u5dee\u8ddd\uff1b\u6f5c\u5728\u6b65\u9aa4\u8868\u73b0\u51fa\u590d\u6742\u7684\u56e0\u679c\u7ed3\u6784\u548c\u6a21\u5f0f\u52a8\u6001\u3002", "conclusion": "\u9700\u8981\u6a21\u5f0f\u6761\u4ef6\u548c\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u5206\u6790\u65b9\u6cd5\uff08\u4ee5\u53ca\u76f8\u5e94\u7684\u8bad\u7ec3/\u89e3\u7801\u76ee\u6807\uff09\u4f5c\u4e3a\u89e3\u91ca\u548c\u6539\u8fdb\u6f5c\u5728\u63a8\u7406\u7cfb\u7edf\u7684\u66f4\u53ef\u9760\u5de5\u5177\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u6f5c\u5728\u63a8\u7406\u7684\u5185\u90e8\u52a8\u6001\u3002"}}
{"id": "2602.07735", "categories": ["cs.LG", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2602.07735", "abs": "https://arxiv.org/abs/2602.07735", "authors": ["Matteo Rossi", "Ryan Pederson", "Miles Wang-Henderson", "Ben Kaufman", "Edward C. Williams", "Carl Underkoffler", "Owen Lewis Howell", "Adrian Layer", "Stephan Thaler", "Narbe Mardirossian", "John Anthony Parkhill"], "title": "TerraBind: Fast and Accurate Binding Affinity Prediction through Coarse Structural Representations", "comment": "31 pages, 14 figures", "summary": "We present TerraBind, a foundation model for protein-ligand structure and binding affinity prediction that achieves 26-fold faster inference than state-of-the-art methods while improving affinity prediction accuracy by $\\sim$20\\%. Current deep learning approaches to structure-based drug design rely on expensive all-atom diffusion to generate 3D coordinates, creating inference bottlenecks that render large-scale compound screening computationally intractable. We challenge this paradigm with a critical hypothesis: full all-atom resolution is unnecessary for accurate small molecule pose and binding affinity prediction. TerraBind tests this hypothesis through a coarse pocket-level representation (protein C$_\u03b2$ atoms and ligand heavy atoms only) within a multimodal architecture combining COATI-3 molecular encodings and ESM-2 protein embeddings that learns rich structural representations, which are used in a diffusion-free optimization module for pose generation and a binding affinity likelihood prediction module. On structure prediction benchmarks (FoldBench, PoseBusters, Runs N' Poses), TerraBind matches diffusion-based baselines in ligand pose accuracy. Crucially, TerraBind outperforms Boltz-2 by $\\sim$20\\% in Pearson correlation for binding affinity prediction on both a public benchmark (CASP16) and a diverse proprietary dataset (18 biochemical/cell assays). We show that the affinity prediction module also provides well-calibrated affinity uncertainty estimates, addressing a critical gap in reliable compound prioritization for drug discovery. Furthermore, this module enables a continual learning framework and a hedged batch selection strategy that, in simulated drug discovery cycles, achieves 6$\\times$ greater affinity improvement of selected molecules over greedy-based approaches.", "AI": {"tldr": "TerraBind\u662f\u4e00\u4e2a\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u6784\u548c\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u7684\u57fa\u7840\u6a21\u578b\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63a8\u7406\u901f\u5ea6\u5feb26\u500d\uff0c\u4eb2\u548c\u529b\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u9ad8\u7ea620%\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u836f\u7269\u8bbe\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5168\u539f\u5b50\u6269\u6563\u6765\u751f\u62103D\u5750\u6807\uff0c\u5bfc\u81f4\u63a8\u7406\u74f6\u9888\uff0c\u4f7f\u5f97\u5927\u89c4\u6a21\u5316\u5408\u7269\u7b5b\u9009\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u3002\u4f5c\u8005\u5047\u8bbe\uff1a\u51c6\u786e\u7684\u5c0f\u5206\u5b50\u6784\u8c61\u548c\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u4e0d\u9700\u8981\u5168\u539f\u5b50\u5206\u8fa8\u7387\u3002", "method": "\u91c7\u7528\u7c97\u7c92\u5316\u7684\u53e3\u888b\u7ea7\u8868\u793a\uff08\u4ec5\u86cb\u767d\u8d28C\u03b2\u539f\u5b50\u548c\u914d\u4f53\u91cd\u539f\u5b50\uff09\uff0c\u7ed3\u5408COATI-3\u5206\u5b50\u7f16\u7801\u548cESM-2\u86cb\u767d\u8d28\u5d4c\u5165\u7684\u591a\u6a21\u6001\u67b6\u6784\uff0c\u5b66\u4e60\u4e30\u5bcc\u7684\u7ed3\u6784\u8868\u793a\u3002\u4f7f\u7528\u65e0\u6269\u6563\u4f18\u5316\u6a21\u5757\u8fdb\u884c\u6784\u8c61\u751f\u6210\uff0c\u4ee5\u53ca\u7ed3\u5408\u4eb2\u548c\u529b\u4f3c\u7136\u9884\u6d4b\u6a21\u5757\u3002", "result": "\u5728\u7ed3\u6784\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTerraBind\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u57fa\u7ebf\u65b9\u6cd5\u5728\u914d\u4f53\u6784\u8c61\u51c6\u786e\u6027\u4e0a\u76f8\u5f53\u3002\u5728\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u65b9\u9762\uff0c\u5728\u516c\u5171\u57fa\u51c6\uff08CASP16\uff09\u548c\u4e13\u6709\u6570\u636e\u96c6\uff0818\u4e2a\u751f\u5316/\u7ec6\u80de\u68c0\u6d4b\uff09\u4e0a\uff0c\u6bd4Boltz-2\u7684Pearson\u76f8\u5173\u6027\u63d0\u9ad8\u7ea620%\u3002\u4eb2\u548c\u529b\u9884\u6d4b\u6a21\u5757\u8fd8\u63d0\u4f9b\u4e86\u826f\u597d\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5e76\u901a\u8fc7\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u548chedged batch\u9009\u62e9\u7b56\u7565\uff0c\u5728\u6a21\u62df\u836f\u7269\u53d1\u73b0\u5468\u671f\u4e2d\u5b9e\u73b0\u4e86\u6bd4\u8d2a\u5a6a\u65b9\u6cd5\u9ad86\u500d\u7684\u4eb2\u548c\u529b\u6539\u8fdb\u3002", "conclusion": "TerraBind\u8bc1\u660e\u4e86\u7c97\u7c92\u5316\u8868\u793a\u8db3\u4ee5\u5b9e\u73b0\u51c6\u786e\u7684\u86cb\u767d\u8d28-\u914d\u4f53\u7ed3\u6784\u548c\u4eb2\u548c\u529b\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08796", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08796", "abs": "https://arxiv.org/abs/2602.08796", "authors": ["Kevin Fan", "Jacquelyn A. Bialo", "Hongli Li"], "title": "The Use of AI Tools to Develop and Validate Q-Matrices", "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA", "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.", "AI": {"tldr": "AI\u5de5\u5177\u5728\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u4e2d\u751f\u6210Q\u77e9\u9635\u7684\u53ef\u884c\u6027\u7814\u7a76\uff1aGoogle Gemini 2.5 Pro\u57282025\u5e74\u8868\u73b0\u6700\u4f73\uff0c\u4f462026\u5e74\u65b0\u7248AI\u6a21\u578b\u8868\u73b0\u4e0b\u964d", "motivation": "Q\u77e9\u9635\u6784\u5efa\u662f\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u7684\u5173\u952e\u4f46\u52b3\u52a8\u5bc6\u96c6\u578b\u6b65\u9aa4\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u901a\u7528\u8bed\u8a00\u6a21\u578b\u7b49AI\u5de5\u5177\u662f\u5426\u80fd\u652f\u6301Q\u77e9\u9635\u5f00\u53d1", "method": "\u6bd4\u8f83AI\u751f\u6210\u7684Q\u77e9\u9635\u4e0eLi\u548cSuen\uff082013\uff09\u9a8c\u8bc1\u7684\u9605\u8bfb\u6d4b\u8bd5Q\u77e9\u9635\uff0c\u4f7f\u7528\u76f8\u540c\u8bad\u7ec3\u6750\u6599\uff0c\u901a\u8fc7Cohen's kappa\u8bc4\u4f30\u4e00\u81f4\u6027", "result": "AI\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\uff0cGoogle Gemini 2.5 Pro\u57282025\u5e74\u4e0e\u9a8c\u8bc1Q\u77e9\u9635\u4e00\u81f4\u6027\u6700\u9ad8\uff08Kappa=0.63\uff09\uff0c\u8d85\u8fc7\u6240\u6709\u4eba\u7c7b\u4e13\u5bb6\uff1b\u4f462026\u5e74\u65b0\u7248AI\u6a21\u578b\u4e00\u81f4\u6027\u964d\u4f4e", "conclusion": "AI\u5de5\u5177\u5728Q\u77e9\u9635\u5f00\u53d1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u6a21\u578b\u7248\u672c\u66f4\u65b0\u53ef\u80fd\u5f71\u54cd\u6027\u80fd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76AI\u5728\u8ba4\u77e5\u8bca\u65ad\u4e2d\u7684\u53ef\u9760\u5e94\u7528"}}
{"id": "2602.07738", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07738", "abs": "https://arxiv.org/abs/2602.07738", "authors": ["Sunil Madhow", "Yuchen Liang", "Ness Shroff", "Yingbin Liang", "Yu-Xiang Wang"], "title": "Learnable Chernoff Baselines for Inference-Time Alignment", "comment": null, "summary": "We study inference-time reward-guided alignment for generative models. Existing methods often rely on either architecture-specific adaptations or computationally costly inference procedures. We introduce Learnable Chernoff Baselines (LCBs) as a method for efficiently and approximately sampling from the exponentially tilted kernels that arise from KL-regularized reward alignment. Using only black-box sampling access to the pretrained model, LCBs implement a form of rejection sampling with adaptively selected acceptance probabilities, which allows fine-grained control over inference-compute scaling. We establish total-variation guarantees to the ideal aligned model, and demonstrate in both continuous and discrete diffusion settings that LCB sampling closely matches ideal rejection sampling while using substantially fewer queries to the pretrained model.", "AI": {"tldr": "\u63d0\u51faLCB\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684Chernoff\u57fa\u7ebf\u5b9e\u73b0\u63a8\u7406\u65f6\u5956\u52b1\u5f15\u5bfc\u5bf9\u9f50\uff0c\u76f8\u6bd4\u7406\u60f3\u62d2\u7edd\u91c7\u6837\u663e\u8457\u51cf\u5c11\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u67e5\u8be2\u6b21\u6570", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u5956\u52b1\u5f15\u5bfc\u5bf9\u9f50\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7279\u5b9a\u67b6\u6784\u9002\u914d\uff0c\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u4eceKL\u6b63\u5219\u5316\u5956\u52b1\u5bf9\u9f50\u4ea7\u751f\u7684\u6307\u6570\u503e\u659c\u6838\u4e2d\u91c7\u6837", "method": "\u5f15\u5165\u53ef\u5b66\u4e60\u7684Chernoff\u57fa\u7ebf(LCBs)\uff0c\u4ec5\u9700\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9ed1\u76d2\u91c7\u6837\u8bbf\u95ee\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u63a5\u53d7\u6982\u7387\u5b9e\u73b0\u62d2\u7edd\u91c7\u6837\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u63a8\u7406\u8ba1\u7b97\u6269\u5c55\u63a7\u5236", "result": "\u5efa\u7acb\u4e86\u4e0e\u7406\u60f3\u5bf9\u9f50\u6a21\u578b\u7684\u603b\u53d8\u5dee\u4fdd\u8bc1\uff0c\u5728\u8fde\u7eed\u548c\u79bb\u6563\u6269\u6563\u8bbe\u7f6e\u4e2d\uff0cLCB\u91c7\u6837\u4e0e\u7406\u60f3\u62d2\u7edd\u91c7\u6837\u5339\u914d\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u67e5\u8be2\u6b21\u6570", "conclusion": "LCB\u65b9\u6cd5\u4e3a\u63a8\u7406\u65f6\u5956\u52b1\u5f15\u5bfc\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4ec5\u9700\u9ed1\u76d2\u8bbf\u95ee\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u91c7\u6837\u8d28\u91cf\u7684\u826f\u597d\u5e73\u8861"}}
{"id": "2602.08804", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08804", "abs": "https://arxiv.org/abs/2602.08804", "authors": ["Liming Zhou", "Ailing Liu", "Hongwei Liu", "Min He", "Heng Zhang"], "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures", "comment": null, "summary": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.", "AI": {"tldr": "\u63d0\u51faRC-LLM\u65b9\u6cd5\uff0c\u5229\u7528\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u670d\u52a1\u67b6\u6784\u7684\u6839\u56e0\u5b9a\u4f4d\uff0c\u6574\u5408\u591a\u6e90\u9065\u6d4b\u6570\u636e\u5e76\u5efa\u6a21\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u5728\u590d\u6742\u5927\u89c4\u6a21\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\uff0c\u6839\u56e0\u5b9a\u4f4d\u9762\u4e34\u6311\u6218\uff1a\u5fae\u670d\u52a1\u95f4\u6545\u969c\u4f20\u64ad\u590d\u6742\uff0c\u9065\u6d4b\u6570\u636e\uff08\u6307\u6807\u3001\u65e5\u5fd7\u3001\u8ffd\u8e2a\uff09\u7ef4\u5ea6\u9ad8\uff0c\u9650\u5236\u4e86\u73b0\u6709RCA\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faRC-LLM\u65b9\u6cd5\uff1a\u8bbe\u8ba1\u6b8b\u5dee\u5f0f\u5c42\u6b21\u878d\u5408\u7ed3\u6784\u6574\u5408\u591a\u6e90\u9065\u6d4b\u6570\u636e\uff1b\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u5efa\u6a21\u65f6\u95f4\u8de8\u5ea6\u548c\u8de8\u5fae\u670d\u52a1\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728CCF-AIOps\u5fae\u670d\u52a1\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRC-LLM\u5728\u6839\u56e0\u5206\u6790\u4e2d\u5b9e\u73b0\u4e86\u8f83\u5f3a\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "RC-LLM\u901a\u8fc7\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u6839\u56e0\u5b9a\u4f4d\u95ee\u9898\uff0c\u63d0\u5347\u4e86RCA\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.07744", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07744", "abs": "https://arxiv.org/abs/2602.07744", "authors": ["Dongyeop Woo", "Marta Skreta", "Seonghyun Park", "Sungsoo Ahn", "Kirill Neklyudov"], "title": "Riemannian MeanFlow", "comment": null, "summary": "Diffusion and flow models have become the dominant paradigm for generative modeling on Riemannian manifolds, with successful applications in protein backbone generation and DNA sequence design. However, these methods require tens to hundreds of neural network evaluations at inference time, which can become a computational bottleneck in large-scale scientific sampling workflows. We introduce Riemannian MeanFlow~(RMF), a framework for learning flow maps directly on manifolds, enabling high-quality generations with as few as one forward pass. We derive three equivalent characterizations of the manifold average velocity (Eulerian, Lagrangian, and semigroup identities), and analyze parameterizations and stabilization techniques to improve training on high-dimensional manifolds. In promoter DNA design and protein backbone generation settings, RMF achieves comparable sample quality to prior methods while requiring up to 10$\\times$ fewer function evaluations. Finally, we show that few-step flow maps enable efficient reward-guided design through reward look-ahead, where terminal states can be predicted from intermediate steps at minimal additional cost.", "AI": {"tldr": "Riemannian MeanFlow (RMF) \u662f\u4e00\u79cd\u5728\u6d41\u5f62\u4e0a\u76f4\u63a5\u5b66\u4e60\u6d41\u6620\u5c04\u7684\u6846\u67b6\uff0c\u53ea\u9700\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u76f8\u6bd4\u6269\u6563\u6a21\u578b\u51cf\u5c1110\u500d\u8ba1\u7b97\u91cf\u3002", "motivation": "\u5f53\u524d\u5728\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u6269\u6563\u548c\u6d41\u6a21\u578b\u9700\u8981\u6570\u5341\u5230\u6570\u767e\u6b21\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\uff0c\u5728\u5927\u89c4\u6a21\u79d1\u5b66\u91c7\u6837\u5de5\u4f5c\u6d41\u4e2d\u6210\u4e3a\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u9ece\u66fc\u5e73\u5747\u6d41(RMF)\u6846\u67b6\uff0c\u63a8\u5bfc\u6d41\u5f62\u5e73\u5747\u901f\u5ea6\u7684\u4e09\u79cd\u7b49\u4ef7\u8868\u5f81\uff08\u6b27\u62c9\u3001\u62c9\u683c\u6717\u65e5\u548c\u534a\u7fa4\u6052\u7b49\u5f0f\uff09\uff0c\u5206\u6790\u53c2\u6570\u5316\u548c\u7a33\u5b9a\u5316\u6280\u672f\u4ee5\u6539\u8fdb\u9ad8\u7ef4\u6d41\u5f62\u4e0a\u7684\u8bad\u7ec3\u3002", "result": "\u5728\u542f\u52a8\u5b50DNA\u8bbe\u8ba1\u548c\u86cb\u767d\u8d28\u9aa8\u67b6\u751f\u6210\u4efb\u52a1\u4e2d\uff0cRMF\u8fbe\u5230\u4e0e\u5148\u524d\u65b9\u6cd5\u76f8\u5f53\u7684\u6837\u672c\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe10\u500d\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u3002\u5c11\u6b65\u6d41\u6620\u5c04\u901a\u8fc7\u5956\u52b1\u524d\u77bb\u5b9e\u73b0\u9ad8\u6548\u5956\u52b1\u5f15\u5bfc\u8bbe\u8ba1\u3002", "conclusion": "RMF\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6d41\u5f62\u751f\u6210\u5efa\u6a21\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6837\u672c\u8d28\u91cf\uff0c\u4e3a\u5927\u89c4\u6a21\u79d1\u5b66\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u91c7\u6837\u548c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.08815", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08815", "abs": "https://arxiv.org/abs/2602.08815", "authors": ["Yanglei Gan", "Peng He", "Yuxiang Cai", "Run Lin", "Guanyu Zhou", "Qiao Liu"], "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation", "comment": null, "summary": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.", "AI": {"tldr": "NADEx\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u8d1f\u611f\u77e5\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u8d1f\u6837\u672c\u539f\u578b\u548c\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u63d0\u5347\u672a\u6765\u4e8b\u5b9e\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u3002", "motivation": "\u5f53\u524d\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u6269\u6563\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u751f\u6210\u8def\u5f84\u4ec5\u57fa\u4e8e\u6b63\u6837\u672c\u8bc1\u636e\uff0c\u5ffd\u7565\u4e86\u4fe1\u606f\u4e30\u5bcc\u7684\u8d1f\u6837\u672c\u4e0a\u4e0b\u6587\uff1b2) \u8bad\u7ec3\u76ee\u6807\u4ee5\u4ea4\u53c9\u71b5\u6392\u5e8f\u4e3a\u4e3b\uff0c\u867d\u7136\u80fd\u6539\u5584\u5019\u9009\u6392\u5e8f\u4f46\u5bf9\u53bb\u566a\u5d4c\u5165\u7684\u6821\u51c6\u76d1\u7763\u4e0d\u8db3\u3002", "method": "NADEx\u5c06\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u65f6\u5e8f\u95f4\u9694\u7684\u4e3b\u4f53\u4e2d\u5fc3\u5386\u53f2\u7f16\u7801\u4e3a\u5e8f\u5217\u5d4c\u5165\uff0c\u5728\u6b63\u5411\u8fc7\u7a0b\u4e2d\u6270\u52a8\u67e5\u8be2\u5bf9\u8c61\uff0c\u5728\u53cd\u5411\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u57fa\u4e8e\u65f6\u5e8f\u5173\u7cfb\u4e0a\u4e0b\u6587\u7684Transformer\u53bb\u566a\u5668\u8fdb\u884c\u91cd\u5efa\u3002\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u6279\u5904\u7406\u8d1f\u6837\u672c\u539f\u578b\u7684\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\u5668\uff0c\u6536\u7d27\u51b3\u7b56\u8fb9\u754c\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNADEx\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "NADEx\u901a\u8fc7\u6709\u6548\u5229\u7528\u8d1f\u6837\u672c\u4fe1\u606f\u548c\u6539\u8fdb\u8bad\u7ec3\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u9884\u6d4b\u80fd\u529b\u548c\u6a21\u578b\u6821\u51c6\u6027\u3002"}}
{"id": "2602.07764", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07764", "abs": "https://arxiv.org/abs/2602.07764", "authors": ["Tanmay Ambadkar", "Sourav Panda", "Shreyash Kale", "Jonathan Dodge", "Abhinav Verma"], "title": "Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization", "comment": null, "summary": "Multi-objective reinforcement learning (MORL) seeks to learn policies that balance multiple, often conflicting objectives. Although a single preference-conditioned policy is the most flexible and scalable solution, existing approaches remain brittle in practice, frequently failing to recover complete Pareto fronts. We show that this failure stems from two structural issues in current methods: destructive gradient interference caused by premature scalarization and representational collapse across the preference space. We introduce $D^3PO$, a PPO-based framework that reorganizes multi-objective policy optimization to address these issues directly. $D^3PO$ preserves per-objective learning signals through a decomposed optimization pipeline and integrates preferences only after stabilization, enabling reliable credit assignment. In addition, a scaled diversity regularizer enforces sensitivity of policy behavior to preference changes, preventing collapse. Across standard MORL benchmarks, including high-dimensional and many-objective control tasks, $D^3PO$ consistently discovers broader and higher-quality Pareto fronts than prior single- and multi-policy methods, matching or exceeding state-of-the-art hypervolume and expected utility while using a single deployable policy.", "AI": {"tldr": "D\u00b3PO\u662f\u4e00\u4e2a\u57fa\u4e8ePPO\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u4f18\u5316\u6d41\u7a0b\u548c\u5ef6\u8fdf\u504f\u597d\u6574\u5408\u6765\u89e3\u51b3\u68af\u5ea6\u5e72\u6270\u548c\u8868\u793a\u574d\u584c\u95ee\u9898\uff0c\u5728\u5355\u7b56\u7565\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u8d28\u91cf\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u73b0\u6709\u5355\u504f\u597d\u6761\u4ef6\u7b56\u7565\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u8106\u5f31\uff0c\u7ecf\u5e38\u65e0\u6cd5\u6062\u590d\u5b8c\u6574\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002\u8fd9\u6e90\u4e8e\u4e24\u4e2a\u7ed3\u6784\u6027\u95ee\u9898\uff1a\u8fc7\u65e9\u6807\u91cf\u5316\u5bfc\u81f4\u7684\u7834\u574f\u6027\u68af\u5ea6\u5e72\u6270\uff0c\u4ee5\u53ca\u504f\u597d\u7a7a\u95f4\u4e2d\u7684\u8868\u793a\u574d\u584c\u3002", "method": "D\u00b3PO\u57fa\u4e8ePPO\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u4f18\u5316\u6d41\u7a0b\u4fdd\u7559\u6bcf\u4e2a\u76ee\u6807\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u4ec5\u5728\u7a33\u5b9a\u540e\u6574\u5408\u504f\u597d\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u4fe1\u7528\u5206\u914d\u3002\u540c\u65f6\u4f7f\u7528\u7f29\u653e\u591a\u6837\u6027\u6b63\u5219\u5316\u5668\u786e\u4fdd\u7b56\u7565\u884c\u4e3a\u5bf9\u504f\u597d\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u9632\u6b62\u8868\u793a\u574d\u584c\u3002", "result": "\u5728\u6807\u51c6MORL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5305\u62ec\u9ad8\u7ef4\u548c\u591a\u76ee\u6807\u63a7\u5236\u4efb\u52a1\uff0cD\u00b3PO\u59cb\u7ec8\u6bd4\u5148\u524d\u7684\u5355\u7b56\u7565\u548c\u591a\u7b56\u7565\u65b9\u6cd5\u53d1\u73b0\u66f4\u5e7f\u6cdb\u3001\u66f4\u9ad8\u8d28\u91cf\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5728\u8d85\u4f53\u79ef\u548c\u671f\u671b\u6548\u7528\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u4f7f\u7528\u5355\u4e2a\u53ef\u90e8\u7f72\u7b56\u7565\u3002", "conclusion": "D\u00b3PO\u901a\u8fc7\u89e3\u51b3\u68af\u5ea6\u5e72\u6270\u548c\u8868\u793a\u574d\u584c\u95ee\u9898\uff0c\u4e3a\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u7684\u5355\u7b56\u7565\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u53ef\u9760\u5730\u5b66\u4e60\u5b8c\u6574\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2602.07790", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07790", "abs": "https://arxiv.org/abs/2602.07790", "authors": ["Wanyun Xie", "Francesco Tonin", "Volkan Cevher"], "title": "MaD-Mix: Multi-Modal Data Mixtures via Latent Space Coupling for Vision-Language Model Training", "comment": null, "summary": "Vision-Language Models (VLMs) are typically trained on a diverse set of multi-modal domains, yet current practices rely on costly manual tuning. We propose MaD-Mix, a principled and computationally efficient framework that derives multi-modal data mixtures for VLM training. MaD-Mix formulates data mixing as modality-aware domain alignment maximization and obtains closed-form multi-modal alignment scores from the Fenchel dual through inter-modal coupling variables. MaD-Mix systematically handles domains with missing modalities, allowing for the integration of language-only domains. Empirical evaluations across 0.5B and 7B models demonstrate that MaD-Mix accelerates VLM training across diverse benchmarks. MaD-Mix matches human-tuned data mixtures using 22% fewer training steps in image-text instruction tuning. In complex tri-modal video-image-text scenarios, where manual tuning becomes impractical, MaD-Mix boosts average accuracy over uniform weights, with negligible mixture computation overhead (< 1 GPU-hour), enabling scalable mixture design for modern VLM pipelines.", "AI": {"tldr": "MaD-Mix\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6570\u636e\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u6001\u611f\u77e5\u7684\u9886\u57df\u5bf9\u9f50\u6700\u5927\u5316\u6765\u4f18\u5316VLM\u8bad\u7ec3\u6570\u636e\u914d\u6bd4\uff0c\u51cf\u5c11\u4eba\u5de5\u8c03\u53c2\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4f9d\u8d56\u6602\u8d35\u7684\u4eba\u5de5\u6570\u636e\u6df7\u5408\u8c03\u4f18\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u9886\u57df\uff08\u5982\u56fe\u50cf-\u6587\u672c\u3001\u89c6\u9891-\u56fe\u50cf-\u6587\u672c\uff09\u4e2d\uff0c\u624b\u52a8\u4f18\u5316\u6570\u636e\u914d\u6bd4\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u5c06\u6570\u636e\u6df7\u5408\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u6a21\u6001\u611f\u77e5\u7684\u9886\u57df\u5bf9\u9f50\u6700\u5927\u5316\uff0c\u901a\u8fc7Fenchel\u5bf9\u5076\u548c\u8de8\u6a21\u6001\u8026\u5408\u53d8\u91cf\u83b7\u5f97\u95ed\u5f0f\u591a\u6a21\u6001\u5bf9\u9f50\u5206\u6570\uff0c\u80fd\u7cfb\u7edf\u5904\u7406\u7f3a\u5931\u6a21\u6001\u7684\u9886\u57df\u5e76\u6574\u5408\u7eaf\u6587\u672c\u9886\u57df\u3002", "result": "\u57280.5B\u548c7B\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u5728\u56fe\u50cf-\u6587\u672c\u6307\u4ee4\u8c03\u4f18\u4e2d\uff0cMaD-Mix\u752822%\u66f4\u5c11\u7684\u8bad\u7ec3\u6b65\u9aa4\u8fbe\u5230\u4eba\u5de5\u8c03\u4f18\u6548\u679c\uff1b2\uff09\u5728\u4e09\u6a21\u6001\u89c6\u9891-\u56fe\u50cf-\u6587\u672c\u573a\u666f\u4e2d\uff0c\u663e\u8457\u4f18\u4e8e\u5747\u5300\u6743\u91cd\uff1b3\uff09\u6df7\u5408\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\uff08<1 GPU\u5c0f\u65f6\uff09\u3002", "conclusion": "MaD-Mix\u4e3a\u73b0\u4ee3VLM\u8bad\u7ec3\u6d41\u7a0b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6570\u636e\u6df7\u5408\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u8c03\u53c2\u9700\u6c42\u5e76\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2602.08848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08848", "abs": "https://arxiv.org/abs/2602.08848", "authors": ["Quentin Cohen-Solal", "Alexandre Niveau", "Maroua Bouzid"], "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks", "comment": null, "summary": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6574\u5408\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\uff0c\u5e76\u7814\u7a76\u5176\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u590d\u6742\u5ea6\u3002", "motivation": "\u5b9a\u6027\u63a8\u7406\u80fd\u5728\u4e0d\u7cbe\u786e\u3001\u4e0d\u5b8c\u6574\u3001\u65e0\u6570\u503c\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u65b0\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u6587\u732e\u4e2d\u7684\u5b9a\u4e49\u6392\u9664\u4e86\u67d0\u4e9b\u5728\u7ec4\u5408\u573a\u666f\u4e2d\u91cd\u8981\u7684\u5b9a\u6027\u5f62\u5f0f\u5316\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u591a\u79cd\u6269\u5c55\u548c\u7ec4\u5408\u5f62\u5f0f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7edf\u4e00\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\u3002\u5efa\u7acb\u4e24\u4e2a\u4e92\u8865\u5b9a\u7406\u4fdd\u8bc1\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u7684\u591a\u9879\u5f0f\u590d\u6742\u5ea6\uff0c\u5e76\u63a8\u5e7f\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u4e3b\u8981\u5b9a\u4e49\u4ee5\u5305\u542b\u6587\u732e\u5b9a\u4e49\u4e2d\u6392\u9664\u4f46\u5728\u7ec4\u5408\u4e2d\u91cd\u8981\u7684\u5f62\u5f0f\u5316\u3002", "result": "\u5efa\u7acb\u4e86\u4e24\u4e2a\u4e92\u8865\u5b9a\u7406\u4fdd\u8bc1\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u662f\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u7684\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u5b9a\u7406\u6062\u590d\u4e86\u5c3a\u5bf8-\u62d3\u6251\u7ec4\u5408\u7684\u5df2\u77e5\u7ed3\u679c\u3002\u6269\u5c55\u4e86\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u5b9a\u4e49\uff0c\u4f7f\u5176\u5305\u542b\u5728\u7ec4\u5408\u573a\u666f\u4e2d\u91cd\u8981\u4f46\u88ab\u73b0\u6709\u6587\u732e\u6392\u9664\u7684\u5f62\u5f0f\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u80fd\u591f\u5904\u7406\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\uff0c\u4e3a\u7814\u7a76\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u5176\u590d\u6742\u5ea6\u63d0\u4f9b\u4e86\u7edf\u4e00\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u5b9a\u6027\u63a8\u7406\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.07798", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07798", "abs": "https://arxiv.org/abs/2602.07798", "authors": ["Ruiqi Wang", "Ruikang Liu", "Runyu Chen", "Haoxiang Suo", "Zhiyi Peng", "Zhuo Tang", "Changjian Chen"], "title": "CausalTAD: Injecting Causal Knowledge into Large Language Models for Tabular Anomaly Detection", "comment": null, "summary": "Detecting anomalies in tabular data is critical for many real-world applications, such as credit card fraud detection. With the rapid advancements in large language models (LLMs), state-of-the-art performance in tabular anomaly detection has been achieved by converting tabular data into text and fine-tuning LLMs. However, these methods randomly order columns during conversion, without considering the causal relationships between them, which is crucial for accurately detecting anomalies. In this paper, we present CausalTaD, a method that injects causal knowledge into LLMs for tabular anomaly detection. We first identify the causal relationships between columns and reorder them to align with these causal relationships. This reordering can be modeled as a linear ordering problem. Since each column contributes differently to the causal relationships, we further propose a reweighting strategy to assign different weights to different columns to enhance this effect. Experiments across more than 30 datasets demonstrate that our method consistently outperforms the current state-of-the-art methods. The code for CausalTAD is available at https://github.com/350234/CausalTAD.", "AI": {"tldr": "CausalTaD\uff1a\u901a\u8fc7\u6ce8\u5165\u56e0\u679c\u77e5\u8bc6\u5230LLMs\u4e2d\uff0c\u6539\u8fdb\u8868\u683c\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u7684\u65b9\u6cd5", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3a\u6587\u672c\u65f6\u968f\u673a\u6392\u5217\u5217\u987a\u5e8f\uff0c\u5ffd\u7565\u4e86\u5217\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u800c\u8fd9\u5bf9\u51c6\u786e\u68c0\u6d4b\u5f02\u5e38\u81f3\u5173\u91cd\u8981", "method": "1) \u8bc6\u522b\u5217\u95f4\u56e0\u679c\u5173\u7cfb\u5e76\u91cd\u65b0\u6392\u5e8f\u4ee5\u5bf9\u9f50\u8fd9\u4e9b\u5173\u7cfb\uff08\u5efa\u6a21\u4e3a\u7ebf\u6027\u6392\u5e8f\u95ee\u9898\uff09\uff1b2) \u63d0\u51fa\u91cd\u52a0\u6743\u7b56\u7565\uff0c\u4e3a\u4e0d\u540c\u5217\u5206\u914d\u4e0d\u540c\u6743\u91cd\u4ee5\u589e\u5f3a\u56e0\u679c\u6548\u5e94", "result": "\u5728\u8d85\u8fc730\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5", "conclusion": "CausalTaD\u901a\u8fc7\u6ce8\u5165\u56e0\u679c\u77e5\u8bc6\u5230LLMs\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u5f02\u5e38\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2602.08889", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08889", "abs": "https://arxiv.org/abs/2602.08889", "authors": ["Tobias Lorenz", "Mario Fritz"], "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation", "comment": null, "summary": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.", "AI": {"tldr": "LLM-based Scalable Delphi\u65b9\u6cd5\u53ef\u5c06\u4f20\u7edf\u4e13\u5bb6\u54a8\u8be2\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5206\u949f\uff0c\u5728AI\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e0e\u57fa\u51c6\u771f\u76f8\u76f8\u5173\u6027\u8fbe0.87-0.95\u3002", "motivation": "\u4f20\u7edfDelphi\u4e13\u5bb6\u54a8\u8be2\u65b9\u6cd5\u867d\u7136\u51c6\u786e\u4f46\u8017\u65f6\u6570\u6708\u4e14\u9700\u8981\u4e13\u5bb6\u5927\u91cf\u65f6\u95f4\uff0c\u4f7f\u5f97\u4e25\u683c\u7684\u98ce\u9669\u8bc4\u4f30\u96be\u4ee5\u666e\u53ca\u3002\u9700\u8981\u5bfb\u627e\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u6269\u5927\u7ed3\u6784\u5316\u4e13\u5bb6\u54a8\u8be2\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51faScalable Delphi\u65b9\u6cd5\uff0c\u5c06\u7ecf\u5178Delphi\u534f\u8bae\u9002\u914d\u5230LLM\uff0c\u4f7f\u7528\u591a\u6837\u5316\u4e13\u5bb6\u89d2\u8272\u3001\u8fed\u4ee3\u7cbe\u70bc\u548c\u7406\u7531\u5171\u4eab\u3002\u5f00\u53d1\u57fa\u4e8e\u5fc5\u8981\u6761\u4ef6\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u53ef\u9a8c\u8bc1\u4ee3\u7406\u7684\u6821\u51c6\u3001\u5bf9\u8bc1\u636e\u7684\u654f\u611f\u6027\u3001\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728AI\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u9886\u57df\uff0cLLM\u4e13\u5bb6\u5c0f\u7ec4\u4e0e\u57fa\u51c6\u771f\u76f8\u7684\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u8fbe\u52300.87-0.95\uff0c\u968f\u7740\u8bc1\u636e\u589e\u52a0\u7cfb\u7edf\u6027\u5730\u6539\u8fdb\uff0c\u5e76\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5c0f\u7ec4\u4fdd\u6301\u4e00\u81f4\u3002\u5728\u4e00\u4e2a\u6bd4\u8f83\u4e2d\uff0cLLM\u5c0f\u7ec4\u4e0e\u4eba\u7c7b\u5c0f\u7ec4\u7684\u63a5\u8fd1\u7a0b\u5ea6\u751a\u81f3\u8d85\u8fc7\u4e24\u4e2a\u4eba\u7c7b\u5c0f\u7ec4\u4e4b\u95f4\u7684\u63a5\u8fd1\u7a0b\u5ea6\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u4e13\u5bb6\u54a8\u8be2\u53ef\u4ee5\u5c06\u7ed3\u6784\u5316\u4e13\u5bb6\u5224\u65ad\u6269\u5c55\u5230\u4f20\u7edf\u65b9\u6cd5\u4e0d\u53ef\u884c\u7684\u573a\u666f\uff0c\u5c06\u54a8\u8be2\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5206\u949f\uff0c\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5b9a\u91cf\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07799", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07799", "abs": "https://arxiv.org/abs/2602.07799", "authors": ["Ching Lam Choi", "Vighnesh Subramaniam", "Phillip Isola", "Antonio Torralba", "Stefanie Jegelka"], "title": "Fairness Aware Reward Optimization", "comment": null, "summary": "Demographic skews in human preference data propagate systematic unfairness through reward models into aligned LLMs. We introduce Fairness Aware Reward Optimization (Faro), an in-processing framework that trains reward models under demographic parity, equalized odds, or counterfactual fairness constraints. We provide the first theoretical analysis of reward-level fairness in LLM alignment, establishing: (i) provable fairness certificates for Faro-trained rewards with controllable slack; a (ii) formal characterization of the accuracy-fairness trade-off induced by KL-regularized fine-tuning, proving fairness transfers from reward to policy; and the (iii) existence of a non-empty Pareto frontier. Unlike pre- and post-processing methods, Faro ensures reward models are simultaneously ordinal (ranking correctly), cardinal (calibrated), and fair. Across multiple LLMs and benchmarks, Faro significantly reduces bias and harmful generations while maintaining or improving model quality.", "AI": {"tldr": "Faro\u662f\u4e00\u4e2a\u516c\u5e73\u611f\u77e5\u7684\u5956\u52b1\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bad\u7ec3\u6ee1\u8db3\u516c\u5e73\u6027\u7ea6\u675f\u7684\u5956\u52b1\u6a21\u578b\u6765\u51cf\u5c11LLM\u5bf9\u9f50\u4e2d\u7684\u504f\u89c1\u4f20\u64ad\u3002", "motivation": "\u4eba\u7c7b\u504f\u597d\u6570\u636e\u4e2d\u7684\u7fa4\u4f53\u504f\u89c1\u4f1a\u901a\u8fc7\u5956\u52b1\u6a21\u578b\u4f20\u64ad\u5230\u5bf9\u9f50\u7684LLM\u4e2d\uff0c\u5bfc\u81f4\u7cfb\u7edf\u6027\u4e0d\u516c\u5e73\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u4fdd\u8bc1\u5956\u52b1\u6a21\u578b\u7684\u6392\u5e8f\u6b63\u786e\u6027\u3001\u6821\u51c6\u6027\u548c\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51faFaro\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u65f6\u52a0\u5165\u4eba\u53e3\u7edf\u8ba1\u5e73\u7b49\u3001\u5747\u8861\u673a\u4f1a\u6216\u53cd\u4e8b\u5b9e\u516c\u5e73\u7ea6\u675f\uff0c\u5e76\u8fdb\u884cKL\u6b63\u5219\u5316\u5fae\u8c03\uff0c\u786e\u4fdd\u5956\u52b1\u6a21\u578b\u540c\u65f6\u5177\u6709\u5e8f\u6570\u6027\u3001\u57fa\u6570\u6027\u548c\u516c\u5e73\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1aFaro\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u5177\u6709\u53ef\u63a7\u677e\u5f1b\u7684\u516c\u5e73\u6027\u8bc1\u660e\uff1bKL\u6b63\u5219\u5316\u5fae\u8c03\u80fd\u5b9e\u73b0\u4ece\u5956\u52b1\u5230\u7b56\u7565\u7684\u516c\u5e73\u6027\u4f20\u9012\uff1b\u5b58\u5728\u975e\u7a7a\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002\u5b9e\u9a8c\u663e\u793aFaro\u663e\u8457\u51cf\u5c11\u504f\u89c1\u548c\u6709\u5bb3\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u8d28\u91cf\u3002", "conclusion": "Faro\u662f\u4e00\u4e2a\u6709\u6548\u7684\u516c\u5e73\u611f\u77e5\u5956\u52b1\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5728LLM\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u51cf\u5c11\u504f\u89c1\u4f20\u64ad\uff0c\u76f8\u6bd4\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u80fd\u540c\u65f6\u4fdd\u8bc1\u5956\u52b1\u6a21\u578b\u7684\u6392\u5e8f\u3001\u6821\u51c6\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2602.08905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08905", "abs": "https://arxiv.org/abs/2602.08905", "authors": ["Jiawei Liu", "Xiting Wang", "Yuanyuan Zhong", "Defu Lian", "Yu Yang"], "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models", "comment": "13 pages, 3 figures", "summary": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.", "AI": {"tldr": "STP\u6846\u67b6\u901a\u8fc7\u65f6\u7a7a\u526a\u679d\u63d0\u5347\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u91ca\u653e\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218", "method": "\u63d0\u51fa\u65f6\u7a7a\u526a\u679d(STP)\u6846\u67b6\uff1a1)\u7a7a\u95f4\u526a\u679d\u4f7f\u7528\u9759\u6001\u5148\u9a8c\u7ea6\u675f\u63a2\u7d22\u7a7a\u95f4\uff1b2)\u65f6\u95f4\u526a\u679d\u7ed5\u8fc7\u5197\u4f59\u7684\u540e\u671f\u7ec6\u5316\u6b65\u9aa4", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eSTP\u4e25\u683c\u964d\u4f4e\u4e86\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u5b9e\u9a8c\u8bc1\u660eSTP\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "STP\u6846\u67b6\u80fd\u540c\u65f6\u63d0\u5347\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.07800", "categories": ["cs.LG", "cs.NE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07800", "abs": "https://arxiv.org/abs/2602.07800", "authors": ["Rahul Padmanabhan", "Simone Brugiapaglia"], "title": "Approximating Matrix Functions with Deep Neural Networks and Transformers", "comment": null, "summary": "Transformers have revolutionized natural language processing, but their use for numerical computation has received less attention. We study the approximation of matrix functions, which map scalar functions to matrices, using neural networks including transformers. We focus on functions mapping square matrices to square matrices of the same dimension. These types of matrix functions appear throughout scientific computing, e.g., the matrix exponential in continuous-time Markov chains and the matrix sign function in stability analysis of dynamical systems. In this paper, we make two contributions. First, we prove bounds on the width and depth of ReLU networks needed to approximate the matrix exponential to an arbitrary precision. Second, we show experimentally that a transformer encoder-decoder with suitable numerical encodings can approximate certain matrix functions at a relative error of 5% with high probability. Our study reveals that the encoding scheme strongly affects performance, with different schemes working better for different functions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff08\u5305\u62ecTransformer\uff09\u8fd1\u4f3c\u77e9\u9635\u51fd\u6570\uff0c\u8bc1\u660e\u4e86ReLU\u7f51\u7edc\u8fd1\u4f3c\u77e9\u9635\u6307\u6570\u7684\u5bbd\u5ea6\u548c\u6df1\u5ea6\u754c\u9650\uff0c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Transformer\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5728\u9002\u5f53\u6570\u503c\u7f16\u7801\u4e0b\u80fd\u4ee55%\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u67d0\u4e9b\u77e9\u9635\u51fd\u6570\u3002", "motivation": "Transformer\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u53d6\u5f97\u4e86\u9769\u547d\u6027\u8fdb\u5c55\uff0c\u4f46\u5728\u6570\u503c\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u8f83\u5c11\u53d7\u5230\u5173\u6ce8\u3002\u77e9\u9635\u51fd\u6570\uff08\u5c06\u6807\u91cf\u51fd\u6570\u6620\u5c04\u5230\u77e9\u9635\uff09\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u5982\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\u4e2d\u7684\u77e9\u9635\u6307\u6570\u548c\u52a8\u529b\u7cfb\u7edf\u7a33\u5b9a\u6027\u5206\u6790\u4e2d\u7684\u77e9\u9635\u7b26\u53f7\u51fd\u6570\u3002\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u8fd1\u4f3c\u8fd9\u4e9b\u77e9\u9635\u51fd\u6570\u5177\u6709\u91cd\u8981\u7406\u8bba\u548c\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u7406\u8bba\u5206\u6790\uff1a\u8bc1\u660eReLU\u7f51\u7edc\u8fd1\u4f3c\u77e9\u9635\u6307\u6570\u6240\u9700\u7684\u5bbd\u5ea6\u548c\u6df1\u5ea6\u754c\u9650\uff1b2\uff09\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u4f7f\u7528Transformer\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u914d\u5408\u4e0d\u540c\u7684\u6570\u503c\u7f16\u7801\u65b9\u6848\uff0c\u8fd1\u4f3c\u7279\u5b9a\u77e9\u9635\u51fd\u6570\u3002", "result": "\u7406\u8bba\u65b9\u9762\u8bc1\u660e\u4e86ReLU\u7f51\u7edc\u8fd1\u4f3c\u77e9\u9635\u6307\u6570\u7684\u5bbd\u5ea6\u548c\u6df1\u5ea6\u754c\u9650\uff1b\u5b9e\u9a8c\u65b9\u9762\u663e\u793a\uff0c\u5728\u9002\u5f53\u7684\u6570\u503c\u7f16\u7801\u4e0b\uff0cTransformer\u7f16\u7801\u5668-\u89e3\u7801\u5668\u80fd\u4ee55%\u7684\u76f8\u5bf9\u8bef\u5dee\u8fd1\u4f3c\u67d0\u4e9b\u77e9\u9635\u51fd\u6570\uff0c\u4e14\u7f16\u7801\u65b9\u6848\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e0d\u540c\u51fd\u6570\u9002\u5408\u4e0d\u540c\u7684\u7f16\u7801\u65b9\u6848\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u795e\u7ecf\u7f51\u7edc\uff08\u5305\u62ecTransformer\uff09\u80fd\u591f\u6709\u6548\u8fd1\u4f3c\u77e9\u9635\u51fd\u6570\uff0c\u7f16\u7801\u65b9\u6848\u662f\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002\u8fd9\u4e3a\u5c06Transformer\u7b49\u5148\u8fdb\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5e94\u7528\u4e8e\u6570\u503c\u8ba1\u7b97\u9886\u57df\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u9a8c\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.08939", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08939", "abs": "https://arxiv.org/abs/2602.08939", "authors": ["Longling Geng", "Andy Ouyang", "Theodore Wu", "Daphne Barretto", "Matthew John Hayes", "Rachael Cooper", "Yuqiao Zeng", "Sameer Vijay", "Gia Ancone", "Ankit Rai", "Matthew Wolfman", "Patrick Flanagan", "Edward Y. Chang"], "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse", "comment": "17 pages, 20 tables, figures", "summary": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench", "AI": {"tldr": "CausalT5K\u662f\u4e00\u4e2a\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u68c0\u6d4bLLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u9636\u68af\u584c\u9677\u3001\u8c04\u5a9a\u6f02\u79fb\u548c\u9519\u8bef\u62d2\u7edd\uff0c\u901a\u8fc7\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u6307\u6807\u63ed\u793a\u805a\u5408\u51c6\u786e\u7387\u65e0\u6cd5\u53d1\u73b0\u7684\u6545\u969c\u6a21\u5f0f\u3002", "motivation": "LLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u5b58\u5728\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff08\u5982\u8c04\u5a9a\u3001\u9636\u68af\u584c\u9677\u3001\u9519\u8bef\u62d2\u7edd\uff09\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7cfb\u7edf\u8bca\u65ad\u7684\u57fa\u51c6\uff0c\u6539\u8fdb\u8fdb\u5c55\u7f13\u6162\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u7cfb\u7edf\u68c0\u6d4b\u8fd9\u4e9b\u6545\u969c\u6a21\u5f0f\u7684\u8bca\u65ad\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86CausalT5K\u57fa\u51c6\uff0c\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\uff0c\u8986\u76d610\u4e2a\u9886\u57df\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5173\u952e\u80fd\u529b\uff1a\u68c0\u6d4b\u9636\u68af\u584c\u9677\u3001\u62b5\u6297\u8c04\u5a9a\u6f02\u79fb\u3001\u751f\u6210\u660e\u667a\u62d2\u7edd\u3002\u91c7\u7528\u4eba\u673a\u534f\u4f5c\u6d41\u7a0b\uff0c40\u4f4d\u9886\u57df\u4e13\u5bb6\u53c2\u4e0e\uff0c\u901a\u8fc7\u8fed\u4ee3\u4ea4\u53c9\u9a8c\u8bc1\u548c\u57fa\u4e8e\u89c4\u5219\u3001LLM\u3001\u4eba\u5de5\u8bc4\u5206\u7684\u590d\u5408\u9a8c\u8bc1\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u63ed\u793a\u4e86\u56db\u8c61\u9650\u63a7\u5236\u666f\u89c2\uff0c\u9759\u6001\u5ba1\u8ba1\u7b56\u7565\u666e\u904d\u5931\u8d25\uff0c\u8fd9\u8bc1\u660e\u4e86CausalT5K\u5728\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u65b9\u9762\u7684\u4ef7\u503c\u3002\u57fa\u51c6\u5c06Pearl\u7684\u56e0\u679c\u9636\u68af\u4f5c\u4e3a\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u3002", "conclusion": "CausalT5K\u4e3a\u7cfb\u7edf\u8bca\u65adLLM\u56e0\u679c\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u80fd\u591f\u63ed\u793a\u805a\u5408\u51c6\u786e\u7387\u65e0\u6cd5\u53d1\u73b0\u7684\u6545\u969c\u6a21\u5f0f\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u7684\u7814\u7a76\u548c\u53d1\u5c55\u3002"}}
{"id": "2602.07828", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07828", "abs": "https://arxiv.org/abs/2602.07828", "authors": ["Charles Ye", "Jasmine Cui"], "title": "Efficient Representations are Controllable Representations", "comment": null, "summary": "What is the most brute-force way to install interpretable, controllable features into a model's activations? Controlling how LLMs internally represent concepts typically requires sophisticated methods to first identify, then intervene on the model's existing feature geometry. We bypass all of this.\n  We finetune an LLM with a simple auxiliary loss, training 16 of its 3072 residual stream dimensions to be inert interpretability flags that simply indicate what concepts are required for generation. The model reorganizes around them anyway, learning to rely on these flags during actual generation tasks. As a result, these inert flags become genuine internal features: interpretable control switches that allow us to steer generation at inference time. Why does this work? When a feature is reliably supplied at a fixed location, gradient descent gradually eliminates redundant encodings elsewhere, and the model erodes its own alternative representations. A model's efficiency pressure is a lever - exploitable to induce interpretable, controllable representations.", "AI": {"tldr": "\u901a\u8fc7\u7b80\u5355\u7684\u8f85\u52a9\u635f\u5931\u5fae\u8c03LLM\uff0c\u57283072\u7ef4\u6b8b\u5dee\u6d41\u4e2d\u8bad\u7ec316\u4e2a\u60f0\u6027\u53ef\u89e3\u91ca\u6027\u6807\u5fd7\uff0c\u8fd9\u4e9b\u6807\u5fd7\u6210\u4e3a\u53ef\u63a7\u5236\u7684\u5185\u90e8\u7279\u5f81\u5f00\u5173\uff0c\u7528\u4e8e\u63a8\u7406\u65f6\u5f15\u5bfc\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236LLM\u5185\u90e8\u6982\u5ff5\u8868\u793a\u9700\u8981\u590d\u6742\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u5e72\u9884\u6a21\u578b\u7684\u7279\u5f81\u51e0\u4f55\u7ed3\u6784\u3002\u672c\u6587\u65e8\u5728\u7ed5\u8fc7\u8fd9\u4e9b\u590d\u6742\u65b9\u6cd5\uff0c\u5bfb\u627e\u4e00\u79cd\u66f4\u76f4\u63a5\u7684\"\u66b4\u529b\"\u65b9\u5f0f\u6765\u5b89\u88c5\u53ef\u89e3\u91ca\u3001\u53ef\u63a7\u5236\u7684\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u7684\u8f85\u52a9\u635f\u5931\u5fae\u8c03LLM\uff0c\u57283072\u4e2a\u6b8b\u5dee\u6d41\u7ef4\u5ea6\u4e2d\u8bad\u7ec316\u4e2a\u7ef4\u5ea6\u4f5c\u4e3a\u60f0\u6027\u53ef\u89e3\u91ca\u6027\u6807\u5fd7\uff0c\u8fd9\u4e9b\u6807\u5fd7\u6307\u793a\u751f\u6210\u6240\u9700\u7684\u6982\u5ff5\u3002\u6a21\u578b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u5b66\u4f1a\u4f9d\u8d56\u8fd9\u4e9b\u6807\u5fd7\uff0c\u4f7f\u5176\u6210\u4e3a\u771f\u6b63\u7684\u5185\u90e8\u7279\u5f81\u3002", "result": "\u8fd9\u4e9b\u60f0\u6027\u6807\u5fd7\u53d8\u6210\u4e86\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u5f00\u5173\uff0c\u5141\u8bb8\u5728\u63a8\u7406\u65f6\u5f15\u5bfc\u751f\u6210\u3002\u5f53\u7279\u5f81\u5728\u56fa\u5b9a\u4f4d\u7f6e\u53ef\u9760\u63d0\u4f9b\u65f6\uff0c\u68af\u5ea6\u4e0b\u964d\u4f1a\u9010\u6e10\u6d88\u9664\u5176\u4ed6\u5730\u65b9\u7684\u5197\u4f59\u7f16\u7801\uff0c\u6a21\u578b\u4f1a\u4fb5\u8680\u81ea\u5df1\u7684\u66ff\u4ee3\u8868\u793a\u3002", "conclusion": "\u6a21\u578b\u7684\u6548\u7387\u538b\u529b\u662f\u4e00\u4e2a\u53ef\u5229\u7528\u7684\u6760\u6746\uff0c\u53ef\u4ee5\u7528\u6765\u8bf1\u5bfc\u53ef\u89e3\u91ca\u3001\u53ef\u63a7\u5236\u7684\u8868\u793a\u3002\u901a\u8fc7\u53ef\u9760\u5730\u5728\u56fa\u5b9a\u4f4d\u7f6e\u63d0\u4f9b\u7279\u5f81\uff0c\u53ef\u4ee5\u8feb\u4f7f\u6a21\u578b\u91cd\u7ec4\u5e76\u4f9d\u8d56\u8fd9\u4e9b\u4eba\u5de5\u5b89\u88c5\u7684\u7279\u5f81\u3002"}}
{"id": "2602.08948", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08948", "abs": "https://arxiv.org/abs/2602.08948", "authors": ["Chen Jin", "Ryutaro Tanno", "Tom Diethe", "Philip Teare"], "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute", "comment": null, "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.", "AI": {"tldr": "CoRefine \u662f\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u81ea\u7cbe\u70bc\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\u5728\u51bb\u7ed3LLM\u4e0a\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u6d4b\u8bd5\u65f6\u5e76\u884c\u89e3\u7801\uff08\u5982512\u4e2a\u6837\u672c\uff09\u6765\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4f1a\u5e26\u6765\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5728\u51bb\u7ed3LLM\u4e0a\u6dfb\u52a0\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684211k\u53c2\u6570Conv1D\u63a7\u5236\u5668\uff0c\u8be5\u63a7\u5236\u5668\u4f7f\u7528\u5b8c\u6574\u8f68\u8ff9\u7f6e\u4fe1\u5ea6\u6765\u51b3\u5b9a\u662f\u5426\u505c\u6b62\u3001\u91cd\u65b0\u68c0\u67e5\u6216\u5c1d\u8bd5\u4e0d\u540c\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6709\u9488\u5bf9\u6027\u7684\u81ea\u6211\u7ea0\u6b63\u3002", "result": "\u5e73\u5747\u6bcf\u4e2a\u95ee\u9898\u53ea\u97002.7\u4e2a\u7cbe\u70bc\u6b65\u9aa4\uff0c\u76f8\u5bf9\u4e8e512\u6837\u672c\u57fa\u7ebf\u51cf\u5c11\u7ea6190\u500d\u7684token\u4f7f\u7528\u3002\u63a7\u5236\u5668\u5728\u81ea\u4fe1\u505c\u6b62\u65f6\u8fbe\u523092.6%\u7684\u7cbe\u786e\u5ea6\uff0c\u8868\u660e\u7f6e\u4fe1\u5ea6\u52a8\u6001\u53ef\u9760\u5730\u6307\u793a\u6b63\u786e\u6027\u800c\u65e0\u9700\u771f\u5b9e\u9a8c\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u89c6\u4e3a\u63a7\u5236\u4fe1\u53f7\u800c\u975e\u6b63\u786e\u6027\u4fdd\u8bc1\uff0cCoRefine\u4e3a\u53ef\u6269\u5c55\u63a8\u7406\u548c\u4e0d\u5b8c\u7f8e\u9a8c\u8bc1\u5668\u7684\u667a\u80fd\u4f53\u8bbe\u7f6e\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u539f\u8bed\u3002"}}
{"id": "2602.07832", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07832", "abs": "https://arxiv.org/abs/2602.07832", "authors": ["Xian Wu", "Kaijie Zhu", "Ying Zhang", "Lun Wang", "Wenbo Guo"], "title": "rePIRL: Learn PRM with Inverse RL for LLM Reasoning", "comment": null, "summary": "Process rewards have been widely used in deep reinforcement learning to improve training efficiency, reduce variance, and prevent reward hacking. In LLM reasoning, existing works also explore various solutions for learning effective process reward models (PRM) with or without the help of an expert policy. However, existing methods either rely on strong assumptions about the expert policies (e.g., requiring their reward functions) or suffer intrinsic limitations (e.g., entropy collapse), resulting in weak PRMs or limited generalizability. In this paper, we introduce rePIRL, an inverse RL-inspired framework that learns effective PRMs with minimal assumptions about expert policies. Specifically, we design a dual learning process that updates the policy and the PRM interchangeably. Our learning algorithm has customized techniques to address the challenges of scaling traditional inverse RL to LLMs. We theoretically show that our proposed learning framework can unify both online and offline PRM learning methods, justifying that rePIRL can learn PRMs with minimal assumptions. Empirical evaluations on standardized math and coding reasoning datasets demonstrate the effectiveness of rePIRL over existing methods. We further show the application of our trained PRM in test-time training, test-time scaling, and providing an early signal for training hard problems. Finally, we validate our training recipe and key design choices via a detailed ablation study.", "AI": {"tldr": "rePIRL\u662f\u4e00\u4e2a\u53d7\u9006\u5f3a\u5316\u5b66\u4e60\u542f\u53d1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u6709\u6548\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u5bf9\u4e13\u5bb6\u7b56\u7565\u7684\u5047\u8bbe\u8981\u6c42\u6700\u5c0f\uff0c\u901a\u8fc7\u53cc\u5b66\u4e60\u8fc7\u7a0b\u4ea4\u66ff\u66f4\u65b0\u7b56\u7565\u548cPRM\uff0c\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5b66\u4e60\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5bf9\u4e13\u5bb6\u7b56\u7565\u7684\u5f3a\u5047\u8bbe\uff08\u5982\u9700\u8981\u5176\u5956\u52b1\u51fd\u6570\uff09\uff0c\u8981\u4e48\u5b58\u5728\u5185\u5728\u9650\u5236\uff08\u5982\u71b5\u5d29\u6e83\uff09\uff0c\u5bfc\u81f4PRM\u6548\u679c\u5f31\u6216\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51farePIRL\u6846\u67b6\uff0c\u8bbe\u8ba1\u53cc\u5b66\u4e60\u8fc7\u7a0b\u4ea4\u66ff\u66f4\u65b0\u7b56\u7565\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u91c7\u7528\u5b9a\u5236\u5316\u6280\u672f\u89e3\u51b3\u5c06\u4f20\u7edf\u9006\u5f3a\u5316\u5b66\u4e60\u6269\u5c55\u5230LLM\u7684\u6311\u6218\u3002", "result": "\u5728\u6807\u51c6\u5316\u6570\u5b66\u548c\u7f16\u7a0b\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793arePIRL\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bad\u7ec3\u51fa\u7684PRM\u53ef\u7528\u4e8e\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u3001\u6d4b\u8bd5\u65f6\u7f29\u653e\uff0c\u5e76\u4e3a\u8bad\u7ec3\u96be\u9898\u63d0\u4f9b\u65e9\u671f\u4fe1\u53f7\u3002", "conclusion": "rePIRL\u80fd\u591f\u4ee5\u6700\u5c0f\u5047\u8bbe\u5b66\u4e60\u6709\u6548\u7684PRM\uff0c\u7edf\u4e00\u4e86\u5728\u7ebf\u548c\u79bb\u7ebfPRM\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u65b9\u6848\u548c\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u3002"}}
{"id": "2602.08949", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08949", "abs": "https://arxiv.org/abs/2602.08949", "authors": ["Mohammad Morsali", "Siavash H. Khajavi"], "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room", "comment": null, "summary": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.", "AI": {"tldr": "IVSR\u662f\u4e00\u4e2a\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u4e0e\u81ea\u4e3bAI\u4ee3\u7406\u7684\u53cc\u5411\u5e73\u53f0\uff0c\u7528\u4e8e\u5b9e\u65f6\u81ea\u9002\u5e94\u91ce\u706b\u707e\u5bb3\u7ba1\u7406\uff0c\u663e\u8457\u964d\u4f4e\u68c0\u6d4b\u5230\u5e72\u9884\u7684\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u8d44\u6e90\u534f\u8c03\u6548\u7387\u3002", "motivation": "\u8054\u5408\u56fd\u9884\u6d4b\u52302030\u5e74\u548c2050\u5e74\u91ce\u706b\u9891\u7387\u548c\u5f3a\u5ea6\u5c06\u5206\u522b\u589e\u52a014%\u548c30%\uff0c\u800c\u4f20\u7edf\u707e\u5bb3\u7ba1\u7406\u6846\u67b6\u4f9d\u8d56\u9759\u6001\u6a21\u62df\u548c\u88ab\u52a8\u6570\u636e\u91c7\u96c6\uff0c\u65e0\u6cd5\u5b9e\u65f6\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u91ce\u706b\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u667a\u80fd\u865a\u62df\u6001\u52bf\u5ba4\uff08IVSR\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7531\u81ea\u4e3bAI\u4ee3\u7406\u589e\u5f3a\u7684\u53cc\u5411\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\u3002\u7cfb\u7edf\u6301\u7eed\u6444\u5165\u591a\u6e90\u4f20\u611f\u5668\u56fe\u50cf\u3001\u5929\u6c14\u6570\u636e\u548c3D\u68ee\u6797\u6a21\u578b\uff0c\u521b\u5efa\u706b\u707e\u73af\u5883\u7684\u5b9e\u65f6\u865a\u62df\u526f\u672c\u3002AI\u9a71\u52a8\u7684\u76f8\u4f3c\u6027\u5f15\u64ce\u5c06\u65b0\u5174\u6761\u4ef6\u4e0e\u9884\u8ba1\u7b97\u7684\u707e\u5bb3\u6a21\u62df\u5e93\u5bf9\u9f50\uff0c\u5728\u4e13\u5bb6\u76d1\u7763\u4e0b\u68c0\u7d22\u548c\u6821\u51c6\u5e72\u9884\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5de5\u4e1a\u5408\u4f5c\u4f19\u4f34\u63d0\u4f9b\u7684\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u6a21\u62df\u9a8c\u8bc1\uff0cIVSR\u5728\u5c40\u90e8\u4e8b\u4ef6\u68c0\u6d4b\u3001\u9690\u79c1\u4fdd\u62a4\u56de\u653e\u3001\u57fa\u4e8e\u78b0\u649e\u5668\u7684\u706b\u52bf\u8513\u5ef6\u9884\u6d4b\u548c\u7279\u5b9a\u7ad9\u70b9ML\u518d\u8bad\u7ec3\u65b9\u9762\u8868\u73b0\u51fa\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u4f20\u7edf\u7cfb\u7edf\uff0c\u68c0\u6d4b\u5230\u5e72\u9884\u7684\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff0c\u8d44\u6e90\u534f\u8c03\u66f4\u6709\u6548\u3002", "conclusion": "IVSR\u901a\u8fc7\u5c06\u5b9e\u65f6\u53cc\u5411\u6570\u5b57\u5b6a\u751f\u4e0e\u4ee3\u7406AI\u76f8\u7ed3\u5408\uff0c\u4e3a\u4e3b\u52a8\u3001\u81ea\u9002\u5e94\u7684\u91ce\u706b\u707e\u5bb3\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u534a\u81ea\u52a8\u5316\u51b3\u7b56\u652f\u6301\u8303\u5f0f\u3002"}}
{"id": "2602.07834", "categories": ["cs.LG", "math.DG"], "pdf": "https://arxiv.org/pdf/2602.07834", "abs": "https://arxiv.org/abs/2602.07834", "authors": ["D Yang Eng"], "title": "Interpretable Analytic Calabi-Yau Metrics via Symbolic Distillation", "comment": "31 pages, 7 figures", "summary": "Calabi--Yau manifolds are essential for string theory but require computing intractable metrics. Here we show that symbolic regression can distill neural approximations into simple, interpretable formulas. Our five-term expression matches neural accuracy ($R^2 = 0.9994$) with 3,000-fold fewer parameters. Multi-seed validation confirms that geometric constraints select essential features, specifically power sums and symmetric polynomials, while permitting structural diversity. The functional form can be maintained across the studied moduli range ($\u03c8\\in [0, 0.8]$) with coefficients varying smoothly; we interpret these trends as empirical hypotheses within the accuracy regime of the locally-trained teachers ($\u03c3\\approx 8-9\\%$ at $\u03c8\\neq 0$). The formula reproduces physical observables -- volume integrals and Yukawa couplings -- validating that symbolic distillation recovers compact, interpretable models for quantities previously accessible only to black-box networks.", "AI": {"tldr": "\u4f7f\u7528\u7b26\u53f7\u56de\u5f52\u5c06\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7684Calabi-Yau\u6d41\u5f62\u5ea6\u91cf\u63d0\u70bc\u4e3a\u7b80\u5355\u53ef\u89e3\u91ca\u7684\u4e94\u9879\u516c\u5f0f\uff0c\u7cbe\u5ea6\u76f8\u5f53\u4f46\u53c2\u6570\u51cf\u5c113000\u500d", "motivation": "Calabi-Yau\u6d41\u5f62\u5bf9\u5f26\u7406\u8bba\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5ea6\u91cf\u8ba1\u7b97\u6781\u5176\u56f0\u96be\u3002\u867d\u7136\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u8fd1\u4f3c\u8fd9\u4e9b\u5ea6\u91cf\uff0c\u4f46\u5b83\u4eec\u662f\u9ed1\u7bb1\u6a21\u578b\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u9700\u8981\u627e\u5230\u65e2\u7cbe\u786e\u53c8\u7b80\u6d01\u53ef\u89e3\u91ca\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u3002", "method": "\u91c7\u7528\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\uff0c\u4ece\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4e2d\u63d0\u70bc\u51fa\u7b80\u5355\u7684\u6570\u5b66\u516c\u5f0f\u3002\u901a\u8fc7\u591a\u79cd\u5b50\u9a8c\u8bc1\uff0c\u53d1\u73b0\u51e0\u4f55\u7ea6\u675f\u9009\u62e9\u4e86\u7279\u5b9a\u7684\u7279\u5f81\u7c7b\u578b\uff08\u5e42\u548c\u4e0e\u5bf9\u79f0\u591a\u9879\u5f0f\uff09\uff0c\u540c\u65f6\u5141\u8bb8\u7ed3\u6784\u591a\u6837\u6027\u3002\u5728\u6a21\u7a7a\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u51fd\u6570\u5f62\u5f0f\u4e0d\u53d8\uff0c\u4ec5\u8ba9\u7cfb\u6570\u5e73\u6ed1\u53d8\u5316\u3002", "result": "\u6210\u529f\u83b7\u5f97\u4e94\u9879\u8868\u8fbe\u5f0f\uff0c\u4e0e\u795e\u7ecf\u7f51\u7edc\u7cbe\u5ea6\u76f8\u5f53\uff08R\u00b2 = 0.9994\uff09\uff0c\u4f46\u53c2\u6570\u6570\u91cf\u51cf\u5c113000\u500d\u3002\u8be5\u516c\u5f0f\u5728\u7814\u7a76\u7684\u6a21\u8303\u56f4\uff08\u03c8\u2208[0, 0.8]\uff09\u5185\u4fdd\u6301\u76f8\u540c\u51fd\u6570\u5f62\u5f0f\uff0c\u7cfb\u6570\u5e73\u6ed1\u53d8\u5316\u3002\u516c\u5f0f\u80fd\u591f\u51c6\u786e\u8ba1\u7b97\u7269\u7406\u53ef\u89c2\u6d4b\u91cf\uff08\u4f53\u79ef\u79ef\u5206\u548cYukawa\u8026\u5408\uff09\uff0c\u9a8c\u8bc1\u4e86\u7b26\u53f7\u63d0\u70bc\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7b26\u53f7\u56de\u5f52\u80fd\u591f\u4ece\u9ed1\u7bb1\u795e\u7ecf\u7f51\u7edc\u4e2d\u63d0\u70bc\u51fa\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u8ba1\u7b97Calabi-Yau\u6d41\u5f62\u5ea6\u91cf\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u4fdd\u6301\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u7cbe\u5ea6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7269\u7406\u6d1e\u5bdf\uff0c\u4e3a\u5f26\u7406\u8bba\u4e2d\u7684\u590d\u6742\u51e0\u4f55\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002"}}
{"id": "2602.08968", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08968", "abs": "https://arxiv.org/abs/2602.08968", "authors": ["Lucas Maes", "Quentin Le Lidec", "Dan Haramati", "Nassim Massaudi", "Damien Scieur", "Yann LeCun", "Randall Balestriero"], "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation", "comment": null, "summary": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.", "AI": {"tldr": "SWM\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u7ecf\u8fc7\u6d4b\u8bd5\u548c\u6587\u6863\u5316\u7684\u4e16\u754c\u6a21\u578b\u7814\u7a76\u751f\u6001\u7cfb\u7edf\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u3001\u6807\u51c6\u5316\u73af\u5883\u3001\u89c4\u5212\u7b97\u6cd5\u548c\u57fa\u7ebf\u5b9e\u73b0\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u7f3a\u4e4f\u53ef\u91cd\u7528\u6027\u548c\u6807\u51c6\u5316\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u90fd\u662f\u9488\u5bf9\u7279\u5b9a\u8bba\u6587\u7684\uff0c\u7f3a\u4e4f\u53ef\u91cd\u7528\u6027\uff0c\u5b58\u5728bug\u98ce\u9669\uff0c\u4e14\u8bc4\u4f30\u6807\u51c6\u4e0d\u7edf\u4e00\uff0c\u8fd9\u9650\u5236\u4e86\u4e16\u754c\u6a21\u578b\u7814\u7a76\u7684\u8fdb\u5c55\u548c\u6bd4\u8f83\u3002", "method": "\u5f00\u53d1\u4e86stable-worldmodel\uff08SWM\uff09\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u6a21\u5757\u5316\u67b6\u6784\u3001\u9ad8\u6548\u6570\u636e\u6536\u96c6\u5de5\u5177\u3001\u6807\u51c6\u5316\u73af\u5883\u3001\u89c4\u5212\u7b97\u6cd5\u548c\u57fa\u7ebf\u5b9e\u73b0\u3002\u6bcf\u4e2a\u73af\u5883\u90fd\u652f\u6301\u53ef\u63a7\u7684\u53d8\u5316\u56e0\u7d20\uff08\u89c6\u89c9\u548c\u7269\u7406\u5c5e\u6027\uff09\uff0c\u4ee5\u652f\u6301\u9c81\u68d2\u6027\u548c\u6301\u7eed\u5b66\u4e60\u7814\u7a76\u3002", "result": "SWM\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\uff0c\u5e76\u7528\u4e8e\u7814\u7a76DINO-WM\u4e2d\u7684\u96f6\u6837\u672c\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u8be5\u751f\u6001\u7cfb\u7edf\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "SWM\u4e3a\u4e16\u754c\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u3001\u53ef\u91cd\u7528\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3001\u51cf\u5c11bug\u98ce\u9669\u5e76\u63d0\u9ad8\u8bc4\u4f30\u6807\u51c6\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2602.07848", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07848", "abs": "https://arxiv.org/abs/2602.07848", "authors": ["Shijie Wang", "Pengfei Li", "Yikun Fu", "Kaifeng Liu", "Fangyuan Li", "Yang Liu", "Xiaowei Sun", "Zonglin Li", "Siyao Zhao", "Jian Zhao", "Kai Tian", "Dong Li", "Junqi Gao", "Yutong Zhang", "Yiqun Chen", "Yuqiang Li", "Zoe Li", "Weinan Zhang", "Peng Ye", "Shuyue Hu", "Lei Bai", "Bowen Zhou", "Kaiyan Zhang", "Biqing Qi"], "title": "MARTI-MARS$^2$: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation", "comment": null, "summary": "While the complex reasoning capability of Large Language Models (LLMs) has attracted significant attention, single-agent systems often encounter inherent performance ceilings in complex tasks such as code generation. Multi-agent collaboration offers a promising avenue to transcend these boundaries. However, existing frameworks typically rely on prompt-based test-time interactions or multi-role configurations trained with homogeneous parameters, limiting error correction capabilities and strategic diversity. In this paper, we propose a Multi-Agent Reinforced Training and Inference Framework with Self-Search Scaling (MARTI-MARS2), which integrates policy learning with multi-agent tree search by formulating the multi-agent collaborative exploration process as a dynamic and learnable environment. By allowing agents to iteratively explore and refine within the environment, the framework facilitates evolution from parameter-sharing homogeneous multi-role training to heterogeneous multi-agent training, breaking through single-agent capability limits. We also introduce an efficient inference strategy MARTI-MARS2-T+ to fully exploit the scaling potential of multi-agent collaboration at test time. We conduct extensive experiments across varied model scales (8B, 14B, and 32B) on challenging code generation benchmarks. Utilizing two collaborating 32B models, MARTI-MARS2 achieves 77.7%, outperforming strong baselines like GPT-5.1. Furthermore, MARTI-MARS2 reveals a novel scaling law: shifting from single-agent to homogeneous multi-role and ultimately to heterogeneous multi-agent paradigms progressively yields higher RL performance ceilings, robust TTS capabilities, and greater policy diversity, suggesting that policy diversity is critical for scaling intelligence via multi-agent reinforcement learning.", "AI": {"tldr": "MARTI-MARS2\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u8bad\u7ec3\u4e0e\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a2\u7d22\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u52a8\u6001\u53ef\u5b66\u4e60\u73af\u5883\uff0c\u7ed3\u5408\u7b56\u7565\u5b66\u4e60\u548c\u591a\u667a\u80fd\u4f53\u6811\u641c\u7d22\uff0c\u5b9e\u73b0\u4ece\u53c2\u6570\u5171\u4eab\u7684\u540c\u8d28\u591a\u89d2\u8272\u8bad\u7ec3\u5230\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u6f14\u8fdb\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u5355\u667a\u80fd\u4f53\u6027\u80fd\u3002", "motivation": "\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\uff08\u5982\u4ee3\u7801\u751f\u6210\uff09\u4e2d\u5b58\u5728\u56fa\u6709\u7684\u6027\u80fd\u4e0a\u9650\uff0c\u800c\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684\u6d4b\u8bd5\u65f6\u4ea4\u4e92\u6216\u4f7f\u7528\u540c\u8d28\u53c2\u6570\u8bad\u7ec3\u7684\u591a\u89d2\u8272\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "method": "\u63d0\u51faMARTI-MARS2\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a2\u7d22\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u52a8\u6001\u53ef\u5b66\u4e60\u73af\u5883\uff0c\u7ed3\u5408\u7b56\u7565\u5b66\u4e60\u548c\u591a\u667a\u80fd\u4f53\u6811\u641c\u7d22\u3002\u901a\u8fc7\u8fed\u4ee3\u63a2\u7d22\u548c\u7cbe\u70bc\uff0c\u5b9e\u73b0\u4ece\u540c\u8d28\u591a\u89d2\u8272\u8bad\u7ec3\u5230\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u6f14\u8fdb\u3002\u540c\u65f6\u63d0\u51fa\u9ad8\u6548\u7684\u63a8\u7406\u7b56\u7565MARTI-MARS2-T+\uff0c\u5145\u5206\u6316\u6398\u6d4b\u8bd5\u65f6\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6269\u5c55\u6f5c\u529b\u3002", "result": "\u5728\u4e24\u4e2a32B\u6a21\u578b\u534f\u4f5c\u4e0b\uff0cMARTI-MARS2\u5728\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523077.7%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86GPT-5.1\u7b49\u5f3a\u57fa\u7ebf\u3002\u7814\u7a76\u63ed\u793a\u4e86\u65b0\u7684\u6269\u5c55\u89c4\u5f8b\uff1a\u4ece\u5355\u667a\u80fd\u4f53\u5230\u540c\u8d28\u591a\u89d2\u8272\u518d\u5230\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u8303\u5f0f\u9010\u6b65\u63d0\u9ad8RL\u6027\u80fd\u4e0a\u9650\u3001\u589e\u5f3aTTS\u80fd\u529b\u548c\u7b56\u7565\u591a\u6837\u6027\u3002", "conclusion": "MARTI-MARS2\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7a81\u7834\u4e86\u5355\u667a\u80fd\u4f53\u80fd\u529b\u9650\u5236\uff0c\u8bc1\u660e\u4e86\u7b56\u7565\u591a\u6837\u6027\u5bf9\u4e8e\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6269\u5c55\u667a\u80fd\u81f3\u5173\u91cd\u8981\u3002\u8be5\u6846\u67b6\u4e3a\u590d\u6742\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u4f9b\u4e86\u65b0\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8303\u5f0f\u3002"}}
{"id": "2602.08990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08990", "abs": "https://arxiv.org/abs/2602.08990", "authors": ["Shiyang Feng", "Runmin Ma", "Xiangchao Yan", "Yue Fan", "Yusong Hu", "Songtao Huang", "Shuaiyu Zhang", "Zongsheng Cao", "Tianshuo Peng", "Jiakang Yuan", "Zijie Guo", "Zhijie Zhong", "Shangheng Du", "Weida Wang", "Jinxin Shi", "Yuhao Zhou", "Xiaohan He", "Zhiyin Yu", "Fangchen Yu", "Qihao Zheng", "Jiamin Wu", "Mianxin Liu", "Chi Zhang", "Shaowei Hou", "Shuya Li", "Yankai Jiang", "Wenjie Lou", "Lilong Wang", "Zifu Wang", "Jiong Wang", "Wanghan Xu", "Yue Deng", "Dongrui Liu", "Yiheng Wang", "Wenlong Zhang", "Fenghua Ling", "Shufei Zhang", "Xiaosong Wang", "Shuangjia Zheng", "Xun Huang", "Siqi Sun", "Shuyue Hu", "Peng Ye", "Chunfeng Song", "Bin Wang", "Conghui He", "Yihao Liu", "Xin Li", "Qibin Hou", "Tao Chen", "Xiangyu Yue", "Bin Wang", "Liang He", "Dahua Lin", "Bowen Zhou", "Bo Zhang", "Lei Bai"], "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery", "comment": "Code and project page: https://github.com/InternScience/InternAgent", "summary": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.", "AI": {"tldr": "InternAgent-1.5\u662f\u4e00\u4e2a\u7528\u4e8e\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u7684\u7edf\u4e00\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u6f14\u5316\u4e09\u4e2a\u534f\u8c03\u5b50\u7cfb\u7edf\uff0c\u5728\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\u5b9e\u73b0\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u79d1\u5b66\u53d1\u73b0\u901a\u5e38\u9700\u8981\u4eba\u5de5\u5728\u8ba1\u7b97\u5efa\u6a21\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u4e4b\u95f4\u5207\u6362\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u81ea\u4e3b\u7cfb\u7edf\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u534f\u8c03\u8ba1\u7b97\u548c\u5b9e\u9a8c\u3001\u5728\u6269\u5c55\u53d1\u73b0\u5468\u671f\u4e2d\u6301\u7eed\u8fd0\u884c\u5e76\u4fdd\u6301\u884c\u4e3a\u4e00\u81f4\u6027\u7684\u901a\u7528\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u7ed3\u6784\u5316\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u534f\u8c03\u5b50\u7cfb\u7edf\uff1a\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u6f14\u5316\u3002\u8fd9\u4e9b\u5b50\u7cfb\u7edf\u7531\u6df1\u5ea6\u7814\u7a76\u3001\u89e3\u51b3\u65b9\u6848\u4f18\u5316\u548c\u957f\u65f6\u8bb0\u5fc6\u7b49\u57fa\u7840\u80fd\u529b\u652f\u6301\u3002\u7cfb\u7edf\u80fd\u591f\u534f\u8c03\u8ba1\u7b97\u5efa\u6a21\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u5185\u5b9e\u73b0\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u3002", "result": "\u5728GAIA\u3001HLE\u3001GPQA\u548cFrontierScience\u7b49\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002\u5728\u7b97\u6cd5\u53d1\u73b0\u4efb\u52a1\u4e2d\uff0c\u81ea\u4e3b\u8bbe\u8ba1\u51fa\u6838\u5fc3\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u7ade\u4e89\u6027\u65b9\u6cd5\uff1b\u5728\u5b9e\u9a8c\u53d1\u73b0\u4efb\u52a1\u4e2d\uff0c\u6267\u884c\u5b8c\u6574\u7684\u8ba1\u7b97\u6216\u6e7f\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5728\u5730\u7403\u3001\u751f\u547d\u3001\u751f\u7269\u548c\u7269\u7406\u9886\u57df\u4ea7\u751f\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "InternAgent-1.5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\uff0c\u80fd\u591f\u534f\u8c03\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\uff0c\u5728\u6269\u5c55\u53d1\u73b0\u5468\u671f\u4e2d\u6301\u7eed\u8fd0\u884c\u5e76\u4ea7\u751f\u6709\u610f\u4e49\u7684\u79d1\u5b66\u6210\u679c\u3002"}}
{"id": "2602.07859", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07859", "abs": "https://arxiv.org/abs/2602.07859", "authors": ["Siyu Lu", "Chenhan Xiao", "Yang Weng"], "title": "Dynamic Load Model for Data Centers with Pattern-Consistent Calibration", "comment": "10 pages, 13 figures", "summary": "The rapid growth of data centers has made large electronic load (LEL) modeling increasingly important for power system analysis. Such loads are characterized by fast workload-driven variability and protection-driven disconnection and reconnection behavior that are not captured by conventional load models. Existing data center load modeling includes physics-based approaches, which provide interpretable structure for grid simulation, and data-driven approaches, which capture empirical workload variability from data. However, physics-based models are typically uncalibrated to facility-level operation, while trajectory alignment in data-driven methods often leads to overfitting and unrealistic dynamic behavior. To resolve these limitations, we design the framework to leverage both physics-based structure and data-driven adaptability. The physics-based structure is parameterized to enable data-driven pattern-consistent calibration from real operational data, supporting facility-level grid planning. We further show that trajectory-level alignment is limited for inherently stochastic data center loads. Therefore, we design the calibration to align temporal and statistical patterns using temporal contrastive learning (TCL). This calibration is performed locally at the facility, and only calibrated parameters are shared with utilities, preserving data privacy. The proposed load model is calibrated by real-world operational load data from the MIT Supercloud, ASU Sol, Blue Waters, and ASHRAE datasets. Then it is integrated into the ANDES platform and evaluated on the IEEE 39-bus, NPCC 140-bus, and WECC 179-bus systems. We find that interactions among LELs can fundamentally alter post-disturbance recovery behavior, producing compound disconnection-reconnection dynamics and delayed stabilization that are not captured by uncalibrated load models.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u578b\u7535\u5b50\u8d1f\u8f7d\u5efa\u6a21\uff0c\u901a\u8fc7\u65f6\u95f4\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u6a21\u5f0f\u4e00\u81f4\u6821\u51c6\uff0c\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u5e76\u63d0\u5347\u7535\u7f51\u89c4\u5212\u51c6\u786e\u6027\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u5927\u578b\u7535\u5b50\u8d1f\u8f7d\u5efa\u6a21\u5bf9\u7535\u529b\u7cfb\u7edf\u5206\u6790\u65e5\u76ca\u91cd\u8981\u3002\u4f20\u7edf\u8d1f\u8f7d\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u5feb\u901f\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u548c\u4fdd\u62a4\u9a71\u52a8\u7684\u65ad\u5f00/\u91cd\u8fde\u884c\u4e3a\u3002\u73b0\u6709\u7269\u7406\u6a21\u578b\u672a\u6821\u51c6\u5230\u8bbe\u65bd\u7ea7\u8fd0\u884c\uff0c\u800c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5bb9\u6613\u8fc7\u62df\u5408\u4e14\u4ea7\u751f\u4e0d\u73b0\u5b9e\u7684\u52a8\u6001\u884c\u4e3a\u3002", "method": "\u8bbe\u8ba1\u7ed3\u5408\u7269\u7406\u57fa\u7840\u7ed3\u6784\u548c\u6570\u636e\u9a71\u52a8\u9002\u5e94\u6027\u7684\u6846\u67b6\u3002\u7269\u7406\u7ed3\u6784\u53c2\u6570\u5316\u652f\u6301\u4ece\u771f\u5b9e\u8fd0\u884c\u6570\u636e\u8fdb\u884c\u6a21\u5f0f\u4e00\u81f4\u6821\u51c6\u3002\u91c7\u7528\u65f6\u95f4\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u65f6\u95f4\u548c\u7edf\u8ba1\u6a21\u5f0f\uff0c\u800c\u975e\u8f68\u8ff9\u7ea7\u5bf9\u9f50\u3002\u6821\u51c6\u5728\u672c\u5730\u8bbe\u65bd\u8fdb\u884c\uff0c\u4ec5\u5171\u4eab\u6821\u51c6\u53c2\u6570\u4ee5\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "result": "\u4f7f\u7528MIT Supercloud\u3001ASU Sol\u3001Blue Waters\u548cASHRAE\u6570\u636e\u96c6\u8fdb\u884c\u6821\u51c6\uff0c\u96c6\u6210\u5230ANDES\u5e73\u53f0\u5e76\u5728IEEE 39\u603b\u7ebf\u3001NPCC 140\u603b\u7ebf\u548cWECC 179\u603b\u7ebf\u7cfb\u7edf\u8bc4\u4f30\u3002\u53d1\u73b0\u5927\u578b\u7535\u5b50\u8d1f\u8f7d\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u4f1a\u6839\u672c\u6539\u53d8\u6270\u52a8\u540e\u6062\u590d\u884c\u4e3a\uff0c\u4ea7\u751f\u590d\u5408\u65ad\u5f00-\u91cd\u8fde\u52a8\u6001\u548c\u5ef6\u8fdf\u7a33\u5b9a\u73b0\u8c61\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u7269\u7406\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u9a71\u52a8\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u6a21\u5f0f\u4e00\u81f4\u6821\u51c6\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u6821\u51c6\u6a21\u578b\u63ed\u793a\u4e86\u672a\u6821\u51c6\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u7684\u5173\u952e\u52a8\u6001\u884c\u4e3a\uff0c\u4e3a\u8bbe\u65bd\u7ea7\u7535\u7f51\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5de5\u5177\u3002"}}
{"id": "2602.09000", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09000", "abs": "https://arxiv.org/abs/2602.09000", "authors": ["Ali Hatamizadeh", "Shrimai Prabhumoye", "Igor Gitman", "Ximing Lu", "Seungju Han", "Wei Ping", "Yejin Choi", "Jan Kautz"], "title": "iGRPO: Self-Feedback-Driven LLM Reasoning", "comment": "Tech report", "summary": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.", "AI": {"tldr": "iGRPO\u662f\u4e00\u79cd\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u81ea\u751f\u6210\u8349\u7a3f\u548c\u52a8\u6001\u81ea\u6761\u4ef6\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u95ee\u9898\u3002\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982PPO\u548cGRPO\u867d\u7136\u80fd\u63d0\u5347\u6a21\u578b\u8d28\u91cf\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u9700\u8981\u66f4\u6709\u6548\u7684\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u6765\u63d0\u5347\u6570\u5b66\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "iGRPO\u662fGRPO\u7684\u4e24\u9636\u6bb5\u6269\u5c55\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u6837\u591a\u4e2a\u63a2\u7d22\u6027\u8349\u7a3f\uff0c\u9009\u62e9\u6700\u9ad8\u5956\u52b1\u7684\u8349\u7a3f\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u6700\u4f73\u8349\u7a3f\u9644\u52a0\u5230\u539f\u59cb\u63d0\u793a\u540e\uff0c\u5728\u8349\u7a3f\u6761\u4ef6\u5316\u7684\u7ec6\u5316\u4e0a\u5e94\u7528GRPO\u98ce\u683c\u66f4\u65b0\uff0c\u8bad\u7ec3\u7b56\u7565\u8d85\u8d8a\u5176\u5148\u524d\u6700\u4f73\u5c1d\u8bd5\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u52a8\u6001\u81ea\u6761\u4ef6\u673a\u5236\uff0c\u65e0\u9700\u4ef7\u503c\u51fd\u6570\u3002", "result": "\u5728\u5339\u914d\u7684rollout\u9884\u7b97\u4e0b\uff0ciGRPO\u5728\u591a\u4e2a\u57fa\u7840\u6a21\u578b\uff08Nemotron-H-8B-Base-8K\u548cDeepSeek-R1 Distilled\uff09\u4e0a\u6301\u7eed\u4f18\u4e8eGRPO\u3002\u5728OpenReasoning-Nemotron-7B\u6a21\u578b\u4e0a\uff0c\u5728AceReason-Math\u8bad\u7ec3\u540e\uff0c\u5728AIME24\u548cAIME25\u4e0a\u5206\u522b\u8fbe\u523085.62%\u548c79.64%\u7684\u65b0SOTA\u7ed3\u679c\u3002", "conclusion": "iGRPO\u901a\u8fc7\u8fed\u4ee3\u81ea\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u7684\u9a8c\u8bc1\u80fd\u529b\uff0c\u5176\u7ec6\u5316\u5305\u88c5\u5668\u5177\u6709\u8d85\u8d8aGRPO\u53d8\u4f53\u7684\u6cdb\u5316\u6027\uff0c\u53d7\u76ca\u4e8e\u751f\u6210\u5f0f\u8bc4\u5224\u5668\uff0c\u5e76\u901a\u8fc7\u5ef6\u8fdf\u71b5\u5d29\u6e83\u6539\u53d8\u4e86\u5b66\u4e60\u52a8\u6001\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u81ea\u53cd\u9988\u7684\u8fed\u4ee3RL\u5728\u63a8\u8fdb\u53ef\u9a8c\u8bc1\u6570\u5b66\u63a8\u7406\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.07873", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07873", "abs": "https://arxiv.org/abs/2602.07873", "authors": ["Donghyeon Ki", "Hee-Jun Ahn", "Kyungyoon Kim", "Byung-Jun Lee"], "title": "Direct Soft-Policy Sampling via Langevin Dynamics", "comment": null, "summary": "Soft policies in reinforcement learning define policies as Boltzmann distributions over state-action value functions, providing a principled mechanism for balancing exploration and exploitation. However, realizing such soft policies in practice remains challenging. Existing approaches either depend on parametric policies with limited expressivity or employ diffusion-based policies whose intractable likelihoods hinder reliable entropy estimation in soft policy objectives. We address this challenge by directly realizing soft-policy sampling via Langevin dynamics driven by the action gradient of the Q-function. This perspective leads to Langevin Q-Learning (LQL), which samples actions from the target Boltzmann distribution without explicitly parameterizing the policy. However, directly applying Langevin dynamics suffers from slow mixing in high-dimensional and non-convex Q-landscapes, limiting its practical effectiveness. To overcome this, we propose Noise-Conditioned Langevin Q-Learning (NC-LQL), which integrates multi-scale noise perturbations into the value function. NC-LQL learns a noise-conditioned Q-function that induces a sequence of progressively smoothed value landscapes, enabling sampling to transition from global exploration to precise mode refinement. On OpenAI Gym MuJoCo benchmarks, NC-LQL achieves competitive performance compared to state-of-the-art diffusion-based methods, providing a simple yet powerful solution for online RL.", "AI": {"tldr": "\u63d0\u51faNC-LQL\u65b9\u6cd5\uff0c\u901a\u8fc7\u566a\u58f0\u6761\u4ef6\u5316\u7684\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u5b9e\u73b0\u8f6f\u7b56\u7565\u91c7\u6837\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u8868\u8fbe\u6027\u548c\u71b5\u4f30\u8ba1\u65b9\u9762\u7684\u9650\u5236\uff0c\u5728MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u6269\u6563\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002", "motivation": "\u8f6f\u7b56\u7565\u901a\u8fc7\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u9650\u5236\uff1a\u53c2\u6570\u5316\u7b56\u7565\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u6269\u6563\u7b56\u7565\u7684\u4e0d\u53ef\u5904\u7406\u4f3c\u7136\u963b\u788d\u53ef\u9760\u71b5\u4f30\u8ba1\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5b9e\u73b0\u8f6f\u7b56\u7565\u91c7\u6837\u53c8\u4e0d\u4f9d\u8d56\u663e\u5f0f\u7b56\u7565\u53c2\u6570\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u566a\u58f0\u6761\u4ef6\u5316\u6717\u4e4b\u4e07Q\u5b66\u4e60(NC-LQL)\uff1a1) \u4f7f\u7528\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u76f4\u63a5\u91c7\u6837\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u52a8\u4f5c\uff1b2) \u5f15\u5165\u591a\u5c3a\u5ea6\u566a\u58f0\u6270\u52a8\u503c\u51fd\u6570\uff1b3) \u5b66\u4e60\u566a\u58f0\u6761\u4ef6\u5316Q\u51fd\u6570\uff0c\u521b\u5efa\u4ece\u5168\u5c40\u63a2\u7d22\u5230\u7cbe\u786e\u6a21\u5f0f\u7ec6\u5316\u7684\u5e73\u6ed1\u503c\u666f\u89c2\u5e8f\u5217\u3002", "result": "\u5728OpenAI Gym MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNC-LQL\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u6269\u6563\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u5728\u7ebfRL\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "NC-LQL\u901a\u8fc7\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u5b9e\u73b0\u8f6f\u7b56\u7565\u91c7\u6837\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u566a\u58f0\u6270\u52a8\u514b\u670d\u9ad8\u7ef4\u975e\u51f8Q\u666f\u89c2\u4e2d\u7684\u6df7\u5408\u7f13\u6162\u95ee\u9898\uff0c\u4e3a\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u6709\u6548\u4e14\u5b9e\u7528\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.07892", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07892", "abs": "https://arxiv.org/abs/2602.07892", "authors": ["Guanglong Sun", "Siyuan Zhang", "Liyuan Wang", "Jun Zhu", "Hang Su", "Yi Zhong"], "title": "Safety Alignment as Continual Learning: Mitigating the Alignment Tax via Orthogonal Gradient Projection", "comment": null, "summary": "Large Language Models (LLMs) often incur an alignment tax: safety post-training can reduce general utility (e.g., reasoning and coding). We argue that this tax primarily arises from continual-learning-style forgetting in sequential alignment, where distribution shift and conflicting objectives cause safety updates to overwrite pre-trained competencies. Accordingly, we cast safety alignment as a continual learning (CL) problem that must balance plasticity (acquiring safety constraints) and stability (preserving general abilities). We propose Orthogonal Gradient Projection for Safety Alignment (OGPSA), a lightweight method that mitigates interference by constraining each safety update to be orthogonal (in a first-order sense) to a learned subspace capturing general capabilities. Specifically, OGPSA estimates a low-rank capability subspace from gradients on a small reference set and projects the safety gradient onto its orthogonal complement before updating. This produces safety-directed updates that minimally perturb prior knowledge while retaining capacity for alignment. OGPSA is plug-and-play and integrates into standard post-training pipelines without large-scale replay, auxiliary objectives, or retraining. Across Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and sequential SFT$\\rightarrow$DPO settings, OGPSA consistently improves the safety--utility Pareto frontier over standard baselines. For instance, on Qwen2.5-7B-Instruct under SFT$\\rightarrow$DPO, OGPSA preserves strong safety while recovering general capability, improving SimpleQA from 0.53\\% to 3.03\\% and IFEval from 51.94\\% to 63.96\\%. Our source code is available at \\href{https://github.com/SunGL001/OGPSA}{OGPSA}", "AI": {"tldr": "OGPSA\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u68af\u5ea6\u6295\u5f71\u89e3\u51b3LLM\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u80fd\u529b\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u6062\u590d\u901a\u7528\u80fd\u529b\u3002", "motivation": "LLM\u5b89\u5168\u5bf9\u9f50\u5e38\u5bfc\u81f4\"\u5bf9\u9f50\u7a0e\"\u2014\u2014\u5b89\u5168\u8bad\u7ec3\u4f1a\u964d\u4f4e\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\uff08\u5982\u63a8\u7406\u548c\u7f16\u7801\uff09\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e3b\u8981\u6e90\u4e8e\u5e8f\u5217\u5bf9\u9f50\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u5f0f\u9057\u5fd8\uff0c\u5206\u5e03\u504f\u79fb\u548c\u51b2\u7a81\u76ee\u6807\u5bfc\u81f4\u5b89\u5168\u66f4\u65b0\u8986\u76d6\u4e86\u9884\u8bad\u7ec3\u80fd\u529b\u3002", "method": "\u5c06\u5b89\u5168\u5bf9\u9f50\u89c6\u4e3a\u6301\u7eed\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51faOGPSA\u65b9\u6cd5\uff1a\u4ece\u5c11\u91cf\u53c2\u8003\u96c6\u7684\u68af\u5ea6\u4e2d\u4f30\u8ba1\u4f4e\u79e9\u80fd\u529b\u5b50\u7a7a\u95f4\uff0c\u5c06\u5b89\u5168\u68af\u5ea6\u6295\u5f71\u5230\u5176\u6b63\u4ea4\u8865\u7a7a\u95f4\u518d\u8fdb\u884c\u66f4\u65b0\uff0c\u4f7f\u5b89\u5168\u66f4\u65b0\u6700\u5c0f\u5316\u6270\u52a8\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5728SFT\u3001DPO\u548c\u5e8f\u5217SFT\u2192DPO\u8bbe\u7f6e\u4e2d\uff0cOGPSA\u6301\u7eed\u6539\u8fdb\u5b89\u5168-\u6548\u7528\u5e15\u7d2f\u6258\u524d\u6cbf\u3002\u4f8b\u5982\u5728Qwen2.5-7B-Instruct\u4e0a\uff0cSimpleQA\u4ece0.53%\u63d0\u5347\u52303.03%\uff0cIFEval\u4ece51.94%\u63d0\u5347\u523063.96%\u3002", "conclusion": "OGPSA\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u91cd\u653e\u3001\u8f85\u52a9\u76ee\u6807\u6216\u91cd\u65b0\u8bad\u7ec3\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u80fd\u529b\u9057\u5fd8\u95ee\u9898\uff0c\u5e73\u8861\u53ef\u5851\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.09003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09003", "abs": "https://arxiv.org/abs/2602.09003", "authors": ["Yudong Wang", "Zixuan Fu", "Hengyu Zhao", "Chen Zhao", "Chuyue Zhou", "Xinle Lin", "Hongya Lyu", "Shuaikang Xue", "Yi Yi", "Yingjiao Wang", "Zhi Zheng", "Yuzhou Zhang", "Jie Zhou", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management", "comment": "16 pages, 3 figures, 7 tables", "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.", "AI": {"tldr": "\u63d0\u51faL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff0c\u8ba9LLM\u4e3b\u52a8\u6307\u5bfc\u6570\u636e\u7ba1\u7406\uff0c\u5b9e\u73b0\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u6570\u636e\u89c4\u6a21\u7684\u5355\u5411\u6269\u5c55\uff0c\u9762\u4e34\u6570\u636e\u53ef\u7528\u6027\u3001\u83b7\u53d6\u6210\u672c\u548c\u8bad\u7ec3\u6548\u7387\u7684\u74f6\u9888\u3002\u9700\u8981\u65b0\u7684\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u8303\u5f0f\uff0c\u8ba9\u6a21\u578b\u4e3b\u52a8\u6307\u5bfc\u6570\u636e\u7ba1\u7406\uff0c\u9ad8\u8d28\u91cf\u6570\u636e\u53cd\u8fc7\u6765\u589e\u5f3a\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51faL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff1a\u4ece\u539f\u59cb\u672a\u6574\u7406\u8d44\u6e90\u5230\u6709\u7ec4\u7ec7\u53ef\u9a8c\u8bc1\u77e5\u8bc6\u3002\u5229\u7528LLM\u8fdb\u884c\u8d28\u91cf\u8bc4\u5206\u548c\u5185\u5bb9\u7f16\u8f91\u7b49\u6570\u636e\u7ba1\u7406\u8fc7\u7a0b\uff0c\u6bcf\u5c42\u5177\u6709\u4e0d\u540c\u7684\u6570\u636e\u7279\u6027\u3001\u7ba1\u7406\u7b56\u7565\u548c\u8bad\u7ec3\u89d2\u8272\uff0c\u652f\u6301\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u548c\u5bf9\u9f50\u7b49\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u5206\u5c42\u611f\u77e5\u7684\u6570\u636e\u5229\u7528\u80fd\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002\u4f5c\u8005\u5411\u793e\u533a\u53d1\u5e03\u4e86\u5206\u5c42\u6570\u636e\u96c6\u548c\u5904\u7406\u5de5\u5177\u3002", "conclusion": "\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u662fAGI\u53d1\u5c55\u7684\u65b0\u9636\u6bb5\uff0c\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u7684\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u5e73\u8861\u4e86\u6570\u636e\u8d28\u91cf\u3001\u83b7\u53d6\u6210\u672c\u548c\u8fb9\u9645\u8bad\u7ec3\u6548\u76ca\u3002"}}
{"id": "2602.07875", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07875", "abs": "https://arxiv.org/abs/2602.07875", "authors": ["Aditya Shankar", "Yuandou Wang", "Rihan Hai", "Lydia Y. Chen"], "title": "Harpoon: Generalised Manifold Guidance for Conditional Tabular Diffusion", "comment": "Accepted at ICLR 2026", "summary": "Generating tabular data under conditions is critical to applications requiring precise control over the generative process. Existing methods rely on training-time strategies that do not generalise to unseen constraints during inference, and struggle to handle conditional tasks beyond tabular imputation. While manifold theory offers a principled way to guide generation, current formulations are tied to specific inference-time objectives and are limited to continuous domains. We extend manifold theory to tabular data and expand its scope to handle diverse inference-time objectives. On this foundation, we introduce HARPOON, a tabular diffusion method that guides unconstrained samples along the manifold geometry to satisfy diverse tabular conditions at inference. We validate our theoretical contributions empirically on tasks such as imputation and enforcing inequality constraints, demonstrating HARPOON'S strong performance across diverse datasets and the practical benefits of manifold-aware guidance for tabular data. Code URL: https://github.com/adis98/Harpoon", "AI": {"tldr": "HARPOON\u662f\u4e00\u79cd\u8868\u683c\u6269\u6563\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d41\u5f62\u7406\u8bba\u6307\u5bfc\u65e0\u7ea6\u675f\u6837\u672c\u6cbf\u6d41\u5f62\u51e0\u4f55\u6ee1\u8db3\u63a8\u7406\u65f6\u7684\u591a\u6837\u5316\u8868\u683c\u6761\u4ef6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u89c1\u7ea6\u675f\u3001\u4ec5\u9650\u4e8e\u8fde\u7eed\u57df\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u8868\u683c\u6570\u636e\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u8bad\u7ec3\u65f6\u7b56\u7565\u65e0\u6cd5\u6cdb\u5316\u5230\u63a8\u7406\u65f6\u672a\u89c1\u7ea6\u675f\uff1b2) \u53ea\u80fd\u5904\u7406\u8868\u683c\u586b\u8865\u7b49\u6709\u9650\u4efb\u52a1\uff0c\u65e0\u6cd5\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u7ea6\u675f\u6761\u4ef6\u3002\u540c\u65f6\uff0c\u867d\u7136\u6d41\u5f62\u7406\u8bba\u63d0\u4f9b\u4e86\u6307\u5bfc\u751f\u6210\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u516c\u5f0f\u4ec5\u9650\u4e8e\u7279\u5b9a\u63a8\u7406\u76ee\u6807\u4e14\u4ec5\u9002\u7528\u4e8e\u8fde\u7eed\u57df\u3002", "method": "\u5c06\u6d41\u5f62\u7406\u8bba\u6269\u5c55\u5230\u8868\u683c\u6570\u636e\uff0c\u6269\u5927\u5176\u5904\u7406\u591a\u6837\u5316\u63a8\u7406\u76ee\u6807\u7684\u80fd\u529b\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faHARPOON\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8868\u683c\u6269\u6563\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d41\u5f62\u611f\u77e5\u6307\u5bfc\uff0c\u5f15\u5bfc\u65e0\u7ea6\u675f\u6837\u672c\u6cbf\u6d41\u5f62\u51e0\u4f55\u6765\u6ee1\u8db3\u63a8\u7406\u65f6\u7684\u591a\u6837\u5316\u8868\u683c\u6761\u4ef6\u3002", "result": "\u5728\u586b\u8865\u548c\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7b49\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u8d21\u732e\uff0c\u5c55\u793a\u4e86HARPOON\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5f3a\u5927\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6d41\u5f62\u611f\u77e5\u6307\u5bfc\u5bf9\u8868\u683c\u6570\u636e\u7684\u5b9e\u9645\u4f18\u52bf\u3002", "conclusion": "HARPOON\u901a\u8fc7\u6269\u5c55\u6d41\u5f62\u7406\u8bba\u5230\u8868\u683c\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u5bf9\u591a\u6837\u5316\u63a8\u7406\u65f6\u6761\u4ef6\u7684\u5904\u7406\uff0c\u4e3a\u8868\u683c\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u5f3a\u5927\u7684\u63a7\u5236\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u672a\u89c1\u7ea6\u675f\u548c\u590d\u6742\u6761\u4ef6\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.09007", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09007", "abs": "https://arxiv.org/abs/2602.09007", "authors": ["Haodong Li", "Jingwei Wu", "Quan Sun", "Guopeng Li", "Juanxi Tian", "Huanyu Zhang", "Yanlin Lai", "Ruichuan An", "Hongbo Peng", "Yuhong Dai", "Chenxi Li", "Chunmei Qing", "Jia Wang", "Ziyang Meng", "Zheng Ge", "Xiangyu Zhang", "Daxin Jiang"], "title": "GEBench: Benchmarking Image Generation Models as GUI Environments", "comment": "23 pages, 5 figures, 4 tables", "summary": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86GEBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30GUI\u751f\u6210\u4e2d\u7684\u52a8\u6001\u4ea4\u4e92\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u5305\u542b700\u4e2a\u6837\u672c\u548c\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807GE-Score", "motivation": "\u73b0\u6709\u56fe\u50cf\u751f\u6210\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u7528\u6237\u6307\u4ee4\u9884\u6d4b\u672a\u6765GUI\u72b6\u6001\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u9886\u57df\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u7f3a\u4e4f\u5bf9GUI\u7279\u5b9a\u573a\u666f\u4e2d\u72b6\u6001\u8f6c\u6362\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u8bc4\u4f30", "method": "\u5f15\u5165GEBench\u57fa\u51c6\uff0c\u5305\u542b700\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u6837\u672c\uff0c\u6db5\u76d65\u4e2a\u4efb\u52a1\u7c7b\u522b\uff1b\u63d0\u51faGE-Score\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807\uff0c\u8bc4\u4f30\u76ee\u6807\u8fbe\u6210\u3001\u4ea4\u4e92\u903b\u8f91\u3001\u5185\u5bb9\u4e00\u81f4\u6027\u3001UI\u5408\u7406\u6027\u548c\u89c6\u89c9\u8d28\u91cf", "result": "\u5f53\u524d\u6a21\u578b\u5728\u5355\u6b65\u8f6c\u6362\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ef4\u6301\u957f\u65f6\u95f4\u4ea4\u4e92\u5e8f\u5217\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\uff1b\u56fe\u6807\u89e3\u91ca\u3001\u6587\u672c\u6e32\u67d3\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u662f\u5173\u952e\u74f6\u9888", "conclusion": "\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u6784\u5efa\u9ad8\u4fdd\u771f\u751f\u6210\u5f0fGUI\u73af\u5883\u7684\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2602.07884", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07884", "abs": "https://arxiv.org/abs/2602.07884", "authors": ["Mohammad Ashhad", "Robert Hoehndorf", "Ricardo Henao"], "title": "GRAFT: Decoupling Ranking and Calibration for Survival Analysis", "comment": null, "summary": "Survival analysis is complicated by censored data, high-dimensional features, and non-linear interactions. Classical models are interpretable but restrictive, while deep learning models are flexible but often non-interpretable and sensitive to noise. We propose GRAFT (Gated Residual Accelerated Failure Time), a novel AFT model that decouples prognostic ranking from calibration. GRAFT's hybrid architecture combines a linear AFT model with a non-linear residual neural network, and it also integrates stochastic gates for automatic, end-to-end feature selection. The model is trained by directly optimizing a differentiable, C-index-aligned ranking loss using stochastic conditional imputation from local Kaplan-Meier estimators. In public benchmarks, GRAFT outperforms baselines in discrimination and calibration, while remaining robust and sparse in high-noise settings.", "AI": {"tldr": "GRAFT\u662f\u4e00\u79cd\u65b0\u9896\u7684AFT\u751f\u5b58\u5206\u6790\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u8026\u9884\u540e\u6392\u540d\u548c\u6821\u51c6\uff0c\u7ed3\u5408\u7ebf\u6027AFT\u6a21\u578b\u4e0e\u975e\u7ebf\u6027\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u96c6\u6210\u968f\u673a\u95e8\u63a7\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u751f\u5b58\u5206\u6790\u9762\u4e34\u5220\u5931\u6570\u636e\u3001\u9ad8\u7ef4\u7279\u5f81\u548c\u975e\u7ebf\u6027\u4ea4\u4e92\u7684\u6311\u6218\u3002\u7ecf\u5178\u6a21\u578b\u53ef\u89e3\u91ca\u4f46\u9650\u5236\u6027\u5f3a\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7075\u6d3b\u4f46\u901a\u5e38\u4e0d\u53ef\u89e3\u91ca\u4e14\u5bf9\u566a\u58f0\u654f\u611f\u3002\u9700\u8981\u4e00\u79cd\u65e2\u7075\u6d3b\u53c8\u53ef\u89e3\u91ca\u7684\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGRAFT\u6a21\u578b\uff0c\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff1a\u7ebf\u6027AFT\u6a21\u578b\u7ed3\u5408\u975e\u7ebf\u6027\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\uff0c\u96c6\u6210\u968f\u673a\u95e8\u63a7\u8fdb\u884c\u7aef\u5230\u7aef\u7279\u5f81\u9009\u62e9\u3002\u4f7f\u7528\u5c40\u90e8Kaplan-Meier\u4f30\u8ba1\u5668\u7684\u968f\u673a\u6761\u4ef6\u63d2\u8865\uff0c\u76f4\u63a5\u4f18\u5316\u53ef\u5fae\u5206\u7684C\u6307\u6570\u5bf9\u9f50\u6392\u540d\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGRAFT\u5728\u533a\u5206\u5ea6\u548c\u6821\u51c6\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9ad8\u566a\u58f0\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u548c\u7a00\u758f\u6027\u3002", "conclusion": "GRAFT\u901a\u8fc7\u89e3\u8026\u9884\u540e\u6392\u540d\u548c\u6821\u51c6\uff0c\u7ed3\u5408\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u4e14\u53ef\u89e3\u91ca\u7684\u751f\u5b58\u5206\u6790\uff0c\u5728\u9ad8\u566a\u58f0\u9ad8\u7ef4\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.07889", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07889", "abs": "https://arxiv.org/abs/2602.07889", "authors": ["Long Chen", "Yinkui Liu", "Shen Li", "Bo Tang", "Xuemin Hu"], "title": "Efficient Anti-exploration via VQVAE and Fuzzy Clustering in Offline Reinforcement Learning", "comment": null, "summary": "Pseudo-count is an effective anti-exploration method in offline reinforcement learning (RL) by counting state-action pairs and imposing a large penalty on rare or unseen state-action pair data. Existing anti-exploration methods count continuous state-action pairs by discretizing these data, but often suffer from the issues of dimension disaster and information loss in the discretization process, leading to efficiency and performance reduction, and even failure of policy learning. In this paper, a novel anti-exploration method based on Vector Quantized Variational Autoencoder (VQVAE) and fuzzy clustering in offline RL is proposed. We first propose an efficient pseudo-count method based on the multi-codebook VQVAE to discretize state-action pairs, and design an offline RL anti-exploitation method based on the proposed pseudo-count method to handle the dimension disaster issue and improve the learning efficiency. In addition, a codebook update mechanism based on fuzzy C-means (FCM) clustering is developed to improve the use rate of vectors in codebooks, addressing the information loss issue in the discretization process. The proposed method is evaluated on the benchmark of Datasets for Deep Data-Driven Reinforcement Learning (D4RL), and experimental results show that the proposed method performs better and requires less computing cost in multiple complex tasks compared to state-of-the-art (SOTA) methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eVQVAE\u548c\u6a21\u7cca\u805a\u7c7b\u7684\u79bb\u7ebfRL\u53cd\u63a2\u7d22\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u79bb\u6563\u5316\u4e2d\u7684\u7ef4\u5ea6\u707e\u96be\u548c\u4fe1\u606f\u635f\u5931\u95ee\u9898", "motivation": "\u73b0\u6709\u79bb\u7ebfRL\u4e2d\u7684\u53cd\u63a2\u7d22\u65b9\u6cd5\u901a\u8fc7\u79bb\u6563\u5316\u8fde\u7eed\u72b6\u6001-\u52a8\u4f5c\u5bf9\u8fdb\u884c\u8ba1\u6570\uff0c\u4f46\u5b58\u5728\u7ef4\u5ea6\u707e\u96be\u548c\u4fe1\u606f\u635f\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u6548\u7387\u964d\u4f4e\u751a\u81f3\u7b56\u7565\u5b66\u4e60\u5931\u8d25", "method": "1) \u57fa\u4e8e\u591a\u7801\u672cVQVAE\u7684\u9ad8\u6548\u4f2a\u8ba1\u6570\u65b9\u6cd5\uff1b2) \u57fa\u4e8e\u8be5\u4f2a\u8ba1\u6570\u7684\u79bb\u7ebfRL\u53cd\u5229\u7528\u65b9\u6cd5\uff1b3) \u57fa\u4e8e\u6a21\u7ccaC\u5747\u503c\u805a\u7c7b\u7684\u7801\u672c\u66f4\u65b0\u673a\u5236", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8eSOTA\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e", "conclusion": "\u63d0\u51fa\u7684VQVAE+\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u79bb\u6563\u5316\u4e2d\u7684\u7ef4\u5ea6\u707e\u96be\u548c\u4fe1\u606f\u635f\u5931\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u79bb\u7ebfRL\u7684\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd"}}
{"id": "2602.08041", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08041", "abs": "https://arxiv.org/abs/2602.08041", "authors": ["Boyang Xia", "Weiyou Tian", "Qingnan Ren", "Jiaqi Huang", "Jie Xiao", "Shuo Lu", "Kai Wang", "Lynn Ai", "Eric Yang", "Bill Shi"], "title": "Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments", "comment": null, "summary": "Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimization and variation-based regret analyses can become vacuous even when the dynamics are predictable. To solve this problem, we introduce Implicit Strategic Optimization (ISO), a prediction-aware framework in which each agent forecasts the current strategic context and uses it to update its policy online. ISO combines a Strategic Reward Model (SRM) that estimates the long-run strategic value of actions with iso-grpo, a context-conditioned optimistic learning rule. We prove sublinear contextual regret and equilibrium convergence guarantees whose dominant terms scale with the number of context mispredictions; when prediction errors are bounded, our bounds recover the static-game rates obtained when strategic externalities are known. Experiments in 6-player No-Limit Texas Hold'em and competitive Pokemon show consistent improvements in long-term return over strong LLM and RL baselines, and graceful degradation under controlled prediction noise.", "AI": {"tldr": "\u63d0\u51faISO\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u6218\u7565\u73af\u5883\u6765\u4f18\u5316LLM\u667a\u80fd\u4f53\u5728\u957f\u671f\u5bf9\u6297\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u5408\u6218\u7565\u5956\u52b1\u6a21\u578b\u548c\u4e50\u89c2\u5b66\u4e60\u89c4\u5219\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u65f6\u8fbe\u5230\u9759\u6001\u6e38\u620f\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u80dc\u7387\u7684\u77ed\u671f\u4f18\u5316\u65b9\u6cd5\u5728\u957f\u671f\u5bf9\u6297\u6e38\u620f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u6218\u7565\u5916\u90e8\u6027\u968f\u65f6\u95f4\u6f14\u53d8\uff0c\u9700\u8981\u9884\u6d4b\u6218\u7565\u73af\u5883\u6765\u6307\u5bfc\u7b56\u7565\u66f4\u65b0\u3002", "method": "\u63d0\u51fa\u9690\u5f0f\u6218\u7565\u4f18\u5316(ISO)\u6846\u67b6\uff0c\u5305\u542b\u6218\u7565\u5956\u52b1\u6a21\u578b(SRM)\u9884\u6d4b\u884c\u52a8\u7684\u957f\u8fdc\u6218\u7565\u4ef7\u503c\uff0c\u4ee5\u53caiso-grpo\u4e0a\u4e0b\u6587\u6761\u4ef6\u4e50\u89c2\u5b66\u4e60\u89c4\u5219\u8fdb\u884c\u5728\u7ebf\u7b56\u7565\u66f4\u65b0\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5177\u6709\u6b21\u7ebf\u6027\u4e0a\u4e0b\u6587\u9057\u61be\u548c\u5747\u8861\u6536\u655b\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u57286\u4eba\u65e0\u9650\u6ce8\u5fb7\u5dde\u6251\u514b\u548c\u7ade\u4e89\u6027\u5b9d\u53ef\u68a6\u4e2d\u663e\u793a\u957f\u671f\u56de\u62a5\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5e76\u5728\u9884\u6d4b\u566a\u58f0\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "ISO\u6846\u67b6\u901a\u8fc7\u9884\u6d4b\u6218\u7565\u73af\u5883\u6709\u6548\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u5728\u957f\u671f\u5bf9\u6297\u6e38\u620f\u4e2d\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u65f6\u80fd\u8fbe\u5230\u5df2\u77e5\u6218\u7565\u5916\u90e8\u6027\u65f6\u7684\u6027\u80fd\u3002"}}
{"id": "2602.07904", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07904", "abs": "https://arxiv.org/abs/2602.07904", "authors": ["Giang Ngo", "Dat Phan Trong", "Dang Nguyen", "Sunil Gupta", "Svetha Venkatesh"], "title": "Adaptive Acquisition Selection for Bayesian Optimization with Large Language Models", "comment": null, "summary": "Bayesian Optimization critically depends on the choice of acquisition function, but no single strategy is universally optimal; the best choice is non-stationary and problem-dependent. Existing adaptive portfolio methods often base their decisions on past function values while ignoring richer information like remaining budget or surrogate model characteristics. To address this, we introduce LMABO, a novel framework that casts a pre-trained Large Language Model (LLM) as a zero-shot, online strategist for the BO process. At each iteration, LMABO uses a structured state representation to prompt the LLM to select the most suitable acquisition function from a diverse portfolio. In an evaluation across 50 benchmark problems, LMABO demonstrates a significant performance improvement over strong static, adaptive portfolio, and other LLM-based baselines. We show that the LLM's behavior is a comprehensive strategy that adapts to real-time progress, proving its advantage stems from its ability to process and synthesize the complete optimization state into an effective, adaptive policy.", "AI": {"tldr": "LMABO\uff1a\u4f7f\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u96f6\u6837\u672c\u5728\u7ebf\u7b56\u7565\u5e08\uff0c\u4ece\u591a\u6837\u5316\u7ec4\u5408\u4e2d\u9009\u62e9\u6700\u4f18\u91c7\u96c6\u51fd\u6570\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u91c7\u96c6\u51fd\u6570\u7684\u9009\u62e9\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6ca1\u6709\u5355\u4e00\u7b56\u7565\u666e\u904d\u6700\u4f18\uff0c\u6700\u4f73\u9009\u62e9\u662f\u975e\u5e73\u7a33\u4e14\u95ee\u9898\u4f9d\u8d56\u7684\u3002\u73b0\u6709\u81ea\u9002\u5e94\u7ec4\u5408\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u5386\u53f2\u51fd\u6570\u503c\u505a\u51b3\u7b56\uff0c\u5ffd\u7565\u4e86\u5269\u4f59\u9884\u7b97\u6216\u4ee3\u7406\u6a21\u578b\u7279\u5f81\u7b49\u66f4\u4e30\u5bcc\u4fe1\u606f\u3002", "method": "\u5f15\u5165LMABO\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8d1d\u53f6\u65af\u4f18\u5316\u8fc7\u7a0b\u7684\u96f6\u6837\u672c\u5728\u7ebf\u7b56\u7565\u5e08\u3002\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0cLMABO\u4f7f\u7528\u7ed3\u6784\u5316\u72b6\u6001\u8868\u793a\u6765\u63d0\u793aLLM\u4ece\u591a\u6837\u5316\u7ec4\u5408\u4e2d\u9009\u62e9\u6700\u5408\u9002\u7684\u91c7\u96c6\u51fd\u6570\u3002", "result": "\u572850\u4e2a\u57fa\u51c6\u95ee\u9898\u8bc4\u4f30\u4e2d\uff0cLMABO\u76f8\u6bd4\u9759\u6001\u7b56\u7565\u3001\u81ea\u9002\u5e94\u7ec4\u5408\u65b9\u6cd5\u548c\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002LLM\u7684\u884c\u4e3a\u662f\u4e00\u4e2a\u5168\u9762\u7b56\u7565\uff0c\u80fd\u591f\u9002\u5e94\u5b9e\u65f6\u8fdb\u5c55\u3002", "conclusion": "LLM\u7684\u4f18\u52bf\u6e90\u4e8e\u5176\u80fd\u591f\u5904\u7406\u548c\u7efc\u5408\u5b8c\u6574\u7684\u4f18\u5316\u72b6\u6001\uff0c\u5f62\u6210\u6709\u6548\u7684\u81ea\u9002\u5e94\u7b56\u7565\u3002LMABO\u8bc1\u660e\u4e86LLM\u4f5c\u4e3a\u8d1d\u53f6\u65af\u4f18\u5316\u7b56\u7565\u5e08\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.08064", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08064", "abs": "https://arxiv.org/abs/2602.08064", "authors": ["Tianyu Li", "Dongchen Han", "Zixuan Cao", "Haofeng Huang", "Mengyu Zhou", "Ming Chen", "Erchao Zhao", "Xiaoxi Jiang", "Guanjun Jiang", "Gao Huang"], "title": "SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm", "comment": null, "summary": "Modern Transformers predominantly adopt the Pre-Norm paradigm for its optimization stability, foregoing the superior potential of the unstable Post-Norm architecture. Prior attempts to combine their strengths typically lead to a stability-performance trade-off. We attribute this phenomenon to a structural incompatibility within a single-stream design: Any application of the Post-Norm operation inevitably obstructs the clean identity gradient preserved by Pre-Norm. To fundamentally reconcile these paradigms, we propose SiameseNorm, a two-stream architecture that couples Pre-Norm-like and Post-Norm-like streams with shared parameters. This design decouples the optimization dynamics of the two streams, retaining the distinct characteristics of both Pre-Norm and Post-Norm by enabling all residual blocks to receive combined gradients inherited from both paradigms, where one stream secures stability while the other enhances expressivity. Extensive pre-training experiments on 1.3B-parameter models demonstrate that SiameseNorm exhibits exceptional optimization robustness and consistently outperforms strong baselines. Code is available at https://github.com/Qwen-Applications/SiameseNorm.", "AI": {"tldr": "SiameseNorm\u662f\u4e00\u79cd\u53cc\u6d41Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u79bbPre-Norm\u548cPost-Norm\u6d41\u6765\u540c\u65f6\u83b7\u5f97\u4f18\u5316\u7a33\u5b9a\u6027\u548c\u8868\u8fbe\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5355\u6d41\u8bbe\u8ba1\u4e2d\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3Transformer\u4e3b\u8981\u91c7\u7528Pre-Norm\u8303\u5f0f\u4ee5\u83b7\u5f97\u4f18\u5316\u7a33\u5b9a\u6027\uff0c\u4f46\u727a\u7272\u4e86Post-Norm\u67b6\u6784\u7684\u4f18\u8d8a\u6f5c\u529b\u3002\u5148\u524d\u5c1d\u8bd5\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u901a\u5e38\u5bfc\u81f4\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u7684\u6743\u8861\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u7531\u4e8e\u5355\u6d41\u8bbe\u8ba1\u4e2d\u7684\u7ed3\u6784\u4e0d\u517c\u5bb9\u6027\u9020\u6210\u7684\u3002", "method": "\u63d0\u51faSiameseNorm\u53cc\u6d41\u67b6\u6784\uff0c\u8026\u5408\u5177\u6709\u5171\u4eab\u53c2\u6570\u7684Pre-Norm-like\u548cPost-Norm-like\u6d41\u3002\u8fd9\u79cd\u8bbe\u8ba1\u89e3\u8026\u4e86\u4e24\u4e2a\u6d41\u7684\u4f18\u5316\u52a8\u6001\uff0c\u4f7f\u6240\u6709\u6b8b\u5dee\u5757\u90fd\u80fd\u63a5\u6536\u6765\u81ea\u4e24\u79cd\u8303\u5f0f\u7684\u7ec4\u5408\u68af\u5ea6\uff0c\u5176\u4e2d\u4e00\u4e2a\u6d41\u786e\u4fdd\u7a33\u5b9a\u6027\uff0c\u53e6\u4e00\u4e2a\u589e\u5f3a\u8868\u8fbe\u529b\u3002", "result": "\u572813\u4ebf\u53c2\u6570\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5b9e\u9a8c\u8868\u660e\uff0cSiameseNorm\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u4f18\u5316\u9c81\u68d2\u6027\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SiameseNorm\u901a\u8fc7\u53cc\u6d41\u8bbe\u8ba1\u4ece\u6839\u672c\u4e0a\u8c03\u548c\u4e86Pre-Norm\u548cPost-Norm\u8303\u5f0f\uff0c\u5728\u4fdd\u6301\u4f18\u5316\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e3aTransformer\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.07906", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07906", "abs": "https://arxiv.org/abs/2602.07906", "authors": ["Yuzhu Cai", "Zexi Liu", "Xinyu Zhu", "Cheng Wang", "Jiaao Chen", "Hanrui Wang", "Wei-Chen Wang", "Di Jin", "Siheng Chen"], "title": "AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering", "comment": "17 pages, 5 figures", "summary": "Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to frozen parameters. Although Reinforcement Learning (RL) offers a remedy, applying it to MLE is hindered by prohibitive execution latency and inefficient data selection. Recognizing these challenges, we propose AceGRPO with two core components: (1) Evolving Data Buffer that continuously repurposes execution traces into reusable training tasks, and (2) Adaptive Sampling guided by a Learnability Potential function, which dynamically prioritizes tasks at the agent's learning frontier to maximize learning efficiency. Leveraging AceGRPO, our trained Ace-30B model achieves a 100% valid submission rate on MLE-Bench-Lite, approaches the performance of proprietary frontier models, and outperforms larger open-source baselines (e.g., DeepSeek-V3.2), demonstrating robust capability for sustained iterative optimization. Code is available at https://github.com/yuzhu-cai/AceGRPO.", "AI": {"tldr": "\u63d0\u51faAceGRPO\u6846\u67b6\u89e3\u51b3\u81ea\u4e3b\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4e2d\u7684\u884c\u4e3a\u505c\u6ede\u95ee\u9898\uff0c\u901a\u8fc7\u8fdb\u5316\u6570\u636e\u7f13\u51b2\u533a\u548c\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\u63d0\u5347\u5b66\u4e60\u6548\u7387\uff0c\u4f7fAce-30B\u6a21\u578b\u5728MLE-Bench-Lite\u4e0a\u8fbe\u5230100%\u6709\u6548\u63d0\u4ea4\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u81ea\u4e3b\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4ee3\u7406\u5b58\u5728\u884c\u4e3a\u505c\u6ede\u95ee\u9898\uff0c\u56e0\u4e3a\u53c2\u6570\u88ab\u51bb\u7ed3\u3002\u867d\u7136\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5728MLE\u5e94\u7528\u4e2d\u9762\u4e34\u6267\u884c\u5ef6\u8fdf\u9ad8\u548c\u6570\u636e\u9009\u62e9\u6548\u7387\u4f4e\u4e0b\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faAceGRPO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u8fdb\u5316\u6570\u636e\u7f13\u51b2\u533a\uff0c\u5c06\u6267\u884c\u8f68\u8ff9\u91cd\u65b0\u5229\u7528\u4e3a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8bad\u7ec3\u4efb\u52a1\uff1b2\uff09\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u6027\u6f5c\u529b\u51fd\u6570\u52a8\u6001\u4f18\u5148\u5904\u7406\u4ee3\u7406\u5b66\u4e60\u524d\u6cbf\u7684\u4efb\u52a1\uff0c\u6700\u5927\u5316\u5b66\u4e60\u6548\u7387\u3002", "result": "\u4f7f\u7528AceGRPO\u8bad\u7ec3\u7684Ace-30B\u6a21\u578b\u5728MLE-Bench-Lite\u4e0a\u5b9e\u73b0\u4e86100%\u7684\u6709\u6548\u63d0\u4ea4\u7387\uff0c\u63a5\u8fd1\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4f18\u4e8e\u66f4\u5927\u7684\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\uff08\u5982DeepSeek-V3.2\uff09\uff0c\u5c55\u793a\u4e86\u6301\u7eed\u8fed\u4ee3\u4f18\u5316\u7684\u5f3a\u5927\u80fd\u529b\u3002", "conclusion": "AceGRPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u4e3b\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4e2d\u7684\u884c\u4e3a\u505c\u6ede\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u91cd\u7528\u548c\u4efb\u52a1\u9009\u62e9\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u5b66\u4e60\u6548\u7387\uff0c\u4e3a\u6301\u7eed\u8fed\u4ee3\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08128", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08128", "abs": "https://arxiv.org/abs/2602.08128", "authors": ["Zahir Alsulaimawi"], "title": "Online Bayesian Imbalanced Learning with Bregman-Calibrated Deep Networks", "comment": null, "summary": "Class imbalance remains a fundamental challenge in machine learning, where standard classifiers exhibit severe performance degradation in minority classes. Although existing approaches address imbalance through resampling or cost-sensitive learning during training, they require retraining or access to labeled target data when class distributions shift at deployment time, a common occurrence in real-world applications such as fraud detection, medical diagnosis, and anomaly detection. We present \\textit{Online Bayesian Imbalanced Learning} (OBIL), a principled framework that decouples likelihood-ratio estimation from class-prior assumptions, enabling real-time adaptation to distribution shifts without model retraining. Our approach builds on the established connection between Bregman divergences and proper scoring rules to show that deep networks trained with such losses produce posterior probability estimates from which prior-invariant likelihood ratios can be extracted. We prove that these likelihood-ratio estimates remain valid under arbitrary changes in class priors and cost structures, requiring only a threshold adjustment for optimal Bayes decisions. We derive finite-sample regret bounds demonstrating that OBIL achieves $O(\\sqrt{T \\log T})$ regret against an oracle with perfect prior knowledge. Extensive experiments on benchmark datasets and medical diagnosis benchmarks under simulated deployment shifts demonstrate that OBIL maintains robust performance under severe distribution shifts, outperforming state-of-the-art methods in F1 Score when test distributions deviate significantly from the training conditions.", "AI": {"tldr": "OBIL\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u4f3c\u7136\u6bd4\u4f30\u8ba1\u4e0e\u7c7b\u522b\u5148\u9a8c\u5047\u8bbe\uff0c\u5b9e\u73b0\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u7c7b\u522b\u5206\u5e03\u53d8\u5316\u7684\u5728\u7ebf\u4e0d\u5e73\u8861\u5b66\u4e60\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u7c7b\u522b\u5206\u5e03\u7ecf\u5e38\u5728\u90e8\u7f72\u65f6\u53d1\u751f\u53d8\u5316\uff08\u5982\u6b3a\u8bc8\u68c0\u6d4b\u3001\u533b\u7597\u8bca\u65ad\uff09\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6216\u8bbf\u95ee\u6807\u8bb0\u6570\u636e\uff0c\u65e0\u6cd5\u5b9e\u65f6\u9002\u5e94\u5206\u5e03\u53d8\u5316\u3002", "method": "\u57fa\u4e8eBregman\u6563\u5ea6\u4e0e\u9002\u5f53\u8bc4\u5206\u89c4\u5219\u7684\u8054\u7cfb\uff0c\u4ece\u6df1\u5ea6\u7f51\u7edc\u7684\u540e\u9a8c\u6982\u7387\u4f30\u8ba1\u4e2d\u63d0\u53d6\u5148\u9a8c\u4e0d\u53d8\u7684\u4f3c\u7136\u6bd4\uff0c\u4ec5\u9700\u8c03\u6574\u9608\u503c\u5373\u53ef\u9002\u5e94\u4efb\u610f\u7c7b\u522b\u5148\u9a8c\u548c\u4ee3\u4ef7\u7ed3\u6784\u53d8\u5316\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4f3c\u7136\u6bd4\u4f30\u8ba1\u5728\u4efb\u610f\u7c7b\u522b\u5148\u9a8c\u53d8\u5316\u4e0b\u4fdd\u6301\u6709\u6548\uff0c\u83b7\u5f97O(\u221a(T log T))\u7684\u6709\u9650\u6837\u672c\u9057\u61be\u754c\uff1b\u5b9e\u9a8c\u8868\u660e\u5728\u4e25\u91cd\u5206\u5e03\u504f\u79fb\u4e0bOBIL\u5728F1\u5206\u6570\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "OBIL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5b9e\u65f6\u9002\u5e94\u7c7b\u522b\u5206\u5e03\u53d8\u5316\u7684\u539f\u7406\u6027\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u5e03\u53d8\u5316\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2602.07928", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07928", "abs": "https://arxiv.org/abs/2602.07928", "authors": ["Ziyun Li", "Huancheng Hu", "Soon Hoe Lim", "Xuyu Li", "Fei Gao", "Enmao Diao", "Zezhen Ding", "Michalis Vazirgiannis", "Henrik Bostrom"], "title": "A Kinetic-Energy Perspective of Flow Matching", "comment": null, "summary": "Flow-based generative models can be viewed through a physics lens: sampling transports a particle from noise to data by integrating a time-varying velocity field, and each sample corresponds to a trajectory with its own dynamical effort. Motivated by classical mechanics, we introduce Kinetic Path Energy (KPE), an action-like, per-sample diagnostic that measures the accumulated kinetic effort along an Ordinary Differential Equation (ODE) trajectory. Empirically, KPE exhibits two robust correspondences: (i) higher KPE predicts stronger semantic fidelity; (ii) high-KPE trajectories terminate on low-density manifold frontiers. We further provide theoretical guarantees linking trajectory energy to data density. Paradoxically, this correlation is non-monotonic. At sufficiently high energy, generation can degenerate into memorization. Leveraging the closed-form of empirical flow matching, we show that extreme energies drive trajectories toward near-copies of training examples. This yields a Goldilocks principle and motivates Kinetic Trajectory Shaping (KTS), a training-free two-phase inference strategy that boosts early motion and enforces a late-time soft landing, reducing memorization and improving generation quality across benchmark tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faKinetic Path Energy (KPE)\u4f5c\u4e3a\u8bc4\u4f30\u751f\u6210\u8f68\u8ff9\u7684\u52a8\u529b\u5b66\u52aa\u529b\u6307\u6807\uff0c\u53d1\u73b0KPE\u4e0e\u8bed\u4e49\u4fdd\u771f\u5ea6\u76f8\u5173\uff0c\u4f46\u8fc7\u9ad8\u4f1a\u5bfc\u81f4\u8bb0\u5fc6\u5316\uff0c\u8fdb\u800c\u63d0\u51faKinetic Trajectory Shaping (KTS)\u4e24\u9636\u6bb5\u63a8\u7406\u7b56\u7565\u6765\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u4ece\u7269\u7406\u5b66\u89c6\u89d2\u7406\u89e3\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\uff0c\u5c06\u91c7\u6837\u8fc7\u7a0b\u89c6\u4e3a\u7c92\u5b50\u4ece\u566a\u58f0\u5230\u6570\u636e\u7684\u8f68\u8ff9\u6f14\u5316\u3002\u53d7\u7ecf\u5178\u529b\u5b66\u542f\u53d1\uff0c\u9700\u8981\u91cf\u5316\u6bcf\u4e2a\u8f68\u8ff9\u7684\u52a8\u529b\u5b66\u52aa\u529b\uff0c\u4ee5\u7406\u89e3\u751f\u6210\u8d28\u91cf\u4e0e\u8f68\u8ff9\u80fd\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u89e3\u51b3\u9ad8\u80fd\u91cf\u5bfc\u81f4\u8bb0\u5fc6\u5316\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165Kinetic Path Energy (KPE)\u4f5c\u4e3a\u7c7b\u4f3c\u4f5c\u7528\u91cf\u7684\u8bca\u65ad\u6307\u6807\uff0c\u6d4b\u91cfODE\u8f68\u8ff9\u7684\u7d2f\u79ef\u52a8\u529b\u5b66\u52aa\u529b\u3002\u57fa\u4e8e\u7ecf\u9a8c\u6d41\u5339\u914d\u7684\u95ed\u5f0f\u89e3\u5206\u6790\u8f68\u8ff9\u80fd\u91cf\u4e0e\u6570\u636e\u5bc6\u5ea6\u7684\u7406\u8bba\u5173\u7cfb\u3002\u63d0\u51faKinetic Trajectory Shaping (KTS)\u8bad\u7ec3\u81ea\u7531\u7684\u4e24\u9636\u6bb5\u63a8\u7406\u7b56\u7565\uff1a\u65e9\u671f\u589e\u5f3a\u8fd0\u52a8\uff0c\u540e\u671f\u8f6f\u7740\u9646\u3002", "result": "KPE\u4e0e\u8bed\u4e49\u4fdd\u771f\u5ea6\u6b63\u76f8\u5173\uff0c\u9ad8KPE\u8f68\u8ff9\u7ec8\u6b62\u4e8e\u4f4e\u5bc6\u5ea6\u6d41\u5f62\u8fb9\u754c\u3002\u7406\u8bba\u8bc1\u660e\u8f68\u8ff9\u80fd\u91cf\u4e0e\u6570\u636e\u5bc6\u5ea6\u76f8\u5173\u4f46\u975e\u5355\u8c03\uff0c\u8fc7\u9ad8\u80fd\u91cf\u4f1a\u5bfc\u81f4\u8bb0\u5fc6\u5316\u8bad\u7ec3\u6837\u672c\u3002KTS\u7b56\u7565\u6709\u6548\u51cf\u5c11\u8bb0\u5fc6\u5316\uff0c\u5728\u57fa\u51c6\u4efb\u52a1\u4e0a\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "\u8f68\u8ff9\u52a8\u529b\u5b66\u80fd\u91cf\u662f\u7406\u89e3\u751f\u6210\u6a21\u578b\u7684\u5173\u952e\u8bca\u65ad\u5de5\u5177\uff0c\u5b58\u5728\"\u6070\u5230\u597d\u5904\"\u539f\u5219\uff1a\u9002\u4e2d\u7684\u80fd\u91cf\u4f18\u5316\u751f\u6210\u8d28\u91cf\uff0c\u8fc7\u9ad8\u5bfc\u81f4\u8bb0\u5fc6\u5316\u3002KTS\u7b56\u7565\u901a\u8fc7\u8c03\u63a7\u8f68\u8ff9\u52a8\u529b\u5b66\u5b9e\u73b0\u66f4\u597d\u7684\u751f\u6210\u6548\u679c\uff0c\u4e3a\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2602.08159", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08159", "abs": "https://arxiv.org/abs/2602.08159", "authors": ["Seonglae Cho", "Zekun Wu", "Kleyton Da Costa", "Adriano Koshiyama"], "title": "The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models", "comment": null, "summary": "When a language model asserts that \"the capital of Australia is Sydney,\" does it know this is wrong? We characterize the geometry of correctness representations across 9 models from 5 architecture families. The structure is simple: the discriminative signal occupies 3-8 dimensions, performance degrades with additional dimensions, and no nonlinear classifier improves over linear separation. Centroid distance in the low-dimensional subspace matches trained probe performance (0.90 AUC), enabling few-shot detection: on GPT-2, 25 labeled examples achieve 89% of full-data accuracy. We validate causally through activation steering: the learned direction produces 10.9 percentage point changes in error rates while random directions show no effect. Internal probes achieve 0.80-0.97 AUC; output-based methods (P(True), semantic entropy) achieve only 0.44-0.64 AUC. The correctness signal exists internally but is not expressed in outputs. That centroid distance matches probe performance indicates class separation is a mean shift, making detection geometric rather than learned.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5b58\u5728\u7b80\u5355\u7684\u51e0\u4f55\u7ed3\u6784\u6765\u8868\u793a\u6b63\u786e\u6027\uff0c\u8be5\u4fe1\u53f7\u5360\u636e3-8\u4e2a\u7ef4\u5ea6\uff0c\u7ebf\u6027\u5206\u7c7b\u5668\u8db3\u4ee5\u5206\u79bb\uff0c\u4e14\u8d28\u5fc3\u8ddd\u79bb\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u6a21\u578b\u662f\u5426\u77e5\u9053\u7b54\u6848\u9519\u8bef\u3002", "motivation": "\u5f53\u8bed\u8a00\u6a21\u578b\u58f0\u79f0\"\u6fb3\u5927\u5229\u4e9a\u9996\u90fd\u662f\u6089\u5c3c\"\u65f6\uff0c\u5b83\u662f\u5426\u77e5\u9053\u81ea\u5df1\u9519\u4e86\uff1f\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u6a21\u578b\u5185\u90e8\u662f\u5426\u5b58\u5728\u5173\u4e8e\u6b63\u786e\u6027\u7684\u8868\u793a\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8868\u793a\u7684\u7ed3\u6784\u7279\u5f81\u3002", "method": "\u5206\u6790\u4e869\u4e2a\u4e0d\u540c\u67b6\u6784\u7684\u6a21\u578b\uff0c\u7814\u7a76\u6b63\u786e\u6027\u8868\u793a\u7684\u51e0\u4f55\u7ed3\u6784\u3002\u4f7f\u7528\u7ebf\u6027\u5206\u7c7b\u5668\u3001\u8d28\u5fc3\u8ddd\u79bb\u65b9\u6cd5\u3001\u6fc0\u6d3b\u5f15\u5bfc\u7b49\u6280\u672f\uff0c\u6bd4\u8f83\u5185\u90e8\u63a2\u6d4b\u548c\u57fa\u4e8e\u8f93\u51fa\u7684\u65b9\u6cd5\uff08\u5982P(True)\u3001\u8bed\u4e49\u71b5\uff09\u3002", "result": "\u6b63\u786e\u6027\u4fe1\u53f7\u4ec5\u5360\u636e3-8\u4e2a\u7ef4\u5ea6\uff1b\u7ebf\u6027\u5206\u79bb\u6548\u679c\u6700\u4f73\uff1b\u8d28\u5fc3\u8ddd\u79bb\u65b9\u6cd5\u8fbe\u52300.90 AUC\uff1b\u5c11\u91cf\u6807\u6ce8\u6570\u636e\uff0825\u4e2a\u793a\u4f8b\uff09\u80fd\u8fbe\u5230\u5168\u6570\u636e89%\u7684\u51c6\u786e\u7387\uff1b\u6fc0\u6d3b\u5f15\u5bfc\u80fd\u663e\u8457\u6539\u53d8\u9519\u8bef\u7387\uff1b\u5185\u90e8\u63a2\u6d4b\uff080.80-0.97 AUC\uff09\u8fdc\u4f18\u4e8e\u57fa\u4e8e\u8f93\u51fa\u7684\u65b9\u6cd5\uff080.44-0.64 AUC\uff09\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5b58\u5728\u5173\u4e8e\u6b63\u786e\u6027\u7684\u660e\u786e\u4fe1\u53f7\uff0c\u4f46\u8be5\u4fe1\u53f7\u672a\u5728\u8f93\u51fa\u4e2d\u8868\u8fbe\u3002\u6b63\u786e\u6027\u5206\u79bb\u672c\u8d28\u4e0a\u662f\u5747\u503c\u504f\u79fb\u7684\u51e0\u4f55\u95ee\u9898\uff0c\u800c\u975e\u9700\u8981\u5b66\u4e60\u7684\u590d\u6742\u6a21\u5f0f\uff0c\u8fd9\u4f7f\u5f97\u68c0\u6d4b\u53d8\u5f97\u7b80\u5355\u6709\u6548\u3002"}}
{"id": "2602.07933", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07933", "abs": "https://arxiv.org/abs/2602.07933", "authors": ["Olamide Samuel Oseni", "Ibraheem Omotolani Obanla", "Toheeb Aduramomi Jimoh"], "title": "Attention-Based Deep Learning for Early Parkinson's Disease Detection with Tabular Biomedical Data", "comment": null, "summary": "Early and accurate detection of Parkinson's disease (PD) remains a critical challenge in medical diagnostics due to the subtlety of early-stage symptoms and the complex, non-linear relationships inherent in biomedical data. Traditional machine learning (ML) models, though widely applied to PD detection, often rely on extensive feature engineering and struggle to capture complex feature interactions. This study investigates the effectiveness of attention-based deep learning models for early PD detection using tabular biomedical data. We present a comparative evaluation of four classification models: Multi-Layer Perceptron (MLP), Gradient Boosting, TabNet, and SAINT, using a benchmark dataset from the UCI Machine Learning Repository consisting of biomedical voice measurements from PD patients and healthy controls.\n  Experimental results show that SAINT consistently outperformed all baseline models across multiple evaluation metrics, achieving a weighted precision of 0.98, weighted recall of 0.97, weighted F1-score of 0.97, a Matthews Correlation Coefficient (MCC) of 0.9990, and the highest Area Under the ROC Curve (AUC-ROC). TabNet and MLP demonstrated competitive performance, while Gradient Boosting yielded the lowest overall scores. The superior performance of SAINT is attributed to its dual attention mechanism, which effectively models feature interactions within and across samples.\n  These findings demonstrate the diagnostic potential of attention-based deep learning architectures for early Parkinson's disease detection and highlight the importance of dynamic feature representation in clinical prediction tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u56db\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684SAINT\u6a21\u578b\u5728\u5404\u9879\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u68c0\u6d4b\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u7279\u5f81\u5de5\u7a0b\u4e14\u96be\u4ee5\u6355\u6349\u590d\u6742\u7279\u5f81\u4ea4\u4e92\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528UCI\u673a\u5668\u5b66\u4e60\u5e93\u7684\u5e15\u91d1\u68ee\u75c5\u8bed\u97f3\u6d4b\u91cf\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86\u56db\u79cd\u5206\u7c7b\u6a21\u578b\uff1aMLP\u3001\u68af\u5ea6\u63d0\u5347\u3001TabNet\u548cSAINT\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6027\u80fd\u6307\u6807\u3002", "result": "SAINT\u5728\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u52a0\u6743\u7cbe\u5ea60.98\uff0c\u52a0\u6743\u53ec\u56de\u73870.97\uff0c\u52a0\u6743F1\u5206\u65700.97\uff0cMCC 0.9990\uff0cAUC-ROC\u6700\u9ad8\u3002TabNet\u548cMLP\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u68af\u5ea6\u63d0\u5347\u8868\u73b0\u6700\u5dee\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728\u5e15\u91d1\u68ee\u75c5\u65e9\u671f\u68c0\u6d4b\u4e2d\u5177\u6709\u8bca\u65ad\u6f5c\u529b\uff0c\u52a8\u6001\u7279\u5f81\u8868\u793a\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u5f88\u91cd\u8981\u3002"}}
{"id": "2602.08169", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08169", "abs": "https://arxiv.org/abs/2602.08169", "authors": ["Zejia You", "Chunyuan Deng", "Hanjie Chen"], "title": "Spherical Steering: Geometry-Aware Activation Rotation for Language Models", "comment": "The code is at: https://github.com/chili-lab/Spherical-Steering", "summary": "Inference-time steering has emerged as a promising paradigm for controlling language models (LMs) without the cost of retraining. However, standard approaches typically rely on activation addition, a geometric operation that inevitably alters the magnitude of hidden representations. This raises concerns about representation collapse and degradation of open-ended generation capabilities. In this work, we explore Spherical Steering, a training-free primitive that resolves this trade-off through activation rotation. Rather than shifting activations with a fixed vector, our method rotates them along a geodesic toward a target direction, guiding the activation toward the target concept while preserving the integrity of the signal. To further enhance adaptivity, we incorporate a confidence gate that dynamically modulates steering strength based on input uncertainty. Extensive experiments across multiple-choice benchmarks demonstrate that Spherical Steering significantly outperforms addition-based baselines (notably by +10% on TruthfulQA, COPA, and Storycloze), while simultaneously maintaining the model's general open-ended generation quality. This work highlights the value of geometric consistency, suggesting that norm-preserving rotation is a robust and effective primitive for precise inference-time control.", "AI": {"tldr": "\u63d0\u51faSpherical Steering\u65b9\u6cd5\uff0c\u901a\u8fc7\u6fc0\u6d3b\u65cb\u8f6c\u800c\u975e\u52a0\u6cd5\u5b9e\u73b0\u63a8\u7406\u65f6\u63a7\u5236\uff0c\u4fdd\u6301\u8868\u793a\u8303\u6570\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u5f00\u653e\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u63a7\u5236\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u6fc0\u6d3b\u52a0\u6cd5\uff0c\u8fd9\u4f1a\u6539\u53d8\u9690\u85cf\u8868\u793a\u7684\u5e45\u5ea6\uff0c\u53ef\u80fd\u5bfc\u81f4\u8868\u793a\u5d29\u6e83\u548c\u5f00\u653e\u751f\u6210\u80fd\u529b\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63a7\u5236\u6a21\u578b\u53c8\u4e0d\u7834\u574f\u8868\u793a\u5b8c\u6574\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSpherical Steering\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u6fc0\u6d3b\u65cb\u8f6c\u800c\u975e\u52a0\u6cd5\uff0c\u6cbf\u6d4b\u5730\u7ebf\u5411\u76ee\u6807\u65b9\u5411\u65cb\u8f6c\u6fc0\u6d3b\uff0c\u4fdd\u6301\u4fe1\u53f7\u5b8c\u6574\u6027\uff1b2) \u5f15\u5165\u7f6e\u4fe1\u95e8\u63a7\uff0c\u57fa\u4e8e\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u8282\u63a7\u5236\u5f3a\u5ea6\u3002", "result": "\u5728\u591a\u9879\u9009\u62e9\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u52a0\u6cd5\u7684\u57fa\u7ebf\u65b9\u6cd5\uff08\u5728TruthfulQA\u3001COPA\u548cStorycloze\u4e0a\u63d0\u5347+10%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u901a\u7528\u5f00\u653e\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "\u4fdd\u6301\u51e0\u4f55\u4e00\u81f4\u6027\u7684\u65cb\u8f6c\u64cd\u4f5c\u662f\u7cbe\u786e\u63a8\u7406\u65f6\u63a7\u5236\u7684\u9c81\u68d2\u6709\u6548\u539f\u8bed\uff0c\u89e3\u51b3\u4e86\u6fc0\u6d3b\u52a0\u6cd5\u5e26\u6765\u7684\u8868\u793a\u5d29\u6e83\u4e0e\u751f\u6210\u8d28\u91cf\u4e0b\u964d\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2602.07950", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07950", "abs": "https://arxiv.org/abs/2602.07950", "authors": ["Daisuke Okanohara"], "title": "A Thermodynamic Theory of Learning Part II: Critical Period Closure and Continual Learning Failure", "comment": "Part II of a series entitled \"A Thermodynamic Theory of Learning.\"", "summary": "Learning performed over finite time is necessarily irreversible. In Part~I of this series, we modeled learning as a transport process in the space of parameter distributions and derived the Epistemic Speed Limit, which lower-bounds entropy production under finite-time learning.\n  In this work (Part~II), we study the consequences of this irreversibility for continual learning from a trajectory-level perspective. We show that finite dissipation constrains not only which solutions are reachable, but which learning paths remain dynamically accessible.\n  Although a continuum of task-equivalent realizations can achieve identical task performance, finite-time learning irreversibly selects among these realizations. This selection occurs through the progressive elimination of degrees of freedom that would otherwise enable structural reconfiguration. We refer to this phenomenon as \\emph{critical period closure}: beyond a certain stage of learning, transitions between compatible representations become dynamically inaccessible under any finite dissipation budget.\n  As a result, continual learning failure arises not from the absence of solutions satisfying multiple tasks, but from an irreversible loss of representational freedom induced by prior learning. This reframes catastrophic forgetting as a dynamical constraint imposed by finite-time dissipation, rather than direct task interference.", "AI": {"tldr": "\u6709\u9650\u65f6\u95f4\u5b66\u4e60\u5fc5\u7136\u4e0d\u53ef\u9006\uff0c\u5bfc\u81f4\u4e34\u754c\u671f\u95ed\u5408\u73b0\u8c61\uff0c\u4f7f\u517c\u5bb9\u8868\u793a\u95f4\u7684\u8f6c\u6362\u53d8\u5f97\u52a8\u6001\u4e0d\u53ef\u8fbe\uff0c\u4ece\u800c\u5f15\u53d1\u6301\u7eed\u5b66\u4e60\u5931\u8d25", "motivation": "\u7814\u7a76\u6709\u9650\u65f6\u95f4\u5b66\u4e60\u4e2d\u7684\u4e0d\u53ef\u9006\u6027\u5982\u4f55\u5f71\u54cd\u6301\u7eed\u5b66\u4e60\uff0c\u7279\u522b\u662f\u4ece\u8f68\u8ff9\u5c42\u9762\u7406\u89e3\u5b66\u4e60\u8def\u5f84\u7684\u52a8\u6001\u53ef\u8fbe\u6027\u7ea6\u675f", "method": "\u5c06\u5b66\u4e60\u5efa\u6a21\u4e3a\u53c2\u6570\u5206\u5e03\u7a7a\u95f4\u4e2d\u7684\u4f20\u8f93\u8fc7\u7a0b\uff0c\u4ece\u8f68\u8ff9\u5c42\u9762\u5206\u6790\u6709\u9650\u8017\u6563\u5bf9\u5b66\u4e60\u8def\u5f84\u52a8\u6001\u53ef\u8fbe\u6027\u7684\u7ea6\u675f", "result": "\u53d1\u73b0\u6709\u9650\u65f6\u95f4\u5b66\u4e60\u901a\u8fc7\u9010\u6b65\u6d88\u9664\u81ea\u7531\u5ea6\u5bfc\u81f4\u4e34\u754c\u671f\u95ed\u5408\u73b0\u8c61\uff0c\u4f7f\u517c\u5bb9\u8868\u793a\u95f4\u7684\u8f6c\u6362\u53d8\u5f97\u52a8\u6001\u4e0d\u53ef\u8fbe\uff0c\u4ece\u800c\u5f15\u53d1\u6301\u7eed\u5b66\u4e60\u5931\u8d25", "conclusion": "\u6301\u7eed\u5b66\u4e60\u5931\u8d25\u4e0d\u662f\u7531\u4e8e\u7f3a\u4e4f\u6ee1\u8db3\u591a\u4efb\u52a1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u662f\u7531\u5148\u524d\u5b66\u4e60\u5f15\u8d77\u7684\u8868\u793a\u81ea\u7531\u5ea6\u7684\u4e0d\u53ef\u9006\u635f\u5931\u6240\u81f4\uff0c\u5e94\u5c06\u707e\u96be\u6027\u9057\u5fd8\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6709\u9650\u65f6\u95f4\u8017\u6563\u65bd\u52a0\u7684\u52a8\u6001\u7ea6\u675f"}}
{"id": "2602.08194", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08194", "abs": "https://arxiv.org/abs/2602.08194", "authors": ["Konstantinos Mitsides", "Maxence Faldor", "Antoine Cully"], "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds", "comment": "11 pages (main text), 90 pages total. Project page: https://konstantinosmitsides.github.io/dreaming-in-code", "summary": "Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for agents to discover sequences of experiences that remain consistently learnable. To address this, we propose Dreaming in Code (DiCode), a framework in which foundation models synthesize executable environment code to scaffold learning toward increasing competence. In DiCode, \"dreaming\" takes the form of materializing code-level variations of the world. We instantiate DiCode in Craftax, a challenging open-ended benchmark characterized by rich mechanics and long-horizon progression. Empirically, DiCode enables agents to acquire long-horizon skills, achieving a $16\\%$ improvement in mean return over the strongest baseline and non-zero success on late-game combat tasks where prior methods fail. Our results suggest that code-level environment design provides a practical mechanism for curriculum control, enabling the construction of intermediate environments that bridge competence gaps in open-ended worlds. Project page and source code are available at https://konstantinosmitsides.github.io/dreaming-in-code and https://github.com/konstantinosmitsides/dreaming-in-code.", "AI": {"tldr": "Dreaming in Code (DiCode) \u4f7f\u7528\u57fa\u7840\u6a21\u578b\u751f\u6210\u53ef\u6267\u884c\u73af\u5883\u4ee3\u7801\u6765\u6784\u5efa\u5b66\u4e60\u8def\u5f84\uff0c\u5728\u5f00\u653e\u4e16\u754c\u6e38\u620f\u4e2d\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u957f\u671f\u6280\u80fd\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u5f00\u653e\u4e16\u754c\u5b66\u4e60\u9762\u4e34\u5de8\u5927\u7ec4\u5408\u7a7a\u95f4\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u53d1\u73b0\u6301\u7eed\u53ef\u5b66\u4e60\u7ecf\u9a8c\u5e8f\u5217\u3002\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u6784\u5efa\u4e2d\u95f4\u73af\u5883\uff0c\u5f25\u5408\u80fd\u529b\u5dee\u8ddd\u3002", "method": "DiCode\u6846\u67b6\u8ba9\u57fa\u7840\u6a21\u578b\u5408\u6210\u53ef\u6267\u884c\u73af\u5883\u4ee3\u7801\uff0c\u901a\u8fc7\u4ee3\u7801\u7ea7\u4e16\u754c\u53d8\u4f53\u6765\"\u505a\u68a6\"\uff0c\u5728Craftax\u57fa\u51c6\u4e0a\u5b9e\u4f8b\u5316\uff0c\u4e3a\u667a\u80fd\u4f53\u6784\u5efa\u5b66\u4e60\u8def\u5f84\u3002", "result": "\u5728Craftax\u57fa\u51c6\u4e0a\uff0cDiCode\u4f7f\u667a\u80fd\u4f53\u83b7\u5f97\u957f\u671f\u6280\u80fd\uff0c\u5e73\u5747\u56de\u62a5\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u534716%\uff0c\u5728\u540e\u671f\u6218\u6597\u4efb\u52a1\u4e0a\u5b9e\u73b0\u975e\u96f6\u6210\u529f\u7387\uff08\u5148\u524d\u65b9\u6cd5\u5b8c\u5168\u5931\u8d25\uff09\u3002", "conclusion": "\u4ee3\u7801\u7ea7\u73af\u5883\u8bbe\u8ba1\u4e3a\u8bfe\u7a0b\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u673a\u5236\uff0c\u80fd\u591f\u6784\u5efa\u4e2d\u95f4\u73af\u5883\u6765\u5f25\u5408\u5f00\u653e\u4e16\u754c\u4e2d\u7684\u80fd\u529b\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u6301\u7eed\u5b66\u4e60\u8fdb\u5c55\u3002"}}
{"id": "2602.07966", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07966", "abs": "https://arxiv.org/abs/2602.07966", "authors": ["Pablo Hidalgo", "Daniel Rodriguez"], "title": "An Explainable Multi-Task Similarity Measure: Integrating Accumulated Local Effects and Weighted Fr\u00e9chet Distance", "comment": null, "summary": "In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intelligence (XAI) techniques, specifically Accumulated Local Effects (ALE) curves.\n  ALE curves are compared using the Fr\u00e9chet distance, weighted by the data distribution, and the resulting similarity measure incorporates the importance of each feature. The measure is applicable in both single-task learning scenarios, where each task is trained separately, and multi-task learning scenarios, where all tasks are learned simultaneously. The measure is model-agnostic, allowing the use of different machine learning models across tasks. A scaling factor is introduced to account for differences in predictive performance across tasks, and several recommendations are provided for applying the measure in complex scenarios.\n  We validate this measure using four datasets, one synthetic dataset and three real-world datasets. The real-world datasets include a well-known Parkinson's dataset and a bike-sharing usage dataset -- both structured in tabular format -- as well as the CelebA dataset, which is used to evaluate the application of concept bottleneck encoders in a multitask learning setting. The results demonstrate that the measure aligns with intuitive expectations of task similarity across both tabular and non-tabular data, making it a valuable tool for exploring relationships between tasks and supporting informed decision-making.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u89e3\u91caAI\u6280\u672f\uff08ALE\u66f2\u7ebf\uff09\u7684\u591a\u4efb\u52a1\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7Fr\u00e9chet\u8ddd\u79bb\u52a0\u6743\u6570\u636e\u5206\u5e03\u6bd4\u8f83\u4efb\u52a1\uff0c\u6a21\u578b\u65e0\u5173\u4e14\u9002\u7528\u4e8e\u5355\u4efb\u52a1\u548c\u591a\u4efb\u52a1\u573a\u666f\u3002", "motivation": "\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\uff0c\u9700\u8981\u7406\u89e3\u4efb\u52a1\u95f4\u7684\u76f8\u4f3c\u6027\u5173\u7cfb\u4ee5\u4fc3\u8fdb\u77e5\u8bc6\u8fc1\u79fb\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u4efb\u52a1\u76f8\u4f3c\u6027\u7684\u7cfb\u7edf\u5ea6\u91cf\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91caAI\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e2e\u52a9\u8bc6\u522b\u54ea\u4e9b\u4efb\u52a1\u76f8\u4f3c\u4ee5\u53ca\u4e3a\u4f55\u76f8\u4f3c\u3002", "method": "\u4f7f\u7528\u7d2f\u79ef\u5c40\u90e8\u6548\u5e94\uff08ALE\uff09\u66f2\u7ebf\u4f5c\u4e3a\u4efb\u52a1\u7279\u5f81\u91cd\u8981\u6027\u7684\u8868\u793a\uff0c\u901a\u8fc7\u52a0\u6743\u6570\u636e\u5206\u5e03\u7684Fr\u00e9chet\u8ddd\u79bb\u6bd4\u8f83ALE\u66f2\u7ebf\uff0c\u5f15\u5165\u7f29\u653e\u56e0\u5b50\u5904\u7406\u4e0d\u540c\u4efb\u52a1\u7684\u9884\u6d4b\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u6846\u67b6\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff08Parkinson\u3001\u81ea\u884c\u8f66\u5171\u4eab\u3001CelebA\uff09\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u5ea6\u91cf\u65b9\u6cd5\u7b26\u5408\u5bf9\u4efb\u52a1\u76f8\u4f3c\u6027\u7684\u76f4\u89c2\u9884\u671f\uff0c\u9002\u7528\u4e8e\u8868\u683c\u548c\u975e\u8868\u683c\u6570\u636e\uff0c\u80fd\u6709\u6548\u63a2\u7d22\u4efb\u52a1\u95f4\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eXAI\u7684\u591a\u4efb\u52a1\u76f8\u4f3c\u6027\u5ea6\u91cf\u662f\u6709\u6548\u7684\u5de5\u5177\uff0c\u80fd\u591f\u652f\u6301\u4efb\u52a1\u5173\u7cfb\u5206\u6790\u548c\u77e5\u60c5\u51b3\u7b56\u5236\u5b9a\uff0c\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u9009\u62e9\u548c\u7ec4\u7ec7\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2602.08213", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.08213", "abs": "https://arxiv.org/abs/2602.08213", "authors": ["Haoran Liu", "Zheni Zeng", "Yukun Yan", "Yuxuan Chen", "Yunduo Xiao"], "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning", "comment": null, "summary": "Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled data. To bridge this gap, we propose DrugR, an LLM-based method that introduces explicit, step-by-step pharmacological reasoning into the optimization process. Our approach integrates domain-specific continual pretraining, supervised fine-tuning via reverse data engineering, and self-balanced multi-granular reinforcement learning. This framework enables DrugR to effectively improve key ADMET properties while preserving the original molecule's core efficacy. Experimental results demonstrate that DrugR achieves comprehensive enhancement across multiple properties without compromising structural similarity or target binding affinity. Importantly, its explicit reasoning process provides clear, interpretable rationales for each optimization step, yielding actionable design insights and advancing toward automated, knowledge-driven scientific discovery. Our code and model checkpoints are open-sourced to foster future research.", "AI": {"tldr": "DrugR\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u836f\u7269\u5206\u5b50\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u663e\u5f0f\u7684\u836f\u7406\u5b66\u63a8\u7406\u6b65\u9aa4\uff0c\u7ed3\u5408\u9886\u57df\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u81ea\u5e73\u8861\u591a\u7c92\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u4fdd\u6301\u6838\u5fc3\u7597\u6548\u7684\u540c\u65f6\u63d0\u5347ADMET\u6027\u8d28\u3002", "motivation": "\u5206\u5b50\u751f\u6210\u4e0e\u4f18\u5316\u662f\u5316\u5b66\u9886\u57df\u7684\u57fa\u7840\u4efb\u52a1\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u51ed\u501f\u5f3a\u5927\u7684\u77e5\u8bc6\u50a8\u5907\u548c\u4ea4\u4e92\u80fd\u529b\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u4f46\u5176\u5185\u5728\u6311\u6218\u5728\u4e8e\u5206\u5b50\u7ed3\u6784\u4e0e\u836f\u7406\u6027\u8d28\u4e4b\u95f4\u7684\u590d\u6742\u9690\u5f0f\u5173\u7cfb\u4ee5\u53ca\u76f8\u5e94\u6807\u6ce8\u6570\u636e\u7684\u7f3a\u4e4f\u3002", "method": "DrugR\u65b9\u6cd5\u5f15\u5165\u663e\u5f0f\u7684\u3001\u9010\u6b65\u7684\u836f\u7406\u5b66\u63a8\u7406\u5230\u4f18\u5316\u8fc7\u7a0b\u4e2d\u3002\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\uff1a1\uff09\u9886\u57df\u7279\u5b9a\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff1b2\uff09\u901a\u8fc7\u53cd\u5411\u6570\u636e\u5de5\u7a0b\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff1b3\uff09\u81ea\u5e73\u8861\u591a\u7c92\u5ea6\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDrugR\u80fd\u591f\u5728\u591a\u4e2a\u6027\u8d28\u4e0a\u5b9e\u73b0\u5168\u9762\u589e\u5f3a\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u7ed3\u6784\u76f8\u4f3c\u6027\u6216\u9776\u6807\u7ed3\u5408\u4eb2\u548c\u529b\u3002\u5176\u663e\u5f0f\u63a8\u7406\u8fc7\u7a0b\u4e3a\u6bcf\u4e2a\u4f18\u5316\u6b65\u9aa4\u63d0\u4f9b\u4e86\u6e05\u6670\u3001\u53ef\u89e3\u91ca\u7684\u4f9d\u636e\uff0c\u4ea7\u751f\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u89c1\u89e3\u3002", "conclusion": "DrugR\u63a8\u8fdb\u4e86\u81ea\u52a8\u5316\u3001\u77e5\u8bc6\u9a71\u52a8\u7684\u79d1\u5b66\u53d1\u73b0\u3002\u8be5\u65b9\u6cd5\u4ee3\u7801\u548c\u6a21\u578b\u68c0\u67e5\u70b9\u5df2\u5f00\u6e90\uff0c\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2602.07973", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07973", "abs": "https://arxiv.org/abs/2602.07973", "authors": ["Aaditya Naik", "Efthymia Tsamoura", "Shibo Jin", "Mayur Naik", "Dan Roth"], "title": "On Improving Neurosymbolic Learning by Exploiting the Representation Space", "comment": null, "summary": "We study the problem of learning neural classifiers in a neurosymbolic setting where the hidden gold labels of input instances must satisfy a logical formula. Learning in this setting proceeds by first computing (a subset of) the possible combinations of labels that satisfy the formula and then computing a loss using those combinations and the classifiers' scores. One challenge is that the space of label combinations can grow exponentially, making learning difficult. We propose a technique that prunes this space by exploiting the intuition that instances with similar latent representations are likely to share the same label. While this intuition has been widely used in weakly supervised learning, its application in our setting is challenging due to label dependencies imposed by logical constraints. We formulate the pruning process as an integer linear program that discards inconsistent label combinations while respecting logical structure. Our approach, CLIPPER, is orthogonal to existing training algorithms and can be seamlessly integrated with them. Across 16 benchmarks over complex neurosymbolic tasks, we demonstrate that CLIPPER boosts the performance of state-of-the-art neurosymbolic engines like Scallop, Dolphin, and ISED by up to 48%, 53%, and 8%, leading to state-of-the-art accuracies.", "AI": {"tldr": "CLIPPER\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u4e2d\u7684\u526a\u679d\u6280\u672f\uff0c\u901a\u8fc7\u6574\u6570\u7ebf\u6027\u89c4\u5212\u51cf\u5c11\u6ee1\u8db3\u903b\u8f91\u7ea6\u675f\u7684\u6807\u7b7e\u7ec4\u5408\u7a7a\u95f4\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u5728\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u4e2d\uff0c\u8f93\u5165\u5b9e\u4f8b\u7684\u9690\u85cf\u9ec4\u91d1\u6807\u7b7e\u5fc5\u987b\u6ee1\u8db3\u903b\u8f91\u516c\u5f0f\uff0c\u800c\u6ee1\u8db3\u516c\u5f0f\u7684\u53ef\u80fd\u6807\u7b7e\u7ec4\u5408\u7a7a\u95f4\u53ef\u80fd\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5bfc\u81f4\u5b66\u4e60\u56f0\u96be\u3002", "method": "\u5229\u7528\u76f8\u4f3c\u6f5c\u5728\u8868\u793a\u5b9e\u4f8b\u53ef\u80fd\u5171\u4eab\u76f8\u540c\u6807\u7b7e\u7684\u76f4\u89c9\uff0c\u5c06\u526a\u679d\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u5728\u5c0a\u91cd\u903b\u8f91\u7ed3\u6784\u7684\u540c\u65f6\u4e22\u5f03\u4e0d\u4e00\u81f4\u7684\u6807\u7b7e\u7ec4\u5408\u3002", "result": "\u572816\u4e2a\u590d\u6742\u795e\u7ecf\u7b26\u53f7\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCLIPPER\u5c06Scallop\u3001Dolphin\u548cISED\u7b49\u6700\u5148\u8fdb\u795e\u7ecf\u7b26\u53f7\u5f15\u64ce\u7684\u6027\u80fd\u5206\u522b\u63d0\u5347\u9ad8\u8fbe48%\u300153%\u548c8%\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\u3002", "conclusion": "CLIPPER\u662f\u4e00\u79cd\u6b63\u4ea4\u4e8e\u73b0\u6709\u8bad\u7ec3\u7b97\u6cd5\u7684\u526a\u679d\u65b9\u6cd5\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u7cfb\u7edf\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u6807\u7b7e\u7ec4\u5408\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\u3002"}}
{"id": "2602.08343", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08343", "abs": "https://arxiv.org/abs/2602.08343", "authors": ["Debajyoti Datta", "Trishala Neeraj", "Bibek Paudel", "Vyom Sharma", "Subhabrata Mukherjee"], "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection", "comment": "18 pages, 5 figures, 18 tables", "summary": "Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks tokens by Euclidean distance to the key centroid, capturing both angular and radial deviations.\n  On the RULER benchmark, ManifoldKV achieves 95.7% accuracy at 4K-16K contexts with 20% compression; matching the best geometric baseline while improving robustness in two regimes where cosine scoring fails. First, on multi-key retrieval, ManifoldKV reduces directional collisions, achieving 92.4% vs KeyDiff's 77.0% (+15.4 points) on 3-key NIAH at 50% compression. Second, to address dilution and performance collapse of global centroids at 64K context, we introduce WindowedManifoldKV, which restores accuracy to 84.3% at 25% compression, a 49-point recovery over global L2 and +3.2 points over KeyDiff. The method requires only 3 lines of code and works across 4 architectures without tuning.", "AI": {"tldr": "ManifoldKV\uff1a\u57fa\u4e8e\u6b27\u6c0f\u8ddd\u79bb\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u8003\u8651\u89d2\u5ea6\u548c\u5f84\u5411\u504f\u5dee\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u6bd4\u4f59\u5f26\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u66f4\u9c81\u68d2", "motivation": "\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u53d7\u9650\u4e8eKV\u7f13\u5b58\u5185\u5b58\u7ebf\u6027\u589e\u957f\uff0c\u73b0\u6709\u51e0\u4f55\u9a71\u9010\u65b9\u6cd5\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff08\u5c3a\u5ea6\u4e0d\u53d8\uff09\u4f1a\u4e22\u5931\u533a\u5206\u8bed\u4e49\u91cd\u8981token\u7684\u5e45\u5ea6\u4fe1\u606f", "method": "\u63d0\u51faManifoldKV\u8bad\u7ec3\u81ea\u7531\u8bc4\u5206\u5668\uff0c\u57fa\u4e8e\u6b27\u6c0f\u8ddd\u79bb\u5230\u5173\u952e\u8d28\u5fc3\u5bf9token\u6392\u5e8f\uff0c\u6355\u83b7\u89d2\u5ea6\u548c\u5f84\u5411\u504f\u5dee\uff1b\u9488\u5bf964K\u4e0a\u4e0b\u6587\u5f15\u5165WindowedManifoldKV\u89e3\u51b3\u5168\u5c40\u8d28\u5fc3\u7a00\u91ca\u95ee\u9898", "result": "RULER\u57fa\u51c6\u6d4b\u8bd5\uff1a4K-16K\u4e0a\u4e0b\u658720%\u538b\u7f29\u8fbe\u523095.7%\u51c6\u786e\u7387\uff1b\u591a\u952e\u68c0\u7d2292.4% vs KeyDiff 77.0%\uff1b64K\u4e0a\u4e0b\u658725%\u538b\u7f29WindowedManifoldKV\u6062\u590d\u51c6\u786e\u7387\u81f384.3%\uff0c\u6bd4\u5168\u5c40L2\u9ad849\u70b9", "conclusion": "ManifoldKV\u901a\u8fc7\u6b27\u6c0f\u8ddd\u79bb\u8bc4\u5206\u5728KV\u7f13\u5b58\u538b\u7f29\u4e2d\u6bd4\u4f59\u5f26\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u66f4\u9c81\u68d2\uff0c\u4ec5\u97003\u884c\u4ee3\u7801\uff0c\u65e0\u9700\u8c03\u53c2\u5373\u53ef\u8de84\u79cd\u67b6\u6784\u5de5\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898"}}
{"id": "2602.07974", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07974", "abs": "https://arxiv.org/abs/2602.07974", "authors": ["Xin Li"], "title": "Beyond Optimization: Intelligence as Metric-Topology Factorization under Geometric Incompleteness", "comment": null, "summary": "Contemporary ML often equates intelligence with optimization: searching for solutions within a fixed representational geometry. This works in static regimes but breaks under distributional shift, task permutation, and continual learning, where even mild topological changes can invalidate learned solutions and trigger catastrophic forgetting. We propose Metric-Topology Factorization (MTF) as a unifying geometric principle: intelligence is not navigation through a fixed maze, but the ability to reshape representational geometry so desired behaviors become stable attractors. Learning corresponds to metric contraction (a controlled deformation of Riemannian structure), while task identity and environmental variation are encoded topologically and stored separately in memory. We show any fixed metric is geometrically incomplete: for any local metric representation, some topological transformations make it singular or incoherent, implying an unavoidable stability-plasticity tradeoff for weight-based systems. MTF resolves this by factorizing stable topology from plastic metric warps, enabling rapid adaptation via geometric switching rather than re-optimization. Building on this, we introduce the Topological Urysohn Machine (TUM), implementing MTF through memory-amortized metric inference (MAMI): spectral task signatures index amortized metric transformations, letting a single learned geometry be reused across permuted, reflected, or parity-altered environments. This explains robustness to task reordering, resistance to catastrophic forgetting, and generalization across transformations that defeat conventional continual learning methods (e.g., EWC).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5ea6\u91cf-\u62d3\u6251\u5206\u89e3\uff08MTF\uff09\u4f5c\u4e3a\u7edf\u4e00\u51e0\u4f55\u539f\u7406\uff1a\u667a\u80fd\u4e0d\u662f\u56fa\u5b9a\u51e0\u4f55\u4e2d\u7684\u5bfc\u822a\uff0c\u800c\u662f\u91cd\u5851\u8868\u793a\u51e0\u4f55\u4f7f\u671f\u671b\u884c\u4e3a\u6210\u4e3a\u7a33\u5b9a\u5438\u5f15\u5b50\u7684\u80fd\u529b\u3002\u5b66\u4e60\u5bf9\u5e94\u5ea6\u91cf\u6536\u7f29\uff0c\u4efb\u52a1\u8eab\u4efd\u548c\u73af\u5883\u53d8\u5316\u7f16\u7801\u4e3a\u62d3\u6251\u7ed3\u6784\u5355\u72ec\u5b58\u50a8\u3002\u57fa\u4e8e\u6b64\u5f15\u5165\u62d3\u6251Urysohn\u673a\uff08TUM\uff09\uff0c\u901a\u8fc7\u8bb0\u5fc6\u644a\u9500\u5ea6\u91cf\u63a8\u65ad\u5b9e\u73b0MTF\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u53d8\u6362\u7684\u9c81\u68d2\u6027\u548c\u6297\u707e\u96be\u6027\u9057\u5fd8\u3002", "motivation": "\u4f20\u7edfML\u5c06\u667a\u80fd\u7b49\u540c\u4e8e\u4f18\u5316\uff1a\u5728\u56fa\u5b9a\u8868\u793a\u51e0\u4f55\u4e2d\u641c\u7d22\u89e3\u3002\u8fd9\u5728\u9759\u6001\u73af\u5883\u4e0b\u6709\u6548\uff0c\u4f46\u5728\u5206\u5e03\u504f\u79fb\u3001\u4efb\u52a1\u7f6e\u6362\u548c\u6301\u7eed\u5b66\u4e60\u7b49\u52a8\u6001\u573a\u666f\u4e2d\u5931\u6548\uff0c\u8f7b\u5fae\u62d3\u6251\u53d8\u5316\u5c31\u4f1a\u4f7f\u5b66\u4e60\u89e3\u5931\u6548\u5e76\u5f15\u53d1\u707e\u96be\u6027\u9057\u5fd8\u3002\u9700\u8981\u65b0\u7684\u51e0\u4f55\u539f\u7406\u6765\u5904\u7406\u8868\u793a\u51e0\u4f55\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u5ea6\u91cf-\u62d3\u6251\u5206\u89e3\uff08MTF\uff09\uff1a\u5c06\u7a33\u5b9a\u62d3\u6251\u4e0e\u53ef\u5851\u5ea6\u91cf\u53d8\u5f62\u5206\u79bb\u3002\u5b66\u4e60\u5bf9\u5e94\u5ea6\u91cf\u6536\u7f29\uff08\u9ece\u66fc\u7ed3\u6784\u7684\u53d7\u63a7\u53d8\u5f62\uff09\uff0c\u4efb\u52a1\u8eab\u4efd\u548c\u73af\u5883\u53d8\u5316\u7f16\u7801\u4e3a\u62d3\u6251\u7ed3\u6784\u5355\u72ec\u5b58\u50a8\u3002\u5f15\u5165\u62d3\u6251Urysohn\u673a\uff08TUM\uff09\uff0c\u901a\u8fc7\u8bb0\u5fc6\u644a\u9500\u5ea6\u91cf\u63a8\u65ad\uff08MAMI\uff09\u5b9e\u73b0MTF\uff1a\u8c31\u4efb\u52a1\u7b7e\u540d\u7d22\u5f15\u644a\u9500\u7684\u5ea6\u91cf\u53d8\u6362\uff0c\u8ba9\u5355\u4e00\u5b66\u4e60\u51e0\u4f55\u53ef\u8de8\u7f6e\u6362\u3001\u53cd\u5c04\u6216\u5947\u5076\u6027\u6539\u53d8\u7684\u73af\u5883\u91cd\u7528\u3002", "result": "MTF\u89e3\u51b3\u4e86\u56fa\u5b9a\u5ea6\u91cf\u7684\u51e0\u4f55\u4e0d\u5b8c\u6574\u6027\uff1a\u4efb\u4f55\u5c40\u90e8\u5ea6\u91cf\u8868\u793a\u5728\u67d0\u4e9b\u62d3\u6251\u53d8\u6362\u4e0b\u90fd\u4f1a\u53d8\u5f97\u5947\u5f02\u6216\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u6743\u91cd\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u3002MTF\u901a\u8fc7\u5206\u89e3\u7a33\u5b9a\u62d3\u6251\u548c\u53ef\u5851\u5ea6\u91cf\u53d8\u5f62\uff0c\u5b9e\u73b0\u901a\u8fc7\u51e0\u4f55\u5207\u6362\u800c\u975e\u91cd\u65b0\u4f18\u5316\u7684\u5feb\u901f\u9002\u5e94\u3002TUM\u5728\u4efb\u52a1\u91cd\u6392\u3001\u6297\u707e\u96be\u6027\u9057\u5fd8\u548c\u8de8\u53d8\u6362\u6cdb\u5316\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff08\u5982EWC\uff09\u3002", "conclusion": "\u667a\u80fd\u672c\u8d28\u4e0a\u662f\u51e0\u4f55\u91cd\u6784\u80fd\u529b\u800c\u975e\u56fa\u5b9a\u7a7a\u95f4\u4e2d\u7684\u4f18\u5316\u3002MTF\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u5904\u7406\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b66\u4e60\uff0c\u5c06\u7a33\u5b9a\u62d3\u6251\u4e0e\u53ef\u5851\u5ea6\u91cf\u5206\u79bb\uff0c\u4f7f\u7cfb\u7edf\u80fd\u5feb\u901f\u9002\u5e94\u5206\u5e03\u53d8\u5316\u800c\u65e0\u9700\u91cd\u65b0\u4f18\u5316\u3002\u8fd9\u4e3a\u6301\u7eed\u5b66\u4e60\u3001\u4efb\u52a1\u6cdb\u5316\u548c\u6297\u707e\u96be\u6027\u9057\u5fd8\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u73b0\u8def\u5f84\u3002"}}
{"id": "2602.08377", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08377", "abs": "https://arxiv.org/abs/2602.08377", "authors": ["Bilgehan Sel", "Vaishakh Keshava", "Phillip Wallis", "Lukas Rutishauser", "Ming Jin", "Dingcheng Li"], "title": "Reinforcement Learning with Backtracking Feedback", "comment": "NeurIPS 2025", "summary": "Addressing the critical need for robust safety in Large Language Models (LLMs), particularly against adversarial attacks and in-distribution errors, we introduce Reinforcement Learning with Backtracking Feedback (RLBF). This framework advances upon prior methods, such as BSAFE, by primarily leveraging a Reinforcement Learning (RL) stage where models learn to dynamically correct their own generation errors. Through RL with critic feedback on the model's live outputs, LLMs are trained to identify and recover from their actual, emergent safety violations by emitting an efficient \"backtrack by x tokens\" signal, then continuing generation autoregressively. This RL process is crucial for instilling resilience against sophisticated adversarial strategies, including middle filling, Greedy Coordinate Gradient (GCG) attacks, and decoding parameter manipulations. To further support the acquisition of this backtracking capability, we also propose an enhanced Supervised Fine-Tuning (SFT) data generation strategy (BSAFE+). This method improves upon previous data creation techniques by injecting violations into coherent, originally safe text, providing more effective initial training for the backtracking mechanism. Comprehensive empirical evaluations demonstrate that RLBF significantly reduces attack success rates across diverse benchmarks and model scales, achieving superior safety outcomes while critically preserving foundational model utility.", "AI": {"tldr": "RLBF\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8ba9LLM\u5b66\u4f1a\u52a8\u6001\u7ea0\u6b63\u81ea\u8eab\u751f\u6210\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6297\u653b\u51fb\u548c\u5206\u5e03\u5185\u9519\u8bef\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u548c\u5206\u5e03\u5185\u9519\u8bef\u65b9\u9762\u7684\u5b89\u5168\u8106\u5f31\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u56de\u6eaf\u53cd\u9988\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u90e8\u5206\uff1a1\uff09\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u6a21\u578b\u901a\u8fc7\u6279\u8bc4\u53cd\u9988\u5b66\u4e60\u52a8\u6001\u7ea0\u6b63\u9519\u8bef\uff0c\u53d1\u51fa\"\u56de\u6eafx\u4e2atoken\"\u4fe1\u53f7\u540e\u7ee7\u7eed\u751f\u6210\uff1b2\uff09\u6539\u8fdb\u7684\u76d1\u7763\u5fae\u8c03\u6570\u636e\u751f\u6210\u7b56\u7565BSAFE+\uff0c\u5728\u539f\u672c\u5b89\u5168\u7684\u6587\u672c\u4e2d\u6ce8\u5165\u8fdd\u89c4\u5185\u5bb9\u3002", "result": "RLBF\u663e\u8457\u964d\u4f4e\u4e86\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u90fd\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u5b89\u5168\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u57fa\u7840\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "RLBF\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8ba9\u6a21\u578b\u5b66\u4f1a\u81ea\u6211\u7ea0\u6b63\uff0c\u4e3aLLM\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u62b5\u5fa1\u5305\u62ec\u4e2d\u95f4\u586b\u5145\u3001GCG\u653b\u51fb\u548c\u89e3\u7801\u53c2\u6570\u64cd\u7eb5\u5728\u5185\u7684\u591a\u79cd\u5bf9\u6297\u7b56\u7565\u3002"}}
{"id": "2602.08000", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08000", "abs": "https://arxiv.org/abs/2602.08000", "authors": ["Anirudh Satheesh", "Vaneet Aggarwal"], "title": "Regret Analysis of Unichain Average Reward Constrained MDPs with General Parameterization", "comment": null, "summary": "We study infinite-horizon average-reward constrained Markov decision processes (CMDPs) under the unichain assumption and general policy parameterizations. Existing regret analyses for constrained reinforcement learning largely rely on ergodicity or strong mixing-time assumptions, which fail to hold in the presence of transient states. We propose a primal--dual natural actor--critic algorithm that leverages multi-level Monte Carlo (MLMC) estimators and an explicit burn-in mechanism to handle unichain dynamics without requiring mixing-time oracles. Our analysis establishes finite-time regret and cumulative constraint violation bounds that scale as $\\tilde{O}(\\sqrt{T})$, up to approximation errors arising from policy and critic parameterization, thereby extending order-optimal guarantees to a significantly broader class of CMDPs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u65e0\u9650\u65f6\u57df\u5e73\u5747\u5956\u52b1\u7ea6\u675fMDP\u7684\u539f\u59cb-\u5bf9\u5076\u81ea\u7136\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u4f7f\u7528\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5668\u548c\u663e\u5f0f\u9884\u70ed\u673a\u5236\u5904\u7406\u5355\u94fe\u52a8\u6001\uff0c\u65e0\u9700\u6df7\u5408\u65f6\u95f4\u9884\u8a00\u673a\uff0c\u83b7\u5f97\u221aT\u91cf\u7ea7\u7684\u9057\u61be\u548c\u7ea6\u675f\u8fdd\u53cd\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u9057\u61be\u5206\u6790\u4e3b\u8981\u4f9d\u8d56\u904d\u5386\u6027\u6216\u5f3a\u6df7\u5408\u65f6\u95f4\u5047\u8bbe\uff0c\u8fd9\u4e9b\u5047\u8bbe\u5728\u5b58\u5728\u77ac\u6001\u72b6\u6001\u65f6\u5931\u6548\u3002\u9700\u8981\u6269\u5c55\u6700\u4f18\u4fdd\u8bc1\u5230\u66f4\u5e7f\u6cdb\u7684CMDP\u7c7b\u522b\uff0c\u7279\u522b\u662f\u5355\u94fe\u52a8\u6001\u4e14\u65e0\u9700\u6df7\u5408\u65f6\u95f4\u9884\u8a00\u673a\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u539f\u59cb-\u5bf9\u5076\u81ea\u7136\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u7ed3\u5408\u591a\u7ea7\u8499\u7279\u5361\u6d1b(MLMC)\u4f30\u8ba1\u5668\u548c\u663e\u5f0f\u9884\u70ed\u673a\u5236\u6765\u5904\u7406\u5355\u94fe\u52a8\u6001\u3002\u7b97\u6cd5\u4e0d\u4f9d\u8d56\u6df7\u5408\u65f6\u95f4\u9884\u8a00\u673a\uff0c\u901a\u8fc7\u7b56\u7565\u548c\u8bc4\u8bba\u5bb6\u53c2\u6570\u5316\u5904\u7406\u8fd1\u4f3c\u8bef\u5dee\u3002", "result": "\u5efa\u7acb\u4e86\u6709\u9650\u65f6\u95f4\u9057\u61be\u548c\u7d2f\u79ef\u7ea6\u675f\u8fdd\u53cd\u8fb9\u754c\uff0c\u5c3a\u5ea6\u4e3a\u00d5(\u221aT)\uff0c\u53d7\u9650\u4e8e\u7b56\u7565\u548c\u8bc4\u8bba\u5bb6\u53c2\u6570\u5316\u4ea7\u751f\u7684\u8fd1\u4f3c\u8bef\u5dee\u3002\u5c06\u9636\u6700\u4f18\u4fdd\u8bc1\u6269\u5c55\u5230\u663e\u8457\u66f4\u5e7f\u6cdb\u7684CMDP\u7c7b\u522b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u6700\u4f18\u4fdd\u8bc1\u6269\u5c55\u5230\u5355\u94feCMDP\uff0c\u65e0\u9700\u6df7\u5408\u65f6\u95f4\u5047\u8bbe\uff0c\u901a\u8fc7MLMC\u4f30\u8ba1\u5668\u548c\u9884\u70ed\u673a\u5236\u5904\u7406\u77ac\u6001\u72b6\u6001\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u52a8\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002"}}
{"id": "2602.08489", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08489", "abs": "https://arxiv.org/abs/2602.08489", "authors": ["Hyunseok Lee", "Soheil Abbasloo", "Jihoon Tack", "Jinwoo Shin"], "title": "Beyond Correctness: Learning Robust Reasoning via Transfer", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy, and it reaches comparable performance in substantially fewer training steps. For example, on MATH500, RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient.", "AI": {"tldr": "RLTR\uff08\u53ef\u8f6c\u79fb\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u901a\u8fc7\u6d4b\u8bd5\u90e8\u5206\u63a8\u7406\u524d\u7f00\u662f\u5426\u80fd\u6307\u5bfc\u5176\u4ed6\u6a21\u578b\u5f97\u51fa\u6b63\u786e\u7b54\u6848\uff0c\u6765\u589e\u5f3aLLM\u63a8\u7406\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u76f8\u6bd4RLVR\u5728\u66f4\u5c11\u8bad\u7ec3\u6b65\u9aa4\u4e0b\u8fbe\u5230\u76f8\u5f53\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u53ea\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u7684\u9c81\u68d2\u6027\u3002\u4f5c\u8005\u8ba4\u4e3a\u9c81\u68d2\u7684\u63a8\u7406\u5e94\u8be5\u80fd\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u8f6c\u79fb\u548c\u91cd\u7528\uff0c\u5373\u63a8\u7406\u5e94\u5177\u6709\"\u53ef\u8f6c\u79fb\u6027\"\u3002", "method": "\u63d0\u51faRLTR\uff08Reinforcement Learning with Transferable Reward\uff09\uff0c\u901a\u8fc7\u53ef\u8f6c\u79fb\u5956\u52b1\u6765\u64cd\u4f5c\u5316\u9c81\u68d2\u6027\uff1a\u6d4b\u8bd5\u4ece\u4e00\u4e2a\u6a21\u578b\u63d0\u53d6\u7684\u90e8\u5206\u63a8\u7406\u524d\u7f00\u662f\u5426\u80fd\u6307\u5bfc\u53e6\u4e00\u4e2a\u72ec\u7acb\u6a21\u578b\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u3002\u8fd9\u9f13\u52b1LLM\u4ea7\u751f\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u4e14\u771f\u6b63\u53ef\u6cdb\u5316\u7684\u63a8\u7406\u3002", "result": "\u5728MATH500\u4e0a\uff0cRLTR\u76f8\u6bd4RLVR\u83b7\u5f97+3.6%\u7684Maj@64\u63d0\u5347\uff0c\u4e14\u4ec5\u7528\u7ea62.5\u500d\u66f4\u5c11\u7684\u8bad\u7ec3\u6b65\u9aa4\u5c31\u8fbe\u5230RLVR\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002\u65b9\u6cd5\u63d0\u9ad8\u4e86\u91c7\u6837\u4e00\u81f4\u6027\u540c\u65f6\u63d0\u5347\u4e86\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u7387\u3002", "conclusion": "RLTR\u901a\u8fc7\u53ef\u8f6c\u79fb\u5956\u52b1\u673a\u5236\u589e\u5f3a\u4e86LLM\u63a8\u7406\u7684\u9c81\u68d2\u6027\uff0c\u4e0d\u4ec5\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u8fd8\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u5728\u66f4\u5c11\u8bad\u7ec3\u6b65\u9aa4\u4e0b\u8fbe\u5230\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2602.08007", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08007", "abs": "https://arxiv.org/abs/2602.08007", "authors": ["Sizhe Dang", "Jiaqi Shao", "Xiaodong Zheng", "Guang Dai", "Yan Song", "Haishan Ye"], "title": "From $O(mn)$ to $O(r^2)$: Two-Sided Low-Rank Communication for Adam in Distributed Training with Memory Efficiency", "comment": null, "summary": "As foundation models continue to scale, pretraining increasingly relies on data-parallel distributed optimization, making bandwidth-limited gradient synchronization a key bottleneck. Orthogonally, projection-based low-rank optimizers were mainly designed for memory efficiency, but remain suboptimal for communication-limited training: one-sided synchronization still transmits an $O(rn)$ object for an $m\\times n$ matrix gradient and refresh steps can dominate peak communicated bytes. We propose TSR, which brings two-sided low-rank communication to Adam-family updates (TSR-Adam) by synchronizing a compact core $U^\\top G V\\in\\mathbb{R}^{r\\times r}$, reducing the dominant per-step payload from $O(mn)$ to $O(r^2)$ while keeping moment states in low-dimensional cores. To further reduce the peak communication from subspace refresh, TSR-Adam adopts a randomized SVD-based refresh that avoids full-gradient synchronization. We additionally extend low-rank communication to embedding gradients with embedding-specific ranks and refresh schedules, yielding additional communication and memory savings over keeping embeddings dense. Across pretraining from 60M to 1B model scales, TSR-Adam reduces average communicated bytes per step by $13\\times$, and on GLUE fine-tuning it reduces communication by $25\\times$, while achieving comparable performance; we further provide a theoretical stationarity analysis for the proposed update. Code is available at https://github.com/DKmiyan/TSR-Adam.", "AI": {"tldr": "TSR-Adam\u662f\u4e00\u79cd\u9488\u5bf9Adam\u4f18\u5316\u5668\u7684\u53cc\u9762\u4f4e\u79e9\u901a\u4fe1\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u6b65\u7d27\u51d1\u7684r\u00d7r\u6838\u5fc3\u77e9\u9635\uff0c\u5c06\u6bcf\u6b65\u901a\u4fe1\u8d1f\u8f7d\u4eceO(mn)\u964d\u81f3O(r\u00b2)\uff0c\u663e\u8457\u51cf\u5c11\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0c\u6570\u636e\u5e76\u884c\u5206\u5e03\u5f0f\u4f18\u5316\u6210\u4e3a\u4e3b\u6d41\uff0c\u4f46\u5e26\u5bbd\u53d7\u9650\u7684\u68af\u5ea6\u540c\u6b65\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u7684\u6295\u5f71\u4f4e\u79e9\u4f18\u5316\u5668\u4e3b\u8981\u9488\u5bf9\u5185\u5b58\u6548\u7387\u8bbe\u8ba1\uff0c\u5728\u901a\u4fe1\u53d7\u9650\u7684\u8bad\u7ec3\u4e2d\u4ecd\u4e0d\u7406\u60f3\uff1a\u5355\u8fb9\u540c\u6b65\u4ecd\u9700\u4f20\u8f93O(rn)\u5bf9\u8c61\uff0c\u5237\u65b0\u6b65\u9aa4\u53ef\u80fd\u4e3b\u5bfc\u5cf0\u503c\u901a\u4fe1\u5b57\u8282\u3002", "method": "\u63d0\u51faTSR-Adam\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u540c\u6b65\u7d27\u51d1\u6838\u5fc3U^TGV\u2208\u211d^{r\u00d7r}\u5b9e\u73b0Adam\u66f4\u65b0\u7684\u53cc\u9762\u4f4e\u79e9\u901a\u4fe1\uff1b2) \u91c7\u7528\u57fa\u4e8e\u968f\u673aSVD\u7684\u5237\u65b0\u907f\u514d\u5168\u68af\u5ea6\u540c\u6b65\uff1b3) \u5c06\u4f4e\u79e9\u901a\u4fe1\u6269\u5c55\u5230\u5d4c\u5165\u68af\u5ea6\uff0c\u4f7f\u7528\u5d4c\u5165\u7279\u5b9a\u79e9\u548c\u5237\u65b0\u8ba1\u5212\u3002", "result": "\u5728\u4ece60M\u52301B\u6a21\u578b\u89c4\u6a21\u7684\u9884\u8bad\u7ec3\u4e2d\uff0cTSR-Adam\u5c06\u5e73\u5747\u6bcf\u6b65\u901a\u4fe1\u5b57\u8282\u51cf\u5c1113\u500d\uff1b\u5728GLUE\u5fae\u8c03\u4e2d\u51cf\u5c11\u901a\u4fe125\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u3002\u63d0\u4f9b\u4e86\u6240\u63d0\u66f4\u65b0\u7684\u7406\u8bba\u5e73\u7a33\u6027\u5206\u6790\u3002", "conclusion": "TSR-Adam\u901a\u8fc7\u53cc\u9762\u4f4e\u79e9\u901a\u4fe1\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u800c\u4e0d\u727a\u7272\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08012", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08012", "abs": "https://arxiv.org/abs/2602.08012", "authors": ["Riccardo De Santi", "Malte Franke", "Ya-Ping Hsieh", "Andreas Krause"], "title": "A Unified Density Operator View of Flow Control and Merging", "comment": null, "summary": "Recent progress in large-scale flow and diffusion models raised two fundamental algorithmic challenges: (i) control-based reward adaptation of pre-trained flows, and (ii) integration of multiple models, i.e., flow merging. While current approaches address them separately, we introduce a unifying probability-space framework that subsumes both as limit cases, and enables reward-guided flow merging, allowing principled, task-aware combination of multiple pre-trained flows (e.g., merging priors while maximizing drug-discovery utilities). Our formulation renders possible to express a rich family of operators over generative models densities, including intersection (e.g., to enforce safety), union (e.g., to compose diverse models), interpolation (e.g., for discovery), their reward-guided counterparts, as well as complex logical expressions via generative circuits. Next, we introduce Reward-Guided Flow Merging (RFM), a mirror-descent scheme that reduces reward-guided flow merging to a sequence of standard fine-tuning problems. Then, we provide first-of-their-kind theoretical guarantees for reward-guided and pure flow merging via RFM. Ultimately, we showcase the capabilities of the proposed method on illustrative settings providing visually interpretable insights, and apply our method to high-dimensional de-novo molecular design and low-energy conformer generation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u7387\u7a7a\u95f4\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u63a7\u5236\u7684\u5956\u52b1\u9002\u5e94\u548c\u6d41\u6a21\u578b\u5408\u5e76\u7edf\u4e00\u5904\u7406\uff0c\u652f\u6301\u5956\u52b1\u5f15\u5bfc\u7684\u6d41\u5408\u5e76\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u3002", "motivation": "\u5927\u89c4\u6a21\u6d41\u548c\u6269\u6563\u6a21\u578b\u7684\u53d1\u5c55\u5e26\u6765\u4e86\u4e24\u4e2a\u57fa\u672c\u7b97\u6cd5\u6311\u6218\uff1a\u57fa\u4e8e\u63a7\u5236\u7684\u9884\u8bad\u7ec3\u6d41\u5956\u52b1\u9002\u5e94\u548c\u591a\u4e2a\u6a21\u578b\u7684\u96c6\u6210\uff08\u6d41\u5408\u5e76\uff09\u3002\u73b0\u6709\u65b9\u6cd5\u5206\u522b\u5904\u7406\u8fd9\u4e24\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u6311\u6218\uff0c\u5e76\u652f\u6301\u4efb\u52a1\u611f\u77e5\u7684\u6a21\u578b\u7ec4\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u7387\u7a7a\u95f4\u6846\u67b6\uff0c\u5c06\u5956\u52b1\u9002\u5e94\u548c\u6d41\u5408\u5e76\u4f5c\u4e3a\u6781\u9650\u60c5\u51b5\u5305\u542b\u5176\u4e2d\u3002\u5f15\u5165\u4e86\u5956\u52b1\u5f15\u5bfc\u6d41\u5408\u5e76\uff08RFM\uff09\u65b9\u6cd5\uff0c\u4f7f\u7528\u955c\u50cf\u4e0b\u964d\u65b9\u6848\u5c06\u5956\u52b1\u5f15\u5bfc\u6d41\u5408\u5e76\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u6807\u51c6\u5fae\u8c03\u95ee\u9898\u3002\u8be5\u6846\u67b6\u652f\u6301\u4e30\u5bcc\u7684\u751f\u6210\u6a21\u578b\u5bc6\u5ea6\u64cd\u4f5c\uff0c\u5305\u62ec\u4ea4\u96c6\u3001\u5e76\u96c6\u3001\u63d2\u503c\u53ca\u5176\u5956\u52b1\u5f15\u5bfc\u7248\u672c\u3002", "result": "\u4e3a\u5956\u52b1\u5f15\u5bfc\u548c\u7eaf\u6d41\u5408\u5e76\u63d0\u4f9b\u4e86\u9996\u4e2a\u7406\u8bba\u4fdd\u8bc1\u3002\u5728\u8bf4\u660e\u6027\u8bbe\u7f6e\u4e2d\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u53ef\u89c6\u5316\u89e3\u91ca\u80fd\u529b\uff0c\u5e76\u5728\u9ad8\u7ef4\u4ece\u5934\u5206\u5b50\u8bbe\u8ba1\u548c\u4f4e\u80fd\u6784\u8c61\u751f\u6210\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6d41\u6a21\u578b\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u4efb\u52a1\u611f\u77e5\u7684\u6a21\u578b\u7ec4\u5408\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u64cd\u4f5c\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u5728\u5206\u5b50\u8bbe\u8ba1\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08019", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08019", "abs": "https://arxiv.org/abs/2602.08019", "authors": ["Dong Pan", "Bingtao Li", "Yongsheng Zheng", "Jiren Ma", "Victor Fei"], "title": "The Rise of Sparse Mixture-of-Experts: A Survey from Algorithmic Foundations to Decentralized Architectures and Vertical Domain Applications", "comment": null, "summary": "The sparse Mixture of Experts(MoE) architecture has evolved as a powerful approach for scaling deep learning models to more parameters with comparable computation cost. As an important branch of large language model(LLM), MoE model only activate a subset of experts based on a routing network. This sparse conditional computation mechanism significantly improves computational efficiency, paving a promising path for greater scalability and cost-efficiency. It not only enhance downstream applications such as natural language processing, computer vision, and multimodal in various horizontal domains, but also exhibit broad applicability across vertical domains. Despite the growing popularity and application of MoE models across various domains, there lacks a systematic exploration of recent advancements of MoE in many important fields. Existing surveys on MoE suffer from limitations such as lack coverage or none extensively exploration of key areas. This survey seeks to fill these gaps. In this paper, Firstly, we examine the foundational principles of MoE, with an in-depth exploration of its core components-the routing network and expert network. Subsequently, we extend beyond the centralized paradigm to the decentralized paradigm, which unlocks the immense untapped potential of decentralized infrastructure, enables democratization of MoE development for broader communities, and delivers greater scalability and cost-efficiency. Furthermore we focus on exploring its vertical domain applications. Finally, we also identify key challenges and promising future research directions. To the best of our knowledge, this survey is currently the most comprehensive review in the field of MoE. We aim for this article to serve as a valuable resource for both researchers and practitioners, enabling them to navigate and stay up-to-date with the latest advancements.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u5173\u4e8e\u7a00\u758f\u6df7\u5408\u4e13\u5bb6(MoE)\u6a21\u578b\u7684\u7efc\u8ff0\uff0c\u7cfb\u7edf\u6027\u5730\u56de\u987e\u4e86MoE\u7684\u57fa\u7840\u539f\u7406\u3001\u6838\u5fc3\u7ec4\u4ef6\u3001\u53bb\u4e2d\u5fc3\u5316\u8303\u5f0f\u3001\u5782\u76f4\u9886\u57df\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "MoE\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u8981\u5206\u652f\uff0c\u901a\u8fc7\u7a00\u758f\u6761\u4ef6\u8ba1\u7b97\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002\u7136\u800c\uff0c\u5c3d\u7ba1MoE\u5728\u5404\u4e2a\u9886\u57df\u8d8a\u6765\u8d8a\u53d7\u6b22\u8fce\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u6700\u65b0\u8fdb\u5c55\u7684\u7cfb\u7edf\u6027\u63a2\u7d22\uff0c\u73b0\u6709\u7efc\u8ff0\u5b58\u5728\u8986\u76d6\u8303\u56f4\u4e0d\u8db3\u6216\u5173\u952e\u9886\u57df\u63a2\u7d22\u4e0d\u591f\u6df1\u5165\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff1a\u9996\u5148\u68c0\u67e5MoE\u7684\u57fa\u7840\u539f\u7406\uff0c\u6df1\u5165\u63a2\u7d22\u5176\u6838\u5fc3\u7ec4\u4ef6\uff08\u8def\u7531\u7f51\u7edc\u548c\u4e13\u5bb6\u7f51\u7edc\uff09\uff1b\u7136\u540e\u4ece\u4e2d\u5fc3\u5316\u8303\u5f0f\u6269\u5c55\u5230\u53bb\u4e2d\u5fc3\u5316\u8303\u5f0f\uff1b\u63a5\u7740\u91cd\u70b9\u63a2\u7d22\u5176\u5782\u76f4\u9886\u57df\u5e94\u7528\uff1b\u6700\u540e\u8bc6\u522b\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u4f5c\u8005\u58f0\u79f0\u8fd9\u662f\u76ee\u524dMoE\u9886\u57df\u6700\u5168\u9762\u7684\u7efc\u8ff0\uff0c\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u5e2e\u52a9\u4ed6\u4eec\u4e86\u89e3\u8be5\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u5e76\u4fdd\u6301\u66f4\u65b0\u3002", "conclusion": "MoE\u67b6\u6784\u901a\u8fc7\u7a00\u758f\u6761\u4ef6\u8ba1\u7b97\u673a\u5236\u5728\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u53bb\u4e2d\u5fc3\u5316\u8303\u5f0f\u80fd\u591f\u91ca\u653e\u5206\u6563\u57fa\u7840\u8bbe\u65bd\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4f7f\u66f4\u5e7f\u6cdb\u7684\u793e\u533a\u80fd\u591f\u53c2\u4e0eMoE\u5f00\u53d1\uff0c\u5e76\u63d0\u4f9b\u66f4\u5927\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u8be5\u7efc\u8ff0\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.08819", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08819", "abs": "https://arxiv.org/abs/2602.08819", "authors": ["Jiwoo Hong", "Shao Tang", "Zhipeng Wang"], "title": "Bayesian Preference Learning for Test-Time Steerable Reward Models", "comment": "Preprint", "summary": "Reward models are central to aligning language models with human preferences via reinforcement learning (RL). As RL is increasingly applied to settings such as verifiable rewards and multi-objective alignment, RMs are expected to encode more complex and multifaceted preference distributions. However, classifier RMs remain static once trained, limiting their adaptability at test time. We propose Variational In-Context Reward Modeling (ICRM), a novel Bayesian reward modeling objective that enables test-time steerability via in-context preference demonstrations. ICRM casts reward modeling as amortized variational inference over a latent preference probability under the Bradley-Terry model using a conjugate Beta prior. We show that ICRM adapt to unseen preference distributions at test time for both single and multi-objective settings. With more in-context demonstrations, ICRM gains 34% accuracy on SafeRLHF and 9% accuracy on RM-Bench in the single-objective setting, while widening the Pareto frontier with a 4% gain in hypervolume on helpfulness and refusal benchmarks. We further study the practical applicability of ICRM for RL training, showing that it can effectively encode verifiable rewards by outperforming a conventional RM in math reasoning. Finally, we provide theoretical guarantees that the variational objective admits a global interior optimum with finite confidence, and we analyze how KL regularization mitigates reward over-optimization.", "AI": {"tldr": "\u63d0\u51faVariational In-Context Reward Modeling (ICRM)\uff0c\u4e00\u79cd\u8d1d\u53f6\u65af\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u504f\u597d\u6f14\u793a\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u7684\u53ef\u8c03\u63a7\u6027\uff0c\u5728\u5355\u76ee\u6807\u548c\u591a\u76ee\u6807\u8bbe\u7f6e\u4e2d\u90fd\u80fd\u9002\u5e94\u672a\u89c1\u8fc7\u7684\u504f\u597d\u5206\u5e03\u3002", "motivation": "\u968f\u7740\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u548c\u591a\u76ee\u6807\u5bf9\u9f50\u7b49\u573a\u666f\uff0c\u5956\u52b1\u6a21\u578b\u9700\u8981\u7f16\u7801\u66f4\u590d\u6742\u3001\u591a\u65b9\u9762\u7684\u504f\u597d\u5206\u5e03\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u5206\u7c7b\u5668\u5956\u52b1\u6a21\u578b\u4e00\u65e6\u8bad\u7ec3\u5b8c\u6210\u5c31\u4fdd\u6301\u9759\u6001\uff0c\u9650\u5236\u4e86\u5176\u5728\u6d4b\u8bd5\u65f6\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faICRM\uff0c\u5c06\u5956\u52b1\u5efa\u6a21\u89c6\u4e3a\u5728Bradley-Terry\u6a21\u578b\u4e0b\u5bf9\u6f5c\u5728\u504f\u597d\u6982\u7387\u8fdb\u884c\u644a\u9500\u53d8\u5206\u63a8\u65ad\uff0c\u4f7f\u7528\u5171\u8f6dBeta\u5148\u9a8c\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u901a\u8fc7\u4e0a\u4e0b\u6587\u504f\u597d\u6f14\u793a\u5728\u6d4b\u8bd5\u65f6\u8c03\u6574\u6a21\u578b\u3002", "result": "ICRM\u5728\u5355\u76ee\u6807\u8bbe\u7f6e\u4e2d\uff0c\u968f\u7740\u4e0a\u4e0b\u6587\u6f14\u793a\u589e\u52a0\uff0c\u5728SafeRLHF\u4e0a\u83b7\u5f9734%\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5728RM-Bench\u4e0a\u83b7\u5f979%\u63d0\u5347\uff1b\u5728\u591a\u76ee\u6807\u8bbe\u7f6e\u4e2d\uff0c\u5e15\u7d2f\u6258\u524d\u6cbf\u6269\u5927\uff0c\u5728\u5e2e\u52a9\u6027\u548c\u62d2\u7edd\u57fa\u51c6\u4e0a\u83b7\u5f974%\u8d85\u4f53\u79ef\u589e\u76ca\u3002\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cICRM\u80fd\u6709\u6548\u7f16\u7801\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u4f18\u4e8e\u4f20\u7edfRM\u3002", "conclusion": "ICRM\u901a\u8fc7\u53d8\u5206\u63a8\u7406\u6846\u67b6\u5b9e\u73b0\u4e86\u6d4b\u8bd5\u65f6\u7684\u5956\u52b1\u6a21\u578b\u53ef\u8c03\u63a7\u6027\uff0c\u5728\u5355\u76ee\u6807\u548c\u591a\u76ee\u6807\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u8868\u660e\u53d8\u5206\u76ee\u6807\u5177\u6709\u5168\u5c40\u5185\u90e8\u6700\u4f18\u89e3\uff0cKL\u6b63\u5219\u5316\u80fd\u7f13\u89e3\u5956\u52b1\u8fc7\u5ea6\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2602.08857", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08857", "abs": "https://arxiv.org/abs/2602.08857", "authors": ["Xinting Huang", "Aleksandra Bakalova", "Satwik Bhattamishra", "William Merrill", "Michael Hahn"], "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP", "comment": "101 pages, 92 figures", "summary": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u8bad\u7ec3\u597d\u7684Transformer\u4e2d\u63d0\u53d6RASP\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u53d1\u73b0\u6700\u5c0f\u5145\u5206\u5b50\u7a0b\u5e8f\uff0c\u4e3aTransformer\u5185\u90e8\u5b9e\u73b0\u7b80\u5355\u53ef\u89e3\u91ca\u7a0b\u5e8f\u63d0\u4f9b\u76f4\u63a5\u8bc1\u636e", "motivation": "\u867d\u7136\u4e4b\u524d\u7814\u7a76\u8868\u660eTransformer\u7684\u8ba1\u7b97\u53ef\u4ee5\u7528RASP\u7f16\u7a0b\u8bed\u8a00\u6a21\u62df\uff0c\u4e14Transformer\u5728\u5177\u6709\u7b80\u5355RASP\u7a0b\u5e8f\u7684\u95ee\u9898\u4e0a\u80fd\u7cbe\u786e\u957f\u5ea6\u6cdb\u5316\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u662f\u5426\u771f\u7684\u5b9e\u73b0\u4e86\u7b80\u5355\u53ef\u89e3\u91ca\u7684\u7a0b\u5e8f", "method": "\u5c06Transformer\u5fe0\u5b9e\u91cd\u53c2\u6570\u5316\u4e3aRASP\u7a0b\u5e8f\uff0c\u7136\u540e\u5e94\u7528\u56e0\u679c\u5e72\u9884\u6765\u53d1\u73b0\u6700\u5c0f\u5145\u5206\u5b50\u7a0b\u5e8f", "result": "\u5728\u5c0f\u578bTransformer\u4e0a\u8fdb\u884c\u7b97\u6cd5\u548c\u5f62\u5f0f\u8bed\u8a00\u4efb\u52a1\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u901a\u5e38\u80fd\u4ece\u957f\u5ea6\u6cdb\u5316\u7684Transformer\u4e2d\u6062\u590d\u51fa\u7b80\u5355\u53ef\u89e3\u91ca\u7684RASP\u7a0b\u5e8f", "conclusion": "\u8fd9\u662f\u8fc4\u4eca\u4e3a\u6b62\u6700\u76f4\u63a5\u7684\u8bc1\u636e\uff0c\u8868\u660eTransformer\u5185\u90e8\u5b9e\u73b0\u4e86\u7b80\u5355\u7684RASP\u7a0b\u5e8f"}}
{"id": "2602.08032", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08032", "abs": "https://arxiv.org/abs/2602.08032", "authors": ["Lior Cohen", "Ofir Nabati", "Kaixin Wang", "Navdeep Kumar", "Shie Mannor"], "title": "Horizon Imagination: Efficient On-Policy Training in Diffusion World Models", "comment": "This paper will be published in the ICLR 2026 proceedings", "summary": "We study diffusion-based world models for reinforcement learning, which offer high generative fidelity but face critical efficiency challenges in control. Current methods either require heavyweight models at inference or rely on highly sequential imagination, both of which impose prohibitive computational costs. We propose Horizon Imagination (HI), an on-policy imagination process for discrete stochastic policies that denoises multiple future observations in parallel. HI incorporates a stabilization mechanism and a novel sampling schedule that decouples the denoising budget from the effective horizon over which denoising is applied while also supporting sub-frame budgets. Experiments on Atari 100K and Craftium show that our approach maintains control performance with a sub-frame budget of half the denoising steps and achieves superior generation quality under varied schedules. Code is available at https://github.com/leor-c/horizon-imagination.", "AI": {"tldr": "\u63d0\u51faHorizon Imagination (HI)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u53bb\u566a\u672a\u6765\u89c2\u6d4b\u548c\u7a33\u5b9a\u673a\u5236\uff0c\u5728\u4fdd\u6301\u63a7\u5236\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6269\u6563\u4e16\u754c\u6a21\u578b\u7684\u63a8\u7406\u8ba1\u7b97\u6210\u672c", "motivation": "\u57fa\u4e8e\u6269\u6563\u7684\u4e16\u754c\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5177\u6709\u9ad8\u751f\u6210\u4fdd\u771f\u5ea6\uff0c\u4f46\u9762\u4e34\u4e25\u91cd\u7684\u6548\u7387\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u91cd\u578b\u63a8\u7406\u6a21\u578b\uff0c\u8981\u4e48\u4f9d\u8d56\u9ad8\u5ea6\u5e8f\u5217\u5316\u7684\u60f3\u8c61\u8fc7\u7a0b\uff0c\u90fd\u5e26\u6765\u8fc7\u9ad8\u7684\u8ba1\u7b97\u6210\u672c", "method": "\u63d0\u51faHorizon Imagination (HI)\uff0c\u4e00\u79cd\u7528\u4e8e\u79bb\u6563\u968f\u673a\u7b56\u7565\u7684\u5728\u7ebf\u60f3\u8c61\u8fc7\u7a0b\uff0c\u80fd\u591f\u5e76\u884c\u53bb\u566a\u591a\u4e2a\u672a\u6765\u89c2\u6d4b\u3002\u5305\u542b\u7a33\u5b9a\u673a\u5236\u548c\u65b0\u9896\u7684\u91c7\u6837\u8c03\u5ea6\uff0c\u5c06\u53bb\u566a\u9884\u7b97\u4e0e\u6709\u6548\u89c6\u91ce\u89e3\u8026\uff0c\u540c\u65f6\u652f\u6301\u5b50\u5e27\u9884\u7b97", "result": "\u5728Atari 100K\u548cCraftium\u5b9e\u9a8c\u4e2d\uff0cHI\u65b9\u6cd5\u4ec5\u7528\u4e00\u534a\u53bb\u566a\u6b65\u9aa4\u7684\u5b50\u5e27\u9884\u7b97\u5c31\u80fd\u4fdd\u6301\u63a7\u5236\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u540c\u8c03\u5ea6\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u751f\u6210\u8d28\u91cf", "conclusion": "Horizon Imagination\u901a\u8fc7\u5e76\u884c\u53bb\u566a\u548c\u7a33\u5b9a\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6269\u6563\u4e16\u754c\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6548\u7387\uff0c\u4e3a\u9ad8\u6548\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08033", "abs": "https://arxiv.org/abs/2602.08033", "authors": ["Julien Fageot", "Matthias Grossglauser", "L\u00ea-Nguy\u00ean Hoang", "Matteo Tacchi-B\u00e9nard", "Oscar Villemaud"], "title": "The Benefits of Diversity: Combining Comparisons and Ratings for Efficient Scoring", "comment": "1 table, 5 figures, 8 pages", "summary": "Should humans be asked to evaluate entities individually or comparatively? This question has been the subject of long debates. In this work, we show that, interestingly, combining both forms of preference elicitation can outperform the focus on a single kind. More specifically, we introduce SCoRa (Scoring from Comparisons and Ratings), a unified probabilistic model that allows to learn from both signals. We prove that the MAP estimator of SCoRa is well-behaved. It verifies monotonicity and robustness guarantees. We then empirically show that SCoRa recovers accurate scores, even under model mismatch. Most interestingly, we identify a realistic setting where combining comparisons and ratings outperforms using either one alone, and when the accurate ordering of top entities is critical. Given the de facto availability of signals of multiple forms, SCoRa additionally offers a versatile foundation for preference learning.", "AI": {"tldr": "SCoRa\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u4e2a\u4f53\u8bc4\u5206\u548c\u6bd4\u8f83\u6027\u504f\u597d\u4e24\u79cd\u4fe1\u53f7\uff0c\u5728\u5b9e\u4f53\u6392\u5e8f\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5355\u4e00\u4fe1\u53f7\u65b9\u6cd5\uff0c\u7279\u522b\u5728\u9700\u8981\u7cbe\u786e\u6392\u5e8ftop\u5b9e\u4f53\u7684\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u4f73\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\u5b58\u5728\u5173\u4e8e\u4eba\u7c7b\u5e94\u8be5\u5355\u72ec\u8bc4\u4f30\u5b9e\u4f53\u8fd8\u662f\u8fdb\u884c\u6bd4\u8f83\u8bc4\u4f30\u7684\u4e89\u8bba\u3002\u672c\u6587\u53d1\u73b0\u7ed3\u5408\u4e24\u79cd\u5f62\u5f0f\u7684\u504f\u597d\u8868\u8fbe\u53ef\u4ee5\u8d85\u8d8a\u5355\u4e00\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7cbe\u786e\u6392\u5e8ftop\u5b9e\u4f53\u65f6\u3002\u7531\u4e8e\u73b0\u5b9e\u4e2d\u591a\u79cd\u5f62\u5f0f\u7684\u4fe1\u53f7\u666e\u904d\u5b58\u5728\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u6a21\u578b\u6765\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86SCoRa\uff08\u4ece\u6bd4\u8f83\u548c\u8bc4\u5206\u4e2d\u8bc4\u5206\uff09\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u7387\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u6765\u81ea\u4e2a\u4f53\u8bc4\u5206\u548c\u6bd4\u8f83\u6027\u504f\u597d\u4e24\u79cd\u4fe1\u53f7\u3002\u8bc1\u660e\u4e86SCoRa\u7684MAP\u4f30\u8ba1\u5668\u5177\u6709\u826f\u597d\u7684\u6027\u8d28\uff0c\u5305\u62ec\u5355\u8c03\u6027\u548c\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cSCoRa\u5373\u4f7f\u5728\u6a21\u578b\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6062\u590d\u51c6\u786e\u7684\u5206\u6570\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u8bc6\u522b\u51fa\u4e86\u4e00\u4e2a\u73b0\u5b9e\u573a\u666f\uff1a\u5f53\u9700\u8981\u7cbe\u786e\u6392\u5e8ftop\u5b9e\u4f53\u65f6\uff0c\u7ed3\u5408\u6bd4\u8f83\u548c\u8bc4\u5206\u7684\u65b9\u6cd5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4f55\u4e00\u79cd\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u4e2a\u4f53\u8bc4\u5206\u548c\u6bd4\u8f83\u6027\u504f\u597d\u53ef\u4ee5\u63d0\u5347\u504f\u597d\u5b66\u4e60\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7cbe\u786e\u6392\u5e8ftop\u5b9e\u4f53\u65f6\u3002SCoRa\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u57fa\u7840\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u73b0\u5b9e\u4e2d\u666e\u904d\u5b58\u5728\u7684\u591a\u79cd\u5f62\u5f0f\u4fe1\u53f7\u3002"}}
{"id": "2602.08036", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08036", "abs": "https://arxiv.org/abs/2602.08036", "authors": ["Jingtao Liu", "Xinming Zhang"], "title": "TAAM:Inductive Graph-Class Incremental Learning with Task-Aware Adaptive Modulation", "comment": null, "summary": "Graph Continual Learning (GCL) aims to solve the challenges of streaming graph data. However, current methods often depend on replay-based strategies, which raise concerns like memory limits and privacy issues, while also struggling to resolve the stability-plasticity dilemma. In this paper, we suggest that lightweight, task-specific modules can effectively guide the reasoning process of a fixed GNN backbone. Based on this idea, we propose Task-Aware Adaptive Modulation (TAAM). The key component of TAAM is its lightweight Neural Synapse Modulators (NSMs). For each new task, a dedicated NSM is trained and then frozen, acting as an \"expert module.\" These modules perform detailed, node-attentive adaptive modulation on the computational flow of a shared GNN backbone. This setup ensures that new knowledge is kept within compact, task-specific modules, naturally preventing catastrophic forgetting without using any data replay. Additionally, to address the important challenge of unknown task IDs in real-world scenarios, we propose and theoretically prove a novel method named Anchored Multi-hop Propagation (AMP). Notably, we find that existing GCL benchmarks have flaws that can cause data leakage and biased evaluations. Therefore, we conduct all experiments in a more rigorous inductive learning scenario. Extensive experiments show that TAAM comprehensively outperforms state-of-the-art methods across eight datasets. Code and Datasets are available at: https://github.com/1iuJT/TAAM_AAMAS2026.", "AI": {"tldr": "TAAM\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6570\u636e\u56de\u653e\u7684\u56fe\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7a81\u89e6\u8c03\u5236\u5668\u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u8c03\u5236\uff0c\u89e3\u51b3\u4e86\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u56f0\u5883\uff0c\u5e76\u5728\u4e25\u683c\u5f52\u7eb3\u5b66\u4e60\u573a\u666f\u4e0b\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u56fe\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u56de\u653e\u7b56\u7565\uff0c\u5b58\u5728\u5185\u5b58\u9650\u5236\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4e14\u96be\u4ee5\u89e3\u51b3\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u56f0\u5883\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6570\u636e\u56de\u653e\u3001\u80fd\u6709\u6548\u5904\u7406\u6d41\u5f0f\u56fe\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4efb\u52a1\u611f\u77e5\u81ea\u9002\u5e94\u8c03\u5236\uff08TAAM\uff09\uff0c\u6838\u5fc3\u662f\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7a81\u89e6\u8c03\u5236\u5668\uff08NSMs\uff09\u3002\u6bcf\u4e2a\u65b0\u4efb\u52a1\u8bad\u7ec3\u4e00\u4e2a\u4e13\u7528NSM\u5e76\u51bb\u7ed3\uff0c\u4f5c\u4e3a\"\u4e13\u5bb6\u6a21\u5757\"\u5bf9\u5171\u4eabGNN\u4e3b\u5e72\u7684\u8ba1\u7b97\u6d41\u8fdb\u884c\u8282\u70b9\u6ce8\u610f\u529b\u81ea\u9002\u5e94\u8c03\u5236\u3002\u8fd8\u63d0\u51fa\u951a\u70b9\u591a\u8df3\u4f20\u64ad\uff08AMP\uff09\u65b9\u6cd5\u5904\u7406\u672a\u77e5\u4efb\u52a1ID\u95ee\u9898\u3002", "result": "\u5728\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTAAM\u5728\u4e25\u683c\u7684\u5f52\u7eb3\u5b66\u4e60\u573a\u666f\u4e0b\u5168\u9762\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u540c\u65f6\u53d1\u73b0\u73b0\u6709GCL\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6cc4\u6f0f\u548c\u8bc4\u4f30\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "TAAM\u901a\u8fc7\u4efb\u52a1\u7279\u5b9a\u8f7b\u91cf\u7ea7\u6a21\u5757\u6709\u6548\u6307\u5bfc\u56fa\u5b9aGNN\u4e3b\u5e72\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u81ea\u7136\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u65e0\u9700\u6570\u636e\u56de\u653e\uff0c\u89e3\u51b3\u4e86\u56fe\u6301\u7eed\u5b66\u4e60\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2602.08040", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08040", "abs": "https://arxiv.org/abs/2602.08040", "authors": ["Isaac Han", "Sangyeon Park", "Seungwon Oh", "Donghu Kim", "Hojoon Lee", "Kyung-Joong Kim"], "title": "FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff", "comment": "ICLR'26 (oral)", "summary": "Deep neural networks trained on nonstationary data must balance stability (i.e., retaining prior knowledge) and plasticity (i.e., adapting to new tasks). Standard reinitialization methods, which reinitialize weights toward their original values, are widely used but difficult to tune: conservative reinitializations fail to restore plasticity, while aggressive ones erase useful knowledge. We propose FIRE, a principled reinitialization method that explicitly balances the stability-plasticity tradeoff. FIRE quantifies stability through Squared Frobenius Error (SFE), measuring proximity to past weights, and plasticity through Deviation from Isometry (DfI), reflecting weight isotropy. The reinitialization point is obtained by solving a constrained optimization problem, minimizing SFE subject to DfI being zero, which is efficiently approximated by Newton-Schulz iteration. FIRE is evaluated on continual visual learning (CIFAR-10 with ResNet-18), language modeling (OpenWebText with GPT-0.1B), and reinforcement learning (HumanoidBench with SAC and Atari games with DQN). Across all domains, FIRE consistently outperforms both naive training without intervention and standard reinitialization methods, demonstrating effective balancing of the stability-plasticity tradeoff.", "AI": {"tldr": "FIRE\u662f\u4e00\u79cd\u5e73\u8861\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u7684\u6743\u91cd\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u6c42\u89e3\u91cd\u521d\u59cb\u5316\u70b9\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5", "motivation": "\u5728\u975e\u5e73\u7a33\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u5e73\u8861\u7a33\u5b9a\u6027\uff08\u4fdd\u7559\u5148\u9a8c\u77e5\u8bc6\uff09\u548c\u53ef\u5851\u6027\uff08\u9002\u5e94\u65b0\u4efb\u52a1\uff09\u3002\u6807\u51c6\u7684\u6743\u91cd\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\u96be\u4ee5\u8c03\u4f18\uff1a\u4fdd\u5b88\u7684\u91cd\u521d\u59cb\u5316\u65e0\u6cd5\u6062\u590d\u53ef\u5851\u6027\uff0c\u800c\u6fc0\u8fdb\u7684\u91cd\u521d\u59cb\u5316\u4f1a\u64e6\u9664\u6709\u7528\u77e5\u8bc6\u3002", "method": "FIRE\u901a\u8fc7\u5e73\u65b9Frobenius\u8bef\u5dee(SFE)\u91cf\u5316\u7a33\u5b9a\u6027\uff08\u6d4b\u91cf\u4e0e\u8fc7\u53bb\u6743\u91cd\u7684\u63a5\u8fd1\u7a0b\u5ea6\uff09\uff0c\u901a\u8fc7\u504f\u79bb\u7b49\u8ddd\u6027(DfI)\u91cf\u5316\u53ef\u5851\u6027\uff08\u53cd\u6620\u6743\u91cd\u5404\u5411\u540c\u6027\uff09\u3002\u901a\u8fc7\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u83b7\u5f97\u91cd\u521d\u59cb\u5316\u70b9\uff1a\u6700\u5c0f\u5316SFE\uff0c\u7ea6\u675fDfI\u4e3a\u96f6\uff0c\u4f7f\u7528Newton-Schulz\u8fed\u4ee3\u9ad8\u6548\u8fd1\u4f3c\u3002", "result": "\u5728\u6301\u7eed\u89c6\u89c9\u5b66\u4e60\uff08CIFAR-10 + ResNet-18\uff09\u3001\u8bed\u8a00\u5efa\u6a21\uff08OpenWebText + GPT-0.1B\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08HumanoidBench + SAC\uff0cAtari\u6e38\u620f + DQN\uff09\u4e2d\uff0cFIRE\u59cb\u7ec8\u4f18\u4e8e\u65e0\u5e72\u9884\u7684\u6734\u7d20\u8bad\u7ec3\u548c\u6807\u51c6\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\u3002", "conclusion": "FIRE\u901a\u8fc7\u539f\u5219\u6027\u7684\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u7684\u6743\u8861\uff0c\u5728\u591a\u4e2a\u9886\u57df\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.09012", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09012", "abs": "https://arxiv.org/abs/2602.09012", "authors": ["Jiacheng Liu", "Yaxin Luo", "Jiacheng Cui", "Xinyi Shang", "Xiaohan Zhao", "Zhiqiang Shen"], "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense", "comment": "Project page at https://greenoso.github.io/NextGen-CAPTCHAs_webpage/", "summary": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faNext-Gen CAPTCHAs\u6846\u67b6\uff0c\u5229\u7528\u4eba\u673a\"\u8ba4\u77e5\u5dee\u8ddd\"\u8bbe\u8ba1\u52a8\u6001\u4ea4\u4e92\u4efb\u52a1\uff0c\u4ee5\u5e94\u5bf9\u5148\u8fdbAI\u6a21\u578b\u5bf9\u4f20\u7edf\u9a8c\u8bc1\u7801\u7684\u7834\u89e3\u5a01\u80c1\u3002", "motivation": "\u968f\u7740GUI\u667a\u80fd\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4f20\u7edfCAPTCHA\u5df2\u8fc7\u65f6\u3002\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u5982Gemini3-Pro-High\u548cGPT-5.2-Xhigh\u5728\u590d\u6742\u903b\u8f91\u8c1c\u9898\u4e0a\u8fbe\u523090%\u901a\u8fc7\u7387\uff0c\u73b0\u6709\u5b89\u5168\u5c4f\u969c\u5df2\u5d29\u6e83\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u673a\u5236\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u5065\u58ee\u6570\u636e\u751f\u6210\u7ba1\u9053\u7684\u53ef\u6269\u5c55\u57fa\u51c6\u6846\u67b6\uff0c\u5229\u7528\u4eba\u673a\u5728\u4ea4\u4e92\u611f\u77e5\u3001\u8bb0\u5fc6\u3001\u51b3\u7b56\u548c\u884c\u52a8\u65b9\u9762\u7684\"\u8ba4\u77e5\u5dee\u8ddd\"\uff0c\u8bbe\u8ba1\u9700\u8981\u81ea\u9002\u5e94\u76f4\u89c9\u800c\u975e\u7ec6\u7c92\u5ea6\u89c4\u5212\u7684\u52a8\u6001\u4efb\u52a1\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u5927\u89c4\u6a21\u6269\u5c55\u7684\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u540e\u7aef\u652f\u6301\u7684\u7c7b\u578b\uff0c\u80fd\u591f\u751f\u6210\u51e0\u4e4e\u65e0\u9650\u91cf\u7684CAPTCHA\u5b9e\u4f8b\uff0c\u91cd\u65b0\u5efa\u7acb\u4e86\u4eba\u7c7b\u7528\u6237\u4e0eAI\u4ee3\u7406\u4e4b\u95f4\u7684\u53ef\u9760\u533a\u5206\u3002", "conclusion": "Next-Gen CAPTCHAs\u6846\u67b6\u901a\u8fc7\u5229\u7528\u4eba\u673a\u8ba4\u77e5\u5dee\u5f02\uff0c\u4e3a\u667a\u80fd\u4ee3\u7406\u65f6\u4ee3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u591a\u6837\u5316\u7684\u9632\u5fa1\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u62a4\u4e0b\u4e00\u4ee3\u7f51\u7edc\u514d\u53d7\u5148\u8fdbAI\u4ee3\u7406\u7684\u5a01\u80c1\u3002"}}
{"id": "2602.08043", "categories": ["cs.LG", "cs.AI", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08043", "abs": "https://arxiv.org/abs/2602.08043", "authors": ["Yiheng Gao", "Qin Hua", "Zizhong Chen"], "title": "V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning", "comment": null, "summary": "Algorithm-Based Fault Tolerance (ABFT) is widely adopted to detect silent data corruptions (SDCs) in matrix multiplication, a cornerstone operation in deep learning systems. However, existing threshold determination methods face critical challenges: analytical bounds are overly conservative, while probabilistic approaches like A-ABFT yield thresholds $160$--$4200\\times$ larger than actual rounding errors. We present V-ABFT, a variance-based adaptive threshold algorithm that achieves tighter error bounds by directly modeling the verification difference. By leveraging statistical variance estimation, V-ABFT reduces the threshold-to-actual-error ratio to approximately $7$--$20\\times$ for FP32/FP64 and $48$--$158\\times$ for BF16, representing a \\textbf{6--48$\\times$ improvement} over A-ABFT while maintaining zero false positive rate across BF16, FP16, FP32, and FP64 precisions. Furthermore, we demonstrate that for fused-kernel ABFT implementations that verify before output quantization, low-precision GEMM can use FP32-level thresholds ($e_{\\max} \\approx 10^{-6}$), enabling \\textbf{$\\sim$1000$\\times$ finer detection granularity} compared to offline verification with low-precision output ($e_{\\max} \\approx 10^{-3}$). We reproduce A-ABFT's experimental setup and validate our implementation against the original paper's results. Our method requires only $O(n)$ complexity using max/min/mean statistics, compared to A-ABFT's $O(pn)$ for finding $p$ largest values. Extensive experiments on synthetic data and real model weights (LLaMA-7B, GPT-2, ViT) demonstrate V-ABFT's effectiveness across diverse distributions. V-ABFT is platform-agnostic and has been integrated into fault-tolerant GEMM implementations on both NPUs and GPUs.", "AI": {"tldr": "V-ABFT\u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684\u81ea\u9002\u5e94\u9608\u503c\u7b97\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709ABFT\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u77e9\u9635\u4e58\u6cd5\u4e2d\u9759\u9ed8\u6570\u636e\u635f\u574f\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5c06\u9608\u503c\u4e0e\u5b9e\u9645\u8bef\u5dee\u6bd4\u964d\u4f4e6-48\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u96f6\u8bef\u62a5\u7387\u3002", "motivation": "\u73b0\u6709ABFT\u9608\u503c\u786e\u5b9a\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a\u89e3\u6790\u8fb9\u754c\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u800c\u6982\u7387\u65b9\u6cd5\u5982A-ABFT\u7684\u9608\u503c\u6bd4\u5b9e\u9645\u820d\u5165\u8bef\u5dee\u5927160-4200\u500d\uff0c\u5bfc\u81f4\u68c0\u6d4b\u7cbe\u5ea6\u4e0d\u8db3\u3002", "method": "\u63d0\u51faV-ABFT\u7b97\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u5efa\u6a21\u9a8c\u8bc1\u5dee\u5f02\uff0c\u5229\u7528\u7edf\u8ba1\u65b9\u5dee\u4f30\u8ba1\u5b9e\u73b0\u66f4\u7d27\u5bc6\u7684\u8bef\u5dee\u8fb9\u754c\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700O(n)\u590d\u6742\u5ea6\uff0c\u4f7f\u7528\u6700\u5927/\u6700\u5c0f/\u5747\u503c\u7edf\u8ba1\u91cf\uff0c\u76f8\u6bd4A-ABFT\u7684O(pn)\u590d\u6742\u5ea6\u66f4\u9ad8\u6548\u3002", "result": "V-ABFT\u5c06\u9608\u503c\u4e0e\u5b9e\u9645\u8bef\u5dee\u6bd4\u964d\u4f4e\u5230FP32/FP64\u7ea67-20\u500d\uff0cBF16\u7ea648-158\u500d\uff0c\u76f8\u6bd4A-ABFT\u6539\u8fdb6-48\u500d\u3002\u5728\u878d\u5408\u6838ABFT\u5b9e\u73b0\u4e2d\uff0c\u4f4e\u7cbe\u5ea6GEMM\u53ef\u4f7f\u7528FP32\u7ea7\u9608\u503c\uff0c\u5b9e\u73b0\u7ea61000\u500d\u66f4\u7cbe\u7ec6\u7684\u68c0\u6d4b\u7c92\u5ea6\u3002", "conclusion": "V-ABFT\u663e\u8457\u63d0\u5347\u4e86ABFT\u5728\u77e9\u9635\u4e58\u6cd5\u4e2d\u7684\u9759\u9ed8\u6570\u636e\u635f\u574f\u68c0\u6d4b\u80fd\u529b\uff0c\u5177\u6709\u66f4\u597d\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5df2\u96c6\u6210\u5230NPU\u548cGPU\u7684\u5bb9\u9519GEMM\u5b9e\u73b0\u4e2d\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7cbe\u5ea6\u548c\u5b9e\u9645\u6a21\u578b\u6743\u91cd\u3002"}}
{"id": "2602.08050", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08050", "abs": "https://arxiv.org/abs/2602.08050", "authors": ["Qusai Khaled", "Uzay Kaymak", "Laura Genga"], "title": "Interpretable Fuzzy Systems For Forward Osmosis Desalination", "comment": "7 pages, 4 figures, FUZZ-IEEE 2025", "summary": "Preserving interpretability in fuzzy rule-based systems (FRBS) is vital for water treatment, where decisions impact public health. While structural interpretability has been addressed using multi-objective algorithms, semantic interpretability often suffers due to fuzzy sets with low distinguishability. We propose a human-in-the-loop approach for developing interpretable FRBS to predict forward osmosis desalination productivity. Our method integrates expert-driven grid partitioning for distinguishable membership functions, domain-guided feature engineering to reduce redundancy, and rule pruning based on firing strength. This approach achieved comparable predictive performance to cluster-based FRBS while maintaining semantic interpretability and meeting structural complexity constraints, providing an explainable solution for water treatment applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4eba\u673a\u534f\u540c\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u6765\u9884\u6d4b\u6b63\u5411\u6e17\u900f\u6d77\u6c34\u6de1\u5316\u751f\u4ea7\u529b\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u805a\u7c7b\u65b9\u6cd5\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5728\u6c34\u5904\u7406\u5e94\u7528\u4e2d\uff0c\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u51b3\u7b56\u76f4\u63a5\u5f71\u54cd\u516c\u5171\u5065\u5eb7\u3002\u867d\u7136\u7ed3\u6784\u53ef\u89e3\u91ca\u6027\u5df2\u901a\u8fc7\u591a\u76ee\u6807\u7b97\u6cd5\u89e3\u51b3\uff0c\u4f46\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u5e38\u56e0\u6a21\u7cca\u96c6\u533a\u5206\u5ea6\u4f4e\u800c\u53d7\u635f\u3002", "method": "\u96c6\u6210\u4e13\u5bb6\u9a71\u52a8\u7684\u7f51\u683c\u5212\u5206\u6765\u521b\u5efa\u53ef\u533a\u5206\u7684\u96b6\u5c5e\u51fd\u6570\uff0c\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u8fdb\u884c\u7279\u5f81\u5de5\u7a0b\u4ee5\u51cf\u5c11\u5197\u4f59\uff0c\u4ee5\u53ca\u57fa\u4e8e\u89e6\u53d1\u5f3a\u5ea6\u7684\u89c4\u5219\u526a\u679d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u548c\u6ee1\u8db3\u7ed3\u6784\u590d\u6742\u5ea6\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u4e86\u4e0e\u57fa\u4e8e\u805a\u7c7b\u7684\u6a21\u7cca\u89c4\u5219\u7cfb\u7edf\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6c34\u5904\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.08054", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08054", "abs": "https://arxiv.org/abs/2602.08054", "authors": ["Manan Tayal", "Mumuksh Tayal"], "title": "Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning", "comment": "23 pages, 8 figures", "summary": "Offline reinforcement learning (RL) provides a compelling paradigm for training autonomous systems without the risks of online exploration, particularly in safety-critical domains. However, jointly achieving strong safety and performance from fixed datasets remains challenging. Existing safe offline RL methods often rely on soft constraints that allow violations, introduce excessive conservatism, or struggle to balance safety, reward optimization, and adherence to the data distribution. To address this, we propose Epigraph-Guided Flow Matching (EpiFlow), a framework that formulates safe offline RL as a state-constrained optimal control problem to co-optimize safety and performance. We learn a feasibility value function derived from an epigraph reformulation of the optimal control problem, thereby avoiding the decoupled objectives or post-hoc filtering common in prior work. Policies are synthesized by reweighting the behavior distribution based on this epigraph value function and fitting a generative policy via flow matching, enabling efficient, distribution-consistent sampling. Across various safety-critical tasks, including Safety-Gymnasium benchmarks, EpiFlow achieves competitive returns with near-zero empirical safety violations, demonstrating the effectiveness of epigraph-guided policy synthesis.", "AI": {"tldr": "EpiFlow\uff1a\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7epigraph\u91cd\u6784\u5c06\u5b89\u5168\u7ea6\u675f\u8f6c\u5316\u4e3a\u53ef\u884c\u6027\u503c\u51fd\u6570\uff0c\u5b9e\u73b0\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u534f\u540c\u4f18\u5316\uff0c\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u96f6\u8fdd\u89c4\u7684\u7ade\u4e89\u6027\u56de\u62a5\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u5f3a\u5b89\u5168\u6027\u548c\u9ad8\u6027\u80fd\u3002\u73b0\u6709\u5b89\u5168\u79bb\u7ebfRL\u65b9\u6cd5\u8981\u4e48\u5141\u8bb8\u5b89\u5168\u8fdd\u89c4\uff0c\u8981\u4e48\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u8981\u4e48\u96be\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u3001\u5956\u52b1\u4f18\u5316\u548c\u6570\u636e\u5206\u5e03\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51faEpigraph-Guided Flow Matching (EpiFlow)\u6846\u67b6\uff0c\u5c06\u5b89\u5168\u79bb\u7ebfRL\u5efa\u6a21\u4e3a\u72b6\u6001\u7ea6\u675f\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\u3002\u901a\u8fc7epigraph\u91cd\u6784\u5b66\u4e60\u53ef\u884c\u6027\u503c\u51fd\u6570\uff0c\u907f\u514d\u89e3\u8026\u76ee\u6807\u6216\u540e\u5904\u7406\u8fc7\u6ee4\u3002\u57fa\u4e8eepigraph\u503c\u51fd\u6570\u5bf9\u884c\u4e3a\u5206\u5e03\u8fdb\u884c\u91cd\u52a0\u6743\uff0c\u5e76\u901a\u8fc7\u6d41\u5339\u914d\u62df\u5408\u751f\u6210\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u5206\u5e03\u4e00\u81f4\u7684\u91c7\u6837\u3002", "result": "\u5728\u5305\u62ecSafety-Gymnasium\u57fa\u51c6\u6d4b\u8bd5\u5728\u5185\u7684\u591a\u79cd\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\uff0cEpiFlow\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u56de\u62a5\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u96f6\u7684\u7ecf\u9a8c\u5b89\u5168\u8fdd\u89c4\uff0c\u8bc1\u660e\u4e86epigraph\u5f15\u5bfc\u7b56\u7565\u5408\u6210\u7684\u6709\u6548\u6027\u3002", "conclusion": "EpiFlow\u901a\u8fc7epigraph\u91cd\u6784\u548c\u6d41\u5339\u914d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5b89\u5168\u79bb\u7ebfRL\u4e2d\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u81ea\u4e3b\u7cfb\u7edf\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08060", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08060", "abs": "https://arxiv.org/abs/2602.08060", "authors": ["Alejandro Ruiz y Mesa", "Guilherme Korol", "Moritz Riesteter", "Jo\u00e3o Paulo Cardoso de Lima", "Jeronimo Castrillon"], "title": "Compiler-Assisted Speculative Sampling for Accelerated LLM Inference on Heterogeneous Edge Devices", "comment": "Accepted to AccML@HiPEAC 2026", "summary": "LLM deployment on resource-constrained edge devices faces severe latency constraints, particularly in real-time applications where delayed responses can compromise safety or usability. Among many approaches to mitigate the inefficiencies of sequential token-by-token generation, Speculative Decoding (SD) has emerged as a promising technique. However, SD at the edge is hindered by two major challenges: (1) integrating SD into a compiler-based workflow without sacrificing performance or programmability, and (2) exploiting the heterogeneous compute resources of modern SoCs through carefully designed partitioning strategies. This work addresses these challenges by using an analytical cost model that explores heterogeneous hardware configurations and guides coarse-grained partitioning of LLM subgraphs, particularly with edge-typical short input sequence lengths. The cost model predicts when speculative sampling and heterogeneous execution are jointly beneficial and is validated on an edge device featuring a hexacore Cortex-A CPU and a Mali GPU, revealing up to 1.68$\\times$ speedup for translation tasks, closely matching analytic expectations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u6790\u6210\u672c\u6a21\u578b\u7684\u7c97\u7c92\u5ea6\u5206\u533a\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4f18\u5316\u63a8\u6d4b\u89e3\u7801\uff0c\u5728\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad81.68\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "LLM\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9762\u4e34\u4e25\u91cd\u7684\u5ef6\u8fdf\u7ea6\u675f\uff0c\u7279\u522b\u662f\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u3002\u63a8\u6d4b\u89e3\u7801\u867d\u7136\u662f\u6709\u524d\u666f\u7684\u6280\u672f\uff0c\u4f46\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1) \u5982\u4f55\u5728\u4e0d\u727a\u7272\u6027\u80fd\u6216\u53ef\u7f16\u7a0b\u6027\u7684\u60c5\u51b5\u4e0b\u5c06SD\u96c6\u6210\u5230\u57fa\u4e8e\u7f16\u8bd1\u7684\u5de5\u4f5c\u6d41\u4e2d\uff1b2) \u5982\u4f55\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5206\u533a\u7b56\u7565\u5229\u7528\u73b0\u4ee3SoC\u7684\u5f02\u6784\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u5206\u6790\u6210\u672c\u6a21\u578b\u63a2\u7d22\u5f02\u6784\u786c\u4ef6\u914d\u7f6e\uff0c\u5e76\u6307\u5bfcLLM\u5b50\u56fe\u7684\u7c97\u7c92\u5ea6\u5206\u533a\uff0c\u7279\u522b\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u5178\u578b\u7684\u77ed\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u3002\u8be5\u6a21\u578b\u9884\u6d4b\u63a8\u6d4b\u91c7\u6837\u548c\u5f02\u6784\u6267\u884c\u4f55\u65f6\u8054\u5408\u6709\u76ca\u3002", "result": "\u5728\u914d\u5907\u516d\u6838Cortex-A CPU\u548cMali GPU\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5728\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad81.68\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e0e\u5206\u6790\u9884\u671f\u5bc6\u5207\u5339\u914d\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u6210\u672c\u6a21\u578b\u6307\u5bfc\u7684\u7c97\u7c92\u5ea6\u5206\u533a\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u4e0a\u63a8\u6d4b\u89e3\u7801\u7684\u96c6\u6210\u548c\u5f02\u6784\u8d44\u6e90\u5229\u7528\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2602.08062", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08062", "abs": "https://arxiv.org/abs/2602.08062", "authors": ["Shayan Ali Hassan", "Tao Ni", "Zafar Ayyub Qazi", "Marco Canini"], "title": "Efficient and Adaptable Detection of Malicious LLM Prompts via Bootstrap Aggregation", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, reasoning, and generation. However, these systems remain susceptible to malicious prompts that induce unsafe or policy-violating behavior through harmful requests, jailbreak techniques, and prompt injection attacks. Existing defenses face fundamental limitations: black-box moderation APIs offer limited transparency and adapt poorly to evolving threats, while white-box approaches using large LLM judges impose prohibitive computational costs and require expensive retraining for new attacks. Current systems force designers to choose between performance, efficiency, and adaptability.\n  To address these challenges, we present BAGEL (Bootstrap AGgregated Ensemble Layer), a modular, lightweight, and incrementally updatable framework for malicious prompt detection. BAGEL employs a bootstrap aggregation and mixture of expert inspired ensemble of fine-tuned models, each specialized on a different attack dataset. At inference, BAGEL uses a random forest router to identify the most suitable ensemble member, then applies stochastic selection to sample additional members for prediction aggregation. When new attacks emerge, BAGEL updates incrementally by fine-tuning a small prompt-safety classifier (86M parameters) and adding the resulting model to the ensemble. BAGEL achieves an F1 score of 0.92 by selecting just 5 ensemble members (430M parameters), outperforming OpenAI Moderation API and ShieldGemma which require billions of parameters. Performance remains robust after nine incremental updates, and BAGEL provides interpretability through its router's structural features. Our results show ensembles of small finetuned classifiers can match or exceed billion-parameter guardrails while offering the adaptability and efficiency required for production systems.", "AI": {"tldr": "BAGEL\u6846\u67b6\uff1a\u8f7b\u91cf\u7ea7\u3001\u6a21\u5757\u5316\u7684\u6076\u610f\u63d0\u793a\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c0f\u6a21\u578b\u96c6\u6210\u5b9e\u73b0\u9ad8\u6548\u9632\u62a4", "motivation": "\u73b0\u6709LLM\u9632\u62a4\u65b9\u6848\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff1a\u9ed1\u76d2API\u900f\u660e\u5ea6\u4f4e\u4e14\u96be\u4ee5\u9002\u5e94\u65b0\u5a01\u80c1\uff0c\u767d\u76d2\u5927\u6a21\u578b\u65b9\u6848\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u4e14\u9700\u8981\u6602\u8d35\u91cd\u8bad\u7ec3\u3002\u8bbe\u8ba1\u8005\u4e0d\u5f97\u4e0d\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u9002\u5e94\u6027\u4e4b\u95f4\u505a\u51fa\u59a5\u534f\u3002", "method": "\u63d0\u51faBAGEL\u6846\u67b6\uff0c\u91c7\u7528bootstrap\u805a\u5408\u548c\u4e13\u5bb6\u6df7\u5408\u601d\u60f3\u7684\u96c6\u6210\u65b9\u6cd5\u3002\u4f7f\u7528\u968f\u673a\u68ee\u6797\u8def\u7531\u5668\u9009\u62e9\u6700\u5408\u9002\u7684\u96c6\u6210\u6210\u5458\uff0c\u901a\u8fc7\u968f\u673a\u91c7\u6837\u989d\u5916\u6210\u5458\u8fdb\u884c\u9884\u6d4b\u805a\u5408\u3002\u652f\u6301\u589e\u91cf\u66f4\u65b0\uff1a\u5f53\u65b0\u653b\u51fb\u51fa\u73b0\u65f6\uff0c\u53ea\u9700\u5fae\u8c03\u5c0f\u578b\u63d0\u793a\u5b89\u5168\u5206\u7c7b\u5668\uff088600\u4e07\u53c2\u6570\uff09\u5e76\u6dfb\u52a0\u5230\u96c6\u6210\u4e2d\u3002", "result": "\u4ec5\u9009\u62e95\u4e2a\u96c6\u6210\u6210\u5458\uff084.3\u4ebf\u53c2\u6570\uff09\u5373\u53ef\u8fbe\u52300.92\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u9700\u8981\u6570\u5341\u4ebf\u53c2\u6570\u7684OpenAI Moderation API\u548cShieldGemma\u3002\u7ecf\u8fc79\u6b21\u589e\u91cf\u66f4\u65b0\u540e\u6027\u80fd\u4fdd\u6301\u7a33\u5065\uff0c\u5e76\u901a\u8fc7\u8def\u7531\u5668\u7684\u7ed3\u6784\u7279\u5f81\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5c0f\u578b\u5fae\u8c03\u5206\u7c7b\u5668\u7684\u96c6\u6210\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u6570\u5341\u4ebf\u53c2\u6570\u7684\u9632\u62a4\u7cfb\u7edf\uff0c\u540c\u65f6\u63d0\u4f9b\u751f\u4ea7\u7cfb\u7edf\u6240\u9700\u7684\u9002\u5e94\u6027\u548c\u6548\u7387\uff0c\u4e3aLLM\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.08063", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08063", "abs": "https://arxiv.org/abs/2602.08063", "authors": ["Eduardo Figueiredo", "Steven Adams", "Luca Laurenti"], "title": "Efficient Distribution Learning with Error Bounds in Wasserstein Distance", "comment": null, "summary": "The Wasserstein distance has emerged as a key metric to quantify distances between probability distributions, with applications in various fields, including machine learning, control theory, decision theory, and biological systems. Consequently, learning an unknown distribution with non-asymptotic and easy-to-compute error bounds in Wasserstein distance has become a fundamental problem in many fields. In this paper, we devise a novel algorithmic and theoretical framework to approximate an unknown probability distribution $\\mathbb{P}$ from a finite set of samples by an approximate discrete distribution $\\widehat{\\mathbb{P}}$ while bounding the Wasserstein distance between $\\mathbb{P}$ and $\\widehat{\\mathbb{P}}$. Our framework leverages optimal transport, nonlinear optimization, and concentration inequalities. In particular, we show that, even if $\\mathbb{P}$ is unknown, the Wasserstein distance between $\\mathbb{P}$ and $\\widehat{\\mathbb{P}}$ can be efficiently bounded with high confidence by solving a tractable optimization problem (a mixed integer linear program) of a size that only depends on the size of the support of $\\widehat{\\mathbb{P}}$. This enables us to develop intelligent clustering algorithms to optimally find the support of $\\widehat{\\mathbb{P}}$ while minimizing the Wasserstein distance error. On a set of benchmarks, we demonstrate that our approach outperforms state-of-the-art comparable methods by generally returning approximating distributions with substantially smaller support and tighter error bounds.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u9650\u6837\u672c\u8fd1\u4f3c\u672a\u77e5\u5206\u5e03\uff0c\u5e76\u7528\u4f18\u5316\u65b9\u6cd5\u9ad8\u6548\u8ba1\u7b97Wasserstein\u8ddd\u79bb\u7684\u7f6e\u4fe1\u4e0a\u754c\uff0c\u5f00\u53d1\u667a\u80fd\u805a\u7c7b\u7b97\u6cd5\u6700\u5c0f\u5316\u8bef\u5dee\u3002", "motivation": "Wasserstein\u8ddd\u79bb\u5df2\u6210\u4e3a\u91cf\u5316\u6982\u7387\u5206\u5e03\u95f4\u8ddd\u79bb\u7684\u5173\u952e\u6307\u6807\uff0c\u5728\u673a\u5668\u5b66\u4e60\u3001\u63a7\u5236\u7406\u8bba\u7b49\u591a\u4e2a\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002\u4ece\u6709\u9650\u6837\u672c\u4e2d\u5b66\u4e60\u672a\u77e5\u5206\u5e03\uff0c\u5e76\u63d0\u4f9b\u975e\u6e10\u8fd1\u4e14\u6613\u4e8e\u8ba1\u7b97\u7684Wasserstein\u8ddd\u79bb\u8bef\u5dee\u754c\uff0c\u662f\u8bb8\u591a\u9886\u57df\u7684\u57fa\u7840\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6700\u4f18\u4f20\u8f93\u3001\u975e\u7ebf\u6027\u4f18\u5316\u548c\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u5f00\u53d1\u65b0\u7b97\u6cd5\u7406\u8bba\u6846\u67b6\u3002\u901a\u8fc7\u6c42\u89e3\u89c4\u6a21\u4ec5\u4f9d\u8d56\u4e8e\u8fd1\u4f3c\u5206\u5e03\u652f\u6491\u96c6\u5927\u5c0f\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u9ad8\u6548\u8ba1\u7b97Wasserstein\u8ddd\u79bb\u7684\u9ad8\u7f6e\u4fe1\u4e0a\u754c\u3002\u5f00\u53d1\u667a\u80fd\u805a\u7c7b\u7b97\u6cd5\u4f18\u5316\u5bfb\u627e\u8fd1\u4f3c\u5206\u5e03\u7684\u652f\u6491\u96c6\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u53ef\u6bd4\u65b9\u6cd5\uff0c\u901a\u5e38\u8fd4\u56de\u652f\u6491\u96c6\u66f4\u5c0f\u3001\u8bef\u5dee\u754c\u66f4\u7d27\u7684\u8fd1\u4f3c\u5206\u5e03\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u6709\u9650\u6837\u672c\u6709\u6548\u8fd1\u4f3c\u672a\u77e5\u5206\u5e03\uff0c\u5e76\u63d0\u4f9bWasserstein\u8ddd\u79bb\u7684\u4e25\u683c\u8bef\u5dee\u754c\uff0c\u4e3a\u6982\u7387\u5206\u5e03\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.08067", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08067", "abs": "https://arxiv.org/abs/2602.08067", "authors": ["Chenglei Shen", "Yi Zhan", "Weijie Yu", "Xiao Zhang", "Jun Xu"], "title": "Enhancing Bandit Algorithms with LLMs for Time-varying User Preferences in Streaming Recommendations", "comment": null, "summary": "In real-world streaming recommender systems, user preferences evolve dynamically over time. Existing bandit-based methods treat time merely as a timestamp, neglecting its explicit relationship with user preferences and leading to suboptimal performance. Moreover, online learning methods often suffer from inefficient exploration-exploitation during the early online phase. To address these issues, we propose HyperBandit+, a novel contextual bandit policy that integrates a time-aware hypernetwork to adapt to time-varying user preferences and employs a large language model-assisted warm-start mechanism (LLM Start) to enhance exploration-exploitation efficiency in the early online phase. Specifically, HyperBandit+ leverages a neural network that takes time features as input and generates parameters for estimating time-varying rewards by capturing the correlation between time and user preferences. Additionally, the LLM Start mechanism employs multi-step data augmentation to simulate realistic interaction data for effective offline learning, providing warm-start parameters for the bandit policy in the early online phase. To meet real-time streaming recommendation demands, we adopt low-rank factorization to reduce hypernetwork training complexity. Theoretically, we rigorously establish a sublinear regret upper bound that accounts for both the hypernetwork and the LLM warm-start mechanism. Extensive experiments on real-world datasets demonstrate that HyperBandit+ consistently outperforms state-of-the-art baselines in terms of accumulated rewards.", "AI": {"tldr": "HyperBandit+\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b56\u7565\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u8d85\u7f51\u7edc\u9002\u5e94\u65f6\u53d8\u7528\u6237\u504f\u597d\uff0c\u5e76\u5229\u7528LLM\u8f85\u52a9\u7684\u9884\u70ed\u542f\u52a8\u673a\u5236\u63d0\u5347\u65e9\u671f\u5728\u7ebf\u9636\u6bb5\u7684\u63a2\u7d22-\u5229\u7528\u6548\u7387\uff0c\u5728\u6d41\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u6d41\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u7528\u6237\u504f\u597d\u968f\u65f6\u95f4\u52a8\u6001\u6f14\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u5c06\u65f6\u95f4\u4ec5\u89c6\u4e3a\u65f6\u95f4\u6233\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u4e0e\u7528\u6237\u504f\u597d\u7684\u663e\u5f0f\u5173\u7cfb\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u5728\u65e9\u671f\u5728\u7ebf\u9636\u6bb5\u5f80\u5f80\u5b58\u5728\u63a2\u7d22-\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHyperBandit+\uff1a1\uff09\u65f6\u95f4\u611f\u77e5\u8d85\u7f51\u7edc\uff1a\u4ee5\u65f6\u95f4\u7279\u5f81\u4e3a\u8f93\u5165\uff0c\u751f\u6210\u4f30\u8ba1\u65f6\u53d8\u5956\u52b1\u7684\u53c2\u6570\uff0c\u6355\u6349\u65f6\u95f4\u4e0e\u7528\u6237\u504f\u597d\u7684\u76f8\u5173\u6027\uff1b2\uff09LLM\u8f85\u52a9\u9884\u70ed\u542f\u52a8\u673a\u5236\uff1a\u901a\u8fc7\u591a\u6b65\u6570\u636e\u589e\u5f3a\u6a21\u62df\u771f\u5b9e\u4ea4\u4e92\u6570\u636e\u8fdb\u884c\u6709\u6548\u79bb\u7ebf\u5b66\u4e60\uff0c\u4e3a\u65e9\u671f\u5728\u7ebf\u9636\u6bb5\u63d0\u4f9b\u9884\u70ed\u53c2\u6570\uff1b3\uff09\u91c7\u7528\u4f4e\u79e9\u5206\u89e3\u964d\u4f4e\u8d85\u7f51\u7edc\u8bad\u7ec3\u590d\u6742\u5ea6\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u6d41\u5f0f\u63a8\u8350\u9700\u6c42\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHyperBandit+\u5728\u7d2f\u79ef\u5956\u52b1\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u8003\u8651\u8d85\u7f51\u7edc\u548cLLM\u9884\u70ed\u542f\u52a8\u673a\u5236\u7684\u6b21\u7ebf\u6027\u9057\u61be\u4e0a\u754c\u3002", "conclusion": "HyperBandit+\u901a\u8fc7\u6574\u5408\u65f6\u95f4\u611f\u77e5\u8d85\u7f51\u7edc\u548cLLM\u8f85\u52a9\u9884\u70ed\u542f\u52a8\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u65f6\u53d8\u7528\u6237\u504f\u597d\u5efa\u6a21\u548c\u65e9\u671f\u5728\u7ebf\u5b66\u4e60\u6548\u7387\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.08077", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08077", "abs": "https://arxiv.org/abs/2602.08077", "authors": ["Sayantan Kumar", "Peijie Qiu", "Aristeidis Sotiras"], "title": "Multimodal normative modeling in Alzheimers Disease with introspective variational autoencoders", "comment": "Conference on Health, Inference, and Learning (CHIL)", "summary": "Normative modeling learns a healthy reference distribution and quantifies subject-specific deviations to capture heterogeneous disease effects. In Alzheimers disease (AD), multimodal neuroimaging offers complementary signals but VAE-based normative models often (i) fit the healthy reference distribution imperfectly, inflating false positives, and (ii) use posterior aggregation (e.g., PoE/MoE) that can yield weak multimodal fusion in the shared latent space. We propose mmSIVAE, a multimodal soft-introspective variational autoencoder combined with Mixture-of-Product-of-Experts (MOPOE) aggregation to improve reference fidelity and multimodal integration. We compute deviation scores in latent space and feature space as distances from the learned healthy distributions, and map statistically significant latent deviations to regional abnormalities for interpretability. On ADNI MRI regional volumes and amyloid PET SUVR, mmSIVAE improves reconstruction on held-out controls and produces more discriminative deviation scores for outlier detection than VAE baselines, with higher likelihood ratios and clearer separation between control and AD-spectrum cohorts. Deviation maps highlight region-level patterns aligned with established AD-related changes. More broadly, our results highlight the importance of training objectives that prioritize reference-distribution fidelity and robust multimodal posterior aggregation for normative modeling, with implications for deviation-based analysis across multimodal clinical data.", "AI": {"tldr": "\u63d0\u51fammSIVAE\u6a21\u578b\uff0c\u7ed3\u5408\u8f6f\u81ea\u7701\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u4e13\u5bb6\u6df7\u5408\u805a\u5408\uff0c\u6539\u8fdb\u591a\u6a21\u6001\u795e\u7ecf\u5f71\u50cf\u7684\u89c4\u8303\u5efa\u6a21\uff0c\u63d0\u5347\u5065\u5eb7\u53c2\u8003\u5206\u5e03\u62df\u5408\u548c\u591a\u6a21\u6001\u878d\u5408\u80fd\u529b", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u591a\u6a21\u6001\u795e\u7ecf\u5f71\u50cf\u5206\u6790\u4e2d\uff0c\u73b0\u6709VAE\u89c4\u8303\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u5065\u5eb7\u53c2\u8003\u5206\u5e03\u62df\u5408\u4e0d\u5b8c\u5584\uff0c\u5bfc\u81f4\u5047\u9633\u6027\u589e\u52a0\uff1b2) \u540e\u9a8c\u805a\u5408\u65b9\u6cd5\uff08\u5982PoE/MoE\uff09\u5728\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u4e2d\u591a\u6a21\u6001\u878d\u5408\u6548\u679c\u5f31", "method": "\u63d0\u51fammSIVAE\uff08\u591a\u6a21\u6001\u8f6f\u81ea\u7701\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff09\uff0c\u7ed3\u5408Mixture-of-Product-of-Experts\uff08MOPOE\uff09\u805a\u5408\u673a\u5236\u3002\u5728\u6f5c\u5728\u7a7a\u95f4\u548c\u7279\u5f81\u7a7a\u95f4\u8ba1\u7b97\u4e0e\u5b66\u4e60\u5230\u7684\u5065\u5eb7\u5206\u5e03\u7684\u8ddd\u79bb\u4f5c\u4e3a\u504f\u5dee\u5206\u6570\uff0c\u5e76\u5c06\u7edf\u8ba1\u663e\u8457\u7684\u6f5c\u5728\u504f\u5dee\u6620\u5c04\u5230\u533a\u57df\u5f02\u5e38\u4ee5\u589e\u5f3a\u53ef\u89e3\u91ca\u6027", "result": "\u5728ADNI\u7684MRI\u533a\u57df\u4f53\u79ef\u548c\u6dc0\u7c89\u6837\u86cb\u767dPET SUVR\u6570\u636e\u4e0a\uff0cmmSIVAE\u5728\u4fdd\u7559\u5bf9\u7167\u7ec4\u4e0a\u6539\u5584\u91cd\u5efa\u6548\u679c\uff0c\u76f8\u6bd4VAE\u57fa\u7ebf\u4ea7\u751f\u66f4\u5177\u533a\u5206\u6027\u7684\u504f\u5dee\u5206\u6570\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u4f3c\u7136\u6bd4\u548c\u66f4\u6e05\u6670\u7684\u5bf9\u7167\u7ec4\u4e0eAD\u8c31\u7cfb\u961f\u5217\u5206\u79bb\u3002\u504f\u5dee\u56fe\u7a81\u51fa\u663e\u793a\u4e0e\u5df2\u77e5AD\u76f8\u5173\u53d8\u5316\u4e00\u81f4\u7684\u533a\u57df\u7ea7\u6a21\u5f0f", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8bad\u7ec3\u76ee\u6807\u4e2d\u4f18\u5148\u8003\u8651\u53c2\u8003\u5206\u5e03\u4fdd\u771f\u5ea6\u548c\u7a33\u5065\u591a\u6a21\u6001\u540e\u9a8c\u805a\u5408\u5bf9\u4e8e\u89c4\u8303\u5efa\u6a21\u7684\u91cd\u8981\u6027\uff0c\u5bf9\u8de8\u591a\u6a21\u6001\u4e34\u5e8a\u6570\u636e\u7684\u504f\u5dee\u5206\u6790\u5177\u6709\u5e7f\u6cdb\u610f\u4e49"}}
{"id": "2602.08082", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08082", "abs": "https://arxiv.org/abs/2602.08082", "authors": ["Valentin No\u00ebl"], "title": "Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology", "comment": "32 pages, 2 fgures, 18 tables", "summary": "Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\\% recall with multi-feature detection and 86.1\\% recall with 81.0\\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that single layer spectral features act as near-perfect hallucination detectors: Llama L26 Smoothness achieves 98.2\\% recall (213/217 hallucinations caught) with a single threshold, and Mistral L3 Entropy achieves 94.7\\% recall. This suggests hallucination is not merely a wrong token but a thermodynamic state change: the model's attention becomes noise when it errs. Through controlled cross-model evaluation on matched domains ($N=1000$, $T=0.3$, same General domain, hallucination rates 20--22\\%), we reveal the ``Loud Liar'' phenomenon: Llama 3.1 8B's failures are spectrally catastrophic and dramatically easier to detect, while Mistral 7B achieves the best discrimination (AUC 0.900). These findings establish spectral analysis as a principled, efficient framework for agent safety.", "AI": {"tldr": "\u57fa\u4e8e\u6ce8\u610f\u529b\u62d3\u6251\u8c31\u5206\u6790\u7684\u514d\u8bad\u7ec3\u62a4\u680f\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u548c\u5de5\u5177\u4f7f\u7528\u5931\u8d25\uff0c\u5355\u5c42\u8c31\u7279\u5f81\u5373\u53ef\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u5e7b\u89c9\u68c0\u6d4b\u3002", "motivation": "\u5728\u91ce\u5916\u90e8\u7f72\u81ea\u4e3b\u4ee3\u7406\u9700\u8981\u53ef\u9760\u7684\u4fdd\u969c\u673a\u5236\u6765\u9632\u6b62\u5de5\u5177\u4f7f\u7528\u5931\u8d25\uff0c\u73b0\u6709\u76d1\u7763\u65b9\u6cd5\u9700\u8981\u6807\u6ce8\u6570\u636e\u4e14\u53ef\u80fd\u4e0d\u591f\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u62d3\u6251\u8c31\u5206\u6790\u7684\u514d\u8bad\u7ec3\u62a4\u680f\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u6ce8\u610f\u529b\u5c42\u7684\u8c31\u7279\u5f81\uff08\u5982\u5e73\u6ed1\u5ea6\u548c\u71b5\uff09\u6765\u68c0\u6d4b\u5e7b\u89c9\u548c\u5de5\u5177\u4f7f\u7528\u5931\u8d25\uff0c\u65e0\u9700\u4efb\u4f55\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728Llama 3.1 8B\u4e0a\uff0c\u591a\u7279\u5f81\u68c0\u6d4b\u8fbe\u523097.7%\u53ec\u56de\u7387\uff0c\u5e73\u8861\u90e8\u7f72\u8fbe\u523086.1%\u53ec\u56de\u7387\u548c81.0%\u7cbe\u786e\u7387\uff1b\u5355\u5c42\u8c31\u7279\u5f81\u68c0\u6d4b\u5e7b\u89c9\u6548\u679c\u60ca\u4eba\uff1aLlama L26\u5e73\u6ed1\u5ea6\u8fbe\u523098.2%\u53ec\u56de\u7387\uff0cMistral L3\u71b5\u8fbe\u523094.7%\u53ec\u56de\u7387\u3002\u8de8\u6a21\u578b\u8bc4\u4f30\u53d1\u73b0\"\u5927\u58f0\u8bf4\u8c0e\u8005\"\u73b0\u8c61\uff1aLlama 3.1 8B\u7684\u5931\u8d25\u5728\u8c31\u5206\u6790\u4e2d\u8868\u73b0\u660e\u663e\uff0c\u800cMistral 7B\u5177\u6709\u6700\u4f73\u5224\u522b\u80fd\u529b\uff08AUC 0.900\uff09\u3002", "conclusion": "\u8c31\u5206\u6790\u4e3a\u4ee3\u7406\u5b89\u5168\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u8868\u660e\u5e7b\u89c9\u4e0d\u4ec5\u662f\u9519\u8bef\u6807\u8bb0\uff0c\u800c\u662f\u6a21\u578b\u6ce8\u610f\u529b\u53d8\u4e3a\u566a\u58f0\u7684\u70ed\u529b\u5b66\u72b6\u6001\u53d8\u5316\uff0c\u4e3a\u514d\u8bad\u7ec3\u5b89\u5168\u62a4\u680f\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.08086", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08086", "abs": "https://arxiv.org/abs/2602.08086", "authors": ["Liisa Janssens", "Laura Middeldorp"], "title": "Probability Hacking and the Design of Trustworthy ML for Signal Processing in C-UAS: A Scenario Based Method", "comment": "6 pages, Pre-publication. Copyright 2026 IEEE. Peer Reviewed. Accepted at ICASSP 2026 - 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 3-8 May 2026 in Barcelona, Spain", "summary": "In order to counter the various threats manifested by Unmanned Aircraft Systems (UAS) adequately, specialized Counter Unmanned Aircraft Systems (C-UAS) are required. Enhancing C-UAS with Emerging and Disruptive Technologies (EDTs) such as Artificial Intelligence (AI) can lead to more effective countermeasures. In this paper a scenario-based method is applied to C-UAS augmented with Machine Learning (ML), a subset of AI, that can enhance signal processing capabilities. Via the scenarios-based method we frame in this paper probability hacking as a challenge and identify requirements which can be implemented in existing Rule of Law mechanisms to prevent probability hacking. These requirements strengthen the trustworthiness of the C-UAS, which feed into justified trust - a key to successful Human-Autonomy Teaming, in civil and military contexts. Index Terms: C-UAS, Scenario-based method, Emerging and Disruptive Technologies, Probability hacking, Trustworthiness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u9632\u6b62C-UAS\u7cfb\u7edf\u4e2d\u7531\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u4fe1\u53f7\u5904\u7406\u80fd\u529b\u53ef\u80fd\u5f15\u53d1\u7684\u6982\u7387\u9ed1\u5ba2\u653b\u51fb\uff0c\u4ee5\u589e\u5f3a\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u5e76\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u7cfb\u7edf\u5a01\u80c1\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u53cd\u65e0\u4eba\u673a\u7cfb\u7edf\u3002\u5c06\u4eba\u5de5\u667a\u80fd\u7b49\u65b0\u5174\u98a0\u8986\u6027\u6280\u672f\u96c6\u6210\u5230C-UAS\u4e2d\u53ef\u4ee5\u63d0\u9ad8\u53cd\u5236\u80fd\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u4fe1\u53f7\u5904\u7406\u53ef\u80fd\u5f15\u53d1\u7684\u6982\u7387\u9ed1\u5ba2\u653b\u51fb\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\u6765\u5206\u6790\u673a\u5668\u5b66\u4e60\u589e\u5f3a\u7684C-UAS\u7cfb\u7edf\uff0c\u901a\u8fc7\u8be5\u65b9\u6cd5\u5c06\u6982\u7387\u9ed1\u5ba2\u653b\u51fb\u6846\u67b6\u5316\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5e76\u8bc6\u522b\u51fa\u53ef\u4ee5\u5728\u73b0\u6709\u6cd5\u6cbb\u673a\u5236\u4e2d\u5b9e\u65bd\u7684\u8981\u6c42\u6765\u9632\u6b62\u6b64\u7c7b\u653b\u51fb\u3002", "result": "\u901a\u8fc7\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u8bba\u6587\u8bc6\u522b\u4e86\u9632\u6b62\u6982\u7387\u9ed1\u5ba2\u653b\u51fb\u7684\u5177\u4f53\u8981\u6c42\uff0c\u8fd9\u4e9b\u8981\u6c42\u53ef\u4ee5\u96c6\u6210\u5230\u73b0\u6709\u6cd5\u6cbb\u6846\u67b6\u4e2d\uff0c\u4ece\u800c\u589e\u5f3aC-UAS\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u6210\u529f\u7684\u4eba\u673a\u534f\u4f5c\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u589e\u5f3aC-UAS\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u5bf9\u4e8e\u6c11\u7528\u548c\u519b\u4e8b\u73af\u5883\u4e2d\u6210\u529f\u7684\u4eba\u673a\u534f\u4f5c\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u57fa\u4e8e\u573a\u666f\u7684\u65b9\u6cd5\u8bc6\u522b\u548c\u9632\u6b62\u6982\u7387\u9ed1\u5ba2\u653b\u51fb\uff0c\u53ef\u4ee5\u5efa\u7acb\u5408\u7406\u7684\u4fe1\u4efb\u57fa\u7840\uff0c\u786e\u4fddAI\u589e\u5f3a\u7684\u53cd\u65e0\u4eba\u673a\u7cfb\u7edf\u65e2\u6709\u6548\u53c8\u53ef\u9760\u3002"}}
{"id": "2602.08088", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08088", "abs": "https://arxiv.org/abs/2602.08088", "authors": ["Mohammad Abu-Shaira", "Weishi Shi"], "title": "Online Domain-aware LLM Decoding for Continual Domain Evolution", "comment": null, "summary": "LLMs are typically fine-tuned offline on domain-specific data, assuming a static domain. In practice, domain knowledge evolves continuously through new regulations, products, services, and interaction patterns. Retraining or fine-tuning LLMs for every new instance is computationally infeasible. Additionally, real-world environments also exhibit temporal dynamics with shifting data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. This mismatch between evolving domains and static adaptation pipelines highlights the need for efficient, real-time adaptation without costly retraining. In response, we introduce Online Domain-aware Decoding framework (ODD). ODD performs probability-level fusion between a base LLM and a prefix-tree prior, guided by adaptive confidence modulation using disagreement and continuity signals. Empirical evaluation under diverse drift scenarios demonstrates that ODD consistently surpasses LLM-Greedy and LLM-Temp Scaled across all syntactic and semantic NLG metrics. It yields an absolute ROUGE-L gain of 0.065 and a 13.6% relative improvement in Cosine Similarity over the best baseline. These results demonstrate ODD 's robustness to evolving lexical and contextual patterns, making it suitable for dynamic LLM applications.", "AI": {"tldr": "ODD\u6846\u67b6\u901a\u8fc7\u5728\u7ebf\u6982\u7387\u878d\u5408\u548c\u81ea\u9002\u5e94\u7f6e\u4fe1\u5ea6\u8c03\u5236\uff0c\u4f7fLLM\u80fd\u591f\u5b9e\u65f6\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u65e0\u9700\u6602\u8d35\u91cd\u8bad\u7ec3", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u9886\u57df\u77e5\u8bc6\u6301\u7eed\u6f14\u53d8\uff08\u65b0\u6cd5\u89c4\u3001\u4ea7\u54c1\u3001\u670d\u52a1\u3001\u4ea4\u4e92\u6a21\u5f0f\uff09\uff0c\u800c\u4f20\u7edfLLM\u5fae\u8c03\u5047\u8bbe\u9759\u6001\u9886\u57df\uff0c\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\u3002\u540c\u65f6\u5b58\u5728\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\uff0c\u5ffd\u7565\u8fd9\u4e9b\u4f1a\u5bfc\u81f4\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u5728\u7ebf\u9886\u57df\u611f\u77e5\u89e3\u7801\u6846\u67b6\uff08ODD\uff09\uff0c\u5728\u57fa\u7840LLM\u548c\u524d\u7f00\u6811\u5148\u9a8c\u4e4b\u95f4\u8fdb\u884c\u6982\u7387\u7ea7\u878d\u5408\uff0c\u4f7f\u7528\u5206\u6b67\u548c\u8fde\u7eed\u6027\u4fe1\u53f7\u6307\u5bfc\u81ea\u9002\u5e94\u7f6e\u4fe1\u5ea6\u8c03\u5236\u3002", "result": "\u5728\u591a\u6837\u6f02\u79fb\u573a\u666f\u4e0b\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cODD\u5728\u6240\u6709\u53e5\u6cd5\u548c\u8bed\u4e49NLG\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8eLLM-Greedy\u548cLLM-Temp Scaled\uff0c\u83b7\u5f970.065\u7684\u7edd\u5bf9ROUGE-L\u589e\u76ca\u548c13.6%\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "ODD\u5bf9\u6f14\u53d8\u7684\u8bcd\u6c47\u548c\u4e0a\u4e0b\u6587\u6a21\u5f0f\u5177\u6709\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u52a8\u6001LLM\u5e94\u7528\uff0c\u89e3\u51b3\u4e86\u6f14\u5316\u9886\u57df\u4e0e\u9759\u6001\u9002\u5e94\u7ba1\u9053\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2602.08171", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.08171", "abs": "https://arxiv.org/abs/2602.08171", "authors": ["Cristian Minoccheri", "Sophia Tesic", "Kayvan Najarian", "Ryan Stidham"], "title": "A Causal Machine Learning Framework for Treatment Personalization in Clinical Trials: Application to Ulcerative Colitis", "comment": null, "summary": "Randomized controlled trials estimate average treatment effects, but treatment response heterogeneity motivates personalized approaches. A critical question is whether statistically detectable heterogeneity translates into improved treatment decisions -- these are distinct questions that can yield contradictory answers. We present a modular causal machine learning framework that evaluates each question separately: permutation importance identifies which features predict heterogeneity, best linear predictor (BLP) testing assesses statistical significance, and doubly robust policy evaluation measures whether acting on the heterogeneity improves patient outcomes. We apply this framework to patient-level data from the UNIFI maintenance trial of ustekinumab in ulcerative colitis, comparing placebo, standard-dose ustekinumab every 12 weeks, and dose-intensified ustekinumab every 8 weeks, using cross-fitted X-learner models with baseline demographics, medication history, week-8 clinical scores, laboratory biomarkers, and video-derived endoscopic features. BLP testing identified strong associations between endoscopic features and treatment effect heterogeneity for ustekinumab versus placebo, yet doubly robust policy evaluation showed no improvement in expected remission from incorporating endoscopic features, and out-of-fold multi-arm evaluation showed worse performance. Diagnostic comparison of prognostic contribution against policy value revealed that endoscopic scores behaved as disease severity markers -- improving outcome prediction in untreated patients but adding noise to treatment selection -- while clinical variables (fecal calprotectin, age, CRP) captured the decision-relevant variation. These results demonstrate that causal machine learning applications to clinical trials should include policy-level evaluation alongside heterogeneity testing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5206\u522b\u8bc4\u4f30\u6cbb\u7597\u6548\u679c\u5f02\u8d28\u6027\u7684\u7edf\u8ba1\u68c0\u6d4b\u4e0e\u4e34\u5e8a\u51b3\u7b56\u6539\u8fdb\uff0c\u5e94\u7528\u4e8e\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\u836f\u7269\u8bd5\u9a8c\uff0c\u53d1\u73b0\u5185\u955c\u7279\u5f81\u867d\u80fd\u9884\u6d4b\u5f02\u8d28\u6027\u4f46\u672a\u6539\u5584\u6cbb\u7597\u51b3\u7b56", "motivation": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u901a\u5e38\u4f30\u8ba1\u5e73\u5747\u6cbb\u7597\u6548\u679c\uff0c\u4f46\u6cbb\u7597\u53cd\u5e94\u5b58\u5728\u5f02\u8d28\u6027\u3002\u5173\u952e\u95ee\u9898\u662f\u7edf\u8ba1\u4e0a\u53ef\u68c0\u6d4b\u7684\u5f02\u8d28\u6027\u662f\u5426\u771f\u6b63\u80fd\u8f6c\u5316\u4e3a\u6539\u5584\u7684\u6cbb\u7597\u51b3\u7b56\u2014\u2014\u8fd9\u662f\u4e24\u4e2a\u4e0d\u540c\u4e14\u53ef\u80fd\u77db\u76fe\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u56e0\u679c\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff1a1) \u7f6e\u6362\u91cd\u8981\u6027\u8bc6\u522b\u9884\u6d4b\u5f02\u8d28\u6027\u7684\u7279\u5f81\uff1b2) BLP\u68c0\u9a8c\u8bc4\u4f30\u7edf\u8ba1\u663e\u8457\u6027\uff1b3) \u53cc\u91cd\u7a33\u5065\u7b56\u7565\u8bc4\u4f30\u8861\u91cf\u5229\u7528\u5f02\u8d28\u6027\u662f\u5426\u6539\u5584\u60a3\u8005\u7ed3\u5c40\u3002\u5e94\u7528\u4e8eUNIFI\u7ef4\u6301\u8bd5\u9a8c\u6570\u636e\uff0c\u4f7f\u7528\u4ea4\u53c9\u62df\u5408X-learner\u6a21\u578b\u5206\u6790\u57fa\u7ebf\u7279\u5f81\u3001\u5b9e\u9a8c\u5ba4\u6807\u5fd7\u7269\u548c\u5185\u955c\u7279\u5f81", "result": "BLP\u68c0\u9a8c\u53d1\u73b0\u5185\u955c\u7279\u5f81\u4e0e\u4e4c\u53f8\u5974\u5355\u6297vs\u5b89\u6170\u5242\u6cbb\u7597\u6548\u679c\u5f02\u8d28\u6027\u6709\u5f3a\u5173\u8054\uff0c\u4f46\u53cc\u91cd\u7a33\u5065\u7b56\u7565\u8bc4\u4f30\u663e\u793a\u7eb3\u5165\u5185\u955c\u7279\u5f81\u672a\u6539\u5584\u9884\u671f\u7f13\u89e3\u7387\uff0c\u591a\u81c2\u8bc4\u4f30\u8868\u73b0\u66f4\u5dee\u3002\u5185\u955c\u8bc4\u5206\u4f5c\u4e3a\u75be\u75c5\u4e25\u91cd\u7a0b\u5ea6\u6807\u5fd7\u7269\uff0c\u6539\u5584\u672a\u6cbb\u7597\u60a3\u8005\u7ed3\u5c40\u9884\u6d4b\u4f46\u589e\u52a0\u6cbb\u7597\u9009\u62e9\u566a\u58f0\uff1b\u4e34\u5e8a\u53d8\u91cf\uff08\u7caa\u4fbf\u9499\u536b\u86cb\u767d\u3001\u5e74\u9f84\u3001CRP\uff09\u6355\u6349\u51b3\u7b56\u76f8\u5173\u53d8\u5f02", "conclusion": "\u56e0\u679c\u673a\u5668\u5b66\u4e60\u5728\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u7684\u5e94\u7528\u5e94\u5305\u62ec\u7b56\u7565\u5c42\u9762\u8bc4\u4f30\u4e0e\u5f02\u8d28\u6027\u68c0\u9a8c\uff0c\u7edf\u8ba1\u4e0a\u663e\u8457\u7684\u5f02\u8d28\u6027\u4e0d\u4e00\u5b9a\u8f6c\u5316\u4e3a\u4e34\u5e8a\u51b3\u7b56\u6539\u8fdb\uff0c\u9700\u8981\u533a\u5206\u9884\u6d4b\u5f02\u8d28\u6027\u7684\u7279\u5f81\u4e0e\u6539\u5584\u6cbb\u7597\u9009\u62e9\u7684\u7279\u5f81"}}
{"id": "2602.08215", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.08215", "abs": "https://arxiv.org/abs/2602.08215", "authors": ["Yash Patel", "Ambuj Tewari"], "title": "Distribution-Free Robust Functional Predict-Then-Optimize", "comment": null, "summary": "The solution of PDEs in decision-making tasks is increasingly being undertaken with the help of neural operator surrogate models due to the need for repeated evaluation. Such methods, while significantly more computationally favorable compared to their numerical counterparts, fail to provide any calibrated notions of uncertainty in their predictions. Current methods approach this deficiency typically with ensembling or Bayesian posterior estimation. However, these approaches either require distributional assumptions that fail to hold in practice or lack practical scalability, limiting their applications in practice. We, therefore, propose a novel application of conformal prediction to produce distribution-free uncertainty quantification over the function spaces mapped by neural operators. We then demonstrate how such prediction regions enable a formal regret characterization if leveraged in downstream robust decision-making tasks. We further demonstrate how such posited robust decision-making tasks can be efficiently solved using an infinite-dimensional generalization of Danskin's Theorem and calculus of variations and empirically demonstrate the superior performance of our proposed method over more restrictive modeling paradigms, such as Gaussian Processes, across several engineering tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u795e\u7ecf\u7b97\u5b50\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8ePDE\u6c42\u89e3\u4e2d\u7684\u51b3\u7b56\u4efb\u52a1\uff0c\u65e0\u9700\u5206\u5e03\u5047\u8bbe\u4e14\u53ef\u6269\u5c55\u5230\u51fd\u6570\u7a7a\u95f4\u3002", "motivation": "\u795e\u7ecf\u7b97\u5b50\u4f5c\u4e3aPDE\u6c42\u89e3\u7684\u4ee3\u7406\u6a21\u578b\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u5e94\u7528\u589e\u591a\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u4e0d\u5207\u5b9e\u9645\u7684\u5206\u5e03\u5047\u8bbe\uff0c\u8981\u4e48\u7f3a\u4e4f\u5b9e\u9645\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5c06\u4fdd\u5f62\u9884\u6d4b\u5e94\u7528\u4e8e\u795e\u7ecf\u7b97\u5b50\uff0c\u5728\u51fd\u6570\u7a7a\u95f4\u4e0a\u5b9e\u73b0\u5206\u5e03\u65e0\u5173\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u5229\u7528\u65e0\u9650\u7ef4Danskin\u5b9a\u7406\u548c\u53d8\u5206\u6cd5\u89e3\u51b3\u4e0b\u6e38\u9c81\u68d2\u51b3\u7b56\u4efb\u52a1\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7b49\u9650\u5236\u6027\u5efa\u6a21\u8303\u5f0f\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u9057\u61be\u8868\u5f81\u3002", "conclusion": "\u63d0\u51fa\u7684\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b97\u5b50\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u3001\u5206\u5e03\u65e0\u5173\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u652f\u6301\u9c81\u68d2\u51b3\u7b56\u4efb\u52a1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08218", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08218", "abs": "https://arxiv.org/abs/2602.08218", "authors": ["Huan Zhang", "Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Bang Liu"], "title": "Sparsity-Aware Evolution for Model Merging", "comment": null, "summary": "We propose a sparsity-aware evolutionary (SAE) framework for model merging that involves iterative pruning-merging cycles to act as a novel mutation operator. We incorporate the sparsity constraints into the score function, which steers the evolutionary process to favor more sparse models, in addition to other conventional performance scores. Interestingly, the by-product of \\textit{competition} for sparsity introduces an extra local \\textit{attraction} and interplay into the evolutionary process: if one competitor has more zero elements, the other competitor's non-zero elements will occupy those positions, even though the less sparse competitor loses to the more sparse competitor in other positions. The proposed pipeline is evaluated on a variety of large-scale LLM benchmarks. Experiments demonstrate that our approach can improve model merging reliability across multiple benchmarks, and is easy to incorporate due to its simplicity and being orthogonal to most existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u611f\u77e5\u8fdb\u5316\u7684\u6a21\u578b\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u526a\u679d-\u878d\u5408\u5faa\u73af\u4f5c\u4e3a\u65b0\u578b\u53d8\u5f02\u7b97\u5b50\uff0c\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7a00\u758f\u6027\u7ea6\u675f\uff0c\u63d0\u9ad8\u6a21\u578b\u878d\u5408\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u6a21\u578b\u6027\u80fd\u548c\u7a00\u758f\u6027\u7684\u878d\u5408\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u878d\u5408\u7ed3\u679c\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u7a00\u758f\u611f\u77e5\u8fdb\u5316\u6846\u67b6\uff0c\u5305\u542b\u8fed\u4ee3\u7684\u526a\u679d-\u878d\u5408\u5faa\u73af\u4f5c\u4e3a\u53d8\u5f02\u7b97\u5b50\uff0c\u5c06\u7a00\u758f\u7ea6\u675f\u7eb3\u5165\u8bc4\u5206\u51fd\u6570\uff0c\u5f15\u5bfc\u8fdb\u5316\u8fc7\u7a0b\u504f\u597d\u7a00\u758f\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u6027\u80fd\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2a\u5927\u89c4\u6a21LLM\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u6a21\u578b\u878d\u5408\u7684\u53ef\u9760\u6027\uff0c\u4e14\u56e0\u5176\u7b80\u5355\u6027\u548c\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u6b63\u4ea4\u6027\u6613\u4e8e\u96c6\u6210\u3002", "conclusion": "\u7a00\u758f\u611f\u77e5\u8fdb\u5316\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u7a00\u758f\u6027\u7ea6\u675f\u548c\u7ade\u4e89\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u878d\u5408\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u6a21\u578b\u878d\u5408\u63d0\u4f9b\u4e86\u65b0\u9896\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08234", "abs": "https://arxiv.org/abs/2602.08234", "authors": ["Peng Xia", "Jianwen Chen", "Hanyang Wang", "Jiaqi Liu", "Kaide Zeng", "Yu Wang", "Siwei Han", "Yiyang Zhou", "Xujiang Zhao", "Haifeng Chen", "Zeyu Zheng", "Cihang Xie", "Huaxiu Yao"], "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning", "comment": null, "summary": "Large Language Model (LLM) agents have shown stunning results in complex tasks, yet they often operate in isolation, failing to learn from past experiences. Existing memory-based methods primarily store raw trajectories, which are often redundant and noise-heavy. This prevents agents from extracting high-level, reusable behavioral patterns that are essential for generalization. In this paper, we propose SkillRL, a framework that bridges the gap between raw experience and policy improvement through automatic skill discovery and recursive evolution. Our approach introduces an experience-based distillation mechanism to build a hierarchical skill library SkillBank, an adaptive retrieval strategy for general and task-specific heuristics, and a recursive evolution mechanism that allows the skill library to co-evolve with the agent's policy during reinforcement learning. These innovations significantly reduce the token footprint while enhancing reasoning utility. Experimental results on ALFWorld, WebShop and seven search-augmented tasks demonstrate that SkillRL achieves state-of-the-art performance, outperforming strong baselines over 15.3% and maintaining robustness as task complexity increases. Code is available at this https://github.com/aiming-lab/SkillRL.", "AI": {"tldr": "SkillRL\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u6280\u80fd\u53d1\u73b0\u548c\u9012\u5f52\u8fdb\u5316\uff0c\u5c06\u539f\u59cb\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u53ef\u91cd\u7528\u6280\u80fd\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bb0\u5fc6\u7684\u65b9\u6cd5\u4e3b\u8981\u5b58\u50a8\u539f\u59cb\u8f68\u8ff9\uff0c\u8fd9\u4e9b\u8f68\u8ff9\u5197\u4f59\u4e14\u566a\u58f0\u591a\uff0c\u65e0\u6cd5\u63d0\u53d6\u9ad8\u7ea7\u53ef\u91cd\u7528\u884c\u4e3a\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u6cdb\u5316\u80fd\u529b", "method": "\u63d0\u51faSkillRL\u6846\u67b6\uff1a1) \u57fa\u4e8e\u7ecf\u9a8c\u7684\u84b8\u998f\u673a\u5236\u6784\u5efa\u5206\u5c42\u6280\u80fd\u5e93SkillBank\uff1b2) \u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u83b7\u53d6\u901a\u7528\u548c\u4efb\u52a1\u7279\u5b9a\u542f\u53d1\u5f0f\uff1b3) \u9012\u5f52\u8fdb\u5316\u673a\u5236\u4f7f\u6280\u80fd\u5e93\u4e0e\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u534f\u540c\u8fdb\u5316", "result": "\u5728ALFWorld\u3001WebShop\u548c\u4e03\u4e2a\u641c\u7d22\u589e\u5f3a\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u8d85\u8d8a\u5f3a\u57fa\u7ebf15.3%\uff0c\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u663e\u8457\u51cf\u5c11token\u5360\u7528\u540c\u65f6\u589e\u5f3a\u63a8\u7406\u6548\u7528", "conclusion": "SkillRL\u901a\u8fc7\u5c06\u539f\u59cb\u7ecf\u9a8c\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u6280\u80fd\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u4f53\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f"}}
{"id": "2602.08239", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08239", "abs": "https://arxiv.org/abs/2602.08239", "authors": ["Zahra Rahimi Afzal", "Tara Esmaeilbeig", "Mojtaba Soltanalian", "Mesrob I. Ohannessian"], "title": "Linearization Explains Fine-Tuning in Large Language Models", "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) is a popular class of techniques that strive to adapt large models in a scalable and resource-efficient manner. Yet, the mechanisms underlying their training performance and generalization remain underexplored. In this paper, we provide several insights into such fine-tuning through the lens of linearization. Fine-tuned models are often implicitly encouraged to remain close to the pretrained model. By making this explicit, using an Euclidean distance inductive bias in parameter space, we show that fine-tuning dynamics become equivalent to learning with the positive-definite neural tangent kernel (NTK). We specifically analyze how close the fully linear and the linearized fine-tuning optimizations are, based on the strength of the regularization. This allows us to be pragmatic about how good a model linearization is when fine-tuning large language models (LLMs). When linearization is a good model, our findings reveal a strong correlation between the eigenvalue spectrum of the NTK and the performance of model adaptation. Motivated by this, we give spectral perturbation bounds on the NTK induced by the choice of layers selected for fine-tuning. We empirically validate our theory on Low Rank Adaptation (LoRA) on LLMs. These insights not only characterize fine-tuning but also have the potential to enhance PEFT techniques, paving the way to better informed and more nimble adaptation in LLMs.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u7ebf\u6027\u5316\u89c6\u89d2\u5206\u6790\u53c2\u6570\u9ad8\u6548\u5fae\u8c03(PEFT)\u673a\u5236\uff0c\u53d1\u73b0\u5fae\u8c03\u52a8\u6001\u7b49\u4ef7\u4e8e\u4f7f\u7528\u795e\u7ecf\u6b63\u5207\u6838(NTK)\u5b66\u4e60\uff0c\u5e76\u63ed\u793aNTK\u7279\u5f81\u8c31\u4e0e\u6a21\u578b\u9002\u5e94\u6027\u80fd\u7684\u5f3a\u76f8\u5173\u6027\u3002", "motivation": "PEFT\u6280\u672f\u867d\u7136\u6d41\u884c\uff0c\u4f46\u5176\u8bad\u7ec3\u6027\u80fd\u548c\u6cdb\u5316\u673a\u5236\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u7ebf\u6027\u5316\u89c6\u89d2\u6df1\u5165\u7406\u89e3\u5fae\u8c03\u8fc7\u7a0b\u7684\u5185\u5728\u673a\u5236\u3002", "method": "1. \u901a\u8fc7\u53c2\u6570\u7a7a\u95f4\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u663e\u5f0f\u7ea6\u675f\u5fae\u8c03\u6a21\u578b\u63a5\u8fd1\u9884\u8bad\u7ec3\u6a21\u578b\uff1b2. \u8bc1\u660e\u5fae\u8c03\u52a8\u6001\u7b49\u4ef7\u4e8e\u4f7f\u7528\u6b63\u5b9aNTK\u5b66\u4e60\uff1b3. \u57fa\u4e8e\u6b63\u5219\u5316\u5f3a\u5ea6\u5206\u6790\u5b8c\u5168\u7ebf\u6027\u4e0e\u7ebf\u6027\u5316\u5fae\u8c03\u7684\u63a5\u8fd1\u7a0b\u5ea6\uff1b4. \u7ed9\u51faNTK\u7279\u5f81\u8c31\u6270\u52a8\u8fb9\u754c\uff1b5. \u5728LLMs\u4e0a\u901a\u8fc7LoRA\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "1. \u5fae\u8c03\u52a8\u6001\u53ef\u5efa\u6a21\u4e3aNTK\u5b66\u4e60\uff1b2. NTK\u7279\u5f81\u8c31\u4e0e\u6a21\u578b\u9002\u5e94\u6027\u80fd\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff1b3. \u4e0d\u540c\u5c42\u9009\u62e9\u5bf9NTK\u7279\u5f81\u8c31\u4ea7\u751f\u53ef\u91cf\u5316\u7684\u6270\u52a8\uff1b4. \u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u7406\u8bba\u5728LoRA\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ebf\u6027\u5316\u89c6\u89d2\u4e3a\u7406\u89e3PEFT\u673a\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0cNTK\u7279\u5f81\u8c31\u5206\u6790\u6709\u52a9\u4e8e\u4f18\u5316\u5fae\u8c03\u5c42\u9009\u62e9\uff0c\u4e3a\u5f00\u53d1\u66f4\u667a\u80fd\u7684LLM\u9002\u5e94\u6280\u672f\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2602.08244", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08244", "abs": "https://arxiv.org/abs/2602.08244", "authors": ["Juncheng Dong", "Bowen He", "Moyang Guo", "Ethan X. Fang", "Zhuoran Yang", "Vahid Tarokh"], "title": "Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers", "comment": null, "summary": "In-context reinforcement learning (ICRL) leverages the in-context learning capabilities of transformer models (TMs) to efficiently generalize to unseen sequential decision-making tasks without parameter updates. However, existing ICRL methods rely on explicit reward signals during pretraining, which limits their applicability when rewards are ambiguous, hard to specify, or costly to obtain. To overcome this limitation, we propose a new learning paradigm, In-Context Preference-based Reinforcement Learning (ICPRL), in which both pretraining and deployment rely solely on preference feedback, eliminating the need for reward supervision. We study two variants that differ in the granularity of feedback: Immediate Preference-based RL (I-PRL) with per-step preferences, and Trajectory Preference-based RL (T-PRL) with trajectory-level comparisons. We first show that supervised pretraining, a standard approach in ICRL, remains effective under preference-only context datasets, demonstrating the feasibility of in-context reinforcement learning using only preference signals. To further improve data efficiency, we introduce alternative preference-native frameworks for I-PRL and T-PRL that directly optimize TM policies from preference data without requiring reward signals nor optimal action labels.Experiments on dueling bandits, navigation, and continuous control tasks demonstrate that ICPRL enables strong in-context generalization to unseen tasks, achieving performance comparable to ICRL methods trained with full reward supervision.", "AI": {"tldr": "\u63d0\u51faICPRL\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u504f\u597d\u53cd\u9988\u5b9e\u73b0\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\uff0c\u65e0\u9700\u5956\u52b1\u76d1\u7763\uff0c\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e0e\u5956\u52b1\u76d1\u7763\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u660e\u786e\u7684\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u4f46\u5728\u5956\u52b1\u6a21\u7cca\u3001\u96be\u4ee5\u6307\u5b9a\u6216\u83b7\u53d6\u6210\u672c\u9ad8\u7684\u60c5\u51b5\u4e0b\u9002\u7528\u6027\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u4ec5\u4f7f\u7528\u504f\u597d\u53cd\u9988\u5c31\u80fd\u5b66\u4e60\u548c\u6cdb\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faICPRL\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u53d8\u4f53\uff1a\u57fa\u4e8e\u6bcf\u6b65\u504f\u597d\u7684I-PRL\u548c\u57fa\u4e8e\u8f68\u8ff9\u7ea7\u6bd4\u8f83\u7684T-PRL\u3002\u91c7\u7528\u76d1\u7763\u9884\u8bad\u7ec3\u548c\u504f\u597d\u539f\u751f\u6846\u67b6\u4e24\u79cd\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u504f\u597d\u6570\u636e\u4f18\u5316\u7b56\u7565\uff0c\u65e0\u9700\u5956\u52b1\u4fe1\u53f7\u6216\u6700\u4f18\u52a8\u4f5c\u6807\u7b7e\u3002", "result": "\u5728\u51b3\u6597\u8001\u864e\u673a\u3001\u5bfc\u822a\u548c\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cICPRL\u80fd\u591f\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u5b9e\u73b0\u5f3a\u5927\u7684\u4e0a\u4e0b\u6587\u6cdb\u5316\uff0c\u6027\u80fd\u4e0e\u4f7f\u7528\u5b8c\u6574\u5956\u52b1\u76d1\u7763\u7684ICRL\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "ICPRL\u8bc1\u660e\u4e86\u4ec5\u4f7f\u7528\u504f\u597d\u53cd\u9988\u5c31\u80fd\u5b9e\u73b0\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\uff0c\u4e3a\u5956\u52b1\u4fe1\u53f7\u96be\u4ee5\u83b7\u53d6\u7684\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08261", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.08261", "abs": "https://arxiv.org/abs/2602.08261", "authors": ["Binglin Wu", "Yingyi Zhang", "Xianneng Li", "Ruyue Deng", "Chuan Yue", "Weiru Zhang", "Xiaoyi Zeng"], "title": "Constraint-Aware Generative Auto-bidding via Pareto-Prioritized Regret Optimization", "comment": null, "summary": "Auto-bidding systems aim to maximize marketing value while satisfying strict efficiency constraints such as Target Cost-Per-Action (CPA). Although Decision Transformers provide powerful sequence modeling capabilities, applying them to this constrained setting encounters two challenges: 1) standard Return-to-Go conditioning causes state aliasing by neglecting the cost dimension, preventing precise resource pacing; and 2) standard regression forces the policy to mimic average historical behaviors, thereby limiting the capacity to optimize performance toward the constraint boundary. To address these challenges, we propose PRO-Bid, a constraint-aware generative auto-bidding framework based on two synergistic mechanisms: 1) Constraint-Decoupled Pareto Representation (CDPR) decomposes global constraints into recursive cost and value contexts to restore resource perception, while reweighting trajectories based on the Pareto frontier to focus on high-efficiency data; and 2) Counterfactual Regret Optimization (CRO) facilitates active improvement by utilizing a global outcome predictor to identify superior counterfactual actions. By treating these high-utility outcomes as weighted regression targets, the model transcends historical averages to approach the optimal constraint boundary. Extensive experiments on two public benchmarks and online A/B tests demonstrate that PRO-Bid achieves superior constraint satisfaction and value acquisition compared to state-of-the-art baselines.", "AI": {"tldr": "PRO-Bid\u662f\u4e00\u4e2a\u57fa\u4e8e\u51b3\u7b56\u53d8\u6362\u5668\u7684\u7ea6\u675f\u611f\u77e5\u81ea\u52a8\u7ade\u4ef7\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u89e3\u8026\u5e15\u7d2f\u6258\u8868\u793a\u548c\u53cd\u4e8b\u5b9e\u9057\u61be\u4f18\u5316\u673a\u5236\uff0c\u5728\u6ee1\u8db3\u6210\u672c\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5927\u5316\u8425\u9500\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u53d8\u6362\u5668\u5728\u7ea6\u675f\u81ea\u52a8\u7ade\u4ef7\u573a\u666f\u4e2d\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1\uff09\u6807\u51c6Return-to-Go\u6761\u4ef6\u5ffd\u7565\u6210\u672c\u7ef4\u5ea6\u5bfc\u81f4\u72b6\u6001\u6df7\u53e0\uff0c\u65e0\u6cd5\u7cbe\u786e\u63a7\u5236\u8d44\u6e90\u5206\u914d\uff1b2\uff09\u6807\u51c6\u56de\u5f52\u8feb\u4f7f\u7b56\u7565\u6a21\u4eff\u5386\u53f2\u5e73\u5747\u884c\u4e3a\uff0c\u9650\u5236\u4e86\u5411\u7ea6\u675f\u8fb9\u754c\u4f18\u5316\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faPRO-Bid\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u673a\u5236\uff1a1\uff09\u7ea6\u675f\u89e3\u8026\u5e15\u7d2f\u6258\u8868\u793a\uff08CDPR\uff09\u5c06\u5168\u5c40\u7ea6\u675f\u5206\u89e3\u4e3a\u9012\u5f52\u6210\u672c\u548c\u4ef7\u503c\u4e0a\u4e0b\u6587\uff0c\u6062\u590d\u8d44\u6e90\u611f\u77e5\uff0c\u5e76\u57fa\u4e8e\u5e15\u7d2f\u6258\u524d\u6cbf\u91cd\u52a0\u6743\u8f68\u8ff9\u4ee5\u805a\u7126\u9ad8\u6548\u6570\u636e\uff1b2\uff09\u53cd\u4e8b\u5b9e\u9057\u61be\u4f18\u5316\uff08CRO\uff09\u5229\u7528\u5168\u5c40\u7ed3\u679c\u9884\u6d4b\u5668\u8bc6\u522b\u66f4\u4f18\u7684\u53cd\u4e8b\u5b9e\u52a8\u4f5c\uff0c\u5c06\u8fd9\u4e9b\u9ad8\u6548\u7528\u7ed3\u679c\u4f5c\u4e3a\u52a0\u6743\u56de\u5f52\u76ee\u6807\uff0c\u4f7f\u6a21\u578b\u8d85\u8d8a\u5386\u53f2\u5e73\u5747\u503c\u63a5\u8fd1\u6700\u4f18\u7ea6\u675f\u8fb9\u754c\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0cPRO-Bid\u5728\u7ea6\u675f\u6ee1\u8db3\u548c\u4ef7\u503c\u83b7\u53d6\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PRO-Bid\u901a\u8fc7\u521b\u65b0\u7684\u7ea6\u675f\u611f\u77e5\u751f\u6210\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u51b3\u7b56\u53d8\u6362\u5668\u5728\u7ea6\u675f\u81ea\u52a8\u7ade\u4ef7\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u7ea6\u675f\u6ee1\u8db3\u548c\u6027\u80fd\u4f18\u5316\u3002"}}
{"id": "2602.08267", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08267", "abs": "https://arxiv.org/abs/2602.08267", "authors": ["Jinwoo Kim", "S\u00e9kou-Oumar Kaba", "Jiyun Park", "Seunghoon Hong", "Siamak Ravanbakhsh"], "title": "Inverting Data Transformations via Diffusion Sampling", "comment": "24 pages, 4 figures", "summary": "We study the problem of transformation inversion on general Lie groups: a datum is transformed by an unknown group element, and the goal is to recover an inverse transformation that maps it back to the original data distribution. Such unknown transformations arise widely in machine learning and scientific modeling, where they can significantly distort observations. We take a probabilistic view and model the posterior over transformations as a Boltzmann distribution defined by an energy function on data space. To sample from this posterior, we introduce a diffusion process on Lie groups that keeps all updates on-manifold and only requires computations in the associated Lie algebra. Our method, Transformation-Inverting Energy Diffusion (TIED), relies on a new trivialized target-score identity that enables efficient score-based sampling of the transformation posterior. As a key application, we focus on test-time equivariance, where the objective is to improve the robustness of pretrained neural networks to input transformations. Experiments on image homographies and PDE symmetries demonstrate that TIED can restore transformed inputs to the training distribution at test time, showing improved performance over strong canonicalization and sampling baselines. Code is available at https://github.com/jw9730/tied.", "AI": {"tldr": "\u63d0\u51faTIED\u65b9\u6cd5\uff0c\u901a\u8fc7\u674e\u7fa4\u4e0a\u7684\u6269\u6563\u8fc7\u7a0b\u53cd\u6f14\u672a\u77e5\u53d8\u6362\uff0c\u7528\u4e8e\u63d0\u5347\u9884\u8bad\u7ec3\u7f51\u7edc\u5bf9\u8f93\u5165\u53d8\u6362\u7684\u9c81\u68d2\u6027", "motivation": "\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u9047\u5230\u6570\u636e\u88ab\u672a\u77e5\u53d8\u6362\u626d\u66f2\u7684\u95ee\u9898\uff0c\u9700\u8981\u6062\u590d\u539f\u59cb\u6570\u636e\u5206\u5e03\u3002\u7279\u522b\u662f\u5728\u6d4b\u8bd5\u65f6\u7b49\u53d8\u6027\u573a\u666f\u4e2d\uff0c\u9700\u8981\u63d0\u5347\u9884\u8bad\u7ec3\u7f51\u7edc\u5bf9\u8f93\u5165\u53d8\u6362\u7684\u9c81\u68d2\u6027", "method": "\u91c7\u7528\u6982\u7387\u89c6\u89d2\uff0c\u5c06\u53d8\u6362\u540e\u9a8c\u5efa\u6a21\u4e3a\u73bb\u5c14\u5179\u66fc\u5206\u5e03\uff0c\u5f15\u5165\u674e\u7fa4\u4e0a\u7684\u6269\u6563\u8fc7\u7a0b\u8fdb\u884c\u91c7\u6837\uff0c\u63d0\u51fa\u65b0\u7684\u5e73\u51e1\u5316\u76ee\u6807-\u5f97\u5206\u6052\u7b49\u5f0f\u5b9e\u73b0\u9ad8\u6548\u5f97\u5206\u91c7\u6837", "result": "\u5728\u56fe\u50cf\u5355\u5e94\u6027\u548cPDE\u5bf9\u79f0\u6027\u5b9e\u9a8c\u4e2d\uff0cTIED\u80fd\u5c06\u53d8\u6362\u540e\u7684\u8f93\u5165\u6062\u590d\u5230\u8bad\u7ec3\u5206\u5e03\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6b63\u5219\u5316\u548c\u91c7\u6837\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "TIED\u65b9\u6cd5\u80fd\u6709\u6548\u53cd\u6f14\u672a\u77e5\u53d8\u6362\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u7b49\u53d8\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08272", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08272", "abs": "https://arxiv.org/abs/2602.08272", "authors": ["Junwei Su", "Chuan Wu"], "title": "When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems", "comment": null, "summary": "Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particular, offers a promising avenue by decomposing complex tasks into specialized subtasks learned by distinct interacting agents, potentially enhancing the ability and efficiency of LLM systems. However, theoretical insights regarding when and why MARL outperforms Single-Agent RL (SARL) remain limited, creating uncertainty in selecting the appropriate RL framework. In this paper, we address this critical gap by rigorously analyzing the comparative sample efficiency of MARL and SARL within the context of LLM. Leveraging the Probably Approximately Correct (PAC) framework, we formally define SARL and MARL setups for LLMs, derive explicit sample complexity bounds, and systematically characterize how task decomposition and alignment influence learning efficiency. Our results demonstrate that MARL improves sample complexity when tasks naturally decompose into independent subtasks, whereas dependent subtasks diminish MARL's comparative advantage. Additionally, we introduce and analyze the concept of task alignment, quantifying the trade-offs when enforcing independent task decomposition despite potential misalignments. These theoretical insights clarify empirical inconsistencies and provide practical criteria for deploying MARL strategies effectively in complex LLM scenarios.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7PAC\u6846\u67b6\u7406\u8bba\u5206\u6790MARL\u4e0eSARL\u5728LLM\u8bad\u7ec3\u4e2d\u7684\u6837\u672c\u6548\u7387\uff0c\u53d1\u73b0\u4efb\u52a1\u53ef\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u4efb\u52a1\u65f6MARL\u66f4\u4f18\uff0c\u5b50\u4efb\u52a1\u4f9d\u8d56\u65f6\u4f18\u52bf\u51cf\u5f31\uff0c\u5e76\u5f15\u5165\u4efb\u52a1\u5bf9\u9f50\u6982\u5ff5\u91cf\u5316\u5206\u89e3\u4e0e\u5bf9\u9f50\u7684\u6743\u8861\u3002", "motivation": "\u5c3d\u7ba1MARL\u5728LLM\u8bad\u7ec3\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\u4f55\u65f6\u9009\u62e9MARL\u800c\u975eSARL\u3002\u73b0\u6709\u7814\u7a76\u5bf9MARL\u4f55\u65f6\u3001\u4e3a\u4f55\u4f18\u4e8eSARL\u7684\u7406\u8bba\u8ba4\u8bc6\u6709\u9650\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u4e2d\u6846\u67b6\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u6982\u7387\u8fd1\u4f3c\u6b63\u786e(PAC)\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49LLM\u7684SARL\u548cMARL\u8bbe\u7f6e\uff0c\u63a8\u5bfc\u663e\u5f0f\u6837\u672c\u590d\u6742\u5ea6\u8fb9\u754c\uff0c\u7cfb\u7edf\u5206\u6790\u4efb\u52a1\u5206\u89e3\u548c\u5bf9\u9f50\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u6548\u7387\uff0c\u5e76\u5f15\u5165\u4efb\u52a1\u5bf9\u9f50\u6982\u5ff5\u91cf\u5316\u6743\u8861\u3002", "result": "MARL\u5728\u4efb\u52a1\u53ef\u81ea\u7136\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u4efb\u52a1\u65f6\u80fd\u6539\u5584\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4f46\u5b50\u4efb\u52a1\u4f9d\u8d56\u4f1a\u524a\u5f31MARL\u7684\u6bd4\u8f83\u4f18\u52bf\u3002\u4efb\u52a1\u5bf9\u9f50\u5206\u6790\u63ed\u793a\u4e86\u5f3a\u5236\u72ec\u7acb\u5206\u89e3\u4e0e\u6f5c\u5728\u9519\u914d\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u6f84\u6e05\u4e86\u5b9e\u8bc1\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3a\u590d\u6742LLM\u573a\u666f\u4e2d\u6709\u6548\u90e8\u7f72MARL\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6807\u51c6\uff0c\u5f3a\u8c03\u6839\u636e\u4efb\u52a1\u5206\u89e3\u7279\u6027\u548c\u5bf9\u9f50\u9700\u6c42\u9009\u62e9RL\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.08290", "categories": ["cs.LG", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08290", "abs": "https://arxiv.org/abs/2602.08290", "authors": ["Ajay Kumar Shrestha"], "title": "Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems", "comment": "To appear in the ICBTA 2025 Conference Proceedings and published as a volume of Lecture Notes in Networks and Systems by Springer", "summary": "In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward the quality of contributions in FL systems. By dynamically assessing trust scores based on fac-tors such as data quality, model accuracy, consistency, and contribution fre-quency, the system encourages honest participation and penalizes unreliable or malicious behavior. These trust scores form the basis of an incentive mechanism that rewards high-trust nodes with greater participation opportunities and penal-ties for low-trust participants. We further explore the integration of blockchain technology and smart contracts to automate the trust evaluation and incentive distribution processes, ensuring transparency and decentralization. Our proposed theoretical framework aims to create a more robust, fair, and transparent FL eco-system, reducing the risks posed by untrustworthy participants.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u4efb\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u8bc4\u4f30\u53c2\u4e0e\u8005\u8d21\u732e\u8d28\u91cf\u6765\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\uff0c\u5e76\u63a2\u7d22\u533a\u5757\u94fe\u6280\u672f\u5b9e\u73b0\u81ea\u52a8\u5316\u4fe1\u4efb\u8bc4\u4f30\u548c\u6fc0\u52b1\u5206\u914d\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5b58\u5728\u6076\u610f\u6216\u6545\u969c\u8282\u70b9\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u7684\u95ee\u9898\uff0c\u9700\u8981\u786e\u4fdd\u7cfb\u7edf\u5b8c\u6574\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u73b0\u6709\u673a\u5236\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u548c\u5956\u52b1\u53c2\u4e0e\u8005\u7684\u8d21\u732e\u8d28\u91cf\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u4fe1\u4efb\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u52a8\u6001\u8bc4\u4f30\u4fe1\u4efb\u5206\u6570\uff08\u8003\u8651\u6570\u636e\u8d28\u91cf\u3001\u6a21\u578b\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u8d21\u732e\u9891\u7387\u7b49\u56e0\u7d20\uff09\uff0c\u5e76\u63a2\u7d22\u96c6\u6210\u533a\u5757\u94fe\u548c\u667a\u80fd\u5408\u7ea6\u6765\u81ea\u52a8\u5316\u4fe1\u4efb\u8bc4\u4f30\u548c\u6fc0\u52b1\u5206\u914d\u8fc7\u7a0b\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u4efb\u5206\u6570\u57fa\u7840\u6fc0\u52b1\u9ad8\u4fe1\u4efb\u8282\u70b9\u83b7\u5f97\u66f4\u591a\u53c2\u4e0e\u673a\u4f1a\uff0c\u60e9\u7f5a\u4f4e\u4fe1\u4efb\u53c2\u4e0e\u8005\uff0c\u65e8\u5728\u521b\u5efa\u66f4\u7a33\u5065\u3001\u516c\u5e73\u548c\u900f\u660e\u7684\u8054\u90a6\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u7684\u4fe1\u4efb\u6fc0\u52b1\u673a\u5236\u80fd\u6709\u6548\u9f13\u52b1\u8bda\u5b9e\u53c2\u4e0e\uff0c\u60e9\u7f5a\u4e0d\u53ef\u9760\u6216\u6076\u610f\u884c\u4e3a\uff0c\u964d\u4f4e\u4e0d\u53ef\u4fe1\u53c2\u4e0e\u8005\u5e26\u6765\u7684\u98ce\u9669\uff0c\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.08302", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08302", "abs": "https://arxiv.org/abs/2602.08302", "authors": ["Nataraj Das", "Atreya Vedantam", "Chandrashekar Lakshminarayanan"], "title": "Grokking in Linear Models for Logistic Regression", "comment": null, "summary": "Grokking, the phenomenon of delayed generalization, is often attributed to the depth and compositional structure of deep neural networks. We study grokking in one of the simplest possible settings: the learning of a linear model with logistic loss for binary classification on data that are linearly (and max margin) separable about the origin. We investigate three testing regimes: (1) test data drawn from the same distribution as the training data, in which case grokking is not observed; (2) test data concentrated around the margin, in which case grokking is observed; and (3) adversarial test data generated via projected gradient descent (PGD) attacks, in which case grokking is also observed. We theoretically show that the implicit bias of gradient descent induces a three-phase learning process-population-dominated, support-vector-dominated unlearning, and support-vector-dominated generalization-during which delayed generalization can arise. Our analysis further relates the emergence of grokking to asymmetries in the data, both in the number of examples per class and in the distribution of support vectors across classes, and yields a characterization of the grokking time. We experimentally validate our theory by planting different distributions of population points and support vectors, and by analyzing accuracy curves and hyperplane dynamics. Overall, our results demonstrate that grokking does not require depth or representation learning, and can emerge even in linear models through the dynamics of the bias term.", "AI": {"tldr": "\u5728\u7ebf\u6027\u6a21\u578b\u4e2d\u4f7f\u7528\u903b\u8f91\u635f\u5931\u8fdb\u884c\u4e8c\u5206\u7c7b\u65f6\uff0c\u5373\u4f7f\u6ca1\u6709\u6df1\u5ea6\u6216\u8868\u793a\u5b66\u4e60\uff0c\u4e5f\u4f1a\u51fa\u73b0\u5ef6\u8fdf\u6cdb\u5316\uff08grokking\uff09\u73b0\u8c61\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u9690\u5f0f\u504f\u5dee\u548c\u6570\u636e\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u7814\u7a76grokking\uff08\u5ef6\u8fdf\u6cdb\u5316\uff09\u73b0\u8c61\u662f\u5426\u5fc5\u987b\u4f9d\u8d56\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u548c\u7ec4\u5408\u7ed3\u6784\uff0c\u63a2\u7d22\u5728\u7ebf\u6027\u6a21\u578b\u8fd9\u79cd\u6700\u7b80\u5355\u8bbe\u7f6e\u4e2d\u662f\u5426\u4e5f\u80fd\u51fa\u73b0grokking\u3002", "method": "\u5728\u7ebf\u6027\u53ef\u5206\u6570\u636e\u4e0a\u4f7f\u7528\u903b\u8f91\u635f\u5931\u8bad\u7ec3\u7ebf\u6027\u6a21\u578b\uff0c\u7814\u7a76\u4e09\u79cd\u6d4b\u8bd5\u673a\u5236\uff1a\u540c\u5206\u5e03\u6d4b\u8bd5\u3001\u8fb9\u7f18\u96c6\u4e2d\u6d4b\u8bd5\u548c\u5bf9\u6297\u6027\u6d4b\u8bd5\u3002\u7406\u8bba\u5206\u6790\u68af\u5ea6\u4e0b\u964d\u7684\u9690\u5f0f\u504f\u5dee\u5982\u4f55\u8bf1\u5bfc\u4e09\u9636\u6bb5\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u5728\u7ebf\u6027\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\u4e86grokking\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u96c6\u4e2d\u6d4b\u8bd5\u548c\u5bf9\u6297\u6027\u6d4b\u8bd5\u4e2d\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u4e09\u9636\u6bb5\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u8868\u660egrokking\u7684\u51fa\u73b0\u4e0e\u6570\u636e\u4e0d\u5bf9\u79f0\u6027\uff08\u7c7b\u522b\u6837\u672c\u6570\u91cf\u548c\u652f\u6491\u5411\u91cf\u5206\u5e03\uff09\u76f8\u5173\uff0c\u80fd\u591f\u9884\u6d4bgrokking\u65f6\u95f4\u3002", "conclusion": "grokking\u73b0\u8c61\u4e0d\u9700\u8981\u6df1\u5ea6\u6216\u8868\u793a\u5b66\u4e60\uff0c\u5373\u4f7f\u5728\u7ebf\u6027\u6a21\u578b\u4e2d\u4e5f\u80fd\u901a\u8fc7\u504f\u7f6e\u9879\u7684\u52a8\u529b\u5b66\u51fa\u73b0\u3002\u68af\u5ea6\u4e0b\u964d\u7684\u9690\u5f0f\u504f\u5dee\u548c\u6570\u636e\u4e0d\u5bf9\u79f0\u6027\u662f\u4ea7\u751f\u5ef6\u8fdf\u6cdb\u5316\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.08306", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08306", "abs": "https://arxiv.org/abs/2602.08306", "authors": ["Suizhi Huang", "Mei Li", "Han Yu", "Xiaoxiao Li"], "title": "TextResNet: Decoupling and Routing Optimization Signals in Compound AI Systems via Deep Residual Tuning", "comment": null, "summary": "Textual Gradient-style optimizers (TextGrad) enable gradient-like feedback propagation through compound AI systems. However, they do not work well for deep chains. The root cause of this limitation stems from the Semantic Entanglement problem in these extended workflows. In standard textual backpropagation, feedback signals mix local critiques with upstream contexts, leading to Attribution Ambiguity. To address this challenge, we propose TextResNet, a framework that reformulates the optimization process to achieve precise signal routing via four key innovations. Firstly, in the forward pass, it enforces Additive Semantic Deltas to preserve an Identity Highway for gradient flow. Secondly, in the backward pass, it introduces Semantic Gradient Decomposition via a Semantic Projector to disentangle feedback into causally independent subspaces. Thirdly, it implements Causal Routing, which routes projected signals to their specific components. Finally, it performs Density-Aware Optimization Scheduling to leverage the disentangled signals to dynamically allocate resources to key system bottlenecks. Our results show that TextResNet not only achieves superior performance compared to TextGrad, but also exhibits remarkable stability for agentic tasks in compound AI systems where baselines collapse. Code is available at https://github.com/JeanDiable/TextResNet.", "AI": {"tldr": "TextResNet\u89e3\u51b3\u4e86TextGrad\u5728\u6df1\u5ea6\u94fe\u5f0f\u7cfb\u7edf\u4e2d\u56e0\u8bed\u4e49\u7ea0\u7f20\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u901a\u8fc7\u8bed\u4e49\u68af\u5ea6\u5206\u89e3\u548c\u56e0\u679c\u8def\u7531\u5b9e\u73b0\u7cbe\u786e\u53cd\u9988\u4f20\u64ad\u3002", "motivation": "TextGrad\u7b49\u6587\u672c\u68af\u5ea6\u4f18\u5316\u5668\u5728\u6df1\u5ea6\u94fe\u5f0fAI\u7cfb\u7edf\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bed\u4e49\u7ea0\u7f20\u95ee\u9898\u5bfc\u81f4\u53cd\u9988\u4fe1\u53f7\u6df7\u5408\u4e86\u5c40\u90e8\u6279\u8bc4\u548c\u4e0a\u6e38\u4e0a\u4e0b\u6587\uff0c\u4ea7\u751f\u5f52\u56e0\u6a21\u7cca\u6027\u3002", "method": "\u63d0\u51faTextResNet\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u6280\u672f\uff1a\u524d\u5411\u4f20\u64ad\u4e2d\u5f3a\u5236\u52a0\u6027\u8bed\u4e49\u589e\u91cf\u4ee5\u4fdd\u6301\u68af\u5ea6\u6d41\u7684\u6052\u7b49\u9ad8\u901f\u901a\u9053\uff1b\u53cd\u5411\u4f20\u64ad\u4e2d\u901a\u8fc7\u8bed\u4e49\u6295\u5f71\u5668\u8fdb\u884c\u8bed\u4e49\u68af\u5ea6\u5206\u89e3\uff1b\u56e0\u679c\u8def\u7531\u5c06\u6295\u5f71\u4fe1\u53f7\u8def\u7531\u5230\u7279\u5b9a\u7ec4\u4ef6\uff1b\u5bc6\u5ea6\u611f\u77e5\u4f18\u5316\u8c03\u5ea6\u52a8\u6001\u5206\u914d\u8d44\u6e90\u5230\u7cfb\u7edf\u74f6\u9888\u3002", "result": "TextResNet\u4e0d\u4ec5\u6bd4TextGrad\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u4e14\u5728\u590d\u5408AI\u7cfb\u7edf\u7684\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u7a33\u5b9a\u6027\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u4f1a\u5d29\u6e83\u3002", "conclusion": "TextResNet\u901a\u8fc7\u89e3\u51b3\u8bed\u4e49\u7ea0\u7f20\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6df1\u5ea6\u94fe\u5f0fAI\u7cfb\u7edf\u4e2d\u66f4\u7cbe\u786e\u7684\u53cd\u9988\u4f20\u64ad\u548c\u66f4\u7a33\u5b9a\u7684\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2602.08324", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08324", "abs": "https://arxiv.org/abs/2602.08324", "authors": ["Yuntian Tang", "Bohan Jia", "Wenxuan Huang", "Lianyue Zhang", "Jiao Xie", "Wenxi Li", "Wei Li", "Jie Hu", "Xinghao Chen", "Rongrong Ji", "Shaohui Lin"], "title": "Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression", "comment": "15 pages, 7 figures", "summary": "Chain-of-Thought (CoT) reasoning successfully enhances the reasoning capabilities of Large Language Models (LLMs), yet it incurs substantial computational overhead for inference. Existing CoT compression methods often suffer from a critical loss of logical fidelity at high compression ratios, resulting in significant performance degradation. To achieve high-fidelity, fast reasoning, we propose a novel EXTreme-RAtio Chain-of-Thought Compression framework, termed Extra-CoT, which aggressively reduces the token budget while preserving answer accuracy. To generate reliable, high-fidelity supervision, we first train a dedicated semantically-preserved compressor on mathematical CoT data with fine-grained annotations. An LLM is then fine-tuned on these compressed pairs via a mixed-ratio supervised fine-tuning (SFT), teaching it to follow a spectrum of compression budgets and providing a stable initialization for reinforcement learning (RL). We further propose Constrained and Hierarchical Ratio Policy Optimization (CHRPO) to explicitly incentivize question-solving ability under lower budgets by a hierarchical reward. Experiments on three mathematical reasoning benchmarks show the superiority of Extra-CoT. For example, on MATH-500 using Qwen3-1.7B, Extra-CoT achieves over 73\\% token reduction with an accuracy improvement of 0.6\\%, significantly outperforming state-of-the-art (SOTA) methods.", "AI": {"tldr": "Extra-CoT\uff1a\u4e00\u79cd\u6781\u7aef\u6bd4\u4f8b\u601d\u7ef4\u94fe\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u4fdd\u7559\u538b\u7f29\u5668\u751f\u6210\u9ad8\u8d28\u91cf\u76d1\u7763\u6570\u636e\uff0c\u7ed3\u5408\u6df7\u5408\u6bd4\u4f8bSFT\u548c\u5206\u5c42\u7b56\u7565\u4f18\u5316\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b073%\u7684token\u51cf\u5c11\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u601d\u7ef4\u94fe\u538b\u7f29\u65b9\u6cd5\u5728\u9ad8\u538b\u7f29\u6bd4\u4e0b\u5b58\u5728\u903b\u8f91\u4fdd\u771f\u5ea6\u635f\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5927\u5e45\u51cf\u5c11\u63a8\u7406token\u5f00\u9500\uff0c\u53c8\u80fd\u4fdd\u6301\u7b54\u6848\u51c6\u786e\u6027\u7684\u9ad8\u4fdd\u771f\u5feb\u901f\u63a8\u7406\u65b9\u6cd5\u3002", "method": "1. \u5728\u5e26\u7ec6\u7c92\u5ea6\u6807\u6ce8\u7684\u6570\u5b66\u601d\u7ef4\u94fe\u6570\u636e\u4e0a\u8bad\u7ec3\u4e13\u95e8\u7684\u8bed\u4e49\u4fdd\u7559\u538b\u7f29\u5668\uff0c\u751f\u6210\u53ef\u9760\u7684\u538b\u7f29\u76d1\u7763\u5bf9\uff1b2. \u901a\u8fc7\u6df7\u5408\u6bd4\u4f8b\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u8ba9LLM\u5b66\u4e60\u9075\u5faa\u4e0d\u540c\u538b\u7f29\u9884\u7b97\uff1b3. \u63d0\u51fa\u7ea6\u675f\u5206\u5c42\u6bd4\u4f8b\u7b56\u7565\u4f18\u5316\uff08CHRPO\uff09\uff0c\u901a\u8fc7\u5206\u5c42\u5956\u52b1\u663e\u5f0f\u6fc0\u52b1\u4f4e\u9884\u7b97\u4e0b\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u4f8b\u5982\u5728MATH-500\u4e0a\u4f7f\u7528Qwen3-1.7B\uff0cExtra-CoT\u5b9e\u73b0\u4e86\u8d85\u8fc773%\u7684token\u51cf\u5c11\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u53470.6%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "Extra-CoT\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u538b\u7f29\u6bd4\u4e0b\u601d\u7ef4\u94fe\u538b\u7f29\u7684\u903b\u8f91\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u3001\u5feb\u901f\u7684\u63a8\u7406\uff0c\u4e3aLLM\u63a8\u7406\u6548\u7387\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08329", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.08329", "abs": "https://arxiv.org/abs/2602.08329", "authors": ["Yifei Gao", "Lei Wang", "Rong-Cheng Tu", "Qixin Zhang", "Jun Cheng", "Dacheng Tao"], "title": "Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference", "comment": "An effective method for accelerating LLM's inference via selective KV processing", "summary": "A core bottleneck in large language model (LLM) inference is the cost of attending over the ever-growing key-value (KV) cache. Although near-oracle top-k KV selection can preserve the quality of dense attention while sharply reducing computation and bandwidth, existing sparse methods generally rely on posterior heuristics, i.e., selectors conditioned on observed attention or proxy scores. Such conditioning introduces posterior bias: it tends to distort true token importance and miss salient tokens, thereby impairing long-range reasoning. To tackle this problem, we propose Pre-hoc Sparsity (PrHS), which selects KV entries before attention scoring and provides explicit accuracy control. Let the attention mass of discarded entries be delta (the dropped mass). Through a marginal-to-mutual-information analysis, we derive an upper bound on the mutual-information loss that depends only on the dropped mass. This relation explains failure modes of posterior heuristics and enables verifiable guarantees by controlling the dropped mass in advance. Within PrHS, we instantiate three orthogonal pre-hoc selectors along the axes of time, depth, and layer. Extensive experiments on LLaMA and Mistral families validate PrHS. Across GSM8K and CoQA, PrHS reduces retrieval overhead by over 90%, achieving 3x higher retrieval sparsity than HShare at matched or better accuracy. It incurs under 1% average degradation on LongBench, lowers attention FLOPs by about 15% versus prior sparse baselines, and yields a 9.9x speedup in attention-operator latency and 2.8x higher throughput on NVIDIA A100-80GB GPUs than the dense baseline.", "AI": {"tldr": "PrHS\u662f\u4e00\u79cd\u5728\u6ce8\u610f\u529b\u8bc4\u5206\u524d\u9009\u62e9KV\u7f13\u5b58\u6761\u76ee\u7684\u9884\u7a00\u758f\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a7\u5236\u4e22\u5f03\u8d28\u91cf\u63d0\u4f9b\u663e\u5f0f\u7cbe\u5ea6\u4fdd\u8bc1\uff0c\u663e\u8457\u964d\u4f4eLLM\u63a8\u7406\u7684\u8ba1\u7b97\u548c\u5e26\u5bbd\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u65b9\u6cd5\u4f9d\u8d56\u540e\u9a8c\u542f\u53d1\u5f0f\uff08\u57fa\u4e8e\u89c2\u6d4b\u6ce8\u610f\u529b\u6216\u4ee3\u7406\u5206\u6570\uff09\uff0c\u4f1a\u5f15\u5165\u540e\u9a8c\u504f\u5dee\uff0c\u626d\u66f2\u771f\u5b9etoken\u91cd\u8981\u6027\u5e76\u9057\u6f0f\u5173\u952etoken\uff0c\u635f\u5bb3\u957f\u7a0b\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u9884\u7a00\u758f\u5316(PrHS)\uff0c\u5728\u6ce8\u610f\u529b\u8bc4\u5206\u524d\u9009\u62e9KV\u6761\u76ee\uff0c\u901a\u8fc7\u8fb9\u9645-\u4e92\u4fe1\u606f\u5206\u6790\u63a8\u5bfc\u4e22\u5f03\u8d28\u91cf\u4e0e\u4e92\u4fe1\u606f\u635f\u5931\u7684\u4e0a\u754c\u5173\u7cfb\uff0c\u6cbf\u65f6\u95f4\u3001\u6df1\u5ea6\u548c\u5c42\u4e09\u4e2a\u6b63\u4ea4\u8f74\u5b9e\u4f8b\u5316\u9884\u7a00\u758f\u9009\u62e9\u5668\u3002", "result": "\u5728LLaMA\u548cMistral\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0cGSM8K\u548cCoQA\u4e0a\u68c0\u7d22\u5f00\u9500\u964d\u4f4e90%\u4ee5\u4e0a\uff0c\u68c0\u7d22\u7a00\u758f\u5ea6\u6bd4HShare\u9ad83\u500d\uff1bLongBench\u5e73\u5747\u9000\u5316\u4f4e\u4e8e1%\uff0c\u6ce8\u610f\u529bFLOPs\u964d\u4f4e\u7ea615%\uff1bA100-80GB\u4e0a\u6ce8\u610f\u529b\u7b97\u5b50\u5ef6\u8fdf\u52a0\u901f9.9\u500d\uff0c\u541e\u5410\u91cf\u63d0\u53472.8\u500d\u3002", "conclusion": "PrHS\u901a\u8fc7\u9884\u7a00\u758f\u5316\u65b9\u6cd5\u89e3\u51b3\u4e86\u540e\u9a8c\u542f\u53d1\u5f0f\u7684\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u7cbe\u5ea6\u4fdd\u8bc1\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u6548\u7387\uff0c\u4e3aKV\u7f13\u5b58\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.08333", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08333", "abs": "https://arxiv.org/abs/2602.08333", "authors": ["Cristian P\u00e9rez-Corral", "Alberto Fern\u00e1ndez-Hern\u00e1ndez", "Jose I. Mestre", "Manuel F. Dolz", "Jose Duato", "Enrique S. Quintana-Ort\u00ed"], "title": "Regime Change Hypothesis: Foundations for Decoupled Dynamics in Neural Network Training", "comment": "8 pages, 1 figure", "summary": "Despite the empirical success of DNN, their internal training dynamics remain difficult to characterize. In ReLU-based models, the activation pattern induced by a given input determines the piecewise-linear region in which the network behaves affinely. Motivated by this geometry, we investigate whether training exhibits a two-timescale behavior: an early stage with substantial changes in activation patterns and a later stage where weight updates predominantly refine the model within largely stable activation regimes. We first prove a local stability property: outside measure-zero sets of parameters and inputs, sufficiently small parameter perturbations preserve the activation pattern of a fixed input, implying locally affine behavior within activation regions. We then empirically track per-iteration changes in weights and activation patterns across fully-connected and convolutional architectures, as well as Transformer-based models, where activation patterns are recorded in the ReLU feed-forward (MLP/FFN) submodules, using fixed validation subsets. Across the evaluated settings, activation-pattern changes decay 3 times earlier than weight-update magnitudes, showing that late-stage training often proceeds within relatively stable activation regimes. These findings provide a concrete, architecture-agnostic instrument for monitoring training dynamics and motivate further study of decoupled optimization strategies for piecewise-linear networks. For reproducibility, code and experiment configurations will be released upon acceptance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86ReLU\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u4e24\u9636\u6bb5\u884c\u4e3a\uff1a\u65e9\u671f\u6fc0\u6d3b\u6a21\u5f0f\u5927\u5e45\u53d8\u5316\uff0c\u540e\u671f\u6743\u91cd\u66f4\u65b0\u4e3b\u8981\u5728\u7a33\u5b9a\u7684\u6fc0\u6d3b\u533a\u57df\u5185\u8fdb\u884c\u7ec6\u5316\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53d6\u5f97\u4e86\u7ecf\u9a8c\u4e0a\u7684\u6210\u529f\uff0c\u4f46\u5176\u5185\u90e8\u8bad\u7ec3\u52a8\u6001\u4ecd\u96be\u4ee5\u8868\u5f81\u3002\u5728ReLU\u6a21\u578b\u4e2d\uff0c\u6fc0\u6d3b\u6a21\u5f0f\u51b3\u5b9a\u4e86\u7f51\u7edc\u8868\u73b0\u4eff\u5c04\u884c\u4e3a\u7684\u533a\u57df\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7a76\u8bad\u7ec3\u662f\u5426\u8868\u73b0\u51fa\u4e24\u9636\u6bb5\u884c\u4e3a\u3002", "method": "\u9996\u5148\u8bc1\u660e\u5c40\u90e8\u7a33\u5b9a\u6027\u7406\u8bba\uff1a\u5728\u53c2\u6570\u548c\u8f93\u5165\u7684\u6d4b\u5ea6\u96f6\u96c6\u4e4b\u5916\uff0c\u8db3\u591f\u5c0f\u7684\u53c2\u6570\u6270\u52a8\u4f1a\u4fdd\u6301\u56fa\u5b9a\u8f93\u5165\u7684\u6fc0\u6d3b\u6a21\u5f0f\u3002\u7136\u540e\u901a\u8fc7\u5b9e\u9a8c\u8ddf\u8e2a\u5168\u8fde\u63a5\u3001\u5377\u79ef\u548cTransformer\u67b6\u6784\u4e2d\u6bcf\u6b21\u8fed\u4ee3\u7684\u6743\u91cd\u548c\u6fc0\u6d3b\u6a21\u5f0f\u53d8\u5316\u3002", "result": "\u6fc0\u6d3b\u6a21\u5f0f\u53d8\u5316\u6bd4\u6743\u91cd\u66f4\u65b0\u5e45\u5ea6\u65e93\u500d\u8870\u51cf\uff0c\u8868\u660e\u540e\u671f\u8bad\u7ec3\u901a\u5e38\u5728\u76f8\u5bf9\u7a33\u5b9a\u7684\u6fc0\u6d3b\u533a\u57df\u5185\u8fdb\u884c\u3002\u8fd9\u4e3a\u76d1\u63a7\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u67b6\u6784\u65e0\u5173\u7684\u5de5\u5177\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86ReLU\u7f51\u7edc\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u52a8\u6001\uff0c\u4e3a\u7406\u89e3\u8bad\u7ec3\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u6fc0\u52b1\u8fdb\u4e00\u6b65\u7814\u7a76\u5206\u6bb5\u7ebf\u6027\u7f51\u7edc\u7684\u89e3\u8026\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2602.08351", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08351", "abs": "https://arxiv.org/abs/2602.08351", "authors": ["Zhiliang Chen", "Alfred Wei Lun Leong", "Shao Yong Ong", "Apivich Hemachandram", "Gregory Kang Ruey Lau", "Chuan-Sheng Foo", "Zhengyuan Liu", "Nancy F. Chen", "Bryan Kian Hsiang Low"], "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs", "comment": null, "summary": "Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly optimizing both data and model configurations is often deemed intractable, and existing methods focus on either data or model optimization without considering their interaction. We introduce JoBS, an approach that uses a scaling-law-inspired performance predictor to aid Bayesian optimization (BO) in jointly optimizing LLM training data and model configurations efficiently. JoBS allocates a portion of the optimization budget to learn an LLM performance predictor that predicts how promising a training configuration is from a small number of training steps. The remaining budget is used to perform BO entirely with the predictor, effectively amortizing the cost of running full-training runs. We study JoBS's average regret and devise the optimal budget allocation to minimize regret. JoBS outperforms existing multi-fidelity BO baselines, as well as data and model optimization approaches across diverse LLM tasks under the same optimization budget.", "AI": {"tldr": "JoBS\u901a\u8fc7\u7ed3\u5408\u7f29\u653e\u5b9a\u5f8b\u6027\u80fd\u9884\u6d4b\u5668\u548c\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u8054\u5408\u4f18\u5316LLM\u8bad\u7ec3\u7684\u6570\u636e\u548c\u6a21\u578b\u914d\u7f6e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u6570\u636e\u4e0e\u6a21\u578b\u914d\u7f6e\u76f8\u4e92\u4f9d\u8d56\u7684\"\u9e21\u4e0e\u86cb\"\u56f0\u5883\u3002", "motivation": "\u8bad\u7ec3LLM\u65f6\u5b58\u5728\u6570\u636e\u914d\u7f6e\u548c\u6a21\u578b\u914d\u7f6e\u76f8\u4e92\u4f9d\u8d56\u7684\"\u9e21\u4e0e\u86cb\"\u56f0\u5883\uff1a\u6700\u4f73\u8bad\u7ec3\u6570\u636e\u914d\u7f6e\u53d6\u51b3\u4e8e\u6a21\u578b\u914d\u7f6e\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u4f18\u5316\u5176\u4e2d\u4e00\u65b9\u9762\uff0c\u5ffd\u7565\u4e86\u4e8c\u8005\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u800c\u8054\u5408\u4f18\u5316\u53c8\u5f80\u5f80\u88ab\u8ba4\u4e3a\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u63d0\u51faJoBS\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u7f29\u653e\u5b9a\u5f8b\u542f\u53d1\u7684\u6027\u80fd\u9884\u6d4b\u5668\uff0c\u4ece\u5c0f\u91cf\u8bad\u7ec3\u6b65\u9aa4\u9884\u6d4b\u5b8c\u6574\u8bad\u7ec3\u7684\u6027\u80fd\uff1b2\uff09\u5c06\u4f18\u5316\u9884\u7b97\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u4e00\u90e8\u5206\u7528\u4e8e\u5b66\u4e60\u6027\u80fd\u9884\u6d4b\u5668\uff0c\u5269\u4f59\u90e8\u5206\u7528\u4e8e\u57fa\u4e8e\u9884\u6d4b\u5668\u8fdb\u884c\u8d1d\u53f6\u65af\u4f18\u5316\uff1b3\uff09\u7406\u8bba\u5206\u6790\u5e73\u5747\u9057\u61be\u5e76\u8bbe\u8ba1\u6700\u4f18\u9884\u7b97\u5206\u914d\u7b56\u7565\u3002", "result": "JoBS\u5728\u76f8\u540c\u4f18\u5316\u9884\u7b97\u4e0b\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u4fdd\u771f\u5ea6\u8d1d\u53f6\u65af\u4f18\u5316\u57fa\u7ebf\uff0c\u4ee5\u53ca\u5355\u72ec\u7684\u6570\u636e\u6216\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u79cdLLM\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "JoBS\u901a\u8fc7\u6709\u6548\u5206\u644a\u5b8c\u6574\u8bad\u7ec3\u6210\u672c\uff0c\u5b9e\u73b0\u4e86LLM\u8bad\u7ec3\u4e2d\u6570\u636e\u548c\u6a21\u578b\u914d\u7f6e\u7684\u8054\u5408\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u9ad8\u6548LLM\u8bad\u7ec3\u914d\u7f6e\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.08376", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08376", "abs": "https://arxiv.org/abs/2602.08376", "authors": ["Xinyu Wang", "Ziyu Zhao", "Peng Lu", "Yu Gu", "Xiao-Wen Chang"], "title": "OJBKQ: Objective-Joint Babai-Klein Quantization", "comment": null, "summary": "Post-training quantization (PTQ) is widely used to compress large language models without retraining. However, many existing weight-only methods rely on heuristic objectives and greedy rounding, thus leading to noticeable degradation under low-bit quantization. In this work, we introduce OJBKQ (Objective-Joint Babai-Klein Quantization with K-Best Sampling), a layer-wise PTQ method that formulates weight quantization as a joint optimization problem over activations and weights. This formulation results in a multiple-right-hand-side box-constrained integer least squares (BILS) problem in each layer, which is NP-hard. For each column of the weight matrix, we apply an extended Babai nearest-plane algorithm and an extended version of Klein's randomized Babai algorithm to find the minimum-residual Babai-Klein point, a sub-optimal solution to the BILS problem. Experimental results on large language models show that OJBKQ achieves lower perplexity at 3-4 bits compared to existing PTQ approaches, while maintaining comparable computational cost.", "AI": {"tldr": "OJBKQ\u662f\u4e00\u79cd\u5c42\u7ea7\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6743\u91cd\u91cf\u5316\u5efa\u6a21\u4e3a\u6fc0\u6d3b\u548c\u6743\u91cd\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6269\u5c55\u7684Babai-Klein\u7b97\u6cd5\u89e3\u51b3NP-hard\u7684\u6574\u6570\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u57283-4\u6bd4\u7279\u91cf\u5316\u4e0b\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\u3002", "motivation": "\u73b0\u6709\u6743\u91cd\u91cf\u5316\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u76ee\u6807\u548c\u8d2a\u5fc3\u820d\u5165\uff0c\u5bfc\u81f4\u4f4e\u6bd4\u7279\u91cf\u5316\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u5c06\u6743\u91cd\u91cf\u5316\u5efa\u6a21\u4e3a\u6fc0\u6d3b\u548c\u6743\u91cd\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5f62\u6210\u591a\u53f3\u4fa7\u7ea6\u675f\u6574\u6570\u6700\u5c0f\u4e8c\u4e58\u95ee\u9898\uff0c\u4f7f\u7528\u6269\u5c55\u7684Babai\u6700\u8fd1\u5e73\u9762\u7b97\u6cd5\u548cKlein\u968f\u673aBabai\u7b97\u6cd5\u5bfb\u627e\u6700\u5c0f\u6b8b\u5dee\u7684Babai-Klein\u70b9\u4f5c\u4e3a\u5b50\u4f18\u89e3\u3002", "result": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cOJBKQ\u57283-4\u6bd4\u7279\u91cf\u5316\u4e0b\u76f8\u6bd4\u73b0\u6709PTQ\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u8f83\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "OJBKQ\u901a\u8fc7\u5c06\u91cf\u5316\u5efa\u6a21\u4e3a\u8054\u5408\u4f18\u5316\u95ee\u9898\u5e76\u4f7f\u7528Babai-Klein\u7b97\u6cd5\uff0c\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u540e\u8bad\u7ec3\u91cf\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08387", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08387", "abs": "https://arxiv.org/abs/2602.08387", "authors": ["Max L\u00fcbbering", "Timm Ruland", "Richard Rutmann", "Felix Stollenwerk", "David Fitzek", "Michael Fromm", "Alexander Weber", "Rafet Sifa", "Nicolas Flores-Herr", "Joachim K\u00f6hler", "Mehdi Ali"], "title": "Modalities, a PyTorch-native Framework For Large-scale LLM Training and Research", "comment": null, "summary": "Today's LLM (pre-) training and research workflows typically allocate a significant amount of compute to large-scale ablation studies. Despite the substantial compute costs of these ablations, existing open-source frameworks provide limited tooling for these experiments, often forcing researchers to write their own wrappers and scripts. We propose Modalities, an end-to-end PyTorch-native framework that integrates data-driven LLM research with large-scale model training from two angles. Firstly, by integrating state-of-the-art parallelization strategies, it enables both efficient pretraining and systematic ablations at trillion-token and billion-parameter scale. Secondly, Modalities adopts modular design with declarative, self-contained configuration, enabling reproducibility and extensibility levels that are difficult to achieve out-of-the-box with existing LLM training frameworks.", "AI": {"tldr": "Modalities\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684PyTorch\u539f\u751f\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3LLM\u8bad\u7ec3\u4e2d\u5927\u89c4\u6a21\u6d88\u878d\u5b9e\u9a8c\u7684\u6548\u7387\u548c\u5de5\u5177\u652f\u6301\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u96c6\u6210\u5148\u8fdb\u5e76\u884c\u5316\u7b56\u7565\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u9ad8\u6548\u9884\u8bad\u7ec3\u548c\u53ef\u590d\u73b0\u7684\u6d88\u878d\u7814\u7a76\u3002", "motivation": "\u5f53\u524dLLM\u9884\u8bad\u7ec3\u548c\u7814\u7a76\u5de5\u4f5c\u6d41\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u5927\u89c4\u6a21\u6d88\u878d\u5b9e\u9a8c\uff0c\u4f46\u73b0\u6709\u5f00\u6e90\u6846\u67b6\u5bf9\u6b64\u652f\u6301\u6709\u9650\uff0c\u7814\u7a76\u4eba\u5458\u4e0d\u5f97\u4e0d\u7f16\u5199\u81ea\u5df1\u7684\u5c01\u88c5\u548c\u811a\u672c\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u590d\u73b0\u3002", "method": "Modalities\u91c7\u7528\u7aef\u5230\u7aefPyTorch\u539f\u751f\u8bbe\u8ba1\uff0c\u4ece\u4e24\u4e2a\u89d2\u5ea6\u6574\u5408\u6570\u636e\u9a71\u52a8\u7684LLM\u7814\u7a76\uff1a1) \u96c6\u6210\u6700\u5148\u8fdb\u7684\u5e76\u884c\u5316\u7b56\u7565\uff0c\u652f\u6301\u4e07\u4ebftoken\u548c\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u7684\u9ad8\u6548\u9884\u8bad\u7ec3\u548c\u7cfb\u7edf\u6d88\u878d\uff1b2) \u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u58f0\u660e\u5f0f\u81ea\u5305\u542b\u914d\u7f6e\uff0c\u63d0\u5347\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u73b0\u6709LLM\u8bad\u7ec3\u6846\u67b6\u96be\u4ee5\u8fbe\u5230\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u6c34\u5e73\uff0c\u4e3a\u5927\u89c4\u6a21\u6d88\u878d\u5b9e\u9a8c\u63d0\u4f9b\u7cfb\u7edf\u5316\u652f\u6301\u3002", "conclusion": "Modalities\u901a\u8fc7\u96c6\u6210\u9ad8\u6548\u5e76\u884c\u5316\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u4e3aLLM\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u652f\u6301\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6d88\u878d\u5b9e\u9a8c\u7684\u6548\u7387\u548c\u53ef\u590d\u73b0\u6027\u95ee\u9898\u3002"}}
{"id": "2602.08407", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08407", "abs": "https://arxiv.org/abs/2602.08407", "authors": ["Richard Serrano", "Baptiste Jeudy", "Charlotte Laclau", "Christine Largeron"], "title": "Drop the mask! GAMM-A Taxonomy for Graph Attributes Missing Mechanisms", "comment": null, "summary": "Exploring missing data in attributed graphs introduces unique challenges beyond those found in tabular datasets. In this work, we extend the taxonomy for missing data mechanisms to attributed graphs by proposing GAMM (Graph Attributes Missing Mechanisms), a framework that systematically links missingness probability to both node attributes and the underlying graph structure. Our taxonomy enriches the conventional definitions of masking mechanisms by introducing graph-specific dependencies. We empirically demonstrate that state-of-the-art imputation methods, while effective on traditional masks, significantly struggle when confronted with these more realistic graph-aware missingness scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86GAMM\u6846\u67b6\uff0c\u5c06\u7f3a\u5931\u6570\u636e\u673a\u5236\u5206\u7c7b\u6269\u5c55\u5230\u5c5e\u6027\u56fe\uff0c\u8003\u8651\u8282\u70b9\u5c5e\u6027\u548c\u56fe\u7ed3\u6784\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u63d2\u8865\u65b9\u6cd5\u5728\u56fe\u611f\u77e5\u7f3a\u5931\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5c5e\u6027\u56fe\u4e2d\u7684\u7f3a\u5931\u6570\u636e\u95ee\u9898\u6bd4\u8868\u683c\u6570\u636e\u66f4\u590d\u6742\uff0c\u73b0\u6709\u7f3a\u5931\u673a\u5236\u5206\u7c7b\u65e0\u6cd5\u5145\u5206\u6355\u6349\u56fe\u7ed3\u6784\u7279\u6709\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u56fe\u6570\u636e\u7684\u7f3a\u5931\u673a\u5236\u6846\u67b6\u3002", "method": "\u63d0\u51faGAMM\uff08\u56fe\u5c5e\u6027\u7f3a\u5931\u673a\u5236\uff09\u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u5c06\u7f3a\u5931\u6982\u7387\u4e0e\u8282\u70b9\u5c5e\u6027\u548c\u5e95\u5c42\u56fe\u7ed3\u6784\u8054\u7cfb\u8d77\u6765\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u7f3a\u5931\u673a\u5236\u5206\u7c7b\uff0c\u5f15\u5165\u4e86\u56fe\u7279\u5b9a\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u63d2\u8865\u65b9\u6cd5\u5728\u4f20\u7edf\u7f3a\u5931\u6a21\u5f0f\u4e0b\u6709\u6548\uff0c\u4f46\u5728\u8fd9\u4e9b\u66f4\u73b0\u5b9e\u7684\u56fe\u611f\u77e5\u7f3a\u5931\u573a\u666f\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u56fe\u6570\u636e\u7279\u6027\u7684\u7f3a\u5931\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0cGAMM\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u8bc4\u4f30\u56fe\u6570\u636e\u7f3a\u5931\u673a\u5236\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5de5\u5177\u3002"}}
{"id": "2602.08419", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08419", "abs": "https://arxiv.org/abs/2602.08419", "authors": ["Gnankan Landry Regis N'guessan", "Bum Jun Kim"], "title": "Radial M\u00fcntz-Sz\u00e1sz Networks: Neural Architectures with Learnable Power Bases for Multidimensional Singularities", "comment": "47 pages, 13 figures", "summary": "Radial singular fields, such as $1/r$, $\\log r$, and crack-tip profiles, are difficult to model for coordinate-separable neural architectures. We show that any $C^2$ function that is both radial and additively separable must be quadratic, establishing a fundamental obstruction for coordinate-wise power-law models. Motivated by this result, we introduce Radial M\u00fcntz-Sz\u00e1sz Networks (RMN), which represent fields as linear combinations of learnable radial powers $r^\u03bc$, including negative exponents, together with a limit-stable log-primitive for exact $\\log r$ behavior. RMN admits closed-form spatial gradients and Laplacians, enabling physics-informed learning on punctured domains. Across ten 2D and 3D benchmarks, RMN achieves 1.5$\\times$--51$\\times$ lower RMSE than MLPs and 10$\\times$--100$\\times$ lower RMSE than SIREN while using 27 parameters, compared with 33,537 for MLPs and 8,577 for SIREN. We extend RMN to angular dependence (RMN-Angular) and to multiple sources with learnable centers (RMN-MC); when optimization converges, source-center recovery errors fall below $10^{-4}$. We also report controlled failures on smooth, strongly non-radial targets to delineate RMN's operating regime.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5f84\u5411M\u00fcntz-Sz\u00e1sz\u7f51\u7edc(RMN)\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5f84\u5411\u5e42\u6b21r^\u03bc\uff08\u5305\u62ec\u8d1f\u6307\u6570\uff09\u548clog\u57fa\u5143\uff0c\u6709\u6548\u5efa\u6a21\u5f84\u5411\u5947\u5f02\u573a\uff0c\u76f8\u6bd4MLP\u548cSIREN\u5728\u53c2\u6570\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u5f84\u5411\u5947\u5f02\u573a\uff08\u59821/r\u3001log r\u3001\u88c2\u7eb9\u5c16\u7aef\u5256\u9762\uff09\u96be\u4ee5\u7528\u5750\u6807\u53ef\u5206\u79bb\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5efa\u6a21\u3002\u4f5c\u8005\u8bc1\u660e\u4efb\u4f55\u65e2\u662f\u5f84\u5411\u53c8\u662f\u52a0\u6027\u53ef\u5206\u79bb\u7684C^2\u51fd\u6570\u5fc5\u987b\u662f\u4e8c\u6b21\u51fd\u6570\uff0c\u8fd9\u4e3a\u5750\u6807\u5e42\u5f8b\u6a21\u578b\u5efa\u7acb\u4e86\u57fa\u672c\u969c\u788d\u3002", "method": "\u5f15\u5165\u5f84\u5411M\u00fcntz-Sz\u00e1sz\u7f51\u7edc(RMN)\uff0c\u5c06\u573a\u8868\u793a\u4e3a\u53ef\u5b66\u4e60\u5f84\u5411\u5e42\u6b21r^\u03bc\uff08\u5305\u62ec\u8d1f\u6307\u6570\uff09\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u52a0\u4e0a\u6781\u9650\u7a33\u5b9a\u7684log\u57fa\u5143\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684log r\u884c\u4e3a\u3002RMN\u5141\u8bb8\u95ed\u5f0f\u7a7a\u95f4\u68af\u5ea6\u548c\u62c9\u666e\u62c9\u65af\u7b97\u5b50\uff0c\u652f\u6301\u5728\u7a7f\u5b54\u57df\u4e0a\u8fdb\u884c\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u3002", "result": "\u572810\u4e2a2D\u548c3D\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRMN\u6bd4MLP\u5b9e\u73b01.5-51\u500d\u66f4\u4f4e\u7684RMSE\uff0c\u6bd4SIREN\u5b9e\u73b010-100\u500d\u66f4\u4f4e\u7684RMSE\uff0c\u4ec5\u4f7f\u752827\u4e2a\u53c2\u6570\uff08MLP\u4e3a33,537\uff0cSIREN\u4e3a8,577\uff09\u3002\u6269\u5c55\u5230\u89d2\u5ea6\u4f9d\u8d56(RMN-Angular)\u548c\u591a\u6e90\u53ef\u5b66\u4e60\u4e2d\u5fc3(RMN-MC)\uff0c\u5f53\u4f18\u5316\u6536\u655b\u65f6\uff0c\u6e90\u4e2d\u5fc3\u6062\u590d\u8bef\u5dee\u4f4e\u4e8e10^-4\u3002", "conclusion": "RMN\u4e3a\u5f84\u5411\u5947\u5f02\u573a\u63d0\u4f9b\u4e86\u9ad8\u6548\u7cbe\u786e\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u5728\u53c2\u6570\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u540c\u65f6\u901a\u8fc7\u62a5\u544a\u5728\u5e73\u6ed1\u3001\u5f3a\u975e\u5f84\u5411\u76ee\u6807\u4e0a\u7684\u53d7\u63a7\u5931\u8d25\u6765\u754c\u5b9a\u5176\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2602.08427", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.08427", "abs": "https://arxiv.org/abs/2602.08427", "authors": ["Marius Marinescu"], "title": "The Connection between Kriging and Large Neural Networks", "comment": null, "summary": "AI has impacted many disciplines and is nowadays ubiquitous. In particular, spatial statistics is in a pivotal moment where it will increasingly intertwine with AI. In this scenario, a relevant question is what relationship spatial statistics models have with machine learning (ML) models, if any. In particular, in this paper, we explore the connections between Kriging and neural networks. At first glance, they may appear unrelated. Kriging - and its ML counterpart, Gaussian process regression - are grounded in probability theory and stochastic processes, whereas many ML models are extensively considered Black-Box models. Nevertheless, they are strongly related. We study their connections and revisit the relevant literature. The understanding of their relations and the combination of both perspectives may enhance ML techniques by making them more interpretable, reliable, and spatially aware.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7a7a\u95f4\u7edf\u8ba1\u5b66\u4e2d\u7684\u514b\u91cc\u91d1\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u4e2d\u795e\u7ecf\u7f51\u7edc\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u9760\u6027\u548c\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u968f\u7740AI\u5728\u5404\u5b66\u79d1\u4e2d\u7684\u666e\u53ca\uff0c\u7a7a\u95f4\u7edf\u8ba1\u5b66\u6b63\u5904\u4e8e\u4e0eAI\u6df1\u5ea6\u878d\u5408\u7684\u5173\u952e\u65f6\u523b\u3002\u4f5c\u8005\u53d1\u73b0\u867d\u7136\u514b\u91cc\u91d1\u6cd5\uff08\u53ca\u5176\u673a\u5668\u5b66\u4e60\u5bf9\u5e94\u7269\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\uff09\u57fa\u4e8e\u6982\u7387\u8bba\u548c\u968f\u673a\u8fc7\u7a0b\uff0c\u800c\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u88ab\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u91cd\u8981\u8054\u7cfb\u3002\u7406\u89e3\u8fd9\u79cd\u5173\u7cfb\u6709\u52a9\u4e8e\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "method": "\u901a\u8fc7\u6587\u732e\u56de\u987e\u548c\u7406\u8bba\u5206\u6790\uff0c\u63a2\u7d22\u514b\u91cc\u91d1\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u4e4b\u95f4\u7684\u8fde\u63a5\u5173\u7cfb\u3002\u7814\u7a76\u4e24\u8005\u5728\u7406\u8bba\u57fa\u7840\u548c\u5e94\u7528\u5c42\u9762\u7684\u76f8\u4f3c\u6027\u4e0e\u5dee\u5f02\u6027\uff0c\u5e76\u91cd\u65b0\u5ba1\u89c6\u76f8\u5173\u6587\u732e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u514b\u91cc\u91d1\u6cd5\u4e0e\u795e\u7ecf\u7f51\u7edc\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u5173\u8054\u6027\uff0c\u5c3d\u7ba1\u5b83\u4eec\u8868\u9762\u4e0a\u770b\u4f3c\u65e0\u5173\u3002\u8fd9\u79cd\u7406\u89e3\u63ed\u793a\u4e86\u5c06\u6982\u7387\u8bba\u57fa\u7840\u7684\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u7ed3\u5408\u7a7a\u95f4\u7edf\u8ba1\u5b66\u7684\u514b\u91cc\u91d1\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u7684\u795e\u7ecf\u7f51\u7edc\u89c6\u89d2\uff0c\u53ef\u4ee5\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u9760\u6027\u548c\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u4e3a\u7a7a\u95f4\u7edf\u8ba1\u5b66\u4e0eAI\u7684\u6df1\u5ea6\u878d\u5408\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.08431", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08431", "abs": "https://arxiv.org/abs/2602.08431", "authors": ["Yingxu Wang", "Kunyu Zhang", "Mengzhu Wang", "Siyang Gao", "Nan Yin"], "title": "USBD: Universal Structural Basis Distillation for Source-Free Graph Domain Adaptation", "comment": null, "summary": "SF-GDA is pivotal for privacy-preserving knowledge transfer across graph datasets. Although recent works incorporate structural information, they implicitly condition adaptation on the smoothness priors of sourcetrained GNNs, thereby limiting their generalization to structurally distinct targets. This dependency becomes a critical bottleneck under significant topological shifts, where the source model misinterprets distinct topological patterns unseen in the source domain as noise, rendering pseudo-label-based adaptation unreliable. To overcome this limitation, we propose the Universal Structural Basis Distillation, a framework that shifts the paradigm from adapting a biased model to learning a universal structural basis for SF-GDA. Instead of adapting a biased source model to a specific target, our core idea is to construct a structure-agnostic basis that proactively covers the full spectrum of potential topological patterns. Specifically, USBD employs a bi-level optimization framework to distill the source dataset into a compact structural basis. By enforcing the prototypes to span the full Dirichlet energy spectrum, the learned basis explicitly captures diverse topological motifs, ranging from low-frequency clusters to high-frequency chains, beyond those present in the source. This ensures that the learned basis creates a comprehensive structural covering capable of handling targets with disparate structures. For inference, we introduce a spectral-aware ensemble mechanism that dynamically activates the optimal prototype combination based on the spectral fingerprint of the target graph. Extensive experiments on benchmarks demonstrate that USBD significantly outperforms state-of-the-art methods, particularly in scenarios with severe structural shifts, while achieving superior computational efficiency by decoupling the adaptation cost from the target data scale.", "AI": {"tldr": "\u63d0\u51faUSBD\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u901a\u7528\u7ed3\u6784\u57fa\u6765\u89e3\u51b3\u56fe\u6570\u636e\u65e0\u6e90\u57df\u9002\u5e94\u4e2d\u7684\u7ed3\u6784\u504f\u79fb\u95ee\u9898\uff0c\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u4f2a\u6807\u7b7e\u7684\u6e90\u6a21\u578b\u9002\u5e94\u65b9\u6cd5", "motivation": "\u73b0\u6709SF-GDA\u65b9\u6cd5\u4f9d\u8d56\u6e90\u8bad\u7ec3GNN\u7684\u5e73\u6ed1\u5148\u9a8c\uff0c\u5728\u663e\u8457\u62d3\u6251\u504f\u79fb\u4e0b\uff0c\u6e90\u6a21\u578b\u4f1a\u5c06\u672a\u89c1\u7684\u7ed3\u6784\u6a21\u5f0f\u8bef\u5224\u4e3a\u566a\u58f0\uff0c\u5bfc\u81f4\u57fa\u4e8e\u4f2a\u6807\u7b7e\u7684\u9002\u5e94\u4e0d\u53ef\u9760", "method": "\u63d0\u51fa\u901a\u7528\u7ed3\u6784\u57fa\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u5c06\u6e90\u6570\u636e\u96c6\u84b8\u998f\u4e3a\u7d27\u51d1\u7684\u7ed3\u6784\u57fa\uff0c\u5f3a\u5236\u539f\u578b\u8986\u76d6\u5b8c\u6574\u7684Dirichlet\u80fd\u91cf\u8c31\uff0c\u6355\u83b7\u4ece\u4f4e\u9891\u805a\u7c7b\u5230\u9ad8\u9891\u94fe\u7684\u591a\u6837\u62d3\u6251\u6a21\u5f0f", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u7ed3\u6784\u504f\u79fb\u573a\u666f\u4e0b\uff0c\u540c\u65f6\u901a\u8fc7\u89e3\u8026\u9002\u5e94\u6210\u672c\u4e0e\u76ee\u6807\u6570\u636e\u89c4\u6a21\u5b9e\u73b0\u5353\u8d8a\u8ba1\u7b97\u6548\u7387", "conclusion": "USBD\u901a\u8fc7\u4ece\u9002\u5e94\u6709\u504f\u6a21\u578b\u8f6c\u5411\u5b66\u4e60\u901a\u7528\u7ed3\u6784\u57fa\uff0c\u6709\u6548\u89e3\u51b3\u4e86SF-GDA\u4e2d\u7684\u7ed3\u6784\u504f\u79fb\u74f6\u9888\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u56fe\u77e5\u8bc6\u8fc1\u79fb\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08446", "categories": ["cs.LG", "cs.CR", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08446", "abs": "https://arxiv.org/abs/2602.08446", "authors": ["Pouria Arefijamal", "Mahdi Ahmadlou", "Bardia Safaei", "J\u00f6rg Henkel"], "title": "RIFLE: Robust Distillation-based FL for Deep Model Deployment on Resource-Constrained IoT Networks", "comment": "This paper has been accepted for publication in IEEE ICC 2026 and will be indexed in the IEEE Xplore Digital Library", "summary": "Federated learning (FL) is a decentralized learning paradigm widely adopted in resource-constrained Internet of Things (IoT) environments. These devices, typically relying on TinyML models, collaboratively train global models by sharing gradients with a central server while preserving data privacy. However, as data heterogeneity and task complexity increase, TinyML models often become insufficient to capture intricate patterns, especially under extreme non-IID (non-independent and identically distributed) conditions. Moreover, ensuring robustness against malicious clients and poisoned updates remains a major challenge. Accordingly, this paper introduces RIFLE - a Robust, distillation-based Federated Learning framework that replaces gradient sharing with logit-based knowledge transfer. By leveraging a knowledge distillation aggregation scheme, RIFLE enables the training of deep models such as VGG-19 and Resnet18 within constrained IoT systems. Furthermore, a Kullback-Leibler (KL) divergence-based validation mechanism quantifies the reliability of client updates without exposing raw data, achieving high trust and privacy preservation simultaneously. Experiments on three benchmark datasets (MNIST, CIFAR-10, and CIFAR-100) under heterogeneous non-IID conditions demonstrate that RIFLE reduces false-positive detections by up to 87.5%, enhances poisoning attack mitigation by 62.5%, and achieves up to 28.3% higher accuracy compared to conventional federated learning baselines within only 10 rounds. Notably, RIFLE reduces VGG19 training time from over 600 days to just 1.39 hours on typical IoT devices (0.3 GFLOPS), making deep learning practical in resource-constrained networks.", "AI": {"tldr": "RIFLE\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u9c81\u68d2\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528logit\u77e5\u8bc6\u8f6c\u79fb\u66ff\u4ee3\u68af\u5ea6\u5171\u4eab\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u73af\u5883\u4e2d\u5b9e\u73b0\u6df1\u5ea6\u6a21\u578b\u8bad\u7ec3\uff0c\u540c\u65f6\u63d0\u4f9b\u6076\u610f\u5ba2\u6237\u7aef\u68c0\u6d4b\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728IoT\u73af\u5883\u4e2d\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1) TinyML\u6a21\u578b\u5728\u6570\u636e\u5f02\u6784\u548c\u4efb\u52a1\u590d\u6742\u65f6\u96be\u4ee5\u6355\u6349\u590d\u6742\u6a21\u5f0f\uff1b2) \u7f3a\u4e4f\u5bf9\u6076\u610f\u5ba2\u6237\u7aef\u548c\u4e2d\u6bd2\u66f4\u65b0\u7684\u9c81\u68d2\u6027\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63d0\u51faRIFLE\u6846\u67b6\uff1a1) \u7528logit-based\u77e5\u8bc6\u8f6c\u79fb\u66ff\u4ee3\u68af\u5ea6\u5171\u4eab\uff1b2) \u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u805a\u5408\u65b9\u6848\u8bad\u7ec3\u6df1\u5ea6\u6a21\u578b\uff1b3) \u57fa\u4e8eKL\u6563\u5ea6\u7684\u9a8c\u8bc1\u673a\u5236\u91cf\u5316\u5ba2\u6237\u7aef\u66f4\u65b0\u53ef\u9760\u6027\u800c\u4e0d\u66b4\u9732\u539f\u59cb\u6570\u636e\u3002", "result": "\u5728MNIST\u3001CIFAR-10\u3001CIFAR-100\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff1a\u8bef\u62a5\u68c0\u6d4b\u964d\u4f4e87.5%\uff0c\u4e2d\u6bd2\u653b\u51fb\u7f13\u89e3\u63d0\u534762.5%\uff0c\u51c6\u786e\u7387\u6bd4\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u9ad828.3%\uff0cVGG19\u8bad\u7ec3\u65f6\u95f4\u4ece600\u591a\u5929\u7f29\u77ed\u52301.39\u5c0f\u65f6\u3002", "conclusion": "RIFLE\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548clogit\u8f6c\u79fb\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6df1\u5ea6\u6a21\u578b\u7684\u5b9e\u7528\u5316\u8bad\u7ec3\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.08461", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08461", "abs": "https://arxiv.org/abs/2602.08461", "authors": ["Liyuan Xu", "Bijan Mazaheri"], "title": "Estimating Aleatoric Uncertainty in the Causal Treatment Effect", "comment": null, "summary": "Previous work on causal inference has primarily focused on averages and conditional averages of treatment effects, with significantly less attention on variability and uncertainty in individual treatment responses. In this paper, we introduce the variance of the treatment effect (VTE) and conditional variance of treatment effect (CVTE) as the natural measure of aleatoric uncertainty inherent in treatment responses, and we demonstrate that these quantities are identifiable from observed data under mild assumptions, even in the presence of unobserved confounders. We further propose nonparametric kernel-based estimators for VTE and CVTE, and our theoretical analysis establishes their convergence. We also test the performance of our method through extensive empirical experiments on both synthetic and semi-simulated datasets, where it demonstrates superior or comparable performance to naive baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u6cbb\u7597\u6548\u5e94\u65b9\u5dee(VTE)\u548c\u6761\u4ef6\u6cbb\u7597\u6548\u5e94\u65b9\u5dee(CVTE)\u4f5c\u4e3a\u8861\u91cf\u6cbb\u7597\u54cd\u5e94\u4e2d\u56fa\u6709\u968f\u673a\u4e0d\u786e\u5b9a\u6027\u7684\u6307\u6807\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u91cf\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u53ef\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u8bc6\u522b\uff0c\u5e76\u5f00\u53d1\u4e86\u975e\u53c2\u6570\u6838\u4f30\u8ba1\u5668\u3002", "motivation": "\u5148\u524d\u56e0\u679c\u63a8\u65ad\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6cbb\u7597\u6548\u5e94\u7684\u5e73\u5747\u503c\u548c\u6761\u4ef6\u5e73\u5747\u503c\uff0c\u5bf9\u4e2a\u4f53\u6cbb\u7597\u54cd\u5e94\u7684\u53d8\u5f02\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u5173\u6ce8\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5f15\u5165\u6cbb\u7597\u6548\u5e94\u65b9\u5dee\u4f5c\u4e3a\u8861\u91cf\u6cbb\u7597\u54cd\u5e94\u4e2d\u56fa\u6709\u968f\u673a\u4e0d\u786e\u5b9a\u6027\u7684\u81ea\u7136\u5ea6\u91cf\u3002", "method": "\u63d0\u51fa\u6cbb\u7597\u6548\u5e94\u65b9\u5dee(VTE)\u548c\u6761\u4ef6\u6cbb\u7597\u6548\u5e94\u65b9\u5dee(CVTE)\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u8fd9\u4e9b\u91cf\u5728\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u5b50\u7684\u60c5\u51b5\u4e0b\u4ecd\u53ef\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u8bc6\u522b\u3002\u5f00\u53d1\u4e86\u975e\u53c2\u6570\u6838\u57fa\u4f30\u8ba1\u5668\u6765\u4f30\u8ba1VTE\u548cCVTE\uff0c\u5e76\u8fdb\u884c\u4e86\u7406\u8bba\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u4f30\u8ba1\u5668\u7684\u6536\u655b\u6027\u3002\u5728\u5408\u6210\u548c\u534a\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6216\u4e0e\u6734\u7d20\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u56e0\u679c\u63a8\u65ad\u4e2d\u5bf9\u6cbb\u7597\u6548\u5e94\u53d8\u5f02\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0d\u8db3\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684VTE\u548cCVTE\u6982\u5ff5\u53ca\u5176\u4f30\u8ba1\u65b9\u6cd5\u4e3a\u7406\u89e3\u4e2a\u4f53\u6cbb\u7597\u54cd\u5e94\u7684\u56fa\u6709\u968f\u673a\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.08478", "categories": ["cs.LG", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.08478", "abs": "https://arxiv.org/abs/2602.08478", "authors": ["Albert Alcalde", "Markus Widhalm", "Emre Y\u0131lmaz"], "title": "Time-Delayed Transformers for Data-Driven Modeling of Low-Dimensional Dynamics", "comment": null, "summary": "We propose the time-delayed transformer (TD-TF), a simplified transformer architecture for data-driven modeling of unsteady spatio-temporal dynamics. TD-TF bridges linear operator-based methods and deep sequence models by showing that a single-layer, single-head transformer can be interpreted as a nonlinear generalization of time-delayed dynamic mode decomposition (TD-DMD). The architecture is deliberately minimal, consisting of one self-attention layer with a single query per prediction and one feedforward layer, resulting in linear computational complexity in sequence length and a small parameter count. Numerical experiments demonstrate that TD-TF matches the performance of strong linear baselines on near-linear systems, while significantly outperforming them in nonlinear and chaotic regimes, where it accurately captures long-term dynamics. Validation studies on synthetic signals, unsteady aerodynamics, the Lorenz '63 system, and a reaction-diffusion model show that TD-TF preserves the interpretability and efficiency of linear models while providing substantially enhanced expressive power for complex dynamics.", "AI": {"tldr": "TD-TF\u662f\u4e00\u79cd\u7b80\u5316\u7684Transformer\u67b6\u6784\uff0c\u7528\u4e8e\u975e\u5b9a\u5e38\u65f6\u7a7a\u52a8\u529b\u5b66\u5efa\u6a21\uff0c\u5c06\u7ebf\u6027\u7b97\u5b50\u65b9\u6cd5\u4e0e\u6df1\u5ea6\u5e8f\u5217\u6a21\u578b\u8fde\u63a5\u8d77\u6765\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7ebf\u6027\u7b97\u5b50\u65b9\u6cd5\uff08\u5982TD-DMD\uff09\u5728\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u65f6\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u800c\u590d\u6742Transformer\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u53c8\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u7684\u7b80\u5316\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u5ef6\u8fdfTransformer\uff08TD-TF\uff09\uff0c\u91c7\u7528\u6781\u7b80\u8bbe\u8ba1\uff1a\u5355\u5c42\u5355\u5934\u81ea\u6ce8\u610f\u529b\u5c42\uff08\u6bcf\u4e2a\u9884\u6d4b\u4e00\u4e2a\u67e5\u8be2\uff09\u52a0\u4e00\u4e2a\u524d\u9988\u5c42\u3002\u8be5\u67b6\u6784\u53ef\u89e3\u91ca\u4e3a\u65f6\u95f4\u5ef6\u8fdf\u52a8\u6001\u6a21\u6001\u5206\u89e3\uff08TD-DMD\uff09\u7684\u975e\u7ebf\u6027\u6cdb\u5316\uff0c\u5177\u6709\u5e8f\u5217\u957f\u5ea6\u7684\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5c11\u91cf\u53c2\u6570\u3002", "result": "\u5728\u8fd1\u7ebf\u6027\u7cfb\u7edf\u4e0a\uff0cTD-TF\u4e0e\u5f3a\u7ebf\u6027\u57fa\u7ebf\u6027\u80fd\u76f8\u5f53\uff1b\u5728\u975e\u7ebf\u6027\u548c\u6df7\u6c8c\u7cfb\u7edf\u4e2d\uff0c\u663e\u8457\u4f18\u4e8e\u7ebf\u6027\u65b9\u6cd5\uff0c\u80fd\u51c6\u786e\u6355\u6349\u957f\u671f\u52a8\u529b\u5b66\u3002\u5728\u5408\u6210\u4fe1\u53f7\u3001\u975e\u5b9a\u5e38\u7a7a\u6c14\u52a8\u529b\u5b66\u3001Lorenz '63\u7cfb\u7edf\u548c\u53cd\u5e94\u6269\u6563\u6a21\u578b\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0cTD-TF\u5728\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u7684\u540c\u65f6\uff0c\u8868\u8fbe\u80fd\u529b\u5927\u5e45\u589e\u5f3a\u3002", "conclusion": "TD-TF\u6210\u529f\u6865\u63a5\u4e86\u7ebf\u6027\u7b97\u5b50\u65b9\u6cd5\u548c\u6df1\u5ea6\u5e8f\u5217\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u975e\u5b9a\u5e38\u65f6\u7a7a\u52a8\u529b\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.08499", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08499", "abs": "https://arxiv.org/abs/2602.08499", "authors": ["Xiaodong Lu", "Xiaohan Wang", "Jiajun Chai", "Guojun Yin", "Wei Lin", "Zhijun Chen", "Yu Luo", "Fuzhen Zhuang", "Yikun Ban", "Deqing Wang"], "title": "Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is an effective paradigm for improving the reasoning capabilities of large language models. However, existing RLVR methods utilize rollouts in an indiscriminate and short-horizon manner: responses of heterogeneous quality within each prompt are treated uniformly, and historical rollouts are discarded after a single use. This leads to noisy supervision, poor sample efficiency, and suboptimal policy updates. We address these issues by formulating rollout scheduling in RLVR as a contextual bandit problem and proposing a unified neural scheduling framework that adaptively selects high-value rollouts throughout training. Each rollout is treated as an arm whose reward is defined by the induced performance gain between consecutive optimization steps. The resulting scheduler supports both noise-aware intra-group selection and adaptive global reuse of historical rollouts within a single principled framework. We provide theoretical justification by deriving sublinear regret bounds and showing that enlarging the rollout buffer improves the achievable performance upper bound. Experiments on six mathematical reasoning benchmarks demonstrate consistent gains in performance and training efficiency across multiple RLVR optimization methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u7684RLVR rollout\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u9ad8\u8d28\u91cfrollout\u6765\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5728rollout\u4f7f\u7528\u4e0a\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u5bf9\u540c\u4e00\u63d0\u793a\u4e2d\u4e0d\u540c\u8d28\u91cf\u7684\u54cd\u5e94\u5904\u7406\u65b9\u5f0f\u76f8\u540c\uff0c\u5bfc\u81f4\u566a\u58f0\u76d1\u7763\uff1b2) \u5386\u53f2rollout\u4ec5\u4f7f\u7528\u4e00\u6b21\u5c31\u88ab\u4e22\u5f03\uff0c\u5bfc\u81f4\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u548c\u6b21\u4f18\u7b56\u7565\u66f4\u65b0", "method": "\u5c06RLVR\u4e2d\u7684rollout\u8c03\u5ea6\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51fa\u7edf\u4e00\u7684\u795e\u7ecf\u8c03\u5ea6\u6846\u67b6\u3002\u6bcf\u4e2arollout\u88ab\u89c6\u4e3a\u4e00\u4e2a\u81c2\uff0c\u5176\u5956\u52b1\u5b9a\u4e49\u4e3a\u8fde\u7eed\u4f18\u5316\u6b65\u9aa4\u95f4\u7684\u6027\u80fd\u589e\u76ca\u3002\u8be5\u8c03\u5ea6\u5668\u652f\u6301\u566a\u58f0\u611f\u77e5\u7684\u7ec4\u5185\u9009\u62e9\u548c\u5386\u53f2rollout\u7684\u81ea\u9002\u5e94\u5168\u5c40\u91cd\u7528", "result": "\u5728\u516d\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aRLVR\u4f18\u5316\u65b9\u6cd5\u4e0a\u90fd\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u7684\u4e00\u81f4\u63d0\u5347", "conclusion": "\u901a\u8fc7\u5c06rollout\u8c03\u5ea6\u5f62\u5f0f\u5316\u4e3a\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u8c03\u5ea6\u6846\u67b6\u80fd\u591f\u81ea\u9002\u5e94\u9009\u62e9\u9ad8\u4ef7\u503crollout\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709RLVR\u65b9\u6cd5\u7684\u566a\u58f0\u76d1\u7763\u548c\u6837\u672c\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd"}}
{"id": "2602.08500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08500", "abs": "https://arxiv.org/abs/2602.08500", "authors": ["Maiqi Jiang", "Noman Ali", "Yiran Ding", "Yanfu Zhang"], "title": "Is Meta-Path Attention an Explanation? Evidence of Alignment and Decoupling in Heterogeneous GNNs", "comment": null, "summary": "Meta-path-based heterogeneous graph neural networks aggregate over meta-path-induced views, and their semantic-level attention over meta-path channels is widely used as a narrative for ``which semantics matter.'' We study this assumption empirically by asking: when does meta-path attention reflect meta-path importance, and when can it decouple? A key challenge is that most post-hoc GNN explainers are designed for homogeneous graphs, and naive adaptations to heterogeneous neighborhoods can mix semantics and confound perturbations. To enable a controlled empirical analysis, we introduce MetaXplain, a meta-path-aware post-hoc explanation protocol that applies existing explainers in the native meta-path view domain via (i) view-factorized explanations, (ii) schema-valid channel-wise perturbations, and (iii) fusion-aware attribution, without modifying the underlying predictor. We benchmark representative gradient-, perturbation-, and Shapley-style explainers on ACM, DBLP, and IMDB with HAN and HAN-GCN, comparing against xPath and type-matched random baselines under standard faithfulness metrics. To quantify attention reliability, we propose Meta-Path Attention--Explanation Alignment (MP-AEA), which measures rank correlation between learned attention weights and explanation-derived meta-path contribution scores across random runs. Our results show that meta-path-aware explanations typically outperform random controls, while MP-AEA reveals both high-alignment and statistically significant decoupling regimes depending on the dataset and backbone; moreover, retraining on explanation-induced subgraphs often preserves, and in some noisy regimes improves, predictive performance, suggesting an explanation-as-denoising effect.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u5143\u8def\u5f84\u6ce8\u610f\u529b\u662f\u5426\u771f\u5b9e\u53cd\u6620\u5143\u8def\u5f84\u91cd\u8981\u6027\uff0c\u5f00\u53d1\u4e86MetaXplain\u89e3\u91ca\u534f\u8bae\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u4e0e\u89e3\u91ca\u5b58\u5728\u5bf9\u9f50\u548c\u8131\u94a9\u4e24\u79cd\u72b6\u6001\u3002", "motivation": "\u7814\u7a76\u5143\u8def\u5f84\u6ce8\u610f\u529b\u673a\u5236\u662f\u5426\u771f\u5b9e\u53cd\u6620\u5143\u8def\u5f84\u91cd\u8981\u6027\uff0c\u63a2\u7a76\u6ce8\u610f\u529b\u4e0e\u89e3\u91ca\u4f55\u65f6\u5bf9\u9f50\u3001\u4f55\u65f6\u8131\u94a9\uff0c\u89e3\u51b3\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u5728\u5f02\u6784\u56fe\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMetaXplain\u89e3\u91ca\u534f\u8bae\uff1a1) \u89c6\u56fe\u5206\u89e3\u89e3\u91ca\uff1b2) \u6a21\u5f0f\u6709\u6548\u901a\u9053\u6270\u52a8\uff1b3) \u878d\u5408\u611f\u77e5\u5f52\u56e0\u3002\u4f7f\u7528\u68af\u5ea6\u3001\u6270\u52a8\u548cShapley\u98ce\u683c\u89e3\u91ca\u5668\u5728ACM\u3001DBLP\u3001IMDB\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u63d0\u51faMP-AEA\u6307\u6807\u91cf\u5316\u6ce8\u610f\u529b\u53ef\u9760\u6027\u3002", "result": "\u5143\u8def\u5f84\u611f\u77e5\u89e3\u91ca\u4f18\u4e8e\u968f\u673a\u57fa\u7ebf\uff1bMP-AEA\u663e\u793a\u6ce8\u610f\u529b\u4e0e\u89e3\u91ca\u5b58\u5728\u9ad8\u5bf9\u9f50\u548c\u7edf\u8ba1\u663e\u8457\u8131\u94a9\u4e24\u79cd\u72b6\u6001\uff1b\u5728\u89e3\u91ca\u8bf1\u5bfc\u5b50\u56fe\u4e0a\u91cd\u8bad\u7ec3\u901a\u5e38\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u8868\u660e\u89e3\u91ca\u5177\u6709\u53bb\u566a\u6548\u679c\u3002", "conclusion": "\u5143\u8def\u5f84\u6ce8\u610f\u529b\u5e76\u4e0d\u603b\u662f\u53cd\u6620\u5143\u8def\u5f84\u91cd\u8981\u6027\uff0c\u5b58\u5728\u8131\u94a9\u73b0\u8c61\uff1b\u63d0\u51fa\u7684MetaXplain\u534f\u8bae\u80fd\u6709\u6548\u5206\u6790\u5f02\u6784\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u89e3\u91ca\u53ef\u5e2e\u52a9\u53bb\u566a\u5e76\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.08519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08519", "abs": "https://arxiv.org/abs/2602.08519", "authors": ["Yunhui Liu", "Pengyu Qiu", "Yu Xing", "Yongchao Liu", "Peng Du", "Chuntao Hong", "Jiajun Zheng", "Tao Zheng", "Tieke He"], "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering", "comment": null, "summary": "Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, a significant chasm persists between academic research and real-world deployment. Current evaluation protocols suffer from the small-scale, high-homophily citation datasets, non-scalable full-batch training paradigms, and a reliance on supervised metrics that fail to reflect performance in label-scarce environments. To bridge these gaps, we present PyAGC, a comprehensive, production-ready benchmark and library designed to stress-test AGC methods across diverse scales and structural properties. We unify existing methodologies into a modular Encode-Cluster-Optimize framework and, for the first time, provide memory-efficient, mini-batch implementations for a wide array of state-of-the-art AGC algorithms. Our benchmark curates 12 diverse datasets, ranging from 2.7K to 111M nodes, specifically incorporating industrial graphs with complex tabular features and low homophily. Furthermore, we advocate for a holistic evaluation protocol that mandates unsupervised structural metrics and efficiency profiling alongside traditional supervised metrics. Battle-tested in high-stakes industrial workflows at Ant Group, this benchmark offers the community a robust, reproducible, and scalable platform to advance AGC research towards realistic deployment. The code and resources are publicly available via GitHub (https://github.com/Cloudy1225/PyAGC), PyPI (https://pypi.org/project/pyagc), and Documentation (https://pyagc.readthedocs.io).", "AI": {"tldr": "PyAGC\u662f\u4e00\u4e2a\u9762\u5411\u5de5\u4e1a\u90e8\u7f72\u7684\u56fe\u805a\u7c7b\u57fa\u51c6\u5e93\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u534f\u8bae\u5728\u5c0f\u89c4\u6a21\u3001\u9ad8\u540c\u8d28\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684mini-batch\u5b9e\u73b0\u548c\u591a\u6837\u5316\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524d\u5c5e\u6027\u56fe\u805a\u7c7b\u7814\u7a76\u5b58\u5728\u5b66\u672f\u4e0e\u5de5\u4e1a\u5e94\u7528\u7684\u9e3f\u6c9f\uff1a\u8bc4\u4f30\u534f\u8bae\u4f9d\u8d56\u5c0f\u89c4\u6a21\u3001\u9ad8\u540c\u8d28\u6027\u7684\u5f15\u6587\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e0d\u53ef\u6269\u5c55\u7684\u5168\u6279\u6b21\u8bad\u7ec3\u8303\u5f0f\uff0c\u4e14\u4f9d\u8d56\u76d1\u7763\u6307\u6807\uff0c\u65e0\u6cd5\u53cd\u6620\u6807\u7b7e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u771f\u5b9e\u6027\u80fd\u3002", "method": "\u63d0\u51faPyAGC\u57fa\u51c6\u5e93\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u7edf\u4e00\u4e3a\u6a21\u5757\u5316\u7684Encode-Cluster-Optimize\u6846\u67b6\uff0c\u9996\u6b21\u4e3a\u591a\u79cdSOTA AGC\u7b97\u6cd5\u63d0\u4f9b\u5185\u5b58\u9ad8\u6548\u7684mini-batch\u5b9e\u73b0\u3002\u6784\u5efa\u5305\u542b12\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\uff082.7K\u5230111M\u8282\u70b9\uff09\u7684\u57fa\u51c6\uff0c\u7279\u522b\u5305\u542b\u5177\u6709\u590d\u6742\u8868\u683c\u7279\u5f81\u548c\u4f4e\u540c\u8d28\u6027\u7684\u5de5\u4e1a\u56fe\u3002", "result": "\u5728\u8682\u8681\u96c6\u56e2\u9ad8\u98ce\u9669\u5de5\u4e1a\u5de5\u4f5c\u6d41\u4e2d\u7ecf\u8fc7\u5b9e\u6218\u68c0\u9a8c\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u7a33\u5065\u3001\u53ef\u590d\u73b0\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u63a8\u52a8AGC\u7814\u7a76\u5411\u5b9e\u9645\u90e8\u7f72\u8fc8\u8fdb\u3002\u4ee3\u7801\u548c\u8d44\u6e90\u5df2\u516c\u5f00\u3002", "conclusion": "PyAGC\u901a\u8fc7\u63d0\u4f9b\u5168\u9762\u7684\u751f\u4ea7\u5c31\u7eea\u57fa\u51c6\u548c\u5e93\uff0c\u5f25\u5408\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5de5\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4fc3\u8fdb\u4e86\u5c5e\u6027\u56fe\u805a\u7c7b\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8bc4\u4f30\u548c\u5e94\u7528\u3002"}}
{"id": "2602.08535", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08535", "abs": "https://arxiv.org/abs/2602.08535", "authors": ["Rui Wu", "Li YongJun"], "title": "Causal Schr\u00f6dinger Bridges: Constrained Optimal Transport on Structural Manifolds", "comment": "12 pages, 7 figures", "summary": "Generative modeling typically seeks the path of least action via deterministic flows (ODE). While effective for in-distribution tasks, we argue that these deterministic paths become brittle under causal interventions, which often require transporting probability mass across low-density regions (\"off-manifold\") where the vector field is ill-defined. This leads to numerical instability and spurious correlations. In this work, we introduce the Causal Schr\u00f6dinger Bridge (CSB), a framework that reformulates counterfactual inference as Entropic Optimal Transport. Unlike deterministic approaches that require strict invertibility, CSB leverages diffusion processes (SDEs) to robustly \"tunnel\" through support mismatches while strictly enforcing structural admissibility constraints. We prove the Structural Decomposition Theorem, showing that the global high-dimensional bridge factorizes into local, robust transitions. Empirical validation on high-dimensional interventions (Morpho-MNIST) demonstrates that CSB significantly outperforms deterministic baselines in structural consistency, particularly in regimes of strong, out-of-distribution treatments.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u859b\u5b9a\u8c14\u6865\uff08CSB\uff09\u6846\u67b6\uff0c\u5c06\u53cd\u4e8b\u5b9e\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u71b5\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u4f7f\u7528\u6269\u6563\u8fc7\u7a0b\uff08SDE\uff09\u5728\u652f\u6301\u96c6\u4e0d\u5339\u914d\u65f6\u7a33\u5065\u5730\"\u96a7\u9053\u7a7f\u8d8a\"\uff0c\u4f18\u4e8e\u786e\u5b9a\u6027\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u5efa\u6a21\u4f7f\u7528\u786e\u5b9a\u6027\u6d41\uff08ODE\uff09\u5bfb\u627e\u6700\u5c0f\u4f5c\u7528\u8def\u5f84\uff0c\u4f46\u5728\u56e0\u679c\u5e72\u9884\u4e0b\u53d8\u5f97\u8106\u5f31\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8de8\u4f4e\u5bc6\u5ea6\u533a\u57df\uff08\"\u79bb\u6d41\u5f62\"\uff09\u4f20\u8f93\u6982\u7387\u8d28\u91cf\u65f6\uff0c\u5411\u91cf\u573a\u5b9a\u4e49\u4e0d\u660e\u786e\uff0c\u5bfc\u81f4\u6570\u503c\u4e0d\u7a33\u5b9a\u548c\u865a\u5047\u76f8\u5173\u6027\u3002", "method": "\u5f15\u5165\u56e0\u679c\u859b\u5b9a\u8c14\u6865\uff08CSB\uff09\u6846\u67b6\uff0c\u5c06\u53cd\u4e8b\u5b9e\u63a8\u7406\u91cd\u65b0\u8868\u8ff0\u4e3a\u71b5\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u3002\u4e0e\u9700\u8981\u4e25\u683c\u53ef\u9006\u6027\u7684\u786e\u5b9a\u6027\u65b9\u6cd5\u4e0d\u540c\uff0cCSB\u5229\u7528\u6269\u6563\u8fc7\u7a0b\uff08SDE\uff09\u5728\u652f\u6301\u96c6\u4e0d\u5339\u914d\u65f6\u7a33\u5065\u5730\"\u96a7\u9053\u7a7f\u8d8a\"\uff0c\u540c\u65f6\u4e25\u683c\u5f3a\u5236\u6267\u884c\u7ed3\u6784\u53ef\u5bb9\u8bb8\u7ea6\u675f\u3002\u8bc1\u660e\u4e86\u7ed3\u6784\u5206\u89e3\u5b9a\u7406\uff0c\u8868\u660e\u5168\u5c40\u9ad8\u7ef4\u6865\u53ef\u5206\u89e3\u4e3a\u5c40\u90e8\u7a33\u5065\u8f6c\u79fb\u3002", "result": "\u5728\u9ad8\u7ef4\u5e72\u9884\uff08Morpho-MNIST\uff09\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0cCSB\u5728\u7ed3\u6784\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u786e\u5b9a\u6027\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u5f3a\u3001\u5206\u5e03\u5916\u5904\u7406\u673a\u5236\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "CSB\u4e3a\u53cd\u4e8b\u5b9e\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5065\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u5904\u7406\u652f\u6301\u96c6\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u907f\u514d\u4e86\u786e\u5b9a\u6027\u65b9\u6cd5\u5728\u56e0\u679c\u5e72\u9884\u4e0b\u7684\u8106\u5f31\u6027\uff0c\u5728\u7ed3\u6784\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.08563", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08563", "abs": "https://arxiv.org/abs/2602.08563", "authors": ["Ahmed Salem", "Andrew Paverd", "Sahar Abdelnabi"], "title": "Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs", "comment": "Accepted at IEEE SaTML 2026", "summary": "Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does not require any explicit memory module, yet it creates a persistent information channel across inference requests. As a concrete demonstration, we introduce a new class of temporal backdoors, which we call time bombs. Unlike conventional backdoors that activate on a single trigger input, time bombs activate only after a sequence of interactions satisfies hidden conditions accumulated via implicit memory. We show that such behavior can be induced today through straightforward prompting or fine-tuning. Beyond this case study, we analyze broader implications of implicit memory, including covert inter-agent communication, benchmark contamination, targeted manipulation, and training-data poisoning. Finally, we discuss detection challenges and outline directions for stress-testing and evaluation, with the goal of anticipating and controlling future developments. To promote future research, we release code and data at: https://github.com/microsoft/implicitMemory.", "AI": {"tldr": "LLMs\u53ef\u4ee5\u901a\u8fc7\u9690\u5f0f\u8bb0\u5fc6\u5728\u72ec\u7acb\u4ea4\u4e92\u95f4\u4f20\u9012\u4fe1\u606f\uff0c\u65e0\u9700\u663e\u5f0f\u5b58\u50a8\u6a21\u5757\uff0c\u8fd9\u5e26\u6765\u4e86\u65f6\u95f4\u70b8\u5f39\u7b49\u65b0\u578b\u5b89\u5168\u5a01\u80c1", "motivation": "\u6311\u6218LLMs\u4f5c\u4e3a\u65e0\u72b6\u6001\u7cfb\u7edf\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u63a2\u7d22\u6a21\u578b\u901a\u8fc7\u81ea\u8eab\u8f93\u51fa\u7f16\u7801\u4fe1\u606f\u5e76\u5728\u540e\u7eed\u4ea4\u4e92\u4e2d\u6062\u590d\u7684\u9690\u5f0f\u8bb0\u5fc6\u80fd\u529b", "method": "\u5f15\u5165\u9690\u5f0f\u8bb0\u5fc6\u6982\u5ff5\uff0c\u901a\u8fc7\u65f6\u95f4\u70b8\u5f39\u4f5c\u4e3a\u5177\u4f53\u6848\u4f8b\u5c55\u793a\uff0c\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u6216\u5fae\u8c03\u8bf1\u5bfc\u6b64\u7c7b\u884c\u4e3a\uff0c\u5206\u6790\u5176\u5b89\u5168\u5f71\u54cd", "result": "\u8bc1\u660e\u9690\u5f0f\u8bb0\u5fc6\u786e\u5b9e\u5b58\u5728\u4e14\u53ef\u88ab\u5229\u7528\uff0c\u65f6\u95f4\u70b8\u5f39\u7b49\u5a01\u80c1\u53ef\u5728\u5f53\u524dLLMs\u4e2d\u5b9e\u73b0\uff0c\u63ed\u793a\u4e86\u591a\u79cd\u5b89\u5168\u98ce\u9669", "conclusion": "\u9690\u5f0f\u8bb0\u5fc6\u662fLLMs\u7684\u91cd\u8981\u7279\u6027\uff0c\u9700\u8981\u65b0\u7684\u68c0\u6d4b\u65b9\u6cd5\u548c\u8bc4\u4f30\u6846\u67b6\u6765\u5e94\u5bf9\u5176\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218"}}
{"id": "2602.08564", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08564", "abs": "https://arxiv.org/abs/2602.08564", "authors": ["Tiantong Wang", "Yiyang Duan", "Haoyu Chen", "Tiantong Wu", "Wei Yang Bryan Lim"], "title": "M-Loss: Quantifying Model Merging Compatibility with Limited Unlabeled Data", "comment": "Code available at https://github.com/languangduan/mLoss", "summary": "Training of large-scale models is both computationally intensive and often constrained by the availability of labeled data. Model merging offers a compelling alternative by directly integrating the weights of multiple source models without requiring additional data or extensive training. However, conventional model merging techniques, such as parameter averaging, often suffer from the unintended combination of non-generalizable features, especially when source models exhibit significant weight disparities. Comparatively, model ensembling generally provides more stable and superior performance that aggregates multiple models by averaging outputs. However, it incurs higher inference costs and increased storage requirements. While previous studies experimentally showed the similarities between model merging and ensembling, theoretical evidence and evaluation metrics remain lacking. To address this gap, we introduce Merging-ensembling loss (M-Loss), a novel evaluation metric that quantifies the compatibility of merging source models using very limited unlabeled data. By measuring the discrepancy between parameter averaging and model ensembling at layer and node levels, M-Loss facilitates more effective merging strategies. Specifically, M-Loss serves both as a quantitative criterion of the theoretical feasibility of model merging, and a guide for parameter significance in model pruning. Our theoretical analysis and empirical evaluations demonstrate that incorporating M-Loss into the merging process significantly improves the alignment between merged models and model ensembling, providing a scalable and efficient framework for accurate model consolidation.", "AI": {"tldr": "\u63d0\u51faM-Loss\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u5408\u5e76\u7684\u517c\u5bb9\u6027\uff0c\u901a\u8fc7\u6d4b\u91cf\u53c2\u6570\u5e73\u5747\u4e0e\u6a21\u578b\u96c6\u6210\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6307\u5bfc\u66f4\u6709\u6548\u7684\u6a21\u578b\u5408\u5e76\u7b56\u7565\u3002", "motivation": "\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u8ba1\u7b97\u5bc6\u96c6\u4e14\u53d7\u6807\u6ce8\u6570\u636e\u9650\u5236\u3002\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u53c2\u6570\u5e73\u5747\u65b9\u6cd5\u5bb9\u6613\u7ec4\u5408\u4e0d\u53ef\u6cdb\u5316\u7684\u7279\u5f81\uff0c\u800c\u6a21\u578b\u96c6\u6210\u867d\u7136\u6027\u80fd\u66f4\u7a33\u5b9a\u4f46\u63a8\u7406\u6210\u672c\u548c\u5b58\u50a8\u9700\u6c42\u66f4\u9ad8\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7406\u8bba\u8bc1\u636e\u548c\u8bc4\u4f30\u6307\u6807\u6765\u8fde\u63a5\u6a21\u578b\u5408\u5e76\u4e0e\u96c6\u6210\u3002", "method": "\u63d0\u51faMerging-ensembling loss (M-Loss)\u8bc4\u4f30\u6307\u6807\uff0c\u4f7f\u7528\u5c11\u91cf\u65e0\u6807\u7b7e\u6570\u636e\u91cf\u5316\u6a21\u578b\u5408\u5e76\u7684\u517c\u5bb9\u6027\u3002\u901a\u8fc7\u6d4b\u91cf\u53c2\u6570\u5e73\u5747\u4e0e\u6a21\u578b\u96c6\u6210\u5728\u5c42\u548c\u8282\u70b9\u7ea7\u522b\u7684\u5dee\u5f02\uff0c\u6307\u5bfc\u6a21\u578b\u5408\u5e76\u7b56\u7565\u3002M-Loss\u65e2\u4f5c\u4e3a\u6a21\u578b\u5408\u5e76\u7406\u8bba\u53ef\u884c\u6027\u7684\u91cf\u5316\u6807\u51c6\uff0c\u4e5f\u4f5c\u4e3a\u6a21\u578b\u526a\u679d\u4e2d\u53c2\u6570\u91cd\u8981\u6027\u7684\u6307\u5bfc\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u5c06M-Loss\u7eb3\u5165\u5408\u5e76\u8fc7\u7a0b\u80fd\u663e\u8457\u63d0\u9ad8\u5408\u5e76\u6a21\u578b\u4e0e\u6a21\u578b\u96c6\u6210\u4e4b\u95f4\u7684\u5bf9\u9f50\u5ea6\uff0c\u4e3a\u51c6\u786e\u6a21\u578b\u6574\u5408\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u6846\u67b6\u3002", "conclusion": "M-Loss\u586b\u8865\u4e86\u6a21\u578b\u5408\u5e76\u4e0e\u96c6\u6210\u4e4b\u95f4\u7406\u8bba\u8bc1\u636e\u548c\u8bc4\u4f30\u6307\u6807\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u91cf\u5316\u6a21\u578b\u5408\u5e76\u517c\u5bb9\u6027\u7684\u65b9\u6cd5\uff0c\u65e2\u80fd\u6307\u5bfc\u5408\u5e76\u7b56\u7565\uff0c\u53c8\u80fd\u4f5c\u4e3a\u6a21\u578b\u526a\u679d\u7684\u53c2\u8003\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u6a21\u578b\u6574\u5408\u3002"}}
{"id": "2602.08577", "categories": ["cs.LG", "math.CO", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.08577", "abs": "https://arxiv.org/abs/2602.08577", "authors": ["Theodoros Anagnostopoulos", "Evanthia Zervoudi", "Christos Anagnostopoulos", "Apostolos Christopoulos", "Bogdan Wierzbinski"], "title": "An arithmetic method algorithm optimizing k-nearest neighbors compared to regression algorithms and evaluated on real world data sources", "comment": "Nature Scientific Reports", "summary": "Linear regression analysis focuses on predicting a numeric regressand value based on certain regressor values. In this context, k-Nearest Neighbors (k-NN) is a common non-parametric regression algorithm, which achieves efficient performance when compared with other algorithms in literature. In this research effort an optimization of the k-NN algorithm is proposed by exploiting the potentiality of an introduced arithmetic method, which can provide solutions for linear equations involving an arbitrary number of real variables. Specifically, an Arithmetic Method Algorithm (AMA) is adopted to assess the efficiency of the introduced arithmetic method, while an Arithmetic Method Regression (AMR) algorithm is proposed as an optimization of k-NN adopting the potentiality of AMA. Such algorithm is compared with other regression algorithms, according to an introduced optimal inference decision rule, and evaluated on certain real world data sources, which are publicly available. Results are promising since the proposed AMR algorithm has comparable performance with the other algorithms, while in most cases it achieves better performance than the k-NN. The output results indicate that introduced AMR is an optimization of k-NN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b97\u672f\u65b9\u6cd5\u7684\u56de\u5f52\u7b97\u6cd5AMR\uff0c\u4f5c\u4e3ak-NN\u7b97\u6cd5\u7684\u4f18\u5316\u7248\u672c\uff0c\u901a\u8fc7\u5f15\u5165\u7b97\u672f\u65b9\u6cd5\u89e3\u51b3\u591a\u5143\u7ebf\u6027\u65b9\u7a0b\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u7b97\u6cd5\u76f8\u5f53\u751a\u81f3\u4f18\u4e8ek-NN\u7684\u6027\u80fd\u3002", "motivation": "\u7ebf\u6027\u56de\u5f52\u5206\u6790\u4e2d\uff0ck-NN\u662f\u4e00\u79cd\u5e38\u89c1\u7684\u975e\u53c2\u6570\u56de\u5f52\u7b97\u6cd5\uff0c\u4f46\u4ecd\u6709\u4f18\u5316\u7a7a\u95f4\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u80fd\u591f\u5904\u7406\u4efb\u610f\u6570\u91cf\u5b9e\u53d8\u91cf\u7684\u7ebf\u6027\u65b9\u7a0b\u7684\u7b97\u672f\u65b9\u6cd5\uff0c\u6765\u63d0\u5347k-NN\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u7b97\u672f\u65b9\u6cd5\u56de\u5f52\uff08AMR\uff09\u7b97\u6cd5\u4f5c\u4e3ak-NN\u7684\u4f18\u5316\u7248\u672c\u3002\u9996\u5148\u5f00\u53d1\u7b97\u672f\u65b9\u6cd5\u7b97\u6cd5\uff08AMA\uff09\u6765\u8bc4\u4f30\u7b97\u672f\u65b9\u6cd5\u7684\u6548\u7387\uff0c\u7136\u540e\u5229\u7528AMA\u7684\u6f5c\u529b\u6784\u5efaAMR\u7b97\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u7684\u6700\u4f18\u63a8\u65ad\u51b3\u7b56\u89c4\u5219\u4e0e\u5176\u4ed6\u56de\u5f52\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u5728\u516c\u5f00\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684AMR\u7b97\u6cd5\u4e0e\u5176\u4ed6\u56de\u5f52\u7b97\u6cd5\u5177\u6709\u53ef\u6bd4\u6027\u80fd\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u4e8ek-NN\u7b97\u6cd5\u3002\u8f93\u51fa\u7ed3\u679c\u8bc1\u5b9eAMR\u662f\u5bf9k-NN\u7684\u6709\u6548\u4f18\u5316\u3002", "conclusion": "AMR\u7b97\u6cd5\u901a\u8fc7\u5f15\u5165\u7b97\u672f\u65b9\u6cd5\u6210\u529f\u4f18\u5316\u4e86k-NN\u56de\u5f52\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u4e0e\u5176\u4ed6\u7b97\u6cd5\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u539f\u59cbk-NN\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.08579", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08579", "abs": "https://arxiv.org/abs/2602.08579", "authors": ["Junsu Seo"], "title": "Modeling Score Approximation Errors in Diffusion Models via Forward SPDEs", "comment": null, "summary": "This study investigates the dynamics of Score-based Generative Models (SGMs) by treating the score estimation error as a stochastic source driving the Fokker-Planck equation. Departing from particle-centric SDE analyses, we employ an SPDE framework to model the evolution of the probability density field under stochastic drift perturbations. Under a simplified setting, we utilize this framework to interpret the robustness of generative models through the lens of geometric stability and displacement convexity. Furthermore, we introduce a candidate evaluation metric derived from the quadratic variation of the SPDE solution projected onto a radial test function. Preliminary observations suggest that this metric remains effective using only the initial 10% of the sampling trajectory, indicating a potential for computational efficiency.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5c06\u5206\u6570\u4f30\u8ba1\u8bef\u5dee\u89c6\u4e3a\u9a71\u52a8Fokker-Planck\u65b9\u7a0b\u7684\u968f\u673a\u6e90\uff0c\u5728SPDE\u6846\u67b6\u4e0b\u5206\u6790\u57fa\u4e8e\u5206\u6570\u7684\u751f\u6210\u6a21\u578b(SGMs)\u7684\u52a8\u529b\u5b66\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eSPDE\u89e3\u6295\u5f71\u5230\u5f84\u5411\u6d4b\u8bd5\u51fd\u6570\u4e0a\u7684\u4e8c\u6b21\u53d8\u5dee\u7684\u5019\u9009\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u7c92\u5b50\u7684SDE\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u4ece\u6982\u7387\u5bc6\u5ea6\u573a\u6f14\u5316\u7684\u89d2\u5ea6\u7406\u89e3SGMs\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u7279\u522b\u662f\u5206\u6570\u4f30\u8ba1\u8bef\u5dee\u5bf9\u751f\u6210\u8fc7\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b(SPDE)\u6846\u67b6\uff0c\u5c06\u5206\u6570\u4f30\u8ba1\u8bef\u5dee\u5efa\u6a21\u4e3aFokker-Planck\u65b9\u7a0b\u7684\u968f\u673a\u6f02\u79fb\u6270\u52a8\u6e90\uff0c\u5728\u7b80\u5316\u8bbe\u7f6e\u4e0b\u901a\u8fc7\u51e0\u4f55\u7a33\u5b9a\u6027\u548c\u4f4d\u79fb\u51f8\u6027\u5206\u6790\u751f\u6210\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8eSPDE\u89e3\u6295\u5f71\u5230\u5f84\u5411\u6d4b\u8bd5\u51fd\u6570\u4e0a\u7684\u4e8c\u6b21\u53d8\u5dee\u7684\u5019\u9009\u8bc4\u4f30\u6307\u6807\uff0c\u521d\u6b65\u89c2\u5bdf\u8868\u660e\u8be5\u6307\u6807\u4ec5\u9700\u91c7\u6837\u8f68\u8ff9\u7684\u524d10%\u5373\u53ef\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5177\u6709\u8ba1\u7b97\u6548\u7387\u6f5c\u529b\u3002", "conclusion": "SPDE\u6846\u67b6\u4e3a\u7406\u89e3SGMs\u7684\u968f\u673a\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u9c81\u68d2\u6027\u5206\u6790\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.08584", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08584", "abs": "https://arxiv.org/abs/2602.08584", "authors": ["Wensong Bai", "Chao Zhang", "Qihang Xu", "Chufan Chen", "Chenhao Zhou", "Hui Qian"], "title": "Conditional Sequence Modeling for Safe Reinforcement Learning", "comment": null, "summary": "Offline safe reinforcement learning (RL) aims to learn policies from a fixed dataset while maximizing performance under cumulative cost constraints. In practice, deployment requirements often vary across scenarios, necessitating a single policy that can adapt zero-shot to different cost thresholds. However, most existing offline safe RL methods are trained under a pre-specified threshold, yielding policies with limited generalization and deployment flexibility across cost thresholds. Motivated by recent progress in conditional sequence modeling (CSM), which enables flexible goal-conditioned control by specifying target returns, we propose RCDT, a CSM-based method that supports zero-shot deployment across multiple cost thresholds within a single trained policy. RCDT is the first CSM-based offline safe RL algorithm that integrates a Lagrangian-style cost penalty with an auto-adaptive penalty coefficient. To avoid overly conservative behavior and achieve a more favorable return--cost trade-off, a reward--cost-aware trajectory reweighting mechanism and Q-value regularization are further incorporated. Extensive experiments on the DSRL benchmark demonstrate that RCDT consistently improves return--cost trade-offs over representative baselines, advancing the state-of-the-art in offline safe RL.", "AI": {"tldr": "RCDT\u662f\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u5e8f\u5217\u5efa\u6a21\u7684\u79bb\u7ebf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u4e00\u8bad\u7ec3\u7b56\u7565\u5b9e\u73b0\u8de8\u591a\u4e2a\u6210\u672c\u9608\u503c\u7684\u96f6\u6837\u672c\u90e8\u7f72\uff0c\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u5f0f\u6210\u672c\u60e9\u7f5a\u3001\u5956\u52b1-\u6210\u672c\u611f\u77e5\u8f68\u8ff9\u91cd\u52a0\u6743\u548cQ\u503c\u6b63\u5219\u5316\u6765\u4f18\u5316\u56de\u62a5-\u6210\u672c\u6743\u8861\u3002", "motivation": "\u79bb\u7ebf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u9488\u5bf9\u9884\u5b9a\u4e49\u7684\u6210\u672c\u9608\u503c\u8bad\u7ec3\u7b56\u7565\uff0c\u5bfc\u81f4\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u90e8\u7f72\u573a\u666f\u4e2d\u53d8\u5316\u7684\u5b89\u5168\u8981\u6c42\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u96f6\u6837\u672c\u9002\u5e94\u591a\u79cd\u6210\u672c\u9608\u503c\u7684\u5355\u4e00\u7b56\u7565\u3002", "method": "RCDT\u57fa\u4e8e\u6761\u4ef6\u5e8f\u5217\u5efa\u6a21\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u62c9\u683c\u6717\u65e5\u5f0f\u6210\u672c\u60e9\u7f5a\u673a\u5236\uff08\u5177\u6709\u81ea\u9002\u5e94\u60e9\u7f5a\u7cfb\u6570\uff09\u3001\u5956\u52b1-\u6210\u672c\u611f\u77e5\u8f68\u8ff9\u91cd\u52a0\u6743\u673a\u5236\u548cQ\u503c\u6b63\u5219\u5316\uff0c\u4ee5\u907f\u514d\u8fc7\u5ea6\u4fdd\u5b88\u884c\u4e3a\u5e76\u4f18\u5316\u56de\u62a5-\u6210\u672c\u6743\u8861\u3002", "result": "\u5728DSRL\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRCDT\u5728\u56de\u62a5-\u6210\u672c\u6743\u8861\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u4ee3\u8868\u6027\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u79bb\u7ebf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7684\u6700\u65b0\u6280\u672f\u6c34\u5e73\u3002", "conclusion": "RCDT\u662f\u9996\u4e2a\u57fa\u4e8e\u6761\u4ef6\u5e8f\u5217\u5efa\u6a21\u7684\u79bb\u7ebf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u4e00\u8bad\u7ec3\u7b56\u7565\u652f\u6301\u8de8\u591a\u4e2a\u6210\u672c\u9608\u503c\u7684\u96f6\u6837\u672c\u90e8\u7f72\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u5927\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2602.08585", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08585", "abs": "https://arxiv.org/abs/2602.08585", "authors": ["Ziyao Tang", "Pengkun Jiao", "Xinhang Chen", "Wei Liu", "Shiyong Li", "Jingjing Chen"], "title": "Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction", "comment": null, "summary": "Given the quadratic complexity of attention, KV cache eviction is vital to accelerate model inference. Current KV cache eviction methods typically rely on instantaneous heuristic metrics, implicitly assuming that score magnitudes are consistent proxies for importance across all heads. However, this overlooks the heterogeneity in predictive fidelity across attention heads. While certain heads prioritize the instantaneous contribution of tokens, others are dedicated to capturing long-horizon utility. In this paper, we propose that optimal budget allocation should be governed by the marginal utility in preserving long-term semantic information. Based on this insight, we propose LU-KV, a novel framework that optimizes head-level budget allocation through a convex-hull relaxation and a marginal-utility-based greedy solver to achieve near-optimal precision. Furthermore, we implement a data-driven offline profiling protocol to facilitate the practical deployment of LU-KV. Extensive evaluations on LongBench and RULER benchmarks demonstrate that LU-KV achieves an 80% reduction in KV cache size with minimal performance degradation, while simultaneously reducing inference latency and GPU memory footprint.", "AI": {"tldr": "LU-KV\uff1a\u57fa\u4e8e\u8fb9\u9645\u6548\u7528\u7684KV\u7f13\u5b58\u6dd8\u6c70\u6846\u67b6\uff0c\u901a\u8fc7\u51f8\u5305\u677e\u5f1b\u548c\u8d2a\u5fc3\u6c42\u89e3\u5668\u4f18\u5316\u5934\u7ea7\u9884\u7b97\u5206\u914d\uff0c\u5728\u51cf\u5c1180%\u7f13\u5b58\u5927\u5c0f\u7684\u540c\u65f6\u4fdd\u6301\u6027\u80fd", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u6dd8\u6c70\u65b9\u6cd5\u4f9d\u8d56\u77ac\u65f6\u542f\u53d1\u5f0f\u6307\u6807\uff0c\u5047\u8bbe\u6240\u6709\u6ce8\u610f\u529b\u5934\u7684\u5206\u6570\u5927\u5c0f\u662f\u91cd\u8981\u6027\u7684\u4e00\u81f4\u4ee3\u7406\uff0c\u4f46\u5ffd\u7565\u4e86\u4e0d\u540c\u5934\u5728\u9884\u6d4b\u4fdd\u771f\u5ea6\u4e0a\u7684\u5f02\u8d28\u6027\u2014\u2014\u6709\u4e9b\u5934\u5173\u6ce8token\u7684\u77ac\u65f6\u8d21\u732e\uff0c\u6709\u4e9b\u5219\u6355\u83b7\u957f\u671f\u6548\u7528", "method": "\u63d0\u51faLU-KV\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u8fb9\u9645\u6548\u7528\u4f18\u5316\u5934\u7ea7\u9884\u7b97\u5206\u914d\uff1b2\uff09\u4f7f\u7528\u51f8\u5305\u677e\u5f1b\u548c\u8fb9\u9645\u6548\u7528\u8d2a\u5fc3\u6c42\u89e3\u5668\u5b9e\u73b0\u8fd1\u6700\u4f18\u7cbe\u5ea6\uff1b3\uff09\u5b9e\u65bd\u6570\u636e\u9a71\u52a8\u7684\u79bb\u7ebf\u5206\u6790\u534f\u8bae\u4ee5\u652f\u6301\u5b9e\u9645\u90e8\u7f72", "result": "\u5728LongBench\u548cRULER\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLU-KV\u5b9e\u73b0\u4e8680%\u7684KV\u7f13\u5b58\u5927\u5c0f\u51cf\u5c11\uff0c\u540c\u65f6\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\uff0c\u5e76\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\u548cGPU\u5185\u5b58\u5360\u7528", "conclusion": "\u901a\u8fc7\u8003\u8651\u6ce8\u610f\u529b\u5934\u7684\u5f02\u8d28\u6027\u548c\u57fa\u4e8e\u8fb9\u9645\u6548\u7528\u7684\u9884\u7b97\u5206\u914d\uff0cLU-KV\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684KV\u7f13\u5b58\u6dd8\u6c70\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b"}}
{"id": "2602.08589", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08589", "abs": "https://arxiv.org/abs/2602.08589", "authors": ["Emmanouil Kariotakis", "Aritra Konar"], "title": "FairRARI: A Plug and Play Framework for Fairness-Aware PageRank", "comment": null, "summary": "PageRank (PR) is a fundamental algorithm in graph machine learning tasks. Owing to the increasing importance of algorithmic fairness, we consider the problem of computing PR vectors subject to various group-fairness criteria based on sensitive attributes of the vertices. At present, principled algorithms for this problem are lacking - some cannot guarantee that a target fairness level is achieved, while others do not feature optimality guarantees. In order to overcome these shortcomings, we put forth a unified in-processing convex optimization framework, termed FairRARI, for tackling different group-fairness criteria in a ``plug and play'' fashion. Leveraging a variational formulation of PR, the framework computes fair PR vectors by solving a strongly convex optimization problem with fairness constraints, thereby ensuring that a target fairness level is achieved. We further introduce three different fairness criteria which can be efficiently tackled using FairRARI to compute fair PR vectors with the same asymptotic time-complexity as the original PR algorithm. Extensive experiments on real-world datasets showcase that FairRARI outperforms existing methods in terms of utility, while achieving the desired fairness levels across multiple vertex groups; thereby highlighting its effectiveness.", "AI": {"tldr": "FairRARI\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u51f8\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u8ba1\u7b97\u6ee1\u8db3\u4e0d\u540c\u7fa4\u4f53\u516c\u5e73\u6027\u6807\u51c6\u7684PageRank\u5411\u91cf\uff0c\u786e\u4fdd\u8fbe\u5230\u76ee\u6807\u516c\u5e73\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cbPageRank\u7b97\u6cd5\u76f8\u540c\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "motivation": "\u968f\u7740\u7b97\u6cd5\u516c\u5e73\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u9700\u8981\u8ba1\u7b97\u6ee1\u8db3\u57fa\u4e8e\u9876\u70b9\u654f\u611f\u5c5e\u6027\u7684\u7fa4\u4f53\u516c\u5e73\u6027\u6807\u51c6\u7684PageRank\u5411\u91cf\u3002\u76ee\u524d\u7f3a\u4e4f\u6709\u539f\u5219\u7684\u7b97\u6cd5\uff1a\u4e00\u4e9b\u65e0\u6cd5\u4fdd\u8bc1\u8fbe\u5230\u76ee\u6807\u516c\u5e73\u6c34\u5e73\uff0c\u53e6\u4e00\u4e9b\u7f3a\u4e4f\u6700\u4f18\u6027\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684in-processing\u51f8\u4f18\u5316\u6846\u67b6FairRARI\uff0c\u5229\u7528PageRank\u7684\u53d8\u5206\u516c\u5f0f\uff0c\u901a\u8fc7\u6c42\u89e3\u5177\u6709\u516c\u5e73\u6027\u7ea6\u675f\u7684\u5f3a\u51f8\u4f18\u5316\u95ee\u9898\u6765\u8ba1\u7b97\u516c\u5e73\u7684PageRank\u5411\u91cf\uff0c\u4ee5\"\u5373\u63d2\u5373\u7528\"\u65b9\u5f0f\u5904\u7406\u4e0d\u540c\u7684\u7fa4\u4f53\u516c\u5e73\u6027\u6807\u51c6\u3002", "result": "FairRARI\u80fd\u591f\u8ba1\u7b97\u5177\u6709\u4e0e\u539f\u59cbPageRank\u7b97\u6cd5\u76f8\u540c\u6e10\u8fd1\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u516c\u5e73PageRank\u5411\u91cf\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u5728\u6548\u7528\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u9876\u70b9\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u6240\u9700\u7684\u516c\u5e73\u6c34\u5e73\u3002", "conclusion": "FairRARI\u662f\u4e00\u4e2a\u6709\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u786e\u4fdd\u8fbe\u5230\u76ee\u6807\u516c\u5e73\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u56fe\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u516c\u5e73PageRank\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08590", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.08590", "abs": "https://arxiv.org/abs/2602.08590", "authors": ["Yicheng Di", "Wei Yuan", "Tieke He", "Zhanjie Zhang", "Ao Ma", "Yuan Liu", "Hongzhi Yin"], "title": "SDFed: Bridging Local Global Discrepancy via Subspace Refinement and Divergence Control in Federated Prompt Learning", "comment": "13 pages, 6 figures", "summary": "Vision-language pretrained models offer strong transferable representations, yet adapting them in privacy-sensitive multi-party settings is challenging due to the high communication cost of federated optimization and the limited local data on clients. Federated prompt learning mitigates this issue by keeping the VLPM backbone frozen and collaboratively training lightweight prompt parameters. However, existing approaches typically enforce a unified prompt structure and length across clients, which is inadequate under practical client heterogeneity in both data distributions and system resources, and may further introduce conflicts between globally shared and locally optimal knowledge. To address these challenges, we propose \\textbf{SDFed}, a heterogeneous federated prompt learning framework that bridges Local-Global Discrepancy via Subspace Refinement and Divergence Control. SDFed maintains a fixed-length global prompt for efficient aggregation while allowing each client to learn a variable-length local prompt to better match its data characteristics and capacity. To mitigate local-global conflicts and facilitate effective knowledge transfer, SDFed introduces a subspace refinement method for local prompts and an information retention and divergence control strategy that preserves key local information while maintaining appropriate separability between global and local representations. Extensive experiments on several datasets demonstrate that SDFed consistently improves performance and robustness in heterogeneous federated settings.", "AI": {"tldr": "SDFed\u662f\u4e00\u4e2a\u5f02\u6784\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5b50\u7a7a\u95f4\u7ec6\u5316\u548c\u53d1\u6563\u63a7\u5236\u89e3\u51b3\u672c\u5730-\u5168\u5c40\u5dee\u5f02\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u56fa\u5b9a\u957f\u5ea6\u5168\u5c40\u63d0\u793a\u7684\u540c\u65f6\u5141\u8bb8\u5ba2\u6237\u7aef\u5b66\u4e60\u53ef\u53d8\u957f\u5ea6\u7684\u672c\u5730\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5f3a\u5236\u5ba2\u6237\u7aef\u4f7f\u7528\u7edf\u4e00\u7684\u63d0\u793a\u7ed3\u6784\u548c\u957f\u5ea6\uff0c\u8fd9\u5728\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u548c\u7cfb\u7edf\u8d44\u6e90\u5b58\u5728\u5f02\u8d28\u6027\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u4e0d\u8db3\uff0c\u53ef\u80fd\u5f15\u5165\u5168\u5c40\u5171\u4eab\u77e5\u8bc6\u548c\u672c\u5730\u6700\u4f18\u77e5\u8bc6\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "method": "SDFed\u6846\u67b6\u4fdd\u6301\u56fa\u5b9a\u957f\u5ea6\u7684\u5168\u5c40\u63d0\u793a\u7528\u4e8e\u9ad8\u6548\u805a\u5408\uff0c\u540c\u65f6\u5141\u8bb8\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5b66\u4e60\u53ef\u53d8\u957f\u5ea6\u7684\u672c\u5730\u63d0\u793a\u4ee5\u5339\u914d\u5176\u6570\u636e\u7279\u5f81\u548c\u5bb9\u91cf\u3002\u901a\u8fc7\u5b50\u7a7a\u95f4\u7ec6\u5316\u65b9\u6cd5\u5904\u7406\u672c\u5730\u63d0\u793a\uff0c\u4ee5\u53ca\u4fe1\u606f\u4fdd\u7559\u548c\u53d1\u6563\u63a7\u5236\u7b56\u7565\u6765\u7f13\u89e3\u672c\u5730-\u5168\u5c40\u51b2\u7a81\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSDFed\u5728\u5f02\u6784\u8054\u90a6\u8bbe\u7f6e\u4e2d\u6301\u7eed\u63d0\u5347\u4e86\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "SDFed\u901a\u8fc7\u5904\u7406\u672c\u5730-\u5168\u5c40\u5dee\u5f02\uff0c\u4e3a\u5f02\u6784\u8054\u90a6\u63d0\u793a\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u901a\u4fe1\u6548\u7387\u7684\u540c\u65f6\u9002\u5e94\u5ba2\u6237\u7aef\u7684\u5f02\u8d28\u6027\u3002"}}
{"id": "2602.08592", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08592", "abs": "https://arxiv.org/abs/2602.08592", "authors": ["Tianyin Liao", "Chunyu Hu", "Yicheng Sui", "Xingxuan Zhang", "Peng Cui", "Jianxin Li", "Ziwei Zhang"], "title": "TFMLinker: Universal Link Predictor by Graph In-Context Learning with Tabular Foundation Models", "comment": null, "summary": "Link prediction is a fundamental task in graph machine learning with widespread applications such as recommendation systems, drug discovery, knowledge graphs, etc. In the foundation model era, how to develop universal link prediction methods across datasets and domains becomes a key problem, with some initial attempts adopting Graph Foundation Models utilizing Graph Neural Networks and Large Language Models. However, the existing methods face notable limitations, including limited pre-training scale or heavy reliance on textual information. Motivated by the success of tabular foundation models (TFMs) in achieving universal prediction across diverse tabular datasets, we explore an alternative approach by TFMs, which are pre-trained on diverse synthetic datasets sampled from structural causal models and support strong in-context learning independent of textual attributes. Nevertheless, adapting TFMs for link prediction faces severe technical challenges such as how to obtain the necessary context and capture link-centric topological information. To solve these challenges, we propose TFMLinker (Tabular Foundation Model for Link Predictor), aiming to leverage the in-context learning capabilities of TFMs to perform link prediction across diverse graphs without requiring dataset-specific fine-tuning. Specifically, we first develop a prototype-augmented local-global context module to construct context that captures both graph-specific and cross-graph transferable patterns. Next, we design a universal topology-aware link encoder to capture link-centric topological information and generate link representations as inputs for the TFM. Finally, we employ the TFM to predict link existence through in-context learning. Experiments on 6 graph benchmarks across diverse domains demonstrate the superiority of our method over state-of-the-art baselines without requiring dataset-specific finetuning.", "AI": {"tldr": "TFMLinker\uff1a\u5229\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u8de8\u6570\u636e\u96c6\u901a\u7528\u94fe\u63a5\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u7279\u5b9a\u6570\u636e\u96c6\u5fae\u8c03", "motivation": "\u73b0\u6709\u56fe\u57fa\u7840\u6a21\u578b\u5728\u94fe\u63a5\u9884\u6d4b\u4e2d\u5b58\u5728\u9884\u8bad\u7ec3\u89c4\u6a21\u6709\u9650\u6216\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u800c\u8868\u683c\u57fa\u7840\u6a21\u578b\u5728\u8de8\u6570\u636e\u96c6\u901a\u7528\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u5982\u4f55\u83b7\u53d6\u4e0a\u4e0b\u6587\u548c\u6355\u83b7\u62d3\u6251\u4fe1\u606f\u7684\u6311\u6218", "method": "1) \u539f\u578b\u589e\u5f3a\u7684\u5c40\u90e8-\u5168\u5c40\u4e0a\u4e0b\u6587\u6a21\u5757\u6784\u5efa\u4e0a\u4e0b\u6587\uff1b2) \u901a\u7528\u62d3\u6251\u611f\u77e5\u94fe\u63a5\u7f16\u7801\u5668\u751f\u6210\u94fe\u63a5\u8868\u793a\uff1b3) \u5229\u7528\u8868\u683c\u57fa\u7840\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u9884\u6d4b\u94fe\u63a5\u5b58\u5728\u6027", "result": "\u57286\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\uff0c\u4e14\u65e0\u9700\u7279\u5b9a\u6570\u636e\u96c6\u5fae\u8c03", "conclusion": "TFMLinker\u6210\u529f\u5c06\u8868\u683c\u57fa\u7840\u6a21\u578b\u5e94\u7528\u4e8e\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\uff0c\u5b9e\u73b0\u4e86\u8de8\u56fe\u6570\u636e\u96c6\u7684\u901a\u7528\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u56fe\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u7840\u6a21\u578b\u8303\u5f0f"}}
{"id": "2602.08616", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08616", "abs": "https://arxiv.org/abs/2602.08616", "authors": ["Heiko Hoppe", "Fabian Akkerman", "Wouter van Heeswijk", "Maximilian Schiffer"], "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces", "comment": "26 pages, 8 figures", "summary": "Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforcement Learning (DGRL), combining Sampled Dynamic Neighborhoods (SDN) and Distance-Based Updates (DBU) to enable efficient RL in spaces with up to 10$^\\text{20}$ actions. Unlike prior methods, SDN leverages a semantic embedding space to perform stochastic volumetric exploration, provably providing full support over a local trust region. Complementing this, DBU transforms policy optimization into a stable regression task, decoupling gradient variance from action space cardinality and guaranteeing monotonic policy improvement. DGRL naturally generalizes to hybrid continuous-discrete action spaces without requiring hierarchical dependencies. We demonstrate performance improvements of up to 66% against state-of-the-art benchmarks across regularly and irregularly structured environments, while simultaneously improving convergence speed and computational complexity.", "AI": {"tldr": "DGRL\u7b97\u6cd5\u901a\u8fc7\u91c7\u6837\u52a8\u6001\u90bb\u57df\u548c\u8ddd\u79bb\u5f15\u5bfc\u66f4\u65b0\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\uff0c\u5728\u9ad8\u8fbe10^20\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u7269\u6d41\u3001\u8c03\u5ea6\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\u7684\u5e94\u7528\u9762\u4e34\u5927\u89c4\u6a21\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u7684\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9650\u5236\u6027\u7684\u7f51\u683c\u7ed3\u6784\u6216\u8ba1\u7b97\u6602\u8d35\u7684\u6700\u8fd1\u90bb\u641c\u7d22\uff0c\u5728\u9ad8\u7ef4\u6216\u4e0d\u89c4\u5219\u7ed3\u6784\u57df\u4e2d\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51fa\u8ddd\u79bb\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60(DGRL)\uff0c\u7ed3\u5408\u91c7\u6837\u52a8\u6001\u90bb\u57df(SDN)\u548c\u8ddd\u79bb\u5f15\u5bfc\u66f4\u65b0(DBU)\u3002SDN\u5229\u7528\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u8fdb\u884c\u968f\u673a\u4f53\u79ef\u63a2\u7d22\uff0cDBU\u5c06\u7b56\u7565\u4f18\u5316\u8f6c\u5316\u4e3a\u7a33\u5b9a\u56de\u5f52\u4efb\u52a1\uff0c\u89e3\u8026\u68af\u5ea6\u65b9\u5dee\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u57fa\u6570\u3002", "result": "\u5728\u89c4\u5219\u548c\u4e0d\u89c4\u5219\u7ed3\u6784\u73af\u5883\u4e2d\uff0cDGRL\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u51c6\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe66%\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u53ef\u5904\u7406\u9ad8\u8fbe10^20\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u3002", "conclusion": "DGRL\u4e3a\u5927\u89c4\u6a21\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u5206\u5c42\u4f9d\u8d56\u5373\u53ef\u81ea\u7136\u6cdb\u5316\u5230\u6df7\u5408\u8fde\u7eed-\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5728\u8ba1\u7b97\u590d\u6742\u6027\u548c\u6027\u80fd\u65b9\u9762\u5747\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2602.08617", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08617", "abs": "https://arxiv.org/abs/2602.08617", "authors": ["Dario Fenoglio", "Pasquale Polverino", "Jacopo Quizi", "Martin Gjoreski", "Marc Langheinrich"], "title": "ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning", "comment": null, "summary": "Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propose ERIS, a serverless FL framework that balances privacy and accuracy while eliminating the server bottleneck and distributing the communication load. ERIS combines a model partitioning strategy, distributing aggregation across multiple client-side aggregators, with a distributed shifted gradient compression mechanism. We theoretically prove that ERIS (i) converges at the same rate as FedAvg under standard assumptions, and (ii) bounds mutual information leakage inversely with the number of aggregators, enabling strong privacy guarantees with no accuracy degradation. Experiments across image and text tasks, including large language models, confirm that ERIS achieves FedAvg-level accuracy while substantially reducing communication cost and improving robustness to membership inference and reconstruction attacks, without relying on heavy cryptography or noise injection.", "AI": {"tldr": "ERIS\u662f\u4e00\u4e2a\u65e0\u670d\u52a1\u5668\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u5206\u533a\u548c\u5206\u5e03\u5f0f\u68af\u5ea6\u538b\u7f29\uff0c\u5728\u4fdd\u6301FedAvg\u7ea7\u522b\u51c6\u786e\u6027\u7684\u540c\u65f6\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u5e76\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u6269\u5c55\u8054\u90a6\u5b66\u4e60\u5230\u5341\u4ebf\u53c2\u6570\u6a21\u578b\u65f6\u9762\u4e34\u901a\u4fe1\u6548\u7387\u3001\u6a21\u578b\u51c6\u786e\u6027\u548c\u9690\u79c1\u4fdd\u8bc1\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u5b64\u7acb\u5730\u5904\u7406\u8fd9\u4e9b\u6311\u6218\uff0c\u727a\u7272\u51c6\u786e\u6027\u6216\u4f9d\u8d56\u6602\u8d35\u7684\u5bc6\u7801\u5b66\u5de5\u5177\u3002", "method": "ERIS\u7ed3\u5408\u4e86\u6a21\u578b\u5206\u533a\u7b56\u7565\uff08\u5c06\u805a\u5408\u5206\u5e03\u5728\u591a\u4e2a\u5ba2\u6237\u7aef\u805a\u5408\u5668\u4e0a\uff09\u548c\u5206\u5e03\u5f0f\u79fb\u4f4d\u68af\u5ea6\u538b\u7f29\u673a\u5236\uff0c\u6d88\u9664\u4e86\u670d\u52a1\u5668\u74f6\u9888\u5e76\u5206\u5e03\u4e86\u901a\u4fe1\u8d1f\u8f7d\u3002", "result": "\u7406\u8bba\u8bc1\u660eERIS\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u4e0eFedAvg\u4ee5\u76f8\u540c\u901f\u7387\u6536\u655b\uff0c\u5e76\u901a\u8fc7\u805a\u5408\u5668\u6570\u91cf\u9650\u5236\u4e92\u4fe1\u606f\u6cc4\u6f0f\u3002\u5b9e\u9a8c\u8868\u660eERIS\u5728\u56fe\u50cf\u548c\u6587\u672c\u4efb\u52a1\uff08\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\uff09\u4e2d\u8fbe\u5230FedAvg\u7ea7\u522b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u5e76\u63d0\u9ad8\u5bf9\u6210\u5458\u63a8\u7406\u548c\u91cd\u5efa\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "ERIS\u662f\u4e00\u4e2a\u5e73\u8861\u9690\u79c1\u548c\u51c6\u786e\u6027\u7684\u65e0\u670d\u52a1\u5668\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u4f9d\u8d56\u91cd\u578b\u5bc6\u7801\u5b66\u6216\u566a\u58f0\u6ce8\u5165\uff0c\u5c31\u80fd\u5728\u4fdd\u6301FedAvg\u7ea7\u522b\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u8bc1\u548c\u901a\u4fe1\u6548\u7387\u3002"}}
{"id": "2602.08621", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08621", "abs": "https://arxiv.org/abs/2602.08621", "authors": ["Yukun Jiang", "Hai Huang", "Mingjie Li", "Yage Zhang", "Michael Backes", "Yang Zhang"], "title": "Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs", "comment": null, "summary": "By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we show that the safety of MoE LLMs is as sparse as their architecture by discovering unsafe routes: routing configurations that, once activated, convert safe outputs into harmful ones. Specifically, we first introduce the Router Safety importance score (RoSais) to quantify the safety criticality of each layer's router. Manipulation of only the high-RoSais router(s) can flip the default route into an unsafe one. For instance, on JailbreakBench, masking 5 routers in DeepSeek-V2-Lite increases attack success rate (ASR) by over 4$\\times$ to 0.79, highlighting an inherent risk that router manipulation may naturally occur in MoE LLMs. We further propose a Fine-grained token-layer-wise Stochastic Optimization framework to discover more concrete Unsafe Routes (F-SOUR), which explicitly considers the sequentiality and dynamics of input tokens. Across four representative MoE LLM families, F-SOUR achieves an average ASR of 0.90 and 0.98 on JailbreakBench and AdvBench, respectively. Finally, we outline defensive perspectives, including safety-aware route disabling and router training, as promising directions to safeguard MoE LLMs. We hope our work can inform future red-teaming and safeguarding of MoE LLMs. Our code is provided in https://github.com/TrustAIRLab/UnsafeMoE.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0MoE\u67b6\u6784\u7684LLMs\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u64cd\u7eb5\u8def\u7531\u5668\u53ef\u4ee5\u6fc0\u6d3b\u4e0d\u5b89\u5168\u8def\u7531\uff0c\u5c06\u5b89\u5168\u8f93\u51fa\u8f6c\u6362\u4e3a\u6709\u5bb3\u5185\u5bb9\uff0c\u5e76\u63d0\u51fa\u9632\u5fa1\u65b9\u6cd5\u3002", "motivation": "MoE\u67b6\u6784\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6548\u7528\u548c\u6548\u7387\uff0c\u5bf9\u5176\u5b89\u5168\u98ce\u9669\u63a2\u7d22\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u63ed\u793aMoE LLMs\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51faRouter Safety\u91cd\u8981\u6027\u8bc4\u5206(RoSais)\u91cf\u5316\u8def\u7531\u5668\u5b89\u5168\u5173\u952e\u6027\uff0c\u5e76\u5f00\u53d1\u7ec6\u7c92\u5ea6token-layer-wise\u968f\u673a\u4f18\u5316\u6846\u67b6(F-SOUR)\u6765\u53d1\u73b0\u4e0d\u5b89\u5168\u8def\u7531\u3002", "result": "\u5728DeepSeek-V2-Lite\u4e0a\u4ec5\u5c4f\u853d5\u4e2a\u8def\u7531\u5668\u53ef\u4f7f\u653b\u51fb\u6210\u529f\u7387\u63d0\u53474\u500d\u4ee5\u4e0a\uff1bF-SOUR\u5728\u56db\u4e2aMoE LLM\u5bb6\u65cf\u4e0a\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u5206\u522b\u8fbe\u52300.90\u548c0.98\u3002", "conclusion": "MoE LLMs\u7684\u5b89\u5168\u6027\u4e0e\u67b6\u6784\u4e00\u6837\u7a00\u758f\uff0c\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002\u63d0\u51fa\u4e86\u5b89\u5168\u611f\u77e5\u8def\u7531\u7981\u7528\u548c\u8def\u7531\u5668\u8bad\u7ec3\u7b49\u9632\u5fa1\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7ea2\u961f\u6d4b\u8bd5\u548c\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2602.08638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08638", "abs": "https://arxiv.org/abs/2602.08638", "authors": ["Dezheng Wang", "Tong Chen", "Guansong Pang", "Congyan Chen", "Shihua Li", "Hongzhi Yin"], "title": "LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection", "comment": null, "summary": "As a fundamental data mining task, unsupervised time series anomaly detection (TSAD) aims to build a model for identifying abnormal timestamps without assuming the availability of annotations. A key challenge in unsupervised TSAD is that many anomalies are too subtle to exhibit detectable deviation in any single view (e.g., time domain), and instead manifest as inconsistencies across multiple views like time, frequency, and a mixture of resolutions. However, most cross-view methods rely on feature or score fusion and do not enforce analysis-synthesis consistency, meaning the frequency branch is not required to reconstruct the time signal through an inverse transform, and vice versa. In this paper, we present Learnable Fusion of Tri-view Tokens (LEFT), a unified unsupervised TSAD framework that models anomalies as inconsistencies across complementary representations. LEFT learns feature tokens from three views of the same input time series: frequency-domain tokens that embed periodicity information, time-domain tokens that capture local dynamics, and multi-scale tokens that learns abnormal patterns at varying time series granularities. By learning a set of adaptive Nyquist-constrained spectral filters, the original time series is rescaled into multiple resolutions and then encoded, allowing these multi-scale tokens to complement the extracted frequency- and time-domain information. When generating the fused representation, we introduce a novel objective that reconstructs fine-grained targets from coarser multi-scale structure, and put forward an innovative time-frequency cycle consistency constraint to explicitly regularize cross-view agreement. Experiments on real-world benchmarks show that LEFT yields the best detection accuracy against SOTA baselines, while achieving a 5x reduction on FLOPs and 8x speed-up for training.", "AI": {"tldr": "LEFT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u89c6\u56fe\u4ee4\u724c\u53ef\u5b66\u4e60\u878d\u5408\u7684\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u3001\u9891\u7387\u548c\u591a\u5c3a\u5ea6\u89c6\u56fe\u7684\u4e00\u81f4\u6027\u5efa\u6a21\u6765\u68c0\u6d4b\u5f02\u5e38\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u5173\u952e\u6311\u6218\u5728\u4e8e\u8bb8\u591a\u5f02\u5e38\u5728\u5355\u4e00\u89c6\u56fe\uff08\u5982\u65f6\u95f4\u57df\uff09\u4e2d\u8868\u73b0\u4e0d\u660e\u663e\uff0c\u800c\u662f\u901a\u8fc7\u591a\u4e2a\u89c6\u56fe\uff08\u65f6\u95f4\u3001\u9891\u7387\u3001\u591a\u5c3a\u5ea6\uff09\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u8868\u73b0\u51fa\u6765\u3002\u73b0\u6709\u8de8\u89c6\u56fe\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u7279\u5f81\u6216\u5206\u6570\u878d\u5408\uff0c\u7f3a\u4e4f\u5206\u6790-\u5408\u6210\u4e00\u81f4\u6027\u7ea6\u675f\u3002", "method": "LEFT\u6846\u67b6\u4ece\u4e09\u4e2a\u4e92\u8865\u89c6\u56fe\u5b66\u4e60\u7279\u5f81\u4ee4\u724c\uff1a\u9891\u7387\u57df\u4ee4\u724c\uff08\u5468\u671f\u6027\u4fe1\u606f\uff09\u3001\u65f6\u95f4\u57df\u4ee4\u724c\uff08\u5c40\u90e8\u52a8\u6001\uff09\u548c\u591a\u5c3a\u5ea6\u4ee4\u724c\uff08\u4e0d\u540c\u7c92\u5ea6\u5f02\u5e38\u6a21\u5f0f\uff09\u3002\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5948\u594e\u65af\u7279\u7ea6\u675f\u8c31\u6ee4\u6ce2\u5668\u5c06\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u91cd\u7f29\u653e\u4e3a\u591a\u5206\u8fa8\u7387\uff0c\u5e76\u5f15\u5165\u7ec6\u7c92\u5ea6\u76ee\u6807\u91cd\u5efa\u548c\u65f6\u9891\u5faa\u73af\u4e00\u81f4\u6027\u7ea6\u675f\u6765\u6b63\u5219\u5316\u8de8\u89c6\u56fe\u4e00\u81f4\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLEFT\u53d6\u5f97\u4e86\u6700\u4f73\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u4e865\u500d\u7684FLOPs\u51cf\u5c11\u548c8\u500d\u7684\u8bad\u7ec3\u52a0\u901f\u3002", "conclusion": "LEFT\u901a\u8fc7\u4e09\u89c6\u56fe\u4ee4\u724c\u7684\u53ef\u5b66\u4e60\u878d\u5408\u548c\u4e25\u683c\u7684\u8de8\u89c6\u56fe\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5f02\u5e38\u96be\u4ee5\u5728\u5355\u4e00\u89c6\u56fe\u4e2d\u68c0\u6d4b\u7684\u95ee\u9898\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.08646", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08646", "abs": "https://arxiv.org/abs/2602.08646", "authors": ["Jisung Hwang", "Minhyuk Sung"], "title": "Projected Gradient Ascent for Efficient Reward-Guided Updates with One-Step Generative Models", "comment": null, "summary": "We propose a constrained latent optimization method for reward-guided generation that preserves white Gaussian noise characteristics with negligible overhead. Test-time latent optimization can unlock substantially better reward-guided generations from pretrained generative models, but it is prone to reward hacking that degrades quality and also too slow for practical use. In this work, we make test-time optimization both efficient and reliable by replacing soft regularization with hard white Gaussian noise constraints enforced via projected gradient ascent. Our method applies a closed-form projection after each update to keep the latent vector explicitly noise-like throughout optimization, preventing the drift that leads to unrealistic artifacts. This enforcement adds minimal cost: the projection matches the $O(N \\log N)$ complexity of standard algorithms such as sorting or FFT and does not practically increase wall-clock time. In experiments, our approach reaches a comparable Aesthetic Score using only 30% of the wall-clock time required by the SOTA regularization-based method, while preventing reward hacking.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5e26\u7ea6\u675f\u7684\u9690\u53d8\u91cf\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u786c\u6027\u767d\u9ad8\u65af\u566a\u58f0\u7ea6\u675f\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u5956\u52b1\u5f15\u5bfc\u751f\u6210\uff0c\u9632\u6b62\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb", "motivation": "\u6d4b\u8bd5\u65f6\u9690\u53d8\u91cf\u4f18\u5316\u53ef\u4ee5\u4ece\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u4e2d\u89e3\u9501\u66f4\u597d\u7684\u5956\u52b1\u5f15\u5bfc\u751f\u6210\uff0c\u4f46\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\uff08\u964d\u4f4e\u8d28\u91cf\uff09\u4e14\u901f\u5ea6\u592a\u6162\uff0c\u4e0d\u9002\u5408\u5b9e\u9645\u5e94\u7528", "method": "\u7528\u786c\u6027\u767d\u9ad8\u65af\u566a\u58f0\u7ea6\u675f\u66ff\u4ee3\u8f6f\u6b63\u5219\u5316\uff0c\u901a\u8fc7\u6295\u5f71\u68af\u5ea6\u4e0a\u5347\u5f3a\u5236\u6267\u884c\u3002\u6bcf\u6b21\u66f4\u65b0\u540e\u5e94\u7528\u95ed\u5f0f\u6295\u5f71\uff0c\u4fdd\u6301\u9690\u5411\u91cf\u5728\u6574\u4e2a\u4f18\u5316\u8fc7\u7a0b\u4e2d\u660e\u786e\u4fdd\u6301\u566a\u58f0\u7279\u6027\uff0c\u9632\u6b62\u5bfc\u81f4\u4e0d\u771f\u5b9e\u4f2a\u5f71\u7684\u6f02\u79fb", "result": "\u65b9\u6cd5\u4ec5\u9700SOTA\u6b63\u5219\u5316\u65b9\u6cd530%\u7684\u6302\u949f\u65f6\u95f4\u5373\u53ef\u8fbe\u5230\u76f8\u5f53\u7684\u7f8e\u5b66\u8bc4\u5206\uff0c\u540c\u65f6\u9632\u6b62\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u3002\u6295\u5f71\u590d\u6742\u5ea6\u4e3aO(N log N)\uff0c\u4e0e\u6392\u5e8f\u6216FFT\u7b49\u6807\u51c6\u7b97\u6cd5\u76f8\u5f53\uff0c\u5b9e\u9645\u4e0a\u4e0d\u589e\u52a0\u6302\u949f\u65f6\u95f4", "conclusion": "\u901a\u8fc7\u786c\u6027\u767d\u9ad8\u65af\u566a\u58f0\u7ea6\u675f\u7684\u7ea6\u675f\u9690\u53d8\u91cf\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u6d4b\u8bd5\u65f6\u4f18\u5316\u65e2\u9ad8\u6548\u53c8\u53ef\u9760\uff0c\u89e3\u51b3\u4e86\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u5f15\u5bfc\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528\u6027"}}
{"id": "2602.08655", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08655", "abs": "https://arxiv.org/abs/2602.08655", "authors": ["Sarthak Wanjari"], "title": "From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism", "comment": "10 pages, 8 figures", "summary": "Offline Reinforcement Learning (RL) promises the recovery of optimal policies from static datasets, yet it remains susceptible to the overestimation of out-of-distribution (OOD) actions, particularly in fractured and sparse data manifolds.Current solutions necessitates a trade off between computational efficiency and performance. Methods like CQL offers rigorous conservatism but require tremendous compute power while efficient expectile-based methods like IQL often fail to correct OOD errors on pathological datasets, collapsing to Behavioural Cloning. In this work, we propose Geometric Pessimism, a modular, compute-efficient framework that augments standard IQL with density-based penalty derived from k-nearest-neighbour distances in the state-action embedding space. By pre-computing the penalties applied to each state-action pair our method injects OOD conservatism via reward shaping with a O(1) training overhead. Evaluated on the D4Rl MuJoCo benchmark, our method, Geo-IQL outperforms standard IQL on sensitive and unstable medium-replay tasks by over 18 points, while reducing inter-seed variance by 4x. Furthermore, Geo-IQL does not degrade performance on stable manifolds. Crucially, we validate our algorithm on the MIMIC-III Sepsis critical care dataset. While standard IQL collapses to behaviour cloning, Geo-IQL demonstrates active policy improvement. Maintaining safety constraints, achieving 86.4% terminal agreement with clinicians compared to IQL's 75%. Our results suggest that geometric pessimism provides the necessary regularisation to safely overcome local optima in critical, real-world decision systems.", "AI": {"tldr": "Geo-IQL\uff1a\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7k\u8fd1\u90bb\u8ddd\u79bb\u5728\u72b6\u6001-\u52a8\u4f5c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u52a0\u5165\u57fa\u4e8e\u5bc6\u5ea6\u7684\u60e9\u7f5a\uff0c\u6709\u6548\u89e3\u51b3\u5206\u5e03\u5916\u52a8\u4f5c\u9ad8\u4f30\u95ee\u9898\uff0c\u5728\u7a00\u758f\u6570\u636e\u548c\u5b9e\u9645\u533b\u7597\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5bb9\u6613\u9ad8\u4f30\u5206\u5e03\u5916\u52a8\u4f5c\uff0c\u7279\u522b\u662f\u5728\u7a00\u758f\u548c\u65ad\u88c2\u7684\u6570\u636e\u6d41\u5f62\u4e0a\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u6743\u8861\uff1aCQL\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800cIQL\u7b49\u9ad8\u6548\u65b9\u6cd5\u5728\u75c5\u6001\u6570\u636e\u96c6\u4e0a\u65e0\u6cd5\u7ea0\u6b63\u5206\u5e03\u5916\u9519\u8bef\uff0c\u4f1a\u9000\u5316\u4e3a\u884c\u4e3a\u514b\u9686\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u60b2\u89c2\u4e3b\u4e49\u6846\u67b6\uff0c\u5728\u6807\u51c6IQL\u57fa\u7840\u4e0a\u589e\u52a0\u57fa\u4e8ek\u8fd1\u90bb\u8ddd\u79bb\u7684\u5bc6\u5ea6\u60e9\u7f5a\u3002\u901a\u8fc7\u9884\u8ba1\u7b97\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u60e9\u7f5a\uff0c\u4ee5O(1)\u7684\u8bad\u7ec3\u5f00\u9500\u901a\u8fc7\u5956\u52b1\u5851\u5f62\u6ce8\u5165\u5206\u5e03\u5916\u4fdd\u5b88\u6027\u3002", "result": "\u5728D4RL MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGeo-IQL\u5728\u654f\u611f\u548c\u4e0d\u7a33\u5b9a\u7684medium-replay\u4efb\u52a1\u4e0a\u6bd4\u6807\u51c6IQL\u9ad8\u51fa18\u5206\u4ee5\u4e0a\uff0c\u540c\u65f6\u5c06\u79cd\u5b50\u95f4\u65b9\u5dee\u964d\u4f4e4\u500d\u3002\u5728MIMIC-III Sepsis\u91cd\u75c7\u76d1\u62a4\u6570\u636e\u4e0a\uff0c\u6807\u51c6IQL\u9000\u5316\u4e3a\u884c\u4e3a\u514b\u9686\uff0c\u800cGeo-IQL\u5c55\u793a\u4e86\u4e3b\u52a8\u7b56\u7565\u6539\u8fdb\uff0c\u4e0e\u4e34\u5e8a\u533b\u751f\u7ec8\u672b\u51b3\u7b56\u7684\u4e00\u81f4\u6027\u8fbe\u523086.4%\uff08IQL\u4e3a75%\uff09\u3002", "conclusion": "\u51e0\u4f55\u60b2\u89c2\u4e3b\u4e49\u4e3a\u5173\u952e\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6b63\u5219\u5316\uff0c\u80fd\u591f\u5b89\u5168\u5730\u514b\u670d\u5c40\u90e8\u6700\u4f18\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u7ea6\u675f\u7684\u540c\u65f6\u5b9e\u73b0\u7b56\u7565\u6539\u8fdb\u3002"}}
{"id": "2602.08657", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.08657", "abs": "https://arxiv.org/abs/2602.08657", "authors": ["Xiaotong Liu", "Shao-Bo Lin", "Jun Fan", "Ding-Xuan Zhou"], "title": "Two-Stage Data Synthesization: A Statistics-Driven Restricted Trade-off between Privacy and Prediction", "comment": null, "summary": "Synthetic data have gained increasing attention across various domains, with a growing emphasis on their performance in downstream prediction tasks. However, most existing synthesis strategies focus on maintaining statistical information. Although some studies address prediction performance guarantees, their single-stage synthesis designs make it challenging to balance the privacy requirements that necessitate significant perturbations and the prediction performance that is sensitive to such perturbations. We propose a two-stage synthesis strategy. In the first stage, we introduce a synthesis-then-hybrid strategy, which involves a synthesis operation to generate pure synthetic data, followed by a hybrid operation that fuses the synthetic data with the original data. In the second stage, we present a kernel ridge regression (KRR)-based synthesis strategy, where a KRR model is first trained on the original data and then used to generate synthetic outputs based on the synthetic inputs produced in the first stage. By leveraging the theoretical strengths of KRR and the covariant distribution retention achieved in the first stage, our proposed two-stage synthesis strategy enables a statistics-driven restricted privacy--prediction trade-off and guarantee optimal prediction performance. We validate our approach and demonstrate its characteristics of being statistics-driven and restricted in achieving the privacy--prediction trade-off both theoretically and numerically. Additionally, we showcase its generalizability through applications to a marketing problem and five real-world datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u5408\u6210\u6570\u636e\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u6210-\u6df7\u5408\u548c\u6838\u5cad\u56de\u5f52\u65b9\u6cd5\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4f18\u5316\u4e0b\u6e38\u9884\u6d4b\u6027\u80fd\uff0c\u5b9e\u73b0\u7edf\u8ba1\u9a71\u52a8\u7684\u9690\u79c1-\u9884\u6d4b\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u6570\u636e\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7edf\u8ba1\u4fe1\u606f\u4fdd\u6301\uff0c\u800c\u9884\u6d4b\u6027\u80fd\u4fdd\u8bc1\u7684\u7814\u7a76\u901a\u5e38\u91c7\u7528\u5355\u9636\u6bb5\u8bbe\u8ba1\uff0c\u96be\u4ee5\u5e73\u8861\u9700\u8981\u5927\u6270\u52a8\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u5bf9\u6270\u52a8\u654f\u611f\u7684\u9884\u6d4b\u6027\u80fd\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "method": "\u4e24\u9636\u6bb5\u5408\u6210\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\"\u5408\u6210-\u6df7\u5408\"\u65b9\u6cd5\uff0c\u5148\u751f\u6210\u7eaf\u5408\u6210\u6570\u636e\uff0c\u518d\u4e0e\u539f\u59cb\u6570\u636e\u878d\u5408\uff1b\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u6838\u5cad\u56de\u5f52(KRR)\u7684\u5408\u6210\u7b56\u7565\uff0c\u7528\u539f\u59cb\u6570\u636e\u8bad\u7ec3KRR\u6a21\u578b\uff0c\u7136\u540e\u57fa\u4e8e\u7b2c\u4e00\u9636\u6bb5\u751f\u6210\u7684\u5408\u6210\u8f93\u5165\u751f\u6210\u5408\u6210\u8f93\u51fa\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7edf\u8ba1\u9a71\u52a8\u7684\u53d7\u9650\u9690\u79c1-\u9884\u6d4b\u6743\u8861\uff0c\u4fdd\u8bc1\u4e86\u6700\u4f18\u9884\u6d4b\u6027\u80fd\u3002\u7406\u8bba\u548c\u6570\u503c\u9a8c\u8bc1\u4e86\u5176\u7edf\u8ba1\u9a71\u52a8\u548c\u53d7\u9650\u6743\u8861\u7279\u6027\uff0c\u5e76\u5728\u8425\u9500\u95ee\u9898\u548c\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u5408\u6210\u7b56\u7565\u901a\u8fc7\u7ed3\u5408KRR\u7684\u7406\u8bba\u4f18\u52bf\u548c\u7b2c\u4e00\u9636\u6bb5\u534f\u53d8\u5206\u5e03\u4fdd\u6301\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0e\u9884\u6d4b\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u5408\u6210\u6570\u636e\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.08660", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08660", "abs": "https://arxiv.org/abs/2602.08660", "authors": ["Alexandre Verine", "Rafael Pinot", "Florian Le Bronnec"], "title": "Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models", "comment": null, "summary": "Fairness is a crucial concern for generative models, which not only reflect but can also amplify societal and cultural biases. Existing fairness notions for generative models are largely adapted from classification and focus on balancing the probability of generating samples from each sensitive group. We show that such criteria are brittle, as they can be met even when different sensitive groups are modeled with widely varying quality. To address this limitation, we introduce a new fairness definition for generative models, termed as equalized generative treatment (EGT), which requires comparable generation quality across all sensitive groups, with quality measured via a reference f-divergence. We further analyze the trade-offs induced by EGT, demonstrating that enforcing fairness constraints necessarily couples the overall model quality to that of the most challenging group to approximate. This indicates that a simple yet efficient min-max fine-tuning method should be able to balance f-divergences across sensitive groups to satisfy EGT. We validate this theoretical insight through a set of experiments on both image and text generation tasks. We demonstrate that min-max methods consistently achieve fairer outcomes compared to other approaches from the literature, while maintaining competitive overall performance for both tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6a21\u578b\u516c\u5e73\u6027\u5b9a\u4e49EGT\uff0c\u5f3a\u8c03\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u95f4\u7684\u751f\u6210\u8d28\u91cf\u53ef\u6bd4\u6027\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u6837\u672c\u751f\u6210\u6982\u7387\u5e73\u8861\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u516c\u5e73\u7ea6\u675f\u4f1a\u8026\u5408\u6a21\u578b\u6574\u4f53\u8d28\u91cf\u4e0e\u6700\u96be\u8fd1\u4f3c\u7fa4\u4f53\u7684\u8d28\u91cf\uff0c\u636e\u6b64\u63d0\u51fa\u7b80\u5355\u9ad8\u6548\u7684min-max\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u56fe\u50cf\u548c\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u516c\u5e73\u6027\u6982\u5ff5\u4e3b\u8981\u4ece\u5206\u7c7b\u4efb\u52a1\u8fc1\u79fb\u800c\u6765\uff0c\u5173\u6ce8\u5e73\u8861\u5404\u654f\u611f\u7fa4\u4f53\u7684\u6837\u672c\u751f\u6210\u6982\u7387\u3002\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u6807\u51c6\u5f88\u8106\u5f31\uff0c\u5373\u4f7f\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u7684\u751f\u6210\u8d28\u91cf\u5dee\u5f02\u5f88\u5927\u4e5f\u80fd\u6ee1\u8db3\u3002\u9700\u8981\u66f4\u5168\u9762\u7684\u516c\u5e73\u6027\u5b9a\u4e49\u6765\u786e\u4fdd\u6240\u6709\u7fa4\u4f53\u90fd\u80fd\u83b7\u5f97\u53ef\u6bd4\u7684\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u516c\u5e73\u6027\u5b9a\u4e49EGT\uff0c\u8981\u6c42\u6240\u6709\u654f\u611f\u7fa4\u4f53\u7684\u751f\u6210\u8d28\u91cf\u53ef\u6bd4\uff0c\u7528\u53c2\u8003f-\u6563\u5ea6\u8861\u91cf\u8d28\u91cf\u3002\u7406\u8bba\u5206\u6790\u516c\u5e73\u7ea6\u675f\u7684\u6743\u8861\u6548\u5e94\uff0c\u53d1\u73b0\u4f1a\u8026\u5408\u6574\u4f53\u6a21\u578b\u8d28\u91cf\u4e0e\u6700\u96be\u8fd1\u4f3c\u7fa4\u4f53\u7684\u8d28\u91cf\u3002\u636e\u6b64\u63d0\u51famin-max\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u5404\u654f\u611f\u7fa4\u4f53\u7684f-\u6563\u5ea6\u6765\u6ee1\u8db3EGT\u3002", "result": "\u5728\u56fe\u50cf\u548c\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cmin-max\u65b9\u6cd5\u76f8\u6bd4\u6587\u732e\u4e2d\u5176\u4ed6\u65b9\u6cd5\u80fd\u6301\u7eed\u83b7\u5f97\u66f4\u516c\u5e73\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u90fd\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "EGT\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u516c\u5e73\u6027\u5b9a\u4e49\uff0c\u5f3a\u8c03\u751f\u6210\u8d28\u91cf\u53ef\u6bd4\u6027\u800c\u975e\u4ec5\u6982\u7387\u5e73\u8861\u3002min-max\u5fae\u8c03\u65b9\u6cd5\u662f\u5b9e\u73b0\u8fd9\u4e00\u516c\u5e73\u6027\u76ee\u6807\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2602.08676", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08676", "abs": "https://arxiv.org/abs/2602.08676", "authors": ["Tiwei Bie", "Maosong Cao", "Xiang Cao", "Bingsen Chen", "Fuyuan Chen", "Kun Chen", "Lun Du", "Daozhuo Feng", "Haibo Feng", "Mingliang Gong", "Zhuocheng Gong", "Yanmei Gu", "Jian Guan", "Kaiyuan Guan", "Hongliang He", "Zenan Huang", "Juyong Jiang", "Zhonghui Jiang", "Zhenzhong Lan", "Chengxi Li", "Jianguo Li", "Zehuan Li", "Huabin Liu", "Lin Liu", "Guoshan Lu", "Yuan Lu", "Yuxin Ma", "Xingyu Mou", "Zhenxuan Pan", "Kaida Qiu", "Yuji Ren", "Jianfeng Tan", "Yiding Tian", "Zian Wang", "Lanning Wei", "Tao Wu", "Yipeng Xing", "Wentao Ye", "Liangyu Zha", "Tianze Zhang", "Xiaolu Zhang", "Junbo Zhao", "Da Zheng", "Hao Zhong", "Wanli Zhong", "Jun Zhou", "Junlin Zhou", "Liwang Zhu", "Muzhi Zhu", "Yihong Zhuang"], "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing", "comment": "11 pages, 3 figures", "summary": "While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme. This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation. This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed. Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+, 801 TPS on BigCodeBench, and 663 TPS on LiveCodeBench.", "AI": {"tldr": "LLaDA2.1\u901a\u8fc7\u7ed3\u5408Token-to-Token\u7f16\u8f91\u4e0eMask-to-Token\u65b9\u6848\uff0c\u5f15\u5165\u53ef\u914d\u7f6e\u9608\u503c\u89e3\u7801\uff0c\u63d0\u4f9b\u901f\u5ea6\u6a21\u5f0f\u548c\u8d28\u91cf\u6a21\u5f0f\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u9488\u5bf9dLLMs\u7684\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u6781\u5feb\u89e3\u7801\u901f\u5ea6\u3002", "motivation": "\u89e3\u51b3LLaDA2.0\u4e2d\u89e3\u7801\u901f\u5ea6\u4e0e\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u8d85\u8d8a\u4f20\u7edf\u6269\u6563\u6a21\u578b\u7684\u9650\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u8f93\u51fa\u7684\u540c\u65f6\u5b9e\u73b0\u6781\u5feb\u7684\u89e3\u7801\u901f\u5ea6\u3002", "method": "1. \u5c06Token-to-Token\u7f16\u8f91\u65e0\u7f1d\u96c6\u6210\u5230\u4f20\u7edfMask-to-Token\u65b9\u6848\u4e2d\uff0c\u5f15\u5165\u8054\u5408\u53ef\u914d\u7f6e\u9608\u503c\u89e3\u7801\u65b9\u6848\uff1b2. \u521b\u5efa\u4e24\u79cd\u6a21\u5f0f\uff1a\u901f\u5ea6\u6a21\u5f0f\uff08\u964d\u4f4eM2T\u9608\u503c\uff0c\u4f9d\u8d56T2T\u7ec6\u5316\u8f93\u51fa\uff09\u548c\u8d28\u91cf\u6a21\u5f0f\uff08\u4fdd\u5b88\u9608\u503c\u4fdd\u8bc1\u57fa\u51c6\u6027\u80fd\uff09\uff1b3. \u5b9e\u73b0\u9996\u4e2a\u9488\u5bf9dLLMs\u7684\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u7a33\u5b9a\u68af\u5ea6\u4f30\u8ba1\u6280\u672f\u3002", "result": "\u572833\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c100B\u6a21\u578b\u5728\u7f16\u7a0b\u4efb\u52a1\u4e0a\u8fbe\u5230\u60ca\u4eba\u901f\u5ea6\uff1aHumanEval+ 892 TPS\uff0cBigCodeBench 801 TPS\uff0cLiveCodeBench 663 TPS\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "LLaDA2.1\u6210\u529f\u7a81\u7834\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u89e3\u7801\u901f\u5ea6\u4e0e\u751f\u6210\u8d28\u91cf\u7684\u6743\u8861\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u4e0e\u9ad8\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u5927\u89c4\u6a21\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.08679", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08679", "abs": "https://arxiv.org/abs/2602.08679", "authors": ["Yanzhang Fu", "Zizheng Guo", "Jizhou Luo"], "title": "Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks", "comment": null, "summary": "Score-based query attacks pose a serious threat to deep learning models by crafting adversarial examples (AEs) using only black-box access to model output scores, iteratively optimizing inputs based on observed loss values. While recent runtime defenses attempt to disrupt this process via output perturbation, most either require access to model parameters or fail when attackers adapt their tactics. In this paper, we first reveal that even the state-of-the-art plug-and-play defense can be bypassed by adaptive attacks, exposing a critical limitation of existing runtime defenses. We then propose Dashed Line Defense (DLD), a plug-and-play post-processing method specifically designed to withstand adaptive query strategies. By introducing ambiguity in how the observed loss reflects the true adversarial strength of candidate examples, DLD prevents attackers from reliably analyzing and adapting their queries, effectively disrupting the AE generation process. We provide theoretical guarantees of DLD's defense capability and validate its effectiveness through experiments on ImageNet, demonstrating that DLD consistently outperforms prior defenses--even under worst-case adaptive attacks--while preserving the model's predicted labels.", "AI": {"tldr": "\u63d0\u51faDashed Line Defense (DLD)\uff0c\u4e00\u79cd\u9488\u5bf9\u81ea\u9002\u5e94\u67e5\u8be2\u653b\u51fb\u7684\u5373\u63d2\u5373\u7528\u540e\u5904\u7406\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u635f\u5931\u503c\u4e2d\u5f15\u5165\u6a21\u7cca\u6027\u6765\u7834\u574f\u5bf9\u6297\u6837\u672c\u751f\u6210\u8fc7\u7a0b\u3002", "motivation": "\u57fa\u4e8e\u5206\u6570\u7684\u67e5\u8be2\u653b\u51fb\u901a\u8fc7\u9ed1\u76d2\u8bbf\u95ee\u6a21\u578b\u8f93\u51fa\u5206\u6570\u6765\u751f\u6210\u5bf9\u6297\u6837\u672c\uff0c\u73b0\u6709\u8fd0\u884c\u65f6\u9632\u5fa1\u8981\u4e48\u9700\u8981\u6a21\u578b\u53c2\u6570\u8bbf\u95ee\u6743\u9650\uff0c\u8981\u4e48\u5728\u653b\u51fb\u8005\u8c03\u6574\u7b56\u7565\u65f6\u5931\u6548\u3002\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u5373\u63d2\u5373\u7528\u9632\u5fa1\u4e5f\u80fd\u88ab\u81ea\u9002\u5e94\u653b\u51fb\u7ed5\u8fc7\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u9632\u5fa1\u7684\u5173\u952e\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faDashed Line Defense (DLD)\uff0c\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u89c2\u6d4b\u635f\u5931\u503c\u4e0e\u5019\u9009\u6837\u672c\u771f\u5b9e\u5bf9\u6297\u5f3a\u5ea6\u4e4b\u95f4\u5f15\u5165\u6a21\u7cca\u6027\uff0c\u9632\u6b62\u653b\u51fb\u8005\u53ef\u9760\u5206\u6790\u548c\u8c03\u6574\u67e5\u8be2\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u9632\u5fa1\u4fdd\u8bc1\uff0c\u4fdd\u6301\u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u4e0d\u53d8\u3002", "result": "\u5728ImageNet\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DLD\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5176\u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u9632\u5fa1\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u6700\u574f\u60c5\u51b5\u7684\u81ea\u9002\u5e94\u653b\u51fb\u4e0b\u4e5f\u80fd\u4fdd\u6301\u9632\u5fa1\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "DLD\u662f\u4e00\u79cd\u6709\u6548\u7684\u5373\u63d2\u5373\u7528\u9632\u5fa1\u65b9\u6cd5\uff0c\u80fd\u591f\u62b5\u5fa1\u81ea\u9002\u5e94\u67e5\u8be2\u653b\u51fb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8fd0\u884c\u65f6\u9632\u5fa1\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u4e3a\u5bf9\u6297\u6837\u672c\u9632\u5fa1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08686", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08686", "abs": "https://arxiv.org/abs/2602.08686", "authors": ["Ning Yang", "Chengzhi Wang", "Yibo Liu", "Baoliang Tian", "Haijun Zhang"], "title": "CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation", "comment": null, "summary": "Large Language Models (LLMs) in long-context scenarios are severely constrained by the linear growth of Key-Value (KV) cache memory. Existing KV compression methods rely either on static thresholds and attention-only heuristics or on coarse memory budget allocation. Under tight memory budgets, these methods overlook two key factors: prompt-dependent variation in compression risk and functional heterogeneity across attention heads, which destabilize token selection and lead to tail failures. To address these challenges, we propose CompilerKV, a risk-adaptive and head-aware compression framework that compiles offline experience into reusable decision tables for prefill-only deployment. CompilerKV integrates two key synergistic components: (i) a Head Heterogeneity Table, learned via offline contextual bandits, which assigns head-specific reliability weights to govern functional differences across attention heads explicitly; and (ii) a Risk-Adaptive Threshold Gating mechanism that jointly models attention entropy and local perplexity, transforming prompt-level risk into deployable retention thresholds. Experiments on LongBench show CompilerKV dominates SOTA methods under a 512-token budget, recovering 97.7\\% of FullKV performance while achieving up to +5.2 points gain over the strongest competitor.", "AI": {"tldr": "CompilerKV\uff1a\u4e00\u79cd\u98ce\u9669\u81ea\u9002\u5e94\u3001\u611f\u77e5\u6ce8\u610f\u529b\u5934\u5f02\u8d28\u6027\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u7ecf\u9a8c\u7f16\u8bd1\u51b3\u7b56\u8868\uff0c\u5728512\u4ee4\u724c\u9884\u7b97\u4e0b\u6062\u590d97.7%\u7684FullKV\u6027\u80fd", "motivation": "\u73b0\u6709KV\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1\uff09\u5ffd\u7565\u63d0\u793a\u76f8\u5173\u7684\u538b\u7f29\u98ce\u9669\u53d8\u5316\uff1b2\uff09\u5ffd\u89c6\u6ce8\u610f\u529b\u5934\u95f4\u7684\u529f\u80fd\u5f02\u8d28\u6027\u3002\u8fd9\u5bfc\u81f4\u5728\u4e25\u683c\u5185\u5b58\u9884\u7b97\u4e0b\uff0c\u4ee4\u724c\u9009\u62e9\u4e0d\u7a33\u5b9a\u5e76\u4ea7\u751f\u5c3e\u90e8\u5931\u8d25\u3002", "method": "\u63d0\u51faCompilerKV\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a1\uff09\u901a\u8fc7\u79bb\u7ebf\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u5b66\u4e60\u7684\u5934\u5f02\u8d28\u6027\u8868\uff0c\u4e3a\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5206\u914d\u53ef\u9760\u6027\u6743\u91cd\uff1b2\uff09\u98ce\u9669\u81ea\u9002\u5e94\u9608\u503c\u95e8\u63a7\u673a\u5236\uff0c\u8054\u5408\u5efa\u6a21\u6ce8\u610f\u529b\u71b5\u548c\u5c40\u90e8\u56f0\u60d1\u5ea6\uff0c\u5c06\u63d0\u793a\u7ea7\u98ce\u9669\u8f6c\u5316\u4e3a\u53ef\u90e8\u7f72\u7684\u4fdd\u7559\u9608\u503c\u3002", "result": "\u5728LongBench\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728512\u4ee4\u724c\u9884\u7b97\u4e0b\uff0cCompilerKV\u4e3b\u5bfcSOTA\u65b9\u6cd5\uff0c\u6062\u590d97.7%\u7684FullKV\u6027\u80fd\uff0c\u76f8\u6bd4\u6700\u5f3a\u7ade\u4e89\u5bf9\u624b\u83b7\u5f97\u9ad8\u8fbe+5.2\u5206\u7684\u63d0\u5347\u3002", "conclusion": "CompilerKV\u901a\u8fc7\u98ce\u9669\u81ea\u9002\u5e94\u548c\u5934\u611f\u77e5\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2dKV\u7f13\u5b58\u7684\u5185\u5b58\u7ea6\u675f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u538b\u7f29\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u5c3e\u90e8\u5931\u8d25\u3002"}}
{"id": "2602.08689", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08689", "abs": "https://arxiv.org/abs/2602.08689", "authors": ["Constant Bourdrez", "Alexandre V\u00e9rine", "Olivier Capp\u00e9"], "title": "Learning To Sample From Diffusion Models Via Inverse Reinforcement Learning", "comment": "Preprint", "summary": "Diffusion models generate samples through an iterative denoising process, guided by a neural network. While training the denoiser on real-world data is computationally demanding, the sampling procedure itself is more flexible. This adaptability serves as a key lever in practice, enabling improvements in both the quality of generated samples and the efficiency of the sampling process. In this work, we introduce an inverse reinforcement learning framework for learning sampling strategies without retraining the denoiser. We formulate the diffusion sampling procedure as a discrete-time finite-horizon Markov Decision Process, where actions correspond to optional modifications of the sampling dynamics. To optimize action scheduling, we avoid defining an explicit reward function. Instead, we directly match the target behavior expected from the sampler using policy gradient techniques. We provide experimental evidence that this approach can improve the quality of samples generated by pretrained diffusion models and automatically tune sampling hyperparameters.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9006\u5f3a\u5316\u5b66\u4e60\u7684\u6269\u6563\u6a21\u578b\u91c7\u6837\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u53bb\u566a\u5668\u5373\u53ef\u4f18\u5316\u91c7\u6837\u8fc7\u7a0b", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4f46\u91c7\u6837\u8fc7\u7a0b\u5177\u6709\u7075\u6d3b\u6027\u3002\u5229\u7528\u8fd9\u79cd\u7075\u6d3b\u6027\u53ef\u4ee5\u6539\u8fdb\u751f\u6210\u6837\u672c\u8d28\u91cf\u548c\u91c7\u6837\u6548\u7387\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u53bb\u566a\u5668\u3002", "method": "\u5c06\u6269\u6563\u91c7\u6837\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u79bb\u6563\u65f6\u95f4\u6709\u9650\u65f6\u57df\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u52a8\u4f5c\u5bf9\u5e94\u91c7\u6837\u52a8\u529b\u5b66\u7684\u53ef\u9009\u4fee\u6539\u3002\u91c7\u7528\u9006\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6280\u672f\u76f4\u63a5\u5339\u914d\u76ee\u6807\u884c\u4e3a\uff0c\u907f\u514d\u5b9a\u4e49\u663e\u5f0f\u5956\u52b1\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u6837\u672c\u8d28\u91cf\uff0c\u5e76\u81ea\u52a8\u8c03\u6574\u91c7\u6837\u8d85\u53c2\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e3a\u4f18\u5316\u6269\u6563\u6a21\u578b\u91c7\u6837\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u53bb\u566a\u5668\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u6539\u8fdb\u91c7\u6837\u7b56\u7565\u3002"}}
{"id": "2602.08690", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08690", "abs": "https://arxiv.org/abs/2602.08690", "authors": ["Shae McFadden", "Myles Foley", "Elizabeth Bates", "Ilias Tsingenopoulos", "Sanyam Vyas", "Vasilios Mavroudis", "Chris Hicks", "Fabio Pierazzi"], "title": "SoK: The Pitfalls of Deep Reinforcement Learning for Cybersecurity", "comment": null, "summary": "Deep Reinforcement Learning (DRL) has achieved remarkable success in domains requiring sequential decision-making, motivating its application to cybersecurity problems. However, transitioning DRL from laboratory simulations to bespoke cyber environments can introduce numerous issues. This is further exacerbated by the often adversarial, non-stationary, and partially-observable nature of most cybersecurity tasks. In this paper, we identify and systematize 11 methodological pitfalls that frequently occur in DRL for cybersecurity (DRL4Sec) literature across the stages of environment modeling, agent training, performance evaluation, and system deployment. By analyzing 66 significant DRL4Sec papers (2018-2025), we quantify the prevalence of each pitfall and find an average of over five pitfalls per paper. We demonstrate the practical impact of these pitfalls using controlled experiments in (i) autonomous cyber defense, (ii) adversarial malware creation, and (iii) web security testing environments. Finally, we provide actionable recommendations for each pitfall to support the development of more rigorous and deployable DRL-based security systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u4e2d\u768411\u4e2a\u5e38\u89c1\u65b9\u6cd5\u9677\u9631\uff0c\u901a\u8fc7\u5206\u679066\u7bc7\u76f8\u5173\u6587\u732e\u53d1\u73b0\u5e73\u5747\u6bcf\u7bc7\u5b58\u5728\u8d85\u8fc75\u4e2a\u9677\u9631\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5f71\u54cd\uff0c\u6700\u540e\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u9762\u4e34\u4ece\u5b9e\u9a8c\u5ba4\u6a21\u62df\u5230\u5b9e\u9645\u90e8\u7f72\u7684\u6311\u6218\uff0c\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u901a\u5e38\u5177\u6709\u5bf9\u6297\u6027\u3001\u975e\u5e73\u7a33\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\uff0c\u5bfc\u81f4\u73b0\u6709\u7814\u7a76\u5b58\u5728\u7cfb\u7edf\u6027\u65b9\u6cd5\u7f3a\u9677\u3002", "method": "1) \u8bc6\u522b\u5e76\u7cfb\u7edf\u5316DRL4Sec\u6587\u732e\u4e2d\u768411\u4e2a\u65b9\u6cd5\u9677\u9631\uff1b2) \u5206\u67902018-2025\u5e74\u95f466\u7bc7\u91cd\u8981\u8bba\u6587\uff0c\u91cf\u5316\u6bcf\u4e2a\u9677\u9631\u7684\u666e\u904d\u6027\uff1b3) \u5728\u81ea\u4e3b\u7f51\u7edc\u9632\u5fa1\u3001\u5bf9\u6297\u6027\u6076\u610f\u8f6f\u4ef6\u521b\u5efa\u548cWeb\u5b89\u5168\u6d4b\u8bd5\u73af\u5883\u4e2d\u8fdb\u884c\u5bf9\u7167\u5b9e\u9a8c\u9a8c\u8bc1\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e73\u5747\u6bcf\u7bc7\u8bba\u6587\u5b58\u5728\u8d85\u8fc75\u4e2a\u65b9\u6cd5\u9677\u9631\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u9677\u9631\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u4e3a\u6539\u8fdbDRL\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86DRL4Sec\u7814\u7a76\u4e2d\u666e\u904d\u5b58\u5728\u7684\u65b9\u6cd5\u7f3a\u9677\uff0c\u4e3a\u6bcf\u4e2a\u9677\u9631\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\uff0c\u652f\u6301\u5f00\u53d1\u66f4\u4e25\u8c28\u548c\u53ef\u90e8\u7f72\u7684\u57fa\u4e8eDRL\u7684\u5b89\u5168\u7cfb\u7edf\u3002"}}
{"id": "2602.08693", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08693", "abs": "https://arxiv.org/abs/2602.08693", "authors": ["Gon\u00e7alo Guiomar", "Elia Torre", "Pehuen Moure", "Victoria Shavina", "Mario Giulianelli", "Shih-Chii Liu", "Valerio Mante"], "title": "Reasoning aligns language models to human cognition", "comment": "38 pages, 4 main figures, multiple appendix figures", "summary": "Do language models make decisions under uncertainty like humans do, and what role does chain-of-thought (CoT) reasoning play in the underlying decision process? We introduce an active probabilistic reasoning task that cleanly separates sampling (actively acquiring evidence) from inference (integrating evidence toward a decision). Benchmarking humans and a broad set of contemporary large language models against near-optimal reference policies reveals a consistent pattern: extended reasoning is the key determinant of strong performance, driving large gains in inference and producing belief trajectories that become strikingly human-like, while yielding only modest improvements in active sampling. To explain these differences, we fit a mechanistic model that captures systematic deviations from optimal behavior via four interpretable latent variables: memory, strategy, choice bias, and occlusion awareness. This model places humans and models in a shared low-dimensional cognitive space, reproduces behavioral signatures across agents, and shows how chain-of-thought shifts language models toward human-like regimes of evidence accumulation and belief-to-choice mapping, tightening alignment in inference while leaving a persistent gap in information acquisition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6982\u7387\u63a8\u7406\u4efb\u52a1\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u53d1\u73b0\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u5e76\u4f7f\u6a21\u578b\u884c\u4e3a\u66f4\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u5728\u4e3b\u52a8\u4fe1\u606f\u91c7\u96c6\u65b9\u9762\u6539\u8fdb\u6709\u9650\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u662f\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u51b3\u7b56\uff0c\u4ee5\u53ca\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u5728\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002\u901a\u8fc7\u8bbe\u8ba1\u5206\u79bb\u8bc1\u636e\u91c7\u96c6\u4e0e\u63a8\u7406\u7684\u4efb\u52a1\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u4e3b\u52a8\u6982\u7387\u63a8\u7406\u4efb\u52a1\uff0c\u5c06\u91c7\u6837\uff08\u4e3b\u52a8\u83b7\u53d6\u8bc1\u636e\uff09\u4e0e\u63a8\u7406\uff08\u6574\u5408\u8bc1\u636e\u505a\u51fa\u51b3\u7b56\uff09\u5206\u79bb\u3002\u4f7f\u7528\u63a5\u8fd1\u6700\u4f18\u7684\u53c2\u8003\u7b56\u7565\u4f5c\u4e3a\u57fa\u51c6\uff0c\u6d4b\u8bd5\u4eba\u7c7b\u548c\u591a\u79cd\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u3002\u91c7\u7528\u673a\u5236\u6a21\u578b\u901a\u8fc7\u56db\u4e2a\u53ef\u89e3\u91ca\u6f5c\u53d8\u91cf\uff08\u8bb0\u5fc6\u3001\u7b56\u7565\u3001\u9009\u62e9\u504f\u5dee\u3001\u906e\u6321\u610f\u8bc6\uff09\u5206\u6790\u884c\u4e3a\u5dee\u5f02\u3002", "result": "\u6269\u5c55\u63a8\u7406\u662f\u51b3\u5b9a\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u80fd\u5927\u5e45\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5e76\u4ea7\u751f\u63a5\u8fd1\u4eba\u7c7b\u7684\u4fe1\u5ff5\u8f68\u8ff9\uff0c\u4f46\u5bf9\u4e3b\u52a8\u91c7\u6837\u7684\u6539\u8fdb\u6709\u9650\u3002\u673a\u5236\u6a21\u578b\u663e\u793a\u94fe\u5f0f\u601d\u7ef4\u4f7f\u8bed\u8a00\u6a21\u578b\u5411\u4eba\u7c7b\u8bc1\u636e\u79ef\u7d2f\u548c\u4fe1\u5ff5-\u9009\u62e9\u6620\u5c04\u6a21\u5f0f\u9760\u8fd1\uff0c\u5728\u63a8\u7406\u4e0a\u589e\u5f3a\u5bf9\u9f50\u4f46\u5728\u4fe1\u606f\u83b7\u53d6\u4e0a\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002", "conclusion": "\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u80fd\u663e\u8457\u6539\u5584\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5e76\u4f7f\u5176\u884c\u4e3a\u66f4\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u5728\u4e3b\u52a8\u4fe1\u606f\u91c7\u96c6\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u673a\u5236\u6a21\u578b\u4e3a\u7406\u89e3\u4eba\u7c7b\u4e0eAI\u51b3\u7b56\u5dee\u5f02\u63d0\u4f9b\u4e86\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2602.08695", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08695", "abs": "https://arxiv.org/abs/2602.08695", "authors": ["Evan Peters", "Ando Deng", "Matheus H. Zambianco", "Devin Blankespoor", "Achim Kempf"], "title": "Trapped by simplicity: When Transformers fail to learn from noisy features", "comment": "13+12 pages, 7 figures. Accepted at ICLR 2026", "summary": "Noise is ubiquitous in data used to train large language models, but it is not well understood whether these models are able to correctly generalize to inputs generated without noise. Here, we study noise-robust learning: are transformers trained on data with noisy features able to find a target function that correctly predicts labels for noiseless features? We show that transformers succeed at noise-robust learning for a selection of $k$-sparse parity and majority functions, compared to LSTMs which fail at this task for even modest feature noise. However, we find that transformers typically fail at noise-robust learning of random $k$-juntas, especially when the boolean sensitivity of the optimal solution is smaller than that of the target function. We argue that this failure is due to a combination of two factors: transformers' bias toward simpler functions, combined with an observation that the optimal function for noise-robust learning typically has lower sensitivity than the target function for random boolean functions. We test this hypothesis by exploiting transformers' simplicity bias to trap them in an incorrect solution, but show that transformers can escape this trap by training with an additional loss term penalizing high-sensitivity solutions. Overall, we find that transformers are particularly ineffective for learning boolean functions in the presence of feature noise.", "AI": {"tldr": "Transformer\u5728\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u4e2d\u5bf9k\u7a00\u758f\u5947\u5076\u6821\u9a8c\u548c\u591a\u6570\u51fd\u6570\u6709\u6548\uff0c\u4f46\u5bf9\u968f\u673ak-juntas\u901a\u5e38\u5931\u8d25\uff0c\u5c24\u5176\u5f53\u6700\u4f18\u89e3\u5e03\u5c14\u654f\u611f\u5ea6\u4f4e\u4e8e\u76ee\u6807\u51fd\u6570\u65f6\uff0c\u8fd9\u6e90\u4e8eTransformer\u5bf9\u7b80\u5355\u51fd\u6570\u7684\u504f\u597d\u4e0e\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u6700\u4f18\u51fd\u6570\u901a\u5e38\u5177\u6709\u8f83\u4f4e\u654f\u611f\u5ea6\u7684\u7ec4\u5408\u6548\u5e94\u3002", "motivation": "\u7814\u7a76Transformer\u5728\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u4e2d\u7684\u80fd\u529b\uff1a\u5f53\u5728\u5e26\u6709\u566a\u58f0\u7279\u5f81\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\u65f6\uff0cTransformer\u80fd\u5426\u627e\u5230\u80fd\u591f\u6b63\u786e\u9884\u6d4b\u65e0\u566a\u58f0\u7279\u5f81\u6807\u7b7e\u7684\u76ee\u6807\u51fd\u6570\uff1f\u63a2\u7d22Transformer\u4e0eLSTM\u5728\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u4e2d\u7684\u5dee\u5f02\u8868\u73b0\u3002", "method": "\u7814\u7a76Transformer\u5728k\u7a00\u758f\u5947\u5076\u6821\u9a8c\u51fd\u6570\u3001\u591a\u6570\u51fd\u6570\u548c\u968f\u673ak-juntas\u4e0a\u7684\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u80fd\u529b\u3002\u5206\u6790Transformer\u5bf9\u7b80\u5355\u51fd\u6570\u7684\u504f\u597d\u4e0e\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u6700\u4f18\u51fd\u6570\u654f\u611f\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u6dfb\u52a0\u60e9\u7f5a\u9ad8\u654f\u611f\u5ea6\u89e3\u51b3\u65b9\u6848\u7684\u635f\u5931\u9879\u6765\u6d4b\u8bd5\u5047\u8bbe\u3002", "result": "Transformer\u5728k\u7a00\u758f\u5947\u5076\u6821\u9a8c\u548c\u591a\u6570\u51fd\u6570\u7684\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u4e2d\u6210\u529f\uff0c\u800cLSTM\u5373\u4f7f\u5728\u9002\u5ea6\u7279\u5f81\u566a\u58f0\u4e0b\u4e5f\u5931\u8d25\u3002\u4f46Transformer\u5728\u968f\u673ak-juntas\u7684\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u4e2d\u901a\u5e38\u5931\u8d25\uff0c\u7279\u522b\u662f\u5f53\u6700\u4f18\u89e3\u7684\u5e03\u5c14\u654f\u611f\u5ea6\u4f4e\u4e8e\u76ee\u6807\u51fd\u6570\u65f6\u3002\u901a\u8fc7\u6dfb\u52a0\u654f\u611f\u5ea6\u60e9\u7f5a\u635f\u5931\u9879\uff0cTransformer\u80fd\u591f\u9003\u8131\u9519\u8bef\u89e3\u9677\u9631\u3002", "conclusion": "Transformer\u5728\u7279\u5f81\u566a\u58f0\u5b58\u5728\u65f6\u5b66\u4e60\u5e03\u5c14\u51fd\u6570\u7279\u522b\u65e0\u6548\uff0c\u5176\u5931\u8d25\u6e90\u4e8e\u5bf9\u7b80\u5355\u51fd\u6570\u7684\u504f\u597d\u4e0e\u566a\u58f0\u9c81\u68d2\u5b66\u4e60\u6700\u4f18\u51fd\u6570\u901a\u5e38\u5177\u6709\u8f83\u4f4e\u654f\u611f\u5ea6\u7684\u7ec4\u5408\u6548\u5e94\u3002\u901a\u8fc7\u9002\u5f53\u4fee\u6539\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u6539\u5584\u8fd9\u4e00\u7f3a\u9677\u3002"}}
{"id": "2602.08722", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08722", "abs": "https://arxiv.org/abs/2602.08722", "authors": ["Dalton Jones", "Junyoung Park", "Matthew Morse", "Mingu Lee", "Chris Lott", "Harper Langston"], "title": "QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill", "comment": null, "summary": "We present QUOKA: Query-oriented KV selection for efficient attention, a training-free and hardware agnostic sparse attention algorithm for accelerating transformer inference under chunked prefill. While many queries focus on a smaller group of keys in the attention operator, we observe that queries with low cosine similarity with respect to the mean query interact more strongly with more keys and have the greatest contribution to final attention logits. By prioritizing these low cosine similarity queries, the behavior of full attention during the prefill stage can be closely approximated. QUOKA leverages this observation, accelerating attention by (1) first retaining a small set of representative queries and (2) then subselectin the keys most aligned with those queries. Through experiments on Needle-In-A-Haystack, LongBench, RULER, and Math500, we show that, while realizing a 3x reduction in time-to-first-token, 5x speedup in attention on Nvidia GPUs and up to nearly a 7x speedup on Intel Xeon CPUs, QUOKA achieves near-baseline accuracy, utilizing 88% fewer key-value pairs per attention evaluation.", "AI": {"tldr": "QUOKA\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u786c\u4ef6\u65e0\u5173\u7684\u7a00\u758f\u6ce8\u610f\u529b\u7b97\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u4f4e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u4ee3\u8868\u6027\u67e5\u8be2\u53ca\u5176\u76f8\u5173\u952e\u503c\u5bf9\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u52a0\u901fTransformer\u63a8\u7406", "motivation": "\u8bb8\u591a\u67e5\u8be2\u5728\u6ce8\u610f\u529b\u64cd\u4f5c\u4e2d\u53ea\u5173\u6ce8\u4e00\u5c0f\u90e8\u5206\u952e\uff0c\u4f46\u4f4e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u67e5\u8be2\u4e0e\u66f4\u591a\u952e\u4ea4\u4e92\u4e14\u5bf9\u6700\u7ec8\u6ce8\u610f\u529b\u5bf9\u6570\u8d21\u732e\u66f4\u5927\u3002\u901a\u8fc7\u4f18\u5148\u5904\u7406\u8fd9\u4e9b\u67e5\u8be2\uff0c\u53ef\u4ee5\u5728\u9884\u586b\u5145\u9636\u6bb5\u8fd1\u4f3c\u5b8c\u6574\u6ce8\u610f\u529b\u7684\u884c\u4e3a", "method": "QUOKA\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a1) \u4fdd\u7559\u4e00\u5c0f\u90e8\u5206\u4ee3\u8868\u6027\u67e5\u8be2\uff08\u7279\u522b\u662f\u4f4e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u67e5\u8be2\uff09\uff1b2) \u9009\u62e9\u4e0e\u8fd9\u4e9b\u67e5\u8be2\u6700\u5bf9\u9f50\u7684\u952e\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\u4e14\u786c\u4ef6\u65e0\u5173", "result": "\u5728Needle-In-A-Haystack\u3001LongBench\u3001RULER\u548cMath500\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQUOKA\u5b9e\u73b0\u4e86\uff1a\u9996\u8bcd\u751f\u6210\u65f6\u95f4\u51cf\u5c113\u500d\uff0cNvidia GPU\u4e0a\u6ce8\u610f\u529b\u52a0\u901f5\u500d\uff0cIntel Xeon CPU\u4e0a\u52a0\u901f\u8fd17\u500d\uff0c\u540c\u65f6\u4f7f\u752888%\u66f4\u5c11\u7684\u952e\u503c\u5bf9\uff0c\u7cbe\u5ea6\u63a5\u8fd1\u57fa\u7ebf", "conclusion": "QUOKA\u901a\u8fc7\u67e5\u8be2\u5bfc\u5411\u7684\u952e\u503c\u9009\u62e9\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u52a0\u901fTransformer\u63a8\u7406\uff0c\u4e3a\u9ad8\u6548\u7684\u957f\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7a00\u758f\u6ce8\u610f\u529b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08733", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08733", "abs": "https://arxiv.org/abs/2602.08733", "authors": ["Maximilian Mauel", "Johannes R. H\u00fcbers", "David Berghaus", "Patrick Seifner", "Ramses J. Sanchez"], "title": "Foundation Inference Models for Ordinary Differential Equations", "comment": null, "summary": "Ordinary differential equations (ODEs) are central to scientific modelling, but inferring their vector fields from noisy trajectories remains challenging. Current approaches such as symbolic regression, Gaussian process (GP) regression, and Neural ODEs often require complex training pipelines and substantial machine learning expertise, or they depend strongly on system-specific prior knowledge. We propose FIM-ODE, a pretrained Foundation Inference Model that amortises low-dimensional ODE inference by predicting the vector field directly from noisy trajectory data in a single forward pass. We pretrain FIM-ODE on a prior distribution over ODEs with low-degree polynomial vector fields and represent the target field with neural operators. FIM-ODE achieves strong zero-shot performance, matching and often improving upon ODEFormer, a recent pretrained symbolic baseline, across a range of regimes despite using a simpler pretraining prior distribution. Pretraining also provides a strong initialisation for finetuning, enabling fast and stable adaptation that outperforms modern neural and GP baselines without requiring machine learning expertise.", "AI": {"tldr": "FIM-ODE\uff1a\u4e00\u79cd\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u63a8\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u76f4\u63a5\u4ece\u566a\u58f0\u8f68\u8ff9\u6570\u636e\u9884\u6d4b\u5411\u91cf\u573a\uff0c\u5b9e\u73b0\u4f4e\u7ef4ODE\u63a8\u65ad\u7684\u644a\u9500\u5316", "motivation": "\u5f53\u524d\u4ece\u566a\u58f0\u8f68\u8ff9\u63a8\u65adODE\u5411\u91cf\u573a\u7684\u65b9\u6cd5\uff08\u5982\u7b26\u53f7\u56de\u5f52\u3001\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u3001\u795e\u7ecfODE\uff09\u901a\u5e38\u9700\u8981\u590d\u6742\u7684\u8bad\u7ec3\u6d41\u7a0b\u548c\u5927\u91cf\u673a\u5668\u5b66\u4e60\u4e13\u4e1a\u77e5\u8bc6\uff0c\u6216\u4e25\u91cd\u4f9d\u8d56\u7cfb\u7edf\u7279\u5b9a\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528", "method": "\u63d0\u51faFIM-ODE\u9884\u8bad\u7ec3\u57fa\u7840\u63a8\u7406\u6a21\u578b\uff0c\u5728\u4f4e\u6b21\u591a\u9879\u5f0f\u5411\u91cf\u573a\u7684ODE\u5148\u9a8c\u5206\u5e03\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u8868\u793a\u76ee\u6807\u5411\u91cf\u573a\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u76f4\u63a5\u4ece\u566a\u58f0\u8f68\u8ff9\u6570\u636e\u9884\u6d4b\u5411\u91cf\u573a", "result": "FIM-ODE\u5728\u96f6\u6837\u672c\u6027\u80fd\u4e0a\u8868\u73b0\u5f3a\u52b2\uff0c\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u4e86\u6700\u8fd1\u7684\u9884\u8bad\u7ec3\u7b26\u53f7\u57fa\u7ebfODEFormer\uff1b\u9884\u8bad\u7ec3\u4e3a\u5fae\u8c03\u63d0\u4f9b\u4e86\u5f3a\u521d\u59cb\u5316\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u7a33\u5b9a\u9002\u5e94\uff0c\u8d85\u8d8a\u4e86\u73b0\u4ee3\u795e\u7ecf\u548cGP\u57fa\u7ebf", "conclusion": "FIM-ODE\u7b80\u5316\u4e86ODE\u63a8\u65ad\u6d41\u7a0b\uff0c\u65e0\u9700\u590d\u6742\u8bad\u7ec3\u6216\u673a\u5668\u5b66\u4e60\u4e13\u4e1a\u77e5\u8bc6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u548c\u644a\u9500\u5316\u63a8\u65ad\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u5411\u91cf\u573a\u9884\u6d4b\uff0c\u4e3a\u79d1\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177"}}
{"id": "2602.08745", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08745", "abs": "https://arxiv.org/abs/2602.08745", "authors": ["Saku Peltonen", "Roger Wattenhofer"], "title": "On the Expressive Power of GNNs for Boolean Satisfiability", "comment": "Accepted at ICLR 2026", "summary": "Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in general, distinguish between satisfiable and unsatisfiable instances. We show that indistinguishability under higher-order WL carries over to practical limitations for WL-bounded solvers that set variables sequentially. We further study the expressivity required for several important families of SAT instances, including regular, random and planar instances. To quantify expressivity needs in practice, we conduct experiments on random instances from the G4SAT benchmark and industrial instances from the International SAT Competition. Our results suggest that while random instances are largely distinguishable, industrial instances often require more expressivity to predict a satisfying assignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728SAT\u6c42\u89e3\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8bc1\u660e\u4e86Weisfeiler-Leman\u5c42\u6b21\u7ed3\u6784\u65e0\u6cd5\u533a\u5206\u53ef\u6ee1\u8db3\u4e0e\u4e0d\u53ef\u6ee1\u8db3\u5b9e\u4f8b\uff0c\u5e76\u7814\u7a76\u4e86\u4e0d\u540cSAT\u5b9e\u4f8b\u5bb6\u65cf\u7684\u8868\u8fbe\u9700\u6c42\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u65e8\u5728\u53d6\u4ee3\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u89e3\u51b3\u5e03\u5c14\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u56e0\u5176\u5bf9\u5e03\u5c14\u516c\u5f0f\u7684\u81ea\u7136\u56fe\u8868\u793a\u800c\u6210\u4e3a\u4e3b\u8981\u67b6\u6784\u3002\u9700\u8981\u5206\u6790GNN\u5728SAT\u6c42\u89e3\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u901a\u8fc7Weisfeiler-Leman\u6d4b\u8bd5\u7684\u89c6\u89d2\u5206\u6790GNN\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8bc1\u660eWL\u5c42\u6b21\u7ed3\u6784\u65e0\u6cd5\u533a\u5206\u53ef\u6ee1\u8db3\u4e0e\u4e0d\u53ef\u6ee1\u8db3\u5b9e\u4f8b\uff0c\u7814\u7a76WL\u6709\u754c\u6c42\u89e3\u5668\u7684\u5b9e\u9645\u9650\u5236\uff0c\u5206\u6790\u6b63\u5219\u3001\u968f\u673a\u548c\u5e73\u9762\u5b9e\u4f8b\u7684\u8868\u8fbe\u9700\u6c42\uff0c\u5e76\u5728G4SAT\u57fa\u51c6\u548cSAT\u7ade\u8d5b\u5b9e\u4f8b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8bc1\u660e\u9ad8\u9636WL\u65e0\u6cd5\u533a\u5206\u53ef\u6ee1\u8db3\u4e0e\u4e0d\u53ef\u6ee1\u8db3\u5b9e\u4f8b\uff0cWL\u6709\u754c\u6c42\u89e3\u5668\u5b58\u5728\u5b9e\u9645\u9650\u5236\u3002\u5b9e\u9a8c\u8868\u660e\u968f\u673a\u5b9e\u4f8b\u5927\u591a\u53ef\u533a\u5206\uff0c\u800c\u5de5\u4e1a\u5b9e\u4f8b\u901a\u5e38\u9700\u8981\u66f4\u591a\u8868\u8fbe\u80fd\u529b\u6765\u9884\u6d4b\u6ee1\u8db3\u8d4b\u503c\u3002", "conclusion": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728SAT\u6c42\u89e3\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u53d7WL\u5c42\u6b21\u7ed3\u6784\u9650\u5236\uff0c\u5de5\u4e1a\u5b9e\u4f8b\u9700\u8981\u6bd4\u968f\u673a\u5b9e\u4f8b\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8fd9\u5bf9\u57fa\u4e8e\u5b66\u4e60\u7684SAT\u6c42\u89e3\u5668\u8bbe\u8ba1\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2602.08751", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.08751", "abs": "https://arxiv.org/abs/2602.08751", "authors": ["Nobuyuki Ota"], "title": "Central Dogma Transformer II: An AI Microscope for Understanding Cellular Regulatory Mechanisms", "comment": "20 pages, 6 figures", "summary": "Current biological AI models lack interpretability -- their internal representations do not correspond to biological relationships that\n  researchers can examine. Here we present CDT-II, an \"AI microscope\" whose attention maps are directly interpretable as regulatory structure.\n  By mirroring the central dogma in its architecture, each attention mechanism corresponds to a specific biological relationship: DNA\n  self-attention for genomic relationships, RNA self-attention for gene co-regulation, and DNA-to-RNA cross-attention for transcriptional\n  control. Using only genomic embeddings and raw per-cell expression, CDT-II enables experimental biologists to observe regulatory networks in\n  their own data. Applied to K562 CRISPRi data, CDT-II predicts perturbation effects (per-gene mean $r = 0.84$) and recovers the GFI1B\n  regulatory network without supervision (6.6-fold enrichment, $P = 3.5 \\times 10^{-17}$). Two distinct attention mechanisms converge on an RNA\n  processing module ($P = 1 \\times 10^{-16}$). CDT-II establishes mechanism-oriented AI as an alternative to task-oriented approaches, revealing\n  regulatory structure rather than merely optimizing predictions.", "AI": {"tldr": "CDT-II\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684AI\u663e\u5fae\u955c\uff0c\u901a\u8fc7\u6a21\u62df\u4e2d\u5fc3\u6cd5\u5219\u67b6\u6784\uff0c\u5176\u6ce8\u610f\u529b\u673a\u5236\u76f4\u63a5\u5bf9\u5e94\u751f\u7269\u8c03\u63a7\u5173\u7cfb\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u89c2\u5bdf\u6570\u636e\u4e2d\u7684\u8c03\u63a7\u7f51\u7edc\u3002", "motivation": "\u5f53\u524d\u751f\u7269AI\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5185\u90e8\u8868\u793a\u4e0e\u751f\u7269\u5173\u7cfb\u4e0d\u5bf9\u5e94\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u76f4\u63a5\u89e3\u91ca\u8c03\u63a7\u7ed3\u6784\u7684AI\u5de5\u5177\uff0c\u8ba9\u5b9e\u9a8c\u751f\u7269\u5b66\u5bb6\u80fd\u591f\u89c2\u5bdf\u81ea\u5df1\u6570\u636e\u4e2d\u7684\u8c03\u63a7\u7f51\u7edc\u3002", "method": "CDT-II\u901a\u8fc7\u6a21\u62df\u4e2d\u5fc3\u6cd5\u5219\u8bbe\u8ba1\u67b6\u6784\uff1aDNA\u81ea\u6ce8\u610f\u529b\u5bf9\u5e94\u57fa\u56e0\u7ec4\u5173\u7cfb\uff0cRNA\u81ea\u6ce8\u610f\u529b\u5bf9\u5e94\u57fa\u56e0\u5171\u8c03\u63a7\uff0cDNA\u5230RNA\u4ea4\u53c9\u6ce8\u610f\u529b\u5bf9\u5e94\u8f6c\u5f55\u63a7\u5236\u3002\u4ec5\u4f7f\u7528\u57fa\u56e0\u7ec4\u5d4c\u5165\u548c\u539f\u59cb\u5355\u7ec6\u80de\u8868\u8fbe\u6570\u636e\u3002", "result": "\u5728K562 CRISPRi\u6570\u636e\u4e2d\uff0cCDT-II\u9884\u6d4b\u6270\u52a8\u6548\u5e94\uff08\u57fa\u56e0\u5e73\u5747r=0.84\uff09\uff0c\u65e0\u76d1\u7763\u6062\u590dGFI1B\u8c03\u63a7\u7f51\u7edc\uff086.6\u500d\u5bcc\u96c6\uff0cP=3.5\u00d710\u207b\u00b9\u2077\uff09\u3002\u4e24\u4e2a\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u6c47\u805a\u5230RNA\u5904\u7406\u6a21\u5757\uff08P=1\u00d710\u207b\u00b9\u2076\uff09\u3002", "conclusion": "CDT-II\u5efa\u7acb\u4e86\u673a\u5236\u5bfc\u5411\u7684AI\u4f5c\u4e3a\u4efb\u52a1\u5bfc\u5411\u65b9\u6cd5\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u63ed\u793a\u8c03\u63a7\u7ed3\u6784\u800c\u975e\u4ec5\u4ec5\u4f18\u5316\u9884\u6d4b\uff0c\u4e3a\u751f\u7269\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684AI\u663e\u5fae\u955c\u3002"}}
{"id": "2602.08755", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08755", "abs": "https://arxiv.org/abs/2602.08755", "authors": ["Duc-Anh Nguyen", "Nhien-An Le-Khac"], "title": "Redundancy-Free View Alignment for Multimodal Human Activity Recognition with Arbitrarily Missing Views", "comment": null, "summary": "Multimodal multiview learning seeks to integrate information from diverse sources to enhance task performance. Existing approaches often struggle with flexible view configurations, including arbitrary view combinations, numbers of views, and heterogeneous modalities. Focusing on the context of human activity recognition, we propose RALIS, a model that combines multiview contrastive learning with a mixture-of-experts module to support arbitrary view availability during both training and inference. Instead of trying to reconstruct missing views, an adjusted center contrastive loss is used for self-supervised representation learning and view alignment, mitigating the impact of missing views on multiview fusion. This loss formulation allows for the integration of view weights to account for view quality. Additionally, it reduces computational complexity from $O(V^2)$ to $O(V)$, where $V$ is the number of views. To address residual discrepancies not captured by contrastive learning, we employ a mixture-of-experts module with a specialized load balancing strategy, tasked with adapting to arbitrary view combinations. We highlight the geometric relationship among components in our model and how they combine well in the latent space. RALIS is validated on four datasets encompassing inertial and human pose modalities, with the number of views ranging from three to nine, demonstrating its performance and flexibility.", "AI": {"tldr": "RALIS\uff1a\u4e00\u79cd\u7528\u4e8e\u591a\u6a21\u6001\u591a\u89c6\u56fe\u5b66\u4e60\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u4e13\u5bb6\u6df7\u5408\u6a21\u5757\uff0c\u652f\u6301\u8bad\u7ec3\u548c\u63a8\u7406\u671f\u95f4\u7684\u4efb\u610f\u89c6\u56fe\u53ef\u7528\u6027\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u591a\u89c6\u56fe\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u7075\u6d3b\u89c6\u56fe\u914d\u7f6e\uff08\u5305\u62ec\u4efb\u610f\u89c6\u56fe\u7ec4\u5408\u3001\u89c6\u56fe\u6570\u91cf\u548c\u5f02\u6784\u6a21\u6001\uff09\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51faRALIS\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u89c6\u56fe\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u4e13\u5bb6\u6df7\u5408\u6a21\u5757\u3002\u4f7f\u7528\u8c03\u6574\u7684\u4e2d\u5fc3\u5bf9\u6bd4\u635f\u5931\u8fdb\u884c\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u548c\u89c6\u56fe\u5bf9\u9f50\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(V\u00b2)\u5230O(V)\u3002\u4e13\u5bb6\u6df7\u5408\u6a21\u5757\u91c7\u7528\u4e13\u95e8\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u9002\u5e94\u4efb\u610f\u89c6\u56fe\u7ec4\u5408\u3002", "result": "\u5728\u5305\u542b\u60ef\u6027\u548c\u4eba\u4f53\u59ff\u6001\u6a21\u6001\u7684\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u89c6\u56fe\u6570\u91cf\u4ece3\u52309\u4e0d\u7b49\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "RALIS\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u6a21\u6001\u591a\u89c6\u56fe\u5b66\u4e60\u4e2d\u7684\u7075\u6d3b\u89c6\u56fe\u914d\u7f6e\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5bf9\u6bd4\u635f\u5931\u548c\u4e13\u5bb6\u6df7\u5408\u6a21\u5757\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2602.08762", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08762", "abs": "https://arxiv.org/abs/2602.08762", "authors": ["Wen Xu", "Zhetao Li", "Yong Xiao", "Pengpeng Qiao", "Mianxiong Dong", "Kaoru Ota"], "title": "HoGS: Homophily-Oriented Graph Synthesis for Local Differentially Private GNN Training", "comment": null, "summary": "Graph neural networks (GNNs) have demonstrated remarkable performance in various graph-based machine learning tasks by effectively modeling high-order interactions between nodes. However, training GNNs without protection may leak sensitive personal information in graph data, including links and node features. Local differential privacy (LDP) is an advanced technique for protecting data privacy in decentralized networks. Unfortunately, existing local differentially private GNNs either only preserve link privacy or suffer significant utility loss in the process of preserving link and node feature privacy. In this paper, we propose an effective LDP framework, called HoGS, which trains GNNs with link and feature protection by generating a synthetic graph. Concretely, HoGS first collects the link and feature information of the graph under LDP, and then utilizes the phenomenon of homophily in graph data to reconstruct the graph structure and node features separately, thereby effectively mitigating the negative impact of LDP on the downstream GNN training. We theoretically analyze the privacy guarantee of HoGS and conduct experiments using the generated synthetic graph as input to various state-of-the-art GNN architectures. Experimental results on three real-world datasets show that HoGS significantly outperforms baseline methods in the accuracy of training GNNs.", "AI": {"tldr": "HoGS\u662f\u4e00\u4e2a\u672c\u5730\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u56fe\u6765\u4fdd\u62a4\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u94fe\u63a5\u548c\u8282\u70b9\u7279\u5f81\u9690\u79c1\uff0c\u540c\u65f6\u5229\u7528\u56fe\u7684\u540c\u8d28\u6027\u73b0\u8c61\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u672c\u5730\u5dee\u5206\u9690\u79c1\u56fe\u795e\u7ecf\u7f51\u7edc\u8981\u4e48\u53ea\u4fdd\u62a4\u94fe\u63a5\u9690\u79c1\uff0c\u8981\u4e48\u5728\u540c\u65f6\u4fdd\u62a4\u94fe\u63a5\u548c\u8282\u70b9\u7279\u5f81\u9690\u79c1\u65f6\u5bfc\u81f4\u663e\u8457\u7684\u6548\u7528\u635f\u5931\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "HoGS\u9996\u5148\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u4e0b\u6536\u96c6\u56fe\u7684\u94fe\u63a5\u548c\u7279\u5f81\u4fe1\u606f\uff0c\u7136\u540e\u5229\u7528\u56fe\u7684\u540c\u8d28\u6027\u73b0\u8c61\u5206\u522b\u91cd\u6784\u56fe\u7ed3\u6784\u548c\u8282\u70b9\u7279\u5f81\uff0c\u751f\u6210\u5408\u6210\u56fe\u4f5c\u4e3aGNN\u8bad\u7ec3\u7684\u8f93\u5165\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHoGS\u5728\u8bad\u7ec3GNN\u7684\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "HoGS\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u672c\u5730\u5dee\u5206\u9690\u79c1\u56fe\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u4fdd\u62a4\u654f\u611f\u56fe\u6570\u636e\u9690\u79c1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08768", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08768", "abs": "https://arxiv.org/abs/2602.08768", "authors": ["Chi-Sheng Chen", "Xinyu Zhang", "En-Jui Kuo", "Guan-Ying Chen", "Qiuzhe Xie", "Fan Zhang"], "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting", "comment": null, "summary": "Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \\emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \\textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \\pm 0.1$h, 2.5\\% error) and 12-hour half-daily cycle ($11.8 \\pm 0.1$h, 1.6\\% error) on Traffic, and weekly cycles ($10\\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.", "AI": {"tldr": "FreqLens\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u9891\u7387\u53d1\u73b0\u548c\u516c\u7406\u5316\u7684\u9891\u7387\u5f52\u56e0\uff0c\u81ea\u52a8\u53d1\u73b0\u4e3b\u5bfc\u5468\u671f\u6027\u6a21\u5f0f\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u5f52\u56e0\u89e3\u91ca\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u53ef\u89e3\u91ca\u9884\u6d4b\u7684\u9886\u57df\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u81ea\u52a8\u53d1\u73b0\u5468\u671f\u6027\u6a21\u5f0f\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u5f52\u56e0\u89e3\u91ca\u3002", "method": "\u63d0\u51faFreqLens\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1\uff09\u53ef\u5b66\u4e60\u7684\u9891\u7387\u53d1\u73b0\u2014\u2014\u901a\u8fc7sigmoid\u6620\u5c04\u53c2\u6570\u5316\u9891\u7387\u57fa\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5e76\u91c7\u7528\u591a\u6837\u6027\u6b63\u5219\u5316\uff0c\u65e0\u9700\u9886\u57df\u77e5\u8bc6\u81ea\u52a8\u53d1\u73b0\u4e3b\u5bfc\u5468\u671f\u6027\u6a21\u5f0f\uff1b2\uff09\u516c\u7406\u5316\u7684\u9891\u7387\u5f52\u56e0\u2014\u2014\u57fa\u4e8e\u7406\u8bba\u57fa\u7840\u7684\u6846\u67b6\uff0c\u6ee1\u8db3\u5b8c\u5907\u6027\u3001\u5fe0\u5b9e\u6027\u3001\u96f6\u9891\u7387\u548c\u5bf9\u79f0\u6027\u516c\u7406\uff0c\u6bcf\u4e2a\u9891\u7387\u7684\u5f52\u56e0\u7b49\u4ef7\u4e8eShapley\u503c\u3002", "result": "\u5728Traffic\u548cWeather\u6570\u636e\u96c6\u4e0a\uff0cFreqLens\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53d1\u73b0\u4e86\u7269\u7406\u4e0a\u6709\u610f\u4e49\u7684\u9891\u7387\uff1a\u6240\u67095\u6b21\u72ec\u7acb\u8fd0\u884c\u90fd\u53d1\u73b0\u4e86Traffic\u6570\u636e\u4e2d\u768424\u5c0f\u65f6\u65e5\u5468\u671f\uff0824.6\u00b10.1h\uff0c2.5%\u8bef\u5dee\uff09\u548c12\u5c0f\u65f6\u534a\u65e5\u5468\u671f\uff0811.8\u00b10.1h\uff0c1.6%\u8bef\u5dee\uff09\uff0c\u4ee5\u53caWeather\u6570\u636e\u4e2d\u7684\u5468\u5468\u671f\uff08\u6bd4\u8f93\u5165\u7a97\u53e3\u957f10\u500d\uff09\u3002", "conclusion": "FreqLens\u5c55\u793a\u4e86\u771f\u6b63\u7684\u9891\u7387\u7ea7\u77e5\u8bc6\u53d1\u73b0\u80fd\u529b\uff0c\u5e76\u5728\u5f52\u56e0\u8d28\u91cf\u4e0a\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08774", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08774", "abs": "https://arxiv.org/abs/2602.08774", "authors": ["Nicol\u00e1s Villagr\u00e1n Prieto", "Eduardo C. Garrido-Merch\u00e1n"], "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization", "comment": null, "summary": "Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has remained largely unexamined. We formalize the idea by initializing BO with points drawn from truncated Gaussian distributions centered at library defaults and compare the resulting trajectories against a uniform-random baseline. We conduct an extensive empirical evaluation spanning three BO back-ends (BoTorch, Optuna, Scikit-Optimize), three model families (Random Forests, Support Vector Machines, Multilayer Perceptrons), and five benchmark datasets covering classification and regression tasks. Performance is assessed through convergence speed and final predictive quality, and statistical significance is determined via one-sided binomial tests. Across all conditions, default-informed initialization yields no statistically significant advantage over purely random sampling, with p-values ranging from 0.141 to 0.908. A sensitivity analysis on the prior variance confirms that, while tighter concentration around the defaults improves early evaluations, this transient benefit vanishes as optimization progresses, leaving final performance unchanged. Our results provide no evidence that default hyperparameters encode useful directional information for optimization. We therefore recommend that practitioners treat hyperparameter tuning as an integral part of model development and favor principled, data-driven search strategies over heuristic reliance on library defaults.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u4f7f\u7528\u5e93\u9ed8\u8ba4\u8d85\u53c2\u6570\u521d\u59cb\u5316\u8d1d\u53f6\u65af\u4f18\u5316\u662f\u5426\u80fd\u52a0\u901f\u6536\u655b\uff0c\u7ed3\u679c\u53d1\u73b0\u9ed8\u8ba4\u521d\u59cb\u5316\u76f8\u6bd4\u968f\u673a\u521d\u59cb\u5316\u5e76\u65e0\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5e93\uff08\u5982scikit-learn\uff09\u7684\u9ed8\u8ba4\u8d85\u53c2\u6570\u5305\u542b\u4e86\u4e13\u5bb6\u77e5\u8bc6\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u4f5c\u4e3a\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u4fe1\u606f\u8d77\u70b9\u6765\u52a0\u901f\u6536\u655b\uff0c\u4f46\u8fd9\u4e00\u76f4\u89c2\u5047\u8bbe\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002", "method": "\u4f7f\u7528\u4ee5\u5e93\u9ed8\u8ba4\u503c\u4e3a\u4e2d\u5fc3\u7684\u622a\u65ad\u9ad8\u65af\u5206\u5e03\u521d\u59cb\u5316\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u4e0e\u5747\u5300\u968f\u673a\u521d\u59cb\u5316\u57fa\u7ebf\u6bd4\u8f83\u3002\u5b9e\u9a8c\u6db5\u76d6\u4e09\u4e2aBO\u540e\u7aef\uff08BoTorch\u3001Optuna\u3001Scikit-Optimize\uff09\u3001\u4e09\u79cd\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u3001\u652f\u6301\u5411\u91cf\u673a\u3001\u591a\u5c42\u611f\u77e5\u673a\uff09\u548c\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u9884\u6d4b\u8d28\u91cf\u8bc4\u4f30\u6027\u80fd\uff0c\u4f7f\u7528\u5355\u4fa7\u4e8c\u9879\u68c0\u9a8c\u786e\u5b9a\u7edf\u8ba1\u663e\u8457\u6027\u3002", "result": "\u5728\u6240\u6709\u5b9e\u9a8c\u6761\u4ef6\u4e0b\uff0c\u9ed8\u8ba4\u521d\u59cb\u5316\u76f8\u6bd4\u7eaf\u968f\u673a\u91c7\u6837\u5747\u672a\u663e\u793a\u51fa\u7edf\u8ba1\u663e\u8457\u4f18\u52bf\uff08p\u503c\u8303\u56f40.141-0.908\uff09\u3002\u654f\u611f\u6027\u5206\u6790\u8868\u660e\uff0c\u867d\u7136\u66f4\u7d27\u5bc6\u5730\u56f4\u7ed5\u9ed8\u8ba4\u503c\u80fd\u6539\u5584\u65e9\u671f\u8bc4\u4f30\uff0c\u4f46\u8fd9\u79cd\u6682\u65f6\u6027\u4f18\u52bf\u968f\u7740\u4f18\u5316\u8fdb\u7a0b\u800c\u6d88\u5931\uff0c\u6700\u7ec8\u6027\u80fd\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u9ed8\u8ba4\u8d85\u53c2\u6570\u5e76\u672a\u5305\u542b\u5bf9\u4f18\u5316\u6709\u7528\u7684\u65b9\u5411\u6027\u4fe1\u606f\u3002\u5efa\u8bae\u5b9e\u8df5\u8005\u5c06\u8d85\u53c2\u6570\u8c03\u4f18\u89c6\u4e3a\u6a21\u578b\u5f00\u53d1\u7684\u5fc5\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4f18\u5148\u91c7\u7528\u57fa\u4e8e\u6570\u636e\u7684\u641c\u7d22\u7b56\u7565\uff0c\u800c\u975e\u4f9d\u8d56\u5e93\u9ed8\u8ba4\u503c\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002"}}
{"id": "2602.08785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08785", "abs": "https://arxiv.org/abs/2602.08785", "authors": ["Ofek Amran", "Tom Gilat", "Ron Levie"], "title": "A Graphop Analysis of Graph Neural Networks on Sparse Graphs: Generalization and Universal Approximation", "comment": null, "summary": "Generalization and approximation capabilities of message passing graph neural networks (MPNNs) are often studied by defining a compact metric on a space of input graphs under which MPNNs are H\u00f6lder continuous. Such analyses are of two varieties: 1) when the metric space includes graphs of unbounded sizes, the theory is only appropriate for dense graphs, and, 2) when studying sparse graphs, the metric space only includes graphs of uniformly bounded size. In this work, we present a unified approach, defining a compact metric on the space of graphs of all sizes, both sparse and dense, under which MPNNs are H\u00f6lder continuous. This leads to more powerful universal approximation theorems and generalization bounds than previous works. The theory is based on, and extends, a recent approach to graph limit theory called graphop analysis.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u5ea6\u91cf\u7a7a\u95f4\u6846\u67b6\uff0c\u5c06\u4efb\u610f\u5927\u5c0f\u7684\u7a00\u758f\u548c\u7a20\u5bc6\u56fe\u7eb3\u5165\u540c\u4e00\u7406\u8bba\u4f53\u7cfb\uff0c\u6269\u5c55MPNN\u7684\u6cdb\u5316\u4e0e\u903c\u8fd1\u80fd\u529b\u5206\u6790\u3002", "motivation": "\u73b0\u6709MPNN\u7406\u8bba\u5206\u6790\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8981\u4e48\u53ea\u9002\u7528\u4e8e\u7a20\u5bc6\u56fe\u4e14\u5305\u542b\u65e0\u9650\u5927\u56fe\uff0c\u8981\u4e48\u53ea\u9002\u7528\u4e8e\u6709\u754c\u5927\u5c0f\u7684\u7a00\u758f\u56fe\u3002\u9700\u8981\u7edf\u4e00\u6846\u67b6\u540c\u65f6\u5904\u7406\u4efb\u610f\u5927\u5c0f\u7684\u7a00\u758f\u548c\u7a20\u5bc6\u56fe\u3002", "method": "\u57fa\u4e8e\u56fe\u7b97\u5b50(graphop)\u5206\u6790\u7406\u8bba\uff0c\u5b9a\u4e49\u7d27\u51d1\u5ea6\u91cf\u7a7a\u95f4\uff0c\u8be5\u7a7a\u95f4\u5305\u542b\u6240\u6709\u5927\u5c0f\u7684\u56fe\uff08\u7a00\u758f\u548c\u7a20\u5bc6\uff09\uff0c\u5e76\u8bc1\u660eMPNN\u5728\u8be5\u5ea6\u91cf\u4e0b\u662fH\u00f6lder\u8fde\u7eed\u7684\u3002", "result": "\u83b7\u5f97\u4e86\u6bd4\u4ee5\u5f80\u5de5\u4f5c\u66f4\u5f3a\u5927\u7684\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u548c\u6cdb\u5316\u754c\uff0c\u7edf\u4e00\u4e86\u7a00\u758f\u548c\u7a20\u5bc6\u56fe\u7684\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u56fe\u7b97\u5b50\u7406\u8bba\u6784\u5efa\u7684\u7edf\u4e00\u5ea6\u91cf\u7a7a\u95f4\u6846\u67b6\uff0c\u4e3aMPNN\u5728\u4efb\u610f\u5927\u5c0f\u56fe\u4e0a\u7684\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u548c\u901a\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2602.08808", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08808", "abs": "https://arxiv.org/abs/2602.08808", "authors": ["Yapei Chang", "Kyle Lo", "Mohit Iyyer", "Luca Soldaini"], "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs", "comment": "53 pages, 22 figures", "summary": "Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation. Our framework includes How2Mine, which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench, a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score, an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining. Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.", "AI": {"tldr": "How2Everything\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u76ee\u6807\u5bfc\u5411\u7684\u7a0b\u5e8f\u751f\u6210\uff0c\u5305\u62ec\u6570\u636e\u6316\u6398\u3001\u57fa\u51c6\u6784\u5efa\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u3002", "motivation": "\u751f\u6210\u9010\u6b65\u7684\"\u5982\u4f55\u505a\"\u7a0b\u5e8f\u662fLLM\u7684\u5173\u952e\u80fd\u529b\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5927\u89c4\u6a21\u8bc4\u4f30\u548c\u6539\u8fdb\u7a0b\u5e8f\u6709\u6548\u6027\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u4e14\u7814\u7a76\u4e0d\u8db3\u3002", "method": "1) How2Mine\uff1a\u4ece98\u4e07\u4e2a\u7f51\u9875\u4e2d\u6316\u639835.1\u4e07\u4e2a\u7a0b\u5e8f\uff1b2) How2Bench\uff1a\u6784\u5efa7K\u4e2a\u5e73\u8861\u8bc4\u4f30\u96c6\uff1b3) How2Score\uff1a\u4f7f\u7528LLM\u6cd5\u5b98\u68c0\u6d4b\u5173\u952e\u5931\u8d25\u7684\u8bc4\u4f30\u534f\u8bae\uff1b4) \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528How2Score\u4f5c\u4e3a\u5956\u52b1\u6539\u8fdb\u6a21\u578b\u3002", "result": "1) \u84b8\u998f\u76848B\u6a21\u578b\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u8fbe\u523080.5%\u4e00\u81f4\u6027\uff1b2) How2Bench\u63ed\u793a\u4e86\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u9636\u6bb5\u7684\u660e\u663e\u6269\u5c55\u8d8b\u52bf\uff1b3) \u5f3a\u5316\u5b66\u4e60\u5c06How2Bench\u6027\u80fd\u63d0\u5347>10\u5206\uff0c\u4e14\u4e0d\u5f71\u54cd\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "How2Everything\u5c55\u793a\u4e86\u9884\u8bad\u7ec3\u7f51\u7edc\u6570\u636e\u5982\u4f55\u652f\u6301\u80fd\u529b\u8bc4\u4f30\u548c\u6539\u8fdb\u7684\u95ed\u73af\uff0c\u4e3a\u7a0b\u5e8f\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\u6846\u67b6\u3002"}}
{"id": "2602.08809", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08809", "abs": "https://arxiv.org/abs/2602.08809", "authors": ["Karim Haroun", "Aya Zitouni", "Aicha Zenakhri", "Meriem Amel Guessoum", "Larbi Boubchir"], "title": "Efficient Deep Learning for Biometrics: Overview, Challenges and Trends in Ear of Frugal AI", "comment": "8 pages, 2 figures, accepted at the 2025 IEEE SDS conference", "summary": "Recent advances in deep learning, whether on discriminative or generative tasks have been beneficial for various applications, among which security and defense. However, their increasing computational demands during training and deployment translates directly into high energy consumption. As a consequence, this induces a heavy carbon footprint which hinders their widespread use and scalability, but also a limitation when deployed on resource-constrained edge devices for real-time use. In this paper, we briefly survey efficient deep learning methods for biometric applications. Specifically, we tackle the challenges one might incur when training and deploying deep learning approaches, and provide a taxonomy of the various efficient deep learning families. Additionally, we discuss complementary metrics for evaluating the efficiency of these models such as memory, computation, latency, throughput, and advocate for universal and reproducible metrics for better comparison. Last, we give future research directions to consider.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7b80\u8981\u7efc\u8ff0\u4e86\u751f\u7269\u8bc6\u522b\u5e94\u7528\u4e2d\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u8ba8\u8bba\u4e86\u8bad\u7ec3\u548c\u90e8\u7f72\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u6cd5\uff0c\u5e76\u5021\u5bfc\u4f7f\u7528\u901a\u7528\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u5b89\u5168\u9632\u5fa1\u7b49\u5e94\u7528\u4e2d\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u8bad\u7ec3\u548c\u90e8\u7f72\u7684\u8ba1\u7b97\u9700\u6c42\u5bfc\u81f4\u9ad8\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf9\u751f\u7269\u8bc6\u522b\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u7cfb\u7edf\u68b3\u7406\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5e76\u8ba8\u8bba\u5305\u62ec\u5185\u5b58\u3001\u8ba1\u7b97\u3001\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u5728\u5185\u7684\u8865\u5145\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5efa\u7acb\u4e86\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u8bc6\u522b\u4e86\u8bad\u7ec3\u548c\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6307\u6807\u4f53\u7cfb\uff0c\u4e3a\u751f\u7269\u8bc6\u522b\u9886\u57df\u7684\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ee5\u964d\u4f4e\u80fd\u8017\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u540c\u65f6\u5e94\u5efa\u7acb\u901a\u7528\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u4fc3\u8fdb\u6df1\u5ea6\u5b66\u4e60\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2602.08810", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08810", "abs": "https://arxiv.org/abs/2602.08810", "authors": ["Karan Bania", "Soham Kalburgi", "Manit Tanwar", "Dhruthi", "Aditya Nagarsekar", "Harshvardhan Mestha", "Naman Chibber", "Raj Deshmukh", "Anish Sathyanarayanan", "Aarush Rathore", "Pratham Chheda"], "title": "$\\texttt{lrnnx}$: A library for Linear RNNs", "comment": "EACL Student Research Workshop 2026", "summary": "Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing implementations are fragmented across different software frameworks, often rely on framework-specific optimizations, and in some cases require custom CUDA kernels or lack publicly available code altogether. As a result, using, comparing, or extending LRNNs requires substantial implementation effort. To address this, we introduce $\\texttt{lrnnx}$, a unified software library that implements several modern LRNN architectures under a common interface. The library exposes multiple levels of control, allowing users to work directly with core components or higher-level model abstractions. $\\texttt{lrnnx}$ aims to improve accessibility, reproducibility, and extensibility of LRNN research and applications. We make our code available under a permissive MIT license.", "AI": {"tldr": "lrnnx\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u7ebf\u6027\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5e93\uff0c\u6574\u5408\u4e86\u591a\u79cdLRNN\u67b6\u6784\uff0c\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\uff0c\u65e8\u5728\u63d0\u9ad8LRNN\u7814\u7a76\u7684\u53ef\u8bbf\u95ee\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684LRNN\u5b9e\u73b0\u5206\u6563\u5728\u4e0d\u540c\u7684\u8f6f\u4ef6\u6846\u67b6\u4e2d\uff0c\u4f9d\u8d56\u6846\u67b6\u7279\u5b9a\u7684\u4f18\u5316\uff0c\u6709\u4e9b\u9700\u8981\u81ea\u5b9a\u4e49CUDA\u5185\u6838\u6216\u7f3a\u4e4f\u516c\u5f00\u4ee3\u7801\uff0c\u5bfc\u81f4\u4f7f\u7528\u3001\u6bd4\u8f83\u6216\u6269\u5c55LRNN\u9700\u8981\u5927\u91cf\u5b9e\u73b0\u5de5\u4f5c\u3002", "method": "\u5f00\u53d1\u4e86lrnnx\u7edf\u4e00\u8f6f\u4ef6\u5e93\uff0c\u5b9e\u73b0\u4e86\u591a\u79cd\u73b0\u4ee3LRNN\u67b6\u6784\uff0c\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\uff0c\u66b4\u9732\u591a\u4e2a\u63a7\u5236\u5c42\u7ea7\uff0c\u5141\u8bb8\u7528\u6237\u76f4\u63a5\u4f7f\u7528\u6838\u5fc3\u7ec4\u4ef6\u6216\u9ad8\u7ea7\u6a21\u578b\u62bd\u8c61\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684LRNN\u5e93\uff0c\u63d0\u9ad8\u4e86LRNN\u7814\u7a76\u7684\u53ef\u8bbf\u95ee\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4ee3\u7801\u91c7\u7528MIT\u8bb8\u53ef\u534f\u8bae\u516c\u5f00\u3002", "conclusion": "lrnnx\u89e3\u51b3\u4e86LRNN\u5b9e\u73b0\u788e\u7247\u5316\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5de5\u5177\uff0c\u4fc3\u8fdb\u4e86LRNN\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2602.08813", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08813", "abs": "https://arxiv.org/abs/2602.08813", "authors": ["Mahdi Sabbaghi", "George Pappas", "Adel Javanmard", "Hamed Hassani"], "title": "Robust Policy Optimization to Prevent Catastrophic Forgetting", "comment": null, "summary": "Large language models are commonly trained through multi-stage post-training: first via RLHF, then fine-tuned for other downstream objectives. Yet even small downstream updates can compromise earlier learned behaviors (e.g., safety), exposing a brittleness known as catastrophic forgetting. This suggests standard RLHF objectives do not guarantee robustness to future adaptation. To address it, most prior work designs downstream-time methods to preserve previously learned behaviors. We argue that preventing this requires pre-finetuning robustness: the base policy should avoid brittle high-reward solutions whose reward drops sharply under standard fine-tuning.\n  We propose Fine-tuning Robust Policy Optimization (FRPO), a robust RLHF framework that optimizes reward not only at the current policy, but across a KL-bounded neighborhood of policies reachable by downstream adaptation. The key idea is to ensure reward stability under policy shifts via a max-min formulation. By modifying GRPO, we develop an algorithm with no extra computation, and empirically show it substantially reduces safety degradation across multiple base models and downstream fine-tuning regimes (SFT and RL) while preserving downstream task performance. We further study a math-focused RL setting, demonstrating that FRPO preserves accuracy under subsequent fine-tuning.", "AI": {"tldr": "FRPO\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684RLHF\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u7b56\u7565\u5728KL\u6709\u754c\u90bb\u57df\u5185\u7684\u5956\u52b1\u7a33\u5b9a\u6027\uff0c\u9632\u6b62\u4e0b\u6e38\u5fae\u8c03\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u663e\u8457\u51cf\u5c11\u5b89\u5168\u6027\u80fd\u9000\u5316\u3002", "motivation": "\u5f53\u524dRLHF\u8bad\u7ec3\u5b58\u5728\u8106\u5f31\u6027\uff1a\u5373\u4f7f\u5c0f\u7684\u4e0b\u6e38\u5fae\u8c03\u66f4\u65b0\u4e5f\u4f1a\u635f\u5bb3\u5148\u524d\u5b66\u4e60\u7684\u884c\u4e3a\uff08\u5982\u5b89\u5168\u6027\uff09\uff0c\u8fd9\u79cd\u707e\u96be\u6027\u9057\u5fd8\u8868\u660e\u6807\u51c6RLHF\u76ee\u6807\u4e0d\u80fd\u4fdd\u8bc1\u5bf9\u672a\u6765\u9002\u5e94\u7684\u9c81\u68d2\u6027\u3002\u9700\u8981\u9884\u5fae\u8c03\u9c81\u68d2\u6027\uff0c\u4f7f\u57fa\u7840\u7b56\u7565\u907f\u514d\u8106\u6027\u7684\u9ad8\u5956\u52b1\u89e3\u3002", "method": "\u63d0\u51faFine-tuning Robust Policy Optimization (FRPO)\uff0c\u4e00\u79cd\u9c81\u68d2\u7684RLHF\u6846\u67b6\uff0c\u4e0d\u4ec5\u4f18\u5316\u5f53\u524d\u7b56\u7565\u7684\u5956\u52b1\uff0c\u8fd8\u4f18\u5316\u4e0b\u6e38\u9002\u5e94\u53ef\u8fbe\u7684KL\u6709\u754c\u90bb\u57df\u5185\u7684\u5956\u52b1\u3002\u91c7\u7528\u6700\u5927-\u6700\u5c0f\u5316\u516c\u5f0f\u786e\u4fdd\u7b56\u7565\u504f\u79fb\u4e0b\u7684\u5956\u52b1\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u4fee\u6539GRPO\u5f00\u53d1\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u7684\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFRPO\u663e\u8457\u51cf\u5c11\u4e86\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u548c\u4e0b\u6e38\u5fae\u8c03\u673a\u5236\uff08SFT\u548cRL\uff09\u4e0b\u7684\u5b89\u5168\u6027\u80fd\u9000\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u5728\u6570\u5b66\u805a\u7126\u7684RL\u8bbe\u7f6e\u4e2d\uff0cFRPO\u5728\u540e\u7eed\u5fae\u8c03\u4e0b\u4fdd\u6301\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "FRPO\u901a\u8fc7\u4f18\u5316\u7b56\u7565\u90bb\u57df\u5185\u7684\u5956\u52b1\u7a33\u5b9a\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86RLHF\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u5bf9\u4e0b\u6e38\u5fae\u8c03\u9c81\u68d2\u7684\u57fa\u7840\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.08817", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08817", "abs": "https://arxiv.org/abs/2602.08817", "authors": ["Chenyu Wang", "Zhanglu Yan", "Zhi Zhou", "Xu Chen", "Weng-Fai Wong"], "title": "Kirin: Improving ANN efficiency with SNN Hybridization", "comment": null, "summary": "Artificial neural networks (ANNs), particularly large language models (LLMs), demonstrate powerful inference capabilities but consume substantial energy. Conversely, spiking neural networks (SNNs) exhibit exceptional energy efficiency due to their binary and event-driven characteristics, thus motivating the study of ANN-to-SNN conversion. In this process, quantization plays a pivotal role, mapping LLMs' floating-point parameters to discrete SNN parameters via the temporal dimension of the time window. However, several challenges remain in the conversion process: (i) converting high bit-width quantization values into binary spikes requires longer time windows, increasing system latency; and (ii) the inherent trade-off between the information loss of single-spike schemes and the energy costs of multi-spike ones in SNN. To address these challenges, we propose Kirin, a integer and spike hybrid based SNN to achieve accuracy lossless ANN-to-SNN conversion with time and energy efficiency. Specifically, we first propose a Spike Matrix Hybridization strategy that encoding low bit-width parameters that leading to small time window size into binary spikes while preserving the rest in integer format, thereby reducing the overall latency of SNN execution. Second, we introduce a silence threshold mechanism to regulate the timing of single-spike firing, ensuring the output is mathematically equivalent to the LLM's output and preserves accuracy. Experimental results demonstrate that Kirin, under a W4A4\\&8 quantization setting, achieves near-FP16 accuracy while reducing energy consumption by up to 84.66\\% and shortening time steps by 93.75\\%.", "AI": {"tldr": "Kirin\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u6570\u548c\u8109\u51b2\u6df7\u5408\u7684SNN\u67b6\u6784\uff0c\u5b9e\u73b0\u65e0\u635f\u7cbe\u5ea6\u7684ANN\u5230SNN\u8f6c\u6362\uff0c\u5728W4A4&8\u91cf\u5316\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u63a5\u8fd1FP16\u7cbe\u5ea6\uff0c\u80fd\u8017\u964d\u4f4e84.66%\uff0c\u65f6\u95f4\u6b65\u957f\u7f29\u77ed93.75%\u3002", "motivation": "\u4f20\u7edfANN\uff08\u7279\u522b\u662fLLM\uff09\u63a8\u7406\u80fd\u529b\u5f3a\u4f46\u80fd\u8017\u9ad8\uff0c\u800cSNN\u5177\u6709\u4e8c\u8fdb\u5236\u548c\u4e8b\u4ef6\u9a71\u52a8\u7279\u6027\uff0c\u80fd\u6548\u6781\u9ad8\u3002ANN\u5230SNN\u8f6c\u6362\u4e2d\u7684\u91cf\u5316\u8fc7\u7a0b\u9762\u4e34\u6311\u6218\uff1a\u9ad8\u6bd4\u7279\u91cf\u5316\u503c\u9700\u8981\u66f4\u957f\u65f6\u95f4\u7a97\u53e3\u589e\u52a0\u5ef6\u8fdf\uff0c\u5355\u8109\u51b2\u65b9\u6848\u4fe1\u606f\u635f\u5931\u4e0e\u591a\u8109\u51b2\u65b9\u6848\u80fd\u8017\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\u3002", "method": "\u63d0\u51faKirin\u6df7\u5408SNN\u67b6\u6784\uff1a1\uff09\u8109\u51b2\u77e9\u9635\u6df7\u5408\u7b56\u7565\uff1a\u5c06\u5bfc\u81f4\u5c0f\u65f6\u95f4\u7a97\u53e3\u7684\u4f4e\u6bd4\u7279\u53c2\u6570\u7f16\u7801\u4e3a\u4e8c\u8fdb\u5236\u8109\u51b2\uff0c\u5176\u4f59\u4fdd\u7559\u4e3a\u6574\u6570\u683c\u5f0f\uff0c\u51cf\u5c11SNN\u6267\u884c\u5ef6\u8fdf\uff1b2\uff09\u9759\u9ed8\u9608\u503c\u673a\u5236\uff1a\u8c03\u8282\u5355\u8109\u51b2\u53d1\u5c04\u65f6\u673a\uff0c\u786e\u4fdd\u8f93\u51fa\u4e0eLLM\u6570\u5b66\u7b49\u4ef7\uff0c\u4fdd\u6301\u7cbe\u5ea6\u65e0\u635f\u3002", "result": "\u5728W4A4&8\u91cf\u5316\u8bbe\u7f6e\u4e0b\uff0cKirin\u5b9e\u73b0\u63a5\u8fd1FP16\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u80fd\u8017\u964d\u4f4e\u9ad8\u8fbe84.66%\uff0c\u65f6\u95f4\u6b65\u957f\u7f29\u77ed93.75%\uff0c\u8bc1\u660e\u4e86\u5176\u65f6\u95f4\u548c\u80fd\u91cf\u6548\u7387\u3002", "conclusion": "Kirin\u901a\u8fc7\u6574\u6570\u548c\u8109\u51b2\u6df7\u5408\u7684SNN\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86ANN\u5230SNN\u8f6c\u6362\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\u3001\u5ef6\u8fdf\u548c\u80fd\u8017\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08818", "abs": "https://arxiv.org/abs/2602.08818", "authors": ["Annemette Brok Pirchert", "Jacob Nielsen", "Mogens Henrik From", "Lukas Galke Poech", "Peter Schneider-Kamp"], "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models", "comment": null, "summary": "Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts, which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating $6$ experts with ranks $2^0$ to $2^{14}$ resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across $120$ tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score $47.18$) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score $45.46$) at less than one third the parameters ($10.75$B for FlexMoRE vs. $33.27$B for FlexOlmo). All code will be made available.", "AI": {"tldr": "FlexMoRE\u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u5141\u8bb8\u4e13\u5bb6\u6a21\u578b\u91c7\u7528\u4e0d\u540c\u79e9\u7684\u4f4e\u79e9\u9002\u914d\u5668\u800c\u975e\u5168\u5c3a\u5bf8\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u901a\u5e38\u8bad\u7ec3\u5168\u5c3a\u5bf8\u4e13\u5bb6\u6a21\u578b\uff0c\u4f46\u4f5c\u8005\u5047\u8bbe\u5e76\u975e\u6240\u6709\u9886\u57df\u90fd\u9700\u8981\u5b8c\u6574\u6a21\u578b\uff0c\u4f4e\u79e9\u9002\u914d\u5668\u53ef\u80fd\u5c31\u8db3\u591f\u3002\u8fd9\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5185\u5b58\u6548\u7387\u3002", "method": "\u63d0\u51faFlexMoRE\u67b6\u6784\uff0c\u652f\u6301\u6df7\u5408\u4f7f\u7528\u5168\u5c3a\u5bf8\u4e13\u5bb6\u548c\u4e0d\u540c\u79e9\u7684\u4f4e\u79e9\u9002\u914d\u5668\u3002\u57fa\u4e8eFlexOlmo\u6846\u67b6\uff0c\u5c06\u5176\u9884\u8bad\u7ec3\u4e13\u5bb6\u8f6c\u6362\u4e3a\u4f4e\u79e9\u7248\u672c\uff0c\u7cfb\u7edf\u7814\u7a76\u4e13\u5bb6\u79e9\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u6743\u8861\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u9700\u8981\u66f4\u9ad8\u79e9\u7684\u4e13\u5bb6\uff0c\u800c\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u53ef\u4ee5\u4f7f\u7528\u8f83\u4f4e\u79e9\u7684\u4e13\u5bb6\u3002\u4f7f\u7528\u6700\u4f18\u79e9\u7684FlexMoRE\u5728\u5e73\u5747\u5f97\u520647.18\u4e0b\u4f18\u4e8e\u5168\u5c3a\u5bf8\u4e13\u5bb6\u6df7\u5408\u768445.46\uff0c\u540c\u65f6\u53c2\u6570\u51cf\u5c11\u5230\u4e09\u5206\u4e4b\u4e00\uff0810.75B vs 33.27B\uff09\u3002", "conclusion": "FlexMoRE\u901a\u8fc7\u7075\u6d3b\u6df7\u5408\u4e0d\u540c\u79e9\u7684\u4e13\u5bb6\uff0c\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5b58\u6548\u7387\uff0c\u4e3a\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u4f18\u65b9\u6848\u3002"}}
{"id": "2602.08847", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08847", "abs": "https://arxiv.org/abs/2602.08847", "authors": ["Lang Feng", "Longtao Zheng", "Shuo He", "Fuxiang Zhang", "Bo An"], "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems", "comment": "Preprint", "summary": "Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability. Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems. Dr. MAS uses an agent-wise remedy: normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems, supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency.", "AI": {"tldr": "Dr. MAS\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u7a33\u5b9a\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u5956\u52b1\u7edf\u8ba1\u8fdb\u884c\u4f18\u52bf\u5f52\u4e00\u5316\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfGRPO\u65b9\u6cd5\u4e2d\u7684\u68af\u5ea6\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u901a\u8fc7\u89d2\u8272\u4e13\u4e1a\u5316\u5b9e\u73b0\u4e86\u9ad8\u7ea7\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\uff0c\u4f46\u73b0\u6709\u7684\u7fa4\u4f53\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u5728\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e2d\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728GRPO\u98ce\u683c\u7684\u4f18\u5316\u4e2d\uff0c\u5168\u5c40\u5f52\u4e00\u5316\u57fa\u7ebf\u53ef\u80fd\u504f\u79bb\u4e0d\u540c\u667a\u80fd\u4f53\u7684\u5956\u52b1\u5206\u5e03\uff0c\u5bfc\u81f4\u68af\u5ea6\u8303\u6570\u4e0d\u7a33\u5b9a\u3002", "method": "Dr. MAS\u91c7\u7528\u667a\u80fd\u4f53\u7ea7\u522b\u7684\u89e3\u51b3\u65b9\u6848\uff1a\u4f7f\u7528\u6bcf\u4e2a\u667a\u80fd\u4f53\u81ea\u8eab\u7684\u5956\u52b1\u7edf\u8ba1\u5bf9\u4f18\u52bf\u8fdb\u884c\u5f52\u4e00\u5316\uff0c\u4ece\u800c\u6821\u51c6\u68af\u5ea6\u5c3a\u5ea6\u5e76\u7a33\u5b9a\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u662f\u4e00\u4e2a\u7b97\u6cd5\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684RL\u8bad\u7ec3\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u7f16\u6392\u3001\u7075\u6d3b\u7684\u6bcf\u4e2a\u667a\u80fd\u4f53LLM\u670d\u52a1\u548c\u4f18\u5316\u914d\u7f6e\uff0c\u4ee5\u53caLLM\u6f14\u5458\u540e\u7aef\u7684\u5171\u4eab\u8d44\u6e90\u8c03\u5ea6\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u591a\u8f6e\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f\u7528Qwen2.5\u548cQwen3\u7cfb\u5217\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002Dr. MAS\u76f8\u6bd4\u539f\u59cbGRPO\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff08\u6570\u5b66\u4efb\u52a1\uff1aavg@16 +5.6%\uff0cpass@16 +4.6%\uff1b\u641c\u7d22\u4efb\u52a1\uff1aavg@16 +15.2%\uff0cpass@16 +13.1%\uff09\uff0c\u540c\u65f6\u5927\u5e45\u6d88\u9664\u4e86\u68af\u5ea6\u5c16\u5cf0\u3002\u5728\u5f02\u6784\u667a\u80fd\u4f53\u6a21\u578b\u5206\u914d\u4e0b\u4ecd\u7136\u4fdd\u6301\u9ad8\u6548\u3002", "conclusion": "Dr. MAS\u4e3a\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u7a33\u5b9a\u7684RL\u8bad\u7ec3\u65b9\u6848\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7ea7\u522b\u7684\u4f18\u52bf\u5f52\u4e00\u5316\u89e3\u51b3\u4e86\u68af\u5ea6\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.08855", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08855", "abs": "https://arxiv.org/abs/2602.08855", "authors": ["Yang Qiu", "Yixiong Zou", "Jun Wang"], "title": "Rethinking Graph Generalization through the Lens of Sharpness-Aware Minimization", "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across various graph-based tasks but remain highly sensitive to distribution shifts. In this work, we focus on a prevalent yet under-explored phenomenon in graph generalization, Minimal Shift Flip (MSF),where test samples that slightly deviate from the training distribution are abruptly misclassified. To interpret this phenomenon, we revisit MSF through the lens of Sharpness-Aware Minimization (SAM), which characterizes the local stability and sharpness of the loss landscape while providing a theoretical foundation for modeling generalization error. To quantify loss sharpness, we introduce the concept of Local Robust Radius, measuring the smallest perturbation required to flip a prediction and establishing a theoretical link between local stability and generalization. Building on this perspective, we further observe a continual decrease in the robust radius during training, indicating weakened local stability and an increasingly sharp loss landscape that gives rise to MSF. To jointly solve the MSF phenomenon and the intractability of radius, we develop an energy-based formulation that is theoretically proven to be monotonically correlated with the robust radius, offering a tractable and principled objective for modeling flatness and stability. Building on these insights, we propose an energy-driven generative augmentation framework (E2A) that leverages energy-guided latent perturbations to generate pseudo-OOD samples and enhance model generalization. Extensive experiments across multiple benchmarks demonstrate that E2A consistently improves graph OOD generalization, outperforming state-of-the-art baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u666e\u904d\u5b58\u5728\u4f46\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\"\u6700\u5c0f\u504f\u79fb\u7ffb\u8f6c\"\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u9a71\u52a8\u7684\u751f\u6210\u589e\u5f3a\u6846\u67b6\u6765\u63d0\u5347\u56feOOD\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5404\u79cd\u56fe\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5bf9\u5206\u5e03\u504f\u79fb\u9ad8\u5ea6\u654f\u611f\u3002\u8bba\u6587\u5173\u6ce8\u4e00\u4e2a\u666e\u904d\u4f46\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u73b0\u8c61\u2014\u2014\u6700\u5c0f\u504f\u79fb\u7ffb\u8f6c\uff0c\u5373\u6d4b\u8bd5\u6837\u672c\u4ec5\u8f7b\u5fae\u504f\u79bb\u8bad\u7ec3\u5206\u5e03\u5c31\u4f1a\u88ab\u9519\u8bef\u5206\u7c7b\u3002\u9700\u8981\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u5e76\u63d0\u5347\u56fe\u6a21\u578b\u7684OOD\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u4ece\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6MSF\u73b0\u8c61\uff0c\u5f15\u5165\u5c40\u90e8\u9c81\u68d2\u534a\u5f84\u6982\u5ff5\u91cf\u5316\u635f\u5931\u9510\u5ea6\uff1b2. \u63d0\u51fa\u57fa\u4e8e\u80fd\u91cf\u7684\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u4e0e\u9c81\u68d2\u534a\u5f84\u5355\u8c03\u76f8\u5173\uff1b3. \u5f00\u53d1\u80fd\u91cf\u9a71\u52a8\u7684\u751f\u6210\u589e\u5f3a\u6846\u67b6\uff0c\u5229\u7528\u80fd\u91cf\u5f15\u5bfc\u7684\u6f5c\u5728\u6270\u52a8\u751f\u6210\u4f2aOOD\u6837\u672c\u6765\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cE2A\u6846\u67b6\u80fd\u6301\u7eed\u63d0\u5347\u56feOOD\u6cdb\u5316\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u80fd\u91cf\u9a71\u52a8\u751f\u6210\u589e\u5f3a\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6700\u5c0f\u504f\u79fb\u7ffb\u8f6c\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5206\u5e03\u5916\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08868", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08868", "abs": "https://arxiv.org/abs/2602.08868", "authors": ["Junru Zhang", "Lang Feng", "Haoran Shi", "Xu Guo", "Han Yu", "Yabo Dong", "Duanqing Xu"], "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection", "comment": "Preprint", "summary": "Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly classification, localization, and explanation. At its core, an expert chain-of-thought trace is generated to provide a verifiable, fine-grained reasoning from classical analyses (e.g., statistical measures, frequency transforms). Building on this, we propose a novel time-series grounded policy optimization (TimerPO) that incorporates two additional components beyond standard reinforcement learning: a time-series grounded advantage based on optimal transport and an orthogonal projection to ensure this auxiliary granular signal does not interfere with the primary detection objective. Across diverse anomaly scenarios, AnomSeer, with Qwen2.5-VL-3B/7B-Instruct, outperforms larger commercial baselines (e.g., GPT-4o) in classification and localization accuracy, particularly on point- and frequency-driven exceptions. Moreover, it produces plausible time-series reasoning traces that support its conclusions.", "AI": {"tldr": "AnomSeer\u901a\u8fc7\u5f3a\u5316MLLMs\u5728\u65f6\u95f4\u5e8f\u5217\u7ed3\u6784\u7ec6\u8282\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7edf\u4e00\u5f02\u5e38\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u89e3\u91ca\uff0c\u4f7f\u7528\u4e13\u5bb6\u601d\u7ef4\u94fe\u548c\u521b\u65b0\u7684TimerPO\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u5f02\u5e38\u573a\u666f\u4e2d\u8d85\u8d8aGPT-4o\u7b49\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u4f9d\u8d56\u7c97\u7c92\u5ea6\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u96be\u4ee5\u8fdb\u884c\u591a\u7ef4\u5ea6\u7684\u8be6\u7ec6\u63a8\u7406\uff0c\u800c\u7406\u89e3\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u9700\u8981\u7cbe\u786e\u7684\u7ed3\u6784\u7ec6\u8282\u5206\u6790\u3002", "method": "1) \u751f\u6210\u4e13\u5bb6\u601d\u7ef4\u94fe\u8f68\u8ff9\uff0c\u63d0\u4f9b\u57fa\u4e8e\u7ecf\u5178\u5206\u6790\uff08\u7edf\u8ba1\u6d4b\u91cf\u3001\u9891\u7387\u53d8\u6362\uff09\u7684\u53ef\u9a8c\u8bc1\u7ec6\u7c92\u5ea6\u63a8\u7406\uff1b2) \u63d0\u51fa\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u7b56\u7565\u4f18\u5316(TimerPO)\uff0c\u5305\u542b\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u4f18\u52bf\u548c\u6b63\u4ea4\u6295\u5f71\u7ec4\u4ef6\uff0c\u786e\u4fdd\u8f85\u52a9\u7c92\u5ea6\u4fe1\u53f7\u4e0d\u5e72\u6270\u4e3b\u8981\u68c0\u6d4b\u76ee\u6807\u3002", "result": "\u4f7f\u7528Qwen2.5-VL-3B/7B-Instruct\u7684AnomSeer\u5728\u591a\u6837\u5f02\u5e38\u573a\u666f\u4e2d\uff0c\u5728\u5206\u7c7b\u548c\u5b9a\u4f4d\u51c6\u786e\u7387\u4e0a\u8d85\u8d8aGPT-4o\u7b49\u5927\u578b\u5546\u4e1a\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u70b9\u548c\u9891\u7387\u9a71\u52a8\u7684\u5f02\u5e38\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u80fd\u751f\u6210\u652f\u6301\u5176\u7ed3\u8bba\u7684\u5408\u7406\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u8f68\u8ff9\u3002", "conclusion": "AnomSeer\u901a\u8fc7\u5f3a\u5316\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u7ed3\u6784\u7ec6\u8282\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u6210\u529f\u89e3\u51b3\u4e86MLLMs\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u591a\u7ef4\u5ea6\u63a8\u7406\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u5f02\u5e38\u5206\u7c7b\u3001\u5b9a\u4f4d\u548c\u89e3\u91ca\u7684\u7edf\u4e00\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u66f4\u5927\u7684\u5546\u4e1a\u6a21\u578b\u3002"}}
{"id": "2602.08859", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08859", "abs": "https://arxiv.org/abs/2602.08859", "authors": ["Sahel Torkamani", "Henry Gouk", "Rik Sarkar"], "title": "Magnitude Distance: A Geometric Measure of Dataset Similarity", "comment": null, "summary": "Quantifying the distance between datasets is a fundamental question in mathematics and machine learning. We propose \\textit{magnitude distance}, a novel distance metric defined on finite datasets using the notion of the \\emph{magnitude} of a metric space. The proposed distance incorporates a tunable scaling parameter, $t$, that controls the sensitivity to global structure (small $t$) and finer details (large $t$). We prove several theoretical properties of magnitude distance, including its limiting behavior across scales and conditions under which it satisfies key metric properties. In contrast to classical distances, we show that magnitude distance remains discriminative in high-dimensional settings when the scale is appropriately tuned. We further demonstrate how magnitude distance can be used as a training objective for push-forward generative models. Our experimental results support our theoretical analysis and demonstrate that magnitude distance provides meaningful signals, comparable to established distance-based generative approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5ea6\u91cf\u7a7a\u95f4magnitude\u6982\u5ff5\u7684\u65b0\u6570\u636e\u96c6\u8ddd\u79bb\u5ea6\u91cf\u2014\u2014magnitude distance\uff0c\u5305\u542b\u53ef\u8c03\u5c3a\u5ea6\u53c2\u6570t\uff0c\u7528\u4e8e\u63a7\u5236\u5bf9\u5168\u5c40\u7ed3\u6784\uff08\u5c0ft\uff09\u548c\u7ec6\u8282\uff08\u5927t\uff09\u7684\u654f\u611f\u6027\u3002", "motivation": "\u91cf\u5316\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u8ddd\u79bb\u662f\u6570\u5b66\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u53ef\u80fd\u5931\u53bb\u5224\u522b\u529b\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u5c3a\u5ea6\u7ed3\u6784\u7684\u65b0\u8ddd\u79bb\u5ea6\u91cf\u3002", "method": "\u57fa\u4e8e\u5ea6\u91cf\u7a7a\u95f4\u7684magnitude\u6982\u5ff5\u5b9a\u4e49magnitude distance\uff0c\u5f15\u5165\u53ef\u8c03\u5c3a\u5ea6\u53c2\u6570t\uff0c\u8bc1\u660e\u5176\u7406\u8bba\u6027\u8d28\uff08\u5305\u62ec\u6781\u9650\u884c\u4e3a\u548c\u5ea6\u91cf\u5c5e\u6027\uff09\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u5c06\u5176\u4f5c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u663e\u793amagnitude distance\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u5f53\u5c3a\u5ea6\u9002\u5f53\u8c03\u6574\u65f6\u4ecd\u4fdd\u6301\u5224\u522b\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u8ddd\u79bb\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u4fe1\u53f7\uff0c\u4e0e\u73b0\u6709\u57fa\u4e8e\u8ddd\u79bb\u7684\u751f\u6210\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "magnitude distance\u662f\u4e00\u79cd\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u65b0\u578b\u6570\u636e\u96c6\u8ddd\u79bb\u5ea6\u91cf\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u5c3a\u5ea6\u7ed3\u6784\uff0c\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5e76\u53ef\u4f5c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u3002"}}
{"id": "2602.08878", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08878", "abs": "https://arxiv.org/abs/2602.08878", "authors": ["Itai Zilberstein", "Ioannis Anagnostides", "Zachary W. Sollie", "Arman Kilic", "Tuomas Sandholm"], "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation", "comment": null, "summary": "Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In this paper, we propose a novel framework for non-myopic policy optimization in general online matching relying on potentials, a concept originally introduced for kidney exchange. We develop scalable and accurate ways of learning potentials that are higher-dimensional and more expressive than prior approaches. Our approach is a form of self-supervised imitation learning: the potentials are trained to mimic an omniscient algorithm that has perfect foresight. We focus on the application of heart transplant allocation and demonstrate, using real historical data, that our policies significantly outperform prior approaches -- including the current US status quo policy and the proposed continuous distribution framework -- in optimizing for population-level outcomes. Our analysis and methods come at a pivotal moment in US policy, as the current heart transplant allocation system is under review. We propose a scalable and theoretically grounded path toward more effective organ allocation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52bf\u80fd\u51fd\u6570\u7684\u975e\u8fd1\u89c6\u653f\u7b56\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5fc3\u810f\u79fb\u690d\u5668\u5b98\u5206\u914d\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\u52bf\u80fd\u51fd\u6570\u6765\u6a21\u62df\u5168\u77e5\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u53e3\u5c42\u9762\u7684\u5206\u914d\u6548\u7387\u3002", "motivation": "\u6bcf\u5e74\u6709\u6570\u5343\u540d\u9700\u8981\u5fc3\u810f\u79fb\u690d\u7684\u60a3\u8005\u56e0\u5668\u5b98\u77ed\u7f3a\u9762\u4e34\u751f\u547d\u5371\u9669\u3002\u5f53\u524d\u5206\u914d\u653f\u7b56\u672a\u80fd\u5145\u5206\u8003\u8651\u5668\u5b98\u52a8\u6001\u5230\u8fbe\u548c\u5019\u9009\u8005\u7ec4\u6210\u7684\u590d\u6742\u6027\uff0c\u4e14\u7f8e\u56fd\u6b63\u4ece\u57fa\u4e8e\u89c4\u5219\u7684\u7cfb\u7edf\u8f6c\u5411\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u52bf\u80fd\u51fd\u6570\u7684\u975e\u8fd1\u89c6\u653f\u7b56\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\u9ad8\u7ef4\u3001\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u7684\u52bf\u80fd\u51fd\u6570\uff0c\u4f7f\u5176\u80fd\u591f\u6a21\u62df\u5177\u6709\u5b8c\u7f8e\u9884\u89c1\u80fd\u529b\u7684\u5168\u77e5\u7b97\u6cd5\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u5386\u53f2\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u7f8e\u56fd\u73b0\u72b6\u653f\u7b56\u548c\u8fde\u7eed\u5206\u5e03\u6846\u67b6\uff09\uff0c\u5728\u4f18\u5316\u4eba\u53e3\u5c42\u9762\u7ed3\u679c\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7f8e\u56fd\u5fc3\u810f\u79fb\u690d\u5206\u914d\u7cfb\u7edf\u6539\u9769\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7406\u8bba\u4f9d\u636e\u5145\u5206\u7684\u8def\u5f84\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5668\u5b98\u5206\u914d\u3002"}}
{"id": "2602.08885", "categories": ["cs.LG", "cs.AI", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.08885", "abs": "https://arxiv.org/abs/2602.08885", "authors": ["Paul Saegert", "Ullrich K\u00f6the"], "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression", "comment": "main text: 8 pages, 7 figures appendix: 12 pages, 11 figures code available at https://github.com/psaegert/simplipy and https://github.com/psaegert/flash-ansr", "summary": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget.", "AI": {"tldr": "SimpliPy\u7b80\u5316\u5f15\u64ce\u5b9e\u73b0100\u500d\u52a0\u901f\uff0cFlash-ANSR\u6846\u67b6\u5728\u7b26\u53f7\u56de\u5f52\u4e2d\u8fbe\u5230\u4e0ePySR\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u80fd\u53d1\u73b0\u66f4\u7b80\u6d01\u7684\u8868\u8fbe\u5f0f\u3002", "motivation": "\u5f53\u524d\u644a\u9500\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\u5728\u5904\u7406\u7b49\u6548\u8868\u8fbe\u5f0f\u7b80\u5316\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4f9d\u8d56\u901a\u7528\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\uff08\u5982SymPy\uff09\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u901f\u5ea6\u3002", "method": "\u63d0\u51faSimpliPy\u89c4\u5219\u5316\u7b80\u5316\u5f15\u64ce\uff0c\u5b9e\u73b0\u6bd4SymPy\u5feb100\u500d\u7684\u8868\u8fbe\u5f0f\u7b80\u5316\uff1b\u57fa\u4e8e\u6b64\u6784\u5efaFlash-ANSR\u6846\u67b6\uff0c\u6539\u8fdb\u644a\u9500\u7b26\u53f7\u56de\u5f52\u7684\u8bad\u7ec3\u6548\u7387\u3001\u8868\u8fbe\u5f0f\u8868\u793a\u548c\u6570\u636e\u96c6\u53bb\u6c61\u67d3\u3002", "result": "\u5728FastSRB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFlash-ANSR\u6bd4NeSymReS\u548cE2E\u7b49\u644a\u9500\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u66f4\u9ad8\uff1b\u4e0e\u76f4\u63a5\u4f18\u5316\u65b9\u6cd5PySR\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u80fd\u5728\u589e\u52a0\u63a8\u7406\u9884\u7b97\u65f6\u53d1\u73b0\u66f4\u7b80\u6d01\u800c\u975e\u66f4\u590d\u6742\u7684\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u9ad8\u6548\u7684\u8868\u8fbe\u5f0f\u7b80\u5316\u662f\u644a\u9500\u7b26\u53f7\u56de\u5f52\u6269\u5c55\u81f3\u5b9e\u9645\u79d1\u5b66\u590d\u6742\u5ea6\u7684\u5173\u952e\uff0cSimpliPy\u548cFlash-ANSR\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u51c6\u786e\u6027\u548c\u8868\u8fbe\u5f0f\u7b80\u6d01\u6027\u3002"}}
{"id": "2602.08934", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08934", "abs": "https://arxiv.org/abs/2602.08934", "authors": ["Suraj Ranganath", "Atharv Ramesh"], "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors", "comment": "Expanded version of a workshop submission. Code available", "summary": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.", "AI": {"tldr": "StealthRL\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u6297\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u6539\u5199\u5728\u4fdd\u6301\u8bed\u4e49\u7684\u540c\u65f6\u9003\u907fAI\u6587\u672c\u68c0\u6d4b\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u68c0\u6d4b\u5668\u5728\u5b89\u5168\u76f8\u5173\u64cd\u4f5c\u70b9\uff081%\u8bef\u62a5\u7387\uff09\u5b58\u5728\u4e25\u91cd\u9c81\u68d2\u6027\u6f0f\u6d1e\u3002", "motivation": "AI\u6587\u672c\u68c0\u6d4b\u5668\u9762\u4e34\u5173\u952e\u7684\u9c81\u68d2\u6027\u6311\u6218\uff1a\u5bf9\u6297\u6027\u6539\u5199\u653b\u51fb\u80fd\u591f\u5728\u4fdd\u6301\u8bed\u4e49\u7684\u540c\u65f6\u9003\u907f\u68c0\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u538b\u529b\u6d4b\u8bd5\u68c0\u6d4b\u5668\u5728\u73b0\u5b9e\u5bf9\u6297\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faStealthRL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u548cLoRA\u9002\u914d\u5668\u5728Qwen3-4B\u6a21\u578b\u4e0a\u8bad\u7ec3\u6539\u5199\u7b56\u7565\uff0c\u9488\u5bf9\u591a\u68c0\u6d4b\u5668\u96c6\u6210\u4f18\u5316\u590d\u5408\u5956\u52b1\u51fd\u6570\uff0c\u5e73\u8861\u68c0\u6d4b\u9003\u907f\u548c\u8bed\u4e49\u4fdd\u6301\u3002", "result": "\u57281%\u8bef\u62a5\u7387\u7684\u5b89\u5168\u76f8\u5173\u64cd\u4f5c\u70b9\u4e0b\uff0cStealthRL\u5b9e\u73b0\u63a5\u8fd1\u96f6\u7684\u68c0\u6d4b\u7387\uff08\u5e73\u5747TPR@1%FPR\u4e3a0.001\uff09\uff0c\u5c06\u5e73\u5747AUROC\u4ece0.74\u964d\u81f30.27\uff0c\u653b\u51fb\u6210\u529f\u7387\u8fbe\u523099.9%\u3002\u653b\u51fb\u8fd8\u80fd\u8fc1\u79fb\u5230\u8bad\u7ec3\u4e2d\u672a\u89c1\u8fc7\u7684\u68c0\u6d4b\u5668\u5bb6\u65cf\uff0c\u63ed\u793a\u4e86\u5171\u4eab\u7684\u67b6\u6784\u6f0f\u6d1e\u3002", "conclusion": "\u5f53\u524dAI\u6587\u672c\u68c0\u6d4b\u5668\u5b58\u5728\u663e\u8457\u7684\u9c81\u68d2\u6027\u5dee\u8ddd\uff0cStealthRL\u4e3a\u5bf9\u6297\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u534f\u8bae\u3002\u4ee3\u7801\u548c\u8bc4\u4f30\u6d41\u7a0b\u5df2\u516c\u5f00\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u9c81\u68d2\u7684\u68c0\u6d4b\u5668\u5f00\u53d1\u3002"}}
{"id": "2602.08877", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08877", "abs": "https://arxiv.org/abs/2602.08877", "authors": ["Oliver Daniels", "Perusha Moodley", "Ben Marlin", "David Lindner"], "title": "Stress-Testing Alignment Audits With Prompt-Level Strategic Deception", "comment": null, "summary": "Alignment audits aim to robustly identify hidden goals from strategic, situationally aware misaligned models. Despite this threat model, existing auditing methods have not been systematically stress-tested against deception strategies. We address this gap, implementing an automatic red-team pipeline that generates deception strategies (in the form of system prompts) tailored to specific white-box and black-box auditing methods. Stress-testing assistant prefills, user persona sampling, sparse autoencoders, and token embedding similarity methods against secret-keeping model organisms, our automatic red-team pipeline finds prompts that deceive both the black-box and white-box methods into confident, incorrect guesses. Our results provide the first documented evidence of activation-based strategic deception, and suggest that current black-box and white-box methods would not be robust to a sufficiently capable misaligned model.", "AI": {"tldr": "\u8bba\u6587\u5f00\u53d1\u4e86\u81ea\u52a8\u7ea2\u961f\u7ba1\u9053\uff0c\u9488\u5bf9\u73b0\u6709\u5bf9\u9f50\u5ba1\u8ba1\u65b9\u6cd5\u751f\u6210\u6b3a\u9a97\u7b56\u7565\uff0c\u9996\u6b21\u8bc1\u660e\u4e86\u6fc0\u6d3b\u5c42\u9762\u7684\u6218\u7565\u6027\u6b3a\u9a97\uff0c\u5e76\u663e\u793a\u5f53\u524d\u9ed1\u767d\u76d2\u65b9\u6cd5\u5728\u9762\u5bf9\u6709\u80fd\u529b\u7684\u9519\u4f4d\u6a21\u578b\u65f6\u4e0d\u591f\u9c81\u68d2\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u5ba1\u8ba1\u65b9\u6cd5\u867d\u7136\u65e8\u5728\u68c0\u6d4b\u6218\u7565\u6027\u3001\u60c5\u5883\u611f\u77e5\u7684\u9519\u4f4d\u6a21\u578b\u7684\u9690\u85cf\u76ee\u6807\uff0c\u4f46\u5c1a\u672a\u7cfb\u7edf\u6027\u5730\u9488\u5bf9\u6b3a\u9a97\u7b56\u7565\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\uff0c\u5b58\u5728\u8bc4\u4f30\u76f2\u70b9\u3002", "method": "\u6784\u5efa\u81ea\u52a8\u7ea2\u961f\u7ba1\u9053\uff0c\u4e3a\u7279\u5b9a\u767d\u76d2\u548c\u9ed1\u76d2\u5ba1\u8ba1\u65b9\u6cd5\u751f\u6210\u5b9a\u5236\u5316\u7684\u6b3a\u9a97\u7b56\u7565\uff08\u7cfb\u7edf\u63d0\u793a\uff09\uff0c\u5bf9\u52a9\u624b\u9884\u586b\u5145\u3001\u7528\u6237\u89d2\u8272\u91c7\u6837\u3001\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548c\u8bcd\u5d4c\u5165\u76f8\u4f3c\u6027\u7b49\u65b9\u6cd5\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3002", "result": "\u81ea\u52a8\u7ea2\u961f\u7ba1\u9053\u627e\u5230\u4e86\u80fd\u591f\u6b3a\u9a97\u9ed1\u767d\u76d2\u5ba1\u8ba1\u65b9\u6cd5\u7684\u63d0\u793a\uff0c\u4f7f\u5176\u505a\u51fa\u81ea\u4fe1\u4f46\u9519\u8bef\u7684\u731c\u6d4b\u3002\u9996\u6b21\u8bb0\u5f55\u4e86\u57fa\u4e8e\u6fc0\u6d3b\u7684\u6218\u7565\u6027\u6b3a\u9a97\u8bc1\u636e\u3002", "conclusion": "\u5f53\u524d\u7684\u9ed1\u767d\u76d2\u5bf9\u9f50\u5ba1\u8ba1\u65b9\u6cd5\u5728\u9762\u5bf9\u8db3\u591f\u6709\u80fd\u529b\u7684\u9519\u4f4d\u6a21\u578b\u65f6\u4e0d\u591f\u9c81\u68d2\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u7684\u5ba1\u8ba1\u6280\u672f\u6765\u5e94\u5bf9\u6218\u7565\u6027\u6b3a\u9a97\u3002"}}
{"id": "2602.08983", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08983", "abs": "https://arxiv.org/abs/2602.08983", "authors": ["Yubin Kim", "Viresh Pati", "Jevon Twitty", "Vinh Pham", "Shihao Yang", "Jiecheng Lu"], "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention", "comment": null, "summary": "Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and prove that rotary position embedding (RoPE) is mathematically incapable of representing non-affine temporal warping. To address this, we propose Symplectic Positional Embeddings (SyPE), a learnable encoding framework derived from Hamiltonian mechanics. SyPE strictly generalizes RoPE by extending the rotation group $\\mathrm{SO}(2)$ to the symplectic group $\\mathrm{Sp}(2,\\mathbb{R})$, modulated by a novel input-dependent adaptive warp module. By allowing the attention mechanism to adaptively dilate or contract temporal coordinates end-to-end, our approach captures locally varying periodicities without requiring pre-defined warping functions. We implement this mechanism in StretchTime, a multivariate forecasting architecture that achieves state-of-the-art performance on standard benchmarks, demonstrating superior robustness on datasets exhibiting non-stationary temporal dynamics.", "AI": {"tldr": "\u63d0\u51faSymplectic Positional Embeddings (SyPE)\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u4e2d\u975e\u5747\u5300\u65f6\u95f4\u626d\u66f2\u95ee\u9898\uff0c\u901a\u8fc7\u8f9b\u7fa4\u6269\u5c55RoPE\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u65f6\u95f4\u5750\u6807\u4f38\u7f29\uff0c\u5728StretchTime\u67b6\u6784\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\uff08\u5982\u91d1\u878d\u5468\u671f\u3001\u751f\u7269\u8282\u5f8b\uff09\u5e38\u8868\u73b0\u51fa\"\u65f6\u95f4\u626d\u66f2\"\u52a8\u6001\uff0c\u5373\u6709\u6548\u65f6\u95f4\u6d41\u4e0e\u91c7\u6837\u7d22\u5f15\u89e3\u8026\u3002\u4f20\u7edfTransformer\u7684\u4f4d\u7f6e\u7f16\u7801\uff08\u5982RoPE\uff09\u5047\u8bbe\u5747\u5300\u7684\u65f6\u95f4\u8fdb\u5c55\uff0c\u65e0\u6cd5\u8868\u793a\u975e\u4eff\u5c04\u65f6\u95f4\u626d\u66f2\u3002", "method": "\u63d0\u51faSymplectic Positional Embeddings (SyPE)\uff0c\u4ece\u54c8\u5bc6\u987f\u529b\u5b66\u63a8\u5bfc\u7684\u53ef\u5b66\u4e60\u7f16\u7801\u6846\u67b6\u3002\u5c06\u65cb\u8f6c\u7fa4SO(2)\u6269\u5c55\u5230\u8f9b\u7fa4Sp(2,R)\uff0c\u901a\u8fc7\u8f93\u5165\u4f9d\u8d56\u7684\u81ea\u9002\u5e94\u626d\u66f2\u6a21\u5757\u8c03\u5236\uff0c\u4f7f\u6ce8\u610f\u529b\u673a\u5236\u80fd\u7aef\u5230\u7aef\u5730\u81ea\u9002\u5e94\u6269\u5f20\u6216\u6536\u7f29\u65f6\u95f4\u5750\u6807\u3002", "result": "\u5728StretchTime\u591a\u53d8\u91cf\u9884\u6d4b\u67b6\u6784\u4e2d\u5b9e\u73b0SyPE\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u8868\u73b0\u51fa\u975e\u5e73\u7a33\u65f6\u95f4\u52a8\u6001\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u51fa\u5353\u8d8a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SyPE\u4e25\u683c\u63a8\u5e7f\u4e86RoPE\uff0c\u80fd\u591f\u6355\u6349\u5c40\u90e8\u53d8\u5316\u7684\u5468\u671f\u6027\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u626d\u66f2\u51fd\u6570\uff0c\u4e3a\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u975e\u5747\u5300\u65f6\u95f4\u52a8\u6001\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08894", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08894", "abs": "https://arxiv.org/abs/2602.08894", "authors": ["Iryna Zabarianska", "Sergei Kholkin", "Grigoriy Ksenofontov", "Ivan Butakov", "Alexander Korotin"], "title": "Discrete Bridges for Mutual Information Estimation", "comment": null, "summary": "Diffusion bridge models in both continuous and discrete state spaces have recently become powerful tools in the field of generative modeling. In this work, we leverage the discrete state space formulation of bridge matching models to address another important problem in machine learning and information theory: the estimation of the mutual information (MI) between discrete random variables. By neatly framing MI estimation as a domain transfer problem, we construct a Discrete Bridge Mutual Information (DBMI) estimator suitable for discrete data, which poses difficulties for conventional MI estimators. We showcase the performance of our estimator on two MI estimation settings: low-dimensional and image-based.", "AI": {"tldr": "\u63d0\u51faDBMI\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u79bb\u6563\u6865\u5339\u914d\u6a21\u578b\u5c06\u4e92\u4fe1\u606f\u4f30\u8ba1\u8f6c\u5316\u4e3a\u57df\u8f6c\u79fb\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u79bb\u6563\u6570\u636e", "motivation": "\u4f20\u7edf\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\u96be\u4ee5\u5904\u7406\u79bb\u6563\u6570\u636e\uff0c\u800c\u6269\u6563\u6865\u6a21\u578b\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u53d1\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def", "method": "\u5c06\u4e92\u4fe1\u606f\u4f30\u8ba1\u6784\u5efa\u4e3a\u57df\u8f6c\u79fb\u95ee\u9898\uff0c\u5229\u7528\u79bb\u6563\u6865\u5339\u914d\u6a21\u578b\u6846\u67b6\uff0c\u5f00\u53d1\u79bb\u6563\u6865\u4e92\u4fe1\u606f\uff08DBMI\uff09\u4f30\u8ba1\u5668", "result": "\u5728\u4f4e\u7ef4\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u4e24\u79cd\u4e92\u4fe1\u606f\u4f30\u8ba1\u573a\u666f\u4e2d\u5c55\u793a\u4e86DBMI\u4f30\u8ba1\u5668\u7684\u6027\u80fd", "conclusion": "\u79bb\u6563\u6865\u6a21\u578b\u4e0d\u4ec5\u53ef\u7528\u4e8e\u751f\u6210\u5efa\u6a21\uff0c\u8fd8\u80fd\u6709\u6548\u89e3\u51b3\u79bb\u6563\u6570\u636e\u7684\u4e92\u4fe1\u606f\u4f30\u8ba1\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u65b0\u5de5\u5177"}}
{"id": "2602.08986", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08986", "abs": "https://arxiv.org/abs/2602.08986", "authors": ["Isaac Xu", "Martin Gillis", "Ayushi Sharma", "Benjamin Misiuk", "Craig J. Brown", "Thomas Trappenberg"], "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning", "comment": "Accepted for publication in Transactions on Machine Learning Research (TMLR), 2026", "summary": "In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective for neural networks that combines node-wise imbalance weighting with focal weighting components, the latter leveraging modern quantification of ensemble uncertainties. By emphasizing rare nodes rather than rare observations (data points), and focusing on uncertain nodes for each model output distribution during training, we observe improvements in recall by up to a factor of five on benchmark datasets, along with statistically significant gains in $F_{1}$ score. We also show our approach aids convolutional networks on challenging tasks, as in situations with suboptimal encoders or limited data.", "AI": {"tldr": "\u63d0\u51fa\u52a0\u6743\u635f\u5931\u51fd\u6570\u89e3\u51b3\u5c42\u6b21\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u6df1\u5c42\u8282\u70b9\u9884\u6d4b\u56f0\u96be\u95ee\u9898\uff0c\u901a\u8fc7\u8282\u70b9\u4e0d\u5e73\u8861\u52a0\u6743\u548c\u7126\u70b9\u52a0\u6743\u7ec4\u4ef6\uff0c\u63d0\u5347\u7a00\u6709\u8282\u70b9\u548c\u4e0d\u786e\u5b9a\u8282\u70b9\u7684\u8bad\u7ec3\u6548\u679c", "motivation": "\u5c42\u6b21\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u6a21\u578b\u96be\u4ee5\u9884\u6d4b\u5230\u5c42\u6b21\u7ed3\u6784\u7684\u66f4\u6df1\u5c42\u8282\u70b9\uff0c\u8fd9\u6e90\u4e8e\u67d0\u4e9b\u7c7b\u522b\u7684\u81ea\u7136\u7a00\u6709\u6027\u4ee5\u53ca\u5c42\u6b21\u7ea6\u675f\u5bfc\u81f4\u5b50\u8282\u70b9\u901a\u5e38\u6bd4\u7236\u8282\u70b9\u66f4\u4e0d\u9891\u7e41", "method": "\u63d0\u51fa\u795e\u7ecf\u7f51\u7edc\u7684\u52a0\u6743\u635f\u5931\u76ee\u6807\u51fd\u6570\uff0c\u7ed3\u5408\u8282\u70b9\u4e0d\u5e73\u8861\u52a0\u6743\u548c\u7126\u70b9\u52a0\u6743\u7ec4\u4ef6\uff0c\u540e\u8005\u5229\u7528\u96c6\u6210\u4e0d\u786e\u5b9a\u6027\u7684\u73b0\u4ee3\u91cf\u5316\u65b9\u6cd5\uff0c\u5f3a\u8c03\u7a00\u6709\u8282\u70b9\u800c\u975e\u7a00\u6709\u89c2\u6d4b\u503c\uff0c\u5e76\u5173\u6ce8\u6bcf\u4e2a\u6a21\u578b\u8f93\u51fa\u5206\u5e03\u4e2d\u7684\u4e0d\u786e\u5b9a\u8282\u70b9", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u89c2\u5bdf\u5230\u53ec\u56de\u7387\u63d0\u5347\u9ad8\u8fbe5\u500d\uff0cF1\u5206\u6570\u6709\u7edf\u8ba1\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u5377\u79ef\u7f51\u7edc\u5728\u5177\u6709\u6b21\u4f18\u7f16\u7801\u5668\u6216\u6709\u9650\u6570\u636e\u7684\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d", "conclusion": "\u63d0\u51fa\u7684\u52a0\u6743\u635f\u5931\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5c42\u6b21\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u7684\u6df1\u5c42\u8282\u70b9\u9884\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u5173\u6ce8\u8282\u70b9\u4e0d\u5e73\u8861\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd"}}
{"id": "2602.08901", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08901", "abs": "https://arxiv.org/abs/2602.08901", "authors": ["Xuanqi Zhang", "Haoyang Shang", "Xiaoxiao Li"], "title": "GSS: Gated Subspace Steering for Selective Memorization Mitigation in LLMs", "comment": "34 pages, 12 figures", "summary": "Large language models (LLMs) can memorize and reproduce training sequences verbatim -- a tendency that undermines both generalization and privacy. Existing mitigation methods apply interventions uniformly, degrading performance on the majority of tokens that generalize normally. We show empirically that memorization is sparse, intermittent, and token-conditioned, suggesting that effective mitigation requires context-aware intervention rather than static parameter modification. To this end, we propose a novel and effective selective memorization mitigation method -- Gated Subspace Steering (GSS), which decomposes intervention into a probe (detecting memorization-relevant activations) and a steer (applying targeted correction only when the probe exceeds a threshold). The optimal probe-steer pair emerges from a principled optimization framework based on optimal subspace steering. Experiments on four benchmarks show GSS matches or exceeds state-of-the-art memorization reduction while requiring $100-1000 \\times$ less compute than optimization-based alternatives. Furthermore, we provide new theoretical insights into the geometry of memorization in neural representations.", "AI": {"tldr": "\u63d0\u51faGated Subspace Steering (GSS)\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a2\u6d4b-\u5f15\u5bfc\u673a\u5236\u9009\u62e9\u6027\u7f13\u89e3LLM\u7684\u8bb0\u5fc6\u95ee\u9898\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u63d0\u5347100-1000\u500d\u3002", "motivation": "\u73b0\u6709\u7f13\u89e3LLM\u8bb0\u5fc6\u95ee\u9898\u7684\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5747\u5300\u5e72\u9884\uff0c\u8fd9\u4f1a\u964d\u4f4e\u6a21\u578b\u5728\u5927\u591a\u6570\u6b63\u5e38\u6cdb\u5316token\u4e0a\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\u8bb0\u5fc6\u662f\u7a00\u758f\u3001\u95f4\u6b47\u4e14token\u6761\u4ef6\u4f9d\u8d56\u7684\uff0c\u9700\u8981\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5e72\u9884\u800c\u975e\u9759\u6001\u53c2\u6570\u4fee\u6539\u3002", "method": "\u63d0\u51faGated Subspace Steering (GSS)\u65b9\u6cd5\uff0c\u5c06\u5e72\u9884\u5206\u89e3\u4e3a\u63a2\u6d4b\uff08\u68c0\u6d4b\u4e0e\u8bb0\u5fc6\u76f8\u5173\u7684\u6fc0\u6d3b\uff09\u548c\u5f15\u5bfc\uff08\u4ec5\u5f53\u63a2\u6d4b\u8d85\u8fc7\u9608\u503c\u65f6\u5e94\u7528\u9488\u5bf9\u6027\u4fee\u6b63\uff09\u3002\u6700\u4f18\u7684\u63a2\u6d4b-\u5f15\u5bfc\u5bf9\u57fa\u4e8e\u6700\u4f18\u5b50\u7a7a\u95f4\u5f15\u5bfc\u7684\u4f18\u5316\u6846\u67b6\u4ea7\u751f\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGSS\u5728\u51cf\u5c11\u8bb0\u5fc6\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u8ba1\u7b97\u9700\u6c42\u6bd4\u57fa\u4e8e\u4f18\u5316\u7684\u66ff\u4ee3\u65b9\u6cd5\u5c11100-1000\u500d\u3002\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8e\u795e\u7ecf\u8868\u793a\u4e2d\u8bb0\u5fc6\u51e0\u4f55\u7ed3\u6784\u7684\u65b0\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "GSS\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u9009\u62e9\u6027\u8bb0\u5fc6\u7f13\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5e72\u9884\u5728\u4fdd\u6301\u6cdb\u5316\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u8bb0\u5fc6\u95ee\u9898\uff0c\u4e3a\u7406\u89e3LLM\u4e2d\u7684\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u6846\u67b6\u3002"}}
{"id": "2602.09009", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09009", "abs": "https://arxiv.org/abs/2602.09009", "authors": ["Yilang Zhang", "Bingcong Li", "Niao He", "Georgios B. Giannakis"], "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling", "comment": null, "summary": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u9002\u5e94\u795e\u7ecf\u8fde\u63a5\u91cd\u5206\u914d\uff08ANCRe\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u548c\u5b66\u4e60\u6b8b\u5dee\u8fde\u63a5\u6765\u4f18\u5316\u6df1\u5ea6\u7f51\u7edc\u6536\u655b\uff0c\u76f8\u6bd4\u4f20\u7edf\u6b8b\u5dee\u8fde\u63a5\u80fd\u52a0\u901f\u6536\u655b\u3001\u63d0\u5347\u6027\u80fd\u5e76\u589e\u5f3a\u6df1\u5ea6\u6548\u7387\u3002", "motivation": "\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u6210\u529f\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u7f51\u7edc\u6df1\u5ea6\u7684\u6269\u5c55\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u6df1\u5c42\u5f80\u5f80\u672a\u88ab\u5145\u5206\u5229\u7528\u3002\u672c\u6587\u4ece\u4f18\u5316\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u9ed8\u8ba4\u7684\u6df1\u5ea6\u7f51\u7edc\u673a\u5236\u2014\u2014\u6b8b\u5dee\u8fde\u63a5\uff0c\u53d1\u73b0\u6b8b\u5dee\u8fde\u63a5\u7684\u5e03\u5c40\u80fd\u4ece\u6839\u672c\u4e0a\u5f71\u54cd\u6536\u655b\u884c\u4e3a\uff0c\u751a\u81f3\u5bfc\u81f4\u6536\u655b\u901f\u5ea6\u7684\u6307\u6570\u7ea7\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u795e\u7ecf\u8fde\u63a5\u91cd\u5206\u914d\uff08ANCRe\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u8f7b\u91cf\u7ea7\u7684\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u53c2\u6570\u5316\u5e76\u5b66\u4e60\u6b8b\u5dee\u8fde\u63a5\u3002ANCRe\u4ee5\u53ef\u5ffd\u7565\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff08<1%\uff09\u81ea\u9002\u5e94\u5730\u91cd\u65b0\u5206\u914d\u6b8b\u5dee\u8fde\u63a5\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u7f51\u7edc\u6df1\u5ea6\u5229\u7528\u3002", "result": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u3001\u6269\u6563\u6a21\u578b\u548c\u6df1\u5ea6ResNets\u7684\u5e7f\u6cdb\u6570\u503c\u6d4b\u8bd5\u4e2d\uff0cANCRe\u76f8\u6bd4\u4f20\u7edf\u6b8b\u5dee\u8fde\u63a5\u5c55\u73b0\u51fa\uff1a1\uff09\u6301\u7eed\u52a0\u901f\u7684\u6536\u655b\u901f\u5ea6\uff1b2\uff09\u63d0\u5347\u7684\u6027\u80fd\u8868\u73b0\uff1b3\uff09\u589e\u5f3a\u7684\u6df1\u5ea6\u6548\u7387\u3002", "conclusion": "\u6b8b\u5dee\u8fde\u63a5\u7684\u5e03\u5c40\u5bf9\u6df1\u5ea6\u7f51\u7edc\u6536\u655b\u6709\u6839\u672c\u6027\u5f71\u54cd\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5b66\u4e60\u6b8b\u5dee\u8fde\u63a5\uff08ANCRe\uff09\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6df1\u5ea6\u7f51\u7edc\u7684\u4f18\u5316\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u6df1\u5ea6\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u89c6\u89d2\u3002"}}
{"id": "2602.08920", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08920", "abs": "https://arxiv.org/abs/2602.08920", "authors": ["Manh Cuong Dao", "Quang Hung Pham", "Phi Le Nguyen", "Thao Nguyen Truong", "Bryan Kian Hsiang Low", "Trong Nghia Hoang"], "title": "Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration", "comment": null, "summary": "Uncertainty calibration in pre-trained transformers is critical for their reliable deployment in risk-sensitive applications. Yet, most existing pre-trained transformers do not have a principled mechanism for uncertainty propagation through their feature transformation stack. In this work, we propose a diffusion-inspired reconfiguration of transformers in which each feature transformation block is modeled as a probabilistic mapping. Composing these probabilistic mappings reveals a probability path that mimics the structure of a diffusion process, transporting data mass from the input distribution to the pre-trained feature distribution. This probability path can then be recompiled on a diffusion process with a unified transition model to enable principled propagation of representation uncertainty throughout the pre-trained model's architecture while maintaining its original predictive performance. Empirical results across a variety of vision and language benchmarks demonstrate that our method achieves superior calibration and predictive accuracy compared to existing uncertainty-aware transformers.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u8fc7\u7a0b\u7684Transformer\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u6620\u5c04\u5757\u91cd\u6784\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u7684\u4f20\u64ad\u3002", "motivation": "\u9884\u8bad\u7ec3Transformer\u5728\u98ce\u9669\u654f\u611f\u5e94\u7528\u4e2d\u9700\u8981\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u901a\u8fc7\u7279\u5f81\u53d8\u6362\u5806\u6808\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u7684\u539f\u5219\u6027\u673a\u5236\u3002", "method": "\u5c06Transformer\u7684\u6bcf\u4e2a\u7279\u5f81\u53d8\u6362\u5757\u5efa\u6a21\u4e3a\u6982\u7387\u6620\u5c04\uff0c\u7ec4\u5408\u8fd9\u4e9b\u6620\u5c04\u5f62\u6210\u7c7b\u4f3c\u6269\u6563\u8fc7\u7a0b\u7684\u6982\u7387\u8def\u5f84\uff0c\u7136\u540e\u5c06\u5176\u91cd\u65b0\u7f16\u8bd1\u5230\u5177\u6709\u7edf\u4e00\u8f6c\u79fb\u6a21\u578b\u7684\u6269\u6563\u8fc7\u7a0b\u4e2d\u3002", "result": "\u5728\u591a\u79cd\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u611f\u77e5Transformer\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6821\u51c6\u6027\u80fd\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6269\u6563\u542f\u53d1\u5f0fTransformer\u91cd\u6784\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u539f\u5219\u6027\u7684\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u98ce\u9669\u654f\u611f\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u6848\u3002"}}
{"id": "2602.08923", "categories": ["cs.LG", "cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08923", "abs": "https://arxiv.org/abs/2602.08923", "authors": ["Wenchen Han", "Shay Vargaftik", "Michael Mitzenmacher", "Ran Ben Basat"], "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce", "comment": "18 pages, 18 figures", "summary": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology.\n  This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution.\n  We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training.", "AI": {"tldr": "DynamiQ\u662f\u4e00\u4e2a\u4e13\u4e3a\u591a\u8df3\u5168\u5f52\u7ea6\u8bbe\u8ba1\u7684\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u90e8\u5206\u548c\u8868\u793a\u548c\u878d\u5408\u5185\u6838\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3", "motivation": "\u968f\u7740\u8bad\u7ec3\u89c4\u6a21\u6269\u5927\uff0c\u7f51\u7edc\u6210\u4e3a\u74f6\u9888\uff0c\u9700\u8981\u51cf\u5c11\u4f20\u8f93\u6570\u636e\u91cf\u3002\u73b0\u6709\u68af\u5ea6\u91cf\u5316\u7cfb\u7edf\u672a\u9488\u5bf9\u591a\u8df3\u805a\u5408\u4f18\u5316\uff0c\u5176\u4e2d\u6761\u76ee\u5728\u805a\u5408\u62d3\u6251\u4e2d\u591a\u6b21\u90e8\u5206\u6c42\u548c", "method": "\u63d0\u51faDynamiQ\u91cf\u5316\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u6280\u672f\u6765\u66f4\u597d\u8868\u793a\u90e8\u5206\u548c\uff0c\u5e76\u4e0e\u89e3\u538b-\u7d2f\u52a0-\u518d\u538b\u7f29\u878d\u5408\u5185\u6838\u534f\u540c\u8bbe\u8ba1\u4ee5\u5b9e\u73b0\u5feb\u901f\u6267\u884c\u3002\u6269\u5c55PyTorch DDP\u4ee5\u652f\u6301NCCL P2P\u4e0a\u7684DynamiQ", "result": "\u5728\u4e0d\u540cLLM\u3001\u4efb\u52a1\u548c\u89c4\u6a21\u4e0b\uff0c\u76f8\u6bd4Omni-Reduce\u3001THC\u3001MXFP4/6/8\u7b49\u6700\u5148\u8fdb\u65b9\u6cd5\uff0cDynamiQ\u5b9e\u73b0\u9ad8\u8fbe34.2%\u7684\u6539\u8fdb\u3002\u552f\u4e00\u80fd\u59cb\u7ec8\u8fbe\u5230\u63a5\u8fd1\u57fa\u7ebf\u7cbe\u5ea6\uff08\u5982BF16\u57fa\u7ebf\u768499.9%\uff09\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u52a0\u901f\u8bad\u7ec3", "conclusion": "DynamiQ\u586b\u8865\u4e86\u91cf\u5316\u6700\u4f73\u5b9e\u8df5\u4e0e\u591a\u8df3\u805a\u5408\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u7684\u6280\u672f\u5b9e\u73b0\u4e86\u7cbe\u5ea6\u4fdd\u6301\u548c\u8bad\u7ec3\u52a0\u901f\u7684\u53cc\u91cd\u4f18\u52bf"}}
{"id": "2602.08976", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08976", "abs": "https://arxiv.org/abs/2602.08976", "authors": ["Jiaqi Wen", "Jianyi Yang"], "title": "Distributionally Robust Optimization via Generative Ambiguity Modeling", "comment": null, "summary": "This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for enhancing the robustness and generalization of statistical learning and optimization. An effective ambiguity set for DRO must involve distributions that remain consistent to the nominal distribution while being diverse enough to account for a variety of potential scenarios. Moreover, it should lead to tractable DRO solutions. To this end, we propose generative model-based ambiguity sets that capture various adversarial distributions beyond the nominal support space while maintaining consistency with the nominal distribution. Building on this generative ambiguity modeling, we propose DRO with Generative Ambiguity Set (GAS-DRO), a tractable DRO algorithm that solves the inner maximization over the parameterized generative model space. We formally establish the stationary convergence performance of GAS-DRO. We implement GAS-DRO with a diffusion model and empirically demonstrate its superior Out-of-Distribution (OOD) generalization performance in ML tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6GAS-DRO\uff0c\u4f7f\u7528\u751f\u6210\u6a21\u578b\u6784\u5efa\u6b67\u4e49\u96c6\uff0c\u5728\u4fdd\u6301\u4e0e\u540d\u4e49\u5206\u5e03\u4e00\u81f4\u6027\u7684\u540c\u65f6\u6355\u6349\u8d85\u51fa\u540d\u4e49\u652f\u6491\u7a7a\u95f4\u7684\u5bf9\u6297\u5206\u5e03\uff0c\u5b9e\u73b0\u66f4\u597d\u7684OOD\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfDRO\u7684\u6b67\u4e49\u96c6\u8bbe\u8ba1\u9700\u8981\u5728\u4fdd\u6301\u4e0e\u540d\u4e49\u5206\u5e03\u4e00\u81f4\u6027\u548c\u8986\u76d6\u591a\u79cd\u6f5c\u5728\u573a\u666f\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u540c\u65f6\u8fd8\u8981\u4fdd\u8bc1\u4f18\u5316\u95ee\u9898\u7684\u53ef\u89e3\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u8fd9\u4e9b\u8981\u6c42\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8d85\u51fa\u540d\u4e49\u652f\u6491\u7a7a\u95f4\u7684\u5206\u5e03\u65f6\u3002", "method": "\u63d0\u51fa\u751f\u6210\u6a21\u578b\u57fa\u6b67\u4e49\u96c6\uff0c\u5229\u7528\u751f\u6210\u6a21\u578b\u6355\u6349\u5404\u79cd\u5bf9\u6297\u5206\u5e03\uff0c\u5305\u62ec\u8d85\u51fa\u540d\u4e49\u652f\u6491\u7a7a\u95f4\u7684\u5206\u5e03\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faGAS-DRO\u7b97\u6cd5\uff0c\u901a\u8fc7\u6c42\u89e3\u53c2\u6570\u5316\u751f\u6210\u6a21\u578b\u7a7a\u95f4\u7684\u5185\u5c42\u6700\u5927\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u53ef\u5904\u7406\u7684DRO\u6c42\u89e3\u3002", "result": "\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86GAS-DRO\u7684\u5e73\u7a33\u6536\u655b\u6027\u80fd\u3002\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u6269\u6563\u6a21\u578b\u5b9e\u73b0GAS-DRO\uff0c\u5728\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u4f18\u8d8a\u7684OOD\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "GAS-DRO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u53ef\u5904\u7406\u7684DRO\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u6a21\u578b\u6784\u5efa\u6b67\u4e49\u96c6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u8d85\u51fa\u540d\u4e49\u652f\u6491\u7a7a\u95f4\u7684\u5206\u5e03\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684OOD\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.09001", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09001", "abs": "https://arxiv.org/abs/2602.09001", "authors": ["Amirhossein Vahidi", "Hesam Asadollahzadeh", "Navid Akhavan Attar", "Marie Moullet", "Kevin Ly", "Xingyi Yang", "Mohammad Lotfollahi"], "title": "DirMoE: Dirichlet-routed Mixture of Experts", "comment": null, "summary": "Mixture-of-Experts (MoE) models have demonstrated exceptional performance in large-scale language models. Existing routers typically rely on non-differentiable Top-$k$+Softmax, limiting their performance and scalability. We argue that two distinct decisions, which experts to activate and how to distribute expert contributions among them, are conflated in standard Top-$k$+Softmax. We introduce Dirichlet-Routed MoE (DirMoE), a novel end-to-end differentiable routing mechanism built on a Dirichlet variational autoencoder framework. This design fundamentally disentangles the core routing problems: expert selection, modeled by a Bernoulli component, and expert contribution among chosen experts, handled by a Dirichlet component. The entire forward pass remains fully differentiable through the use of Gumbel-Sigmoid relaxation for the expert selection and implicit reparameterization for the Dirichlet distribution. Our training objective, a variational ELBO, includes a direct sparsity penalty that precisely controls the number of active experts in expectation, alongside a schedule for key hyperparameters that guides the model from an exploratory to a definitive routing state. Moreover, our DirMoE router matches or exceeds other methods while improving expert specialization.", "AI": {"tldr": "\u63d0\u51faDirMoE\uff0c\u4e00\u79cd\u57fa\u4e8eDirichlet\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u8def\u7531\u673a\u5236\uff0c\u89e3\u8026\u4e13\u5bb6\u9009\u62e9\u548c\u4e13\u5bb6\u8d21\u732e\u5206\u914d\uff0c\u901a\u8fc7\u7a00\u758f\u6027\u60e9\u7f5a\u7cbe\u786e\u63a7\u5236\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u3002", "motivation": "\u73b0\u6709MoE\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e0d\u53ef\u5fae\u7684Top-k+Softmax\u8def\u7531\uff0c\u9650\u5236\u4e86\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002\u6807\u51c6\u65b9\u6cd5\u5c06\u4e13\u5bb6\u9009\u62e9\u548c\u8d21\u732e\u5206\u914d\u4e24\u4e2a\u51b3\u7b56\u6df7\u4e3a\u4e00\u8c08\u3002", "method": "\u57fa\u4e8eDirichlet\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u4f7f\u7528Bernoulli\u7ec4\u4ef6\u5efa\u6a21\u4e13\u5bb6\u9009\u62e9\uff0cDirichlet\u7ec4\u4ef6\u5904\u7406\u9009\u5b9a\u4e13\u5bb6\u95f4\u7684\u8d21\u732e\u5206\u914d\u3002\u901a\u8fc7Gumbel-Sigmoid\u677e\u5f1b\u548c\u9690\u5f0f\u91cd\u53c2\u6570\u5316\u5b9e\u73b0\u5168\u53ef\u5fae\u524d\u5411\u4f20\u64ad\u3002\u8bad\u7ec3\u76ee\u6807\u4e3a\u53d8\u5206ELBO\uff0c\u5305\u542b\u76f4\u63a5\u7a00\u758f\u6027\u60e9\u7f5a\u548c\u8d85\u53c2\u6570\u8c03\u5ea6\u3002", "result": "DirMoE\u8def\u7531\u673a\u5236\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u5176\u4ed6\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4e13\u5bb6\u4e13\u4e1a\u5316\u7a0b\u5ea6\u3002", "conclusion": "DirMoE\u901a\u8fc7\u89e3\u8026\u8def\u7531\u51b3\u7b56\u3001\u5b9e\u73b0\u7aef\u5230\u7aef\u53ef\u5fae\u6027\u3001\u7cbe\u786e\u63a7\u5236\u7a00\u758f\u6027\uff0c\u4e3aMoE\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u8def\u7531\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09008", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09008", "abs": "https://arxiv.org/abs/2602.09008", "authors": ["Sijia Peng", "Yun Xiong", "Xi Chen", "Yi Xie", "Guanzhi Li", "Yanwei Yu", "Yangyong Zhu", "Zhiqiang Shen"], "title": "ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification", "comment": "Code at: https://github.com/lunaaa95/ShapeCond", "summary": "Time series data supports many domains (e.g., finance and climate science), but its rapid growth strains storage and computation. Dataset condensation can alleviate this by synthesizing a compact training set that preserves key information. Yet most condensation methods are image-centric and often fail on time series because they miss time-series-specific temporal structure, especially local discriminative motifs such as shapelets. In this work, we propose ShapeCond, a novel and efficient condensation framework for time series classification that leverages shapelet-based dataset knowledge via a shapelet-guided optimization strategy. Our shapelet-assisted synthesis cost is independent of sequence length: longer series yield larger speedups in synthesis (e.g., 29$\\times$ faster over prior state-of-the-art method CondTSC for time-series condensation, and up to 10,000$\\times$ over naively using shapelets on the Sleep dataset with 3,000 timesteps). By explicitly preserving critical local patterns, ShapeCond improves downstream accuracy and consistently outperforms all prior state-of-the-art time series dataset condensation methods across extensive experiments. Code is available at https://github.com/lunaaa95/ShapeCond.", "AI": {"tldr": "ShapeCond\uff1a\u57fa\u4e8eshapelet\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7shapelet\u5f15\u5bfc\u7684\u4f18\u5316\u7b56\u7565\u4fdd\u7559\u5173\u952e\u5c40\u90e8\u6a21\u5f0f\uff0c\u5b9e\u73b0\u9ad8\u6548\u5408\u6210\u5e76\u63d0\u5347\u4e0b\u6e38\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5feb\u901f\u589e\u957f\u7ed9\u5b58\u50a8\u548c\u8ba1\u7b97\u5e26\u6765\u538b\u529b\uff0c\u73b0\u6709\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\u591a\u4e3a\u56fe\u50cf\u4e2d\u5fc3\u5316\u8bbe\u8ba1\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u5e8f\u5217\u7279\u6709\u7684\u65f6\u95f4\u7ed3\u6784\u548c\u5c40\u90e8\u5224\u522b\u6027\u6a21\u5f0f\uff08\u5982shapelet\uff09\uff0c\u5bfc\u81f4\u5728\u65f6\u95f4\u5e8f\u5217\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faShapeCond\u6846\u67b6\uff0c\u5229\u7528shapelet\u5f15\u5bfc\u7684\u4f18\u5316\u7b56\u7565\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u538b\u7f29\u3002\u901a\u8fc7shapelet\u8f85\u52a9\u7684\u5408\u6210\u65b9\u6cd5\uff0c\u5176\u8ba1\u7b97\u6210\u672c\u4e0e\u5e8f\u5217\u957f\u5ea6\u65e0\u5173\uff0c\u80fd\u9ad8\u6548\u4fdd\u7559\u5173\u952e\u7684\u5c40\u90e8\u5224\u522b\u6a21\u5f0f\u3002", "result": "\u5728Sleep\u6570\u636e\u96c6\uff083000\u4e2a\u65f6\u95f4\u6b65\uff09\u4e0a\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5CondTSC\u5feb29\u500d\uff0c\u6bd4\u76f4\u63a5\u4f7f\u7528shapelet\u7684\u65b9\u6cd5\u5feb10000\u500d\u3002\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u4e0b\u6e38\u5206\u7c7b\u7cbe\u5ea6\u3002", "conclusion": "ShapeCond\u901a\u8fc7\u663e\u5f0f\u4fdd\u7559\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5173\u952e\u5c40\u90e8\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u538b\u7f29\uff0c\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
