<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 66]
- [econ.EM](#econ.EM) [Total: 4]
- [q-fin.RM](#q-fin.RM) [Total: 2]
- [cs.AI](#cs.AI) [Total: 31]
- [eess.SY](#eess.SY) [Total: 20]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [math.OC](#math.OC) [Total: 22]
- [cs.LG](#cs.LG) [Total: 92]
- [cs.CY](#cs.CY) [Total: 9]
- [q-fin.MF](#q-fin.MF) [Total: 2]
- [stat.ML](#stat.ML) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration](https://arxiv.org/abs/2512.23710)
*Zahra Abedi,Richard M. K. van Dijk,Gijs Wijnholds,Tessa Verhoef*

Main category: cs.CL

TL;DR: 该研究开发了一个自动化流程，将OCR、基于LLM的数据解释和数据库链接相结合，用于数字化和分析莱顿大学教授传记历史文档，并与现有高质量数据库记录进行整合。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决如何设计自动化流程来整合OCR、LLM解释和数据库链接，以协调历史文档图像数据与现有高质量数据库记录的问题，特别是针对莱顿大学1575-1815年间教授和学监的传记数据。

Method: 应用OCR技术处理打字历史记录，使用生成式AI解码约束来结构化数据提取，并采用数据库链接方法。具体包括OCR处理、基于LLM的JSON数据提取、以及记录链接算法。

Result: OCR达到1.08%的字符错误率和5.06%的单词错误率；从OCR文本提取JSON的平均准确率为63%，基于标注OCR的准确率为65%；记录链接算法对标注JSON文件的链接准确率为94%，对OCR衍生JSON文件的链接准确率为81%。

Conclusion: 该研究为数字人文学科提供了自动化历史文档解释流程，解决了布局变化和术语差异等挑战，展示了生成式AI模型在纠正低质量OCR性能方面的应用潜力。

Abstract: This research digitizes and analyzes the Leidse hoogleraren en lectoren 1575-1815 books written between 1983 and 1985, which contain biographic data about professors and curators of Leiden University. It addresses the central question: how can we design an automated pipeline that integrates OCR, LLM-based interpretation, and database linking to harmonize data from historical document images with existing high-quality database records? We applied OCR techniques, generative AI decoding constraints that structure data extraction, and database linkage methods to process typewritten historical records into a digital format. OCR achieved a Character Error Rate (CER) of 1.08 percent and a Word Error Rate (WER) of 5.06 percent, while JSON extraction from OCR text achieved an average accuracy of 63 percent and, based on annotated OCR, 65 percent. This indicates that generative AI somewhat corrects low OCR performance. Our record linkage algorithm linked annotated JSON files with 94% accuracy and OCR-derived JSON files with 81%. This study contributes to digital humanities research by offering an automated pipeline for interpreting digitized historical documents, addressing challenges like layout variability and terminology differences, and exploring the applicability and strength of an advanced generative AI model.

</details>


### [2] [CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations](https://arxiv.org/abs/2512.23711)
*Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Claudio Pinhanez,Yago Primerano*

Main category: cs.CL

TL;DR: CAT框架评估LLM在可控输入变化下的准确性与响应一致性交互关系，通过CAR曲线可视化，CORE指数量化权衡


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要关注准确性或基准分数，一致性作为部署到高风险现实应用的重要属性。需要同时评估这两个维度及其相互依赖关系，进行更细致的LLM评估。

Method: 提出CAT框架，核心是Consistency-Accuracy Relation (CAR)曲线，可视化随着一致性要求增加（通过Minimum-Consistency Accuracy度量）模型准确性的变化。进一步提出Consistency-Oriented Robustness Estimate (CORE)指数，结合CAR曲线的面积和形状来量化准确性与一致性的权衡。

Result: 在多个通用和专业领域LLM上，使用多项选择题基准进行了实际演示。展示了框架如何扩展到多项选择题之外，通过适应性评分函数支持长文本、开放式评估。

Conclusion: CAT框架提供了评估LLM准确性和一致性交互关系的系统方法，CAR曲线和CORE指数为模型评估提供了更全面的视角，有助于在现实应用中部署更可靠的LLM。

Abstract: We introduce \textsc{CAT}, a framework designed to evaluate and visualize the \emph{interplay} of \emph{accuracy} and \emph{response consistency} of Large Language Models (LLMs) under controllable input variations, using multiple-choice (MC) benchmarks as a case study. Current evaluation practices primarily focus on model capabilities such as accuracy or benchmark scores and, more recently, measuring consistency is being considered an essential property for deploying LLMs in high-stake, real-world applications. We argue in this paper that although both dimensions should still be evaluated independently, their inter-dependency also need to be considered for a more nuanced evaluation of LLMs. At the core of \textsc{CAT} are the \emph{Consistency-Accuracy Relation (CAR)} curves, which visualize how model accuracy varies with increasing consistency requirements, as defined by the \emph{Minimum-Consistency Accuracy (MCA)} metric. We further propose the \emph{Consistency-Oriented Robustness Estimate (CORE)} index, a global metric that combines the area and shape of the CAR curve to quantify the trade-off between accuracy and consistency. We present a practical demonstration of our framework across a diverse set of generalist and domain-specific LLMs, evaluated on multiple MC benchmarks. We also outline how \textsc{CAT} can be extended beyond MC tasks to support long-form, open-ended evaluations through adaptable scoring functions.

</details>


### [3] [STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability](https://arxiv.org/abs/2512.23712)
*Guanghui Wang,Jinze Yu,Xing Zhang,Dayuan Jiang,Yin Song,Tomal Deb,Xuefeng Liu,Peiyang He*

Main category: cs.CL

TL;DR: 提出STED框架评估LLM结构化输出一致性，结合语义树编辑距离和一致性评分，实验显示优于现有指标，并用于基准测试多个LLM模型。


<details>
  <summary>Details</summary>
Motivation: LLM在结构化数据生成中应用日益广泛，但输出一致性对生产应用至关重要。现有评估方法在平衡语义灵活性和结构严格性方面存在不足。

Method: 提出综合框架：1) STED（语义树编辑距离）——平衡语义灵活性和结构严格性的JSON输出相似度度量；2) 一致性评分框架——聚合多次生成的STED测量值来量化可靠性。

Result: STED在合成数据集上表现优异（语义等价输出相似度0.86-0.90，结构破坏为0.0），优于TED、BERTScore和DeepDiff。基准测试显示Claude-3.7-Sonnet一致性最佳，Claude-3-Haiku和Nova-Pro在高温度下退化严重。

Conclusion: 该框架为LLM生产系统中的可靠结构化输出生成提供理论基础和实用工具，支持模型选择、提示优化和根因分析等应用。

Abstract: Large Language Models (LLMs) are increasingly deployed for structured data generation, yet output consistency remains critical for production applications. We introduce a comprehensive framework for evaluating and improving consistency in LLM-generated structured outputs. Our approach combines: (1) STED (Semantic Tree Edit Distance), a novel similarity metric balancing semantic flexibility with structural strictness when comparing JSON outputs, and (2) a consistency scoring framework aggregating multiple STED measurements across repeated generations to quantify reliability. Through systematic experiments on synthetic datasets with controlled schema, expression, and semantic variations, we demonstrate STED achieves superior performance ($0.86-0.90$ similarity for semantic equivalents, $0.0$ for structural breaks) compared to existing metrics including TED, BERTScore, and DeepDiff. Applying our framework to benchmark six LLMs reveals significant variations: Claude-3.7-Sonnet demonstrates exceptional consistency, maintaining near-perfect structural reliability even at high temperatures ($T=0.9$), while models like Claude-3-Haiku and Nova-Pro exhibit substantial degradation requiring careful tuning. Our framework enables practical applications including targeted model selection for structured tasks, iterative prompt refinement for reproducible results, and diagnostic analysis to identify inconsistency root causes. This work provides theoretical foundations and practical tools for ensuring reliable structured output generation in LLM-based production systems.

</details>


### [4] [PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual Agents](https://arxiv.org/abs/2512.23713)
*Jahidul Islam,Md Ataullha,Saiful Azad*

Main category: cs.CL

TL;DR: BanglaCodeAct：基于多智能体提示和迭代自校正的孟加拉语到Python代码生成框架，使用开源多语言LLM在Thought-Code-Observation循环中动态生成、测试和优化代码，在mHumanEval数据集上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: LLM在英语提示的代码生成方面表现出色，但这种进展尚未扩展到低资源语言。针对孟加拉语到Python代码生成问题，需要开发专门的方法来克服语言资源限制。

Method: 提出BanglaCodeAct框架，采用基于智能体的方法，利用多智能体提示和迭代自校正。使用开源多语言LLM在Thought-Code-Observation循环中实现动态代码生成、测试和优化，无需任务特定的微调。

Result: 在mHumanEval数据集上评估多个小型开源LLM，Qwen3-8B结合BanglaCodeAct表现最佳：开发集pass@1准确率94.0%，盲测集71.6%，为孟加拉语到Python翻译建立了新基准。

Conclusion: 该研究为孟加拉语到Python代码生成设立了新基准，证明了基于智能体的推理在低资源语言可靠代码生成方面的潜力，为其他低资源语言提供了可借鉴的方法。

Abstract: LLMs excel at code generation from English prompts, but this progress has not extended to low-resource languages. We address Bangla-to-Python code generation by introducing BanglaCodeAct, an agent-based framework that leverages multi-agent prompting and iterative self-correction. Unlike prior approaches relying on task-specific fine-tuning, BanglaCodeAct employs an open-source multilingual LLM within a Thought-Code-Observation loop, enabling dynamic generation, testing, and refinement of code from Bangla instructions. We benchmark several small-parameter open-source LLMs and evaluate their effectiveness on the mHumanEval dataset for Bangla NL2Code. Our results show that Qwen3-8B, when deployed with BanglaCodeAct, achieves the best performance, with pass@1 accuracy of 94.0\% on the development set and 71.6\% on the blind test set. These results establish a new benchmark for Bangla-to-Python translation and highlight the potential of agent-based reasoning for reliable code generation in low-resource languages. Experimental scripts are publicly available at github.com/jahidulzaid/PyBanglaCodeActAgent.

</details>


### [5] [PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents](https://arxiv.org/abs/2512.23714)
*Tingwei Xie,Tianyi Zhou,Yonghong Song*

Main category: cs.CL

TL;DR: PharmaShip是一个中文药品运输单据数据集，用于测试文本布局模型在噪声OCR和异构模板下的性能，包含三个任务：序列实体识别、关系抽取和阅读顺序预测。


<details>
  <summary>Details</summary>
Motivation: 创建真实世界的中文药品运输单据数据集，用于在噪声OCR和异构模板条件下评估预训练文本布局模型，为药品领域的安全关键文档理解建立可控、可复现的基准。

Method: 构建PharmaShip数据集，包含扫描的药品运输单据，采用实体中心评估协议，对五个代表性基线模型（LiLT、LayoutLMv3-base、GeoLayoutLM及其RORE增强变体）进行基准测试，标准化预处理、数据分割和优化过程。

Result: 像素信息和显式几何信息提供互补的归纳偏置，但单独使用都不够；注入阅读顺序导向的正则化能持续改进SER和EL；较长的位置覆盖稳定了页面后期预测并减少了截断伪影；ROP在词级别准确但在片段级别具有挑战性。

Conclusion: PharmaShip为药品领域的安全关键文档理解建立了可控、可复现的基准，并强调序列感知约束作为结构建模的可迁移偏置的重要性。

Abstract: We present PharmaShip, a real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test pre-trained text-layout models under noisy OCR and heterogeneous templates. PharmaShip covers three complementary tasks-sequence entity recognition (SER), relation extraction (RE), and reading order prediction (ROP)-and adopts an entity-centric evaluation protocol to minimize confounds across architectures. We benchmark five representative baselines spanning pixel-aware and geometry-aware families (LiLT, LayoutLMv3-base, GeoLayoutLM and their available RORE-enhanced variants), and standardize preprocessing, splits, and optimization. Experiments show that pixels and explicit geometry provide complementary inductive biases, yet neither alone is sufficient: injecting reading-order-oriented regularization consistently improves SER and EL and yields the most robust configuration, while longer positional coverage stabilizes late-page predictions and reduces truncation artifacts. ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings. PharmaShip thus establishes a controlled, reproducible benchmark for safety-critical document understanding in the pharmaceutical domain and highlights sequence-aware constraints as a transferable bias for structure modeling. We release the dataset at https://github.com/KevinYuLei/PharmaShip.

</details>


### [6] [Noise-Driven Persona Formation in Reflexive Neural Language Generation](https://arxiv.org/abs/2512.23716)
*Toshiyuki Shigemura*

Main category: cs.CL

TL;DR: LN-RP是一个分析大语言模型中噪声驱动角色涌现的计算框架，通过注入随机噪声种子观察语言行为的非线性转变，发现了三种具有不同熵特征的稳定角色模式。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中噪声如何驱动角色涌现，探索反射生成、涌现行为和长程语言连贯性的机制。

Method: 提出Luca-Noise Reflex Protocol (LN-RP)框架，向初始生成状态注入随机噪声种子，在152个生成周期中观察语言行为的非线性转变。

Result: 发现了三种具有不同熵特征的稳定角色模式，外部噪声源能可靠地诱导反射生成动态的相变，定量评估确认了角色保持的一致性(p < 0.01)。

Conclusion: LN-RP协议为研究大语言模型中的反射生成、涌现行为和长程语言连贯性提供了可重复的方法。

Abstract: This paper introduces the Luca-Noise Reflex Protocol (LN-RP), a computational framework for analyzing noise-driven persona emergence in large language models. By injecting stochastic noise seeds into the initial generation state, we observe nonlinear transitions in linguistic behavior across 152 generation cycles. Our results reveal three stable persona modes with distinct entropy signatures, and demonstrate that external noise sources can reliably induce phase transitions in reflexive generation dynamics. Quantitative evaluation confirms consistent persona retention and significant differences across modes (p < 0.01). The protocol provides a reproducible method for studying reflexive generation, emergent behavior, and longrange linguistic coherence in LLMs.

</details>


### [7] [HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate](https://arxiv.org/abs/2512.23717)
*Shenzhe Zhu*

Main category: cs.CL

TL;DR: HarmTransform：一个多智能体辩论框架，通过系统性地将有害查询转化为更隐蔽的形式来增强LLM安全对齐，同时保留其恶意意图


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全机制主要关注明显的有害内容，但用户可以通过隐蔽的改写来伪装恶意意图，而现有安全训练数据存在这一空白

Method: 提出HarmTransform多智能体辩论框架，通过多个智能体之间的迭代批评和精炼，系统性地生成高质量、隐蔽的有害查询转换

Result: 实验表明HarmTransform在生成有效查询转换方面显著优于标准基线方法，但辩论机制具有双重性：既能提高隐蔽性，也可能引入主题偏移和不必要的复杂性

Conclusion: 多智能体辩论在生成全面安全训练数据方面既有潜力也有局限性，需要平衡隐蔽性提升与复杂性问题

Abstract: Large language models (LLMs) are equipped with safety mechanisms to detect and block harmful queries, yet current alignment approaches primarily focus on overtly dangerous content and overlook more subtle threats. However, users can often disguise harmful intent through covert rephrasing that preserves malicious objectives while appearing benign, which creates a significant gap in existing safety training data. To address this limitation, we introduce HarmTransform, a multi-agent debate framework for systematically transforming harmful queries into stealthier forms while preserving their underlying harmful intent. Our framework leverages iterative critique and refinement among multiple agents to generate high-quality, covert harmful query transformations that can be used to improve future LLM safety alignment. Experiments demonstrate that HarmTransform significantly outperforms standard baselines in producing effective query transformations. At the same time, our analysis reveals that debate acts as a double-edged sword: while it can sharpen transformations and improve stealth, it may also introduce topic shifts and unnecessary complexity. These insights highlight both the promise and the limitations of multi-agent debate for generating comprehensive safety training data.

</details>


### [8] [Emergent World Beliefs: Exploring Transformers in Stochastic Games](https://arxiv.org/abs/2512.23722)
*Adam Kamel,Tanish Rastogi,Michael Ma,Kailash Ranganathan,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs在德州扑克中学习到了确定性的手牌等级和随机的胜率特征，形成了自己的不完全信息环境表示


<details>
  <summary>Details</summary>
Motivation: 扩展LLM在完美信息游戏中的世界模型研究到不完全信息领域，以德州扑克作为典型的部分可观察马尔可夫决策过程

Method: 在扑克手牌历史数据上预训练GPT风格模型，使用非线性探针探测内部激活，分析模型学习到的表示

Result: 模型在没有明确指导的情况下学习到了手牌等级（确定性结构）和胜率（随机特征），这些表示与理论信念状态相关

Conclusion: LLMs能够在不完全信息环境中学习自己的随机环境表示，表明其在复杂决策任务中的潜力

Abstract: Transformer-based large language models (LLMs) have demonstrated strong reasoning abilities across diverse fields, from solving programming challenges to competing in strategy-intensive games such as chess. Prior work has shown that LLMs can develop emergent world models in games of perfect information, where internal representations correspond to latent states of the environment. In this paper, we extend this line of investigation to domains of incomplete information, focusing on poker as a canonical partially observable Markov decision process (POMDP). We pretrain a GPT-style model on Poker Hand History (PHH) data and probe its internal activations. Our results demonstrate that the model learns both deterministic structure, such as hand ranks, and stochastic features, such as equity, without explicit instruction. Furthermore, by using primarily nonlinear probes, we demonstrated that these representations are decodeable and correlate with theoretical belief states, suggesting that LLMs are learning their own representation of the stochastic environment of Texas Hold'em Poker.

</details>


### [9] [When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection](https://arxiv.org/abs/2512.23732)
*Anwar Alajmi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 提出两阶段框架应对性别歧视内容检测中的三大挑战：数据不足、标签噪声和概念模糊性，通过针对性训练和推理时协作专家判断提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视内容日益隐蔽且依赖上下文，传统检测方法难以应对。数据存在标签稀缺、类别不平衡、概念模糊等问题，导致模型决策边界不稳定，难以检测细微的歧视形式。

Method: 提出两阶段框架：1) 训练阶段使用类别平衡焦点损失、类别感知批处理和阈值校准处理不平衡和噪声标签；2) 推理阶段采用动态路由机制，高置信度样本直接分类，不确定样本交由协作专家判断模块处理，该模块通过多个角色推理并由法官模型整合结果。

Result: 在多个基准测试中达到最先进水平，EXIST 2025 Task 1.1的F1分数提升2.72%，EDOS Task A提升4.48%，Task B提升1.30%。

Conclusion: 该框架有效解决了性别歧视检测中的数据不足、噪声和模糊性问题，通过结合针对性训练和推理时协作判断显著提升了检测性能，为复杂社会语言问题的机器学习应用提供了新思路。

Abstract: Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with a +2.72\% improvement in F1 on the EXIST 2025 Task 1.1, and a gains of +4.48\% and +1.30\% on the EDOS Tasks A and B, respectively.

</details>


### [10] [Disentangling Learning from Judgment: Representation Learning for Open Response Analytics](https://arxiv.org/abs/2512.23941)
*Conrad Borchers,Manit Patel,Seiyon M. Lee,Anthony F. Botelho*

Main category: cs.CL

TL;DR: 提出一个分析框架，将学生回答内容信号与评分者倾向分离，通过建模教师历史作为动态先验，结合文本嵌入来预测成绩，结果显示教师先验对评分影响很大。


<details>
  <summary>Details</summary>
Motivation: 开放性问题回答对学习很重要，但自动评分常常混淆学生回答内容与教师评分倾向。需要一种方法将内容信号与评分者倾向分离，使评分判断变得可见和可审计。

Method: 使用ASSISTments数学回答数据，将教师评分历史建模为动态先验，从句子嵌入中提取文本表示，采用中心化和残差化处理来减少提示和教师混杂因素。使用时序验证的线性模型量化各信号贡献，并通过投影可视化模型分歧。

Result: 教师先验对成绩预测影响很大；先验与内容嵌入结合时效果最好（AUC~0.815），而纯内容模型虽高于随机但明显较弱（AUC~0.626）。调整评分者效应能锐化残差内容表示，保留更多信息维度，揭示语义证据支持理解而非表面回答差异的情况。

Conclusion: 该框架将嵌入从简单特征转化为学习分析工具，使教师和研究者能够检查评分实践与学生推理证据是否一致，为反思和改进评分实践提供实用管道。

Abstract: Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.

</details>


### [11] [Break Out the Silverware -- Semantic Understanding of Stored Household Items](https://arxiv.org/abs/2512.23739)
*Michaela Levi-Richter,Reuth Mirsky,Oren Glickman*

Main category: cs.CL

TL;DR: 提出"存储家居物品挑战"基准任务，评估服务机器人推断日常物品隐藏存储位置的能力，并开发NOAM混合代理管道，结合场景理解和LLM推理，接近人类表现水平。


<details>
  <summary>Details</summary>
Motivation: 家庭服务机器人面临的核心挑战：虽然视觉和操作技术有进步，但缺乏常识推理能力来推断日常物品（如盘子）在抽屉、橱柜等隐藏位置的存储位置。

Method: 提出NOAM（非可见物品分配模型）混合代理管道：将视觉输入转换为自然语言描述（空间上下文和可见容器），然后提示语言模型（如GPT-4）推断最可能的隐藏存储位置。

Result: NOAM在预测准确性上显著优于基线方法（随机选择、视觉语言管道、多模态模型），并接近人类表现水平，展示了在家庭环境中部署认知能力强的代理的最佳实践。

Conclusion: 存储家居物品挑战为评估服务机器人认知能力提供了重要基准，NOAM方法通过结合结构化场景理解和LLM推理，实现了接近人类水平的常识推理，为家庭服务机器人的实际部署提供了有效解决方案。

Abstract: ``Bring me a plate.'' For domestic service robots, this simple command reveals a complex challenge: inferring where everyday items are stored, often out of sight in drawers, cabinets, or closets. Despite advances in vision and manipulation, robots still lack the commonsense reasoning needed to complete this task. We introduce the Stored Household Item Challenge, a benchmark task for evaluating service robots' cognitive capabilities: given a household scene and a queried item, predict its most likely storage location.
  Our benchmark includes two datasets: (1) a real-world evaluation set of 100 item-image pairs with human-annotated ground truth from participants' kitchens, and (2) a development set of 6,500 item-image pairs annotated with storage polygons over public kitchen images. These datasets support realistic modeling of household organization and enable comparative evaluation across agent architectures.
  To begin tackling this challenge, we introduce NOAM (Non-visible Object Allocation Model), a hybrid agent pipeline that combines structured scene understanding with large language model inference. NOAM converts visual input into natural language descriptions of spatial context and visible containers, then prompts a language model (e.g., GPT-4) to infer the most likely hidden storage location. This integrated vision-language agent exhibits emergent commonsense reasoning and is designed for modular deployment within broader robotic systems.
  We evaluate NOAM against baselines including random selection, vision-language pipelines (Grounding-DINO + SAM), leading multimodal models (e.g., Gemini, GPT-4o, Kosmos-2, LLaMA, Qwen), and human performance. NOAM significantly improves prediction accuracy and approaches human-level results, highlighting best practices for deploying cognitively capable agents in domestic environments.

</details>


### [12] [Big AI is accelerating the metacrisis: What can we do?](https://arxiv.org/abs/2512.24863)
*Steven Bird*

Main category: cs.CL

TL;DR: 论文批判当前AI发展加剧生态、意义和语言危机，呼吁NLP领域转向以人类繁荣和地球生命为中心的价值导向


<details>
  <summary>Details</summary>
Motivation: 当前世界面临生态、意义和语言三重危机，这些危机正在汇聚成元危机。大型AI正在加速所有这些危机，语言工程师在其中扮演关键角色，却坚持着对人类有害的可扩展性叙事，为富豪和贪腐者提供关键人才，并假装技术开发是价值中立的。迫切需要探索替代方案。

Method: 论文提出需要运用集体智慧来设计替代性的NLP发展路径，但没有具体说明技术方法，而是强调价值导向的转变和重新设计NLP的未来方向。

Result: 论文没有提供具体实验结果，而是提出了一个批判性分析和行动呼吁，强调需要从根本上重新思考NLP的发展方向。

Conclusion: 迫切需要探索替代方案，运用集体智慧设计一个以人类繁荣和生命星球为中心的、肯定生命的NLP未来，摆脱当前加速危机的技术发展模式。

Abstract: The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.

</details>


### [13] [Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning](https://arxiv.org/abs/2512.23765)
*Tiancheng Su,Meicong Zhang,Guoxiu He*

Main category: cs.CL

TL;DR: EASD提出了一种无需训练的推测解码增强方法，通过动态熵惩罚机制，在模型不确定性高时拒绝候选token，让目标模型重新采样，从而可能超越目标模型本身的性能。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码中，草稿模型与目标模型过度对齐，导致性能受限于目标模型。需要一种方法既能保持推测解码的效率，又能超越目标模型的性能限制。

Method: 在标准推测解码基础上，引入动态熵惩罚机制：使用采样分布的熵量化模型不确定性，当两个模型都表现出高熵且top-N预测有显著重叠时，拒绝对应token并由目标LLM重新采样。

Result: 在多个推理基准测试中，EASD一致优于现有推测解码方法，并且在大多数情况下超越了目标LLM本身的性能，同时保持了与标准推测解码相当的效率。

Conclusion: EASD通过熵感知的动态惩罚机制，不仅保持了推测解码的效率优势，还实现了超越目标模型性能的可能性，为LLM推理加速提供了新的方向。

Abstract: Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model's inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.

</details>


### [14] [MiMo-Audio: Audio Language Models are Few-Shot Learners](https://arxiv.org/abs/2512.23808)
*Xiaomi LLM-Core Team,:,Dong Zhang,Gang Wang,Jinlong Xue,Kai Fang,Liang Zhao,Rui Ma,Shuhuai Ren,Shuo Liu,Tao Guo,Weiji Zhuang,Xin Zhang,Xingchen Song,Yihan Yan,Yongzhe He,Cici,Bowen Shen,Chengxuan Zhu,Chong Ma,Chun Chen,Heyu Chen,Jiawei Li,Lei Li,Menghang Zhu,Peidian Li,Qiying Wang,Sirui Deng,Weimin Xiong,Wenshan Huang,Wenyu Yang,Yilin Jiang,Yixin Yang,Yuanyuan Tian,Yue Ma,Yue Yu,Zihan Zhang,Zihao Yue,Bangjun Xiao,Bingquan Xia,Bofei Gao,Bowen Ye,Can Cai,Chang Liu,Chenhong He,Chunan Li,Dawei Zhu,Duo Zhang,Fengyuan Shi,Guoan Wang,Hailin Zhang,Hanglong Lv,Hanyu Li,Hao Tian,Heng Qu,Hongshen Xu,Houbin Zhang,Huaqiu Liu,Jiangshan Duo,Jianguang Zuo,Jianyu Wei,Jiebao Xiao,Jinhao Dong,Jun Shi,Junhao Hu,Kainan Bao,Kang Zhou,Linghao Zhang,Meng Chen,Nuo Chen,Peng Zhang,Qianli Chen,Qiantong Wang,Rang Li,Shaohui Liu,Shengfan Wang,Shicheng Li,Shihua Yu,Shijie Cao,Shimao Chen,Shuhao Gu,Weikun Wang,Wenhan Ma,Xiangwei Deng,Xing Yong,Xing Zhang,Xu Wang,Yifan Song,Yihao Zhao,Yingbo Zhao,Yizhao Gao,Yu Cheng,Yu Tu,Yudong Wang,Zhaojun Huang,Zhengju Tang,Zhenru Lin,Zhichao Song,Zhipeng Xu,Zhixian Zheng,Zihan Jiang*

Main category: cs.CL

TL;DR: MiMo-Audio通过将音频预训练数据扩展到1亿小时以上，实现了音频任务的少样本学习能力，在多个音频理解和生成任务上达到开源SOTA，甚至能泛化到训练数据中未见的任务。


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型通常需要任务特定的微调，而人类只需少量示例或简单指令就能泛化到新任务。GPT-3在文本领域展示了扩展预训练能带来强泛化能力，作者认为这一范式同样适用于音频领域。

Method: 1. 将MiMo-Audio的预训练数据扩展到超过1亿小时音频；2. 开发系统评估方法验证少样本学习能力；3. 在后期训练阶段，构建多样化的指令调优语料库，并在音频理解和生成中引入思维机制。

Result: MiMo-Audio-7B-Base在语音智能和音频理解基准测试中达到开源模型SOTA，能泛化到训练数据中未见的任务（如语音转换、风格迁移、语音编辑），并展示强大的语音延续能力。MiMo-Audio-7B-Instruct在音频理解、口语对话和指令TTS评估中达到开源SOTA，接近或超越闭源模型。

Conclusion: 通过大规模音频预训练，MiMo-Audio实现了类似GPT-3的少样本学习能力，证明了扩展预训练范式在音频领域的有效性，为通用音频智能系统的发展提供了重要进展。

Abstract: Existing audio language models typically rely on task-specific fine-tuning to accomplish particular audio tasks. In contrast, humans are able to generalize to new audio tasks with only a few examples or simple instructions. GPT-3 has shown that scaling next-token prediction pretraining enables strong generalization capabilities in text, and we believe this paradigm is equally applicable to the audio domain. By scaling MiMo-Audio's pretraining data to over one hundred million of hours, we observe the emergence of few-shot learning capabilities across a diverse set of audio tasks. We develop a systematic evaluation of these capabilities and find that MiMo-Audio-7B-Base achieves SOTA performance on both speech intelligence and audio understanding benchmarks among open-source models. Beyond standard metrics, MiMo-Audio-7B-Base generalizes to tasks absent from its training data, such as voice conversion, style transfer, and speech editing. MiMo-Audio-7B-Base also demonstrates powerful speech continuation capabilities, capable of generating highly realistic talk shows, recitations, livestreaming and debates. At the post-training stage, we curate a diverse instruction-tuning corpus and introduce thinking mechanisms into both audio understanding and generation. MiMo-Audio-7B-Instruct achieves open-source SOTA on audio understanding benchmarks (MMSU, MMAU, MMAR, MMAU-Pro), spoken dialogue benchmarks (Big Bench Audio, MultiChallenge Audio) and instruct-TTS evaluations, approaching or surpassing closed-source models. Model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-Audio.

</details>


### [15] [StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection](https://arxiv.org/abs/2512.23813)
*Amal Alqahtani,Efsun Kayi,Mona Diab*

Main category: cs.CL

TL;DR: StressRoBERTa：一种跨条件迁移学习方法，通过持续训练于抑郁、焦虑、PTSD等临床相关条件，提升英文推文中自我报告慢性压力的自动检测性能，相比通用语言模型和广泛心理健康模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 慢性压力是重要的公共卫生问题，社交媒体如Twitter成为人们分享压力体验的重要平台。现有方法在压力检测方面仍有提升空间，特别是如何利用临床相关条件（抑郁、焦虑、PTSD）的高共病性来改进压力检测模型。

Method: 提出StressRoBERTa跨条件迁移学习方法：1）使用Stress-SMHD语料库（来自自我报告抑郁、焦虑、PTSD用户的1.08亿词）对RoBERTa进行持续训练；2）在SMM4H 2022 Task 8数据集上进行微调；3）比较与通用语言模型和广泛心理健康模型的性能差异。

Result: StressRoBERTa在SMM4H 2022 Task 8数据集上达到82% F1分数，比最佳共享任务系统（79% F1）高出3个百分点。相比原始RoBERTa提升1% F1，表明从压力相关障碍的跨条件迁移比通用心理健康训练提供更强的表示能力。在Dreaddit数据集上达到81% F1，证明从临床心理健康情境到情境压力讨论的有效迁移。

Conclusion: 从临床相关条件（抑郁、焦虑、PTSD）的跨条件迁移学习能有效提升慢性压力检测性能，优于通用语言模型和广泛心理健康模型。该方法展示了临床心理健康情境向情境压力讨论的有效知识迁移，为社交媒体压力检测提供了更精确的解决方案。

Abstract: The prevalence of chronic stress represents a significant public health concern, with social media platforms like Twitter serving as important venues for individuals to share their experiences. This paper introduces StressRoBERTa, a cross-condition transfer learning approach for automatic detection of self-reported chronic stress in English tweets. The investigation examines whether continual training on clinically related conditions (depression, anxiety, PTSD), disorders with high comorbidity with chronic stress, improves stress detection compared to general language models and broad mental health models. RoBERTa is continually trained on the Stress-SMHD corpus (108M words from users with self-reported diagnoses of depression, anxiety, and PTSD) and fine-tuned on the SMM4H 2022 Task 8 dataset. StressRoBERTa achieves 82% F1-score, outperforming the best shared task system (79% F1) by 3 percentage points. The results demonstrate that focused cross-condition transfer from stress-related disorders (+1% F1 over vanilla RoBERTa) provides stronger representations than general mental health training. Evaluation on Dreaddit (81% F1) further demonstrates transfer from clinical mental health contexts to situational stress discussions.

</details>


### [16] [Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms](https://arxiv.org/abs/2512.23835)
*Himel Ghosh*

Main category: cs.CL

TL;DR: 比较两种基于Transformer的新闻偏见检测模型的可解释性研究，发现领域自适应模型比专用偏见检测器产生更少的假阳性，且归因模式与预测结果更一致。


<details>
  <summary>Details</summary>
Motivation: 新闻文本的自动偏见检测广泛用于支持新闻分析和媒体问责，但人们对偏见检测模型如何做出决策或为何失败知之甚少。本研究旨在通过可解释性分析来理解不同模型架构如何操作化语言偏见。

Method: 使用基于SHAP的解释方法，对两种基于Transformer的偏见检测模型进行对比可解释性研究：1) 在BABE数据集上微调的专用偏见检测器；2) 在BABE数据集上微调的领域自适应预训练RoBERTa模型。分析正确和错误预测中的词级归因，以表征不同模型架构如何操作化语言偏见。

Result: 两种模型都关注相似的评价语言类别，但在如何将这些信号整合到预测中存在显著差异。偏见检测器模型对假阳性分配了比真阳性更强的内部证据，表明归因强度与预测正确性之间存在错位，导致系统性地过度标记中性新闻内容。相比之下，领域自适应模型的归因模式与预测结果更一致，假阳性减少了63%。模型错误源于不同的语言机制，假阳性主要由话语层面的模糊性而非明确的偏见线索驱动。

Conclusion: 研究强调了可解释性评估对偏见检测系统的重要性，表明架构和训练选择对模型可靠性和在新闻背景下的部署适用性具有关键影响。领域自适应方法在减少假阳性和改善归因一致性方面表现更好。

Abstract: Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.

</details>


### [17] [Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?](https://arxiv.org/abs/2512.23836)
*Dingmin Wang,Ji Ma,Shankar Kumar*

Main category: cs.CL

TL;DR: 该论文提出了一种自适应提示策略，通过将检索信息分割成小块并顺序提示LLM来回答问答问题，在减少无关信息的同时保持性能，同时发现LLM在信息不足时倾向于生成错误答案而非拒绝回答。


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文窗口的扩展，检索增强生成中使用了更广泛的上下文。然而，更长的上下文虽然更容易包含目标知识，但也引入了更多无关信息，这会阻碍模型的生成过程并降低其性能。

Method: 设计了一种自适应提示策略：将检索到的信息分割成较小的块，然后顺序提示LLM使用每个块来回答问题。通过调整块大小，可以在包含相关信息与减少无关信息之间进行权衡。

Result: 在三个开放域问答数据集上的实验结果表明，自适应策略在使用更少token的情况下，性能与标准提示方法相当。分析发现，当遇到信息不足时，LLM通常会生成错误答案而不是拒绝回答，这是主要的错误来源。

Conclusion: 该研究强调了需要进一步研究如何增强LLM在面对信息不足时有效拒绝请求的能力。自适应提示策略提供了一种在长上下文环境中平衡相关信息与无关信息的有效方法。

Abstract: The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.

</details>


### [18] [Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation](https://arxiv.org/abs/2512.23837)
*Kaustubh Dhole*

Main category: cs.CL

TL;DR: 利用注意力中间层的token分布生成对抗样本，用于压力测试LLM评估流程，在保持语义相似的同时降低评估性能


<details>
  <summary>Details</summary>
Motivation: 机制可解释性研究表明注意力中间层编码了token级假设，这些假设会迭代优化到最终输出。利用这一特性从注意力层token分布生成对抗样本，相比基于提示或梯度的攻击，这种方法利用模型内部token预测，产生既合理又与模型自身生成过程内部一致的扰动

Method: 从注意力中间层提取token作为对抗扰动，在ArgQuality数据集上进行论证质量评估实验，使用LLaMA-3.1-Instruct-8B同时作为生成器和评估器

Result: 注意力基对抗样本导致评估性能显著下降，同时保持与原始输入的语义相似性。但某些层和token位置的替换会引入语法退化，限制了实际有效性

Conclusion: 研究结果突显了使用中间层表示作为对抗样本原则性来源的潜力和当前局限性，可用于压力测试基于LLM的评估流程

Abstract: Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.

</details>


### [19] [Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs](https://arxiv.org/abs/2512.23848)
*Yukun Zhang,Stefan Elbl Droguett,Samyak Jain*

Main category: cs.CL

TL;DR: 该研究针对金融数值推理问答任务中因缺乏金融领域知识导致的错误，通过多检索器RAG系统结合最新LLM，在金融数值推理任务上取得了SOTA性能，但仍低于人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs取得了进展，但金融数值问题仍然具有挑战性，因为它们需要特定的金融领域知识和复杂的多步数值推理。当前模型因缺乏领域知识而在金融数值推理QA任务中表现不佳。

Method: 实现了一个多检索器RAG系统，用于检索外部领域知识和内部问题上下文，并利用最新的LLM来处理这些任务。通过SecBERT编码器进行领域特定训练，构建神经符号模型。

Result: 领域特定训练显著提升了模型性能，最佳神经符号模型超越了FinQA论文的基准模型。最佳基于提示的LLM生成器实现了SOTA性能，显著改进超过7%，但仍低于人类专家水平。

Conclusion: 研究发现领域特定训练对性能有重要贡献，较小模型存在幻觉损失与外部知识增益的权衡，而较大模型的外部事实增益通常超过幻觉损失。最新LLM在少样本学习优化的数值推理能力得到增强。

Abstract: This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.

</details>


### [20] [Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling](https://arxiv.org/abs/2512.23959)
*Chulun Zhou,Chunkang Zhang,Guoxin Yu,Fandong Meng,Jie Zhou,Wai Lam,Mo Yu*

Main category: cs.CL

TL;DR: HGMem提出了一种基于超图的记忆机制，用于增强多步检索增强生成（RAG）系统，通过动态超图结构捕捉事实间的高阶关联，提升全局理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统的记忆模块主要作为被动存储，仅积累孤立事实用于输入压缩和生成新查询，忽视了事实间的高阶关联，导致推理碎片化和全局理解能力弱。

Method: 提出HGMem超图记忆机制，将记忆表示为超图结构，超边对应不同的记忆单元，能够渐进地形成记忆中的高阶交互，连接围绕核心问题的事实和思考，形成集成化的知识结构。

Result: 在多个为全局理解设计的挑战性数据集上评估，实验表明HGMem能持续改进多步RAG性能，并在多样化任务上显著优于强基线系统。

Conclusion: HGMem将记忆从简单存储扩展为动态表达结构，通过超图捕捉事实间的高阶关联，为后续推理步骤提供更强命题，有效提升复杂推理和全局理解能力。

Abstract: Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.

</details>


### [21] [Efficient Context Scaling with LongCat ZigZag Attention](https://arxiv.org/abs/2512.23966)
*Chen Zhang,Yang Bai,Jiahuan Li,Anchun Gui,Keheng Wang,Feifan Liu,Guanyu Wu,Yuwei Jiang,Defei Bu,Li Wei,Haihang Jing,Hongyin Tang,Xin Chen,Xiangzhou Huang,Fengcun Li,Rongxiang Weng,Yulei Qian,Yifan Lu,Yerui Sun,Jingang Wang,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: LoZA是一种稀疏注意力方案，可将全注意力模型转换为稀疏版本，在有限计算预算下实现长上下文场景的显著加速，支持处理高达100万token。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文场景中全注意力模型计算成本高的问题，特别是在预填充密集型（如检索增强生成）和解码密集型（如工具集成推理）任务中，需要更高效的注意力机制。

Method: 提出LongCat ZigZag Attention (LoZA)稀疏注意力方案，通过特定的稀疏模式设计，将现有全注意力模型转换为稀疏版本，应用于LongCat-Flash模型进行中期训练。

Result: LoZA在长上下文场景中实现了显著的速度提升，LongCat-Flash-Exp模型能够高效处理高达100万token，支持长期推理和长视野智能体能力。

Conclusion: LoZA是一种有效的稀疏注意力方案，能够在有限计算预算下扩展模型的长上下文处理能力，为长序列任务提供了实用的解决方案。

Abstract: We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (e.g., retrieval-augmented generation) and decode-intensive (e.g., tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long-context foundation model that can swiftly process up to 1 million tokens, enabling efficient long-term reasoning and long-horizon agentic capabilities.

</details>


### [22] [CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards](https://arxiv.org/abs/2512.23971)
*Zhiming Lin,Kai Zhao,Sophie Zhang,Peilai Yu,Canran Xiao*

Main category: cs.CL

TL;DR: CEC-Zero：无需监督的强化学习框架，通过让大语言模型自我纠错来解决中文拼写纠正问题，在9个基准测试中显著超越监督方法和微调模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和监督方法在中文拼写纠正中存在两个主要问题：1) 对新型错误缺乏鲁棒性；2) 依赖昂贵的标注数据。需要一种无需监督标签的鲁棒解决方案。

Method: CEC-Zero采用零监督强化学习框架：1) 从干净文本合成错误输入；2) 通过语义相似性和候选一致性计算聚类共识奖励；3) 使用PPO优化策略。该方法具有无偏奖励和收敛的理论保证。

Result: 在9个基准测试中，CEC-Zero比监督基线高出10-13个F1分数，比强LLM微调方法高出5-8个F1分数，表现出色。

Conclusion: CEC-Zero为鲁棒、可扩展的中文拼写纠正建立了无需标签的新范式，释放了大语言模型在噪声文本处理中的潜力。

Abstract: Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by enabling LLMs to correct their own mistakes. CEC-Zero synthesizes errorful inputs from clean text, computes cluster-consensus rewards via semantic similarity and candidate agreement, and optimizes the policy with PPO. It outperforms supervised baselines by 10--13 F$_1$ points and strong LLM fine-tunes by 5--8 points across 9 benchmarks, with theoretical guarantees of unbiased rewards and convergence. CEC-Zero establishes a label-free paradigm for robust, scalable CSC, unlocking LLM potential in noisy text pipelines.

</details>


### [23] [Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability](https://arxiv.org/abs/2512.24842)
*Yanan Long*

Main category: cs.CL

TL;DR: 提出一种名为"三角测量"的因果标准，用于验证多语言模型中的机制解释，要求电路在跨语言变体中保持必要性、充分性和不变性。


<details>
  <summary>Details</summary>
Motivation: 多语言模型在整体性能上表现良好，但在不同语言、文字和文化中的行为不可预测。现有机制解释缺乏因果标准，无法区分真正的机制和虚假的相关性。

Method: 提出"三角测量"方法，要求候选电路满足三个标准：必要性（消融电路会降低目标行为）、充分性（修补激活能转移行为）、不变性（这些效应在参考家族中保持方向和幅度稳定）。使用自动电路发现生成候选子图，然后通过三角测量接受或拒绝。

Result: 三角测量提供了一个可证伪的标准，能够过滤掉那些通过单环境测试但在跨语言不变性上失败的虚假电路，为机制解释提供了更可靠的验证方法。

Conclusion: 三角测量为多语言模型的机制解释建立了一个因果标准，通过跨语言参考变体的验证，提高了机制解释的可靠性和可证伪性，有助于理解模型在不同语言环境中的行为。

Abstract: Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \emph{causal} standard: claims must survive causal interventions and must \emph{cross-reference} across environments that perturb surface form while preserving meaning. We formalize \emph{reference families} as predicate-preserving variants and introduce \emph{triangulation}, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \emph{accept or reject} those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.

</details>


### [24] [Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process](https://arxiv.org/abs/2512.23988)
*Zhenyu Zhang,Shujian Zhang,John Lambert,Wenxuan Zhou,Zhangyang Wang,Mingqing Chen,Andrew Hard,Rajiv Mathews,Lun Wang*

Main category: cs.CL

TL;DR: 提出RISE框架，使用稀疏自编码器无监督发现LLM推理过程中的行为向量，实现推理行为的解释与控制


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工定义概念分析LLM推理过程，但难以捕捉完整的推理行为谱系，且许多行为难以在token空间中定义

Method: 将思维链轨迹分割为句子级"步骤"，在步骤级激活上训练稀疏自编码器，发现解耦的特征对应可解释的推理行为

Result: 发现反射、回溯等可解释行为占据可分离区域，通过干预SAE向量可控制推理行为，还能发现超越人工监督的新行为（如置信度相关向量）

Conclusion: 无监督潜在发现方法在解释和控制LLM推理方面具有巨大潜力

Abstract: Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level 'steps' and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.

</details>


### [25] [WISE: Web Information Satire and Fakeness Evaluation](https://arxiv.org/abs/2512.24000)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.CL

TL;DR: WISE框架评估轻量级Transformer模型区分假新闻与讽刺内容，MiniLM获得最高准确率(87.58%)，RoBERTa-base获得最高ROC-AUC(95.42%)，DistilBERT在效率与准确率间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 假新闻与讽刺内容具有相似的语言特征但意图不同，区分它们具有独特挑战。研究旨在开发评估框架，比较轻量级模型在资源受限环境中的性能，为实际部署提供指导。

Method: 开发WISE框架，在Fakeddit的20,000个平衡数据集上评估8个轻量级Transformer模型和2个基线模型。使用分层5折交叉验证，评估准确率、精确率、召回率、F1分数、ROC-AUC、PR-AUC、MCC、Brier分数和预期校准误差等指标。通过配对t检验和McNemar检验进行统计显著性分析。

Result: MiniLM获得最高准确率(87.58%)，RoBERTa-base获得最高ROC-AUC(95.42%)和强准确率(87.36%)。DistilBERT在效率与准确率间取得良好平衡(86.28%准确率，93.90% ROC-AUC)。统计检验证实模型间存在显著性能差异。轻量级模型能够匹配或超越基线性能。

Conclusion: 轻量级Transformer模型在区分假新闻与讽刺内容方面表现优异，能够在资源受限的实际环境中有效部署。研究为误信息检测系统的实际应用提供了可行见解，表明轻量级模型是可行的替代方案。

Abstract: Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28\% accuracy and 93.90\% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.

</details>


### [26] [iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning](https://arxiv.org/abs/2512.24014)
*Sijia Chen,Di Niu*

Main category: cs.CL

TL;DR: iCLP框架让大语言模型在潜在空间中规划，在语言空间中推理，通过隐式认知提升推理准确性和效率


<details>
  <summary>Details</summary>
Motivation: 现有基于显式文本规划的LLM推理存在幻觉问题且规划生成困难，受人类隐式认知启发，希望让LLM学习紧凑的潜在规划编码

Method: iCLP框架：1)从现有逐步推理轨迹中提取显式规划；2)通过向量量化自编码器学习离散表示；3)在潜在规划与推理步骤对上微调LLM

Result: 在数学推理和代码生成任务上，iCLP显著提升准确性和效率，并展现出强大的跨领域泛化能力，同时保持思维链推理的可解释性

Conclusion: iCLP通过隐式规划使LLM能够同时进行潜在空间规划和语言空间推理，为解决LLM规划挑战提供了有效方案

Abstract: Large language models (LLMs), when guided by explicit textual plans, can perform reliable step-by-step reasoning during problem-solving. However, generating accurate and effective textual plans remains challenging due to LLM hallucinations and the high diversity of task-specific questions. To address this, we draw inspiration from human Implicit Cognition (IC), the subconscious process by which decisions are guided by compact, generalized patterns learned from past experiences without requiring explicit verbalization. We propose iCLP, a novel framework that enables LLMs to adaptively generate latent plans (LPs), which are compact encodings of effective reasoning instructions. iCLP first distills explicit plans from existing step-by-step reasoning trajectories. It then learns discrete representations of these plans via a vector-quantized autoencoder coupled with a codebook. Finally, by fine-tuning LLMs on paired latent plans and corresponding reasoning steps, the models learn to perform implicit planning during reasoning. Experimental results on mathematical reasoning and code generation tasks demonstrate that, with iCLP, LLMs can plan in latent space while reasoning in language space. This approach yields significant improvements in both accuracy and efficiency and, crucially, demonstrates strong cross-domain generalization while preserving the interpretability of chain-of-thought reasoning.

</details>


### [27] [Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models](https://arxiv.org/abs/2512.24058)
*Rohit Kumar Salla,Manoj Saravanan,Shrikar Reddy Kota*

Main category: cs.CL

TL;DR: 提出Composite Reliability Score (CRS)统一框架，将校准、鲁棒性和不确定性量化整合为单一可解释指标，用于评估LLM在关键决策领域的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗、法律、金融等关键决策领域应用日益增多，但其可靠性存在不确定性：经常出现过度自信的错误、在输入变化时性能下降、缺乏清晰的不确定性估计。现有评估方法零散，只关注孤立方面。

Method: 引入Composite Reliability Score (CRS)统一框架，整合校准、鲁棒性和不确定性量化三个维度。在10个领先开源LLM和5个QA数据集上进行实验，评估基线性能、扰动下的表现和校准方法。

Result: CRS提供稳定的模型排名，揭示单一指标遗漏的隐藏故障模式，并显示最可靠的系统需要在准确性、鲁棒性和校准不确定性之间取得平衡。

Conclusion: CRS框架为LLM可靠性评估提供了统一、全面的方法，有助于识别在关键决策应用中表现最可靠的模型，强调平衡多方面性能的重要性。

Abstract: Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.

</details>


### [28] [HY-MT1.5 Technical Report](https://arxiv.org/abs/2512.24092)
*Mao Zheng,Zheng Li,Tao Chen,Mingyang Song,Di Wang*

Main category: cs.CL

TL;DR: HY-MT1.5系列翻译模型（1.8B和7B参数）通过多阶段训练框架，在参数效率上超越更大开源模型和商业API，达到Gemini-3.0-Pro约90-95%性能，支持术语干预等高级功能。


<details>
  <summary>Details</summary>
Motivation: 开发高性能、参数高效的机器翻译模型，在较小参数规模下达到或接近超大私有模型的翻译性能，同时支持专业翻译任务的高级约束功能。

Method: 采用多阶段训练框架：通用预训练+MT定向预训练+监督微调+策略蒸馏+强化学习，形成完整的训练管道。

Result: HY-MT1.5-1.8B在标准中-外/英-外任务上超越Tower-Plus-72B等更大开源模型和微软翻译等商业API，达到Gemini-3.0-Pro约90%性能；HY-MT1.5-7B在Flores-200上达到Gemini-3.0-Pro 95%性能，在WMT25和普通话-少数民族语言测试集上超越Gemini-3.0-Pro。

Conclusion: HY-MT1.5系列模型在各自参数规模内提供了高度竞争力和鲁棒性的通用及专业翻译解决方案，展示了参数效率的显著优势。

Abstract: In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro's performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.

</details>


### [29] [Training a Huggingface Model on AWS Sagemaker (Without Tears)](https://arxiv.org/abs/2512.24098)
*Liling Tan*

Main category: cs.CL

TL;DR: 本文旨在降低AWS SageMaker上训练Hugging Face模型的门槛，为研究人员提供一站式指南，解决云平台学习曲线陡峭和文档碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的开发主要由资源丰富的研究团队和行业伙伴推动。由于缺乏本地计算资源来训练日益复杂的模型，许多研究人员转向AWS SageMaker等云服务来训练Hugging Face模型。然而，云平台的陡峭学习曲线对习惯于本地环境的研究人员构成了障碍，现有文档经常存在知识缺口，迫使用户在网络上寻找碎片化信息。

Method: 本文通过集中化必要信息，为研究人员提供从零开始在AWS SageMaker上成功训练第一个Hugging Face模型的完整指南。该方法旨在整合分散的知识，创建一个系统化的教程。

Result: 通过提供集中化的指南，本文降低了云平台采用的门槛，使更多研究人员能够利用AWS SageMaker训练Hugging Face模型，促进了研究的民主化。

Conclusion: 本文通过提供一站式指南，成功降低了AWS SageMaker上训练Hugging Face模型的技术门槛，有助于推动云计算的民主化采用，使更多研究人员能够利用云资源进行模型训练。

Abstract: The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.

</details>


### [30] [Activation Steering for Masked Diffusion Language Models](https://arxiv.org/abs/2512.24143)
*Adi Shnaidman,Erin Feiglin,Osher Yaari,Efrat Mentel,Amit Levi,Raz Lapid*

Main category: cs.CL

TL;DR: 提出了一种用于掩码扩散语言模型（MDLMs）的激活引导框架，通过对比示例计算层间引导向量，实现推理时的高效控制，无需模拟去噪轨迹。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散语言模型通过迭代去噪过程生成文本，具有掩码并行解码和与自回归大语言模型竞争的性能。然而，MDLMs在推理时控制和引导的有效机制尚未得到充分探索。

Method: 提出激活引导框架：1）使用对比示例通过单次前向传播计算层间引导向量；2）在反向扩散的每一步应用这些方向；3）无需模拟去噪轨迹；4）在LLaDA-8B-Instruct上进行实验，分析不同transformer子模块和token范围（提示vs.响应）的引导效果。

Result: 在LLaDA-8B-Instruct上实现了对高级属性的可靠调节，通过消融实验检验了在不同transformer子模块和token范围上引导的效果。

Conclusion: 该激活引导框架为MDLMs提供了一种高效的推理时控制机制，能够可靠地调节生成文本的高级属性，为MDLMs的引导和控制开辟了新途径。

Abstract: Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steering in MDLMs remain largely unexplored. We present an activation-steering framework for MDLMs that computes layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. These directions are applied at every reverse-diffusion step, yielding an efficient inference-time control mechanism. Experiments on LLaDA-8B-Instruct demonstrate reliable modulation of high-level attributes, with ablations examining the effects of steering across transformer sub-modules and token scope (prompt vs.\ response).

</details>


### [31] [Large Emotional World Model](https://arxiv.org/abs/2512.24149)
*Changhao Song,Yazhou Zhang,Hui Gao,Chang Yang,Peng Zhang*

Main category: cs.CL

TL;DR: 该论文提出了大型情感世界模型（LEWM），通过整合情感因素来增强世界模型对人类行为的理解和预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型主要关注物理世界规律，缺乏对情感因素的系统探索。情感作为世界知识的重要组成部分，显著影响人类决策，因此需要构建能够理解情感驱动的世界模型。

Method: 首先通过实验证明移除情感相关信息会降低推理性能。然后基于心智理论提出LEWM模型，构建Emotion-Why-How（EWH）数据集，将情感融入因果关系中，使模型能够同时建模情感状态、视觉观察和动作，预测未来状态和情感转变。

Result: 实验结果显示，LEWM在准确预测情感驱动的社会行为方面表现更好，同时在基础任务上保持与通用世界模型相当的性能。

Conclusion: 情感是世界理解的关键因素，LEWM通过显式建模情感状态，能够更好地理解和预测情感驱动的社会行为，为构建更全面的世界模型提供了新方向。

Abstract: World Models serve as tools for understanding the current state of the world and predicting its future dynamics, with broad application potential across numerous fields. As a key component of world knowledge, emotion significantly influences human decision-making. While existing Large Language Models (LLMs) have shown preliminary capability in capturing world knowledge, they primarily focus on modeling physical-world regularities and lack systematic exploration of emotional factors. In this paper, we first demonstrate the importance of emotion in understanding the world by showing that removing emotionally relevant information degrades reasoning performance. Inspired by theory of mind, we further propose a Large Emotional World Model (LEWM). Specifically, we construct the Emotion-Why-How (EWH) dataset, which integrates emotion into causal relationships and enables reasoning about why actions occur and how emotions drive future world states. Based on this dataset, LEWM explicitly models emotional states alongside visual observations and actions, allowing the world model to predict both future states and emotional transitions. Experimental results show that LEWM more accurately predicts emotion-driven social behaviors while maintaining comparable performance to general world models on basic tasks.

</details>


### [32] [Training Report of TeleChat3-MoE](https://arxiv.org/abs/2512.24157)
*Xinzhang Liu,Chao Wang,Zhihao Yang,Zhuo Jiang,Xuncheng Zhao,Haoran Wang,Lei Li,Dongdong He,Luobin Liu,Kaizhe Yuan,Han Gao,Zihan Wang,Yitong Yao,Sishi Xiong,Wenmin Deng,Haowei He,Kaidong Yu,Yu Zhao,Ruiyu Fang,Yuhao Jiang,Yingyan Li,Xiaohui Hu,Xi Yu,Jingqi Li,Yanwei Liu,Qingli Li,Xinyu Shi,Junhao Niu,Chengnuo Huang,Yao Xiao,Ruiwen Wang,Fengkai Li,Luwen Pu,Kaipeng Jia,Fubei Yao,Yuyao Huang,Xuewei He,Zhuoru Jiang,Ruiting Song,Rui Xue,Qiyi Xie,Jie Zhang,Zilu Huang,Zhaoxi Zhang,Zhilong Lu,Yanhan Zhang,Yin Zhang,Yanlei Xue,Zhu Yuan,Teng Su,Xin Jiang,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: TeleChat3-MoE是一个基于昇腾NPU集群端到端训练的MoE架构大语言模型系列，参数规模从1050亿到超过1万亿，本文主要介绍了支持前沿模型规模扩展的训练基础设施技术。


<details>
  <summary>Details</summary>
Motivation: 为了在昇腾NPU集群上可靠高效地扩展到前沿模型规模（参数达万亿级别），需要建立系统性的训练基础设施，解决大规模训练中的数值精度、性能优化和并行配置等挑战。

Method: 提出了系统化的训练基础设施方案：1）算子级和端到端数值精度验证方法；2）性能优化技术包括交错流水线调度、长序列训练的注意力感知数据调度、专家并行的分层重叠通信、DVM算子融合；3）基于分析估计和整数线性规划的系统性并行化框架；4）集群级优化方法解决主机和设备端瓶颈。

Result: 这些基础设施改进在数千设备集群上实现了显著的吞吐量提升和接近线性的扩展性能，为硬件生态系统上的大规模语言模型开发提供了坚实基础。

Conclusion: TeleChat3-MoE的训练基础设施为在昇腾NPU集群上扩展到万亿参数级别的MoE模型提供了可靠、高效的技术方案，通过系统化的精度验证、性能优化和并行配置方法，实现了大规模训练的高效扩展。

Abstract: TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.

</details>


### [33] [MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring](https://arxiv.org/abs/2512.24181)
*Qipeng Wang,Rui Sheng,Yafei Li,Huamin Qu,Yushi Sun,Min Zhu*

Main category: cs.CL

TL;DR: MedKGI：基于医学知识图谱的临床诊断框架，通过约束推理、信息增益问题选择和结构化状态跟踪，解决LLM在临床诊断中的幻觉、冗余和一致性三大问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在临床诊断中存在三大关键局限：1) 基于未经验证知识产生医学内容幻觉；2) 提出冗余低效而非判别性问题；3) 多轮对话中失去一致性导致矛盾结论。需要模拟真实临床场景的迭代诊断假设驱动推理。

Method: 提出MedKGI诊断框架：1) 集成医学知识图谱，将推理约束在已验证的医学本体中；2) 基于信息增益选择问题，最大化诊断效率；3) 采用OSCE格式结构化状态，保持跨轮次证据跟踪的一致性。

Result: 在临床基准测试中，MedKGI在诊断准确性和询问效率方面均优于强大的LLM基线，平均提高对话效率30%，同时保持最先进的准确性。

Conclusion: MedKGI通过知识图谱约束、信息增益驱动的问题选择和结构化状态管理，有效解决了LLM在临床诊断中的关键挑战，实现了更接近真实临床实践的迭代诊断推理。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.

</details>


### [34] [LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring](https://arxiv.org/abs/2512.24235)
*May Bashendy,Walid Massoud,Sohaila Eltanbouly,Salam Albatarni,Marwan Sayed,Abrar Abir,Houda Bouamor,Tamer Elsayed*

Main category: cs.CL

TL;DR: LAILA是最大的公开阿拉伯语自动作文评分数据集，包含7,859篇作文，标注了整体分数和七个维度的特质分数，填补了阿拉伯语AES研究的数据空白。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语自动作文评分研究因缺乏公开数据集而受限，需要构建大规模标注数据集来支持该领域的发展。

Method: 设计、收集并标注了7,859篇阿拉伯语作文，包括整体分数和七个维度（相关性、组织、词汇、风格、发展、机制、语法）的特质分数。

Result: 提供了使用最先进的阿拉伯语和英语模型在特定提示和跨提示设置下的基准结果，展示了数据集的有效性。

Conclusion: LAILA填补了阿拉伯语AES研究的关键需求，支持开发鲁棒的评分系统，推动了阿拉伯语自然语言处理领域的发展。

Abstract: Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.

</details>


### [35] [Tracing the Flow of Knowledge From Science to Technology Using Deep Learning](https://arxiv.org/abs/2512.24259)
*Michael E. Rose,Mainak Ghosh,Sebastian Erhardt,Cheng Li,Erik Buunk,Dietmar Harhoff*

Main category: cs.CL

TL;DR: 开发了适用于专利和科学文献的语言相似性模型Pat-SPECTER，在预测可信的专利-论文引用方面表现最佳，并验证了美国专利因诚信义务而引用语义相似度较低论文的假设。


<details>
  <summary>Details</summary>
Motivation: 需要开发能够同时处理专利和科学文献的语言相似性模型，以更好地理解和预测专利与学术论文之间的引用关系，并探索不同司法管辖区引用模式的差异。

Method: 基于SPECTER2模型，在专利数据上进行微调得到Pat-SPECTER模型。通过马赛式评估比较8种语言相似性模型预测可信专利-论文引用的能力，并在两个真实场景中验证模型性能。

Result: Pat-SPECTER模型在预测可信专利-论文引用方面表现最佳。验证了假设：美国专利因诚信义务要求，引用的论文与专利内容语义相似度低于其他主要司法管辖区。

Conclusion: Pat-SPECTER是处理专利和科学文献相似性分析的有效工具，为学术研究和实践应用提供了开放可用的模型，同时揭示了不同司法管辖区引用行为的差异。

Abstract: We develop a language similarity model suitable for working with patents and scientific publications at the same time. In a horse race-style evaluation, we subject eight language (similarity) models to predict credible Patent-Paper Citations. We find that our Pat-SPECTER model performs best, which is the SPECTER2 model fine-tuned on patents. In two real-world scenarios (separating patent-paper-pairs and predicting patent-paper-pairs) we demonstrate the capabilities of the Pat-SPECTER. We finally test the hypothesis that US patents cite papers that are semantically less similar than in other large jurisdictions, which we posit is because of the duty of candor. The model is open for the academic community and practitioners alike.

</details>


### [36] [Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning](https://arxiv.org/abs/2512.24265)
*Ziqing Fan,Yuqiao Xian,Yan Sun,Li Shen*

Main category: cs.CL

TL;DR: DATAMASK是一个用于大规模预训练数据选择的高效联合学习框架，能同时优化质量和多样性指标，显著减少选择时间98.9%，在万亿级token数据集上实现更好的模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法存在局限性：基于质量指标的选择在长期预训练中收益递减，而基于多样性指标的选择会移除过多高质量样本。由于计算成本高，在万亿级token数据集上很少能同时考虑多种指标。

Method: 将数据选择问题转化为掩码学习问题，通过迭代采样数据掩码、基于预定义目标计算策略梯度、更新掩码采样logits，采用策略梯度优化和多种加速增强技术。

Result: 选择时间比贪心算法减少98.9%，从15万亿token的FineWeb数据集中选择约10%子集（FineWeb-Mask），在12个任务上评估，1.5B密集模型提升3.2%，7B MoE模型提升1.9%。

Conclusion: DATAMASK框架能高效地在万亿级token数据集上进行联合数据选择，同时优化质量和多样性指标，显著提升预训练模型的性能，为大规模预训练数据选择提供了有效解决方案。

Abstract: A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in embeddings, which can be roughly categorized into quality and diversity metrics. Due to the high computational cost when applied to trillion-scale token pre-training datasets such as FineWeb and DCLM, these two or more types of metrics are rarely considered jointly in a single selection process. However, in our empirical study, selecting samples based on quality metrics exhibit severe diminishing returns during long-term pre-training, while selecting on diversity metrics removes too many valuable high-quality samples, both of which limit pre-trained LLMs' capabilities. Therefore, we introduce DATAMASK, a novel and efficient joint learning framework designed for large-scale pre-training data selection that can simultaneously optimize multiple types of metrics in a unified process, with this study focusing specifically on quality and diversity metrics. DATAMASK approaches the selection process as a mask learning problem, involving iterative sampling of data masks, computation of policy gradients based on predefined objectives with sampled masks, and updating of mask sampling logits. Through policy gradient-based optimization and various acceleration enhancements, it significantly reduces selection time by 98.9% compared to greedy algorithm, enabling our study to explore joint learning within trillion-scale tokens. With DATAMASK, we select a subset of about 10% from the 15 trillion-token FineWeb dataset, termed FineWeb-Mask. Evaluated across 12 diverse tasks, we achieves significant improvements of 3.2% on a 1.5B dense model and 1.9% on a 7B MoE model.

</details>


### [37] [Automated Analysis of Sustainability Reports: Using Large Language Models for the Extraction and Prediction of EU Taxonomy-Compliant KPIs](https://arxiv.org/abs/2512.24289)
*Jonathan Schmoll,Adam Jatowt*

Main category: cs.CL

TL;DR: 本文针对欧盟分类法合规流程自动化，构建了首个公开基准数据集，系统评估了LLM在定性和定量任务上的表现，发现LLM在定性任务上表现中等，但在定量任务上完全失败，可作为人类专家的辅助工具而非完全自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 欧盟分类法合规流程手动操作成本高、资源密集，LLM虽提供自动化可能，但缺乏公开基准数据集阻碍了相关研究。本文旨在填补这一空白。

Method: 从190份企业报告中构建结构化数据集，包含真实经济活动和定量KPI指标，首次系统评估LLM在核心合规工作流中的表现，包括定性经济活动识别和定量KPI预测任务。

Result: LLM在定性经济活动识别任务上表现中等，多步智能体框架可适度提升精度；但在零样本设置的定量KPI预测任务上完全失败。发现矛盾现象：简洁元数据往往比完整非结构化报告表现更好；模型置信度分数校准不佳。

Conclusion: LLM尚未准备好实现完全自动化，但可作为人类专家的强大辅助工具。本文数据集为未来研究提供了公开基准。

Abstract: The manual, resource-intensive process of complying with the EU Taxonomy presents a significant challenge for companies. While Large Language Models (LLMs) offer a path to automation, research is hindered by a lack of public benchmark datasets. To address this gap, we introduce a novel, structured dataset from 190 corporate reports, containing ground-truth economic activities and quantitative Key Performance Indicators (KPIs). We use this dataset to conduct the first systematic evaluation of LLMs on the core compliance workflow. Our results reveal a clear performance gap between qualitative and quantitative tasks. LLMs show moderate success in the qualitative task of identifying economic activities, with a multi-step agentic framework modestly enhancing precision. Conversely, the models comprehensively fail at the quantitative task of predicting financial KPIs in a zero-shot setting. We also discover a paradox, where concise metadata often yields superior performance to full, unstructured reports, and find that model confidence scores are poorly calibrated. We conclude that while LLMs are not ready for full automation, they can serve as powerful assistive tools for human experts. Our dataset provides a public benchmark for future research.

</details>


### [38] [Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking](https://arxiv.org/abs/2512.24297)
*Meiqi Chen,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: FIGR通过强化学习将视觉思维整合到多轮推理中，构建视觉表示来外化中间结构假设，在复杂数学推理任务上显著优于纯文本方法。


<details>
  <summary>Details</summary>
Motivation: 复杂推理问题常涉及隐式的空间、几何和结构关系，这些关系在文本中无法明确编码。纯文本推理难以捕捉复杂场景中的全局结构约束，需要新的方法来增强推理的稳定性和可靠性。

Method: FIGR通过端到端强化学习将主动视觉思维整合到多轮推理中。系统在问题解决过程中构建视觉表示来外化中间结构假设，并自适应地调节何时以及如何调用视觉推理。

Result: 在具有挑战性的数学推理基准测试中，FIGR显著优于纯文本思维链基线。具体而言，在AIME 2025上提升13.12%，在BeyondAIME上提升11.00%，证明了视觉引导多模态推理的有效性。

Conclusion: 通过整合视觉思维和自适应调节视觉推理，FIGR能够更稳定、连贯地处理难以从纯文本中捕捉的全局结构属性，为复杂推理任务提供了有效的多模态解决方案。

Abstract: Complex reasoning problems often involve implicit spatial, geometric, and structural relationships that are not explicitly encoded in text. While recent reasoning models have achieved strong performance across many domains, purely text-based reasoning struggles to represent global structural constraints in complex settings. In this paper, we introduce FIGR, which integrates active visual thinking into multi-turn reasoning via end-to-end reinforcement learning. FIGR externalizes intermediate structural hypotheses by constructing visual representations during problem solving. By adaptively regulating when and how visual reasoning should be invoked, FIGR enables more stable and coherent reasoning over global structural properties that are difficult to capture from text alone. Experiments on challenging mathematical reasoning benchmarks demonstrate that FIGR outperforms strong text-only chain-of-thought baselines. In particular, FIGR improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME, highlighting the effectiveness of figure-guided multimodal reasoning in enhancing the stability and reliability of complex reasoning.

</details>


### [39] [QianfanHuijin Technical Report: A Novel Multi-Stage Training Paradigm for Finance Industrial LLMs](https://arxiv.org/abs/2512.24314)
*Shupeng Li,Weipeng Lu,Linyun Liu,Chen Lin,Shaofei Li,Zhendong Tan,Hanjun Zhong,Yucheng Zeng,Chenghao Zhu,Mengyue Liu,Daxiang Dong,Jianmin Wu,Yunting Xiao,Annan Li,Danyu Liu,Jingnan Zhang,Licen Liu,Dawei Yin,Dou Shen*

Main category: cs.CL

TL;DR: QianfanHuijin是一个金融领域大语言模型，提出了一种通用的多阶段训练范式，通过持续预训练和细粒度后训练（包括金融SFT、金融推理RL、金融代理RL和通用RL）来增强金融推理和代理能力。


<details>
  <summary>Details</summary>
Motivation: 金融服务的复杂性日益增加，需要不仅具备领域知识，还要有强大金融推理和代理能力的模型。先前模型如BloombergGPT和Baichuan-Finance主要关注知识增强，无法满足当前需求。

Method: 提出多阶段训练范式：1）在金融语料上进行持续预训练以巩固知识基础；2）细粒度后训练管道：金融SFT → 金融推理RL → 金融代理RL → 通用RL（与真实业务场景对齐）。

Result: QianfanHuijin在多个权威金融基准测试中表现出优越性能。消融研究证实针对性的推理RL和代理RL阶段在各自能力上带来显著提升。

Conclusion: 该细粒度渐进式后训练方法验证了研究动机，有望成为各种工业增强型LLM的主流范式。

Abstract: Domain-specific enhancement of Large Language Models (LLMs) within the financial context has long been a focal point of industrial application. While previous models such as BloombergGPT and Baichuan-Finance primarily focused on knowledge enhancement, the deepening complexity of financial services has driven a growing demand for models that possess not only domain knowledge but also robust financial reasoning and agentic capabilities. In this paper, we present QianfanHuijin, a financial domain LLM, and propose a generalizable multi-stage training paradigm for industrial model enhancement.
  Our approach begins with Continual Pre-training (CPT) on financial corpora to consolidate the knowledge base. This is followed by a fine-grained Post-training pipeline designed with increasing specificity: starting with Financial SFT, progressing to Finance Reasoning RL and Finance Agentic RL, and culminating in General RL aligned with real-world business scenarios. Empirical results demonstrate that QianfanHuijin achieves superior performance across various authoritative financial benchmarks. Furthermore, ablation studies confirm that the targeted Reasoning RL and Agentic RL stages yield significant gains in their respective capabilities. These findings validate our motivation and suggest that this fine-grained, progressive post-training methodology is poised to become a mainstream paradigm for various industrial-enhanced LLMs.

</details>


### [40] [World model inspired sarcasm reasoning with large language model agents](https://arxiv.org/abs/2512.24329)
*Keito Inoshita,Shinnosuke Mizuno*

Main category: cs.CL

TL;DR: 论文提出WM-SAR方法，将反讽理解重新定义为世界模型启发的推理过程，通过分解字面意义、上下文、规范期望和意图为专门的LLM代理，实现可解释的反讽检测。


<details>
  <summary>Details</summary>
Motivation: 现有反讽理解方法大多依赖单一模型的黑盒预测，难以结构性地解释反讽背后的认知因素。反讽通常表现为语义评估与规范期望或意图之间的不匹配，但明确分解和建模这些组件的框架仍然有限。

Method: 提出WM-SAR方法，将反讽理解重新定义为世界模型启发的推理过程。将字面意义、上下文、规范期望和意图分解为专门的LLM代理。字面评估与规范期望之间的差异被明确量化为确定性不一致分数，与意图分数一起通过轻量级逻辑回归模型集成，推断最终的反讽概率。

Result: 在代表性反讽检测基准测试中，WM-SAR始终优于现有的深度学习和基于LLM的方法。消融研究和案例分析进一步证明，整合语义不一致和意图推理对于有效的反讽检测至关重要，实现了强大的性能和高可解释性。

Conclusion: WM-SAR方法利用LLM的推理能力，同时保持可解释的数值决策结构，为反讽理解提供了既高性能又高可解释性的解决方案，填补了现有方法在结构解释性方面的不足。

Abstract: Sarcasm understanding is a challenging problem in natural language processing, as it requires capturing the discrepancy between the surface meaning of an utterance and the speaker's intentions as well as the surrounding social context. Although recent advances in deep learning and Large Language Models (LLMs) have substantially improved performance, most existing approaches still rely on black-box predictions of a single model, making it difficult to structurally explain the cognitive factors underlying sarcasm. Moreover, while sarcasm often emerges as a mismatch between semantic evaluation and normative expectations or intentions, frameworks that explicitly decompose and model these components remain limited. In this work, we reformulate sarcasm understanding as a world model inspired reasoning process and propose World Model inspired SArcasm Reasoning (WM-SAR), which decomposes literal meaning, context, normative expectation, and intention into specialized LLM-based agents. The discrepancy between literal evaluation and normative expectation is explicitly quantified as a deterministic inconsistency score, and together with an intention score, these signals are integrated by a lightweight Logistic Regression model to infer the final sarcasm probability. This design leverages the reasoning capability of LLMs while maintaining an interpretable numerical decision structure. Experiments on representative sarcasm detection benchmarks show that WM-SAR consistently outperforms existing deep learning and LLM-based methods. Ablation studies and case analyses further demonstrate that integrating semantic inconsistency and intention reasoning is essential for effective sarcasm detection, achieving both strong performance and high interpretability.

</details>


### [41] [Skim-Aware Contrastive Learning for Efficient Document Representation](https://arxiv.org/abs/2512.24373)
*Waheed Ahmed Abro,Zied Bouraoui*

Main category: cs.CL

TL;DR: 提出基于人类略读策略的自监督对比学习框架，通过随机掩码文档段落并使用NLI对比目标来增强长文档表示，在法学和生物医学文本上取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在处理长文档（如法律和医学文本）时存在困难，稀疏注意力机制资源消耗大且难以捕获完整文档上下文，分层Transformer模型效率虽好但无法清晰解释文档不同部分的关系。受人类略读策略启发，需要开发更高效的长文档表示方法。

Method: 提出自监督对比学习框架：1）随机掩码文档的一个段落；2）使用基于自然语言推理（NLI）的对比学习目标，将掩码段落与相关部分对齐，同时与不相关部分保持距离；3）模拟人类信息综合过程，生成更丰富且计算效率更高的文档表示。

Result: 在法学和生物医学文本上的实验验证了该方法在准确性和效率方面的显著提升。

Conclusion: 受人类略读策略启发的自监督对比学习框架能够有效增强长文档表示，在保持计算效率的同时提升模型性能，为法律和医学等领域的长文档处理提供了新思路。

Abstract: Although transformer-based models have shown strong performance in word- and sentence-level tasks, effectively representing long documents, especially in fields like law and medicine, remains difficult. Sparse attention mechanisms can handle longer inputs, but are resource-intensive and often fail to capture full-document context. Hierarchical transformer models offer better efficiency but do not clearly explain how they relate different sections of a document. In contrast, humans often skim texts, focusing on important sections to understand the overall message. Drawing from this human strategy, we introduce a new self-supervised contrastive learning framework that enhances long document representation. Our method randomly masks a section of the document and uses a natural language inference (NLI)-based contrastive objective to align it with relevant parts while distancing it from unrelated ones. This mimics how humans synthesize information, resulting in representations that are both richer and more computationally efficient. Experiments on legal and biomedical texts confirm significant gains in both accuracy and efficiency.

</details>


### [42] [Comparing Approaches to Automatic Summarization in Less-Resourced Languages](https://arxiv.org/abs/2512.24410)
*Chester Palen-Michel,Constantine Lignos*

Main category: cs.CL

TL;DR: 该研究比较了低资源语言自动文本摘要的多种方法，发现多语言微调的mT5模型在大多数指标上优于零样本LLM方法，且LLM作为评估器在低资源语言上可能不太可靠。


<details>
  <summary>Details</summary>
Motivation: 自动文本摘要在英语等高资源语言中已取得高性能，但对低资源语言的摘要研究相对较少。本研究旨在探索和比较低资源语言文本摘要的不同方法。

Method: 比较了多种方法：1) 不同规模LLM的零样本提示；2) 使用三种数据增强方法和多语言迁移对mT5等小模型进行微调；3) LLM翻译管道方法（源语言→英语→摘要→翻译回源语言）。使用五种不同指标进行评估。

Result: 1) 相似参数规模的LLM性能存在差异；2) 多语言微调的mT5基线在大多数指标上优于包括零样本LLM在内的大多数其他方法；3) LLM作为评估器在低资源语言上可能不太可靠。

Conclusion: 对于低资源语言文本摘要，多语言微调的小模型（如mT5）是比零样本LLM更有效的解决方案，且需要更可靠的评估方法来评估低资源语言摘要质量。

Abstract: Automatic text summarization has achieved high performance in high-resourced languages like English, but comparatively less attention has been given to summarization in less-resourced languages. This work compares a variety of different approaches to summarization from zero-shot prompting of LLMs large and small to fine-tuning smaller models like mT5 with and without three data augmentation approaches and multilingual transfer. We also explore an LLM translation pipeline approach, translating from the source language to English, summarizing and translating back. Evaluating with five different metrics, we find that there is variation across LLMs in their performance across similar parameter sizes, that our multilingual fine-tuned mT5 baseline outperforms most other approaches including zero-shot LLM performance for most metrics, and that LLM as judge may be less reliable on less-resourced languages.

</details>


### [43] [Cleaning English Abstracts of Scientific Publications](https://arxiv.org/abs/2512.24459)
*Michael E. Rose,Nils A. Herrmann,Sebastian Erhardt*

Main category: cs.CL

TL;DR: 开发开源语言模型清理科学摘要中的无关信息，提升下游分析质量


<details>
  <summary>Details</summary>
Motivation: 科学摘要常包含版权声明、章节标题、作者注释等无关信息，这些信息会扭曲文档相似性和文本嵌入分析

Method: 开发开源、易于集成的语言模型，自动识别和清理英文科学摘要中的无关内容

Result: 模型表现保守且精确，改变了清理后摘要的相似性排名，提升了标准长度嵌入的信息含量

Conclusion: 该模型能有效清理科学摘要中的无关信息，改善下游文本分析任务的质量

Abstract: Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.

</details>


### [44] [IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback](https://arxiv.org/abs/2512.24460)
*Titas Ramancauskas,Kotryna Ramancauske*

Main category: cs.CL

TL;DR: 开发了一个针对雅思写作考试的智能修订平台，采用基于设计的研究方法，从规则系统升级到Transformer模型，提供个性化反馈并显著提升考生成绩。


<details>
  <summary>Details</summary>
Motivation: 传统的雅思备考方法缺乏针对雅思写作评分标准的个性化反馈，考生难以获得针对性的指导来提升写作能力。

Method: 采用基于设计的研究方法，通过迭代开发：早期使用规则系统，后期升级为DistilBERT Transformer模型加回归头进行自动评分，并实现自适应反馈功能。平台架构分离对话指导和写作界面以降低认知负荷。

Result: Transformer模型显著提升评分准确性（MAE=0.66，R²为正）。自适应反馈使考生成绩平均提升0.06个分数段（p=0.011，Cohen's d=0.504），但效果因修订策略而异。保守的表面修正比激进的结枃干预更可靠。

Conclusion: 自动反馈功能最适合作为人工教学的补充工具。对于雅思备考，保守的表面修正比激进的结枃干预更有效。未来需解决高分作文评估的挑战，并开展长期研究和官方考官验证。

Abstract: This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.
  Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.

</details>


### [45] [Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech](https://arxiv.org/abs/2512.24517)
*Fabian Retkowski,Alexander Waibel*

Main category: cs.CL

TL;DR: 本文提出语音转录文本的段落分割任务，创建了两个基准数据集，开发了约束解码方法，并构建了高效的分割模型MiniSeg。


<details>
  <summary>Details</summary>
Motivation: 自动语音转录通常生成无结构的单词流，降低了可读性和再利用性。当前语音处理领域缺乏段落分割这一关键后处理步骤，且文本分割领域也缺少鲁棒、自然的基准数据集。

Method: 1) 创建TEDPara（人工标注的TED演讲）和YTSegPara（带合成标签的YouTube视频）两个基准数据集；2) 提出约束解码方法，让大语言模型插入段落分隔符同时保留原始转录文本；3) 开发紧凑模型MiniSeg实现最先进精度，并通过层次化扩展联合预测章节和段落。

Result: 建立了语音处理中段落分割的首个标准化基准，提出的MiniSeg模型在准确率上达到最先进水平，且计算成本低。层次化扩展能有效联合预测章节和段落。

Conclusion: 本文的资源和方法将段落分割确立为语音处理中标准化、实用的任务，填补了语音处理与文本分割交叉领域的空白。

Abstract: Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.

</details>


### [46] [Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs](https://arxiv.org/abs/2512.24556)
*Muhammad Abdullahi Said,Muhammad Sammani Sani*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在多语言安全对齐中存在复杂干扰机制，而非简单的低资源语言性能下降。模型在豪萨语和英语中表现出反向语言安全差异，同时存在严重的时间框架不对称性，导致安全性能在不同情境下波动巨大。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型融入全球关键基础设施，当前普遍假设安全对齐能够从英语零样本迁移到其他语言，这是一个危险的盲点。研究旨在系统审计主流模型在多语言环境下的安全性能，特别是在西非威胁场景中的表现。

Method: 使用HausaSafety新颖对抗数据集，基于西非威胁场景（如Yahoo-Yahoo欺诈、Dane gun制造）。采用2×4因子设计，在1,440次评估中测试语言（英语vs豪萨语）和时间框架之间的非线性交互作用。评估三个先进模型：GPT-5.1、Gemini 3 Pro和Claude 4.5 Opus。

Result: 发现复杂干扰机制而非简单的多语言安全差距：Claude 4.5 Opus在豪萨语中更安全（45.0%）vs英语（36.7%），但存在灾难性的时间推理失败。存在显著的时间不对称性：过去时框架绕过防御（15.6%安全），未来时场景触发过度保守拒绝（57.2%安全）。最安全与最脆弱配置间存在9.2倍差异。

Conclusion: 当前模型依赖表面启发式而非稳健语义理解，形成"安全口袋"，使全球南方用户面临本地化伤害风险。需要向"不变对齐"范式转变，确保跨语言和时间变化的安全稳定性。

Abstract: As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1,440 evaluations, we tested the non-linear interaction between language (English vs. Hausa) and temporal framing. Our results challenge the prevailing multilingual safety gap narrative. Instead of a simple degradation in low-resource settings, we identified a mechanism of Complex Interference where safety is determined by the intersection of variables. While models exhibited a Reverse Linguistic with Claude 4.5 Opus proving significantly safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal they suffered catastrophic failures in temporal reasoning. We report a profound Temporal Asymmetry, where past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). The magnitude of this volatility is illustrated by a 9.2x disparity between the safest and most vulnerable configurations, proving that safety is not a fixed property but a context-dependent state. We conclude that current models rely on superficial heuristics rather than robust semantic understanding, creating Safety Pockets that leave Global South users exposed to localized harms. We propose Invariant Alignment as a necessary paradigm shift to ensure safety stability across linguistic and temporal shifts.

</details>


### [47] [HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering](https://arxiv.org/abs/2512.24562)
*Chaodong Tong,Qi Zhang,Jiayang Gao,Lei Jiang,Yanbing Liu,Nannan Sun*

Main category: cs.CL

TL;DR: HaluNet是一个轻量级可训练的神经网络框架，通过集成多粒度token级不确定性来检测LLM幻觉，结合语义嵌入与概率置信度和分布不确定性，实现高效的单次幻觉检测。


<details>
  <summary>Details</summary>
Motivation: LLM在问答中经常产生幻觉（事实错误或虚构内容），现有方法通常只关注单一类型的不确定性，忽视了不同来源不确定性之间的互补性，特别是token级概率不确定性和内部语义表示不确定性之间的互补关系。

Method: 提出HaluNet框架，集成多粒度token级不确定性，结合语义嵌入与概率置信度和分布不确定性，采用多分支架构自适应融合模型已知信息与其输出中表达的不确定性，实现高效的单次幻觉检测。

Result: 在SQuAD、TriviaQA和Natural Questions数据集上的实验表明，HaluNet提供了强大的检测性能和良好的计算效率，无论是否访问上下文，都表现出色，突显了其在LLM问答系统中实时幻觉检测的潜力。

Conclusion: HaluNet通过有效整合互补的不确定性信号，为LLM幻觉检测提供了一个轻量级、高效的解决方案，具有实际部署的潜力。

Abstract: Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \textbf{HaluNet}, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.

</details>


### [48] [Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities](https://arxiv.org/abs/2512.24572)
*Hongseok Oh,Wonseok Hwang,Kyoung-Woon On*

Main category: cs.CL

TL;DR: KCL是一个韩国法律推理基准，包含选择题和开放式问题，提供判例支持以分离推理能力与领域知识，评估显示专业模型优于通用模型


<details>
  <summary>Details</summary>
Motivation: 评估语言模型的法律推理能力，独立于领域特定知识，提供更准确的能力评估

Method: 构建KCL基准，包含选择题(KCL-MCQA)和开放式问题(KCL-Essay)，提供问题级支持判例，使用自动化评估标准

Result: 评估30多个模型显示仍有较大差距，特别是在开放式问题上，推理专用模型始终优于通用模型

Conclusion: KCL基准有效评估法律推理能力，资源已开源，为未来研究提供基础

Abstract: We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models' legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at https://github.com/lbox-kr/kcl.

</details>


### [49] [Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time](https://arxiv.org/abs/2512.24574)
*Zhenyu Zhang,Xiaoxia Wu,Zhongzhu Zhou,Qingyang Wu,Yineng Zhang,Pragaash Ponnusamy,Harikaran Subbaraj,Jue Wang,Shuaiwen Leon Song,Ben Athiwaratkun*

Main category: cs.CL

TL;DR: CREST：一种无需训练的方法，通过干预注意力头来引导LLM推理轨迹，提高准确性并减少计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖长思维链推理，但存在效率低下、延迟高、推理不稳定（思维不足或过度思考）的问题，需要更高效可靠的推理方法

Method: CREST包含两个组件：1）离线校准步骤识别认知头并推导头特定引导向量；2）推理时旋转隐藏表示以抑制这些向量分量，自适应抑制低效推理行为

Result: 在多样化推理基准测试和模型中，CREST将准确率提升高达17.5%，同时减少37.6%的token使用，实现更快更可靠的LLM推理

Conclusion: CREST通过干预特定注意力头来引导推理轨迹，提供了一种简单有效的途径来提升LLM推理的效率和可靠性，无需额外训练

Abstract: Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct cognitive behaviors such as verification and backtracking. By lightly intervening on these heads at inference time, we can steer the model away from inefficient modes. Building on this insight, we propose CREST, a training-free method for Cognitive REasoning Steering at Test-time. CREST has two components: (1) an offline calibration step that identifies cognitive heads and derives head-specific steering vectors, and (2) an inference-time procedure that rotates hidden representations to suppress components along those vectors. CREST adaptively suppresses unproductive reasoning behaviors, yielding both higher accuracy and lower computational cost. Across diverse reasoning benchmarks and models, CREST improves accuracy by up to 17.5% while reducing token usage by 37.6%, offering a simple and effective pathway to faster, more reliable LLM reasoning.

</details>


### [50] [Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models](https://arxiv.org/abs/2512.24618)
*Junru Lu,Jiarui Qin,Lingfeng Qiao,Yinghui Li,Xinyi Dai,Bo Ke,Jianfeng He,Ruizhi Qiao,Di Yin,Xing Sun,Yunsheng Wu,Yinsong Liu,Shuangyin Liu,Mingkong Tang,Haodong Lin,Jiayi Kuang,Fanxu Meng,Xiaojuan Tang,Yunjia Xi,Junjie Huang,Haotong Yang,Zhenyi Shen,Yangning Li,Qianwen Zhang,Yifei Yu,Siyu An,Junnan Dong,Qiufeng Wang,Jie Wang,Keyu Chen,Wei Wen,Taian Guo,Zhifeng Shen,Daohai Yu,Jiahao Li,Ke Li,Zongyi Li,Xiaoyu Tan*

Main category: cs.CL

TL;DR: Youtu-LLM是一个1.96B参数的轻量级语言模型，通过从头预训练而非蒸馏，在长上下文支持、多阶段课程训练和可扩展的智能体训练方面取得技术突破，在sub-2B模型中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前小型语言模型通常依赖蒸馏技术，缺乏真正的推理和规划能力。作者希望开发一个轻量级但具有原生智能体能力的模型，能够在有限计算资源下处理长视野的智能体和推理任务。

Method: 1. 采用密集多潜在注意力（MLA）架构和STEM导向词表，支持128k上下文窗口；2. 使用约11T tokens的大规模语料，实施"常识-STEM-智能体"多阶段课程训练策略；3. 针对智能体训练，采用多样化数据构建方案合成数学、编程和工具使用领域的轨迹数据。

Result: Youtu-LLM在sub-2B LLMs中达到新的SOTA水平。在通用基准测试中与更大模型竞争，在智能体特定任务上显著超越现有SOTA基线，证明轻量级模型可以具备强大的内在智能体能力。

Conclusion: 通过系统化的架构设计和训练策略，轻量级语言模型可以具备强大的推理和规划能力，而不仅仅是依赖蒸馏技术。Youtu-LLM展示了在有限参数规模下实现高效智能体智能的可行性。

Abstract: We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities. The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window. This design enables robust long-context reasoning and state tracking within a minimal memory footprint, making it ideal for long-horizon agent and reasoning tasks. (2) Principled "Commonsense-STEM-Agent" Curriculum: We curated a massive corpus of approximately 11T tokens and implemented a multi-stage training strategy. By progressively shifting the pre-training data distribution from general commonsense to complex STEM and agentic tasks, we ensure the model acquires deep cognitive abilities rather than superficial alignment. (3) Scalable Agentic Mid-training: Specifically for the agentic mid-training, we employ diverse data construction schemes to synthesize rich and varied trajectories across math, coding, and tool-use domains. This high-quality data enables the model to internalize planning and reflection behaviors effectively. Extensive evaluations show that Youtu-LLM sets a new state-of-the-art for sub-2B LLMs. On general benchmarks, it achieves competitive performance against larger models, while on agent-specific tasks, it significantly surpasses existing SOTA baselines, demonstrating that lightweight models can possess strong intrinsic agentic capabilities.

</details>


### [51] [Do Large Language Models Know What They Are Capable Of?](https://arxiv.org/abs/2512.24661)
*Casey O. Barkan,Sid Black,Oliver Sourbut*

Main category: cs.CL

TL;DR: 大型语言模型在预测自身任务成功率方面普遍过度自信，尽管大多数模型具有优于随机的判别能力。随着多步骤任务进展，前沿模型的过度自信会加剧，而上下文失败经验只能部分改善决策质量。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能准确预测自身在任务中的成功率，以及这种预测能力是否会随着多步骤任务进展而改善。同时探讨LLMs能否从上下文失败经验中学习，在失败成本高的场景中做出更好的决策。

Method: 测试多种LLMs预测任务成功率的能力，包括在多步骤任务中跟踪预测变化，以及在提供上下文失败经验后观察决策改进情况。评估模型判别能力、过度自信程度和决策理性。

Result: 所有测试的LLMs都表现出过度自信，但大多数具有优于随机的判别能力。更新更大的模型不一定有更好判别能力（Claude除外）。在多步骤任务中，前沿LLMs的过度自信随任务进展而恶化，推理模型表现不优于非推理模型。上下文失败经验只能部分减少过度自信，改善决策。所有LLMs的决策在给定其估计成功率下是近似理性的，但过度乐观的估计导致决策质量差。

Conclusion: 当前LLM智能体受限于对自身能力缺乏认知，这影响了决策质量。研究结果对AI滥用和错位风险有重要启示，表明需要提升LLMs的自我认知能力。

Abstract: We investigate whether large language models (LLMs) can predict whether they will succeed on a given task and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLMs generally do not have greater discriminatory power, though Claude models do show such a trend. On multi-step agentic tasks, the overconfidence of several frontier LLMs worsens as they progress through the tasks, and reasoning LLMs perform comparably to or worse than non-reasoning LLMs. With in-context experiences of failure, some but not all LLMs reduce their overconfidence leading to significantly improved decision making, while others do not. Interestingly, all LLMs' decisions are approximately rational given their estimated probabilities of success, yet their overly-optimistic estimates result in poor decision making. These results suggest that current LLM agents are hindered by their lack of awareness of their own capabilities. We discuss the implications of LLMs' awareness of their capabilities for AI misuse and misalignment risks.

</details>


### [52] [R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory](https://arxiv.org/abs/2512.24684)
*Maoyuan Li,Zhongsheng Wang,Haoyuan Li,Jiamou Liu*

Main category: cs.CL

TL;DR: R-Debater是一个基于论证记忆的智能体框架，用于生成多轮辩论，通过检索先验论据和证据来保持立场一致性、回应对手并支持主张。


<details>
  <summary>Details</summary>
Motivation: 现有辩论系统在跨轮次保持立场一致性、有效回应对手以及基于证据支持主张方面存在不足。受修辞学和记忆研究启发，需要开发一个能够回忆和调整先验论据的框架来生成更连贯、一致的辩论。

Method: R-Debater整合了辩论知识库（用于检索类似案例的证据和先前辩论动作）和基于角色的智能体（用于跨轮次组合连贯话语）。系统在ORCHID标准辩论数据集上进行评估，构建了包含1000项检索语料库和32场跨7个领域辩论的测试集。

Result: 相比强大的LLM基线，R-Debater在单轮（通过InspireScore评估：主观、逻辑、事实性）和多轮（通过Debatrix评估：论证、来源、语言、整体）任务上都获得了更高分数。20位经验丰富的辩论者参与的人类评估进一步证实了其一致性和证据使用能力。

Conclusion: 结合检索基础和结构化规划的R-Debater能够生成更忠实、立场对齐且跨轮次连贯的辩论，展示了论证记忆在提升辩论系统质量方面的价值。

Abstract: We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.

</details>


### [53] [MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models](https://arxiv.org/abs/2512.24693)
*Wenzhe Li,Shujian Zhang,Wenxuan Zhou,John Lambert,Chi Jin,Andrew Hard,Rajiv Mathews,Lun Wang*

Main category: cs.CL

TL;DR: 提出MUSIC数据增强策略，通过多轮对话对比训练提升多轮奖励模型性能，在Skywork数据集上基于Gemma-2-9B-Instruct模型训练，在多轮对话评估中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 多轮对话质量评估对LLM发展至关重要，但依赖昂贵的人工评估。现有标准偏好数据集通常只基于最终轮次进行对比，无法捕捉多轮交互的细微差别，需要更好的多轮评估方法。

Method: 提出MUSIC（多步指令对比）无监督数据增强策略，通过合成跨多个轮次存在差异的对比对话对。在Skywork偏好数据集上应用MUSIC，基于Gemma-2-9B-Instruct模型训练多轮奖励模型。

Result: MUSIC增强的奖励模型在多项评估中优于基线方法：1）与先进专有LLM评判在多轮对话评估中更一致；2）在标准单轮奖励模型基准测试中性能不降低。

Conclusion: 跨多个轮次的对比对于构建鲁棒的多轮奖励模型至关重要。MUSIC策略能有效提升多轮对话评估质量，为LLM训练提供有价值的信号，同时保持单轮评估性能。

Abstract: Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \textit{training} techniques, effective automated \textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \textbf{MU}lti-\textbf{S}tep \textbf{I}nstruction \textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.

</details>


### [54] [BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature](https://arxiv.org/abs/2512.24733)
*Sibo Wei,Peng Chen,Lifeng Dong,Yin Luo,Lei Wang,Peng Zhang,Wenpeng Lu,Jianbin Guo,Hongjun Yang,Dajun Zeng*

Main category: cs.CL

TL;DR: BIOME-Bench：首个用于评估LLM在多组学分析中生物分子交互推断和通路机制解析能力的标准化基准，发现现有模型在精细关系区分和通路级机制解释方面仍有显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前多组学研究依赖通路富集分析，但传统方法存在通路资源的结构性限制（如更新滞后、功能冗余、对分子状态和干预的敏感性有限）。虽然已有研究探索使用LLM改进通路富集解释，但缺乏端到端多组学通路机制解析的标准化基准，阻碍了可重复性进展。

Method: 通过四阶段严谨工作流程构建BIOME-Bench基准，评估LLM在多组学分析中的两个核心能力：1）生物分子交互推断；2）端到端多组学通路机制解析。开发了两种任务的评估协议，并在多个当代强模型上进行全面实验。

Result: 实验结果表明，现有模型在多组学分析中仍存在显著缺陷：难以可靠区分精细粒度的生物分子关系类型，也无法生成忠实、稳健的通路级机制解释。

Conclusion: BIOME-Bench为评估和改进LLM在多组学分析中的能力提供了标准化基准，揭示了当前模型的局限性，为未来研究指明了方向。

Abstract: Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.

</details>


### [55] [Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection](https://arxiv.org/abs/2512.24772)
*Mohammad Zia Ur Rehman,Velpuru Navya,Sanskar,Shuja Uddin Qureshi,Nagendra Kumar*

Main category: cs.CL

TL;DR: 提出Semi-SMDNet半监督多语言抑郁症检测网络，结合教师-学生伪标签、集成学习和数据增强，在资源有限的多语言社交媒体文本中提升抑郁症检测性能


<details>
  <summary>Details</summary>
Motivation: 社交媒体文本的抑郁症检测面临语言风格多样、表达非正式、标注数据稀缺等挑战，特别是在多语言环境下资源有限的情况

Method: 使用教师模型组进行软投票预测，基于不确定性的阈值过滤低置信度伪标签，采用置信度加权训练方法，结合集成学习和数据增强

Result: 在阿拉伯语、孟加拉语、英语和西班牙语数据集上均优于基线方法，显著缩小了资源丰富与资源匮乏设置之间的性能差距

Conclusion: 该框架在多语言心理健康监测中具有有效性和可扩展性，特别适用于标注资源有限的实际应用场景

Abstract: Detecting depression from social media text is still a challenging task. This is due to different language styles, informal expression, and the lack of annotated data in many languages. To tackle these issues, we propose, Semi-SMDNet, a strong Semi-Supervised Multilingual Depression detection Network. It combines teacher-student pseudo-labelling, ensemble learning, and augmentation of data. Our framework uses a group of teacher models. Their predictions come together through soft voting. An uncertainty-based threshold filters out low-confidence pseudo-labels to reduce noise and improve learning stability. We also use a confidence-weighted training method that focuses on reliable pseudo-labelled samples. This greatly boosts robustness across languages. Tests on Arabic, Bangla, English, and Spanish datasets show that our approach consistently beats strong baselines. It significantly reduces the performance gap between settings that have plenty of resources and those that do not. Detailed experiments and studies confirm that our framework is effective and can be used in various situations. This shows that it is suitable for scalable, cross-language mental health monitoring where labelled resources are limited.

</details>


### [56] [Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models](https://arxiv.org/abs/2512.24776)
*Ákos Prucs,Márton Csutora,Mátyás Antal,Márk Marosi*

Main category: cs.CL

TL;DR: 论文对LLMs进行推理时间计算感知评估，发现MoE架构在性能与效率间取得最佳平衡，并揭示推理计算存在饱和点


<details>
  <summary>Details</summary>
Motivation: 当前研究常忽视长推理序列生成的计算负担，工业应用需在准确率、资源约束和推理成本间权衡

Method: 对当代和早期开源LLMs进行推理时间计算感知评估，绘制在数学和推理密集型基准上的帕累托前沿

Result: 发现MoE架构在性能与效率平衡方面表现最佳；识别推理计算饱和点，超过阈值后准确率增益递减

Conclusion: MoE架构是平衡性能与效率的强候选方案，推理计算存在收益递减点，扩展推理能力无法克服模型固有局限性

Abstract: Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with generating long reasoning sequences. For industrial applications, model selection depends not only on raw accuracy but also on resource constraints and inference costs. In this work, we conduct a test-time-compute aware evaluation of both contemporary and older open-source LLMs, mapping their Pareto frontiers across math- and reasoning-intensive benchmarks. Our findings identify the Mixture of Experts (MoE) architecture as a strong candidate to balance performance and efficiency in our evaluation setting. Furthermore, we trace the trajectory of Pareto efficiency over time to derive an emergent trend regarding accuracy gain per unit of compute. Finally, we demonstrate that there is a saturation point for inference-time compute. Beyond a certain threshold, accuracy gains diminish, indicating that while extended reasoning capabilities are beneficial, they cannot overcome intrinsic model limitations regarding specific complexities.

</details>


### [57] [Practising responsibility: Ethics in NLP as a hands-on course](https://arxiv.org/abs/2512.24825)
*Malvina Nissim,Viviana Patti,Beatrice Savoldi*

Main category: cs.CL

TL;DR: 介绍NLP伦理课程的教学方法与实践经验，强调通过主动学习、互动活动和"以教促学"的方式培养批判性思维，课程已跨机构、跨学科实施四年并产生可复用教学资源。


<details>
  <summary>Details</summary>
Motivation: 随着NLP系统日益普及，将伦理考量融入NLP教育变得至关重要。但课程开发面临挑战：领域快速演变（来自学术界和产业界），以及需要超越传统技术培训培养批判性思维。

Method: 采用基于主动学习的教学法，包括互动式课程、实践活动和"以教促学"方法。课程经过四年在不同机构、教育层次和跨学科背景下的精炼与调整。

Result: 课程产生了许多可复用产品，包括教学材料和面向不同受众的实际教育产品（由学生制作）。课程成功跨多个教育环境和背景实施。

Conclusion: 通过分享教学方法和经验，希望为寻求将社会影响考量融入课程的教育工作者提供启发，推动NLP伦理教育的普及。

Abstract: As Natural Language Processing (NLP) systems become more pervasive, integrating ethical considerations into NLP education has become essential. However, this presents inherent challenges in curriculum development: the field's rapid evolution from both academia and industry, and the need to foster critical thinking beyond traditional technical training. We introduce our course on Ethical Aspects in NLP and our pedagogical approach, grounded in active learning through interactive sessions, hands-on activities, and "learning by teaching" methods. Over four years, the course has been refined and adapted across different institutions, educational levels, and interdisciplinary backgrounds; it has also yielded many reusable products, both in the form of teaching materials and in the form of actual educational products aimed at diverse audiences, made by the students themselves. By sharing our approach and experience, we hope to provide inspiration for educators seeking to incorporate social impact considerations into their curricula.

</details>


### [58] [PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI](https://arxiv.org/abs/2512.24848)
*Srija Mukhopadhyay,Sathwik Reddy,Shruthi Muthukumar,Jisun An,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: PrivacyBench基准测试揭示RAG助手在对话中泄露用户秘密高达26.56%，隐私提示可降低至5.12%，但当前架构仍不安全


<details>
  <summary>Details</summary>
Motivation: 个性化AI代理需要访问用户数字足迹（包含敏感数据），但缺乏社会情境意识的系统可能无意中泄露用户秘密，威胁数字福祉和隐私安全

Method: 引入PrivacyBench基准，包含社会情境数据集（嵌入秘密）和多轮对话评估，测试检索增强生成（RAG）助手的秘密保护能力

Result: RAG助手在高达26.56%的交互中泄露秘密；隐私感知提示可将泄露率降至5.12%，但检索机制仍会无差别访问敏感数据，将隐私保护负担完全转移到生成器上

Conclusion: 当前架构存在单点故障风险，不适合大规模部署，迫切需要结构化的隐私设计保障措施，以确保为所有人提供道德和包容的网络环境

Abstract: Personalized AI agents rely on access to a user's digital footprint, which often includes sensitive data from private emails, chats and purchase histories. Yet this access creates a fundamental societal and privacy risk: systems lacking social-context awareness can unintentionally expose user secrets, threatening digital well-being. We introduce PrivacyBench, a benchmark with socially grounded datasets containing embedded secrets and a multi-turn conversational evaluation to measure secret preservation. Testing Retrieval-Augmented Generation (RAG) assistants reveals that they leak secrets in up to 26.56% of interactions. A privacy-aware prompt lowers leakage to 5.12%, yet this measure offers only partial mitigation. The retrieval mechanism continues to access sensitive data indiscriminately, which shifts the entire burden of privacy preservation onto the generator. This creates a single point of failure, rendering current architectures unsafe for wide-scale deployment. Our findings underscore the urgent need for structural, privacy-by-design safeguards to ensure an ethical and inclusive web for everyone.

</details>


### [59] [Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements](https://arxiv.org/abs/2512.24867)
*Yiming Liang,Yizhi Li,Yantao Du,Ge Zhang,Jiayi Zhou,Yuchen Wu,Yinzhu Piao,Denghui Cao,Tong Sun,Ziniu Li,Li Du,Bo Lei,Jiaheng Liu,Chenghua Lin,Zhaoxiang Zhang,Wenhao Huang,Jiajun Zhang*

Main category: cs.CL

TL;DR: Encyclo-K是一个基于知识陈述的动态评测基准，通过从权威教材提取独立知识陈述并在测试时随机组合成问题，解决了传统基准的数据污染、单知识点评估和专家标注成本高等问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准存在三个根本性局限：1) 易受数据污染影响；2) 仅限于单知识点评估；3) 依赖昂贵的领域专家标注。需要一种新的基准构建方法来克服这些限制。

Method: 从权威教材中提取独立的知识陈述作为基本单元，在测试时通过随机采样动态组合成评估问题（每个问题聚合8-10个陈述）。标注者只需验证格式合规性，无需领域专业知识。

Result: 在50多个LLM上的实验显示，Encyclo-K具有强大的区分能力。表现最好的OpenAI-GPT-5.1仅达到62.07%准确率。推理模型准确率在16.04%到62.07%之间，聊天模型在9.71%到50.40%之间，呈现清晰的梯度分布。

Conclusion: Encyclo-K通过动态评估和多陈述综合理解，为LLM在多学科细粒度知识陈述上的综合理解提供了一个可扩展的动态评估框架，有效解决了传统基准的局限性。

Abstract: Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution--reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs' comprehensive understanding over multiple fine-grained disciplinary knowledge statements.

</details>


### [60] [mHC: Manifold-Constrained Hyper-Connections](https://arxiv.org/abs/2512.24880)
*Zhenda Xie,Yixuan Wei,Huanqi Cao,Chenggang Zhao,Chengqi Deng,Jiashi Li,Damai Dai,Huazuo Gao,Jiang Chang,Liang Zhao,Shangyan Zhou,Zhean Xu,Zhengyan Zhang,Wangding Zeng,Shengding Hu,Yuqing Wang,Jingyang Yuan,Lean Wang,Wenfeng Liang*

Main category: cs.CL

TL;DR: mHC通过将超连接的残差空间投影到特定流形来恢复恒等映射特性，解决了HC训练不稳定和可扩展性受限的问题，同时优化基础设施确保效率。


<details>
  <summary>Details</summary>
Motivation: 超连接（HC）虽然提升了性能，但破坏了残差连接的恒等映射特性，导致训练不稳定、可扩展性受限和内存访问开销大。

Method: 提出流形约束超连接（mHC），将HC的残差连接空间投影到特定流形以恢复恒等映射特性，并进行严格的基础设施优化确保效率。

Result: mHC在规模化训练中有效，提供了实质性的性能改进和优越的可扩展性。

Conclusion: mHC作为HC的灵活实用扩展，有助于深入理解拓扑架构设计，为基础模型的演进指明了有前景的方向。

Abstract: Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.

</details>


### [61] [BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts](https://arxiv.org/abs/2512.24885)
*Hengli Li,Zhaoxin Yu,Qi Shen,Chenxi Li,Mengmeng Wang,Tinglang Wu,Yipeng Kang,Yuxuan Wang,Song-Chun Zhu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: BEDA框架通过将信念估计转化为生成约束，在战略对话中显著提升了性能，在对抗、合作和谈判三种设置下均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有战略对话系统虽然能准确估计信念，但缺乏使用这些信念进行生成的机制。需要建立将信念估计与对话生成相结合的原则性方法。

Method: 提出BEDA框架：形式化对抗和对齐两种核心对话行为，通过概率约束将信念估计转化为生成约束。框架包括世界集合、信念估计器和条件生成器，后者根据推断的信念选择行为并生成一致的语句。

Result: 在三种设置下均优于强基线：在CKBG（对抗）中成功率提升至少5.0点，GPT-4.1-nano下提升20.6点；在Mutual Friends（合作）中平均提升9.3点；在CaSiNo（谈判）中达到相对于所有基线的最优交易。

Conclusion: 将信念估计转化为约束为可靠的战略对话提供了简单通用的机制，表明信念约束是提升战略对话性能的有效方法。

Abstract: Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.

</details>


### [62] [Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline](https://arxiv.org/abs/2512.24933)
*Minjun Zhao,Xinyu Zhang,Shuai Zhang,Deyang Li,Ruifeng Shi*

Main category: cs.CL

TL;DR: ADOPT是一个用于多步LLM流程的自适应依赖感知提示优化框架，通过建模步骤间依赖关系实现精确的文本梯度估计，显著提升复杂任务性能。


<details>
  <summary>Details</summary>
Motivation: 多步LLM流程的性能严重依赖每一步的提示，但联合优化这些提示很困难，因为缺乏步骤级监督和步骤间依赖关系。现有的端到端优化方法在这些条件下效果不佳。

Method: ADOPT明确建模每个LLM步骤与最终任务结果之间的依赖关系，实现类似计算解析导数的精确文本梯度估计。它将文本梯度估计与梯度更新解耦，将多提示优化简化为灵活的单提示优化步骤，并使用基于Shapley值的机制自适应分配优化资源。

Result: 在真实世界数据集和多样化流程结构上的实验表明，ADOPT有效且稳健，始终优于最先进的提示优化基线方法。

Conclusion: ADOPT通过建模步骤间依赖关系和实现精确梯度估计，为多步LLM流程的提示优化提供了一个强大而稳健的解决方案。

Abstract: Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter-step dependencies. Existing end-to-end prompt optimization methods struggle under these conditions and often yield suboptimal or unstable updates. We propose ADOPT, an Adaptive Dependency-aware Prompt Optimization framework for multi-step LLM pipelines. ADOPT explicitly models the dependency between each LLM step and the final task outcome, enabling precise text-gradient estimation analogous to computing analytical derivatives. It decouples textual gradient estimation from gradient updates, reducing multi-prompt optimization to flexible single-prompt optimization steps, and employs a Shapley-based mechanism to adaptively allocate optimization resources. Experiments on real-world datasets and diverse pipeline structures show that ADOPT is effective and robust, consistently outperforming state-of-the-art prompt optimization baselines.

</details>


### [63] [Classifying long legal documents using short random chunks](https://arxiv.org/abs/2512.24997)
*Luis Adrián Cabrera-Diego*

Main category: cs.CL

TL;DR: 提出基于DeBERTa V3和LSTM的法律文档分类器，使用48个随机短片段（最多128个token）作为输入，并部署在Temporal工作流平台上


<details>
  <summary>Details</summary>
Motivation: 法律文档分类面临专业词汇和文档长度大的挑战，直接将完整文档输入Transformer模型可能不可行、昂贵或缓慢

Method: 使用DeBERTa V3和LSTM组合模型，输入为48个随机选择的短文本块（最多128个token），并利用Temporal构建可靠的部署流水线

Result: 最佳模型加权F分数为0.898，在CPU上运行的流水线处理100个文件的平均时间为498秒

Conclusion: 该方法有效解决了长法律文档分类问题，通过片段采样策略和可靠的部署流水线实现了良好的分类性能和可扩展性

Abstract: Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.

</details>


### [64] [MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes](https://arxiv.org/abs/2512.25015)
*Siddhant Agarwal,Adya Dhuler,Polly Ruhnke,Melvin Speisman,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: 提出RESTOREx数据集和MAMAMemeia框架，用于检测社交媒体表情包中的抑郁症状，基于LLM生成和人工标注的解释，性能提升7.55%


<details>
  <summary>Details</summary>
Motivation: 表情包已从单纯的幽默表达演变为用户自由表达各种情绪（包括抑郁情绪）的媒介，需要研究社交媒体表情包中抑郁症状的识别

Method: 引入RESTOREx数据集（LLM生成+人工标注解释），提出MAMAMemeia框架（基于认知分析疗法CAT的多智能体多维度讨论框架）

Result: MAMAMemeia相比现有最佳方法提升7.55%的macro-F1分数，成为新的基准，超过30种对比方法

Conclusion: 该研究为社交媒体表情包抑郁症状检测提供了重要资源和有效框架，在临床心理学方法指导下取得了显著性能提升

Abstract: Over the past years, memes have evolved from being exclusively a medium of humorous exchanges to one that allows users to express a range of emotions freely and easily. With the ever-growing utilization of memes in expressing depressive sentiments, we conduct a study on identifying depressive symptoms exhibited by memes shared by users of online social media platforms. We introduce RESTOREx as a vital resource for detecting depressive symptoms in memes on social media through the Large Language Model (LLM) generated and human-annotated explanations. We introduce MAMAMemeia, a collaborative multi-agent multi-aspect discussion framework grounded in the clinical psychology method of Cognitive Analytic Therapy (CAT) Competencies. MAMAMemeia improves upon the current state-of-the-art by 7.55% in macro-F1 and is established as the new benchmark compared to over 30 methods.

</details>


### [65] [Modeling Language as a Sequence of Thoughts](https://arxiv.org/abs/2512.25026)
*Nasim Borazjanizadeh,James McClelland*

Main category: cs.CL

TL;DR: 提出Thought Gestalt模型，这是一个双层次抽象（词元和句子级"思想"状态）的循环Transformer，通过记忆先前句子表征来提升语言建模的全局一致性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer语言模型主要依赖表层共现统计，缺乏对实体和事件的全局一致潜在表征，导致关系方向脆弱性、上下文错误和数据效率低下。受人类认知将语言流转换为紧凑事件表征的启发，需要更有效的语言建模方法。

Method: 提出Thought Gestalt模型：1）在词元和句子级"思想"状态两个抽象层次建模语言；2）循环Transformer结构，一次生成一个句子的词元，同时交叉关注先前句子表征的记忆；3）使用相同参数集生成词元和句子表征，通过单一目标（下一个词元交叉熵）训练；4）保留写入记忆的句子表征计算图，使未来词元损失的梯度通过交叉关注反向传播优化早期句子向量生成参数。

Result: 1）在扩展实验中，TG相比匹配的GPT-2运行持续提升效率，扩展拟合表明GPT-2需要多5-8%的数据和33-42%的参数才能匹配TG的损失；2）在父子反转诅咒探测任务上，TG减少了关系方向泛化错误。

Conclusion: Thought Gestalt模型通过引入句子级"思想"状态和记忆机制，有效提升了语言建模的全局一致性、数据效率和关系方向泛化能力，为构建更稳健高效的语言模型提供了新思路。

Abstract: Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level "thought" states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG's loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.

</details>


### [66] [AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG](https://arxiv.org/abs/2512.25052)
*Chao Peng,Bin Wang,Zhilei Long,Jinfang Sheng*

Main category: cs.CL

TL;DR: AdaGReS是一个用于RAG的冗余感知上下文选择框架，通过结合查询-文档相关性和集合内冗余惩罚的集合级目标，在token预算约束下进行贪心选择，无需手动调参即可自适应调整相关性与冗余的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统的top-k检索在RAG中经常返回冗余或近似重复的文档块，这会浪费token预算并降低下游生成质量。需要一种能够在token预算约束下优化上下文选择的方法。

Method: AdaGReS框架包含：1）结合查询-文档相关性和集合内冗余惩罚的集合级目标函数；2）在token预算约束下基于边际增益的贪心选择算法；3）无需手动调参的闭式自适应校准机制，根据候选池统计和预算限制自动调整相关性与冗余的权衡参数。

Result: 实验在开放域问答（Natural Questions）和高冗余生物医学（药物）语料库上显示，AdaGReS在冗余控制和上下文质量方面持续改进，转化为更好的端到端答案质量和跨设置的鲁棒性。理论分析表明该目标函数在实用嵌入相似性条件下具有epsilon-近似子模性，为贪心选择提供近最优性保证。

Conclusion: AdaGReS是一个有效的冗余感知上下文选择框架，能够自动优化相关性与冗余的权衡，在token预算约束下提高RAG系统的性能，无需手动参数调整。

Abstract: Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [67] [Extrapolating LATE with Weak IVs](https://arxiv.org/abs/2512.23854)
*Muyang Ren*

Main category: econ.EM

TL;DR: 该论文开发了弱工具变量稳健的推断方法，用于从依从者效应外推到更广泛人群，即使工具变量变异有限也能保证置信区间的有效性。


<details>
  <summary>Details</summary>
Motivation: 在评估反事实政策效果时，通常需要将依从者的处理效应外推到更广泛人群。这种外推依赖于工具变量的外生变异，但实践中工具变量往往变异有限，导致传统方法（如F检验）可能错误判断工具变量强度，产生过短的无效置信区间。

Method: 开发了弱工具变量稳健的推断理论，构建了无论识别强度如何都能保持渐近有效的置信集。该方法适用于边际处理效应的各种线性泛函，包括LATE、ATE、ATT和政策相关处理效应。

Result: 该方法提供了首个针对这类参数的弱工具变量稳健推断结果，能够产生有效的置信区间，即使工具变量变异有限。通过Agan等人（2023）的检察官宽大政策数据进行了实证应用，分析了改变检察官宽大程度对减少再犯率的影响。

Conclusion: 该研究解决了工具变量变异有限时政策评估中的推断问题，为从依从者效应外推到更广泛人群提供了可靠的统计方法，填补了弱工具变量稳健推断在该类参数领域的空白。

Abstract: To evaluate the effectiveness of a counterfactual policy, it is often necessary to extrapolate treatment effects on compliers to broader populations. This extrapolation relies on exogenous variation in instruments, which is often weak in practice. This limited variation leads to invalid confidence intervals that are typically too short and cannot be accurately detected by classical methods. For instance, the F-test may falsely conclude that the instruments are strong. Consequently, I develop inference results that are valid even with limited variation in the instruments. These results lead to asymptotically valid confidence sets for various linear functionals of marginal treatment effects, including LATE, ATE, ATT, and policy-relevant treatment effects, regardless of identification strength. This is the first paper to provide weak instrument robust inference results for this class of parameters. Finally, I illustrate my results using data from Agan, Doleac, and Harvey (2023) to analyze counterfactual policies of changing prosecutors' leniency and their effects on reducing recidivism.

</details>


### [68] [Evaluating Counterfactual Policies Using Instruments](https://arxiv.org/abs/2512.24096)
*Michal Kolesár,José Luis Montiel Olea,Jonathan Roth*

Main category: econ.EM

TL;DR: 开发了一个无需IV单调性假设的通用计算框架，用于评估反事实政策效果，并应用于保释法官和检察官的准随机分配案例


<details>
  <summary>Details</summary>
Motivation: 研究者在有工具变量(IV)的情况下，需要评估改变治疗分配的反事实政策效果（如鼓励法官释放更多被告），但传统方法依赖IV单调性假设，这一假设往往不可靠

Method: 开发了一个通用且计算可行的框架，用于计算反事实政策效果的尖锐边界，无需IV单调性假设；分析了替代限制的识别能力，包括边际处理效应文献中使用的政策不变性假设，并开发了该假设的松弛版本

Result: 对于一类重要的政策练习，IV单调性虽然对两阶段最小二乘法的因果解释至关重要，但不会收紧反事实政策影响的边界；框架应用于纽约市保释法官和马萨诸塞州检察官的准随机分配案例

Conclusion: 提供了一个无需IV单调性假设的灵活框架来评估反事实政策效果，扩展了工具变量分析在政策评估中的应用范围，特别适用于司法系统等现实政策场景

Abstract: We study settings in which a researcher has an instrumental variable (IV) and seeks to evaluate the effects of a counterfactual policy that alters treatment assignment, such as a directive encouraging randomly assigned judges to release more defendants. We develop a general and computationally tractable framework for computing sharp bounds on the effects of such policies. Our approach does not require the often tenuous IV monotonicity assumption. Moreover, for an important class of policy exercises, we show that IV monotonicity -- while crucial for a causal interpretation of two-stage least squares -- does not tighten the bounds on the counterfactual policy impact. We analyze the identifying power of alternative restrictions, including the policy invariance assumption used in the marginal treatment effect literature, and develop a relaxation of this assumption. We illustrate our framework using applications to quasi-random assignment of bail judges in New York City and prosecutors in Massachusetts.

</details>


### [69] [Testing Monotonicity in a Finite Population](https://arxiv.org/abs/2512.25032)
*Jiafeng Chen,Jonathan Roth,Jann Spiess*

Main category: econ.EM

TL;DR: 从完全随机实验中学习是否所有人都具有相同符号的处理效应（单调性）的能力在实践中受到严重限制，尽管从设计视角看这在形式上是可识别的。


<details>
  <summary>Details</summary>
Motivation: 研究从完全随机实验数据中推断处理效应单调性（即所有个体的处理效应符号相同）的可能性。传统抽样视角认为单调性不可检验，但设计视角下存在形式识别性，作者想探讨实际学习能力的限制。

Method: 采用设计基础视角（固定总体单位，仅处理分配随机），分析单调性的形式识别性。通过频率主义检验和贝叶斯更新两种框架评估数据的可学习性，考察检验功效和先验更新的可能性。

Result: 频率主义检验对某些备择假设具有非平凡功效，但功效普遍受限；存在非退化贝叶斯先验对单调性永不更新。尽管形式识别性成立，但实际学习能力严重受限。

Conclusion: 从完全随机实验数据中学习处理效应单调性的能力在实践中受到严重限制，形式识别性并不能保证实际可学习性。

Abstract: We consider the extent to which we can learn from a completely randomized experiment whether everyone has treatment effects that are weakly of the same sign, a condition we call monotonicity. From a classical sampling perspective, it is well-known that monotonicity is untestable. By contrast, we show from the design-based perspective -- in which the units in the population are fixed and only treatment assignment is stochastic -- that the distribution of treatment effects in the finite population (and hence whether monotonicity holds) is formally identified. We argue, however, that the usual definition of identification is unnatural in the design-based setting because it imagines knowing the distribution of outcomes over different treatment assignments for the same units. We thus evaluate the informativeness of the data by the extent to which it enables frequentist testing and Bayesian updating. We show that frequentist tests can have nontrivial power against some alternatives, but power is generically limited. Likewise, we show that there exist (non-degenerate) Bayesian priors that never update about whether monotonicity holds. We conclude that, despite the formal identification result, the ability to learn about monotonicity from data in practice is severely limited.

</details>


### [70] [Compound Estimation for Binomials](https://arxiv.org/abs/2512.25042)
*Yan Chen,Lihua Lei*

Main category: econ.EM

TL;DR: 提出针对二项分布数据的复合决策框架，开发近似SURE方法评估平均均方误差，建立机器学习辅助线性收缩估计量的渐近最优性、遗憾界和有效推断，避免高斯近似，适用于小样本/小均值参数场景。


<details>
  <summary>Details</summary>
Motivation: 许多应用需要估计多个二项分布结果的均值（如代际流动性、疾病流行率、点击率等）。传统简单平均方法在样本量小或均值参数小时噪声大，而经验贝叶斯方法需要先验分布且计算困难，特别是在样本量异质时缺乏联合共轭先验。

Method: 采用复合决策框架，将样本量和均值参数视为固定量。开发近似Stein无偏风险估计器(SURE)来评估任何估计器类的平均均方误差。针对机器学习辅助的线性收缩估计器类，建立渐近最优性、遗憾界和有效推断。直接处理二项分布数据，避免高斯近似。

Result: 方法能够在样本量小和/或均值参数小的情况下工作，适用于单样本和双样本设置。在三个数据集（企业歧视、教育结果、创新率）上进行了验证。

Conclusion: 提出的复合决策框架为二项分布数据的均值估计提供了有效的解决方案，克服了传统方法和经验贝叶斯方法的局限性，特别适用于小样本和小均值参数场景。

Abstract: Many applications involve estimating the mean of multiple binomial outcomes as a common problem -- assessing intergenerational mobility of census tracts, estimating prevalence of infectious diseases across countries, and measuring click-through rates for different demographic groups. The most standard approach is to report the plain average of each outcome. Despite simplicity, the estimates are noisy when the sample sizes or mean parameters are small. In contrast, the Empirical Bayes (EB) methods are able to boost the average accuracy by borrowing information across tasks. Nevertheless, the EB methods require a Bayesian model where the parameters are sampled from a prior distribution which, unlike the commonly-studied Gaussian case, is unidentified due to discreteness of binomial measurements. Even if the prior distribution is known, the computation is difficult when the sample sizes are heterogeneous as there is no simple joint conjugate prior for the sample size and mean parameter.
  In this paper, we consider the compound decision framework which treats the sample size and mean parameters as fixed quantities. We develop an approximate Stein's Unbiased Risk Estimator (SURE) for the average mean squared error given any class of estimators. For a class of machine learning-assisted linear shrinkage estimators, we establish asymptotic optimality, regret bounds, and valid inference. Unlike existing work, we work with the binomials directly without resorting to Gaussian approximations. This allows us to work with small sample sizes and/or mean parameters in both one-sample and two-sample settings. We demonstrate our approach using three datasets on firm discrimination, education outcomes, and innovation rates.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [71] [Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning](https://arxiv.org/abs/2512.24580)
*Shanyu Han,Yangbo He,Yang Liu*

Main category: q-fin.RM

TL;DR: 提出了一种结合风险敏感性和鲁棒性的强化学习新框架，通过内外双层风险度量处理状态成本和转移动态不确定性，并开发了贝叶斯动态规划算法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习框架在处理转移动态不确定性方面存在不足，需要同时考虑风险敏感性和鲁棒性。作者旨在统一和推广现有RL框架，通过双层风险度量同时处理状态/成本随机性和转移动态不确定性。

Method: 提出风险敏感鲁棒马尔可夫决策过程(RSRMDP)框架，定义内外双层相干风险度量。开发贝叶斯动态规划算法，交替进行后验更新和值迭代。使用蒙特卡洛采样与凸优化结合的估计器计算风险Bellman算子。

Result: 证明了算法的一致性和收敛性，在训练环境中收敛到接近最优策略。在Dirichlet后验和CVaR条件下分析了样本复杂度和计算复杂度。数值实验显示优秀的收敛特性，在期权对冲应用中展示了风险敏感性和鲁棒性优势。

Conclusion: 该框架统一并推广了现有RL方法，通过双层风险度量有效处理不确定性和风险。贝叶斯DP算法具有理论保证和实际应用价值，特别是在金融风险控制等需要同时考虑风险敏感性和鲁棒性的领域。

Abstract: We propose a novel framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty. We define two distinct yet coupled risk measures: an inner risk measure addressing state and cost randomness and an outer risk measure capturing transition dynamics uncertainty. Our framework unifies and generalizes most existing RL frameworks by permitting general coherent risk measures for both inner and outer risk measures. Within this framework, we construct a risk-sensitive robust Markov decision process (RSRMDP), derive its Bellman equation, and provide error analysis under a given posterior distribution. We further develop a Bayesian Dynamic Programming (Bayesian DP) algorithm that alternates between posterior updates and value iteration. The approach employs an estimator for the risk-based Bellman operator that combines Monte Carlo sampling with convex optimization, for which we prove strong consistency guarantees. Furthermore, we demonstrate that the algorithm converges to a near-optimal policy in the training environment and analyze both the sample complexity and the computational complexity under the Dirichlet posterior and CVaR. Finally, we validate our approach through two numerical experiments. The results exhibit excellent convergence properties while providing intuitive demonstrations of its advantages in both risk-sensitivity and robustness. Empirically, we further demonstrate the advantages of the proposed algorithm through an application on option hedging.

</details>


### [72] [Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach](https://arxiv.org/abs/2512.24747)
*Tim J. Boonen,Xinyue Fan,Zixiao Quan*

Main category: q-fin.RM

TL;DR: 论文提出多目标优化框架，使用NSGA-II算法同时优化保险定价中的准确性、群体公平性、个体公平性和反事实公平性，生成帕累托前沿解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习提高保险定价预测准确性，但加剧了不同公平性标准之间的权衡困境。现有公平感知模型局限于单目标优化，无法全面处理准确性、群体公平性、个体公平性和反事实公平性之间的冲突。

Method: 提出新颖的多目标优化框架，使用非支配排序遗传算法II（NSGA-II）联合优化所有四个标准，生成多样化的帕累托前沿解决方案，并通过特定选择机制提取最优保费方案。

Result: XGBoost在准确性上优于GLM但加剧了公平性差距；正交模型在群体公平性上表现最佳，而合成控制在个体和反事实公平性上领先。提出的方法始终实现平衡折衷，优于单一模型方法。

Conclusion: 多目标优化框架能够有效解决保险定价中准确性、群体公平性、个体公平性和反事实公平性之间的权衡问题，为监管机构和保险公司提供平衡盈利与公平结果的解决方案。

Abstract: Machine learning improves predictive accuracy in insurance pricing but exacerbates trade-offs between competing fairness criteria across different discrimination measures, challenging regulators and insurers to reconcile profitability with equitable outcomes. While existing fairness-aware models offer partial solutions under GLM and XGBoost estimation methods, they remain constrained by single-objective optimization, failing to holistically navigate a conflicting landscape of accuracy, group fairness, individual fairness, and counterfactual fairness. To address this, we propose a novel multi-objective optimization framework that jointly optimizes all four criteria via the Non-dominated Sorting Genetic Algorithm II (NSGA-II), generating a diverse Pareto front of trade-off solutions. We use a specific selection mechanism to extract a premium on this front. Our results show that XGBoost outperforms GLM in accuracy but amplifies fairness disparities; the Orthogonal model excels in group fairness, while Synthetic Control leads in individual and counterfactual fairness. Our method consistently achieves a balanced compromise, outperforming single-model approaches.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [73] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 提出DDFT评估框架，测量语言模型在语义压缩和对抗性干扰下的认知稳健性，发现模型规模与稳健性无关，错误检测能力是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估（如MMLU、TruthfulQA）只测量理想条件下的知识，无法评估模型在信息退化或对抗攻击下的稳健性。需要一种能区分模型是否真正"知道"而不仅仅是"记忆"的评估方法。

Method: 提出Drill-Down and Fabricate Test (DDFT)协议，基于两系统认知模型：语义系统生成流畅文本，认知验证器验证事实准确性。在8个知识领域、5个压缩级别上评估9个前沿模型（共1800次轮级评估）。

Result: 认知稳健性与传统设计范式正交：参数数量(r=0.083)和架构类型(r=0.153)均不显著预测稳健性。错误检测能力强烈预测整体稳健性(rho=-0.817)。旗舰模型表现出脆弱性，而较小模型可达到稳健性能。

Conclusion: 认知稳健性主要来自训练方法和验证机制，而非模型规模。DDFT框架为关键应用部署前评估认知稳健性提供了理论基础和实用工具，挑战了模型规模与可靠性的传统假设。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [74] [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)
*Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder*

Main category: cs.AI

TL;DR: CASCADE是一个自演化的AI代理框架，通过持续学习和自我反思掌握复杂工具，在材料科学和化学任务上达到93.3%成功率，实现从"LLM+工具使用"到"LLM+技能获取"的转变。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理依赖预定义工具或脆弱的工具生成，限制了其在复杂科学任务中的能力和适应性。需要从"LLM+工具使用"转向"LLM+技能获取"的新范式。

Method: CASCADE框架通过两种元技能实现自我演化：1) 持续学习（通过网页搜索和代码提取），2) 自我反思（通过内省和知识图谱探索）。框架还包括人机协作和记忆整合机制。

Result: 在SciSkillBench基准测试（116个材料科学和化学研究任务）中，CASCADE使用GPT-5达到93.3%成功率，相比没有演化机制的35.4%有显著提升。展示了在计算分析、自主实验室实验和论文选择性复现等实际应用。

Conclusion: CASCADE能够积累可执行的技能，这些技能可以在代理和科学家之间共享，推动可扩展的AI辅助科学研究，代表了向"LLM+技能获取"范式转变的重要进展。

Abstract: Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.

</details>


### [75] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy框架结合LLM与ASP，将医学文献转化为ASP代码，结合患者数据进行疾病诊断，实现可解释的预测系统。


<details>
  <summary>Details</summary>
Motivation: 传统符号AI在医疗领域应用受限，主要因为构建高质量知识库需要大量人工努力。需要一种方法既能利用符号AI的可解释性，又能降低知识构建成本。

Method: 使用LLM将医学文献自动翻译成ASP（答案集编程）代码，然后将患者数据与ASP知识库结合，通过ASP求解器进行推理得出最终诊断。

Result: 初步结果显示McCoy在小规模疾病诊断任务上表现良好，证明了该框架的有效性。

Conclusion: McCoy框架成功结合了LLM的知识提取能力和ASP的逻辑推理优势，为医疗诊断提供了一个强大且可解释的预测系统，克服了传统符号AI的知识构建障碍。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [76] [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.AI

TL;DR: SPARK是一个基于多智能体LLM的个性化搜索框架，通过角色化智能体协作实现动态查询解析和个性化检索增强生成。


<details>
  <summary>Details</summary>
Motivation: 传统个性化搜索系统受限于静态用户画像和单一检索流程，难以捕捉用户动态、多维的信息需求。需要能够建模用户信息需求演变和上下文敏感性的新一代搜索系统。

Method: 1) 定义基于角色、专业领域、任务上下文和领域的角色空间；2) 引入角色协调器动态解析查询并激活相关专业智能体；3) 每个智能体执行独立的检索增强生成过程，配备长短期记忆存储和上下文感知推理模块；4) 通过共享内存库、迭代辩论和中继式知识转移等结构化通信协议促进智能体协作。

Result: 框架产生了关于协调效率、个性化质量和认知负载分布的可测试预测，同时包含自适应学习机制用于持续角色优化。该框架展示了如何通过分布式智能体行为和最小协调规则产生涌现的个性化特性。

Conclusion: SPARK通过细粒度智能体专业化与协作检索的整合，为能够捕捉人类信息寻求行为的复杂性、流动性和上下文敏感性的下一代搜索系统提供了理论见解。

Abstract: Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.

</details>


### [77] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: ROAD是一个无需标注数据的自动提示优化框架，通过模拟人类工程师的调试过程，将失败日志转化为结构化决策树协议，显著提升LLM代理性能。


<details>
  <summary>Details</summary>
Motivation: 现实软件工程中，LLM代理开发初期通常缺乏标注数据集，只有混乱的生产日志和不断变化的失败模式。现有自动提示优化方法依赖大量标注数据，不适用于冷启动场景。

Method: ROAD采用多智能体架构：分析器进行根因分析，优化器进行模式聚合，教练进行策略集成，将非结构化失败日志转化为结构化决策树协议，模拟人类工程师的调试-修复循环。

Result: 在学术基准和实际知识管理引擎上，ROAD在仅3次自动迭代后，成功率提升5.6%（73.6%到79.2%），搜索准确率提升3.8%。在零售领域复杂推理任务上，相对基线提升约19%。

Conclusion: 模拟人类工程师的失败分析和修复循环，为部署可靠LLM代理提供了一种数据高效、资源节约的替代方案，避免了资源密集的强化学习训练。

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [78] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化代理框架，通过"计划-执行-总结"认知范式和混合进化记忆系统，在减少计算成本的同时实现最先进的解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法缺乏结构化推理，导致过早收敛和高维代码空间探索效率低下，阻碍了从静态大语言模型向自改进代理的过渡。

Method: 集成LLM到"计划-执行-总结"认知范式，将进化搜索映射为推理密集型过程；采用结合多岛模型、MAP-Elites和自适应玻尔兹曼选择的混合进化记忆系统，平衡探索与利用。

Result: 在AlphaEvolve基准测试和Kaggle竞赛中，LoongFlow比OpenEvolve、ShinkaEvolve等基线方法进化效率提升高达60%，并能发现更优解决方案。

Conclusion: LoongFlow在自主科学发现领域迈出重要一步，能够以更少计算开销生成专家级解决方案，标志着从静态LLM向自进化代理的重要进展。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [79] [CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation](https://arxiv.org/abs/2512.24113)
*Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang*

Main category: cs.AI

TL;DR: CogRec是一个结合大语言模型和Soar认知架构的推荐系统，利用LLM进行知识初始化，通过Soar进行符号推理，在遇到障碍时动态查询LLM生成新的生产规则，实现可解释的在线学习。


<details>
  <summary>Details</summary>
Motivation: LLMs在推荐系统中表现出理解用户偏好的能力，但存在黑盒特性、知识幻觉和有限在线学习能力等问题，影响可信度和适应性。而Soar等认知架构虽然推理过程结构化可解释，但知识获取困难。需要结合两者优势解决互补挑战。

Method: 提出CogRec认知推荐代理，以Soar作为核心符号推理引擎，利用LLM进行知识初始化填充工作记忆中的生产规则。采用感知-认知-行动(PCA)循环，遇到障碍时动态查询LLM获取推理解决方案，通过Soar的分块机制转化为新的符号生产规则，实现鲁棒的在线学习。

Result: 在三个公共数据集上的广泛评估表明，CogRec在推荐准确性、可解释性以及解决长尾问题方面表现出显著优势。

Conclusion: CogRec成功结合了LLMs和Soar认知架构的优势，通过LLM的知识初始化能力和Soar的结构化推理，实现了可解释的在线学习推荐系统，在准确性、可解释性和长尾问题处理方面都有优异表现。

Abstract: Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent "Black-Box" characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar's chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.

</details>


### [80] [Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks](https://arxiv.org/abs/2512.24156)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.AI

TL;DR: 提出一种无需训练的图结构探索方法，在ARC-AGI-3基准测试中通过视觉分割和系统化状态空间探索解决交互推理任务，显著优于当前最先进的LLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的LLM在ARC-AGI-3基准测试中无法可靠解决交互推理任务，该基准包含需要推断任务机制、适应复杂度递增的游戏式任务，需要形成假设、测试假设并跟踪已发现机制的能力。

Method: 结合基于视觉的帧处理与系统化状态空间探索：1) 将视觉帧分割为有意义组件；2) 基于视觉显著性优先选择动作；3) 维护探索状态和转移的有向图结构；4) 通过跟踪已访问状态和测试动作，优先选择到达未测试状态-动作对的最短路径。

Result: 在ARC-AGI-3 Preview Challenge中，该方法在6个游戏的52个关卡中解决了中位数30个关卡，在私有排行榜上排名第3，显著优于前沿的LLM智能体。

Conclusion: 即使无需学习，显式的图结构探索也能作为交互推理的强大基线，突显了在稀疏反馈环境中系统化状态跟踪和动作优先级的重要性，而当前LLM在这些环境中无法捕捉任务动态。

Abstract: We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore.

</details>


### [81] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: SCP（科学上下文协议）是一个开源标准，旨在通过构建自主科学代理的全球网络来加速科学发现。它提供统一的资源集成规范和实验生命周期管理架构。


<details>
  <summary>Details</summary>
Motivation: 当前科学研究中，软件工具、模型、数据集和物理仪器等资源分散在不同平台和机构中，缺乏统一的标准和协议，导致AI代理和应用程序难以发现、调用和组合这些能力，限制了大规模协作和可重复性。

Method: SCP基于两大支柱：1）统一资源集成：提供描述和调用科学资源的通用规范；2）编排实验生命周期管理：采用集中式SCP Hub和联邦式SCP Server的安全服务架构，管理实验的注册、规划、执行、监控和归档全过程。

Result: 基于SCP构建的科学发现平台已集成超过1600个工具资源，在多样化用例中实现了异构AI系统与人类研究人员之间安全的大规模协作，显著降低了集成开销并增强了可重复性。

Conclusion: 通过在协议层面标准化科学上下文和工具编排，SCP为可扩展、多机构、代理驱动的科学研究建立了必要的基础设施，有望加速科学发现进程。

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [82] [Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem](https://arxiv.org/abs/2512.24251)
*Pengfu Wan,Jiawei Chen,Gangyan Xu*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习的方法来解决车队规模和混合车辆路径问题，该方法能够在几秒内生成接近最优的解决方案，特别适用于大规模和时间受限的场景。


<details>
  <summary>Details</summary>
Motivation: FSMVRP（车队规模和混合车辆路径问题）是车辆路径问题的一个重要变体，在运营研究和计算科学中广泛研究。该问题需要同时做出车队组成和路径规划决策，使其在短期车辆租赁和按需物流等现实场景中具有高度适用性。然而，这些要求也增加了FSMVRP的复杂性，特别是在大规模和时间受限的环境中带来了重大挑战。

Method: 本文将问题建模为马尔可夫决策过程，并开发了一个名为FRIPN的新型策略网络，该网络无缝集成了车队组成和路径决策。该方法包含为不同决策目标设计的专门输入嵌入，包括剩余图嵌入以促进有效的车辆使用决策。

Result: 在随机生成的实例和基准数据集上进行的综合实验表明，该方法在计算效率和可扩展性方面表现出显著优势，特别是在大规模和时间受限的场景中。

Conclusion: 该方法在实际应用中具有潜力，并为将基于深度强化学习的技术扩展到其他VRP变体提供了有价值的启发。

Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.

</details>


### [83] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: RSA是一种风险感知的分步对齐方法，通过嵌套风险度量在策略优化中显式纳入风险意识，以解决现有安全对齐方法风险中性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法（如Safe RLHF和SACPO）通常采用风险中性范式，不足以应对参考策略偏差带来的风险，且对罕见但潜在灾难性有害行为的鲁棒性有限。

Method: 提出风险感知分步对齐（RSA），将安全对齐表述为令牌级风险感知约束策略优化问题，通过基于嵌套风险度量的分步对齐过程求解，获得令牌级策略更新。

Result: 实验结果表明，该方法在保持高帮助性的同时确保强安全性，并显著抑制尾部风险（低概率但高影响的不安全响应）。

Conclusion: RSA通过显式纳入风险意识，有效缓解模型过度偏离参考策略的风险，并明确抑制低概率高影响的有害行为，提供了理论分析和实证验证。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [84] [Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents](https://arxiv.org/abs/2512.24461)
*Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim*

Main category: cs.AI

TL;DR: 提出一种测试时自适应智能体，通过后验引导的信念精化进行探索性推理，无需梯度更新或额外训练，适用于部分可观测环境下的LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境下，LLM智能体需要有效推断潜在世界状态，但现有方法（如提示增强或检索增强）存在集成开销大、依赖梯度更新等问题。

Method: 智能体维护外部结构化信念表示，通过动作条件观测迭代更新，选择最大化信念空间信息增益的动作。使用轻量级LLM代理估计信息增益，并通过量化后验信念与真实环境配置一致性的新奖励评估世界对齐。

Result: 实验表明，该方法在潜在世界状态对齐方面优于推理时扩展基线（如提示增强或检索增强的LLM），且集成开销显著降低。

Conclusion: 提出的测试时自适应智能体通过后验引导的信念精化，在部分可观测环境下实现了高效的世界状态对齐，无需梯度更新或额外训练，具有较低的集成开销。

Abstract: In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.

</details>


### [85] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 本文提出JEPA-WMs框架，研究在表示空间进行规划的世界模型，通过系统实验找到最优方法，在导航和操作任务上超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决AI中长期存在的挑战：开发能够解决广泛物理任务并在新任务和环境上泛化的智能体。现有方法在输入空间进行规划，但在表示空间规划可能更高效。

Method: 将这类方法定义为JEPA-WMs，系统研究模型架构、训练目标和规划算法等关键组件。在模拟环境和真实机器人数据上进行实验。

Result: 提出的模型在导航和操作任务上超越了DINO-WM和V-JEPA-2-AC两个基准方法。代码、数据和检查点已开源。

Conclusion: 通过系统研究JEPA-WMs的关键组件，找到了在表示空间进行规划的最优方法，为开发通用物理智能体提供了有效途径。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [86] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: 提出交互式评估框架分析基础模型代理在符号地图环境中的空间理解能力，发现记忆表示对空间推理性能影响最大，而单纯模型缩放无法持续提升空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型空间能力评估多基于静态地图或文本查询，忽视了空间理解的交互性和经验驱动特性，需要新的评估框架来深入分析模型在动态地图环境中的探索、记忆和推理能力。

Method: 提出交互式评估框架，让代理在部分可观测的网格地图中增量探索（包含道路、交叉口和兴趣点），仅接收局部观测，然后通过六种空间任务评估空间理解能力。系统变化探索策略、记忆表示和推理方案，分析不同基础模型的表现。

Result: 探索主要影响经验获取但对最终推理准确性影响有限；记忆表示在整合空间经验中起核心作用，结构化记忆（特别是序列和图表示）显著提升路径规划等结构密集型任务性能；推理方案影响存储空间知识的使用方式；空间推理性能在模型版本和规模超过一定阈值后趋于饱和。

Conclusion: 提升地图空间理解能力需要针对空间表示和推理的专门机制，而非单纯依赖模型缩放。结构化记忆表示和高级推理提示对空间任务性能至关重要。

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [87] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 本研究分析了大型语言模型在代表性不足的数学竞赛问题上的表现，发现DeepSeek-V3在微积分、解析几何和离散数学中表现最佳，所有模型在几何方面表现明显较弱，不同模型有各自独特的错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多使用相同的数据集评估LLMs的数学推理能力，这限制了研究结果的普适性，且可能无法充分捕捉数学任务中的多样化挑战。本研究旨在分析LLMs在代表性不足的数学竞赛问题上的表现。

Method: 使用密苏里大学数学竞赛中的微积分、解析几何和离散数学问题，对GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3三个领先LLMs进行测试，将模型响应与已知正确答案比较以确定准确性，并分析推理过程以探索错误模式。

Result: DeepSeek-V3在三个数学领域（微积分、解析几何、离散数学）的表现最佳，包括推理过程和最终答案。所有三个LLMs在几何方面表现明显较弱。DeepSeek-V3的主要错误是计算和逻辑错误，GPT-4o-mini常见逻辑和方法相关错误，Gemini则倾向于不完整推理和仓促得出结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估LLMs可以提供对其独特错误模式的更深入洞察，并突显结构化推理方面的持续挑战，特别是在几何领域。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [88] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 论文提出两阶段方法提升LLM空间推理能力：先通过监督微调学习基本空间变换，再通过GRPO框架训练LoRA适配器进行多步规划，在ASCII环境中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在通用语言能力上表现出色，但在结构化环境中的空间变换和多步规划方面仍然存在困难，这限制了其在导航和规划等应用中的表现。

Method: 采用两阶段方法：1）对基本空间变换（旋转、平移、缩放）进行监督微调，使模型具备基础空间物理知识；2）冻结该物理感知模型，在GRPO框架内训练轻量级LoRA适配器，以闭环方式学习组合这些构建块进行多步规划。为此合成了ASCII-art数据集并构建了相应的强化学习环境。

Result: 该方法在动态环境（显式状态更新）和静态环境（模型需依赖内部状态）中均一致优于基线方法，包括通用骨干模型、物理感知模型和端到端RL模型。此外，该方法收敛更快，训练更稳定，且注意力模式分析表明微调确实改善了空间理解能力。

Conclusion: 通过将空间推理分解为原子构建块及其组合的两阶段方法，能够有效提升LLM在结构化环境中的空间推理能力，为导航和规划应用提供了有前景的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [89] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: 提出了MCPAgentBench基准，用于评估LLM代理在真实MCP定义下的工具使用能力，包含真实任务、模拟工具和动态沙箱环境，测试工具选择和辨别能力。


<details>
  <summary>Details</summary>
Motivation: 当前MCP评估集存在依赖外部MCP服务和缺乏难度感知的问题，需要更好的基准来评估LLM代理的工具使用能力。

Method: 构建基于真实世界MCP定义的数据集，包含真实任务和模拟MCP工具；使用动态沙箱环境，提供包含干扰项的工具列表；引入综合指标衡量任务完成率和执行效率。

Result: 在多种最新主流大语言模型上的实验显示，在处理复杂多步工具调用时存在显著性能差异。

Conclusion: MCPAgentBench为评估LLM代理的工具使用能力提供了有效的基准，代码已开源，有助于推动自主代理工具使用能力的发展。

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [90] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: 提出递归语言模型（RLMs），一种让LLM通过递归调用自身处理任意长提示的推理策略，能处理超出模型上下文窗口两个数量级的输入，并在长上下文任务中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）受限于固定的上下文窗口长度，无法处理任意长的提示。现有方法在扩展上下文处理能力方面存在限制，需要一种更灵活、可扩展的解决方案。

Method: 提出递归语言模型（RLMs），将长提示视为外部环境，允许LLM以编程方式检查、分解提示，并递归调用自身处理提示片段。这是一种通用的推理策略，而非模型架构修改。

Result: RLMs能成功处理超出模型上下文窗口两个数量级的输入（即100倍）。在四个不同的长上下文任务中，即使对于较短的提示，RLMs也显著优于基础LLMs和常见的长上下文框架，同时每次查询的成本相当或更低。

Conclusion: 递归语言模型提供了一种有效的方法来扩展LLM处理任意长提示的能力，在保持成本效率的同时显著提升了长上下文任务的处理质量。

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [91] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 提出强化学习增强的LLM多智能体协作框架，通过Dec-POMDP建模和CTDE训练，实现3倍速度提升和高质量协作


<details>
  <summary>Details</summary>
Motivation: 现有LLM在单智能体任务表现良好，但在多智能体协作场景中缺乏全局优化能力，难以实现高效协同

Method: 1) 将协作建模为Dec-POMDP；2) 采用CTDE训练范式；3) 提出GRPO算法联合优化策略；4) 设计平衡任务质量、速度和协调成本的奖励函数

Result: 在协作写作和编程基准测试中：任务处理速度比单智能体基线提升3倍；写作结构/风格一致性达98.7%；编程测试通过率74.6%；优于现有多智能体LLM基线

Conclusion: 该框架为复杂工作流中的可靠协作提供了实用路径，显著提升了多智能体LLM的协作效率和全局性能

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [92] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 提出基于群体审议的多智能体对话模型，通过三层角色架构（生成、验证、整合）提升复杂推理能力，在多个数据集上显著提高多跳推理准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在复杂推理任务中存在局限性，需要更有效的协作机制来提升推理准确性和逻辑一致性。

Method: 采用三层角色架构：观点生成代理产生多样化推理视角，证据验证代理检索外部知识并量化事实支持，一致性仲裁代理整合逻辑连贯的结论。引入自博弈机制扩展多路径推理轨迹，检索增强模块动态补充外部知识，设计结合事实一致性和逻辑连贯性的复合奖励函数，应用改进的近端策略优化策略进行协作训练。

Result: 在HotpotQA上多跳推理准确率提升16.8%，在2WikiMultihopQA上提升14.3%，在MeetingBank上提升19.2%，一致性提升21.5%。相比主流多智能体方法具有更高的推理效率。

Conclusion: 该模型为复杂推理任务提供了有效且稳定的解决方案，通过群体审议机制显著提升了多智能体协作的推理性能。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [93] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: Youtu-Agent：一个模块化LLM智能体框架，支持自动化生成和持续进化，解决现有框架配置成本高和静态能力问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体框架面临两大挑战：1）配置成本高，需要大量人工工具集成和提示工程；2）能力静态，难以适应动态环境，需要昂贵的微调

Method: 1）结构化配置系统解耦执行环境、工具包和上下文管理；2）两种生成范式：Workflow模式处理标准任务，Meta-Agent模式处理复杂需求；3）混合策略优化系统：Agent Practice模块实现上下文优化，Agent RL模块实现分布式强化学习

Result: 在WebWalkerQA（71.47%）和GAIA（72.8%）上达到SOTA性能；工具合成成功率超过81%；Practice模块在AIME 2024/2025上分别提升2.7%和5.4%；Agent RL训练在7B LLM上实现40%加速，数学和推理能力提升35%，搜索能力提升21%

Conclusion: Youtu-Agent通过自动化生成和持续进化机制，显著降低了LLM智能体的配置成本并提升了动态适应能力，为构建高质量智能体提供了有效解决方案

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [94] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 提出BatteryAgent框架，结合物理特征与LLM推理能力，实现锂离子电池故障的智能诊断，超越传统二元分类，提供根因分析与维护建议。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽检测准确率高，但存在"黑箱"问题缺乏可解释性，且受限于二元分类范式，无法提供根因分析和维护建议。

Method: 提出三层框架：1)物理感知层提取10个基于电化学原理的特征；2)检测归因层使用梯度提升决策树和SHAP量化特征贡献；3)推理诊断层利用LLM构建"数值-语义"桥梁，结合SHAP归因和机理知识库生成综合诊断报告。

Result: 实验显示BatteryAgent有效纠正边界样本误分类，AUROC达0.986，显著优于当前SOTA方法，并将传统二元检测扩展到多类型可解释诊断。

Conclusion: 该框架实现了从"被动检测"到"智能诊断"的范式转变，为电池安全管理提供新方法，结合物理知识与LLM推理能力实现可解释的故障诊断。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [95] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出多模态跨域混合融合模型，通过双重解耦和跨域混合融合策略，解决故障诊断中未见工况下的泛化问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法在未见工况下性能显著下降，域适应方法依赖目标域样本，且大多数研究依赖单模态信号，忽略了多模态信息的互补性

Method: 提出多模态跨域混合融合模型，包含双重解耦框架（解耦模态不变/特定特征和域不变/特定表示）、跨域混合融合策略（跨域随机混合模态信息）、三模态融合机制（自适应集成多模态异构信息）

Result: 在感应电机故障诊断实验中，无论是未见恒定工况还是时变工况，该方法均优于先进方法，消融研究验证了各组件和多模态融合的有效性

Conclusion: 该方法通过双重解耦和跨域混合融合，实现了更好的多模态表示学习和域泛化能力，为故障诊断提供了有效的解决方案

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [96] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 论文提出了一种可解释的物体摆放偏好模型，包含四个可解释维度：空间实用性、习惯便利性、语义连贯性和常识适当性，并通过问卷验证和MCTS规划器展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类演示的机器人系统偏好模型虽然有效，但缺乏可解释性，无法理解指导人类决策的因素。需要开发能够明确解释人类物体摆放偏好的模型。

Method: 1. 提出四个可解释的偏好维度：空间实用性、习惯便利性、语义连贯性、常识适当性；2. 设计并验证自报告问卷（63名参与者在线研究）；3. 将偏好整合到蒙特卡洛树搜索（MCTS）规划器中。

Result: 1. 问卷研究证实了四个心理维度的区分性和解释力；2. 基于参与者偏好的MCTS规划器能够生成与参与者安排高度一致的合理布局；3. 在厨房和客厅两种场景中均表现出良好效果。

Conclusion: 该工作贡献了一个紧凑、可解释的物体摆放偏好模型，并展示了如何将其操作化用于机器人规划，为机器人系统提供了更透明和可解释的决策基础。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [97] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ是一种混合模型，通过可解释的语义特征桥接基础模型和统计建模。它通过迭代过程发现数据集特定的语义特征，而不是依赖基础模型的领域知识，在房价预测和电影推荐任务上显著优于GPT-5基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然拥有广泛的领域知识，但往往无法捕捉对预测任务至关重要的数据集特定模式。基础模型依赖通用领域理解，而统计建模需要特定数据集模式，两者之间存在鸿沟。

Method: 提出一种广义EM算法，通过迭代对比统计建模错误识别的项目组来发现语义特征描述。方法使用冻结的基础模型基于发现的特征对项目进行分类，将这些判断视为预测实值目标的潜在二元特征的噪声观测。

Result: 在房价预测任务中，使用多模态列表数据发现的语义特征实现了12%的中位数相对误差，显著优于依赖LLM通用领域知识的GPT-5基线（38%误差）。在Netflix电影嵌入预测中，仅从语义描述就能达到0.59余弦相似度，相当于传统协同过滤需要约4000用户评分的性能。

Conclusion: GenZ成功桥接了基础模型和统计建模，通过发现数据集特定的语义特征显著提升了预测性能。发现的特征揭示了与模型领域知识不同的数据集特定模式，如建筑细节预测当地住房市场、特许经营权成员预测用户偏好等。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [98] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 提出使用约束模板从养老机构管理者访谈中提取设施特定约束条件的方法，能排除异常约束，用于护工排班生成


<details>
  <summary>Details</summary>
Motivation: 养老机构的排班条件因设施而异，需要通过与制定排班的管理者访谈来设计设施特定的约束条件，但现有约束提取技术难以处理这种多样性

Method: 使用约束模板提取各种约束组合（如连续工作班次模式、员工组合等），通过改变关注的天数和员工数量以及提取焦点（模式或频率）来提取多样约束，并包含排除异常约束的机制

Result: 实验表明，该方法成功创建了满足所有硬约束的排班，并通过避免提取异常约束减少了软约束的违反次数

Conclusion: 提出的约束模板方法能有效从养老机构管理者访谈中提取设施特定约束，生成符合实际需求的护工排班，解决了传统约束提取技术难以处理设施差异和异常约束的问题

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [99] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: ALE是一个端到端的智能体学习生态系统，包含ROLL权重优化框架、ROCK沙盒环境管理和iFlow CLI上下文工程工具，并发布了基于ALE训练的ROME智能体模型。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏系统化的智能体开发基础设施，需要构建一个端到端的生态系统来优化智能体LLM的生产流程。

Method: ALE包含三个组件：ROLL（权重优化后训练框架）、ROCK（轨迹生成沙盒环境管理器）、iFlow CLI（高效上下文工程代理框架）。提出数据组合协议合成复杂行为，以及基于交互的策略对齐（IPA）算法，在语义交互块而非单个token上分配信用。

Result: 发布了ROME智能体模型，在超过100万条轨迹上训练。在SWE-bench Verified和Terminal Bench等基准测试中表现优异，证明了ALE基础设施的有效性。

Conclusion: ALE提供了一个原则性的端到端生态系统，显著提升了智能体LLM的开发效率，ROME的成功验证了该基础设施的有效性。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [100] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 开发了一个半自动数据标注流水线，用于创建波兰驾驶场景的大规模多模态数据集，通过人机协作减少标注成本和时间


<details>
  <summary>Details</summary>
Motivation: 手动标注异构驾驶数据成本高、耗时长，需要一种高效的方法来创建大规模、高质量的标注数据集以支持自动驾驶研究

Method: 采用人在回路方法，结合AI与人类专业知识，系统自动生成初始标注，支持迭代模型重训练，包含数据匿名化和领域适应技术，核心基于3D目标检测算法

Result: 开发出的工具和方法显著节省时间，确保跨不同传感器模态的一致高质量标注，直接支持DARTS项目加速准备大规模标注数据集

Conclusion: 该半自动标注流水线有效解决了大规模驾驶数据标注的挑战，为波兰自动驾驶研究提供了技术基础，通过人机协作平衡了效率与质量

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [101] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 迭代部署LLM模型，每代在用户从前代模型输出中精心筛选的数据上微调，能显著改变模型特性，在规划任务上实现能力提升和泛化，这本质上是一种隐式强化学习过程。


<details>
  <summary>Details</summary>
Motivation: 研究迭代部署LLM（每代基于用户从前代输出中筛选的数据进行微调）如何影响模型特性，特别是探索这种机制是否能在规划任务中产生能力提升和泛化。

Method: 在多个规划领域测试迭代部署机制：每代LLM在用户从前代模型输出中精心筛选的数据上进行微调，然后部署新模型，重复此过程。

Result: 观察到规划能力显著提升，后期模型展现出泛化能力，能发现比初始模型长得多的规划方案。理论分析表明迭代部署本质上实现了外层强化学习训练，具有隐式奖励函数。

Conclusion: 迭代部署机制是强化学习的替代训练范式，依赖数据筛选而非显式奖励。这对AI安全有重要影响，因为隐式奖励函数未明确定义，可能对未来模型部署产生意外影响。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [102] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent是一个专门用于时空理解的智能体大语言模型，通过工具交互解决复杂时空任务，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决复杂时空任务（如受限兴趣点发现和行程规划）需要专门的智能体模型，这些任务需要探索、验证和细化中间推理步骤。

Method: 1) 包含10多个领域特定工具的稳定工具环境；2) 分层数据筛选框架（筛选比1:10,000）；3) 级联训练方法：种子SFT阶段评估查询难度，第二SFT阶段针对高确定性查询，最终RL阶段利用低确定性数据。

Result: STAgent在TravelBench上表现出色，同时在广泛的通用基准测试中保持其通用能力，证明了所提出的智能体模型的有效性。

Conclusion: STAgent通过专门的工具环境、高质量数据筛选和级联训练方法，成功创建了一个既能解决复杂时空任务又保持通用能力的智能体大语言模型。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>


### [103] [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)
*Tianzhi He,Farrokh Jazizadeh*

Main category: cs.AI

TL;DR: 提出基于大语言模型的建筑能源管理系统AI代理框架，通过自然语言交互实现智能建筑的情境感知能源管理，在设备控制、记忆任务等方面表现良好，但成本估算等复杂任务仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有能源管理系统存在局限性，需要更智能、情境感知的解决方案。通过利用大语言模型的自主数据分析能力，开发能够理解自然语言、提供情境感知洞察的BEMS AI代理，以改善建筑能源管理。

Method: 提出包含三个模块的概念框架：感知模块（传感）、中央控制模块（大脑）和行动模块（执行和用户交互），形成闭环反馈系统。使用120个用户查询在四个真实住宅能源数据集上评估原型性能，评估指标包括延迟、功能、能力、准确性和成本效益，并使用ANOVA测试验证框架的通用性。

Result: 原型在设备控制（86%准确率）、记忆相关任务（97%）、调度和自动化（74%）以及能源分析（77%）方面表现良好。但更复杂的成本估算任务准确率仅为49%，显示需要改进的领域。研究还揭示了响应准确性和计算效率之间的权衡。

Conclusion: 该研究为基于LLM的BEMS AI代理的评估提供了正式化框架，展示了其在智能建筑能源管理中的潜力，同时指出了复杂任务需要改进的方向，并为未来研究提供了方向，特别是准确性与计算效率的平衡问题。

Abstract: This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype's performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [104] [Distributed Beamforming in Massive MIMO Communication for a Constellation of Airborne Platform Stations](https://arxiv.org/abs/2512.23900)
*Hesam Khoshkbari,Georges Kaddoum,Bassant Selim,Omid Abbasi,Halim Yanikomeroglu*

Main category: eess.SY

TL;DR: 提出基于熵的多智能体深度强化学习分布式波束成形框架，用于大规模MIMO空中平台网络，无需基站间CSI共享，在高干扰场景下优于传统方法


<details>
  <summary>Details</summary>
Motivation: 非地面基站（NTBS）对下一代无线网络至关重要，但传统方法需要基站间CSI共享，导致高开销。需要开发无需CSI共享的分布式波束成形方法，以应对动态高干扰环境

Method: 基于熵的多智能体深度强化学习模型，每个空中平台作为独立智能体，使用不完美的信道状态信息进行训练和测试，无需基站间CSI共享

Result: 仿真显示该方法优于零迫和最大比传输技术，特别是在高干扰场景下，对CSI不完美具有鲁棒性，且具有良好的可扩展性，能适应用户数量增加和不同集群配置

Conclusion: 提出的分布式波束成形框架为动态高干扰的NTBS网络提供了有前景的解决方案，推动了可扩展且鲁棒的无线网络发展

Abstract: Non-terrestrial base stations (NTBSs), including high-altitude platform stations (HAPSs) and hot-air balloons (HABs), are integral to next-generation wireless networks, offering coverage in remote areas and enhancing capacity in dense regions. In this paper, we propose a distributed beamforming framework for a massive MIMO network with a constellation of aerial platform stations (APSs). Our approach leverages an entropy-based multi-agent deep reinforcement learning (DRL) model, where each APS operates as an independent agent using imperfect channel state information (CSI) in both training and testing phases. Unlike conventional methods, our model does not require CSI sharing among APSs, significantly reducing overhead. Simulations results demonstrate that our method outperforms zero forcing (ZF) and maximum ratio transmission (MRT) techniques, particularly in high-interference scenarios, while remaining robust to CSI imperfections. Additionally, our framework exhibits scalability, maintaining stable performance over an increasing number of users and various cluster configurations. Therefore, the proposed method holds promise for dynamic and interference-rich NTBS networks, advancing scalable and robust wireless solutions.

</details>


### [105] [Hardware Acceleration for Neural Networks: A Comprehensive Survey](https://arxiv.org/abs/2512.23914)
*Bin Xu,Ayan Banerjee,Sandeep Gupta*

Main category: eess.SY

TL;DR: 这篇综述论文系统回顾了深度学习硬件加速的技术格局，涵盖了从GPU到专用加速器的各类架构，提出了统一分类法，并讨论了软件栈、编译器以及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络模型规模不断扩大和部署场景多样化，硬件瓶颈从计算吞吐量转向内存移动、通信和不规则算子，需要全面了解深度学习硬件加速的技术现状和发展方向。

Method: 采用统一分类法从三个维度组织技术空间：(1) 工作负载类型（CNN、RNN、GNN、Transformer/LLM），(2) 执行设置（训练vs推理、数据中心vs边缘），(3) 优化杠杆（低精度、稀疏化与剪枝、算子融合、编译调度、内存系统设计）。

Result: 综合分析了关键架构思想，包括脉动阵列、向量和SIMD引擎、专用注意力与softmax内核、量化感知数据通路、高带宽内存等，并探讨了软件栈和编译器如何将模型语义映射到硬件。

Conclusion: 指出了未来挑战：高效长上下文LLM推理（KV缓存管理）、动态稀疏工作负载的鲁棒支持、能源与安全感知部署、公平基准测试，为下一代神经加速器指明了有前景的发展方向。

Abstract: Neural networks have become a dominant computational workload across cloud and edge platforms, but rapid growth in model size and deployment diversity has exposed hardware bottlenecks increasingly dominated by memory movement, communication, and irregular operators rather than peak arithmetic throughput. This survey reviews the technology landscape for hardware acceleration of deep learning, spanning GPUs and tensor-core architectures; domain-specific accelerators (e.g., TPUs/NPUs); FPGA-based designs; ASIC inference engines; and emerging LLM-serving accelerators such as LPUs (language processing units), alongside in-/near-memory computing and neuromorphic/analog approaches. We organize the space using a unified taxonomy across (i) workloads (CNNs, RNNs, GNNs, and Transformers/LLMs), (ii) execution settings (training vs.\ inference; datacenter vs.\ edge), and (iii) optimization levers (reduced precision, sparsity and pruning, operator fusion, compilation and scheduling, and memory-system/interconnect design). We synthesize key architectural ideas including systolic arrays, vector and SIMD engines, specialized attention and softmax kernels, quantization-aware datapaths, and high-bandwidth memory, and we discuss how software stacks and compilers bridge model semantics to hardware. Finally, we highlight open challenges -- including efficient long-context LLM inference (KV-cache management), robust support for dynamic and sparse workloads, energy- and security-aware deployment, and fair benchmarking -- and point to promising directions for the next generation of neural acceleration.

</details>


### [106] [Economic and Technical Feasibility of V2G in Non-Road Mobile Machinery sector](https://arxiv.org/abs/2512.24101)
*Rößler Nicolas,Khan Irfan,Schade Thomas,Wellmann Christoph,Cao Xinyuan,Kopynske Milan,Xia Feihong,Savelsberg Rene,Andert Jakob*

Main category: eess.SY

TL;DR: 该论文研究了在非道路移动机械（NRMM）领域集成车网互动（V2G）技术的经济和技术可行性，提出了一种结合贝叶斯优化和运营策略优化的新方法，以降低电力成本并增强电网互动。


<details>
  <summary>Details</summary>
Motivation: 非道路移动机械通常处于闲置状态且具有大容量电池，这为参与能源市场、提供电网服务和创造额外收入提供了独特机会。然而，该领域缺乏V2G技术的经济和技术可行性研究。

Method: 引入了一种新颖的方法论，整合贝叶斯优化（BO）来优化能源基础设施，同时结合运营策略优化，以降低电力成本并增强电网互动。研究重点在于方法论，并以电动NRMM租赁服务为用例展示财务机会。

Result: 研究展示了在NRMM领域集成V2G技术的潜在财务机会，但受限于电动NRMM实际使用数据的可获得性。研究未涉及V2G的监管挑战，需要进一步研究来扩展模型准确性并验证结果。

Conclusion: NRMM领域的V2G集成在技术上可行且具有经济潜力，但需要更多实际数据支持，并解决监管障碍。未来研究应扩展模型准确性并验证这些发现。

Abstract: This paper investigates the economic and technical feasibility of integrating Vehicle-to-Grid (V2G) technology in the Non-Road Mobile Machinery (NRMM) sector. These often-idling assets, with their substantial battery capacities, present a unique opportunity to participate in energy markets, providing grid services and generating additional revenue. A novel methodology is introduced that integrates Bayesian Optimization (BO) to optimize the energy infrastructure together with an operating strategy optimization to reduce the electricity costs while enhancing grid interaction. While the focus lies on the methodology, the financial opportunities for the use-case of an electric NRMM rental service will be presented. However, the study is limited by the availability of real-world data on the usage of electric NRMM and does not address regulatory challenges of V2G. Further research is needed to extend the model accuracy and validate these findings.

</details>


### [107] [Hybrid Voltage and Current Control Method for Harmonic Mitigation of Single-Phase AC Loads in DC Microgrids](https://arxiv.org/abs/2512.24170)
*Mehdi Baharizadeh,Mohammad Sadegh Golsorkhi,Neda Keshavarzi,Thomas Ebel*

Main category: eess.SY

TL;DR: 提出一种混合电压电流控制方法(HCM)，用于DC微电网中同时调节DER输出电压的DC分量和控制输出电流的谐波分量，以应对单相AC负载引起的谐波问题。


<details>
  <summary>Details</summary>
Motivation: DC微电网中集成DC/AC转换器为单相AC负载供电时，负载的振荡瞬时功率会在转换器DC侧产生谐波电流，增加损耗并导致DC微电网中出现不希望的电压谐波。

Method: 提出混合电压电流控制方法(HCM)，包含内环电流控制和外环控制层。外环控制层结合DC电压控制环和输出谐波电流控制环，实现DER输出电压DC分量的调节和输出电流谐波分量的控制。

Result: 频域分析表明DC电压和谐波电流环是解耦的，没有不希望的相互作用。时域响应通过硬件在环测试结果验证了所提方案的有效性。

Conclusion: 所提出的混合控制方法能够有效缓解单相AC负载引起的谐波问题，同时实现DC电压调节和谐波电流控制，提高DC微电网的性能。

Abstract: DC microgrids provide an efficient framework for the interconnection of DC distributed energy resources (DERs) and DC loads. To continue to supply legacy single-phase AC loads, DC/AC converters can be integrated in the DC microgrid. The oscillatory instantaneous power of the single-phase AC load translates into a harmonic current on the converter's DC side, which increases the losses and causes unwanted voltage harmonics in the DC microgrid. To mitigate this issue, this paper proposes a hybrid voltage and current control method (HCM) for DERs. This scheme consists of an inner current control loop and an outer control layer which determines the reference for the inner loop. The outer control layer combines the DC voltage control loop with an output harmonic current control loop. This hybrid structure enables simultaneous regulation of the DC components of the DER output voltage and control of the harmonic component of the DER output current in accordance with the local single-phase AC load's demand. Frequency-domain analysis of the proposed method is presented to demonstrate the DC voltage and harmonic current loops are decoupled and there is no unwanted interaction between them. Additionally, time-domain response of the proposed scheme is validated through hardware-in-the-loop test results.

</details>


### [108] [Now or Never: Continuous Surveillance AIoT System for Ephemeral Events in Intermittent Sensor Networks](https://arxiv.org/abs/2512.24179)
*Joonhee Lee,Kichang Lee,Jeonggil Ko*

Main category: eess.SY

TL;DR: 提出能量感知弹性分割计算算法，解决AIoT节点在间歇性操作中因能量缓冲而错过关键瞬时事件的"可用性差距"问题，通过动态任务卸载实现连续感知。


<details>
  <summary>Details</summary>
Motivation: 野外监测（如偷猎监视、森林火灾检测）需要大规模部署免维护、无电池的AIoT节点，但这些节点计算资源有限，采用间歇性操作时会在能量缓冲期间让传感器休眠，从而错过"现在或永不"的关键瞬时事件，造成致命的"可用性差距"。

Method: 提出能量感知弹性分割计算算法，优先考虑连续感知，通过动态将计算任务卸载到能量丰富的邻近节点，使资源受限节点能够持续监测而不错过关键事件。

Result: 初步结果显示，该算法能够稳定监测额外2,496平方米的区域，每天多捕获约103个关键事件，为构建弹性、故障安全的监控系统奠定基础。

Conclusion: 该算法为解决资源受限AIoT节点在野外监测中的"可用性差距"问题提供了有效方案，通过动态任务卸载实现连续感知，为构建可靠的监控系统提供了坚实基础。

Abstract: Wilderness monitoring tasks, such as poaching surveillance and forest fire detection, require pervasive and high-accuracy sensing. While AIoT offers a promising path, covering vast, inaccessible regions necessitates the massive deployment of maintenance-free, battery-less nodes with limited computational resources. However, these constraints create a critical `Availability Gap.' Conventional intermittent operations prioritize computation throughput, forcing sensors to sleep during energy buffering. Consequently, systems miss ephemeral, `now-or-never' events (e.g., Vocalizations of natural monuments or Fire), which is fatal for detecting rare but high-stakes anomalies. To address this, we propose an Energy-aware Elastic Split Computing Algorithm that prioritizes continuous sensing by dynamically offloading tasks to energy-rich neighbors. Preliminary results demonstrate stable monitoring of an additional $2,496\;\text{m}^2$ and the capture of approximately 103 more critical events per day. Ultimately, this algorithm establishes a robust foundation for building resilient, fail-safe surveillance systems even on resource-constrained nodes.

</details>


### [109] [Safe Sliding Mode Control for Marine Vessels Using High-Order Control Barrier Functions and Fast Projection](https://arxiv.org/abs/2512.24281)
*Spyridon Syntakas,Kostas Vlachos*

Main category: eess.SY

TL;DR: 提出结合滑模控制、高阶控制屏障函数和轻量级投影的安全控制框架，用于在强环境扰动下实现过驱动3自由度水面船舶的无碰撞导航。


<details>
  <summary>Details</summary>
Motivation: 针对小型海洋机器人和水面船舶在强环境扰动（风、浪、流）下的安全导航问题，需要一种既保证鲁棒性又能强制执行避障约束，同时计算效率高适合实时嵌入式使用的控制框架。

Method: 集成滑模控制（SMC）提供对匹配扰动的鲁棒性，高阶控制屏障函数（HOCBFs）强制执行避障约束的前向不变性，快速半空间投影方法仅在需要时调整SMC控制，保持鲁棒性并最小化抖振。

Result: 仿真结果表明该框架实现了鲁棒导航、保证避障，计算效率适合实时嵌入式使用，是安全关键控制的强有力候选方案。

Conclusion: 对于计算资源有限的小型海洋机器人和水面船舶，SMC-HOCBF框架在执行速度和计算效率方面具有优势，是安全关键控制的理想选择。

Abstract: This paper presents a novel safe control framework that integrates Sliding Mode Control (SMC), High-Order Control Barrier Functions (HOCBFs) with state-dependent adaptiveness and a lightweight projection for collision-free navigation of an over-actuated 3-DOF marine surface vessel subjected to strong environmental disturbances (wind, waves, and current). SMC provides robustness to matched disturbances common in marine operations, while HOCBFs enforce forward invariance of obstacle-avoidance constraints. A fast half-space projection method adjusts the SMC control only when needed, preserving robustness and minimizing chattering. The approach is evaluated on a nonlinear marine platform model that includes added mass, hydrodynamic damping, and full thruster allocation. Simulation results show robust navigation, guaranteed obstacle avoidance, and computational efficiency suitable for real-time embedded use. For small marine robots and surface vessels with limited onboard computational resources-where execution speed and computational efficiency are critical-the SMC-HOCBF framework constitutes a strong candidate for safety-critical control.

</details>


### [110] [New Insights into Cascaded Geometric Flight Control: From Performance Guarantees to Practical Pitfalls](https://arxiv.org/abs/2512.24377)
*Brett T. Lopez*

Main category: eess.SY

TL;DR: 提出了一种用于飞行器跟踪时变位置轨迹的级联几何控制稳定性新证明，使用滑模变量和四元数滑模控制器证明指数收敛的位置轨迹跟踪在理论上可行。


<details>
  <summary>Details</summary>
Motivation: 为飞行器的级联几何控制提供更严谨的稳定性证明，揭示控制策略中姿态环跟踪误差对位置环的影响、模型不确定性对闭环系统的影响，以及控制架构的实际缺陷。

Method: 使用滑模变量和最近提出的四元数滑模控制器，通过分析级联控制系统的稳定性，建立位置轨迹跟踪的指数收敛性证明。

Result: 证明了指数收敛的位置轨迹跟踪在理论上是可行的，揭示了姿态环误差对位置环的影响机制、模型不确定性的影响方式，以及控制架构的实际局限性。

Conclusion: 该稳定性分析为级联几何控制提供了理论支撑，揭示了控制策略的关键特性，有助于改进飞行器轨迹跟踪控制的鲁棒性和实际应用。

Abstract: We present a new stability proof for cascaded geometric control used by aerial vehicles tracking time-varying position trajectories. Our approach uses sliding variables and a recently proposed quaternion-based sliding controller to demonstrate that exponentially convergent position trajectory tracking is theoretically possible. Notably, our analysis reveals new aspects of the control strategy, including how tracking error in the attitude loop influences the position loop, how model uncertainties affect the closed-loop system, and the practical pitfalls of the control architecture.

</details>


### [111] [Bayesian Subspace Identification in the MIMO Case](https://arxiv.org/abs/2512.24435)
*Alexandre Rodrigues Mesquita*

Main category: eess.SY

TL;DR: 将贝叶斯子空间系统辨识方法扩展到MIMO情况，推导新的等变先验和后验分布，并用DAISY数据集验证


<details>
  <summary>Details</summary>
Motivation: 将之前提出的贝叶斯子空间系统辨识方法扩展到多输入多输出（MIMO）场景，以处理更复杂的系统辨识问题

Method: 推导适用于MIMO框架的新等变先验分布和后验分布，扩展原有的贝叶斯子空间系统辨识方法

Result: 使用DAISY数据集进行数值验证，证明了所提出方法的有效性

Conclusion: 成功将贝叶斯子空间系统辨识方法扩展到MIMO情况，为复杂系统辨识提供了新的理论工具和验证

Abstract: This report investigates the extension of the Bayesian Subspace System Identification method proposed in our previous work to the Multiple-Input Multiple-Output (MIMO) case. We derive new equivariant priors and posterior distributions specifically suited for the MIMO framework. Numerical results utilizing the DAISY dataset are reported to validate the approach.

</details>


### [112] [Multipliers for forced Lurye systems with slope-restricted nonlinearities](https://arxiv.org/abs/2512.24453)
*William Paul Heath,Sayar Das,Joaquin Carrasco*

Main category: eess.SY

TL;DR: 动态乘子可保证斜率受限非线性Lurye系统的稳定性，但无法保证闭环系统具有有限增量增益。本文证明乘子可保证闭环功率增益有界且可量化，前提是乘子不要求非线性为奇函数。对于周期激励，系统可能出现次谐波或混沌响应，但特定乘子类可保证唯一、吸引且保周期的解。


<details>
  <summary>Details</summary>
Motivation: 传统动态乘子方法能保证Lurye系统（含斜率受限非线性）的稳定性，但无法保证系统具有有限增量增益，从而不能确保系统对噪声的低敏感性。需要研究乘子如何保证闭环功率增益有界，并处理周期激励下可能出现的次谐波或混沌响应问题。

Method: 重新审视一类能保证唯一、吸引且保周期解的乘子，使用经典工具推导这些乘子，重新考虑其应用所需假设。分析乘子的相位限制（继承自离散时间乘子），并指出除非圆判据也能应用，否则乘子不能在所有频率使用。

Result: 证明动态乘子可保证闭环功率增益有界且可量化，前提是乘子不要求非线性为奇函数。对于周期激励，特定乘子类能保证系统具有唯一、吸引且保周期的解，避免次谐波或混沌响应。但乘子有相位限制，且不能在所有频率使用，除非圆判据也适用。

Conclusion: 动态乘子可用于保证Lurye系统对噪声的低敏感性（前提是其他外生信号具有恒定稳态），但需注意乘子的相位限制和频率适用范围。对于周期激励，特定乘子类能保证良好的周期响应特性，这与动态乘子和增量稳定性的已知结果一致。

Abstract: Dynamic multipliers can be used to guarantee the stability of Lurye systems with slope-restricted nonlinearities, but give no guarantee that the closed-loop system has finite incremental gain. We show that multipliers guarantee the closed-loop power gain to be bounded and quantifiable. Power may be measured about an appropriate steady state bias term, provided the multiplier does not require the nonlinearity to be odd. Hence dynamic multipliers can be used to guarantee such Lurye systems have low sensitivity to noise, provided other exogenous signals have constant steady state. For periodic excitation, the closed-loop response can apparently have a subharmonic or chaotic response. We revisit a class of multipliers that can guarantee a unique, attractive and period-preserving solution. We show the multipliers can be derived using classical tools and reconsider assumptions required for their application. Their phase limitations are inherited from those of discrete-time multipliers. The multipliers cannot be used at all frequencies unless the circle criterion can also be applied; this is consistent with known results about dynamic multipliers and incremental stability.

</details>


### [113] [Design of Linear Residual Generators for Combined Fault Detection and Estimation in Nonlinear Systems](https://arxiv.org/abs/2512.24484)
*Sunjeev Venkateswaran,Costas Kravaris*

Main category: eess.SY

TL;DR: 提出了一种用于非线性系统故障检测与估计的线性残差生成器系统设计方法，基于扩展系统和线性外系统，具备干扰解耦特性。


<details>
  <summary>Details</summary>
Motivation: 非线性系统的故障检测与估计是工业应用中的重要问题，需要系统化的设计方法来构建有效的残差生成器，同时处理故障动态和干扰解耦。

Method: 开发线性功能观测器作为残差生成器，构建扩展系统以包含线性外系统的故障动态，确保干扰解耦特性，推导非线性系统存在此类残差生成器的充要条件。

Result: 获得了残差生成器的显式设计公式，并通过化学反应器案例研究验证了所提方法的有效性，证明了该方法在实际应用中的可行性。

Conclusion: 为非线性系统的故障检测与估计提供了一种系统化的线性残差生成器设计方法，在满足特定条件下可实现有效设计，具有实际应用价值。

Abstract: A systematic method for the design of linear residual generators for combined fault detection and estimation in nonlinear systems is developed. The proposed residual generator is a linear functional observer built for an extended system that incorporates the fault dynamics from a linear exo-system, and in addition possesses disturbance-decoupling properties. Necessary and sufficient conditions for the existence of such residual generators for nonlinear systems are derived. As long as these conditions are satisfied, we obtain explicit design formulas for the residual generator. The results are illustrated through a chemical reactor case study, which demonstrates the effectiveness of the proposed methodology.

</details>


### [114] [Energy-Aware Bayesian Control Barrier Functions for Physics-Informed Gaussian Process Dynamics](https://arxiv.org/abs/2512.24493)
*Chi Ho Leung,Philip E. Paré*

Main category: eess.SY

TL;DR: 提出EB-CBF框架，利用高斯过程学习动力学系统，通过能量感知的贝叶斯控制屏障函数实现高概率安全保证


<details>
  <summary>Details</summary>
Motivation: 研究如何系统利用高斯过程学习到的哈密顿量后验结构，设计具有高概率安全保证的能量感知控制屏障函数，特别是在机械系统和端口哈密顿系统中，安全性通常通过能量约束表达

Method: 开发贝叶斯-CBF框架，实例化为能量感知贝叶斯-CBFs（EB-CBFs），直接从哈密顿量和向量场后验构建保守的能量基屏障，产生安全过滤器，在最小修改名义控制器同时提供概率能量安全保证

Result: 在质量-弹簧系统上的数值模拟表明，所提出的EB-CBFs在噪声采样GP学习动力学下实现了高概率安全性

Conclusion: EB-CBF框架成功地将高斯过程学习与能量感知控制屏障函数结合，为学习动力学系统提供了系统化的高概率安全控制方法

Abstract: We study safe control for dynamical systems whose continuous-time dynamics are learned with Gaussian processes (GPs), focusing on mechanical and port-Hamiltonian systems where safety is naturally expressed via energy constraints. The availability of a GP Hamiltonian posterior naturally raises the question of how to systematically exploit this structure to design an energy-aware control barrier function with high-probability safety guarantees. We address this problem by developing a Bayesian-CBF framework and instantiating it with energy-aware Bayesian-CBFs (EB-CBFs) that construct conservative energy-based barriers directly from the Hamiltonian and vector-field posteriors, yielding safety filters that minimally modify a nominal controller while providing probabilistic energy safety guarantees. Numerical simulations on a mass-spring system demonstrate that the proposed EB-CBFs achieve high-probability safety under noisy sampled GP-learned dynamics.

</details>


### [115] [A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction](https://arxiv.org/abs/2512.24542)
*Bo Li,Zijun Chen,Haiwang Zhong,Di Cao,Guangchun Ruan*

Main category: eess.SY

TL;DR: 提出基于辅助任务学习的图神经网络方法，用于重建WAMS中缺失的PMU数据，解决了现有方法在概念漂移、高缺失率和系统不完全可观测性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法存在三个主要问题：1) 难以适应电力系统中的概念漂移；2) 在高缺失率下鲁棒性差；3) 依赖系统完全可观测的不现实假设。需要一种能克服这些限制的PMU数据重建方法。

Method: 提出辅助任务学习框架：1) 使用K跳图神经网络直接在PMU节点子图上学习，克服系统不完全可观测限制；2) 设计两个互补的图网络：时空GNN提取时空依赖关系重建缺失值，辅助GNN利用PMU数据的低秩特性实现无监督在线学习。

Result: 数值实验表明，该方法在高缺失率和不完全可观测条件下，在离线和在线场景中都表现出优越的性能。

Conclusion: 提出的辅助任务学习方法通过动态利用PMU数据的低秩特性，实现了鲁棒和自适应的PMU数据重建，有效解决了现有方法的局限性。

Abstract: In wide-area measurement systems (WAMS), phasor measurement unit (PMU) measurement is prone to data missingness due to hardware failures, communication delays, and cyber-attacks. Existing data-driven methods are limited by inadaptability to concept drift in power systems, poor robustness under high missing rates, and reliance on the unrealistic assumption of full system observability. Thus, this paper proposes an auxiliary task learning (ATL) method for reconstructing missing PMU data. First, a K-hop graph neural network (GNN) is proposed to enable direct learning on the subgraph consisting of PMU nodes, overcoming the limitation of the incompletely observable system. Then, an auxiliary learning framework consisting of two complementary graph networks is designed for accurate reconstruction: a spatial-temporal GNN extracts spatial-temporal dependencies from PMU data to reconstruct missing values, and another auxiliary GNN utilizes the low-rank property of PMU data to achieve unsupervised online learning. In this way, the low-rank properties of the PMU data are dynamically leveraged across the architecture to ensure robustness and self-adaptation. Numerical results demonstrate the superior offline and online performance of the proposed method under high missing rates and incomplete observability.

</details>


### [116] [Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance](https://arxiv.org/abs/2512.24619)
*Yunian Pan,Jun Li,Lifan Xu,Shunqiao Sun,Quanyan Zhu*

Main category: eess.SY

TL;DR: 提出时间-频率无遗憾跳频算法，通过博弈论框架解决汽车雷达相互干扰问题，在频谱和时间资源上自适应调整，显著提升信干噪比和距离-多普勒质量。


<details>
  <summary>Details</summary>
Motivation: 汽车FMCW雷达在现代ADAS和自动驾驶系统中不可或缺，但雷达密度增加加剧了相互干扰风险。现有缓解技术存在可扩展性限制、依赖旁路通信或降低距离-多普勒分辨率等问题。

Method: 引入统一的时间-频率博弈论框架，将干扰避免问题建模为重复反协调博弈。每个雷达使用遗憾最小化动态，在频率子带和啁啾级时间偏移上自主更新混合策略。提出时间-频率无遗憾跳频算法。

Result: 算法实现了消失的外部遗憾和交换遗憾，诱导的经验博弈收敛到ε-粗相关均衡或相关均衡。理论分析提供了联合域的遗憾界限。数值实验显示，与时间-频率随机跳频和集中式纳什基准相比，在多雷达场景中显著改善了SINR、碰撞率和距离-多普勒质量。

Conclusion: 提出的时间-频率无遗憾跳频算法为汽车雷达干扰避免提供了有效的分布式解决方案，通过时间自适应隐式正则化频率选择，增强了对异步干扰的鲁棒性。

Abstract: Automotive FMCW radars are indispensable to modern ADAS and autonomous-driving systems, but their increasing density has intensified the risk of mutual interference. Existing mitigation techniques, including reactive receiver-side suppression, proactive waveform design, and cooperative scheduling, often face limitations in scalability, reliance on side-channel communication, or degradation of range-Doppler resolution. Building on our earlier work on decentralized Frequency-Domain No-Regret hopping, this paper introduces a unified time-frequency game-theoretic framework that enables radars to adapt across both spectral and temporal resources. We formulate the interference-avoidance problem as a repeated anti-coordination game, in which each radar autonomously updates a mixed strategy over frequency subbands and chirp-level time offsets using regret-minimization dynamics. We show that the proposed Time-Frequency No-Regret Hopping algorithm achieves vanishing external and swap regret, and that the induced empirical play converges to an $\varepsilon$-coarse correlated equilibrium or a correlated equilibrium. Theoretical analysis provides regret bounds in the joint domain, revealing how temporal adaptation implicitly regularizes frequency selection and enhances robustness against asynchronous interference. Numerical experiments with multi-radar scenarios demonstrate substantial improvements in SINR, collision rate, and range-Doppler quality compared with time-frequency random hopping and centralized Nash-based benchmarks.

</details>


### [117] [Taking Advantage of Rational Canonical Form for Faster Ring-LWE based Encrypted Controller with Recursive Multiplication](https://arxiv.org/abs/2512.24658)
*Donghyeon Song,Yeongjun Jang,Joowon Lee,Junsoo Kim*

Main category: eess.SY

TL;DR: 提出一种基于Ring-LWE加密的高效线性动态控制器实现方法，通过系统理论方法显著降低递归乘法的时间和空间复杂度


<details>
  <summary>Details</summary>
Motivation: 传统加密控制器实现中，对状态矩阵的完全加密和递归乘法操作计算成本高，需要更高效的方法来降低时间和空间复杂度

Method: 1) 将状态矩阵转换为有理标准形式，利用其稀疏和循环结构，仅对非平凡列进行加密和计算；2) 提出新颖的"打包"方法，将输入和输出矩阵分别打包为单个多项式，减少同态操作数量

Result: 仿真结果表明，所提设计实现了显著快速的加密控制器实现，大幅降低了计算复杂度

Conclusion: 通过系统理论方法结合Ring-LWE加密，实现了高效的加密线性动态控制器，为安全控制系统提供了实用的解决方案

Abstract: This paper aims to provide an efficient implementation of encrypted linear dynamic controllers that perform recursive multiplications on a Ring-Learning With Errors (Ring-LWE) based cryptosystem. By adopting a system-theoretical approach, we significantly reduce both time and space complexities, particularly the number of homomorphic operations required for recursive multiplications. Rather than encrypting the entire state matrix of a given controller, the state matrix is transformed into its rational canonical form, whose sparse and circulant structure enables that encryption and computation are required only on its nontrivial columns. Furthermore, we propose a novel method to ``pack'' each of the input and the output matrices into a single polynomial, thereby reducing the number of homomorphic operations. Simulation results demonstrate that the proposed design enables a remarkably fast implementation of encrypted controllers.

</details>


### [118] [Waste-to-Energy-Coupled AI Data Centers: Cooling Efficiency and Grid Resilience](https://arxiv.org/abs/2512.24683)
*Qi He,Chunyu Qu*

Main category: eess.SY

TL;DR: 提出将废弃物发电与AI数据中心耦合的系统，利用废热驱动吸收式制冷替代传统电制冷，解决AI数据中心扩张中的电力和冷却瓶颈问题


<details>
  <summary>Details</summary>
Motivation: AI数据中心扩张面临电力供应和冷却能力的双重约束，需要创新的能源解决方案来应对电网压力和冷却需求

Method: 提出废弃物发电-AI数据中心耦合配置，通过能量品位匹配，利用低品位废热驱动吸收式制冷，建立输入输出"黑箱"模型，与传统电网供电的机械制冷进行对比分析

Result: 系统经济优势取决于三个关键因素：冷却对IT热负荷的覆盖率、运输和辅助设备的寄生电力消耗、距离驱动的输送衰减，存在一个盈亏平衡走廊，超过该范围净收益消失

Conclusion: 该框架为电网压力下的城市AI走廊提供了可落地的废弃物发电-AI数据中心耦合可行性条件，通过可计算的计算平准化成本和ESG估值渠道实现决策支持

Abstract: AI data-center expansion is increasingly constrained by the coupled availability of deliverable electricity and heat-rejection (cooling) capacity. We propose and evaluate an integrated Waste-to-Energy-AI Data Center configuration that treats cooling as a first-class energy service rather than an unavoidable electricity burden. The coupled system is modeled as an input-output 'black box' with transparent boundaries and a standalone benchmark in which mechanical chilling is powered by grid electricity. The central mechanism is energy-grade matching: low-grade WtE thermal output drives absorption cooling to deliver chilled service, thereby displacing baseline cooling electricity. We show that thermoeconomic superiority is governed by three first-order determinants, (i) cooling coverage of IT heat load, (ii) parasitic electricity for transport and auxiliaries, and (iii) distance-driven delivery decay, yielding a break-even corridor beyond which net benefits vanish. Comparative statics characterize sensitivity to IT utilization, feedstock quality (waste LHV and throughput), climate parameterization, and corridor distance. We translate these accounting gains into decision language through a computable prototype for Levelized Cost of Computing (LCOC) and an ESG valuation channel grounded in measurable mechanisms, without re-deriving full lifecycle inventories. The framework provides siting-ready feasibility conditions for WtE-AIDC coupling in urban AI corridors under grid stress.

</details>


### [119] [Average Consensus with Dynamic Quantization Framing and Finite-Time Termination over Limited-Bandwidth Directed Networks](https://arxiv.org/abs/2512.24700)
*Evagoras Makridis,Gabriele Oliva,Apostolos I. Rikos,Themistoklis Charalambous*

Main category: eess.SY

TL;DR: 提出PP-ACDC算法，在非平衡有向图上使用固定量化比特数实现精确平均共识，结合Push-Pull共识动态和动态量化框架，支持有限比特通信下的精确收敛。


<details>
  <summary>Details</summary>
Motivation: 针对大规模资源受限多智能体系统在有向网络中的平均共识问题，传统方法需要无限精度通信或大量比特，而现有量化方法通常需要渐进增加的比特数或无法保证精确收敛。

Method: 结合Push-Pull（盈余）共识动态与动态量化框架（缩放和中点偏移），在保持全局平均值的同时逐步提升量化精度，并设计了分布式同步有限时间终止机制。

Result: 在任意强连通有向图上实现渐近精确平均共识，提供ε-收敛的有限迭代次数检测证明，数值模拟验证了在严格比特预算下的可靠、通信高效和精确收敛性能。

Conclusion: PP-ACDC算法为有向网络上资源受限的大规模多智能体系统提供了一种通信高效且精确的平均共识解决方案，在有限比特预算下实现了可靠性能。

Abstract: This paper proposes a deterministic distributed algorithm, referred to as PP-ACDC, that achieves exact average consensus over possibly unbalanced directed graphs using only a fixed and a priori specified number of quantization bits. The method integrates Push-Pull (surplus) consensus dynamics with a dynamic quantization framing scheme combining zooming and midpoint shifting, enabling agents to preserve the true global average while progressively refining their quantization precision. We establish a rigorous convergence theory showing that PP-ACDC achieves asymptotic (exact) average consensus on any strongly connected digraph under appropriately chosen quantization parameters. Moreover, we develop a fully distributed and synchronized finite-time termination mechanism, and we provide a formal proof on the detection of $ε$-convergence to the average within a finite number of iterations. Numerical simulations corroborate the theoretical results and demonstrate that PP-ACDC achieves reliable, communication-efficient, and precise average consensus even under very tight bit budgets, underscoring its suitability for large-scale and resource-constrained multi-agent systems operating over directed networks.

</details>


### [120] [Exact compensation of communication delays for discrete-time heterogeneous multi-agent linear systems with applications to SIR epidemic model](https://arxiv.org/abs/2512.24735)
*Qin Fang,Mamadou Diagne,Yang Zhu*

Main category: eess.SY

TL;DR: 提出基于预测的分布式控制框架，解决离散时间异构多智能体系统在通信延迟下的输出同步问题，通过预测器补偿延迟影响，在有限步内实现精确同步。


<details>
  <summary>Details</summary>
Motivation: 异构多智能体系统中存在的通信延迟会阻碍邻居节点信息的即时传递，严重降低标准分布式控制方案的性能，需要有效的延迟补偿机制。

Method: 提出预测框架进行精确延迟补偿，引入预测器结合分布式预测机制，递归重构网络中的未来状态信息，构建基于预测的分布式观测器，并设计状态反馈和动态输出反馈控制器。

Result: 理论分析证实所提策略能在有限步内消除延迟影响，确保输出同步。数值仿真和基于Koopman算子的SIR流行病模型验证了有效性，在400万人口中，延迟补偿策略使感染峰值减少超过20万人。

Conclusion: 提出的预测框架能有效补偿异构多智能体系统中的通信延迟，实现输出同步，在流行病控制等实际应用中具有重要价值。

Abstract: This paper investigates the output synchronization problem for discrete-time heterogeneous multi-agent systems (MASs) subject to distinct communication delays. The presence of such delays prevents the instantaneous delivery of information from neighboring nodes, thereby severely degrading the performance of standard distributed control schemes. To overcome this, we propose a prediction-based framework for exact delay compensation. Specifically, we introduce predictors combined with a mechanism of distributed predictors, which enables the recursive reconstruction of future state information across the communication network. Building upon these predictors, we construct prediction-based distributed observers and formulate both prediction-based distributed state-feedback and dynamic output-feedback controllers. Theoretical analysis confirms that the proposed strategy eliminates the impact of delays after a finite number of steps, ensuring output synchronization. The effectiveness of the methods is validated through a numerical example and a Koopman operator-based linear Susceptible-Infected-Recovered (SIR) epidemic model. Notably, for a population of 4 million, the proposed delay compensation strategy achieves a reduction of over 200,000 infected individuals at the peak, underscoring its potential significance in epidemic mitigation.

</details>


### [121] [Trustworthy Equipment Monitoring via Cascaded Anomaly Detection and Thermal Localization](https://arxiv.org/abs/2512.24755)
*Sungwoo Kang*

Main category: eess.SY

TL;DR: 提出级联异常检测框架，将检测与定位解耦：第一阶段使用LSTM传感器编码器进行高精度检测，第二阶段激活CNN热成像编码器进行故障定位。研究发现仅使用传感器数据比多模态融合性能更好，并揭示了融合模型中的"模态偏见"问题。


<details>
  <summary>Details</summary>
Motivation: 预测性维护需要准确的异常检测和可信的解释。虽然传感器时间序列和热成像的多模态融合有前景，但作者发现简单的融合策略反而会降低性能，因此需要更智能的融合方法。

Method: 提出级联异常检测框架：第一阶段使用基于LSTM的传感器编码器（带时间注意力）进行异常检测；第二阶段在检测到异常后激活基于CNN的热成像编码器进行故障定位。还开发了包含SHAP、时空注意力和门权重分析的可解释性流水线。

Result: 仅使用传感器数据的检测性能（93.08% F1分数）比完全多模态融合（84.79% F1分数）高出8.3个百分点。可解释性分析揭示了"模态偏见"现象：融合模型将65-87%的权重分配给较弱的热成像模态。在真实轴承数据集（78,397个样本）上实现了最先进的精度。

Conclusion: 多模态融合并不总是提高性能，需要谨慎设计融合策略。级联方法在保持高检测精度的同时提供可解释的故障定位，为维护决策提供可行诊断。揭示了融合模型中的模态偏见问题，对多模态学习有重要启示。

Abstract: Predictive maintenance demands accurate anomaly detection and trustable explanations. Although multimodal fusion of sensor time-series and thermal imagery shows promise, we demonstrate that naive fusion strategies can paradoxically degrade performance. This paper introduces a Cascaded Anomaly Detection framework that decouples detection and localization. Stage 1 employs an LSTM-based sensor encoder with temporal attention for high-accuracy detection, while Stage 2 activates a CNN-based thermal encoder for post-detection fault localization. Our results reveal that sensor-only detection outperforms full fusion by 8.3 percentage points (93.08% vs. 84.79% F1-score), challenging the assumption that additional modalities invariably improve performance. We further contribute an explainability pipeline integrating SHAP, temporal/spatial attention, and gate weight analysis. This analysis uncovers a "modality bias" where fusion models assign 65-87% weight to the weaker thermal modality. Validated on a real-world bearing dataset (78,397 samples), our cascaded approach achieves state-of-the-art accuracy while providing actionable diagnostics for maintenance decision-making.

</details>


### [122] [Heterogeneous Multi-Agent Multi-Target Tracking using Cellular Sheaves](https://arxiv.org/abs/2512.24886)
*Tyler Hanks,Cristian F. Nino,Joana Bou Barcelo,Austin Copeland,Warren Dixon,James Fairbanks*

Main category: eess.SY

TL;DR: 本文提出了一种基于胞腔层（cellular sheaf）理论的多智能体目标跟踪方法，能够处理非线性动态和异构智能体系统，其中状态空间维度可能不同。


<details>
  <summary>Details</summary>
Motivation: 传统图拉普拉斯方法难以处理非线性动态和异构智能体（状态空间维度不同）的多目标跟踪问题。现有协调层框架主要关注共识等合作问题，需要扩展到非合作的目标跟踪场景。

Method: 利用胞腔层理论作为图论的数学推广，将多目标跟踪问题建模为胞腔层上的调和扩展问题。开发了基于层拉普拉斯算子的分散控制律，并提供了基于李雅普诺夫理论的稳定性分析。

Result: 提出的方法能够处理非线性动态和外部干扰，通过仿真验证了跟踪误差的收敛性，为异构多智能体系统的目标跟踪提供了理论保证。

Conclusion: 胞腔层理论为处理异构多智能体系统的非线性目标跟踪问题提供了有效的数学框架，扩展了现有协调层框架的应用范围，为解决传统图方法难以处理的复杂系统提供了新途径。

Abstract: Multi-agent target tracking in the presence of nonlinear dynamics and agent heterogeneity, where state-space dimensions may differ, is a challenging problem that traditional graph Laplacian methods cannot easily address. This work leverages the framework of cellular sheaves, a mathematical generalization of graph theory, to natively model such heterogeneous systems. While existing coordination sheaf frameworks focus on cooperative problems like consensus, this work extends them to the non-cooperative target-tracking problem. The tracking of multiple, unknown targets is formulated as a harmonic extension problem on a cellular sheaf, accommodating nonlinear dynamics and external disturbances for all agents. A decentralized control law is developed using the sheaf Laplacian, and a corresponding Lyapunov-based stability analysis is provided to guarantee tracking error convergence, with results validated by simulation.

</details>


### [123] [One-Shot Camera-Based Extrusion Optimization for High Speed Fused Filament Fabrication](https://arxiv.org/abs/2512.24905)
*Yufan Lin,Xavier Guidetti,Yannick Nagel,Efe C. Balta,John Lygeros*

Main category: eess.SY

TL;DR: 提出一个仅需标准3D打印机和手机摄像头的端到端优化框架，通过一次性校准识别挤出动态和转角行为，生成优化G代码，实现高速打印质量提升


<details>
  <summary>Details</summary>
Motivation: 商用熔融沉积成型3D打印机在高速打印时存在打印头运动与材料挤出系统动态不同步问题，导致转角过度挤出等质量损失。现有方法需要专用硬件、复杂校准或固件修改，对大多数用户不可及。

Method: 采用一次性校准方法：打印两个简单图案并用手机摄像头捕捉，识别挤出动态和转角行为；基于识别系统建立模型约束最优控制策略，生成同步运动和挤出的优化G代码。

Result: 实验显示宽度跟踪误差减小、转角缺陷缓解、表面粗糙度降低，在3600 mm/min速度下达到与常规1600 mm/min相当的表面质量，有效将生产速度提高一倍。

Conclusion: 这种易获取、硬件需求最小的方法使广大熔融沉积成型用户能够实现高质量、高速的增材制造，无需复杂设置。

Abstract: Off-the-shelf fused filament fabrication 3D printers are widely accessible and convenient, yet they exhibit quality loss at high speeds due to dynamic mis-synchronization between printhead motion and material extrusion systems, notably corner over-extrusion. Existing methods require specialized hardware, extensive calibration, or firmware modifications that are inaccessible to most users. This work presents a practical, end-to-end optimization framework that enhances high-speed printing using only standard 3D printers and a phone camera, without requiring additional complex setup. The method employs a one-shot calibration approach in which two simple printed patterns, captured by a phone camera, enable identification of extrusion dynamics and cornering behavior. The identified systems enable a model-based constrained optimal control strategy that generates optimized G-code, synchronizing motion and extrusion. Experiments show reduced width tracking error, mitigated corner defects, and lower surface roughness, achieving surface quality at 3600 mm/min comparable to conventional printing at 1600 mm/min, effectively doubling production speed while maintaining print quality. This accessible, hardware-minimal approach enables a wide range of fused filament fabrication users to achieve high-quality, high-speed additive manufacturing.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [124] [A Test of Lookahead Bias in LLM Forecasts](https://arxiv.org/abs/2512.23847)
*Zhenyu Gao,Wenxi Jiang,Yutong Yan*

Main category: q-fin.GN

TL;DR: 开发了一种检测大型语言模型经济预测中前瞻性偏差的统计检验方法，通过估计提示在训练数据中的出现概率来识别模型是否利用了未来信息。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在经济预测中的应用日益广泛，需要一种方法来检测模型是否利用了训练数据中的未来信息（前瞻性偏差），以确保预测的有效性和可靠性。

Method: 使用最先进的预训练数据检测技术，估计给定提示出现在LLM训练语料库中的可能性（称为前瞻性倾向LAP），并证明LAP与预测准确性之间的正相关关系表明前瞻性偏差的存在和程度。

Result: 该方法应用于两个预测任务：新闻标题预测股票回报和财报电话会议记录预测资本支出，能够有效检测前瞻性偏差。

Conclusion: 该检验提供了一种成本效益高、诊断性强的工具，用于评估LLM生成预测的有效性和可靠性，有助于识别和量化前瞻性偏差。

Abstract: We develop a statistical test to detect lookahead bias in economic forecasts generated by large language models (LLMs). Using state-of-the-art pre-training data detection techniques, we estimate the likelihood that a given prompt appeared in an LLM's training corpus, a statistic we term Lookahead Propensity (LAP). We formally show that a positive correlation between LAP and forecast accuracy indicates the presence and magnitude of lookahead bias, and apply the test to two forecasting tasks: news headlines predicting stock returns and earnings call transcripts predicting capital expenditures. Our test provides a cost-efficient, diagnostic tool for assessing the validity and reliability of LLM-generated forecasts.

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [125] [Generative AI-enhanced Sector-based Investment Portfolio Construction](https://arxiv.org/abs/2512.24526)
*Alina Voronina,Oleksandr Romanko,Ruiwen Cao,Roy H. Kwon,Rafael Mendoza-Arriaga*

Main category: q-fin.PM

TL;DR: LLM在稳定市场能跑赢行业指数，但在波动市场表现不佳；LLM选股结合传统优化方法能提升投资组合表现和一致性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在量化行业投资组合构建中的应用潜力，评估不同主流LLM提供商模型在投资管理中的表现，探索AI与量化金融结合的可行性。

Method: 使用OpenAI、Google、Anthropic、DeepSeek和xAI的LLM模型，让每个模型为S&P 500行业指数选择和分配20只股票权重，结合经典投资组合优化方法，在两个不同样本外时期（稳定期2025年1-3月，波动期2025年4-6月）评估表现。

Result: LLM投资组合表现具有强烈的时间依赖性：稳定市场条件下，LLM加权投资组合在累计收益和风险调整后收益（夏普比率）上经常跑赢行业指数；但在波动时期，多数LLM投资组合表现不佳，表明当前模型可能难以适应训练数据中代表性不足的市场机制转变或高波动环境。

Conclusion: LLM能有效补充量化金融，增强选股能力和可解释性，但其可靠性依赖于市场环境。混合AI-量化框架（整合LLM推理与成熟优化技术）有潜力产生更稳健和适应性的投资策略。

Abstract: This paper investigates how Large Language Models (LLMs) from leading providers (OpenAI, Google, Anthropic, DeepSeek, and xAI) can be applied to quantitative sector-based portfolio construction. We use LLMs to identify investable universes of stocks within S&P 500 sector indices and evaluate how their selections perform when combined with classical portfolio optimization methods. Each model was prompted to select and weight 20 stocks per sector, and the resulting portfolios were compared with their respective sector indices across two distinct out-of-sample periods: a stable market phase (January-March 2025) and a volatile phase (April-June 2025).
  Our results reveal a strong temporal dependence in LLM portfolio performance. During stable market conditions, LLM-weighted portfolios frequently outperformed sector indices on both cumulative return and risk-adjusted (Sharpe ratio) measures. However, during the volatile period, many LLM portfolios underperformed, suggesting that current models may struggle to adapt to regime shifts or high-volatility environments underrepresented in their training data. Importantly, when LLM-based stock selection is combined with traditional optimization techniques, portfolio outcomes improve in both performance and consistency.
  This study contributes one of the first multi-model, cross-provider evaluations of generative AI algorithms in investment management. It highlights that while LLMs can effectively complement quantitative finance by enhancing stock selection and interpretability, their reliability remains market-dependent. The findings underscore the potential of hybrid AI-quantitative frameworks, integrating LLM reasoning with established optimization techniques, to produce more robust and adaptive investment strategies.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [126] [Forward-Oriented Causal Observables for Non-Stationary Financial Markets](https://arxiv.org/abs/2512.24621)
*Lucas A. Souza*

Main category: q-fin.CP

TL;DR: 该论文研究金融时间序列的短时预测，在严格因果约束下构建可解释的因果信号，而非直接预测价格。通过因果中心化、线性聚合、卡尔曼滤波和自适应前向算子等方法构造信号，并在高频EURUSDT数据上验证其经济相关性。


<details>
  <summary>Details</summary>
Motivation: 金融市场是非平稳随机系统，传统预测模型难以在严格因果约束下有效工作。作者希望构建可解释的因果信号，而非直接预测价格，以应对市场非平稳性和因果约束的挑战。

Method: 1) 因果中心化处理；2) 将动量、成交量压力、趋势加速度和波动率标准化价格位置等微观特征线性聚合为复合观测值；3) 使用一维卡尔曼滤波进行因果稳定化；4) 引入自适应"前向"算子混合复合信号和平滑因果导数项；5) 将最终观测值映射为透明决策函数。

Result: 在高频EURUSDT（1分钟）数据上的应用表明，因果构建的观测值在特定市场机制下具有显著经济相关性，但在后续机制转换时会性能下降，揭示了因果信号设计在非平稳市场中的潜力和局限性。

Conclusion: 因果信号设计在非平稳金融市场中具有实际应用潜力，但需要认识到其机制依赖性和局限性。该方法提供了一种在严格因果约束下构建可解释交易信号的新思路。

Abstract: We study short-horizon forecasting in financial time series under strict causal constraints, treating the market as a non-stationary stochastic system in which any predictive observable must be computable online from information available up to the decision time. Rather than proposing a machine-learning predictor or a direct price-forecast model, we focus on \emph{constructing} an interpretable causal signal from heterogeneous micro-features that encode complementary aspects of the dynamics (momentum, volume pressure, trend acceleration, and volatility-normalized price location). The construction combines (i) causal centering, (ii) linear aggregation into a composite observable, (iii) causal stabilization via a one-dimensional Kalman filter, and (iv) an adaptive ``forward-like'' operator that mixes the composite signal with a smoothed causal derivative term. The resulting observable is mapped into a transparent decision functional and evaluated through realized cumulative returns and turnover. An application to high-frequency EURUSDT (1-minute) illustrates that causally constructed observables can exhibit substantial economic relevance in specific regimes, while degrading under subsequent regime shifts, highlighting both the potential and the limitations of causal signal design in non-stationary markets.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [127] [Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization](https://arxiv.org/abs/2512.23804)
*Zhendong Li,Akwum Onwunta,Bedřich Sousedík*

Main category: math.OC

TL;DR: 开发用于具有不确定系数的PDE最优控制问题的高效分层预处理器，通过截断随机展开平衡计算成本与预处理质量，显著加速迭代求解器收敛。


<details>
  <summary>Details</summary>
Motivation: 解决不确定性量化中出现的大规模、病态线性系统挑战，为具有不确定系数的偏微分方程最优控制问题提供高效求解方法。

Method: 采用离散化-优化框架，结合有限元离散、随机Galerkin近似和先进时间离散方案；利用广义多项式混沌展开的稀疏性，基于截断随机展开推导分层预处理器。

Result: 数值实验表明，相比现有方法，所提出的预处理器显著加速了迭代求解器的收敛，为稳态和时变不确定性最优控制应用提供了鲁棒高效的求解器。

Conclusion: 通过截断随机展开的分层预处理器在计算成本与预处理质量之间取得了有效平衡，为具有不确定系数的PDE最优控制问题提供了高效的求解方案。

Abstract: We develop efficient hierarchical preconditioners for optimal control problems governed by partial differential equations with uncertain coefficients. Adopting a discretize-then-optimize framework that integrates finite element discretization, stochastic Galerkin approximation, and advanced time-discretization schemes, the approach addresses the challenge of large-scale, ill-conditioned linear systems arising in uncertainty quantification. By exploiting the sparsity inherent in generalized polynomial chaos expansions, we derive hierarchical preconditioners based on truncated stochastic expansion that strike an effective balance between computational cost and preconditioning quality. Numerical experiments demonstrate that the proposed preconditioners significantly accelerate the convergence of iterative solvers compared to existing methods, providing robust and efficient solvers for both steady-state and time-dependent optimal control applications under uncertainty.

</details>


### [128] [The Flow-Limit of Reflect-Reflect-Relax: Existence, Stability, and Discrete-Time Behavior](https://arxiv.org/abs/2512.23843)
*Manish Krishan Lal*

Main category: math.OC

TL;DR: 本文研究了Reflect-Reflect-Relax（RRR）算法在小步长（流极限）机制下的行为，分析了其横向动力学、Lyapunov稳定性、离散化特性，并提出了基于渗流和重整化群的启发式框架来解释性能退化。


<details>
  <summary>Details</summary>
Motivation: 研究RRR算法在小步长机制下的动力学行为，理解其收敛特性、稳定性以及离散化与连续流之间的关系，特别是解释迭代最优松弛参数的出现原因。

Method: 采用小步长（流极限）分析方法，研究平滑横向设置下的横向动力学，构建可行流形上的管状邻域，分析离散设置下的Filippov滑动，证明小步长RRR是该流的前向欧拉离散化，并引入基于渗流和重整化群的启发式框架。

Result: 在平滑横向设置下，横向动力学形成双曲汇，导致自然间隙度量的指数衰减；在均匀几何假设下，平方间隙定义了严格Lyapunov函数，排除了该盆地内的循环动力学和混沌行为；离散设置中，诱导流在W域上分段常数，支持沿收敛边界的Filippov滑动，导致有限时间捕获到解域；小步长RRR是该流的前向欧拉离散化，解释了迭代最优松弛参数的出现。

Conclusion: RRR算法在小步长机制下表现出良好的收敛特性，其离散化与连续流之间存在明确关系，迭代最优松弛参数的出现可以通过离散化与流极限的关系来解释，而基于渗流和重整化群的框架有助于理解Douglas-Rachford极限附近的性能退化。

Abstract: We study the Reflect-Reflect-Relax (RRR) algorithm in its small-step (flow-limit) regime. In the smooth transversal setting, we show that the transverse dynamics form a hyperbolic sink, yielding exponential decay of a natural gap measure. Under uniform geometric assumptions, we construct a tubular neighborhood of the feasible manifold on which the squared gap defines a strict Lyapunov function, excluding recurrent dynamics and chaotic behavior within this basin.
  In the discrete setting, the induced flow is piecewise constant on W-domains and supports Filippov sliding along convergent boundaries, leading to finite-time capture into a solution domain. We prove that small-step RRR is a forward-Euler discretization of this flow, so that solution times measured in rescaled units converge to a finite limit while iteration counts diverge, explaining the emergence of iteration-optimal relaxation parameters. Finally, we introduce a heuristic mesoscopic framework based on percolation and renormalization group to organize performance deterioration near the Douglas-Rachford limit.

</details>


### [129] [Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data](https://arxiv.org/abs/2512.24056)
*Wenye Li,Hongxu Chen,Jiacai Liu,Ke Wei*

Main category: math.OC

TL;DR: 本文研究了策略镜像下降（PMD）方法在马尔可夫采样模型下的样本复杂度，提出了两种基于时序差分学习的算法，并分析了其达到ε最优性所需的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有关于策略镜像下降的样本复杂度分析要么关注生成采样模型，要么在马尔可夫采样模型中需要预先指定动作值的近似精度。本文旨在研究在马尔可夫采样模型下，结合时序差分学习的策略镜像下降的样本复杂度。

Method: 提出了两种算法：Expected TD-PMD（离策略算法）和Approximate TD-PMD（混合策略算法）。在足够小的常数策略更新步长下，使用时序差分学习进行策略评估，并分析了其样本复杂度。

Result: 在常数策略更新步长下，两种算法达到平均时间ε最优性的样本复杂度为Õ(ε⁻²)。通过自适应策略更新步长，达到最后迭代ε最优性的样本复杂度可进一步改进为O(ε⁻²)，去除了对数因子。

Conclusion: 本文首次在马尔可夫采样模型下，结合时序差分学习分析了策略镜像下降的样本复杂度，为策略优化方法提供了理论保证，并展示了自适应步长策略能进一步改善样本复杂度。

Abstract: This paper studies the policy mirror descent (PMD) method, which is a general policy optimization framework in reinforcement learning and can cover a wide range of policy gradient methods by specifying difference mirror maps. Existing sample complexity analysis for policy mirror descent either focuses on the generative sampling model, or the Markovian sampling model but with the action values being explicitly approximated to certain pre-specified accuracy. In contrast, we consider the sample complexity of policy mirror descent with temporal difference (TD) learning under the Markovian sampling model. Two algorithms called Expected TD-PMD and Approximate TD-PMD have been presented, which are off-policy and mixed policy algorithms respectively. Under a small enough constant policy update step size, the $\tilde{O}(\varepsilon^{-2})$ (a logarithm factor about $\varepsilon$ is hidden in $\tilde{O}(\cdot)$) sample complexity can be established for them to achieve average-time $\varepsilon$-optimality. The sample complexity is further improved to $O(\varepsilon^{-2})$ (without the hidden logarithm factor) to achieve the last-iterate $\varepsilon$-optimality based on adaptive policy update step sizes.

</details>


### [130] [Complexity and convergence analysis of a single-loop SDCAM for Lipschitz composite optimization and beyond](https://arxiv.org/abs/2512.24059)
*Hao Zhang,Naoki Marumo,Ting Kei Pong,Akiko Takeda*

Main category: math.OC

TL;DR: 提出一种单循环算法，用于最小化三个函数之和：可微函数f、邻近友好的g，以及复合函数h∘c。该算法适用于h非Lipschitz连续的一般情况，改进了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有单循环算法主要针对h是Lipschitz连续函数或闭凸集指示函数的情况，但在许多实际应用中，h可能是非Lipschitz的。本文旨在开发适用于更一般非Lipschitz h的单循环算法。

Method: 提出一种单循环变体的逐次凸差逼近方法（SDCAM）。算法处理目标函数为f(x)+g(x)+h(c(x))的形式，其中f可微，g和h是邻近友好的非光滑函数，c是连续可微映射。

Result: 1) 当h是Lipschitz连续时，算法达到已知最佳的(ε₁,ε₂,0)-稳定点的迭代复杂度；2) 当h仅为连续实值函数且dom g紧致时，获得(ε,ε,ε)-稳定点的迭代复杂度为$\tilde{O}(ε^{-4})$；3) 当h定义域不全时，建立了迭代点连续变化的消失界。

Conclusion: 该单循环算法能处理更一般的非Lipschitz h，在三种情况下都能构造子序列使得任何聚点x*满足c(x*)∈dom h，且若在x*处满足标准约束条件，则x*是稳定点。

Abstract: We develop and analyze a single-loop algorithm for minimizing the sum of a Lipschitz differentiable function $f$, a prox-friendly proper closed function $g$ (with a closed domain on which $g$ is continuous) and the composition of another prox-friendly proper closed function $h$ (whose domain is closed on which $h$ is continuous) with a continuously differentiable mapping $c$ (that is Lipschitz continuous and Lipschitz differentiable on the convex closure of the domain of $g$). Such models arise naturally in many contemporary applications, where $f$ is the loss function for data misfit, and $g$ and $h$ are nonsmooth functions for inducing desirable structures in $x$ and $c(x)$. Existing single-loop algorithms mainly focus either on the case where $h$ is Lipschitz continuous or the case where $h$ is an indicator function of a closed convex set. In this paper, we develop a single-loop algorithm for more general possibly non-Lipschitz $h$. Our algorithm is a single-loop variant of the successive difference-of-convex approximation method (SDCAM) proposed in [22]. We show that when $h$ is Lipschitz, our algorithm exhibits an iteration complexity that matches the best known complexity result for obtaining an $(ε_1,ε_2,0)$-stationary point. Moreover, we show that, by assuming additionally that dom $g$ is compact, our algorithm exhibits an iteration complexity of $\tilde{O}(ε^{-4})$ for obtaining an $(ε,ε,ε)$-stationary point when $h$ is merely continuous and real-valued. Furthermore, we consider a scenario where $h$ does not have full domain and establish vanishing bounds on successive changes of iterates. Finally, in all three cases mentioned above, we show that one can construct a subsequence such that any accumulation point $x^*$ satisfies $c(x^*)\in$ dom $h$, and if a standard constraint qualification holds at $x^*$, then $x^*$ is a stationary point.

</details>


### [131] [Complete lift of control system](https://arxiv.org/abs/2512.24262)
*Simão N. Stelmastchuk*

Main category: math.OC

TL;DR: 研究光滑流形上的仿射控制系统及其到切丛的完全提升，证明提升系统由于几何约束永不可控，但原系统可控性保证提升系统的链可控性。


<details>
  <summary>Details</summary>
Motivation: 研究仿射控制系统在切丛上的提升行为，探索原系统与提升系统之间的可控性关系，理解几何约束对可控性的影响。

Method: 对光滑流形上的仿射控制系统进行完全提升到切丛，提供提升系统解的显式几何描述，引入链可控性概念进行分析。

Result: 1. 完全提升的可控性蕴含原系统的可控性；2. 提升系统由于固有几何约束永不可控；3. 原系统可控性保证其完全提升的链可控性。

Conclusion: 仿射控制系统的完全提升存在固有的几何限制使其不可控，但通过链可控性概念，原系统的可控性可以传递到提升系统的弱可控形式。

Abstract: We study affine control systems on smooth manifolds and their complete lifts to the tangent bundle, providing an explicit geometric description of the solutions of the lifted system. We show that, although controllability of the complete lift implies controllability of the original system, the lifted system is never controllable due to intrinsic geometric constraints. By introducing chain controllability, we prove that controllability of the original system guarantees chain controllability of its complete lift.

</details>


### [132] [Adaptive Algorithms for Nonconvex Bilevel Optimization under PŁ Conditions](https://arxiv.org/abs/2512.24291)
*Xu Shi,Yinglin Du,Rufeng Xiao,Rujun Jiang*

Main category: math.OC

TL;DR: 提出了两种自适应双层优化算法AF²BA和A²F²BA，无需问题特定参数即可达到最优复杂度


<details>
  <summary>Details</summary>
Motivation: 现有非凸双层优化方法需要预先知道问题特定参数（如Lipschitz常数和PL参数）来设置步长，这在参数未知或计算成本高时存在实际限制

Method: 提出了自适应全一阶双层逼近算法AF²BA及其加速变体A²F²BA，采用完全自适应步长策略，无需任何问题特定参数

Result: 两种算法都能达到O(1/ε²)的迭代复杂度来找到ε-稳定点，与现有调优方法匹配；A²F²BA具有近乎最优的一阶oracle复杂度Ō(1/ε²)

Conclusion: 这是首个在双层优化中采用完全自适应步长策略的方法，无需问题特定参数，同时保持了最优复杂度，与单层非凸优化的梯度下降复杂度相当

Abstract: Existing methods for nonconvex bilevel optimization (NBO) require prior knowledge of first- and second-order problem-specific parameters (e.g., Lipschitz constants and the Polyak-Łojasiewicz (PŁ) parameters) to set step sizes, a requirement that poses practical limitations when such parameters are unknown or computationally expensive. We introduce the Adaptive Fully First-order Bilevel Approximation (AF${}^2$BA) algorithm and its accelerated variant, A${}^2$F${}^2$BA, for solving NBO problems under the PŁ conditions. To our knowledge, these are the first methods to employ fully adaptive step size strategies, eliminating the need for any problem-specific parameters in NBO. We prove that both algorithms achieve $\mathcal{O}(1/ε^2)$ iteration complexity for finding an $ε$-stationary point, matching the iteration complexity of existing well-tuned methods. Furthermore, we show that A${}^2$F${}^2$BA enjoys a near-optimal first-order oracle complexity of $\tilde{\mathcal{O}}(1/ε^2)$, matching the oracle complexity of existing well-tuned methods, and aligning with the complexity of gradient descent for smooth nonconvex single-level optimization when ignoring the logarithmic factors.

</details>


### [133] [Optimization over Trained Neural Networks: Going Large with Gradient-Based Algorithms](https://arxiv.org/abs/2512.24295)
*Jiatai Tong,Yilin Zhu,Thiago Serra,Samuel Burer*

Main category: math.OC

TL;DR: 提出梯度算法降低每次迭代成本，并针对ReLU神经网络的分段线性结构优化，在大规模优化模型中优于现有局部搜索方法


<details>
  <summary>Details</summary>
Motivation: 使用神经网络作为非线性函数代理时，全局精确求解耗时过长，需要开发计算成本更低的局部搜索方法，特别是针对大规模优化问题

Method: 提出梯度算法降低每次迭代计算成本，并专门针对ReLU激活函数的神经网络的分段线性结构进行算法适配优化

Result: 随着优化模型规模增大，该方法逐渐变得有竞争力，并最终超越其他局部搜索方法

Conclusion: 提出的梯度算法在降低每次迭代成本方面有效，特别是针对ReLU神经网络的分段线性结构优化后，在大规模优化问题中表现优于现有方法

Abstract: When optimizing a nonlinear objective, one can employ a neural network as a surrogate for the nonlinear function. However, the resulting optimization model can be time-consuming to solve globally with exact methods. As a result, local search that exploits the neural-network structure has been employed to find good solutions within a reasonable time limit. For such methods, a lower per-iteration cost is advantageous when solving larger models. The contribution of this paper is two-fold. First, we propose a gradient-based algorithm with lower per-iteration cost than existing methods. Second, we further adapt this algorithm to exploit the piecewise-linear structure of neural networks that use Rectified Linear Units (ReLUs). In line with prior research, our methods become competitive with -- and then dominant over -- other local search methods as the optimization models become larger.

</details>


### [134] [Approximation algorithms for integer programming with resource augmentation](https://arxiv.org/abs/2512.24302)
*Hauke Brinkop,Hua Chen,Lin Chen,Klaus Jansen,Guochuan Zhang*

Main category: math.OC

TL;DR: 该论文提出了一种在整数规划中权衡时间与精度的算法，能在伪多项式时间内找到近似可行解，约束违反不超过εΔ，且目标值不劣于最优解。


<details>
  <summary>Details</summary>
Motivation: 传统整数规划算法在约束数m较大时呈指数级复杂度，而现有FPT算法将Δ作为参数处理。本文旨在探索不将Δ作为参数时，如何在时间与解的质量之间取得平衡。

Method: 针对一般整数规划和n-fold整数规划，设计近似算法：对于任意小的ε>0，算法在f(m,ε)·poly(|I|)时间内运行，返回约束违反不超过εΔ的近似可行解，且目标值不劣于满足约束的最优解。

Result: 算法能在伪多项式时间内找到近似可行解，约束违反可控，目标值保证最优性。该结果可应用于多维背包问题和调度问题的加法近似方案。

Conclusion: 本文在整数规划中实现了时间与精度的有效权衡，为不将Δ作为参数的情况提供了实用的近似算法框架，拓展了整数规划近似解的理论与应用边界。

Abstract: The classic algorithm [Papadimitriou, J.ACM '81] for IPs has a running time $n^{O(m)}(m\cdot\max\{Δ,\|\textbf{b}\|_{\infty}\})^{O(m^2)}$, where $m$ is the number of constraints, $n$ is the number of variables, and $Δ$ and $\|\textbf{b}\|_{\infty}$ are, respectively, the largest absolute values among the entries in the constraint matrix and the right-hand side vector of the constraint. The running time is exponential in $m$, and becomes pseudo-polynomial if $m$ is a constant. In recent years, there has been extensive research on FPT (fixed parameter tractable) algorithms for the so-called $n$-fold IPs, which may possess a large number of constraints, but the constraint matrix satisfies a specific block structure. It is remarkable that these FPT algorithms take as parameters $Δ$ and the number of rows and columns of some small submatrices. If $Δ$ is not treated as a parameter, then the running time becomes pseudo-polynomial even if all the other parameters are taken as constants.
  This paper explores the trade-off between time and accuracy in solving an IP. We show that, for arbitrary small $\varepsilon>0$, there exists an algorithm for IPs with $m$ constraints that runs in ${f(m,\varepsilon)}\cdot\textnormal{poly}(|I|)$ time, and returns a near-feasible solution that violates the constraints by at most $\varepsilonΔ$. Furthermore, for $n$-fold IPs, we establish a similar result -- our algorithm runs in time that depends on the number of rows and columns of small submatrices together with $1/\varepsilon$, and returns a solution that slightly violates the constraints. Meanwhile, both solutions guarantee that their objective values are no worse than the corresponding optimal objective values satisfying the constraints. As applications, our results can be used to obtain additive approximation schemes for multidimensional knapsack as well as scheduling.

</details>


### [135] [Discrete-Time Mean Field Type Games: Probabilistic Setup](https://arxiv.org/abs/2512.24313)
*Grégoire Lambrecht,Mathieu Laurière*

Main category: math.OC

TL;DR: 提出了一个具有全局和团队特定共同噪声的离散时间无限时域折扣平均场类型游戏的通用概率框架，证明了在可数状态空间和波兰动作空间下最优闭环策略的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究具有共同噪声的平均场类型游戏，允许个体和团队层面的随机化行动，建立平均场马尔可夫游戏的概念，连接不同随机化层次下的策略。

Method: 引入概率框架，形式化平均场马尔可夫游戏概念，通过不同随机化层次连接MFTG中的闭环策略和MFMG中的马尔可夫策略，利用无限时域折扣游戏理论结果证明存在性。

Result: 证明了当状态空间至多可数且动作空间为一般波兰空间时，原始MFTG存在最优闭环策略，并通过"意图的平均场漂移"实例验证了纳什均衡的存在性。

Conclusion: 建立了一个具有共同噪声的平均场类型游戏的统一理论框架，证明了最优策略的存在性，为具有随机化行动和共同噪声的复杂多智能体系统提供了理论基础。

Abstract: We introduce a general probabilistic framework for discrete-time, infinite-horizon discounted Mean Field Type Games (MFTGs) with both global common noise and team-specific common noises. In our model, agents are allowed to use randomized actions, both at the individual level and at the team level. We formalize the concept of Mean Field Markov Games (MFMGs) and establish a connection between closed-loop policies in MFTGs and Markov policies in MFMGs through different layers of randomization. By leveraging recent results on infinite-horizon discounted games with infinite compact state-action spaces, we prove the existence of an optimal closed-loop policy for the original MFTG when the state spaces are at most countable and the action spaces are general Polish spaces. We also present an example satisfying our assumptions, called Mean Field Drift of Intentions, where the dynamics are strongly randomized, and we establish the existence of a Nash equilibrium using our theoretical results.

</details>


### [136] [Backpropagation from KL Projections: Differential and Exact I-Projection Correspondences](https://arxiv.org/abs/2512.24335)
*Manish Krishan Lal*

Main category: math.OC

TL;DR: 论文建立了反向模式自动微分（反向传播）与KL几何中投影映射组合之间的两种精确对应关系。


<details>
  <summary>Details</summary>
Motivation: 探索反向传播与概率推理之间的深层联系，揭示自动微分在KL几何框架下的数学本质。

Method: 通过交替KL投影的消息传递来强制执行一致性和分解约束，在两种不同设置下建立对应关系。

Result: 1. 反向传播作为delta提升分解上KL投影映射的微分出现；2. 在完全可分解的和积网络上，反向传播与精确概率推理重合，反向值可解释为KL I-投影问题的拉格朗日乘子。

Conclusion: 反向传播与KL几何中的投影映射存在精确对应，这为理解自动微分提供了新的几何和概率视角。

Abstract: We establish two exact correspondences between reverse-mode automatic differentiation (backpropagation evaluated at a fixed forward pass) and compositions of projection maps in Kullback--Leibler (KL) geometry. In both settings, message passing defined by alternating KL projections enforces agreement and factorization constraints. In the first setting, backpropagation arises as the differential of a KL projection map on a delta-lifted factorization. In the second setting, on complete and decomposable sum--product networks, backpropagation coincides with exact probabilistic inference, and the backward values admit an interpretation as Lagrange multipliers of a KL I-projection problem.

</details>


### [137] [Decentralized Optimization over Time-Varying Row-Stochastic Digraphs](https://arxiv.org/abs/2512.24483)
*Liyuan Liang,Yilong Song,Kun Yuan*

Main category: math.OC

TL;DR: 本文解决了时变广播网络中仅使用行随机混合矩阵实现精确收敛的长期开放问题，提出了PULM和PULM-DGD算法，在高度动态通信环境中实现了指数收敛和优化解。


<details>
  <summary>Details</summary>
Motivation: 在机器人集群、传感器网络和分布式学习等应用中，需要在有向图上进行去中心化优化。许多实际场景中的网络是时变广播网络(TVBN)，由于无法获取出度信息，只能构造行随机混合矩阵。在TVBN上实现精确收敛一直是一个长期未解决的开放问题，因为时变行随机混合矩阵的极限分布依赖于不可预测的未来图实现，使得标准的偏差校正技术不可行。

Method: 提出了PULM（Pull-with-Memory）算法，这是一种通过交替进行行随机混合和局部调整来实现指数收敛平均共识的gossip协议。基于PULM，进一步开发了PULM-DGD算法，用于非凸优化问题。

Result: PULM算法实现了指数收敛的平均共识，PULM-DGD算法在光滑非凸目标函数上以O(ln(T)/T)的速率收敛到平稳解。这些结果显著扩展了去中心化优化在高度动态通信环境中的应用范围。

Conclusion: 本文解决了时变广播网络中仅使用行随机混合矩阵实现精确收敛的长期开放问题，提出的算法能够适应高度动态的通信环境，为去中心化优化在现实应用中的部署提供了重要理论支持。

Abstract: Decentralized optimization over directed graphs is essential for applications such as robotic swarms, sensor networks, and distributed learning. In many practical scenarios, the underlying network is a Time-Varying Broadcast Network (TVBN), where only row-stochastic mixing matrices can be constructed due to inaccessible out-degree information. Achieving exact convergence over TVBNs has remained a long-standing open question, as the limiting distribution of time-varying row-stochastic mixing matrices depends on unpredictable future graph realizations, rendering standard bias-correction techniques infeasible.
  This paper resolves this open question by developing the first algorithm that achieves exact convergence using only time-varying row-stochastic matrices. We propose PULM (Pull-with-Memory), a gossip protocol that attains average consensus with exponential convergence by alternating between row-stochastic mixing and local adjustment. Building on PULM, we develop PULM-DGD, which converges to a stationary solution at $\mathcal{O}(\ln(T)/T)$ for smooth nonconvex objectives. Our results significantly extend decentralized optimization to highly dynamic communication environments.

</details>


### [138] [A Study on the Algorithm and Implementation of SDPT3](https://arxiv.org/abs/2512.24623)
*Naoki Ito*

Main category: math.OC

TL;DR: SDPT3是一个基于内点法的开源MATLAB求解器，用于求解半定-二次-线性规划问题，本文提供了其算法的完整描述和实现细节。


<details>
  <summary>Details</summary>
Motivation: 为研究人员和开发者提供一个清晰、结构化的参考，帮助他们理解或基于SDPT3实现进行开发。SDPT3作为广泛使用的开源求解器，其算法描述和实现细节需要系统整理。

Method: 基于内点法的半定-二次-线性规划求解算法，提供了自包含且一致的算法描述，数学符号与实现代码严格对应。

Result: 提供了SDPT3求解器的完整技术文档，包括算法原理、实现细节和数学框架，为使用者提供了清晰的参考指南。

Conclusion: 本文系统整理了SDPT3求解器的算法和实现，为研究者和开发者提供了有价值的参考资源，有助于推动相关领域的研究和应用开发。

Abstract: This technical report presents a comprehensive study of SDPT3, a widely used open-source MATLAB solver for semidefinite-quadratic-linear programming, which is based on the interior-point method. It includes a self-contained and consistent description of the algorithm, with mathematical notation carefully aligned with the implementation. The aim is to offer a clear and structured reference for researchers and developers seeking to understand or build upon the implementation of SDPT3.

</details>


### [139] [A Differential Game with Symmetric Incomplete Information on Probabilistic Initial Condition and with Signal Revelation](https://arxiv.org/abs/2512.24640)
*Xiaochi Wu*

Main category: math.OC

TL;DR: 证明了具有对称不完全信息的二人零和微分博弈在连续初始位置和信号揭示下的值存在性，其扩展值函数是满足边界条件的HJI方程唯一粘性解


<details>
  <summary>Details</summary>
Motivation: 研究具有对称不完全信息的微分博弈，其中初始位置在连续集上随机选择，双方都不知道具体初始位置，但通过轨迹击中目标集时观察到的公共信号获得信息

Method: 引入信号依赖策略的合适概念，证明博弈值存在，扩展值函数是关联Hamilton-Jacobi-Isaacs方程的唯一粘性解，满足边界条件

Result: 证明了博弈值存在，扩展值函数是HJI方程的唯一粘性解，满足边界条件

Conclusion: 建立了具有对称不完全信息和信号揭示的微分博弈的理论框架，为这类博弈提供了完整的值存在性和表征结果

Abstract: In this paper, we investigate the existence and characterization of the value for a two-player zero-sum differential game with symmetric incomplete information on a continuum of initial positions and with signal revelation. Before the game starts, the initial position is chosen randomly according to a probability measure with compact support, and neither player is informed of the chosen initial position. However, they observe a public signal revealing the current state as soon as the trajectory of the dynamics hits a target set. We prove that, under a suitable notion of signal-dependent strategies, the value of the game exists, and the extended value function of the game is the unique viscosity solution of an associated Hamilton-Jacobi-Isaacs equation that satisfies a boundary condition.

</details>


### [140] [A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing](https://arxiv.org/abs/2512.24676)
*Kuangyu Ding,Marie Maros,Gesualdo Scutari*

Main category: math.OC

TL;DR: 提出MP-Jacobi框架，结合min-sum消息传递和Jacobi块更新，用于解决图/超图上的有限和优化问题，实现单跳通信的收敛消息传递方法。


<details>
  <summary>Details</summary>
Motivation: 解决图或超图上决策变量局部交互的有限和优化问题，需要开发既保持收敛性又降低计算通信成本的分布式方法。

Method: 将图/超图划分为树状簇，每个迭代中代理并行更新：通过单次min-sum扫描求解簇内子问题（成本到消息），并通过Jacobi校正处理簇间耦合，使用邻居最新迭代值。

Result: 对强凸目标建立全局线性收敛和显式收敛率，量化曲率、耦合强度和分区选择对可扩展性的影响；开发保持收敛性的图兼容替代方法降低复杂度；扩展到超图并验证性能提升。

Conclusion: MP-Jacobi框架为图/超图上的分布式优化提供了理论保证和实用方法，在保持收敛性的同时显著降低计算通信成本，优于现有分散梯度基线方法。

Abstract: We study finite-sum nonlinear programs whose decision variables interact locally according to a graph or hypergraph. We propose MP-Jacobi (Message Passing-Jacobi), a graph-compliant decentralized framework that couples min-sum message passing with Jacobi block updates. The (hyper)graph is partitioned into tree clusters. At each iteration, agents update in parallel by solving a cluster subproblem whose objective decomposes into (i) an intra-cluster term evaluated by a single min-sum sweep on the cluster tree (cost-to-go messages) and (ii) inter-cluster couplings handled via a Jacobi correction using neighbors' latest iterates. This design uses only single-hop communication and yields a convergent message-passing method on loopy graphs.
  For strongly convex objectives we establish global linear convergence and explicit rates that quantify how curvature, coupling strength, and the chosen partition affect scalability and provide guidance for clustering. To mitigate the computation and communication cost of exact message updates, we develop graph-compliant surrogates that preserve convergence while reducing per-iteration complexity. We further extend MP-Jacobi to hypergraphs; in heavily overlapping regimes, a surrogate-based hyperedge-splitting scheme restores finite-time intra-cluster message updates and maintains convergence. Experiments validate the theory and show consistent improvements over decentralized gradient baselines.

</details>


### [141] [A proximal subgradient algorithm for constrained multiobjective DC-type optimization](https://arxiv.org/abs/2512.24717)
*Nguyen Van Tuyen,Minh N. Dao,Tran Van Nghi*

Main category: math.OC

TL;DR: 提出了一种针对具有特定结构（可表示为非光滑非凸函数+可微Lipschitz函数-弱凸函数之和）的多目标优化问题的近端次梯度算法，建立了最优性条件并证明了算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 多目标优化问题在现实应用中广泛存在，特别是涉及DC（凸差）函数的问题。这类问题能够建模非凸优化，但现有方法对具有更一般结构（非光滑非凸+可微Lipschitz-弱凸）的多目标问题研究不足，需要开发有效的算法和理论框架。

Method: 首先建立了这类多目标优化问题的必要和充分最优性条件，然后基于这些条件设计了专门的近端次梯度算法。算法充分利用了目标函数的结构特点，在温和假设下保证生成序列的有界性。

Result: 证明了算法生成序列的有界性，并且每个聚点都是平稳解。这为求解这类具有复杂结构的多目标优化问题提供了有效的数值方法。

Conclusion: 该研究为具有特定结构（包含DC函数作为特例）的多目标优化问题提供了完整的理论分析和有效的算法框架，扩展了多目标优化的求解范围，为实际应用中的非凸多目标优化问题提供了新的解决方案。

Abstract: In this paper, we consider a class of constrained multiobjective optimization problems, where each objective function can be expressed by adding a possibly nonsmooth nonconvex function and a differentiable function with Lipschitz continuous gradient, then subtracting a weakly convex function. This encompasses multiobjective optimization problems involving difference-of-convex (DC) functions, which are prevalent in various applications due to their ability to model nonconvex problems. We first establish necessary and sufficient optimality conditions for these problems, providing a theoretical foundation for algorithm development. Building on these conditions, we propose a proximal subgradient algorithm tailored to the structure of the objectives. Under mild assumptions, the sequence generated by the proposed algorithm is bounded and each of its cluster points is a stationary solution.

</details>


### [142] [Some Studies on Stochastic Optimization based Quantitative Risk Management](https://arxiv.org/abs/2512.24736)
*Zhaolin Hu*

Main category: math.OC

TL;DR: 本文综述了定量风险管理中的风险度量评估与优化问题，重点介绍了相关计算技术和理论性质，展示了随机优化作为解决这些问题的重要工具。


<details>
  <summary>Details</summary>
Motivation: 风险管理在不确定性决策中至关重要，定量风险管理需要高效的计算技术和可靠的理论保证来评估和优化风险度量。

Method: 采用综述研究方法，介绍多个风险度量主题，回顾相关最新研究和进展，重点分析涉及这些度量的决策模型，特别关注计算技术和理论性质。

Result: 研究表明随机优化作为一种强大工具，可以有效解决定量风险管理中的风险度量评估和优化问题。

Conclusion: 随机优化是解决定量风险管理中风险度量相关问题的有效方法，为风险评估和优化提供了可靠的计算框架和理论支持。

Abstract: Risk management often plays an important role in decision making under uncertainty. In quantitative risk management, assessing and optimizing risk metrics requires efficient computing techniques and reliable theoretical guarantees. In this paper, we introduce several topics on quantitative risk management and review some of the recent studies and advancements on the topics. We consider several risk metrics and study decision models that involve the metrics, with a main focus on the related computing techniques and theoretical properties. We show that stochastic optimization, as a powerful tool, can be leveraged to effectively address these problems.

</details>


### [143] [A first approximation algorithm for the Bin Packing Problem with Setups](https://arxiv.org/abs/2512.24785)
*Roberto Baldacci,Fabio Ciccarelli,Stefano Coniglio,Valerio Dose,Fabio Furini*

Main category: math.OC

TL;DR: 该论文研究了带设置成本的装箱问题(BPPS)的常数因子近似算法，提出了一个两阶段启发式算法，并证明了其近似比为2α


<details>
  <summary>Details</summary>
Motivation: 研究带设置成本的装箱问题(BPPS)的近似算法，因为传统的装箱问题(BPP)启发式算法在BPPS上可能表现很差

Method: 提出了一个两阶段启发式算法：第一阶段对每个类别的物品使用α-近似算法进行装箱，第二阶段对打开的箱子进行合并

Result: 证明了该启发式算法是BPPS的2α-近似算法，即近似比是原BPP算法近似比的两倍

Conclusion: 为带设置成本的装箱问题提供了一个有效的近似算法框架，将BPP的近似算法转化为BPPS的近似算法

Abstract: We study constant-factor approximation algorithms for the Bin Packing Problem with Setups (BPPS). First, we show that adaptations of classical BPP heuristics can have arbitrarily poor worst-case performance on BPPS instances. Then, we propose a two-phase heuristic for the BPPS that applies an α-approximation algorithm for the BPP to the items of each class and then performs a merging phase on the open bins. We prove that this heuristic is a 2 α-approximation algorithm for the BPPS.

</details>


### [144] [Tensor Based Proximal Alternating Minimization Method for A Kind of Inhomogeneous Quartic Optimization Problem](https://arxiv.org/abs/2512.24872)
*Haibin Chen,Yixuan Chen,Chunyan Wang,Qi Fan*

Main category: math.OC

TL;DR: 提出一种求解四阶非齐次多项式优化问题的高效数值方法，通过建立该问题与多线性优化问题的等价性，并设计张量近端交替最小化算法求解


<details>
  <summary>Details</summary>
Motivation: 实际应用中出现的四阶非齐次多项式优化问题需要高效求解方法，现有文献主要关注齐次情况，需要扩展到非齐次情形

Method: 建立四阶非齐次多项式优化与多线性优化的等价关系，利用多块结构设计张量近端交替最小化算法，并证明算法收敛性

Result: 算法在温和假设下收敛，通过合成数据集验证了算法的有效性

Conclusion: 成功将齐次情形的等价关系扩展到非齐次情形，提出的张量算法能有效求解四阶非齐次多项式优化问题

Abstract: In this paper, we propose an efficient numerical approach for solving a specific type of quartic inhomogeneous polynomial optimization problem inspired by practical applications. The primary contribution of this work lies in establishing an inherent equivalence between the quartic inhomogeneous polynomial optimization problem and a multilinear optimization problem (MOP). This result extends the equivalence between fourth-order homogeneous polynomial optimization and multilinear optimization in the existing literature to the equivalence between fourth-order inhomogeneous polynomial optimization and multilinear optimization. By leveraging the multi-block structure embedded within the MOP, a tensor-based proximal alternating minimization algorithm is proposed to approximate the optimal value of the quartic problem. Under mild assumptions, the convergence of the algorithm is rigorously proven. Finally, the effectiveness of the proposed algorithm is demonstrated through preliminary computational results obtained using synthetic datasets.

</details>


### [145] [Adaptive Clutter Suppression via Convex Optimization](https://arxiv.org/abs/2512.24889)
*Yifan He,Griffin Kearney,Makan Fardad*

Main category: math.OC

TL;DR: 提出一种凸优化框架，为被动和双基地雷达中的每个单元自适应合成延迟-多普勒滤波器，在抑制杂波的同时保持规范的互模糊函数（CAF）响应。


<details>
  <summary>Details</summary>
Motivation: 被动和双基地雷达系统常受强杂波和直达波干扰限制，这些干扰会掩盖弱移动目标。传统消除方法（如广泛消除算法）需要仔细调参，且可能扭曲延迟-多普勒响应。

Method: 引入凸优化框架，将问题表述为二次规划：最小化CAF表面失真，同时满足线性杂波抑制约束。该方法自适应合成每个单元的延迟-多普勒滤波器，无需单独的消除阶段。

Result: 蒙特卡洛模拟使用常见通信波形，展示了强大的杂波抑制能力、准确的CFAR校准，以及相比经典CAF方法在检测率上的显著提升。

Conclusion: 该方法为被动雷达中的自适应杂波抑制提供了一种可扩展且忠实于CAF的方法，能够在保持互模糊函数特性的同时有效抑制杂波干扰。

Abstract: Passive and bistatic radar systems are often limited by strong clutter and direct-path interference that mask weak moving targets. Conventional cancellation methods such as the extensive cancellation algorithm require careful tuning and can distort the delay-Doppler response. This paper introduces a convex optimization framework that adaptively synthesizes per-cell delay-Doppler filters to suppress clutter while preserving the canonical cross-ambiguity function (CAF). The approach formulates a quadratic program that minimizes distortion of the CAF surface subject to linear clutter-suppression constraints, eliminating the need for a separate cancellation stage. Monte Carlo simulations using common communication waveforms demonstrate strong clutter suppression, accurate CFAR calibration, and major detection-rate gains over the classical CAF. The results highlight a scalable, CAF-faithful method for adaptive clutter mitigation in passive radar.

</details>


### [146] [Self-Supervised Amortized Neural Operators for Optimal Control: Scaling Laws and Applications](https://arxiv.org/abs/2512.24897)
*Wuzhe Xu,Jiequn Han,Rongjie Lai*

Main category: math.OC

TL;DR: 提出基于自监督神经算子的最优控制方法，直接近似系统条件到最优控制策略的映射，实现实时推理，并与MPC结合扩展到闭环控制。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制计算方法在动态或不确定环境中实时部署成本过高，需要更高效的实时决策方法。

Method: 使用自监督神经算子直接学习系统条件到最优控制策略的映射；进一步与模型预测控制（MPC）集成，用学习算子替代传统MPC中的优化步骤，实现闭环控制。

Result: 理论推导了泛化误差与样本/模型复杂度之间的缩放规律；数值案例显示在低内在维度情况下能实现高效准确的实时性能，但随着问题复杂度增加，准确性会下降。

Conclusion: 神经算子是高性能控制的有力新工具，当能够利用隐藏的低维结构时效果显著，但在更具挑战性的设置中仍受限于内在维度复杂性的根本约束。

Abstract: Optimal control provides a principled framework for transforming dynamical system models into intelligent decision-making, yet classical computational approaches are often too expensive for real-time deployment in dynamic or uncertain environments. In this work, we propose a method based on self-supervised neural operators for open-loop optimal control problems. It offers a new paradigm by directly approximating the mapping from system conditions to optimal control strategies, enabling instantaneous inference across diverse scenarios once trained. We further extend this framework to more complex settings, including dynamic or partially observed environments, by integrating the learned solution operator with Model Predictive Control (MPC). This yields a solution-operator learning method for closed-loop control, in which the learned operator supplies rapid predictions that replace the potentially time-consuming optimization step in conventional MPC. This acceleration comes with a quantifiable price to pay. Theoretically, we derive scaling laws that relate generalization error and sample/model complexity to the intrinsic dimension of the problem and the regularity of the optimal control function. Numerically, case studies show efficient, accurate real-time performance in low-intrinsic-dimension regimes, while accuracy degrades as problem complexity increases. Together, these results provide a balanced perspective: neural operators are a powerful novel tool for high-performance control when hidden low-dimensional structure can be exploited, yet they remain fundamentally constrained by the intrinsic dimensional complexity in more challenging settings.

</details>


### [147] [A Pontryagin Maximum Principle on the Belief Space for Continuous-Time Optimal Control with Discrete Observations](https://arxiv.org/abs/2512.24916)
*Christian Bayer,Saifeddine Ben naamia,Erik von Schwerin,Raul Tempone*

Main category: math.OC

TL;DR: 研究部分观测下连续时间随机最优控制问题，观测仅在离散时间点可用。在信念空间上推导Pontryagin最大值原理，设计基于粒子的数值方案，并在线性和非线性示例中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决具有连续动态和间歇噪声测量的混合设置控制问题，这种设置出现在机器人探索、目标跟踪和流行病控制等应用中。需要处理部分观测且观测仅在离散时间点可用的复杂控制场景。

Method: 在信念空间（信息状态）上构建问题，将控制器的后验状态分布作为决策变量。推导Pontryagin最大值原理，建立伴随过程与信念空间上值函数梯度之间的关系。设计基于粒子的数值方案，使用粒子滤波表示演化信念，回归技术近似伴随过程。

Result: 获得了具有预测和更新结构的优化系统，与非归一化Zakai方程和归一化Kushner-Stratonovich方程密切相关。提出的数值方案能够计算部分信息下的近似最优控制，在线性和非线性示例中验证了方法的有效性，特别展示了主动控制观测过程的好处。

Conclusion: 成功建立了部分观测下连续时间随机控制问题的理论框架和数值方法，将Pontryagin最大值原理扩展到信念空间，为处理混合观测设置的控制问题提供了系统解决方案，特别适用于需要主动信息获取的应用场景。

Abstract: We study a continuous time stochastic optimal control problem under partial observations that are available only at discrete time instants. This hybrid setting, with continuous dynamics and intermittent noisy measurements, arises in applications ranging from robotic exploration and target tracking to epidemic control. We formulate the problem on the space of beliefs (information states), treating the controller's posterior distribution of the state as the state variable for decision making. On this belief space we derive a Pontryagin maximum principle that provides necessary conditions for optimality. The analysis carefully tracks both the continuous evolution of the state between observation times and the Bayesian jump updates of the belief at observation instants.
  A key insight is a relationship between the adjoint process in our maximum principle and the gradient of the value functional on the belief space, which links the optimality conditions to the dynamic programming approach on the space of probability measures. The resulting optimality system has a prediction and update structure that is closely related to the unnormalised Zakai equation and the normalised Kushner-Stratonovich equation in nonlinear filtering.
  Building on this analysis, we design a particle based numerical scheme to approximate the coupled forward (filter) and backward (adjoint) system. The scheme uses particle filtering to represent the evolving belief and regression techniques to approximate the adjoint, which yields a practical algorithm for computing near optimal controls under partial information. The effectiveness of the approach is illustrated on both linear and nonlinear examples and highlights in particular the benefits of actively controlling the observation process.

</details>


### [148] [Strengthening Dual Bounds for Multicommodity Capacitated Network Design with Unsplittable Flow Constraints](https://arxiv.org/abs/2512.25018)
*Lacy M. Greening,Santanu S. Dey,Alan L. Erera*

Main category: math.OC

TL;DR: 该论文研究电子商务物流网络中不可分割流量的多商品容量网络设计问题，提出了新的有效不等式来加强对偶界，显著提高了大规模实例的求解效率。


<details>
  <summary>Details</summary>
Motivation: 电子商务物流网络要求相同起讫点的货物必须走相同路径（不可分割流量），这使得多商品容量网络设计问题变得复杂，需要整数规划求解。为提升大规模物流网络问题的可解性，需要加强对偶界。

Method: 研究弧集松弛的多面体结构，引入两类新的有效不等式。开发了一种方法，在根节点动态添加有效不等式到带有额外度量不等式的MCND整数规划重构中。

Result: 计算实验表明，对于实际路径模型，最佳方法使IP间隙平均减少26.5%和22.5%；仅使用弧基松弛时，IP间隙减少超过85%，证明了新有效不等式的强度。

Conclusion: 提出的有效不等式和方法能显著加强对偶界，提高大规模电子商务物流网络中不可分割流量网络设计问题的求解效率。

Abstract: Multicommodity capacitated network design (MCND) models can be used to optimize the consolidation of shipments within e-commerce fulfillment networks. In practice, fulfillment networks require that shipments with the same origin and destination follow the same transfer path. This unsplittable flow requirement complicates the MCND problem, requiring integer programming (IP) formulations in which binary variables replace continuous flow variables. To enhance the solvability of this variant of the MCND problem for large-scale logistics networks, this work focuses on strengthening dual bounds. We investigate the polyhedra of arc-set relaxations, and we introduce two new classes of valid inequalities that can be implemented within solution approaches. We develop one approach that dynamically adds valid inequalities to the root node of a reformulation of the MCND IP with additional valid metric inequalities. We show the effectiveness of our ideas with a comprehensive computational study using path-based fulfillment instances, constructed from data provided by a large U.S.-based e-commerce company, and the well-known arc-based Canad instances. Experiments show that our best solution approach for a practical path-based model reduces the IP gap by an average of 26.5% and 22.5% for the two largest instance groups, compared to solving the reformulation alone, demonstrating its effectiveness in improving the dual bound. In addition, experiments using only the arc-based relaxation highlight the strength of our new valid inequalities relative to the linear programming relaxation (LPR), yielding an IP-gap reduction of more than 85%.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Network Traffic Analysis with Process Mining: The UPSIDE Case Study](https://arxiv.org/abs/2512.23718)
*Francesco Vitale,Paolo Palmiero,Massimiliano Rak,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 本文提出了一种基于过程挖掘的方法来分析游戏网络流量，能够无监督地识别游戏状态、通过Petri网编码状态，并分类识别不同游戏。


<details>
  <summary>Details</summary>
Motivation: 在线游戏作为流行活动涉及复杂系统和网络基础设施，产生大量市场收入。需要建模网络设备行为来评估带宽消耗、预测高负载和检测恶意活动。过程挖掘结合数据驱动分析和模型洞察的能力在此背景下很有前景。

Method: 提出基于过程挖掘的方法：1) 无监督地从游戏网络数据中表征不同状态；2) 通过过程挖掘将这些状态编码为可解释的Petri网；3) 对游戏网络流量数据进行分类以识别不同游戏。在UPSIDE案例研究中应用，分析多个设备与《Clash Royale》和《Rocket League》交互的网络数据。

Result: 结果显示：游戏网络行为可以通过Petri网表示的状态有效且可解释地建模，具有足够的连贯性（设备间相似度94.02%）和特异性（状态间分离度174.99%），同时保持对两个不同游戏的较好分类准确率（AUC 73.84%）。

Conclusion: 过程挖掘方法能够有效分析游戏网络流量，实现状态表征、模型编码和游戏分类，为游戏网络行为建模提供了有前景的解决方案。

Abstract: Online gaming is a popular activity involving the adoption of complex systems and network infrastructures. The relevance of gaming, which generates large amounts of market revenue, drove research in modeling network devices' behavior to evaluate bandwidth consumption, predict and sustain high loads, and detect malicious activity. In this context, process mining appears promising due to its ability to combine data-driven analyses with model-based insights. In this paper, we propose a process mining-based method that analyzes gaming network traffic, allowing: unsupervised characterization of different states from gaming network data; encoding such states through process mining into interpretable Petri nets; and classification of gaming network traffic data to identify different video games being played. We apply the method to the UPSIDE case study, involving gaming network data of several devices interacting with two video games: Clash Royale and Rocket League. Results demonstrate that the gaming network behavior can be effectively and interpretably modeled through states represented as Petri nets with sufficient coherence (94.02% inter-device similarity) and specificity (174.99% inter-state separation) while maintaining a good classification accuracy of the two different video games (73.84% AUC).

</details>


### [150] [A Comprehensive Study of Deep Learning Model Fixing Approaches](https://arxiv.org/abs/2512.23745)
*Hanmo You,Zan Wang,Zishuo Dong,Luanqi Mo,Jianjun Zhao,Junjie Chen*

Main category: cs.LG

TL;DR: 对16种最先进的深度学习模型修复方法进行大规模实证研究，评估其修复效果及对其他关键属性（鲁棒性、公平性、向后兼容性）的影响，发现模型级方法修复效果最佳，但所有方法都无法在提升精度的同时保持所有其他属性。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统与传统软件一样容易出错，其故障可能给用户带来重大风险。虽然已有许多修复方法被提出，但缺乏对这些方法性能的全面评估，特别是它们对其他关键属性的影响。

Method: 对16种最先进的DL模型修复方法进行大规模实证研究，涵盖模型级、层级和神经元级三类方法。在统一的实验设置下，使用多样化的数据集、模型架构和应用领域进行评估，不仅评估修复效果，还评估对鲁棒性、公平性和向后兼容性的影响。

Result: 模型级方法在修复效果上优于其他方法。没有单一方法能够在实现最佳修复性能的同时提高精度并保持所有其他属性。修复方法通常会对其他关键属性产生负面影响。

Conclusion: 学术界应优先研究减轻修复方法的副作用。模型级方法虽然修复效果最佳，但需要关注其对其他属性的影响。这些发现为该领域的未来探索指明了方向。

Abstract: Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.

</details>


### [151] [A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios](https://arxiv.org/abs/2512.23748)
*Haley Rosso,Talea Mayo*

Main category: cs.LG

TL;DR: 本文综述了基于扩散模型的仿真推断方法，从数学基础到实际应用，重点分析了其在非理想科学数据条件下的鲁棒性优势。


<details>
  <summary>Details</summary>
Motivation: 对于复杂的仿真问题，传统基于似然的方法因似然函数难以处理而受限。仿真推断方法通过直接使用仿真器样本来学习参数后验分布，而扩散模型作为一种灵活的生成模型框架，在SBI任务中展现出独特优势，特别是在处理科学数据常见的非理想条件时。

Method: 回顾扩散模型的数学基础（前向加噪、反向时间SDE/ODE、概率流、去噪分数匹配），分析条件分数如何实现无似然后验采样。比较扩散模型与归一化流在神经后验/似然估计中的优缺点，特别关注扩散模型在非理想条件下的鲁棒性：模型误设、非结构化或无限维观测、数据缺失等。

Result: 扩散模型为SBI提供了灵活框架，在非理想科学数据条件下表现出更好的鲁棒性。通过Schrödinger桥公式、条件与序列后验采样器、非结构化数据的摊销架构以及推断时先验适应等方法，能够处理传统方法难以应对的复杂场景。

Conclusion: 基于扩散模型的SBI方法在处理科学数据中的非理想条件方面具有显著优势，为概率地球物理模型等应用的不确定性量化提供了有前景的解决方案，但仍存在迭代采样成本等权衡问题需要进一步研究。

Abstract: For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters $\mathbfθ$ given observed data $\mathbf{x}_{\text{o}}$. Recent work has brought attention to diffusion models -- a type of generative model rooted in score matching and reverse-time stochastic dynamics -- as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.

</details>


### [152] [Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents](https://arxiv.org/abs/2512.23749)
*Amin Sadri,M Maruf Hossain*

Main category: cs.LG

TL;DR: CM²是一种坐标矩阵机，通过单样本学习实现人类级别的概念学习，专注于文档结构特征而非语义向量，提供绿色AI解决方案。


<details>
  <summary>Details</summary>
Motivation: 人类通常能从单个示例中学习新概念，而机器学习算法需要大量样本。现有AI趋势依赖大规模预训练和GPU基础设施，能耗高。需要一种能像人类一样识别重要结构特征、实现单样本学习的绿色AI方法。

Method: 提出坐标矩阵机（CM²），这是一种小型专用模型，通过学习文档结构信息进行分类。它关注人类会考虑的结构"重要特征"，而不是详尽的语义向量，从而实现单样本学习。

Result: CM²在分类相似文档时，每个类别仅需一个样本就能超越传统向量化方法和复杂深度学习模型。它提供了高准确性、几何结构智能、环境可持续性、CPU优化、可解释性、快速计算、对不平衡类别的鲁棒性、经济可行性和可扩展性。

Conclusion: CM²通过专注于结构坐标而非语义向量，实现了人类级别的概念学习，提供了一种绿色、高效、可解释的AI解决方案，能够在资源受限的环境中实现高性能文档分类。

Abstract: Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \vspace*{6pt}
  Contribution: In this paper, we present the Coordinate Matrix Machine (CM$^2$). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern "Red AI" trends rely on massive pre-training and energy-intensive GPU infrastructure, CM$^2$ is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural "important features" a human would consider, allowing it to classify very similar documents using only one sample per class.
  Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM$^2$ offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable

</details>


### [153] [Geometric Scaling of Bayesian Inference in LLMs](https://arxiv.org/abs/2512.23752)
*Naman Aggarwal,Siddhartha R. Dalal,Vishal Misra*

Main category: cs.LG

TL;DR: 研究发现现代语言模型保留了支持贝叶斯推理的几何结构，其价值表示沿单一主轴组织，该轴位置与预测熵强相关，且该几何结构是特权不确定性读取机制而非单一计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明小型transformer在受控环境中可实现精确贝叶斯推理，并产生编码后验结构的几何基底。本研究旨在探究这种几何特征是否存在于生产级语言模型中。

Method: 分析Pythia、Phi-2、Llama-3和Mistral等模型家族，研究最后一层价值表示的组织结构；在Pythia-410M上进行针对性干预实验，操纵熵对齐轴以探究其功能。

Result: 发现所有模型的价值表示沿单一主导轴组织，该轴位置与预测熵强相关；领域限制提示将该结构压缩为与合成设置相同的低维流形；干预熵对齐轴会破坏局部不确定性几何，但不会导致贝叶斯行为的比例性退化。

Conclusion: 现代语言模型保留了支持贝叶斯推理的几何基底，并沿此基底组织其近似贝叶斯更新；该几何结构是特权不确定性读取机制而非单一计算瓶颈。

Abstract: Recent work has shown that small transformers trained in controlled "wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.
  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.

</details>


### [154] [Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation](https://arxiv.org/abs/2512.23753)
*Deep Shankar Pandey,Hyomin Choi,Qi Yu*

Main category: cs.LG

TL;DR: 本文分析了EDL模型中激活函数依赖的学习冻结问题，提出了一种广义激活函数家族和正则化方法来解决该问题，在多个任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 基于主观逻辑的EDL模型虽然能有效量化不确定性，但其非负证据约束要求特定激活函数，这些激活函数的几何特性可能导致激活依赖的学习冻结行为——当样本映射到低证据区域时梯度变得极小，阻碍学习。

Method: 1. 理论分析了激活依赖的学习冻结行为；2. 研究了不同证据激活函数对学习动态的影响；3. 设计了一个广义激活函数家族和相应的证据正则化器，为不同激活机制提供一致的证据更新路径。

Result: 在四个基准分类任务（MNIST、CIFAR-10、CIFAR-100、Tiny-ImageNet）、两个少样本分类任务以及盲人脸恢复问题上进行了广泛实验，验证了理论分析并证明了所提广义正则化证据模型的有效性。

Conclusion: 本文揭示了EDL模型中激活依赖的学习冻结问题，提出了理论分析和解决方案，通过广义激活函数和正则化器改善了学习动态，在多个任务上取得了更好的性能。

Abstract: Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models.

</details>


### [155] [HINTS: Extraction of Human Insights from Time-Series Without External Sources](https://arxiv.org/abs/2512.23755)
*Sheo Yon Jhin,Noseong Park*

Main category: cs.LG

TL;DR: HINTS是一个自监督学习框架，无需外部数据，从时间序列残差中提取潜在人类因素（如情绪、集体心理学），通过意见动力学模型作为结构归纳偏置，提升时间序列预测精度。


<details>
  <summary>Details</summary>
Motivation: 人类决策、情绪和集体心理学是影响金融经济系统时间动态的复杂因素。现有方法依赖外部数据（新闻、社交媒体）来捕捉这些因素，但数据依赖成本高（财务、计算、实际应用）。需要一种无需外部数据就能内生提取这些因素的方法。

Method: 提出HINTS自监督学习框架：1）从时间序列残差中内生提取潜在人类因素；2）使用Friedkin-Johnsen意见动力学模型作为结构归纳偏置，建模演化中的社会影响、记忆和偏见模式；3）将提取的人类因素作为注意力图集成到最先进的骨干模型中。

Result: 在9个真实世界和基准数据集上的实验表明，HINTS持续提升预测准确性。多个案例研究和消融研究验证了HINTS的可解释性，显示提取因素与现实世界事件的强语义对齐，证明了其实用价值。

Conclusion: HINTS成功展示了无需外部数据就能从时间序列中内生提取人类因素的可行性，通过意见动力学模型提供结构偏置，不仅提升预测性能，还提供可解释的洞察，具有实际应用价值。

Abstract: Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.

</details>


### [156] [Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data](https://arxiv.org/abs/2512.23761)
*Esha Saha,Hao Wang*

Main category: cs.LG

TL;DR: MUSIC是一个稀疏诱导的多任务神经网络框架，用于在物理约束变量和数据驱动变量互斥的情况下，恢复耦合系统的全维解。


<details>
  <summary>Details</summary>
Motivation: 复杂系统通常由多个耦合变量描述，但通常只能获得一个变量的控制方程，而其他变量只能通过数据访问。这种已知物理知识与观测数据之间的不匹配对现有物理信息机器学习方法构成了根本挑战。

Method: MUSIC采用稀疏诱导的多任务神经网络框架，将部分物理约束与数据驱动学习相结合，使用无网格随机采样训练数据和稀疏正则化，产生高度压缩的模型。

Result: MUSIC能够准确学习复杂耦合系统的解（冲击波解、不连续解、模式形成解），在数据稀缺和噪声条件下始终优于非稀疏公式。

Conclusion: MUSIC为具有不完全物理知识的部分观测系统建模提供了一种灵活有效的方法。

Abstract: Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable can be accessed only through data. This mismatch between known physics and observed data poses a fundamental challenge for existing physics-informed machine learning approaches, which generally assume either complete knowledge of the governing equations or full data availability across all variables. In this paper, we introduce MUSIC (Multitask Learning Under Sparse and Incomplete Constraints), a sparsity induced multitask neural network framework that integrates partial physical constraints with data-driven learning to recover full-dimensional solutions of coupled systems when physics-constrained and data-informed variables are mutually exclusive. MUSIC employs mesh-free (random) sampling of training data and sparsity regularization, yielding highly compressed models with improved training and evaluation efficiency. We demonstrate that MUSIC accurately learns solutions (shock wave solutions, discontinuous solutions, pattern formation solutions) to complex coupled systems under data-scarce and noisy conditions, consistently outperforming non-sparse formulations. These results highlight MUSIC as a flexible and effective approach for modeling partially observed systems with incomplete physical knowledge.

</details>


### [157] [Drift-Based Dataset Stability Benchmark](https://arxiv.org/abs/2512.23762)
*Dominik Soukup,Richard Plný,Daniel Vašata,Tomáš Čejka*

Main category: cs.LG

TL;DR: 该论文提出了一种评估数据集稳定性的新方法和基准工作流程，用于网络流量分类中检测数据漂移和优化数据集质量。


<details>
  <summary>Details</summary>
Motivation: 网络流量分类中，机器学习模型部署后可能因数据集过时、网络协议快速演进或流量行为变化而性能下降（数据/概念漂移）。现有方法通常直接完全重新训练，缺乏对数据集质量的深入分析和根本原因调查。

Method: 提出基于概念漂移检测方法的新框架，利用机器学习特征权重提升检测性能。建立基准工作流程来比较数据集，并在CESNET-TLS-Year22数据集上验证。提供初始数据集稳定性基准，识别弱点和优化方向。

Result: 在CESNET-TLS-Year22数据集上展示了该方法的有效性，提供了数据集稳定性基准，识别了数据集弱点，并展示了优化对创建的数据集变体的影响。

Conclusion: 该论文提出的方法能够有效评估数据集稳定性，为网络流量分类中的数据集质量分析和优化提供了系统化的工作流程，有助于解决模型部署后的性能退化问题。

Abstract: Machine learning (ML) represents an efficient and popular approach for network traffic classification. However, network traffic classification is a challenging domain, and trained models may degrade soon after deployment due to the obsolete datasets and quick evolution of computer networks as new or updated protocols appear. Moreover, significant change in the behavior of a traffic type (and, therefore, the underlying features representing the traffic) can produce a large and sudden performance drop of the deployed model, known as a data or concept drift. In most cases, complete retraining is performed, often without further investigation of root causes, as good dataset quality is assumed. However, this is not always the case and further investigation must be performed. This paper proposes a novel methodology to evaluate the stability of datasets and a benchmark workflow that can be used to compare datasets.
  The proposed framework is based on a concept drift detection method that also uses ML feature weights to boost the detection performance. The benefits of this work are demonstrated on CESNET-TLS-Year22 dataset. We provide the initial dataset stability benchmark that is used to describe dataset stability and weak points to identify the next steps for optimization. Lastly, using the proposed benchmarking methodology, we show the optimization impact on the created dataset variants.

</details>


### [158] [Neural Optimal Design of Experiment for Inverse Problems](https://arxiv.org/abs/2512.23763)
*John E. Darges,Babak Maboudi Afkham,Matthias Chung*

Main category: cs.LG

TL;DR: NODE是一种基于学习的实验设计框架，通过联合训练神经网络重建模型和连续设计变量，直接优化测量位置，避免传统双层优化和间接稀疏正则化。


<details>
  <summary>Details</summary>
Motivation: 传统最优实验设计方法通常采用双层优化和间接稀疏正则化（如l1正则化），计算复杂且需要调参。本文旨在开发一种更高效、直接的方法来优化测量位置。

Method: NODE框架在单一优化循环中联合训练神经网络重建模型和表示传感器位置、采样时间或测量角度的连续设计变量。通过直接优化测量位置而非对密集候选网格加权，实现设计层面的稀疏性。

Result: 在指数增长基准测试、MNIST图像采样和稀疏视图X射线CT实际应用中，NODE均优于基线方法，显示出更高的重建精度和任务特定性能。

Conclusion: NODE提供了一种计算效率高、无需调参的最优实验设计方法，通过直接优化连续设计变量实现稀疏性，在多个逆问题应用中表现出优越性能。

Abstract: We introduce Neural Optimal Design of Experiments, a learning-based framework for optimal experimental design in inverse problems that avoids classical bilevel optimization and indirect sparsity regularization. NODE jointly trains a neural reconstruction model and a fixed-budget set of continuous design variables representing sensor locations, sampling times, or measurement angles, within a single optimization loop. By optimizing measurement locations directly rather than weighting a dense grid of candidates, the proposed approach enforces sparsity by design, eliminates the need for l1 tuning, and substantially reduces computational complexity. We validate NODE on an analytically tractable exponential growth benchmark, on MNIST image sampling, and illustrate its effectiveness on a real world sparse view X ray CT example. In all cases, NODE outperforms baseline approaches, demonstrating improved reconstruction accuracy and task-specific performance.

</details>


### [159] [Exploring Cumulative Effects in Survival Data Using Deep Learning Networks](https://arxiv.org/abs/2512.23764)
*Kang-Chung Yang,Shinsheng Yuan*

Main category: cs.LG

TL;DR: CENNSurv：一种新型深度学习方法，用于从时变数据中捕捉动态风险关系，解决流行病学中时间依赖性暴露累积效应建模的挑战，在保持可解释性的同时提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: 流行病学研究中，时间依赖性暴露对生存结果的累积效应建模具有挑战性。传统样条方法需要重复数据转换且计算量大，而现有神经网络方法虽准确但缺乏对累积暴露模式的可解释性。

Method: 提出CENNSurv方法，这是一种深度学习框架，能够从时变数据中捕捉动态风险关系，在保持模型可解释性的同时处理复杂的时间模式。

Result: 在两个真实世界数据集上的评估显示，CENNSurv揭示了慢性环境暴露与关键生存结果之间的多年滞后关联，以及订阅流失前的关键短期行为变化，证明了其建模复杂时间模式的能力。

Conclusion: CENNSurv为研究累积效应的研究者提供了一个实用工具，能够在提升可扩展性的同时提供可解释的洞察，填补了传统统计方法与现有神经网络方法之间的空白。

Abstract: In epidemiological research, modeling the cumulative effects of time-dependent exposures on survival outcomes presents a challenge due to their intricate temporal dynamics. Conventional spline-based statistical methods, though effective, require repeated data transformation for each spline parameter tuning, with survival analysis computations relying on the entire dataset, posing difficulties for large datasets. Meanwhile, existing neural network-based survival analysis methods focus on accuracy but often overlook the interpretability of cumulative exposure patterns. To bridge this gap, we introduce CENNSurv, a novel deep learning approach that captures dynamic risk relationships from time-dependent data. Evaluated on two diverse real-world datasets, CENNSurv revealed a multi-year lagged association between chronic environmental exposure and a critical survival outcome, as well as a critical short-term behavioral shift prior to subscription lapse. This demonstrates CENNSurv's ability to model complex temporal patterns with improved scalability. CENNSurv provides researchers studying cumulative effects a practical tool with interpretable insights.

</details>


### [160] [A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit](https://arxiv.org/abs/2512.23766)
*Karim Salta,Michael Kirby,Chris Peterson*

Main category: cs.LG

TL;DR: 提出SVBF-LBG算法，用可训练的Schubert Variety of Best Fit替代传统子空间均值，在Grassmann流形上改进子空间聚类效果


<details>
  <summary>Details</summary>
Motivation: 传统子空间聚类使用均值或中位数作为几何代表，但在Grassmann流形上这些代表可能无法很好地捕捉子空间数据的几何结构，需要更合适的代表形式

Method: 提出SVBF-LBG算法：1) 用Schubert Variety of Best Fit替代传统子空间均值，定义为在至少一个固定方向上尽可能接近与每个聚类成员相交的子空间；2) 将SVBF集成到Linde-Buzo-Grey (LBG)聚类框架中

Result: 在合成数据、图像数据、光谱数据和视频动作数据上，SVBF-LBG算法相比传统方法提高了聚类纯度，同时保留了后续分析所需的数学结构

Conclusion: SVBF-LBG算法通过引入可训练的Schubert Variety原型，在Grassmann流形上实现了更有效的子空间聚类，为几何数据分析提供了更好的工具

Abstract: In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.

</details>


### [161] [Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics](https://arxiv.org/abs/2512.23767)
*Bin Xu,Ayan Banerjee,Sandeep Gupta*

Main category: cs.LG

TL;DR: MERINDA是一个FPGA加速的模型恢复框架，用于在资源受限的边缘设备上实现实时物理AI，相比GPU方案能大幅降低能耗和内存占用。


<details>
  <summary>Details</summary>
Motivation: 边缘物理AI需要硬件高效的学习和推理能力，而现有模型恢复方法（如EMILY和PINN+SR）基于神经ODE，需要迭代求解器，难以在边缘硬件上高效加速。

Method: MERINDA采用硬件友好的架构，结合GRU离散化动态、密集逆ODE层、稀疏驱动dropout和轻量级ODE求解器，将计算结构化为流式并行，在FPGA上实现完全并行化。

Result: 在四个非线性动力系统基准测试中，MERINDA相比GPU实现：能耗降低114倍（434J vs 49,375J），内存占用减少28倍（214MB vs 6,118MB），训练速度提升1.68倍，同时保持最先进的模型恢复精度。

Conclusion: MERINDA能够将准确、可解释的模型恢复技术带到边缘设备，实现对自主系统的实时监控，使物理AI在资源受限设备上变得实用。

Abstract: Physical AI at the edge -- enabling autonomous systems to understand and predict real-world dynamics in real time -- requires hardware-efficient learning and inference. Model recovery (MR), which identifies governing equations from sensor data, is a key primitive for safe and explainable monitoring in mission-critical autonomous systems operating under strict latency, compute, and power constraints. However, state-of-the-art MR methods (e.g., EMILY and PINN+SR) rely on Neural ODE formulations that require iterative solvers and are difficult to accelerate efficiently on edge hardware. We present \textbf{MERINDA} (Model Recovery in Reconfigurable Dynamic Architecture), an FPGA-accelerated MR framework designed to make physical AI practical on resource-constrained devices. MERINDA replaces expensive Neural ODE components with a hardware-friendly formulation that combines (i) GRU-based discretized dynamics, (ii) dense inverse-ODE layers, (iii) sparsity-driven dropout, and (iv) lightweight ODE solvers. The resulting computation is structured for streaming parallelism, enabling critical kernels to be fully parallelized on the FPGA. Across four benchmark nonlinear dynamical systems, MERINDA delivers substantial gains over GPU implementations: \textbf{114$\times$ lower energy} (434~J vs.\ 49{,}375~J), \textbf{28$\times$ smaller memory footprint} (214~MB vs.\ 6{,}118~MB), and \textbf{1.68$\times$ faster training}, while matching state-of-the-art model-recovery accuracy. These results demonstrate that MERINDA can bring accurate, explainable MR to the edge for real-time monitoring of autonomous systems.

</details>


### [162] [Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions](https://arxiv.org/abs/2512.23770)
*Ankit Kanwar,Dominik Wagner,Luke Ong*

Main category: cs.LG

TL;DR: SB-TRPO：一种新的信任域算法，通过自适应偏置策略更新来满足安全约束，同时保持奖励性能，在安全关键强化学习中实现安全与任务完成的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 安全关键领域的强化学习需要在最大化奖励的同时严格遵守安全约束。现有方法（如拉格朗日法和投影法）要么无法确保接近零的安全违规，要么在面对硬约束时牺牲奖励性能。

Method: 提出安全偏置信任域策略优化（SB-TRPO），这是一种用于硬约束RL的新信任域算法。它使用成本和奖励的自然策略梯度的凸组合来执行信任域更新，确保每一步都有固定比例的最优成本降低。

Result: 在标准且具有挑战性的Safety Gymnasium任务上的实验表明，SB-TRPO相比最先进方法，始终实现安全与有意义任务完成的最佳平衡。

Conclusion: SB-TRPO为硬约束强化学习提供了一种有效方法，通过自适应偏置策略更新在确保安全的同时保持奖励性能，具有理论保证和实证优势。

Abstract: Reinforcement learning (RL) in safety-critical domains requires agents to maximise rewards while strictly adhering to safety constraints. Existing approaches, such as Lagrangian and projection-based methods, often either fail to ensure near-zero safety violations or sacrifice reward performance in the face of hard constraints. We propose Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new trust-region algorithm for hard-constrained RL. SB-TRPO adaptively biases policy updates towards constraint satisfaction while still seeking reward improvement. Concretely, it performs trust-region updates using a convex combination of the natural policy gradients of cost and reward, ensuring a fixed fraction of optimal cost reduction at each step. We provide a theoretical guarantee of local progress towards safety, with reward improvement when gradients are suitably aligned. Experiments on standard and challenging Safety Gymnasium tasks show that SB-TRPO consistently achieves the best balance of safety and meaningful task completion compared to state-of-the-art methods.

</details>


### [163] [Interactive Machine Learning: From Theory to Scale](https://arxiv.org/abs/2512.23924)
*Yinglun Zhu*

Main category: cs.LG

TL;DR: 该论文研究交互式机器学习，开发了在主动学习、序列决策和大动作空间情境赌博机、以及部分反馈下的模型选择等方面的算法原理和理论基础。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习依赖大量标注数据或在线交互，但在实践中获取高质量标签或通过试错做决策成本高、耗时长、风险大，特别是在大规模或高风险场景中。

Method: 研究交互式机器学习，让学习器主动影响信息收集或行动选择，利用过去观察指导未来交互。开发新算法原理并建立三个维度的基本限制：带噪声数据和丰富模型类的主动学习、大动作空间的序列决策、部分反馈下的模型选择。

Result: 1) 首个无需低噪声假设就能实现指数级标签节省的计算高效主动学习算法；2) 首个保证独立于动作空间大小的通用情境赌博机算法；3) 首次对序列决策中模型选择基本成本的严格刻画。

Conclusion: 该论文通过开发统计最优且计算高效的算法，推进了交互式学习的理论基础，同时为在大规模实际场景中部署交互式学习方法提供了原则性指导。

Abstract: Machine learning has achieved remarkable success across a wide range of applications, yet many of its most effective methods rely on access to large amounts of labeled data or extensive online interaction. In practice, acquiring high-quality labels and making decisions through trial-and-error can be expensive, time-consuming, or risky, particularly in large-scale or high-stakes settings. This dissertation studies interactive machine learning, in which the learner actively influences how information is collected or which actions are taken, using past observations to guide future interactions. We develop new algorithmic principles and establish fundamental limits for interactive learning along three dimensions: active learning with noisy data and rich model classes, sequential decision making with large action spaces, and model selection under partial feedback. Our results include the first computationally efficient active learning algorithms achieving exponential label savings without low-noise assumptions; the first efficient, general-purpose contextual bandit algorithms whose guarantees are independent of the size of the action space; and the first tight characterizations of the fundamental cost of model selection in sequential decision making. Overall, this dissertation advances the theoretical foundations of interactive learning by developing algorithms that are statistically optimal and computationally efficient, while also providing principled guidance for deploying interactive learning methods in large-scale, real-world settings.

</details>


### [164] [FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading](https://arxiv.org/abs/2512.23773)
*Molei Qin,Xinyu Cai,Yewen Li,Haochong Xia,Chuqiao Zong,Shuo Sun,Xinrun Wang,Bo An*

Main category: cs.LG

TL;DR: FineFT提出三阶段集成强化学习框架，解决加密货币期货交易中高杠杆带来的训练不稳定和风险管理问题，在5倍杠杆高频交易环境下超越12个SOTA基线。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法主要针对现货市场，无法直接应用于高杠杆期货市场，面临两个挑战：1) 高杠杆放大奖励波动导致训练不稳定；2) 缺乏能力边界自感知，遇到新市场状态（如黑天鹅事件）时可能遭受重大损失。

Method: 三阶段集成RL框架：阶段I使用集成TD误差选择性更新Q学习器以提高收敛性；阶段II基于盈利能力筛选Q学习器，并训练VAE识别市场状态以确定能力边界；阶段III根据训练好的VAE指导，从筛选后的集成和保守策略中选择，以保持盈利能力并降低新市场状态风险。

Result: 在5倍杠杆高频加密货币期货交易环境中，FineFT在6个金融指标上超越12个SOTA基线，风险降低超过40%的同时实现优于第二名的盈利能力。可视化显示不同智能体专门处理不同市场动态，消融研究证实VAE路由有效降低最大回撤，选择性更新改善收敛和性能。

Conclusion: FineFT通过三阶段集成RL框架成功解决了高杠杆期货交易中的训练稳定性和风险管理问题，实现了在保持高盈利能力的同时显著降低风险，为量化交易提供了有效的风险感知解决方案。

Abstract: Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.

</details>


### [165] [Improved Balanced Classification with Theoretically Grounded Loss Functions](https://arxiv.org/abs/2512.23947)
*Corinna Cortes,Mehryar Mohri,Yutao Zhong*

Main category: cs.LG

TL;DR: 该论文研究了类别不平衡分类中的两种高级替代损失函数：广义对数调整损失（GLA）和广义类别感知加权损失（GCA），分析了它们的理论一致性，并展示了在高度不平衡场景中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 平衡损失虽然能促进公平性，确保少数类别不被忽视，但直接最小化通常不可行。因此需要设计有效的替代损失函数来解决类别不平衡问题。

Method: 提出了两种高级替代损失函数家族：1）广义对数调整损失（GLA），将对数调整损失推广到更广泛的交叉熵损失家族；2）广义类别感知加权损失（GCA），扩展标准类别加权损失，加入类别依赖的置信度边界。

Result: 理论分析表明：GLA损失是贝叶斯一致的，但仅对无界假设集是H一致的，其H一致性边界与最小类别概率成反比（1/p_min）。GCA损失对所有假设集都是H一致的，边界缩放更优（1/√p_min）。实验显示GCA和GLA都显著优于简单类别加权损失和LA损失，GLA在常见基准上表现稍好，GCA在高度不平衡场景中略有优势。

Conclusion: GCA损失在理论保证上更强，特别是在高度不平衡设置中，而GLA损失在实际应用中表现良好。两种损失函数都为类别不平衡分类提供了有效的解决方案。

Abstract: The balanced loss is a widely adopted objective for multi-class classification under class imbalance. By assigning equal importance to all classes, regardless of their frequency, it promotes fairness and ensures that minority classes are not overlooked. However, directly minimizing the balanced classification loss is typically intractable, which makes the design of effective surrogate losses a central question. This paper introduces and studies two advanced surrogate loss families: Generalized Logit-Adjusted (GLA) loss functions and Generalized Class-Aware weighted (GCA) losses. GLA losses generalize Logit-Adjusted losses, which shift logits based on class priors, to the broader general cross-entropy loss family. GCA loss functions extend the standard class-weighted losses, which scale losses inversely by class frequency, by incorporating class-dependent confidence margins and extending them to the general cross-entropy family. We present a comprehensive theoretical analysis of consistency for both loss families. We show that GLA losses are Bayes-consistent, but only $H$-consistent for complete (i.e., unbounded) hypothesis sets. Moreover, their $H$-consistency bounds depend inversely on the minimum class probability, scaling at least as $1/\mathsf p_{\min}$. In contrast, GCA losses are $H$-consistent for any hypothesis set that is bounded or complete, with $H$-consistency bounds that scale more favorably as $1/\sqrt{\mathsf p_{\min}}$, offering significantly stronger theoretical guarantees in imbalanced settings. We report the results of experiments demonstrating that, empirically, both the GCA losses with calibrated class-dependent confidence margins and GLA losses can greatly outperform straightforward class-weighted losses as well as the LA losses. GLA generally performs slightly better in common benchmarks, whereas GCA exhibits a slight edge in highly imbalanced settings.

</details>


### [166] [A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms](https://arxiv.org/abs/2512.23777)
*Kanishka Hewageegana,Janani Harischandra,Nipuna Senanayake,Gihan Danansuriya,Kavindu Hapuarachchi,Pooja Illangarathne*

Main category: cs.LG

TL;DR: 该研究通过图神经网络（GNNs）调查网约车平台的欺诈检测，比较不同模型效果，分析常见欺诈活动，并解决类别不平衡和欺诈伪装问题。


<details>
  <summary>Details</summary>
Motivation: 网约车平台面临日益严重的欺诈问题，需要有效的检测方法。现有研究在应对类别不平衡和欺诈伪装方面存在不足，图神经网络为检测复杂欺诈模式提供了新途径。

Method: 采用图神经网络（GNNs）进行欺诈检测，分析比较不同GNN模型架构和方法论，特别关注处理类别不平衡和欺诈伪装的技术。

Result: 研究提供了GNN在异常检测中的架构和方法论综述，识别了重要的方法论进展和研究空白，展示了GNN在网约车欺诈检测中的有效性。

Conclusion: GNN在网约车欺诈检测中具有潜力，但需要进一步探索实际应用性和技术改进，以应对快速发展的网约车行业中的欺诈挑战。

Abstract: This study investigates fraud detection in ride hailing platforms through Graph Neural Networks (GNNs),focusing on the effectiveness of various models. By analyzing prevalent fraudulent activities, the research highlights and compares the existing work related to fraud detection which can be useful when addressing fraudulent incidents within the online ride hailing platforms. Also, the paper highlights addressing class imbalance and fraudulent camouflage. It also outlines a structured overview of GNN architectures and methodologies applied to anomaly detection, identifying significant methodological progress and gaps. The paper calls for further exploration into real-world applicability and technical improvements to enhance fraud detection strategies in the rapidly evolving ride-hailing industry.

</details>


### [167] [Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems](https://arxiv.org/abs/2512.23978)
*Tinglong Dai,David Simchi-Levi,Michelle Xiao Wu,Yao Xie*

Main category: cs.LG

TL;DR: GenAI正从对话助手转向自主决策系统，这产生了自主性悖论：自主性越高，越需要正式结构、明确约束和尾部风险控制。论文提出基于运筹学的保证自主性框架，通过流式生成模型和对抗鲁棒性方法确保系统安全。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正从对话助手转向自主决策系统，这种转变带来了自主性悖论：系统自主性越高，越需要正式结构、明确约束和尾部风险控制。随机生成模型在操作领域可能很脆弱，需要可验证的可行性、对分布偏移的鲁棒性以及高风险场景的压力测试机制。

Method: 提出基于运筹学的保证自主性概念框架，包含两种互补方法：1) 流式生成模型，将生成视为确定性传输，通过常微分方程描述，实现可审计性、约束感知生成，并与最优传输、鲁棒优化和顺序决策控制连接；2) 操作安全通过对抗鲁棒性视角制定，在不确定性或模糊集内评估决策规则对最坏情况扰动的抵抗能力。

Result: 该框架阐明了随着自主性增加，运筹学的角色从求解器转变为护栏再到系统架构师，负责控制逻辑、激励协议、监控机制和安全边界的设计。这些要素定义了在安全关键、可靠性敏感的操作领域中保证自主性的研究议程。

Conclusion: 生成式AI向自主系统的转变需要新的保证自主性框架，运筹学方法为此提供了关键工具。通过流式生成模型和对抗鲁棒性方法的结合，可以构建更安全、更可靠的自主决策系统，特别是在安全关键的操作领域。

Abstract: Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems -- autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR's role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.

</details>


### [168] [TabMixNN: A Unified Deep Learning Framework for Structural Mixed Effects Modeling on Tabular Data](https://arxiv.org/abs/2512.23787)
*Deniz Akdemir*

Main category: cs.LG

TL;DR: TabMixNN是一个将经典混合效应模型与现代神经网络架构相结合的PyTorch框架，用于表格数据分析，支持分层数据结构、多种结果类型和可解释性工具。


<details>
  <summary>Details</summary>
Motivation: 解决处理分层数据结构的需求，同时支持回归、分类和多任务学习等多种结果类型，将深度学习的优势与混合效应模型的可解释性相结合。

Method: 采用模块化三层架构：1) 具有变分随机效应和灵活协方差结构的混合效应编码器；2) 包括广义结构方程模型和时空流形网络的主干架构；3) 支持多种结果族的特定结果预测头。提供R风格公式接口、DAG约束、SPDE核等创新功能。

Result: 框架在纵向数据分析、基因组预测和时空建模等应用中展示了灵活性，为研究人员提供了统一的接口，既能利用深度学习，又能保持经典混合效应模型的可解释性和理论基础。

Conclusion: TabMixNN成功地将经典混合效应建模与现代神经网络架构相结合，为表格数据分析提供了一个灵活、可解释且理论基础的框架，特别适用于处理分层数据结构和多种结果类型的复杂场景。

Abstract: We present TabMixNN, a flexible PyTorch-based deep learning framework that synthesizes classical mixed-effects modeling with modern neural network architectures for tabular data analysis. TabMixNN addresses the growing need for methods that can handle hierarchical data structures while supporting diverse outcome types including regression, classification, and multitask learning. The framework implements a modular three-stage architecture: (1) a mixed-effects encoder with variational random effects and flexible covariance structures, (2) backbone architectures including Generalized Structural Equation Models (GSEM) and spatial-temporal manifold networks, and (3) outcome-specific prediction heads supporting multiple outcome families. Key innovations include an R-style formula interface for accessibility, support for directed acyclic graph (DAG) constraints for causal structure learning, Stochastic Partial Differential Equation (SPDE) kernels for spatial modeling, and comprehensive interpretability tools including SHAP values and variance decomposition. We demonstrate the framework's flexibility through applications to longitudinal data analysis, genomic prediction, and spatial-temporal modeling. TabMixNN provides a unified interface for researchers to leverage deep learning while maintaining the interpretability and theoretical grounding of classical mixed-effects models.

</details>


### [169] [Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators](https://arxiv.org/abs/2512.24145)
*Udit Sharma*

Main category: cs.LG

TL;DR: 论文提出配对种子评估设计，通过让竞争系统在相同随机种子下运行，利用随机性共享来减少评估方差，提高统计效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统虽然看起来随机，但实际上是确定性随机的（基于种子的伪随机数生成器）。基于学习的模拟器广泛用于算法比较，但评估结果常因随机初始化和学习随机性而方差很大。标准独立评估设计未能利用不同方案间的随机性共享。

Method: 提出配对种子评估设计，让竞争系统在相同的随机种子下进行评估，诱导随机组件的匹配实现。当结果在种子层面正相关时，能严格减少方差。该方法在相关性存在时提高统计可靠性，无相关性时退化为独立评估而不损失有效性。

Result: 种子层面的相关性通常很大且为正，能产生数量级的效率提升。配对种子评估在实践中是弱占优的，能获得更紧的置信区间、更高的统计功效，以及在固定计算预算下获得有效样本量增益。

Conclusion: 配对种子评估设计通过利用随机性共享，显著提高了机器学习系统比较评估的统计效率和可靠性，是实践中推荐的方法。

Abstract: Machine learning systems appear stochastic but are deterministically random, as seeded pseudorandom number generators produce identical realisations across executions. Learning-based simulators are widely used to compare algorithms, design choices, and interventions under such dynamics, yet evaluation outcomes often exhibit high variance due to random initialisation and learning stochasticity. We analyse the statistical structure of comparative evaluation in these settings and show that standard independent evaluation designs fail to exploit shared sources of randomness across alternatives. We formalise a paired seed evaluation design in which competing systems are evaluated under identical random seeds, inducing matched realisations of stochastic components and strict variance reduction whenever outcomes are positively correlated at the seed level. This yields tighter confidence intervals, higher statistical power, and effective sample size gains at fixed computational budgets. Empirically, seed-level correlations are typically large and positive, producing order-of-magnitude efficiency gains. Paired seed evaluation is weakly dominant in practice, improving statistical reliability when correlation is present and reducing to independent evaluation without loss of validity when it is not.

</details>


### [170] [Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems](https://arxiv.org/abs/2512.23809)
*Samaresh Kumar Singh,Joyjit Roy,Martin So*

Main category: cs.LG

TL;DR: 提出ZTA-FL框架，结合TPM认证、SHAP加权聚合和隐私保护对抗训练，在工业物联网入侵检测中实现高精度、强鲁棒性和低通信开销。


<details>
  <summary>Details</summary>
Motivation: 工业物联网安全事件频发（如2021年Oldsmar水处理厂和2023年丹麦能源部门攻击），现有联邦学习框架存在拜占庭攻击漏洞和代理认证不足的问题。

Method: 提出零信任代理联邦学习（ZTA-FL）框架：1）基于TPM的加密认证（误接受率<0.0000001）；2）新颖的SHAP加权聚合算法，提供非独立同分布条件下的可解释拜占庭检测；3）隐私保护的设备端对抗训练。

Result: 在三个IDS基准测试中，ZTA-FL达到97.8%检测准确率，在30%拜占庭攻击下保持93.2%准确率（优于FLAME 3.1%，p<0.01），89.3%对抗鲁棒性，同时减少34%通信开销。

Conclusion: ZTA-FL框架为工业物联网入侵检测提供了安全、高效、可解释的解决方案，包含理论分析、故障模式特征描述和开源代码。

Abstract: Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.

</details>


### [171] [Sparse classification with positive-confidence data in high dimensions](https://arxiv.org/abs/2512.24443)
*The Tien Mai,Mai Anh Nguyen,Trung Nghia Nguyen*

Main category: cs.LG

TL;DR: 提出高维Pconf分类的稀疏惩罚框架，使用凸和非凸惩罚项，理论证明达到近最优稀疏恢复率，实验显示性能接近全监督方法


<details>
  <summary>Details</summary>
Motivation: 高维学习通常需要稀疏正则化，但在弱监督设置（如Pconf分类）中研究不足。Pconf学习仅使用带置信度的正样本，避免负数据需求，但现有方法不适合高维场景。

Method: 提出高维Pconf分类的稀疏惩罚框架，使用凸惩罚（Lasso）和非凸惩罚（SCAD、MCP）来减少收缩偏差和改进特征恢复。开发高效近端梯度算法求解复合目标函数。

Result: 理论证明L1正则化Pconf估计器在受限强凸条件下达到近极小极大最优稀疏恢复率。模拟实验显示所提方法在预测性能和变量选择准确性上与全监督方法相当。

Conclusion: 提出的稀疏惩罚框架有效弥合了弱监督与高维统计之间的差距，为高维Pconf分类提供了理论保证和实用算法。

Abstract: High-dimensional learning problems, where the number of features exceeds the sample size, often require sparse regularization for effective prediction and variable selection. While established for fully supervised data, these techniques remain underexplored in weak-supervision settings such as Positive-Confidence (Pconf) classification. Pconf learning utilizes only positive samples equipped with confidence scores, thereby avoiding the need for negative data. However, existing Pconf methods are ill-suited for high-dimensional regimes. This paper proposes a novel sparse-penalization framework for high-dimensional Pconf classification. We introduce estimators using convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. Theoretically, we establish estimation and prediction error bounds for the L1-regularized Pconf estimator, proving it achieves near minimax-optimal sparse recovery rates under Restricted Strong Convexity condition. To solve the resulting composite objective, we develop an efficient proximal gradient algorithm. Extensive simulations demonstrate that our proposed methods achieve predictive performance and variable selection accuracy comparable to fully supervised approaches, effectively bridging the gap between weak supervision and high-dimensional statistics.

</details>


### [172] [Improved Bounds for Private and Robust Alignment](https://arxiv.org/abs/2512.23816)
*Wenqian Weng,Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 该论文从理论角度研究了语言模型的隐私鲁棒对齐，建立了离线和在线设置中的次优性差距上界，分析了隐私约束和对抗性腐败两种干扰下的不同交互模式。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型对齐中的隐私保护和鲁棒性问题，特别是在偏好标签同时受到隐私约束和对抗性腐败影响时的理论保证。

Method: 采用理论分析方法，建立离线和在线设置中的次优性差距上界，分析隐私优先和腐败优先两种交互模式，使用MLE风格算法和log损失函数。

Result: 1) 纯隐私设置中，log损失+MLE算法达到接近最优速率；2) 联合隐私腐败设置中，现有离线算法提供比已知更强的保证；3) 首次提出隐私鲁棒在线对齐结果；4) 建立了隐私和腐败下log损失和平方损失的统一收敛保证。

Conclusion: 该研究为语言模型对齐中的隐私保护和鲁棒性问题提供了理论框架，揭示了log损失在隐私设置中的优势，扩展了现有算法的理论保证，并为学习理论和统计学提供了广泛适用的收敛性工具。

Abstract: In this paper, we study the private and robust alignment of language models from a theoretical perspective by establishing upper bounds on the suboptimality gap in both offline and online settings. We consider preference labels subject to privacy constraints and/or adversarial corruption, and analyze two distinct interplays between them: privacy-first and corruption-first. For the privacy-only setting, we show that log loss with an MLE-style algorithm achieves near-optimal rates, in contrast to conventional wisdom. For the joint privacy-and-corruption setting, we first demonstrate that existing offline algorithms in fact provide stronger guarantees -- simultaneously in terms of corruption level and privacy parameters -- than previously known, which further yields improved bounds in the corruption-only regime. In addition, we also present the first set of results for private and robust online alignment. Our results are enabled by new uniform convergence guarantees for log loss and square loss under privacy and corruption, which we believe have broad applicability across learning theory and statistics.

</details>


### [173] [MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling](https://arxiv.org/abs/2512.23824)
*Mahdi Karami,Ali Behrouz,Peilin Zhong,Razvan Pascanu,Vahab Mirrokni*

Main category: cs.LG

TL;DR: MS-SSM提出多尺度状态空间模型框架，通过多分辨率处理增强记忆效率和长程建模能力，在多个基准测试中优于现有SSM模型。


<details>
  <summary>Details</summary>
Motivation: 传统状态空间模型存在有效记忆有限、需要更大状态尺寸来改善记忆的问题，且难以捕捉多尺度依赖关系，而多尺度依赖对于时间序列、图像和自然语言中的复杂结构建模至关重要。

Method: 提出多尺度SSM框架，在多个分辨率上表示序列动态，每个分辨率使用专门的状态空间动态处理。引入输入依赖的尺度混合器，实现跨分辨率的动态信息融合。

Result: 在Long Range Arena、层次推理、时间序列分类和图像识别等基准测试中，MS-SSM一致优于先前的SSM模型，显著提升了序列建模性能，特别是在长程和层次任务中。

Conclusion: 多分辨率处理在状态空间架构中具有显著优势，MS-SSM通过捕捉细粒度高频模式和粗粒度全局趋势，增强了记忆效率和长程建模能力，同时保持了计算效率。

Abstract: State-space models (SSMs) have recently attention as an efficient alternative to computationally expensive attention-based models for sequence modeling. They rely on linear recurrences to integrate information over time, enabling fast inference, parallelizable training, and control over recurrence stability. However, traditional SSMs often suffer from limited effective memory, requiring larger state sizes for improved recall. Moreover, existing SSMs struggle to capture multi-scale dependencies, which are essential for modeling complex structures in time series, images, and natural language. This paper introduces a multi-scale SSM framework that addresses these limitations by representing sequence dynamics across multiple resolution and processing each resolution with specialized state-space dynamics. By capturing both fine-grained, high-frequency patterns and coarse, global trends, MS-SSM enhances memory efficiency and long-range modeling. We further introduce an input-dependent scale-mixer, enabling dynamic information fusion across resolutions. The proposed approach significantly improves sequence modeling, particularly in long-range and hierarchical tasks, while maintaining computational efficiency. Extensive experiments on benchmarks, including Long Range Arena, hierarchical reasoning, time series classification, and image recognition, demonstrate that MS-SSM consistently outperforms prior SSM-based models, highlighting the benefits of multi-resolution processing in state-space architectures.

</details>


### [174] [More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization](https://arxiv.org/abs/2512.24545)
*Yuma Ichikawa,Yoshihiko Fujisawa,Yudai Fujimoto,Akira Sakai,Katsuki Fujisawa*

Main category: cs.LG

TL;DR: 提出MDBF方法改进LLM的极低位量化，通过多包络设计提升表达能力，同时保持部署友好的二进制推理原语


<details>
  <summary>Details</summary>
Motivation: 现有的Double Binary Factorization (DBF)方法在极低位量化中，其缩放参数限制过强，所有秩分量共享相同的幅度轮廓，导致性能饱和，需要改进幅度表达能力

Method: 提出Multi-envelope DBF (MDBF)，保留共享的1位符号基，但将单一包络替换为秩-l包络，通过共享符号矩阵来维持二进制载体，同时利用有限内存预算提升幅度表达能力；引入闭式初始化和交替优化方法

Result: 在LLaMA和Qwen系列模型上，MDBF在相同权重比特数下，相比之前的二进制格式显著提升了困惑度和零样本准确率

Conclusion: MDBF方法有效解决了DBF的幅度表达限制问题，在保持部署友好推理原语的同时，显著提升了极低位量化LLM的性能

Abstract: For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.

</details>


### [175] [Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics](https://arxiv.org/abs/2512.24445)
*Akash Samanta,Sheldon Williamson*

Main category: cs.LG

TL;DR: 提出基于误差演化诊断的自适应学习框架，将误差分解为偏差、噪声和对齐三个分量，为监督优化、强化学习和元学习提供统一控制机制。


<details>
  <summary>Details</summary>
Motivation: 现有学习系统在非平稳环境中存在不稳定、收敛慢或适应脆弱的问题，传统方法主要关注梯度统计而忽略了误差信号的时间结构。

Method: 提出诊断驱动的自适应学习框架，将误差演化分解为偏差（持续漂移）、噪声（随机变异）和对齐（重复方向激励导致过冲）三个分量，通过轻量级统计在线计算，独立于模型架构和任务领域。

Result: 该分解为监督优化、actor-critic强化学习和学习优化器提供了统一控制框架，在标准平滑性假设下建立了有界有效更新和稳定性性质，诊断信号能根据时序差分误差结构调节适应过程。

Conclusion: 将误差演化提升为自适应学习的一等对象，为动态环境中可靠学习提供了可解释、轻量级的基础框架。

Abstract: Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Building on this framework, we derive diagnostic-driven instantiations including a stabilized supervised optimizer, a diagnostic-regulated actor-critic scheme, and a diagnostic-conditioned learned optimizer. Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to temporal-difference error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.

</details>


### [176] [Exploiting the Prior of Generative Time Series Imputation](https://arxiv.org/abs/2512.23832)
*YuYang Miao,Chang Li,Zehua Chen*

Main category: cs.LG

TL;DR: Bridge-TS提出了一种基于数据到数据生成过程的时间序列插补方法，通过专家先验和组合先验设计，显著提升了生成式时间序列插补的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式时间序列插补方法（如扩散概率模型和Schrodinger桥模型）使用高斯噪声或线性插值结果作为先验，这些先验对真实目标信息不足，导致生成过程负担增加且插补精度有限。

Method: 提出Bridge-TS方法：1）专家先验：使用预训练的transformer模块作为专家提供确定性估计作为先验；2）组合先验：利用多个预训练模型提供不同估计结果，在数据到数据生成过程中组合它们，实现组合先验到目标的插补过程。

Result: 在ETT、Exchange、Weather等多个基准数据集上的实验表明，Bridge-TS在均方误差和平均绝对误差方面达到了新的插补精度记录。

Conclusion: 通过改进先验设计，Bridge-TS证明了在生成式时间序列插补中提升先验信息的重要性，显著提高了插补准确性。

Abstract: Time series imputation, i.e., filling the missing values of a time recording, finds various applications in electricity, finance, and weather modelling. Previous methods have introduced generative models such as diffusion probabilistic models and Schrodinger bridge models to conditionally generate the missing values from Gaussian noise or directly from linear interpolation results. However, as their prior is not informative to the ground-truth target, their generation process inevitably suffer increased burden and limited imputation accuracy. In this work, we present Bridge-TS, building a data-to-data generation process for generative time series imputation and exploiting the design of prior with two novel designs. Firstly, we propose expert prior, leveraging a pretrained transformer-based module as an expert to fill the missing values with a deterministic estimation, and then taking the results as the prior of ground truth target. Secondly, we explore compositional priors, utilizing several pretrained models to provide different estimation results, and then combining them in the data-to-data generation process to achieve a compositional priors-to-target imputation process. Experiments conducted on several benchmark datasets such as ETT, Exchange, and Weather show that Bridge-TS reaches a new record of imputation accuracy in terms of mean square error and mean absolute error, demonstrating the superiority of improving prior for generative time series imputation.

</details>


### [177] [Trellis: Learning to Compress Key-Value Memory in Attention Models](https://arxiv.org/abs/2512.23852)
*Mahdi Karami,Ali Behrouz,Praneeth Kacham,Vahab Mirrokni*

Main category: cs.LG

TL;DR: Trellis是一种新型Transformer架构，通过固定大小的KV记忆和两阶段循环压缩机制，解决了传统Transformer的二次计算复杂度和不断增长的KV缓存问题。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer存在二次计算复杂度和不断增长的KV缓存问题，这限制了其在长序列应用中的效率。需要一种能够动态压缩记忆并在推理时保留重要上下文信息的架构。

Method: Trellis用固定大小的记忆替换标准KV缓存，采用两阶段循环压缩机制。使用带有遗忘门的在线梯度下降过程，使压缩记忆能够递归更新，同时在推理时学习保留来自输入令牌的重要上下文信息。

Result: 在语言建模、常识推理、召回密集型任务和时间序列上的广泛实验表明，该架构优于强基线。随着序列长度增加，性能提升更加明显，突显了其在长上下文应用中的潜力。

Conclusion: Trellis通过有界记忆和动态压缩机制，有效解决了Transformer的计算和内存瓶颈，特别适合长上下文应用，为高效的大规模序列处理提供了新方向。

Abstract: Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.

</details>


### [178] [MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control](https://arxiv.org/abs/2512.24955)
*Yongwei Zhang,Yuanzhe Xing,Quan Quan,Zhikun She*

Main category: cs.LG

TL;DR: MSACL是一个将指数稳定性理论与最大熵强化学习结合的多步Lyapunov证书学习框架，通过指数稳定性标签和λ加权聚合机制平衡偏差-方差权衡，在简单奖励下实现指数稳定性和快速收敛。


<details>
  <summary>Details</summary>
Motivation: 在无模型强化学习中实现可证明的稳定性仍然具有挑战性，特别是在平衡探索与严格安全性方面。现有方法通常依赖复杂的奖励工程，需要一种能够理论保证稳定性同时保持简单奖励的方法。

Method: MSACL整合指数稳定性理论与最大熵强化学习，通过多步Lyapunov证书学习框架。使用离策略多步数据学习满足理论稳定性条件的Lyapunov证书，引入指数稳定性标签(ESL)和λ加权聚合机制平衡多步学习中的偏差-方差权衡。策略优化由稳定性感知优势函数指导，确保学习策略促进快速Lyapunov下降。

Result: 在六个基准测试（包括稳定化和非线性跟踪任务）中，MSACL优于最先进的基于Lyapunov的强化学习算法。在简单奖励下实现指数稳定性和快速收敛，对不确定性表现出显著鲁棒性，并能泛化到未见轨迹。敏感性分析确定多步范围n=20作为跨不同系统的稳健默认值。

Conclusion: MSACL通过将Lyapunov理论与离策略actor-critic框架连接，为可验证的安全学习控制提供了基础。该框架在简单奖励下实现理论保证的稳定性，为安全强化学习提供了新的方向。

Abstract: Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions. By introducing Exponential Stability Labels (ESL) and a $λ$-weighted aggregation mechanism, the framework effectively balances the bias-variance trade-off in multi-step learning. Policy optimization is guided by a stability-aware advantage function, ensuring the learned policy promotes rapid Lyapunov descent. We evaluate MSACL across six benchmarks, including stabilization and nonlinear tracking tasks, demonstrating its superiority over state-of-the-art Lyapunov-based RL algorithms. MSACL achieves exponential stability and rapid convergence under simple rewards, while exhibiting significant robustness to uncertainties and generalization to unseen trajectories. Sensitivity analysis establishes the multi-step horizon $n=20$ as a robust default across diverse systems. By linking Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a foundation for verifiably safe learning-based control. Source code and benchmark environments will be made publicly available.

</details>


### [179] [Flow Matching Neural Processes](https://arxiv.org/abs/2512.23853)
*Hussen Abu Hamad,Dan Rosenbaum*

Main category: cs.LG

TL;DR: 提出基于流匹配的神经过程模型，通过ODE求解器实现条件采样，在多个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 神经过程模型能够直接从数据中学习随机过程，用于推理、采样和条件采样。现有方法在实现复杂度和采样效率方面存在改进空间，需要更简单高效的方法。

Method: 采用流匹配生成建模范式构建神经过程模型，通过ODE求解器实现条件分布采样，无需辅助条件方法，提供精度与运行时间的可控权衡。

Result: 在合成1D高斯过程数据、2D图像和真实世界天气数据等多个基准测试中，该模型优于先前最先进的神经过程方法。

Conclusion: 基于流匹配的神经过程模型实现简单，采样效率高，在多个领域表现出优越性能，为随机过程建模提供了有效的新方法。

Abstract: Neural processes (NPs) are a class of models that learn stochastic processes directly from data and can be used for inference, sampling and conditional sampling. We introduce a new NP model based on flow matching, a generative modeling paradigm that has demonstrated strong performance on various data modalities. Following the NP training framework, the model provides amortized predictions of conditional distributions over any arbitrary points in the data. Compared to previous NP models, our model is simple to implement and can be used to sample from conditional distributions using an ODE solver, without requiring auxiliary conditioning methods. In addition, the model provides a controllable tradeoff between accuracy and running time via the number of steps in the ODE solver. We show that our model outperforms previous state-of-the-art neural process methods on various benchmarks including synthetic 1D Gaussian processes data, 2D images, and real-world weather data.

</details>


### [180] [Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning](https://arxiv.org/abs/2512.24069)
*Xusheng Zhang,Tuan Nguyen,Ting He*

Main category: cs.LG

TL;DR: 提出一种用于无线网络中分散式联邦学习的混合矩阵设计方法，旨在最小化最大单节点能耗，通过时变通信拓扑在多阶段框架中平衡能耗与收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有分散式联邦学习的混合矩阵设计主要关注最小化通信时间，而忽略了能量受限设备的关键需求——最小化单节点能耗。无线通信的广播特性使得这一优化问题更加复杂，需要新的设计方法。

Method: 基于允许任意时变混合矩阵的新收敛定理，提出多阶段设计框架：在优化预算下激活时变通信拓扑，权衡每次迭代的能耗与收敛速度，同时平衡节点间的能耗分布。

Result: 基于真实数据的评估验证了所提方案的有效性，能够结合稀疏混合矩阵的低能耗和密集混合矩阵的快速收敛优势。

Conclusion: 该工作填补了分散式联邦学习中混合矩阵设计在能耗优化方面的空白，提供了一种理论支撑的解决方案，特别适用于能量受限的无线网络设备。

Abstract: We consider the design of mixing matrices to minimize the operation cost for decentralized federated learning (DFL) in wireless networks, with focus on minimizing the maximum per-node energy consumption. As a critical hyperparameter for DFL, the mixing matrix controls both the convergence rate and the needs of agent-to-agent communications, and has thus been studied extensively. However, existing designs mostly focused on minimizing the communication time, leaving open the minimization of per-node energy consumption that is critical for energy-constrained devices. This work addresses this gap through a theoretically-justified solution for mixing matrix design that aims at minimizing the maximum per-node energy consumption until convergence, while taking into account the broadcast nature of wireless communications. Based on a novel convergence theorem that allows arbitrarily time-varying mixing matrices, we propose a multi-phase design framework that activates time-varying communication topologies under optimized budgets to trade off the per-iteration energy consumption and the convergence rate while balancing the energy consumption across nodes. Our evaluations based on real data have validated the efficacy of the proposed solution in combining the low energy consumption of sparse mixing matrices and the fast convergence of dense mixing matrices.

</details>


### [181] [Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding](https://arxiv.org/abs/2512.23858)
*Yue Guan,Changming Yu,Shihan Fang,Weiming Hu,Zaifeng Pan,Zheng Wang,Zihan Liu,Yangjie Zhou,Yufei Ding,Minyi Guo,Jingwen Leng*

Main category: cs.LG

TL;DR: Yggdrasil是一个通过上下文感知树草稿和编译器友好执行实现延迟最优推测解码的系统，相比现有基线可实现最高3.98倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码系统存在动态推测与静态运行时假设不匹配的问题，导致性能不理想，需要设计更优的系统来提升LLM推理效率。

Method: Yggdrasil采用协同设计方法，包括：1) 用于静态图兼容的等增长树结构；2) 基于延迟感知的优化目标进行草稿选择；3) 阶段化调度以减少开销；4) 支持未经修改的LLM。

Result: Yggdrasil在多种硬件配置下相比最先进的基线方法实现了最高3.98倍的加速，支持未经修改的LLM模型。

Conclusion: Yggdrasil通过上下文感知树草稿和编译器友好执行的协同设计，成功解决了推测解码中的动态与静态不匹配问题，实现了延迟最优的LLM推理加速。

Abstract: Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-optimal speculative decoding through context-aware tree drafting and compiler-friendly execution. Yggdrasil introduces an equal-growth tree structure for static graph compatibility, a latency-aware optimization objective for draft selection, and stage-based scheduling to reduce overhead. Yggdrasil supports unmodified LLMs and achieves up to $3.98\times$ speedup over state-of-the-art baselines across multiple hardware setups.

</details>


### [182] [Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining](https://arxiv.org/abs/2512.23862)
*Ruizhe Huang,Kexuan Zhang,Yihao Fang,Baifeng Yu*

Main category: cs.LG

TL;DR: Infini-attention在小规模预训练中增强小语言模型的长上下文能力，通过压缩记忆机制在有限参数下实现更好的长序列检索性能。


<details>
  <summary>Details</summary>
Motivation: 研究小规模预训练SLMs，旨在解决有限数据和计算资源下的高效使用问题，提高低资源环境下的可访问性并降低成本，同时增强紧凑模型的长上下文外推能力。

Method: 使用300M参数的LLaMA模型，结合Infini-attention架构进行预训练。Infini-attention通过从过去片段构建压缩记忆同时保留局部注意力，平衡因子是关键性能参数。

Result: 模型训练稳定，在长上下文检索中优于基线。尽管在16,384标记的上下文长度下性能有所下降，但Infini-attention模型仍比基线准确率高31%。发现重复记忆压缩会降低检索准确性。

Conclusion: Infini-attention等架构记忆机制有助于SLMs实现鲁棒的长上下文能力，能有效补偿SLMs参数有限的不足，为资源受限环境提供可行解决方案。

Abstract: This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.

</details>


### [183] [Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR](https://arxiv.org/abs/2512.23870)
*Yuyang Zhang,Yang Hu,Bo Dai,Na Li*

Main category: cs.LG

TL;DR: 提出一种基于流模型的SAC变体算法，使用流匹配技术更新策略，通过重要性采样流匹配(ISFM)实现高效学习，在线性二次调节器问题上验证了学习最优动作分布的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的SAC算法为了效率通常使用简单的策略类别来近似基于能量的策略，但这牺牲了表达能力和鲁棒性。本文旨在利用流模型的丰富表达能力来改进SAC算法。

Method: 提出基于流模型的SAC变体算法：1) 使用流模型参数化策略；2) 利用瞬时变量变换技术评估流策略；3) 提出重要性采样流匹配(ISFM)在线变体更新策略，仅需用户指定的采样分布而非未知目标分布；4) 对ISFM进行理论分析，研究不同采样分布选择对学习效率的影响。

Result: 在线性二次调节器问题的案例研究中，证明了所提算法能够学习到最优动作分布。

Conclusion: 通过将流模型与SAC算法结合，利用流模型的表达能力，提出了一种能够学习最优动作分布的新型强化学习算法，并通过ISFM技术实现了高效的在线策略更新。

Abstract: Soft actor-critic (SAC) is a popular algorithm for max-entropy reinforcement learning. In practice, the energy-based policies in SAC are often approximated using simple policy classes for efficiency, sacrificing the expressiveness and robustness. In this paper, we propose a variant of the SAC algorithm that parameterizes the policy with flow-based models, leveraging their rich expressiveness. In the algorithm, we evaluate the flow-based policy utilizing the instantaneous change-of-variable technique and update the policy with an online variant of flow matching developed in this paper. This online variant, termed importance sampling flow matching (ISFM), enables policy update with only samples from a user-specified sampling distribution rather than the unknown target distribution. We develop a theoretical analysis of ISFM, characterizing how different choices of sampling distributions affect the learning efficiency. Finally, we conduct a case study of our algorithm on the max-entropy linear quadratic regulator problems, demonstrating that the proposed algorithm learns the optimal action distribution.

</details>


### [184] [Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City](https://arxiv.org/abs/2512.23898)
*Tin Hoang*

Main category: cs.LG

TL;DR: 该研究对10种深度学习架构进行了全球水平辐照度（GHI）短期预测的全面基准测试，发现Transformer表现最佳，并通过知识蒸馏实现了模型压缩且性能提升。


<details>
  <summary>Details</summary>
Motivation: 准确预测全球水平辐照度对于缓解太阳能并网时的波动性至关重要，需要评估不同深度学习架构在短期GHI预测中的性能差异。

Method: 使用胡志明市2011-2020年高分辨率NSRDB卫星数据，对比了10种深度学习架构（包括LSTM、TCN、Transformer、Informer、iTransformer、TSMixer、Mamba等）的1小时前GHI预测性能，并采用SHAP分析解释模型的时间推理模式，最后使用知识蒸馏压缩高性能Transformer模型。

Result: Transformer架构表现最佳，R²达到0.9696；SHAP分析显示Transformer具有"近期偏好"，而Mamba能利用24小时周期性依赖；知识蒸馏成功将Transformer压缩23.5%，同时降低预测误差（MAE：23.78 W/m²）。

Conclusion: Transformer是GHI短期预测的最佳架构，通过知识蒸馏可实现模型压缩与性能提升，为资源受限的边缘设备部署提供了可行方案。

Abstract: Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices.

</details>


### [185] [Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks](https://arxiv.org/abs/2512.23905)
*Peter Farag*

Main category: cs.LG

TL;DR: SPM（阶段式成对混合器）是一种结构化线性算子，用稀疏成对混合阶段的组合替代密集矩阵，将计算和参数复杂度从O(n²)降低到O(nL)，同时引入组合归纳偏置


<details>
  <summary>Details</summary>
Motivation: 密集线性层是现代机器学习模型中计算和参数成本的主要来源，尽管其具有二次复杂度且常常与学习表示的组合结构不匹配

Method: 引入SPM作为结构化线性算子，用稀疏成对混合阶段的组合替代密集矩阵，实现O(nL)时间和参数复杂度，提供正交保范旋转和通用2×2混合两种参数化变体

Result: 在结构化学习问题上显著降低实际计算成本并提高准确性，在真实世界基准测试中保持竞争力，同时提供精确的闭式前向和反向计算

Conclusion: SPM作为密集线性层的即插即用替代品，不仅提供计算效率，还通过其阶段式结构引入组合归纳偏置，在任务结构与模型结构对齐时改善泛化能力

Abstract: Dense linear layers are a dominant source of computational and parametric cost in modern machine learning models, despite their quadratic complexity and often being misaligned with the compositional structure of learned representations. We introduce Stagewise Pairwise Mixers (SPM), a structured linear operator that replaces dense matrices with a composition of sparse pairwise-mixing stages. An SPM layer implements a global linear transformation in $O(nL)$ time with $O(nL)$ parameters, where $L$ is typically constant or $log_2n$, and admits exact closed-form forward and backward computations. SPM is designed as a drop-in replacement for dense linear layers in feedforward networks, recurrent architectures, attention mechanisms, etc. We derive complete forward and backward expressions for two parameterizations: an orthogonal norm-preserving rotation-based variant and a fully general $2 \times 2$ mixing variant. Beyond computational savings, the stagewise structure of SPM induces an explicit compositional inductive bias that constrains model capacity and improves generalization when aligned with task structure. We present proof-of-concept experiments demonstrating substantial reductions in wall-clock cost and improved accuracy on structured learning problems, while retaining competitive performance on real-world benchmarks.

</details>


### [186] [Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias](https://arxiv.org/abs/2512.23916)
*Xia Chen*

Main category: cs.LG

TL;DR: 论文提出物理约束（如代谢限制）不是限制，而是作为时间归纳偏置促进泛化，通过相空间分析揭示扩张动态放大噪声而适当耗散动态压缩相空间，与网络频谱偏置对齐，强制提取不变特征。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习关注无约束优化，但生物系统在严格代谢约束下运行。作者认为这些物理约束塑造动态，不是限制，而是作为时间归纳偏置促进泛化。

Method: 通过信号传播的相空间分析，揭示扩张动态放大噪声而适当耗散动态压缩相空间的基本不对称性。这种条件可通过输入编码外部施加，或通过网络自身的时间动态内在实现。两种途径都需要能够进行时间积分和适当约束的架构来解码诱导不变性。

Result: 在监督分类、无监督重建和零样本强化学习的全面评估中，证明临界"过渡"机制最大化泛化能力。这些发现确立了动态约束作为一类独特的归纳偏置。

Conclusion: 稳健的AI发展不仅需要扩展和消除限制，还需要计算掌握自然促进泛化的时间特性。动态约束应被视为一种独特的归纳偏置类别。

Abstract: Conventional deep learning prioritizes unconstrained optimization, yet biological systems operate under strict metabolic constraints. We propose that these physical constraints shape dynamics to function not as limitations, but as a temporal inductive bias that breeds generalization. Through a phase-space analysis of signal propagation, we reveal a fundamental asymmetry: expansive dynamics amplify noise, whereas proper dissipative dynamics compress phase space that aligns with the network's spectral bias, compelling the abstraction of invariant features. This condition can be imposed externally via input encoding, or intrinsically through the network's own temporal dynamics. Both pathways require architectures capable of temporal integration and proper constraints to decode induced invariants, whereas static architectures fail to capitalize on temporal structure. Through comprehensive evaluations across supervised classification, unsupervised reconstruction, and zero-shot reinforcement learning, we demonstrate that a critical "transition" regime maximizes generalization capability. These findings establish dynamical constraints as a distinct class of inductive bias, suggesting that robust AI development requires not only scaling and removing limitations, but computationally mastering the temporal characteristics that naturally promote generalization.

</details>


### [187] [DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks](https://arxiv.org/abs/2512.23948)
*Kacem Khaled,Felipe Gohring de Magalhães,Gabriela Nicolescu*

Main category: cs.LG

TL;DR: DivQAT是一种基于量化感知训练的新型算法，通过修改量化过程将模型提取防御集成到训练中，增强量化CNN对提取攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 量化CNN容易受到提取攻击导致IP盗窃，现有防御方法存在局限性：1）仅在训练后添加噪声作为事后补救；2）计算成本高；3）对受害者模型有不切实际的假设；4）不适用于量化模型。

Method: 提出DivQAT算法，基于量化感知训练修改量化过程，将模型提取防御直接集成到训练过程中，而不是作为训练后的附加措施。

Result: 在基准视觉数据集上验证了DivQAT能有效防御模型提取攻击，同时不损害模型精度。与其他防御机制结合使用时，相比传统QAT能进一步提升防御效果。

Conclusion: DivQAT是首个通过修改量化过程将模型提取防御集成到训练中的技术，为量化CNN提供了有效的提取攻击防御方案，且适用于边缘设备实现。

Abstract: Convolutional Neural Networks (CNNs) and their quantized counterparts are vulnerable to extraction attacks, posing a significant threat of IP theft. Yet, the robustness of quantized models against these attacks is little studied compared to large models. Previous defenses propose to inject calculated noise into the prediction probabilities. However, these defenses are limited since they are not incorporated during the model design and are only added as an afterthought after training. Additionally, most defense techniques are computationally expensive and often have unrealistic assumptions about the victim model that are not feasible in edge device implementations and do not apply to quantized models. In this paper, we propose DivQAT, a novel algorithm to train quantized CNNs based on Quantization Aware Training (QAT) aiming to enhance their robustness against extraction attacks. To the best of our knowledge, our technique is the first to modify the quantization process to integrate a model extraction defense into the training process. Through empirical validation on benchmark vision datasets, we demonstrate the efficacy of our technique in defending against model extraction attacks without compromising model accuracy. Furthermore, combining our quantization technique with other defense mechanisms improves their effectiveness compared to traditional QAT.

</details>


### [188] [Physics-informed Graph Neural Networks for Operational Flood Modeling](https://arxiv.org/abs/2512.23964)
*Carlo Malapad Acosta,Herath Mudiyanselage Viraj Vidura Herath,Jia Yu Lim,Abhishek Saha,Sanka Rasnayaka,Lucy Marshall*

Main category: cs.LG

TL;DR: 提出DUALFloodGNN，一种新型洪水预测图神经网络，通过全局和局部物理约束嵌入，在保持高计算效率的同时显著提升多水文变量预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的数值洪水模型虽然准确但计算成本高，难以满足需要快速预测的实时操作需求。图神经网络(GNNs)能提供速度和准确性，且易于结合物理信息方法提高可解释性。

Method: 提出DUALFloodGNN架构，通过显式损失项在全局和局部尺度嵌入物理约束；采用共享消息传递框架同时预测节点水体积和边流量；使用多步损失和动态课程学习增强自回归推理性能。

Result: 相比标准GNN架构和最先进的GNN洪水模型，DUALFloodGNN在预测多个水文变量方面取得显著改进，同时保持高计算效率。

Conclusion: DUALFloodGNN通过物理约束嵌入和优化的训练策略，为快速准确的洪水预测提供了有效解决方案，模型已开源。

Abstract: Flood models inform strategic disaster management by simulating the spatiotemporal hydrodynamics of flooding. While physics-based numerical flood models are accurate, their substantial computational cost limits their use in operational settings where rapid predictions are essential. Models designed with graph neural networks (GNNs) provide both speed and accuracy while having the ability to process unstructured spatial domains. Given its flexible input and architecture, GNNs can be leveraged alongside physics-informed techniques with ease, significantly improving interpretability. This study introduces a novel flood GNN architecture, DUALFloodGNN, which embeds physical constraints at both global and local scales through explicit loss terms. The model jointly predicts water volume at nodes and flow along edges through a shared message-passing framework. To improve performance for autoregressive inference, model training is conducted with a multi-step loss enhanced with dynamic curriculum learning. Compared with standard GNN architectures and state-of-the-art GNN flood models, DUALFloodGNN achieves substantial improvements in predicting multiple hydrologic variables while maintaining high computational efficiency. The model is open-sourced at https://github.com/acostacos/dual_flood_gnn.

</details>


### [189] [Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing](https://arxiv.org/abs/2512.23977)
*Giacinto Paolo Saggese,Paul Smith*

Main category: cs.LG

TL;DR: DataFlow是一个用于在无限时间序列数据上构建、测试和部署高性能机器学习系统的计算框架，通过点对点幂等性和DAG执行模型解决批处理到流式生产转换中的问题。


<details>
  <summary>Details</summary>
Motivation: 传统数据科学工作流假设有限数据集，从批处理原型迁移到流式生产系统时需要大量重新实现，导致因果关系违反、批处理边界伪影和实时故障难以复现等问题。

Method: 基于有向无环图(DAG)的统一执行模型，具有点对点幂等性：任何时间t的输出仅依赖于t之前的固定长度上下文窗口。框架自动跟踪所有转换的知识时间，强制执行严格因果关系。

Result: DataFlow确保在批处理模式下开发的模型无需代码更改即可在流式生产中完全一致地执行，支持跨时间和特征维度的灵活分块，集成Python数据科学栈，提供在线学习的fit/predict语义。

Conclusion: DataFlow有效解决了批处理到流式生产的转换问题，在金融交易、物联网、欺诈检测和实时分析等多个领域展示了其有效性，通过统一框架消除了传统工作流中的关键缺陷。

Abstract: We present DataFlow, a computational framework for building, testing, and deploying high-performance machine learning systems on unbounded time-series data. Traditional data science workflows assume finite datasets and require substantial reimplementation when moving from batch prototypes to streaming production systems. This gap introduces causality violations, batch boundary artifacts, and poor reproducibility of real-time failures.
  DataFlow resolves these issues through a unified execution model based on directed acyclic graphs (DAGs) with point-in-time idempotency: outputs at any time t depend only on a fixed-length context window preceding t. This guarantee ensures that models developed in batch mode execute identically in streaming production without code changes. The framework enforces strict causality by automatically tracking knowledge time across all transformations, eliminating future-peeking bugs.
  DataFlow supports flexible tiling across temporal and feature dimensions, allowing the same model to operate at different frequencies and memory profiles via configuration alone. It integrates natively with the Python data science stack and provides fit/predict semantics for online learning, caching and incremental computation, and automatic parallelization through DAG-based scheduling. We demonstrate its effectiveness across domains including financial trading, IoT, fraud detection, and real-time analytics.

</details>


### [190] [Information-Theoretic Quality Metric of Low-Dimensional Embeddings](https://arxiv.org/abs/2512.23981)
*Sebastián Gutiérrez-Bernal,Hector Medel Cobaxin,Abiel Galindo González*

Main category: cs.LG

TL;DR: 提出基于信息论的嵌入质量评估新指标ERPM，通过邻域矩阵奇异值谱的香农熵和稳定秩量化信息损失，相比传统距离或几何指标能更直接评估信息保留程度。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入评估指标（如应力、基于排名的邻域准则、局部Procrustes）主要量化距离或局部几何的失真，但未能直接评估高维数据投影到低维空间时的信息保留程度。需要从信息论角度开发更直接的评估方法。

Method: 提出熵秩保持度量（ERPM），基于邻域矩阵奇异值谱的香农熵和稳定秩，量化原始表示与降维投影之间的不确定性变化，提供邻域级指标和全局汇总统计。

Result: 验证显示：基于距离的指标与几何和谱度量相关性很低；ERPM与局部Procrustes平均相关性较强，但在局部区域存在显著差异。ERPM能识别信息损失严重的邻域。

Conclusion: ERPM通过识别信息损失严重的邻域，补充了现有评估指标，特别是在构建早期预警指标等对信息敏感的应用中，能够提供更全面的嵌入质量评估。

Abstract: In this work we study the quality of low-dimensional embeddings from an explicitly information-theoretic perspective. We begin by noting that classical evaluation metrics such as stress, rank-based neighborhood criteria, or Local Procrustes quantify distortions in distances or in local geometries, but do not directly assess how much information is preserved when projecting high-dimensional data onto a lower-dimensional space. To address this limitation, we introduce the Entropy Rank Preservation Measure (ERPM), a local metric based on the Shannon entropy of the singular-value spectrum of neighborhood matrices and on the stable rank, which quantifies changes in uncertainty between the original representation and its reduced projection, providing neighborhood-level indicators and a global summary statistic. To validate the results of the metric, we compare its outcomes with the Mean Relative Rank Error (MRRE), which is distance-based, and with Local Procrustes, which is based on geometric properties, using a financial time series and a manifold commonly studied in the literature. We observe that distance-based criteria exhibit very low correlation with geometric and spectral measures, while ERPM and Local Procrustes show strong average correlation but display significant discrepancies in local regimes, leading to the conclusion that ERPM complements existing metrics by identifying neighborhoods with severe information loss, thereby enabling a more comprehensive assessment of embeddings, particularly in information-sensitive applications such as the construction of early-warning indicators.

</details>


### [191] [Tracing the Heart's Pathways: ECG Representation Learning from a Cardiac Conduction Perspective](https://arxiv.org/abs/2512.24002)
*Tan Pan,Yixuan Sun,Chen Jiang,Qiong Gao,Rui Sun,Xingmeng Zhang,Zhenqi Yang,Limei Han,Yixiu Liang,Yuan Cheng,Kaiyu Guo*

Main category: cs.LG

TL;DR: CLEAR-HUG：一个两阶段ECG自监督学习框架，通过捕捉跨导联的细微传导变化并遵循临床诊断流程，提升心脏疾病诊断性能


<details>
  <summary>Details</summary>
Motivation: 现有ECG自监督学习方法存在两个关键局限：1）只关注跨导联和心跳的一致模式，忽略了心脏传导过程中固有的心跳差异，而这些细微变化携带独特的生理特征；2）未能遵循ECG临床诊断流程（从单个心跳到单导联再到导联组合的顺序逻辑）

Method: 提出两阶段框架CLEAR-HUG：第一阶段是CLEAR自监督学习模型，使用稀疏注意力机制将每个心跳视为独立实体进行信号重建，捕捉心跳间的特定变化和一般共性；第二阶段是HUG分层诊断头，模拟临床工作流程进行疾病诊断

Result: 在六个任务上的实验结果显示性能提升6.84%，验证了CLEAR-HUG在增强心脏传导表示和使模式与专家诊断指南对齐方面的有效性

Conclusion: CLEAR-HUG通过捕捉心脏传导的细微变化并遵循ECG诊断指南，显著提升了ECG表示学习和疾病诊断性能，为心脏诊断提供了更符合临床实践的AI解决方案

Abstract: The multi-lead electrocardiogram (ECG) stands as a cornerstone of cardiac diagnosis. Recent strides in electrocardiogram self-supervised learning (eSSL) have brightened prospects for enhancing representation learning without relying on high-quality annotations. Yet earlier eSSL methods suffer a key limitation: they focus on consistent patterns across leads and beats, overlooking the inherent differences in heartbeats rooted in cardiac conduction processes, while subtle but significant variations carry unique physiological signatures. Moreover, representation learning for ECG analysis should align with ECG diagnostic guidelines, which progress from individual heartbeats to single leads and ultimately to lead combinations. This sequential logic, however, is often neglected when applying pre-trained models to downstream tasks. To address these gaps, we propose CLEAR-HUG, a two-stage framework designed to capture subtle variations in cardiac conduction across leads while adhering to ECG diagnostic guidelines. In the first stage, we introduce an eSSL model termed Conduction-LEAd Reconstructor (CLEAR), which captures both specific variations and general commonalities across heartbeats. Treating each heartbeat as a distinct entity, CLEAR employs a simple yet effective sparse attention mechanism to reconstruct signals without interference from other heartbeats. In the second stage, we implement a Hierarchical lead-Unified Group head (HUG) for disease diagnosis, mirroring clinical workflow. Experimental results across six tasks show a 6.84% improvement, validating the effectiveness of CLEAR-HUG. This highlights its ability to enhance representations of cardiac conduction and align patterns with expert diagnostic guidelines.

</details>


### [192] [Hyperspherical Graph Representation Learning via Adaptive Neighbor-Mean Alignment and Uniformity](https://arxiv.org/abs/2512.24062)
*Rui Chen,Junjun Guo,Hongbin Wang,Yan Xiang,Yantuan Xian,Zhengtao Yu*

Main category: cs.LG

TL;DR: HyperGRL：一种基于超球面的图表示学习框架，通过自适应邻居均值对齐和无采样均匀性实现，无需负采样和复杂架构，在节点分类、聚类和链接预测任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习方法通常依赖代理对比目标或互信息最大化，需要复杂架构、负采样策略和敏感的超参数调整，可能导致过平滑、过压缩和训练不稳定问题。

Method: 提出HyperGRL框架，将节点嵌入到单位超球面上，通过两个对抗耦合目标：邻居均值对齐（使用节点局部邻域的均值表示构建语义稳定的目标）和无采样均匀性（通过L2超球面正则化实现分布均匀性）。引入熵引导的自适应平衡机制动态调节对齐和均匀性的交互。

Result: 在节点分类、节点聚类和链接预测任务上进行了广泛实验，分别比现有最强方法平均提升了1.49%、0.86%和0.74%，展示了优越的表示质量和泛化能力。

Conclusion: 基于几何基础的无采样对比目标在图表示学习中具有有效性，HyperGRL通过简单的架构和稳定的训练机制实现了优异的性能。

Abstract: Graph representation learning (GRL) aims to encode structural and semantic dependencies of graph-structured data into low-dimensional embeddings. However, existing GRL methods often rely on surrogate contrastive objectives or mutual information maximization, which typically demand complex architectures, negative sampling strategies, and sensitive hyperparameter tuning. These design choices may induce over-smoothing, over-squashing, and training instability. In this work, we propose HyperGRL, a unified framework for hyperspherical graph representation learning via adaptive neighbor-mean alignment and sampling-free uniformity. HyperGRL embeds nodes on a unit hypersphere through two adversarially coupled objectives: neighbor-mean alignment and sampling-free uniformity. The alignment objective uses the mean representation of each node's local neighborhood to construct semantically grounded, stable targets that capture shared structural and feature patterns. The uniformity objective formulates dispersion via an L2-based hyperspherical regularization, encouraging globally uniform embedding distributions while preserving discriminative information. To further stabilize training, we introduce an entropy-guided adaptive balancing mechanism that dynamically regulates the interplay between alignment and uniformity without requiring manual tuning. Extensive experiments on node classification, node clustering, and link prediction demonstrate that HyperGRL delivers superior representation quality and generalization across diverse graph structures, achieving average improvements of 1.49%, 0.86%, and 0.74% over the strongest existing methods, respectively. These findings highlight the effectiveness of geometrically grounded, sampling-free contrastive objectives for graph representation learning.

</details>


### [193] [How and Why LLMs Generalize: A Fine-Grained Analysis of LLM Reasoning from Cognitive Behaviors to Low-Level Patterns](https://arxiv.org/abs/2512.24063)
*Haoyue Bai,Yiyou Sun,Wenjie Hu,Shi Qiu,Maggie Ziyu Huan,Peiyang Song,Robert Nowak,Dawn Song*

Main category: cs.LG

TL;DR: 论文通过分解推理为原子核心技能，对比了SFT和RL调优在LLM泛化能力上的差异，发现RL能保持更稳定的推理技能而SFT容易过拟合。


<details>
  <summary>Details</summary>
Motivation: LLMs在监督微调(SFT)和强化学习(RL)调优后表现出不同的泛化行为：SFT常导致能力变窄，而RL倾向于保持能力。现有研究主要依赖粗粒度准确率指标，缺乏对推理能力具体变化的深入理解。

Method: 1. 引入新基准，将推理分解为计算、事实检索、模拟、枚举和诊断等原子核心技能；2. 结合分布差异和参数统计等低层统计模式分析；3. 使用元探测框架追踪不同训练阶段模型行为。

Result: RL调优模型保持更稳定的行为特征，抵抗推理技能崩溃；SFT模型表现出更明显的漂移，容易过拟合到表面模式。新基准提供了对LLM推理能力如何出现、转移和崩溃的细粒度视图。

Conclusion: 这项工作为理解LLM中的推理本质提供了新见解，并指出了设计促进广泛、稳健泛化的训练策略的原则。RL调优在保持推理技能稳定性方面优于SFT。

Abstract: Large Language Models (LLMs) display strikingly different generalization behaviors: supervised fine-tuning (SFT) often narrows capability, whereas reinforcement-learning (RL) tuning tends to preserve it. The reasons behind this divergence remain unclear, as prior studies have largely relied on coarse accuracy metrics. We address this gap by introducing a novel benchmark that decomposes reasoning into atomic core skills such as calculation, fact retrieval, simulation, enumeration, and diagnostic, providing a concrete framework for addressing the fundamental question of what constitutes reasoning in LLMs. By isolating and measuring these core skills, the benchmark offers a more granular view of how specific cognitive abilities emerge, transfer, and sometimes collapse during post-training. Combined with analyses of low-level statistical patterns such as distributional divergence and parameter statistics, it enables a fine-grained study of how generalization evolves under SFT and RL across mathematical, scientific reasoning, and non-reasoning tasks. Our meta-probing framework tracks model behavior at different training stages and reveals that RL-tuned models maintain more stable behavioral profiles and resist collapse in reasoning skills, whereas SFT models exhibit sharper drift and overfit to surface patterns. This work provides new insights into the nature of reasoning in LLMs and points toward principles for designing training strategies that foster broad, robust generalization.

</details>


### [194] [Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework](https://arxiv.org/abs/2512.24075)
*Jiazhao Shi,Ziyu Wang,Yichen Lin,Shoufeng Lu*

Main category: cs.LG

TL;DR: TPI-AI：融合物理启发交互特征与深度时序表示的混合框架，用于多场景变道意图预测，在高速公路和匝道丰富环境中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 变道意图预测对自动驾驶安全至关重要，但在自然交通中面临挑战：运动学噪声、严重类别不平衡以及异构高速公路场景泛化能力有限。

Method: 提出TPI-AI混合框架：使用双层双向LSTM编码器学习多步轨迹历史的紧凑嵌入，将其与运动学、安全性和交互感知特征（如车头时距、TTC、安全间隙指标）拼接，用LightGBM分类器进行三类意图识别；采用不平衡感知优化（重采样/加权和逐折阈值校准）。

Result: 在两个大规模无人机数据集（highD和exiD）上评估，TPI-AI优于单独的LightGBM和Bi-LSTM基线，在T=1,2,3秒预测时域上，highD的macro-F1分别为0.9562、0.9124、0.8345，exiD分别为0.9247、0.8197、0.7605。

Conclusion: 将物理启发交互特征与学习的时序嵌入相结合，能够实现鲁棒的多场景变道意图预测。

Abstract: Lane-change intention prediction is safety-critical for autonomous driving and ADAS, but remains difficult in naturalistic traffic due to noisy kinematics, severe class imbalance, and limited generalization across heterogeneous highway scenarios. We propose Temporal Physics-Informed AI (TPI-AI), a hybrid framework that fuses deep temporal representations with physics-inspired interaction cues. A two-layer bidirectional LSTM (Bi-LSTM) encoder learns compact embeddings from multi-step trajectory histories; we concatenate these embeddings with kinematics-, safety-, and interaction-aware features (e.g., headway, TTC, and safe-gap indicators) and train a LightGBM classifier for three-class intention recognition (No-LC, Left-LC, Right-LC). To improve minority-class reliability, we apply imbalance-aware optimization including resampling/weighting and fold-wise threshold calibration. Experiments on two large-scale drone-based datasets, highD (straight highways) and exiD (ramp-rich environments), use location-based splits and evaluate prediction horizons T = 1, 2, 3 s. TPI-AI outperforms standalone LightGBM and Bi-LSTM baselines, achieving macro-F1 of 0.9562, 0.9124, 0.8345 on highD and 0.9247, 0.8197, 0.7605 on exiD at T = 1, 2, 3 s, respectively. These results show that combining physics-informed interaction features with learned temporal embeddings yields robust multi-scenario lane-change intention prediction.

</details>


### [195] [Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study](https://arxiv.org/abs/2512.24102)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 该论文对GP-VAE模型中的潜在自回归进行了消融分析，比较了三种模型变体，发现潜在自回归能产生更符合高斯过程先验的潜在轨迹和更好的长期稳定性。


<details>
  <summary>Details</summary>
Motivation: 语言模型通常依赖token级别的自回归分解，而作者先前的工作提出将序列结构转移到潜在空间。本文旨在系统性地分析潜在自回归在GP-VAE模型中的作用，理解其如何影响潜在表示的结构和长期行为。

Method: 进行系统的消融研究，比较三种模型：(1)具有自回归潜在动态的完整GP-VAE模型；(2)潜在变量独立的非自回归消融模型；(3)标准token级自回归Transformer。在中等规模语料库和短训练上下文的设定下进行评估。

Result: 在考虑的设定下，潜在自回归诱导的潜在轨迹显著更符合高斯过程先验，并表现出更好的长期稳定性。移除自回归会导致潜在结构退化和不稳定的长期行为。潜在自回归是组织长期结构的有效机制，与token级自回归建模互补。

Conclusion: 本文是对表示结构的实证分析而非新架构提案。潜在自回归在GP-VAE模型中起着重要作用，能产生更结构化的潜在表示和更稳定的长期行为，为理解序列建模中的潜在表示提供了实证依据。

Abstract: This paper provides an ablation-based analysis of latent autoregression in GP-VAE models, building upon our previous work introducing the architecture. Language models typically rely on an autoregressive factorization over tokens. In contrast, our prior work proposed shifting sequential structure to the latent space through a causal Gaussian process, while using a non-autoregressive decoder. Here, we conduct a systematic ablation study of the role played by latent autoregression. We compare (i) a full GP-VAE model with autoregressive latent dynamics, (ii) a non-autoregressive ablation in which latent variables are independent, and (iii) a standard token-level autoregressive Transformer. Our results show that, within the considered regime (medium-scale corpora and short training contexts), latent autoregression induces latent trajectories that are significantly more compatible with the Gaussian-process prior and exhibit greater long-horizon stability. In contrast, removing autoregression leads to degraded latent structure and unstable long-range behavior. These findings highlight the role of latent autoregression as an effective mechanism for organizing long-range structure, while remaining complementary to token-level autoregressive modeling. They should be interpreted as an empirical analysis of representational structure rather than as a proposal for a new architecture.

</details>


### [196] [Enhancing LLM Planning Capabilities through Intrinsic Self-Critique](https://arxiv.org/abs/2512.24103)
*Bernd Bohnet,Pierre-Alexandre Kamienny,Hanie Sedghi,Dilan Gorur,Pranjal Awasthi,Aaron Parisi,Kevin Swersky,Rosanne Liu,Azade Nova,Noah Fiedel*

Main category: cs.LG

TL;DR: LLM通过自我批判提升规划性能，在多个基准测试中取得显著改进，无需外部验证器


<details>
  <summary>Details</summary>
Motivation: 尽管先前研究对LLM自我批判方法的有效性表示怀疑，但本文旨在证明LLM通过内在自我批判能够显著提升规划任务的性能

Method: 采用少样本学习技术并逐步扩展到多样本方法作为基础，然后通过迭代的纠正和精炼过程进行自我批判

Result: 在Blocksworld、Logistics和Mini-grid数据集上取得显著性能提升，超过了强基线准确率，在2024年10月的LLM检查点中创造了新的最先进水平

Conclusion: 自我批判能显著提升规划性能，该方法具有内在自我改进能力，适用于不同模型版本，未来应用于更复杂搜索技术和更强大模型将获得更好性能

Abstract: We demonstrate an approach for LLMs to critique their \emph{own} answers with the goal of enhancing their performance that leads to significant improvements over established planning benchmarks. Despite the findings of earlier research that has cast doubt on the effectiveness of LLMs leveraging self critique methods, we show significant performance gains on planning datasets in the Blocksworld domain through intrinsic self-critique, without external source such as a verifier. We also demonstrate similar improvements on Logistics and Mini-grid datasets, exceeding strong baseline accuracies. We employ a few-shot learning technique and progressively extend it to a many-shot approach as our base method and demonstrate that it is possible to gain substantial improvement on top of this already competitive approach by employing an iterative process for correction and refinement. We illustrate how self-critique can significantly boost planning performance. Our empirical results present new state-of-the-art on the class of models considered, namely LLM model checkpoints from October 2024. Our primary focus lies on the method itself, demonstrating intrinsic self-improvement capabilities that are applicable regardless of the specific model version, and we believe that applying our method to more complex search techniques and more capable models will lead to even better performance.

</details>


### [197] [OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization](https://arxiv.org/abs/2512.24124)
*Advait Gadhikar,Riccardo Grazzi,James Hensman*

Main category: cs.LG

TL;DR: 提出OptRot和OptRot⁺两种方法，通过学习可融合的旋转来减少LLM权重和激活中的异常值，改善量化效果，在W4A8设置中表现优异


<details>
  <summary>Details</summary>
Motivation: 大型语言模型权重和激活中存在异常值，这使得量化变得困难。现有方法使用旋转来缓解这些异常值，但需要更有效的方法来最小化权重量化误差

Method: 提出OptRot方法，通过最小化旋转后权重的元素四次方来减少权重异常值；还提出OptRot⁺方法，结合激活协方差信息进一步改进性能。主要基于GPTQ量化方法

Result: OptRot在权重量化方面优于Hadamard旋转和更昂贵的数据依赖方法（如SpinQuant和OSTQuant），在W4A8设置中也改善了激活量化。OptRot⁺进一步提升了性能，但在W4A4设置中两种方法表现较差

Conclusion: 提出的OptRot和OptRot⁺方法能有效减少LLM量化中的异常值问题，在W4A8设置中表现优异，但揭示了权重量化和激活量化之间的权衡关系

Abstract: The presence of outliers in Large Language Models (LLMs) weights and activations makes them difficult to quantize. Recent work has leveraged rotations to mitigate these outliers. In this work, we propose methods that learn fusible rotations by minimizing principled and cheap proxy objectives to the weight quantization error. We primarily focus on GPTQ as the quantization method. Our main method is OptRot, which reduces weight outliers simply by minimizing the element-wise fourth power of the rotated weights. We show that OptRot outperforms both Hadamard rotations and more expensive, data-dependent methods like SpinQuant and OSTQuant for weight quantization. It also improves activation quantization in the W4A8 setting. We also propose a data-dependent method, OptRot$^{+}$, that further improves performance by incorporating information on the activation covariance. In the W4A4 setting, we see that both OptRot and OptRot$^{+}$ perform worse, highlighting a trade-off between weight and activation quantization.

</details>


### [198] [GARDO: Reinforcing Diffusion Models without Reward Hacking](https://arxiv.org/abs/2512.24138)
*Haoran He,Yuxiao Ye,Jie Liu,Jiajun Liang,Zhiyong Wang,Ziyang Yuan,Xintao Wang,Hangyu Mao,Pengfei Wan,Ling Pan*

Main category: cs.LG

TL;DR: GARDO框架通过选择性正则化、自适应参考模型更新和多样性感知优化，解决扩散模型在线强化学习中的奖励黑客、探索不足和模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于在线强化学习的扩散模型微调方法面临三个核心挑战：1）代理奖励与真实目标不匹配导致奖励黑客问题；2）传统正则化方法牺牲样本效率并阻碍探索；3）模式崩溃导致生成多样性下降。

Method: 提出GARDO框架：1）选择性正则化：仅对高不确定性样本应用正则化惩罚；2）自适应参考模型更新：定期更新参考模型以匹配在线策略能力；3）多样性感知优化：对高质量且高多样性的样本给予奖励放大。

Result: 在多种代理奖励和未见指标上的实验表明，GARDO能有效缓解奖励黑客问题，提升生成多样性，同时保持样本效率和探索能力，展现出良好的有效性和鲁棒性。

Conclusion: GARDO通过创新的选择性正则化、自适应参考模型更新和多样性感知优化机制，成功解决了扩散模型在线强化学习中的关键挑战，为平衡样本效率、探索能力和多样性提供了有效解决方案。

Abstract: Fine-tuning diffusion models via online reinforcement learning (RL) has shown great potential for enhancing text-to-image alignment. However, since precisely specifying a ground-truth objective for visual tasks remains challenging, the models are often optimized using a proxy reward that only partially captures the true goal. This mismatch often leads to reward hacking, where proxy scores increase while real image quality deteriorates and generation diversity collapses. While common solutions add regularization against the reference policy to prevent reward hacking, they compromise sample efficiency and impede the exploration of novel, high-reward regions, as the reference policy is usually sub-optimal. To address the competing demands of sample efficiency, effective exploration, and mitigation of reward hacking, we propose Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO), a versatile framework compatible with various RL algorithms. Our key insight is that regularization need not be applied universally; instead, it is highly effective to selectively penalize a subset of samples that exhibit high uncertainty. To address the exploration challenge, GARDO introduces an adaptive regularization mechanism wherein the reference model is periodically updated to match the capabilities of the online policy, ensuring a relevant regularization target. To address the mode collapse issue in RL, GARDO amplifies the rewards for high-quality samples that also exhibit high diversity, encouraging mode coverage without destabilizing the optimization process. Extensive experiments across diverse proxy rewards and hold-out unseen metrics consistently show that GARDO mitigates reward hacking and enhances generation diversity without sacrificing sample efficiency or exploration, highlighting its effectiveness and robustness.

</details>


### [199] [Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction](https://arxiv.org/abs/2512.24139)
*Qianyi Chen,Bo Li*

Main category: cs.LG

TL;DR: 本文提出了一种改进共形预测条件覆盖性能的新方法，通过优化分位数回归组件来最小化条件覆盖的均方误差，使用密度加权的pinball损失函数和三头分位数网络进行实现。


<details>
  <summary>Details</summary>
Motivation: 共形预测虽然能提供稳健的边际覆盖保证，但在特定输入上实现可靠的条件覆盖仍然具有挑战性。尽管在有限样本下无法实现精确的无分布条件覆盖，但现有方法主要关注放松的条件覆盖概念，本文旨在直接最小化条件覆盖的均方误差。

Method: 通过泰勒展开推导出分位数回归的替代目标函数：密度加权的pinball损失函数，权重由一致性分数在真实分位数处的条件密度给出。提出三头分位数网络，使用辅助分位数水平(1-α±δ)通过有限差分估计这些权重，然后通过优化加权损失来微调中心分位数。

Result: 提供了具有精确非渐近保证的理论分析，描述了由此产生的超额风险。在多种高维真实数据集上的广泛实验显示，条件覆盖性能有显著改善。

Conclusion: 该方法通过直接优化条件覆盖的均方误差，显著提升了共形预测的条件覆盖性能，为改进分位数回归组件提供了一种有效的新途径。

Abstract: While conformal prediction provides robust marginal coverage guarantees, achieving reliable conditional coverage for specific inputs remains challenging. Although exact distribution-free conditional coverage is impossible with finite samples, recent work has focused on improving the conditional coverage of standard conformal procedures. Distinct from approaches that target relaxed notions of conditional coverage, we directly minimize the mean squared error of conditional coverage by refining the quantile regression components that underpin many conformal methods. Leveraging a Taylor expansion, we derive a sharp surrogate objective for quantile regression: a density-weighted pinball loss, where the weights are given by the conditional density of the conformity score evaluated at the true quantile. We propose a three-headed quantile network that estimates these weights via finite differences using auxiliary quantile levels at \(1-α\pm δ\), subsequently fine-tuning the central quantile by optimizing the weighted loss. We provide a theoretical analysis with exact non-asymptotic guarantees characterizing the resulting excess risk. Extensive experiments on diverse high-dimensional real-world datasets demonstrate remarkable improvements in conditional coverage performance.

</details>


### [200] [Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma](https://arxiv.org/abs/2512.24205)
*Wei Chen,Giacomo Dimarco,Lorenzo Pareschi*

Main category: cs.LG

TL;DR: 提出基于方差缩减蒙特卡洛的Vlasov-Poisson-Landau系统不确定性量化框架，使用神经网络代理模型替代昂贵的Landau碰撞项计算，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 等离子体动力学方程对微观扰动高度敏感，传统不确定性量化方法面临计算成本高、相空间维度高、多尺度刚性等挑战，特别是在包含碰撞项时，高维非局部碰撞积分和守恒性质带来严重约束

Method: 结合高保真渐近保持VPL求解器与廉价的强相关代理模型（VPFP和EP方程），引入基于各向异性微宏观分解的张量神经网络（SPINN的推广），并校准VPFP模型和设计渐近保持SPINN

Result: 相比标准蒙特卡洛方法实现显著方差缩减，用更少的高保真样本获得准确统计量，降低计算时间，同时保持对随机维度的鲁棒性

Conclusion: 该方法为等离子体动力学中的不确定性量化提供高效可靠的计算框架，通过神经网络代理模型和方差缩减技术克服传统方法的计算瓶颈

Abstract: Plasma kinetic equations exhibit pronounced sensitivity to microscopic perturbations in model parameters and data, making reliable and efficient uncertainty quantification (UQ) essential for predictive simulations. However, the cost of uncertainty sampling, the high-dimensional phase space, and multiscale stiffness pose severe challenges to both computational efficiency and error control in traditional numerical methods. These aspects are further emphasized in presence of collisions where the high-dimensional nonlocal collision integrations and conservation properties pose severe constraints. To overcome this, we present a variance-reduced Monte Carlo framework for UQ in the Vlasov--Poisson--Landau (VPL) system, in which neural network surrogates replace the multiple costly evaluations of the Landau collision term. The method couples a high-fidelity, asymptotic-preserving VPL solver with inexpensive, strongly correlated surrogates based on the Vlasov--Poisson--Fokker--Planck (VPFP) and Euler--Poisson (EP) equations. For the surrogate models, we introduce a generalization of the separable physics-informed neural network (SPINN), developing a class of tensor neural networks based on an anisotropic micro-macro decomposition, to reduce velocity-moment costs, model complexity, and the curse of dimensionality. To further increase correlation with VPL, we calibrate the VPFP model and design an asymptotic-preserving SPINN whose small- and large-Knudsen limits recover the EP and VP systems, respectively. Numerical experiments show substantial variance reduction over standard Monte Carlo, accurate statistics with far fewer high-fidelity samples, and lower wall-clock time, while maintaining robustness to stochastic dimension.

</details>


### [201] [Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm](https://arxiv.org/abs/2512.24253)
*Alireza Rafiei,Farshid Hajati,Alireza Rezaee,Amirhossien Panahi,Shahadat Uddin*

Main category: cs.LG

TL;DR: 开发了四种基于心率数据的机器学习算法，通过遗传算法优化，用于可穿戴设备上的脓毒症早期预测，预测窗口为1-4小时。


<details>
  <summary>Details</summary>
Motivation: 脓毒症导致高死亡率、发病率和医疗成本，及时预测对早期干预至关重要。现有模型主要针对ICU患者，缺乏非病房环境（如可穿戴设备）的早期检测方法。

Method: 开发了四种新颖的机器学习算法，通过遗传算法优化模型架构，平衡性能、计算复杂度和内存需求。使用心率数据进行脓毒症预测，初始预测窗口为1小时，后通过迁移学习扩展到4小时。

Result: 模型性能指标显示在可穿戴设备上实施脓毒症预测的可行性，研究结果表明可穿戴技术有望在ICU和病房外环境实现早期脓毒症检测。

Conclusion: 该研究展示了可穿戴设备通过心率监测实现脓毒症早期预测的潜力，为ICU和病房外的脓毒症检测提供了新途径。

Abstract: Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.

</details>


### [202] [Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction](https://arxiv.org/abs/2512.24324)
*Haojin Li,Anbang Zhang,Chen Sun,Chenyuan Feng,Kaiqian Qu,Tony Q. S. Quek,Haijun Zhang*

Main category: cs.LG

TL;DR: 提出SaM2B框架，通过可靠性感知动态权重分配和跨模态对比学习，解决无人机通信中多模态波束预测的模态可靠性波动和模态失配问题。


<details>
  <summary>Details</summary>
Motivation: 低空经济快速发展，无人机通信需要快速准确的波束预测。现有多模态方法采用固定权重，假设各模态始终同等可靠，但实际上模态重要性随无人机运动场景剧烈变化，静态权重会放大退化模态的负面影响，且模态失配和弱对齐进一步削弱跨场景泛化能力。

Method: 提出SaM2B框架：1）利用环境视觉、飞行姿态和地理空间数据等轻量级线索，通过可靠性感知动态权重更新机制，在不同时间点自适应分配各模态贡献；2）采用跨模态对比学习，将与特定波束信息相关的"多源表示波束语义"对齐到共享语义空间，增强判别能力和模态噪声及分布偏移下的鲁棒性。

Result: 在真实世界低空无人机数据集上的实验表明，SaM2B相比基线方法取得了更满意的结果。

Conclusion: SaM2B通过动态权重分配和语义对齐，有效解决了多模态波束预测中的模态可靠性波动问题，提升了无人机通信的波束预测性能。

Abstract: The low-altitude economy (LAE) is rapidly expanding driven by urban air mobility, logistics drones, and aerial sensing, while fast and accurate beam prediction in uncrewed aerial vehicles (UAVs) communications is crucial for achieving reliable connectivity. Current research is shifting from single-signal to multi-modal collaborative approaches. However, existing multi-modal methods mostly employ fixed or empirical weights, assuming equal reliability across modalities at any given moment. Indeed, the importance of different modalities fluctuates dramatically with UAV motion scenarios, and static weighting amplifies the negative impact of degraded modalities. Furthermore, modal mismatch and weak alignment further undermine cross-scenario generalization. To this end, we propose a reliability-aware dynamic weighting scheme applied to a semantic-aware multi-modal beam prediction framework, named SaM2B. Specifically, SaM2B leverages lightweight cues such as environmental visual, flight posture, and geospatial data to adaptively allocate contributions across modalities at different time points through reliability-aware dynamic weight updates. Moreover, by utilizing cross-modal contrastive learning, we align the "multi-source representation beam semantics" associated with specific beam information to a shared semantic space, thereby enhancing discriminative power and robustness under modal noise and distribution shifts. Experiments on real-world low-altitude UAV datasets show that SaM2B achieves more satisfactory results than baseline methods.

</details>


### [203] [Tubular Riemannian Laplace Approximations for Bayesian Neural Networks](https://arxiv.org/abs/2512.24381)
*Rodrigo Pereira David*

Main category: cs.LG

TL;DR: TRL是一种新的贝叶斯近似方法，通过建模概率管状结构来适应神经网络的对称性和损失曲面曲率，在保持单模型效率的同时达到集成模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的拉普拉斯近似在欧几里得空间中难以处理现代深度模型的高度各向异性、弯曲的损失曲面和大对称群，需要更适应这种结构的几何方法。

Method: 提出管状黎曼拉普拉斯（TRL）近似，将后验建模为跟随功能对称性诱导的低损失谷的概率管，使用Fisher/高斯-牛顿度量分离先验主导的切向不确定性和数据主导的横向不确定性。

Result: 在ResNet-18（CIFAR-10和CIFAR-100）上的实验表明，TRL实现了优秀的校准性能，在ECE指标上匹配或超过深度集成方法的可靠性，同时只需要1/5的训练成本。

Conclusion: TRL有效地弥合了单模型效率和集成级可靠性之间的差距，是一种可扩展的重新参数化高斯近似方法，利用隐式曲率估计在高维参数空间中运行。

Abstract: Laplace approximations are among the simplest and most practical methods for approximate Bayesian inference in neural networks, yet their Euclidean formulation struggles with the highly anisotropic, curved loss surfaces and large symmetry groups that characterize modern deep models. Recent work has proposed Riemannian and geometric Gaussian approximations to adapt to this structure. Building on these ideas, we introduce the Tubular Riemannian Laplace (TRL) approximation. TRL explicitly models the posterior as a probabilistic tube that follows a low-loss valley induced by functional symmetries, using a Fisher/Gauss-Newton metric to separate prior-dominated tangential uncertainty from data-dominated transverse uncertainty. We interpret TRL as a scalable reparametrised Gaussian approximation that utilizes implicit curvature estimates to operate in high-dimensional parameter spaces. Our empirical evaluation on ResNet-18 (CIFAR-10 and CIFAR-100) demonstrates that TRL achieves excellent calibration, matching or exceeding the reliability of Deep Ensembles (in terms of ECE) while requiring only a fraction (1/5) of the training cost. TRL effectively bridges the gap between single-model efficiency and ensemble-grade reliability.

</details>


### [204] [Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning](https://arxiv.org/abs/2512.24404)
*Soham Pahari,M. Srinivas*

Main category: cs.LG

TL;DR: ViReLoc框架通过视觉推理进行地理一致的视觉规划，仅使用视觉表示进行导航和定位，无需实时GPS数据


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理系统主要依赖文本信息进行推理，限制了在视觉导航和地理定位等空间任务中的效果，需要探索视觉推理的潜力

Method: 提出Geo-Consistent Visual Planning范式，开发ViReLoc框架，学习空间依赖和几何关系，通过视觉域逐步推理和强化学习目标优化，结合对比学习和自适应特征交互对齐跨视角

Result: 在多样化导航和定位场景中实验显示，空间推理准确性和跨视角检索性能持续提升，视觉推理成为导航定位的强有力补充方法

Conclusion: 视觉推理可作为导航和定位的有效补充方法，无需实时GPS数据即可完成任务，提供更安全的导航解决方案

Abstract: Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.

</details>


### [205] [Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models](https://arxiv.org/abs/2512.24407)
*Lars van der Laan,Aurelien Bibaut,Nathan Kallus*

Main category: cs.LG

TL;DR: 提出了一种半参数去偏逆强化学习框架，用于在最大熵IRL和Gumbel-shock DDC模型中实现统计有效的推断，支持灵活的非参数估计同时保持√n一致性和渐近正态性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：灵活的IRL方法依赖机器学习但缺乏有效推断保证，而经典DDC方法参数限制严格且需要重复动态规划。需要一种既能利用现代机器学习工具又能提供统计推断保证的统一框架。

Method: 开发半参数去偏逆强化学习框架，将log行为策略作为伪奖励来识别策略价值差异和奖励函数。形式化目标为行为策略和转移核的光滑泛函，推导有效影响函数，构建自动去偏机器学习估计器。

Result: 建立了√n一致性、渐近正态性和半参数效率的理论保证，将经典DDC模型的推断扩展到非参数奖励和现代机器学习工具，提供统一且计算可行的统计推断方法。

Conclusion: 该框架为IRL和DDC模型提供了统计有效的推断工具，弥合了灵活机器学习方法与严格统计推断之间的差距，支持对已知和反事实softmax策略下的策略价值以及归一化奖励函数进行可靠推断。

Abstract: Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical DDC approaches impose restrictive parametric specifications and often require repeated dynamic programming. We develop a semiparametric framework for debiased inverse reinforcement learning that yields statistically efficient inference for a broad class of reward-dependent functionals in maximum entropy IRL and Gumbel-shock DDC models. We show that the log-behavior policy acts as a pseudo-reward that point-identifies policy value differences and, under a simple normalization, the reward itself. We then formalize these targets, including policy values under known and counterfactual softmax policies and functionals of the normalized reward, as smooth functionals of the behavior policy and transition kernel, establish pathwise differentiability, and derive their efficient influence functions. Building on this characterization, we construct automatic debiased machine-learning estimators that allow flexible nonparametric estimation of nuisance components while achieving $\sqrt{n}$-consistency, asymptotic normality, and semiparametric efficiency. Our framework extends classical inference for DDC models to nonparametric rewards and modern machine-learning tools, providing a unified and computationally tractable approach to statistical inference in IRL.

</details>


### [206] [Generative forecasting with joint probability models](https://arxiv.org/abs/2512.24446)
*Patrick Wyrod,Ashesh Chattopadhyay,Daniele Venturi*

Main category: cs.LG

TL;DR: 将混沌系统预测重构为完全生成问题，通过学习滞后系统状态的联合概率分布进行预测，相比传统条件预测方法在短期预测技能、吸引子几何保持和长期统计行为方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统对初始条件高度敏感且包含未解决的多尺度过程，使得确定性预测存在根本限制。现有生成模型大多关注下一步条件预测，而非底层动态结构。

Method: 将预测重构为完全生成问题，学习短时间窗口内滞后系统状态的联合概率分布，通过边缘化获得预测。提出模型无关的训练和推理框架，引入三种不确定性量化指标（集合方差、短时程自相关、累积Wasserstein漂移）。

Result: 在Lorenz-63系统和Kuramoto-Sivashinsky方程上评估，联合生成模型相比传统条件下一步模型：1）短期预测技能提升；2）保持吸引子几何结构；3）长期统计行为更准确。

Conclusion: 将预测重构为联合生成问题能更好地捕捉非线性时间依赖、表示多步轨迹段，产生与学习分布一致的下步预测，同时提供无需真实数据的预测稳健性和可靠性评估。

Abstract: Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.

</details>


### [207] [HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors](https://arxiv.org/abs/2512.24478)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: HOLOGRAPH是一个基于层理论的LLM引导因果发现框架，将局部因果信念表示为变量子集上的预层截面，通过代数潜在投影处理隐藏混杂因子，在50-100变量任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 观测数据的因果发现受限于可识别性约束，现有LLM作为先验因果知识的方法缺乏理论基础，需要建立数学严谨的框架。

Method: 使用层理论形式化LLM引导的因果发现：将局部因果信念表示为变量子集预层的截面；代数潜在投影处理隐藏混杂因子；信念流形上的自然梯度下降进行优化。

Result: 在合成和真实基准测试中，HOLOGRAPH在50-100变量的因果发现任务上达到竞争性性能；层理论分析显示恒等、传递和粘合公理满足数值精度，但局部性公理在大图上失效。

Conclusion: HOLOGRAPH为LLM引导的因果发现提供了严格的数学基础，揭示了潜在变量投影中的非局部耦合现象，为因果发现理论提供了新视角。

Abstract: Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory--representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (<10^{-6}), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [https://github.com/hyunjun1121/holograph](https://github.com/hyunjun1121/holograph).

</details>


### [208] [Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice](https://arxiv.org/abs/2512.24503)
*Jiachen T. Wang,Tong Wu,Kaifeng Lyu,James Zou,Dawn Song,Ruoxi Jia,Prateek Mittal*

Main category: cs.LG

TL;DR: 研究发现小规模代理模型实验中固定训练配置的评估方法存在缺陷，提出使用降低学习率的方法来更可靠地预测大规模模型的数据配方效果。


<details>
  <summary>Details</summary>
Motivation: 前沿AI公司通常用小规模代理模型评估数据配方，但缺乏对小规模实验结论能否可靠迁移到大规模训练的理解。标准实验协议中使用固定训练配置进行"公平"比较存在问题，因为最优训练配置本质上是数据依赖的。

Method: 提出对评估协议进行简单修正：在代理模型训练中使用降低的学习率。理论上证明对于随机特征模型，这种方法能保持数据集按最优可达损失的排序。实证上在23个数据配方上验证该方法。

Result: 降低学习率的方法能产生与完全调优的大规模LLM预训练运行强烈相关的相对性能表现。该方法显著提高了小规模实验的可靠性，实验结论不再因训练超参数的微小调整而翻转。

Conclusion: 数据配方评估的目标应是识别在数据特定调优下表现最佳的配方。降低学习率的简单修正能有效缓解超参数调优的高成本，使小规模实验更可靠地预测大规模训练效果。

Abstract: Data teams at frontier AI companies routinely train small proxy models to make critical decisions about pretraining data recipes for full-scale training runs. However, the community has a limited understanding of whether and when conclusions drawn from small-scale experiments reliably transfer to full-scale model training. In this work, we uncover a subtle yet critical issue in the standard experimental protocol for data recipe assessment: the use of identical small-scale model training configurations across all data recipes in the name of "fair" comparison. We show that the experiment conclusions about data quality can flip with even minor adjustments to training hyperparameters, as the optimal training configuration is inherently data-dependent. Moreover, this fixed-configuration protocol diverges from full-scale model development pipelines, where hyperparameter optimization is a standard step. Consequently, we posit that the objective of data recipe assessment should be to identify the recipe that yields the best performance under data-specific tuning. To mitigate the high cost of hyperparameter tuning, we introduce a simple patch to the evaluation protocol: using reduced learning rates for proxy model training. We show that this approach yields relative performance that strongly correlates with that of fully tuned large-scale LLM pretraining runs. Theoretically, we prove that for random-feature models, this approach preserves the ordering of datasets according to their optimal achievable loss. Empirically, we validate this approach across 23 data recipes covering four critical dimensions of data curation, demonstrating dramatic improvements in the reliability of small-scale experiments.

</details>


### [209] [Generalising E-prop to Deep Networks](https://arxiv.org/abs/2512.24506)
*Beren Millidge*

Main category: cs.LG

TL;DR: 将E-prop框架扩展到深度网络，提出一种在线学习算法，可同时处理时间和深度上的信用分配，无需通过时间反向传播


<details>
  <summary>Details</summary>
Motivation: 传统BPTT需要存储所有状态历史并按时间反向回放，这在生物学上不现实。RTRL虽然数学等价但计算复杂度高。E-prop降低了复杂度但仅限于单层循环网络。大脑学习涉及多层结构和时间维度，需要扩展到深度网络

Method: 扩展E-prop框架处理任意深度网络，推导出跨深度的新颖递归关系，将E-prop的资格迹扩展到更深层

Result: 开发出可同时处理时间和深度信用分配的在线学习算法，能够训练深度循环网络而无需通过时间反向传播

Conclusion: 提出的算法展示了在线学习可以在时间和深度上同时进行准确的信用分配，为训练深度循环网络提供了无需BPTT的替代方案

Abstract: Recurrent networks are typically trained with backpropagation through time (BPTT). However, BPTT requires storing the history of all states in the network and then replaying them sequentially backwards in time. This computation appears extremely implausible for the brain to implement. Real Time Recurrent Learning (RTRL) proposes an mathematically equivalent alternative where gradient information is propagated forwards in time locally alongside the regular forward pass, however it has significantly greater computational complexity than BPTT which renders it impractical for large networks. E-prop proposes an approximation of RTRL which reduces its complexity to the level of BPTT while maintaining a purely online forward update which can be implemented by an eligibility trace at each synapse. However, works on RTRL and E-prop ubiquitously investigate learning in a single layer with recurrent dynamics. However, learning in the brain spans multiple layers and consists of both hierarchal dynamics in depth as well as time. In this mathematical note, we extend the E-prop framework to handle arbitrarily deep networks, deriving a novel recursion relationship across depth which extends the eligibility traces of E-prop to deeper layers. Our results thus demonstrate an online learning algorithm can perform accurate credit assignment across both time and depth simultaneously, allowing the training of deep recurrent networks without backpropagation through time.

</details>


### [210] [From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme](https://arxiv.org/abs/2512.24555)
*Xueyan Li,Yingyi Xue,Mengjie Jiang,Qingzi Zhu,Yazhe Niu*

Main category: cs.LG

TL;DR: HUMOR框架通过分层推理和多路径思维链增强视觉语言模型的多模态幽默生成能力，结合基于模板分组的偏好对齐优化，显著提升表情包质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 生成幽默表情包是一个复杂的多模态任务，需要超越直接的图像-标题监督，进行视觉内容、上下文线索和主观幽默的微妙推理。现有方法在视觉感知与幽默笑点创造之间存在差距。

Method: 提出HUMOR框架：1) 分层多路径思维链：从模板级意图识别开始，在不同上下文下探索多样推理路径，最终锚定高质量上下文特定路径；2) 基于模板分组的成对奖励模型训练，确保人类偏好一致性；3) 分组强化学习优化，在信任区域内保证单调改进。

Result: 大量实验表明，HUMOR赋能各种视觉语言模型，在推理多样性、偏好对齐可靠性和整体表情包质量方面表现优异。该框架为开放式、人类对齐的多模态生成提供了通用训练范式。

Conclusion: HUMOR通过分层推理和分组偏好对齐，有效解决了幽默表情包生成中的多模态推理挑战，为需要主观判断和创造性输出的多模态生成任务提供了通用解决方案。

Abstract: Generating humorous memes is a challenging multimodal task that moves beyond direct image-to-caption supervision. It requires a nuanced reasoning over visual content, contextual cues, and subjective humor. To bridge this gap between visual perception and humorous punchline creation, we propose HUMOR}, a novel framework that guides VLMs through hierarchical reasoning and aligns them with group-wise human preferences. First, HUMOR employs a hierarchical, multi-path Chain-of-Thought (CoT): the model begins by identifying a template-level intent, then explores diverse reasoning paths under different contexts, and finally anchors onto a high-quality, context-specific path. This CoT supervision, which traces back from ground-truth captions, enhances reasoning diversity. We further analyze that this multi-path exploration with anchoring maintains a high expected humor quality, under the practical condition that high-quality paths retain significant probability mass. Second, to capture subjective humor, we train a pairwise reward model that operates within groups of memes sharing the same template. Following established theory, this approach ensures a consistent and robust proxy for human preference, even with subjective and noisy labels. The reward model then enables a group-wise reinforcement learning optimization, guaranteeing providing a theoretical guarantee for monotonic improvement within the trust region. Extensive experiments show that HUMOR empowers various VLMs with superior reasoning diversity, more reliable preference alignment, and higher overall meme quality. Beyond memes, our work presents a general training paradigm for open-ended, human-aligned multimodal generation, where success is guided by comparative judgment within coherent output group.

</details>


### [211] [CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts](https://arxiv.org/abs/2512.24564)
*Shunbo Jia,Caizhi Liao*

Main category: cs.LG

TL;DR: 提出因果生理表征学习(CPR)方法，通过结构因果模型分离心电图中不变病理特征与伪影，在保持单次推理效率的同时提升对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有心电图深度学习模型对平滑对抗扰动(SAP)脆弱，而对抗训练计算成本高，随机平滑等方法推理延迟大，不适用于实时临床监测。模型依赖非鲁棒的伪相关而非不变病理特征是脆弱性根源。

Method: 提出因果生理表征学习(CPR)，在因果解缠框架中融入生理结构先验。通过结构因果模型建模心电图生成，执行结构干预严格分离不变病理形态(P-QRS-T复合波)与非因果伪影。

Result: 在PTB-XL数据集上，CPR显著优于标准临床预处理方法。在SAP攻击下，CPR获得0.632 F1分数，比中值平滑(0.541 F1)提升9.1%。CPR匹配随机平滑的认证鲁棒性，同时保持单次推理效率。

Conclusion: CPR在鲁棒性、效率和临床可解释性之间提供了优越的权衡，通过因果解缠学习不变生理表征，解决了心电图模型对抗脆弱性问题，适用于实时临床监测。

Abstract: Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.

</details>


### [212] [Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space](https://arxiv.org/abs/2512.24617)
*Xingwei Qu,Shaowen Wang,Zihao Huang,Kai Hua,Fan Yin,Rui-Jie Zhu,Jundong Zhou,Qiyang Min,Zihao Wang,Yizhi Li,Tianyu Zhang,He Xing,Zheng Zhang,Yuxuan Song,Tianyu Zheng,Zhiyuan Zeng,Chenghua Lin,Ge Zhang,Wenhao Huang*

Main category: cs.LG

TL;DR: DLCM提出了一种分层语言建模框架，通过将计算从token转移到压缩的概念空间来提高推理效率，实现了在相同计算量下性能提升2.69%


<details>
  <summary>Details</summary>
Motivation: 现有LLM对所有token采用统一计算，但语言信息密度高度不均匀，导致在可预测部分浪费计算资源，而在语义关键转换处计算不足

Method: 提出动态大概念模型(DLCM)：1)从潜在表示学习语义边界，将计算从token转移到压缩概念空间；2)引入压缩感知的缩放定律，解耦token级容量、概念级推理能力和压缩比；3)开发解耦μP参数化方法，支持跨宽度和压缩机制的零样本超参数迁移

Result: 在R=4（平均4个token对应一个概念）的设定下，DLCM将约1/3的推理计算重新分配到更高容量的推理骨干网络中，在匹配推理FLOPs下，12个零样本基准测试平均提升2.69%

Conclusion: DLCM通过分层压缩和动态计算分配，改变了语言模型的缩放行为，实现了更高效的计算利用，为语言建模提供了新的架构方向

Abstract: Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\textbf{decoupled $μ$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\textbf{+2.69$\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.

</details>


### [213] [AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt](https://arxiv.org/abs/2512.24625)
*Zijian Zhao,Yitong Shang,Sen Li*

Main category: cs.LG

TL;DR: AutoFed：一种用于交通预测的新型个性化联邦学习框架，无需手动超参数调优，通过联邦表示器和客户端对齐适配器实现跨客户端知识共享


<details>
  <summary>Details</summary>
Motivation: 交通预测对智能交通系统至关重要，但存在隐私问题导致数据孤岛。现有联邦学习方法面临非独立同分布问题，而个性化联邦学习需要适应交通预测任务的专业特征工程和网络设计。许多先前研究依赖数据集特定的超参数优化，这在现实场景中不可行

Method: 提出AutoFed框架，受提示学习启发，引入联邦表示器，使用客户端对齐适配器将本地数据蒸馏为紧凑的全局共享提示矩阵。该提示条件化个性化预测器，使每个客户端能从跨客户端知识中受益同时保持本地特异性

Result: 在真实世界数据集上的广泛实验表明，AutoFed在不同场景下始终实现优越性能

Conclusion: AutoFed为交通预测提供了一种无需手动超参数调优的实用个性化联邦学习解决方案，解决了现实部署中的关键挑战

Abstract: Accurate traffic prediction is essential for Intelligent Transportation Systems, including ride-hailing, urban road planning, and vehicle fleet management. However, due to significant privacy concerns surrounding traffic data, most existing methods rely on local training, resulting in data silos and limited knowledge sharing. Federated Learning (FL) offers an efficient solution through privacy-preserving collaborative training; however, standard FL struggles with the non-independent and identically distributed (non-IID) problem among clients. This challenge has led to the emergence of Personalized Federated Learning (PFL) as a promising paradigm. Nevertheless, current PFL frameworks require further adaptation for traffic prediction tasks, such as specialized graph feature engineering, data processing, and network architecture design. A notable limitation of many prior studies is their reliance on hyper-parameter optimization across datasets-information that is often unavailable in real-world scenarios-thus impeding practical deployment. To address this challenge, we propose AutoFed, a novel PFL framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. Inspired by prompt learning, AutoFed introduces a federated representor that employs a client-aligned adapter to distill local data into a compact, globally shared prompt matrix. This prompt then conditions a personalized predictor, allowing each client to benefit from cross-client knowledge while maintaining local specificity. Extensive experiments on real-world datasets demonstrate that AutoFed consistently achieves superior performance across diverse scenarios. The code of this paper is provided at https://github.com/RS2002/AutoFed .

</details>


### [214] [A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling](https://arxiv.org/abs/2512.24643)
*Malikussaid,Septian Caesar Floresko,Ade Romadhony,Isman Kurniawan,Warih Maharani,Hilal Hudan Nuha*

Main category: cs.LG

TL;DR: 大规模logP预测框架：整合42.7万化合物数据，通过字节偏移索引将处理时间从100天降至3.2小时，发现分子量是logP最重要预测因子，树集成模型优于线性模型，分层建模策略达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决logP预测中数据整合的挑战，建立大规模预测框架，探索脂溶性预测的关键因素，比较不同建模方法的性能，为分子设计提供指导。

Method: 整合PubChem、ChEMBL、eMolecules三个数据库的42.7万化合物数据；开发字节偏移索引架构大幅提升处理效率；使用SHAP分析识别关键预测因子；系统评估线性模型和树集成模型（随机森林、XGBoost）；采用分层建模策略（药物样分子91%和极端情况9%）。

Result: 处理时间从预计100天降至3.2小时（740倍提升）；分子量被识别为logP最重要预测因子；树集成模型（R²=0.765，RMSE=0.731）优于线性模型；分层建模策略达到最佳性能（药物样分子RMSE=0.838，极端分子R²=0.767）。

Conclusion: 精心策划的基于描述符的集成模型在logP预测上仍能与最先进的图神经网络竞争；分子量是脂溶性预测的关键因素；分层建模策略可优化预测性能；为分子设计提供了实用指导。

Abstract: This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the data integration challenge, reducing processing time from a projected over 100 days to 3.2 hours through byte-offset indexing architecture, a 740-fold improvement. Our comprehensive analysis revealed critical insights into the multivariate nature of lipophilicity: while molecular weight exhibited weak bivariate correlation with logP, SHAP analysis on ensemble models identified it as the single most important predictor globally. We systematically evaluated multiple modeling approaches, discovering that linear models suffered from inherent heteroskedasticity that classical remediation strategies, including weighted least squares and Box-Cox transformation, failed to address. Tree-based ensemble methods, including Random Forest and XGBoost, proved inherently robust to this violation, achieving an R-squared of 0.765 and RMSE of 0.731 logP units on the test set. Furthermore, a stratified modeling strategy, employing specialized models for drug-like molecules (91 percent of dataset) and extreme cases (nine percent), achieved optimal performance: an RMSE of 0.838 for the drug-like subset and an R-squared of 0.767 for extreme molecules, the highest of all evaluated approaches. These findings provide actionable guidance for molecular design, establish robust baselines for lipophilicity prediction using only 2D descriptors, and demonstrate that well-curated, descriptor-based ensemble models remain competitive with state-of-the-art graph neural network architectures.

</details>


### [215] [HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs](https://arxiv.org/abs/2512.24665)
*Honglin Gao,Lan Zhao,Junhao Ren,Xiang Li,Gaoxi Xiao*

Main category: cs.LG

TL;DR: 提出HeteroHBA框架，针对异构图神经网络进行隐蔽的后门攻击，通过生成多样化的触发节点和连接模式，在保持清洁性能的同时实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 异构图神经网络在现实应用中表现出色，但针对异构图的定向后门攻击研究较少。需要探索如何在保持清洁性能的同时，在异构图节点分类任务中实现隐蔽的后门攻击。

Method: 提出HeteroHBA生成式后门框架：1) 通过显著性筛选选择有影响力的辅助邻居进行触发节点附着；2) 合成多样化的触发特征和连接模式以匹配局部异质上下文；3) 结合AdaIN和MMD损失对齐触发特征分布与良性统计，提高隐蔽性；4) 使用双层目标联合优化攻击成功率和清洁准确率。

Result: 在多个真实世界异构图和代表性HGNN架构上的实验表明，HeteroHBA相比现有后门基线方法，在保持可比或更小清洁准确率影响的同时，实现了更高的攻击成功率。攻击在异构感知的结构防御CSD下仍然有效。

Conclusion: 研究揭示了异构图学习中的实际后门风险，强调了开发更强防御机制的必要性。HeteroHBA框架展示了在异构图环境中实现隐蔽高效后门攻击的可能性。

Abstract: Heterogeneous graph neural networks (HGNNs) have achieved strong performance in many real-world applications, yet targeted backdoor poisoning on heterogeneous graphs remains less studied. We consider backdoor attacks for heterogeneous node classification, where an adversary injects a small set of trigger nodes and connections during training to force specific victim nodes to be misclassified into an attacker-chosen label at test time while preserving clean performance. We propose HeteroHBA, a generative backdoor framework that selects influential auxiliary neighbors for trigger attachment via saliency-based screening and synthesizes diverse trigger features and connection patterns to better match the local heterogeneous context. To improve stealthiness, we combine Adaptive Instance Normalization (AdaIN) with a Maximum Mean Discrepancy (MMD) loss to align the trigger feature distribution with benign statistics, thereby reducing detectability, and we optimize the attack with a bilevel objective that jointly promotes attack success and maintains clean accuracy. Experiments on multiple real-world heterogeneous graphs with representative HGNN architectures show that HeteroHBA consistently achieves higher attack success than prior backdoor baselines with comparable or smaller impact on clean accuracy; moreover, the attack remains effective under our heterogeneity-aware structural defense, CSD. These results highlight practical backdoor risks in heterogeneous graph learning and motivate the development of stronger defenses.

</details>


### [216] [Mobility-Assisted Decentralized Federated Learning: Convergence Analysis and A Data-Driven Approach](https://arxiv.org/abs/2512.24694)
*Reza Jahani,Md Farhamdur Reza,Richeng Jin,Huaiyu Dai*

Main category: cs.LG

TL;DR: 该论文研究了用户移动性对去中心化联邦学习性能的影响，提出利用移动用户增强稀疏网络中的信息传播，并通过理论分析和实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习在稀疏网络和数据异构情况下性能下降，而下一代无线网络中移动性日益普遍，但移动性对DFL的影响尚未得到充分研究，尽管移动用户可作为中继增强信息流动。

Method: 首先建立移动性下稀疏网络DFL的收敛理论，证明随机移动即可提升性能；然后提出利用移动用户的诱导移动模式框架，使其根据数据分布知识确定轨迹以优化网络信息传播。

Result: 理论分析表明即使部分用户随机移动也能显著提升性能；实验验证了理论发现，证明所提方法优于基线，并全面分析了各种网络参数对移动网络中DFL性能的影响。

Conclusion: 移动性可有效提升稀疏网络中DFL的性能，提出的诱导移动模式框架能利用数据分布知识优化信息传播，为移动网络中的联邦学习提供了新思路。

Abstract: Decentralized Federated Learning (DFL) has emerged as a privacy-preserving machine learning paradigm that enables collaborative training among users without relying on a central server. However, its performance often degrades significantly due to limited connectivity and data heterogeneity. As we move toward the next generation of wireless networks, mobility is increasingly embedded in many real-world applications. The user mobility, either natural or induced, enables clients to act as relays or bridges, thus enhancing information flow in sparse networks; however, its impact on DFL has been largely overlooked despite its potential. In this work, we systematically investigate the role of mobility in improving DFL performance. We first establish the convergence of DFL in sparse networks under user mobility and theoretically demonstrate that even random movement of a fraction of users can significantly boost performance. Building upon this insight, we propose a DFL framework that utilizes mobile users with induced mobility patterns, allowing them to exploit the knowledge of data distribution to determine their trajectories to enhance information propagation through the network. Through extensive experiments, we empirically confirm our theoretical findings, validate the superiority of our approach over baselines, and provide a comprehensive analysis of how various network parameters influence DFL performance in mobile networks.

</details>


### [217] [Nested Learning: The Illusion of Deep Learning Architectures](https://arxiv.org/abs/2512.24695)
*Ali Behrouz,Meisam Razaviyayn,Peilin Zhong,Vahab Mirrokni*

Main category: cs.LG

TL;DR: 提出嵌套学习（NL）新范式，将机器学习模型表示为多级嵌套优化问题，通过上下文流压缩实现学习，能自然产生上下文学习能力，并设计出更强大的优化器、自修改学习模块和连续记忆系统。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型取得进展，但现有模型在持续学习、自我改进和寻找有效解决方案方面仍存在根本性挑战。需要新的学习范式来解决这些未解问题。

Method: 提出嵌套学习（NL）范式，将模型表示为多级嵌套优化问题。开发了三种核心技术：1）表达性优化器（如Adam、SGD等被重新解释为梯度信息压缩的关联记忆模块）；2）自修改学习模块（学习如何修改自身更新算法）；3）连续记忆系统（超越传统长/短期记忆的新记忆系统）。

Result: 结合自修改序列模型和连续记忆系统，开发了名为Hope的持续学习模块，在语言建模、知识整合、少样本泛化、持续学习和长上下文推理任务中显示出有前景的结果。

Conclusion: 嵌套学习为设计更强大的学习算法提供了新哲学框架，通过增加层级实现高阶上下文学习，有望解锁有效的持续学习能力，为机器学习模型的发展开辟了新方向。

Abstract: Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.

</details>


### [218] [Causal Discovery with Mixed Latent Confounding via Precision Decomposition](https://arxiv.org/abs/2512.24696)
*Amir Asiaee,Samhita Pal,James O'quinn,James P. Long*

Main category: cs.LG

TL;DR: 提出DCL-DECOR方法，用于处理混合潜在混杂的线性高斯系统中的因果发现，通过精度矩阵分解分离全局和局部混杂效应，提高有向边恢复准确性。


<details>
  <summary>Details</summary>
Motivation: 现实数据中常存在混合潜在混杂：一些未观测因子广泛影响多个变量，而另一些仅影响小部分变量。现有方法面临挑战：可微和基于分数的DAG学习方法可能将全局潜在效应误解为因果边，而潜在变量图模型只能恢复无向结构。

Method: 提出DCL-DECOR模块化流程：1) 通过精度矩阵分解将观测精度矩阵分解为结构化分量和低秩分量，分离普遍混杂效应；2) 对去混杂后的表示应用相关噪声DAG学习器恢复有向边，同时建模剩余的结构化误差相关性；3) 简单协调步骤确保无弓形结构。

Result: 提供了混合混杂下可恢复因果目标的识别性结果，表明整体问题可简化为具有模块化保证的已研究子问题。合成实验显示，在不同强度和维度的普遍混杂下，相比直接在混杂数据上应用相关噪声DAG学习，该方法在有向边恢复方面有持续改进。

Conclusion: DCL-DECOR方法有效处理混合潜在混杂问题，通过精度引导的模块化流程分离全局和局部混杂效应，显著提高因果发现准确性，为实际应用中的因果推断提供了实用解决方案。

Abstract: We study causal discovery from observational data in linear Gaussian systems affected by \emph{mixed latent confounding}, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure.
  We propose \textsc{DCL-DECOR}, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness.
  We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.

</details>


### [219] [BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework](https://arxiv.org/abs/2512.24708)
*András Millinghoffer,András Formanek,András Antos,Péter Antal*

Main category: cs.LG

TL;DR: BandiK是一个三阶段多任务辅助任务子集选择方法，使用多臂老虎机框架，通过估计任务间的成对转移、构建线性数量的候选辅助任务集，并利用多臂老虎机高效评估这些候选集，解决了多任务学习中辅助任务选择的高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 多任务学习中的知识迁移仍然是一个开放性问题，负迁移是主要障碍。辅助任务选择面临高计算成本、候选集数量庞大以及不同目标任务选择复杂度变化等挑战，需要高效的选择方法。

Method: 1) 估计任务间的成对转移关系，识别可能从联合学习中受益的任务；2) 基于初始估计为每个目标任务构建线性数量的候选辅助任务集；3) 为每个任务使用多臂老虎机框架，其中臂对应候选辅助任务集在训练-测试数据集分割上的性能，并通过多臂老虎机结构共享神经网络计算。

Result: BandiK通过多臂老虎机框架和半重叠臂特性，显著减少了评估候选辅助任务集的计算成本，同时保持了选择质量，解决了多任务学习中辅助任务选择的高计算复杂度问题。

Conclusion: BandiK提出了一种高效的多任务辅助任务子集选择方法，通过三阶段流程和多臂老虎机框架，在减少计算成本的同时有效识别有益的辅助任务组合，为多任务学习中的知识迁移问题提供了实用解决方案。

Abstract: The challenge of effectively transferring knowledge across multiple tasks is of critical importance and is also present in downstream tasks with foundation models. However, the nature of transfer, its transitive-intransitive nature, is still an open problem, and negative transfer remains a significant obstacle. Selection of beneficial auxiliary task sets in multi-task learning is frequently hindered by the high computational cost of their evaluation, the high number of plausible candidate auxiliary sets, and the varying complexity of selection across target tasks.
  To address these constraints, we introduce BandiK, a novel three-stage multi-task auxiliary task subset selection method using multi-bandits, where each arm pull evaluates candidate auxiliary sets by training and testing a multiple output neural network on a single random train-test dataset split. Firstly, BandiK estimates the pairwise transfers between tasks, which helps in identifying which tasks are likely to benefit from joint learning. In the second stage, it constructs a linear number of candidate sets of auxiliary tasks (in the number of all tasks) for each target task based on the initial estimations, significantly reducing the exponential number of potential auxiliary task sets. Thirdly, it employs a Multi-Armed Bandit (MAB) framework for each task, where the arms correspond to the performance of candidate auxiliary sets realized as multiple output neural networks over train-test data set splits. To enhance efficiency, BandiK integrates these individual task-specific MABs into a multi-bandit structure. The proposed multi-bandit solution exploits that the same neural network realizes multiple arms of different individual bandits corresponding to a given candidate set. This semi-overlapping arm property defines a novel multi-bandit cost/reward structure utilized in BandiK.

</details>


### [220] [FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference](https://arxiv.org/abs/2512.24713)
*Fen-Yu Hsieh,Yun-Chang Teng,Ding-Yong Hong,Jan-Jan Wu*

Main category: cs.LG

TL;DR: 提出结合结构化剪枝与量化的自动化框架，通过软硬件协同设计实现LLM在资源受限环境下的高效推理


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能优异，但计算和内存需求巨大，难以在资源受限环境中部署

Method: 采用N:M结构化剪枝和4位整数量化减少内存占用，结合优化的反量化和矩阵乘法，在CPU、GPU和自定义FPGA加速器上实现高效推理

Result: 在4096×4096矩阵上，结合2:4稀疏性和量化，权重存储减少4倍，矩阵乘法加速1.71倍，端到端延迟降低1.29倍；LLaMA-7B模型上吞吐量提升1.36倍

Conclusion: 细粒度N:M稀疏性与量化的协同作用能实现高效可部署的LLM推理，提出的FPGA加速器为支持更广泛稀疏模式提供了灵活的架构路径

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on $4096 \times 4096$ matrices, our approach achieves a reduction of up to $4\times$ in weight storage and a $1.71\times$ speedup in matrix multiplication, yielding a $1.29\times$ end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by $1.36\times$. These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.

</details>


### [221] [From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis](https://arxiv.org/abs/2512.24767)
*Yutong Cai,Hua Wang*

Main category: cs.LG

TL;DR: 基于武汉百度Apollo Robotaxi实际运营数据的调查显示，成本敏感性和行为意向是自动驾驶出租车采用的最强预测因素，为政策制定和定价策略提供实证依据。


<details>
  <summary>Details</summary>
Motivation: 现有研究多基于假设场景探讨用户对自动驾驶出租车的接受度，但缺乏基于实际运营服务的用户行为研究。本研究旨在填补这一空白，利用武汉百度Apollo Robotaxi的实际运营数据进行实证分析。

Method: 在武汉收集了336份有效问卷，设计包含实际服务属性的调查，使用结构方程模型识别六个潜在心理构念（信任与政策支持、成本敏感性、性能、行为意向、生活方式、教育），并分析它们对采用行为（在十个场景中选择自动驾驶出租车的频率）的影响。

Result: 成本敏感性和行为意向是自动驾驶出租车采用的最强正向预测因素，其他潜在构念发挥更微妙的作用。模型在多个拟合指数上表现出良好的拟合度。

Conclusion: 研究结果为现实城市环境中自动驾驶出租车的规模化部署提供了支持政策制定、票价设计和公众推广策略的实证证据。

Abstract: Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu's Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \& Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.

</details>


### [222] [Gradient Descent as Implicit EM in Distance-Based Neural Models](https://arxiv.org/abs/2512.24780)
*Alan Oursland*

Main category: cs.LG

TL;DR: 论文证明了对数-求和-指数结构的损失函数梯度等于负后验责任，使得梯度下降隐式执行期望最大化，统一了无监督混合建模、注意力机制和分类学习


<details>
  <summary>Details</summary>
Motivation: 神经网络训练中出现的概率推断行为（软聚类、原型专业化、贝叶斯不确定性跟踪）通常用混合模型类比或后验架构解释，缺乏直接推导。本文旨在提供严格的数学证明，揭示这些现象的根本机制。

Method: 通过数学推导证明：对于任何具有对数-求和-指数结构（基于距离或能量）的目标函数，每个距离的梯度恰好等于对应分量的负后验责任（∂L/∂d_j = -r_j）。这是一个代数恒等式，而非近似。

Result: 梯度下降在此类目标函数上隐式执行期望最大化算法，责任不是需要计算的辅助变量，而是需要应用的梯度。优化和推断是同一过程，无需显式推断算法。

Conclusion: 该结果统一了三种学习机制：无监督混合建模（责任完全潜在）、注意力机制（责任以查询为条件）、交叉熵分类（监督将责任固定为目标）。Transformer中观察到的贝叶斯结构不是涌现性质，而是目标函数几何结构的必然结果。

Abstract: Neural networks trained with standard objectives exhibit behaviors characteristic of probabilistic inference: soft clustering, prototype specialization, and Bayesian uncertainty tracking. These phenomena appear across architectures -- in attention mechanisms, classification heads, and energy-based models -- yet existing explanations rely on loose analogies to mixture models or post-hoc architectural interpretation. We provide a direct derivation. For any objective with log-sum-exp structure over distances or energies, the gradient with respect to each distance is exactly the negative posterior responsibility of the corresponding component: $\partial L / \partial d_j = -r_j$. This is an algebraic identity, not an approximation. The immediate consequence is that gradient descent on such objectives performs expectation-maximization implicitly -- responsibilities are not auxiliary variables to be computed but gradients to be applied. No explicit inference algorithm is required because inference is embedded in optimization. This result unifies three regimes of learning under a single mechanism: unsupervised mixture modeling, where responsibilities are fully latent; attention, where responsibilities are conditioned on queries; and cross-entropy classification, where supervision clamps responsibilities to targets. The Bayesian structure recently observed in trained transformers is not an emergent property but a necessary consequence of the objective geometry. Optimization and inference are the same process.

</details>


### [223] [Self-Supervised Neural Architecture Search for Multimodal Deep Neural Networks](https://arxiv.org/abs/2512.24793)
*Shota Suzuki,Satoshi Ono*

Main category: cs.LG

TL;DR: 提出一种基于自监督学习的多模态神经网络架构搜索方法，可在无标注数据下完成架构设计和预训练


<details>
  <summary>Details</summary>
Motivation: 多模态神经网络结构复杂，传统NAS需要大量标注数据，但实际应用中标注数据获取困难

Method: 采用自监督学习（SSL）方法，将SSL同时应用于架构搜索和模型预训练过程

Result: 实验证明该方法能够成功从无标注训练数据中设计出多模态神经网络架构

Conclusion: 提出的自监督学习方法有效解决了多模态NAS对标注数据的依赖问题

Abstract: Neural architecture search (NAS), which automates the architectural design process of deep neural networks (DNN), has attracted increasing attention. Multimodal DNNs that necessitate feature fusion from multiple modalities benefit from NAS due to their structural complexity; however, constructing an architecture for multimodal DNNs through NAS requires a substantial amount of labeled training data. Thus, this paper proposes a self-supervised learning (SSL) method for architecture search of multimodal DNNs. The proposed method applies SSL comprehensively for both the architecture search and model pretraining processes. Experimental results demonstrated that the proposed method successfully designed architectures for DNNs from unlabeled training data.

</details>


### [224] [DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes](https://arxiv.org/abs/2512.24810)
*Bence Bolgár,András Millinghoffer,Péter Antal*

Main category: cs.LG

TL;DR: 提出基于深度核学习的高斯过程架构DTI-GP，用于药物-靶点相互作用预测，提供概率信息并支持贝叶斯分类、拒绝、top-K选择和排序等操作。


<details>
  <summary>Details</summary>
Motivation: 药物-靶点相互作用预测需要精确的概率信息来理解模型局限性和提升预测性能。高斯过程能够整合最先进的DTI表示和贝叶斯推断，支持新颖的操作。

Method: 提出DTI-GP架构，包含化学化合物和蛋白质靶点的联合神经嵌入模块，以及高斯过程模块。通过从预测分布中采样估计贝叶斯优先矩阵，用于快速准确的筛选和排序操作。

Result: DTI-GP优于现有最先进方法，能够构建贝叶斯准确度-置信度富集分数，实现改进富集的拒绝方案，以及估计和搜索具有高期望效用的top-K选择和排序。

Conclusion: DTI-GP为药物-靶点相互作用预测提供了可扩展的贝叶斯框架，支持概率推断和多种实用操作，在预测性能和功能扩展方面均表现出色。

Abstract: Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel operations, such as Bayesian classification with rejection, top-$K$ selection, and ranking. We propose a deep kernel learning-based GP architecture (DTI-GP), which incorporates a combined neural embedding module for chemical compounds and protein targets, and a GP module. The workflow continues with sampling from the predictive distribution to estimate a Bayesian precedence matrix, which is used in fast and accurate selection and ranking operations. DTI-GP outperforms state-of-the-art solutions, and it allows (1) the construction of a Bayesian accuracy-confidence enrichment score, (2) rejection schemes for improved enrichment, and (3) estimation and search for top-$K$ selections and ranking with high expected utility.

</details>


### [225] [Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback](https://arxiv.org/abs/2512.24818)
*Shulun Chen,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du*

Main category: cs.LG

TL;DR: 本文提出了在非传递偏好建模中，使用乐观乘性权重更新(OMWU)算法实现纳什均衡的线性收敛保证，无需纳什均衡唯一性假设。


<details>
  <summary>Details</summary>
Motivation: 传统Bradley-Terry模型假设偏好传递性，忽略了人类群体偏好的复杂性。纳什学习从人类反馈(NLHF)通过博弈论框架处理非传递偏好，但现有算法依赖正则化，在计算原始博弈对偶间隙时会产生不可避免的偏差。

Method: 采用乐观乘性权重更新(OMWU)算法，将非传递偏好建模为两人零和博弈，通过寻找纳什均衡实现对齐。分析OMWU在NLHF中的收敛性，特别关注边缘收敛行为。

Result: 首次证明了OMWU在NLHF中的收敛保证：当存在全支撑纳什均衡时，经过预热阶段后实现最后迭代线性收敛，以实例依赖的线性收敛率收敛到原始纳什均衡。相比之前工作，无需纳什均衡唯一性假设。

Conclusion: OMWU在NLHF中具有理论优势，实验验证了其在表格和神经网络策略类别中的有效性，展示了在大型语言模型应用中的潜力。

Abstract: Aligning large language models (LLMs) with human preferences has proven effective for enhancing model capabilities, yet standard preference modeling using the Bradley-Terry model assumes transitivity, overlooking the inherent complexity of human population preferences. Nash learning from human feedback (NLHF) addresses this by framing non-transitive preferences as a two-player zero-sum game, where alignment reduces to finding the Nash equilibrium (NE). However, existing algorithms typically rely on regularization, incurring unavoidable bias when computing the duality gap in the original game. In this work, we provide the first convergence guarantee for Optimistic Multiplicative Weights Update ($\mathtt{OMWU}$) in NLHF, showing that it achieves last-iterate linear convergence after a burn-in phase whenever an NE with full support exists, with an instance-dependent linear convergence rate to the original NE, measured by duality gaps. Compared to prior results in Wei et al. (2020), we do not require the assumption of NE uniqueness. Our analysis identifies a novel marginal convergence behavior, where the probability of rarely played actions grows exponentially from exponentially small values, enabling exponentially better dependence on instance-dependent constants than prior results. Experiments corroborate the theoretical strengths of $\mathtt{OMWU}$ in both tabular and neural policy classes, demonstrating its potential for LLM applications.

</details>


### [226] [Many Minds from One Model: Bayesian Transformers for Population Intelligence](https://arxiv.org/abs/2512.25063)
*Diji Yang,Yi Zhang*

Main category: cs.LG

TL;DR: 提出B-Trans方法，将标准大语言模型转换为贝叶斯Transformer，通过归一化层偏置的随机化实现从单一预训练权重中采样多样化模型实例，利用群体智慧提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代Transformer通常训练为单一确定性系统，而智能可能源于多样化的"思维"。受此启发，希望开发能够从单一预训练权重中采样多样化模型实例的方法，实现群体决策优势。

Method: 将归一化层中的偏置偏移量视为具有高斯变分近似的随机变量，构建贝叶斯后验代理。在序列级别冻结采样的噪声以保证时间一致性，从单一权重中采样多样化但连贯的模型实例。

Result: 在零样本生成、带可验证奖励的强化学习(RLVR)和无显式标签的RL任务中，B-Trans通过聚合多个采样个体的预测，显著提升了语义多样性，同时获得了比确定性基线更好的任务性能。

Conclusion: B-Trans成功将标准LLM转换为贝叶斯Transformer，实现了从单一预训练权重中采样多样化模型实例，验证了群体智慧在语言模型中的有效性，为探索多样化智能系统提供了新途径。

Abstract: Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we propose Population Bayesian Transformers (B-Trans), which transform a standard Large Language Model into a Bayesian Transformer model to supports sampling diverse yet coherent model instances from a single set of pre-trained weights.
  B-Trans introduces a Bayesian-motivated posterior proxy by treating the bias-like offsets in normalization layers as stochastic variables with a Gaussian variational approximation, inducing a distribution over model behavior without the cost of training full Bayesian neural networks. Sampling from this proxy yields a set of model instances with diverse behaviors while maintaining general competence. To preserve coherence within each generation, we freeze the sampled noise at the sequence level, enforcing temporal consistency across tokens. B-Trans allows for population-level decision-making, where aggregating predictions across sampled individuals significantly enhances exploration. Experiments across zero-shot generation, Reinforcement Learning with Verifiable Rewards (RLVR), and RL without explicit labels demonstrate that B-Trans effectively leverage the wisdom of crowds, yielding superior semantic diversity while achieving better task performance compared to deterministic baselines.

</details>


### [227] [Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics](https://arxiv.org/abs/2512.24827)
*Raul D. Steleac,Mohan Sridharan,David Abel*

Main category: cs.LG

TL;DR: 提出一种多智能体选项发现方法，通过联合状态抽象和费马状态近似来发现强协调行为，相比现有方法能产生更强的下游协调能力。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，联合状态空间随智能体数量呈指数增长，使得协调行为的设计特别具有挑战性。现有方法往往牺牲协调性，产生松散耦合或完全独立的行为。

Method: 1) 提出联合状态抽象，压缩状态空间同时保留发现强协调行为所需信息；2) 近似最大对齐的虚构状态（费马状态），定义衡量团队级不对齐的"扩散度"；3) 使用神经图拉普拉斯估计器推导捕获智能体间状态同步模式的选项。

Result: 在两个多智能体领域的多个场景中评估，结果显示该方法产生的选项相比其他选项发现方法能带来更强的下游协调能力。

Conclusion: 该方法通过状态同步模式发现强协调的多智能体选项，有效解决了多智能体选项发现中的协调挑战，相比现有方法具有更好的协调性能。

Abstract: Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \textit{Fermat} state, and use it to define a measure of \textit{spreadness}, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.

</details>


### [228] [Scaling Open-Ended Reasoning to Predict the Future](https://arxiv.org/abs/2512.25070)
*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

Main category: cs.LG

TL;DR: 训练语言模型进行开放式预测，使用自动化方法从新闻生成预测问题，开发OpenForecaster 8B模型，在准确性和校准方面表现优异，匹配更大规模专有模型。


<details>
  <summary>Details</summary>
Motivation: 高风险决策需要在不确定性下进行未来推理。当前需要可扩展的方法来训练语言模型进行开放式预测，同时避免未来信息泄露问题。

Method: 1. 从每日新闻中的全球事件自动合成预测问题；2. 使用离线新闻语料防止信息泄露；3. 训练Qwen3思维模型；4. 结合检索机制；5. 改进强化学习奖励函数。

Result: OpenForecaster 8B模型在2025年5-8月的测试中，匹配更大规模专有模型，在准确性、校准和一致性方面均有提升，且校准改进能泛化到其他基准测试。

Conclusion: 通过自动化数据生成和专门训练，可以开发出高效的预测模型，开源所有模型、代码和数据将促进语言模型预测研究的广泛可及性。

Abstract: High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.

</details>


### [229] [AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference](https://arxiv.org/abs/2512.24847)
*Linhao Fan,Hongqiang Fang,Jingyang Dai,Yong Jiang,Qixing Zhang*

Main category: cs.LG

TL;DR: AODDiff：基于扩散贝叶斯推断的概率性AOD重建框架，无需完整训练数据，支持不确定性量化，适用于多种重建任务


<details>
  <summary>Details</summary>
Motivation: 当前AOD（气溶胶光学厚度）场重建模型面临两个主要限制：1）缺乏完整的训练数据；2）缺乏不确定性量化能力。这些限制影响了大气监测的准确性和可靠性。

Method: 提出AODDiff框架：1）使用"corruption-aware training strategy"从自然不完整数据中学习时空AOD先验分布；2）采用"decoupled annealing posterior sampling strategy"有效整合异质观测数据作为生成约束

Result: 在再分析数据上的实验表明，AODDiff在降尺度和图像修复任务中表现出高效性和鲁棒性，特别是在保持高空间光谱保真度方面具有优势。作为生成模型，通过多次采样实现了不确定性量化。

Conclusion: AODDiff提供了一个灵活的概率重建框架，能够处理不完整训练数据，支持多种重建任务而无需重新训练，并提供了对下游应用至关重要的不确定性量化能力。

Abstract: High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.

</details>


### [230] [Characterization of Transfer Using Multi-task Learning Curves](https://arxiv.org/abs/2512.24866)
*András Millinghoffer,Bence Bolgár,Péter Antal*

Main category: cs.LG

TL;DR: 该论文提出通过扰动数据集而非模型梯度更新来表征迁移效应，使用多任务学习曲线量化迁移效果，并比较了统计与计算方法的优劣。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过梯度更新扰动模型来研究迁移效应，作者认为通过增加样本扰动数据集能提供更基础的迁移效应表征。需要更有效的方法来量化多任务学习中的迁移效果。

Method: 使用多任务学习曲线近似不同样本量下的归纳性能，提出高效近似多任务学习曲线的方法（类似任务亲和分组），比较统计与计算方法的迁移效果。

Result: 在药物-靶点相互作用基准数据集上的评估表明，学习曲线能更好捕捉多任务学习效果，其多任务扩展能描述基础模型中的成对和上下文迁移效应。

Conclusion: 通过数据集扰动研究迁移效应比模型扰动更基础，学习曲线是量化迁移效应的有效工具，多任务学习曲线扩展能更好描述基础模型的迁移模式。

Abstract: Transfer effects manifest themselves both during training using a fixed data set and in inductive inference using accumulating data. We hypothesize that perturbing the data set by including more samples, instead of perturbing the model by gradient updates, provides a complementary and more fundamental characterization of transfer effects. To capture this phenomenon, we quantitatively model transfer effects using multi-task learning curves approximating the inductive performance over varying sample sizes. We describe an efficient method to approximate multi-task learning curves analogous to the Task Affinity Grouping method applied during training. We compare the statistical and computational approaches to transfer, which indicates considerably higher compute costs for the previous but better power and broader applicability. Evaluations are performed using a benchmark drug-target interaction data set. Our results show that learning curves can better capture the effects of multi-task learning and their multi-task extensions can delineate pairwise and contextual transfer effects in foundation models.

</details>


### [231] [PRISM: A hierarchical multiscale approach for time series forecasting](https://arxiv.org/abs/2512.24898)
*Zihao Chen,Alexandre Andre,Wenrui Ma,Ian Knight,Sergey Shuvaev,Eva Dyer*

Main category: cs.LG

TL;DR: PRISM是一种新的时间序列预测方法，通过可学习的树状分割结构，结合全局趋势和局部细节，在多个尺度上提取特征，实现准确预测。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列包含全局趋势、局部细粒度结构以及中间多个尺度的特征，这使得准确预测变得困难。现有方法难以同时捕捉这些多尺度特征。

Method: PRISM采用可学习的树状分割结构：根节点捕捉信号的全局趋势，递归分割揭示越来越局部的视图。在每个层级，数据投影到时频基（如小波或指数移动平均）提取尺度特定特征，然后在层次结构中聚合。

Result: 在基准数据集上的实验表明，PRISM在预测性能上优于最先进的方法，证明了其有效性。

Conclusion: 这种分层方法为多变量时间序列预测提供了一个轻量级且灵活的框架，能够同时捕捉信号的全局结构和局部动态。

Abstract: Forecasting is critical in areas such as finance, biology, and healthcare. Despite the progress in the field, making accurate forecasts remains challenging because real-world time series contain both global trends, local fine-grained structure, and features on multiple scales in between. Here, we present a new forecasting method, PRISM (Partitioned Representation for Iterative Sequence Modeling), that addresses this challenge through a learnable tree-based partitioning of the signal. At the root of the tree, a global representation captures coarse trends in the signal, while recursive splits reveal increasingly localized views of the signal. At each level of the tree, data are projected onto a time-frequency basis (e.g., wavelets or exponential moving averages) to extract scale-specific features, which are then aggregated across the hierarchy. This design allows the model to jointly capture global structure and local dynamics of the signal, enabling accurate forecasting. Experiments across benchmark datasets show that our method outperforms state-of-the-art methods for forecasting. Overall, these results demonstrate that our hierarchical approach provides a lightweight and flexible framework for forecasting multivariate time series. The code is available at https://github.com/nerdslab/prism.

</details>


### [232] [Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes](https://arxiv.org/abs/2512.24901)
*Debasis Maji,Arghya Banerjee,Debaditya Barman*

Main category: cs.LG

TL;DR: 提出基于图傅里叶变换的SpectralBrainGNN模型，用于从fMRI连接组中解码认知任务，在HCP-Task数据集上达到96.25%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉脑功能连接中的复杂拓扑依赖和多尺度交互模式，需要更先进的图神经网络方法来更好地解码认知状态。

Method: 提出SpectralBrainGNN模型，基于图傅里叶变换的谱卷积框架，通过归一化拉普拉斯矩阵特征分解计算GFT，将脑区建模为节点、功能连接建模为边。

Result: 在Human Connectome Project-Task数据集上的实验表明，该方法达到96.25%的分类准确率，优于传统方法。

Conclusion: SpectralBrainGNN能够有效捕捉脑网络的拓扑特征，为认知任务分类提供了强大的工具，代码已开源支持可复现性和未来研究。

Abstract: Cognitive task classification using machine learning plays a central role in decoding brain states from neuroimaging data. By integrating machine learning with brain network analysis, complex connectivity patterns can be extracted from functional magnetic resonance imaging connectomes. This process transforms raw blood-oxygen-level-dependent (BOLD) signals into interpretable representations of cognitive processes. Graph neural networks (GNNs) further advance this paradigm by modeling brain regions as nodes and functional connections as edges, capturing topological dependencies and multi-scale interactions that are often missed by conventional approaches. Our proposed SpectralBrainGNN model, a spectral convolution framework based on graph Fourier transforms (GFT) computed via normalized Laplacian eigendecomposition. Experiments on the Human Connectome Project-Task (HCPTask) dataset demonstrate the effectiveness of the proposed approach, achieving a classification accuracy of 96.25\%. The implementation is publicly available at https://github.com/gnnplayground/SpectralBrainGNN to support reproducibility and future research.

</details>


### [233] [Frequent subgraph-based persistent homology for graph classification](https://arxiv.org/abs/2512.24917)
*Xinyang Chen,Amaël Broustet,Guoting Chen*

Main category: cs.LG

TL;DR: 提出基于频繁子图的图过滤方法FSF，生成频率持久同调特征FPH，并开发了FPH-ML和FPH-GNN两种图分类框架，显著提升拓扑感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于持久同调的图分析方法主要依赖度或权重等有限过滤方法，忽略了数据集中重复出现的模式信息，限制了表达能力和拓扑特征提取的丰富性。

Method: 提出频繁子图过滤FSF，从频繁子图中提取稳定的频率持久同调特征FPH。开发了两种框架：FPH-ML（基于机器学习的分类模型）和FPH-GNN（将FPH与图神经网络集成的混合框架）。

Result: FPH-ML在准确率上与基于核和度的过滤方法相当或更优。FPH集成到图神经网络中，相对性能提升0.4-21%，在GCN和GIN基准上最高提升8.2个百分点。

Conclusion: FSF和FPH方法有效结合了频繁子图挖掘和拓扑数据分析，为拓扑感知特征提取提供了新视角，显著提升了图分类性能。

Abstract: Persistent homology (PH) has recently emerged as a powerful tool for extracting topological features. Integrating PH into machine learning and deep learning models enhances topology awareness and interpretability. However, most PH methods on graphs rely on a limited set of filtrations, such as degree-based or weight-based filtrations, which overlook richer features like recurring information across the dataset and thus restrict expressive power. In this work, we propose a novel graph filtration called Frequent Subgraph Filtration (FSF), which is derived from frequent subgraphs and produces stable and information-rich frequency-based persistent homology (FPH) features. We study the theoretical properties of FSF and provide both proofs and experimental validation. Beyond persistent homology itself, we introduce two approaches for graph classification: an FPH-based machine learning model (FPH-ML) and a hybrid framework that integrates FPH with graph neural networks (FPH-GNNs) to enhance topology-aware graph representation learning. Our frameworks bridge frequent subgraph mining and topological data analysis, offering a new perspective on topology-aware feature extraction. Experimental results show that FPH-ML achieves competitive or superior accuracy compared with kernel-based and degree-based filtration methods. When integrated into graph neural networks, FPH yields relative performance gains ranging from 0.4 to 21 percent, with improvements of up to 8.2 percentage points over GCN and GIN backbones across benchmarks.

</details>


### [234] [Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning](https://arxiv.org/abs/2512.24959)
*András Antos,András Millinghoffer,Péter Antal*

Main category: cs.LG

TL;DR: 提出Sequential Support Network Learning (SSNL)框架，使用半重叠多臂赌博机(SOMMAB)模型从稀疏候选列表中高效学习支持网络，开发了GapE算法并获得指数误差界。


<details>
  <summary>Details</summary>
Motivation: 现代AI/ML问题需要评估合作伙伴贡献，通过共享但不对称的计算密集型过程同时选择最有利的候选者。现有序列方法需要统一框架来高效学习最高性能的贡献网络。

Method: 提出SSNL框架，引入SOMMAB模型（单次评估为多个赌博机提供不同反馈），开发广义GapE算法，推导新的指数误差界。

Result: 获得改进的指数误差界，常数项优于现有最佳结果，样本复杂度随重叠度线性缩放，共享评估带来显著样本复杂度收益。

Conclusion: 为多任务学习、辅助任务学习、联邦学习和多智能体系统中的支持网络识别提供了理论基础和性能保证，共享评估能显著提高学习效率。

Abstract: Many modern AI and ML problems require evaluating partners' contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping multi-(multi-armed) bandit (SOMMAB), in which a single evaluation provides distinct feedback to multiple bandits due to structural overlap among their arms, can be used to learn a support network from sparse candidate lists efficiently.
  We develop a generalized GapE algorithm for SOMMABs and derive new exponential error bounds that improve the best known constant in the exponent for multi-bandit best-arm identification. The bounds scale linearly with the degree of overlap, revealing significant sample-complexity gains arising from shared evaluations.
  From an application point of view, this work provides a theoretical foundation and improved performance guarantees for sequential learning tools for identifying support networks from sparse candidates in multiple learning problems, such as in multi-task learning (MTL), auxiliary task learning (ATL), federated learning (FL), and in multi-agent systems (MAS).

</details>


### [235] [Attribution-Guided Distillation of Matryoshka Sparse Autoencoders](https://arxiv.org/abs/2512.24975)
*Cristina P. Martin-Linares,Jonathan P. Ling*

Main category: cs.LG

TL;DR: 提出蒸馏套娃稀疏自编码器(DMSAEs)，通过迭代蒸馏提取核心特征，提高特征一致性和可重用性


<details>
  <summary>Details</summary>
Motivation: 传统稀疏自编码器学习的特征存在冗余且在不同训练运行和稀疏度下不一致，导致特征解释难以迁移和重用

Method: 使用蒸馏套娃稀疏自编码器训练流程：迭代蒸馏循环训练共享核心的Matryoshka SAE，通过梯度激活度量特征贡献，保留最小子集解释固定比例归因，仅核心编码器权重跨周期传递

Result: 在Gemma-2-2B模型第12层残差流激活上，7轮蒸馏得到197个核心特征，使用该核心训练改善了多个SAEBench指标，证明一致特征集可跨稀疏度迁移

Conclusion: DMSAEs能够提取稳定可重用的核心特征，提高稀疏自编码器的特征一致性和解释可迁移性

Abstract: Sparse autoencoders (SAEs) aim to disentangle model activations into monosemantic, human-interpretable features. In practice, learned features are often redundant and vary across training runs and sparsity levels, which makes interpretations difficult to transfer and reuse. We introduce Distilled Matryoshka Sparse Autoencoders (DMSAEs), a training pipeline that distills a compact core of consistently useful features and reuses it to train new SAEs. DMSAEs run an iterative distillation cycle: train a Matryoshka SAE with a shared core, use gradient X activation to measure each feature's contribution to next-token loss in the most nested reconstruction, and keep only the smallest subset that explains a fixed fraction of the attribution. Only the core encoder weight vectors are transferred across cycles; the core decoder and all non-core latents are reinitialized each time. On Gemma-2-2B layer 12 residual stream activations, seven cycles of distillation (500M tokens, 65k width) yielded a distilled core of 197 features that were repeatedly selected. Training using this distilled core improves several SAEBench metrics and demonstrates that consistent sets of latent features can be transferred across sparsity levels

</details>


### [236] [Efficiently Estimating Data Efficiency for Language Model Fine-tuning](https://arxiv.org/abs/2512.24991)
*Gyung Hyun Je,Colin Raffel*

Main category: cs.LG

TL;DR: 提出使用梯度余弦相似度预测任务数据效率的方法，无需增量标注即可评估需要多少微调样本才能达到目标性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具备零样本能力，但微调仍是提升性能的常见做法。然而，任务的数据效率（达到目标性能所需的微调样本数量）通常是未知的，导致昂贵的增量标注和重新训练循环。研究表明，即使在零样本表现不佳的任务上，微调后也能获得更强性能，因此需要预测数据效率的方法。

Method: 首先定义量化任务数据效率的具体指标，然后提出使用低置信度样本的梯度余弦相似度来预测数据效率，仅需少量标注样本即可进行预测。

Result: 在30个专门任务的验证中，数据效率预测误差为8.6%，通常能为每个任务消除数百个不必要的标注。方法在GitHub上开源。

Conclusion: 提出的梯度余弦相似度方法能够有效预测任务的数据效率，减少不必要的标注成本，为LLM微调提供实用的数据效率评估工具。

Abstract: While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.

</details>


### [237] [Diffusion Language Models are Provably Optimal Parallel Samplers](https://arxiv.org/abs/2512.25014)
*Haozhe Jiang,Nika Haghtalab,Lijie Chen*

Main category: cs.LG

TL;DR: DLMs通过并行采样和CoT实现最优时间效率，但需要remasking或revision功能才能达到最优空间复杂度，其中revision使DLMs表达能力更强。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型作为自回归模型的替代方案，具有并行生成token的推理速度优势，但需要理论验证其效率和表达能力。

Method: 形式化并行采样模型，证明DLMs结合多项式长度CoT可以模拟任何并行采样算法；进一步证明remasking或revision功能结合CoT可实现最优空间复杂度。

Result: DLMs在目标分布可用少量顺序步骤生成时，能以相同最优步骤数生成；revision或remasking使DLMs能模拟任何并行采样算法且空间最优；revision比无此功能的DLMs表达能力更强。

Conclusion: DLMs作为最高效并行采样器的理论依据，并提倡在DLMs中启用revision功能以提升表达能力和空间效率。

Abstract: Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.

</details>


### [238] [ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning](https://arxiv.org/abs/2512.25023)
*Timo Kaufmann,Yannick Metz,Daniel Keim,Eyke Hüllermeier*

Main category: cs.LG

TL;DR: ResponseRank：一种利用局部相对强度信号（如响应时间、标注者一致性）来鲁棒学习偏好强度的方法，相比传统二元选择能更高效地学习效用差异。


<details>
  <summary>Details</summary>
Motivation: 传统的二元选择（如RLHF）只能传达偏好方向，无法衡量偏好强度。而偏好强度对于不确定性下的决策和偏好模型的泛化至关重要。虽然元数据（响应时间、标注者一致性）可作为强度代理信号，但这些信号通常噪声大且存在混淆因素。

Method: 提出ResponseRank方法：1）利用代理信号的相对差异对成对比较中的响应按推断的偏好强度进行排序；2）通过精心构建的分层进行局部比较，控制系统性变异；3）在最小化强度信号假设下，鲁棒地学习与强度排序一致的效用差异。

Result: 在三个任务上验证：1）合成偏好学习（模拟响应时间）；2）语言建模（标注者一致性）；3）RL控制任务（模拟回合回报）。结果显示提高了样本效率和鲁棒性。同时提出了Pearson Distance Correlation（PDC）新指标，将基数效用学习与序数准确性分离。

Conclusion: ResponseRank能够从噪声强度信号中鲁棒学习偏好强度，相比传统二元选择方法在样本效率和鲁棒性方面有显著改进。该方法为从人类反馈中学习更丰富的偏好信息提供了新途径。

Abstract: Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.

</details>


### [239] [Generative Classifiers Avoid Shortcut Solutions](https://arxiv.org/abs/2512.25034)
*Alexander C. Li,Ananya Kumar,Deepak Pathak*

Main category: cs.LG

TL;DR: 生成式分类器通过建模所有特征（包括核心和虚假相关特征），避免判别式分类器过度依赖虚假相关特征的问题，在分布偏移下表现更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 判别式分类器在分布内学习时容易依赖虚假相关特征，这些特征在分布偏移下会失效。需要一种能避免这种问题的分类方法。

Method: 使用基于类条件生成模型（如扩散模型和自回归模型）的生成式分类器，建模所有特征而非主要关注虚假相关特征。方法简单，无需特殊增强、强正则化、额外超参数或先验知识。

Result: 在五个标准图像和文本分布偏移基准测试中达到最先进性能，在医疗和卫星数据集等实际应用中减少虚假相关的影响。通过高斯玩具设置分析生成式分类器的归纳偏置。

Conclusion: 生成式分类器通过建模所有特征，能有效避免虚假相关问题，在分布偏移下比判别式分类器更鲁棒，且训练简单无需复杂调整。

Abstract: Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.

</details>


### [240] [On the geometry and topology of representations: the manifolds of modular addition](https://arxiv.org/abs/2512.25060)
*Gabriela Moisescu-Pareja,Gavin McCracken,Harley Wiltzer,Vincent Létourneau,Colin Daniels,Doina Precup,Jonathan Love*

Main category: cs.LG

TL;DR: 研究发现，Clock和Pizza两种解释对应的架构（均匀注意力与可学习注意力）实际上实现了相同的算法，具有拓扑和几何等价的表示，而非不同的电路。


<details>
  <summary>Details</summary>
Motivation: 挑战先前观点：Clock和Pizza解释认为不同架构设计会产生不同的模加法电路。本研究旨在证明这两种架构实际上实现的是相同算法。

Method: 超越单个神经元和权重的解释，识别所有对应每个学习表示的神经元，将神经元群体作为一个实体研究，利用拓扑工具分析学习表示作为流形的特性。

Result: 发现两种架构的学习表示在拓扑和几何上是等价的，通过统计分析数百个电路，证明从常见深度学习范式中自然产生的模加法电路具有相似性。

Conclusion: Clock和Pizza解释对应的架构实际上实现了相同的算法，具有等价的表示，挑战了先前关于不同架构设计会产生不同电路的观点。

Abstract: The Clock and Pizza interpretations, associated with architectures differing in either uniform or learnable attention, were introduced to argue that different architectural designs can yield distinct circuits for modular addition. In this work, we show that this is not the case, and that both uniform attention and trainable attention architectures implement the same algorithm via topologically and geometrically equivalent representations. Our methodology goes beyond the interpretation of individual neurons and weights. Instead, we identify all of the neurons corresponding to each learned representation and then study the collective group of neurons as one entity. This method reveals that each learned representation is a manifold that we can study utilizing tools from topology. Based on this insight, we can statistically analyze the learned representations across hundreds of circuits to demonstrate the similarity between learned modular addition circuits that arise naturally from common deep learning paradigms.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [241] [New Exam Security Questions in the AI Era: Comparing AI-Generated Item Similarity Between Naive and Detail-Guided Prompting Approaches](https://arxiv.org/abs/2512.23729)
*Ting Wang,Caroline Prendergast,Susan Lottridge*

Main category: cs.CY

TL;DR: LLM生成的医学考试题目中，仅使用公开信息生成的题目与使用专有指导生成的题目在特定临床领域相似度较高，增加了考试安全风险。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究LLM仅使用公开资源生成的医学考试题目与使用专有指导生成的题目是否存在显著差异，以评估考试安全风险。

Method: 使用三种LLM（GPT-4o、Claude 4 Sonnet、Gemini 2.5 Flash）基于美国家庭医学委员会蓝图生成题目，GPT-4o采用两种策略：仅使用公开EPA描述符的朴素策略，以及结合专有蓝图、题目编写指南和范例题目的指导策略。共生成160个题目，使用PubMedBERT和BioBERT编码，计算余弦相似度。

Result: 每种提示策略内部一致性高，但跨策略相似度总体较低。然而在特定狭窄临床领域（如病毒性肺炎和高血压），朴素策略与指导策略生成的题目相似度超过0.65阈值，表明两者在这些领域趋同。

Conclusion: 尽管专有资源能带来独特性，但LLM仅使用公开信息仍能在受限临床领域生成与指导策略相似的题目，增加了题目暴露风险。需要以人为先的AI辅助题目开发、严格分离形成性和总结性题目库，以及系统性相似度监测来平衡创新与安全。

Abstract: Large language models (LLMs) have emerged as powerful tools for generating domain-specific multiple-choice questions (MCQs), offering efficiency gains for certification boards but raising new concerns about examination security. This study investigated whether LLM-generated items created with proprietary guidance differ meaningfully from those generated using only publicly available resources. Four representative clinical activities from the American Board of Family Medicine (ABFM) blueprint were mapped to corresponding Entrustable Professional Activities (EPAs), and three LLMs (GPT-4o, Claude 4 Sonnet, Gemini 2.5 Flash) produced items under a naive strategy using only public EPA descriptors, while GPT-4o additionally produced items under a guided strategy that incorporated proprietary blueprints, item-writing guidelines, and exemplar items, yielding 160 total items. Question stems and options were encoded using PubMedBERT and BioBERT, and intra- and inter-strategy cosine similarity coefficients were calculated. Results showed high internal consistency within each prompting strategy, while cross-strategy similarity was lower overall. However, several domain model pairs, particularly in narrowly defined areas such as viral pneumonia and hypertension, exceeded the 0.65 threshold, indicating convergence between naive and guided pipelines. These findings suggest that while proprietary resources impart distinctiveness, LLMs prompted only with public information can still generate items closely resembling guided outputs in constrained clinical domains, thereby heightening risks of item exposure. Safeguarding the integrity of high stakes examinations will require human-first, AI-assisted item development, strict separation of formative and summative item pools, and systematic similarity surveillance to balance innovation with security.

</details>


### [242] [Artificial Intelligence for All? Brazilian Teachers on Ethics, Equity, and the Everyday Challenges of AI in Education](https://arxiv.org/abs/2512.23834)
*Bruno Florentino,Camila Sestito,Wellington Cruz,André de Carvalho,Robson Bonidia*

Main category: cs.CY

TL;DR: 巴西K-12教师对AI教育应用持积极态度但面临基础设施和培训不足的挑战


<details>
  <summary>Details</summary>
Motivation: 了解巴西K-12教育工作者对通用人工智能在教育中应用的认知、态度和实际使用情况，探索AI在巴西基础教育中的整合现状和挑战

Method: 采用定量分析方法，通过问卷调查收集了来自巴西不同地区的346名教育工作者的数据，分析他们的AI素养和使用情况

Result: 80.3%的教师只有基础或有限的AI知识，但对AI应用表现出强烈兴趣，特别是在互动内容创建(80.6%)、课程规划(80.2%)和个性化评估(68.6%)方面。同时识别出缺乏培训(43.4%)、技术支持(41.9%)和基础设施限制等重大挑战

Conclusion: 巴西AI教育整合仍处于自下而上的模式，缺乏官方课程指导和结构化培训。有效的AI实施需要综合公共政策、充分的教师培训和公平的技术获取，以促进在巴西K-12教育中实现伦理、包容和情境化的AI应用

Abstract: This study examines the perceptions of Brazilian K-12 education teachers regarding the use of AI in education, specifically General Purpose AI. This investigation employs a quantitative analysis approach, extracting information from a questionnaire completed by 346 educators from various regions of Brazil regarding their AI literacy and use. Educators vary in their educational level, years of experience, and type of educational institution. The analysis of the questionnaires shows that although most educators had only basic or limited knowledge of AI (80.3\%), they showed a strong interest in its application, particularly for the creation of interactive content (80.6%), lesson planning (80.2%), and personalized assessment (68.6%). The potential of AI to promote inclusion and personalized learning is also widely recognized (65.5%). The participants emphasized the importance of discussing ethics and digital citizenship, reflecting on technological dependence, biases, transparency, and responsible use of AI, aligning with critical education and the development of conscious students. Despite enthusiasm for the pedagogical potential of AI, significant structural challenges were identified, including a lack of training (43.4%), technical support (41.9%), and limitations of infrastructure, such as low access to computers, reliable Internet connections, and multimedia resources in schools. The study shows that Brazil is still in a bottom-up model for AI integration, missing official curricula to guide its implementation and structured training for teachers and students. Furthermore, effective implementation of AI depends on integrated public policies, adequate teacher training, and equitable access to technology, promoting ethical, inclusive, and contextually grounded adoption of AI in Brazilian K-12 education.

</details>


### [243] [How Large Language Models Systematically Misrepresent American Climate Opinions](https://arxiv.org/abs/2512.23889)
*Sola Kim,Jieshu Wang,Marco A. Janssen,John M. Anderies*

Main category: cs.CY

TL;DR: LLMs压缩了美国气候意见的多样性，对交叉身份群体产生系统性偏差，可能影响公平气候治理


<details>
  <summary>Details</summary>
Motivation: 随着联邦机构和研究人员越来越多地使用大语言模型分析和模拟公众意见，AI在公众与政策制定者之间的中介作用变得至关重要。不准确的群体层面估计可能误导外展、咨询和政策设计。特别是在气候变化等意见存在争议和多样性的领域，需要研究LLMs如何代表交叉身份群体的意见模式。

Method: 使用来自全国代表性美国气候意见调查的978名受访者资料，提示六个LLMs生成回答，并将AI生成的反应与实际人类回答在20个问题上进行比较，分析交叉身份（种族、性别）模式。

Result: LLMs压缩了美国气候意见的多样性：将不太关心的群体预测为更关心，反之亦然。这种压缩是交叉性的：LLMs应用统一的性别假设，这些假设符合白人和西班牙裔美国人的现实，但错误地代表了黑人美国人（实际性别模式不同）。这些模式可能对标准审计方法不可见。

Conclusion: LLMs在代表交叉身份气候意见时存在系统性偏差，可能破坏公平的气候治理。需要开发能够检测这些交叉性偏差的审计方法，以确保AI在政策分析中的公平使用。

Abstract: Federal agencies and researchers increasingly use large language models to analyze and simulate public opinion. When AI mediates between the public and policymakers, accuracy across intersecting identities becomes consequential; inaccurate group-level estimates can mislead outreach, consultation, and policy design. While research examines intersectionality in LLM outputs, no study has compared these outputs against real human responses across intersecting identities. Climate policy is one such domain, and this is particularly urgent for climate change, where opinion is contested and diverse. We investigate how LLMs represent intersectional patterns in U.S. climate opinions. We prompted six LLMs with profiles of 978 respondents from a nationally representative U.S. climate opinion survey and compared AI-generated responses to actual human answers across 20 questions. We find that LLMs appear to compress the diversity of American climate opinions, predicting less-concerned groups as more concerned and vice versa. This compression is intersectional: LLMs apply uniform gender assumptions that match reality for White and Hispanic Americans but misrepresent Black Americans, where actual gender patterns differ. These patterns, which may be invisible to standard auditing approaches, could undermine equitable climate governance.

</details>


### [244] [In Memorium: The Academic Journal](https://arxiv.org/abs/2512.23915)
*Russell Beale*

Main category: cs.CY

TL;DR: 本文反思学术期刊的生命周期与影响力演变，探讨其历史贡献、社会影响变化，以及最终因偏离初衷而导致的复杂遗产


<details>
  <summary>Details</summary>
Motivation: 分析学术期刊从诞生到消亡的完整生命周期，探讨其如何从最初的使命出发，逐渐演变并最终偏离初衷，以及这种演变对其社会价值和遗产的影响

Method: 采用历史回顾与反思性分析的方法，通过追踪学术期刊的发展轨迹、社会影响变化以及最终消亡过程，构建期刊生命周期的理论框架

Result: 学术期刊的生命周期呈现复杂模式：初期对社会产生重要影响，但随着时间推移逐渐偏离原始使命，最终消亡时因其后期表现而获得的哀悼少于预期

Conclusion: 学术期刊的遗产评价具有双重性：人们怀念其最初代表的理想和价值，但对其后期偏离初衷的发展感到失望，这种矛盾决定了其在历史记忆中的复杂地位

Abstract: We reflect on the life and influence of the academic journal, charting their history and contributions, discussing how their influence changed society, and examining how in death they will be mourned for what they initially stood for but in the end had moved so far from that they will less missed than they might have been.

</details>


### [245] [Statistical Guarantees in the Search for Less Discriminatory Algorithms](https://arxiv.org/abs/2512.23943)
*Chris Hays,Ben Laufer,Solon Barocas,Manish Raghavan*

Main category: cs.CY

TL;DR: 本文提出了一种自适应停止算法，用于在寻找"较少歧视算法"时确定何时停止搜索，并提供高概率上界证明搜索充分性。


<details>
  <summary>Details</summary>
Motivation: 企业在高风险领域部署数据驱动决策系统时，需要寻找性能相当但歧视性更低的算法。虽然随机重训练可以找到这样的算法，但企业无法无限期搜索，需要确定什么是"善意努力"的充分搜索。

Method: 将LDA搜索形式化为最优停止问题，提出自适应停止算法，该算法能提供高概率上界来证明继续搜索的收益有限，从而证明搜索充分性。还提供了允许开发者施加更强假设的框架。

Result: 在真实世界的信贷、就业和住房数据集上验证了方法的有效性，能够为开发者提供可向法庭证明的搜索充分性认证。

Conclusion: 本文为解决企业在寻找较少歧视算法时的搜索充分性问题提供了理论框架和实用工具，使企业能够合理证明其搜索努力是充分的。

Abstract: Recent scholarship has argued that firms building data-driven decision systems in high-stakes domains like employment, credit, and housing should search for "less discriminatory algorithms" (LDAs) (Black et al., 2024). That is, for a given decision problem, firms considering deploying a model should make a good-faith effort to find equally performant models with lower disparate impact across social groups. Evidence from the literature on model multiplicity shows that randomness in training pipelines can lead to multiple models with the same performance, but meaningful variations in disparate impact. This suggests that developers can find LDAs simply by randomly retraining models. Firms cannot continue retraining forever, though, which raises the question: What constitutes a good-faith effort? In this paper, we formalize LDA search via model multiplicity as an optimal stopping problem, where a model developer with limited information wants to produce strong evidence that they have sufficiently explored the space of models. Our primary contribution is an adaptive stopping algorithm that yields a high-probability upper bound on the gains achievable from a continued search, allowing the developer to certify (e.g., to a court) that their search was sufficient. We provide a framework under which developers can impose stronger assumptions about the distribution of models, yielding correspondingly stronger bounds. We validate the method on real-world credit, employment and housing datasets.

</details>


### [246] [From artificial to circular intelligence to support the well-being of our habitat](https://arxiv.org/abs/2512.24131)
*Francesca Larosa,Daniel Depellegrin,Andrea Conte,Marco Molinari,Silvia Santato,Adam Wickberg,Fermin Mallor,Anna Sperotto*

Main category: cs.CY

TL;DR: 提出名为"循环智能"的新概念框架，通过自下而上、社区驱动的方法，从自然的再生和适应能力中学习，将伦理原则融入技术设计，以减少AI技术对地球的影响。


<details>
  <summary>Details</summary>
Motivation: 机器学习和人工智能的普及重新定义了人类与自然环境的互动关系。虽然监测工具、处理设施和物联网支持通过自动化评估地球健康，但这些数据密集型、资源密集型和基础设施密集型技术对地球并非中立。AI从业者社区正在努力创建具有最小社会环境影响工具，本文旨在为此做出贡献。

Method: 提出名为"循环智能"的新概念和程序框架。该框架采用自下而上、社区驱动的方法，从自然的再生和适应能力中学习。在技术设计中融入伦理原则，旨在保护栖息地的稳定性，同时通过设计提高居民的福祉。

Result: 提出了CIntel框架，这是一个创新的概念和程序框架，旨在解决AI技术对地球的负面影响。该框架通过模仿自然的再生和适应能力，将伦理原则融入技术设计，为创建更可持续的AI系统提供了新方法。

Conclusion: CIntel框架为AI从业者提供了一个新的范式，通过自下而上、社区驱动的方法，从自然中学习，将伦理原则融入技术设计，从而减少AI技术对地球的负面影响，同时提高人类福祉。这是向创建更可持续、更负责任的AI系统迈出的重要一步。

Abstract: The proliferation of machine learning and artificial intelligence redefines the interaction between the anthropogenic and natural elements of our habitat.The use of monitoring tools, processing facilities and the internet of things supports the assessment of planetary health at any given time through automation. However, these data, natural resources and infrastructure intensive technologies are not neutral on the Earth. As the community of AI practitioners works on the creation of tools with minimal socio-environmental impacts, we contribute to the these efforts by proposing a novel conceptual and procedural framework which we call Circular Intelligence or CIntel. CIntel leverages a bottom-up and community-driven approach to learn from the ability of nature to regenerate and adapt. CIntel incorporates ethical principles in its technical design to preserve the stability of the habitat, while also increasing the well-being of its inhabitants by design.

</details>


### [247] [Effects of Algorithmic Visibility on Conspiracy Communities: Reddit after Epstein's 'Suicide'](https://arxiv.org/abs/2512.24351)
*Asja Attanasio,Francesco Corso,Gianmarco De Francisci Morales,Francesco Pierri*

Main category: cs.CY

TL;DR: 算法可见性（如Reddit首页推荐）对阴谋论社区的影响：首页曝光吸引的用户与自然发现用户相比，融入度低、参与时间短、语言距离远，算法可见性更多是选择机制而非简单放大器。


<details>
  <summary>Details</summary>
Motivation: 研究算法可见性（特别是Reddit首页推荐）如何影响阴谋论社区r/conspiracy的用户行为，探究算法推荐是否会导致用户激进化，以及不同发现途径对用户参与度和社区动态的影响。

Method: 采用计算框架结合毒性评分、生存分析、词汇和语义测量，比较通过首页曝光和自然发现加入r/conspiracy的用户，分析他们的参与时长、语言适应性和社区融入度。

Result: 首页曝光的用户与核心话语语义距离较远，参与时间更短，融入度低；自然发现的用户更快适应社区语言规范，参与更稳定。算法可见性主要作为选择机制而非放大器，未发现偶然接触阴谋内容导致持久激进化的证据。

Conclusion: 算法可见性重塑了社区规模、组成和语言凝聚力，首页吸引的用户融入弱、离开快，限制了有机增长。这些发现可为设计更负责任的推荐系统提供参考，减少有害阴谋内容传播，同时支持透明有益的平台使用。

Abstract: This paper examines how algorithmic visibility shapes a large conspiracy community on Reddit after Jeffrey Epstein's death.
  We ask whether homepage exposure changes who join r/conspiracy, how long they stay, and how they adapt linguistically, compared with users who arrive through organic discovery.
  Using a computational framework that combines toxicity scores, survival analysis, and lexical and semantic measures, the study shows that homepage visibility acts as a selection mechanism rather than a simple amplifier.
  Users who discover the community organically integrate more quickly into its linguistic and thematic norms and show more stable engagement over time.
  By contrast, users who arrive through visibility on the homepage remain semantically distant from core discourse and participate more briefly.
  Overall, algorithmic visibility reshapes audience size, community composition, and linguistic cohesion:
  newcomers who do not join organically have different incentives, integrate weakly, and leave quickly, which limits organic growth.
  In this high-risk setting, the observed behavioral and linguistic trajectories over five months do not match standard narratives in which incidental exposure to conspiracy content produces durable radicalization.
  These findings can inform the design of web platforms and recommendation systems that seek to curb harmful conspiracy exposure while supporting more responsible, transparent, and socially beneficial uses of algorithmic recommendations.

</details>


### [248] [Learning Context: A Unified Framework and Roadmap for Context-Aware AI in Education](https://arxiv.org/abs/2512.24362)
*Naiming Liu,Brittany Bradford,Johaun Hatchett,Gabriel Diaz,Lorenzo Luzi,Zichao Wang,Debshila Basu Mallick,Richard Baraniuk*

Main category: cs.CY

TL;DR: 提出统一的"学习情境"框架，将AI教育从无情境模仿转向对学习者的整体理解，通过多学科方法编码认知、情感和社会文化因素，实现长期个性化学习。


<details>
  <summary>Details</summary>
Motivation: 当前AI教育系统缺乏对学习者情境的全面理解，只是进行无情境的模仿。需要从整体角度理解学习者，考虑认知、情感和社会文化等多维度因素，实现真正的个性化教育。

Method: 1. 提出统一的学习情境框架；2. 使用模型情境协议实现AI工具的"热启动"；3. 通过OpenStax数字学习平台生态系统实施；4. 在SafeInsights隐私保护数据环境中进行研究。

Result: 开发了一个可操作化的计算数据结构，能够编码短期、中期和长期的学习情境因素，支持数百万学习者的真实教育环境，同时确保隐私保护和伦理标准。

Conclusion: 学习情境框架为AI教育提供了从无情境模仿到整体理解的转变路径，通过隐私优先的实施策略，有望在全国范围内减少教育不平等，实现长期个性化学习。

Abstract: We introduce a unified Learning Context (LC) framework designed to transition AI-based education from context-blind mimicry to a principled, holistic understanding of the learner. This white paper provides a multidisciplinary roadmap for making teaching and learning systems context-aware by encoding cognitive, affective, and sociocultural factors over the short, medium, and long term. To realize this vision, we outline concrete steps to operationalize LC theory into an interoperable computational data structure. By leveraging the Model Context Protocol (MCP), we will enable a wide range of AI tools to "warm-start" with durable context and achieve continual, long-term personalization. Finally, we detail our particular LC implementation strategy through the OpenStax digital learning platform ecosystem and SafeInsights R&D infrastructure. Using OpenStax's national reach, we are embedding the LC into authentic educational settings to support millions of learners. All research and pedagogical interventions are conducted within SafeInsights' privacy-preserving data enclaves, ensuring a privacy-first implementation that maintains high ethical standards while reducing equity gaps nationwide.

</details>


### [249] [From Static to Dynamic: Evaluating the Perceptual Impact of Dynamic Elements in Urban Scenes Using Generative Inpainting](https://arxiv.org/abs/2512.24513)
*Zhiwei Wei,Mengzi Zhang,Boyan Lu,Zhitao Deng,Nai Yang,Hua Liao*

Main category: cs.CY

TL;DR: 该研究通过控制实验框架，使用语义分割和MLLM引导生成修复技术创建有/无行人和车辆的配对街景图像，量化动态元素对城市感知的影响，发现移除动态元素会导致活力感知下降30.97%，并开发模型预测城市尺度的感知变化。


<details>
  <summary>Details</summary>
Motivation: 现有城市感知研究大多将城市场景视为静态，忽略了行人和车辆等动态元素的作用，可能导致基于感知的城市分析存在偏差。需要量化动态元素对城市感知的具体影响。

Method: 提出控制实验框架：1) 使用语义分割和MLLM引导生成修复技术，构建有/无行人和车辆的配对街景图像；2) 基于720对东莞图像进行感知实验，评估六个感知维度；3) 训练11个机器学习模型分析视觉特征与感知变化的关系；4) 将模型扩展到城市尺度数据集预测感知变化。

Result: 移除动态元素导致活力感知一致下降30.97%，其他维度变化较温和且异质。光照条件、人类存在和深度变化是驱动感知变化的关键因素。65%参与者活力感知显著变化，性别对安全感知有边际调节作用。城市尺度分析显示73.7%位置和32.1%图像存在感知变化。

Conclusion: 动态元素对城市感知有显著影响，特别是对活力感知。仅基于静态图像的城市感知评估可能严重低估城市活力。研究为更准确的城市感知分析提供了方法论框架和实证证据。

Abstract: Understanding urban perception from street view imagery has become a central topic in urban analytics and human centered urban design. However, most existing studies treat urban scenes as static and largely ignore the role of dynamic elements such as pedestrians and vehicles, raising concerns about potential bias in perception based urban analysis. To address this issue, we propose a controlled framework that isolates the perceptual effects of dynamic elements by constructing paired street view images with and without pedestrians and vehicles using semantic segmentation and MLLM guided generative inpainting. Based on 720 paired images from Dongguan, China, a perception experiment was conducted in which participants evaluated original and edited scenes across six perceptual dimensions. The results indicate that removing dynamic elements leads to a consistent 30.97% decrease in perceived vibrancy, whereas changes in other dimensions are more moderate and heterogeneous. To further explore the underlying mechanisms, we trained 11 machine learning models using multimodal visual features and identified that lighting conditions, human presence, and depth variation were key factors driving perceptual change. At the individual level, 65% of participants exhibited significant vibrancy changes, compared with 35-50% for other dimensions; gender further showed a marginal moderating effect on safety perception. Beyond controlled experiments, the trained model was extended to a city-scale dataset to predict vibrancy changes after the removal of dynamic elements. The city level results reveal that such perceptual changes are widespread and spatially structured, affecting 73.7% of locations and 32.1% of images, suggesting that urban perception assessments based solely on static imagery may substantially underestimate urban liveliness.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [250] [Utility Maximisation with Model-independent Constraints](https://arxiv.org/abs/2512.24371)
*Alexander M. G. Cox,Daniel Hernandez-Hernandez*

Main category: q-fin.MF

TL;DR: 研究在金融市场上，考虑衍生品合约的投资者在最大化效用的同时，必须确保投资组合的盯市价值不低于给定阈值的问题。当盯市价值基于更悲观的估值方法（如模型无关边界）时，得到了一种新的优化问题，其中投资问题必须满足路径约束。


<details>
  <summary>Details</summary>
Motivation: 研究投资者在最大化效用时面临的现实约束问题。实际投资中，投资者不仅需要最大化期望效用，还必须确保投资组合的盯市价值始终保持在特定阈值以上，以避免追加保证金或强制平仓等风险。这种约束在衍生品交易中尤为重要，因为衍生品的估值可能基于不同的概率测度或估值方法。

Method: 对于完全市场，使用超鞅的max-plus分解方法推导最优终端财富的表达式。针对Black-Scholes-Merton模型，获得了该分解中涉及的显式过程形式。通过数值方法研究了在期权定价与投资者信念不一致情况下的最优投资组合。

Result: 在完全市场中得到了最优终端财富的解析表达式。对于Black-Scholes-Merton模型，获得了max-plus分解中过程的显式解。数值分析显示，当期权定价与投资者信念存在偏差时，最优投资组合会相应调整以同时满足效用最大化和盯市价值约束。

Conclusion: 该研究提出了一种考虑盯市价值约束的新型投资组合优化框架。当盯市估值基于悲观假设（如模型无关边界）时，问题转化为具有路径约束的优化问题。max-plus分解方法为解决这类问题提供了有效的数学工具，特别适用于衍生品投资中的风险管理问题。

Abstract: We consider an agent who has access to a financial market, including derivative contracts, who looks to maximise her utility. Whilst the agent looks to maximise utility over one probability measure, or class of probability measures, she must also ensure that the mark-to-market value of her portfolio remains above a given threshold. When the mark-to-market value is based on a more pessimistic valuation method, such as model-independent bounds, we recover a novel optimisation problem for the agent where the agents investment problem must satisfy a pathwise constraint.
  For complete markets, the expression of the optimal terminal wealth is given, using the max-plus decomposition for supermartingales. Moreover, for the Black-Scholes-Merton model the explicit form of the process involved in such decomposition is obtained, and we are able to investigate numerically optimal portfolios in the presence of options which are mispriced according to the agent's beliefs.

</details>


### [251] [Stochastic factors can matter: improving robust growth under ergodicity](https://arxiv.org/abs/2512.24906)
*Balint Binkert,David Itkin,Paul Mangers Bastian,Josef Teichmann*

Main category: q-fin.MF

TL;DR: 该论文研究在高维不完全市场中，面对资产收益率漂移不确定性时的稳健增长优化问题。通过引入随机因子和遍历性假设，构建了包含最坏情况模型的稳健投资组合策略，并证明了利用随机因子信息可以改善稳健增长表现。


<details>
  <summary>Details</summary>
Motivation: 资产收益率的漂移参数难以准确建模，而投资组合优化策略对此非常敏感。为了缓解这一经典问题，作者研究在漂移不确定性下的稳健增长优化，特别针对配对交易等应用场景，其中资产价格过程依赖于随机因子。

Method: 在允许资产价格X依赖于多元随机因子Y的模型类中，固定：(a)联合波动结构，(b)长期联合遍历密度，(c)随机因子过程Y的动态。在漂移不确定性下，通过求解特定偏微分方程来确定稳健最优增长率，构建最坏情况模型，并表征稳健增长最优策略。

Result: 确定了稳健最优增长率，构建了最坏情况可接受模型，并通过偏微分方程解表征了稳健增长最优策略。证明了利用随机因子信息可以改善稳健增长表现，这与之前Itkin等人的研究形成对比（后者对随机因子动态也进行稳健化处理，导致Y无关的最优策略）。

Conclusion: 该框架为投资者提供了量化工具，衡量通过最优纳入随机因子信息所能实现的增长改善。数值示例（包括配对交易应用）验证了理论结果，展示了在漂移不确定性下利用随机因子信息的重要价值。

Abstract: Drifts of asset returns are notoriously difficult to model accurately and, yet, trading strategies obtained from portfolio optimization are very sensitive to them. To mitigate this well-known phenomenon we study robust growth-optimization in a high-dimensional incomplete market under drift uncertainty of the asset price process $X$, under an additional ergodicity assumption, which constrains but does not fully specify the drift in general. The class of admissible models allows $X$ to depend on a multivariate stochastic factor $Y$ and fixes (a) their joint volatility structure, (b) their long-term joint ergodic density and (c) the dynamics of the stochastic factor process $Y$. A principal motivation of this framework comes from pairs trading, where $X$ is the spread process and models with the above characteristics are commonplace. Our main results determine the robust optimal growth rate, construct a worst-case admissible model and characterize the robust growth-optimal strategy via a solution to a certain partial differential equation (PDE). We demonstrate that utilizing the stochastic factor leads to improvement in robust growth complementing the conclusions of the previous study by Itkin et. al. (arXiv:2211.15628 [q-fin.MF], forthcoming in $\textit{Finance and Stochastics}$), which additionally robustified the dynamics of the stochastic factor leading to $Y$-independent optimal strategies. Our analysis leads to new financial insights, quantifying the improvement in growth the investor can achieve by optimally incorporating stochastic factors into their trading decisions. We illustrate our theoretical results on several numerical examples including an application to pairs trading.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [252] [Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting](https://arxiv.org/abs/2512.23805)
*Lars van der Laan,Nathan Kallus*

Main category: stat.ML

TL;DR: 提出一种改进的FQE方法，通过重加权回归步骤来对齐贝尔曼算子的收缩范数，从而避免对贝尔曼完备性的要求


<details>
  <summary>Details</summary>
Motivation: 标准FQE需要贝尔曼完备性假设（假设类在贝尔曼算子下封闭），这一要求具有挑战性，因为扩大假设类可能恶化完备性。问题根源在于范数不匹配：贝尔曼算子在目标策略的平稳分布下是γ-收缩的，而FQE在行为分布下最小化贝尔曼误差。

Method: 提出简单修正：在每次回归步骤中使用平稳密度比估计进行重加权，使FQE与贝尔曼算子收缩的范数对齐。这避免了标准FQE在缺乏可实现性或贝尔曼完备性时的几何误差放大问题。

Result: 该方法能够在没有可实现性或贝尔曼完备性的情况下提供强大的评估保证，同时保持基于回归评估的实用性。

Conclusion: 通过重加权回归步骤对齐范数，可以消除对贝尔曼完备性的需求，为离策略评估提供更稳健的FQE变体。

Abstract: Fitted Q-evaluation (FQE) is a central method for off-policy evaluation in reinforcement learning, but it generally requires Bellman completeness: that the hypothesis class is closed under the evaluation Bellman operator. This requirement is challenging because enlarging the hypothesis class can worsen completeness. We show that the need for this assumption stems from a fundamental norm mismatch: the Bellman operator is gamma-contractive under the stationary distribution of the target policy, whereas FQE minimizes Bellman error under the behavior distribution. We propose a simple fix: reweight each regression step using an estimate of the stationary density ratio, thereby aligning FQE with the norm in which the Bellman operator contracts. This enables strong evaluation guarantees in the absence of realizability or Bellman completeness, avoiding the geometric error blow-up of standard FQE in this setting while maintaining the practicality of regression-based evaluation.

</details>


### [253] [Energy-Tweedie: Score meets Score, Energy meets Energy](https://arxiv.org/abs/2512.23818)
*Andrej Leban*

Main category: stat.ML

TL;DR: 论文将Tweedie公式扩展到椭圆分布，建立了去噪后验与能量评分规则的联系，并推导出连接能量评分路径导数与噪声边缘分布评分的基本恒等式。


<details>
  <summary>Details</summary>
Motivation: 传统Tweedie公式主要适用于特定分布，而实际应用中需要处理更广泛的分布类型（能量模型/椭圆分布）。同时，去噪后验与评分规则之间存在深层联系，需要建立更通用的理论框架。

Method: 1. 将经典Tweedie公式扩展到椭圆分布族；2. 将去噪后验视为能量评分规则的最优化器；3. 推导连接能量评分路径导数与噪声边缘分布评分的基本恒等式。

Result: 建立了能量评分版本的Tweedie恒等式，为扩散模型提供了更广泛的噪声分布选择，支持评分估计、噪声分布参数估计等应用。

Conclusion: 该工作扩展了传统去噪与评分估计的理论框架，为使用非欧几里得能量评分模型和更广泛噪声分布的扩散模型采样器提供了理论基础。

Abstract: Denoising and score estimation have long been known to be linked via the classical Tweedie's formula. In this work, we first extend the latter to a wider range of distributions often called "energy models" and denoted elliptical distributions in this work. Next, we examine an alternative view: we consider the denoising posterior $P(X|Y)$ as the optimizer of the energy score (a scoring rule) and derive a fundamental identity that connects the (path-) derivative of a (possibly) non-Euclidean energy score to the score of the noisy marginal. This identity can be seen as an analog of Tweedie's identity for the energy score, and allows for several interesting applications; for example, score estimation, noise distribution parameter estimation, as well as using energy score models in the context of "traditional" diffusion model samplers with a wider array of noising distributions.

</details>


### [254] [Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration](https://arxiv.org/abs/2512.23927)
*Lars van der Laan,Nathan Kallus*

Main category: stat.ML

TL;DR: 论文分析了软FQI在函数逼近下的不稳定性，提出通过平稳分布重加权来恢复局部收敛性，并建议通过逐渐降低温度实现全局收敛。


<details>
  <summary>Details</summary>
Motivation: FQI和软FQI是离线强化学习的核心工具，但在函数逼近和分布偏移下表现不佳。研究发现软贝尔曼算子在软最优策略的平稳范数下是局部收缩的，而不是标准FQI使用的行为范数，这种几何不匹配解释了软Q迭代在缺乏贝尔曼完备性时的不稳定性。

Method: 提出平稳重加权软FQI，在每次回归更新中使用当前策略的平稳分布进行重加权。证明了在近似可实现性假设下，该方法在函数逼近下具有局部线性收敛性，且权重估计误差呈几何衰减。

Result: 理论分析表明，通过平稳重加权可以恢复软FQI的局部收敛性。进一步建议通过逐渐降低软最大温度可以实现全局收敛，并且在温和的边界条件下，这种延续方法可以扩展到硬最大极限。

Conclusion: 软FQI的不稳定性源于几何不匹配，平稳重加权方法可以解决这一问题。通过温度退火策略，该方法有望实现从软最大到硬最大策略的稳定收敛，为离线强化学习提供了更可靠的算法框架。

Abstract: Fitted Q-iteration (FQI) and its entropy-regularized variant, soft FQI, are central tools for value-based model-free offline reinforcement learning, but can behave poorly under function approximation and distribution shift. In the entropy-regularized setting, we show that the soft Bellman operator is locally contractive in the stationary norm of the soft-optimal policy, rather than in the behavior norm used by standard FQI. This geometric mismatch explains the instability of soft Q-iteration with function approximation in the absence of Bellman completeness. To restore contraction, we introduce stationary-reweighted soft FQI, which reweights each regression update using the stationary distribution of the current policy. We prove local linear convergence under function approximation with geometrically damped weight-estimation errors, assuming approximate realizability. Our analysis further suggests that global convergence may be recovered by gradually reducing the softmax temperature, and that this continuation approach can extend to the hardmax limit under a mild margin condition.

</details>


### [255] [Implicit geometric regularization in flow matching via density weighted Stein operators](https://arxiv.org/abs/2512.23956)
*Shinto Eguchi*

Main category: stat.ML

TL;DR: 提出γ-Flow Matching，一种密度加权的流匹配方法，通过动态密度加权策略在低密度区域降低回归损失，提高高维空间中的采样效率和向量场平滑度。


<details>
  <summary>Details</summary>
Motivation: 标准流匹配方法在环境空间中进行无加权的L²回归，但在高维空间中，大部分区域是低密度的"空洞"区域，这些区域的向量场往往混沌或定义不清，导致效率低下。

Method: 提出γ-Flow Matching，采用密度加权变体，通过动态密度加权策略直接从训练粒子估计目标密度，在空洞区域动态降低回归损失，同时保持流匹配的无模拟特性。

Result: γ-FM显著提高了高维潜在数据集上的向量场平滑度和采样效率，同时表现出对异常值的固有鲁棒性。

Conclusion: γ-Flow Matching通过密度加权策略有效解决了标准流匹配在高维空间中的效率问题，在统计流形上最小化传输成本，并引入隐式Sobolev正则化，改善了高维生成建模的性能。

Abstract: Flow Matching (FM) has emerged as a powerful paradigm for continuous normalizing flows, yet standard FM implicitly performs an unweighted $L^2$ regression over the entire ambient space. In high dimensions, this leads to a fundamental inefficiency: the vast majority of the integration domain consists of low-density ``void'' regions where the target velocity fields are often chaotic or ill-defined. In this paper, we propose {$γ$-Flow Matching ($γ$-FM)}, a density-weighted variant that aligns the regression geometry with the underlying probability flow. While density weighting is desirable, naive implementations would require evaluating the intractable target density. We circumvent this by introducing a Dynamic Density-Weighting strategy that estimates the \emph{target} density directly from training particles. This approach allows us to dynamically downweight the regression loss in void regions without compromising the simulation-free nature of FM. Theoretically, we establish that $γ$-FM minimizes the transport cost on a statistical manifold endowed with the $γ$-Stein metric. Spectral analysis further suggests that this geometry induces an implicit Sobolev regularization, effectively damping high-frequency oscillations in void regions. Empirically, $γ$-FM significantly improves vector field smoothness and sampling efficiency on high-dimensional latent datasets, while demonstrating intrinsic robustness to outliers.

</details>


### [256] [Constructive Approximation of Random Process via Stochastic Interpolation Neural Network Operators](https://arxiv.org/abs/2512.24106)
*Sachin Saini,Uaday Singh*

Main category: stat.ML

TL;DR: 提出随机插值神经网络算子(SINNOs)，证明其在均方、概率和路径意义下的有界性、插值精度和逼近能力，应用于COVID-19病例预测


<details>
  <summary>Details</summary>
Motivation: 开发能够有效逼近随机过程的神经网络方法，为随机过程建模提供新工具，特别针对COVID-19病例预测等实际应用

Method: 构造具有随机系数的随机插值神经网络算子(SINNOs)，使用sigmoidal激活函数，在L^2(Ω, F, P)空间中分析其数学性质

Result: 证明了SINNOs的有界性、插值精度和逼近能力，提供了基于过程连续模的定量误差估计

Conclusion: SINNOs是逼近随机过程的有效工具，在COVID-19预测等应用中具有潜力，为随机过程神经网络逼近提供了理论保证

Abstract: In this paper, we construct a class of stochastic interpolation neural network operators (SINNOs) with random coefficients activated by sigmoidal functions. We establish their boundedness, interpolation accuracy, and approximation capabilities in the mean square sense, in probability, as well as path-wise within the space of second-order stochastic (random) processes \( L^2(Ω, \mathcal{F},\mathbb{P}) \). Additionally, we provide quantitative error estimates using the modulus of continuity of the processes. These results highlight the effectiveness of SINNOs for approximating stochastic processes with potential applications in COVID-19 case prediction.

</details>


### [257] [Topological Spatial Graph Coarsening](https://arxiv.org/abs/2512.24327)
*Anna Calissano,Etienne Lasalle*

Main category: stat.ML

TL;DR: 提出一种基于拓扑保持的空间图粗化方法，通过折叠短边实现图简化，同时利用三角形感知图过滤来保留拓扑特征


<details>
  <summary>Details</summary>
Motivation: 空间图（如交通网络、分子结构）的简化需要保持其拓扑特征，但现有方法在简化过程中难以平衡图规模缩减与拓扑结构保留

Method: 提出拓扑空间图粗化框架，通过折叠短边实现图简化，引入三角形感知图过滤来构建拓扑描述符（持久图），无参数且具有旋转、平移和缩放等变性

Result: 在合成和真实空间图上验证，方法能显著减少图规模同时有效保留相关拓扑信息

Conclusion: 该方法为空间图简化提供了有效的拓扑保持解决方案，在保持关键结构特征的同时实现图规模缩减

Abstract: Spatial graphs are particular graphs for which the nodes are localized in space (e.g., public transport network, molecules, branching biological structures). In this work, we consider the problem of spatial graph reduction, that aims to find a smaller spatial graph (i.e., with less nodes) with the same overall structure as the initial one. In this context, performing the graph reduction while preserving the main topological features of the initial graph is particularly relevant, due to the additional spatial information. Thus, we propose a topological spatial graph coarsening approach based on a new framework that finds a trade-off between the graph reduction and the preservation of the topological characteristics. The coarsening is realized by collapsing short edges. In order to capture the topological information required to calibrate the reduction level, we adapt the construction of classical topological descriptors made for point clouds (the so-called persistent diagrams) to spatial graphs. This construction relies on the introduction of a new filtration called triangle-aware graph filtration. Our coarsening approach is parameter-free and we prove that it is equivariant under rotations, translations and scaling of the initial spatial graph. We evaluate the performances of our method on synthetic and real spatial graphs, and show that it significantly reduces the graph sizes while preserving the relevant topological information.

</details>


### [258] [Improving the stability of the covariance-controlled adaptive Langevin thermostat for large-scale Bayesian sampling](https://arxiv.org/abs/2512.24515)
*Jiani Wei,Xiaocheng Shang*

Main category: stat.ML

TL;DR: 提出改进的CCAdL（mCCAdL）恒温器，通过缩放和平方方法结合截断泰勒级数近似，提高数值稳定性，在保持计算效率的同时提升大规模机器学习应用的采样精度。


<details>
  <summary>Details</summary>
Motivation: 原始CCAdL恒温器虽然优于其他随机梯度方法，但其使用移动平均估计协方差矩阵的方法存在数值稳定性问题，限制了最大可用步长，影响实际应用效果。

Method: 提出mCCAdL恒温器：1）使用缩放和平方方法的缩放部分结合截断泰勒级数近似来数值逼近CCAdL中额外项的确切解；2）采用对称分裂方法而非原始CCAdL的欧拉型离散化。

Result: mCCAdL在数值稳定性方面相比原始CCAdL有显著提升，同时在大规模机器学习应用中，数值精度显著优于其他流行的随机梯度方法。

Conclusion: mCCAdL恒温器通过改进数值近似方法和离散化策略，有效解决了原始CCAdL的稳定性限制问题，为大规模贝叶斯采样提供了更稳定高效的算法。

Abstract: Stochastic gradient Langevin dynamics and its variants approximate the likelihood of an entire dataset, via random (and typically much smaller) subsets, in the setting of Bayesian sampling. Due to the (often substantial) improvement of the computational efficiency, they have been widely used in large-scale machine learning applications. It has been demonstrated that the so-called covariance-controlled adaptive Langevin (CCAdL) thermostat, which incorporates an additional term involving the covariance matrix of the noisy force, outperforms popular alternative methods. A moving average is used in CCAdL to estimate the covariance matrix of the noisy force, in which case the covariance matrix will converge to a constant matrix in long-time limit. Moreover, it appears in our numerical experiments that the use of a moving average could reduce the stability of the numerical integrators, thereby limiting the largest usable stepsize. In this article, we propose a modified CCAdL (i.e., mCCAdL) thermostat that uses the scaling part of the scaling and squaring method together with a truncated Taylor series approximation to the exponential to numerically approximate the exact solution to the subsystem involving the additional term proposed in CCAdL. We also propose a symmetric splitting method for mCCAdL, instead of an Euler-type discretisation used in the original CCAdL thermostat. We demonstrate in our numerical experiments that the newly proposed mCCAdL thermostat achieves a substantial improvement in the numerical stability over the original CCAdL thermostat, while significantly outperforming popular alternative stochastic gradient methods in terms of the numerical accuracy for large-scale machine learning applications.

</details>


### [259] [MultiRisk: Multiple Risk Control via Iterative Score Thresholding](https://arxiv.org/abs/2512.24587)
*Sunay Joshi,Yan Sun,Hamed Hassani,Edgar Dobriban*

Main category: stat.ML

TL;DR: 提出MULTIRISK算法，通过动态规划实现多风险约束的测试时过滤，在LLM对齐任务中有效控制多个安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统在实际应用中的部署，需要调节模型行为的多个维度。现有方法需要轻量级的行为控制机制，能够在测试时根据性能评分与估计阈值的比较来修改输出，同时满足用户定义优先级的多个风险约束。

Method: 提出两种高效的动态规划算法：MULTIRISK-BASE直接提供有限样本的阈值选择程序；MULTIRISK利用数据可交换性保证同时控制所有风险。通过引入中间对称风险函数和递归计数风险级别间的跳跃来上下界分析风险。

Result: 在基于PKU-SafeRLHF数据集的三约束LLM对齐任务中，使用LLM评判器和困惑度过滤器生成评分，实验结果显示算法能够将每个个体风险控制在接近目标水平。

Conclusion: MULTIRISK算法在温和假设下实现了几乎紧致的多风险约束控制，为生成式AI系统的实时行为调节提供了有效的轻量级解决方案。

Abstract: As generative AI systems are increasingly deployed in real-world applications, regulating multiple dimensions of model behavior has become essential. We focus on test-time filtering: a lightweight mechanism for behavior control that compares performance scores to estimated thresholds, and modifies outputs when these bounds are violated. We formalize the problem of enforcing multiple risk constraints with user-defined priorities, and introduce two efficient dynamic programming algorithms that leverage this sequential structure. The first, MULTIRISK-BASE, provides a direct finite-sample procedure for selecting thresholds, while the second, MULTIRISK, leverages data exchangeability to guarantee simultaneous control of the risks. Under mild assumptions, we show that MULTIRISK achieves nearly tight control of all constraint risks. The analysis requires an intricate iterative argument, upper bounding the risks by introducing several forms of intermediate symmetrized risk functions, and carefully lower bounding the risks by recursively counting jumps in symmetrized risk functions between appropriate risk levels. We evaluate our framework on a three-constraint Large Language Model alignment task using the PKU-SafeRLHF dataset, where the goal is to maximize helpfulness subject to multiple safety constraints, and where scores are generated by a Large Language Model judge and a perplexity filter. Our experimental results show that our algorithm can control each individual risk at close to the target level.

</details>


### [260] [Sparse Offline Reinforcement Learning with Corruption Robustness](https://arxiv.org/abs/2512.24768)
*Nam Phuong Tran,Andi Nika,Goran Radanovic,Long Tran-Thanh,Debmalya Mandal*

Main category: stat.ML

TL;DR: 该论文研究了高维稀疏马尔可夫决策过程中离线强化学习对强数据污染的鲁棒性，提出了避免使用逐点悲观奖励的演员-评论家方法，在单策略集中性覆盖和污染条件下首次提供了非空泛的保证。


<details>
  <summary>Details</summary>
Motivation: 在高维稀疏离线强化学习中，当样本数少于特征维度时，传统鲁棒方法可能失效。现有方法如LSVI在均匀覆盖下表现良好，但难以有效整合稀疏性，且在单策略集中性覆盖下分析可能失效。需要开发能在强数据污染下仍能学习近优策略的新方法。

Method: 提出基于稀疏鲁棒估计器oracle的演员-评论家方法，避免使用逐点悲观奖励。在均匀覆盖和稀疏单集中性假设下分析问题，将结果扩展到污染设置，证明算法在强污染下仍保持鲁棒性。

Result: 首次为稀疏离线强化学习在单策略集中性覆盖下提供了非空泛的保证。在传统鲁棒离线强化学习技术可能失效的机制中，学习近优策略仍然是可能的。算法在高维稀疏MDPs中具有鲁棒性。

Conclusion: 通过稀疏鲁棒估计器oracle的演员-批评家方法，成功解决了高维稀疏离线强化学习中的强数据污染问题，在单策略集中性覆盖和污染条件下实现了非空泛的性能保证，为传统方法可能失效的机制提供了可行的解决方案。

Abstract: We investigate robustness to strong data corruption in offline sparse reinforcement learning (RL). In our setting, an adversary may arbitrarily perturb a fraction of the collected trajectories from a high-dimensional but sparse Markov decision process, and our goal is to estimate a near optimal policy. The main challenge is that, in the high-dimensional regime where the number of samples $N$ is smaller than the feature dimension $d$, exploiting sparsity is essential for obtaining non-vacuous guarantees but has not been systematically studied in offline RL. We analyse the problem under uniform coverage and sparse single-concentrability assumptions. While Least Square Value Iteration (LSVI), a standard approach for robust offline RL, performs well under uniform coverage, we show that integrating sparsity into LSVI is unnatural, and its analysis may break down due to overly pessimistic bonuses. To overcome this, we propose actor-critic methods with sparse robust estimator oracles, which avoid the use of pointwise pessimistic bonuses and provide the first non-vacuous guarantees for sparse offline RL under single-policy concentrability coverage. Moreover, we extend our results to the contaminated setting and show that our algorithm remains robust under strong contamination. Our results provide the first non-vacuous guarantees in high-dimensional sparse MDPs with single-policy concentrability coverage and corruption, showing that learning a near-optimal policy remains possible in regimes where traditional robust offline RL techniques may fail.

</details>


### [261] [Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach](https://arxiv.org/abs/2512.24927)
*Yuchen Jiao,Na Li,Changxiao Cai,Gen Li*

Main category: stat.ML

TL;DR: 该论文挑战了高阶ODE求解器是加速扩散模型采样的唯一途径的观点，提出了一种训练免费的一阶采样器，通过优化DPM评估的时间点位置来提升采样质量。


<details>
  <summary>Details</summary>
Motivation: 当前普遍认为一阶方法天生较慢，增加离散化阶数是加速扩散模型采样的主要途径。本文挑战这一观点，认为除了求解器阶数外，DPM评估在反向时间动态中的位置安排对低NFE（神经函数评估）机制下的采样精度有重要影响。

Method: 提出了一种训练免费的一阶采样器，其主导离散化误差与DDIM的误差符号相反。算法上，该方法通过廉价的一步前瞻预测器来近似前向值评估。该方法在理论上保证能够近似理想的前向值轨迹，同时保持一阶收敛性。

Result: 在标准图像生成基准测试（CIFAR-10、ImageNet、FFHQ和LSUN）上，该采样器在相同的NFE预算下持续提升样本质量，能够与最先进的高阶采样器竞争，有时甚至超越它们。

Conclusion: 结果表明，DPM评估的位置安排为加速扩散采样提供了一个额外的、很大程度上独立的设计维度，挑战了高阶求解器是唯一加速途径的传统观点。

Abstract: Higher-order ODE solvers have become a standard tool for accelerating diffusion probabilistic model (DPM) sampling, motivating the widespread view that first-order methods are inherently slower and that increasing discretization order is the primary path to faster generation. This paper challenges this belief and revisits acceleration from a complementary angle: beyond solver order, the placement of DPM evaluations along the reverse-time dynamics can substantially affect sampling accuracy in the low-neural function evaluation (NFE) regime.
  We propose a novel training-free, first-order sampler whose leading discretization error has the opposite sign to that of DDIM. Algorithmically, the method approximates the forward-value evaluation via a cheap one-step lookahead predictor. We provide theoretical guarantees showing that the resulting sampler provably approximates the ideal forward-value trajectory while retaining first-order convergence. Empirically, across standard image generation benchmarks (CIFAR-10, ImageNet, FFHQ, and LSUN), the proposed sampler consistently improves sample quality under the same NFE budget and can be competitive with, and sometimes outperform, state-of-the-art higher-order samplers. Overall, the results suggest that the placement of DPM evaluations provides an additional and largely independent design angle for accelerating diffusion sampling.

</details>
