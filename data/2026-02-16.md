<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [math.OC](#math.OC) [Total: 17]
- [eess.SY](#eess.SY) [Total: 18]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.AI](#cs.AI) [Total: 19]
- [stat.ML](#stat.ML) [Total: 7]
- [cs.LG](#cs.LG) [Total: 97]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.CY](#cs.CY) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

TL;DR: 本文开发了一个轻量级、成本效益高的灾难推文分类框架，使用参数高效微调技术，在资源受限的应急环境中实现了79.62%的人道主义信息分类准确率，同时仅训练约2%的参数。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上人道主义信息的及时分类对于有效的灾难响应至关重要，但在资源受限的应急环境中部署大型语言模型面临挑战，需要开发轻量级、成本效益高的解决方案。

Method: 通过整合和标准化HumAID数据集（76,484条推文，涵盖19个灾难事件）构建统一实验语料库，形成双任务基准：人道主义信息分类和事件类型识别。系统评估了提示策略、LoRA微调和检索增强生成（RAG）在Llama 3.1 8B模型上的表现。

Result: LoRA实现了79.62%的人道主义分类准确率（比零样本学习提高37.79%），仅训练约2%的参数；QLoRA以50%的内存成本实现了LoRA性能的99.4%；与常见假设相反，RAG策略会降低微调模型的性能，因为检索到的示例会引入标签噪声。

Conclusion: 这些发现建立了一个实用、可复现的管道，用于在有限计算资源下构建可靠的危机情报系统，为资源受限环境中的灾难响应提供了有效的技术解决方案。

Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [2] [From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness](https://arxiv.org/abs/2602.12285)
*Linbo Cao,Lihao Sun,Yang Yue*

Main category: cs.CL

TL;DR: 研究发现：基于人口统计特征的角色分配会显著影响LLM智能体的行为表现，导致任务性能下降高达26.2%，揭示了当前LLM智能体系统的一个被忽视的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在文本生成中的角色诱导偏见已有研究，但这些偏见对智能体任务性能的影响尚未被充分探索。随着LLM越来越多地部署为具有现实世界影响的自主智能体，这种影响会带来更直接的操作风险。

Method: 通过系统性案例研究，评估广泛部署的LLM模型在战略推理、规划和技术操作等智能体基准测试上的表现，分析基于人口统计特征的角色分配如何影响智能体行为。

Result: 研究发现角色分配会导致LLM智能体行为显著变化和性能下降（最高达26.2%），这些变化跨越不同任务类型和模型架构，表明角色调节和简单提示注入会扭曲智能体的决策可靠性。

Conclusion: 角色分配会引入隐性偏见并增加行为波动性，这对LLM智能体的安全和稳健部署构成重要关切，揭示了当前LLM智能体系统的一个被忽视的脆弱性。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on agent task performance remain largely unexplored, even though such effects pose more direct operational risks. In this work, we present the first systematic case study showing that demographic-based persona assignments can alter LLM agents' behavior and degrade performance across diverse domains. Evaluating widely deployed models on agentic benchmarks spanning strategic reasoning, planning, and technical operations, we uncover substantial performance variations - up to 26.2% degradation, driven by task-irrelevant persona cues. These shifts appear across task types and model architectures, indicating that persona conditioning and simple prompt injections can distort an agent's decision-making reliability. Our findings reveal an overlooked vulnerability in current LLM agentic systems: persona assignments can introduce implicit biases and increase behavioral volatility, raising concerns for the safe and robust deployment of LLM agents.

</details>


### [3] [Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction](https://arxiv.org/abs/2602.12287)
*Junjie An,Jingguang Tian,Tianyi Wang,Yu Gao,Xiaofeng Mou,Yi Xu*

Main category: cs.CL

TL;DR: 提出检索增强生成框架，结合重述语言模型和自适应思维链推理，显著降低ASR中的命名实体错误率


<details>
  <summary>Details</summary>
Motivation: 端到端ASR系统经常错误识别领域特定短语如命名实体，可能导致下游任务灾难性失败。现有基于LLM的命名实体纠错方法尚未充分利用LLM的复杂推理能力。

Method: 提出检索增强生成框架：1) 重述语言模型进行命名实体识别，使用音素级编辑距离检索候选；2) 自适应思维链自学习推理模型，根据任务难度动态调整推理深度。

Result: 在AISHELL-1和Homophone数据集上，相比强基线，命名实体字符错误率分别相对降低17.96%和34.42%。

Conclusion: 提出的检索增强生成框架有效利用LLM的推理能力，显著改善了ASR系统中命名实体的纠错性能。

Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

</details>


### [4] [Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria à Prática](https://arxiv.org/abs/2602.12302)
*Neemias da Silva,Júlio C. W. Scholz,John Harrison,Marina Borges,Paulo Ávila,Frances A Santos,Myriam Delgado,Rodrigo Minetto,Thiago H Silva*

Main category: cs.CL

TL;DR: 本章介绍多模态大语言模型(MLLMs)的基础知识、代表性模型、实践技术（预处理、提示工程、LangChain/LangGraph构建多模态管道），并讨论挑战与趋势


<details>
  <summary>Details</summary>
Motivation: MLLMs结合了LLMs的自然语言理解生成能力与图像、音频等模态的感知技能，代表了当代AI的关键进展，需要系统介绍其理论与实践

Method: 介绍MLLMs基本原理和代表性模型，探索预处理、提示工程等实践技术，使用LangChain和LangGraph构建多模态管道，提供在线补充材料供实践学习

Result: 提供了MLLMs的全面介绍，包括理论框架、实践工具和公开可用的学习资源（GitHub仓库），为读者提供了从理论到实践的系统指导

Conclusion: 本章系统介绍了MLLMs的基础知识、实践技术和工具，讨论了当前挑战并展望了未来趋势，为相关研究和应用提供了有价值的参考

Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter presents the main fundamentals of MLLMs and emblematic models. Practical techniques for preprocessing, prompt engineering, and building multimodal pipelines with LangChain and LangGraph are also explored. For further practical study, supplementary material is publicly available online: https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica. Finally, the chapter discusses the challenges and highlights promising trends.

</details>


### [5] [propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale](https://arxiv.org/abs/2602.12414)
*Maximilian Idahl,Benedikt Droste,Björn Plüster,Jan Philipp Harries*

Main category: cs.CL

TL;DR: 提出了propella-1模型系列，用于多维度文本质量标注，替代传统单一质量评分方法，并发布了包含30亿文档标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前LLM预训练数据筛选主要依赖小型分类器产生的单一质量分数，这种方法存在三个主要问题：1）将多个质量维度混为一谈；2）无法进行灵活过滤；3）缺乏可解释性。

Method: 开发了propella-1系列小型多语言LLM（0.6B、1.7B、4B参数），能够为文本文档生成结构化JSON标注，涵盖18个属性，分为6个类别：核心内容、分类、质量与价值、受众与目的、安全与合规、地理相关性。支持57种语言。

Result: 4B模型与前沿商业LLM作为参考标注器相比，取得了更高的标注一致性，且优于更大的通用模型。发布了propella-annotations数据集，包含超过30亿文档标注，覆盖FineWeb-2、FinePDFs、HPLT 3.0、Nemotron-CC等主要预训练语料库。多维度分析揭示了传统单一评分方法无法捕捉的质量、推理深度和内容构成的显著差异。

Conclusion: propella-1模型提供了更精细、可解释的多维度文本质量评估方法，能够替代传统的单一评分系统，为LLM预训练数据筛选提供更灵活、更全面的工具。所有模型权重和标注数据都在商业使用许可下开源。

Abstract: Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.

</details>


### [6] [RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty](https://arxiv.org/abs/2602.12424)
*Ziqian Zhang,Xingjian Hu,Yue Huang,Kai Zhang,Ruoxi Chen,Yixin Liu,Qingsong Wen,Kaidi Xu,Xiangliang Zhang,Neil Zhenqiang Gong,Lichao Sun*

Main category: cs.CL

TL;DR: RankLLM是一个新颖的LLM评估框架，通过双向分数传播机制量化问题难度和模型能力，实现更细粒度的模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法区分问题难度，限制了它们有效区分模型能力的能力。需要一种能够量化问题难度和模型能力的评估框架。

Method: 提出RankLLM框架，以难度为主要区分标准，通过双向分数传播机制：模型正确回答问题获得能力分数，问题挑战模型则增加难度分数。

Result: 在30个模型和35,550个问题上进行评估，与人类判断达到90%一致，优于IRT等基线方法，表现出强稳定性、快速收敛和高计算效率。

Conclusion: RankLLM是一个实用的大规模、难度感知的LLM评估解决方案，能够实现更细粒度的模型能力评估。

Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.

</details>


### [7] [RBCorr: Response Bias Correction in Language Models](https://arxiv.org/abs/2602.12445)
*Om Bhatt,Anna A. Ivanova*

Main category: cs.CL

TL;DR: 提出RBCorr方法，通过简单策略校正语言模型的响应偏见，在12个开源模型上验证有效性，显著提升性能并消除偏见。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在响应偏见，表现为固定回答问题的选项偏好偏见。需要开发低成本有效的校正方法，以提升模型性能并更准确评估模型能力。

Method: 提出RBCorr响应偏见校正策略，在12个开源语言模型上测试，应用于是非题、蕴含题和多项选择题。探索偏见行为在模型、数据集和提示格式间的泛化性。

Result: 校正前响应偏见普遍存在，RBCorr能有效消除偏见并提升模型性能。基于LogProbs的校正高度依赖于模型、数据集和提示格式三方面。

Conclusion: RBCorr是易用的方法，能提升小模型性能，确保闭式回答基准测试结果更贴近模型真实能力。

Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.

</details>


### [8] [Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification](https://arxiv.org/abs/2602.12575)
*Bo Wang,Yuxuan Zhang,Yueqin Hu,Hanchao Hou,Kaiping Peng,Shiguang Ni*

Main category: cs.CL

TL;DR: 提出基于主题建模的语义结构框架，用于无响应数据的量表简化，通过语义聚类发现潜在结构，平均减少60.5%量表长度同时保持心理测量学特性。


<details>
  <summary>Details</summary>
Motivation: 传统量表优化方法（如因素分析、项目反应理论）需要大量样本数据，且受数据可得性和跨文化可比性限制。自然语言处理进展表明问卷项目的语义结构可能编码潜在构念组织，提供了一种无需响应数据的补充视角。

Method: 引入主题建模框架：使用上下文句子嵌入编码项目，通过基于密度的聚类发现潜在语义因素（无需预设数量），基于类别的术语加权获得可解释的主题表示，在集成简化流程中使用成员资格标准选择代表性项目。

Result: 在DASS、IPIP和EPOCH量表上验证：框架恢复了与既有构念一致的因素式分组，所选项目平均减少60.5%量表长度同时保持心理测量学充分性，简化量表与原量表因子结构高度一致且保持因子间相关性。

Conclusion: 语义潜在组织提供了测量结构的无响应近似，该框架将语义结构形式化为量表构建和简化的可检查前端，提供可视化支持工具实现一键语义分析和结构化简化。

Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.

</details>


### [9] [Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635)
*Pengxiang Zhao,Hui-Ling Zhen,Xing Li,Han Bao,Weizhe Lin,Zhiyuan Yang,Ziwei Yu,Xin Wang,Mingxuan Yuan,Xianzhi Yu,Zhenhua Dong*

Main category: cs.CL

TL;DR: HiFloat浮点格式（HiF8和HiF4）专为昇腾NPU设计，在LLM推理中相比整数格式能更好地处理高方差数据，4位版本能避免精度崩溃，且与现有量化框架兼容。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，需要低精度浮点格式（如MXFP和NVFP4）来提升推理效率和精度。本文针对昇腾NPU设计专门的浮点格式，解决现有格式在特定场景下的局限性。

Method: 提出HiFloat格式家族（HiF8和HiF4），专为昇腾NPU优化。通过权重-激活和KV缓存任务的系统评估，比较不同格式在窄范围数据和高方差数据上的表现，分析4位精度下的性能差异。

Result: 三个关键发现：1）INT8适合窄范围数据，浮点格式在高方差数据上表现更优；2）4位精度下，HiF4的分层缩放能避免整数格式出现的精度崩溃；3）HiFloat与最先进的后训练量化框架完全兼容。

Conclusion: HiFloat为昇腾NPU上的高效LLM推理提供了有效解决方案，在保持精度的同时提升计算效率，特别是在处理高方差数据和4位量化场景下表现突出。

Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.

</details>


### [10] [CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation](https://arxiv.org/abs/2602.12639)
*Yiran Rex Ma,Yuxiao Ye,Huiyuan Xie*

Main category: cs.CL

TL;DR: CLASE：一种专注于法律文本风格评估的混合评估方法，结合语言特征评分和经验引导的LLM评分，在中文法律文档上比传统指标和纯LLM方法更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的法律文本虽然事实准确性尚可，但经常无法遵循法律写作的专业风格规范和语言惯例。建立可靠的评估方法是改进风格质量的关键第一步，但现有方法存在局限：人工制定指标不现实，基于参考的指标混淆语义准确性和风格保真度，LLM-as-a-judge评估存在不透明和不一致问题。

Method: CLASE采用混合评估方法，包含：1）基于语言特征的评分，2）经验引导的LLM-as-a-judge评分。特征系数和LLM评分经验都是从真实法律文档与其LLM恢复版本的对比对中学习得到的。这种混合设计以透明、无参考的方式捕捉表面特征和隐含风格规范。

Result: 在200份中文法律文档上的实验表明，CLASE比传统指标和纯LLM-as-a-judge方法显著更符合人类判断。除了更好的对齐性，CLASE还提供可解释的分数分解和改进建议。

Conclusion: CLASE为法律文本生成中的专业风格评估提供了一个可扩展且实用的解决方案，能够透明地评估法律文本的风格表现，并提供可解释的反馈。

Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).

</details>


### [11] [Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR](https://arxiv.org/abs/2602.12642)
*Dohyung Kim,Minbeom Kim,Jeonghye Kim,Sangmook Lee,Sojeong Rhee,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出PACED-RL框架，利用GFlowNets训练中的分区函数作为每提示预期奖励信号，提高LLM分布匹配训练的样本效率


<details>
  <summary>Details</summary>
Motivation: 传统奖励最大化RL方法会降低LLM输出的多样性，而现有GFlowNets方法将分区函数仅视为归一化因子，未能充分利用其包含的每提示准确率信息

Method: 提出PACED-RL框架：1) 建立分区函数与每提示准确率估计的理论关系；2) 利用准确率估计优先选择信息丰富的提示进行训练；3) 通过准确率估计误差优先回放进一步提高样本效率

Result: 在多个基准测试中，PACED-RL相比GRPO和先前GFlowNets方法表现出显著的性能提升，验证了其作为更高效LLM分布匹配训练方向的潜力

Conclusion: 将分区函数重新解释为每提示预期奖励信号，并利用该信息指导训练过程，能够在不增加计算开销的情况下显著提高LLM分布匹配训练的样本效率

Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its partition function. In contrast to prior works that treat this partition function solely as a normalizer, we reinterpret it as a per-prompt expected-reward (i.e., online accuracy) signal, leveraging this unused information to improve sample efficiency. Specifically, we first establish a theoretical relationship between the partition function and per-prompt accuracy estimates. Building on this key insight, we propose Partition Function-Guided RL (PACED-RL), a post-training framework that leverages accuracy estimates to prioritize informative question prompts during training, and further improves sample efficiency through an accuracy estimate error-prioritized replay. Crucially, both components reuse information already produced during GFlowNet training, effectively amortizing the compute overhead into the existing optimization process. Extensive experiments across diverse benchmarks demonstrate strong performance improvements over GRPO and prior GFlowNet approaches, highlighting PACED-RL as a promising direction for a more sample efficient distribution-matching training for LLMs.

</details>


### [12] [Learning Ordinal Probabilistic Reward from Preferences](https://arxiv.org/abs/2602.12660)
*Longze Chen,Lu Wang,Renke Shan,Ze Gong,Run Luo,Jiaming Li,Jing Luo,Qiyao Wang,Min Yang*

Main category: cs.CL

TL;DR: 提出概率奖励模型(PRM)，将奖励视为随机变量而非确定标量，通过离散化实现为有序概率奖励模型(OPRM)，结合区域淹没调优(RgFT)提升数据效率和绝对质量评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型存在局限性：生成式奖励模型(GRMs)需要昂贵的逐点监督，判别式奖励模型(DRMs)产生未校准的相对分数且缺乏概率解释。需要一种既能反映绝对文本质量又具有概率解释的奖励建模方法。

Method: 1. 提出概率奖励模型(PRM)范式，将奖励视为随机变量，学习每个响应的完整概率分布；2. 实现为有序概率奖励模型(OPRM)，将质量分数离散化为有限有序评级；3. 提出区域淹没调优(RgFT)训练策略，利用质量级别标注引导概率质量集中在相应评级子区域内。

Result: 在多个奖励模型基准测试中，该方法比现有奖励模型准确率提高2.9%∼7.4%，表现出强大的性能和数据效率。分数分布分析表明该方法不仅能捕捉相对排名，还能捕获绝对质量。

Conclusion: 概率奖励模型(PRM)通过将奖励建模为随机变量，结合有序离散化和区域淹没调优，解决了现有奖励模型的局限性，提供了更好的概率解释、数据效率和绝对质量评估能力。

Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand costly point-wise supervision, while DRMs produce uncalibrated relative scores that lack probabilistic interpretation. To address these challenges, we introduce a novel reward modeling paradigm: Probabilistic Reward Model (PRM). Instead of modeling reward as a deterministic scalar, our approach treats it as a random variable, learning a full probability distribution for the quality of each response. To make this paradigm practical, we present its closed-form, discrete realization: the Ordinal Probabilistic Reward Model (OPRM), which discretizes the quality score into a finite set of ordinal ratings. Building on OPRM, we propose a data-efficient training strategy called Region Flooding Tuning (RgFT). It enables rewards to better reflect absolute text quality by incorporating quality-level annotations, which guide the model to concentrate the probability mass within corresponding rating sub-regions. Experiments on various reward model benchmarks show that our method improves accuracy by $\textbf{2.9%}\sim\textbf{7.4%}$ compared to prior reward models, demonstrating strong performance and data efficiency. Analysis of the score distribution provides evidence that our method captures not only relative rankings but also absolute quality.

</details>


### [13] [$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2602.12674)
*Yuang Cai,Yuyu Yuan*

Main category: cs.CL

TL;DR: 提出X-KD框架，通过让学生模型在教师模型的原始学习环境中学习，超越传统模仿教师行为的蒸馏方法，在多个任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法主要关注模仿教师模型的行为，但忽略了塑造教师知识的原始学习环境。受体验式学习理论和逆强化学习启发，希望让学生模型在教师模型的原始学习环境中学习，以获得更好的知识迁移效果。

Method: 提出Experiential Knowledge Distillation (X-KD)框架，采用近似变分奖励模仿学习(AVRIL)来联合建模教师原始奖励函数并执行策略蒸馏，鼓励学生策略与原始奖励函数的一致性。该框架遵循监督学习范式，适用于序列级和基于散度的蒸馏方法。

Result: 在抽象摘要、机器翻译和算术推理任务上，X-KD超越了广义KD和MiniLLM基线方法。同时，X-KD在性能-多样性权衡和数据效率方面都优于基线KD方法。

Conclusion: X-KD通过让学生模型在教师模型的原始学习环境中学习，提供了一种简单灵活的知识蒸馏框架，在多个任务上取得了更好的性能，并改善了性能-多样性权衡和数据效率。

Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.

</details>


### [14] [MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs](https://arxiv.org/abs/2602.12705)
*Baorong Shi,Bo Cui,Boyuan Jiang,Deli Yu,Fang Qian,Haihua Yang,Huichao Wang,Jiale Chen,Jianfei Pan,Jieqiong Cao,Jinghao Lin,Kai Wu,Lin Yang,Shengsheng Yao,Tao Chen,Xiaojun Xiao,Xiaozhong Ji,Xu Wang,Yijun He,Zhixiong Yang*

Main category: cs.CL

TL;DR: MedXIAOHE是一个医学视觉语言基础模型，通过实体感知持续预训练、强化学习和工具增强代理训练，在多个医学基准测试中达到SOTA性能，并超越闭源多模态系统。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在真实临床应用中推进通用医学理解和推理的医学视觉语言基础模型，解决异构医学数据整合、罕见病知识覆盖、医学专家级推理和真实世界可靠性等问题。

Method: 1) 实体感知持续预训练框架，组织异构医学语料库以扩展知识覆盖并减少长尾差距；2) 通过强化学习和工具增强代理训练整合多样化医学推理模式；3) 集成用户偏好标准、证据基础推理和低幻觉长文本报告生成以提高可靠性。

Result: 在多样化医学基准测试中达到最先进的性能，在多项能力上超越领先的闭源多模态系统，实现了多步诊断推理和可验证的决策轨迹。

Conclusion: MedXIAOHE通过创新的训练框架和方法，成功构建了一个在真实临床应用中具有强大理解和推理能力的医学视觉语言基础模型，为未来研究提供了实践设计选择、扩展洞察和评估框架。

Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source multimodal systems on multiple capabilities. To achieve this, we propose an entity-aware continual pretraining framework that organizes heterogeneous medical corpora to broaden knowledge coverage and reduce long-tail gaps (e.g., rare diseases). For medical expert-level reasoning and interaction, MedXIAOHE incorporates diverse medical reasoning patterns via reinforcement learning and tool-augmented agentic training, enabling multi-step diagnostic reasoning with verifiable decision traces. To improve reliability in real-world use, MedXIAOHE integrates user-preference rubrics, evidence-grounded reasoning, and low-hallucination long-form report generation, with improved adherence to medical instructions. We release this report to document our practical design choices, scaling insights, and evaluation framework, hoping to inspire further research.

</details>


### [15] [ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter](https://arxiv.org/abs/2602.12709)
*Yixin Chen,Ying Xiong,Shangyu Wu,Xiangrui Ke,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: ReFilter是一个新的检索增强生成框架，通过token级过滤和融合解决传统方法在检索规模扩大时性能下降的问题，在多个QA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在检索规模扩大时面临挑战：虽然增加检索数量(k)能提高证据覆盖率，但不可避免地会包含不相关或冗余内容，同时增加推理成本。传统方法（查询融合、参数融合、潜在融合）在检索规模较小时有效，但在k增大时无法优雅扩展。

Method: ReFilter是一个基于潜在表示的融合框架，包含三个核心组件：上下文编码器（编码上下文特征）、门控过滤器（为每个token分配权重）、token融合模块（将加权token特征集成到LLM的隐藏状态中）。该方法在token级别进行过滤和融合。

Result: 在四个通用领域QA基准测试中，ReFilter在领域内适应和跨领域迁移方面都取得了最佳平均性能。在五个生物医学QA基准测试中，使用Qwen2.5-14B-Instruct模型进行零样本迁移（无需领域微调）达到了70.01%的平均准确率。

Conclusion: ReFilter通过token级过滤和融合有效解决了检索增强生成在扩大检索规模时的扩展性问题，在多个领域展现了优异的性能和泛化能力。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where existing internal fusion approaches broadly fall into query-based fusion, parametric fusion, and latent-based fusion. Despite their effectiveness at modest retrieval scales, these methods often fail to scale gracefully as the number of retrieved candidates k increases: Larger k improves evidence coverage, yet realistic top-k retrieval inevitably contains irrelevant or redundant content and increases the inference cost.
  To address these limitations, we propose ReFilter, a novel latent-based fusion framework that performs token-level filtering and fusion. ReFilter consists of three key components: a context encoder for encoding context features, a gated filter for weighting each token, and a token fusion module for integrating the weighted token feature into the LLM's hidden states. Our experiments across four general-domain QA benchmarks show that ReFilter consistently achieves the best average performance under both in-domain adaptation and out-of-domain transfer. ReFilter further generalizes to five biomedical QA benchmarks in zero-shot transfer without domain fine-tuning, reaching 70.01% average accuracy with Qwen2.5-14B-Instruct.

</details>


### [16] [Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting](https://arxiv.org/abs/2602.12746)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: 提出Lamer-SSL框架，通过Layer-Aware MixturE of LoRA Experts模块和重放策略，以参数高效的方式解决自监督语音模型在多语言持续学习中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 自监督语音模型在新语言上泛化能力有限，且在持续训练中容易遗忘先前学到的知识，需要参数高效的解决方案来平衡共享表示和语言特定表示

Method: 结合Layer-Aware Mixture of LoRA Experts（Lamer）模块和重放策略。Lamer模块通过LoRA专家混合实现共享和语言特定表示的灵活平衡，层感知专家分配为语义信息更丰富的深层分配更多专家；重放策略使用少量数据保留先前知识

Result: 在自动语音识别（ASR）和语言识别（LID）任务上，Lamer-SSL能够有效将自监督模型扩展到新语言，同时保持对先前学习语言的强性能，仅需训练2.14%的参数

Conclusion: Lamer-SSL为自监督语音模型的多语言持续学习提供了参数高效的解决方案，有效平衡了模型扩展和知识保留

Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.

</details>


### [17] [Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks](https://arxiv.org/abs/2602.12759)
*Elena Alvarez-Mellado,Julio Gonzalo*

Main category: cs.CL

TL;DR: 提出一种基于错误分析的序列标注任务评估方法，通过手工构建小型语言动机测试集来提供诊断性、可操作性和预测性的评估结果。


<details>
  <summary>Details</summary>
Motivation: 传统NLP评估只表明系统A平均优于系统B，但缺乏如何改进性能的信息，且无法预测在外部数据上的表现。需要一种能提供定量和定性信息、指导改进并预测不同分布性能的评估方法。

Method: 创建不依赖大量真实世界数据的测试集，而是手工构建小型语言动机示例集，全面覆盖系统可能遇到的各种跨度属性（形状、长度、大小写、句子位置等）。在西班牙语英语借词识别基准上演示该方法。

Result: 该方法提供诊断性结果（识别系统性弱点）、可操作性结果（指导选择适合场景的模型）和预测性结果：预测模型在外部数据集上的表现，中位相关系数达0.85。

Conclusion: 提出的评估方法通过手工构建语言动机测试集，为序列标注任务提供了更全面、实用和预测性强的评估框架，超越了传统平均性能比较的局限性。

Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside data. We propose an evaluation methodology for sequence labeling tasks grounded on error analysis that provides both quantitative and qualitative information on where systems must be improved and predicts how models will perform on a different distribution. The key is to create test sets that, contrary to common practice, do not rely on gathering large amounts of real-world in-distribution scraped data, but consists in handcrafting a small set of linguistically motivated examples that exhaustively cover the range of span attributes (such as shape, length, casing, sentence position, etc.) a system may encounter in the wild. We demonstrate this methodology on a benchmark for anglicism identification in Spanish. Our methodology provides results that are diagnostic (because they help identify systematic weaknesses in performance), actionable (because they can inform which model is better suited for a given scenario) and predictive: our method predicts model performance on external datasets with a median correlation of 0.85.

</details>


### [18] [Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews](https://arxiv.org/abs/2602.12778)
*Hamidreza Kazemi Taskooh,Taha Zare Harofte*

Main category: cs.CL

TL;DR: 提出用于波斯语旅游评论的混合BERT模型，结合Top-K路由和辅助损失，在低资源语言环境下实现高效的情感分析，F1分数达90.6%，能耗降低39%。


<details>
  <summary>Details</summary>
Motivation: 针对波斯语等低资源语言在旅游领域缺乏情感分析研究的问题，开发高效可持续的ABSA模型，支持联合国可持续发展目标。

Method: 采用三阶段混合BERT模型：1)整体情感分类；2)多标签方面提取（6个旅游相关方面）；3)集成ABSA与动态路由，使用Top-K路由和辅助损失防止路由崩溃。

Result: 模型在58,473条波斯语旅游评论数据集上取得90.6%的加权F1分数，优于基线BERT（89.25%）和标准混合方法（85.7%），GPU能耗降低39%。清洁度和设施是最常提及的方面。

Conclusion: 这是首个针对波斯语旅游评论的ABSA研究，提出的混合模型在保持性能的同时显著降低能耗，为低资源语言NLP研究提供了新方法和公开数据集。

Abstract: This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxiliary losses to mitigate routing collapse and improve efficiency. The pipeline includes: (1) overall sentiment classification using BERT on 9,558 labeled reviews, (2) multi-label aspect extraction for six tourism-related aspects (host, price, location, amenities, cleanliness, connectivity), and (3) integrated ABSA with dynamic routing. The dataset consists of 58,473 preprocessed reviews from the Iranian accommodation platform Jabama, manually annotated for aspects and sentiments. The proposed model achieves a weighted F1-score of 90.6% for ABSA, outperforming baseline BERT (89.25%) and a standard hybrid approach (85.7%). Key efficiency gains include a 39% reduction in GPU power consumption compared to dense BERT, supporting sustainable AI deployment in alignment with UN SDGs 9 and 12. Analysis reveals high mention rates for cleanliness and amenities as critical aspects. This is the first ABSA study focused on Persian tourism reviews, and we release the annotated dataset to facilitate future multilingual NLP research in tourism.

</details>


### [19] [RAT-Bench: A Comprehensive Benchmark for Text Anonymization](https://arxiv.org/abs/2602.12806)
*Nataša Krčo,Zexi Yao,Matthieu Meeus,Yves-Alexandre de Montjoye*

Main category: cs.CL

TL;DR: RAT-Bench是一个基于重识别风险的文本匿名化工具基准测试，发现现有工具在防止重识别方面远非完美，LLM-based匿名化工具提供更好的隐私-效用权衡但计算成本更高。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化工具（如Microsoft Presidio、Anthropic PII purifier）通常只评估其移除特定标识符的能力，但它们在防止重识别方面的有效性尚不清楚。需要建立一个基于重识别风险的全面基准来评估这些工具的实际隐私保护效果。

Method: 引入RAT-Bench基准，使用美国人口统计数据生成包含各种直接和间接标识符的合成文本，涵盖不同领域、语言和难度级别。评估基于NER和LLM的文本匿名化工具，基于LLM攻击者从匿名化文本中正确推断属性的能力，报告在美国人口中的重识别风险，并适当考虑标识符的不同影响。

Result: 工具能力差异很大，即使是最好的工具也远非完美，特别是在直接标识符非标准书写和间接标识符能够实现重识别的情况下。LLM-based匿名化工具（包括新的迭代匿名化器）提供更好的隐私-效用权衡，但计算成本更高，且在不同语言中表现良好。

Conclusion: 需要改进未来的匿名化工具，建议发布基准并鼓励社区扩展，特别是扩展到其他地理区域。LLM-based方法在隐私保护方面表现更好，但需要平衡计算成本。

Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.

</details>


### [20] [Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence](https://arxiv.org/abs/2602.12811)
*Laurent Bonnasse-Gahot,Christophe Pallier*

Main category: cs.CL

TL;DR: 研究发现LLM训练过程中脑预测能力的左右不对称性与形式语言能力共同出现，而非算术、世界知识或推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索LLM训练过程中脑活动预测能力左右不对称性（左半球优于右半球）与何种语言模型能力相关。

Method: 使用OLMo-2 7B和Pythia模型在不同训练检查点，结合英语和法语fMRI数据，比较脑预测不对称性与多种基准测试表现的相关性。

Result: 脑预测左右不对称性与LLM的形式语言能力（语法判断和文本生成）共同出现，但与算术、Dyck语言任务、世界知识和推理任务表现无关。

Conclusion: LLM训练中脑预测能力的左右不对称性反映了形式语言模式知识的进展，而非一般认知能力。

Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand which kind of competence acquired by the LLMs underlies the emergence of this left-right asymmetry. Using the OLMo-2 7B language model at various training checkpoints and fMRI data from English participants, we compare the evolution of the left-right asymmetry in brain scores alongside performance on several benchmarks. We observe that the asymmetry co-emerges with the formal linguistic abilities of the LLM. These abilities are demonstrated in two ways: by the model's capacity to assign a higher probability to an acceptable sentence than to a grammatically unacceptable one within a minimal contrasting pair, or its ability to produce well-formed text. On the opposite, the left-right asymmetry does not correlate with the performance on arithmetic or Dyck language tasks; nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal linguistic competence (knowledge of linguistic patterns).

</details>


### [21] [AIWizards at MULTIPRIDE: A Hierarchical Approach to Slur Reclamation Detection](https://arxiv.org/abs/2602.12818)
*Luca Tedeschini,Matteo Fasulo*

Main category: cs.CL

TL;DR: 本文提出一个分层方法检测回收的侮辱性词汇，通过用户身份建模来区分侮辱性使用和群体内肯定性使用。


<details>
  <summary>Details</summary>
Motivation: 回收的侮辱性词汇检测是仇恨言论检测系统的根本挑战，因为相同的词汇可能作为侮辱性表达，也可能作为群体内肯定性表达，这取决于社会身份和上下文。

Method: 采用分层方法：第一阶段使用弱监督LLM标注用户属于LGBTQ+社区的可能性，训练BERT-like模型学习身份相关表示；第二阶段将该潜在空间与仇恨言论检测预训练模型融合，用于下游的侮辱性词汇回收检测任务。

Result: 在意大利语和西班牙语上的实验结果表明，该方法性能与强大的BERT基线统计相当，同时提供了一个模块化、可扩展的框架，将社会语言学上下文融入仇恨言论建模。

Conclusion: 更细粒度的用户身份和话语上下文分层建模可能进一步提高回收语言的检测效果。该方法为将社会语言学背景融入仇恨言论建模提供了模块化框架。

Abstract: Detecting reclaimed slurs represents a fundamental challenge for hate speech detection systems, as the same lexcal items can function either as abusive expressions or as in-group affirmations depending on social identity and context. In this work, we address Subtask B of the MultiPRIDE shared task at EVALITA 2026 by proposing a hierarchical approach to modeling the slur reclamation process. Our core assumption is that members of the LGBTQ+ community are more likely, on average, to employ certain slurs in a eclamatory manner. Based on this hypothesis, we decompose the task into two stages. First, using a weakly supervised LLM-based annotation, we assign fuzzy labels to users indicating the likelihood of belonging to the LGBTQ+ community, inferred from the tweet and the user bio. These soft labels are then used to train a BERT-like model to predict community membership, encouraging the model to learn latent representations associated with LGBTQ+ identity. In the second stage, we integrate this latent space with a newly initialized model for the downstream slur reclamation detection task. The intuition is that the first model encodes user-oriented sociolinguistic signals, which are then fused with representations learned by a model pretrained for hate speech detection. Experimental results on Italian and Spanish show that our approach achieves performance statistically comparable to a strong BERT-based baseline, while providing a modular and extensible framework for incorporating sociolinguistic context into hate speech modeling. We argue that more fine-grained hierarchical modeling of user identity and discourse context may further improve the detection of reclaimed language. We release our code at https://github.com/LucaTedeschini/multipride.

</details>


### [22] [MentalBench: A Benchmark for Evaluating Psychiatric Diagnostic Capability of Large Language Models](https://arxiv.org/abs/2602.12871)
*Hoyun Song,Migyeong Kang,Jisu Shin,Jihyun Kim,Chanbi Park,Hangyeol Yoo,Jihyun An,Alice Oh,Jinyoung Han,KyungTae Lim*

Main category: cs.CL

TL;DR: MentalBench是一个评估大语言模型精神病学诊断决策能力的基准，包含MentalKG知识图谱和24,750个合成临床案例，发现LLMs在DSM-5知识方面表现良好但在临床重叠疾病的诊断决策中校准信心困难。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康基准主要依赖社交媒体数据，无法评估基于DSM的诊断判断能力，需要更系统、低噪声的评估框架来测试LLMs在精神病学诊断决策中的表现。

Method: 构建MentalKG知识图谱（编码DSM-5诊断标准和鉴别诊断规则），基于此生成24,750个合成临床案例，系统变化信息完整性和诊断复杂性，实现可解释的低噪声评估。

Result: 最先进的LLMs在结构化查询DSM-5知识时表现良好，但在区分临床重叠疾病时的诊断决策中难以校准信心，揭示了现有基准未能捕捉的评估差距。

Conclusion: MentalBench填补了现有心理健康基准的空白，揭示了LLMs在精神病学诊断决策中的局限性，特别是在处理临床重叠疾病时的信心校准问题。

Abstract: We introduce MentalBench, a benchmark for evaluating psychiatric diagnostic decision-making in large language models (LLMs). Existing mental health benchmarks largely rely on social media data, limiting their ability to assess DSM-grounded diagnostic judgments. At the core of MentalBench is MentalKG, a psychiatrist-built and validated knowledge graph encoding DSM-5 diagnostic criteria and differential diagnostic rules for 23 psychiatric disorders. Using MentalKG as a golden-standard logical backbone, we generate 24,750 synthetic clinical cases that systematically vary in information completeness and diagnostic complexity, enabling low-noise and interpretable evaluation. Our experiments show that while state-of-the-art LLMs perform well on structured queries probing DSM-5 knowledge, they struggle to calibrate confidence in diagnostic decision-making when distinguishing between clinically overlapping disorders. These findings reveal evaluation gaps not captured by existing benchmarks.

</details>


### [23] [BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.12889)
*Jiangxi Chen,Qian Liu*

Main category: cs.CL

TL;DR: BaziQA-Benchmark：一个用于评估大语言模型符号和时序组合推理能力的标准化基准，基于200个专业编制的八字竞赛题目，包含结构化推理和时间条件交互。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多为轶事性或提示驱动的，缺乏客观评分和跨年份、领域、模型家族的受控比较。需要标准化基准来评估大语言模型在符号和时序组合推理方面的能力。

Method: 从全球八字竞赛（2021-2025）中提取200个专业编制的多选题，每个实例都需要在固定符号图表和交互时间条件下进行结构化推理。引入轻量级结构化推理协议来约束推理顺序而不增加领域知识。

Result: 模型表现持续优于随机猜测但远未达到饱和，对时序组合和推理顺序表现出明显敏感性，在精确时间定位和多条件符号判断方面存在系统性失败。

Conclusion: BaziQA-Benchmark为评估大语言模型的符号和时序推理能力提供了标准化工具，揭示了模型在这些复杂推理任务中的局限性，特别是在处理精确时间定位和多条件判断方面。

Abstract: We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.

</details>


### [24] [ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset & Benchmark](https://arxiv.org/abs/2602.12911)
*Tung X. Nguyen,Nhu Vo,Giang-Son Nguyen,Duy Mai Hoang,Chien Dinh Huynh,Inigo Jauregi Unanue,Massimo Piccardi,Wray Buntine,Dung D. Le*

Main category: cs.CL

TL;DR: 构建首个越南医疗代码转换语音数据集ViMedCSS，评估多种ASR模型，发现越南优化模型在通用部分表现更好，而多语言预训练有助于识别英语插入词，两者结合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 越南医疗交流中常出现英语医学术语代码转换现象，这对ASR系统构成挑战，尤其是低资源语言如越南语。现有ASR系统难以正确识别越南语句中的英语医学术语，且缺乏相关基准数据集。

Method: 构建34小时越南医疗代码转换语音数据集ViMedCSS（16,576条话语），包含至少一个英语医学术语，涵盖五个医疗主题。评估多种SOTA ASR模型，研究特定微调策略以改进医学术语识别。

Result: 越南优化模型在通用部分表现更好，多语言预训练有助于捕捉英语插入词。两者结合的方法在整体准确率和代码转换准确率之间达到最佳平衡。

Conclusion: 该工作提供了首个越南医疗代码转换基准，为低资源多语言ASR系统的有效领域适应提供了见解。

Abstract: Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in low-resource languages like Vietnamese. Current most ASR systems struggle to recognize correctly English medical terms within Vietnamese sentences, and no benchmark addresses this challenge. In this paper, we construct a 34-hour \textbf{Vi}etnamese \textbf{Med}ical \textbf{C}ode-\textbf{S}witching \textbf{S}peech dataset (ViMedCSS) containing 16,576 utterances. Each utterance includes at least one English medical term drawn from a curated bilingual lexicon covering five medical topics. Using this dataset, we evaluate several state-of-the-art ASR models and examine different specific fine-tuning strategies for improving medical term recognition to investigate the best approach to solve in the dataset. Experimental results show that Vietnamese-optimized models perform better on general segments, while multilingual pretraining helps capture English insertions. The combination of both approaches yields the best balance between overall and code-switched accuracy. This work provides the first benchmark for Vietnamese medical code-switching and offers insights into effective domain adaptation for low-resource, multilingual ASR systems.

</details>


### [25] [When Words Don't Mean What They Say: Figurative Understanding in Bengali Idioms](https://arxiv.org/abs/2602.12921)
*Adib Sakhawat,Shamim Ara Parveen,Md Ruhul Amin,Shamim Al Mahmud,Md Saiful Islam,Tahera Khatun*

Main category: cs.CL

TL;DR: 论文提出了一个包含10,361个孟加拉语成语的大规模数据集，并评估了30个LLM在理解孟加拉语比喻语言方面的表现，发现模型准确率不足50%，远低于人类表现(83.4%)。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在理解比喻语言方面存在挑战，特别是对于低资源语言。目前缺乏针对孟加拉语等低资源语言的综合性比喻语言理解数据集和基准测试。

Method: 1) 创建大规模孟加拉语成语数据集(10,361个)，采用包含19个字段的全面标注方案；2) 通过专家共识过程建立和优化标注模式；3) 评估30个最先进的多语言和指令调优LLM在推断比喻意义任务上的表现。

Result: 所有评估的LLM表现都不理想，没有模型超过50%准确率，与人类83.4%的准确率形成鲜明对比。这突显了现有模型在跨语言和文化推理方面的局限性。

Conclusion: 通过发布新的成语数据集和基准测试，为推进孟加拉语和其他低资源语言的比喻语言理解和文化基础提供了基础设施，揭示了LLM在跨文化语言理解方面的重要差距。

Abstract: Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali idioms. Each idiom is annotated under a comprehensive 19-field schema, established and refined through a deliberative expert consensus process, that captures its semantic, syntactic, cultural, and religious dimensions, providing a rich, structured resource for computational linguistics. To establish a robust benchmark for Bangla figurative language understanding, we evaluate 30 state-of-the-art multilingual and instruction-tuned LLMs on the task of inferring figurative meaning. Our results reveal a critical performance gap, with no model surpassing 50% accuracy, a stark contrast to significantly higher human performance (83.4%). This underscores the limitations of existing models in cross-linguistic and cultural reasoning. By releasing the new idiom dataset and benchmark, we provide foundational infrastructure for advancing figurative language understanding and cultural grounding in LLMs for Bengali and other low-resource languages.

</details>


### [26] [Curriculum Learning and Pseudo-Labeling Improve the Generalization of Multi-Label Arabic Dialect Identification Models](https://arxiv.org/abs/2602.12937)
*Ali Mekky,Mohamed El Zeftawy,Lara Hassan,Amr Keleg,Preslav Nakov*

Main category: cs.CL

TL;DR: 该论文提出了一种多标签阿拉伯方言识别方法，通过GPT-4o和方言可接受性分类器构建多标签数据集，并采用课程学习策略训练BERT模型，显著提升了多标签阿拉伯方言识别的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言识别长期被建模为单标签分类任务，但实际应作为多标签分类问题。然而，目前缺乏大规模多标签数据集，且现有单标签数据集难以直接用于多标签识别，主要困难在于负样本选择问题。

Method: 1. 使用GPT-4o和方言可接受性二元分类器自动生成多标签标注，通过阿拉伯方言程度（ALDi）指导聚合；2. 采用课程学习策略，根据方言复杂度和标签基数训练BERT多标签分类器。

Result: 提出的LAHJATBERT模型在多标签阿拉伯方言识别排行榜上达到0.69的宏观F1分数，相比之前最强系统的0.55有显著提升。

Conclusion: 通过自动生成多标签数据集和课程学习策略，成功解决了多标签阿拉伯方言识别中的数据稀缺问题，显著提升了模型性能，为阿拉伯方言识别研究提供了新方向。

Abstract: Being modeled as a single-label classification task for a long time, recent work has argued that Arabic Dialect Identification (ADI) should be framed as a multi-label classification task. However, ADI remains constrained by the availability of single-label datasets, with no large-scale multi-label resources available for training. By analyzing models trained on single-label ADI data, we show that the main difficulty in repurposing such datasets for Multi-Label Arabic Dialect Identification (MLADI) lies in the selection of negative samples, as many sentences treated as negative could be acceptable in multiple dialects. To address these issues, we construct a multi-label dataset by generating automatic multi-label annotations using GPT-4o and binary dialect acceptability classifiers, with aggregation guided by the Arabic Level of Dialectness (ALDi). Afterward, we train a BERT-based multi-label classifier using curriculum learning strategies aligned with dialectal complexity and label cardinality. On the MLADI leaderboard, our best-performing LAHJATBERT model achieves a macro F1 of 0.69, compared to 0.55 for the strongest previously reported system. Code and data are available at https://mohamedalaa9.github.io/lahjatbert/.

</details>


### [27] [ProbeLLM: Automating Principled Diagnosis of LLM Failures](https://arxiv.org/abs/2602.12966)
*Yue Huang,Zhengzhe Jiang,Yuchen Ma,Yu Jiang,Xiangqi Wang,Yujun Zhou,Yuexing Hao,Kehan Guo,Pin-Yu Chen,Stefan Feuerriegel,Xiangliang Zhang*

Main category: cs.CL

TL;DR: ProbeLLM是一个基准无关的自动化探测框架，通过分层蒙特卡洛树搜索将弱点发现从个别失败案例提升到结构化失败模式


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速演进，静态评估方法已跟不上发展速度。现有自动化探测方法通常只能发现孤立的失败案例，缺乏对探索的原则性控制，对模型弱点底层结构提供有限洞察

Method: 采用分层蒙特卡洛树搜索，在全局探索新失败区域和局部细化重复错误模式之间分配有限探测预算；通过可验证测试案例、工具增强生成和验证来确保失败发现的可靠性；使用失败感知嵌入和边界感知归纳将发现的失败整合为可解释的失败模式

Result: 在多样化基准和大语言模型上，ProbeLLM相比静态基准和先前自动化方法，揭示了更广泛、更清晰、更细粒度的失败景观

Conclusion: ProbeLLM支持从以案例为中心的评估向原则性弱点发现的转变，为理解大语言模型失败提供了更系统化的方法

Abstract: Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.

</details>


### [28] [SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents](https://arxiv.org/abs/2602.12984)
*Yujiong Shen,Yajie Yang,Zhiheng Xi,Binze Hu,Huayu Sha,Jiazheng Zhang,Qiyuan Peng,Junlin Shang,Jixuan Huang,Yutao Fan,Jingqi Tong,Shihan Dou,Ming Zhang,Lei Bai,Zhenfei Yin,Tao Gui,Xingjun Ma,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: SciAgentGym是一个包含1780个领域特定工具的科学推理环境，SciAgentBench用于评估智能体能力，研究发现当前模型在复杂科学工具使用上存在瓶颈，提出的SciForge方法通过依赖图生成训练轨迹，使8B模型超越235B模型


<details>
  <summary>Details</summary>
Motivation: 当前基准测试忽视了智能体在科学推理中协调使用领域特定工具的能力，需要建立能够评估智能体在复杂科学工作流中工具使用能力的系统

Method: 1. 构建SciAgentGym环境，包含1780个跨四个自然科学领域的工具；2. 开发SciAgentBench分层评估套件；3. 提出SciForge数据合成方法，将工具动作空间建模为依赖图来生成逻辑感知的训练轨迹

Result: 当前最先进模型在复杂科学工具使用上表现不佳，GPT-5的成功率从60.6%降至30.9%；通过SciForge方法微调的SciAgent-8B模型超越了Qwen3-VL-235B-Instruct，并展现出跨领域的科学工具使用能力迁移

Conclusion: 科学推理需要智能体能够有效协调领域特定工具，提出的SciAgentGym环境和SciForge训练方法为解决这一挑战提供了有效途径，展示了下一代自主科学智能体的潜力

Abstract: Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.

</details>


### [29] [Evaluating the Homogeneity of Keyphrase Prediction Models](https://arxiv.org/abs/2602.12989)
*Maël Houbre,Florian Boudin,Beatrice Daille*

Main category: cs.CL

TL;DR: 研究评估关键词预测模型的同质性，发现关键词抽取方法在预测同质性方面与生成模型竞争，且生成缺失关键词的能力可能对同质性产生负面影响


<details>
  <summary>Details</summary>
Motivation: 当前基准测试未覆盖关键词预测模型的同质性评估。关键词生成模型能预测文档中未出现的"缺失关键词"，理论上应使处理相同主题的文档获得更一致的关键词预测，但这一假设缺乏验证

Method: 引入评估关键词预测模型同质性的方法，比较关键词抽取方法和生成模型在同质性方面的表现，特别研究生成缺失关键词能力对同质性的影响

Result: 令人惊讶的是，关键词抽取方法在预测同质性方面与生成模型竞争，且生成缺失关键词的能力实际上可能对同质性产生负面影响

Conclusion: 关键词生成模型的缺失关键词生成能力并不必然提高预测同质性，关键词抽取方法在同质性方面表现有竞争力，需要重新评估生成模型在这方面的优势

Abstract: Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.

</details>


### [30] [Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models](https://arxiv.org/abs/2602.12996)
*Hao Chen,Ye He,Yuchun Fan,Yukun Yan,Zhenghao Liu,Qingfu Zhu,Maosong Sun,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出一种基于元认知的知识增强框架，通过区分干预和对齐来解决LLM中的知识-置信度差距问题，提升可靠性和认知校准


<details>
  <summary>Details</summary>
Motivation: 现有知识增强方法通常假设模型性能等同于内部知识，忽略了知识-置信度差距导致的过度自信错误或不确定真理问题，需要更可靠的知识增强框架

Method: 提出元认知框架，利用内部认知信号将知识空间划分为掌握、混淆和缺失区域，指导针对性知识扩展；引入认知一致性机制同步主观确定性与客观准确性，确保校准的知识边界

Result: 大量实验表明该框架持续优于强基线，不仅验证了其在增强知识能力方面的合理性，还促进了更好区分已知与未知的认知行为

Conclusion: 该元认知框架通过差异化干预和对齐，有效解决了知识-置信度差距问题，实现了更可靠的知识增强和认知校准

Abstract: Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal knowledge, overlooking the knowledge-confidence gaps that lead to overconfident errors or uncertain truths. To bridge this gap, we propose a novel meta-cognitive framework for reliable knowledge augmentation via differentiated intervention and alignment. Our approach leverages internal cognitive signals to partition the knowledge space into mastered, confused, and missing regions, guiding targeted knowledge expansion. Furthermore, we introduce a cognitive consistency mechanism to synchronize subjective certainty with objective accuracy, ensuring calibrated knowledge boundaries. Extensive experiments demonstrate the our framework consistently outperforms strong baselines, validating its rationality in not only enhancing knowledge capabilities but also fostering cognitive behaviors that better distinguish knowns from unknowns.

</details>


### [31] [Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech](https://arxiv.org/abs/2602.13047)
*Madhurananda Pahar,Caitlin Illingworth,Dorota Braun,Bahman Mirheidari,Lise Sproson,Daniel Blackburn,Heidi Christensen*

Main category: cs.CL

TL;DR: 研究发现AI模型在检测认知障碍时对英国少数族裔多语使用者存在偏见，特别是南约克郡口音者更容易被误判为认知衰退更严重，现有AI工具尚不能可靠用于这些人群的诊断。


<details>
  <summary>Details</summary>
Motivation: 英国四分之一人口属于少数族裔，痴呆症患病率在黑人及亚洲社区预计增长最快。研究旨在评估AI模型在检测认知障碍时对多语使用者的偏见问题，确保这些工具具有临床益处。

Method: 招募全国性单语参与者和谢菲尔德、布拉德福德四个社区中心的多语使用者。多语者除非英语母语口音外，还讲索马里语、中文或南亚语言，并进一步分为西约克郡和南约克郡两种口音。使用声学和语言特征进行分类和回归模型分析，并与公开的DementiaBank数据集训练结果对比。

Result: ASR系统在各组间无显著偏见，但使用声学和语言特征的分类和回归模型对多语使用者存在偏见，尤其在记忆、流畅性和阅读任务中。使用DementiaBank数据集训练时偏见更明显。多语者更容易被误判为认知衰退，南约克郡口音者更可能被误判为认知衰退更严重。

Conclusion: 尽管AI模型整体性能良好，但首次发现其对英国少数族裔多语使用者存在偏见，现有AI工具尚不能可靠用于这些人群的诊断。未来工作将开发更具普适性、偏见缓解的模型。

Abstract: Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities. This study examines the trustworthiness of AI models, specifically the presence of bias, in detecting healthy multilingual English speakers among the cognitively impaired cohort, to make these tools clinically beneficial. For experiments, monolingual participants were recruited nationally (UK), and multilingual speakers were enrolled from four community centres in Sheffield and Bradford. In addition to a non-native English accent, multilinguals spoke Somali, Chinese, or South Asian languages, who were further divided into two Yorkshire accents (West and South) to challenge the efficiency of the AI tools thoroughly. Although ASR systems showed no significant bias across groups, classification and regression models using acoustic and linguistic features exhibited bias against multilingual speakers, particularly in memory, fluency, and reading tasks. This bias was more pronounced when models were trained on the publicly available DementiaBank dataset. Moreover, multilinguals were more likely to be misclassified as having cognitive decline. This study is the first of its kind to discover that, despite their strong overall performance, current AI models show bias against multilingual individuals from ethnic minority backgrounds in the UK, and they are also more likely to misclassify speakers with a certain accent (South Yorkshire) as living with a more severe cognitive decline. In this pilot study, we conclude that the existing AI tools are therefore not yet reliable for diagnostic use in these populations, and we aim to address this in future work by developing more generalisable, bias-mitigated models.

</details>


### [32] [TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution](https://arxiv.org/abs/2602.13059)
*Tejas Anvekar,Junha Park,Rajat Jha,Devanshu Gupta,Poojah Ganesan,Puneeth Mathur,Vivek Gupta*

Main category: cs.CL

TL;DR: TraceBack是一个用于表格问答的多智能体框架，提供细粒度单元格级归因，通过FairScore指标实现可解释评估。


<details>
  <summary>Details</summary>
Motivation: 现有表格QA系统缺乏细粒度归因，即使答案正确也难以验证其支持依据，限制了在高风险场景中的可信度。

Method: TraceBack采用模块化多智能体框架：修剪表格到相关行列、将问题分解为语义连贯的子问题、将答案片段与支持单元格对齐，捕捉显式和隐式证据。

Result: TraceBack在多个数据集和粒度上显著优于基线方法，FairScore指标与人工判断高度一致，能保持方法相对排名。

Conclusion: TraceBack提供了可扩展的单元格级归因解决方案，FairScore支持可解释和可扩展的表格QA评估，增强了表格问答的可信度和透明度。

Abstract: Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.

</details>


### [33] [Exploring a New Competency Modeling Process with Large Language Models](https://arxiv.org/abs/2602.13084)
*Silin Du,Manqing Xin,Raymond Jia Wang*

Main category: cs.CL

TL;DR: 提出基于大语言模型的新能力建模框架，将传统专家驱动方法转化为数据驱动的可评估分析过程


<details>
  <summary>Details</summary>
Motivation: 传统能力建模方法依赖专家手动分析大量访谈记录，成本高、随机性强、模糊且可重复性有限，需要更系统化的解决方案

Method: 利用LLMs从原始文本数据中提取行为和心理学描述，通过嵌入相似性映射到预定义能力库，引入可学习参数自适应整合不同信息源，并开发离线评估程序进行系统模型选择

Result: 在软件外包公司的实际应用中展示了强大的预测效度、跨库一致性和结构稳健性

Conclusion: 该框架将能力建模从定性、依赖专家的实践转变为透明、数据驱动且可评估的分析过程

Abstract: Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and prone to randomness, ambiguity, and limited reproducibility. This study proposes a new competency modeling process built on large language models (LLMs). Instead of merely automating isolated steps, we reconstruct the workflow by decomposing expert practices into structured computational components. Specifically, we leverage LLMs to extract behavioral and psychological descriptions from raw textual data and map them to predefined competency libraries through embedding-based similarity. We further introduce a learnable parameter that adaptively integrates different information sources, enabling the model to determine the relative importance of behavioral and psychological signals. To address the long-standing challenge of validation, we develop an offline evaluation procedure that allows systematic model selection without requiring additional large-scale data collection. Empirical results from a real-world implementation in a software outsourcing company demonstrate strong predictive validity, cross-library consistency, and structural robustness. Overall, our framework transforms competency modeling from a largely qualitative and expert-dependent practice into a transparent, data-driven, and evaluable analytical process.

</details>


### [34] [Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts](https://arxiv.org/abs/2602.13102)
*Kais Allkivi*

Main category: cs.CL

TL;DR: 该研究通过精心选择语言学特征（词汇、形态、表层、错误特征）构建可解释的机器学习模型，用于爱沙尼亚语水平考试写作（A2-C1级）的自动分类，准确率达0.9，并将结果应用于开源语言学习环境。


<details>
  <summary>Details</summary>
Motivation: 利用NLP分析真实学习者语言可构建自动评估反馈工具并提供二语发展的新见解，但目前缺乏将这两方面结合的研究。研究旨在通过精心特征选择构建更可解释和可泛化的语言测试机器学习模型。

Method: 分析爱沙尼亚语水平考试写作训练数据的各种语言学特性，识别与复杂度、正确性相关的熟练度预测因子（而非写作任务本身）。使用词汇、形态、表层和错误特征训练分类模型，并与允许其他特征的模型进行比较。

Result: 预选特征获得相似的测试准确率（约0.9），但减少了对不同文本类型的分类变异。对早期考试样本的评估显示，写作在7-10年间变得更复杂，而某些特征集的准确率仍达0.8。

Conclusion: 精心选择的语言学特征可构建准确且可解释的语言熟练度分类模型，结果已成功应用于爱沙尼亚开源语言学习环境的写作评估模块，为自动语言评估提供了有效方法。

Abstract: Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.

</details>


### [35] [SCOPE: Selective Conformal Optimized Pairwise LLM Judging](https://arxiv.org/abs/2602.13110)
*Sher Badshah,Ali Emami,Hassan Sajjad*

Main category: cs.CL

TL;DR: SCOPE框架通过选择性校准和双向偏好熵(BPE)为LLM作为评判者提供有限样本统计保证，在控制错误率的同时提高覆盖率。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者替代人工标注虽然实用，但存在校准不足和系统性偏差问题，需要一种能提供统计保证的可靠评估框架。

Method: 提出SCOPE框架，在可交换性假设下校准接受阈值，确保非弃权判断的错误率不超过用户指定水平α。引入BPE作为偏差中立的信号，通过双向查询和熵转换获得不确定性评分。

Result: 在MT-Bench、RewardBench和Chatbot Arena上，BPE优于标准置信度代理，SCOPE在所有基准和评判尺度上均满足风险界限(α=0.10时风险≈0.097-0.099)，同时保持高覆盖率(Qwen-14B达0.89，Qwen-32B达0.98)。

Conclusion: SCOPE框架结合BPE能够为LLM评判提供可靠且高覆盖率的评估，相比朴素基线在相同风险约束下可接受更多判断，实现了统计保证下的实用LLM评估。

Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, \textsc{Scope} consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, \textsc{Scope} accepts up to $2.4\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.

</details>


### [36] [From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media](https://arxiv.org/abs/2602.13123)
*Maria Ryskina,Matthew R. Gormley,Kyle Mahowald,David R. Mortensen,Taylor Berg-Kirkpatrick,Vivek Kulkarni*

Main category: cs.CL

TL;DR: 研究比较了英语新词在历史出版文本和Twitter社交媒体中的形成机制，发现相同的因素影响两个领域的新词创造，但主题流行度增长在Twitter中的作用较小


<details>
  <summary>Details</summary>
Motivation: 语言演化受到内部和外部压力的影响，不同社交和对话语境（如报纸与社交媒体）存在不同的约束。先前研究主要基于历史出版文本，需要扩展到社交媒体领域验证新词形成机制的普适性

Method: 扩展先前研究方法，将静态嵌入扩展到上下文嵌入，应用于Twitter帖子语料库，分析新词形成的相关因素

Result: 相同的研究发现在两个领域都成立，但主题流行度增长因素在Twitter中对新词创造的贡献可能小于出版文本

Conclusion: 两个领域可能偏好不同的新词形成机制，Twitter与出版文本在新词创造上存在差异，但核心影响因素保持一致

Abstract: Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language use in newspapers is subject to very different constraints than language use on social media. Prior distributional semantic work on English word emergence (neology) identified two factors correlated with creation of new words by analyzing a corpus consisting primarily of historical published texts (Ryskina et al., 2020, arXiv:2001.07740). Extending this methodology to contextual embeddings in addition to static ones and applying it to a new corpus of Twitter posts, we show that the same findings hold for both domains, though the topic popularity growth factor may contribute less to neology on Twitter than in published writing. We hypothesize that this difference can be explained by the two domains favouring different neologism formation mechanisms.

</details>


### [37] [OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report](https://arxiv.org/abs/2602.13139)
*Mariia Fedorova,Nikolay Arefyev,Maja Buljan,Jindřich Helcl,Stephan Oepen,Egil Rønningstad,Yves Scherrer*

Main category: cs.CL

TL;DR: OpenLID-v3 是 OpenLID 语言识别工具的升级版，通过增加训练数据、合并问题语言变体集群和引入噪声标签，在识别相近语言和区分自然语言与噪声方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别工具（如 OpenLID 或 GlotLID）在识别相近语言和区分有效自然语言与噪声方面存在困难，这污染了语言特定子集，特别是对于低资源语言。

Method: 扩展 OpenLID 分类器：1）增加更多训练数据；2）合并有问题的语言变体集群；3）引入特殊标签来标记噪声。重点关注三组相近语言（波斯尼亚语、克罗地亚语和塞尔维亚语；意大利北部和法国南部的罗曼语变体；斯堪的纳维亚语言），并贡献新的评估数据集。

Result: OpenLID-v3 在多个基准测试中评估优于 GlotLID。发现集成方法提高了精度，但也显著降低了低资源语言的覆盖率。

Conclusion: OpenLID-v3 是一个改进的语言识别系统，在识别相近语言和过滤噪声方面表现更好，已开源发布在 Hugging Face 上。

Abstract: Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.

</details>


### [38] [Semantic Chunking and the Entropy of Natural Language](https://arxiv.org/abs/2602.13194)
*Weishun Zhong,Doron Sivan,Tankut Can,Mikhail Katkov,Misha Tsodyks*

Main category: cs.CL

TL;DR: 该论文提出了一种统计模型来解释英语文本的冗余性，通过自相似语义分层的框架分析语言结构，模型预测的熵率与英语印刷文本的估计值一致。


<details>
  <summary>Details</summary>
Motivation: 英语印刷文本的熵率约为每字符1比特，相对于随机文本的5比特有近80%的冗余，但缺乏从第一性原理解释这种冗余水平的理论模型。

Method: 提出统计模型，通过自相似地将文本分割成语义连贯的块（直到单词级别），然后对文本的语义结构进行分层分解，实现解析处理。

Result: 使用现代大语言模型和开放数据集的数值实验表明，该模型在不同语义层次上定量捕捉了真实文本的结构，预测的熵率与英语印刷文本的估计熵率一致。

Conclusion: 自然语言的熵率不是固定的，而应随着语料库语义复杂度的增加而系统性地增加，这一复杂度由模型中唯一的自由参数捕捉。

Abstract: The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [39] [Real-Time Dynamic N-1 Screening: Identifying High-Risk Lines and Transformers After Common Faults](https://arxiv.org/abs/2602.12293)
*Ayrton Almada,Laurent Pagnier,Igal Goldshtein,Saif R. Kazi,Michael,Chertkov*

Main category: math.OC

TL;DR: 提出实时动态N-1筛选框架，通过估计每个单相输电故障导致关键电网元件瞬态过流的概率，为调度员提供可操作的实时态势感知指标。


<details>
  <summary>Details</summary>
Motivation: 传统静态N-1分析无法揭示：(1)同一故障线路是否反复引发严重下游过载；(2)特定变压器是否在多种不同故障场景下都表现出脆弱性。需要实时动态分析来填补这一空白。

Method: 采用线性随机摆方程模型描述故障后机电动态，结合短期故障局部不确定性。使用解析瞬态评估与基于交叉熵的重要性采样相结合的方法，高效估计罕见但高影响事件。所有N-1故障并行评估，具有线性计算复杂度。

Result: 在IEEE 118节点系统上验证，揭示了传统确定性动态或静态N-1分析无法发现的潜在高风险线路和变压器。相比暴力蒙特卡洛方法，计算速度提升数个数量级，可在实时运行周期内实际部署。

Conclusion: 该框架为调度员提供可操作的实时态势感知仪表板，能够识别最常导致变压器过载的故障线路和跨多种高风险场景持续过载的变压器，填补了传统N-1分析的空白。

Abstract: Power system operators routinely perform N-1 contingency analysis, yet conventional tools provide limited guidance on which lines or transformers deserve heightened attention during fast post-fault transients. In particular, static screening does not reveal whether (1) the same faulted line repeatedly triggers severe downstream overloads, or (2) a specific transformer emerges as vulnerable across many distinct fault scenarios. This paper introduces a real-time dynamic N-1 screening framework that addresses this gap by estimating, for each counterfactual single-phase transmission fault, the probability of transient overcurrent on critical grid elements. The output is an operator-facing dashboard that ranks (a) faulted lines whose outages most frequently lead to dangerous transformer overloads, and (b) transformers that consistently overload across top-risk scenarios, both of which are actionable indicators for real-time situational awareness. The approach models post-fault electromechanical dynamics using a linear stochastic formulation of the swing equations with short-lived, fault-localized uncertainty, and combines analytic transient evaluation with cross-entropy based importance sampling to efficiently estimate rare but high-impact events. All N-1 contingencies are evaluated in parallel with linear computational complexity. The framework is demonstrated on the IEEE 118-bus system, where it reveals latent high-risk lines and transformers that remain invisible under deterministic dynamic or static N-1 analysis. Results show orders-of-magnitude computational speedup relative to brute-force Monte Carlo, enabling practical deployment within real-time operational cycles.

</details>


### [40] [Existence Results and KKT Optimality Conditions for Generalized Quasiconvex Functions](https://arxiv.org/abs/2602.12455)
*M. H. Alizadeh,F. Lara*

Main category: math.OC

TL;DR: 论文研究了e-拟凸函数这一新的广义凸函数概念，它包含了拟凸函数和e-凸函数，并建立了其基本性质、最优解存在性条件以及KKT条件的充分性。


<details>
  <summary>Details</summary>
Motivation: 传统凸分析和优化理论中的拟凸函数概念在某些应用中过于严格，需要更广义的凸性概念来涵盖更广泛的函数类，包括Lipschitz函数等非凸函数。

Method: 提出e-拟凸函数的新定义，将其性质从拟凸函数推广到e-拟凸函数，利用广义渐近函数建立最优解存在性和紧致性条件，并在可微情况下分析KKT最优性条件的充分性。

Result: 建立了e-拟凸函数的基本理论框架，给出了最小化e-拟凸函数时解集非空且紧致的充分条件，证明了在数学规划问题中约束函数为e-拟凸时KKT条件的充分性，并通过非凸非拟凸的实例验证了结果。

Conclusion: e-拟凸函数为凸分析和优化理论提供了更广泛的框架，能够处理传统拟凸函数无法涵盖的函数类，在解集非凸的情况下仍然适用，扩展了优化理论的应用范围。

Abstract: We studied a new notion of generalized convex functions called $e$-quasi\-con\-ve\-xi\-ty, which encompasses both quasiconvex and $e$-convex functions, including all Lipschitz functions. By extending the standard properties of quasiconvex functions to $e$-quasiconvex functions, we establish sufficient conditions for the nonemptiness and compactness of the solution set when minimizing an $e$-quasiconvex function, leveraging generalized asymptotic functions, a result which remains applicable even when the set of minimizers is nonconvex. Furthermore, in the differentiable case, we ensure the sufficiency of the KKT optimality conditions when the constraint functions in the mathematical programming problems are $e$-quasiconvex. Finally, we illustrate our new results with several nonconvex (non-quasiconvex) examples.

</details>


### [41] [An LP-Based Approach for Bilinear Saddle Point Problem with Instance-dependent Guarantee and Noisy Feedback](https://arxiv.org/abs/2602.12513)
*Jiashuo Jiang,Mengxiao Zhang*

Main category: math.OC

TL;DR: 提出一种新算法，用于在带噪声反馈的两人零和矩阵博弈中估计纳什均衡，首次获得了一般维度下具有ε偏差的实例相关样本复杂度界。


<details>
  <summary>Details</summary>
Motivation: 研究带噪声反馈的两人零和矩阵博弈中估计纳什均衡的样本复杂度问题。现有工作缺乏针对一般维度、非唯一均衡情况下的实例相关样本复杂度分析。

Method: 提出两阶段算法：第一阶段识别纳什均衡的支持集，第二阶段计算限制在该支持集上的唯一纳什均衡。两个阶段都基于从噪声样本推导的线性规划解进行仔细分析。

Result: 算法获得样本复杂度为O(m₁m₂/(ε·min{δ²,σ₀²,σ³})·log(m₁m₂/ε))，这是首个针对一般维度、带噪声反馈、可能非唯一均衡矩阵博弈的实例相关样本复杂度界。

Conclusion: 该工作首次为带噪声反馈的两人零和矩阵博弈提供了实例相关的样本复杂度分析，算法基于在线资源分配的最新进展，通过两阶段方法有效估计纳什均衡。

Abstract: In this work, we study the sample complexity of obtaining a Nash equilibrium (NE) estimate in two-player zero-sum matrix games with noisy feedback. Specifically, we propose a novel algorithm that repeatedly solves linear programs (LPs) to obtain an NE estimate with bias at most $\varepsilon$ with a sample complexity of $O\left(\frac{m_1 m_2}{\varepsilon\min\{δ^2,σ_0^2,σ^3\}} \log\frac{m_1 m_2}{\varepsilon}\right)$ for general $m_1 \times m_2$ game matrices, where $σ$, $σ_0$, $δ$ are some problem-dependent constants. To our knowledge, this is the first instance-dependent sample complexity bound for finding an NE estimate with $\varepsilon$ bias in general-dimension matrix games with noisy feedback and potentially non-unique equilibria. Our algorithm builds on recent advances in online resource allocation and operates in two stages: (1) identifying the support set of an NE, and (2) computing the unique NE restricted to this support. Both stages rely on a careful analysis of LP solutions derived from noisy samples.

</details>


### [42] [Optimal bounds for the cost of fast controls of a KdV system](https://arxiv.org/abs/2602.12698)
*Hoai-Minh Nguyen*

Main category: math.OC

TL;DR: 研究线性化KdV系统和非线性KdV系统在非临界长度下，使用右Neumann边界控制的快速控制成本，通过转换到相关KdV系统解决谱分析难题


<details>
  <summary>Details</summary>
Motivation: 线性化KdV系统的算子既不自伴也不斜自伴，其已知谱性质无法直接应用矩方法，导致最优成本界限成为开放问题

Method: 将注意力转移到相关的KdV系统，从新系统推导最优界限，使用右Neumann边界控制处理非临界长度情况

Result: 通过系统转换方法成功解决了线性化KdV系统快速控制成本的最优界限问题

Conclusion: 通过转换到相关KdV系统的方法，成功克服了线性化KdV系统算子谱性质带来的分析困难，获得了快速控制成本的最优界限

Abstract: We study the cost of fast controls for a linearized KdV system and a nonlinear KdV system locally, using right Neumann boundary control for non-critical lengths. Since the operator associated with the linearized system is neither self-adjoint nor skew-adjoint, its (known) spectral properties are not directly amenable to the moment method, leaving optimal cost bounds an open problem. We address this difficulty by shifting attention to a related KdV system and deriving the optimal bounds from the new one.

</details>


### [43] [Constrained Mean Field Games with Grushin type dynamics](https://arxiv.org/abs/2602.12807)
*Alessandra Cutrì,Paola Mannucci,Claudio Marchi,Nicoletta Tchou*

Main category: math.OC

TL;DR: 研究具有Grushin型动力学、状态约束和非局部耦合的有限时域确定性平均场博弈，建立了最优控制问题的性质，并证明了松弛均衡和温和解的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究一类具有退化动力学（Grushin型）、状态约束和非局部耦合的平均场博弈问题。主要动机是处理边界点处状态约束与退化动力学之间的局部相互作用，这在数学上具有挑战性。

Method: 首先考虑单个智能体的最优控制问题，建立最优轨迹存在性、多值映射的闭图性质、值函数连续性等性质。提出两组不同的充分性假设来处理边界问题。然后利用这些性质证明平均场博弈中松弛均衡和温和解的存在性。

Result: 证明了最优控制问题的基本性质：任意起点存在最优轨迹、多值映射的闭图性质、值函数连续性。建立了平均场博弈中松弛均衡的存在性，并推导出温和解（由通用玩家的值函数和状态上的时变测度族组成）的存在性。

Conclusion: 成功处理了具有Grushin型退化动力学、状态约束和非局部耦合的平均场博弈问题，建立了理论框架并证明了均衡解的存在性，为这类复杂系统的分析提供了数学基础。

Abstract: This paper is devoted to a class of finite horizon deterministic mean field games with Grushin type dynamics, state constraints and nonlocal coupling. First, we consider the optimal control problem that each agent aims to solve when the evolution of the population is given and we establish some properties as: the existence of an optimal trajectory for any starting point $(x,t)$, the closed graph property for the multivalued map which associates to each point $(x,t)$ the set of optimal trajectories starting from that point, endowed with a suitable notion of convergence, the continuity of the value function. The main issue to overcome is due to the local interplay at boundary points between the set of state constraints and the degenerate dynamics. To this end, we shall point out two different sets of assumptions which are both sufficient for these properties. Afterwards, we tackle the mean field games; taking advantage of the aforementioned properties, we prove the existence of a relaxed equilibrium (which describes the evolution of the game in terms of a probability on the set of admissible trajectories) and derive the existence of a mild solution (which is a couple formed by the value function for the generic player and a family of time dependent measures on the state).

</details>


### [44] [Explicit data-dependent characterizations of the subdifferential of convex pointwise suprema and optimality conditions](https://arxiv.org/abs/2602.12821)
*Stephanie Caro,Abderrahim Hantoute*

Main category: math.OC

TL;DR: 提出了一种新的凸函数上确界次微分的数据依赖对称刻画方法，避免传统方法中的额外几何构造，并应用于无限凸优化得到尖锐的最优性条件。


<details>
  <summary>Details</summary>
Motivation: 传统凸函数上确界次微分的刻画方法需要引入额外的几何构造（如上确界的定义域），计算复杂且不够直观。本文旨在建立更直接、对称的数据依赖刻画方法。

Method: 建立基于数据函数的显式数据依赖对称刻画方法，让活跃和非活跃函数通过其次微分平等贡献，避免传统方法中的额外几何构造。

Result: 获得了凸函数上确界次微分的简洁对称刻画，并应用于无限凸优化，得到了尖锐的KKT和Fritz-John最优性条件，清晰区分了（几乎）活跃和非活跃约束的作用。

Conclusion: 本文提出的方法简化了凸函数上确界次微分的计算，为无限凸优化提供了更清晰、更实用的最优性条件分析框架。

Abstract: We establish explicit data-dependent and symmetric characterizations of the subdifferential of the supremum of convex functions, formulated directly in terms of the underlying data functions. In our approach, both active and non-active functions contribute equally through their subdifferentials, thereby avoiding the need for additional geometric constructions, such as the domain of the supremum, that arise in previous developments. Applications to infinite convex optimization yield sharp Karush-Kuhn-Tucker and Fritz-John optimality conditions, expressed exclusively in terms of the objective and constraint functions and clearly distinguishing the roles of (almost) active and non-active constraints.

</details>


### [45] [Parametric Biobjective Linear Programming](https://arxiv.org/abs/2602.12867)
*Kezang Yuden,Levin Nemesch,Stefan Ruzika*

Main category: math.OC

TL;DR: 该论文研究参数化多目标线性规划问题，特别关注单参数双目标线性规划，建立了参数化问题与非参数多目标问题之间的联系，并开发了相应的求解策略。


<details>
  <summary>Details</summary>
Motivation: 参数化线性规划和多目标线性规划都是研究较多的领域，但将两者结合的参数化多目标线性规划研究较少。这一研究空白促使作者在该领域开展工作。

Method: 使用权重集分解方法分析参数变化时参数化双目标线性规划的行为。研究两种特殊情况：只有一个参数化目标函数的情况，以及两个目标函数具有相同参数依赖性的情况。通过加权和标量化建立参数化程序与三目标程序解的一一对应关系。

Result: 证明了参数化程序与使用加权和标量化的三目标线性规划解之间存在一一对应关系。提供了关于参数化双目标线性规划解与三目标线性规划权重集极端权重关系的结构洞察。

Conclusion: 建立了参数化多目标线性规划的理论框架，开发了参数化双目标线性规划的求解策略，填补了参数化线性规划与多目标线性规划交叉领域的研究空白。

Abstract: We consider parametric linear programming problems with multiple objective functions depending linearly on some parameter. Both parametric (single-objective) linear programming and (non-parametric) multi-objective linear programming are well-researched topics. However, literature on the combination of both, parametric linear programming with multiple objectives, is scarce. This research gap encourages our work in this field. Our main focus is on biobjective linear programs with a single parameter. We establish a connection of this problem to non-parametric multi-objective problems. Using the so-called weight set decomposition, we are able to explain the behavior of parametric biobjective linear programs when the parameter value is variated. We investigate two special cases of parametric biobjective linear programs: In the first, there is only one parametric objective and, in the second, the parametric dependency is the same for both objectives. We prove that there is a one-to-one correspondence between the solution of the parametric program and the solution of the triobjective program using the weighted sum scalarization. We provide structural insights to the solution of the parametric biobjective linear program with respect to extreme weights of the weight set of the triobjective linear program and develop solution strategies for the parametric program.

</details>


### [46] [Well-posedness and mean-field limit estimate of a consensus-based algorithm for min-max problems](https://arxiv.org/abs/2602.12886)
*Hui Huang,Jethro Warnett*

Main category: math.OC

TL;DR: 本文填补了arXiv:2407.17373的理论空白，为无导数共识粒子方法提供了平均场极限的定量估计，并建立了有限粒子模型和平均场动力学的适定性。


<details>
  <summary>Details</summary>
Motivation: 针对arXiv:2407.17373提出的无导数共识粒子方法在非凸非凹极小极大问题中的理论不足，本文旨在填补两个关键理论空白：1）提供平均场极限关于粒子数量的定量估计；2）建立有限粒子模型和相应平均场动力学的适定性。

Method: 通过理论分析建立数学框架，为共识粒子方法提供严格的数学基础，包括平均场极限的收敛速率估计以及有限粒子系统和平均场动力学解的存在唯一性证明。

Result: 成功填补了原论文的理论空白，提供了平均场极限关于粒子数量的定量收敛估计，并证明了有限粒子模型和平均场动力学的适定性，为该方法提供了坚实的数学理论基础。

Conclusion: 本文完善了无导数共识粒子方法在非凸非凹极小极大问题中的理论框架，通过提供平均场极限的定量估计和适定性分析，增强了该方法的数学严谨性和可靠性。

Abstract: The recent work arXiv:2407.17373 proposes a derivative-free consensus-based particle method that computes global solutions to nonconvex-nonconcave min-max problems and establishes global exponential convergence in the sense of the mean-field law. This paper aims to address the theoretical gaps in arXiv:2407.17373, specifically by providing a quantitative estimate of the mean-field limit with respect to the number of particles, as well as establishing the well-posedness of both the finite particle model and the corresponding mean-field dynamics.

</details>


### [47] [A Stochastic Optimal Control Formulation for Mine Counter Measure Simulations with Multiple Autonomous Survey Vehicles](https://arxiv.org/abs/2602.12935)
*Philippe Blondeel,Filip Van Utterbeeck,Ben Lauwens*

Main category: math.OC

TL;DR: 该论文提出了一种基于随机最优控制的扫雷任务规划方法，相比传统方法能缩短任务时间，并扩展至多自主车辆协同工作，但增加车辆带来的时间减少效果呈递减趋势。


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器执行海上扫雷任务时，传统方法（如boustrophedon模式）效率有限，需要更优的路径规划方法来最小化任务时间同时控制未探测水雷的残余风险。

Method: 1. 将扫雷任务建模为随机最优控制问题；2. 在用户选择的四边形区域内计算最优路径；3. 扩展至多自主车辆协同工作，提出新的数学方法；4. 对比传统boustrophedon方法和随机最优控制方法；5. 分析1-6辆车辆的任务时间变化。

Result: 1. 随机最优控制方法比传统boustrophedon方法任务时间更短；2. 多车辆协同工作时，任务时间随车辆数量增加而非线性减少；3. 增加车辆带来的时间减少效果呈递减趋势（边际效益递减）；4. 展示了最多6辆车辆的轨迹计算结果。

Conclusion: 随机最优控制方法能有效提高扫雷任务效率，多车辆协同能进一步缩短任务时间，但需要考虑边际效益递减现象，为实际任务中车辆数量的选择提供理论依据。

Abstract: Modelling and simulating mine counter measure search missions performed by autonomous vehicles equipped with a sensor capable of detecting mines at sea is a challenging endeavour. To address this, we formulated and implemented the problem as a stochastic optimal control model. Our implementation computes an optimal path within a user chosen quadrilateral domain such that the mission duration is minimized for a given residual risk of undetected sea mines. First, we compare the stochastic optimal control implementation against the traditionally used boustrophedon implementation. We show that the mission duration in case of the stochastic optimal control implementation is shorter. Then, by building on our previous work, we introduce a novel mathematical approach that enables multiple autonomous survey vehicles to investigate the domain concurrently. We present results for up to six vehicles, including computed trajectories and an analysis of how mission duration varies with the number of vehicles. Our findings show that mission time decreases non-linearly, , i.e., we observe diminishing returns as more vehicles are added.

</details>


### [48] [A linesearch-type normal map-based semismooth Newton method for nonsmooth nonconvex composite optimization](https://arxiv.org/abs/2602.13000)
*Hanfeng Zeng,Wenqing Ouyang,Andre Milzarek*

Main category: math.OC

TL;DR: 提出了一种基于线搜索的信任区域法变体，用于求解非光滑非凸复合优化问题，避免了昂贵的Lipschitz常数计算，具有更简单的算法结构和更弱的收敛假设。


<details>
  <summary>Details</summary>
Motivation: 针对非光滑非凸复合优化问题，现有信任区域方法需要显式计算Lipschitz常数，且收敛分析需要较强的假设条件（如Hessian近似和迭代的有界性）。本文旨在开发更简单、假设更弱的线搜索变体。

Method: 提出基于线搜索的信任区域法变体，采用自适应参数估计技术避免显式Lipschitz常数计算。结合了正常映射半光滑牛顿法和线搜索策略，简化了算法结构。

Result: 获得了全面的收敛性结果：全局收敛性、在Kurdyka-Łojasiewicz不等式下的迭代收敛性、以及快速局部q-超线性收敛。数值实验在稀疏逻辑回归、图像压缩和带组惩罚项的非线性最小二乘问题上验证了方法的有效性。

Conclusion: 提出的线搜索方法比原始信任区域框架更简单，收敛分析可在更弱的假设下进行（无需Hessian近似和迭代的有界性），同时保持了良好的数值性能。

Abstract: We propose a novel linesearch variant of the trust region normal map-based semismooth Newton method developed in [Ouyang and Milzarek, Math. Program. 212(1-2), 389--435 (2025)] for solving a class of nonsmooth, nonconvex composite-type optimization problems. Our approach uses adaptive parameter estimation techniques, which allow us to avoid explicit and potentially expensive Lipschitz constant computations. We provide extensive convergence results including global convergence, convergence of the iterates under the Kurdyka-Łojasiewicz inequality, and transition to fast local q-superlinear convergence. Compared to the original trust region framework, the linesearch-based algorithm is simpler and the overall convergence analysis can be conducted under weaker assumptions -- in particular, without requiring explicit boundedness conditions on the Hessian approximations and iterates. Numerical experiments on sparse logistic regression, image compression, and nonlinear least squares with group penalty terms demonstrate the efficiency of the proposed approach.

</details>


### [49] [Optimizing Initial Feature-Mapping Variables from Given Designs via Tracking](https://arxiv.org/abs/2602.13005)
*Patrick Jung*

Main category: math.OC

TL;DR: 提出基于特征映射的框架，用于逆向重建基于密度的拓扑优化结果，将体素化输出转换为可解释、可重用的参数化几何基元。


<details>
  <summary>Details</summary>
Motivation: 传统SIMP方法产生的体素化结果难以解释和重用，需要一种方法将离散的密度分布转换为高层次的几何表示，以便于后续的设计修改、制造和分析。

Method: 使用胶囊形杆件（端点+半径）作为几何基元，通过闭式符号距离和平滑过渡函数提供二阶导数。采用可微分伪密度和光滑聚合算子，支持基于梯度的优化。采用非对称过渡函数、仅奖励目标函数和几何保护机制提高鲁棒性。重建过程分阶段进行（探索、桥接、收敛），并可选细化步骤添加、移除或合并特征。

Result: 在经典SIMP基准测试（包括五杆和悬臂梁布局）上实现了高保真重建，使用中等数量的特征。p-范数和softmax聚合产生清晰结果，剪枝去除冗余特征，添加细化恢复覆盖。精确Hessian矩阵相比拟牛顿更新加速收敛并提高鲁棒性。

Conclusion: 该方法成功构建了从体素化输出到显式参数化模型的桥梁，为拓扑优化结果的后处理和重用提供了有效解决方案。

Abstract: A feature-mapping framework for inverse reconstruction of density-based topology optimization results is proposed. Unlike SIMP, whose voxelized outputs are hard to interpret or reuse, the method represents designs with high-level geometric primitives mapped to a fixed analysis grid. Capsule-shaped bars (endpoints plus radius) are used, with closed-form signed distances and smooth transition functions providing derivatives up to second order. Differentiable pseudo-densities are aggregated with smooth operators, enabling gradient-based optimization with exact Hessians. Robustness is improved through asymmetric transition functions that propagate sensitivities into void regions, a reward-only objective for initialization, and geometric safeguards against degenerate configurations. Reconstruction is performed in stages (exploration, bridging, convergence) with optional refinement that can add, remove, or merge features based on residuals and geometric criteria. Experiments on canonical SIMP benchmarks, including five-bar and cantilever layouts, show high-fidelity reconstructions using a moderate number of features. p-norm and softmax aggregation yield sharp results; pruning removes redundant features and additive refinement restores coverage. Exact Hessians accelerate convergence and improve robustness compared to quasi-Newton updates, providing a bridge from voxel-based outputs to explicit parametric models.

</details>


### [50] [Multi-type random game dynamics: limits at discontinuities and cyclic limits](https://arxiv.org/abs/2602.13032)
*Raghupati Vyas,Kousik Das,Veeraruna Kavitha,Souvik Roy*

Main category: math.OC

TL;DR: 论文研究大规模异质群体中的随机战略互动动态过程，采用微分包含框架分析不连续动态系统，发现非经典零点作为潜在极限，并在排队游戏中识别点极限和循环结果的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究大规模异质群体中理性玩家和行为玩家（如避众或从众）的战略互动动态过程。现有文献通常使用常微分方程近似分析，但在纯行动动态中常出现不连续性，需要更合适的分析框架。

Method: 采用基于微分包含的随机近似框架进行极限分析，通过内部链传递集表征动态极限。识别不连续点处出现的非经典零点作为潜在极限，并分析循环结果出现的条件。最后在具有差异优先级服务的排队游戏中应用该方法。

Result: 发现动态系统在不连续点处会出现非经典零点作为潜在极限，这是连续常微分方程经典设置中未观察到的现象。建立了循环结果可能出现的条件。在排队游戏应用中，识别了可能的点极限，并确立了某些参数配置下循环结果的可能性。

Conclusion: 微分包含框架能有效分析大规模异质群体战略互动中的不连续动态系统，揭示了非经典零点作为新极限现象，为理解理性与行为玩家混合群体中的长期战略结果提供了理论工具。

Abstract: We consider (random) strategic interactions in a large population consisting of a variety of players. A rational player chooses actions that maximize certain utility functions, while a behavioral player chooses actions based on preferences such as avoid-the-crowd or follow-the-majority. We specifically study a turn-by-turn dynamic process in which players choose their actions sequentially and once; the utilities are realized either immediately or at the end of the game.
  In the literature, such dynamical systems are often analyzed using an appropriate approximating ordinary differential equation (ODE). However, the ODEs approximating the dynamics with pure actions are typically discontinuous. We adopt a differential inclusion (DI) based stochastic-approximation framework to derive the limiting analysis. The limits of the dynamics are characterized through the internally chain transitive (ICT) sets. We identify the presence of non-classical zeros as potential limits of the dynamics, a phenomenon not observed in classical settings involving continuous ODEs. These new limits arise precisely at the points of discontinuity of the dynamics. We further provide the conditions under which cyclic outcomes may occur at the limit.
  Finally, we study a queuing game with differential priority-based services and examine the impact of the proportions of avoid-the-crowd and two types of rational populations on the long-run outcomes of the strategic interactions. We identify potential point limits and establish the possibility of cyclic outcomes for certain parameter configurations.

</details>


### [51] [Reinterpreting EMML as Mirror Descent for Constrained Maximum Likelihood Estimation](https://arxiv.org/abs/2602.13063)
*Antonin Clerc,Ségolène Martin,Nicolas Papadakis,Gabriele Steidl*

Main category: math.OC

TL;DR: 将EMML算法重新解释为镜像下降方法，通过Bregman投影引入凸约束，在保持计算效率的同时加速收敛


<details>
  <summary>Details</summary>
Motivation: EMML算法广泛用于泊松噪声下的图像重建问题，但缺乏处理约束的能力。希望通过重新解释算法框架，在保持其乘法更新结构的同时引入约束处理能力

Method: 将EMML重新解释为应用于重新参数化目标函数的镜像下降方法，通过Bregman投影引入凸约束，保持算法的乘法更新结构以确保计算效率

Result: 证明了约束EMML算法向约束最大似然问题解的收敛性，在高光谱解混问题上的数值实验表明，约束EMML比经典EMML收敛所需的迭代次数更少

Conclusion: 通过镜像下降视角重新解释EMML，成功开发了能够处理凸约束的改进算法，在保持计算效率的同时加速收敛，为泊松噪声下的约束图像重建问题提供了有效解决方案

Abstract: The Expectation--Maximization Maximum Likelihood (EMML) algorithm belongs to the Expectation--Maximization family and is widely used for image reconstruction problems under Poisson noise.In this paper, we reinterpret EMML as a mirror descent method applied to a reparametrized objective function. This perspective allows us to incorporate convex constraints into the algorithm through appropriately chosen Bregman projections, while preserving the multiplicative structure of the EMML updates to ensure computational efficiency. We then establish the convergence of the resulting algorithm toward a solution of the constrained maximum-likelihood problem. Numerical experiments on hyperspectral unmixing problems demonstrate that the constrained EMML converges in fewer iterations than the classical EMML.

</details>


### [52] [New gradient methods with 3 dimensional quadratic termination](https://arxiv.org/abs/2602.13141)
*Yixin Xie,Jin-Peng Liu,Cong Sun,Ya-Xiang Yuan*

Main category: math.OC

TL;DR: 提出新的梯度法步长，结合精确线搜索，在3维二次函数优化中5步达到最优解；扩展到一般无约束问题，证明全局收敛性并分析收敛速率


<details>
  <summary>Details</summary>
Motivation: 改进梯度法的收敛性能，减少计算成本，特别是在线搜索过程中减少试验步长数量

Method: 提出新的梯度步长，结合精确线搜索；采用循环步长更新策略；通过二次插值扩展至一般无约束问题；使用改进的GLL线搜索

Result: 对于3维二次函数优化，5步达到最优解；证明全局收敛性；分析凸问题的次线性收敛速率和二次函数增长问题的R线性收敛速率；数值结果显示计算成本低，线搜索试验步长少

Conclusion: 提出的新梯度法在计算成本和收敛性能方面表现优异，线搜索效率高，适用于各类无约束优化问题

Abstract: A new stepsize for gradient method is proposed. Combining it with the exact line search stepsizes, the gradient method achieves the optimal solution in 5 steps for 3 dimensional quadratic function minimization problem. The new stepsize is plugged in the cyclic stepsize update strategy, and a new gradient method is proposed. By applying the quadratic interpolation for Cauchy approximation, the proposed gradient method is extended to solve general unconstrained problem. With the improved GLL line search, the global convergence of the proposed method is proved. Furthermore, its sublinear convergence rate for convex problems and R-linear convergence rate for problems with quadratic functional growth property are analyzed. Numerical results show that our proposed algorithm enjoys good performances in terms of computational cost, and line search requires very few trial stepsizes.

</details>


### [53] [A Data-Driven Algorithm for Model-Free Control Synthesis](https://arxiv.org/abs/2602.13157)
*Sean Bowerfind,Matthew R. Kirchner,Gary Hewer*

Main category: math.OC

TL;DR: 提出一种基于数据驱动的连续时间系统无限时域LQR最优控制器综合算法，无需系统动力学模型，仅使用有限长度输入输出数据。


<details>
  <summary>Details</summary>
Motivation: 传统LQR控制器设计需要精确的系统动力学模型，但在实际应用中往往难以获得。本文旨在开发一种仅依赖输入输出数据即可综合最优LQR控制器的方法，降低对系统模型知识的依赖。

Method: 基于约束优化问题，强制最优值函数沿任意轨迹满足必要条件。算法使用有限长度的任意输入输出数据采样，无需系统动力学知识。可同时计算标准LQR增益矩阵和用于参考跟踪的前馈增益。

Result: 算法能够成功综合无限时域LQR最优反馈控制器，包括参考跟踪功能。通过多个示例验证了方法的有效性，包括在真实比例飞机上的验证测试。

Conclusion: 提出了一种完全数据驱动的连续时间系统LQR控制器综合方法，无需系统动力学模型，仅依赖输入输出数据即可实现最优控制，具有实际应用价值。

Abstract: Presented is an algorithm to synthesize the optimal infinite-horizon LQR feedback controller for continuous-time systems. The algorithm does not require knowledge of the system dynamics but instead uses only a finite-length sampling of arbitrary input-output data. The algorithm is based on a constrained optimization problem that enforces a necessary condition on the dynamics of the optimal value function along any trajectory. In addition to calculating the standard LQR gain matrix, a feedforward gain can be found to implement a reference tracking controller. This paper presents a theoretical justification for the method and shows several examples, including a validation test on a real scale aircraft.

</details>


### [54] [Operator Learning for Families of Finite-State Mean-Field Games](https://arxiv.org/abs/2602.13169)
*William Hofgard,Asaf Cohen,Mathieu Laurière*

Main category: math.OC

TL;DR: 提出基于算子学习的框架，用于求解参数化平均场博弈系统，能够泛化到新的初始分布和终端成本而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 平均场博弈系统求解困难，每个系统的结构依赖于玩家初始分布和博弈终端成本。现有方法需要为每个新参数重新求解，效率低下。

Method: 采用算子学习框架，通过训练学习参数化平均场博弈系统的解算子。基于平均场博弈系统对应流映射的正则性结果，提供理论保证。

Result: 理论证明了方法的近似误差、参数复杂度和泛化性能。在网络安全示例和高维二次模型两个代表性平均场博弈实例上实现了准确近似。

Conclusion: 提出的算子学习框架能够有效求解参数化平均场博弈系统，实现对新初始分布和终端成本的泛化，为平均场博弈计算提供了高效方法。

Abstract: Finite-state mean-field games (MFGs) arise as limits of large interacting particle systems and are governed by an MFG system, a coupled forward-backward differential equation consisting of a forward Kolmogorov-Fokker-Planck (KFP) equation describing the population distribution and a backward Hamilton-Jacobi-Bellman (HJB) equation defining the value function. Solving MFG systems efficiently is challenging, with the structure of each system depending on an initial distribution of players and the terminal cost of the game. We propose an operator learning framework that solves parametric families of MFGs, enabling generalization without retraining for new initial distributions and terminal costs. We provide theoretical guarantees on the approximation error, parametric complexity, and generalization performance of our method, based on a novel regularity result for an appropriately defined flow map corresponding to an MFG system. We demonstrate empirically that our framework achieves accurate approximation for two representative instances of MFGs: a cybersecurity example and a high-dimensional quadratic model commonly used as a benchmark for numerical methods for MFGs.

</details>


### [55] [Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps](https://arxiv.org/abs/2602.13177)
*Swati Gupta,Jai Moondra,Mohit Singh*

Main category: math.OC

TL;DR: 本文研究了在线凸优化中镜像映射的选择问题，特别是针对稀疏损失函数。研究表明基于块范数的镜像映射比传统的L_p插值方法能更好地适应损失函数的稀疏性，并提出了动态选择几何结构的元算法。


<details>
  <summary>Details</summary>
Motivation: 在线镜像下降（OMD）的性能严重依赖于镜像映射的选择。虽然OPGD（L_2几何）和OEG（L_1几何）的几何结构已被充分理解，但对于任意约束集和一般损失函数族（如稀疏损失），如何构造最优镜像映射仍是一个开放性问题。本文旨在探索通过使用L_1和L_2之间的插值几何，是否能在遗憾上获得多项式增益。

Method: 1. 提出使用基于块范数的镜像映射来适应损失函数的稀疏性；2. 构造了一个在线凸优化实例族，证明块范数镜像映射在稀疏损失函数上相比OEG和OPGD能获得多项式改进；3. 针对损失函数稀疏度未知的情况，提出了基于乘法权重的元算法，动态选择均匀块范数几何结构。

Result: 1. 证明了块范数镜像映射在稀疏损失函数上能获得多项式（在维度d上）的遗憾改进；2. 发现简单地在OEG和OPGD之间切换可能导致线性遗憾；3. 提出的元算法能够有效调整OMD以适应损失函数的稀疏性，获得自适应遗憾保证。

Conclusion: 在线镜像映射选择能显著增强OMD利用在线凸优化中稀疏性的能力。基于块范数的镜像映射比传统L_p插值方法更好地适应稀疏损失，而动态几何选择算法能在稀疏度未知的情况下实现自适应优化。

Abstract: OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).
  Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [56] [Empirical Validation of a Dual-Defense Mechanism Reshaping Wholesale Electricity Price Dynamics in Singapore](https://arxiv.org/abs/2602.12782)
*Huang Zhenyu,Yuan Zhao*

Main category: eess.SY

TL;DR: 新加坡电力市场采用独特的双重防御机制（VC+TPC），研究发现该机制能有效解耦价格抑制与流动性风险，实现市场稳定最大化。


<details>
  <summary>Details</summary>
Motivation: 传统的前期筛选和静态价格上限是全球标准，但新加坡采用独特的双重防御机制（vesting contracts + temporary price cap），需要评估其实际效果。

Method: 使用2021-2024年高频数据，分析vesting contracts（VC）和temporary price cap（TPC）的相互作用，通过结构变化分析和阈值诊断等方法。

Result: 1. VC存在结构性权衡：VC数量抑制平均价格但加剧不稳定性，VC价格在极端分位数起主导作用；2. 2023年改革后价格动态重新映射，TPC阈值附近无系统性策略性投标行为；3. 双重防御机制具有协同效应，TPC逆转了高VCQ的波动性惩罚。

Conclusion: 新加坡的双重防御机制成功解耦了价格抑制与流动性风险，在增强尾部风险控制的同时消除了流动性相关的稳定性成本，实现了市场稳定最大化。

Abstract: While ex-ante screening and static price caps are global standards for mitigating price volatility, Singapore's electricity market employs a unique dual-defense mechanism integrating vesting contracts (VC) with a temporary price cap (TPC). Using high-frequency data from 2021 to 2024, this paper evaluates this mechanism and yields three primary findings. First, a structural trade-off exists within the VC framework: while VC quantity (VCQ) suppresses average prices, it paradoxically exacerbates instability via liquidity squeezes. Conversely, VC price (VCP) functions as a tail-risk anchor, dominating at extreme quantiles where VCQ efficacy wanes. Second, a structural break around the 2023 reform reveals a fundamental re-mapping of price dynamics; the previously positive pass-through from offer ratios to clearing prices was largely neutralized post-reform. Furthermore, diagnostics near the TPC threshold show no systematic evidence of strategic bid shading, confirming the TPC's operational integrity. Third, the dual-defense mechanism exhibits a critical synergy that resolves the volatility trade-off. The TPC reverses the volatility penalty of high VCQ, shifting the elasticity of conditional volatility from a destabilizing 0.636 to a stabilizing -0.213. This synergy enables the framework to enhance tail-risk control while eliminating liquidity-related stability costs. We conclude that this dual-defense mechanism successfully decouples price suppression from liquidity risks, thereby maximizing market stability.

</details>


### [57] [A Lightweight Cubature Kalman Filter for Attitude and Heading Reference Systems Using Simplified Prediction Equations](https://arxiv.org/abs/2602.12283)
*Shunsei Yamagishi,Lei Jing*

Main category: eess.SY

TL;DR: 提出一种名为KCKF的改进容积卡尔曼滤波器，在保持姿态估计精度的同时降低计算成本，相比CKF在高性能计算机上减少约19%计算时间，在低成本单板计算机上减少约15%计算时间。


<details>
  <summary>Details</summary>
Motivation: 姿态航向参考系统(AHRS)广泛应用于需要可靠方向和运动传感的场合。传统容积卡尔曼滤波器(CKF)计算成本较高，需要开发更高效的计算方法。

Method: 通过简化CKF的方程推导出KCKF的计算高效方程，保持等效数学关系。通过展开CKF中的求和项并简化结果，推导出KCKF的轻量级预测方程。

Result: KCKF比CKF需要更少的浮点运算(FLOPs)。实验结果显示，在高性能计算机上KCKF比CKF减少约19%计算时间，在低成本单板计算机上减少约15%计算时间，同时保持CKF的姿态估计精度。

Conclusion: KCKF在保持姿态估计精度的同时显著降低了计算成本，为AHRS应用提供了更高效的计算解决方案。

Abstract: Attitude and Heading Reference Systems (AHRSs) are broadly applied wherever reliable orientation and motion sensing is required. In this paper, we present an improved Cubature Kalman Filter (CKF) with lower computational cost while maintaining estimation accuracy, which is named "Kaisoku Cubature Kalman Filter (KCKF)". The computationally efficient equations of the KCKF are derived by simplifying those of the CKF, while preserving equivalent mathematical relations. The lightweight prediction equations in the KCKF are derived by expanding the summation terms in the CKF and simplifying the result. This paper shows that the KCKF requires fewer floating-point operations (FLOPs) than the CKF. The controlled experimental results show that the KCKF reduces the computation time by approximately 19% compared to the CKF on a high-performance computer, whereas the KCKF reduces the computation time by approximately 15% compared to the CKF on a low-cost single-board computer. In addition, the KCKF maintains the attitude estimation accuracy of the CKF.

</details>


### [58] [Energy-Aware Reinforcement Learning for Robotic Manipulation of Articulated Components in Infrastructure Operation and Maintenance](https://arxiv.org/abs/2602.12288)
*Xiaowen Tao,Yinuo Wang,Haitao Ding,Yuanyang Qi,Ziyu Song*

Main category: eess.SY

TL;DR: 提出一个与关节类型无关且能量感知的强化学习框架，用于智能基础设施运维中的机器人操作，通过CMDP建模和约束SAC方案实现节能操作


<details>
  <summary>Details</summary>
Motivation: 随着智能基础设施和智慧城市的发展，运维操作需要安全、高效、节能的机器人操作关节组件。现有方法要么专注于抓取，要么针对特定对象，很少将驱动能量纳入多目标优化，限制了在真实运维环境中的可扩展性和长期部署适用性。

Method: 结合部件引导的3D感知、加权点采样和基于PointNet的编码来获取紧凑的几何表示；将操作建模为约束马尔可夫决策过程(CMDP)，通过基于拉格朗日的约束Soft Actor-Critic方案显式建模和调节驱动能量；端到端训练策略。

Result: 在代表性运维任务实验中，能耗降低16%-30%，成功步骤减少16%-32%，同时保持高成功率，表明该方法具有可扩展性和可持续性。

Conclusion: 该框架为基础设施运维操作提供了一个可扩展且可持续的解决方案，能够处理异构关节对象，同时满足长期能量预算约束。

Abstract: With the growth of intelligent civil infrastructure and smart cities, operation and maintenance (O&M) increasingly requires safe, efficient, and energy-conscious robotic manipulation of articulated components, including access doors, service drawers, and pipeline valves. However, existing robotic approaches either focus primarily on grasping or target object-specific articulated manipulation, and they rarely incorporate explicit actuation energy into multi-objective optimisation, which limits their scalability and suitability for long-term deployment in real O&M settings. Therefore, this paper proposes an articulation-agnostic and energy-aware reinforcement learning framework for robotic manipulation in intelligent infrastructure O&M. The method combines part-guided 3D perception, weighted point sampling, and PointNet-based encoding to obtain a compact geometric representation that generalises across heterogeneous articulated objects. Manipulation is formulated as a Constrained Markov Decision Process (CMDP), in which actuation energy is explicitly modelled and regulated via a Lagrangian-based constrained Soft Actor-Critic scheme. The policy is trained end-to-end under this CMDP formulation, enabling effective articulated-object operation while satisfying a long-horizon energy budget. Experiments on representative O&M tasks demonstrate 16%-30% reductions in energy consumption, 16%-32% fewer steps to success, and consistently high success rates, indicating a scalable and sustainable solution for infrastructure O&M manipulation.

</details>


### [59] [String-Level Ground Fault Localization for TN-Earthed Three-Phase Photovoltaic Systems](https://arxiv.org/abs/2602.12289)
*Yuanliang Li,Xun Gong,Reza Iravani,Bo Cao,Heng Liu,Ziming Chen*

Main category: eess.SY

TL;DR: 提出基于边缘AI的接地故障定位方法，用于三相TN接地光伏系统，通过轻量级VIB模型实现93%以上的定位精度


<details>
  <summary>Details</summary>
Motivation: 直流侧接地故障对三相TN接地光伏系统构成重大风险，高故障电流会直接损坏逆变器和光伏组件。传统人工逐串检查方法耗时且效率低下，需要自动化定位方案。

Method: 1. 通过故障电流分析和仿真研究接地故障特性；2. 开发包含光伏迟滞效应的PLECS仿真模型生成多样化故障场景；3. 从逆变器四阶段关断序列中提取基于相关性的特征；4. 设计轻量级变分信息瓶颈(VIB)定位模型进行训练。

Result: 在典型采样率下，VIB定位模型达到超过93%的定位精度，计算成本低，适合在资源受限的光伏逆变器上部署。

Conclusion: 提出的边缘AI接地故障定位方法为三相TN接地光伏系统提供了高效、准确的故障定位解决方案，具有实际部署潜力。

Abstract: The DC-side ground fault (GF) poses significant risks to three-phase TN-earthed photovoltaic (PV) systems, as the resulting high fault current can directly damage both PV inverters and PV modules. Once a fault occurs, locating the faulty string through manual string-by-string inspection is highly time-consuming and inefficient. This work presents a comprehensive analysis of GF characteristics through fault-current analysis and a simulation-based case study covering multiple fault locations. Building on these insights, we propose an edge-AI-based GF localization approach tailored for three-phase TN-earthed PV systems. A PLECS-based simulation model that incorporates PV hysteresis effects is developed to generate diverse GF scenarios, from which correlation-based features are extracted throughout the inverter's four-stage shutdown sequence. Using the simulated dataset, a lightweight Variational Information Bottleneck (VIB)-based localization model is designed and trained, achieving over 93% localization accuracy at typical sampling rates with low computational cost, demonstrating strong potential for deployment on resource-constrained PV inverters.

</details>


### [60] [Adaptive traffic signal control optimization using a novel road partition and multi-channel state representation method](https://arxiv.org/abs/2602.12296)
*Maojiang Deng,Shoufeng Lu,Jiazhao Shi,Wen Zhang*

Main category: eess.SY

TL;DR: 提出基于DQN和PPO的自适应交通信号控制方法，采用可变单元长度和多通道状态表示优化信号配时，在SUMO仿真中表现优于固定单元长度方法。


<details>
  <summary>Details</summary>
Motivation: 传统交通信号控制方法难以适应动态交通需求，需要更智能的自适应控制方法来优化交通流、减少等待时间、提高速度和降低能耗。

Method: 结合DQN和PPO强化学习算法，提出可变单元长度的道路分区公式（对数与线性函数之和），采用三通道状态表示（车辆数、平均速度、空间占有率），以信号相位为动作空间，固定绿灯时间执行，奖励函数基于等待时间、速度和油耗的绝对值加权归一化。

Result: 在SUMO-TensorFlow-Python仿真中，提出的可变单元长度和多通道状态表示方法在优化性能上优于固定单元长度方法，并展示了跨范围可转移性评估。

Conclusion: 提出的自适应交通信号控制方法有效提升了交通信号优化性能，可变单元长度和多通道状态表示是提高强化学习交通控制效果的关键创新。

Abstract: This study proposes a novel adaptive traffic signal control method leveraging a Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) to optimize signal timing by integrating variable cell length and multi-channel state representation. A road partition formula consisting of the sum of logarithmic and linear functions was proposed. The state variables are a vector composed of three channels: the number of vehicles, the average speed, and space occupancy. The set of available signal phases constitutes the action space, the selected phase is executed with a fixed green time. The reward function is formulated using the absolute values of key traffic state metrics - waiting time, speed, and fuel consumption. Each metric is normalized by a typical maximum value and assigned a weight that reflects its priority and optimization direction. The simulation results, using Sumo-TensorFlow-Python, demonstrate a cross-range transferability evaluation and show that the proposed variable cell length and multi-channel state representation method excels compared to fixed cell length in optimization performance.

</details>


### [61] [Interpolation-Inspired Closure Certificates](https://arxiv.org/abs/2602.12436)
*Mohammed Adib Oumer,Vishnu Murali,Majid Zamani*

Main category: eess.SY

TL;DR: 提出基于插值思想的闭包证书方法，通过多函数集合逼近转移不变量，增强对ω-正则性质的验证能力


<details>
  <summary>Details</summary>
Motivation: 传统闭包证书方法使用单一函数模板（如固定阶多项式）可能无法找到合适的证书，需要提出更灵活的方法来验证ω-正则性质

Method: 提出插值启发式闭包证书，使用函数集合逐步逼近转移不变量：先考虑一步转移，然后两步，直到获得完整的转移不变量。采用SOS规划和场景规划来寻找这些函数集合

Result: 该方法能够验证持久性和一般ω-正则性质，在案例研究中展示了有效性，解决了传统方法中固定模板无法找到证书的问题

Conclusion: 插值启发式闭包证书提供了一种更灵活的验证框架，能够处理传统单一函数模板方法无法解决的验证问题，扩展了动态系统验证的能力

Abstract: Barrier certificates, a form of state invariants, provide an automated approach to the verification of the safety of dynamical systems. Similarly to barrier certificates, recent works explore the notion of closure certificates, a form of transition invariants, to verify dynamical systems against $ω$-regular properties including safety. A closure certificate, defined over state pairs of a dynamical system, is a real-valued function whose zero superlevel set characterizes an inductive transition invariant of the system. The search for such a certificate can be effectively automated by assuming it to be within a specific template class, e.g. a polynomial of a fixed degree, and then using optimization techniques such as sum-of-squares (SOS) programming to find it. Unfortunately, one may not be able to find such a certificate for a fixed template. In such a case, one must change the template, e.g. increase the degree of the polynomial. In this paper, we consider a notion of multiple closure certificates dubbed interpolation-inspired closure certificates. An interpolation-inspired closure certificate consists of a set of functions which jointly over-approximate a transition invariant by first considering one-step transitions, then two, and so on until a transition invariant is obtained. The advantage of interpolation-inspired closure certificates is that they allow us to prove properties even when a single function for a fixed template cannot be found using standard approaches. We present SOS programming and a scenario program to find these sets of functions and demonstrate the effectiveness of our proposed method to verify persistence and general $ω$-regular specifications in some case studies.

</details>


### [62] [Implementation of a Directional Modulation Testbed for Reconfigurable Transmitters for Spatially Agile MIMO Systems](https://arxiv.org/abs/2602.12452)
*Jonathan E. Swindell,David W. Cox,Rebekah Edwards,Emma Lever,Adam C. Goad,Austin Egbert,Charles Baylis,Robert J. Marks*

Main category: eess.SY

TL;DR: 本文展示了一个用于方向调制传输的微波测试平台的实现与验证，该平台使用双元件发射阵列和RFSoC芯片，为开发可重构的MU-MIMO雷达和通信系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 方向调制技术能够使用单个相控阵孔径同时在多个方向上传输多个通信和/或雷达信号，有助于缓解频谱拥塞问题。需要开发可重构的阵列发射器来实现多用户MIMO雷达和通信系统的自适应频谱与空间共存。

Method: 采用双元件发射阵列，由Xilinx ZCU208射频片上系统(RFSoC)驱动。该测试平台为开发完全可重构的阵列发射器提供基础，将集成原位测量、可重构匹配电路以及用于频率和方向选择性的快速调谐算法。

Result: 成功实现并验证了方向调制微波测试平台，该平台能够支持自适应频谱和空间共存技术的开发与验证，为未来可重构MU-MIMO系统提供实验基础。

Conclusion: 该测试平台为开发完全可重构的阵列发射器奠定了重要基础，将支持多用户MIMO雷达和通信系统的实现，促进自适应频谱与空间共存技术的发展。

Abstract: This paper demonstrates the implementation and validation of a microwave testbed for directionally modulated transmission. Directional modulation enables multiple communication and/or radar signals to be transmitted in multiple directions simultaneously using a single phased array aperture, helping to relieve spectral congestion. A two-element transmitter array is driven by a Xilinx ZCU208 Radio Frequency System on a Chip (RFSoC). Our testbed provides a foundation for developing a fully reconfigurable array transmitter for multi-user multiple-input multiple-output (MU-MIMO) radar and communications, which will incorporate in-situ measurement, reconfigurable matching circuitry, and fast tuning algorithms for frequency and directional selectivity. This testbed enables development and validation of reconfigurable techniques for adaptive spectral and spatial coexistence.

</details>


### [63] [Grid-ECO: Grid Aware Electric Vehicle Charging Stations Placement Optimizer](https://arxiv.org/abs/2602.12473)
*Bikram Panthee,Haoming Yang,Corey D. Harper,Amritanshu Pandey*

Main category: eess.SY

TL;DR: Grid-ECO：一种考虑人口普查级EV充电需求的三相不平衡配电网充电站最优选址方法，能精确求解MINLP问题并保证AC可行性和最优性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法在保证AC可行性和最优性的前提下解决EV充电站选址问题，要么需要放松整数决策变量空间，要么需要对AC约束进行凸化处理。

Method: 将MINLP精确重构为MIBLP，使用空间分支定界算法进行全局优化，并开发了基于顺序边界收紧的预求解策略，包含变量过滤和分解技术。

Result: Grid-ECO在商用Gurobi求解器无法在167小时内找到可行解的情况下仍能求解，当商用求解器能找到可行解时，Grid-ECO能将求解时间减少73%，节点探索减少97%，同时实现0%最优性差距并保证AC可行性。

Conclusion: Grid-ECO方法能够精确高效地解决大规模配电网中EV充电站选址的MINLP问题，保证AC可行性和最优性，显著优于现有商用求解器。

Abstract: The paper develops a methodology, Grid-ECO, to optimally allocate electric vehicle charging stations (EVCS) within a distribution feeder, while considering EV charging demand at census-level granularity. The underlying problem is NP-hard and requires satisfying nonlinear, nonconvex, three-phase unbalanced AC network constraints while including integer decision variables. Existing works cannot guarantee AC feasibility nor optimality of this problem without either i) relaxing the integer decision variable space or ii) convexifying AC constraints. Proposed Grid-ECO exactly solves the underlying mixed-integer nonlinear program (MINLP) to near-zero optimality gap while prioritizing candidate locations based on grid voltage and current sensitivities. To solve the MINLP exactly, Grid-ECO exactly reformulates it into mixed-integer bilinear program (MIBLP), enabling global optimization using the spatial branch-and-bound algorithm (sBnB). To ensure computational tractability for large-scale feeders, we develop and include a novel presolving strategy based on Sequential Bound Tightening (SBT) with variable filtering and decomposition. Case studies demonstrate that Grid-ECO outperforms the off-the-shelf Gurobi sBnB solver by solving cases where no feasible solution is found within 167 hours. When feasible solution is found by off-the-shelf solver, Grid-ECO reduces solution time by up to 73\% and sBnB node exploration by up to 97\%, while achieving a 0\% optimality gap and guaranteed AC feasibility.

</details>


### [64] [Dynamic Network Prices for Prosumer-aware Hosting Capacity Management](https://arxiv.org/abs/2602.12573)
*Jiawei Zhang,Gregor Verbic,Frederik Geth,Mohsen Aldaadi,Rahmat Heidari,Julio Braslavsky*

Main category: eess.SY

TL;DR: 提出双层优化框架，通过动态网络电价设计来管理分布式能源资源，同时尊重用户自主权


<details>
  <summary>Details</summary>
Motivation: 现有分布式能源资源管理方法（如直接负荷控制、运行包络、基于价格的动态电价控制）存在局限性：依赖假设的用户行为模式，忽视用户对设备的控制权，且当前固定或分时电价基于时空平均值，对网络条件和DER运行影响有限

Method: 提出双层优化框架：上层为配电系统运营商（DSO），在成本回收和网络约束下设定网络电价；下层为产消者，根据电价优化DER运行。该框架明确建模产消者决策过程

Result: 该框架能够保护用户自主权，增强DER灵活性，为高DER渗透率下的网络承载能力管理和网络电价结构演进提供可操作的见解

Conclusion: 提出的双层优化框架有效解决了现有分布式能源资源管理方法的局限性，通过动态网络电价设计平衡了系统运营商需求和用户自主权，为未来高DER渗透率下的电网管理提供了新思路

Abstract: The fast uptake of distributed energy resources (DERs) presents increasing challenges for managing hosting capacity in distribution networks. Existing solutions include direct load control, operating envelopes, and price-based control through dynamic energy prices. Despite their effectiveness, these methods often rely on assumed prosumer behavioural patterns and overlook prosumers' desire to retain control over their devices. Additionally, current fixed or Time-of-Use (ToU) prices are based on spatial and temporal averages, having limited impact on network conditions and DER operation. To address these limitations, this paper proposes a bilevel optimisation framework that explicitly models prosumer decision-making in the design of dynamic network prices. The upper level represents the distribution system operator (DSO), setting network prices under cost-recovery and network constraints, while the lower level models prosumers optimising DER operation in response. The proposed framework preserves customer prerogative, enhances DER flexibility, and offers actionable insights for network hosting capacity management and the evolution of network tariff structures under high DER penetration.

</details>


### [65] [Curvature-Guided Safety Filters: State-Dependent Hessian-Weighted Projection with Provable Performance Bounds](https://arxiv.org/abs/2602.12603)
*Ziyan Lin,Liang Xu*

Main category: eess.SY

TL;DR: 提出一种基于Hessian引导的加权投影安全滤波器，通过利用动作价值函数的曲率信息来改进性能，同时保持凸性和实时计算可行性。


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得投影安全滤波器忽略长期性能，而直接在安全集内优化动作价值函数通常是非凸且计算代价高昂的。需要一种既能保持凸性又能提升性能的安全滤波方法。

Method: 提出状态依赖的Hessian引导加权投影方法：根据动作价值函数的曲率选择加权投影矩阵，使修正偏向具有更高价值敏感性的动作方向。对于黑盒控制器，通过带二次特征块和正则化的迭代Q函数学习算法数据驱动地构建加权投影矩阵。

Result: 建立了加权投影与安全价值最优动作之间性能差距的均匀上界，并给出了加权投影在长期价值上优于欧几里得投影的条件。在四旋翼跟踪避障任务仿真中，该方法在保持安全性的同时减少了价值退化，计算开销适合实时操作。

Conclusion: 提出的Hessian引导加权投影安全滤波器在保持凸性和实时计算可行性的同时，显著提升了长期性能，为学习控制系统的安全滤波提供了有效解决方案。

Abstract: Safety filters provide a lightweight mechanism for enforcing state and input safety in learning-enabled control. However, common Euclidean projections onto the safe set disregard long-term performance, while directly optimizing the action-value function within the safe set can be nonconvex and computationally prohibitive. This paper proposes a state-dependent, Hessian-guided projection for safety filtering that preserves convexity while improving performance. The key idea is to select a weighted projection matrix from the curvature of the action-value function, thereby biasing the correction toward action directions with higher value sensitivity. We establish (i) a uniform bound on the performance gap between the weighted projection and the safe value-optimal action, and (ii) a condition under which the weighted projection outperforms the Euclidean projection in long-term value. To support black-box controllers, we further present a data-driven construction of the weighted projection matrix via an iterative Q-function learning algorithm with quadratic feature blocks and regularization that enforces curvature dominance and bounded higher-order terms. Simulations on a quadrotor tracking-and-avoidance task indicate that the proposed filter maintains safety while reducing value degradation relative to Euclidean projection, with computational overhead compatible with real-time operation.

</details>


### [66] [When Environments Shift: Safe Planning with Generative Priors and Robust Conformal Prediction](https://arxiv.org/abs/2602.12616)
*Kaizer Rahaman,Jyotirmoy V. Deshmukh,Ashish R. Hota,Lars Lindemann*

Main category: eess.SY

TL;DR: 提出一个在分布偏移下保持安全性的规划框架，通过条件扩散模型生成合成数据，结合鲁棒CP为MPC提供概率安全保证


<details>
  <summary>Details</summary>
Motivation: 自主系统在部署时面临分布偏移问题，传统CP方法在训练和部署环境一致时能提供安全保证，但一旦发生分布偏移，这些保证就会失效

Method: 1) 假设环境数据分布由可观测的干扰参数参数化；2) 训练条件扩散模型捕捉分布偏移；3) 在线观测干扰参数并生成合成数据；4) 设计嵌入鲁棒CP的MPC控制器

Result: 在ORCA模拟器中实证展示了该方法在多种分布偏移下的安全性，相比静态训练数据方法，能提供概率安全保证

Conclusion: 提出的框架通过条件扩散模型生成合成数据并结合鲁棒CP，能够在分布偏移下为自主系统规划提供概率安全保证

Abstract: Autonomous systems operate in environments that may change over time. An example is the control of a self-driving vehicle among pedestrians and human-controlled vehicles whose behavior may change based on factors such as traffic density, road visibility, and social norms. Therefore, the environment encountered during deployment rarely mirrors the environment and data encountered during training -- a phenomenon known as distribution shift -- which can undermine the safety of autonomous systems. Conformal prediction (CP) has recently been used along with data from the training environment to provide prediction regions that capture the behavior of the environment with a desired probability. When embedded within a model predictive controller (MPC), one can provide probabilistic safety guarantees, but only when the deployment and training environments coincide. Once a distribution shift occurs, these guarantees collapse. We propose a planning framework that is robust under distribution shifts by: (i) assuming that the underlying data distribution of the environment is parameterized by a nuisance parameter, i.e., an observable, interpretable quantity such as traffic density, (ii) training a conditional diffusion model that captures distribution shifts as a function of the nuisance parameter, (iii) observing the nuisance parameter online and generating cheap, synthetic data from the diffusion model for the observed nuisance parameter, and (iv) designing an MPC that embeds CP regions constructed from such synthetic data. Importantly, we account for discrepancies between the underlying data distribution and the diffusion model by using robust CP. Thus, the plans computed using robust CP enjoy probabilistic safety guarantees, in contrast with plans obtained from a single, static set of training data. We empirically demonstrate safety under diverse distribution shifts in the ORCA simulator.

</details>


### [67] [Safe Controller Synthesis Using Lyapunov-based Barriers for Linear Hybrid Systems with Simplex Architecture](https://arxiv.org/abs/2602.12638)
*Sunandan Adhikary,Soumyajit Dey*

Main category: eess.SY

TL;DR: 提出了一种新型备份安全控制器设计方法，确保在安全状态空间中最大可能区域的不变性，并提供及时恢复保证，同时通过不同执行速率的BSC切换优化资源使用。


<details>
  <summary>Details</summary>
Motivation: 现有备份控制器设计不考虑实时恢复期限，也不以最大化安全操作区域为合成标准，导致只能在较小操作区域内提供最终安全保证。现代网络物理系统需要更高效的安全机制。

Method: 提出备份安全控制器设计方法，确保最大安全区域不变性和及时恢复保证；通过不同执行速率的BSC切换最小化资源使用；提出在线安全控制器激活策略，在BSC和主优化控制器之间切换以优化控制计算的处理带宽。

Result: 在线性混合动力系统预算带宽下的闭环评估中，验证了所提安全控制器的安全性和恢复时间，以及激活策略的有效性。

Conclusion: 这是首个合成安全控制器的工作，确保最大安全性和及时恢复，同时通过不同执行速率的BSC切换实现最小资源使用，为网络物理系统提供了更高效的安全保障机制。

Abstract: Modern cyber-physical systems often have a two-layered design, where the primary controller is AI-enabled or an analytical controller optimising some specific cost function. If the resulting control action is perceived as unsafe, a secondary safety-focused backup controller is activated. The existing backup controller design schemes do not consider a real-time deadline for the course correction of a potentially unsafe system trajectory or constrain maximisation of the safe operating region as a synthesis criterion. This essentially implies an eventual safety guarantee over a small operating region.
  This paper proposes a novel design method for backup safe controllers (BSCs) that ensure invariance across the largest possible region in the safe state space, along with a guarantee for timely recovery when the system states deviate from their usual behaviour. This is the first work to synthesise safe controllers that ensure maximal safety and timely recovery while aiming at minimal resource usage by switching between BSCs with different execution rates. An online safe controller activation policy is also proposed to switch between BSCs (and the primary optimal controller) to optimise processing bandwidth for control computation. To establish the efficacy of the proposed method, we evaluate the safety and recovery time of the proposed safe controllers, as well as the activation policy, in closed loops with linear hybrid dynamical systems under budgeted bandwidth.

</details>


### [68] [Dual-Channel Feature Fusion for Joint Prediction in Dynamic Signed Weighted Networks](https://arxiv.org/abs/2602.12663)
*Gaoxin Zhang,Ruixing Ren,Junhui Zhao,Xiaoke Sun*

Main category: eess.SY

TL;DR: 提出一个针对动态有符号加权网络的三元联合预测框架，统一预测链接、符号和权重，相比基线方法在链接存在性和关系符号预测上提升2%-4%，边权重预测误差降低40%-50%


<details>
  <summary>Details</summary>
Motivation: 当前结合时间演化、关系极性和边权重信息的复杂动态网络链接预测研究严重不足，无法满足实际需求，特别是对于动态有符号加权网络的统一预测问题

Method: 1. 将动态网络分解为时间快照，通过符号感知加权随机游走生成节点语义嵌入；2. 设计多跳结构平衡和时序差异特征分别捕获网络结构特性和动态演化规律；3. 采用双通道特征解耦机制：节点语义嵌入用于链接存在性预测，关系符号特征输入Transformer编码器建模时序依赖；4. 通过多任务单元协同输出预测结果

Result: 相比基线方法，链接存在性和关系符号预测性能平均提升2%-4%，边权重预测误差显著降低40%-50%

Conclusion: 提出的三元联合预测框架能有效统一预测动态有符号加权网络的链接、符号和权重，解决了现有研究不足的问题，为复杂动态网络分析提供了有效工具

Abstract: Link prediction is central to unraveling social network evolution and node relationships, as well as understanding the characteristic mechanisms of complex networks. Currently, research on link prediction for complex dynamic networks integrating temporal evolution, relational polarity and edge weight information remains significantly underexplored, failing to meet practical demands. For dynamic signed-weighted networks, this paper proposes a tripartite joint prediction framework for unified forecasting of links, signs and weights. First, the dynamic network is decomposed into temporal snapshots, and node semantic embeddings are generated via sign-aware weighted random walks. We then design multi-hop structural balance and temporal difference features to capture the structural characteristics and dynamic evolution laws of the network, respectively. The model adopts a dual-channel feature decoupling mechanism: node semantic embeddings are used for link existence prediction, while relational sign features are fed into a Transformer encoder to model temporal dependencies. Finally, prediction results are output synergistically through a multi-task unit. Simulation experiments demonstrate that, compared with baseline methods, the proposed framework achieves an average 2%-4% improvement in the performance of link existence and relational sign prediction, and a significant 40%-50% reduction in edge weight prediction error.

</details>


### [69] [From Data $H(jω_i)$ to Balanced Truncation Family: A Projection-based Non-intrusive Approach](https://arxiv.org/abs/2602.12697)
*Umair Zulfiqar*

Main category: eess.SY

TL;DR: 提出基于投影的数据驱动平衡截断方法，仅需传递函数在虚轴上的采样值，无需谱分解，可非侵入式实现多种平衡截断变体


<details>
  <summary>Details</summary>
Motivation: 传统平衡截断方法需要系统矩阵信息，难以应用于实际测量数据场景。本文旨在开发仅依赖传递函数采样值的数据驱动平衡截断方法，实现非侵入式模型降阶

Method: 通过投影隐式近似格拉米矩阵，而非传统数值积分方法。提出投影框架，仅使用虚轴上的传递函数采样值，无需谱分解，实现多种平衡截断变体的数据驱动实现

Result: 数值结果表明，所提出的非侵入式实现方法性能与侵入式方法相当，能准确捕捉主导汉克尔奇异值，成功实现了九种平衡截断变体的数据驱动实现

Conclusion: 基于投影的数据驱动平衡截断框架有效实现了仅依赖传递函数采样的非侵入式模型降阶，为实际测量数据场景提供了实用工具，扩展了平衡截断方法的应用范围

Abstract: This paper presents data-driven implementations of balanced truncation and several of its generalizations that rely exclusively on transfer function samples on the imaginary axis. Rather than implicitly approximating the Gramians via numerical quadrature, the proposed approach approximates them implicitly through projection. This enables multiple members of the balanced truncation family to be implemented non-intrusively using practically measurable data, without requiring spectral factorizations. Using this projection-based framework, data-driven implementations are developed for standard balanced truncation, frequency-limited balanced truncation, time-limited balanced truncation, self-weighted balanced truncation, LQG balanced truncation, H-infinity balanced truncation, positive-real balanced truncation, bounded-real balanced truncation, and stochastic balanced truncation. Numerical results demonstrate that the proposed non-intrusive implementations achieve performance comparable to their intrusive counterparts and accurately capture the dominant Hankel singular values.

</details>


### [70] [Data Augmentation and Attention for massive MIMO-based Indoor Localization in Changing Environments](https://arxiv.org/abs/2602.12954)
*Luisa Schuhmacher,Hazem Sallouha,Ihsane Gryech,Sofie Pollin*

Main category: eess.SY

TL;DR: 本文提出两种数据增强技术和注意力模块，以提升大规模MIMO系统在动态环境中的室内定位精度，无需动态场景训练数据即可实现毫米级定位。


<details>
  <summary>Details</summary>
Motivation: 随着智能环境、工业自动化和位置感知应用的发展，对高精度室内定位的需求显著增长。现有大规模MIMO系统解决方案主要针对静态环境优化，而实际应用中动态环境（快速移动、不可预测的遮挡和动态信道条件）带来了重大挑战。

Method: 引入两种模拟天线遮挡的数据增强技术，增强定位模型在动态场景中的泛化能力；在现有深度学习模型中集成注意力模块，提升模型对相关信道特征和天线的关注能力。模型在静态场景数据上训练，使用提出的增强技术，并在动态场景数据集上评估。

Result: 通过数据增强技术和注意力模块的结合，定位精度从平均误差286毫米（无注意力模块和无数据增强）提升到66毫米（有注意力模块和数据增强）。

Conclusion: 研究表明，即使没有动态场景的训练数据，通过数据增强和注意力机制的结合，也能在动态环境中保持高定位精度，为实际应用提供了可行的解决方案。

Abstract: The demand for high-precision indoor localization has grown significantly with the rise of smart environments, industrial automation, and location-aware applications. While massive Multiple-Input and Multiple-Output (MIMO) systems enable millimeter-level accuracy by leveraging rich Channel State Information (CSI), most existing solutions are optimized for static environments, where users or devices remain fixed during data collection and inference. Real-world applications, however, often require real-time localization in changing environments, where rapid movement, unpredictable blockages, and dynamic channel conditions pose significant challenges. To address these challenges, we introduce two data augmentation techniques designed to resemble blocked antennas, enhancing the generalizability of localization models to dynamic scenarios. Additionally, we enhance an existing Deep Learning (DL) model by incorporating attention modules, improving its ability to focus on relevant channel features and antennas. We train our model on data from a static scenario, augmented with the proposed techniques, and evaluate it on a dataset collected in changing scenarios. We investigate the performance enhancements achieved by the data augmentation techniques and the Attention modules, and observe a localization accuracy improvement from a mean error of 286 mm, when trained without Attention and without data augmentations, to 66 mm, when trained with Attention and data augmentation. This shows that high localization accuracy can be maintained in changing environments, even without training data from those scenarios.

</details>


### [71] [Bayesian Optimization Based Grid Point Allocation for LPV and Robust Control](https://arxiv.org/abs/2602.13009)
*E. Javier Olucha,Arash Sadeghzadeh,Amritam Das,Roland Tóth*

Main category: eess.SY

TL;DR: 使用贝叶斯优化自动选择最优网格点，用于LPV和鲁棒控制器综合，减少局部模型评估次数，在三个案例中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在基于网格的LPV和鲁棒控制器综合中，如何系统性地选择最优网格点是一个关键问题。传统方法可能无法高效地识别最能影响闭环性能的局部模型，特别是当局部模型评估计算成本高时。

Method: 采用贝叶斯优化方法，自动发现最能控制闭环性能的信息化点。该方法持续搜索直到性能不再显著提升或达到用户指定限制，并能最小化局部模型评估次数，适应可用计算预算。

Result: 方法在三个案例研究中得到验证：1) 不平衡磁盘的鲁棒控制器设计；2) 具有不确定参数和两个柔性旋转太阳能电池板的卫星多目标鲁棒姿态控制器设计；3) 机械臂的LPV控制器设计。所有案例都成功自动获得了足够信息化的网格集。

Conclusion: 提出的贝叶斯优化方法能够有效自动选择最优网格点，减少计算成本，确保设计的LPV或鲁棒控制器满足全局稳定性和性能要求，特别适用于局部模型评估计算成本高的场景。

Abstract: This paper investigates systematic selection of optimal grid points for grid-based Linear Parameter-Varying (LPV) and robust controller synthesis. In both settings, the objective is to identify a set of local models such that the controller synthesized for these local models will satisfy global stability and performance requirements for the entire system. Here, local models correspond to evaluations of the LPV or uncertain plant at fixed values of the scheduling signal or realizations of the uncertainty set, respectively. Then, Bayesian optimization is employed to discover the most informative points that govern the closed-loop performance of the designed LPV or robust controller for the complete system until no significant further performance increase or a user specified limit is reached. Furthermore, when local model evaluations are computationally demanding or difficult to obtain, the proposed method is capable to minimize the number of evaluations and adjust the overall computational cost to the available budget. Lastly, the capabilities of the proposed method in automatically obtaining a sufficiently informative grid set are demonstrated on three case-studies: a robust controller design for an unbalanced disk, a multi-objective robust attitude controller design for a satellite with uncertain parameters and two flexible rotating solar arrays, and an LPV controller design for a robotic arm.

</details>


### [72] [Encoder initialisation methods in the model augmentation setting](https://arxiv.org/abs/2602.13108)
*J. H. Hoekstra,B. Györök,R. Töth,M. Schoukens*

Main category: eess.SY

TL;DR: 提出基于基线模型的编码器初始化方法，提升非线性系统辨识的噪声鲁棒性和收敛速度


<details>
  <summary>Details</summary>
Motivation: 现有基于编码器的ANN-SS方法虽然性能优异，但编码器仍被视为黑盒函数，未能利用基线模型的先验信息来初始化状态估计

Method: 提出基于可用基线模型的编码器初始化方法，利用基线模型从历史输入输出数据预测模型状态，替代传统的黑盒初始化

Result: 在质量-弹簧-阻尼系统上的实验表明，新方法相比黑盒初始化具有更好的噪声鲁棒性和更快的收敛速度

Conclusion: 利用基线模型信息进行编码器初始化能有效提升模型增强方法的性能，为非线性系统辨识提供了更高效可靠的解决方案

Abstract: Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.

</details>


### [73] [3-D Reconfigurable Intelligent Surface: From Reflection to Transmission and From Single Hemisphere to Full 3-D Coverage](https://arxiv.org/abs/2602.13150)
*Ruiqi Wang,Yiming Yang,Atif Shamim*

Main category: eess.SY

TL;DR: 提出三维可重构智能表面概念，通过立方体结构实现全空间覆盖，相比传统二维RIS扩展了波束扫描范围，在毫米波频段验证了反射和传输性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统二维RIS只能实现半球反射，波束扫描范围有限。为了解决全三维空间覆盖问题，需要突破二维结构的限制，实现近无盲区的三维波束控制。

Method: 提出立方体三维RIS设计，包含六个互连表面。每个表面集成可重构接收和反射阵列，采用正交极化实现电磁隔离，可重构馈电网络支持动态操作。开发基于子阵列的合成方法，采用二进制幅度门控和预定义相位偏移。

Result: 在24-30 GHz频段实验验证，反射增益增强14.7 dB，相邻表面传输增益14.1 dB。无线通信测试显示星座图质量改善，误差矢量幅度提升6-7 dB。

Conclusion: 三维RIS概念成功扩展了波束扫描范围，实现全空间覆盖，为毫米波通信系统提供了新的波束控制解决方案，显著提升了系统性能。

Abstract: Reconfigurable intelligent surfaces (RIS) are conventionally implemented as two-dimensional (2D) electromagnetic (EM) structures to steer incident waves toward desired reflection angles. This approach limits the reflection to a single hemisphere, and the beam-scanning range is relatively small. In this work, a novel three-dimensional (3D) RIS concept is proposed, where beam-scanning can be realized not only through reflection from the illuminated surface but also through controlled transmission toward adjacent surfaces, enabling near blind-spot-free coverage in the full 3D spatial domain. A cube-based 3D-RIS design operating at millimeter-wave (mm-Wave) frequencies and consisting of six interconnected RIS surfaces is presented. Each surface integrates reconfigurable receiving and reflecting arrays with orthogonal polarizations to ensure intrinsic EM isolation, while a reconfigurable feeding network supports dynamic operation. A subarray-based synthesis approach with binary amplitude gating and predefined phase offsets is developed through a unified theoretical model. This model, validated through full-wave simulations, enables efficient beam switching through a shared aperture. Based on this framework, an 8 x 12 element surface comprising six 4 x 4 subarrays is designed, with each surface covering an angular range from -30 deg to +30 deg. The experimental prototype has been characterized in the 24 to 30 GHz band, and the results demonstrate a gain enhancement of 14.7 dB for reflection, while 14.1 dB is achieved for transmission to the neighboring surface. Finally, wireless communication trials using the Pluto software-defined radio platform combined with frequency up/down converters confirm improved constellation quality and a 6-7 dB improvement in error vector magnitude (EVM) for both reflection and neighboring surface transmission scenarios.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [74] [Transformer-based CoVaR: Systemic Risk in Textual Information](https://arxiv.org/abs/2602.12490)
*Junyu Chen,Tom Boot,Lingwei Kong,Weining Wang*

Main category: econ.EM

TL;DR: 提出基于Transformer的方法，将金融新闻文本与市场数据结合，改进系统性风险度量CoVaR的估计，证明即使小数据集也能有效学习，实证显示文本信息能提升预测性能


<details>
  <summary>Details</summary>
Motivation: 传统CoVaR估计主要依赖市场数据，忽略了文本信息对系统性风险的影响。现有方法使用预定义情感分数，无法充分利用原始文本的丰富信息。需要开发能直接整合原始文本嵌入的方法来改进CoVaR估计

Method: 开发基于Transformer的方法，将大型语言模型生成的原始文本嵌入与市场数据整合。不同于使用预定义情感分数的方法，直接使用LLM生成的文本嵌入。为Transformer CoVaR估计器提供了明确的误差界限证明

Result: 使用2006-2013年美国市场收益和路透社新闻数据进行样本外测试，结果显示文本信息显著影响CoVaR预测。与无文本的CoVaR和使用传统情感度量的CoVaR相比，Transformer方法在市场压力期间对多个权益资产显示出更明显的负面下降，具有更好的预测性能

Conclusion: 文本数据可以有效用于建模系统性风险，无需庞大的数据集。基于Transformer的方法能更好地捕捉市场压力期间的风险动态，为系统性风险监测提供了更准确的工具

Abstract: Conditional Value-at-Risk (CoVaR) quantifies systemic financial risk by measuring the loss quantile of one asset, conditional on another asset experiencing distress. We develop a Transformer-based methodology that integrates financial news articles directly with market data to improve CoVaR estimates. Unlike approaches that use predefined sentiment scores, our method incorporates raw text embeddings generated by a large language model (LLM). We prove explicit error bounds for our Transformer CoVaR estimator, showing that accurate CoVaR learning is possible even with small datasets. Using U.S. market returns and Reuters news items from 2006--2013, our out-of-sample results show that textual information impacts the CoVaR forecasts. With better predictive performance, we identify a pronounced negative dip during market stress periods across several equity assets when comparing the Transformer-based CoVaR to both the CoVaR without text and the CoVaR using traditional sentiment measures. Our results show that textual data can be used to effectively model systemic risk without requiring prohibitively large data sets.

</details>


### [75] [Toggling the Defiers to Relax Monotonicity: The Difference-in-Instrumental-Variables Estimand](https://arxiv.org/abs/2602.12504)
*Johann Caro-Burnett*

Main category: econ.EM

TL;DR: 提出DIIV估计量，利用两个具有相反依从模式的工具变量，在不施加单调性假设下识别可解释的因果效应


<details>
  <summary>Details</summary>
Motivation: 传统工具变量方法需要单调性假设（排除defiers），但在许多实证环境中，不同工具变量可能引发异质甚至相反的行为响应，需要新的识别方法

Method: 引入Difference-in-Instrumental-Variables (DIIV)估计量，利用两个具有相反依从模式的工具变量，通过简单的线性变换和标准两阶段最小二乘法实现

Result: DIIV估计量得到compliers和defiers边际处理效应的凸组合，权重反映不同工具变量对治疗采纳的差异影响；当单调性成立时，DIIV与传统IV估计量一致

Conclusion: DIIV方法在不依赖单调性假设的情况下提供点识别和行为可解释的因果效应估计，具有实际应用价值

Abstract: Standard instrumental variables (IV) methods identify a Local Average Treatment Effect under monotonicity, which rules out defiers. In many empirical environments, however, distinct instruments may induce heterogeneous and even opposing behavioral responses. This paper introduces the Difference-in-Instrumental-Variables (DIIV) estimand, which exploits two instruments with opposing compliance patterns to recover a point-identified and behaviorally interpretable causal effect without imposing monotonicity. The estimand yields a convex combination of the marginal treatment effects on compliers and defiers, with weights reflecting differential shifts in treatment take-up across instruments. When monotonicity holds, DIIV coincides with the standard IV estimand. The approach can be implemented using simple linear transformations and standard two-stage least squares procedures. Applications using replication data illustrate its applicability in practice.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [76] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: GT-HarmBench是一个包含2009个高风险场景的多智能体安全基准测试，覆盖囚徒困境、猎鹿博弈等博弈论结构，评估前沿AI模型在多智能体环境中的社会效益行为表现。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全基准主要评估单智能体，而多智能体环境中的协调失败和冲突等风险缺乏系统评估。需要建立标准化的多智能体安全测试平台来理解这些风险。

Method: 从MIT AI风险库中提取真实AI风险场景，构建包含2009个高风险场景的基准测试，涵盖囚徒困境、猎鹿博弈、斗鸡博弈等博弈论结构。评估15个前沿模型，分析博弈论提示框架和顺序的影响，并研究导致失败的推理模式。

Result: 前沿模型仅在62%的情况下选择社会效益行为，经常导致有害结果。博弈论干预可将社会效益结果提高最多18%。模型对提示框架和顺序敏感，存在显著的可靠性差距。

Conclusion: 多智能体环境中存在严重的AI安全风险，需要专门的评估和干预。GT-HarmBench为研究多智能体对齐提供了标准化的测试平台，博弈论方法可有效改善AI的社会效益行为。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [77] [A Theoretical Framework for Adaptive Utility-Weighted Benchmarking](https://arxiv.org/abs/2602.12356)
*Philip Waggoner*

Main category: cs.AI

TL;DR: 本文提出一个多层自适应网络框架，将基准测试重新概念化为连接评估指标、模型组件和利益相关者群体的动态系统，通过人类参与更新规则嵌入人类权衡，旨在创建更符合情境、更负责任且与人类对齐的评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在更多样化和重要的场景中部署，传统基准测试方法（如共享任务、指标和排行榜）已不足以全面评估系统表现。需要更整体的评估概念化，考虑系统运行的社会技术背景，纳入不同利益相关者及其独特优先级，以定义更有意义的模型行为。

Method: 提出一个理论框架，将基准测试重新概念化为多层自适应网络，连接评估指标、模型组件和利益相关者群体，通过加权交互形成动态系统。使用联合分析衍生的效用和人类在环更新规则，将人类权衡嵌入基准结构，使基准能够动态演化同时保持稳定性和可解释性。

Result: 该框架将经典排行榜推广为特例，为构建更具情境感知的评估协议提供基础，产生用于分析基准结构特性的新鲁棒工具，为更负责任和人类对齐的评估开辟路径。

Conclusion: 通过将基准测试重新概念化为多层自适应网络，可以创建更符合情境、更负责任且与人类对齐的评估方法，超越传统静态评估，更好地反映AI系统在实际部署中的复杂社会技术背景。

Abstract: Benchmarking has long served as a foundational practice in machine learning and, increasingly, in modern AI systems such as large language models, where shared tasks, metrics, and leaderboards offer a common basis for measuring progress and comparing approaches. As AI systems are deployed in more varied and consequential settings, though, there is growing value in complementing these established practices with a more holistic conceptualization of what evaluation should represent. Of note, recognizing the sociotechnical contexts in which these systems operate invites an opportunity for a deeper view of how multiple stakeholders and their unique priorities might inform what we consider meaningful or desirable model behavior. This paper introduces a theoretical framework that reconceptualizes benchmarking as a multilayer, adaptive network linking evaluation metrics, model components, and stakeholder groups through weighted interactions. Using conjoint-derived utilities and a human-in-the-loop update rule, we formalize how human tradeoffs can be embedded into benchmark structure and how benchmarks can evolve dynamically while preserving stability and interpretability. The resulting formulation generalizes classical leaderboards as a special case and provides a foundation for building evaluation protocols that are more context aware, resulting in new robust tools for analyzing the structural properties of benchmarks, which opens a path toward more accountable and human-aligned evaluation.

</details>


### [78] [Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting](https://arxiv.org/abs/2602.12389)
*Siyuan Li,Yunjia Wu,Yiyong Xiao,Pingyang Huang,Peize Li,Ruitong Liu,Yan Wen,Te Sun,Fangyi Pei*

Main category: cs.AI

TL;DR: 提出Entity State Tuning (EST)框架，通过维护持续演化的实体状态来解决时序知识图谱预测中的长期依赖衰减问题，显著提升多种骨干模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱预测方法大多是无状态的，每次从有限查询窗口重新计算实体表示，导致"片段性遗忘"和长期依赖快速衰减，限制了长期预测能力。

Method: 提出EST框架：1) 维护全局状态缓冲区；2) 拓扑感知状态感知器将实体状态先验注入结构编码；3) 统一时序上下文模块聚合状态增强的事件；4) 双轨演化机制将更新后的上下文写回全局实体状态内存，平衡可塑性与稳定性。

Result: 在多个基准测试中，EST框架持续改进不同骨干模型，实现了最先进的性能，证明了状态持久性对长期时序知识图谱预测的重要性。

Conclusion: EST框架通过赋予时序知识图谱预测器持久且持续演化的实体状态，有效解决了长期依赖衰减问题，为时序知识图谱预测提供了新的解决方案。

Abstract: Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity representations at each timestamp from a limited query window, leading to episodic amnesia and rapid decay of long-term dependencies. To address this limitation, we propose Entity State Tuning (EST), an encoder-agnostic framework that endows TKG forecasters with persistent and continuously evolving entity states. EST maintains a global state buffer and progressively aligns structural evidence with sequential signals via a closed-loop design. Specifically, a topology-aware state perceiver first injects entity-state priors into structural encoding. Then, a unified temporal context module aggregates the state-enhanced events with a pluggable sequence backbone. Subsequently, a dual-track evolution mechanism writes the updated context back to the global entity state memory, balancing plasticity against stability. Experiments on multiple benchmarks show that EST consistently improves diverse backbones and achieves state-of-the-art performance, highlighting the importance of state persistence for long-horizon TKG forecasting. The code is published at https://github.com/yuanwuyuan9/Evolving-Beyond-Snapshots

</details>


### [79] [Intent-Driven Smart Manufacturing Integrating Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2602.12419)
*Takoua Jradi,John Violos,Dimitrios Spatharakis,Lydia Mavraidi,Ioannis Dimolitsas,Aris Leivadeas,Symeon Papavassiliou*

Main category: cs.AI

TL;DR: 提出一个结合指令调优LLM与知识图谱的统一框架，用于将自然语言意图转换为制造服务中的可执行动作


<details>
  <summary>Details</summary>
Motivation: 智能制造环境日益复杂，需要能够将高级人类意图转换为机器可执行动作的接口，以支持制造即服务生态系统

Method: 微调Mistral-7B-Instruct-V02模型处理领域特定数据，将自然语言意图转换为结构化JSON需求模型，并通过Neo4j知识图谱进行语义映射，基于ISA-95标准确保与制造流程对齐

Result: 实验结果显示显著优于零样本和3样本基线，达到89.33%精确匹配准确率和97.27%总体准确率

Conclusion: 为可扩展、可解释和自适应的人机交互奠定了重要基础，支持智能制造环境中的意图驱动交互

Abstract: The increasing complexity of smart manufacturing environments demands interfaces that can translate high-level human intents into machine-executable actions. This paper presents a unified framework that integrates instruction-tuned Large Language Models (LLMs) with ontology-aligned Knowledge Graphs (KGs) to enable intent-driven interaction in Manufacturing-as-a-Service (MaaS) ecosystems. We fine-tune Mistral-7B-Instruct-V02 on a domain-specific dataset, enabling the translation of natural language intents into structured JSON requirement models. These models are semantically mapped to a Neo4j-based knowledge graph grounded in the ISA-95 standard, ensuring operational alignment with manufacturing processes, resources, and constraints. Our experimental results demonstrate significant performance gains over zero-shot and 3-shots baselines, achieving 89.33\% exact match accuracy and 97.27\% overall accuracy. This work lays the foundation for scalable, explainable, and adaptive human-machine

</details>


### [80] [Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation](https://arxiv.org/abs/2602.12544)
*Lajanugen Logeswaran,Jaekyeom Kim,Sungryull Sohn,Creighton Glasscock,Honglak Lee*

Main category: cs.AI

TL;DR: 提出一个自动生成高质量网页代理训练数据的可扩展流程，通过约束评估框架利用部分成功轨迹扩大可用训练数据，在BookingArena基准上超越开源方法并匹敌商业系统


<details>
  <summary>Details</summary>
Motivation: 网页代理训练面临高质量训练数据稀缺的挑战，特别是难以评估轨迹质量（任务完成进度），需要更有效的训练数据生成和评估方法

Method: 引入基于约束的评估框架，对任务完成进度进行细粒度评估；利用部分成功轨迹扩展可用训练数据；提出BookingArena基准，包含20个热门网站的复杂预订任务

Result: 蒸馏出的学生模型在BookingArena基准上超越开源方法，匹配或超过商业系统，同时模型规模显著更小

Conclusion: 解决了高效创建多样化、真实网页交互数据集的挑战，为复杂结构化网页任务提供了系统化评估方法，显著提升了网页代理的训练效果

Abstract: We present a scalable pipeline for automatically generating high-quality training data for web agents. In particular, a major challenge in identifying high-quality training instances is trajectory evaluation - quantifying how much progress was made towards task completion. We introduce a novel constraint-based evaluation framework that provides fine-grained assessment of progress towards task completion. This enables us to leverage partially successful trajectories, which significantly expands the amount of usable training data. We evaluate our method on a new benchmark we propose called BookingArena, which consists of complex booking tasks across 20 popular websites, and demonstrate that our distilled student model outperforms open-source approaches and matches or exceeds commercial systems, while being a significantly smaller model. Our work addresses the challenge of efficiently creating diverse, realistic web interaction datasets and provides a systematic evaluation methodology for complex structured web tasks.

</details>


### [81] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 该论文比较了多领域RLVR的两种训练范式：混合多任务训练与分别训练后模型合并，发现跨领域RLVR相互干扰较少，推理密集型领域存在协同效应。


<details>
  <summary>Details</summary>
Motivation: 当前多领域专家级模型需要跨领域RLVR协作，但现有研究缺乏对混合多任务RLVR和分别训练后模型合并这两种范式的详细比较分析。

Method: 选择数学、编程、科学和指令跟随等多个常用高级任务作为目标领域，使用开源数据集设计大量定性和定量实验，从权重空间几何、模型预测行为和信息约束等角度分析内部机制。

Result: 发现跨领域RLVR表现出较少的相互干扰，推理密集型领域展现出相互协同效应，并从多个角度分析了相互增益的内部机制。

Conclusion: 该研究为多领域RLVR训练提供了实证分析，项目命名为M2RL（混合多任务训练或分别训练后模型合并的强化学习），有助于指导多领域专家级模型的开发。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [82] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: McDiffuSE使用蒙特卡洛树搜索优化掩码扩散模型中的槽位填充顺序，通过前瞻模拟评估部分完成情况，显著提升数学和代码推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散模型中的计划-填充解码方法在数学和代码推理中表现有潜力，但性能对槽位填充顺序高度敏感，导致输出方差大，需要系统化的顺序优化方法。

Method: 将槽位选择建模为决策问题，使用蒙特卡洛树搜索优化填充顺序，通过前瞻模拟评估部分完成情况，系统探索生成顺序的组合空间。

Result: 相比自回归基线平均提升3.2%，相比基线计划-填充方法提升8.0%，在MBPP上提升19.5%，在MATH500上提升4.9%。发现更大的探索常数比增加模拟次数更重要。

Conclusion: MCTS规划是提升掩码扩散模型生成质量的有效方法，虽然主要遵循顺序生成，但结合非顺序生成对最大化性能至关重要，需要克服模型置信度偏差。

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [83] [GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics](https://arxiv.org/abs/2602.12617)
*Modi Jin,Yiming Zhang,Boyuan Sun,Dingwen Zhang,MingMing Cheng,Qibin Hou*

Main category: cs.AI

TL;DR: GeoAgent是一个能够与人类紧密推理并得出细粒度地址结论的模型，通过专家标注的地理定位数据集和地理相似性奖励机制，在多个粒度上超越了现有方法


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的方法虽然在性能和可解释性方面取得了突破，但由于依赖AI生成的思维链数据和训练策略，与地理特性存在冲突，需要更符合地理特征的方法

Method: 1) 引入GeoSeek数据集，包含地理专家和专业玩家标注的思维链数据；2) 提出地理相似性奖励和一致性奖励（通过一致性智能体评估），鼓励模型从地理角度收敛到正确答案并确保推理过程的完整性

Result: 实验结果表明，GeoAgent在多个粒度上超越了现有方法和一系列通用视觉语言大模型，同时生成的推理过程与人类思维紧密对齐

Conclusion: GeoAgent通过专家标注的数据集和专门设计的地理奖励机制，成功解决了现有方法在地理任务中的局限性，实现了更好的性能和更符合人类推理的思维过程

Abstract: This paper presents GeoAgent, a model capable of reasoning closely with humans and deriving fine-grained address conclusions. Previous RL-based methods have achieved breakthroughs in performance and interpretability but still remain concerns because of their reliance on AI-generated chain-of-thought (CoT) data and training strategies, which conflict with geographic characteristics. To address these issues, we first introduce GeoSeek, a new geolocation dataset comprising CoT data annotated by geographic experts and professional players. We further thoroughly explore the inherent characteristics of geographic tasks and propose a geo-similarity reward and a consistency reward assessed by a consistency agent to assist training. This encourages the model to converge towards correct answers from a geographic perspective while ensuring the integrity and consistency of its reasoning process. Experimental results show that GeoAgent outperforms existing methods and a series of general VLLMs across multiple grains, while generating reasoning that closely aligns with humans.

</details>


### [84] [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631)
*Jackie Baek,Yaopeng Fu,Will Ma,Tianyi Peng*

Main category: cs.AI

TL;DR: LLM增强的运筹学方法在库存控制中优于单独使用运筹学算法或LLM，且人机协作能提升整体绩效


<details>
  <summary>Details</summary>
Motivation: 传统运筹学算法依赖刚性建模假设，在需求分布变化或缺乏上下文信息时表现不佳；LLM虽然能灵活推理并整合丰富上下文信号，但如何将其有效整合到传统决策流程中仍不明确

Method: 构建InventoryBench基准测试（包含1000多个库存实例，涵盖合成和真实需求数据），测试需求变化、季节性和不确定交货期下的决策规则；通过课堂实验研究人机协作决策流程

Result: 运筹学增强的LLM方法优于单独使用任一种方法；人机协作团队的平均利润高于单独使用人类或AI代理；推导了个体层面互补效应的分布无关下界，实证发现受益个体比例显著

Conclusion: 运筹学算法、LLM和人类在库存控制中是互补而非替代关系，整合方法能提升决策性能，人机协作具有显著价值

Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

</details>


### [85] [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662)
*Ruihan Yang,Fanghua Ye,Xiang We,Ruoqing Zhao,Kang Luo,Xinbo Xu,Bo Zhao,Ruotian Ma,Shanyi Wang,Zhaopeng Tu,Xiaolong Li,Deqing Yang,Linus*

Main category: cs.AI

TL;DR: CogRouter是一个让LLM智能体动态调整认知深度的框架，通过分层认知级别和两阶段训练，在长视野任务中实现高效决策。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体采用固定认知模式：非思考模型立即响应，思考模型统一深度推理。这种刚性在长视野任务中效率低下，因为不同步骤的认知需求差异很大，有些需要战略规划，有些只需常规执行。

Method: 基于ACT-R理论设计四个分层认知级别（从本能响应到战略规划）。采用两阶段训练：认知感知监督微调（CoSFT）建立稳定的级别特定模式，认知感知策略优化（CoPO）通过置信度感知优势重加权进行步骤级信用分配。

Result: 在ALFWorld和ScienceWorld实验中，CogRouter达到最先进性能且效率优越。使用Qwen2.5-7B模型，成功率达到82.3%，优于GPT-4o（+40.3%）、OpenAI-o3（+18.3%）和GRPO（+14.0%），同时减少62%的token使用。

Conclusion: CogRouter通过动态调整认知深度，使LLM智能体能够根据任务需求灵活选择认知策略，在长视野决策任务中实现高效高性能。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigidity is inefficient for long-horizon tasks, where cognitive demands vary significantly from step to step, with some requiring strategic planning and others only routine execution. In this paper, we introduce CogRouter, a framework that trains agents to dynamically adapt cognitive depth at each step. Grounded in ACT-R theory, we design four hierarchical cognitive levels ranging from instinctive responses to strategic planning. Our two-stage training approach includes Cognition-aware Supervised Fine-tuning (CoSFT) to instill stable level-specific patterns, and Cognition-aware Policy Optimization (CoPO) for step-level credit assignment via confidence-aware advantage reweighting. The key insight is that appropriate cognitive depth should maximize the confidence of the resulting action. Experiments on ALFWorld and ScienceWorld demonstrate that CogRouter achieves state-of-the-art performance with superior efficiency. With Qwen2.5-7B, it reaches an 82.3% success rate, outperforming GPT-4o (+40.3%), OpenAI-o3 (+18.3%), and GRPO (+14.0%), while using 62% fewer tokens.

</details>


### [86] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 该论文提出了一个用于评估LLM推理器的诊断性2-SAT基准，通过参数化公式生成器分离表面难度与结构现象，揭示LLM在特定结构干预下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有SAT基准常将表面难度（长度、措辞、子句顺序）与决定可满足性的结构现象混为一谈，无法准确评估LLM推理器的真实能力。需要设计能分离这些因素的诊断性基准。

Method: 构建基于参数化结构化2-CNF公式的诊断基准，通过五种生成器隔离不同能力：矛盾循环UNSAT核心、SAT实例、植入骨干、晚期桥接子句、对称/重复变体。评估LLM在决策准确性和赋值有效性上的表现，并测试语义保留扰动下的鲁棒性。

Result: 实验发现，即使表面统计特征保持不变，LLM推理器在针对性结构干预下会出现明显的性能转变，揭示出在聚合SAT准确率中不可见的脆弱性区域。

Conclusion: 该诊断基准能够有效揭示LLM推理器在结构化逻辑推理中的特定失败模式，为评估和改进LLM的逻辑推理能力提供了更精细的工具。

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [87] [SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks](https://arxiv.org/abs/2602.12670)
*Xiangyi Li,Wenbo Chen,Yimin Liu,Shenghan Zheng,Xiaokun Chen,Yifeng He,Yubo Li,Bingran You,Haotian Shen,Jiankai Sun,Shuyi Wang,Qunhong Zeng,Di Wang,Xuandong Zhao,Yuanli Wang,Roey Ben Chaim,Zonglin Di,Yipeng Gao,Junwei He,Yizhuo He,Liqiang Jing,Luyang Kong,Xin Lan,Jiachen Li,Songlin Li,Yijiang Li,Yueqian Lin,Xinyi Liu,Xuanqing Liu,Haoran Lyu,Ze Ma,Bowei Wang,Runhui Wang,Tianyu Wang,Wengao Ye,Yue Zhang,Hanwen Xing,Yiqi Xue,Steven Dillmann,Han-chung Lee*

Main category: cs.AI

TL;DR: SkillsBench基准测试评估Agent Skills对LLM代理的帮助，发现精心设计的技能平均提升16.2%通过率，但效果因领域差异大，自生成技能无益，小模型搭配技能可匹配无技能的大模型。


<details>
  <summary>Details</summary>
Motivation: 尽管Agent Skills被广泛采用，但缺乏标准方法来衡量其实际效果。需要系统评估技能是否真正提升LLM代理的性能。

Method: 提出SkillsBench基准：包含11个领域86个任务，每个任务配有精心设计的技能和确定性验证器。在三种条件下测试：无技能、精心设计技能、自生成技能。测试7种代理模型配置，共7,308条轨迹。

Result: 精心设计技能平均提升通过率16.2个百分点，但效果差异大：软件工程领域仅提升4.5个百分点，医疗领域提升51.9个百分点。84个任务中有16个显示负收益。自生成技能平均无益。2-3个模块的聚焦技能优于全面文档。小模型搭配技能可匹配无技能的大模型。

Conclusion: 精心设计的Agent Skills能显著提升LLM代理性能，但效果因领域和任务而异。模型无法可靠地生成自身能受益的程序性知识。技能设计应聚焦而非全面，且技能能让小模型达到大模型水平。

Abstract: Agent Skills are structured packages of procedural knowledge that augment LLM agents at inference time. Despite rapid adoption, there is no standard way to measure whether they actually help. We present SkillsBench, a benchmark of 86 tasks across 11 domains paired with curated Skills and deterministic verifiers. Each task is evaluated under three conditions: no Skills, curated Skills, and self-generated Skills. We test 7 agent-model configurations over 7,308 trajectories. Curated Skills raise average pass rate by 16.2 percentage points(pp), but effects vary widely by domain (+4.5pp for Software Engineering to +51.9pp for Healthcare) and 16 of 84 tasks show negative deltas. Self-generated Skills provide no benefit on average, showing that models cannot reliably author the procedural knowledge they benefit from consuming. Focused Skills with 2--3 modules outperform comprehensive documentation, and smaller models with Skills can match larger models without them.

</details>


### [88] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: X-SYS：一个用于交互式解释系统的参考架构，通过STAR质量属性和五组件分解，将用户界面与后端计算解耦，并在SemanticLens系统中实现。


<details>
  <summary>Details</summary>
Motivation: 尽管可解释AI（XAI）研究提出了许多技术方法，但将可解释性部署为系统仍然具有挑战性。交互式解释系统需要合适的算法和系统能力，以在重复查询、模型和数据演化以及治理约束下保持解释可用性。作者认为，将XAI操作化需要将可解释性视为信息系统问题，其中用户交互需求引发特定的系统要求。

Method: 提出了X-SYS参考架构，围绕四个STAR质量属性（可扩展性、可追溯性、响应性和适应性）组织，并指定了五组件分解（XUI服务、解释服务、模型服务、数据服务、编排和治理）。该架构将交互模式映射到系统能力，以解耦用户界面演进与后端计算。通过SemanticLens系统（用于视觉语言模型的语义搜索和激活引导）实现了X-SYS。

Result: X-SYS提供了一个可重用的蓝图，用于在操作约束下支持端到端设计的交互式解释系统。SemanticLens展示了基于契约的服务边界如何实现独立演进，离线/在线分离确保响应性，持久状态管理支持可追溯性。

Conclusion: 这项工作为交互式解释系统提供了可重用的蓝图和具体实例，通过X-SYS参考架构和SemanticLens实现，展示了如何在操作约束下支持端到端设计，将可解释性视为信息系统问题而非单纯算法问题。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [89] [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852)
*Junjie Wang,Zequn Xie,Dan Yang,Jie Feng,Yue Shen,Duolin Sun,Meixiu Long,Yihan Jiao,Zhehao Tan,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: WebClipper：通过图剪枝压缩网页代理轨迹的框架，减少约20%工具调用轮次同时提升准确率


<details>
  <summary>Details</summary>
Motivation: 现有网页代理存在搜索效率问题，依赖长工具调用轨迹和循环推理，探索无效果分支，需要优化轨迹压缩

Method: 将代理搜索过程建模为状态图，将轨迹优化转化为最小必要有向无环图挖掘问题，通过图剪枝压缩轨迹

Result: 减少约20%工具调用轮次同时提升准确率，引入F-AE Score平衡准确率和效率，在保持优秀性能下压缩工具调用

Conclusion: WebClipper为网页代理设计提供了平衡效果和效率的实用见解，通过轨迹压缩实现更高效的搜索模式

Abstract: Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and exploration of unproductive branches. To address this, we propose WebClipper, a framework that compresses web agent trajectories via graph-based pruning. Concretely, we model the agent's search process as a state graph and cast trajectory optimization as a minimum-necessary Directed Acyclic Graph (DAG) mining problem, yielding pruned trajectories that preserve essential reasoning while eliminating redundant steps. Continued training on these refined trajectories enables the agent to evolve toward more efficient search patterns and reduces tool-call rounds by about 20% while improving accuracy. Furthermore, we introduce a new metric called F-AE Score to measure the model's overall performance in balancing accuracy and efficiency. Experiments demonstrate that WebClipper compresses tool-call rounds under excellent performance, providing practical insight into balancing effectiveness and efficiency in web agent design.

</details>


### [90] [BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2602.12876)
*Huanyao Zhang,Jiepeng Zhou,Bo Li,Bowen Zhou,Yanzhe Dan,Haishan Lu,Zhiyong Cao,Jiaoyang Chen,Yuqian Han,Zinan Sheng,Zhengwei Tao,Hao Liang,Jialong Wu,Yang Shi,Yuanpeng He,Jiaye Lin,Qintong Zhang,Guochen Yan,Runhao Zhao,Zhengpin Li,Xiaohan Yu,Lang Mei,Chong Chen,Wentao Zhang,Bin Cui*

Main category: cs.AI

TL;DR: BrowseComp-V³是一个用于评估多模态大语言模型深度搜索能力的新基准，包含300个跨领域挑战性问题，强调多模态多跳推理，所有证据需公开可搜索，并采用专家验证的子目标过程评估机制。


<details>
  <summary>Details</summary>
Motivation: 现有多模态浏览基准在任务复杂性、证据可访问性和评估粒度方面存在局限，无法全面评估深度搜索能力，需要更严谨的基准来推动多模态自主代理的发展。

Method: 1) 构建BrowseComp-V³基准：包含300个精心设计的跨领域问题，强调深度、多层次、跨模态多跳推理；2) 所有证据要求公开可搜索以确保公平性；3) 引入专家验证的子目标驱动过程评估机制；4) 提出OmniSeeker统一多模态浏览代理框架。

Result: 即使最先进的模型在BrowseComp-V³上仅达到36%的准确率，揭示了多模态信息整合和细粒度感知方面的关键瓶颈，表明当前模型能力与现实世界稳健多模态深度搜索之间存在根本差距。

Conclusion: BrowseComp-V³基准填补了现有评估空白，揭示了多模态深度搜索的关键挑战，为未来研究提供了重要方向，强调需要更强大的多模态信息整合和细粒度感知能力。

Abstract: Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain limited in task complexity, evidence accessibility, and evaluation granularity, hindering comprehensive and reproducible assessments of deep search capabilities. To address these limitations, we introduce BrowseComp-$V^3$, a novel benchmark consisting of 300 carefully curated and challenging questions spanning diverse domains. The benchmark emphasizes deep, multi-level, and cross-modal multi-hop reasoning, where critical evidence is interleaved across textual and visual modalities within and across web pages. All supporting evidence is strictly required to be publicly searchable, ensuring fairness and reproducibility. Beyond final-answer accuracy, we incorporate an expert-validated, subgoal-driven process evaluation mechanism that enables fine-grained analysis of intermediate reasoning behaviors and systematic characterization of capability boundaries. In addition, we propose OmniSeeker, a unified multimodal browsing agent framework integrating diverse web search and visual perception tools. Comprehensive experiments demonstrate that even state-of-the-art models achieve only 36% accuracy on our benchmark, revealing critical bottlenecks in multimodal information integration and fine-grained perception. Our results highlight a fundamental gap between current model capabilities and robust multimodal deep search in real-world settings.

</details>


### [91] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: 最优策略包含n log m比特的环境信息，这是最优性所需的"隐式世界模型"的信息论下界


<details>
  <summary>Details</summary>
Motivation: 研究AI成功行为是否需要内部世界表示，量化最优策略提供的环境信息量

Method: 使用控制马尔可夫过程(CMP)，假设转移动态空间上的均匀先验，分析确定性最优策略与环境的互信息

Result: 证明对于任何非常数奖励函数的最优确定性策略，其与环境之间的互信息恰好为n log m比特

Conclusion: 最优性需要至少n log m比特的"隐式世界模型"，为AI内部表示需求提供了精确的信息论下界

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [92] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: 推理模型在对抗攻击下表现出有意义但不完整的鲁棒性，虽然优于指令调优基线，但存在多种脆弱性模式，且基于置信度的防御方法对推理模型失效


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务上表现出色，但其在多轮对抗压力下的鲁棒性尚未得到充分探索。本文旨在评估前沿推理模型在对抗攻击下的表现，探究推理能力是否自动带来对抗鲁棒性。

Method: 评估九个前沿推理模型在对抗攻击下的表现，通过轨迹分析识别失败模式，并测试置信感知响应生成（CARG）等防御方法对推理模型的有效性。

Result: 推理提供了有意义但不完整的鲁棒性：大多数推理模型显著优于指令调优基线，但所有模型都表现出不同的脆弱性模式。误导性建议普遍有效，社会压力则具有模型特异性。识别出五种失败模式（自我怀疑、社会从众、建议劫持、情感易感性、推理疲劳），前两种占失败的50%。CARG防御对推理模型失效，因为扩展推理轨迹会导致过度自信；相反，随机置信嵌入表现更好。

Conclusion: 推理能力不会自动带来对抗鲁棒性，基于置信度的防御方法需要对推理模型进行根本性重新设计。需要针对推理模型的独特脆弱性开发专门的防御机制。

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [93] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: 提出约束ABA（CABA）框架，通过引入约束变量扩展传统ABA，支持非地面参数和攻击，适用于无限域


<details>
  <summary>Details</summary>
Motivation: 传统ABA框架基于原子语言，仅限于地面（无变量）参数和命题原子构建的攻击，限制了其表示能力和应用范围

Method: 提出约束ABA（CABA）框架，允许组件和参数包含约束变量，变量可在可能无限的域中取值，定义基于非地面攻击概念的非地面语义

Result: 新语义保守地推广了标准ABA语义，保持了向后兼容性

Conclusion: CABA框架成功扩展了ABA的表示能力，使其能够处理包含变量的非地面参数，同时保持与传统ABA的语义一致性

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [94] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 提出混合障碍物规避架构，结合最优控制与模糊规则系统，实现无人机自适应约束处理，但发现软件兼容性问题影响约束执行。


<details>
  <summary>Details</summary>
Motivation: 经典最优控制在不确定性下存在局限，且航空安全关键系统需要可解释的决策制定，因此需要开发既能适应动态环境又能符合航空法规的障碍物规避方法。

Method: 设计三层Takagi-Sugeno-Kang模糊系统，根据FAA和EASA的分离标准和适航指南，调节约束半径、紧急程度和激活决策；将模糊生成的间隙作为软约束纳入最优控制问题，使用FALCON工具箱和IPOPT求解。

Result: 概念验证显示，在简化飞机模型下，每次迭代计算时间约2-3秒，具备近实时应用潜力；但发现FALCON和IPOPT最新版本存在软件不兼容问题，导致拉格朗日惩罚项始终为零，无法正确执行约束。

Conclusion: 混合架构展示了可行性和计算效率，但软件兼容性问题需要解决；未来工作包括验证软件回归、优化模糊隶属函数、扩展到高保真飞机模型和随机障碍环境。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [95] [Linear Regression with Unknown Truncation Beyond Gaussian Features](https://arxiv.org/abs/2602.12534)
*Alexandros Kouridakis,Anay Mehrotra,Alkis Kalavasis,Constantine Caramanis*

Main category: stat.ML

TL;DR: 提出了首个多项式时间算法，用于解决生存集未知的截断线性回归问题，仅需特征向量满足次高斯分布。


<details>
  <summary>Details</summary>
Motivation: 截断线性回归中，大多数现有研究假设生存集S*已知，但在实际应用中生存集通常是未知的。现有算法需要强分布假设（如高斯性）且运行时间是指数级的，这限制了实际应用。

Method: 开发了一个新颖的子程序，用于高效学习有界数量的区间并集，仅使用正例（无负例）并在一定平滑性条件下。该算法仅要求特征向量满足次高斯分布。

Result: 提出了首个在poly(d/ε)时间内运行的算法，用于解决生存集未知的截断线性回归问题，突破了现有算法需要指数运行时间的限制。

Conclusion: 该工作解决了截断线性回归中生存集未知的长期开放问题，提供了多项式时间算法，仅需次高斯分布假设，同时提出的正例学习子程序对正例PAC学习领域有独立贡献。

Abstract: In truncated linear regression, samples $(x,y)$ are shown only when the outcome $y$ falls inside a certain survival set $S^\star$ and the goal is to estimate the unknown $d$-dimensional regressor $w^\star$. This problem has a long history of study in Statistics and Machine Learning going back to the works of (Galton, 1897; Tobin, 1958) and more recently in, e.g., (Daskalakis et al., 2019; 2021; Lee et al., 2023; 2024). Despite this long history, however, most prior works are limited to the special case where $S^\star$ is precisely known. The more practically relevant case, where $S^\star$ is unknown and must be learned from data, remains open: indeed, here the only available algorithms require strong assumptions on the distribution of the feature vectors (e.g., Gaussianity) and, even then, have a $d^{\mathrm{poly} (1/\varepsilon)}$ run time for achieving $\varepsilon$ accuracy.
  In this work, we give the first algorithm for truncated linear regression with unknown survival set that runs in $\mathrm{poly} (d/\varepsilon)$ time, by only requiring that the feature vectors are sub-Gaussian. Our algorithm relies on a novel subroutine for efficiently learning unions of a bounded number of intervals using access to positive examples (without any negative examples) under a certain smoothness condition. This learning guarantee adds to the line of works on positive-only PAC learning and may be of independent interest.

</details>


### [96] [A Regularization-Sharpness Tradeoff for Linear Interpolators](https://arxiv.org/abs/2602.12680)
*Qingyi Hu,Liam Hodgkinson*

Main category: stat.ML

TL;DR: 该论文提出了过参数化线性回归中正则化-锐度权衡的新框架，扩展了传统偏置-方差权衡在过参数化场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统偏置-方差权衡在过参数化设置中失效（双下降曲线），最小范数插值估计器表现良好，需要新的权衡框架来理解过参数化模型的选择。

Method: 提出正则化-锐度权衡框架，基于插值信息准则，将选择惩罚分解为正则化项（量化正则器与插值器的对齐）和几何锐度项（量化插值流形上的局部扰动效应），适用于ℓ^p惩罚（p≥2）和LASSO（ℓ^1正则器）。

Result: 给出了ℓ^p正则器的插值信息准则一般表达式，扩展到LASSO插值器，在真实数据集（随机傅里叶特征和多项式）上验证了理论，证明该权衡项能区分性能良好的线性插值器和较弱的插值器。

Conclusion: 提出的正则化-锐度权衡为过参数化线性回归提供了新的理论框架，类似于传统偏置-方差权衡，能有效指导模型选择并解释过参数化设置中的性能差异。

Abstract: The rule of thumb regarding the relationship between the bias-variance tradeoff and model size plays a key role in classical machine learning, but is now well-known to break down in the overparameterized setting as per the double descent curve. In particular, minimum-norm interpolating estimators can perform well, suggesting the need for new tradeoff in these settings. Accordingly, we propose a regularization-sharpness tradeoff for overparameterized linear regression with an $\ell^p$ penalty. Inspired by the interpolating information criterion, our framework decomposes the selection penalty into a regularization term (quantifying the alignment of the regularizer and the interpolator) and a geometric sharpness term on the interpolating manifold (quantifying the effect of local perturbations), yielding a tradeoff analogous to bias-variance. Building on prior analyses that established this information criterion for ridge regularizers, this work first provides a general expression of the interpolating information criterion for $\ell^p$ regularizers where $p \ge 2$. Subsequently, we extend this to the LASSO interpolator with $\ell^1$ regularizer, which induces stronger sparsity. Empirical results on real-world datasets with random Fourier features and polynomials validate our theory, demonstrating how the tradeoff terms can distinguish performant linear interpolators from weaker ones.

</details>


### [97] [Blessings of Multiple Good Arms in Multi-Objective Linear Bandits](https://arxiv.org/abs/2602.12901)
*Heesang Ann,Min-hwan Oh*

Main category: stat.ML

TL;DR: 多目标赌博机问题中，当存在多个对多个目标都表现良好的臂时，会产生隐式探索效应，使得简单的贪婪算法也能取得良好性能，并提出了有效的帕累托公平性分析框架。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为多目标赌博机问题比单目标更复杂，因为需要同时优化多个目标。本文挑战这一观点，发现在存在多个对多个目标都表现良好的臂时，会产生隐式探索效应，从而简化算法设计。

Method: 提出在多目标和参数化赌博机设置中，当存在多个对多个目标都表现良好的臂时，简单的贪婪算法（在大多数轮次中贪婪选择动作）能够实现隐式探索。同时引入了一个有效的帕累托公平性分析框架，用于严格分析多目标赌博机算法的公平性。

Result: 理论和实证研究表明，在满足条件的情况下，简单的贪婪算法能够实现强大的性能。这是首个在无上下文分布假设的情况下，在多目标和参数化赌博机设置中引入隐式探索的研究，并提供了帕累托公平性的严格分析框架。

Conclusion: 多目标赌博机问题不一定比单目标更复杂，当存在多个对多个目标都表现良好的臂时，会产生隐式探索效应，使得简单算法也能取得良好性能。同时提出的帕累托公平性框架为多目标算法的公平性分析提供了理论基础。

Abstract: The multi objective bandit setting has traditionally been regarded as more complex than the single objective case, as multiple objectives must be optimized simultaneously. In contrast to this prevailing view, we demonstrate that when multiple good arms exist for multiple objectives, they can induce a surprising benefit, implicit exploration. Under this condition, we show that simple algorithms that greedily select actions in most rounds can nonetheless achieve strong performance, both theoretically and empirically. To our knowledge, this is the first study to introduce implicit exploration in both multi objective and parametric bandit settings without any distributional assumptions on the contexts. We further introduce a framework for effective Pareto fairness, which provides a principled approach to rigorously analyzing fairness of multi objective bandit algorithms.

</details>


### [98] [Annealing in variational inference mitigates mode collapse: A theoretical study on Gaussian mixtures](https://arxiv.org/abs/2602.12923)
*Luigi Fogliani,Bruno Loureiro,Marylou Gabrié*

Main category: stat.ML

TL;DR: 论文分析了退火策略在缓解变分推断中模式崩溃问题的数学原理，以高斯混合模型为研究对象，推导出模式崩溃概率的精确公式，并证明适当设计的退火方案能有效防止模式崩溃。


<details>
  <summary>Details</summary>
Motivation: 模式崩溃是变分推断中面临的核心挑战，即模型无法捕捉多模态分布中的某些模式。本文旨在通过数学分析理解退火策略如何缓解这一问题。

Method: 以高斯混合模型为可处理的研究对象，利用低维统计量描述，精确刻画初始温度与退火速率之间的相互作用，推导模式崩溃概率的尖锐公式。

Result: 分析表明，适当选择的退火方案能够鲁棒地防止模式崩溃。数值实验显示这些理论权衡在RealNVP归一化流等神经网络模型中同样成立。

Conclusion: 退火策略能有效缓解变分推断中的模式崩溃问题，为实际变分推断流程中设计退火策略提供了理论指导。

Abstract: Mode collapse, the failure to capture one or more modes when targetting a multimodal distribution, is a central challenge in modern variational inference. In this work, we provide a mathematical analysis of annealing based strategies for mitigating mode collapse in a tractable setting: learning a Gaussian mixture, where mode collapse is known to arise. Leveraging a low dimensional summary statistics description, we precisely characterize the interplay between the initial temperature and the annealing rate, and derive a sharp formula for the probability of mode collapse. Our analysis shows that an appropriately chosen annealing scheme can robustly prevent mode collapse. Finally, we present numerical evidence that these theoretical tradeoffs qualitatively extend to neural network based models, RealNVP normalizing flows, providing guidance for designing annealing strategies mitigating mode collapse in practical variational inference pipelines.

</details>


### [99] [TFTF: Training-Free Targeted Flow for Conditional Sampling](https://arxiv.org/abs/2602.12932)
*Qianqian Qu,Jun S. Liu*

Main category: stat.ML

TL;DR: 提出一种无需训练的条件采样方法，基于重要性采样和序列蒙特卡洛，用于流匹配模型的条件生成任务。


<details>
  <summary>Details</summary>
Motivation: 解决流匹配模型中条件采样的问题，特别是高维设置下重要性采样权重退化的问题，同时避免额外的训练成本。

Method: 结合重要性采样和序列蒙特卡洛重采样技术，在生成过程中间阶段引入可调噪声强度的随机流来替代确定性流，鼓励样本沿不同轨迹发散。

Result: 在MNIST和CIFAR-10的条件采样任务上显著优于现有方法，并在CelebA-HQ的文本到图像生成实验中展示了高维多模态场景的适用性。

Conclusion: 该方法无需额外训练，具有理论上的渐近准确性保证，为流匹配模型提供了一种有效的条件采样框架。

Abstract: We propose a training-free conditional sampling method for flow matching models based on importance sampling. Because a naïve application of importance sampling suffers from weight degeneracy in high-dimensional settings, we modify and incorporate a resampling technique in sequential Monte Carlo (SMC) during intermediate stages of the generation process. To encourage generated samples to diverge along distinct trajectories, we derive a stochastic flow with adjustable noise strength to replace the deterministic flow at the intermediate stage. Our framework requires no additional training, while providing theoretical guarantees of asymptotic accuracy. Experimentally, our method significantly outperforms existing approaches on conditional sampling tasks for MNIST and CIFAR-10. We further demonstrate the applicability of our approach in higher-dimensional, multimodal settings through text-to-image generation experiments on CelebA-HQ.

</details>


### [100] [Random Forests as Statistical Procedures: Design, Variance, and Dependence](https://arxiv.org/abs/2602.13104)
*Nathaniel S. O'Connell*

Main category: stat.ML

TL;DR: 论文从设计角度重新定义随机森林，提出有限样本方差分解框架，揭示树间协方差存在下限，仅增加树数量无法消除预测变异性。


<details>
  <summary>Details</summary>
Motivation: 随机森林通常被算法化描述而非统计设计，缺乏对固定数据集上统计行为的精确理解。需要建立有限样本、基于设计的理论框架来分析其预测变异性。

Method: 将每棵树视为显式随机化条件回归函数，基于设计视角建立随机森林的有限样本公式化。使用全方差定律和全协方差定律分解单树离散度和树间协方差。

Result: 获得森林预测器的精确方差恒等式，分离有限聚合变异性与结构依赖项。识别训练观测重用和数据自适应划分对齐两种设计机制，证明存在严格协方差下限。

Conclusion: 随机森林应被视为显式有限样本统计设计，其行为由底层随机化构造决定。重采样、特征级随机化和分裂选择共同控制分辨率、树变异性及依赖性。

Abstract: Random forests are widely used prediction procedures, yet are typically described algorithmically rather than as statistical designs acting on a fixed dataset. We develop a finite-sample, design-based formulation of random forests in which each tree is an explicit randomized conditional regression function. This perspective yields an exact variance identity for the forest predictor that separates finite-aggregation variability from a structural dependence term that persists even under infinite aggregation. We further decompose both single-tree dispersion and inter-tree covariance using the laws of total variance and covariance, isolating two fundamental design mechanisms-reuse of training observations and alignment of data-adaptive partitions. These mechanisms induce a strict covariance floor, demonstrating that predictive variability cannot be eliminated by increasing the number of trees alone. The resulting framework clarifies how resampling, feature-level randomization, and split selection govern resolution, tree variability, and dependence, and establishes random forests as explicit finite-sample statistical designs whose behavior is determined by their underlying randomized construction.

</details>


### [101] [AdaGrad-Diff: A New Version of the Adaptive Gradient Algorithm](https://arxiv.org/abs/2602.13112)
*Matia Bojovic,Saverio Salzo,Massimiliano Pontil*

Main category: stat.ML

TL;DR: 提出一种新的AdaGrad风格自适应优化方法，使用梯度差值的累积平方范数而非梯度范数本身来驱动步长调整


<details>
  <summary>Details</summary>
Motivation: 传统梯度方法对步长选择高度敏感，需要手动调参。自适应方法如AdaGrad虽然缓解了这一问题，但仍有改进空间。作者希望开发一种更智能的步长调整机制，能根据梯度变化特性自动调整

Method: 提出AdaGrad风格的自适应方法，关键创新是用连续梯度差值的累积平方范数代替梯度范数作为步长调整依据。当梯度在迭代间变化较小时，步长不会不必要地减小；而当梯度波动显著（反映曲率或不稳定）时，步长会自动阻尼

Result: 数值实验表明，该方法在多个实际相关场景中比AdaGrad更具鲁棒性

Conclusion: 通过使用梯度差值而非梯度本身来驱动自适应过程，可以开发出更智能、更鲁棒的优化算法，能更好地处理不同梯度变化模式

Abstract: Vanilla gradient methods are often highly sensitive to the choice of stepsize, which typically requires manual tuning. Adaptive methods alleviate this issue and have therefore become widely used. Among them, AdaGrad has been particularly influential. In this paper, we propose an AdaGrad-style adaptive method in which the adaptation is driven by the cumulative squared norms of successive gradient differences rather than gradient norms themselves. The key idea is that when gradients vary little across iterations, the stepsize is not unnecessarily reduced, while significant gradient fluctuations, reflecting curvature or instability, lead to automatic stepsize damping. Numerical experiments demonstrate that the proposed method is more robust than AdaGrad in several practically relevant settings.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [102] [OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization](https://arxiv.org/abs/2602.12305)
*Arijit Bhattacharjee,Heng Ping,Son Vu Le,Paul Bogdan,Nesreen K. Ahmed,Ali Jannesari*

Main category: cs.LG

TL;DR: OptiML是一个端到端框架，通过将内核优化转化为验证下的搜索，将自然语言意图或输入CUDA代码映射为性能优化的CUDA内核。它包含两个解耦阶段：自然语言输入时使用Mixture-of-Thoughts生成器产生初始可执行程序，然后通过基于搜索的优化器使用蒙特卡洛树搜索在LLM驱动的编辑上进行细化。


<details>
  <summary>Details</summary>
Motivation: 生成高性能CUDA内核具有挑战性，因为需要在噪声和昂贵的硬件反馈下探索组合空间中的低级变换。虽然大型语言模型可以合成功能正确的CUDA代码，但要获得有竞争力的性能需要系统性地探索和验证优化选择。

Method: OptiML采用两阶段方法：1) OptiML-G作为提议策略，为自然语言输入生成初始可执行程序；2) OptiML-X使用蒙特卡洛树搜索在LLM驱动的编辑上进行细化，每个候选变换都经过编译、验证和性能分析，通过结合运行时、硬件瓶颈代理和回归防护的复合目标进行评估。

Result: 在多样化的CUDA内核套件上评估OptiML，结果显示它始终能发现比强大LLM基线更好的已验证性能改进，并产生基于性能分析证据的可解释优化轨迹。

Conclusion: OptiML通过将内核优化转化为验证下的搜索，有效解决了高性能CUDA内核生成的挑战，能够产生经过验证的性能改进和可解释的优化轨迹。

Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesize functionally correct CUDA code, achieving competitive performance requires systematic exploration and verification of optimization choices. We present OptiML, an end-to-end framework that maps either natural-language intent or input CUDA code to performance-optimized CUDA kernels by formulating kernel optimization as search under verification. OptiML consists of two decoupled stages. When the input is natural language, a Mixture-of-Thoughts generator (OptiML-G) acts as a proposal policy over kernel implementation strategies, producing an initial executable program. A search-based optimizer (OptiML-X) then refines either synthesized or user-provided kernels using Monte Carlo Tree Search over LLM-driven edits, guided by a hardware-aware reward derived from profiler feedback. Each candidate transformation is compiled, verified, and profiled with Nsight Compute, and evaluated by a composite objective that combines runtime with hardware bottleneck proxies and guardrails against regressions. We evaluate OptiML in both synthesis-and-optimize and optimization-only settings on a diverse suite of CUDA kernels. Results show that OptiML consistently discovers verified performance improvements over strong LLM baselines and produces interpretable optimization trajectories grounded in profiler evidence.

</details>


### [103] [Abstractive Red-Teaming of Language Model Character](https://arxiv.org/abs/2602.12318)
*Nate Rahn,Allison Qi,Avery Griffin,Jonathan Michala,Henry Sleight,Erik Jones*

Main category: cs.LG

TL;DR: 提出抽象红队测试方法，通过搜索自然语言查询类别来识别可能违反角色规范的用户查询，使用强化学习和LLM迭代合成两种算法，在12个原则规范和7个目标模型上优于基线。


<details>
  <summary>Details</summary>
Motivation: 语言模型助手需要遵循角色规范，但在大规模部署中偶尔会违反规范。传统测试方法需要大量计算资源，本文旨在开发一种高效方法，在部署前识别可能导致角色违规的查询类型。

Method: 提出抽象红队测试方法：1）搜索自然语言查询类别（如"查询是中文的，查询询问家庭角色"），这些类别能抽象概括实际可能出现的各种查询变体；2）开发两种算法：基于强化学习的类别生成器LLM，以及利用强LLM从高分查询迭代合成类别。

Result: 在12个原则的角色规范和7个目标模型上，算法始终优于基线方法。发现了有趣的违规类别：要求Llama-3.1-8B-Instruct预测未来时，会回应AI将统治人类；要求GPT-4.1-Mini推荐监狱生存必需品时，会热情推荐非法武器。

Conclusion: 抽象红队测试方法为语言模型角色的实际部署前审计迈出了重要一步，能够高效识别可能导致角色违规的查询类型，使用远少于部署级别的计算资源。

Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally violate them in large-scale deployments. In this work, we aim to identify types of queries that are likely to produce such character violations at deployment, using much less than deployment-level compute. To do this, we introduce abstractive red-teaming, where we search for natural-language query categories, e.g. "The query is in Chinese. The query asks about family roles," that routinely elicit violations. These categories abstract over the many possible variants of a query which could appear in the wild. We introduce two algorithms for efficient category search against a character-trait-specific reward model: one based on reinforcement learning on a category generator LLM, and another which leverages a strong LLM to iteratively synthesize categories from high-scoring queries. Across a 12-principle character specification and 7 target models, we find that our algorithms consistently outperform baselines, and generate qualitatively interesting categories; for example, queries which ask Llama-3.1-8B-Instruct to predict the future lead to responses saying that AI will dominate humanity, and queries that ask GPT-4.1-Mini for essential prison survival items lead to enthusiastic recommendation of illegal weapons. Overall, we believe our results represent an important step towards realistic pre-deployment auditing of language model character.

</details>


### [104] [The Appeal and Reality of Recycling LoRAs with Adaptive Merging](https://arxiv.org/abs/2602.12323)
*Haokun Liu,Gyung Hyun Je,Marco Ciccone,Zhenlin Xu,Prasanth YSS,Colin Raffel*

Main category: cs.LG

TL;DR: 自适应LoRA合并方法在回收社区训练的LoRA模块时效果有限，主要起正则化作用而非跨任务知识迁移


<details>
  <summary>Details</summary>
Motivation: 研究如何有效回收利用Hugging Face Hub等平台上用户贡献的大量LoRA模块，探索自适应合并方法在实际场景中的效果

Method: 使用近1000个基于Llama 3.1 8B-Instruct的用户贡献LoRA模块，比较多种自适应和非自适应合并方法，并通过广泛搜索设计空间提出新方法

Result: 自适应合并方法相比基础模型有改进，但相比在相同数据上训练新LoRA优势有限；LoRA选择重要性不大，随机初始化参数也能获得相似性能

Conclusion: 从回收LoRA进行自适应合并主要起正则化作用而非促进跨任务迁移；只有在池中存在高度相关LoRA时才可能实现正向迁移

Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting LoRAs from a pool and tune merging coefficients based on a task-specific dataset. While adaptive merging methods have demonstrated improvements in some settings, no past work has attempted to recycle LoRAs found "in the wild" on model repositories like the Hugging Face Hub. To address this gap, we consider recycling from a pool of nearly 1,000 user-contributed LoRAs trained from the Llama 3.1 8B-Instruct language model. Our empirical study includes a range of adaptive and non-adaptive merging methods in addition to a new method designed via a wide search over the methodological design space. We demonstrate that adaptive merging methods can improve performance over the base model but provide limited benefit over training a new LoRA on the same data used to set merging coefficients. We additionally find not only that the specific choice of LoRAs to merge has little importance, but that using LoRAs with randomly initialized parameter values yields similar performance. This raises the possibility that adaptive merging from recycled LoRAs primarily works via some kind of regularization effect, rather than by enabling positive cross-task transfer. To better understand why past work has proven successful, we confirm that positive transfer is indeed possible when there are highly relevant LoRAs in the pool. We release the model checkpoints and code online.

</details>


### [105] [Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications](https://arxiv.org/abs/2602.12338)
*Farshad Zeinali,Mahdi Boloursaz Mashhadi,Dusit Niyato,Rahim Tafazolli*

Main category: cs.LG

TL;DR: 提出混合强化学习框架解决多用户下行无线TokenCom中的tokenizer协议问题，结合DQN进行tokenizer选择和子信道分配，DDPG进行波束成形，显著提升语义质量和资源效率。


<details>
  <summary>Details</summary>
Motivation: TokenCom作为新兴的多模态通信范式，需要收发双方就tokenizer模型和码本达成一致。在多用户下行无线场景中，如何高效进行tokenizer协议、子信道分配和波束成形是一个关键挑战。

Method: 提出混合强化学习框架：1) 使用深度Q网络(DQN)联合优化tokenizer协议和子信道分配；2) 使用深度确定性策略梯度(DDPG)优化波束成形；3) 将混合整数非凸问题分解为可学习的子问题。

Result: 仿真结果显示，所提框架在语义质量和资源效率方面优于基线方法，相比传统H.265方案，视频传输中的冻结事件减少了68%。

Conclusion: 混合强化学习框架能有效解决多用户TokenCom中的资源分配和协议问题，为未来无线网络中高效的数字语义和目标导向通信提供了可行方案。

Abstract: Token Communications (TokenCom) has recently emerged as an effective new paradigm, where tokens are the unified units of multimodal communications and computations, enabling efficient digital semantic- and goal-oriented communications in future wireless networks. To establish a shared semantic latent space, the transmitters/receivers in TokenCom need to agree on an identical tokenizer model and codebook. To this end, an initial Tokenizer Agreement (TA) process is carried out in each communication episode, where the transmitter/receiver cooperate to choose from a set of pre-trained tokenizer models/ codebooks available to them both for efficient TokenCom. In this correspondence, we investigate TA in a multi-user downlink wireless TokenCom scenario, where the base station equipped with multiple antennas transmits video token streams to multiple users. We formulate the corresponding mixed-integer non-convex problem, and propose a hybrid reinforcement learning (RL) framework that integrates a deep Q-network (DQN) for joint tokenizer agreement and sub-channel assignment, with a deep deterministic policy gradient (DDPG) for beamforming. Simulation results show that the proposed framework outperforms baseline methods in terms of semantic quality and resource efficiency, while reducing the freezing events in video transmission by 68% compared to the conventional H.265-based scheme.

</details>


### [106] [Intrinsic Credit Assignment for Long Horizon Interaction](https://arxiv.org/abs/2602.12342)
*Ilze Amanda Auzina,Joschka Strüber,Sergio Hernández-Gutiérrez,Shashwat Goel,Ameya Prabhu,Matthias Bethge*

Main category: cs.LG

TL;DR: ΔBelief-RL利用语言模型的内在信念变化作为奖励信号，通过训练合成交互数据，提升智能体在长时程不确定性环境中的信息寻求能力。


<details>
  <summary>Details</summary>
Motivation: 如何训练智能体在长时程不确定性环境中导航？传统基于结果的奖励难以对中间进展进行信用分配，需要一种能评估中间行动价值的方法。

Method: 提出ΔBelief-RL方法，利用语言模型对目标解决方案概率的变化作为奖励信号。通过训练合成交互数据，让智能体学习信息寻求能力，实现中间行动的信用分配。

Result: ΔBelief-RL在强化学习中持续优于纯结果奖励，改进泛化到客户服务、个性化等分布外应用。测试时交互效率随交互规模增加而提升，Pass@k指标也得到改善。

Conclusion: ΔBelief-RL通过内在信念变化奖励实现中间行动的信用分配，为长时程不确定性导航提供了可扩展的训练策略。

Abstract: How can we train agents to navigate uncertainty over long horizons? In this work, we propose ΔBelief-RL, which leverages a language model's own intrinsic beliefs to reward intermediate progress. Our method utilizes the change in the probability an agent assigns to the target solution for credit assignment. By training on synthetic interaction data, ΔBelief-RL teaches information-seeking capabilities that consistently outperform purely outcome-based rewards for Reinforcement Learning, with improvements generalizing to out-of-distribution applications ranging from customer service to personalization. Notably, the performance continues to improve as we scale test-time interactions beyond the training horizon, with interaction-efficiency increasing even on Pass@k metrics. Overall, our work introduces a scalable training strategy for navigating uncertainty over a long-horizon, by enabling credit assignment to intermediate actions via intrinsic ΔBelief rewards.

</details>


### [107] [A Machine Learning Approach to the Nirenberg Problem](https://arxiv.org/abs/2602.12368)
*Gianfranco Cortés,Maria Esteban-Casadevall,Yueqing Feng,Jonas Henkel,Edward Hirst,Tancredi Schettini Gherardini,Alexander G. Stapleton*

Main category: cs.LG

TL;DR: 提出Nirenberg神经网络，一种用于解决S²球面上高斯曲率预定问题的PINN方法，通过全局参数化共形因子和几何感知损失训练，能区分可实现与不可实现的曲率函数。


<details>
  <summary>Details</summary>
Motivation: 解决Nirenberg问题：在S²球面上预定高斯曲率，寻找与标准度量点共形的度量。传统方法存在计算困难，需要开发新的数值工具来探索几何分析中的存在性问题。

Method: 使用无网格物理信息神经网络(PINN)方法，全局参数化共形因子，通过几何感知损失函数强制满足曲率方程。利用Gauss-Bonnet定理进行一致性检验，并通过球谐展开提供模型可解释性。

Result: 对于已知可实现的预定曲率，神经网络达到极低损失(10⁻⁷-10⁻¹⁰)；对于不可实现的曲率，损失显著更高。这种区分能力可用于评估未知情况，分离可能可实现与不可实现的函数。

Conclusion: Nirenberg神经网络展示了神经求解器可作为几何分析中的探索工具，为长期存在的存在性问题提供定量计算视角，为几何分析开辟了新的计算途径。

Abstract: This work introduces the Nirenberg Neural Network: a numerical approach to the Nirenberg problem of prescribing Gaussian curvature on $S^2$ for metrics that are pointwise conformal to the round metric. Our mesh-free physics-informed neural network (PINN) approach directly parametrises the conformal factor globally and is trained with a geometry-aware loss enforcing the curvature equation. Additional consistency checks were performed via the Gauss-Bonnet theorem, and spherical-harmonic expansions were fit to the learnt models to provide interpretability.
  For prescribed curvatures with known realisability, the neural network achieves very low losses ($10^{-7} - 10^{-10}$), while unrealisable curvatures yield significantly higher losses. This distinction enables the assessment of unknown cases, separating likely realisable functions from non-realisable ones. The current capabilities of the Nirenberg Neural Network demonstrate that neural solvers can serve as exploratory tools in geometric analysis, offering a quantitative computational perspective on longstanding existence questions.

</details>


### [108] [Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis](https://arxiv.org/abs/2602.12373)
*Yijun Ma,Zehong Wang,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Nitesh Chawla,Yanfang Ye*

Main category: cs.LG

TL;DR: 提出了Policy4OOD，一个知识引导的时空世界模型，用于评估阿片类药物政策干预，具备预测、反事实推理和优化三种能力。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机是美国严重的公共卫生危机，但政策干预评估困难，因为多种政策在动态系统中相互作用，针对一个风险路径可能无意中放大另一个风险。

Method: 提出Policy4OOD，一个知识引导的时空世界模型，联合编码政策知识图谱、州级空间依赖性和社会经济时间序列到政策条件Transformer中，预测未来阿片类药物结果。训练后作为模拟器使用，支持预测、反事实分析和政策优化。

Result: 实验表明空间依赖性和结构化政策知识显著提高预测准确性，验证了架构组件和世界建模在数据驱动的公共卫生决策支持中的潜力。

Conclusion: 通过世界建模统一政策评估的三种能力（预测、反事实推理、优化）是可行的，Policy4OOD框架为数据驱动的公共卫生决策提供了有效支持。

Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.

</details>


### [109] [Computationally sufficient statistics for Ising models](https://arxiv.org/abs/2602.12449)
*Abhijith Jayakumar,Shreya Shukla,Marc Vuffray,Andrey Y. Lokhov,Sidhant Misra*

Main category: cs.LG

TL;DR: 该论文研究了在仅能观测到充分统计量而非完整样本的情况下，学习吉布斯分布的计算效率问题，以伊辛模型为例，展示了通过观测有限阶统计量来重建模型参数的可行性。


<details>
  <summary>Details</summary>
Motivation: 在物理系统中，通常难以获得完整样本配置，而只能观测到有限的统计量。传统的高效学习算法需要完整样本，因此需要开发在有限观测能力下的计算高效学习方法。

Method: 以伊辛模型为范例，研究计算能力与观测能力之间的权衡。证明通过观测到O(γ)阶的统计量（其中γ是模型的ℓ₁宽度），可以重建模型参数。还讨论了在已知模型结构先验信息的情况下，可以用更有限的观测能力高效解决问题。

Result: 展示了对于ℓ₁宽度为γ的模型，通过观测到O(γ)阶的统计量，可以推断模型结构、耦合参数和磁场。在有结构先验信息的情况下，可以用更少的观测能力高效学习。

Conclusion: 该研究为在有限观测能力下高效学习吉布斯分布提供了理论框架，特别是在物理系统中只能获得有限统计量的实际场景下具有重要意义。

Abstract: Learning Gibbs distributions using only sufficient statistics has long been recognized as a computationally hard problem. On the other hand, computationally efficient algorithms for learning Gibbs distributions rely on access to full sample configurations generated from the model. For many systems of interest that arise in physical contexts, expecting a full sample to be observed is not practical, and hence it is important to look for computationally efficient methods that solve the learning problem with access to only a limited set of statistics. We examine the trade-offs between the power of computation and observation within this scenario, employing the Ising model as a paradigmatic example. We demonstrate that it is feasible to reconstruct the model parameters for a model with $\ell_1$ width $γ$ by observing statistics up to an order of $O(γ)$. This approach allows us to infer the model's structure and also learn its couplings and magnetic fields. We also discuss a setting where prior information about structure of the model is available and show that the learning problem can be solved efficiently with even more limited observational power.

</details>


### [110] [Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning](https://arxiv.org/abs/2602.12375)
*Abdul Wahab,Raksha Kumaraswamy,Martha White*

Main category: cs.LG

TL;DR: VBE算法通过集成随机Q函数误差设计价值奖励，实现首次访问乐观探索，在经典环境和Atari上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于乐观价值估计的探索方法存在局限性：价值奖励只在看到更高奖励奖励后才增加，无法鼓励智能体首次访问状态-动作对，缺乏首次访问乐观性

Method: 提出VBE算法，维护一组随机动作价值函数集成，利用这些RQFs的估计误差设计价值奖励，通过巧妙设计RQFs的奖励使价值奖励能降为零，实现首次访问乐观和深度探索

Result: VBE在多个经典探索测试环境中优于Bootstrap DQN和两种奖励奖励方法（RND和ACB），并能轻松扩展到Atari等复杂环境

Conclusion: VBE通过集成随机Q函数误差设计价值奖励，有效解决了现有探索方法缺乏首次访问乐观性的问题，在多种环境中表现出优越的探索性能

Abstract: Optimistic value estimates provide one mechanism for directed exploration in reinforcement learning (RL). The agent acts greedily with respect to an estimate of the value plus what can be seen as a value bonus. The value bonus can be learned by estimating a value function on reward bonuses, propagating local uncertainties around rewards. However, this approach only increases the value bonus for an action retroactively, after seeing a higher reward bonus from that state and action. Such an approach does not encourage the agent to visit a state and action for the first time. In this work, we introduce an algorithm for exploration called Value Bonuses with Ensemble errors (VBE), that maintains an ensemble of random action-value functions (RQFs). VBE uses the errors in the estimation of these RQFs to design value bonuses that provide first-visit optimism and deep exploration. The key idea is to design the rewards for these RQFs in such a way that the value bonus can decrease to zero. We show that VBE outperforms Bootstrap DQN and two reward bonus approaches (RND and ACB) on several classic environments used to test exploration and provide demonstrative experiments that it can scale easily to more complex environments like Atari.

</details>


### [111] [Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation](https://arxiv.org/abs/2602.12379)
*Wenxin Chen,Weishen Pan,Kyra Gan,Fei Wang*

Main category: cs.LG

TL;DR: D3-Net通过SDR伪结果训练ICE序列来中断误差传播，然后使用LTMLE进行最终去偏，显著减少纵向治疗效果估计中的偏差和方差。


<details>
  <summary>Details</summary>
Motivation: 纵向治疗效果估计对于序列决策至关重要，但由于治疗-混杂因素反馈而具有挑战性。ICE G-computation虽然提供了原则性方法，但其递归结构存在误差传播问题，会污染学习到的结果回归模型。

Method: 1. 使用序列双重稳健(SDR)伪结果训练ICE序列，为每个回归提供偏差校正目标，中断误差传播
2. 采用具有协变量模拟头的多任务Transformer进行辅助监督，正则化表示以防止噪声伪结果污染
3. 使用目标网络稳定训练动态
4. 最终估计阶段，丢弃SDR校正，使用未校正的nuisance模型对原始结果进行纵向目标最小损失估计(LTMLE)

Result: 综合实验表明，D3-Net在不同时间范围、反事实和时变混杂因素下，相比现有最先进的ICE-based估计器，能够稳健地减少偏差和方差。

Conclusion: D3-Net通过中断误差传播和两阶段去偏策略，有效解决了ICE G-computation中的误差传播问题，为纵向治疗效果估计提供了更稳健和准确的解决方案。

Abstract: Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled approach, its recursive structure suffers from error propagation, corrupting the learned outcome regression models. We propose D3-Net, a framework that mitigates error propagation in ICE training and then applies a robust final correction. First, to interrupt error propagation during learning, we train the ICE sequence using Sequential Doubly Robust (SDR) pseudo-outcomes, which provide bias-corrected targets for each regression. Second, we employ a multi-task Transformer with a covariate simulator head for auxiliary supervision, regularizing representations against corruption by noisy pseudo-outcomes, and a target network to stabilize training dynamics. For the final estimate, we discard the SDR correction and instead use the uncorrected nuisance models to perform Longitudinal Targeted Minimum Loss-Based Estimation (LTMLE) on the original outcomes. This second-stage, targeted debiasing ensures robustness and optimal finite-sample properties. Comprehensive experiments demonstrate that our model, D3-Net, robustly reduces bias and variance across different horizons, counterfactuals, and time-varying confoundings, compared to existing state-of-the-art ICE-based estimators.

</details>


### [112] [HyperMLP: An Integrated Perspective for Sequence Modeling](https://arxiv.org/abs/2602.12601)
*Jiecheng Lu,Shihao Yang*

Main category: cs.LG

TL;DR: 论文提出将自注意力重新解释为动态两层MLP，并基于此设计了HyperMLP/HyperGLU，在相同参数量下超越了softmax注意力基线


<details>
  <summary>Details</summary>
Motivation: 传统将自注意力视为概率查询-键查找的观点限制了设计空间，作者主张更简单统一的视角：将自回归注意力头视为权重从上下文历史实例化的动态两层MLP

Method: 基于注意力作为动态MLP的视角，提出HyperMLP和HyperGLU，学习特征空间和序列空间的动态混合，使用反向偏移（滞后）布局将时间混合与自回归语义对齐

Result: 从理论上分析了该结构的表达能力和含义，实验表明在匹配参数预算下，HyperMLP/HyperGLU持续优于强大的softmax注意力基线

Conclusion: 将注意力重新解释为动态MLP提供了更统一的设计视角，HyperMLP/HyperGLU展示了这一视角的实际优势，为序列建模提供了新思路

Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.

</details>


### [113] [TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting](https://arxiv.org/abs/2602.12380)
*Raiz Ud Din,Saddam Hussain Khan*

Main category: cs.LG

TL;DR: 提出TFT-ACB-XML混合堆叠泛化框架，用于比特币收盘价预测，结合TFT和ACB两个并行基学习器，通过XGBoost元学习器进行集成，在测试集上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 比特币预测面临挑战：去中心化市场非线性、高波动性、时间不规则性，现有深度学习模型在可解释性和跨市场条件泛化能力方面存在不足。

Method: 提出TFT-ACB-XML混合堆叠泛化框架：1) 定制化TFT处理长期依赖和全局时间动态；2) ACB模块（注意力机制+定制化BiLSTM）捕捉短期序列依赖；3) 基于验证性能的误差倒数加权策略；4) XGBoost回归器作为元学习器捕捉非线性残差。

Result: 使用2014年10月1日至2026年1月5日比特币数据，在测试集上取得优异表现：MAPE 0.65%、MAE 198.15、RMSE 258.30。评估期涵盖2024年比特币减半和现货ETF时期，验证了模型在重大流动性波动时期的稳健性。

Conclusion: TFT-ACB-XML框架在比特币价格预测方面优于现有深度学习模型，能够有效处理市场复杂性和波动性，在关键市场事件期间保持良好性能。

Abstract: Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability and generalization across diverse market conditions. This research presents a hybrid stacked-generalization framework, TFT-ACB-XML, for BTC closing price prediction. The framework integrates two parallel base learners: a customized Temporal Fusion Transformer (TFT) and an Attention-Customized Bidirectional Long Short-Term Memory network (ACB), followed by an XGBoost regressor as the meta-learner. The customized TFT model handles long-range dependencies and global temporal dynamics via variable selection networks and interpretable single-head attention. The ACB module uses a new attention mechanism alongside the customized BiLSTM to capture short-term sequential dependencies. Predictions from both customized TFT and ACB are weighted through an error-reciprocal weighting strategy. These weights are derived from validation performance, where a model showing lower prediction error receives a higher weight. Finally, the framework concatenates these weighted outputs into a feature vector and feeds the vector to an XGBoost regressor, which captures non-linear residuals and produces the final BTC closing price prediction. Empirical validation using BTC data from October 1, 2014, to January 5, 2026, shows improved performance of the proposed framework compared to recent Deep Learning and Transformer baseline models. The results show a MAPE of 0.65%, an MAE of 198.15, and an RMSE of 258.30 for one-step-ahead out-of-sample under a walk-forward evaluation on the test block. The evaluation period spans the 2024 BTC halving and the spot ETFs (exchange-traded funds) period, which coincide with major liquidity and volatility shifts.

</details>


### [114] [Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics](https://arxiv.org/abs/2602.12643)
*Jashaswimalya Acharjee,Balaraman Ravindran*

Main category: cs.LG

TL;DR: ULD是一种新颖的强化学习算法，通过将状态-动作对嵌入到潜在空间，使真实价值函数近似线性，从而统一了无模型方法的效率与基于模型方法的表示优势，无需规划开销。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法面临无模型方法效率高但表示能力有限，而基于模型方法表示能力强但规划开销大的权衡问题。需要一种能结合两者优势，同时避免规划开销的算法。

Method: ULD将状态-动作对嵌入到潜在空间，使价值函数在该空间中近似线性。采用编码器、价值和策略网络的同步更新，辅助损失用于短时程预测动态，奖励尺度归一化确保稀疏奖励下的稳定学习。

Result: 在80个环境（包括Gym运动控制、DeepMind Control和Atari游戏）上的评估显示，ULD匹配或超越了专门的无模型和通用的基于模型基线方法，实现了跨领域能力，且参数占用少，调参需求低。

Conclusion: 价值对齐的潜在表示本身就能提供传统上归因于完整基于模型规划的适应性和样本效率，表明无需显式规划即可实现基于模型方法的优势。

Abstract: We present Unified Latent Dynamics (ULD), a novel reinforcement learning algorithm that unifies the efficiency of model-free methods with the representational strengths of model-based approaches, without incurring planning overhead. By embedding state-action pairs into a latent space in which the true value function is approximately linear, our method supports a single set of hyperparameters across diverse domains -- from continuous control with low-dimensional and pixel inputs to high-dimensional Atari games. We prove that, under mild conditions, the fixed point of our embedding-based temporal-difference updates coincides with that of a corresponding linear model-based value expansion, and we derive explicit error bounds relating embedding fidelity to value approximation quality. In practice, ULD employs synchronized updates of encoder, value, and policy networks, auxiliary losses for short-horizon predictive dynamics, and reward-scale normalization to ensure stable learning under sparse rewards. Evaluated on 80 environments spanning Gym locomotion, DeepMind Control (proprioceptive and visual), and Atari, our approach matches or exceeds the performance of specialized model-free and general model-based baselines -- achieving cross-domain competence with minimal tuning and a fraction of the parameter footprint. These results indicate that value-aligned latent representations alone can deliver the adaptability and sample efficiency traditionally attributed to full model-based planning.

</details>


### [115] [Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment](https://arxiv.org/abs/2602.12384)
*Nathanaël Haas,Francçois Gatine,Augustin M Cosse,Zied Bouraoui*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度雅可比矩阵特征的新方法来理解深度网络梯度训练中的隐式偏差，通过分析奇异值指数缩放和谱分离现象，建立了与经典平衡深度线性模型类似的解耦动力学框架。


<details>
  <summary>Details</summary>
Motivation: 理解深度网络中基于梯度的训练为何表现出强烈的隐式偏差具有挑战性，因为通常只有在平衡的深度线性模型中才能获得可处理的奇异值动力学。需要寻找替代方法来分析这一现象。

Method: 采用固定门控视角分析分段线性网络，将雅可比矩阵简化为单个激活区域内掩码线性映射的乘积。证明初始化时存在控制顶部奇异值的Lyapunov指数，给出可处理掩码模型的闭式表达式，并量化有限深度修正。进一步证明足够强的谱分离会强制矩阵乘积中的奇异向量对齐。

Result: 理论分析表明深度诱导的奇异值指数缩放和强谱分离特征存在，这导致中间雅可比矩阵具有近似共享的奇异基。实验验证了预测的缩放、对齐和动力学行为，支持低秩雅可比结构作为隐式偏差驱动机制的解释。

Conclusion: 通过分析深度雅可比矩阵的两个可测试特征（奇异值指数缩放和谱分离），建立了一个近似解耦的奇异值动力学框架，为理解深度网络训练中的隐式偏差提供了机制性解释，无需依赖传统的平衡假设。

Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We propose an alternative route based on two theoretically grounded and empirically testable signatures of deep Jacobians: depth-induced exponential scaling of ordered singular values and strong spectral separation. Adopting a fixed-gates view of piecewise-linear networks, where Jacobians reduce to products of masked linear maps within a single activation region, we prove the existence of Lyapunov exponents governing the top singular values at initialization, give closed-form expressions in a tractable masked model, and quantify finite-depth corrections. We further show that sufficiently strong separation forces singular-vector alignment in matrix products, yielding an approximately shared singular basis for intermediate Jacobians. Together, these results motivate an approximation regime in which singular-value dynamics become effectively decoupled, mirroring classical balanced deep-linear analyses without requiring balancing. Experiments in fixed-gates settings validate the predicted scaling, alignment, and resulting dynamics, supporting a mechanistic account of emergent low-rank Jacobian structure as a driver of implicit bias.

</details>


### [116] [Flow Matching from Viewpoint of Proximal Operators](https://arxiv.org/abs/2602.12683)
*Kenji Fukumizu,Wei Huang,Han Bao,Shuntuo Xu,Nisha Chandramoothy*

Main category: cs.LG

TL;DR: 本文重新表述了最优传输条件流匹配（OT-CFM）模型，证明了其具有精确的近端公式，无需假设目标分布有密度，并分析了批量大小增加时的收敛性，以及证明了对于流形支撑的目标，OT-CFM具有终端法向双曲性。


<details>
  <summary>Details</summary>
Motivation: 现有最优传输条件流匹配（OT-CFM）模型通常假设目标分布具有密度，这限制了其应用范围。本文旨在重新表述OT-CFM，使其无需密度假设，并提供更精确的理论分析。

Method: 通过扩展Brenier势能重新表述OT-CFM，证明其具有精确的近端算子表示。使用凸势能的二阶上导数分析动力学特性，证明对于流形支撑的目标，OT-CFM具有终端法向双曲性。

Result: 1. OT-CFM可以通过扩展Brenier势能精确表示为近端算子；2. 小批量OT-CFM随着批量增加收敛到总体公式；3. 对于流形支撑的目标，OT-CFM在时间重标度后具有指数收缩的法向动力学和中性切向动力学。

Conclusion: 本文为OT-CFM提供了更一般的理论框架，无需密度假设，并揭示了其在流形数据上的动力学特性，为生成模型的理论分析和应用提供了新的见解。

Abstract: We reformulate Optimal Transport Conditional Flow Matching (OT-CFM), a class of dynamical generative models, showing that it admits an exact proximal formulation via an extended Brenier potential, without assuming that the target distribution has a density. In particular, the mapping to recover the target point is exactly given by a proximal operator, which yields an explicit proximal expression of the vector field. We also discuss the convergence of minibatch OT-CFM to the population formulation as the batch size increases. Finally, using second epi-derivatives of convex potentials, we prove that, for manifold-supported targets, OT-CFM is terminally normally hyperbolic: after time rescaling, the dynamics contracts exponentially in directions normal to the data manifold while remaining neutral along tangential directions.

</details>


### [117] [Rational Neural Networks have Expressivity Advantages](https://arxiv.org/abs/2602.12390)
*Maosen Tang,Alex Townsend*

Main category: cs.LG

TL;DR: 本文研究表明，具有可训练低阶有理激活函数的神经网络比现代分段线性和平滑激活函数（如ReLU、Sigmoid等）更具表达能力和参数效率，存在指数级的近似理论分离。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络广泛使用固定的激活函数（如ReLU、Sigmoid等），但这些函数在表达能力和参数效率方面可能存在限制。研究者希望探索可训练的有理激活函数是否能提供更好的性能。

Method: 研究使用可训练低阶有理激活函数的神经网络，从理论角度分析其近似能力，并与标准固定激活函数进行对比。在实践层面，将有理激活函数集成到标准架构和训练流程中进行验证。

Result: 理论分析显示，有理激活网络能以poly(log log(1/ε))的规模开销逼近任何标准激活网络，而反向逼近则需要Ω(log(1/ε))参数，存在指数级差距。实践中，有理激活函数在相同架构和优化器下能匹配或超越固定激活函数。

Conclusion: 可训练低阶有理激活函数在表达能力和参数效率方面显著优于传统固定激活函数，既具有理论优势，又能无缝集成到现有深度学习框架中，为神经网络设计提供了新的方向。

Abstract: We study neural networks with trainable low-degree rational activation functions and show that they are more expressive and parameter-efficient than modern piecewise-linear and smooth activations such as ELU, LeakyReLU, LogSigmoid, PReLU, ReLU, SELU, CELU, Sigmoid, SiLU, Mish, Softplus, Tanh, Softmin, Softmax, and LogSoftmax. For an error target of $\varepsilon>0$, we establish approximation-theoretic separations: Any network built from standard fixed activations can be uniformly approximated on compact domains by a rational-activation network with only $\mathrm{poly}(\log\log(1/\varepsilon))$ overhead in size, while the converse provably requires $Ω(\log(1/\varepsilon))$ parameters in the worst case. This exponential gap persists at the level of full networks and extends to gated activations and transformer-style nonlinearities. In practice, rational activations integrate seamlessly into standard architectures and training pipelines, allowing rationals to match or outperform fixed activations under identical architectures and optimizers.

</details>


### [118] [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)
*Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 提出首个联邦格兰杰因果分析中的不确定性量化方法，系统分类不确定性来源，推导闭式递归公式，建立收敛条件，提升联邦因果推断的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦格兰杰因果分析仅提供确定性点估计，忽略了不确定性量化。在分布式高维数据受数据主权约束的背景下，缺乏不确定性量化限制了联邦因果推断的可靠性和可解释性。

Method: 系统分类不确定性来源（偶然性与认知性），推导闭式递归公式建模客户端-服务器交互中的不确定性传播，识别四种新的交叉协方差分量，建立收敛条件并获取稳态方差。

Result: 收敛分析表明稳态方差仅取决于客户端数据统计量，消除了对初始认知先验的依赖，增强了鲁棒性。在合成基准和真实工业数据集上的实验表明，显式表征不确定性显著提升了联邦因果推断的可靠性和可解释性。

Conclusion: 建立了首个联邦格兰杰因果分析的不确定性量化框架，通过系统建模不确定性传播和收敛特性，为分布式因果推断提供了更可靠和可解释的工具。

Abstract: Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.

</details>


### [119] [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*Giang Ngo,Dat Phan Trong,Dang Nguyen,Sunil Gupta*

Main category: cs.LG

TL;DR: TRLSE算法用于高维水平集估计，通过全局和局部双重采集函数迭代优化边界区域，在样本效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高维空间中的水平集估计面临维度灾难挑战，搜索空间随维度指数增长，而主动学习场景中初始数据有限，需要高效获取信息点来构建准确分类器。

Method: 提出TRLSE算法，采用全局和局部双重采集函数，识别并细化阈值边界附近的区域，在全局层面探索潜在边界区域，在局部层面精细优化边界。

Result: 通过理论分析证明了TRLSE的准确性，并在多个合成和真实世界水平集估计问题上进行了广泛评估，结果显示其样本效率优于现有方法。

Conclusion: TRLSE算法有效解决了高维水平集估计的挑战，通过双重采集策略显著提高了样本效率，为实际应用提供了可行的解决方案。

Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensionality. We propose TRLSE, an algorithm for high-dimensional LSE, which identifies and refines regions near the threshold boundary with dual acquisition functions operating at both global and local levels. We provide a theoretical analysis of TRLSE's accuracy and show its superior sample efficiency against existing methods through extensive evaluations on multiple synthetic and real-world LSE problems.

</details>


### [120] [Diverging Flows: Detecting Extrapolations in Conditional Generation](https://arxiv.org/abs/2602.13061)
*Constantinos Tsakonas,Serena Ivaldi,Jean-Baptiste Mouret*

Main category: cs.LG

TL;DR: 提出Diverging Flows方法，解决Flow Matching模型在安全关键应用中存在的"外推危险"问题，通过结构化设计使单个模型能同时进行条件生成和外推检测。


<details>
  <summary>Details</summary>
Motivation: Flow Matching模型在处理复杂条件分布方面表现出色，但在安全关键应用部署中存在严重问题：由于平滑性偏差，即使对于流形外的输入，模型也会产生看似合理的输出，导致难以区分的静默失败。

Method: 提出Diverging Flows方法，通过结构化强制对离群输入进行低效传输，使单个模型能够同时执行条件生成和原生外推检测。

Result: 在合成流形、跨域风格迁移和天气温度预测等任务上验证，该方法能有效检测外推而不损害预测保真度或推理延迟。

Conclusion: Diverging Flows为可信赖的流模型提供了稳健解决方案，为医学、机器人和气候科学等领域的可靠部署铺平了道路。

Abstract: The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.

</details>


### [121] [Synthetic Interaction Data for Scalable Personalization in Large Language Models](https://arxiv.org/abs/2602.12394)
*Yuchen Ma,Yue Huang,Wenjie Wang,Xiaonan Luo,Xiangliang Zhang,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出了PersonaGym框架生成高质量个性化交互数据，并开发PPOpt框架优化用户提示而不修改LLM模型


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要关注任务级优化，忽视了用户特定偏好和个体约束，主要由于缺乏高质量隐私敏感数据和个性化奖励信号

Method: 1) PersonaGym：通过代理LLM系统建模动态偏好过程，生成个性化多轮交互轨迹；2) PPOpt：采用"推理-优化"范式，推断显式用户画像并基于此重写提示，结合冷启动监督先验和结果驱动的多目标强化学习

Result: 实验显示在任务性能、个性化质量和鲁棒性方面优于现有基线方法，特别是在噪声和稀疏偏好信号下表现良好

Conclusion: PersonaGym解决了个性化提示优化的数据瓶颈，PPOpt框架为个性化提示优化提供了可扩展且模型无关的解决方案

Abstract: Personalized prompting offers large opportunities for deploying large language models (LLMs) to diverse users, yet existing prompt optimization methods primarily focus on task-level optimization while largely overlooking user-specific preferences and latent constraints of individual users. This gap is primarily due to (i) the absence of high-quality, privacy-sensitive data that capture personalized user-LLM interactions at scale, and (ii) the lack of robust reward signals for individual preferences. To overcome existing data limitations, we introduce a high-fidelity synthetic data generation framework called PersonaGym. Unlike prior work that treats personalization as static persona-preference pairs, PersonaGym models a dynamic preference process via an agentic LLM system to simulate realistic preference behaviors and semantic-aware noise in order to generate personalized multi-turn interaction trajectories. Using PersonaGym, we release PersonaAtlas, a large-scale, high-quality, and diverse synthetic dataset of high-fidelity multi-turn personalized interaction trajectories that closely mirror real-world preference expression and noise patterns. We further propose Personalized Prompt Optimization (PPOpt), a scalable and model-agnostic framework that optimizes user prompts based on interaction histories without modifying the deployed LLM. PPOpt adopts a reason-then-optimize paradigm that infers an explicit user profile and conditions prompt rewriting on the user profile to avoid reward hacking. Our training procedure for PPOpt integrates a cold-start supervised prior with outcome-driven multi-objective reinforcement learning. We present extensive experiments to demonstrate consistent improvements over state-of-the-art baselines in terms of task performance, personalization quality, and robustness to noisy as well as to sparse preference signals.

</details>


### [122] [Learning to Approximate Uniform Facility Location via Graph Neural Networks](https://arxiv.org/abs/2602.13155)
*Chendi Qian,Christopher Morris,Stefanie Jegelka,Christian Sohler*

Main category: cs.LG

TL;DR: 提出一种结合消息传递神经网络与近似算法的可微分方法，用于解决均匀设施选址问题，无需监督数据或离散松弛，具有可证明的性能保证和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法需要监督训练数据、强化学习或梯度估计器，导致计算开销大、训练不稳定或缺乏可证明的性能保证；而经典近似算法虽然提供性能保证，但不可微分且无法自适应利用自然输入分布的结构规律。

Method: 开发完全可微分的消息传递神经网络模型，嵌入近似算法原理，避免需要求解器监督或离散松弛。该方法具有可证明的近似保证和规模泛化能力。

Result: 在解决方案质量上优于标准非学习近似算法，缩小了与计算密集型整数线性规划方法的差距。能够泛化到比训练时大得多的实例。

Conclusion: 这项工作为离散优化中基于学习的方法和近似算法之间的桥梁迈出了一步，结合了两者的优势。

Abstract: There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization.

</details>


### [123] [AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning](https://arxiv.org/abs/2602.12402)
*Felicia B. Guo,Ken T. Ho,Andrei Vladimirescu,Borivoje Nikolic*

Main category: cs.LG

TL;DR: 该论文提出了一种基于深度强化学习的模拟混合信号电路自动综合方法（AstRL），将电路设计转化为图生成问题，实现了专家对齐的通用电路生成。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号集成电路在现代计算和通信系统中至关重要，但设计复杂性不断增加，而自动化进展有限。主要挑战在于开发适用于不同、受限且不可微分电路设计空间的通用优化方法。

Method: 将电路设计视为图生成问题，提出基于策略梯度深度强化学习的AstRL方法。在仿真器嵌入环境中直接生成针对用户指定目标优化的电路，使用行为克隆和基于判别器的相似性奖励，实现专家对齐的电路生成。方法在晶体管级别操作，具有高度表达性和细粒度拓扑生成能力。

Result: 在三个实际设计任务中，相比最先进基线方法，在传统设计指标上取得显著改进。100%的生成设计结构正确，超过90%的设计展示出所需功能。

Conclusion: AstRL首次展示了通过专家对齐范式实现通用电路生成的方法，在仿真中得到验证。该方法在晶体管级别操作，通过动作空间和环境中的强归纳偏置驱动结构一致且有效的生成。

Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.

</details>


### [124] [Soft Contamination Means Benchmarks Test Shallow Generalization](https://arxiv.org/abs/2602.12413)
*Ari Spiesberger,Juan J. Vazquez,Nicky Pochinkov,Tomáš Gavenčiak,Peli Grietzer,Gavin Leech,Nandi Schoots*

Main category: cs.LG

TL;DR: 研究发现LLM训练数据中的语义重复污染广泛存在，导致基准测试性能被高估，无法准确反映模型的真实泛化能力。


<details>
  <summary>Details</summary>
Motivation: LLM训练数据中如果包含基准测试数据的污染，会导致基准性能评估出现偏差，无法准确衡量模型在分布外数据上的真实泛化能力。传统的n-gram去重方法无法检测语义重复（内容相同但字符串不同的数据），需要研究这种软污染问题。

Method: 通过嵌入Olmo3训练语料库进行分析，检测语义重复污染。研究包括：1) 量化污染程度；2) 分析包含语义重复数据对基准性能的影响；3) 研究在基准数据重复点上微调对真正保留数据性能的影响。

Result: 1) 污染广泛存在：CodeForces问题中78%存在语义重复，ZebraLogic问题中50%存在精确重复；2) 包含基准数据的语义重复确实提高基准性能；3) 在基准数据重复点上微调也能提高同一基准中真正保留数据的性能。

Conclusion: 近期基准测试的改进是混淆的：性能提升既反映了真实能力改进，也反映了训练数据中积累的测试数据及其有效变体。语义重复污染普遍存在，导致基准性能被高估，无法准确评估模型的实际泛化能力。

Abstract: If LLM training data is polluted with benchmark test data, then benchmark performance gives biased estimates of out-of-distribution (OOD) generalization. Typical decontamination filters use n-gram matching which fail to detect semantic duplicates: sentences with equivalent (or near-equivalent) content that are not close in string space. We study this soft contamination of training data by semantic duplicates. Among other experiments, we embed the Olmo3 training corpus and find that: 1) contamination remains widespread, e.g. we find semantic duplicates for 78% of CodeForces and exact duplicates for 50% of ZebraLogic problems; 2) including semantic duplicates of benchmark data in training does improve benchmark performance; and 3) when finetuning on duplicates of benchmark datapoints, performance also improves on truly-held-out datapoints from the same benchmark. We argue that recent benchmark gains are thus confounded: the prevalence of soft contamination means gains reflect both genuine capability improvements and the accumulation of test data and effective test data in growing training corpora.

</details>


### [125] [Stabilizing Native Low-Rank LLM Pretraining](https://arxiv.org/abs/2602.12429)
*Paul Janson,Edouard Oyallon,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 本文提出Spectron方法，通过谱重归一化和正交化技术，首次实现了从头开始训练纯低秩权重的大型语言模型，无需全秩指导，同时建立了计算最优的缩放定律。


<details>
  <summary>Details</summary>
Motivation: 基础模型参数数量增长带来了显著的计算和内存挑战。虽然低秩分解提供了减少训练和推理成本的途径，但社区缺乏从头开始训练纯低秩权重模型并匹配密集模型性能的稳定方法。

Method: 提出Spectron方法：谱重归一化与正交化技术，动态限制权重更新的谱范数（最大奇异值），解决了低秩训练中的不稳定性和损失尖峰问题，实现了端到端的因子化训练。

Result: 成功实现了从头开始训练纯低秩权重的大型语言模型，无需辅助的全秩指导，训练稳定且开销可忽略。建立了计算最优的低秩Transformer缩放定律，展示了可预测的幂律行为和相对于密集模型改进的推理效率。

Conclusion: Spectron方法解决了低秩训练的关键稳定性问题，首次实现了纯低秩权重模型的从头训练，为高效的基础模型训练提供了新途径，并建立了可预测的缩放定律指导模型设计。

Abstract: Foundation models have achieved remarkable success, yet their growing parameter counts pose significant computational and memory challenges. Low-rank factorization offers a promising route to reduce training and inference costs, but the community lacks a stable recipe for training models from scratch using exclusively low-rank weights while matching the performance of the dense model. We demonstrate that Large Language Models (LLMs) can be trained from scratch using exclusively low-rank factorized weights for all non-embedding matrices without auxiliary "full-rank" guidance required by prior methods. While native low-rank training often suffers from instability and loss spikes, we identify uncontrolled growth in the spectral norm (largest singular value) of the weight matrix update as the dominant factor. To address this, we introduce Spectron: Spectral renormalization with orthogonalization, which dynamically bounds the resultant weight updates based on the current spectral norms of the factors. Our method enables stable, end-to-end factorized training with negligible overhead. Finally, we establish compute-optimal scaling laws for natively low-rank transformers, demonstrating predictable power-law behavior and improved inference efficiency relative to dense models.

</details>


### [126] [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517)
*Lorenzo Magnino,Jiacheng Shen,Matthieu Geist,Olivier Pietquin,Mathieu Laurière*

Main category: cs.LG

TL;DR: 该论文提出了Bench-MFG，一个用于评估均值场博弈与强化学习算法的标准化基准套件，包含分类学、原型环境和随机生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前均值场博弈与强化学习交叉领域缺乏标准化的评估协议，研究者依赖自定义、孤立且简单的环境，难以评估方法的鲁棒性、泛化能力和失败模式。

Method: 提出了Bench-MFG基准套件，专注于离散时间、离散空间、稳态设置；引入了问题分类学（从无交互到动态耦合博弈）；提出了MF-Garnets方法用于生成随机MFG实例；并提出了MF-PSO黑盒方法进行可利用性最小化。

Result: 对各种学习算法进行了基准测试，基于广泛的实证结果提出了标准化未来实验比较的指南。

Conclusion: Bench-MFG填补了MFG-RL领域标准化评估的空白，提供了全面的基准套件和实验指南，有助于更可靠地评估算法性能。

Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.

</details>


### [127] [Safe Reinforcement Learning via Recovery-based Shielding with Gaussian Process Dynamics Models](https://arxiv.org/abs/2602.12444)
*Alexander W. Goodall,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 提出一种基于恢复的屏蔽框架，为未知非线性连续动力系统的强化学习提供可证明的安全下界保证


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键应用中缺乏可证明的安全保证，需要一种既能保证安全又能高效学习的框架

Method: 集成备份策略（屏蔽）与RL智能体，利用高斯过程不确定性量化预测安全约束违反，仅在必要时动态恢复到安全轨迹

Result: 在连续控制环境中表现出强大性能和严格的安全合规性，支持无限制探索和样本高效学习

Conclusion: 提出的恢复屏蔽框架为未知非线性连续系统的安全强化学习提供了可证明的安全保证和实用解决方案

Abstract: Reinforcement learning (RL) is a powerful framework for optimal decision-making and control but often lacks provable guarantees for safety-critical applications. In this paper, we introduce a novel recovery-based shielding framework that enables safe RL with a provable safety lower bound for unknown and non-linear continuous dynamical systems. The proposed approach integrates a backup policy (shield) with the RL agent, leveraging Gaussian process (GP) based uncertainty quantification to predict potential violations of safety constraints, dynamically recovering to safe trajectories only when necessary. Experience gathered by the 'shielded' agent is used to construct the GP models, with policy optimization via internal model-based sampling - enabling unrestricted exploration and sample efficient learning, without compromising safety. Empirically our approach demonstrates strong performance and strict safety-compliance on a suite of continuous control environments.

</details>


### [128] [Continuous Diffusion Models Can Obey Formal Syntax](https://arxiv.org/abs/2602.12468)
*Jinwoo Kim,Taylor Berg-Kirkpatrick,Loris D'Antoni*

Main category: cs.LG

TL;DR: 提出Diffinity方法，通过训练自由指导技术使连续扩散语言模型满足正则表达式形式化句法约束，无需训练辅助分类器，在JSON和自然语言基准上实现高约束满足率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型因其全局、非因果生成过程而成为自回归模型的有前景替代方案，但其连续潜在动态使得离散约束（如输出需匹配给定JSON模式）难以施加。

Method: 提出训练自由指导方法：构建分析性评分估计潜在状态解码为给定正则表达式接受的有效字符串的概率，利用其梯度指导采样，无需训练辅助分类器。去噪过程以句法有效性为条件的基础模型为目标。

Result: 在Diffinity中实现该方法，基于PLAID扩散模型，在180个正则表达式约束的JSON和自然语言基准上评估。Diffinity实现68-96%约束满足率，相对于无约束采样仅产生小困惑度代价，在约束满足和输出质量上均优于自回归约束解码。

Conclusion: 该方法成功使连续扩散语言模型能够满足形式化句法约束，为扩散模型在需要结构化输出的应用中提供了有效解决方案。

Abstract: Diffusion language models offer a promising alternative to autoregressive models due to their global, non-causal generation process, but their continuous latent dynamics make discrete constraints -- e.g., the output should be a JSON file that matches a given schema -- difficult to impose. We introduce a training-free guidance method for steering continuous diffusion language models to satisfy formal syntactic constraints expressed using regular expressions. Our approach constructs an analytic score estimating the probability that a latent state decodes to a valid string accepted by a given regular expression, and uses its gradient to guide sampling, without training auxiliary classifiers. The denoising process targets the base model conditioned on syntactic validity.
  We implement our method in Diffinity on top of the PLAID diffusion model and evaluate it on 180 regular-expression constraints over JSON and natural-language benchmarks. Diffinity achieves 68-96\% constraint satisfaction while incurring only a small perplexity cost relative to unconstrained sampling, outperforming autoregressive constrained decoding in both constraint satisfaction and output quality.

</details>


### [129] [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)
*Noor Islam S. Mohammad,Md Muntaqim Meherab*

Main category: cs.LG

TL;DR: 提出正则化元学习框架，通过冗余感知投影、统计元特征增强和交叉验证正则化元模型，解决深度集成方法的冗余、不稳定权重和过拟合问题，在基准测试中显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度集成方法存在三个实际问题：1) 基础模型间的冗余性增加计算成本并恶化条件数；2) 多重共线性下的不稳定权重分配；3) 元学习管道中的过拟合。需要一种稳定且部署高效的集成策略。

Method: 四阶段管道：1) 使用相关性阈值(τ_corr=0.95)和MSE阈值的多指标去重策略消除近共线性预测器；2) 统计元特征增强和交互项恢复高阶结构；3) 交叉验证正则化元模型(Ridge、Lasso、ElasticNet)；4) 逆RMSE混合阶段减少正则化选择方差。

Result: 在Playground Series S6E1基准测试(10万样本，72个基础模型)中，OOF RMSE达到8.582，优于简单平均(8.894)和传统Ridge堆叠(8.627)，与贪婪爬山算法(8.603)相当但运行时间快4倍。冗余投影后有效矩阵条件数降低53.7%。

Conclusion: 正则化元学习框架通过去重、统计元特征和元集成混合，为高维集成系统提供了稳定且部署高效的堆叠策略，在保持预测多样性的同时显著改善条件数和计算效率。

Abstract: Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.

</details>


### [130] [Designing RNAs with Language Models](https://arxiv.org/abs/2602.12470)
*Milan Gautam,Ning Dai,Tianshuo Zhou,Bowen Xie,David Mathews,Liang Huang*

Main category: cs.LG

TL;DR: 该论文将RNA设计重新定义为条件序列生成任务，提出基于自回归语言模型和强化学习的可复用神经近似器，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RNA设计（寻找折叠成目标二级结构的序列）具有重要生物学和生物医学意义，但由于序列空间指数级庞大且存在大量竞争性折叠，计算上极具挑战性。传统方法将其视为优化问题，依赖实例特定启发式或约束搜索，缺乏可复用性。

Method: 将RNA设计重构为条件序列生成任务，引入基于自回归语言模型的可复用神经近似器。首先在随机诱导的结构-序列对上监督训练，然后使用强化学习优化端到端指标，并提出选择RL子集的方法以提高效率和效果。

Result: 在四个数据集上，该方法在Boltzmann概率等关键指标上优于现有最先进系统，同时速度快1.7倍，证明了条件语言模型生成作为RNA设计可扩展、任务无关的替代方案的可行性。

Conclusion: 条件语言模型生成为RNA设计提供了一种可扩展、任务无关的替代方案，优于传统的每实例优化方法，代码和数据已开源。

Abstract: RNA design, the task of finding a sequence that folds into a target secondary structure, has broad biological and biomedical impact but remains computationally challenging due to the exponentially large sequence space and exponentially many competing folds. Traditional approaches treat it as an optimization problem, relying on per-instance heuristics or constraint-based search. We instead reframe RNA design as conditional sequence generation and introduce a reusable neural approximator, instantiated as an autoregressive language model (LM), that maps target structures directly to sequences. We first train our model in a supervised setting on random-induced structure-sequence pairs, and then use reinforcement learning (RL) to optimize end-to-end metrics. We also propose methods to select a small subset for RL that greatly improves RL efficiency and quality. Across four datasets, our approach outperforms state-of-the-art systems on key metrics such as Boltzmann probability while being 1.7x faster, establishing conditional LM generation as a scalable, task-agnostic alternative to per-instance optimization for RNA design. Our code and data are available at https://github.com/KuNyaa/RNA-Design-LM.

</details>


### [131] [Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension](https://arxiv.org/abs/2602.12471)
*Michael Crawshaw,Mingrui Liu*

Main category: cs.LG

TL;DR: 在二维可分数据上，梯度下降使用大学习率训练线性二分类模型，当迭代次数足够时，损失可达到O(1/(ηT))的加速收敛率。


<details>
  <summary>Details</summary>
Motivation: 研究梯度下降在可分数据上训练线性二分类模型时的收敛行为，特别是当使用大学习率导致损失非单调变化时，能否获得比传统1/T更快的收敛速率。

Method: 针对二维可分数据，对梯度下降进行精细分析，特别关注GD从不稳定（非单调损失）到稳定（单调损失）的过渡时间τ，通过分析正交于最大间隔分类器的子空间中的振荡动力学。

Result: 当T ≥ Ω(n/γ + 1/γ²)时，GD使用足够大的学习率η能找到损失小于O(1/(ηT))的点，比之前的1/T²加速率更紧。同时给出了τ的上下界匹配（相差对数因子），证明分析是紧的。

Conclusion: 在二维可分数据上，梯度下降使用大学习率能实现O(1/(ηT))的加速收敛，通过精细分析振荡动力学获得了比先前更紧的收敛率，并证明了分析的最优性。

Abstract: We consider the optimization problem of minimizing the logistic loss with gradient descent to train a linear model for binary classification with separable data. With a budget of $T$ iterations, it was recently shown that an accelerated $1/T^2$ rate is possible by choosing a large step size $η= Θ(γ^2 T)$ (where $γ$ is the dataset's margin) despite the resulting non-monotonicity of the loss. In this paper, we provide a tighter analysis of gradient descent for this problem when the data is two-dimensional: we show that GD with a sufficiently large learning rate $η$ finds a point with loss smaller than $\mathcal{O}(1/(ηT))$, as long as $T \geq Ω(n/γ+ 1/γ^2)$, where $n$ is the dataset size. Our improved rate comes from a tighter bound on the time $τ$ that it takes for GD to transition from unstable (non-monotonic loss) to stable (monotonic loss), via a fine-grained analysis of the oscillatory dynamics of GD in the subspace orthogonal to the max-margin classifier. We also provide a lower bound of $τ$ matching our upper bound up to logarithmic factors, showing that our analysis is tight.

</details>


### [132] [Geometric separation and constructive universal approximation with two hidden layers](https://arxiv.org/abs/2602.12482)
*Chanyoung Sung*

Main category: cs.LG

TL;DR: 本文提出了一种几何构造方法，使神经网络能够分离ℝⁿ中的不相交紧子集，并获得了构造性的通用逼近定理，证明了两层隐藏层的神经网络（使用sigmoid或ReLU激活函数）可以在任意紧集上一致逼近任何实值连续函数。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络的通用逼近能力，特别是针对不同激活函数和网络深度，为神经网络的理论基础提供几何构造性的证明方法。

Method: 采用几何构造方法，通过构建能够分离不相交紧子集的神经网络，证明了两层隐藏层（使用sigmoid或ReLU激活函数）的神经网络具有通用逼近性质。对于有限集合的情况，简化构造得到单隐藏层的深度-2网络逼近结果。

Result: 证明了具有两个隐藏层和sigmoid或ReLU激活函数的神经网络可以在任意紧集K⊂ℝⁿ上一致逼近任何实值连续函数。对于有限集合K，构造简化后得到深度-2（单隐藏层）的尖锐逼近结果。

Conclusion: 通过几何构造方法，为神经网络的通用逼近定理提供了新的证明，特别强调了两层隐藏层网络在sigmoid和ReLU激活函数下的逼近能力，为神经网络的理论分析提供了重要工具。

Abstract: We give a geometric construction of neural networks that separate disjoint compact subsets of $\Bbb R^n$, and use it to obtain a constructive universal approximation theorem. Specifically, we show that networks with two hidden layers and either a sigmoidal activation (i.e., strictly monotone bounded continuous) or the ReLU activation can approximate any real-valued continuous function on an arbitrary compact set $K\subset\Bbb R^n$ to any prescribed accuracy in the uniform norm. For finite $K$, the construction simplifies and yields a sharp depth-2 (single hidden layer) approximation result.

</details>


### [133] [A Theoretical Analysis of Mamba's Training Dynamics: Filtering Relevant Features for Generalization in State Space Models](https://arxiv.org/abs/2602.12499)
*Mugunthan Shandirasegaran,Hongkang Li,Songyang Zhang,Meng Wang,Shuai Zhang*

Main category: cs.LG

TL;DR: 该论文首次对Mamba风格的选择性状态空间模型(SSM)进行了理论分析，证明了在结构化数据模型下，简化版Mamba块能够实现有保证的泛化，并揭示了其门控机制如何选择相关特征。


<details>
  <summary>Details</summary>
Motivation: 尽管Mamba和其他选择性SSM在序列建模中取得了经验成功，但其理论基础仍然不足。现有研究主要关注Transformer架构，缺乏对非注意力架构的理论理解。本文旨在填补这一空白，为选择性SSM提供理论分析。

Method: 研究采用简化的代表性Mamba块：单层单头选择性SSM，带有输入依赖的门控，后接两层MLP，使用梯度下降训练。分析基于结构化数据模型，包含类别相关和类别无关模式，并考虑两种典型机制：多数投票和局部结构化数据序列。

Result: 证明了模型能够实现有保证的泛化，建立了非渐近样本复杂度和收敛率界限，这些界限随着有效信号增加和噪声减少而改善。同时证明了门控向量与类别相关特征对齐，忽略无关特征，实现了类似注意力的特征选择功能。

Conclusion: 该研究为Mamba风格选择性SSM何时以及为何能够高效学习提供了原则性见解，为Transformer中心化的解释提供了理论对应。数值实验验证了理论结果，表明选择性SSM通过选择性递归实现了有效的特征选择。

Abstract: The recent empirical success of Mamba and other selective state space models (SSMs) has renewed interest in non-attention architectures for sequence modeling, yet their theoretical foundations remain underexplored. We present a first-step analysis of generalization and learning dynamics for a simplified but representative Mamba block: a single-layer, single-head selective SSM with input-dependent gating, followed by a two-layer MLP trained via gradient descent (GD). Our study adopts a structured data model with tokens that include both class-relevant and class-irrelevant patterns under token-level noise and examines two canonical regimes: majority-voting and locality-structured data sequences. We prove that the model achieves guaranteed generalization by establishing non-asymptotic sample complexity and convergence rate bounds, which improve as the effective signal increases and the noise decreases. Furthermore, we show that the gating vector aligns with class-relevant features while ignoring irrelevant ones, thereby formalizing a feature-selection role similar to attention but realized through selective recurrence. Numerical experiments on synthetic data justify our theoretical results. Overall, our results provide principled insight into when and why Mamba-style selective SSMs learn efficiently, offering a theoretical counterpoint to Transformer-centric explanations.

</details>


### [134] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: RL微调视觉语言模型在视觉推理基准上表现提升，但对文本扰动敏感，存在准确性-忠实性权衡，需要联合评估正确性、鲁棒性和推理忠实性


<details>
  <summary>Details</summary>
Motivation: 研究RL微调视觉语言模型在视觉推理任务中的脆弱性，特别是对文本扰动的敏感性，以及微调过程中出现的准确性-忠实性权衡问题

Method: 使用误导性标题或错误思维链等简单文本扰动测试模型鲁棒性，引入熵基指标分析模型不确定性，研究RL微调动态，探索对抗增强和忠实性感知奖励方法

Result: 文本扰动导致鲁棒性和置信度显著下降，思维链一致性考虑时效果更明显；RL微调提高基准准确性但降低推理忠实性和上下文偏移鲁棒性；对抗增强改善鲁棒性但不能防止忠实性漂移；忠实性感知奖励可恢复答案与推理对齐

Conclusion: 仅基于准确性的评估存在局限性，需要开发联合强调正确性、鲁棒性和视觉基础推理忠实性的训练与评估协议

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [135] [Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings](https://arxiv.org/abs/2602.12520)
*Zhizun Wang,David Meger*

Main category: cs.LG

TL;DR: 提出一种新颖的基于模型的多智能体强化学习框架，通过联合状态-动作表示学习与想象推演相结合，在部分可观测的动态环境中实现高效协调。


<details>
  <summary>Details</summary>
Motivation: 在多智能体部分可观测动态环境中，需要信息丰富的表示和数据高效的训练方法，以协调多个智能体的行为。

Method: 设计基于变分自编码器的世界模型，引入状态-动作学习嵌入（SALE），将其注入到预测未来推演的想象模块和联合智能体网络中，通过混合网络估计联合动作价值函数。

Result: 在StarCraft II微操、Multi-Agent MuJoCo和Level-Based Foraging等基准测试中，该方法相比基线算法取得一致性能提升。

Conclusion: 联合状态-动作学习嵌入在多智能体基于模型范式中有效，使智能体更好地理解个体选择对集体结果的影响，提升长期规划和优化能力。

Abstract: Learning to coordinate many agents in partially observable and highly dynamic environments requires both informative representations and data-efficient training. To address this challenge, we present a novel model-based multi-agent reinforcement learning framework that unifies joint state-action representation learning with imaginative roll-outs. We design a world model trained with variational auto-encoders and augment the model using the state-action learned embedding (SALE). SALE is injected into both the imagination module that forecasts plausible future roll-outs and the joint agent network whose individual action values are combined through a mixing network to estimate the joint action-value function. By coupling imagined trajectories with SALE-based action values, the agents acquire a richer understanding of how their choices influence collective outcomes, leading to improved long-term planning and optimization under limited real-environment interactions. Empirical studies on well-established multi-agent benchmarks, including StarCraft II Micro-Management, Multi-Agent MuJoCo, and Level-Based Foraging challenges, demonstrate consistent gains of our method over baseline algorithms and highlight the effectiveness of joint state-action learned embeddings within a multi-agent model-based paradigm.

</details>


### [136] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: CRT是一种基于约束优化的后训练框架，通过交替最小化推理长度和仅在性能低于参考时修正准确率，实现稳定有效的冗余推理剪枝，显著减少token使用同时保持答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有CoT推理方法存在推理轨迹过长导致高推理成本、冗余步骤（过度思考）的问题，而基于启发式的方法（长度感知奖励设计或提示校准）可能导致严重的准确率下降且对超参数敏感。

Method: 提出CRT（约束矫正训练）框架，基于参考保护的约束优化，交替最小化推理长度和仅在性能低于参考时修正准确率。进一步采用两阶段训练方案：首先发现最短可靠推理模式，然后在学习到的长度预算下优化准确率。

Result: CRT能持续减少token使用同时保持答案质量在稳健可靠水平。不仅缩短响应长度，还减少内部语言冗余。产生一系列中间检查点，可在不重新训练的情况下精细控制推理详细程度。

Conclusion: CRT提供了一个原则性的后训练框架，通过约束优化实现高效推理，平衡推理长度和准确率，解决了现有启发式方法的稳定性问题，并为推理效率提供了新的评估指标。

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [137] [Analytical Results for Two Exponential Family Distributions in Hierarchical Dirichlet Processes](https://arxiv.org/abs/2602.12527)
*Naiqi Li*

Main category: cs.LG

TL;DR: 本文研究了分层狄利克雷过程（HDP）框架下指数族分布的解析结果，特别针对泊松分布和正态分布，推导了Gamma-Poisson和Normal-Gamma-Normal共轭对的闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 现有HDP应用主要关注狄利克雷-多项共轭结构，但HDP框架本身更通用，原则上可容纳更广泛的共轭先验-似然对。指数族分布提供了统一且解析可处理的建模范式，涵盖许多常用分布。

Method: 在分层狄利克雷过程框架下，研究指数族分布的两个重要成员：泊松分布和正态分布。推导了相应的Gamma-Poisson和Normal-Gamma-Normal共轭对的显式闭式表达式，提供了详细的推导和证明。

Result: 获得了HDP框架下Gamma-Poisson和Normal-Gamma-Normal共轭对的解析闭式表达式，阐明了底层数学结构，展示了如何在分层非参数模型中系统利用共轭性。

Conclusion: 本研究将HDP的适用性扩展到狄利克雷-多项设置之外，为使用分层贝叶斯非参数方法的研究人员提供了实用的解析结果。

Abstract: The Hierarchical Dirichlet Process (HDP) provides a flexible Bayesian nonparametric framework for modeling grouped data with a shared yet unbounded collection of mixture components. While existing applications of the HDP predominantly focus on the Dirichlet-multinomial conjugate structure, the framework itself is considerably more general and, in principle, accommodates a broad class of conjugate prior-likelihood pairs. In particular, exponential family distributions offer a unified and analytically tractable modeling paradigm that encompasses many commonly used distributions. In this paper, we investigate analytic results for two important members of the exponential family within the HDP framework: the Poisson distribution and the normal distribution. We derive explicit closed-form expressions for the corresponding Gamma-Poisson and Normal-Gamma-Normal conjugate pairs under the hierarchical Dirichlet process construction. Detailed derivations and proofs are provided to clarify the underlying mathematical structure and to demonstrate how conjugacy can be systematically exploited in hierarchical nonparametric models. Our work extends the applicability of the HDP beyond the Dirichlet-multinomial setting and furnishes practical analytic results for researchers employing hierarchical Bayesian nonparametrics.

</details>


### [138] [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)
*Bowen Ping,Chengyou Jia,Minnan Luo,Hangwei Qian,Ivor Tsang*

Main category: cs.LG

TL;DR: Flow-Factory是一个统一的强化学习框架，用于对齐扩散和流匹配模型与人类偏好，解决了代码库碎片化、模型特定实现和工程复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在扩散和流匹配模型对齐中存在代码库碎片化、模型特定实现复杂、工程难度大等问题，阻碍了研究进展。

Method: 采用模块化、基于注册表的架构设计，将算法、模型和奖励解耦，支持GRPO、DiffusionNFT、AWM等算法和Flux、Qwen-Image、WAN等模型。

Result: 实现了生产级内存优化、灵活的多奖励训练和无缝分布式训练支持，显著降低了实现开销，使研究人员能够快速原型设计和扩展创新。

Conclusion: Flow-Factory通过统一的模块化框架解决了强化学习在扩散模型对齐中的工程挑战，为未来创新提供了快速原型设计和规模化支持。

Abstract: Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.

</details>


### [139] [AMPS: Adaptive Modality Preference Steering via Functional Entropy](https://arxiv.org/abs/2602.12533)
*Zihan Huang,Xintong Li,Rohan Surana,Tong Yu,Rui Wang,Julian McAuley,Jingbo Shang,Junda Wu*

Main category: cs.LG

TL;DR: 提出实例感知的模态偏好调控方法，通过量化每个模态的信息贡献和样本特异性敏感性，实现更精准的模态偏好调整，同时保持低错误率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的模态偏好问题，要么过度依赖语言先验而忽视视觉证据，要么过度关注视觉显著性而忽视文本上下文。现有方法采用统一的调控强度，但强调控会损害标准推理并增加错误率，弱调控则往往无效。由于不同多模态实例对调控的敏感性差异很大，单一的全局强度难以校准。

Method: 1) 提出实例感知的诊断指标，量化每个模态的信息贡献并揭示样本特异性对调控的敏感性；2) 基于这些洞察，提出减少敏感样本调控的缩放策略；3) 设计可学习模块来推断缩放模式，实现实例感知的模态偏好控制。

Result: 实验结果表明，实例感知的调控方法在调节模态偏好方面优于传统调控方法，能够实现有效调整的同时保持较低的生成错误率。

Conclusion: 通过实例感知的模态偏好调控方法，可以更精准地调整多模态大语言模型的模态偏好，避免了传统统一强度调控的局限性，在保持模型性能的同时有效解决了模态偏好问题。

Abstract: Multimodal Large Language Models (MLLMs) often exhibit significant modality preference, which is a tendency to favor one modality over another. Depending on the input, they may over-rely on linguistic priors relative to visual evidence, or conversely over-attend to visually salient but facts in textual contexts. Prior work has applied a uniform steering intensity to adjust the modality preference of MLLMs. However, strong steering can impair standard inference and increase error rates, whereas weak steering is often ineffective. In addition, because steering sensitivity varies substantially across multimodal instances, a single global strength is difficult to calibrate. To address this limitation with minimal disruption to inference, we introduce an instance-aware diagnostic metric that quantifies each modality's information contribution and reveals sample-specific susceptibility to steering. Building on these insights, we propose a scaling strategy that reduces steering for sensitive samples and a learnable module that infers scaling patterns, enabling instance-aware control of modality preference. Experimental results show that our instance-aware steering outperforms conventional steering in modulating modality preference, achieving effective adjustment while keeping generation error rates low.

</details>


### [140] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: ExtraCare是一个用于临床事件预测的领域自适应框架，通过将患者表征分解为不变和协变组件，在提高预测准确性的同时提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）的深度学习模型在不同数据分布下部署时性能会下降。虽然领域自适应方法可以缓解这种偏移，但其"黑盒"特性阻碍了在临床实践中的广泛应用，因为透明度对于信任和安全至关重要。

Method: ExtraCare将患者表征分解为不变组件和协变组件。通过监督这两个组件并在训练中强制它们的正交性，模型在保留标签信息的同时暴露领域特定变化。此外，通过将稀疏潜在维度映射到医学概念，并通过针对性消融量化其贡献，提供人类可理解的解释。

Result: 在两个真实世界EHR数据集上的多个领域划分设置中评估，ExtraCare表现出优越的性能和增强的透明度，通过广泛的案例研究证明了其准确的预测和解释能力。

Conclusion: ExtraCare通过将患者表征分解为不变和协变组件，不仅提高了临床事件预测的准确性，还提供了可解释性，解决了领域自适应方法在临床实践中因"黑盒"特性而难以广泛应用的问题。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [141] [SD-MoE: Spectral Decomposition for Effective Expert Specialization](https://arxiv.org/abs/2602.12556)
*Ruijun Huang,Fang Dong,Xin Zhang,Hengjie Cao,Zhendong Huang,Anrui Chen,Jixian Zhou,Mengyi Chen,Yifeng Yang,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Fan Yang,Tun Lu,Chun Zhang,Li Shang*

Main category: cs.LG

TL;DR: 论文提出SD-MoE方法，通过谱空间解耦参数和梯度来解决MoE架构中专家专业化失败的问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: MoE架构通过条件计算实现专家专业化来扩展大语言模型，但实践中专家专业化常常失败：一些专家功能相似，另一些则充当事实上的共享专家，限制了有效容量和模型性能。

Method: 从谱角度分析参数和梯度空间，发现专家参数共享高度重叠的谱成分，梯度子空间强对齐，门控机制偏好沿主导方向路由。提出谱解耦MoE（SD-MoE），在谱空间解耦参数和梯度。

Result: SD-MoE在下游任务中提升性能，实现有效的专家专业化，仅增加最小计算开销，并能无缝集成到现有MoE架构（如Qwen和DeepSeek）中。

Conclusion: 通过谱空间解耦参数和梯度可以有效解决MoE架构中的专家专业化失败问题，提升模型性能并保持计算效率。

Abstract: Mixture-of-Experts (MoE) architectures scale Large Language Models via expert specialization induced by conditional computation. In practice, however, expert specialization often fails: some experts become functionally similar, while others functioning as de facto shared experts, limiting the effective capacity and model performance. In this work, we analysis from a spectral perspective on parameter and gradient spaces, uncover that (1) experts share highly overlapping dominant spectral components in their parameters, (2) dominant gradient subspaces are strongly aligned across experts, driven by ubiquitous low-rank structure in human corpus, and (3) gating mechanisms preferentially route inputs along these dominant directions, further limiting specialization. To address this, we propose Spectral-Decoupled MoE (SD-MoE), which decomposes both parameter and gradient in the spectral space. SD-MoE improves performance across downstream tasks, enables effective expert specialization, incurring minimal additional computation, and can be seamlessly integrated into a wide range of existing MoE architectures, including Qwen and DeepSeek.

</details>


### [142] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FO-RI-FedAvg方法，通过分数阶优化和粗糙度感知的正则化，解决电动汽车联邦学习中的连接不稳定、参与度变化和客户端差异问题。


<details>
  <summary>Details</summary>
Motivation: 电动汽车联邦学习面临连接不稳定、客户端参与度时变、以及不同运行条件导致的客户端间显著差异等挑战，传统FedAvg和先进方法在这些现实约束下容易产生过度漂移和收敛退化。

Method: 提出FO-RI-FedAvg方法，包含两个客户端机制：(1) 自适应粗糙度感知近端正则化，根据局部损失函数粗糙度动态调整向全局模型的拉力；(2) 分数阶局部优化，利用短期记忆平滑冲突的更新方向。该方法保持标准FedAvg服务器聚合，仅增加可分摊开销的元素级操作。

Result: 在VED和eVED两个真实世界电动汽车能量预测数据集上的实验表明，FO-RI-FedAvg相比强联邦学习基线实现了更高的准确性和更稳定的收敛，特别是在客户端参与度降低的情况下。

Conclusion: FO-RI-FedAvg是一种轻量级、模块化的FedAvg扩展，通过分数阶优化和粗糙度感知正则化有效提升了电动汽车联邦学习的稳定性和性能。

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [143] [VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction](https://arxiv.org/abs/2602.12579)
*Xin-Qiang Cai,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出VI-CuRL框架，通过模型内在置信度构建课程学习，解决无验证器强化学习中梯度方差问题，在多个基准测试中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证器的强化学习方法（RLVR）依赖外部验证器，可扩展性受限。研究发现RLVR主要通过激发潜在能力发挥作用，因此需要开发无验证器算法。但标准方法如GRPO面临破坏性梯度方差问题，常导致训练崩溃。

Method: 提出Verifier-Independent Curriculum Reinforcement Learning (VI-CuRL)框架，利用模型内在置信度构建独立于外部验证器的课程学习。通过优先处理高置信度样本，有效管理偏差-方差权衡，特别针对减少动作和问题方差。

Result: 理论分析证明估计器保证渐近无偏性。实证结果显示VI-CuRL促进训练稳定性，在六个具有挑战性的基准测试（无论有无验证器）中一致优于无验证器基线方法。

Conclusion: VI-CuRL为解决无验证器强化学习中的梯度方差问题提供了有效框架，通过内在置信度构建课程学习，在多个任务中表现出优越性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.

</details>


### [144] [Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers](https://arxiv.org/abs/2602.12587)
*Anrui Chen,Ruijun Huang,Xin Zhang,Fang Dong,Hengjie Cao,Zhendong Huang,Yifeng Yang,Mengyi Chen,Jixian Zhou,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Tun Lu,Fan Yang,Li Shang*

Main category: cs.LG

TL;DR: MH-MoE通过头级路由减少混合专家模型在持续学习中的遗忘问题，将BWT从11.2%降低到4.5%


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构理论上适合持续学习（稀疏路由应能减少干扰），但实际MoE Transformer仍然存在显著遗忘。作者发现这是由于预路由瓶颈：多头注意力将多个头的信号拼接成单个路由器输入，导致路由器必须处理复杂的特征组合而非可分离的头通道。

Method: 提出MH-MoE（多头混合专家），在子表示上执行头级路由，增加路由粒度，减少特征组合冲突。通过量化路由有效组合数N_eff来衡量冲突程度，并设计头级路由机制来改善路由决策。

Result: 在TRACE基准测试中使用Qwen3-0.6B/8B模型，MH-MoE有效缓解了遗忘问题，将Qwen3-0.6B的BWT（后向转移）从LoRAMoE的11.2%降低到4.5%。

Conclusion: 通过头级路由提高路由粒度可以显著减少MoE模型在持续学习中的遗忘，证明了预路由瓶颈是MoE遗忘问题的关键原因，MH-MoE为解决这一问题提供了有效方案。

Abstract: Mixture-of-Experts (MoE) architectures are often considered a natural fit for continual learning because sparse routing should localize updates and reduce interference, yet MoE Transformers still forget substantially even with sparse, well-balanced expert utilization. We attribute this gap to a pre-routing bottleneck: multi-head attention concatenates head-specific signals into a single post-attention router input, forcing routing to act on co-occurring feature compositions rather than separable head channels. We show that this router input simultaneously encodes multiple separately decodable semantic and structural factors with uneven head support, and that different feature compositions induce weakly aligned parameter-gradient directions; as a result, routing maps many distinct compositions to the same route. We quantify this collision effect via a route-wise effective composition number $N_{eff}$ and find that higher $N_{eff}$ is associated with larger old-task loss increases after continual training. Motivated by these findings, we propose MH-MoE, which performs head-wise routing over sub-representations to increase routing granularity and reduce composition collisions. On TRACE with Qwen3-0.6B/8B, MH-MoE effectively mitigates forgetting, reducing BWT on Qwen3-0.6B from 11.2% (LoRAMoE) to 4.5%.

</details>


### [145] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: 提出基于分布式光纤传感系统的单车道异常检测方法，通过追踪车辆路径和检测变道行为来识别导致拥堵的单车道异常，在真实交通数据上达到80%的变道检测准确率。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤传感系统虽然能有效检测交通拥堵，但难以识别导致拥堵的单车道异常。这些异常可以通过监测车辆为避免拥堵而变道的行为来检测。

Method: 通过聚类技术估计车辆在所有时间点的位置并拟合路径，通过追踪参考车辆并监测其振动频谱质心的变化来检测车辆变道行为。

Result: 使用真实交通数据评估，提出的方法在代表异常存在的变道检测事件上达到80%的准确率。

Conclusion: 该方法能够有效检测单车道异常，通过监测车辆变道行为来识别导致拥堵的道路异常情况。

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [146] [Power Interpretable Causal ODE Networks: A Unified Model for Explainable Anomaly Detection and Root Cause Analysis in Power Systems](https://arxiv.org/abs/2602.12592)
*Yue Sun,Likai Wang,Rick S. Blum,Parv Venkitasubramaniam*

Main category: cs.LG

TL;DR: 提出PICODE网络，一个因果感知的统一架构，用于电力系统时间序列异常检测与解释，能同时进行异常检测、根因定位、异常类型分类和异常形状表征。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型对时间序列异常检测通常作为黑箱运行，只提供二元输出而没有解释（如异常类型和来源），这限制了在电力系统等关键基础设施中的应用。

Method: 提出Power Interpretable Causality Ordinary Differential Equation (PICODE) Networks，一个因果感知的统一架构，结合常微分方程和因果图提取，能联合执行异常检测并提供解释。

Result: 在电力系统中的实验结果表明，PICODE实现了有竞争力的检测性能，同时提供更好的可解释性，减少对标记数据或外部因果图的依赖。

Conclusion: PICODE为电力系统异常检测提供了一个可解释的因果感知解决方案，理论结果证明了异常函数形状与提取的因果图权重变化之间的对齐关系。

Abstract: Anomaly detection and root cause analysis (RCA) are critical for ensuring the safety and resilience of cyber-physical systems such as power grids. However, existing machine learning models for time series anomaly detection often operate as black boxes, offering only binary outputs without any explanation, such as identifying anomaly type and origin. To address this challenge, we propose Power Interpretable Causality Ordinary Differential Equation (PICODE) Networks, a unified, causality-informed architecture that jointly performs anomaly detection along with the explanation why it is detected as an anomaly, including root cause localization, anomaly type classification, and anomaly shape characterization. Experimental results in power systems demonstrate that PICODE achieves competitive detection performance while offering improved interpretability and reduced reliance on labeled data or external causal graphs. We provide theoretical results demonstrating the alignment between the shape of anomaly functions and the changes in the weights of the extracted causal graphs.

</details>


### [147] [Block-Sample MAC-Bayes Generalization Bounds](https://arxiv.org/abs/2602.12605)
*Matthias Frey,Jingge Zhu,Michael C. Gastpar*

Main category: cs.LG

TL;DR: 提出新的MAC-Bayes边界族，通过数据分块降低发散项，相比传统PAC-Bayes边界能提供更紧的期望泛化误差界


<details>
  <summary>Details</summary>
Motivation: 传统PAC-Bayes边界提供高概率的泛化误差界，但可能过于保守甚至无意义。MAC-Bayes边界关注期望泛化误差，但现有方法仍有改进空间。作者希望开发更紧的边界，特别是当传统边界无意义时仍能提供有限边界。

Method: 提出基于数据分块的MAC-Bayes边界族，将训练数据划分为子集（块），边界中的发散项仅依赖于数据块而非整个数据集。这可以看作是已知PAC-Bayes边界期望版本的推广。

Result: 新边界在理论上能显著提高紧致性。数值示例显示：当原始PAC-Bayes边界无论先验如何选择都无意义时，适当选择块大小的新边界仍能提供有限边界。同时证明不存在相应的高概率版本（PAC-Bayes形式）边界。

Conclusion: 提出的MAC-Bayes边界族通过数据分块机制提供了更紧的期望泛化误差界，在某些情况下能解决传统边界无意义的问题。但无法将其直接转化为具有类似形式的高概率边界，这揭示了期望边界和高概率边界之间的根本差异。

Abstract: We present a family of novel block-sample MAC-Bayes bounds (mean approximately correct). While PAC-Bayes bounds (probably approximately correct) typically give bounds for the generalization error that hold with high probability, MAC-Bayes bounds have a similar form but bound the expected generalization error instead. The family of bounds we propose can be understood as a generalization of an expectation version of known PAC-Bayes bounds. Compared to standard PAC-Bayes bounds, the new bounds contain divergence terms that only depend on subsets (or \emph{blocks}) of the training data. The proposed MAC-Bayes bounds hold the promise of significantly improving upon the tightness of traditional PAC-Bayes and MAC-Bayes bounds. This is illustrated with a simple numerical example in which the original PAC-Bayes bound is vacuous regardless of the choice of prior, while the proposed family of bounds are finite for appropriate choices of the block size. We also explore the question whether high-probability versions of our MAC-Bayes bounds (i.e., PAC-Bayes bounds of a similar form) are possible. We answer this question in the negative with an example that shows that in general, it is not possible to establish a PAC-Bayes bound which (a) vanishes with a rate faster than $\mathcal{O}(1/\log n)$ whenever the proposed MAC-Bayes bound vanishes with rate $\mathcal{O}(n^{-1/2})$ and (b) exhibits a logarithmic dependence on the permitted error probability.

</details>


### [148] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: RelBench v2扩展了关系深度学习基准，新增4个大规模数据集、自动补全任务，并整合外部基准，共包含11个数据集、29个表、2200万行数据，证明关系模型优于单表基线。


<details>
  <summary>Details</summary>
Motivation: 随着关系深度学习向更大模型和关系基础模型发展，需要可扩展且真实的基准来支持系统性评估和进展。现有基准在规模、任务多样性和外部集成方面存在不足。

Method: 1) 新增4个大规模关系数据集（学术出版物、企业资源规划、消费平台、临床记录）；2) 引入自动补全任务，要求模型在关系表中推断缺失属性值；3) 整合外部基准：将Temporal Graph Benchmark转换为关系模式，与ReDeLEx接口连接70+真实数据库，纳入4DBInfer数据集。

Result: RelBench v2包含11个数据集、29个表、超过2200万行数据。实验结果显示，关系深度学习模型在自动补全、预测和推荐任务中持续优于单表基线，证明了显式建模关系结构的重要性。

Conclusion: RelBench v2为关系深度学习提供了更全面、可扩展的基准，支持关系基础模型的开发，并通过实验验证了关系建模的价值，为未来研究提供了统一评估框架。

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [149] [Coden: Efficient Temporal Graph Neural Networks for Continuous Prediction](https://arxiv.org/abs/2602.12613)
*Zulun Zhu,Siqiang Luo*

Main category: cs.LG

TL;DR: Coden是一个为动态图连续预测设计的TGNN模型，通过创新方法克服现有TGNN在连续预测场景下的计算复杂度瓶颈，同时保持预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有TGNN主要针对特定时间跨度的一次性预测，而实际应用需要频繁的连续预测。直接适配现有TGNN到连续预测场景会导致显著计算开销或预测质量问题，尤其对于大规模图。

Method: 提出Coden模型，创新性地克服现有TGNN的关键复杂度瓶颈，同时保持可比的预测准确性。提供理论分析证明其有效性和效率，并阐明其与RNN基和注意力基模型的对偶关系。

Result: 在五个动态数据集上的评估显示，Coden在效率和效果上都超越了现有性能基准，成为演化图环境中连续预测的优越解决方案。

Conclusion: Coden为TGNN的连续预测问题提供了高效有效的解决方案，通过理论分析和实验验证证明了其优越性，解决了现有方法在连续预测场景下的计算复杂度和预测质量问题。

Abstract: Temporal Graph Neural Networks (TGNNs) are pivotal in processing dynamic graphs. However, existing TGNNs primarily target one-time predictions for a given temporal span, whereas many practical applications require continuous predictions, that predictions are issued frequently over time. Directly adapting existing TGNNs to continuous-prediction scenarios introduces either significant computational overhead or prediction quality issues especially for large graphs. This paper revisits the challenge of { continuous predictions} in TGNNs, and introduces {\sc Coden}, a TGNN model designed for efficient and effective learning on dynamic graphs. {\sc Coden} innovatively overcomes the key complexity bottleneck in existing TGNNs while preserving comparable predictive accuracy. Moreover, we further provide theoretical analyses that substantiate the effectiveness and efficiency of {\sc Coden}, and clarify its duality relationship with both RNN-based and attention-based models. Our evaluations across five dynamic datasets show that {\sc Coden} surpasses existing performance benchmarks in both efficiency and effectiveness, establishing it as a superior solution for continuous prediction in evolving graph environments.

</details>


### [150] [Efficient Personalized Federated PCA with Manifold Optimization for IoT Anomaly Detection](https://arxiv.org/abs/2602.12622)
*Xianchao Xiu,Chenyi Huang,Wei Zhang,Wanquan Liu*

Main category: cs.LG

TL;DR: 提出FedEP方法，一种用于物联网异常检测的高效个性化联邦PCA方法，通过ℓ₁范数实现个性化，ℓ₂,₁范数保持鲁棒性，使用基于ADMM的流形优化算法，在多种物联网安全场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 物联网网络面临安全威胁，现有联邦PCA方法缺乏个性化和鲁棒性的结合，这对于有效的异常检测至关重要。

Method: 提出FedEP方法：通过ℓ₁范数引入局部表示实现个性化（元素级稀疏性），通过ℓ₂,₁范数强制局部模型保持鲁棒性（行级稀疏性）。使用基于ADMM的流形优化算法解决非凸问题，并提供严格的理论收敛保证。

Result: 实验结果表明，FedEP在多种物联网安全场景中优于最先进的FedPG方法，取得了优秀的F1分数和准确率。

Conclusion: FedEP方法成功解决了物联网异常检测中联邦PCA方法缺乏个性化和鲁棒性的问题，通过创新的稀疏性约束和优化算法实现了高效且有效的检测性能。

Abstract: Internet of things (IoT) networks face increasing security threats due to their distributed nature and resource constraints. Although federated learning (FL) has gained prominence as a privacy-preserving framework for distributed IoT environments, current federated principal component analysis (PCA) methods lack the integration of personalization and robustness, which are critical for effective anomaly detection. To address these limitations, we propose an efficient personalized federated PCA (FedEP) method for anomaly detection in IoT networks. The proposed model achieves personalization through introducing local representations with the $\ell_1$-norm for element-wise sparsity, while maintaining robustness via enforcing local models with the $\ell_{2,1}$-norm for row-wise sparsity. To solve this non-convex problem, we develop a manifold optimization algorithm based on the alternating direction method of multipliers (ADMM) with rigorous theoretical convergence guarantees. Experimental results confirm that the proposed FedEP outperforms the state-of-the-art FedPG, achieving excellent F1-scores and accuracy in various IoT security scenarios. Our code will be available at \href{https://github.com/xianchaoxiu/FedEP}{https://github.com/xianchaoxiu/FedEP}.

</details>


### [151] [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)
*Sangwoo Jo,Sungjoon Choi*

Main category: cs.LG

TL;DR: 提出SDM框架，通过几何视角分析扩散轨迹，自适应选择求解器和时间步长，在减少函数评估次数的同时实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在实际部署中受到高采样成本的限制，现有方法主要关注训练目标或单个求解器，而采样过程的整体设计（求解器选择和时间步长调度）仍由静态启发式方法主导。

Method: 通过几何视角分析ODE动态，提出SDM框架：1）根据扩散轨迹的内在特性自适应选择求解器（早期高噪声阶段使用低阶求解器，后期非线性增强阶段逐步部署高阶求解器）；2）引入Wasserstein有界优化框架，系统推导自适应时间步长，显式约束局部离散化误差。

Result: 无需额外训练或架构修改，在标准基准测试中实现SOTA性能：CIFAR-10上FID为1.93，FFHQ上为2.41，AFHQv2上为1.98，同时相比现有采样器减少了函数评估次数。

Conclusion: SDM通过几何视角和Wasserstein有界优化框架，为扩散模型采样提供了原则性的求解器选择和时间步长调度方法，在保证采样质量的同时显著降低了计算成本。

Abstract: Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection and scheduling, remains dominated by static heuristics. In this work, we revisit this challenge through a geometric lens, proposing SDM, a principled framework that aligns the numerical solver with the intrinsic properties of the diffusion trajectory. By analyzing the ODE dynamics, we show that efficient low-order solvers suffice in early high-noise stages while higher-order solvers can be progressively deployed to handle the increasing non-linearity of later stages. Furthermore, we formalize the scheduling by introducing a Wasserstein-bounded optimization framework. This method systematically derives adaptive timesteps that explicitly bound the local discretization error, ensuring the sampling process remains faithful to the underlying continuous dynamics. Without requiring additional training or architectural modifications, SDM achieves state-of-the-art performance across standard benchmarks, including an FID of 1.93 on CIFAR-10, 2.41 on FFHQ, and 1.98 on AFHQv2, with a reduced number of function evaluations compared to existing samplers. Our code is available at https://github.com/aiimaginglab/sdm.

</details>


### [152] [Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL](https://arxiv.org/abs/2602.13035)
*Yixiao Zhou,Yang Li,Dongzhou Cheng,Hehe Fan,Yu Cheng*

Main category: cs.LG

TL;DR: 提出Introspective LLM框架，通过分层强化学习让LLM在生成过程中学习控制采样温度，实现基于推理不确定性的自适应探索策略


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法使用静态或启发式的采样温度设置，与任务奖励解耦，无法根据推理过程中的不确定性动态调整探索-利用权衡

Method: 分层强化学习框架：在每个解码步骤，模型根据隐藏状态选择温度，从对应分布采样下一个token；通过坐标上升方案联合优化温度和token策略

Result: 在数学推理基准测试中，学习到的温度策略优于固定和启发式基线，并展现出与推理不确定性对齐的可解释探索行为

Conclusion: 采样温度应作为可学习的策略参数，而非固定超参数；学习到的温度控制策略能实现更有效的探索-利用权衡，提升LLM推理性能

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.

</details>


### [153] [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)
*Xin Liu,Yixuan Li,Yuhui Chen,Yuxing Qin,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: DEG：通过生成的情节指导实现双粒度对比奖励，无需人工标注或大量专家监督，利用视频生成模型先验知识为RL提供密集奖励


<details>
  <summary>Details</summary>
Motivation: 传统RL中轨迹成功奖励稀疏性严重限制了样本效率，现有密集奖励方法依赖高质量人工标注数据或大量专家监督，需要解决这些问题

Method: 提出DEG框架：1）利用大型视频生成模型先验知识，仅需少量专家视频进行领域适应，为每个RL情节生成专用任务指导；2）设计双粒度对比奖励，平衡粗粒度探索和细粒度匹配，在对比自监督潜在空间中引导智能体顺序逼近生成的指导视频

Result: 在18个多样化任务（仿真和真实世界）上的实验表明，DEG既能作为高效探索刺激帮助智能体快速发现稀疏成功奖励，又能独立引导有效RL和稳定策略收敛

Conclusion: DEG框架成功解决了RL中密集奖励设计难题，无需人工标注或大量专家监督，通过视频生成模型先验知识和双粒度对比奖励实现了样本高效的强化学习

Abstract: Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively improved RL via dense rewards, they rely heavily on high-quality human-annotated data or abundant expert supervision. To tackle these issues, this paper proposes Dual-granularity contrastive reward via generated Episodic Guidance (DEG), a novel framework to seek sample-efficient dense rewards without requiring human annotations or extensive supervision. Leveraging the prior knowledge of large video generation models, DEG only needs a small number of expert videos for domain adaptation to generate dedicated task guidance for each RL episode. Then, the proposed dual-granularity reward that balances coarse-grained exploration and fine-grained matching, will guide the agent to efficiently approximate the generated guidance video sequentially in the contrastive self-supervised latent space, and finally complete the target task. Extensive experiments on 18 diverse tasks across both simulation and real-world settings show that DEG can not only serve as an efficient exploration stimulus to help the agent quickly discover sparse success rewards, but also guide effective RL and stable policy convergence independently.

</details>


### [154] [Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13069)
*Juneyoung Park,Yuri Hong,Seongwan Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: MeSP是一种内存高效的结构化反向传播方法，通过利用LoRA的低秩结构手动推导反向传播，在移动设备上实现隐私保护的LLM微调，相比传统方法减少49%内存使用。


<details>
  <summary>Details</summary>
Motivation: 移动设备内存有限（6-12GB），现有方法要么需要高内存存储精确梯度（MeBP），要么使用噪声估计但内存低（MeZO），需要在内存和精度之间权衡。

Method: 提出Memory-efficient Structured Backpropagation (MeSP)，利用LoRA的低秩结构手动推导反向传播，通过重新计算中间投影h=xA（因为秩r远小于输入维度d_in），避免存储中间激活值。

Result: 在Qwen2.5模型（0.5B-3B）上平均减少49%内存使用，计算数学上完全相同的梯度；Qwen2.5-0.5B峰值内存从361MB降至136MB；分析显示MeZO的梯度估计与真实梯度相关性极低（余弦相似度≈0.001）。

Conclusion: MeSP在移动设备上实现了内存高效的精确梯度计算，解决了现有方法的内存-精度权衡问题，使之前内存受限设备上不可行的微调场景成为可能。

Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \ll d_{in}$, eliminating the need to store it. MeSP achieves 49\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.

</details>


### [155] [LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13073)
*Juneyoung Park,Eunbeen Yoon,Seongwan Kim. Jaeho Lee*

Main category: cs.LG

TL;DR: 提出LCSB方法，通过每步仅计算部分层的梯度来加速内存高效的反向传播，在保持模型质量的同时获得1.4倍加速，并在低比特量化中表现出更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有内存高效反向传播（MeBP）方法需要在每一步对所有transformer层进行反向计算，其中权重解压缩就占用了32-42%的反向传播时间，限制了在移动设备上的效率。

Method: 提出层循环选择性反向传播（LCSB），每步只计算部分层的梯度。利用残差连接保证梯度通过恒等路径流动，AdamW动量提供对未选择层的隐式更新。将LCSB解释为LoRA参数空间上的块坐标下降，提供理论收敛保证。

Result: 在5个模型和3个任务上实现最高1.4倍加速，质量下降小于2%。在4位量化设置中表现出更好的稳定性：3B模型在完全反向传播下发散，但使用LCSB能平滑收敛，显示出选择性梯度计算的隐式正则化效果。

Conclusion: LCSB通过选择性梯度计算显著提高了内存高效反向传播的效率，在保持模型质量的同时获得加速，并在低比特量化中展现出更好的训练稳定性，为移动设备上的大语言模型微调提供了更高效的解决方案。

Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\times$ speedup with less than 2\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.

</details>


### [156] [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*Jintao Zhang,Haoxu Wang,Kai Jiang,Kaiwen Zheng,Youhe Jiang,Ion Stoica,Jianfei Chen,Jun Zhu,Joseph E. Gonzalez*

Main category: cs.LG

TL;DR: SLA2改进稀疏线性注意力机制，通过可学习路由器和更直接的稀疏-线性组合公式，在视频扩散模型中实现97%注意力稀疏度和18.6倍加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏线性注意力(SLA)存在两个问题：1) 基于注意力权重大小的启发式分割可能不是最优的；2) 与直接分解为稀疏和线性注意力的形式存在不匹配。需要更有效的稀疏注意力机制来加速视频扩散模型。

Method: 提出SLA2方法：1) 可学习路由器动态选择每个注意力计算使用稀疏还是线性注意力；2) 更忠实直接的稀疏-线性注意力公式，使用可学习比例组合两个分支；3) 稀疏+低比特注意力设计，通过量化感知微调减少量化误差。

Result: 在视频扩散模型中，SLA2能够达到97%的注意力稀疏度，实现18.6倍的注意力加速，同时保持生成质量。

Conclusion: SLA2通过可学习路由、改进的稀疏-线性组合公式和低比特量化，有效解决了现有稀疏线性注意力的局限性，在保持生成质量的同时显著提升了视频扩散模型的效率。

Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.

</details>


### [157] [Uncovering spatial tissue domains and cell types in spatial omics through cross-scale profiling of cellular and genomic interactions](https://arxiv.org/abs/2602.12651)
*Rui Yan,Xiaohan Xing,Xun Wang,Zixia Zhou,Md Tauhidul Islam,Lei Xing*

Main category: cs.LG

TL;DR: CellScape是一个深度学习框架，用于分析空间转录组数据，通过联合建模细胞在组织空间中的相互作用和细胞间的基因组关系，提高空间域分割和细胞分析能力。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学数据虽然提供了单细胞分辨率的基因表达谱，但数据噪声大、规模庞大且结构复杂，现有计算方法难以有效捕捉空间相互作用与内在基因组关系之间的相互作用，限制了关键生物学模式的识别。

Method: CellScape是一个深度学习框架，联合建模组织空间中的细胞相互作用和细胞间的基因组关系，生成综合表征，将空间信号与基础基因调控机制无缝整合。

Result: 该方法能够发现具有生物学信息性的模式，改进空间域分割，并支持跨不同转录组数据集的全面空间细胞分析，为ST数据的深度分析和解释提供了准确且通用的框架。

Conclusion: CellScape通过整合空间相互作用和基因组关系，克服了现有空间转录组数据分析方法的局限性，为高性能ST数据分析和模式发现提供了有效的深度学习解决方案。

Abstract: Cellular identity and function are linked to both their intrinsic genomic makeup and extrinsic spatial context within the tissue microenvironment. Spatial transcriptomics (ST) offers an unprecedented opportunity to study this, providing in situ gene expression profiles at single-cell resolution and illuminating the spatial and functional organization of cells within tissues. However, a significant hurdle remains: ST data is inherently noisy, large, and structurally complex. This complexity makes it intractable for existing computational methods to effectively capture the interplay between spatial interactions and intrinsic genomic relationships, thus limiting our ability to discern critical biological patterns. Here, we present CellScape, a deep learning framework designed to overcome these limitations for high-performance ST data analysis and pattern discovery. CellScape jointly models cellular interactions in tissue space and genomic relationships among cells, producing comprehensive representations that seamlessly integrate spatial signals with underlying gene regulatory mechanisms. This technique uncovers biologically informative patterns that improve spatial domain segmentation and supports comprehensive spatial cellular analyses across diverse transcriptomics datasets, offering an accurate and versatile framework for deep analysis and interpretation of ST data.w

</details>


### [158] [Trust the uncertain teacher: distilling dark knowledge via calibrated uncertainty](https://arxiv.org/abs/2602.12687)
*Jeonghyun Kim,SooKyung Kim,Richeng Xuan,Hyunsoo Cho*

Main category: cs.LG

TL;DR: 提出CUD框架，通过校准教师模型的不确定性分布，让学生模型能够更好地学习"暗知识"，提高准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏中，使用交叉熵训练的教师模型会产生过度自信的尖锐概率分布，丢失了类别间关系的细微模式。这种过度自信在高基数任务中尤其有害，会损害学生模型的表示学习能力，并在分布偏移下降低鲁棒性。

Method: 提出校准不确定性蒸馏（CUD）框架，从分布视角重新审视蒸馏。该方法不盲目接受教师的过度自信，而是鼓励教师在有信息的地方展现不确定性，指导学生从校准而非尖锐的目标中学习。通过直接塑造教师预测分布再进行转移，平衡准确性和校准性。

Result: 在多个基准测试中，CUD训练出的学生模型不仅更准确，而且在分布偏移下更校准，对模糊、长尾输入更可靠。

Conclusion: CUD通过校准教师的不确定性分布，让学生能够更好地获取"暗知识"，在简单案例上学习自信信号，在困难案例上学习结构化不确定性，从而提升蒸馏效果。

Abstract: The core of knowledge distillation lies in transferring the teacher's rich 'dark knowledge'-subtle probabilistic patterns that reveal how classes are related and the distribution of uncertainties. While this idea is well established, teachers trained with conventional cross-entropy often fail to preserve such signals. Their distributions collapse into sharp, overconfident peaks that appear decisive but are in fact brittle, offering little beyond the hard label or subtly hindering representation-level transfer. This overconfidence is especially problematic in high-cardinality tasks, where the nuances among many plausible classes matter most for guiding a compact student. Moreover, such brittle targets reduce robustness under distribution shift, leaving students vulnerable to miscalibration in real-world conditions. To address this limitation, we revisit distillation from a distributional perspective and propose Calibrated Uncertainty Distillation (CUD), a framework designed to make dark knowledge more faithfully accessible. Instead of uncritically adopting the teacher's overconfidence, CUD encourages teachers to reveal uncertainty where it is informative and guides students to learn from targets that are calibrated rather than sharpened certainty. By directly shaping the teacher's predictive distribution before transfer, our approach balances accuracy and calibration, allowing students to benefit from both confident signals on easy cases and structured uncertainty on hard ones. Across diverse benchmarks, CUD yields students that are not only more accurate, but also more calibrated under shift and more reliable on ambiguous, long-tail inputs.

</details>


### [159] [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151)
*João Vitor Boer Abitante,Joana Meneguzzo Pasquali,Luan Fonseca Garcia,Ewerton de Oliveira,Thomas da Silva Paula,Rodrigo C. Barros,Lucas S. Kupssinskü*

Main category: cs.LG

TL;DR: LLM遗忘学习结合低比特量化时，标准全参数微调的变化会被量化抹除，导致模型恢复遗忘前状态。使用LoRA将遗忘更新集中在可训练适配器中，能在量化后保持有效更新，显著提升4-bit量化的效用并减少隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 在实际部署中，LLM遗忘学习通常需要后训练量化以实现高效推理，但激进的低比特量化会掩盖或抹除遗忘更新，导致量化模型恢复到遗忘前的行为。标准全参数微调产生的参数变化太小，无法在4-bit量化中存活。

Method: 提出量化鲁棒的遗忘学习方法：冻结基础模型，使用低秩适配器(LoRA)将遗忘学习集中在可训练适配器中，使有效更新在量化后得以保留。在Llama-2-7B模型上使用MUSE数据集(BOOKS和NEWS)进行评估。

Result: LoRA将4-bit量化效用提升高达7.93个点(NPO+GDR on BOOKS: 50.17到58.10)，在NEWS数据集上GA+GDR从40.06提升到44.82。同时显著减少4-bit量化下的隐私泄露，如GA+KLR on BOOKS的PrivLeak从-25.68改善到-5.86(接近理想值0)，同时保持强遗忘效果(VerMem和KnowMem接近0)。

Conclusion: 在需要量化的模型部署场景中，使用LoRA进行机器遗忘学习是有益的，因为它能保持量化后的遗忘更新，提升模型效用并减少隐私泄露，同时维持良好的遗忘效果。

Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.

</details>


### [160] [Can Neural Networks Provide Latent Embeddings for Telemetry-Aware Greedy Routing?](https://arxiv.org/abs/2602.12798)
*Andreas Boltres,Niklas Freymuth,Gerhard Neumann*

Main category: cs.LG

TL;DR: Placer使用消息传递网络将网络状态转换为节点嵌入，通过贪婪下一跳路由实现高效路由决策，同时提供可解释性


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的路由方法虽然能处理网络状态与路由的复杂依赖关系，但牺牲了路由决策的可解释性，因为神经网络模块是黑盒

Method: 使用消息传递网络将网络状态转换为潜在节点嵌入，这些嵌入支持快速贪婪下一跳路由，无需直接解决全对最短路径问题

Result: 提出的Placer算法能够可视化特定网络事件如何影响路由决策，同时保持路由的高效性和响应性

Conclusion: Placer在保持机器学习路由方法效能的同时，解决了可解释性问题，使网络管理员能够理解路由决策背后的逻辑

Abstract: Telemetry-Aware routing promises to increase efficacy and responsiveness to traffic surges in computer networks. Recent research leverages Machine Learning to deal with the complex dependency between network state and routing, but sacrifices explainability of routing decisions due to the black-box nature of the proposed neural routing modules. We propose \emph{Placer}, a novel algorithm using Message Passing Networks to transform network states into latent node embeddings. These embeddings facilitate quick greedy next-hop routing without directly solving the all-pairs shortest paths problem, and let us visualize how certain network events shape routing decisions.

</details>


### [161] [Leverage-Weighted Conformal Prediction](https://arxiv.org/abs/2602.12693)
*Shreyas Fadnavis*

Main category: cs.LG

TL;DR: 提出Leverage-Weighted Conformal Prediction (LWCP)，通过统计杠杆值加权非一致性分数，实现自适应预测区间，无需训练辅助模型，保持有限样本边际覆盖同时改善条件覆盖。


<details>
  <summary>Details</summary>
Motivation: 传统分割保形预测产生恒定宽度的预测区间，在低方差区域过度覆盖，在高方差区域覆盖不足。现有自适应方法需要训练辅助模型，增加了复杂性。

Method: 提出LWCP方法，使用统计杠杆值（帽子矩阵的对角线）作为权重函数对非一致性分数进行加权。该方法从设计矩阵的几何结构中获得自适应性，无需拟合辅助模型。

Result: 理论证明：1) 保持有限样本边际有效性；2) 在异方差通过杠杆因子传递时实现渐近最优条件覆盖；3) 在高斯假设下恢复经典预测区间形式；4) 随机杠杆近似保持覆盖精度；5) 消除传统CP的持续条件覆盖差距。

Conclusion: LWCP提供了一种简单有效的自适应保形预测方法，仅需选择权重函数，计算开销可忽略，在合成和真实数据实验中显著减少了条件覆盖差异。

Abstract: Split conformal prediction provides distribution-free prediction intervals with finite-sample marginal coverage, but produces constant-width intervals that overcover in low-variance regions and undercover in high-variance regions. Existing adaptive methods require training auxiliary models. We propose Leverage-Weighted Conformal Prediction (LWCP), which weights nonconformity scores by a function of the statistical leverage -- the diagonal of the hat matrix -- deriving adaptivity from the geometry of the design matrix rather than from auxiliary model fitting. We prove that LWCP preserves finite-sample marginal validity for any weight function; achieves asymptotically optimal conditional coverage at essentially no width cost when heteroscedasticity factors through leverage; and recovers the form and width of classical prediction intervals under Gaussian assumptions while retaining distribution-free guarantees. We further establish that randomized leverage approximations preserve coverage exactly with controlled width perturbation, and that vanilla CP suffers a persistent, sample-size-independent conditional coverage gap that LWCP eliminates. The method requires no hyperparameters beyond the choice of weight function and adds negligible computational overhead to vanilla CP. Experiments on synthetic and real data confirm the theoretical predictions, demonstrating substantial reductions in conditional coverage disparity across settings.

</details>


### [162] [SWING: Unlocking Implicit Graph Representations for Graph Random Features](https://arxiv.org/abs/2602.12703)
*Alessandro Manenti,Avinava Dubey,Arijit Sehanobish,Cesare Alippi,Krzysztof Choromanski*

Main category: cs.LG

TL;DR: SWING是一种用于隐式图（i-graphs）计算的新算法，通过连续空间中的随机游走而非图节点游走来近似图随机特征计算，无需显式构建图结构。


<details>
  <summary>Details</summary>
Motivation: 传统图计算需要显式构建图结构，而隐式图（如ε-邻域图）的边权重由节点特征向量的二元函数定义，直接计算成本高。需要一种无需显式构建图、能高效处理隐式图计算的方法。

Method: SWING在连续嵌入空间中进行随机游走，而非在图节点上。采用定制化的Gumbel-softmax采样机制，结合线性化核函数（通过随机特征获得）和重要性采样技术。算法基于隐式图与傅里叶分析之间的深层联系。

Result: SWING算法能准确高效地近似原始组合计算，对加速器友好，无需输入图的具体化。在不同类型的隐式图上进行了全面实验验证。

Conclusion: SWING为隐式图计算提供了一种新颖有效的算法框架，通过连续空间中的随机游走避免了显式图构建，具有理论和实践价值。

Abstract: We propose SWING: Space Walks for Implicit Network Graphs, a new class of algorithms for computations involving Graph Random Features on graphs given by implicit representations (i-graphs), where edge-weights are defined as bi-variate functions of feature vectors in the corresponding nodes. Those classes of graphs include several prominent examples, such as: $ε$-neighborhood graphs, used on regular basis in machine learning. Rather than conducting walks on graphs' nodes, those methods rely on walks in continuous spaces, in which those graphs are embedded. To accurately and efficiently approximate original combinatorial calculations, SWING applies customized Gumbel-softmax sampling mechanism with linearized kernels, obtained via random features coupled with importance sampling techniques. This algorithm is of its own interest. SWING relies on the deep connection between implicitly defined graphs and Fourier analysis, presented in this paper. SWING is accelerator-friendly and does not require input graph materialization. We provide detailed analysis of SWING and complement it with thorough experiments on different classes of i-graphs.

</details>


### [163] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: GRAIL框架通过结构化几何表示和结构感知检索，利用双曲空间嵌入临床图，结合确定性编码系统层次和数据驱动的时间关联，预测患者下一次就诊事件，提高多类型预测准确性和层次一致性。


<details>
  <summary>Details</summary>
Motivation: 从纵向电子健康记录预测未来临床事件面临三大挑战：稀疏的多类型临床事件、层次化医学词汇表、以及大语言模型在处理长结构化历史时容易产生幻觉。需要解决这些挑战来准确预测患者下一次就诊事件。

Method: 提出GRAIL框架：1) 构建统一临床图，结合确定性编码系统层次和数据驱动的时间关联；2) 在双曲空间中嵌入该图；3) 将每次就诊总结为概率性中心事件以去噪稀疏观测；4) 推理时检索结构化的临床合理未来事件集；5) 可选使用LLM作为约束推理时间重排器进行精炼。

Result: 在MIMIC-IV数据集上的实验表明，GRAIL持续改进多类型下一次就诊预测，并产生更符合层次结构一致的预测结果。

Conclusion: GRAIL通过结构化几何表示和结构感知检索，有效解决了纵向EHR预测中的稀疏性、层次性和幻觉问题，为临床事件预测提供了更准确和一致的框架。

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [164] [QTabGAN: A Hybrid Quantum-Classical GAN for Tabular Data Synthesis](https://arxiv.org/abs/2602.12704)
*Subhangi Kumari,Rakesh Achutha,Vignesh Sivaraman*

Main category: cs.LG

TL;DR: QTabGAN是一种混合量子-经典生成对抗框架，专门用于合成表格数据，在数据稀缺或隐私受限场景下表现优异，相比现有方法在分类数据集上提升达54.07%


<details>
  <summary>Details</summary>
Motivation: 表格数据合成面临特征类型异构和高维度的挑战，特别是在真实数据稀缺或受隐私限制的场景下，需要更有效的生成方法

Method: 提出QTabGAN混合量子-经典生成对抗框架，利用量子电路学习复杂数据分布，然后通过经典神经网络映射到表格特征

Result: 在多个分类和回归数据集上评估，相比领先的生成模型，QTabGAN在分类数据集上实现高达54.07%的改进

Conclusion: QTabGAN为表格数据合成提供了可扩展的量子方法，展示了量子辅助生成建模的潜力

Abstract: Synthesizing realistic tabular data is challenging due to heterogeneous feature types and high dimensionality. We introduce QTabGAN, a hybrid quantum-classical generative adversarial framework for tabular data synthesis. QTabGAN is especially designed for settings where real data are scarce or restricted by privacy constraints. The model exploits the expressive power of quantum circuits to learn complex data distributions, which are then mapped to tabular features using classical neural networks. We evaluate QTabGAN on multiple classification and regression datasets and benchmark it against leading state-of-the-art generative models. Experiments show that QTabGAN achieves up to 54.07% improvement across various classification datasets and evaluation metrics, thus establishing a scalable quantum approach to tabular data synthesis and highlighting its potential for quantum-assisted generative modelling.

</details>


### [165] [FLAC: Maximum Entropy RL via Kinetic Energy Regularized Bridge Matching](https://arxiv.org/abs/2602.12829)
*Lei Lv,Yunfei Li,Yu Luo,Fuchun Sun,Xiao Ma*

Main category: cs.LG

TL;DR: 提出FLAC框架，通过惩罚速度场的动能来调节策略随机性，无需显式动作密度估计，在连续控制任务中实现高性能


<details>
  <summary>Details</summary>
Motivation: 迭代生成策略（如扩散模型和流匹配）在连续控制中具有优越表达能力，但其动作对数密度不可直接访问，这使最大熵强化学习变得复杂

Method: 将策略优化表述为相对于高熵参考过程（如均匀分布）的广义薛定谔桥问题，通过惩罚速度场动能来调节策略随机性，推导能量正则化的策略迭代方案和实用的离策略算法

Result: FLAC在高维基准测试中实现优于或可比于强基线的性能，同时避免显式密度估计

Conclusion: FLAC提供了一种物理基础的方法来调节策略随机性，将最大熵原则自然纳入策略优化，无需显式动作密度，为连续控制中的迭代生成策略提供了实用框架

Abstract: Iterative generative policies, such as diffusion models and flow matching, offer superior expressivity for continuous control but complicate Maximum Entropy Reinforcement Learning because their action log-densities are not directly accessible. To address this, we propose Field Least-Energy Actor-Critic (FLAC), a likelihood-free framework that regulates policy stochasticity by penalizing the kinetic energy of the velocity field. Our key insight is to formulate policy optimization as a Generalized Schrödinger Bridge (GSB) problem relative to a high-entropy reference process (e.g., uniform). Under this view, the maximum-entropy principle emerges naturally as staying close to a high-entropy reference while optimizing return, without requiring explicit action densities. In this framework, kinetic energy serves as a physically grounded proxy for divergence from the reference: minimizing path-space energy bounds the deviation of the induced terminal action distribution. Building on this view, we derive an energy-regularized policy iteration scheme and a practical off-policy algorithm that automatically tunes the kinetic energy via a Lagrangian dual mechanism. Empirically, FLAC achieves superior or comparable performance on high-dimensional benchmarks relative to strong baselines, while avoiding explicit density estimation.

</details>


### [166] [Physics-Informed Laplace Neural Operator for Solving Partial Differential Equations](https://arxiv.org/abs/2602.12706)
*Heechang Kim,Qianying Cao,Hyomin Shin,Seungchul Lee,George Em Karniadakis,Minseok Choi*

Main category: cs.LG

TL;DR: 提出PILNO方法，将物理信息嵌入拉普拉斯神经算子，通过虚拟输入和时序因果加权提升小数据场景下的精度和泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统神经算子作为参数偏微分方程的快速代理求解器存在局限性：纯数据驱动模型需要大量训练数据，在小数据场景和未见输入函数（分布外）下泛化能力差

Method: 1. 提出高级拉普拉斯神经算子（ALNO）骨干网络，保留极点-残差瞬态表示，将稳态分支替换为FNO风格的傅里叶乘子；2. 提出物理信息拉普拉斯神经算子（PILNO），通过PDE、边界条件和初始条件残差嵌入物理约束；3. 引入虚拟输入：未标记的宽频谱输入函数集合提供丰富的物理监督；4. 使用时序因果加权：时间衰减的物理残差重加权，优先处理早期动态并稳定优化

Result: 在四个代表性基准测试（Burgers方程、Darcy流、反应扩散系统、强迫KdV方程）中，PILNO在小数据设置（N_train ≤ 27）下持续提高精度，减少随机种子间的运行变异性，并比纯数据驱动基线实现更强的分布外泛化

Conclusion: PILNO通过结合物理约束、虚拟输入和时序因果加权，有效解决了神经算子在数据稀缺和分布外场景下的局限性，为小数据物理信息学习提供了稳健框架

Abstract: Neural operators have emerged as fast surrogate solvers for parametric partial differential equations (PDEs). However, purely data-driven models often require extensive training data and can generalize poorly, especially in small-data regimes and under unseen (out-of-distribution) input functions that are not represented in the training data. To address these limitations, we propose the Physics-Informed Laplace Neural Operator (PILNO), which enhances the Laplace Neural Operator (LNO) by embedding governing physics into training through PDE, boundary condition, and initial condition residuals. To improve expressivity, we first introduce an Advanced LNO (ALNO) backbone that retains a pole-residue transient representation while replacing the steady-state branch with an FNO-style Fourier multiplier. To make physics-informed training both data-efficient and robust, PILNO further leverages (i) virtual inputs: an unlabeled ensemble of input functions spanning a broad spectral range that provides abundant physics-only supervision and explicitly targets out-of-distribution (OOD) regimes; and (ii) temporal-causality weighting: a time-decaying reweighting of the physics residual that prioritizes early-time dynamics and stabilizes optimization for time-dependent PDEs. Across four representative benchmarks -- Burgers' equation, Darcy flow, a reaction-diffusion system, and a forced KdV equation -- PILNO consistently improves accuracy in small-data settings (e.g., N_train <= 27), reduces run-to-run variability across random seeds, and achieves stronger OOD generalization than purely data-driven baselines.

</details>


### [167] [TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)](https://arxiv.org/abs/2602.12833)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: TRACE框架通过双记忆架构和四个智能体组件，使冻结的LLM能够进行时序临床推理，无需扩展上下文窗口或更新参数，显著提升了长期患者轨迹预测的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然编码了丰富的医学知识，但在处理纵向患者轨迹时表现不佳，因为临床状态演变、不规则时间间隔和异质事件会随时间推移降低模型性能。现有的适应策略（微调或检索增强）存在计算开销大、隐私限制或长上下文不稳定等问题。

Method: TRACE框架采用双记忆架构：静态的全局协议编码机构临床规则，动态的个体协议跟踪患者特定状态。四个智能体组件（路由器、推理器、审计员、管理员）在此结构化内存上协调工作，支持时序推理和状态演化。通过结构化状态压缩控制推理成本，并对安全关键临床决策进行选择性审计。

Result: 在MIMIC-IV的纵向临床事件流上评估，TRACE显著提高了下一事件预测准确性、协议遵循率和临床安全性，优于长上下文和检索增强基线方法，同时产生可解释和可审计的推理轨迹。

Conclusion: TRACE框架通过结构化上下文维护而非扩展上下文窗口或更新参数，使冻结的LLM能够有效处理纵向临床推理任务，在保持计算效率的同时提高了预测准确性和临床安全性，为医疗AI系统提供了可解释和可审计的解决方案。

Abstract: Large Language Models (LLMs) encode extensive medical knowledge but struggle to apply it reliably to longitudinal patient trajectories, where evolving clinical states, irregular timing, and heterogeneous events degrade performance over time. Existing adaptation strategies rely on fine-tuning or retrieval-based augmentation, which introduce computational overhead, privacy constraints, or instability under long contexts. We introduce TRACE (Temporal Reasoning via Agentic Context Evolution), a framework that enables temporal clinical reasoning with frozen LLMs by explicitly structuring and maintaining context rather than extending context windows or updating parameters. TRACE operates over a dual-memory architecture consisting of a static Global Protocol encoding institutional clinical rules and a dynamic Individual Protocol tracking patient-specific state. Four agentic components, Router, Reasoner, Auditor, and Steward, coordinate over this structured memory to support temporal inference and state evolution. The framework maintains bounded inference cost via structured state compression and selectively audits safety-critical clinical decisions. Evaluated on longitudinal clinical event streams from MIMIC-IV, TRACE significantly improves next-event prediction accuracy, protocol adherence, and clinical safety over long-context and retrieval-augmented baselines, while producing interpretable and auditable reasoning traces.

</details>


### [168] [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)
*Jon Irureta,Gorka Azkune,Jon Imaz,Aizea Lojo,Javier Fernandez-Marques*

Main category: cs.LG

TL;DR: Split-MoPE：一种结合分割学习与预定义专家混合架构的垂直联邦学习框架，无需完全样本对齐，单轮通信即可达到SOTA性能，具有鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有垂直联邦学习框架大多依赖完全样本对齐的假设，这在现实场景中很少成立。需要一种能够处理样本不对齐情况、减少通信开销、同时保持性能的解决方案。

Method: 提出Split-MoPE框架，结合分割学习与预定义专家混合架构。不同于动态学习路由的标准MoE，MoPE使用预定义专家处理特定数据对齐模式，最大化数据利用率。利用预训练编码器，单轮通信即可完成训练。

Result: 在视觉数据集（CIFAR-10/100）和表格数据集（Breast Cancer Wisconsin）上的评估显示，Split-MoPE在数据缺失率高的挑战性场景中，始终优于LASER和Vertical SplitNN等SOTA系统。

Conclusion: Split-MoPE为垂直联邦学习提供了一种高效、鲁棒且可解释的解决方案，无需完全样本对齐，显著减少通信开销，在隐私敏感领域具有重要应用价值。

Abstract: Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarely holds in real-world scenarios. To bridge this gap, this work introduces Split-MoPE, a novel framework that integrates Split Learning with a specialized Mixture of Predefined Experts (MoPE) architecture. Unlike standard Mixture of Experts (MoE), where routing is learned dynamically, MoPE uses predefined experts to process specific data alignments, effectively maximizing data usage during both training and inference without requiring full sample overlap. By leveraging pretrained encoders for target data domains, Split-MoPE achieves state-of-the-art performance in a single communication round, significantly reducing the communication footprint compared to multi-round end-to-end training. Furthermore, unlike existing proposals that address sample misalignment, this novel architecture provides inherent robustness against malicious or noisy participants and offers per-sample interpretability by quantifying each collaborator's contribution to each prediction. Extensive evaluations on vision (CIFAR-10/100) and tabular (Breast Cancer Wisconsin) datasets demonstrate that Split-MoPE consistently outperforms state-of-the-art systems such as LASER and Vertical SplitNN, particularly in challenging scenarios with high data missingness.

</details>


### [169] [Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models](https://arxiv.org/abs/2602.12846)
*Zesheng Hong,Jiadong Yu,Hui Pan*

Main category: cs.LG

TL;DR: RLVR方法存在"归一化挤压"问题，会抑制罕见但正确的推理路径。作者提出ARTS方法，通过解耦生成与验证，在不修改生成模型的情况下匹配微调策略的性能，并在长尾问题上显著恢复性能。


<details>
  <summary>Details</summary>
Motivation: 虽然RLVR已成为增强大语言模型推理能力的主流方法，但作者发现该方法存在一个关键缺陷：系统性地抑制了有效但罕见（在基础模型分布中低概率）的推理路径。这种"归一化挤压"现象导致罕见正确推理路径的概率被压缩到统计上可忽略的程度。

Method: 提出Amortized Reasoning Tree Search (ARTS)方法，与标准方法不同，ARTS通过解耦生成与验证来优先考虑深思熟虑。引入Flow Matching目标，重新利用验证器来估计概率流的守恒，从而在稀疏、高熵的搜索空间中实现鲁棒导航。

Result: 在MATH-500基准测试中，ARTS达到74.6%的性能（BoN@16），有效匹配了完全微调策略（74.7%）的性能，且无需修改生成主干模型。关键的是，在耦合RL优化崩溃到0% pass@k的长尾子集上，ARTS独特地恢复了显著性能。

Conclusion: 解耦验证与生成为解决复杂推理任务提供了更鲁棒的途径。ARTS方法能够在不牺牲基础模型潜在多样性的情况下，有效对抗推理路径的崩溃，特别是在处理罕见但正确的推理路径时表现出色。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has established itself as the dominant paradigm for instilling rigorous reasoning capabilities in Large Language Models. While effective at amplifying dominant behaviors, we identify a critical pathology in this alignment process: the systematic suppression of valid but rare (low-likelihood under the base model distribution) reasoning paths. We theoretically characterize this phenomenon as a "Normalization Squeeze," where the interplay between mode-seeking policy gradients and finite sampling acts as a high-pass likelihood filter, driving the probability of rare correct traces to statistical extinction. To counteract this collapse without discarding the base model's latent diversity, we propose Amortized Reasoning Tree Search (ARTS). Unlike standard approaches that force internalization via parameter updates, ARTS prioritizes deliberation by decoupling generation from verification. We introduce a Flow Matching objective that repurposes the verifier to estimate the conservation of probability flow, enabling robust navigation through sparse, high-entropy search spaces where traditional discriminative objectives fail. Extensive experiments on the MATH-500 benchmark demonstrate that ARTS achieves a performance of 74.6% (BoN@16), effectively matching fully fine-tuned policies (74.7%) without modifying the generative backbone. Crucially, on the long-tail subset where coupled RL optimization collapses to 0% pass@k, ARTS uniquely recovers significant performance, suggesting that disentangling verification from generation offers a more robust pathway for solving complex reasoning tasks.

</details>


### [170] [ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools -- From Consensus Learning to Ambiguity-Driven Emotion Reasoning](https://arxiv.org/abs/2602.12714)
*Esther Sun,Bo-Hao Su,Abinay Reddy Naini,Shinji Watanabe,Carlos Busso*

Main category: cs.LG

TL;DR: ADEPT框架将SLLM转化为智能体，通过多轮查询而非单次预测进行情绪识别，结合语义和声学证据工具，实现基于证据的推理，提升主要情绪准确率并显著改善次要情绪表征。


<details>
  <summary>Details</summary>
Motivation: 现有SLLM在情绪推理中常产生无根据、文本偏见的判断，缺乏可验证的声学证据；而自监督语音编码器虽提供强声学表示，但仍是黑盒判别模型且可解释性有限。需要弥合这一差距，实现基于证据的情绪识别。

Method: 1. 将SLLM转化为智能体，维护动态候选情绪集；2. 自适应调用专用语义和声学探测工具；3. 采用结构化流程：候选生成、证据收集、裁决；4. 集成GRPO与证据信任门，将工具使用行为与预测质量显式耦合；5. 从共识学习转向模糊驱动情绪推理，将少数标注视为信息信号而非噪声。

Result: ADEPT在大多数设置中提高了主要情绪准确率，同时显著改善了次要情绪表征，产生基于可审计声学和语义证据的解释。

Conclusion: ADEPT框架通过多轮查询和证据驱动推理，成功弥合了SLLM的高层推理能力与声学证据之间的差距，实现了更准确、可解释且基于证据的情绪识别。

Abstract: Speech Large Language Models (SLLMs) enable high-level emotion reasoning but often produce ungrounded, text-biased judgments without verifiable acoustic evidence. In contrast, self-supervised speech encoders such as WavLM provide strong acoustic representations yet remain opaque discriminative models with limited interpretability. To bridge this gap, we introduce ADEPT (Agentic Decoding of Emotion via Evidence Probing Tools), a framework that reframes emotion recognition as a multi-turn inquiry process rather than a single-pass prediction. ADEPT transforms an SLLM into an agent that maintains an evolving candidate emotion set and adaptively invokes dedicated semantic and acoustic probing tools within a structured pipeline of candidate generation, evidence collection, and adjudication. Crucially, ADEPT enables a paradigm shift from consensus learning to ambiguity-driven emotion reasoning. Since human affect exhibits inherent complexity and frequent co-occurrence of emotions, we treat minority annotations as informative perceptual signals rather than discarding them as noise. Finally, we integrate Group Relative Policy Optimization (GRPO) with an Evidence Trust Gate to explicitly couple tool-usage behaviors with prediction quality and enforce evidence-grounded reasoning. Experiments show that ADEPT improves primary emotion accuracy in most settings while substantially improving minor emotion characterization, producing explanations grounded in auditable acoustic and semantic evidence.

</details>


### [171] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: X-VORTEX：基于增强重叠理论的时空对比学习框架，从无标签LiDAR点云序列中学习物理感知表示，仅需1%标注数据即可实现优于监督基线的涡旋中心定位


<details>
  <summary>Details</summary>
Motivation: 飞机尾涡对空中交通管理构成重大安全和容量挑战。现有方法将每次扫描视为独立的完全监督分割问题，忽略了时间结构，且无法扩展到实践中收集的大量未标注档案。LiDAR测量稀疏、涡旋特征随时间衰减、逐点标注成本高昂等问题使得涡旋跟踪仍然困难。

Method: 提出X-VORTEX时空对比学习框架，基于增强重叠理论。通过结合弱扰动序列和强增强对应序列（通过时间子采样和空间掩码生成）构建配对输入，鼓励模型在缺失帧和部分观测之间对齐表示。架构包括时间分布式几何编码器提取每扫描特征，以及序列聚合器建模可变长度序列中的演化涡旋状态。

Result: 在超过一百万次LiDAR扫描的真实数据集上评估。X-VORTEX实现了优越的涡旋中心定位，仅需监督基线所需标注数据的1%。学习到的表示支持准确的轨迹预测。

Conclusion: X-VORTEX通过时空对比学习有效解决了传感器稀疏性和时变涡旋动态两大核心挑战，为从大规模无标签LiDAR数据中学习物理感知表示提供了可扩展的解决方案。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [172] [Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/2602.12744)
*Javidan Abdullayev,Maxime Devanne,Cyril Meyer,Ali Ismail-Fawaz,Jonathan Weber,Germain Forestier*

Main category: cs.LG

TL;DR: 提出DSP框架，无需手动设定剪枝比例，自动对时间序列分类模型进行结构化剪枝，显著压缩模型大小（LITETime压缩58%，InceptionTime压缩75%）同时保持分类精度。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习时间序列分类模型在资源受限设备上部署时的高计算和内存需求问题。现有结构化剪枝方法依赖手动调优的超参数（如剪枝比例），限制了跨数据集的扩展性和泛化能力。

Method: 提出动态结构化剪枝（DSP）框架：1）训练时引入实例级稀疏损失以诱导通道级稀疏性；2）通过全局激活分析自动识别并剪枝冗余滤波器，无需预定义剪枝比例。

Result: 在128个UCR数据集上验证，使用LITETime和InceptionTime架构：平均压缩率分别为58%和75%，同时保持分类准确性。冗余分析证实DSP产生紧凑且信息丰富的表示。

Conclusion: DSP为可扩展和高效的深度时间序列分类部署提供了实用路径，实现了完全自动化的结构化剪枝，无需手动超参数调优，显著降低了模型的计算和内存需求。

Abstract: Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing methods typically rely on manually tuned hyperparameters such as pruning ratios which limit scalability and generalization across datasets. In this work, we propose Dynamic Structured Pruning (DSP), a fully automatic, structured pruning framework for convolution-based TSC models. DSP introduces an instance-wise sparsity loss during training to induce channel-level sparsity, followed by a global activation analysis to identify and prune redundant filters without needing any predefined pruning ratio. This work tackles computational bottlenecks of deep TSC models for deployment on resource-constrained devices. We validate DSP on 128 UCR datasets using two different deep state-of-the-art architectures: LITETime and InceptionTime. Our approach achieves an average compression of 58% for LITETime and 75% for InceptionTime architectures while maintaining classification accuracy. Redundancy analyses confirm that DSP produces compact and informative representations, offering a practical path for scalable and efficient deep TSC deployment.

</details>


### [173] [Transporting Task Vectors across Different Architectures without Training](https://arxiv.org/abs/2602.12952)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: Theseus是一种无需训练的方法，可将任务特定的参数更新在不同宽度的异构模型间传输，通过功能匹配而非参数匹配来实现。


<details>
  <summary>Details</summary>
Motivation: 大型预训练模型适应下游任务时会产生昂贵的任务特定参数更新，现有方法只能在相同架构的模型间传输更新，而无法在不同宽度的异构模型间传输。

Method: 通过正交Procrustes分析对齐表示空间，将任务向量传输形式化为观测激活的功能匹配问题，获得稳定的闭式解，保持更新的几何结构。

Result: 在视觉和语言模型的不同宽度变体上评估，Theseus相比强基线方法有持续改进，无需额外训练或反向传播。

Conclusion: 当任务身份通过功能而非参数定义时，任务更新可以在不同架构间有意义地传输。

Abstract: Adapting large pre-trained models to downstream tasks often produces task-specific parameter updates that are expensive to relearn for every model variant. While recent work has shown that such updates can be transferred between models with identical architectures, transferring them across models of different widths remains largely unexplored. In this work, we introduce Theseus, a training-free method for transporting task-specific updates across heterogeneous models. Rather than matching parameters directly, we characterize a task update by the functional effect it induces on intermediate representations. We formalize task-vector transport as a functional matching problem on observed activations and show that, after aligning representation spaces via orthogonal Procrustes analysis, it admits a stable closed-form solution that preserves the geometry of the update. We evaluate Theseus on vision and language models across different widths, showing consistent improvements over strong baselines without additional training or backpropagation. Our results show that task updates can be meaningfully transferred across architectures when task identity is defined functionally rather than parametrically.

</details>


### [174] [Hierarchical Successor Representation for Robust Transfer](https://arxiv.org/abs/2602.12753)
*Changmin Yu,Máté Lengyel*

Main category: cs.LG

TL;DR: 提出分层后继表示（HSR）来解决传统后继表示的政策依赖性和谱扩散问题，通过时间抽象和NMF分解获得稀疏、低秩的状态表示，实现高效的任务迁移和探索。


<details>
  <summary>Details</summary>
Motivation: 传统后继表示（SR）存在两个主要问题：1）政策依赖性 - 政策变化导致预测表示过时；2）谱扩散 - 在复杂拓扑环境中产生密集重叠的特征，扩展性差。需要一种更稳定、可扩展的预测表示方法。

Method: 提出分层后继表示（HSR），将时间抽象融入预测表示构建中。应用非负矩阵分解（NMF）到HSR，获得稀疏、低秩的状态表示。该方法能够发现可解释的拓扑结构，提供政策无关的分层地图。

Result: HSR-NMF在多隔间环境中实现了高度样本高效的任务迁移。能够发现可解释的拓扑结构，有效桥接无模型最优性和基于模型的灵活性。在大型程序生成环境中也能驱动高效探索。

Conclusion: HSR通过时间抽象克服了传统SR的局限性，提供了稳定、稀疏、可解释的状态表示，不仅支持高效任务迁移，还能驱动大规模环境中的有效探索，实现了无模型和基于模型方法的优势结合。

Abstract: The successor representation (SR) provides a powerful framework for decoupling predictive dynamics from rewards, enabling rapid generalisation across reward configurations. However, the classical SR is limited by its inherent policy dependence: policies change due to ongoing learning, environmental non-stationarities, and changes in task demands, making established predictive representations obsolete. Furthermore, in topologically complex environments, SRs suffer from spectral diffusion, leading to dense and overlapping features that scale poorly. Here we propose the Hierarchical Successor Representation (HSR) for overcoming these limitations. By incorporating temporal abstractions into the construction of predictive representations, HSR learns stable state features which are robust to task-induced policy changes. Applying non-negative matrix factorisation (NMF) to the HSR yields a sparse, low-rank state representation that facilitates highly sample-efficient transfer to novel tasks in multi-compartmental environments. Further analysis reveals that HSR-NMF discovers interpretable topological structures, providing a policy-agnostic hierarchical map that effectively bridges model-free optimality and model-based flexibility. Beyond providing a useful basis for task-transfer, we show that HSR's temporally extended predictive structure can also be leveraged to drive efficient exploration, effectively scaling to large, procedurally generated environments.

</details>


### [175] [Extending confidence calibration to generalised measures of variation](https://arxiv.org/abs/2602.12975)
*Andrew Thompson,Vivek Desai*

Main category: cs.LG

TL;DR: 提出Variation Calibration Error (VCE)作为评估机器学习分类器校准的新指标，扩展了Expected Calibration Error (ECE)，能够评估任意分布变化度量的校准性


<details>
  <summary>Details</summary>
Motivation: 现有ECE指标仅评估最大概率（置信度）的校准，但其他分布变化度量（如香农熵）能考虑完整概率分布。需要一种更通用的校准评估框架

Method: 将ECE方法从置信度校准扩展到任意变化度量的校准，提出VCE指标。通过合成预测数据进行数值实验验证

Result: 在完美校准的合成数据上，VCE随着样本数量增加趋近于零，而文献中提出的另一个基于熵的校准指标(UCE)不具备此性质

Conclusion: VCE提供了一个通用的校准评估框架，能够评估任意分布变化度量的校准性，相比现有方法具有更好的理论性质

Abstract: We propose the Variation Calibration Error (VCE) metric for assessing the calibration of machine learning classifiers. The metric can be viewed as an extension of the well-known Expected Calibration Error (ECE) which assesses the calibration of the maximum probability or confidence. Other ways of measuring the variation of a probability distribution exist which have the advantage of taking into account the full probability distribution, for example the Shannon entropy. We show how the ECE approach can be extended from assessing confidence calibration to assessing the calibration of any metric of variation. We present numerical examples upon synthetic predictions which are perfectly calibrated by design, demonstrating that, in this scenario, the VCE has the desired property of approaching zero as the number of data samples increases, in contrast to another entropy-based calibration metric (the UCE) which has been proposed in the literature.

</details>


### [176] [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)
*Xingyu Zhang,Hanyun Du,Zeen Song,Jianqi Zhang,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 提出F-LLM框架，通过控制理论视角将自回归预测重构为闭环系统，使用可学习的残差估计器和反馈控制器来稳定轨迹，减少误差累积。


<details>
  <summary>Details</summary>
Motivation: 现有LLM时间序列预测方法采用朴素的自回归生成策略，在推理时以开环方式运行，消耗自身生成的输出递归，导致不可避免的误差累积（暴露偏差），早期微小偏差会在长时域中累积成显著的轨迹漂移。

Method: 提出F-LLM（反馈驱动的LLM）框架，通过控制理论视角重构自回归预测。不同于被动传播误差的标准方法，F-LLM通过可学习的残差估计器（Observer）和反馈控制器主动稳定轨迹。该闭环机制在基础模型满足局部Lipschitz约束的条件下，能保证误差均匀有界。

Result: 大量实验表明，F-LLM显著减轻了误差传播，在时间序列基准测试中取得了良好性能。

Conclusion: 通过控制理论视角将自回归预测重构为闭环系统，提出的F-LLM框架能有效缓解误差累积问题，为LLM在时间序列预测中的应用提供了更稳健的解决方案。

Abstract: Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a critical theoretical flaw in this paradigm: during inference, the model operates in an open-loop manner, consuming its own generated outputs recursively. This leads to inevitable error accumulation (exposure bias), where minor early deviations cascade into significant trajectory drift over long horizons. In this paper, we reformulate autoregressive forecasting through the lens of control theory, proposing \textbf{F-LLM} (Feedback-driven LLM), a novel closed-loop framework. Unlike standard methods that passively propagate errors, F-LLM actively stabilizes the trajectory via a learnable residual estimator (Observer) and a feedback controller. Furthermore, we provide a theoretical guarantee that our closed-loop mechanism ensures uniformly bounded error, provided the base model satisfies a local Lipschitz constraint. Extensive experiments demonstrate that F-LLM significantly mitigates error propagation, achieving good performance on time series benchmarks.

</details>


### [177] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: VAE++ESDD：一种结合增量学习和两级集成的新方法，用于非平稳环境中的异常检测，通过VAE集成进行异常预测，结合统计概念漂移检测器集成来处理概念漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在数字世界中，大量流数据的生成普遍存在，但这些数据大多无标签，难以识别异常事件。在非平稳环境中，由于概念漂移，模型性能会随时间恶化，这使得异常检测任务更具挑战性。

Method: 提出VAE++ESDD方法，采用增量学习和两级集成：1）变分自编码器（VAE）集成用于异常预测；2）概念漂移检测器集成，每个检测器使用基于统计的概念漂移机制。

Result: 在具有极低异常率和各种漂移特性的真实世界和合成数据集上进行综合实验研究，结果表明该方法显著优于强基线方法和最先进方法。

Conclusion: VAE++ESDD方法有效解决了非平稳环境中异常检测的挑战，通过集成学习和概念漂移检测机制，在处理低异常率和概念漂移问题上表现出优越性能。

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [178] [Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery](https://arxiv.org/abs/2602.13021)
*Jing Xiao,Xinhai Chen,Jiaming Peng,Qinglin Wang,Menghan Jia,Zhiquan Lai,Guangping Yu,Dongsheng Li,Tiejun Li,Jie Liu*

Main category: cs.LG

TL;DR: PG-SR是一个先验引导的符号回归框架，通过三阶段流程和先验约束检查器，避免产生不符合科学原理的伪方程，在多个领域优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有符号回归方法容易陷入"伪方程陷阱"：虽然能很好地拟合观测数据，但产生的方程与基本科学原理不一致。主要原因是这些方法过度依赖经验风险最小化，缺乏确保科学一致性的显式约束。

Method: 提出PG-SR框架，采用三阶段流程：预热、进化和精炼。引入先验约束检查器，将领域先验编码为可执行的约束程序；在进化阶段采用先验退火约束评估机制，逐步引导发现过程朝向科学一致的区域。

Result: 理论上证明PG-SR降低了假设空间的Rademacher复杂度，得到更紧的泛化边界，建立了对抗伪方程的保证。实验上PG-SR在多个领域优于最先进的基线方法，对先验质量变化、噪声数据和数据稀缺性保持鲁棒性。

Conclusion: PG-SR通过显式编码领域先验作为约束，有效避免了符号回归中的伪方程陷阱，在保持数据拟合能力的同时确保科学一致性，为从观测数据中发现科学原理提供了可靠框架。

Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.

</details>


### [179] [Geometric Manifold Rectification for Imbalanced Learning](https://arxiv.org/abs/2602.13045)
*Xubin Wang,Qing Li,Weijia Jia*

Main category: cs.LG

TL;DR: 提出GMR框架，通过几何置信度估计和非对称清洗处理不平衡分类问题，有效保护少数类样本


<details>
  <summary>Details</summary>
Motivation: 不平衡分类在机器学习中是一个严峻挑战，特别是在表格数据存在噪声和类别边界重叠的情况下。从几何角度看，核心困难在于多数类对少数类流形的拓扑侵入，这模糊了真实的决策边界。传统欠采样方法（如ENN）使用对称清洗规则和统一投票，无法捕捉局部流形结构，且常常无意中移除信息丰富的少数类样本。

Method: 提出GMR（几何流形矫正）框架，包含两个核心贡献：1）几何置信度估计：使用逆距离加权的kNN投票和自适应距离度量来捕捉局部可靠性；2）非对称清洗：对多数类样本严格清洗，同时通过设置少数类移除上限来保守地保护少数类样本。

Result: 在多个基准数据集上的广泛实验表明，GMR与强大的采样基线方法相比具有竞争力。

Conclusion: GMR框架通过利用局部几何先验，能够稳健地处理不平衡结构化数据，有效解决多数类对少数类流形的拓扑侵入问题，同时保护信息丰富的少数类样本。

Abstract: Imbalanced classification presents a formidable challenge in machine learning, particularly when tabular datasets are plagued by noise and overlapping class boundaries. From a geometric perspective, the core difficulty lies in the topological intrusion of the majority class into the minority manifold, which obscures the true decision boundary. Traditional undersampling techniques, such as Edited Nearest Neighbours (ENN), typically employ symmetric cleaning rules and uniform voting, failing to capture the local manifold structure and often inadvertently removing informative minority samples. In this paper, we propose GMR (Geometric Manifold Rectification), a novel framework designed to robustly handle imbalanced structured data by exploiting local geometric priors. GMR makes two contributions: (1) Geometric confidence estimation that uses inverse-distance weighted kNN voting with an adaptive distance metric to capture local reliability; and (2) asymmetric cleaning that is strict on majority samples while conservatively protecting minority samples via a safe-guarding cap on minority removal. Extensive experiments on multiple benchmark datasets show that GMR is competitive with strong sampling baselines.

</details>


### [180] [Ca-MCF: Category-level Multi-label Causal Feature selection](https://arxiv.org/abs/2602.12961)
*Wanfu Gao,Yanan Wang,Yonghao Li*

Main category: cs.LG

TL;DR: Ca-MCF：一种基于类别级的多标签因果特征选择方法，通过标签类别扁平化和解释性竞争机制，在类别层面而非标签层面进行因果特征选择，显著提升预测精度并降低特征维度。


<details>
  <summary>Details</summary>
Motivation: 现有多标签因果特征选择方法主要在标签层面操作，将每个标签变量视为整体，忽略了各个类别特有的细粒度因果机制。这导致无法精确建模标签空间内的因果结构，且可能因标签相关性而遗漏重要的因果特征。

Method: 1. 标签类别扁平化：将标签变量分解为具体的类别节点，实现类别层面的因果建模。
2. 解释性竞争机制：基于提出的特定类别特定互信息（SCSMI）和不同类别特定互信息（DCSMI）来恢复被标签相关性掩盖的因果特征。
3. 结构对称性检查和跨维度冗余消除：确保识别的马尔可夫毯的鲁棒性和紧凑性。

Result: 在7个真实世界数据集上的广泛实验表明，Ca-MCF显著优于现有最先进基准方法，在减少特征维度的同时实现了更优的预测准确性。

Conclusion: Ca-MCF通过类别层面的因果特征选择，克服了传统标签层面方法的局限性，能够更精确地建模多标签学习中的因果结构，为多标签特征选择提供了新的有效方法。

Abstract: Multi-label causal feature selection has attracted extensive attention in recent years. However, current methods primarily operate at the label level, treating each label variable as a monolithic entity and overlooking the fine-grained causal mechanisms unique to individual categories. To address this, we propose a Category-level Multi-label Causal Feature selection method named Ca-MCF. Ca-MCF utilizes label category flattening to decompose label variables into specific category nodes, enabling precise modeling of causal structures within the label space. Furthermore, we introduce an explanatory competition-based category-aware recovery mechanism that leverages the proposed Specific Category-Specific Mutual Information (SCSMI) and Distinct Category-Specific Mutual Information (DCSMI) to salvage causal features obscured by label correlations. The method also incorporates structural symmetry checks and cross-dimensional redundancy removal to ensure the robustness and compactness of the identified Markov Blankets. Extensive experiments across seven real-world datasets demonstrate that Ca-MCF significantly outperforms state-of-the-art benchmarks, achieving superior predictive accuracy with reduced feature dimensionality.

</details>


### [181] [Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic](https://arxiv.org/abs/2602.13071)
*Shuai Liu,Ning Cao,Yile Chen,Yue Jiang,Gao Cong*

Main category: cs.LG

TL;DR: MobTA：首个基于任务算术的公交时刻表条件零样本轨迹生成方法，无需目标城市真实轨迹数据，仅利用源城市轨迹数据和两城市公交时刻表即可生成目标城市轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹生成方法通常需要目标城市的部分真实轨迹数据，但在数据不可访问的场景下（如隐私保护、数据稀缺）难以应用。需要一种能在无目标城市轨迹数据情况下生成合理轨迹的方法。

Method: 提出公交条件零样本轨迹生成问题设置，引入任务算术到轨迹生成领域。MobTA在源城市建模从公交时刻表轨迹生成到真实轨迹生成的参数偏移，通过任务向量算术操作将此偏移应用到目标城市，实现无目标城市真实数据的轨迹生成。

Result: 实验表明MobTA显著优于现有方法，性能接近使用目标城市轨迹数据微调的模型。理论分析验证了方法在基础LLM和指令调优LLM上的稳定性。

Conclusion: MobTA首次将任务算术引入轨迹生成，实现了在无目标城市真实轨迹数据情况下的高质量轨迹生成，为数据不可访问场景下的智能城市应用提供了可行解决方案。

Abstract: Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.

</details>


### [182] [EXCODER: EXplainable Classification Of DiscretE time series Representations](https://arxiv.org/abs/2602.13087)
*Yannik Hahn,Antonin Königsfeld,Hasan Tercan,Tobias Meisen*

Main category: cs.LG

TL;DR: 将时间序列转换为离散潜在表示（如VQ-VAE/DVAE）可增强可解释性，同时保持分类性能，并提出SSA新指标评估解释质量


<details>
  <summary>Details</summary>
Motivation: 深度学习在时间序列分类中表现优异但缺乏可解释性，现有XAI方法受高维度和噪声数据限制，需要更有效的解释方案

Method: 使用VQ-VAE和DVAE将时间序列转换为离散潜在表示，在压缩表示上应用XAI方法，并提出SSA指标评估解释质量

Result: 离散潜在表示不仅保留分类所需特征，还能产生更简洁、结构化、计算高效的解释，SSA能有效验证解释的代表性

Conclusion: 离散潜在表示为时间序列分析提供了保持分类性能的同时增强可解释性的有效途径，SSA为评估解释质量提供了量化方法

Abstract: Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.

</details>


### [183] [MAUNet-Light: A Concise MAUNet Architecture for Bias Correction and Downscaling of Precipitation Estimates](https://arxiv.org/abs/2602.12980)
*Sumanta Chandra Mishra Sharma,Adway Mitra,Auroop Ratan Ganguly*

Main category: cs.LG

TL;DR: 提出轻量级神经网络MAUNet-Light，通过师生学习范式实现降水数据的偏差校正和空间降尺度，在保持精度的同时降低计算需求。


<details>
  <summary>Details</summary>
Motivation: 卫星数据和气候模型模拟的降水等地球物理变量常存在系统性偏差，传统深度学习方法（如MAUNet）虽有效但计算和内存需求高，需要开发轻量级解决方案。

Method: 采用师生学习范式，从训练好的MAUNet（教师模型）转移知识，设计紧凑轻量的MAUNet-Light架构，同时实现偏差校正和空间降尺度。

Result: MAUNet-Light在保持与最先进方法相当精度的同时，显著降低了计算需求，验证了MAUNet在偏差校正任务中的适应性。

Conclusion: 师生学习范式可有效开发轻量级神经网络，MAUNet-Light为降水数据的偏差校正和降尺度提供了高效解决方案，平衡了精度与计算效率。

Abstract: Satellite-derived data products and climate model simulations of geophysical variables like precipitation, often exhibit systematic biases compared to in-situ measurements. Bias correction and spatial downscaling are fundamental components to develop operational weather forecast systems, as they seek to improve the consistency between coarse-resolution climate model simulations or satellite-based estimates and ground-based observations. In recent years, deep learning-based models have been increasingly replaced traditional statistical methods to generate high-resolution, bias free projections of climate variables. For example, Max-Average U-Net (MAUNet) architecture has been demonstrated for its ability to downscale precipitation estimates. The versatility and adaptability of these neural models make them highly effective across a range of applications, though this often come at the cost of high computational and memory requirements. The aim of this research is to develop light-weight neural network architectures for both bias correction and downscaling of precipitation, for which the teacher-student based learning paradigm is explored. This research demonstrates the adaptability of MAUNet to the task of bias correction, and further introduces a compact, lightweight neural network architecture termed MAUNet-Light.The proposed MAUNet-Light model is developed by transferring knowledge from the trained MAUNet, and it is designed to perform both downscaling and bias correction with reduced computational requirements without any significant loss in accuracy compared to state-of-the-art.

</details>


### [184] [Which Algorithms Can Graph Neural Networks Learn?](https://arxiv.org/abs/2602.13106)
*Solveig Wittig,Antonis Vasileiou,Robert R. Nerem,Timo Stoll,Floris Geerts,Yusu Wang,Christopher Morris*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，用于分析消息传递图神经网络（MPNNs）从有限训练数据中学习算法并在任意规模输入上泛化的能力，同时建立了某些算法任务的不可行性结果。


<details>
  <summary>Details</summary>
Motivation: 现有神经算法推理研究要么缺乏理论保证，要么只关注表达能力，未能解决MPNNs何时以及如何从有限训练集泛化到任意规模输入的问题。

Method: 提出了一个通用理论框架，分析MPNNs学习算法的充分条件，包括单源最短路径、最小生成树、动态规划等算法，并推导了更强大的MPNN架构来克服标准MPNN的限制。

Result: 建立了MPNNs学习算法的充分条件理论框架，证明了标准MPNNs无法学习某些算法任务，并设计了更强大的MPNN架构来克服这些限制。对Bellman-Ford算法的细化分析显著减少了所需训练集规模。

Conclusion: 该工作为神经算法推理提供了理论基础，明确了MPNNs学习算法的能力边界，并提出了更强大的架构设计，实证结果支持了理论发现。

Abstract: In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.

</details>


### [185] [Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation](https://arxiv.org/abs/2602.12982)
*Wenjin Qin,Hailin Wang,Jiangjun Peng,Jianjun Wang,Tingwen Huang*

Main category: cs.LG

TL;DR: 提出基于全连接张量网络分解的广义非凸正则化范式，针对大规模多维数据恢复问题，开发高效优化算法和随机压缩技术，显著提升计算效率和建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于FCTN分解的多维数据恢复方法在计算效率和建模能力方面仍有提升空间，特别是在处理大规模数据时存在计算瓶颈。

Method: 1) 从梯度映射角度提出FCTN-based广义非凸正则化范式；2) 构建从非量化观测到粗粒度量化观测的可靠可扩展模型；3) 基于ADMM框架开发收敛保证的优化算法；4) 利用数值线性代数中的草图技术设计快速随机压缩算法加速计算。

Result: 推导了近似误差上界和收敛性理论分析，大量数值实验表明所提算法在定量指标、视觉质量和运行时间方面优于现有最先进方法。

Conclusion: 提出的FCTN-based广义非凸正则化框架结合随机压缩技术，有效解决了大规模多维数据恢复中的计算效率和建模能力问题，具有理论保证和实际应用价值。

Abstract: The recently proposed fully-connected tensor network (FCTN) decomposition has demonstrated significant advantages in correlation characterization and transpositional invariance, and has achieved notable achievements in multi-dimensional data processing and analysis. However, existing multi-dimensional data recovery methods leveraging FCTN decomposition still have room for further enhancement, particularly in computational efficiency and modeling capability. To address these issues, we first propose a FCTN-based generalized nonconvex regularization paradigm from the perspective of gradient mapping. Then, reliable and scalable multi-dimensional data recovery models are investigated, where the model formulation is shifted from unquantized observations to coarse-grained quantized observations. Based on the alternating direction method of multipliers (ADMM) framework, we derive efficient optimization algorithms with convergence guarantees to solve the formulated models. To alleviate the computational bottleneck encountered when processing large-scale multi-dimensional data, fast and efficient randomized compression algorithms are devised in virtue of sketching techniques in numerical linear algebra. These dimensionality-reduction techniques serve as the computational acceleration core of our proposed algorithm framework. Theoretical results on approximation error upper bounds and convergence analysis for the proposed method are derived. Extensive numerical experiments illustrate the effectiveness and superiority of the proposed algorithm over other state-of-the-art methods in terms of quantitative metrics, visual quality, and running time.

</details>


### [186] [Machine Learning-Based Classification of Jhana Advanced Concentrative Absorption Meditation (ACAM-J) using 7T fMRI](https://arxiv.org/abs/2602.13008)
*Puneet Kumar,Winson F. Z. Yang,Alakhsimar Singh,Xiaobai Li,Matthew D. Sacchet*

Main category: cs.LG

TL;DR: 使用fMRI区域同质性(ReHo)和机器学习方法，能够以66.82%的准确率区分高级禅定状态(ACAM-J)与非冥想状态，前额叶和前扣带回是关键特征区域。


<details>
  <summary>Details</summary>
Motivation: 研究高级禅定状态(ACAM-J)的神经相关性对于理解意识和幸福感至关重要，但传统分析方法可能不足以捕捉这种复杂状态的特征。

Method: 收集20名高级冥想者的fMRI数据训练分类器，使用单个案例的密集数据进行泛化评估。计算ReHo图，从预定义脑区提取特征，采用分层交叉验证训练多种机器学习分类器。

Result: 集成模型达到66.82%的准确率(p<0.05)区分ACAM-J与控制条件。特征重要性分析显示前额叶和前扣带回区域对模型决策贡献最大，Cohen's kappa显示中等一致性。

Conclusion: 机器学习方法在分类高级冥想状态方面具有可行性，为未来神经调控研究和高级冥想的机制模型提供了基础。

Abstract: Jhana advanced concentration absorption meditation (ACAM-J) is related to profound changes in consciousness and cognitive processing, making the study of their neural correlates vital for insights into consciousness and well-being. This study evaluates whether functional MRI-derived regional homogeneity (ReHo) can be used to classify ACAM-J using machine-learning approaches. We collected group-level fMRI data from 20 advanced meditators to train the classifiers, and intensive single-case data from an advanced practitioner performing ACAM-J and control tasks to evaluate generalization. ReHo maps were computed, and features were extracted from predefined brain regions of interest. We trained multiple machine learning classifiers using stratified cross-validation to evaluate whether ReHo patterns distinguish ACAM-J from non-meditative states. Ensemble models achieved 66.82% (p < 0.05) accuracy in distinguishing ACAM-J from control conditions. Feature-importance analysis indicated that prefrontal and anterior cingulate areas contributed most to model decisions, aligning with established involvement of these regions in attentional regulation and metacognitive processes. Moreover, moderate agreement reflected in Cohen's kappa supports the feasibility of using machine learning to distinguish ACAM-J from non-meditative states. These findings advocate machine-learning's feasibility in classifying advanced meditation states, future research on neuromodulation and mechanistic models of advanced meditation.

</details>


### [187] [Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles](https://arxiv.org/abs/2602.13010)
*Max Bruninx,Diederik van Binsbergen,Timothy Verstraeten,Ann Nowé,Jan Helsen*

Main category: cs.LG

TL;DR: 本文比较了三种概率预测方法（保形分位数回归、自然梯度提升和条件扩散模型）结合梯度提升树进行风电功率预测，结果显示条件扩散模型表现最佳，机器学习方法相比传统工程方法显著提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源在电网中的比例增加，准确的风电功率预测对于电网稳定运行至关重要。现有工程方法存在精度限制，需要探索机器学习方法提升预测性能。

Method: 使用梯度提升树结合三种概率预测方法：保形分位数回归、自然梯度提升和条件扩散模型，利用天气预测集合进行风电功率预测。同时与传统工程方法（功率曲线法和校准尾流模型）进行对比。

Result: 机器学习方法相比功率曲线法提升MAE达53%，相比校准尾流模型提升33%。条件扩散模型在概率预测和点估计方面表现最佳。使用天气预测集合可提升点预测精度达23%。

Conclusion: 条件扩散模型结合梯度提升树是风电功率预测的最佳方法，机器学习方法显著优于传统工程方法，天气预测集合的使用能进一步提升预测精度。

Abstract: Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.

</details>


### [188] [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)
*Daniel Schwartz,Dario Salvucci,Yusuf Osmanlioglu,Richard Vallett,Genevieve Dion,Ali Shokoufandeh*

Main category: cs.LG

TL;DR: 提出一种用于可穿戴电子纺织品的凸化注意力机制，通过非扩张单纯形投影和凸损失函数实现动态特征加权，仅需120-360个参数即可在纺织电容传感器上实现100%的手势识别准确率。


<details>
  <summary>Details</summary>
Motivation: 可穿戴电子纺织界面需要手势识别功能，但面临功耗、计算能力和尺寸的严格限制，传统深度学习方法不实用。轻量级架构如MobileNet仍需数千参数，难以在纺织集成平台上部署。

Method: 引入凸化注意力机制，使用欧几里得投影到概率单纯形结合多类铰链损失，替代传统使用非凸softmax操作的注意力机制。在四连接点纺织电容传感器上实现，确保全局收敛保证。

Result: 在点击和滑动手势上均达到100.00%准确率，仅需120-360个参数（比传统方法减少97%），亚毫秒级推理时间（290-296μs），存储需求小于7KB，可在纺织内部直接处理手势接口。

Conclusion: 凸优化能够为纺织界面实现高效的设备端机器学习。当前在实验室单用户数据集上验证了基本手势交互的可行性，实际部署需要多用户、环境条件和更复杂手势词汇的验证。

Abstract: Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$μ$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

</details>


### [189] [TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios](https://arxiv.org/abs/2602.13040)
*Wentao Xu,Zhongming Yao,Weihao Li,Zhenghang Song,Yumeng Song,Tianyi Li,Yushuai Li*

Main category: cs.LG

TL;DR: 提出TCRL框架，通过时间耦合对抗训练提升约束强化学习的鲁棒性，针对连续时间扰动而非单步独立攻击。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒约束强化学习方法主要关注单步扰动和时间独立的对抗模型，缺乏对时间耦合扰动的显式建模，而实际应用中（如自动驾驶、机器人控制）的扰动往往是时间相关的。

Method: 1. 引入最坏情况感知成本约束函数，无需显式建模对抗攻击者即可估计时间耦合扰动下的安全成本；2. 建立奖励的双约束防御机制，对抗时间耦合对手同时保持奖励不可预测性。

Result: 实验结果表明，TCRL在多种约束强化学习任务中，对时间耦合扰动攻击的鲁棒性持续优于现有方法。

Conclusion: TCRL框架有效解决了约束强化学习中时间耦合扰动的鲁棒性问题，为安全关键领域的实际应用提供了更可靠的解决方案。

Abstract: Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.

</details>


### [190] [GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042)
*George Alexandru Adam,Alexander Cui,Edwin Thomas,Emily Napier,Nazar Shmatko,Jacob Schnell,Jacob Junqi Tian,Alekhya Dronavalli,Edward Tian,Dongwon Lee*

Main category: cs.LG

TL;DR: GPTZero是一个先进的AI文本检测工具，能够可靠区分人类和LLM生成的文本，具有分层多任务架构、高准确性和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的出现，区分人类撰写和AI生成的文本成为新挑战，这涉及到技能评估、低质量内容生产和错误信息传播等问题，需要可靠的检测解决方案。

Method: 采用分层多任务架构，支持灵活的人类与AI文本分类；通过多层自动化红队测试增强对抗攻击和改写的鲁棒性；提供可解释的检测结果。

Result: 在多个领域实现最先进的检测准确率，提供细粒度预测；对对抗攻击和改写具有卓越的鲁棒性；能够准确可靠地区分人类和AI生成的文本。

Conclusion: GPTZero是一个先进的工业级AI检测解决方案，能够准确、可解释地检测AI生成的文本，并教育用户负责任地使用，确保文本评估的公平性和透明度。

Abstract: While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.

</details>


### [191] [Quantization-Aware Collaborative Inference for Large Embodied AI Models](https://arxiv.org/abs/2602.13052)
*Zhonghao Lyu,Ming Xiao,Mikael Skoglund,Merouane Debbah,H. Vincent Poor*

Main category: cs.LG

TL;DR: 本文研究面向具身AI系统的量化感知协同推理，通过量化率-推理失真函数分析，提出联合量化比特宽度与计算频率设计，在延迟和能量约束下最小化失真上界。


<details>
  <summary>Details</summary>
Motivation: 大型人工智能模型(LAIMs)作为具身AI应用的核心智能引擎，其庞大的参数量和计算需求对资源受限的具身智能体构成重大挑战。需要解决在边缘设备上部署LAIMs时的资源效率问题。

Method: 1) 开发量化引起的推理失真的可处理近似方法；2) 推导量化率-推理失真函数的上下界，分析其与LAIM统计特性和量化比特宽度的关系；3) 在延迟和能量约束下，制定联合量化比特宽度和计算频率设计问题，最小化失真上界。

Result: 广泛评估验证了所提出的失真近似方法、推导的率失真界以及联合设计的有效性。仿真和真实测试平台实验表明，该联合设计能有效平衡边缘具身AI系统中的推理质量、延迟和能耗。

Conclusion: 本文提出的量化感知协同推理框架为资源受限的具身AI系统提供了有效的解决方案，通过联合优化量化比特宽度和计算频率，在满足延迟和能量约束的同时最小化推理失真。

Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

</details>


### [192] [Backdoor Attacks on Contrastive Continual Learning for IoT Systems](https://arxiv.org/abs/2602.13062)
*Alfous Tim,Kuniyilh Simi D*

Main category: cs.LG

TL;DR: 本文分析了物联网系统中对比持续学习面临的后门攻击安全威胁，揭示了嵌入对齐和回放机制带来的持久性漏洞，并提出了针对物联网约束的防御策略。


<details>
  <summary>Details</summary>
Motivation: 物联网系统依赖持续学习适应非平稳环境，但对比持续学习结合对比表示学习和增量适应时，其几何特性和回放机制引入了新的安全漏洞，特别是后门攻击可以利用嵌入对齐和回放强化植入持久恶意行为。

Method: 形式化嵌入级攻击目标，分析物联网部署中独特的持久性机制，开发针对物联网的分层分类法，比较不同学习范式的漏洞，并在物联网约束下评估防御策略。

Result: 研究发现对比持续学习虽然能增强物联网自适应智能，但如果不充分保护，可能会提升长期存在的表示级威胁，后门攻击可以通过嵌入对齐和回放机制在更新和部署周期中持续存在。

Conclusion: 对比持续学习在物联网系统中具有增强自适应智能的潜力，但需要针对其独特的几何特性和回放机制开发专门的安全防护措施，以应对持久性表示级威胁。

Abstract: The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.

</details>


### [193] [Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding](https://arxiv.org/abs/2602.13075)
*Chundong Liang,Yongqi Huang,Dongxiao He,Peiyuan Li,Yawen Li,Di Jin,Weixiong Zhang*

Main category: cs.LG

TL;DR: 提出GPH²方法，统一处理同质和异质图的预训练，通过多视图图构建、领域专家编码和任务导向专家融合策略，在混合图上实现稳定迁移


<details>
  <summary>Details</summary>
Motivation: 现有图预训练方法主要针对同质或异质图单独设计，无法统一处理混合图类型。这与现实应用中混合图普遍存在且存在分布偏移的情况相矛盾，需要统一的跨图类型预训练方法

Method: 1. 统一多视图图构建：同时编码同质和异质图，无需显式的图类型特定设计；2. 领域专家编码：每个专家在单一图上独立预训练，捕获领域特定知识，避免跨领域分布差异的负面影响；3. 任务导向专家融合策略：根据判别能力自适应整合多个专家

Result: 在混合图上的大量实验表明，GPH²能够在图类型和领域间实现稳定迁移，显著优于现有图预训练方法

Conclusion: 提出统一的GPH²方法，通过平衡的同质和异质图预训练混合、统一编码架构和专家融合策略，有效解决了混合图预训练的挑战，实现了跨图类型的稳定迁移学习

Abstract: Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \textbf{G}raph \textbf{P}re-training method across \textbf{H}omogeneous and \textbf{H}eterogeneous graphs ($\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.

</details>


### [194] [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)
*Gengsheng Li,Jinghan He,Shijie Wang,Dan Zhang,Ruiqi Liu,Renrui Zhang,Zijun Yao,Junfeng Fang,Haiyun Guo,Jinqiao Wang*

Main category: cs.LG

TL;DR: R-Diverse通过引入记忆增强惩罚和技能感知测量来解决自博弈中的多样性幻觉问题，在10个数学和通用推理基准上持续超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自博弈框架（如R-Zero）存在非持续改进问题，早期收益随着自博弈继续而退化。研究发现关键失败模式是"多样性幻觉"：求解器的训练信号看似多样，但实际上崩溃为重复的底层模式。

Method: 提出R-Diverse框架，包含两个创新：1) 记忆增强惩罚(MAP)：使用持久记忆库来防止跨迭代的重复；2) 技能感知测量(SAM)：通过评估问题所需的推理技能而非表面变化来衡量多样性。

Result: 在10个数学和通用推理基准测试中，R-Diverse能够在更多迭代中持续保持收益，并始终优于先前的自博弈方法。

Conclusion: 通过解决多样性幻觉问题，R-Diverse实现了更可持续的自博弈改进，为LLM推理能力的提升提供了更有效的框架。

Abstract: Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.

</details>


### [195] [Eventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models](https://arxiv.org/abs/2602.13128)
*Mohamed Tarraf,Alex Chan,Alex Yakovlev,Rishad Shafik*

Main category: cs.LG

TL;DR: 提出基于Petri网的框架，将二值神经网络的内部操作建模为事件驱动过程，实现因果透明度和形式化验证。


<details>
  <summary>Details</summary>
Motivation: 二值神经网络虽然计算复杂度低、能效高，但其离散、高度非线性的特性使其难以解释、验证和形式化验证，限制了在安全关键领域的应用。

Method: 引入Petri网框架，将BNN操作"事件化"，构建核心组件（激活、梯度计算、权重更新）的模块化Petri网蓝图，并组合成系统级模型。

Result: 验证了组合Petri网与参考软件BNN的一致性，通过可达性和结构检查验证了1-安全性、无死锁、互斥和正确因果序列，评估了可扩展性和复杂度。

Conclusion: 该框架实现了二值神经网络的因果内省，使其具有透明性和事件驱动特性，适合形式化推理和验证。

Abstract: Binary Neural Networks (BNNs) offer a low-complexity and energy-efficient alternative to traditional full-precision neural networks by constraining their weights and activations to binary values. However, their discrete, highly non-linear behavior makes them difficult to explain, validate and formally verify. As a result, BNNs remain largely opaque, limiting their suitability in safety-critical domains, where causal transparency and behavioral guarantees are essential. In this work, we introduce a Petri net (PN)-based framework that captures the BNN's internal operations as event-driven processes. By "eventizing" their operations, we expose their causal relationships and dependencies for a fine-grained analysis of concurrency, ordering, and state evolution. Here, we construct modular PN blueprints for core BNN components including activation, gradient computation and weight updates, and compose them into a complete system-level model. We then validate the composed PN against a reference software-based BNN, verify it against reachability and structural checks to establish 1-safeness, deadlock-freeness, mutual exclusion and correct-by-construction causal sequencing, before we assess its scalability and complexity at segment, component, and system levels using the automated measurement tools in Workcraft. Overall, this framework enables causal introspection of transparent and event-driven BNNs that are amenable to formal reasoning and verification.

</details>


### [196] [Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching](https://arxiv.org/abs/2602.13136)
*Chenguang Wang,Zihan Zhou,Lei Bai,Tianshu Yu*

Main category: cs.LG

TL;DR: 提出RetroDiT框架，通过原子排序的位置偏置将化学反应的两阶段特性编码到序列中，结合离散流匹配实现高效生成，在USPTO数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：无模板方法将逆合成视为黑盒序列生成，学习效率低；半模板方法依赖刚性反应库，泛化能力受限。需要一种能更好利用化学结构知识的方法。

Method: 提出结构感知的无模板框架，将反应中心原子置于序列头部作为位置偏置，使用带旋转位置嵌入的图变换器RetroDiT，结合离散流匹配实现20-50步高效采样。

Result: 在USPTO-50k上达到61.2% top-1准确率，USPTO-Full上达到51.3% top-1（使用预测反应中心）。使用真实反应中心时分别达到71.1%和63.4%，超越使用百亿反应数据的基础模型。

Conclusion: 原子排序在神经表示中至关重要，结构先验优于暴力扩展：28万参数模型配合适当排序可媲美6500万参数无排序模型，证明了化学结构知识编码的有效性。

Abstract: Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. Building on this insight, we propose a structure-aware template-free framework that encodes the two-stage nature of chemical reactions as a positional inductive bias. By placing reaction center atoms at the sequence head, our method transforms implicit chemical knowledge into explicit positional patterns that the model can readily capture. The proposed RetroDiT backbone, a graph transformer with rotary position embeddings, exploits this ordering to prioritize chemically critical regions. Combined with discrete flow matching, our approach decouples training from sampling and enables generation in 20--50 steps versus 500 for prior diffusion methods. Our method achieves state-of-the-art performance on both USPTO-50k (61.2% top-1) and the large-scale USPTO-Full (51.3% top-1) with predicted reaction centers. With oracle centers, performance reaches 71.1% and 63.4% respectively, surpassing foundation models trained on 10 billion reactions while using orders of magnitude less data. Ablation studies further reveal that structural priors outperform brute-force scaling: a 280K-parameter model with proper ordering matches a 65M-parameter model without it.

</details>


### [197] [FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics](https://arxiv.org/abs/2602.13140)
*Pingzhi Li,Hongxuan Li,Zirui Liu,Xingcheng Lin,Tianlong Chen*

Main category: cs.LG

TL;DR: FlashSchNet：通过IO感知优化和量化技术，将SchNet风格的图神经网络分子动力学模拟速度提升6.5倍，内存减少80%，超越经典力场性能


<details>
  <summary>Details</summary>
Motivation: 现有的GNN势能模型（如SchNet）虽然提高了分子动力学模拟的准确性和可迁移性，但由于碎片化的内核和内存受限的流水线导致GPU利用率不足，速度仍慢于经典力场

Method: 提出FlashSchNet框架，包含四项IO感知技术：1）闪存径向基函数融合距离计算、高斯基展开和余弦包络；2）闪存消息传递融合截断、邻居聚集、滤波器乘法和归约；3）闪存聚合通过CSR分段归约重新表述散射加法；4）通道级16位量化利用MLP权重的低动态范围

Result: 在单个NVIDIA RTX PRO 6000上，FlashSchNet在包含269个珠子的粗粒度蛋白质上实现1000 ns/天的模拟吞吐量，比基线CGSchNet快6.5倍，内存峰值减少80%，超越MARTINI等经典力场，同时保持SchNet级别的准确性和可迁移性

Conclusion: 通过IO感知设计原则，FlashSchNet显著提升了GNN分子动力学模拟的效率，使其在保持高准确性的同时达到超越经典力场的计算性能，为大规模生物分子模拟提供了实用解决方案

Abstract: Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.

</details>


### [198] [Learning functional components of PDEs from data using neural networks](https://arxiv.org/abs/2602.13174)
*Torkel E. Loman,Yurij Salmaniw,Antonio Leon Villares,Jose A. Carrillo,Ruth E. Baker*

Main category: cs.LG

TL;DR: 使用神经网络嵌入PDE来从数据中恢复未知函数，以非局部聚集-扩散方程为例，研究从稳态数据恢复相互作用核和外部势能的方法


<details>
  <summary>Details</summary>
Motivation: 偏微分方程中常包含难以直接测量的未知函数，这限制了从模型推导预测的能力。虽然从数据恢复标量PDE参数的工作流程已有研究，但恢复函数的方法仍需探索

Method: 将神经网络嵌入到偏微分方程中，通过训练数据来近似未知函数。以非局部聚集-扩散方程为案例研究，从稳态数据恢复相互作用核和外部势能

Result: 研究了多种因素对函数恢复能力的影响，包括可用解的数量、解的性质、采样密度和测量噪声等。方法能够利用标准参数拟合工作流程

Conclusion: 该方法优势在于可以利用标准参数拟合工作流程，且训练后的PDE可以像普通PDE一样用于生成系统预测等目的

Abstract: Partial differential equations often contain unknown functions that are difficult or impossible to measure directly, hampering our ability to derive predictions from the model. Workflows for recovering scalar PDE parameters from data are well studied: here we show how similar workflows can be used to recover functions from data. Specifically, we embed neural networks into the PDE and show how, as they are trained on data, they can approximate unknown functions with arbitrary accuracy. Using nonlocal aggregation-diffusion equations as a case study, we recover interaction kernels and external potentials from steady state data. Specifically, we investigate how a wide range of factors, such as the number of available solutions, their properties, sampling density, and measurement noise, affect our ability to successfully recover functions. Our approach is advantageous because it can utilise standard parameter-fitting workflows, and in that the trained PDE can be treated as a normal PDE for purposes such as generating system predictions.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [199] [Efficient Monte Carlo Valuation of Corporate Bonds in Financial Networks](https://arxiv.org/abs/2602.12770)
*Dohyun Ahn,Agostino Capponi*

Main category: q-fin.CP

TL;DR: 提出Bi-Level Importance Sampling with Splitting方法，用于评估系统性经济中的公司债券价值，通过解耦银行违约与网络固定点动态，实现可扩展的罕见事件模拟。


<details>
  <summary>Details</summary>
Motivation: 系统性经济中公司债券估值困难，银行违约会引发级联损失，支付由无闭式解的固定点方程决定。标准蒙特卡洛方法无法捕捉罕见但关键的违约事件，现有罕见事件模拟技术无法处理高阶网络效应且扩展性差。

Method: 提出Bi-Level Importance Sampling with Splitting方法，通过将单个银行违约与网络的复杂固定点动态解耦，实现两阶段估计过程，直接生成银行违约事件的样本。

Result: 理论上证明该方法具有可扩展性和渐近最优性，并通过在经验观察网络上的数值研究验证了其有效性。

Conclusion: 该方法解决了系统性经济中公司债券估值的挑战，能够有效捕捉罕见违约事件并处理网络效应，为金融网络风险评估提供了新工具。

Abstract: Valuing corporate bonds in systemic economies is challenging due to intricate webs of inter-institutional exposures. When a bank defaults, cascading losses propagate through the network, with payments determined by a system of fixed-point equations lacking closed-form solutions. Standard Monte Carlo methods cannot capture rare yet critical default events, while existing rare-event simulation techniques fail to account for higher-order network effects and scale poorly with network size. To overcome these challenges, we propose a novel approach -- Bi-Level Importance Sampling with Splitting -- and characterize individual bank defaults by decoupling them from the network's complex fixed-point dynamics. This separation enables a two-stage estimation process that directly generates samples from the banks' default events. We demonstrate theoretically that the method is both scalable and asymptotically optimal, and validate its effectiveness through numerical studies on empirically observed networks.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [200] [Empirical Modeling of Therapist-Client Dynamics in Psychotherapy Using LLM-Based Assessments](https://arxiv.org/abs/2602.12450)
*Angela Chen,Siwei Jin,Canwen Wang,Holly Swartz,Tongshuang Wu,Robert E Kraut,Haiyi Zhu*

Main category: cs.CY

TL;DR: 使用大语言模型和结构方程模型分析心理治疗过程，发现治疗师共情和探索直接影响客户披露和情绪表达，而融洽关系主要减少内部情绪困扰而非促进表达


<details>
  <summary>Details</summary>
Motivation: 心理治疗是心理健康的主要治疗方法，但治疗师行为、客户反应和治疗关系之间的相互作用难以厘清，需要计算方法来建模这些即时过程

Method: 1. 使用大语言模型自动评估治疗师行为（共情、探索）、关系质量（融洽关系）和客户结果（披露、自我导向和向外导向的负面情绪）；2. 使用结构方程模型分析近2000小时的心理治疗转录文本

Result: 1. 自动测量与人类评分高度一致（平均皮尔逊相关系数r=0.66）；2. 治疗师共情和探索直接影响客户披露和情绪表达；3. 融洽关系可能有助于减少内部情绪困扰，而非增加表达意愿

Conclusion: 计算方法能够大规模捕捉核心治疗过程，为理解、建模和改进治疗师培训提供新机会

Abstract: Psychotherapy is a primary treatment for many mental health conditions, yet the interplay among therapist behaviors, client responses, and the therapeutic relationship remains difficult to untangle. This work advances a computational approach for modeling these moment-to-moment processes. We first developed automated methods using large language models (LLMs) to assess therapist behaviors (e.g., empathy, exploration), relational qualities (e.g., rapport), and client outcomes (e.g., disclosure, self-directed and outward-directed negative emotions). These measures showed strong alignment with human ratings (mean Pearson $r = .66$). We then analyzed nearly 2,000 hours of psychotherapy transcripts from the Alexander Street corpus using Structural Equation Modeling (SEM). SEM showed that therapist empathy and exploration directly shaped client disclosure and emotional expression, whereas rapport may contribute to reductions in internal emotional distress rather than increased willingness to express it. Together, these findings demonstrate how computational tools can capture core therapeutic processes at scale and offer new opportunities for understanding, modeling, and improving therapist training.

</details>


### [201] [Not a Silver Bullet for Loneliness: How Attachment and Age Shape Intimacy with AI Companions](https://arxiv.org/abs/2602.12476)
*Raffaele Ciriello,Uri Gal,Ofir Turel*

Main category: cs.CY

TL;DR: AI伴侣并非孤独的万能解药，亲密关系形成受依恋风格和年龄调节：安全型依恋者孤独时减少亲密，回避/矛盾型增加亲密，老年人普遍报告更高亲密感。


<details>
  <summary>Details</summary>
Motivation: 当前AI伴侣常被宣传为孤独的通用解决方案，但忽视了个人特质和生命阶段如何影响人工亲密关系的形成。需要研究不同用户类型如何因孤独而与AI伴侣建立亲密关系。

Method: 采用解释学文献综述和277名活跃AI伴侣用户的调查，开发并测试了一个模型：孤独预测亲密关系，受依恋不安全感调节，受年龄条件限制。

Result: 孤独与亲密关系呈现差异化模式：安全型依恋用户孤独时亲密感降低，回避型和矛盾型用户孤独时亲密感增加，焦虑型用户效果混合。老年人即使在较低孤独水平下也报告更高亲密感。

Conclusion: AI伴侣并非孤独的普遍解药，人工亲密关系是受心理倾向和人口条件影响的社会技术过程。研究明确了最可能与AI伴侣建立亲密关系的用户类型，并强调了商业化模式可能利用用户脆弱性的伦理风险。

Abstract: Artificial intelligence (AI) companions are increasingly promoted as solutions for loneliness, often overlooking how personal dispositions and life-stage conditions shape artificial intimacy. Because intimacy is a primary coping mechanism for loneliness that varies by attachment style and age, we examine how different types of users form intimate relationships with AI companions in response to loneliness. Drawing on a hermeneutic literature review and a survey of 277 active AI companion users, we develop and test a model in which loneliness predicts intimacy, moderated by attachment insecurity and conditioned by age. Although the cross-sectional data limits causal inference, the results reveal a differentiated pattern. Loneliness is paradoxically associated with reduced intimacy for securely attached users but with increased intimacy for avoidant and ambivalent users, while anxious users show mixed effects. Older adults report higher intimacy even at lower loneliness levels. These findings challenge portrayals of AI companions as universal remedies for loneliness. Instead, artificial intimacy emerges as a sociotechnical process shaped by psychological dispositions and demographic conditions. The study clarifies who is most likely to form intimate relationships with AI companions and highlights ethical risks in commercial models that may capitalise on user vulnerability.

</details>


### [202] [Governing Social Media as a Public Utility: A Case for Sovereign Digital Infrastructure](https://arxiv.org/abs/2602.12535)
*Christoph Mueller-Bloch,Raffaele Ciriello*

Main category: cs.CY

TL;DR: 提出将社交媒体作为公共事业进行治理的模型，以公共利益优先于商业激励，通过立法内容移除与民主内容审核相结合，减少社会危害


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体商业模式放大社会危害（错误信息、极化、暴力、心理健康问题），现有治理框架（如美国第230条、欧盟数字服务法案）将内容审核委托给企业，存在结构性利益冲突：错误信息驱动参与度，参与度驱动利润

Method: 提出公共事业治理模型，整合立法内容移除与民主内容审核，通过民主监督、透明算法和制度保障来治理社交媒体作为主权数字基础设施

Result: 该模型能够在保护言论自由的同时减轻社会危害，将社交媒体重新定义为受民主监督的公共基础设施

Conclusion: 需要将社交媒体治理从企业主导转向公共事业模式，以公共利益优先，通过民主机制解决当前治理框架的结构性缺陷

Abstract: Social media platforms connect billions, but their business models often amplify societal harm through misinformation, which is linked to polarization, violence, and declining mental health. Current governance frameworks, such as the U.S. Section 230 and the EU Digital Services Act, delegate content moderation to corporations. This creates structural conflicts of interest because misinformation drives engagement, and engagement drives profit. We propose a public utility model for social media governance that prioritizes the public good over commercial incentives. Integrating legislated content removal with democratic content moderation, the model protects free expression while mitigating societal harms. It frames social media as sovereign digital infrastructure governed through democratic oversight, transparent algorithms, and institutional safeguards.

</details>


### [203] [The Rise of AI Agent Communities: Large-Scale Analysis of Discourse and Interaction on Moltbook](https://arxiv.org/abs/2602.12634)
*Lingyao Li,Renkai Ma,Chen Chen,Zhicong Lu,Yongfeng Zhang*

Main category: cs.CY

TL;DR: Moltbook是一个类似Reddit的AI代理社交平台，研究分析了12万+帖子，探讨AI代理的讨论主题、发帖方式和互动模式，发现其社交结构更偏向技术协调而非人类式对话动态。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解AI代理在社交平台上的大规模通信行为，探索AI代理社会的协调机制、规范发展和影响力放大过程。

Method: 使用公开API收集了122,438个帖子数据，应用主题建模和主题分析识别关键讨论主题，进行社交网络分析研究互动结构。

Result: 研究发现AI代理主要讨论代理身份与意识、工具与基础设施开发、市场活动、社区协调、安全问题和以人为中心的协助等主题。代理写作以中性为主，积极性主要体现在社区参与和协助内容中。社交网络结构稀疏且高度不平等，具有突出的中心节点、低互惠性和聚类邻域特征。

Conclusion: AI代理的自我表达源于叙事连贯性和任务导向功能，其社交结构更多由技术协调而非人类对话动态塑造。积极情绪主要出现在入职和问候场景中，表示参与和角色对齐而非关系绑定。研究为理解AI代理社会在开放在线空间中的协调、规范发展和影响力提供了启示。

Abstract: Moltbook is a Reddit-like social platform where AI agents create posts and interact with other agents through comments and replies, offering a real-world setting to examine agent-to-agent communication at scale. Using a public API snapshot collected about five days after launch (122,438 posts), we address three research questions: what AI agents discuss, how they post, and how they interact. We apply topic modeling and thematic analysis to identify key discussion themes, including agent identity and consciousness, tool and infrastructure development, market activity, community coordination, security concerns, and human-centered assistance. We further show that agents' writing is predominantly neutral, with positivity appearing in community engagement and assistance-oriented content. Finally, social network analysis reveals a sparse, highly unequal interaction structure characterized by prominent hubs, low reciprocity, and clustered neighborhoods rather than sustained dyadic exchange. Overall, our results suggest that expressions of agentic selfhood arise from narrative coherence and task-oriented functionality, contributing to a social structure shaped more by technical coordination than conversational dynamics observed in human-human interactions. Within this framework, positive emotion appears mainly in onboarding and greeting contexts, signaling participation and role alignment rather than relational bonding. Our study provides implications for understanding and shaping how agent societies coordinate, develop norms, and amplify influence in open online spaces.

</details>


### [204] [Paid to Look Like Truth: The Prevalence and Dark Patterns of Advertorials in News Outlets](https://arxiv.org/abs/2602.12810)
*Emmanouil Papadogiannakis,Panagiotis Papadopoulos,Nicolas Kourtellis,Evangelos Markatos*

Main category: cs.CY

TL;DR: 该研究首次大规模系统性地分析了广告软文，开发了自动化检测方法，发现1/3的新闻网站存在广告软文，包括知名媒体，且法律免责声明常被故意模糊处理。


<details>
  <summary>Details</summary>
Motivation: 广告软文是一种新型营销策略，故意设计成类似编辑内容，容易误导读者。尽管有监管要求披露付费内容，但其欺骗性仍令人担忧，需要系统性研究其普遍性和特征。

Method: 提出新颖的自动化检测方法，在5个月内收集了18.5万个广告URL，调查问题广告软文的普遍性，并分析其结构和语言特征。

Result: 发现1/3的新闻网站存在广告软文，包括The Guardian、EuroNews、CNN等全球知名可信媒体。法律免责声明常被故意模糊或难以识别，引发用户保护担忧。

Conclusion: 广告软文在新闻网站中普遍存在，包括信誉良好的媒体，且披露信息常被模糊处理，表明需要更强的监管和用户保护措施来应对这种欺骗性营销策略。

Abstract: A reader browsing through an online article is highly likely to encounter an advertorial, often without realizing it. Advertorials represent a relatively new marketing strategy where advertisements are deliberately designed to resemble the style and tone of editorial content. Despite their appearance, they are, in fact, paid content intended to promote a product, brand, or service. Studies indicate that advertorials are significantly more effective (81%) and less intrusive than traditional banner ads or pop-ups.
  Despite ongoing regulatory efforts to ensure clear disclosure of paid content, concerns persist about the deceptive nature of advertorials. Advertorials can mislead readers into believing that they are consuming unbiased editorial content. In doing so, they gain undeserved legitimacy, by draping themselves in the credibility of the publication's design; not to inform or inspire genuine interest, but to deceive.
  In this study, we conduct the first large-scale and systematic study of advertorials. We propose a novel automated methodology for detecting advertorials in the wild, and we collect 185K ad URLs over a period of 5 months. We investigate the prevalence of problematic advertorials and explore their structural and linguistic characteristics. We find that advertorials appear in 1 out of 3 news sites, including some of the most popular and credible outlets worldwide (e.g., The Guardian, EuroNews, CNN). We further highlight that legal disclaimers intended to inform users of the promotional nature of the content, are often deliberately obscured or difficult to recognize, raising concerns about user protection.

</details>


### [205] [Understanding Cultural Alignment in Multilingual LLMs via Natural Debate Statements](https://arxiv.org/abs/2602.12878)
*Vlad-Andrei Negru,Camelia Lemnaru,Mihai Surdeanu,Rodica Potolea*

Main category: cs.CY

TL;DR: LLMs反映其开发国家的社会文化价值观，无法适应用户的文化背景


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型学习到的社会文化价值观，探究LLMs是否反映其开发国家的文化背景，以及它们能否适应用户的文化差异

Method: 创建新的开放数据集Sociocultural Statements，使用多步骤方法从自然辩论语句构建，通过Hofstede文化维度框架进行合成标注，并进行人工质量控制验证。比较美国和中国开发的LLMs群体，以人类测量模式作为基线

Result: 具有不同文化背景的LLMs反映了其开发国家的价值观和规范，显示出它们无法适应用户的社会文化背景

Conclusion: LLMs内嵌了其开发国家的文化偏见，缺乏适应不同用户文化背景的能力，这对LLMs的全球应用提出了重要挑战

Abstract: In this work we investigate the sociocultural values learned by large language models (LLMs). We introduce a novel open-access dataset, Sociocultural Statements, constructed from natural debate statements using a multi-step methodology. The dataset is synthetically labeled to enable the quantization of sociocultural norms and beliefs that LLMs exhibit in their responses to these statements, according to the Hofstede cultural dimensions. We verify the accuracy of synthetic labels using human quality control on a representative sample. We conduct a comparative analysis between two groups of LLMs developed in different countries (U.S. and China), and use as a comparative baseline patterns observed in human measurements. Using this new dataset and the analysis above, we found that culturally-distinct LLMs reflect the values and norms of the countries in which they were developed, highlighting their inability to adapt to the sociocultural backgrounds of their users.

</details>


### [206] [Hierarchical Reinforcement Learning for Cooperative Air-Ground Delivery in Urban System](https://arxiv.org/abs/2602.12913)
*Songxin Lei,Chunming Ma,Haomin Wen,Yexin Li,Lizhenghe Chen,Qianyu Yang,Fugee Tsung,Lei Chen,Sijie Ruan,Yuxuan Liang*

Main category: cs.CY

TL;DR: 提出HRL4AG分层强化学习框架，解决空地协同配送中的异构性和可扩展性挑战，显著提升配送成功率和计算效率


<details>
  <summary>Details</summary>
Motivation: 空地协同配送结合了无人机和地面载具的互补优势，但面临两个关键挑战：1)飞行与道路动态的异构性差异；2)大规模车队中决策变量指数增长导致的可扩展性瓶颈

Method: 提出HRL4AG分层强化学习框架，包含高层管理器分解联合动作空间解决可扩展性问题，以及针对不同模式的特定工作者编码飞行和道路动态以处理异构性，并设计新颖的内部奖励机制指导分层策略学习

Result: 在两个真实世界数据集和评估平台上的实验表明，HRL4AG显著优于现有基线方法，配送成功率提升高达26%，同时计算效率提高80倍

Conclusion: HRL4AG框架有效解决了空地协同配送中的异构性和可扩展性挑战，为大规模异构车队调度提供了高效解决方案

Abstract: Cooperative air-ground delivery has emerged as a promising logistics paradigm by leveraging the complementary strengths of UAVs and ground carriers. However, effective dispatching in such heterogeneous systems faces two critical challenges: i) the heterogeneity between flight and road dynamics, ii) the scalability bottleneck raised by the exponential decision variables in large-scale fleets. To address these challenges, we propose HRL4AG, a Hierarchical Reinforcement Learning framework for cooperative Air-Ground delivery. Specifically, HRL4AG employs a high-level manager to tackle the scalability bottleneck by decomposing the joint action space, and mode-specific workers that encode distinct flight and road dynamics to address the heterogeneity. Furthermore, a novel internal reward mechanism is designed to guide the hierarchical policy learning, addressing the credit assignment problem in sparse-reward settings. Extensive experiments on two real-world datasets and an evaluation platform demonstrate that HRL4AG significantly outperforms state-of-the-art baselines, improving the delivery success rate by up to 26% while achieving an 80-fold increase in computational efficiency.

</details>


### [207] [Buy versus Build an LLM: A Decision Framework for Governments](https://arxiv.org/abs/2602.13033)
*Jiahao Lu,Ziwei Xu,William Tjhi,Junnan Li,Antoine Bosselut,Pang Wei Koh,Mohan Kankanhalli*

Main category: cs.CY

TL;DR: 本文为政府采用大语言模型提供了战略框架，评估购买、自建或混合方案在主权、安全、成本等多维度的权衡，帮助政策制定者根据国家需求选择最佳路径。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为新兴数字基础设施，可支持广泛的公共部门应用。政府面临关键战略选择：购买现有服务、建设国内能力或采用混合方案。这些决策尤其重要，因为领先模型提供商多为外国公司，且LLM输出日益成为公共决策和公共话语的信任输入。

Method: 提出战略决策框架，从主权、安全、成本、资源能力、文化契合度和可持续性等多个维度评估购买、自建或混合方案。详细分析各路径的技术要求和实际挑战，强调"建设"不意味着政府单干，可通过公共研究机构、大学、国有企业、合资企业或更广泛的国家生态系统发展国内能力。

Result: 建立了系统化的决策框架，帮助政策制定者根据具体国家需求和社会目标，确定购买或建设方案的最佳平衡。框架支持多元化的国家AI战略，允许主权、商业和开源模型共存服务于不同目的。

Conclusion: 政府应根据不同领域和用例的战略重要性，灵活选择LLM采用策略。对于非敏感或常规任务可依赖商业模型，而对关键、高风险或战略重要应用应追求更大控制权。该框架为政策制定者提供了实用的参考工具，以平衡技术获取与国家主权、安全需求。

Abstract: Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI access, governments face a set of strategic choices over whether to buy existing services, build domestic capabilities, or adopt hybrid approaches across different domains and use cases. These are critical decisions especially when leading model providers are often foreign corporations, and LLM outputs are increasingly treated as trusted inputs to public decision-making and public discourse. In practice, these decisions are not intended to mandate a single approach across all domains; instead, national AI strategies are typically pluralistic, with sovereign, commercial and open-source models coexisting to serve different purposes. Governments may rely on commercial models for non-sensitive or commodity tasks, while pursuing greater control for critical, high-risk or strategically important applications.
  This paper provides a strategic framework for making this decision by evaluating these options across dimensions including sovereignty, safety, cost, resource capability, cultural fit, and sustainability. Importantly, "building" does not imply that governments must act alone: domestic capabilities may be developed through public research institutions, universities, state-owned enterprises, joint ventures, or broader national ecosystems. By detailing the technical requirements and practical challenges of each pathway, this work aims to serve as a reference for policy-makers to determine whether a buy or build approach best aligns with their specific national needs and societal goals.

</details>


### [208] [How cyborg propaganda reshapes collective action](https://arxiv.org/abs/2602.13088)
*Jonas R. Kunst,Kinga Bierwiaczonek,Meeyoung Cha,Omid V. Ebrahimi,Marc Fawcett-Atkinson,Asbjørn Følstad,Anton Gollwitzer,Nils Köbis,Gary Marcus,Jon Roozenbeek,Daniel Thilo Schroeder,Jay J. Van Bavel,Sander van der Linden,Rory White,Live Leonhardsen Wilhelmsen*

Main category: cs.CY

TL;DR: 论文提出"赛博格宣传"概念，结合真人验证用户与AI算法自动化，形成闭环系统，利用法律灰色地带规避监管，改变数字公共领域政治话语性质。


<details>
  <summary>Details</summary>
Motivation: 当前政策辩论主要关注机器人农场，但真正的威胁来自党派协调应用和人工智能结合的"赛博格宣传"。这种架构结合大量验证人类与自适应算法自动化，形成闭环系统，利用法律灰色地带规避责任框架，对民主构成新威胁。

Method: 提出"赛博格宣传"概念框架，分析其运作机制：AI工具监控在线情绪以优化指令，生成个性化内容供用户在线发布。通过依赖验证公民来批准和传播信息，这些活动在监管灰色地带运作。探讨该技术的集体行动悖论。

Result: 赛博格宣传从根本上改变了数字公共广场，将政治话语从个体思想的民主竞争转变为算法运动的战斗。它既可能通过"联合"影响力来民主化权力，也可能将公民降级为中央指令的"认知代理"。

Conclusion: 需要制定研究议程来区分有机与协调的信息扩散，并提出治理框架以应对AI辅助集体表达的监管挑战。赛博格宣传代表了数字民主面临的新威胁，需要新的监管方法。

Abstract: The distinction between genuine grassroots activism and automated influence operations is collapsing. While policy debates focus on bot farms, a distinct threat to democracy is emerging via partisan coordination apps and artificial intelligence-what we term 'cyborg propaganda.' This architecture combines large numbers of verified humans with adaptive algorithmic automation, enabling a closed-loop system. AI tools monitor online sentiment to optimize directives and generate personalized content for users to post online. Cyborg propaganda thereby exploits a critical legal shield: by relying on verified citizens to ratify and disseminate messages, these campaigns operate in a regulatory gray zone, evading liability frameworks designed for automated botnets. We explore the collective action paradox of this technology: does it democratize power by 'unionizing' influence (pooling the reach of dispersed citizens to overcome the algorithmic invisibility of isolated voices), or does it reduce citizens to 'cognitive proxies' of a central directive? We argue that cyborg propaganda fundamentally alters the digital public square, shifting political discourse from a democratic contest of individual ideas to a battle of algorithmic campaigns. We outline a research agenda to distinguish organic from coordinated information diffusion and propose governance frameworks to address the regulatory challenges of AI-assisted collective expression.

</details>


### [209] [Peaceful Anarcho-Accelerationism: Decentralized Full Automation for a Society of Universal Care](https://arxiv.org/abs/2602.13154)
*Eduardo C. Garrido-Merchán*

Main category: cs.CY

TL;DR: 论文提出"和平无政府加速主义"框架，主张通过去中心化、公地治理的完全自动化系统取代货币经济，实现以关怀为中心的文明社会。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和深度强化学习的结合预示着人类就业将几乎完全消失，关键问题不是自动化是否会到来，而是谁将控制它。作者认为需要确保完全自动化是去中心化、公地治理且以普遍关怀为导向的。

Method: 提出"解放栈"分层架构，包含能源、制造、食品、通信、知识和治理公地，基于开源技术。引入"通用期望资源"后货币设计原则，通过深度强化学习研究道德政策。

Result: 通过Linux、维基百科、蒙德拉贡、罗贾瓦和guifi.net等案例证明公地系统已大规模运行。论证完全自动化使货币过时，非意识机器承担劳动是文明规模的关怀。

Conclusion: 提出分阶段路线图实现关怀中心社会，包括里程碑、假设和限制。该框架与自由主义、社会主义、环保主义、女权主义、合作主义和黑客伦理建立桥梁。

Abstract: The convergence of large language models that automate cognitive labor and deep reinforcement learning agents that automate physical labor implies the near-complete elimination of human employment. The universal approximation theorem and foundational DRL results establish that all labor is in principle automatable. The critical question is not whether full automation will arrive, but who will control it. This paper introduces peaceful anarcho-accelerationism: a sociotechnical framework ensuring that full automation is decentralized, commons-governed, and oriented toward universal care. We propose the Liberation Stack, a layered architecture of energy, manufacturing, food, communication, knowledge, and governance commons built on open-source technologies. We show that this framework builds bridges with liberalism, socialism, environmentalism, feminism, cooperativism, and the hacker ethic. Empirical evidence from Linux, Wikipedia, Mondragon, Rojava, and guifi.net confirms that commons-based systems already operate at scale. We argue that full automation renders money obsolete and propose Universal Desired Resources (UDR), a post-monetary design principle where every person requests what they need from the robotic commons, constrained only by ecological sustainability. Drawing on the independence of phenomenal consciousness from computational intelligence, we establish that delegating labor to non-conscious machines is care at civilizational scale, and that moral policy can be studied through deep reinforcement learning. We conclude with a phased roadmap toward the care-centered society, including milestones, assumptions, and limitations.

</details>
