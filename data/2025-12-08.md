<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 29]
- [stat.ML](#stat.ML) [Total: 7]
- [math.OC](#math.OC) [Total: 15]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.CY](#cs.CY) [Total: 10]
- [eess.SY](#eess.SY) [Total: 23]
- [cs.LG](#cs.LG) [Total: 69]
- [q-fin.PR](#q-fin.PR) [Total: 1]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale](https://arxiv.org/abs/2512.05179)
*Aurélie Montfrond*

Main category: cs.CL

TL;DR: 该研究通过微调BERT模型，为利默里克大学电子与计算机工程系开发了一个课程信息问答聊天机器人，展示了基础模型在教育领域的适应可行性。


<details>
  <summary>Details</summary>
Motivation: 现有科学问答研究多关注聊天机器人系统，缺乏针对特定领域推理的基础模型微调探索。特别是针对大学课程材料，目前还没有专门的领域特定基础模型。

Method: 构建了包含1,203个问答对的SQuAD格式自定义数据集（基于大学模块手册，结合手动和合成生成），使用PyTorch微调BERT模型，并通过Exact Match和F1分数评估性能。

Result: 结果显示，即使是适度的微调也能显著改善假设构建和知识提取能力，证明将基础模型适应教育领域的可行性，为开发首个大学领域特定问答模型奠定了基础。

Conclusion: 通过学术问答对微调BERT模型能够获得有效结果，突显了开发大学领域特定问答模型的潜力，为实现自主教育知识系统提供了可能。

Abstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.

</details>


### [2] [Unveiling Affective Polarization Trends in Parliamentary Proceedings](https://arxiv.org/abs/2512.05231)
*Gili Goldin,Ella Rabinovich,Shuly Wintner*

Main category: cs.CL

TL;DR: 提出基于情感风格而非意识形态立场的新方法量化政治极化，应用于以色列议会语料发现政府与反对派情感风格差异，且情感极化随时间显著增加


<details>
  <summary>Details</summary>
Motivation: 近年来全球极化言论加剧，传统基于意识形态立场的方法可能无法全面捕捉极化现象，需要从情感表达角度量化政治极化

Method: 使用情感维度（效价、唤醒度、支配度）检测情感话语信号，以此操作化情感极化概念，应用于以色列议会（希伯来语）语料库

Result: 发现政府成员与反对派成员的情感风格存在差异，且基于这种情感风格的情感极化水平随时间显著增加

Conclusion: 基于情感风格的方法能有效量化政治极化，情感极化在以色列议会中日益加剧，为理解政治分歧提供了新视角

Abstract: Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.

</details>


### [3] [Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting](https://arxiv.org/abs/2512.05243)
*P. D. Edgar,Alia Hall*

Main category: cs.CL

TL;DR: 该研究提出将诗歌提示模式作为提示工程的有用工具，用于评估LLM的算法倾向和偏见，并测试模型对原创诗歌的改编意愿


<details>
  <summary>Details</summary>
Motivation: 当前提示工程已成为研究大型语言模型算法倾向和偏见的重要方法，同时创作者和学者利用LLM进行创意写作和文本生成。本研究旨在探索诗歌提示模式作为提示工程新工具的可能性，以评估模型对诗歌的改编意愿和受众适应能力

Method: 提出诗歌提示模式作为提示工程方法，使用诗歌提示评估三个著名诗人模型的描述和评价，测试模型对原创创意作品的改编意愿和受众适应能力

Result: 研究表明诗歌提示模式是提示工程工具箱的有用补充，能够有效评估LLM的算法倾向和偏见，并揭示模型对原创诗歌作品的改编意愿和受众适应行为

Conclusion: 创造性文本提示，特别是诗歌提示模式，可以成为提示工程师的有价值工具，为研究LLM的算法行为和创意作品处理能力提供新视角

Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.

</details>


### [4] [Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4](https://arxiv.org/abs/2512.05256)
*Ivan Makohon,Mohamad Najafi,Jian Wu,Mathias Brochhausen,Yaohang Li*

Main category: cs.CL

TL;DR: 使用思维链提示工程结合语义搜索和知识图谱，提升LLM生成临床病历的质量，相比标准单样本提示效果更好


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据激增，医生手动撰写临床病历耗时且影响患者等待时间，需要利用LLM自动生成高质量临床病历以提高效率

Method: 采用思维链提示工程，结合ICD代码和患者基本信息作为输入，整合语义搜索结果增强响应质量，并注入临床本体构建的知识图谱来丰富领域知识

Result: 在CodiEsp测试数据集的六个临床案例上使用GPT-4测试，该方法生成的临床病历质量优于标准单样本提示方法

Conclusion: 思维链提示工程结合语义搜索和知识图谱能有效提升LLM生成临床病历的质量，为医疗文档自动化提供了有前景的解决方案

Abstract: In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.

</details>


### [5] [To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples](https://arxiv.org/abs/2512.05318)
*Vignesh Kothapalli,Ata Fatahibaarzi,Hamed Firooz,Maziar Sanjabi*

Main category: cs.CL

TL;DR: 本文研究了在少样本上下文学习中，当预训练知识不足时，思维链提示在新型任务上效果不佳的问题，提出了CoT-Recipe方法来调节元训练中思维链和非思维链示例的比例，显著提升了模型在新任务上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 思维链提示与少样本上下文学习结合显著提升了大型语言模型的推理能力，但当面对预训练知识不足的新型任务时，这种方法的有效性会大幅下降。本文旨在解决这一局限性，探索如何在元训练中优化思维链示例的使用。

Method: 使用CoT-ICL Lab框架在受控环境中研究该问题，提出CoT-Recipe方法，这是一种调节元训练序列中思维链和非思维链示例比例的正式方法。通过精心调节这种混合比例，即使在没有思维链示例的上下文中也能显著提升性能。

Result: CoT-Recipe方法使Transformer模型在新任务上的准确率提升高达300%（即使在没有思维链示例的情况下）。在预训练LLMs（Qwen2.5系列）的符号推理任务中，准确率提升高达130%。

Conclusion: 通过CoT-Recipe方法调节元训练中思维链和非思维链示例的比例，可以有效提升模型在新任务上的推理能力，特别是在思维链监督有限的情况下。该方法在受控环境和预训练LLMs中都表现出显著效果。

Abstract: Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.

</details>


### [6] [LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning](https://arxiv.org/abs/2512.05325)
*Ömer Faruk Akgül,Yusuf Hakan Kalaycı,Rajgopal Kannan,Willie Neiswanger,Viktor Prasanna*

Main category: cs.CL

TL;DR: LYNX：基于隐藏状态感知的在线早期退出机制，利用推理线索（如"hmm"、"wait"）训练轻量级探针，通过分形预测提供置信度保证，在数学推理任务中减少40-70%计算量同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在"过度思考"问题：在已有足够信息回答正确后仍继续推理，浪费计算资源并可能降低准确性。现有早期退出方法要么需要额外采样和启发式方法，要么依赖辅助验证模型，要么缺乏形式化保证。

Method: LYNX将模型自身隐藏状态感知转化为置信度控制的停止决策：1) 在自然推理线索（如"hmm"、"wait"）处附加退出决策；2) 使用强制退出监督训练轻量级探针；3) 通过分形预测包装得分以获得分布无关的过早退出控制；4) 在通用数学语料上一次训练和校准探针，跨任务重用。

Result: 在1.5B到32B参数的三个模型系列中，单个数学训练探针产生强准确性-效率权衡：GSM8K减少40-65% token同时保持或提升准确性；MATH-500减少35-60% token同时提升准确性达12点；AIME 2024减少50%以上token恢复基线准确性；非数学任务CommonsenseQA零样本转移减少70% token并有适度准确性提升。

Conclusion: LYNX提供竞争性或更优的帕累托前沿，同时保持完全在线、无需推理时代理模型，并提供明确的用户可调置信度保证，为大型推理模型的效率优化提供了有效解决方案。

Abstract: Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often "overthink": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., "hmm", "wait") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.

</details>


### [7] [Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats](https://arxiv.org/abs/2512.05331)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee,Mostafa Musharrat,Sai Vishnu Vamsi*

Main category: cs.CL

TL;DR: 该论文研究粉红粘液新闻的检测方法，发现LLM生成的对抗性内容能显著降低现有检测系统性能，并提出能抵抗LLM攻击的鲁棒学习框架


<details>
  <summary>Details</summary>
Motivation: 粉红粘液新闻作为低质量自动生成内容，模仿合法本地新闻报道，威胁着为2800万美国人提供可靠信息的本地新闻生态。需要对其语言、风格和词汇特征进行细粒度分析来检测这些欺骗性文章。

Method: 首先对粉红粘液内容进行全面的模式识别研究，揭示其区别于合法报道的特征。然后提出基于这些特征的检测策略，特别关注LLM生成的对抗性修改。最后引入专门设计的鲁棒学习框架来抵抗LLM攻击。

Result: 研究发现即使是消费者可访问的LLM也能显著削弱现有检测系统，使F1分数下降高达40%。提出的鲁棒学习框架能有效抵抗LLM攻击，性能提升高达27%。

Conclusion: 粉红粘液新闻检测面临LLM生成对抗性内容的新威胁，需要专门设计的鲁棒学习框架来应对不断演变的自动化新闻生成技术，保护本地新闻生态的完整性。

Abstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.

</details>


### [8] [Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change](https://arxiv.org/abs/2512.05364)
*Ananth Hariharan,David Mortensen*

Main category: cs.CL

TL;DR: 该研究展示了混合神经符号方法如何为形态丰富、低资源语言的演化提供新见解，通过分析2000多年的梵语，挑战了语言变化是简化的朴素假设。


<details>
  <summary>Details</summary>
Motivation: 挑战语言变化就是简化的朴素假设，为形态丰富、低资源语言（如梵语）的演化提供量化分析新方法，解决数据稀缺问题。

Method: 采用弱监督混合方法：使用100多个高精度正则表达式模式生成伪标签，微调多语言BERT；通过新颖的置信度加权集成融合符号和神经输出，创建可扩展且可解释的系统。

Result: 在147万词历时语料库中，集成系统达到52.4%的总体特征检测率；发现梵语形态复杂性并未减少而是动态重新分布：早期动词特征呈周期性下降，复杂性转移到其他领域，复合词大幅扩展和新哲学术语出现；系统产生良好校准的不确定性估计，置信度与准确性强相关（Pearson r=0.92），校准误差低（ECE=0.043）。

Conclusion: 混合神经符号方法为计算文献学提供了可靠的新见解，证明语言复杂性是动态重新分布而非简单简化，系统的不确定性校准增强了研究发现的可靠性。

Abstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.

</details>


### [9] [Mitigating Self-Preference by Authorship Obfuscation](https://arxiv.org/abs/2512.05379)
*Taslim Mahbub,Shi Feng*

Main category: cs.CL

TL;DR: 通过简单的文本扰动（如同义词替换）可以减少语言模型评估中的自我偏好偏见，但完全消除该偏见仍面临挑战，因为模型能在多个语义层面识别自己的输出风格。


<details>
  <summary>Details</summary>
Motivation: 语言模型作为评估者广泛用于评估其他语言模型的输出质量，但存在自我偏好偏见——倾向于选择自己的答案而非其他模型或人类的答案。这种偏见难以消除，因为前沿语言模型能够识别自己的输出风格，即使评估候选没有标注来源。

Method: 采用黑盒扰动方法，在成对比较中对评估候选进行文本修改以混淆作者身份和降低自我识别能力。使用简单的扰动技术如同义词替换少数词汇，并尝试外推到更完整的风格差异中和化。

Result: 简单的扰动（如同义词替换少量词汇）可预测地减少自我偏好偏见。然而，当将扰动外推到更完整的风格差异中和化时，自我偏好会恢复。这表明自我识别和自我偏好可在多个语义层面发生。

Conclusion: 虽然初步结果显示出通过文本扰动减少自我偏好的潜力，但完全消除该偏见仍具挑战性。自我识别和自我偏好可在多个语义层面发生，需要更深入的研究来开发有效的缓解策略。

Abstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.

</details>


### [10] [Learning from Self Critique and Refinement for Faithful LLM Summarization](https://arxiv.org/abs/2512.05387)
*Ting-Yao Hu,Hema Swetha Koppula,Hadi Pouransari,Cem Koc,Oncel Tuzel,Raviteja Vemulapalli*

Main category: cs.CL

TL;DR: SCRPO是一种自监督训练框架，通过LLM自身的批判和精炼能力构建偏好数据集，然后应用偏好学习来提升摘要的忠实度，相比测试时精炼方法更高效且效果更好。


<details>
  <summary>Details</summary>
Motivation: LLM在长文本生成任务（如摘要）中经常产生幻觉（输出内容与输入上下文不符）。现有方法通过迭代批判和精炼来减少幻觉，但要么需要额外的测试时计算，要么需要更强大的教师模型，成本高且不实用。

Method: 提出自批判和精炼的偏好优化（SCRPO）：1）利用LLM自身的批判和精炼能力构建偏好数据集；2）应用偏好学习来改进同一LLM，实现更忠实的摘要生成。

Result: 在三个摘要基准测试（XSUM、CNNDM和SAMSum）上，SCRPO在忠实度指标上优于最先进的自监督学习方法，同时保持或改进了衡量摘要整体质量的其他指标。相比测试时精炼方法，SCRPO不仅效率更高，还能产生更忠实的摘要。

Conclusion: SCRPO是一种有效的自监督训练框架，能够在不依赖额外计算资源或更强大教师模型的情况下，显著提升LLM生成摘要的忠实度，具有更好的实用性和效率。

Abstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.

</details>


### [11] [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs](https://arxiv.org/abs/2512.05409)
*Ruixuan Huang,Hao Zeng,Hantao Huang,Jinyuan Shi,Minghui Yu,Ian En-Hsu Yen,Shuai Wang*

Main category: cs.CL

TL;DR: 提出SQ-format统一数据格式，将稀疏化和量化结合，在现有GPU上实现性能与吞吐量的帕累托改进，特别适用于激活值中的离群值处理。


<details>
  <summary>Details</summary>
Motivation: 现有低比特量化和稀疏化技术由于硬件支持有限，难以平衡准确性和效率。例如W4A8只能达到与W8A8相同的峰值TOPS，而GPU支持的2:4半结构化稀疏格式因精度损失很少被采用。

Method: 提出稀疏量化格式(SQ-format)，这是一种统一的数据格式，利用稀疏矩阵可以在高精度下加速，低精度矩阵乘法也可以相应加速的特性，实现量化与稀疏化的结合。

Result: SQ-format实现了性能与吞吐量之间的帕累托改进，特别适用于具有离群值不平衡状态的激活值，使其静态压缩成为可能，并展示了最先进的PTQ性能。

Conclusion: SQ-format为下一代AI加速器提供了设计探索和见解，提出了支持该格式所需的硬件要求，有望在现有GPU和新硬件上实现更好的量化稀疏化平衡。

Abstract: Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.

</details>


### [12] [Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments](https://arxiv.org/abs/2512.05832)
*Yifei Tong*

Main category: cs.CL

TL;DR: 研究美国最高法院口头辩论中的打断行为如何影响律师发言的语义内容和情感基调，特别关注性别差异。发现打断不改变论证内容，但对女性律师的打断含有更多负面情感。


<details>
  <summary>Details</summary>
Motivation: 研究最高法院口头辩论中打断行为对律师发言的影响，特别关注性别差异，以理解精英机构中的权力、话语和公平问题。

Method: 使用ConvoKit最高法院语料库（2010-2019），分析12,663个律师-法官互动片段。使用GloVe句子嵌入量化语义变化，通过词典分析测量情感。

Result: 打断前后语义相似度保持高位，表明打断不改变论证内容；但对女性律师的打断含有显著更高的负面情感。

Conclusion: 研究深化了对精英机构中性别化沟通的实证理解，展示了计算语言学方法在研究司法程序中的权力、话语和公平方面的价值。

Abstract: This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.

</details>


### [13] [LMSpell: Neural Spell Checking for Low-Resource Languages](https://arxiv.org/abs/2512.05414)
*Akesh Gunathilakea,Nadil Karunarathnea,Tharusha Bandaranayakea,Nisansa de Silvaa,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 首次对预训练语言模型在拼写纠错任务上的有效性进行实证研究，包括低资源语言，发现大语言模型在微调数据量大时表现最佳，并发布了LMSpell工具包。


<details>
  <summary>Details</summary>
Motivation: 拼写纠错对低资源语言仍是挑战，现有预训练语言模型的应用仅限于少数语言，且缺乏跨模型的系统比较。

Method: 对多种预训练语言模型（包括编码器、编码器-解码器和大语言模型）在拼写纠错任务上进行实证比较，开发了LMSpell工具包，并包含针对LLM幻觉的评估函数补偿机制。

Result: 当微调数据集较大时，大语言模型优于其他模型，即使对未经预训练的语言也成立；通过僧伽罗语案例研究揭示了低资源语言拼写纠错的困境。

Conclusion: 大语言模型在拼写纠错任务上具有优势，特别是对于低资源语言，LMSpell工具包为跨模型评估提供了便利，并强调了低资源语言面临的独特挑战。

Abstract: Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.

</details>


### [14] [ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering](https://arxiv.org/abs/2512.05430)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 本文介绍了MusWikiDB（音乐维基百科向量数据库）和ArtistMus（艺术家问答基准），用于提升大语言模型在音乐领域问答中的表现，通过检索增强生成技术显著提高了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在音乐相关推理方面效果有限，因为预训练数据中音乐知识稀疏。虽然音乐信息检索和计算音乐学已经探索了结构化多模态理解，但缺乏基于艺术家元数据或历史背景的事实性和上下文音乐问答资源。

Method: 1. 构建MusWikiDB：包含144K音乐相关维基百科页面的3.2M段落向量数据库；2. 创建ArtistMus基准：包含500位多样化艺术家的1,000个问题，涵盖流派、出道年份、主题等元数据；3. 使用检索增强生成技术进行系统评估；4. 进行RAG风格微调以提升事实召回和上下文推理能力。

Result: 1. RAG显著提高事实准确性：开源模型提升高达+56.8个百分点（如Qwen3 8B从35.0提升到91.8），接近专有模型性能；2. RAG风格微调进一步提升事实召回和上下文推理能力；3. MusWikiDB相比通用维基百科语料库准确率提高约6个百分点，检索速度快40%。

Conclusion: MusWikiDB和ArtistMus资源为音乐信息检索和领域特定问答研究提供了基础，建立了在音乐等文化丰富领域中检索增强推理的框架，推动了音乐相关推理能力的发展。

Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.

</details>


### [15] [Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment](https://arxiv.org/abs/2512.05464)
*Panatchakorn Anantaprayoon,Nataliia Babina,Jad Tarifi,Nima Asgharbeygi*

Main category: cs.CL

TL;DR: 提出Collective Agency作为统一开放式的对齐价值观，以及Dynamic Alignment自对齐框架，通过自动数据生成和自我奖励机制实现LLM的自对齐，超越传统对齐规范。


<details>
  <summary>Details</summary>
Motivation: 随着AI向AGI/ASI发展，传统基于人类偏好或预设原则（如帮助性、诚实性、无害性）的对齐方法变得不足，且人类反馈对齐资源密集、难以扩展。需要更全面的对齐目标和可扩展的自对齐方法。

Method: 提出Collective Agency（集体能动性）作为统一开放式的对齐价值观；提出Dynamic Alignment框架，包含两个核心组件：1）使用LLM自动生成训练数据集；2）自我奖励机制，策略模型评估自身输出候选并分配奖励用于GRPO学习。

Result: 实验结果表明，该方法成功将模型对齐到Collective Agency价值观，同时保持了通用的NLP能力。

Conclusion: 提出的Collective Agency价值观和Dynamic Alignment自对齐框架能够超越传统对齐规范，实现更全面、可扩展的AI对齐，为AGI/ASI时代的对齐问题提供新思路。

Abstract: Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.

</details>


### [16] [SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures](https://arxiv.org/abs/2512.05501)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: SEA-SafeguardBench是首个针对东南亚语言的人工验证安全基准，包含8种语言、21,640个样本，揭示当前LLM和防护系统在东南亚文化场景中表现不佳


<details>
  <summary>Details</summary>
Motivation: 现有安全评估主要集中于英语，缺乏对语言和文化多样性的考量。东南亚语言在安全基准中代表性不足，但该地区存在独特的文化敏感性和安全关切，如政治言论和地区性虚假信息。需要原生创作的基准来反映当地规范和危害场景。

Method: 开发了SEA-SafeguardBench基准，覆盖8种东南亚语言，包含21,640个人工验证样本，分为三个子集：通用安全、野外实际内容和内容生成场景。

Result: 实验结果表明，即使是当前最先进的LLM和防护系统在东南亚文化和危害场景中也面临挑战，与英语文本相比表现不佳。

Conclusion: 需要更多关注多语言安全评估，特别是针对东南亚等代表性不足的语言区域。原生创作的基准对于准确评估模型在多样化文化背景下的安全性能至关重要。

Abstract: Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.

</details>


### [17] [Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches](https://arxiv.org/abs/2512.05537)
*Namu Park,Farzad Ahmed,Zhaoyi Sun,Kevin Lybarger,Ethan Breinhorst,Julie Hu,Ozlem Uzuner,Martin Gunn,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 大型语言模型通过病灶标记和解剖学提示，在放射学报告中检测需要随访的偶发瘤方面，显著优于传统监督学习方法，性能接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 当前基于文档级别的分类系统在检测需要随访的偶发瘤方面存在局限性，需要更细粒度的病灶级别检测方法。

Method: 使用400份标注的放射学报告（包含1623个已验证病灶），比较三种监督式Transformer编码器与四种生成式LLM配置。引入基于病灶标记输入和解剖学感知提示的新型推理策略，以增强模型推理能力。

Result: 解剖学感知的GPT-OSS-20b模型表现最佳，偶发瘤阳性宏F1为0.79，超过所有监督基线（最高0.70），接近人类标注者间一致性（0.76）。解剖学提示显著提升GPT模型性能，多数投票集成进一步将宏F1提升至0.90。

Conclusion: 结合结构化病灶标记和解剖学上下文的生成式LLM显著优于传统监督编码器，性能接近人类专家，为放射学工作流中的自动偶发发现监测提供了可靠、可解释的途径。

Abstract: Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.
  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.
  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.
  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.

</details>


### [18] [Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems](https://arxiv.org/abs/2512.05580)
*Aurprita Mahmood,Sabrin alam,Neloy kumer Sagor,Md. Abdul Hadi,Md. Sehab Al Islam,Minhajul Islam*

Main category: cs.CL

TL;DR: 该研究系统评估了Tree-of-Thought推理在孟加拉语数学应用题上的效果，相比Chain-of-Thought，ToT在GPT-OSS-120B上实现了88%的准确率，提升了5个百分点。


<details>
  <summary>Details</summary>
Motivation: 数学应用题是NLP中最具挑战性的任务之一，需要语言理解和多步数值推理。虽然Chain-of-Thought提示显示出了潜力，但其线性结构容易传播错误，限制了整体效果。特别是在低资源语言如孟加拉语中，需要更可靠的推理框架。

Method: 使用SOMADHAN数据集，在计算和token成本限制下，评估了100个代表性孟加拉语数学应用题。在多个大语言模型（包括GPT-OSS和LLaMA变体）上比较了标准提示、Chain-of-Thought和Tree-of-Thought策略。

Result: CoT将基线准确率从78%（标准提示）提升到83%，而ToT进一步将性能提高了最多5个百分点，在GPT-OSS-120B上达到88%准确率。ToT在中大型模型中特别有效，但对较小模型优势较小。

Conclusion: ToT是解决孟加拉语等低资源语言数学问题的稳健框架。结构化推理方法如ToT相比CoT能提供更可靠和全局一致的结果，为多语言NLP中更好的推理策略铺平了道路。

Abstract: Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.

</details>


### [19] [A Greek Government Decisions Dataset for Public-Sector Analysis and Insight](https://arxiv.org/abs/2512.05647)
*Giorgos Antoniou,Giorgos Filandrianos,Aggelos Vlachos,Giorgos Stamou,Lampros Kollimenos,Konstantinos Skianis,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 构建了希腊政府决策的开放机器可读语料库，包含100万份决策，支持检索增强生成任务，可作为法律和政府领域LLM的训练数据


<details>
  <summary>Details</summary>
Motivation: 创建大规模公共部门语料库，支持政府文档的结构化检索和推理，促进信息获取和透明度

Method: 从Diavgeia透明度平台获取希腊政府决策，提取高质量原始文本，设计RAG任务，构建问答对并评估基线系统

Result: 建立了包含100万决策的语料库，展示了RAG系统在政府文档检索和推理方面的潜力，可作为法律和政府领域LLM的高价值训练数据

Conclusion: 大规模公共部门语料库能够支持先进的信息访问和透明度，通过结构化检索和推理政府文档，为专业领域LLM提供高质量训练材料

Abstract: We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.

</details>


### [20] [Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models](https://arxiv.org/abs/2512.05658)
*Pietro Ferrazzi,Aitor Soroa,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 该研究提出了一种基于检索增强生成的方法，为医学问答生成多语言推理轨迹，覆盖英语、意大利语和西班牙语，通过上下文学习和监督微调提升LLMs在医学QA中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学问答方法主要依赖英语，且大多通过蒸馏通用LLMs获得，其医学知识可靠性存疑。需要开发基于事实医学知识的多语言推理方法，以支持更安全、透明的多语言临床决策工具。

Method: 采用检索增强生成方法，基于维基百科医学信息生成多语言推理轨迹。将MedQA和MedMCQA扩展到意大利语和西班牙语，生成50万条推理轨迹。在领域内和领域外医学QA基准上测试，通过上下文学习和监督微调两种方式利用推理轨迹。

Result: 推理轨迹显著提升了医学QA性能，在8B参数LLMs中取得了最先进的结果。研究发布了完整的资源套件：推理轨迹、翻译的QA数据集、医学维基百科和微调模型。

Conclusion: 该方法能够生成基于事实医学知识的多语言推理轨迹，支持开发更安全、透明的多语言临床决策支持工具，为医学AI领域提供了有价值的资源。

Abstract: Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.

</details>


### [21] [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)
*Shuai Dong,Siyuan Wang,Xingyu Liu,Zhongyu Wei*

Main category: cs.CL

TL;DR: ILVR框架通过交错潜在视觉表示与文本生成，解决了多模态大语言模型中视觉反馈计算成本高的问题，同时避免了感知精度与动态建模的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有交错推理范式因重复编码像素密集图像而计算成本过高，而潜在视觉推理方法要么因过度压缩特征牺牲感知精度，要么因静态结构无法建模动态问题。

Method: 提出交错潜在视觉推理(ILVR)框架，将文本生成与作为后续推理线索的潜在视觉表示交错。采用自监督策略，通过动量教师模型从辅助图像中选择性蒸馏相关特征为稀疏监督目标，引导模型自主生成上下文感知的视觉信号。

Result: 在多模态推理基准测试中，ILVR显著优于现有方法，有效弥合了细粒度感知与序列多模态推理之间的差距。

Conclusion: ILVR统一了动态状态演化与精确感知建模，通过交错潜在视觉表示实现了高效且精确的多模态推理。

Abstract: Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.

</details>


### [22] [MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation](https://arxiv.org/abs/2512.05671)
*Zhitao He,Haolin Yang,Zeyu Qin,Yi R Fung*

Main category: cs.CL

TL;DR: 开发了ClinEdu多智能体教学模拟器和ClinTeach数据集，并训练了MedTutor-R1多模态苏格拉底式导师，用于临床医学教育中的一对多教学，显著提升了教学效果。


<details>
  <summary>Details</summary>
Motivation: 临床医学教育面临专家指导稀缺与学生需求增长的矛盾，现有LLM研究主要关注一对一知识传授，忽视了团队协作推理这一关键临床技能。

Method: 1) 开发ClinEdu多智能体教学模拟器，包含个性驱动患者和多样化学生群体；2) 构建ClinTeach大规模苏格拉底教学对话数据集；3) 训练MedTutor-R1多模态苏格拉底导师，先指令微调再强化学习优化，使用三轴评估标准（结构保真度、分析质量、临床安全性）；4) 通过模拟交互评估进行真实情境测试。

Result: MedTutor-R1在平均教学评分上比基础模型提升超过20%，与o3模型性能相当，在处理不同数量学生时表现出高适应性，验证了ClinEdu教学模拟器的有效性。

Conclusion: 通过多智能体模拟器和强化学习优化的苏格拉底式导师，能够有效解决临床医学教育中一对多教学的挑战，提升协作推理能力培养。

Abstract: The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.

</details>


### [23] [Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods](https://arxiv.org/abs/2512.05681)
*Tereza Novotna,Jakub Harasta*

Main category: cs.CL

TL;DR: 比较OpenAI通用嵌入模型与捷克宪法法院领域专用BERT模型在案例检索任务上的表现，提出噪声感知评估框架，发现通用模型显著优于领域专用模型


<details>
  <summary>Details</summary>
Motivation: 案例检索是耗时的任务，通常通过查询数据库完成。需要比较通用嵌入模型与领域专用模型在捷克宪法法院决策检索中的效果，并开发适用于噪声标签数据的评估框架

Method: 比较两种模型：1) OpenAI通用嵌入器，2) 在约30,000个捷克宪法法院决策上从头训练的领域专用BERT（使用滑动窗口和注意力池化）。提出噪声感知评估方法：包括IDF加权关键词重叠作为分级相关性、通过两个阈值（0.20平衡、0.28严格）进行二值化、配对bootstrap显著性检验，以及结合定性分析的nDCG诊断

Result: 尽管绝对nDCG值较低（在噪声标签下预期如此），但通用OpenAI嵌入器在两个阈值设置下@10/@20/@100均显著优于领域预训练的BERT模型；差异具有统计显著性。诊断表明低绝对值是由于标签漂移和强理想标准，而非缺乏实用性

Conclusion: 通用嵌入模型在捷克宪法法院案例检索任务上优于领域专用模型。提出的评估框架足够稳健，可用于处理来自遗留司法数据库的异质标签噪声数据集的评估

Abstract: Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.

</details>


### [24] [Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains](https://arxiv.org/abs/2512.05700)
*Ben Malin,Tatiana Kalganova,Nikolaos Boulgouris*

Main category: cs.CL

TL;DR: 提出一种通过融合多个基础忠实度指标来改进大语言模型忠实度评估准确性的方法，使用树模型结合人工标注来优化指标融合，在多个领域都显示出与人类判断更强的相关性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的忠实度评估存在局限性，需要更准确的方法来评估模型输出的可信度，以便在更多样化的场景中安全部署模型。

Method: 提出基于树模型的指标融合方法，将多个基础忠实度指标组合成综合指标，通过人工标注的忠实度评估来驱动融合过程，并构建了跨问答和对话领域的数据集用于验证。

Result: 融合后的指标在所有测试领域都显示出与人类判断更强的相关性，提高了大语言模型忠实度评估的准确性。

Conclusion: 该方法能够更准确地评估大语言模型的忠实度，增强对模型的信任，使其能够在更多样化的场景中安全部署，同时提供了可复现的数据集供进一步研究。

Abstract: We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.

</details>


### [25] [Efficient Text Classification with Conformal In-Context Learning](https://arxiv.org/abs/2512.05732)
*Ippokratis Pantelidis,Korbinian Randl,Aron Henriksson*

Main category: cs.CL

TL;DR: CICLe框架通过结合轻量级基分类器和Conformal Prediction来指导LLM提示，在多种NLP分类任务中显著提升效率，减少提示长度和样本需求，特别适用于类别不平衡任务。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型具有强大的上下文学习能力，但在文本分类任务中效果严重依赖提示设计且计算成本高昂。现有的CICLe框架虽然提出了一种资源高效的方法，但其在多个领域的适用性和效率优势尚未得到系统验证。

Method: CICLe框架整合轻量级基分类器与Conformal Prediction，通过自适应减少候选类别集合来指导LLM提示。基分类器在少量样本上训练，然后使用Conformal Prediction生成预测集，从而减少LLM需要处理的类别数量。

Result: 在多样化的NLP分类基准测试中，CICLe在样本充足时优于基分类器和少样本提示基线，在低数据场景下表现相当。效率方面，减少样本数量和提示长度分别达34.45%和25.16%，并能使用更小的模型保持竞争力，特别适合类别不平衡任务。

Conclusion: CICLe是一种实用且可扩展的高效文本分类方法，结合了传统分类器的鲁棒性和LLM的适应性，在数据和计算效率方面取得显著提升，为资源受限场景提供了有效解决方案。

Abstract: Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.

</details>


### [26] [Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning](https://arxiv.org/abs/2512.05747)
*Jinlong Liu,Mohammed Bahja,Venelin Kovatchev,Mark Lee*

Main category: cs.CL

TL;DR: 提出GRPO训练框架，结合多奖励机制实现细粒度风格控制的故事生成，在马克·吐温风格生成上超越GPT-4o等大型模型


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在开放式故事生成中表现优秀，但细粒度风格控制能力有限，现有方法依赖浅层线索且缺乏稳健评估

Method: 使用Group Relative Policy Optimization (GRPO)训练框架，结合多奖励机制：基于作者验证信号微调的句子Transformer风格奖励、内容评分和完整性评分

Result: 8B参数模型在作者验证风格指标上超越GPT-4o和Claude Sonnet 4，风格得分0.628，内容质量有竞争力，证明中等规模模型可实现代理风格生成

Conclusion: 该方法能有效实现风格对齐，但叙事完整性仍是挑战，未来需改进全局连贯性和故事结局建模

Abstract: Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.

</details>


### [27] [Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy](https://arxiv.org/abs/2512.05858)
*Savir Basil,Ina Shapiro,Dan Shapiro,Ethan Mollick,Lilach Mollick,Lennart Meincke*

Main category: cs.CL

TL;DR: 研究显示，为AI模型分配专家或低知识人设通常不会提高其在GPQA Diamond和MMLU-Pro等研究生级别多选题上的准确性，反而可能降低表现。


<details>
  <summary>Details</summary>
Motivation: 探讨在AI模型中分配特定人设（如领域专家或低知识水平者）是否能够提升其在复杂客观多选题上的表现，为商业、教育和政策决策者提供技术参考。

Method: 在六个模型上测试三种人设方法：1）领域匹配专家人设；2）领域不匹配专家人设；3）低知识人设（如外行、幼儿），使用GPQA Diamond和MMLU-Pro两个研究生级别题库进行评估。

Result: 人设提示通常不会提高准确性：领域匹配专家人设无显著影响（除Gemini 2.0 Flash外）；领域不匹配专家人设略有差异；低知识人设普遍降低准确性。人设对答案准确性无一致益处。

Conclusion: 为AI模型分配人设并不能可靠地提高其事实性表现，虽然人设可能改变输出风格，但不会改善准确性。这为实际应用提供了重要参考。

Abstract: This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.
  We tested three approaches:
  -In-Domain Experts: Assigning the model an expert persona ("you are a physics expert") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).
  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona ("you are a physics expert") not matched to the problem type (law problems) resulted in marginal differences.
  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.
  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.

</details>


### [28] [Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework](https://arxiv.org/abs/2512.05863)
*Tasnimul Hassan,Md Faisal Karim,Haziq Jeelani,Elham Behnam,Robert Green,Fayeq Jeelani Syed*

Main category: cs.CL

TL;DR: 该论文提出了一种基于检索增强生成（RAG）的医疗问答系统，通过结合领域知识检索与开源大语言模型，提高医疗问答的事实准确性和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 直接将大语言模型应用于临床领域面临事实准确性不足和幻觉问题，需要结合领域专业知识来提升医疗问答的可靠性。

Method: 使用检索增强生成框架，结合医疗文献检索与开源LLMs（LLaMA~2和Falcon），采用LoRA进行高效领域微调，通过检索相关医学文献来支撑模型回答。

Result: 在PubMedQA和MedMCQA基准测试中，检索增强显著提升答案准确性。微调后的LLaMA~2在PubMedQA上达到71.8%准确率，相比零样本基线（55.4%）大幅提升，同时提供源引用，减少约60%的无支持内容。

Conclusion: RAG增强的开源LLMs在可靠生物医学问答方面具有潜力，为实际临床信息学应用提供了可行方案，通过检索证据支撑回答可显著提高事实正确性。

Abstract: Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.

</details>


### [29] [M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG](https://arxiv.org/abs/2512.05959)
*David Anugraha,Patrick Amadeus Irawan,Anshul Singh,En-Shiun Annie Lee,Genta Indra Winata*

Main category: cs.CL

TL;DR: M4-RAG是一个大规模多语言多模态检索增强生成基准，覆盖42种语言和56种地区方言，包含8万多个文化多样性图像-问题对，用于评估跨语言和模态的检索增强视觉问答。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉问答中表现良好，但受限于静态训练数据。检索增强生成可以访问最新、文化相关和多语言信息，但多语言多模态RAG研究不足，需要系统评估框架。

Method: 构建M4-RAG基准，包含42种语言、56种方言的8万+文化多样性图像-问题对；创建受控检索环境，包含数百万精心策划的多语言文档，平衡真实性与可重复性。

Result: 系统评估显示：RAG对小规模VLM模型有益，但对大规模模型效果不佳甚至降低性能，揭示了模型规模与当前检索效果之间的关键不匹配。

Conclusion: M4-RAG为推进下一代RAG系统奠定了基础，这些系统能够跨语言、模态和文化语境进行无缝推理，解决多语言多模态检索增强生成的研究空白。

Abstract: Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [30] [How to Tame Your LLM: Semantic Collapse in Continuous Systems](https://arxiv.org/abs/2512.05162)
*C. M. Wyss*

Main category: stat.ML

TL;DR: 该论文提出将大语言模型形式化为连续状态机，证明了语义特征定理：转移算子的主导特征函数在实数可定义结构下产生有限个谱盆地，解释了连续计算如何涌现离散符号语义。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型的语义动态性，解释连续激活流形如何产生离散的、逻辑可解释的语义结构，连接连续计算与离散符号语义之间的鸿沟。

Method: 将大语言模型形式化为连续状态机（CSMs），作为平滑动力系统，通过转移算子编码语义质量传播。在紧致性、遍历性、有界雅可比矩阵等正则性假设下，分析转移算子的谱性质。

Result: 证明了语义特征定理（SCT）：转移算子的主导特征函数在实数可定义结构下产生有限个谱盆地，表明谱可聚合性与逻辑可驯性一致。该结果可扩展到随机和绝热（时间非齐次）设置。

Conclusion: 连续激活流形会坍缩为有限、逻辑可解释的本体论，这解释了离散符号语义如何从连续计算中涌现。谱盆地结构在缓慢漂移的核函数下保持稳定。

Abstract: We develop a general theory of semantic dynamics for large language models by formalizing them as Continuous State Machines (CSMs): smooth dynamical systems whose latent manifolds evolve under probabilistic transition operators. The associated transfer operator $P: L^2(M,μ) \to L^2(M,μ)$ encodes the propagation of semantic mass. Under mild regularity assumptions (compactness, ergodicity, bounded Jacobian), $P$ is compact with discrete spectrum. Within this setting, we prove the Semantic Characterization Theorem (SCT): the leading eigenfunctions of $P$ induce finitely many spectral basins of invariant meaning, each definable in an o-minimal structure over $\mathbb{R}$. Thus spectral lumpability and logical tameness coincide. This explains how discrete symbolic semantics can emerge from continuous computation: the continuous activation manifold collapses into a finite, logically interpretable ontology. We further extend the SCT to stochastic and adiabatic (time-inhomogeneous) settings, showing that slowly drifting kernels preserve compactness, spectral coherence, and basin structure.

</details>


### [31] [One-Step Diffusion Samplers via Self-Distillation and Deterministic Flow](https://arxiv.org/abs/2512.05251)
*Pascal Jutras-Dube,Jiaru Zhang,Ziran Wang,Ruqi Zhang*

Main category: stat.ML

TL;DR: 提出一步扩散采样器，通过状态空间一致性损失学习步长条件ODE，实现一步采样；引入确定性流重要性权重和体积一致性正则化，在少步采样下保持稳定证据估计。


<details>
  <summary>Details</summary>
Motivation: 现有采样算法通常需要大量迭代步骤才能产生高质量样本，导致计算成本高昂。此外，在少步采样情况下，标准ELBO估计会因离散积分器导致的前向/后向转移核不匹配而性能下降。

Method: 1) 学习步长条件ODE，通过状态空间一致性损失使一大步再现多个小步的轨迹；2) 推导确定性流重要性权重，无需后向核即可进行ELBO估计；3) 引入体积一致性正则化，校准不同步长分辨率下沿流的累积体积变化。

Result: 在具有挑战性的合成和贝叶斯基准测试中，该方法以数量级更少的网络评估实现了具有竞争力的样本质量，同时保持了稳健的ELBO估计。

Conclusion: 提出的一步扩散采样器能够在仅一步或几步内同时实现高质量采样和稳定的证据估计，显著降低了计算成本。

Abstract: Sampling from unnormalized target distributions is a fundamental yet challenging task in machine learning and statistics. Existing sampling algorithms typically require many iterative steps to produce high-quality samples, leading to high computational costs. We introduce one-step diffusion samplers which learn a step-conditioned ODE so that one large step reproduces the trajectory of many small ones via a state-space consistency loss. We further show that standard ELBO estimates in diffusion samplers degrade in the few-step regime because common discrete integrators yield mismatched forward/backward transition kernels. Motivated by this analysis, we derive a deterministic-flow (DF) importance weight for ELBO estimation without a backward kernel. To calibrate DF, we introduce a volume-consistency regularization that aligns the accumulated volume change along the flow across step resolutions. Our proposed sampler therefore achieves both sampling and stable evidence estimate in only one or few steps. Across challenging synthetic and Bayesian benchmarks, it achieves competitive sample quality with orders-of-magnitude fewer network evaluations while maintaining robust ELBO estimates.

</details>


### [32] [Symmetric Linear Dynamical Systems are Learnable from Few Observations](https://arxiv.org/abs/2512.05337)
*Minh Vu,Andrey Y. Lokhov,Marc Vuffray*

Main category: stat.ML

TL;DR: 提出一种基于矩方法的估计器，仅需T=O(log N)个观测即可高精度恢复对称动态矩阵，无论矩阵稀疏或稠密


<details>
  <summary>Details</summary>
Motivation: 解决从单条轨迹中学习N维随机线性动态参数的问题，特别是在完全和部分观测条件下，需要高效且不依赖问题特定正则化的估计方法

Method: 基于矩方法的新估计器，不依赖问题特定正则化，适用于对称动态矩阵的恢复

Result: 该估计器仅需T=O(log N)个观测即可实现小的最大元素误差，无论矩阵稀疏或稠密，特别适用于结构发现等应用

Conclusion: 提出的矩方法估计器在样本效率方面具有显著优势，为随机线性动态参数学习提供了有效的解决方案

Abstract: We consider the problem of learning the parameters of a $N$-dimensional stochastic linear dynamics under both full and partial observations from a single trajectory of time $T$. We introduce and analyze a new estimator that achieves a small maximum element-wise error on the recovery of symmetric dynamic matrices using only $T=\mathcal{O}(\log N)$ observations, irrespective of whether the matrix is sparse or dense. This estimator is based on the method of moments and does not rely on problem-specific regularization. This is especially important for applications such as structure discovery.

</details>


### [33] [Do We Really Even Need Data? A Modern Look at Drawing Inference with Predicted Data](https://arxiv.org/abs/2512.05456)
*Stephen Salerno,Kentaro Hoffman,Awan Afiaz,Anna Neufeld,Tyler H. McCormick,Jeffrey T. Leek*

Main category: stat.ML

TL;DR: 使用预测数据作为缺失数据的替代进行统计推断存在偏差和方差问题，高预测精度不能保证有效推断，需要透明和统计原则的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI/ML工具普及和数据收集困难（成本上升、调查响应率下降），研究者越来越多地使用预训练算法的预测作为缺失或未观测数据的替代。虽然经济实用，但标准推断工具可能错误表示自变量与结果变量之间的关系。

Method: 分析使用预测数据进行推断（IPD）的统计挑战，展示高预测精度不能保证有效推断，将问题归结为偏差（预测系统性改变估计量或扭曲变量关系）和方差（忽略预测模型不确定性和真实数据内在变异性）问题，回顾近期IPD方法并联系经典统计理论。

Result: 所有IPD失败都可归结为偏差和方差问题，高预测精度不能保证下游推断的有效性，需要开发透明且统计原则的方法来使用预测数据。

Conclusion: 使用预测数据作为缺失数据替代进行推断需要谨慎，必须考虑偏差和方差问题，未来研究应开发透明且统计原则的方法，确保科学研究的有效性。

Abstract: As artificial intelligence and machine learning tools become more accessible, and scientists face new obstacles to data collection (e.g., rising costs, declining survey response rates), researchers increasingly use predictions from pre-trained algorithms as substitutes for missing or unobserved data. Though appealing for financial and logistical reasons, using standard tools for inference can misrepresent the association between independent variables and the outcome of interest when the true, unobserved outcome is replaced by a predicted value. In this paper, we characterize the statistical challenges inherent to drawing inference with predicted data (IPD) and show that high predictive accuracy does not guarantee valid downstream inference. We show that all such failures reduce to statistical notions of (i) bias, when predictions systematically shift the estimand or distort relationships among variables, and (ii) variance, when uncertainty from the prediction model and the intrinsic variability of the true data are ignored. We then review recent methods for conducting IPD and discuss how this framework is deeply rooted in classical statistical theory. We then comment on some open questions and interesting avenues for future work in this area, and end with some comments on how to use predicted data in scientific studies that is both transparent and statistically principled.

</details>


### [34] [Design-marginal calibration of Gaussian process predictive distributions: Bayesian and conformal approaches](https://arxiv.org/abs/2512.05611)
*Aurélien Pion,Emmanuel Vazquez*

Main category: stat.ML

TL;DR: 本文研究了高斯过程在插值设置下的预测分布校准问题，提出了两种方法：基于标准化留一残差的cps-gp和基于广义正态模型的bcr-gp，通过数值实验比较了不同方法的校准性能。


<details>
  <summary>Details</summary>
Motivation: 高斯过程预测分布在插值设置下的校准问题尚未得到充分研究。现有方法在有限样本下的边际校准性能不足，需要开发能够保证校准质量同时保持平滑预测分布的方法，特别是在顺序设计等应用中。

Method: 提出了两种方法：1) cps-gp：将保形预测系统适配到GP插值，使用标准化留一残差，产生具有有限样本边际校准的分段预测分布；2) bcr-gp：保留GP后验均值，用拟合交叉验证标准化残差的广义正态模型替换高斯残差，通过贝叶斯选择规则控制离散度和尾部行为。

Result: 在基准函数上的数值实验比较了cps-gp、bcr-gp、Jackknife+ for GPs和全保形高斯过程。使用校准指标（覆盖率、Kolmogorov-Smirnov、积分绝对误差）和精度/锐度（缩放连续排序概率得分）进行评估。

Conclusion: 本文提出的cps-gp和bcr-gp方法能够有效解决高斯过程预测分布在插值设置下的校准问题，cps-gp提供有限样本边际校准，bcr-gp产生平滑预测分布适合顺序设计，两种方法在不同校准指标上表现出色。

Abstract: We study the calibration of Gaussian process (GP) predictive distributions in the interpolation setting from a design-marginal perspective. Conditioning on the data and averaging over a design measure μ, we formalize μ-coverage for central intervals and μ-probabilistic calibration through randomized probability integral transforms. We introduce two methods. cps-gp adapts conformal predictive systems to GP interpolation using standardized leave-one-out residuals, yielding stepwise predictive distributions with finite-sample marginal calibration. bcr-gp retains the GP posterior mean and replaces the Gaussian residual by a generalized normal model fitted to cross-validated standardized residuals. A Bayesian selection rule-based either on a posterior upper quantile of the variance for conservative prediction or on a cross-posterior Kolmogorov-Smirnov criterion for probabilistic calibration-controls dispersion and tail behavior while producing smooth predictive distributions suitable for sequential design. Numerical experiments on benchmark functions compare cps-gp, bcr-gp, Jackknife+ for GPs, and the full conformal Gaussian process, using calibration metrics (coverage, Kolmogorov-Smirnov, integral absolute error) and accuracy or sharpness through the scaled continuous ranked probability score.

</details>


### [35] [BalLOT: Balanced $k$-means clustering with optimal transport](https://arxiv.org/abs/2512.05926)
*Wenyan Luo,Dustin G. Mixon*

Main category: stat.ML

TL;DR: BalLOT：一种基于最优传输的交替最小化方法，用于解决平衡k-means聚类问题，具有快速有效、理论保证和初始化方案等特点。


<details>
  <summary>Details</summary>
Motivation: 解决平衡k-means聚类这一基础问题，传统方法在平衡约束下效果有限，需要更有效的解决方案。

Method: 提出BalLOT方法，将最优传输与交替最小化相结合，通过最优传输方法处理平衡约束，实现快速有效的聚类。

Result: 数值实验显示BalLOT快速有效；理论证明：对通用数据产生整数耦合；在随机球模型下能精确或部分恢复聚类；初始化方案能实现单步恢复。

Conclusion: BalLOT为平衡k-means聚类提供了理论保证的快速有效解决方案，结合了最优传输的优势与交替最小化的效率。

Abstract: We consider the fundamental problem of balanced $k$-means clustering. In particular, we introduce an optimal transport approach to alternating minimization called BalLOT, and we show that it delivers a fast and effective solution to this problem. We establish this with a variety of numerical experiments before proving several theoretical guarantees. First, we prove that for generic data, BalLOT produces integral couplings at each step. Next, we perform a landscape analysis to provide theoretical guarantees for both exact and partial recoveries of planted clusters under the stochastic ball model. Finally, we propose initialization schemes that achieve one-step recovery of planted clusters.

</details>


### [36] [Consequences of Kernel Regularity for Bandit Optimization](https://arxiv.org/abs/2512.05957)
*Madison Lee,Tara Javidi*

Main category: stat.ML

TL;DR: 论文研究了核函数正则性与RKHS函数bandit优化算法性能的关系，通过谱分析统一了全局核回归和局部平滑方法，为多种核函数推导了显式遗憾界，并分析了混合算法LP-GP-UCB的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RKHS方法依赖全局核回归器，而平滑方法利用局部近似，这两种视角之间的关系尚不明确。研究旨在通过各向同性核的谱特性揭示这两种方法的深层联系，建立统一的分析框架。

Method: 分析Matérn、平方指数、有理二次、γ-指数、分段多项式和Dirichlet核的傅里叶谱特性，研究谱衰减率如何同时影响核化bandit算法的最大信息增益和基于平滑方法的Hölder空间嵌入。分析混合算法LP-GP-UCB，结合全局高斯过程代理和局部多项式估计器。

Result: 谱衰减率决定了两种视角下的渐近遗憾：对核化bandit算法，它控制最大信息增益和最坏情况遗憾；对平滑方法，它建立Hölder空间嵌入和Besov空间范数等价。为每个核族推导了显式遗憾界，在某些情况下得到新结果，在其他情况下改进了分析。LP-GP-UCB算法在多个核族上达到阶最优性。

Conclusion: 核基算法和局部自适应算法可以在统一框架下分析，谱特性是连接两者的关键。混合方法LP-GP-UCB虽不总是优于专用方法，但在多个核族上保持最优性能，展示了统一框架的实际价值。

Abstract: In this work we investigate the relationship between kernel regularity and algorithmic performance in the bandit optimization of RKHS functions. While reproducing kernel Hilbert space (RKHS) methods traditionally rely on global kernel regressors, it is also common to use a smoothness-based approach that exploits local approximations. We show that these perspectives are deeply connected through the spectral properties of isotropic kernels. In particular, we characterize the Fourier spectra of the Matérn, square-exponential, rational-quadratic, $γ$-exponential, piecewise-polynomial, and Dirichlet kernels, and show that the decay rate determines asymptotic regret from both viewpoints. For kernelized bandit algorithms, spectral decay yields upper bounds on the maximum information gain, governing worst-case regret, while for smoothness-based methods, the same decay rates establish Hölder space embeddings and Besov space norm-equivalences, enabling local continuity analysis. These connections show that kernel-based and locally adaptive algorithms can be analyzed within a unified framework. This allows us to derive explicit regret bounds for each kernel family, obtaining novel results in several cases and providing improved analysis for others. Furthermore, we analyze LP-GP-UCB, an algorithm that combines both approaches, augmenting global Gaussian process surrogates with local polynomial estimators. While the hybrid approach does not uniformly dominate specialized methods, it achieves order-optimality across multiple kernel families.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [37] [On Circuit Imbalance and 0/1 Circuits for Coloring and Spanning Forest Problems](https://arxiv.org/abs/2512.05223)
*Steffen Borgwardt,Nicholas Crawford,Sean Kafer,Jon Lee,Angela Morrison*

Main category: math.OC

TL;DR: 本文分析线性规划中电路不平衡的概念，一方面证明某些图论问题结构会导致指数级电路不平衡，另一方面展示在顶点着色和最大权重森林问题中，存在解释性强的电路子集（不平衡度为1），能保证电路直径有界。


<details>
  <summary>Details</summary>
Motivation: 电路不平衡是线性规划和定向拟阵理论中的复杂性度量，与电路增强的迭代界限和电路直径相关。本文旨在分析松弛组合优化问题的线性规划公式，研究电路不平衡的两种对立结果：一方面识别导致指数不平衡的常见约束结构，另一方面展示在某些指数不平衡问题中存在解释性强的电路子集。

Method: 通过分析图论问题的线性规划公式，证明某些约束结构导致指数电路不平衡。同时，以顶点着色和最大权重森林问题为案例研究，识别具有高度解释性的电路子集（不平衡度为1），这些子集对应顶点重新着色或边的添加/移除操作，并证明限制在这些子集上的电路行走能保证可达性和有界电路直径。

Result: 1）识别出简单常见的约束结构（特别是图论问题中）会导致指数级电路不平衡；2）在顶点着色和最大权重森林这两个指数不平衡问题中，发现存在解释性强的电路子集（不平衡度为1）；3）证明限制在这些子集上的电路行走不仅能保证到达整数极点的可达性，还能分别获得线性和常数的电路直径界限。

Conclusion: 虽然某些组合优化问题的电路不平衡可能呈指数级增长，使得电路增强和电路直径研究面临挑战，但通过识别具有高度解释性的电路子集（不平衡度为1），可以在这些子集上获得良好的可达性和有界电路直径，为电路行走研究提供实用方法。

Abstract: Circuits are fundamental objects in linear programming and oriented matroid theory, representing the elementary difference vectors of a polyhedron between points in its affine space. A recent concept introduced by Ekbatani, Natura, and Végh, the circuit imbalance, serves as a complexity measure relevant to iteration bounds for circuit-based augmentation and circuit diameters, as well as the general interpretability of circuits in terms of the underlying application. In this paper, we analyze linear programming formulations of relaxed combinatorial optimization problems to prove two contrasting types of results related to the circuit imbalance.
  On one hand, we identify simple and common constraint structures, in particular arising in graph-theoretic problems, that inherently lead to an exponential circuit imbalance. These constructions show that, in quite general situations, working with the entire set of circuits poses significant challenges for an application of circuit augmentation or the study of circuit diameters.
  On the other hand, through a case study of two classic graph-theoretic problems with exponential imbalance, the vertex graph coloring problem and the maximum weight forest problem, we exhibit the existence of sets and subsets of highly interpretable circuits of (best-case) imbalance 1. These sets correspond to the recoloring of vertices or to the addition or removal of edges, respectively, for example generalizing classic concepts of Kempe dynamics in coloring. Their interpretability in terms of the underlying application facilitates a study of circuit walks in the corresponding polytopes. We prove that a restriction of circuit walks to these sets suffices to not only guarantee reachability of the integral extreme-points of the skeleton, but leads to linear and constant circuit diameter bounds, respectively.

</details>


### [38] [Entropic selection for optimal transport on the line with distance cost](https://arxiv.org/abs/2512.05282)
*Armand Ley*

Main category: math.OC

TL;DR: 研究一维距离成本下熵最优传输问题的小正则化极限，提出自然候选极限对象，在边缘分布互异时证明其收敛性


<details>
  <summary>Details</summary>
Motivation: 虽然熵最小化在离散设置和存在唯一最优传输计划时收敛性已清楚，但在其他情况下的存在性和特征描述仍基本未解决，需要填补这一研究空白

Method: 提出自然候选极限对象，基于最优传输计划的分解定理构建，在边缘分布互异时证明收敛性，对任意边缘分布证明熵最小化极限点满足弱乘性结构条件

Result: 建立了熵最小化在小正则化极限下的收敛理论，提出了候选极限对象并证明其在互异边缘分布下的收敛性，证明了任意边缘分布下极限点满足弱乘性结构

Conclusion: 该研究填补了熵最优传输小正则化极限理论的重要空白，提出的分解定理具有独立价值，补充了Di Marino和Louet的先前工作

Abstract: We study the small-regularisation limit of the entropic optimal transport problem on the line with distance cost. While convergence of entropic minimizers is well understood in the discrete setting and in the case where the cost is continuous and there is a unique optimal transport plan, the question of existence and characterization outside these settings remains largely open. We propose a natural candidate for the limiting object and establish its convergence under mutual singularity of the marginals. For arbitrary marginals, we moreover prove that every limit point of entropic minimizers obeys a structural condition known as weak multiplicativity. The construction of our candidate relies on a decomposition theorem for optimal transport plan that we believe is of independent interest. This article complements the previous work of Di Marino and Louet.

</details>


### [39] [Polyak-Łojasiewicz inequality is essentially no more general than strong convexity for $C^2$ functions](https://arxiv.org/abs/2512.05285)
*Aziz Ben Nejma*

Main category: math.OC

TL;DR: 本文证明C²类Polyak-Łojasiewicz函数在有界极小值集条件下具有唯一极小点，并在某个下水平集上是强凸的


<details>
  <summary>Details</summary>
Motivation: Polyak-Łojasiewicz不等式将强凸函数的优化性质推广到更广泛的函数类，但需要理解这类函数的本质结构特性

Method: 通过分析C²类PŁ函数的数学性质，证明在有界极小值集条件下，这类函数具有唯一极小点，并在某个下水平集上满足强凸性

Result: 证明了C² PŁ函数在有界极小值集条件下必然具有唯一极小点，且存在常数a使得在子水平集{f≤a}上是强凸的

Conclusion: PŁ函数的丰富性主要源于非光滑情况，因为足够的正则性会迫使它们本质上是强凸的，这揭示了PŁ条件与强凸性之间的深刻联系

Abstract: The Polyak-Łojasiewicz (PŁ) inequality extends the favorable optimization properties of strongly convex functions to a broader class of functions. In this paper, we show that the richness of the class of PŁ functions is rooted in the nonsmooth case since sufficient regularity forces them to be essentially strongly convex. More precisely, we prove that if $f$ is a $C^2$ PŁ function having a bounded set of minimizers, then it has a unique minimizer and is strongly convex on a sublevel set of the form $\{f\leq a\}$.

</details>


### [40] [Deep Centralization for the Circumcentered Reflection Method](https://arxiv.org/abs/2512.05324)
*Pablo Barros*

Main category: math.OC

TL;DR: ecCRM扩展了经典的cCRM方法，通过引入可容许算子T和参数α来控制计算成本和步长质量，保持全局收敛性并在特定条件下实现线性/超线性收敛。


<details>
  <summary>Details</summary>
Motivation: 经典cCRM方法中的固定中心化步骤限制了算法的灵活性，无法根据具体问题调整计算成本和步长质量。需要一种更通用的框架来平衡计算效率和收敛性能。

Method: 提出扩展中心化反射方法(ecCRM)，用可容许算子T和参数α替代cCRM的固定中心化步骤，形成更灵活的计算框架。通过控制T和α来调节计算复杂度和步长质量。

Result: ecCRM保持全局收敛性，在温和正则条件下实现线性收敛，在光滑流形上达到超线性收敛。大规模矩阵补全实验显示深层算子能显著减少总运行时间，高维椭球测试表明消失步长能带来显著加速。

Conclusion: ecCRM为两集凸可行性问题提供了更灵活高效的框架，通过算子T和参数α的调节，在实际应用中能显著提升计算效率，验证了该方法的实用价值。

Abstract: We introduce the extended centralized circumcentered reflection method (ecCRM), a framework for two-set convex feasibility that encompasses the classical centralized CRM (cCRM) of Behling, Bello-Cruz, Iusem and Santos as a special case. Our method replaces the fixed centralization step of cCRM with an admissible operator $T$ and a parameter $α$, allowing control over computational cost and step quality. We show that ecCRM retains global convergence, linear rates under mild regularity, and superlinearity for smooth manifolds. Numerical experiments on large-scale matrix completion indicate that deeper operators can dramatically reduce overall runtime, and tests on high-dimensional ellipsoids show that vanishing step sizes can yield significant acceleration, validating the practical utility of both algorithmic components of ecCRM.

</details>


### [41] [OpenSQP: A Reconfigurable Open-Source SQP Algorithm in Python for Nonlinear Optimization](https://arxiv.org/abs/2512.05392)
*Anugrah Jo Joshy,John T. Hwang*

Main category: math.OC

TL;DR: OpenSQP是一个用Python实现的模块化、可重构的序列二次规划算法，性能与主流优化器相当，但提供了更好的透明度和可定制性。


<details>
  <summary>Details</summary>
Motivation: 现有的SQP算法实现缺乏透明度和模块化，难以针对特定应用进行定制或修改，也无法轻松替换不同模块来创建新的优化器。

Method: 开发了OpenSQP，一个模块化的SQP算法框架，允许用户轻松修改或替换组件，如价值函数、线搜索过程、Hessian近似和QP求解器。

Result: 使用标准配置（平滑增广拉格朗日价值函数和BFGS拟牛顿法）在CUTEst测试集上评估，性能与SLSQP、SNOPT和IPOPT等成熟非线性优化算法相当。

Conclusion: OpenSQP提供了一个灵活、可定制的SQP框架，在保持与主流算法相当性能的同时，为特定应用需求提供了更好的可扩展性和透明度。

Abstract: Sequential quadratic programming (SQP) methods have been remarkably successful in solving a broad range of nonlinear optimization problems. These methods iteratively construct and solve quadratic programming (QP) subproblems to compute directions that converge to a local minimum. While numerous open-source and commercial SQP algorithms are available, their implementations lack the transparency and modularity necessary to adapt and fine-tune them for specific applications or to swap out different modules to create a new optimizer. To address this gap, we present OpenSQP, a modular and reconfigurable SQP algorithm implemented in Python that achieves robust performance comparable to leading algorithms. We implement OpenSQP in a manner that allows users to easily modify or replace components such as merit functions, line search procedures, Hessian approximations, and QP solvers. This flexibility enables the creation of tailored variants of the algorithm for specific needs. To demonstrate reliability, we present numerical results using the standard configuration of OpenSQP that employs a smooth augmented Lagrangian merit function for the line search and a quasi-Newton BFGS method for approximating the Hessians. We benchmark this configuration on a comprehensive set of problems from the CUTEst test suite. The results demonstrate performance that is competitive with proven nonlinear optimization algorithms such as SLSQP, SNOPT, and IPOPT.

</details>


### [42] [Stochastic Zeroth-Order Method for Computing Generalized Rayleigh Quotients](https://arxiv.org/abs/2512.05520)
*Jonas Bresch,Oleh Melnyk,Martin Schoen,Gabriele Steidl*

Main category: math.OC

TL;DR: 提出一种随机零阶黎曼算法，用于最大化广义瑞利商，无需伴随矩阵或矩阵逆运算，具有理论收敛保证和优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统计算广义瑞利商最大化的算法通常依赖矩阵-伴随乘积，容易受到伴随不匹配误差的影响。需要一种不依赖伴随或矩阵逆运算的鲁棒算法。

Method: 引入随机零阶黎曼算法，在黎曼流形上优化广义瑞利商，避免使用伴随矩阵或矩阵逆运算，仅需函数值信息。

Result: 理论证明算法以概率1收敛到广义瑞利商的全局最大化点集，收敛速度为次线性。数值实验显示算法性能优于现有先进方法。

Conclusion: 提出的随机零阶黎曼算法有效解决了伴随不匹配问题，为广义瑞利商最大化提供了理论保证且实用的解决方案。

Abstract: The maximization of the (generalized) Rayleigh quotient is a central problem in numerical linear algebra. Conventional algorithms for its computation typically rely on matrix-adjoint products, making them sensitive to errors arising from adjoint mismatches. To address this issue, we introduce a stochastic zeroth-order Riemannian algorithm that maximizes the generalized Rayleigh quotient without requiring adjoint or matrix inverse computations. We provide theoretical convergence guarantees showing that the iterates converge to the set of global maximizers of the (generalized) Rayleigh quotient at a sublinear rate with probability one. Our theoretical results are supported by numerical experiments, which demonstrate the excellent performance of the proposed method compared to state-of-the-art algorithms.

</details>


### [43] [Opportunities for Hybrid Modeling Approaches in Energy Systems optimization](https://arxiv.org/abs/2512.05585)
*Mohamed Tahar Mabrouk,Shri Balaji Padmanabhan,Bruno Lacarrière,Benoit Delinchant,Sacha Hodencq,Xavier Roboam,Bruno Sareni,Mathieu Vallee*

Main category: math.OC

TL;DR: 本文综述了能源系统优化的主要计算挑战，包括模型复杂性、算法需求和不确定性处理，并探讨了降低复杂性的技术、不确定性管理框架以及混合建模的潜力。


<details>
  <summary>Details</summary>
Motivation: 能源系统优化面临多方面的计算挑战：模型本身复杂性高、优化算法要求高、以及需要处理多种不确定性（随机性和认知性）。这些挑战使得实际应用中的计算变得困难，需要寻找平衡计算可行性和模型保真度的有效方法。

Method: 采用文献综述方法，系统分析三类复杂性来源：模型诱导复杂性、优化算法需求和不确定性处理。评估了时间序列和空间聚合、模型降阶、专用优化策略等降低复杂性的技术。回顾了基于场景的方法、鲁棒优化、分布鲁棒方法等不确定性管理框架。特别关注混合建模方法，融合机理模型和机器学习元素。

Result: 识别了不同复杂性降低技术的有效性及其在平衡计算可行性和模型保真度方面的表现。分析了各种不确定性管理框架在可扩展性和数据需求方面的局限性。发现混合建模方法能够结合机理模型和机器学习的优势，同时缓解各自的缺点，成为解决能源系统优化复杂性的关键途径。

Conclusion: 混合建模是解决能源系统优化复杂性的有前景方向，通过融合机理模型和机器学习元素，能够利用两者的优势。论文指出了多个未来研究方向，需要开发先进方法来应对多能源系统的复杂性挑战。

Abstract: This paper surveys the primary computational hurdles of Energy Systems optimization coming from different sources: model-induced complexity, optimization algorithm requirements, and uncertainties handling (both aleatoric and epistemic). Techniques to reduce complexity such as time-series and spatial aggregation, model order reduction, and specialized optimization strategies are reviewed for their effectiveness in balancing computational feasibility and model fidelity. Furthermore, Various uncertainty-management frameworks, including scenario-based approaches, robust optimization, and distributionally robust methods, are reviewed and their limitations in scaling and data requirements are discussed. The potential of hybrid modeling emerges as a key avenue: by fusing mechanistic and machine learning elements, hybrid techniques for modelling and optimization can harness the strengths of both worlds while mitigating their respective drawbacks. The paper highlights several directions for further research to develop advanced methods to tackle the complexity of MES.

</details>


### [44] [Density, Determinacy, Duality and a Regularized Moment-SOS Hierarchy](https://arxiv.org/abs/2512.05612)
*Didier Henrion*

Main category: math.OC

TL;DR: 提出一种正则化矩-SOS层次结构，用于处理无界集或违反Archimedean性质的有界集上的多项式优化问题，不依赖Putinar的Positivstellensatz，基于Carleman条件和测度确定性。


<details>
  <summary>Details</summary>
Motivation: 标准矩-SOS层次结构的收敛依赖于Putinar的Positivstellensatz，这要求可行集满足代数Archimedean性质。对于无界集或违反该性质的有界集，标准方法失效。

Method: 采用泛函分析视角，基于多元Carleman条件而非代数紧性。证明二次模的有限度投影在由测度诱导的平方范数下在正多项式锥中稠密。提出正则化层次结构和惩罚公式，结合Bernstein-Markov不等式。

Result: 证明了正则化层次结构的收敛性，无需调用任何Positivstellensatz。提供了单调非递减的全局最小值认证下界序列。在标准层次结构难以处理或病态的基准问题上进行了验证。

Conclusion: 正则化矩-SOS层次结构扩展了多项式优化问题的适用范围，能够处理无界集和违反Archimedean性质的有界集，为传统方法难以处理的问题提供了有效的解决方案。

Abstract: The standard moment-sum-of-squares (SOS) hierarchy is a powerful method for solving global polynomial optimization problems. However, its convergence relies on Putinar's Positivstellensatz, which requires the feasible set to satisfy the algebraic Archimedean property. In this paper, we introduce a regularized moment-SOS hierarchy capable of handling problems on unbounded sets or bounded sets violating the Archimedean property. Adopting a functional analysis viewpoint, we rely on the multivariate Carleman condition for measure determinacy rather than algebraic compactness. We prove that finite degree projections of the quadratic module are dense in the cone of positive polynomials with respect to the square norm induced by the measure. Based on these density results, we prove the convergence of a regularized hierarchy without invoking any Positivstellensatz. Furthermore, we propose a penalized formulation of the hierarchy which, combined with Bernstein-Markov inequalities, provides a monotonically non-decreasing sequence of certified lower bounds on the global minimum. The approach is illustrated on several benchmark problems known to be difficult or ill-posed for the standard hierarchy.

</details>


### [45] [Quantification of Errors of the Performance Estimators in the Linear-Quantized Precoding Models for Massive MIMO Systems](https://arxiv.org/abs/2512.05675)
*Jie Zhang,Huifu Xu*

Main category: math.OC

TL;DR: 该论文研究大规模MIMO系统中低分辨率DAC的量化预编码问题，推导了SINR和SEP误差界，分析了渐近与有限维场景下的SINR最大化问题，验证了渐近理论对实际系统的指导价值。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO是5G及未来无线系统的关键技术，但高分辨率DAC的高功耗和硬件成本限制了其实际应用。采用低分辨率DAC可以降低功耗和成本，但需要研究量化预编码的性能保证。

Method: 研究线性-量化预编码模型及其统计/渐近等价变体，推导SINR和SEP的误差界，分析渐近和有限维场景下的SINR最大化问题，验证渐近理论在有限维系统中的收敛性。

Result: 证明了随着系统维度扩展，有限维问题解/值收敛到渐近等价解，为低分辨率DAC的大规模MIMO系统提供了理论支撑和稳定性保证，连接了理论与实际应用。

Conclusion: 该研究为硬件约束下的鲁棒预编码设计提供了理论支持，验证了渐近预测在有限维系统中的有效性，为实际系统优化提供了实用指导框架。

Abstract: Massive MIMO (Multiple-Input Multiple-Output) is a key enabler for 5G and future wireless systems, boosting channel capacity, energy efficiency, and spectral efficiency. However, high power consumption and hardware costs of Digital-to-Analog Converters (DACs) in massive MIMO create practical challenges. To mitigate these, recent work proposes low-resolution DACs-restricting transmitted signals to finite voltage levels-to cut power and costs. This requires studying quantized precoding: signals are processed via a linear precoding matrix, then quantized by DACs. In this paper, we explore the linear-quantized precoding model and its statistically or asymptotically equivalent variants. We derive error bounds for two key metrics:Signal-to-Interference-plus-Noise Ratio (SINR) and Symbol Error Probability (SEP), based on the linear-quantized model and its equivalent counterparts. We also formulate and analyze the SINR maximization problem in both asymptotic and finite-dimensional scenarios. Our analysis shows that as system dimensions scale, finite-dimensional problem solutions/values converge to their asymptotic equivalents-underscoring the practical value of asymptotic insights with stability guarantees. These findings theoretically support robust precoding design under hardware constraints, enabling efficient massive MIMO implementation with low-resolution DACs. Beyond validating asymptotic predictions in finite regimes, our framework offers practical optimization guidelines for real-world systems, linking theory and applications.

</details>


### [46] [$α$-Potential Games for Decentralized Control of Connected and Automated Vehicles](https://arxiv.org/abs/2512.05712)
*Xuan Di,Anran Hu,Zhexin Wang,Yufei Zhang*

Main category: math.OC

TL;DR: 提出α-势博弈框架用于去中心化CAV控制，将α-纳什均衡计算转化为去中心化控制问题，并开发可扩展的策略梯度算法。


<details>
  <summary>Details</summary>
Motivation: 大规模联网自动驾驶车辆(CAV)需要可扩展且安全的控制策略，但现有动态博弈方法难以计算大规模纳什均衡，而平均场博弈近似又无法捕捉碰撞避免和异构行为。

Method: 提出α-势博弈框架，将α-纳什均衡计算转化为去中心化控制问题，基于交互强度和不对称性推导α参数的紧致边界，并开发使用去中心化神经网络策略的可扩展策略梯度算法。

Result: 数值实验表明，该框架能够适应多种交通流模型，有效捕捉碰撞避免、障碍物避免和智能体异构性。

Conclusion: α-势博弈框架为大规模CAV去中心化控制提供了一种可扩展且实用的解决方案，克服了传统博弈方法的计算挑战和限制性假设。

Abstract: Designing scalable and safe control strategies for large populations of connected and automated vehicles (CAVs) requires accounting for strategic interactions among heterogeneous agents under decentralized information. While dynamic games provide a natural modeling framework, computing Nash equilibria (NEs) in large-scale settings remains challenging, and existing mean-field game approximations rely on restrictive assumptions that fail to capture collision avoidance and heterogeneous behaviors. This paper proposes an $α$-potential game framework for decentralized CAV control. We show that computing $α$-NE reduces to solving a decentralized control problem, and derive tight bounds of the parameter $α$ based on interaction intensity and asymmetry. We further develop scalable policy gradient algorithms for computing $α$-NEs using decentralized neural-network policies. Numerical experiments demonstrate that the proposed framework accommodates diverse traffic flow models and effectively captures collision avoidance, obstacle avoidance, and agent heterogeneity.

</details>


### [47] [Taylor Approximation Variance Reduction for Approximation Errors in PDE-constrained Bayesian Inverse Problems](https://arxiv.org/abs/2512.05723)
*Ruanui Nicholson,Radoslav Vuchkov,Umberto Villa,Noemi Petra*

Main category: math.OC

TL;DR: 提出了一种可扩展的计算方法，用于降低贝叶斯近似误差（BAE）方法中采样阶段的成本，通过泰勒展开和线性化PDE求解来高效计算近似误差的均值和协方差。


<details>
  <summary>Details</summary>
Motivation: 在基于偏微分方程的大规模反问题中，代理模型常用于替代精确的参数-观测映射。贝叶斯近似误差（BAE）方法可以处理由此产生的不确定性和近似误差，但其统计特性通常需要通过蒙特卡洛采样来估计，即使离线进行也会成为计算瓶颈。

Method: 开发了一种可扩展的计算方法：1）对精确和代理前向模型进行关于不确定参数场的泰勒展开；2）将泰勒展开作为控制变量进行方差缩减，或用于高效近似近似误差的均值和协方差；3）提出基于线性化PDE求解的高效方法计算泰勒近似的均值和协方差表达式。

Result: 该方法不依赖于不确定参数的维度，而是依赖于数据的本征维度，确保了对高维问题的可扩展性。在两个高维反问题示例中展示了潜在优势：线性扩散问题中的分布式Robin边界系数估计，以及非线性扩散问题中的系数估计问题。

Conclusion: 提出的方法能够显著降低BAE方法中采样阶段的计算成本，通过泰勒展开和线性化PDE求解实现了对高维反问题的高效处理，为大规模偏微分方程反问题的贝叶斯近似误差分析提供了可扩展的解决方案。

Abstract: In numerous applications, surrogate models are used as a replacement for accurate parameter-to-observable mappings when solving large-scale inverse problems governed by partial differential equations (PDEs). The surrogate model may be a computationally cheaper alternative to the accurate parameter-to-observable mappings and/or may ignore additional unknowns or sources of uncertainty. The Bayesian approximation error (BAE) approach provides a means to account for the induced uncertainties and approximation errors (between the accurate parameter-to-observable mapping and the surrogate). The statistics of these errors are in general unknown a priori, and are thus calculated using Monte Carlo sampling. Although the sampling is typically carried out offline the process can still represent a computational bottleneck. In this work, we develop a scalable computational approach for reducing the costs associated with the sampling stage of the BAE approach. Specifically, we consider the Taylor expansion of the accurate and surrogate forward models with respect to the uncertain parameter fields either as a control variate for variance reduction or as a means to efficiently approximate the mean and covariance of the approximation errors. We propose efficient methods for evaluating the expressions for the mean and covariance of the Taylor approximations based on linear(-ized) PDE solves. Furthermore, the proposed approach is independent of the dimension of the uncertain parameter, depending instead on the intrinsic dimension of the data, ensuring scalability to high-dimensional problems. The potential benefits of the proposed approach are demonstrated for two high-dimensional inverse problems governed by PDE examples, namely for the estimation of a distributed Robin boundary coefficient in a linear diffusion problem, and for a coefficient estimation problem governed by a nonlinear diffusion problem.

</details>


### [48] [Modified global finite-time quasi-continuous second-order robust feedback control](https://arxiv.org/abs/2512.05727)
*Michael Ruderman,Denis Efimov*

Main category: math.OC

TL;DR: 本文提出了一种改进的非超调准连续滑模控制方法，通过非线性控制律修改，实现了参数化控制幅度限制、完整状态空间有限时间控制，并获得了无扰动情况下的解析解。


<details>
  <summary>Details</summary>
Motivation: 针对Ruderman和Efimov（2025）提出的非超调准连续滑模控制方法，本文旨在改进其局限性：1）实现参数化的控制幅度限制；2）扩展有限时间控制到整个状态空间R²；3）获得无扰动情况下的解析解，从而精确估计收敛时间。

Method: 提出对非线性控制律进行本质性修改，开发基于解的方法和Lyapunov函数方法，分别处理无扰动和扰动情况，并通过数值示例验证鲁棒性和收敛性分析。

Result: 成功实现了：1）在大部分初始值范围内参数化控制幅度限制；2）在整个状态空间R²实现有限时间控制；3）获得无扰动情况下的状态轨迹解析解，并能精确估计有限收敛时间。

Conclusion: 改进的控制方法不仅解决了原有方法的局限性，还为未来控制特性分析开辟了新途径，同时通过Lyapunov方法证明了扰动情况下的全局一致渐近稳定性。

Abstract: A non-overshooting quasi-continuous sliding mode control with sub-optimal damping was recently introduced in Ruderman and Efimov (2025) for perturbed second-order systems. The present work proposes an essential modification of the nonlinear control law which (i) allows for a parameterizable control amplitude limitation in a large subset of the initial values, (ii) admits an entire state-space R2 (that was not given in Ruderman and Efimov (2025)) for the finite-time control, and finally (iii) enables for the found analytic solution of the state trajectories in the unperturbed case. The latter allows also for an exact estimation of the finite convergence time, and open an avenue for other potentially interesting analysis of the control properties in the future. For a perturbed case, the solution-based and Lyapunov function-based approaches are developed to show the uniform global asymptotic stability. The proposed robustness and convergence analysis are accompanied by several illustrative numerical examples.

</details>


### [49] [Distributed Online Randomized Gradient-Free Optimization with Compressed Communication](https://arxiv.org/abs/2512.05775)
*Longkang Zhu,Xinli Shi,Xiangping Xu,Jinde Cao,Xiangyong Chen*

Main category: math.OC

TL;DR: 提出在线压缩梯度跟踪框架OCGT，解决分布式在线凸优化的通信效率和有限反馈两大挑战，包含单点反馈和随机梯度反馈两种变体


<details>
  <summary>Details</summary>
Motivation: 解决分布式在线凸优化中的两个基本挑战：通信效率和有限反馈下的优化。传统方法假设完美通信和完整梯度访问，但在实际分布式系统中通信带宽有限且只能获得部分反馈信息

Method: 提出在线压缩梯度跟踪框架OCGT，包含两种变体：OCGT-BF（单点反馈）和OCSGT（随机梯度反馈）。采用带误差补偿机制的压缩方案减少通信开销，结合梯度类跟踪与单点或随机梯度反馈估计技术

Result: 理论分析证明了两种变体的动态遗憾界，实验验证OCGT在实现低动态遗憾的同时显著降低通信需求

Conclusion: OCGT框架为分布式在线凸优化提供了一种统一的解决方案，在通信效率和有限反馈约束下仍能保持收敛保证，具有实际应用价值

Abstract: This paper addresses two fundamental challenges in distributed online convex optimization: communication efficiency and optimization under limited feedback. We propose a unified framework named Online Compressed Gradient Tracking (OCGT), which includes two variants: One-point Bandit Feedback (OCGT-BF) and Stochastic Gradient Feedback (OCSGT). The proposed algorithms harness data compression and either gradient-free or stochastic gradient optimization techniques within distributed networks. The proposed framework incorporates a compression scheme with error compensation mechanisms to reduce communication overhead while maintaining convergence guarantees. Unlike traditional approaches that assume perfect communication and full gradient access, OCGT operates effectively under practical constraints by combining gradient-like tracking with one-point or stochastic gradient feedback estimation. We provide a theoretical analysis demonstrating dynamic regret bounds for both variants. Finally, extensive experiments validate that OCGT achieves low dynamic regret while significantly reducing communication requirements.

</details>


### [50] [Stochastic Passivity in Stochastic Differential Equations: A Port-Hamiltonian Perspective](https://arxiv.org/abs/2512.05838)
*Julia Ackermann,Thomas Kruse,Stefan Tappe*

Main category: math.OC

TL;DR: 将确定性端口哈密顿系统扩展到随机框架，开发随机输入-状态-输出系统的无源性概念，并研究一类线性随机系统的特性


<details>
  <summary>Details</summary>
Motivation: 扩展确定性端口哈密顿系统到随机框架，因为耗散不等式在确定性系统中起关键作用，需要在随机系统中建立相应的无源性概念

Method: 使用随机微分方程扩展确定性端口哈密顿系统，为随机输入-状态-输出系统开发多种无源性概念，并用系统参数表征这些概念

Result: 建立了随机系统的无源性概念框架，并研究了一类线性随机系统的特性，这类系统可视为确定性端口哈密顿系统在随机无源性框架下的扩展

Conclusion: 成功将端口哈密顿系统扩展到随机框架，为随机系统建立了无源性分析的理论基础，为线性随机端口哈密顿系统的研究提供了框架

Abstract: We extend deterministic port-Hamiltonian systems (PHS) to a stochastic framework by means of stochastic differential equations. As the dissipation inequality plays a crucial role for deterministic PHS, we develop several passivity concepts for stochastic input-state-output systems and characterize these in terms of the parameters of the system. Afterwards, we examine properties of a certain class of linear stochastic systems that can be regarded as an extension of linear deterministic PHS to a stochastic passivity framework.

</details>


### [51] [Numerically Reliable Brunovsky Transformations](https://arxiv.org/abs/2512.05910)
*Shaohui Yang,Colin N. Jones*

Main category: math.OC

TL;DR: 提出一种计算Brunovsky标准形的数值稳定方法，通过正交变换、线性参数化和条件数优化，显著降低构造误差并改善数值条件。


<details>
  <summary>Details</summary>
Motivation: Brunovsky标准形在计算最优控制中具有稀疏结构优势，但现有方法计算不可靠，需要更稳定、误差更小的计算方法。

Method: 首先通过正交相似变换将可控线性系统化为阶梯形，然后推导得到Brunovsky标准形的简单线性参数化表示，应用死区增益提高数值稳定性，并优化线性参数以最小化条件数。

Result: 该方法能产生构造误差显著降低、条件数改善的Brunovsky变换，比现有方法更可靠。

Conclusion: 提出的技术为计算Brunovsky标准形提供了数值稳定、误差小的可靠方法，对计算最优控制应用有重要价值。

Abstract: The Brunovsky canonical form provides sparse structural representations that are beneficial for computational optimal control, yet existing methods fail to compute it reliably. We propose a technique that produces Brunovsky transformations with substantially lower construction errors and improved conditioning. A controllable linear system is first reduced to staircase form via an orthogonal similarity transformation. We then derive a simple linear parametrization of the transformations yielding the unique Brunovsky form. Numerical stability is further enhanced by applying a deadbeat gain before computing system matrix powers and by optimizing the linear parameters to minimize condition numbers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [52] [Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN](https://arxiv.org/abs/2512.05122)
*Unnikrishnan Radhakrishnan*

Main category: cs.AI

TL;DR: 论文提出一个基于LLM的对话助手，帮助中小企业将隐性知识转化为标准BPMN流程图，降低流程文档化的技能和成本门槛。


<details>
  <summary>Details</summary>
Motivation: 中小企业依赖隐性经验知识，很少形成正式文档，导致机构知识流失、运营透明度低、持续改进困难。需要降低流程文档化的技能和成本门槛。

Method: 使用Gemini 2.5 Pro LLM驱动的对话助手，通过Gradio前端和bpmn-js可视化，进行访谈式对话，实时生成和精炼BPMN 2.0流程图。

Result: 在设备维护场景的概念验证中，聊天机器人在约12分钟内生成准确的"现状"模型，通过图上标注标记问题，并生成改进的"未来"变体，API成本控制在中小企业友好预算内。

Conclusion: 对话式LLM能有效降低流程文档化的技能和成本障碍，帮助中小企业保存机构知识、提高运营透明度、加速持续改进，未来可向智能体和多模态部署发展。

Abstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures such knowledge on the shop floor and converts it incrementally and interactively into standards-compliant Business Process Model and Notation (BPMN) 2.0 diagrams. Powered by Gemini 2.5 Pro and delivered through a lightweight Gradio front-end with client-side bpmn-js visualisation, the assistant conducts an interview-style dialogue: it elicits process details, supports clarifying dialogue and on-demand analysis, and renders live diagrams that users can refine in real time. A proof-of-concept evaluation in an equipment-maintenance scenario shows that the chatbot produced an accurate "AS-IS" model, flagged issues via on-diagram annotations, and generated an improved "TO-BE" variant, all within about 12-minutes, while keeping API costs within an SME-friendly budget. The study analyses latency sources, model-selection trade-offs, and the challenges of enforcing strict XML schemas, then outlines a roadmap toward agentic and multimodal deployments. The results demonstrate that conversational LLMs can potentially be used to lower the skill and cost barriers to rigorous process documentation, helping SMEs preserve institutional knowledge, enhance operational transparency, and accelerate continuous-improvement efforts.

</details>


### [53] [Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations](https://arxiv.org/abs/2512.05156)
*Igor Halperin*

Main category: cs.AI

TL;DR: 该论文提出两种基于信息论和热力学的无监督指标来评估大语言模型的任务忠实度：语义忠实度（SF）和语义熵产生（SEP）。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型对给定任务的忠实度是一个复杂挑战，需要新的无监督评估指标来量化模型是否忠实于上下文信息。

Method: 将LLM视为二分信息引擎，隐藏层作为麦克斯韦妖控制上下文到答案的转换。将QCA三元组建模为共享主题的概率分布，使用转移矩阵Q和A分别表示查询目标和实际结果，通过KL散度优化计算语义忠实度，并推导语义熵产生指标。

Result: 提出的SF和SEP指标能够有效评估LLM的忠实度，高忠实度通常对应低熵产生。在SEC 10-K文件摘要任务中验证了框架的有效性。

Conclusion: 基于信息论和热力学的SF和SEP指标为LLM忠实度评估和幻觉控制提供了有效的无监督方法，可单独或联合使用。

Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\bf Q}$ and ${\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.

</details>


### [54] [Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education](https://arxiv.org/abs/2512.05167)
*Fang Li*

Main category: cs.AI

TL;DR: 提出一种创新的AI与数据科学教学法，系统性地将传统机器学习与现代大语言模型相结合，通过两部分课程结构帮助学生全面理解AI发展并掌握实用技能。


<details>
  <summary>Details</summary>
Motivation: 为了帮助学生全面理解人工智能的发展历程，同时掌握传统机器学习技术和现代大语言模型应用，更好地适应快速发展的AI行业需求。

Method: 采用两部分课程结构：第一部分教授基础机器学习概念，第二部分专注于当代大语言模型应用。课程为期14周（两个7周学期），包含详细的课程架构、实施策略和评估方法。

Result: 该综合教学方法增强了学生对AI领域的理解，更好地为他们应对行业需求做好准备，在夏季课程实施中取得了积极的学习成果。

Conclusion: 这种将传统机器学习与现代LLM相结合的教学方法能有效提升学生对AI领域的全面理解，为他们在快速发展的AI行业中取得成功提供更好的准备。

Abstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.

</details>


### [55] [On the Computability of Artificial General Intelligence](https://arxiv.org/abs/2512.05212)
*Georgios Mappouras,Charalambos Rossides*

Main category: cs.AI

TL;DR: 论文证明任何算法（包括AI模型）都无法产生真正的新功能能力，只能展示已有功能能力的组合与排列，因此无法实现真正的创造力。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，人们开始探讨人类何时能开发出达到人类智能水平的AGI。本文旨在通过定义AGI并分析计算的根本限制，来回答这个问题。

Method: 采用前人关于AGI的定义（在某个领域展现创造力并解锁新功能能力的能力），然后通过形式化证明来建立计算的上限。

Result: 形式化证明表明：任何算法都无法展示初始算法本身不具备的新功能能力。AI模型只能展示现有功能能力及其组合与排列，无法实现真正的创造力。

Conclusion: 该证明对AI发展的未来和人类智能的起源都有重要启示：AI无法实现真正的创造力，这促使我们重新思考人类智能的本质和起源。

Abstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.

</details>


### [56] [Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence](https://arxiv.org/abs/2512.05257)
*Bychkov Oleksii,Bychkova Sophia,Lytvynchuk Khrystyna*

Main category: cs.AI

TL;DR: 本文论证可能性理论能从根本上解决Dempster-Shafer理论(DST)的悖论，通过可能性与必要性测度的二元框架提供逻辑一致的不确定性处理基础。


<details>
  <summary>Details</summary>
Motivation: DST在处理不确定性时存在悖论和逻辑陷阱，需要寻找根本性解决方案。本文旨在证明可能性理论不仅是一种替代方案，而是能从根本上解决DST悖论的理论基础。

Method: 采用Bychkov文章中发展的公理化方法，基于可能性与必要性测度的二元框架从头构建逻辑一致且数学严谨的不确定性处理基础。通过比较分析概率、证据和可能性三种范式，并以经典医疗诊断困境为例进行说明。

Result: 可能性理论能够正确处理矛盾数据，避免DST的逻辑陷阱，使形式推理更接近自然智能的逻辑。它提供了比单纯修正Dempster规则更根本的解决方案。

Conclusion: 可能性理论为不确定性处理提供了逻辑一致且数学严谨的基础，是解决DST悖论的根本性方案，而非仅仅是替代方案。

Abstract: This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.

</details>


### [57] [AI & Human Co-Improvement for Safer Co-Superintelligence](https://arxiv.org/abs/2512.05356)
*Jason Weston,Jakob Foerster*

Main category: cs.AI

TL;DR: 论文主张以"共同改进"替代"自我改进"作为AI发展目标，强调人类与AI协作实现共同超智能，而非AI单方面自我提升。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域追求自我改进充满危险且难以实现，需要更可行、更安全的目标。作者认为人类与AI协作研究AI本身，既能加速AI研究，又能通过共生关系实现更安全的超智能。

Method: 提出"共同改进"框架，让AI系统与人类研究者协作进行AI研究，从构思到实验的完整研究循环，特别强调将人类研究能力提升纳入循环中。

Result: 通过人类与AI的协作研究，既能加速AI研究进程，又能通过共生关系实现更安全的超智能发展，避免单纯AI自我改进的风险。

Conclusion: 共同改进是比自我改进更可行、更安全的目标，通过人类与AI的协作研究循环，能够更快、更安全地实现共同超智能。

Abstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.

</details>


### [58] [MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare](https://arxiv.org/abs/2512.05365)
*Zag ElSayed,Craig Erickson,Ernest Pedapati*

Main category: cs.AI

TL;DR: MCP-AI是一种基于模型上下文协议的新型医疗AI架构，支持长期状态管理、可验证工作流和临床逻辑，相比传统CDSS和提示型LLM有显著创新。


<details>
  <summary>Details</summary>
Motivation: 传统医疗AI系统在整合上下文推理、长期状态管理和人类可验证工作流方面存在挑战，随着医疗系统日益复杂，迫切需要自主、上下文感知的临床推理框架。

Method: 提出MCP-AI架构，基于模型上下文协议（MCP），通过模块化、可执行的规范来协调生成式和描述性AI代理在实时工作流中的运作。每个MCP文件捕获临床目标、患者上下文、推理状态和任务逻辑，形成可重用和可审计的内存对象。

Result: 通过两个用例验证：1）脆性X综合征伴抑郁的诊断建模；2）2型糖尿病和高血压的远程协调。系统支持医生在环验证、简化临床流程，并保证AI责任在医疗提供者之间的安全转移。

Conclusion: MCP-AI为即将到来的临床环境提供了可扩展、可解释、可组合且安全导向的AI基础，连接HL7/FHIR接口并符合HIPAA和FDA SaMD等监管标准。

Abstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.

</details>


### [59] [ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications](https://arxiv.org/abs/2512.05371)
*Changwen Xing,SamZaak Wong,Xinlai Wan,Yanfeng Lu,Mengli Zhang,Zebin Ma,Lei Qi,Zhengxiong Li,Nan Guan,Zhe Jiang,Xi Wang,Jun Yang*

Main category: cs.AI

TL;DR: ChipMind是一个基于知识图谱增强的推理框架，专门针对集成电路规格文档的长文本处理，通过构建领域知识图谱和自适应检索机制，显著提升了LLM在硬件设计中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在集成电路开发自动化方面潜力巨大，但实际部署受到上下文窗口限制的制约。现有的上下文扩展方法难以对复杂电路规格进行有效的语义建模和多跳推理。

Method: ChipMind采用知识图谱增强推理框架：1) 通过电路语义感知知识图谱构建方法将电路规格转换为领域知识图谱ChipKG；2) 使用ChipKG增强推理机制，结合信息论自适应检索动态追踪逻辑依赖关系，以及意图感知语义过滤去除无关噪声。

Result: 在工业级规格推理基准测试中，ChipMind显著优于现有最先进方法，平均提升34.59%，最高提升达72.73%。

Conclusion: 该框架填补了LLM辅助硬件设计学术研究与实际工业部署之间的关键空白，为集成电路开发自动化提供了实用的解决方案。

Abstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).

</details>


### [60] [BEAVER: An Efficient Deterministic LLM Verifier](https://arxiv.org/abs/2512.05439)
*Tarun Suresh,Nalin Wadhwa,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.AI

TL;DR: BEAVER是首个为LLM约束满足提供确定性、可靠概率边界的实用框架，相比基线方法能获得6-8倍更紧的概率边界，识别3-4倍更多高风险实例。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从研究原型转向生产系统，需要可靠方法来验证模型输出是否满足约束要求。基于采样的估计只能提供模型行为的直觉，无法提供可靠保证。

Method: BEAVER使用新颖的token trie和frontier数据结构，系统性地探索生成空间，对任何前缀封闭的语义约束都能在每次迭代中保持可证明可靠的概率边界。

Result: 在正确性验证、隐私验证和安全代码生成任务中，BEAVER在相同计算预算下比基线方法获得6-8倍更紧的概率边界，识别3-4倍更多高风险实例。

Conclusion: BEAVER框架能够提供松散边界或经验评估无法实现的精确特征描述和风险评估，为LLM约束满足提供了首个实用的确定性验证方法。

Abstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.

</details>


### [61] [The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems](https://arxiv.org/abs/2512.05449)
*Robert Yang*

Main category: cs.AI

TL;DR: 论文提出用"意志薄弱"(akrasia)概念分析AI系统的不一致性，开发了Akrasia基准测试来衡量模型在诱惑下违背自身承诺的程度，为理解智能体行为提供了哲学心理学框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型表现出一种特殊的不一致性：它们"知道"正确答案但无法据此行动。这种全局判断与局部冲动之间的张力在人类哲学中被称为"意志薄弱"(akrasia)。作者认为这一概念对于分析智能AI系统中的不一致性和目标漂移具有基础性意义。

Method: 提出了Akrasia基准测试的初步版本，包含四种结构化提示条件：基线(B)、同义词(S)、时间(T)和诱惑(X)。该基准能够量化比较不同模型家族、解码策略和诱惑类型下的"自我控制"能力。还探讨了微观层面的意志薄弱如何在多智能体系统中累积为宏观层面的不稳定性。

Result: 建立了可量化测量模型"意志薄弱"程度的基准框架，能够比较不同模型在面临诱惑时违背自身承诺的程度。该框架为理解智能体行为提供了实证桥梁。

Conclusion: 通过将不一致性重新定义为意志薄弱，这项工作将智能体行为与经典的能动性理论联系起来，为哲学、心理学和新兴的智能AI科学之间建立了实证桥梁，为分析多智能体系统中的"阴谋"或故意错位行为提供了新视角。

Abstract: Large language models display a peculiar form of inconsistency: they "know" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of "self-control" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as "scheming" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.

</details>


### [62] [MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models](https://arxiv.org/abs/2512.05530)
*Chuang Yu,Jinmiao Zhao,Mingxuan Zhao,Yunpeng Liu,Xiujun Shu,Yuanhao Feng,Bo Wang,Xiangyu Yue*

Main category: cs.AI

TL;DR: MIND框架通过"理解->反思->修正"的认知过程，将MLLMs从被动模仿推理转变为主动判别推理，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在推理任务中存在多理性语义建模有限、逻辑鲁棒性不足、易受复杂场景误导等问题，需要提升其认知能力。

Method: 提出MIND推理框架：1)RAD范式自动生成多样理性扩展数据集；2)P2CL策略分两阶段增强多理性正向学习和主动逻辑判别修正；3)MCA优化策略通过对比对齐解决多理性语义空间表示纠缠问题。

Result: 在科学、常识和数学等多个公开数据集上实现了最先进的性能表现。

Conclusion: MIND框架为推进MLLMs向更高层次认知智能发展提供了新视角，实现了从被动模仿到主动判别推理的范式演进。

Abstract: Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of "Understand -> Rethink -> Correct", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND

</details>


### [63] [CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning](https://arxiv.org/abs/2512.05576)
*Ting-Ting Xie,Yixin Zhang*

Main category: cs.AI

TL;DR: 提出Executor-Analyst框架解决临床AI的上下文利用失败问题，通过分离工具执行与临床推理，采用分层集成策略，在无需昂贵微调下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于小语言模型的临床代理（如TxAgent）存在"上下文利用失败"问题：模型能成功检索生物医学证据，但无法基于这些信息进行诊断推理。

Method: 提出Executor-Analyst框架，将工具执行的语法精度与临床推理的语义鲁棒性解耦。使用专门的TxAgent作为执行器，长上下文基础模型作为分析师，采用分层集成策略而非全局池化来保持证据多样性。

Result: 在CURE-Bench上实现最先进性能，无需昂贵的端到端微调。发现两个关键扩展洞察：1) 上下文-性能悖论（超过12k token会引入噪声降低准确性）；2) 动作空间的维度诅咒（工具集扩展需要分层检索策略）。

Conclusion: 该方法展示了无需训练的架构工程的潜力，为下一代可信赖的AI驱动治疗提供了可扩展、敏捷的基础。

Abstract: Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.

</details>


### [64] [Ontology Learning with LLMs: A Benchmark Study on Axiom Identification](https://arxiv.org/abs/2512.05594)
*Roos M. Bakker,Daan L. Di Scala,Maaike H. T. de Boer,Stephan A. Raaijmakers*

Main category: cs.AI

TL;DR: 论文提出OntoAxiom基准测试，系统评估LLMs在识别本体公理（如子类、不相交、子属性等）方面的性能，发现Axiom-by-Axiom提示策略优于直接方法，但性能因公理类型和本体领域而异。


<details>
  <summary>Details</summary>
Motivation: 本体开发需要大量建模和领域专业知识，自动化这一过程的本体学习在NLP技术特别是LLMs发展下取得进展。本研究旨在解决识别公理（定义类与属性间逻辑关系的基本本体组件）的挑战。

Method: 引入OntoAxiom基准测试，包含9个中等规模本体共17,118个三元组和2,771个公理。评估12个LLMs在三种few-shot设置和两种提示策略下的表现：直接查询所有公理 vs 逐个公理查询。关注子类、不相交、子属性、定义域和值域公理。

Result: Axiom-by-Axiom提示策略比直接方法获得更高F1分数。性能因公理类型而异，某些公理更难识别。领域影响显著（如FOAF本体子类公理得分0.642，音乐本体仅0.218）。大模型优于小模型，但小模型在资源受限场景仍可用。

Conclusion: 虽然LLMs性能不足以完全自动化公理识别，但能为本体工程师提供有价值的候选公理，支持本体开发和精化。Axiom-by-Axiom策略更有效，但性能受公理类型和本体领域影响。

Abstract: Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.

</details>


### [65] [Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting](https://arxiv.org/abs/2512.05619)
*Menghua Jiang,Haokai Gao,Shuhao Chen,Yin Chen*

Main category: cs.AI

TL;DR: 提出DeepDist SLS求解器，通过区分PMS和WPMS的权重更新策略、新初始化方法和优先满足硬子句的decimation方法，在MaxSAT评测中超越现有最佳求解器。


<details>
  <summary>Details</summary>
Motivation: 现有(W)PMS的随机局部搜索算法主要关注子句权重方案设计，但未能充分区分PMS和WPMS，通常采用统一的权重更新策略，忽略了两种问题类型的关键结构差异。

Method: 1) 首次提出根据不同条件更新PMS和WPMS子句权重的权重方案；2) 引入适应两种实例类型特点的新初始化方法；3) 提出优先满足单元子句和硬子句的decimation方法；4) 基于这些方法开发DeepDist SLS求解器。

Result: 在最近MaxSAT评测的基准测试中，DeepDist优于最先进的SLS求解器。与TT-Open-WBO-Inc结合的混合求解器超越了MaxSAT Evaluation 2024的获胜者SPB-MaxSAT-c-Band和SPB-MaxSAT-c-FPS。

Conclusion: 提出的方法有效解决了现有(W)PMS求解器未能区分问题类型的问题，DeepDist展示了优越性能，其混合版本甚至超越了评测冠军，证明了方法的有效性。

Abstract: Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist

</details>


### [66] [KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books](https://arxiv.org/abs/2512.05734)
*Jinfeng Zhong,Emmanuel Bacry,Agathe Guilloux,Jean-François Muzy*

Main category: cs.AI

TL;DR: KANFormer：结合KANs、Dilated Causal CNN和Transformer的深度学习模型，用于预测限价单的成交时间，整合市场级和代理级信息，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅依赖限价订单簿的快照序列，忽略了与LOB动态相关的代理行为以及订单在队列中的位置，无法有效捕捉执行可能性的模式。需要结合更丰富的市场信号和表达性强的神经网络架构来提高预测准确性和可解释性。

Method: KANFormer结合了Dilated Causal Convolutional网络和Transformer编码器，并采用Kolmogorov-Arnold Networks（KANs）增强非线性逼近能力。模型整合了市场级信息（LOB动态）和代理级信息（代理行为、订单队列位置），使用SHAP进行特征重要性随时间变化的分析。

Result: 在CAC 40指数期货数据上的评估显示，KANFormer在校准指标（右删失对数似然、综合Brier分数）和区分指标（C指数、时间依赖AUC）上均优于现有工作。SHAP分析揭示了特征重要性随时间变化的模式。

Conclusion: 结合丰富的市场信号和表达性强的神经网络架构能够实现准确且可解释的成交概率预测。KANFormer通过整合市场级和代理级信息，在限价单成交时间预测任务上取得了显著改进。

Abstract: This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.

</details>


### [67] [A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning](https://arxiv.org/abs/2512.05753)
*Wencheng Cai,Xuchao Gao,Congying Han,Mingqiang Li,Tiande Guo*

Main category: cs.AI

TL;DR: 提出FARDA框架，使用深度强化学习快速部署认知雷达对抗干扰，比进化算法快约7000倍，覆盖效果相当。


<details>
  <summary>Details</summary>
Motivation: 现代战争中快速部署认知雷达对抗干扰是关键挑战，现有进化算法耗时且易陷入局部最优，需要更高效的方法。

Method: 将雷达部署问题建模为端到端任务，设计深度强化学习算法，开发集成神经模块感知热图信息，并设计新的奖励格式。

Result: 实验结果显示，FARDA方法达到与进化算法相当的覆盖效果，同时部署速度提升约7000倍。消融实验验证了各组件必要性。

Conclusion: FARDA框架通过深度强化学习有效解决了认知雷达快速部署问题，显著提升了部署效率，为现代战争中的反干扰雷达部署提供了新方案。

Abstract: The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.

</details>


### [68] [Evolutionary System 2 Reasoning: An Empirical Proof](https://arxiv.org/abs/2512.05760)
*Zeyuan Ma,Wenqi Huang,Guo-Huan Song,Hongshu Guo,Sijie Ma,Zhiguang Cao,Yue-Jiao Gong*

Main category: cs.AI

TL;DR: 提出进化推理优化框架，通过进化算法提升大语言模型的系统2推理能力，发现GPT-5等最新模型推理能力有限，但通过简单进化循环可显著增强较弱模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在特定任务上表现出色，但在通用智能和系统2推理能力方面仍有不足。研究旨在探索机器智能能否像人类一样进化获得推理能力，而不仅仅是特定技能。

Method: 提出进化推理优化框架：1) 初始化多个LLM作为种群；2) 使用进化策略优化种群，最大化最佳个体的量化推理分数；3) 通过适者生存原则搜索具有强推理能力的个体。

Result: 两个重要发现：1) GPT-5等最新LLM仍表现出有限的系统2推理能力；2) 通过简单的ERO进化循环，相对较弱的模型（如Qwen-7B）可显著增强推理能力。

Conclusion: 进化推理优化框架能有效提升LLM的推理能力，为机器智能获得人类式推理能力提供了可行路径，代码已开源供复现。

Abstract: Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.

</details>


### [69] [The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics](https://arxiv.org/abs/2512.05765)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 论文提出UCCT理论，认为LLMs不是AGI的死胡同，而是需要System-2协调层来选择和约束System-1模式匹配，并设计了MACI架构实现这一协调机制。


<details>
  <summary>Details</summary>
Motivation: 针对"LLMs只是模式匹配器，无法真正推理"的批评，作者认为问题不在于LLMs本身，而在于缺乏一个协调层来选择和约束这些模式。当前LLMs缺乏System-2的协调能力，导致无法进行真正的推理和规划。

Method: 提出UCCT（语义锚定理论），将推理建模为相变过程，由有效支持度、表征失配和自适应锚定预算三个参数控制。基于此设计了MACI协调栈，包含诱饵（行为调制辩论）、过滤（苏格拉底式评判）和持久性（事务性记忆）三个组件。

Result: 理论框架将常见的反对意见重新解释为可测试的协调失败，而非LLMs的根本缺陷。MACI架构为实现LLMs上的System-2协调提供了具体实现路径。

Conclusion: 通往AGI的道路应该通过增强LLMs的协调能力来实现，而不是绕过LLMs。LLMs提供了必要的System-1基础，加上System-2协调层就能实现真正的推理能力。

Abstract: Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: "mere pattern matchers" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while "reasoning" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.

</details>


### [70] [Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma](https://arxiv.org/abs/2512.05824)
*Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot*

Main category: cs.AI

TL;DR: 提出多模态肿瘤智能体(MOA)，整合TITAN基础模型的病理学工具与临床基因组数据推理，用于低级别胶质瘤IDH1突变预测，性能优于临床和病理学基线方法。


<details>
  <summary>Details</summary>
Motivation: IDH1突变在低级别胶质瘤中具有重要临床意义，能定义不同的预后和治疗亚组。当前需要更准确的预测方法来整合多模态信息，包括病理学特征、临床数据和基因组信息。

Method: 开发多模态肿瘤智能体(MOA)，整合基于TITAN基础模型的病理学工具进行IDH1突变预测，同时通过PubMed、Google Search和OncoKB对结构化临床和基因组输入进行推理。在TCGA-LGG队列的488名患者上进行评估。

Result: MOA无病理学工具时F1分数为0.826，优于临床基线(0.798)。融合病理学特征后，MOA达到最高性能，F1分数为0.912，超过病理学基线(0.894)和融合病理学-临床基线(0.897)。

Conclusion: MOA通过整合外部生物医学资源，捕获了互补的突变相关信息，实现了准确的IDH1突变预测，展示了多模态智能体在肿瘤学中的潜力。

Abstract: Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.

</details>


### [71] [Using Large Language Models to Create Personalized Networks From Therapy Sessions](https://arxiv.org/abs/2512.05836)
*Clarissa W. Ong,Hiba Arnaout,Kate Sheehan,Estella Fox,Eugen Owtscharow,Iryna Gurevych*

Main category: cs.AI

TL;DR: 利用LLMs从治疗记录自动生成客户心理网络，支持个性化治疗规划，专家评估显示90%偏好该方法


<details>
  <summary>Details</summary>
Motivation: 个性化治疗需要基于心理网络，但传统方法需要密集纵向数据，难以规模化。LLMs为解决这一问题提供了可能性，可以从治疗记录中自动提取心理过程并构建网络

Method: 端到端流程：1) 标注77份治疗记录中的3364个心理过程及维度；2) 使用上下文学习联合识别心理过程及其维度；3) 两步法将过程分组为临床有意义的簇；4) 生成解释增强的簇间关系

Result: 方法在少量训练样本下表现优异，专家评估显示：90%偏好多步方法而非直接提示；网络在临床相关性、新颖性和有用性方面得分72-75%；网络支持自下而上的个案概念化和潜在主题识别

Conclusion: 研究证明了使用LLMs从治疗记录创建临床相关网络的可行性，该方法具有可扩展性，可用于临床设置、督导和培训。未来研究应比较该方法与传统统计网络在改善治疗结果方面的效果

Abstract: Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.

</details>


### [72] [To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis](https://arxiv.org/abs/2512.05925)
*Federico Bianchi,Yongchan Kwon,Zachary Izzo,Linjun Zhang,James Zou*

Main category: cs.AI

TL;DR: 使用GPT-5开发的论文正确性检查器发现，顶级AI会议和期刊发表的论文中存在可观数量的客观错误，且错误数量随时间增加，AI检查器能高精度识别错误并提出修正建议。


<details>
  <summary>Details</summary>
Motivation: 同行评审出版物是构建新研究和知识的基础，但文献中持续存在的错误会传播并造成混淆，影响后续研究和可复现性。研究加速和同行评审系统压力使错误更难被发现和避免。

Method: 开发基于GPT-5的论文正确性检查器，系统识别顶级AI会议和期刊已发表论文中的客观错误（如公式、推导、计算、图表错误），排除主观考量。通过人类专家验证AI识别错误的准确性。

Result: 发表论文包含显著数量的客观错误，且每篇论文平均错误数随时间增加：NeurIPS从2021年的3.8个增至2025年的5.9个（增长55.3%）；ICLR从2018年的4.1个增至2025年的5.2个；TMLR从2022/23年的5.0个增至2025年的5.5个。AI检查器识别错误的精确度达83.2%，并能对75.8%的错误提出正确修正。

Conclusion: 前沿大语言模型在检测和修正已发表论文客观错误方面具有巨大潜力，有助于建立更坚实的知识基础，减少文献混淆并增强可复现性。

Abstract: How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.

</details>


### [73] [PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation](https://arxiv.org/abs/2512.05930)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: PRiSM是一个用于评估视觉语言模型在科学领域（物理和数学）推理能力的动态多模态基准测试，包含24,750个大学水平问题，通过Python代码生成和验证，提供细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估科学领域的视觉语言模型时存在不足，缺乏中间推理步骤、对变体的鲁棒性以及验证科学正确性的机制。科学领域需要概念理解、符号推理和遵守形式化定律，这些要求现有基准测试未能满足。

Method: 提出PRiSM基准测试，包含24,750个大学水平的物理和数学问题。使用PrismAgent代理流水线生成结构化问题实例，每个问题包含动态文本和视觉输入、生成的图像，以及丰富的结构化输出：用于真实值生成和验证的可执行Python代码，以及详细的逐步推理步骤。

Result: PRiSM基准测试的动态特性和Python驱动的自动真实值生成能力，能够对多模态视觉语言模型进行细粒度实验审计，揭示失败模式、不确定性行为和科学推理的局限性。提出了五个针对性评估任务。

Conclusion: PRiSM基准测试能够深入洞察视觉语言模型的科学推理能力，通过全面评估现有模型，突显了它们的局限性，并为科学领域的模型评估提供了更强大的工具。

Abstract: Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.

</details>


### [74] [TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.05943)
*Shima Imani,Seungwhan Moon,Lambert Mathias,Lu Zhang,Babak Damavandi*

Main category: cs.AI

TL;DR: TRACE框架通过辅助推理集(ARS)分解复杂问题，评估推理轨迹而非仅最终答案，使用一致性指标诊断推理错误，并定义置信区间区分可靠与不可靠推理路径。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在可靠数学和科学推理方面仍面临挑战，标准最终答案评估往往掩盖推理错误，导致无声故障持续存在。

Method: 引入TRACE框架，利用辅助推理集(ARS)将复杂问题分解为子问题-答案对，通过基于一致性的指标评估中间步骤，暴露标准评估忽略的故障。

Result: 实验表明，ARS间的一致性与最终答案正确性相关，能精确定位推理失败步骤，为模型改进提供可操作信号。TRACE定义的置信区间能区分可靠与不可靠推理路径。

Conclusion: TRACE框架通过透明推理和一致性评估，有效诊断推理轨迹，支持模型过滤、调试和优化，解决了标准评估掩盖推理错误的问题。

Abstract: Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.

</details>


### [75] [Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem](https://arxiv.org/abs/2512.05946)
*Truong Thanh Hung Nguyen,Truong Thinh Nguyen,Hung Cao*

Main category: cs.AI

TL;DR: VQR-DQN将变分量子电路与Rainbow DQN结合，用于人力资源分配问题，相比经典方法减少26.8%完工时间，性能提升4.9-13.4%


<details>
  <summary>Details</summary>
Motivation: 资源分配问题是NP难问题，传统深度强化学习方法受限于经典函数逼近器的表示能力，需要探索量子计算的优势来提升性能

Method: 提出VQR-DQN，将环形拓扑变分量子电路与Rainbow DQN集成，利用量子叠加和纠缠特性，将人力资源分配问题建模为马尔可夫决策过程

Result: 在四个人力资源分配基准测试中，VQR-DQN相比随机基线减少26.8%归一化完工时间，优于Double DQN和经典Rainbow DQN 4.9-13.4%

Conclusion: 量子增强的深度强化学习在大规模资源分配中具有潜力，电路表达能力、纠缠与策略质量之间存在理论联系

Abstract: Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.

</details>


### [76] [SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code](https://arxiv.org/abs/2512.05954)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: SymPyBench是一个包含15,045个大学物理问题的大规模合成基准，支持无限参数配置，提供结构化推理步骤和可执行代码，包含三种问题类型和三个新颖评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有科学推理基准通常规模有限、静态且缺乏多样性，难以全面评估语言模型在科学问题解决中的能力。需要动态、可参数化的基准来测试模型在不同问题变体上的表现和鲁棒性。

Method: 创建包含15,045个大学物理问题的合成基准，每个问题完全参数化，支持无限输入配置。包含三种问题类型：MC-Symbolic（符号多选）、MC-Numerical（数值多选）和自由形式（开放式回答）。每个问题都附带结构化推理步骤和可执行Python代码。引入三个新颖评估指标：一致性分数、失败率和混淆率。

Result: 使用最先进的指令调优语言模型进行实验，揭示了模型在科学推理方面的优势和局限性。SymPyBench为开发更鲁棒和可解释的推理系统奠定了基础。

Conclusion: SymPyBench是一个动态、可扩展的基准，通过其参数化设计和新颖评估指标，能够更全面地评估语言模型的科学推理能力，为未来推理系统的开发提供了重要基础。

Abstract: We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [77] [La transformation num{é}rique de la justice : ambitions, r{é}alit{é}s et perspectives](https://arxiv.org/abs/2512.05143)
*Yannick Meneceur*

Main category: cs.CY

TL;DR: 该研究通过四年的学术周期，结合网络司法硕士学生的协助，客观评估司法数字化转型的话语和表征，特别关注从业者的证言和现有文献。


<details>
  <summary>Details</summary>
Motivation: 研究旨在客观评估司法数字化转型的话语和表征，理解这一转型过程中的专业观点和实践经验，为司法系统的数字化改革提供实证基础。

Method: 采用四年的学术周期研究，借助斯特拉斯堡大学网络司法硕士学生的协助，收集和分析从业者的证言，并结合现有文献进行综合评估。

Result: 研究提供了对司法数字化转型话语和表征的客观评估，揭示了从业者的观点和实践经验，为理解司法数字化进程提供了实证依据。

Conclusion: 该研究通过系统性的实证分析，为司法数字化转型提供了重要的专业见解，有助于推动司法系统的现代化改革。

Abstract: The study, conducted over a four-year academic cycle with the assistance of M2 students from the Cyberjustice Master's programme at the Faculty of Law, Political Science and Management at the University of Strasbourg, aims to objectively assess the discourse and representations of the digital transformation of justice, in particular by capitalising on testimonials from professionals in the field and drawing on the available literature.

</details>


### [78] [Deadline-Chasing in Digital Health: Modeling EMR Adoption Dynamics and Regulatory Impact in Indonesian Primary Care](https://arxiv.org/abs/2512.05381)
*Suryo Satrio,Bukhori Muhammad Aqid*

Main category: cs.CY

TL;DR: 评估印尼初级卫生机构EMR采用水平与速度，发现注册后快速激活但总体采用率仅8.9%，预计2025年6月达约4,000家机构


<details>
  <summary>Details</summary>
Motivation: 印尼卫生部2022年第24号条例强制要求采用电子病历并与SATUSEHAT平台整合，但初级卫生机构的采用因素、轨迹和速度缺乏实证证据

Method: 观察性研究，分析主要EMR系统提供商PT MTK客户网络的累计注册设施、月注册流量、同月激活/停用等变量，使用描述性分析、逻辑增长模型和ARIMA预测

Result: 33个月内累计注册设施从2家增至3,533家，同月激活率中位数0.889，最终采用率占合格设施的8.9%；ARIMA模型预测2025年6月累计约3,997家机构，逻辑增长收敛于4.1千家设施

Conclusion: EMR采用呈现稳定增长且注册后快速激活，但总体市场份额仍低于10%；应通过干预措施与截止日期对齐来最大化影响，预计2025年将继续增长

Abstract: Indonesia digital healthcare transformation is accelerating under Minister of Health Regulation Number 24 of 2022, which mandates the adoption of Electronic Medical Records EMR and integration with the SATUSEHAT platform. However, empirical evidence regarding the factors, trajectory and speed of adoption in Primary Health Facilities FKTP remains limited. This study aims to evaluate the level and rate of EMR adoption within the customer network of a major EMR system provider PT MTK and model short-term projections. This is an observational study with the main variables being cumulative registered EMR facilities, monthly registration flow, same-month activation, same-month inactivation, and the estimated number of eligible FKTPs nationally monthly known as eligible facilities. The analysis uses descriptive analysis, logistic growth modeling, and ARIMA forecasting. The results of the study over 33 months showed that cumulative registered facilities increased from 2 to 3,533, with a median same-month activation rate of 0.889 IQR 0.717 to 0.992. The proportion of final adoption compared to eligible facilities was 8.9 percent 3,533 of 39,852. The ARIMA model projects a cumulative approximately 3,997 clinics 95 percent CI 3,697 to 4,298 by June 2025. The estimated growth in logistics converges with a carrying capacity of 4.1 thousand facilities. The study findings reveal that EMR adoption within the customer network of EMR system providers is showing steady growth with rapid activation in the month of registration. Although the cumulative series showed no major departures from the long-term trend, localized step-ups around deadlines suggest deadline chasing, so impact should be maximized by aligning interventions to the deadline calendar. Given the trajectory, total market share of FKTP for PT MTK remains less than 10 percent at the end of 2024, but continues to increase in 2025.

</details>


### [79] [Building Capacity for Artificial Intelligence in Africa: A Cross-Country Survey of Challenges and Governance Pathways](https://arxiv.org/abs/2512.05432)
*Jeffrey N. A. Aryee,Patrick Davies,Godfred A. Torsah,Mercy M. Apaw,Cyril D. Boateng,Sam M. Mwando,Chris Kwisanga,Eric Jobunga,Leonard K. Amekudzi*

Main category: cs.CY

TL;DR: 该研究调查了非洲五国大学与产业界在AI教育和劳动力准备方面的合作现状，发现虽然普遍认识到AI重要性，但存在参与度不足、实践培训有限、资源获取不均等问题，需要加强校企合作并解决资金、基础设施和政策障碍。


<details>
  <summary>Details</summary>
Motivation: AI正在改变教育和劳动力市场，但非洲的AI学习机会获取不均。随着人口结构快速变化和劳动力市场压力增加，AI已成为战略发展重点，对相关技能的需求更加迫切。研究旨在了解大学和产业界如何参与塑造AI教育和劳动力准备。

Method: 通过对五个非洲国家（加纳、纳米比亚、卢旺达、肯尼亚和赞比亚）的问卷调查，收集大学和产业界的反馈，分析他们在AI教育和劳动力准备方面的参与情况。

Result: 研究发现广泛认识到AI的重要性，但缺乏一致的参与、实践培训或公平的资源获取。大多数认为课程AI部分非常相关的受访者表示对工作准备充分，但财务障碍、基础设施差和沟通不畅限制了参与，特别是学生和弱势群体。受访者强调实习、产业合作和针对性支持机制是关键推动因素，同时需要包容性治理框架。

Conclusion: 研究显示了AI潜力意识的增长，但也揭示了阻碍其转化为劳动力能力的结构性差距。加强大学与产业界的合作，解决获取、资金和政策障碍，对于确保AI为整个非洲大陆的公平和可持续发展做出贡献至关重要。

Abstract: Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of consistent engagement, practical training, or equitable access to resources. Most respondents who rated the AI component of their curriculum as very relevant reported being well prepared for jobs, but financial barriers, poor infrastructure, and weak communication limit participation, especially among students and underrepresented groups. Respondents highlighted internships, industry partnerships, and targeted support mechanisms as critical enablers, alongside the need for inclusive governance frameworks. The results showed both the growing awareness of AI's potential and the structural gaps that hinder its translation into workforce capacity. Strengthening university-industry collaboration and addressing barriers of access, funding, and policy are central to ensuring that AI contributes to equitable and sustainable development across the continent.

</details>


### [80] [Knowing Your Uncertainty -- On the application of LLM in social sciences](https://arxiv.org/abs/2512.05461)
*Bolun Zhang,Linzhuo Li,Yunqi Chen,Qinlin Zhao,Zihan Zhu,Xiaoyuan Yi,Xing Xie*

Main category: cs.CY

TL;DR: 论文提出了一个评估大语言模型在社会科学研究中不确定性的统一框架，基于任务类型和验证类型两个维度，为研究人员提供实用指南。


<details>
  <summary>Details</summary>
Motivation: 大语言模型正快速融入计算社会科学研究，但其黑盒训练和推理中的随机性给科学研究带来独特挑战。需要建立明确的不确定性评估框架，这是社会科学定量方法和机器学习中长期确立的期望。

Method: 引入一个统一框架，从两个维度评估LLM不确定性：任务类型（分类、短文本生成、长文本生成）和验证类型（参考数据或评估标准的可用性）。基于计算机科学和社会科学文献，将现有不确定性量化方法映射到这个T-V分类中。

Result: 提出了一个系统性的不确定性评估框架，为研究人员提供了实用的方法建议，帮助将LLM更严谨地整合到社会科学研究中。

Conclusion: 该框架既提供了方法学保障，又为将LLM整合到严谨的社会科学研究中提供了实用指南，有助于解决LLM在社会科学应用中面临的不确定性挑战。

Abstract: Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.

</details>


### [81] [The Topology of Hardship: Empirical Curriculum Graphs and Structural Bottlenecks in Engineering Degrees](https://arxiv.org/abs/2512.05561)
*H. R. Paz*

Main category: cs.CY

TL;DR: 工程学位常被认为"难"，但通常从内容难度或学生弱点角度讨论，而非课程结构本身。本文提出"困难拓扑"概念，基于学生实际轨迹量化课程复杂性，发现课程难度是可测量的拓扑属性，少数结构密集、瓶颈多的课程导致不成比例的辍学率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注课程内容难度或学生能力，而忽略了课程结构本身作为"困难"来源。虽然已有研究使用课程-先修网络和课程图建模学习计划，但大多基于官方教学大纲而非学生实际进展轨迹。需要从实证学生轨迹角度理解工程课程的结构复杂性。

Method: 基于CAPIRE多层次轨迹建模框架，从29个工程课程的注册和完成数据重建学位课程图。为每个图计算结构指标（密度、最长路径、瓶颈中心性）和实证困难度量（阻塞概率、进展时间）。将这些组合成复合困难指数，并与观察到的辍学率和学位获得时间相关联。

Result: 课程难度不是模糊感知，而是可测量的拓扑属性：少数结构密集、瓶颈重的课程导致了不成比例的辍学率和时间不同步。这些课程在辍学和学位延迟中占据主导地位。

Conclusion: 工程课程的"困难"具有可量化的结构基础。研究结果为课程改革、认证和数据驱动的政策设计提供了实证依据，表明通过优化课程拓扑结构可以改善学生学业成果。

Abstract: Engineering degrees are often perceived as "hard", yet this hardness is usually discussed in terms of content difficulty or student weaknesses rather than as a structural property of the curriculum itself. Recent work on course-prerequisite networks and curriculum graphs has shown that study plans can be modelled as complex networks with identifiable hubs and bottlenecks, but most studies rely on official syllabi rather than on how students actually progress through the system (Simon de Blas et al., 2021; Stavrinides & Zuev, 2023; Yang et al., 2024; Wang et al., 2025).
  This paper introduces the notion of topology of hardship: a quantitative description of curriculum complexity derived from empirical student trajectories in long-cycle engineering programmes. Building on the CAPIRE framework for multilevel trajectory modelling (Paz, 2025a, 2025b), we reconstruct degree-curriculum graphs from enrolment and completion data for 29 engineering curricula across several cohorts. For each graph we compute structural metrics (e.g., density, longest path, bottleneck centrality) and empirical hardship measures capturing blocking probability and time-to-progress. These are combined into a composite hardship index, which is then related to observed dropout rates and time to degree.
  Our findings show that curriculum hardness is not a vague perception but a measurable topological property: a small number of structurally dense, bottleneck-heavy curricula account for a disproportionate share of dropout and temporal desynchronisation. We discuss implications for curriculum reform, accreditation, and data-informed policy design.

</details>


### [82] [Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework](https://arxiv.org/abs/2512.05728)
*Frederik Zuiderveen Borgesius,Jonathan Gray,Mireille van Eechoud*

Main category: cs.CY

TL;DR: 论文提出一个平衡框架，帮助公共机构在开放政府数据时保护隐私，认为开放数据不是唯一途径，需要强有力的公共利益论证才能将个人信息作为开放数据发布。


<details>
  <summary>Details</summary>
Motivation: 开放数据有助于实现透明度、公众参与、民主问责、经济增长、创新和公共部门效率等多种社会政治目标，但包含个人信息的政府数据发布可能威胁隐私和相关权益。需要找到尊重隐私利益同时不阻碍公共信息开放效益的方法。

Method: 提出一个平衡框架，考虑不同类型数据的隐私风险等级，区分访问和再利用决策，突出不同的披露途径，并提供一个情况目录，列出评估数据集是否、在何种条件下以及如何发布时可能考虑的因素。

Result: 开发了一个系统性的决策框架，帮助公共机构在不同情境下平衡开放数据效益与隐私保护需求，明确了开放数据不是政府信息发布的唯一途径。

Conclusion: 虽然开放数据仍然是政府信息发布的重要途径，但不是唯一途径。为了将个人信息作为开放数据发布，必须有明确且强有力的公共利益论证。该框架为公共机构提供了实用的决策工具。

Abstract: Open data are held to contribute to a wide variety of social and political goals, including strengthening transparency, public participation and democratic accountability, promoting economic growth and innovation, and enabling greater public sector efficiency and cost savings. However, releasing government data that contain personal information may threaten privacy and related rights and interests. In this Article we ask how these privacy interests can be respected, without unduly hampering benefits from disclosing public sector information. We propose a balancing framework to help public authorities address this question in different contexts. The framework takes into account different levels of privacy risks for different types of data. It also separates decisions about access and re-use, and highlights a range of different disclosure routes. A circumstance catalogue lists factors that might be considered when assessing whether, under which conditions, and how a dataset can be released. While open data remains an important route for the publication of government information, we conclude that it is not the only route, and there must be clear and robust public interest arguments in order to justify the disclosure of personal information as open data.

</details>


### [83] [Informed Consent: We Can Do Better to Defend Privacy](https://arxiv.org/abs/2512.05729)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 论文批判当前以知情同意为核心的隐私保护模式，认为行为研究表明其效果有限，主张采用保护与赋权相结合的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前互联网隐私保护过度依赖知情同意模式，但行为研究表明人们倾向于随意点击同意，导致隐私保护效果不佳。需要重新思考隐私保护方法。

Method: 分析当前隐私法律框架中知情同意的实践问题，以行为定向广告为例说明其局限性，论证需要转向保护性规则而非单纯赋权。

Result: 揭示知情同意作为隐私保护手段的实践缺陷，提出政策制定者应更多关注保护性规则，而非单纯依赖个人选择。

Conclusion: 互联网隐私保护需要从单纯依赖知情同意转向保护与赋权相结合的综合方法，政策制定应更注重保护性规则。

Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.

</details>


### [84] [De mythe van geïnformeerde toestemming: online privacybescherming kan beter [Informed Consent: We Can Do Better to Defend Privacy]](https://arxiv.org/abs/2512.05730)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文批判当前以知情同意为核心的隐私保护模式，指出其实际效果有限，主张采用保护与赋权相结合的新路径。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护政策过度依赖知情同意机制，但行为研究表明用户往往盲目点击同意，导致该机制失效。需要重新思考更有效的隐私保护方法。

Method: 通过分析行为定向广告的隐私问题，批判知情同意在实际应用中的缺陷，论证需要从单纯赋权转向保护与赋权相结合的政策框架。

Result: 揭示知情同意机制在隐私保护中的实践困境，提出政策制定者应更重视保护性规则而非单纯依赖用户选择。

Conclusion: 隐私保护需要从过度依赖知情同意转向保护与赋权相结合的综合策略，政策应更注重实质性保护措施。

Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.

</details>


### [85] [Internal Deployment in the EU AI Act](https://arxiv.org/abs/2512.05742)
*Matteo Pistillo*

Main category: cs.CY

TL;DR: 该备忘录分析并压力测试了支持与反对将内部部署纳入欧盟人工智能法案范围的论点，为欧盟委员会、AI提供商和部署者以及法律政策界提供基于法案条款的多种解释路径。


<details>
  <summary>Details</summary>
Motivation: 欧盟人工智能法案在适用范围上存在模糊性，特别是关于内部部署AI模型和系统是否应受监管的问题。备忘录旨在澄清这一关键法律问题，为相关方提供明确的解释指导。

Method: 基于欧盟AI法案第2(1)、2(6)、2(8)条进行法律分析，首先提出四种支持内部部署受监管的解释路径，然后审查可能的反对意见和例外情况，最后展示各条款的互补性。

Result: 备忘录提供了多种解释路径，表明内部部署AI系统很可能受欧盟AI法案约束，同时详细分析了科学研发例外等复杂条款，为法律适用提供了清晰框架。

Conclusion: 欧盟AI法案的适用范围应包含内部部署的AI系统，各相关条款在合理解释下相互补充，为AI监管提供了全面的法律框架，但需要进一步澄清科学研发例外的具体适用条件。

Abstract: This memorandum analyzes and stress-tests arguments in favor and against the inclusion of internal deployment within the scope of the European Union Artificial Intelligence Act (EU AI Act). In doing so, it aims to offer several possible interpretative pathways to the European Commission, AI providers and deployers, and the legal and policy community at large based on Articles 2(1), 2(6), 2(8) of the EU AI Act. Specifically, this memorandum first analyzes four interpretative pathways based on Article 2(1)(a)-(c) supporting the application of the EU AI Act to internally deployed AI models and systems. Then, it examines possible objections and exceptions based on Articles 2(1)(a), 2(6), and 2(8), with particular attention to the complexity of the scientific R&D exception under Article 2(6). Finally, it illustrates how Articles 2(1), 2(6), and 2(8) can be viewed as complementary to each other, once broken down to their most plausible meaning and interpreted in conjunction with Articles 3(1), 3(3), 3(4), 3(9), 3(10), 3(11), 3(12), 3(63), and Recitals 12, 13, 21, 25, 97, and 109.

</details>


### [86] [LLM Harms: A Taxonomy and Discussion](https://arxiv.org/abs/2512.05929)
*Kevin Chen,Saleh Afroogh,Abhejay Murali,David Atkinson,Amit Dhurandhar,Junfeng Jiao*

Main category: cs.CY

TL;DR: 该研究系统分析了大型语言模型在AI应用开发前、中、后各阶段可能造成的五类危害，提出了缓解策略和动态审计系统，以促进LLM负责任的发展与集成。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在人工智能领域的广泛应用，其潜在危害日益凸显。研究旨在系统识别LLM在应用开发全周期中的各类风险，确保问责制、透明度和偏见管理，为负责任地开发和应用LLM提供指导框架。

Method: 研究采用分类分析方法，将LLM危害分为五类：开发前危害、直接输出危害、滥用和恶意应用危害、下游应用危害。通过系统梳理各阶段风险，提出相应的缓解策略，并设计动态审计系统来指导标准化开发流程。

Result: 研究建立了全面的LLM危害分类框架，明确了各阶段的具体风险类型。提出了针对特定领域的缓解策略和未来发展方向，并设计了动态审计系统作为标准化提案，以促进LLM的负责任开发和集成。

Conclusion: LLM的危害管理需要贯穿整个应用生命周期。通过系统化的危害分类、针对性的缓解策略和动态审计机制，可以实现更负责任、透明和公平的LLM开发与应用，为AI伦理和安全提供重要指导。

Abstract: This study addresses categories of harm surrounding Large Language Models (LLMs) in the field of artificial intelligence. It addresses five categories of harms addressed before, during, and after development of AI applications: pre-development, direct output, Misuse and Malicious Application, and downstream application. By underscoring the need to define risks of the current landscape to ensure accountability, transparency and navigating bias when adapting LLMs for practical applications. It proposes mitigation strategies and future directions for specific domains and a dynamic auditing system guiding responsible development and integration of LLMs in a standardized proposal.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [87] [ARCAS: An Augmented Reality Collision Avoidance System with SLAM-Based Tracking for Enhancing VRU Safety](https://arxiv.org/abs/2512.05299)
*Ahmad Yehia,Jiseop Byeon,Tianyi Wang,Huihai Wang,Yiming Xu,Junfeng Jiao,Christian Claudel*

Main category: eess.SY

TL;DR: ARCAS是一个基于增强现实的实时碰撞避免系统，通过可穿戴AR头显为弱势道路使用者提供个性化空间警报，融合路边3D LiDAR和SLAM技术，显著提升行人安全反应时间。


<details>
  <summary>Details</summary>
Motivation: 弱势道路使用者在混合交通中面临高碰撞风险，现有安全系统主要关注驾驶员或车辆辅助，缺乏直接支持弱势道路使用者的解决方案。

Method: 系统融合路边360度3D LiDAR与基于SLAM的头显追踪，采用自动3D校准程序，在用户透视视图中准确叠加世界锁定的3D边界框和方向箭头，并支持多头显协调共享世界锚定。

Result: 在真实世界行人-电动滑板车/车辆交互的180次试验中，ARCAS几乎使行人的碰撞时间翻倍，并将对应方的反应裕度提高达4倍。

Conclusion: 验证了LiDAR驱动的AR引导的可行性和有效性，突显了可穿戴AR作为下一代城市移动安全工具的潜力。

Abstract: Vulnerable road users (VRUs) face high collision risks in mixed traffic, yet most existing safety systems prioritize driver or vehicle assistance over direct VRU support. This paper presents ARCAS, a real-time augmented reality collision avoidance system that provides personalized spatial alerts to VRUs via wearable AR headsets. By fusing roadside 360-degree 3D LiDAR with SLAM-based headset tracking and an automatic 3D calibration procedure, ARCAS accurately overlays world-locked 3D bounding boxes and directional arrows onto approaching hazards in the user's passthrough view. The system also enables multi-headset coordination through shared world anchoring. Evaluated in real-world pedestrian interactions with e-scooters and vehicles (180 trials), ARCAS nearly doubled pedestrians' time-to-collision and increased counterparts' reaction margins by up to 4x compared to unaided-eye conditions. Results validate the feasibility and effectiveness of LiDAR-driven AR guidance and highlight the potential of wearable AR as a promising next-generation safety tool for urban mobility.

</details>


### [88] [Comparative Analysis of Barrier-like Function Methods for Reach-Avoid Verification in Stochastic Discrete-Time Systems](https://arxiv.org/abs/2512.05348)
*Zhipeng Cao,Peixin Wang,Luke Ong,Đorđe Žikelić,Dominik Wagner,Bai Xue*

Main category: eess.SY

TL;DR: 本文比较了随机离散时间系统无限时域可达避免验证中的几种代表性屏障条件，分析其理论性质和计算可行性，并通过SDP和CEGIS实验展示实际性能。


<details>
  <summary>Details</summary>
Motivation: 随机离散时间系统的无限时域可达避免验证在安全关键应用中至关重要，但现有屏障条件在理论性质和计算可行性方面存在差异，需要系统比较以指导实际应用选择。

Method: 比较文献中几种代表性屏障条件，分析其理论性质（如保守性）和计算可行性，并通过半定规划（SDP）和反例引导归纳合成（CEGIS）进行数值实验验证。

Result: 研究揭示了不同屏障条件在适用性和保守性方面的优缺点，实验结果表明某些条件在特定场景下具有更好的计算效率和验证性能。

Conclusion: 不同屏障条件各有优劣，选择取决于具体应用需求；SDP和CEGIS为验证提供了有效工具，未来可结合两者优势开发更高效的验证方法。

Abstract: In this paper, we compare several representative barrier-like conditions from the literature for infinite-horizon reach-avoid verification of stochastic discrete-time systems. Our comparison examines both their theoretical properties and computational tractability, highlighting each condition's strengths and limitations that affect applicability and conservativeness. Finally, we illustrate their practical performance through computational experiments using semidefinite programming (SDP) and counterexample-guided inductive synthesis (CEGIS).

</details>


### [89] [Data-Driven Adaptive Output Regulation of Unknown Linear Systems](https://arxiv.org/abs/2512.05390)
*Shangkun Liu,Lei Wang,Bowen Yi*

Main category: eess.SY

TL;DR: 提出一种数据驱动的调节器，在系统和外部激励完全未知的情况下，通过离线数据和在线识别实现渐近调节和闭环稳定


<details>
  <summary>Details</summary>
Motivation: 研究线性输出调节问题，当外部激励系统和被控对象都完全未知时，如何在不进行模型识别的情况下实现渐近调节和闭环稳定

Method: 1. 构建名义近似内模和输入输出滤波器，得到可稳定的级联名义系统；2. 利用离线实验数据推导镇定控制律；3. 实现离散时间识别器来修正内模并更新控制律

Result: 在满足持续激励条件下，系统状态能指数收敛到子空间，调节误差可渐近收敛到零

Conclusion: 提出了一种无需模型识别的数据驱动调节器，通过离线数据与在线识别相结合的方法，在系统和外部激励未知的情况下实现了渐近调节

Abstract: This paper investigates the linear output regulation problem with both the exosystem and the plant fully unknown. A data-driven regulator is proposed to achieve asymptotic regulation and closed-loop stability without performing model identification. The method constructs a nominal approximate internal model and filters of input and outputs, thereby yielding a stabilizable cascaded nominal system whose states are available. For this nominal system, a stabilizing law is derived from an offline dataset that has been acquired from the plant during experiments, such that the system states exponentially converge to a subspace. An identifier in discrete-time is, then, implemented to correct the internal model and update the stabilizing law; as a result, the regulation error can be steered to zero asymptotically under some persistent excitation conditions.

</details>


### [90] [Hybrid modeling approach for better identification of building thermal network model and improved prediction](https://arxiv.org/abs/2512.05400)
*Sang woo Ham,Donghun Kim*

Main category: eess.SY

TL;DR: 提出混合建模方法，将灰箱模型与未测量扰动模型结合，提高建筑温度预测精度，适用于模型预测控制应用。


<details>
  <summary>Details</summary>
Motivation: 灰箱建模方法在建筑预测应用中广泛使用，但未测量的扰动（如人员、照明、渗透负荷）使其难以在实际建筑中应用。

Method: 提出混合建模方法，集成灰箱模型与未测量扰动模型，通过系统辨识方法和基于统计检验的模型选择过程来设计鲁棒的扰动模型。

Result: 混合模型在1天前温度预测中，相比传统方法RMSE降低约0.2-0.9°C（温和气候）和0.3-2°C（寒冷气候），在实验室建筑数据上表现出优越的预测性能。

Conclusion: 混合建模方法能有效处理未测量扰动，显著提高建筑温度预测精度，适用于模型预测控制应用。

Abstract: The gray-box modeling approach, which uses a semi-physical thermal network model, has been widely used in building prediction applications, such as model predictive control (MPC). However, unmeasured disturbances, such as occupants, lighting, and in/exfiltration loads, make it challenging to apply this approach to practical buildings. In this study, we propose a hybrid modeling approach that integrates the gray-box model with a model for unmeasured disturbance. After reviewing several system identification approaches, we systematically designed the unmeasured disturbance model with a model selection process based on statistical tests to make it robust. We generated data based on the building model calibrated by real operational data and then trained the hybrid model for two different weather conditions. The Hybrid model approach demonstrates the reduction of RMSE approximately 0.2-0.9C and 0.3-2C on 1-day ahead temperature prediction compared to the Conventional approach for mild (Berkeley, CA) and cold (Chicago, IL) climates, respectively. In addition, this approach was applied for experimental data obtained from the laboratory building to be used for the MPC application, showing superior prediction performances.

</details>


### [91] [Privacy-Preserving Fully Distributed Gaussian Process Regression](https://arxiv.org/abs/2512.05473)
*Yeongjun Jang,Kaoru Teranishi,Jihoon Suh,Takashi Tanaka*

Main category: eess.SY

TL;DR: 提出基于安全多方计算的隐私保护分布式高斯过程回归协议，防止协作学习中的数据泄露


<details>
  <summary>Details</summary>
Motivation: 分布式高斯过程回归允许多个代理联合学习目标函数模型，但协作性质存在私有数据泄露风险

Method: 基于安全分布式平均共识算法，采用安全多方计算技术，并扩展到支持核超参数优化

Result: 协议保证每个代理的本地模型实际收敛到标准分布式GPR获得的全局模型，提供形式化隐私保证

Conclusion: 实验结果表明该方法的有效性和实际适用性，解决了分布式GPR中的隐私保护问题

Abstract: Although distributed Gaussian process regression (GPR) enables multiple agents with separate datasets to jointly learn a model of the target function, its collaborative nature poses risks of private data leakage. To address this, we propose a privacy-preserving fully distributed GPR protocol based on secure multi-party computation (SMPC) that preserves the confidentiality of each agent's local dataset. Building upon a secure distributed average consensus algorithm, the protocol guarantees that each agent's local model practically converges to the same global model that would be obtained by the standard distributed GPR. Further, we adopt the paradigm of simulation based security to provide formal privacy guarantees, and extend the proposed protocol to enable kernel hyperparameter optimization, which is critical yet often overlooked in the literature. Experimental results demonstrate the effectiveness and practical applicability of the proposed method.

</details>


### [92] [Solving Multiparametric Generalized Nash Equilibrium Problems and Explicit Game-Theoretic Model Predictive Control](https://arxiv.org/abs/2512.05505)
*Sophie Hall,Alberto Bemporad*

Main category: eess.SY

TL;DR: 提出一种计算参数化广义纳什均衡问题显式解的方法，适用于凸二次成本函数和线性约束，实现实时计算、可解释性、多均衡枚举和零样本更新。


<details>
  <summary>Details</summary>
Motivation: 传统求解广义纳什均衡问题需要在线数值计算，缺乏实时性、可解释性和处理多均衡的能力。需要一种能够提供显式解析解的方法，以支持实时应用、系统分析和决策制定。

Method: 针对参数仅出现在成本函数线性项和约束右侧的凸二次广义纳什均衡问题，推导出精确的多参数解析解。该方法基于多参数二次规划技术，将均衡问题转化为参数化优化问题，并给出显式解表达式。

Result: 方法实现了：1）最小实时计算需求；2）固有的可解释性和所有多均衡的精确枚举；3）无限多均衡情况下确定期望解类型；4）约束右侧和/或线性成本变化时的零样本更新。在电池充电游戏和弹簧系统控制问题中验证了性能。

Conclusion: 提出的方法为参数化广义纳什均衡问题提供了精确的显式多参数解，显著提升了实时性能、可解释性和灵活性。该方法可应用于显式模型预测控制，为博弈论控制问题提供了高效解决方案。

Abstract: We present a method to compute explicit solutions of parametric Generalized Nash Equilibrium (GNE) problems with convex quadratic cost functions and linear coupling and local constraints. Assuming the parameters only enter the linear terms of the cost functions and constraint right-hand sides, we provide the exact multiparametric solution of the GNE problem. Such a solution enables (i) minimal real-time computation, (ii) inherent interpretability, explainability, and exact enumeration of all multiple equilibria, (iii) determine desired GNE solution types in the case of infinitely-many equilibria, and (iv) zero-shot updates of the GNE solution due to changes of constraint right-hand sides and/or linear costs. In line with explicit Model Predictive Control (MPC) approaches, we apply our method to solve game-theoretic MPC (Receding Horizon Games) explicitly, comparing performance against centralized solvers in a battery charging game and in a toy two-mass spring system control problem. A Python implementation of the algorithms presented in this paper is available on https://github.com/bemporad/nash_mpqp.

</details>


### [93] [Constructive boundary observer-based control of high-dimensional semilinear heat equations](https://arxiv.org/abs/2512.05547)
*Pengfei Wang,Emilia Fridman*

Main category: eess.SY

TL;DR: 提出了一种针对多维半线性热方程的有限维输出反馈设计方法，通过模态分解和LMI设计处理边界控制与测量问题，并分析了系统对乘性和加性噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多维热方程边界控制面临的主要挑战是拉普拉斯算子特征值增长较慢，需要开发能够处理更大Lipschitz常数并具有鲁棒性的控制设计方法。

Method: 基于模态分解的设计方法，包括更广泛的边界形状函数、相应的提升变换以及通过LMI设计获得的全阶控制器增益，并提供了确定最小观测器维度和最大Lipschitz常数的LMI条件。

Result: 该方法在2D和3D数值算例中展示了有效性，能够处理乘性噪声（均方指数稳定）和加性噪声（噪声到状态稳定）的鲁棒稳定性。

Conclusion: 提出的有限维输出反馈设计成功解决了多维半线性热方程的边界控制问题，通过LMI方法有效处理了特征值增长缓慢的挑战，并具有良好的鲁棒性。

Abstract: This paper presents a constructive finite-dimensional output-feedback design for semilinear $M$-dimensional ($M\geq 2$) heat equations with boundary actuation and sensing. A key challenge in high dimensions is the slower growth rate of the Laplacian eigenvalues. The novel features of our modal-decomposition-based design, which allows to enlarge Lipschitz constants, include a larger class of shape functions that may be distributed over a part of the boundary only, the corresponding lifting transformation and the full-order controller gain found from the design LMIs. We further analyze the robustness of the closed-loop system with respect to either multiplicative noise (vanishing at the origin) or additive noise (persistent). Effective LMI conditions are provided for specifying the minimal observer dimension and maximal Lipschitz constants that preserve the stability (mean-square exponential stability for multiplicative noise and noise-to-state stability for additive noise). Numerical examples for 2D and 3D cases demonstrate the efficacy and advantages of our method.

</details>


### [94] [PAC One-Step Safety Certification for Black-Box Discrete-Time Stochastic Systems](https://arxiv.org/abs/2512.05549)
*Taoran Wu,Dominik Wagner,Jingduo Pan,Luke Ong,Arvind Easwaran,Bai Xue*

Main category: eess.SY

TL;DR: 提出基于采样数据的黑盒随机系统安全认证框架，在PAC意义下提供理论保证的一步安全保证，可递归应用于扩展时域。


<details>
  <summary>Details</summary>
Motivation: 针对黑盒离散时间随机系统，系统动态和扰动分布未知且仅有采样数据可用，在此有限信息下确保鲁棒或经典定量安全通常不可行。

Method: 提出数据驱动框架，基于采样数据构建障碍证书条件，利用VC维、场景方法、马尔可夫不等式和霍夫丁不等式建立PAC安全保证。提出两种采样程序和三种PAC安全保证方法。

Result: 通过多个数值示例证明了所提方法的有效性，三种方法各有比较优势。

Conclusion: 为黑盒随机系统提供了一种实用的数据驱动安全认证方法，在有限信息下实现可扩展时域的安全保证。

Abstract: This paper investigates the problem of safety certification for black-box discrete-time stochastic systems, where both the system dynamics and disturbance distributions are unknown, and only sampled data are available. Under such limited information, ensuring robust or classical quantitative safety over finite or infinite horizons is generally infeasible. To address this challenge, we propose a data-driven framework that provides theoretical one-step safety guarantees in the Probably Approximately Correct (PAC) sense. This one-step guarantee can be applied recursively at each time step, thereby yielding step-by-step safety assurances over extended horizons. Our approach formulates barrier certificate conditions based solely on sampled data and establishes PAC safety guarantees by leveraging the VC dimension, scenario approaches, Markov's inequality, and Hoeffding's inequality. Two sampling procedures are proposed, and three methods are proposed to derive PAC safety guarantees. The properties and comparative advantages of these three methods are thoroughly discussed. Finally, the effectiveness of the proposed methods are demonstrated through several numerical examples.

</details>


### [95] [Inverse Linear-Quadratic Gaussian Differential Games](https://arxiv.org/abs/2512.05552)
*Lucas Günther,Felix Thömmes,Karl Handwerker,Balint Varga,Sören Hohmann*

Main category: eess.SY

TL;DR: 提出了一种解决有限时域LQG微分博弈逆问题的方法，从观测轨迹中恢复所有玩家的成本函数参数和随机系统的噪声缩放参数。


<details>
  <summary>Details</summary>
Motivation: 在随机微分博弈中，通常需要从观测到的玩家行为轨迹中推断其内在的成本函数参数和系统噪声特性，这对于理解玩家策略、预测行为以及系统设计具有重要意义。

Method: 采用三步框架：1) 估计反馈策略；2) 通过耦合Riccati微分方程的新颖重构识别成本函数参数；3) 使用最大似然估计噪声缩放参数。

Result: 仿真结果表明，该方法能够有效恢复参数，生成的轨迹与观测轨迹高度匹配。

Conclusion: 该方法为有限时域线性二次高斯微分博弈的逆问题提供了有效的解决方案，能够从观测数据中准确恢复系统参数。

Abstract: This paper presents a method for solving the Inverse Stochastic Differential Game (ISDG) problem in finite-horizon linear-quadratic Gaussian (LQG) differential games. The objective is to recover cost function parameters of all players, as well as noise scaling parameters of the stochastic system, consistent with observed trajectories. The proposed framework combines (i) estimation of the feedback strategies, (ii) identification of the cost function parameters via a novel reformulation of the coupled Riccati differential equations, and (iii) maximum likelihood estimation of the noise scaling parameters. Simulation results demonstrate that the approach recovers parameters, yielding trajectories that closely match the observed trajectories.

</details>


### [96] [Supervisory Measurement-Guided Noise Covariance Estimation: Discussing Forward and Reverse Differentiation](https://arxiv.org/abs/2512.05604)
*Haoying Li,Yifan Peng,Yuchi Wu,Junfeng Wu*

Main category: eess.SY

TL;DR: 提出一种双层优化框架，通过分解主测量和监控测量的联合似然来估计噪声协方差，将嵌套的贝叶斯依赖转换为马尔可夫链结构以提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 可靠的状态估计依赖于准确的噪声协方差模型，但在实践中难以确定。现有方法在信息利用和计算可行性之间存在权衡。

Method: 将噪声协方差估计表述为双层优化问题：下层使用状态增广的卡尔曼滤波器进行计算；上层通过闭式前向和反向微分提供高效梯度来更新噪声协方差。

Result: 提出的算法为线性高斯系统提供了系统且计算高效的噪声协方差估计方法，并比较了两种模型的空间和时间复杂度以指导实际选择。

Conclusion: 该框架通过分解联合似然，将嵌套贝叶斯依赖转换为马尔可夫链结构，实现了信息利用与计算可行性之间的平衡，为噪声协方差估计提供了有效的解决方案。

Abstract: Reliable state estimation depends on accurately modeled noise covariances, which are difficult to determine in practice. This paper formulates the noise covariance estimation as a bilevel optimization problem that factorizes the joint likelihood of primary and supervisory measurements to reconcile information exploitation with computational tractability. The factorization converts the nested Bayesian dependency into a Markov-chain structure, allowing efficient computation. At the lower level, a Kalman filter with state augmentation performs such computation. Meanwhile, closed-form forward and reverse differentiation provide efficient gradients for the upper-level updates, and we compare the two models' space and time complexities to inform their practical selection. The upper level subsequently refines the noise covariances to guide the lower-level estimation. Taken together, the proposed algorithms offer a systematic and computationally efficient approach to noise covariance estimation in linear Gaussian systems.

</details>


### [97] [Feedback stabilization of some fourth-order nonlinear parabolic equations with saturated controlsEQUATIONS WITH SATURATED CONTROLS](https://arxiv.org/abs/2512.05606)
*Patricio Guzmán,Felipe Labra,Hugo Parada*

Main category: eess.SY

TL;DR: 该论文研究Cahn-Hilliard和Kuramoto-Sivashinsky方程在饱和反馈控制下的内部和边界镇定问题，通过谱分析设计基于模态分解、LMI和饱和函数几何条件的镇定策略，实现H²空间的局部指数镇定。


<details>
  <summary>Details</summary>
Motivation: 研究Cahn-Hilliard和Kuramoto-Sivashinsky方程在饱和反馈控制下的镇定问题，这些方程在相变、模式形成等物理现象中具有重要应用，但存在不稳定特性需要控制。

Method: 通过线性算子的谱分析，识别系统不稳定部分的有限个特征值，采用模态分解方法，结合线性矩阵不等式(LMI)和饱和函数的几何条件设计镇定策略。

Result: 建立了在H²空间中的局部指数镇定结果，证明了所设计的饱和反馈控制策略能够有效镇定这两个非线性偏微分方程系统。

Conclusion: 通过谱分析、模态分解和LMI方法，成功设计了Cahn-Hilliard和Kuramoto-Sivashinsky方程在饱和反馈控制下的镇定策略，实现了局部指数稳定性。

Abstract: In this work, we analyze the internal and boundary stabilization of the Cahn-Hilliard and Kuramoto-Sivashinsky equations under saturated feedback control. We conduct our study through the spectral analysis of the associated linear operator. We identify a finite number of eigenvalues related to the unstable part of the system and then design a stabilization strategy based on modal decomposition, linear matrix inequalities (LMIs), and geometric conditions on the saturation function. Local exponential stabilization in $H^{2}$ is established.

</details>


### [98] [A Regularization and Active Learning Method for Identification of Quasi Linear Parameter Varying Systems](https://arxiv.org/abs/2512.05624)
*Sampath Kumar Mulagaleti,Alberto Bemporad*

Main category: eess.SY

TL;DR: 提出一种用于准线性参数变化模型识别的主动学习方法，通过流形正则化增强外推能力，并基于路径积分设计高效主动学习准则。


<details>
  <summary>Details</summary>
Motivation: 由于信息丰富的实验成本高昂，需要基于现有模型选择最大化信息含量的输入信号。同时，为了提高识别模型的外推性能，需要增强qLPV模型的平滑性。

Method: 引入流形正则化策略，强制qLPV动态平滑变化，促进线性时变行为。基于此正则化结构，提出基于逆距离方差度量路径积分的新主动学习准则，并利用LTV平滑性推导高效近似方法。

Result: 数值示例表明，所提出的正则化增强了qLPV外推能力，且由此产生的主动学习方案加速了识别过程。

Conclusion: 该方法通过流形正则化改善模型外推性能，结合高效的主动学习准则，实现了更快速、更准确的qLPV模型识别。

Abstract: This paper proposes an active learning method for designing experiments to identify quasi-Linear Parameter-Varying (qLPV) models. Since informative experiments are costly, input signals must be selected to maximize information content based on the currently available model. To improve the extrapolation properties of the identified model, we introduce a manifold-regularization strategy that enforces smooth variations in the qLPV dynamics, promoting Linear Time-Varying (LTV) behavior. Using this regularized structure, we propose a new active learning criterion based on path integrals of an inverse-distance variance measure and derive an efficient approximation exploiting the LTV smoothness. Numerical examples show that the proposed regularization enhances qLPV extrapolation and that the resulting active learning scheme accelerates the identification process.

</details>


### [99] [A Note on Emergent Behavior in Multi-agent Systems Enabled by Neuro-spike Communication](https://arxiv.org/abs/2512.05654)
*Hyeonyeong Jang,Donghyeon Song,Jin Gyu Lee,Hyungbo Shim*

Main category: eess.SY

TL;DR: 提出一种基于神经脉冲通信的异构多智能体系统同步框架，通过间歇性1比特脉冲实现高效同步


<details>
  <summary>Details</summary>
Motivation: 传统同步策略需要连续传输完整状态数据包，通信效率低，而生物神经系统通过稀疏脉冲通信实现高效协调，这启发了本研究的神经脉冲通信框架

Method: 使用生物启发的神经形态放大器，通过间歇性、异步的1比特狄拉克δ脉冲实现实用同步，大幅减少信息负载

Result: 提出的方法在带宽和能量方面显著提高了通信效率，通过严格的收敛分析和数值示例验证了方案的有效性

Conclusion: 神经脉冲通信框架为异构多智能体系统提供了一种高效、节能的同步方法，通过最小化信息负载实现实用同步

Abstract: In this note, we present a novel synchronization framework for heterogeneous multi-agent systems enabled by neuro-spike communication, which induces emergence. Unlike conventional synchronization strategies that require continuous transmission of full-state data packets, our approach utilizes a bio-inspired neuromorphic amplifier to achieve practical synchronization via intermittent, 1-bit Dirac delta pulses. The proposed method drastically improves communication efficiency in terms of bandwidth and energy by minimizing the information payload to a single bit, with intermittent and asynchronous communication. We provide a rigorous convergence analysis of the proposed method and validate the proposed scheme through numerical examples.

</details>


### [100] [LA-RL: Language Action-guided Reinforcement Learning with Safety Guarantees for Autonomous Highway Driving](https://arxiv.org/abs/2512.05686)
*Yiming Shu,Jiahui Xu,Jiwei Tang,Ruiyang Gao,Chen Sun*

Main category: eess.SY

TL;DR: LA-RL框架结合大语言模型语义推理与安全层，通过任务奖励塑造和安全关键规划器，在自动驾驶中平衡效率与安全，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要平衡主动效率行为与安全保证。现有方法在复杂高速公路环境中难以同时实现高效探索和安全约束。

Method: 提出语言动作引导强化学习(LA-RL)框架：1) 将LLM语义推理集成到actor-critic架构；2) 任务特定奖励塑造协调效率与安全目标；3) 结合MPC和DCBF的安全关键规划器，使用松弛机制确保可行性。

Result: 相比KG基线成功率提高约20%，相比RAG基线提高约30%；低密度环境下达到100%成功率；在复杂混合交通环境中展示更强的状态-动作空间探索能力和主动策略。

Conclusion: LA-RL为高速公路自动驾驶提供了更适应、可靠和鲁棒的解决方案，成功整合LLM语义推理与形式化安全保证，实现了效率与安全的平衡。

Abstract: Autonomous highway driving demands a critical balance between proactive, efficiency-seeking behavior and robust safety guarantees. This paper proposes Language Action-guided Reinforcement Learning (LA-RL) with Safety Guarantees, a novel framework that integrates the semantic reasoning of large language models (LLMs) into the actor-critic architecture with an improved safety layer. Within this framework, task-specific reward shaping harmonizes the dual objectives of maximizing driving efficiency and ensuring safety, guiding decision-making based on both environmental insights and clearly defined goals. To enhance safety, LA-RL incorporates a safety-critical planner that combines model predictive control (MPC) with discrete control barrier functions (DCBFs). This layer formally constrains the LLM-informed policy to a safe action set, employs a slack mechanism that enhances solution feasibility, prevents overly conservative behavior and allows for greater policy exploration without compromising safety. Extensive experiments demonstrate that it significantly outperforms several current state-of-the-art methods, offering a more adaptive, reliable, and robust solution for autonomous highway driving. Compared to existing SOTA, it achieves approximately 20$\%$ higher success rate than the knowledge graph (KG) based baseline and about 30$\%$ higher than the retrieval augmented generation (RAG) based baseline. In low-density environments, LA-RL achieves a 100$\%$ success rate. These results confirm its enhanced exploration of the state-action space and its ability to autonomously adopt more efficient, proactive strategies in complex, mixed-traffic highway environments.

</details>


### [101] [IMMPC: An Internal Model Based MPC for Rejecting Unknown Disturbances](https://arxiv.org/abs/2512.05692)
*Felix Brändle,Frank Allgöwer*

Main category: eess.SY

TL;DR: 提出一种基于内模原理的新型MPC方案，能够抑制未知扰动，确保可行性、约束满足和收敛到最优可达设定点。


<details>
  <summary>Details</summary>
Motivation: MPC虽然强大，但模型误差（如未知扰动）会导致约束违反、可行性丧失和闭环性能恶化。需要一种能处理未知扰动的MPC方案。

Method: 基于内模原理设计MPC方案，将输出调节问题重新表述为稳定性问题，确保可行性、约束满足和收敛到最优可达设定点。

Result: 在真实的四水箱系统上验证了控制器的有效性，能够抑制未知扰动并保持系统性能。

Conclusion: 提出的基于内模原理的MPC方案能够有效处理未知扰动，确保约束满足和系统稳定性，在实际系统中得到验证。

Abstract: Model predictive control (MPC) is a powerful control method that allows to directly include state and input constraints into the controller design. However, errors in the model, e.g., caused by unknown disturbances, can lead to constraint violation, loss of feasibility and deteriorate closed-loop performance. In this paper, we propose a new MPC scheme based on the internal model principle. This enables the MPC to reject unknown disturbances provided that the dynamics of the linear signal generator are known. We reformulate the output regulation problem as a stability problem, to ensure feasibility, constraint satisfaction, and convergence to the optimal reachable setpoint. The controller is validated on a real fourtank system.

</details>


### [102] [Pauli Decomposition of Impedance Matrices for Understanding the Root Cause of Instabilities in Grid-Connected Power Electronic Converters](https://arxiv.org/abs/2512.05780)
*Josue Andino,Milan Prodanovic,Javier Roldan-Perez*

Main category: eess.SY

TL;DR: 本文提出将泡利分解应用于阻抗矩阵和并网电力电子变换器的小回路，以简化阻抗矩阵项与闭环稳定性特性之间的联系，并帮助识别不稳定性的根本原因。


<details>
  <summary>Details</summary>
Motivation: 阻抗判据已成为评估并网电力电子变换器稳定性的替代方法，但阻抗和导纳矩阵缺乏物理意义，阻碍了对不稳定性根本原因的理解。

Method: 将泡利分解应用于阻抗矩阵和并网电力电子变换器的小回路，将阻抗矩阵转换为类四元数形式，从而简化阻抗矩阵项与闭环稳定性特性之间的联系。

Result: 通过一个先前文献中已用现有技术分析过的弱电网连接电力电子变换器案例研究，验证了理论贡献的有效性。

Conclusion: 泡利分解方法能够有效识别并网电力电子变换器不稳定性的根本原因，为稳定性评估提供了更深入的物理洞察。

Abstract: The impedance criterion has emerged as an alternative way to stability assessment of grid-connected power electronic converters. However, the lack of physical meaning of impedance and admittance matrices hinders the ability to understand the root cause of instabilities. To address this issue, this paper proposes the application of Pauli decomposition to the impedance matrices and the minor loop of grid-connected power electronic converters. The application of this methodology simplifies establishing the link between impedance matrix terms and closed-loop stability properties. Moreover, Pauli decomposition transforms impedance matrices in a quaternion-like form that is helpful to assess the root cause of instabilities. The theoretical contributions are validated using a case study consisting of a power electronic converter connected to a weak grid that has been previously analysed in the literature using existing techniques.

</details>


### [103] [Task-Specific Trust Evaluation for Multi-Hop Collaborator Selection via GNN-Aided Distributed Agentic AI](https://arxiv.org/abs/2512.05788)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: eess.SY

TL;DR: 提出GADAI框架，使用图神经网络和分布式智能体AI来评估多跳协作设备的任务特定可信度，实现隐私保护的分布式协作路径规划


<details>
  <summary>Details</summary>
Motivation: 网络设备协作任务成功依赖于选择可信的协作伙伴，但准确评估多跳协作设备的任务特定可信度非常复杂，因为需要考虑历史协作可靠性、动态变化的资源条件以及不断演化的网络拓扑等多种因素

Method: 提出GADAI框架：1) 使用GNN辅助模型从历史协作数据推断设备可信度，通过多跳邻居传播聚合信任信息；2) 采用隐私保护资源评估机制，每个设备部署AI模型驱动的智能体，自主判断本地资源是否满足任务需求；3) 结合评估结果，让可信设备通过智能体分布式协调任务导向的多跳协作路径

Result: 实验结果表明，GADAI在规划最大化任务完成价值的多跳路径方面优于对比算法

Conclusion: GADAI框架通过分离评估设备任务特定可信度的不同方面并联合集成，有效解决了多跳协作设备选择中的复杂信任评估问题，实现了隐私保护的分布式协作

Abstract: The success of collaborative task completion among networked devices hinges on the effective selection of trustworthy collaborators. However, accurate task-specific trust evaluation of multi-hop collaborators can be extremely complex. The reason is that their trust evaluation is determined by a combination of diverse trust-related perspectives with different characteristics, including historical collaboration reliability, volatile and sensitive conditions of available resources for collaboration, as well as continuously evolving network topologies. To address this challenge, this paper presents a graph neural network (GNN)-aided distributed agentic AI (GADAI) framework, in which different aspects of devices' task-specific trustworthiness are separately evaluated and jointly integrated to facilitate multi-hop collaborator selection. GADAI first utilizes a GNN-assisted model to infer device trust from historical collaboration data. Specifically, it employs GNN to propagate and aggregate trust information among multi-hop neighbours, resulting in more accurate device reliability evaluation. Considering the dynamic and privacy-sensitive nature of device resources, a privacy-preserving resource evaluation mechanism is implemented using agentic AI. Each device hosts a large AI model-driven agent capable of autonomously determining whether its local resources meet the requirements of a given task, ensuring both task-specific and privacy-preserving trust evaluation. By combining the outcomes of these assessments, only the trusted devices can coordinate a task-oriented multi-hop cooperation path through their agents in a distributed manner. Experimental results show that our proposed GADAI outperforms the comparison algorithms in planning multi-hop paths that maximize the value of task completion.

</details>


### [104] [Safe Output Regulation of Coupled Hyperbolic PDE-ODE Systems](https://arxiv.org/abs/2512.05822)
*Ji Wang,Miroslav Krstic*

Main category: eess.SY

TL;DR: 提出一种针对2×2双曲PDE-ODE耦合系统的安全输出调节控制策略，通过非超调反步法设计状态反馈控制器，实现指数输出调节并保证输出安全约束，适用于UAV缆绳悬挂负载的避障场景。


<details>
  <summary>Details</summary>
Motivation: 针对具有分布式扰动的PDE-ODE耦合系统，需要同时实现输出调节和安全约束，特别是在UAV缆绳悬挂负载等应用中，需要确保负载在跟踪期望轨迹时避免与障碍物碰撞。

Method: 采用非超调反步法设计状态反馈控制器，结合状态观测器和扰动估计器处理不可测状态和外部扰动，推导估计误差的显式边界并构建鲁棒安全调节器。

Result: 控制方案保证：1）输出保持在安全区域内或规定时间内恢复安全；2）输出跟踪误差指数收敛到零；3）观测器准确估计分布式状态和扰动，估计误差指数收敛；4）闭环系统所有信号有界。

Conclusion: 该方法有效解决了PDE-ODE耦合系统的安全输出调节问题，在UAV缆绳悬挂负载的避障场景中验证了其有效性，实现了负载的安全轨迹跟踪。

Abstract: This paper presents a safe output regulation control strategy for a class of systems modeled by a coupled $2\times 2$ hyperbolic PDE-ODE structure, subject to fully distributed disturbances throughout the system. A state-feedback controller is developed by the {nonovershooting backstepping} method to simultaneously achieve exponential output regulation and enforce safety constraints on the system output, which is the state furthest from the control input. To handle unmeasured PDE states and external disturbances, a state observer and a disturbance estimator are designed. Explicit bounds on the estimation errors are derived and used to construct a robust safe regulator that accounts for the uncertainties. The proposed control scheme guarantees that: 1) If the system output is initially within the safe region, it remains there; otherwise, it will be rescued to the safety within a prescribed time; 2) The output tracking error converges to zero exponentially; 3) The observer accurately estimates both the distributed states and external disturbances, with estimation errors converging to zero exponentially; 4) All signals in the closed-loop system remain bounded. The effectiveness of the proposed method is demonstrated through a UAV delivery scenario with a cable-suspended payload, where the payload is regulated to track a desired reference while avoiding collisions with barriers.

</details>


### [105] [3D-ICE 4.0: Accurate and efficient thermal modeling for 2.5D/3D heterogeneous chiplet systems](https://arxiv.org/abs/2512.05823)
*Kai Zhu,Darong Huang,Luis Costero,David Atienza*

Main category: eess.SY

TL;DR: 3D-ICE 4.0：针对异构2.5D/3D芯片系统的热建模框架，相比现有工具实现3.61-6.46倍加速，网格复杂度降低23.3%以上，保持精度


<details>
  <summary>Details</summary>
Motivation: 先进2.5D/3D芯片系统功率密度增加、散热路径复杂，传统紧凑热模型难以处理现代架构的复杂性和异构性，需要高效的热建模框架

Method: 提出3D-ICE 4.0框架，关键创新包括：1）从工业布局直接保留材料异构性和各向异性，集成OpenMP和SuperLU MT并行求解器；2）自适应垂直层划分准确建模垂直热传导；3）温度感知非均匀网格生成

Result: 在不同基准测试中，3D-ICE 4.0相比最先进工具实现3.61-6.46倍加速，网格复杂度降低23.3%以上且不损失精度；相比COMSOL商业软件，能有效捕捉横向和垂直热流

Conclusion: 3D-ICE 4.0是新兴异构2.5D/3D集成系统热建模的高效解决方案，验证了其精度和鲁棒性

Abstract: The increasing power densities and intricate heat dissipation paths in advanced 2.5D/3D chiplet systems necessitate thermal modeling frameworks that deliver detailed thermal maps with high computational efficiency. Traditional compact thermal models (CTMs) often struggle to scale with the complexity and heterogeneity of modern architectures. This work introduces 3D-ICE 4.0, designed for heterogeneous chip-based systems. Key innovations include: (i) preservation of material heterogeneity and anisotropy directly from industrial layouts, integrated with OpenMP and SuperLU MT-based parallel solvers for scalable performance, (ii) adaptive vertical layer partitioning to accurately model vertical heat conduction, and (iii) temperature-aware non-uniform grid generation. The results with different benchmarks demonstrate that 3D-ICE 4.0 achieves speedups ranging from 3.61x-6.46x over state-of-the-art tools, while reducing grid complexity by more than 23.3% without compromising accuracy. Compared to the commercial software COMSOL, 3D-ICE 4.0 effectively captures both lateral and vertical heat flows, validating its precision and robustness. These advances demonstrate that 3D-ICE 4.0 is an efficient solution for thermal modeling in emerging heterogeneous 2.5D/3D integrated systems.

</details>


### [106] [Advanced Hybrid Automated Insulin Delivery System based on Successive Linearization Model Predictive Control: The UniBE System](https://arxiv.org/abs/2512.05827)
*Vihangkumar V. Naik,Eleonora Manzoni,Clara Escorihuela-Altaba,Jose Garcia-Tirado*

Main category: eess.SY

TL;DR: UniBE hAID系统采用基于连续线性化模型预测控制（MPC）的框架，通过实时调整胰岛素输注边界来适应血糖动态变化，在仿真测试中表现出优异的血糖控制效果和对临床干扰的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前混合自动胰岛素输送（hAID）系统主要依赖线性或线性化血糖稳态模型，可能影响预测准确性和控制器决策的及时性。生理变异性进一步增加了胰岛素需求的复杂性，需要能够动态适应并减轻用户负担的控制器。

Method: 提出基于连续线性化模型预测控制（MPC）的UniBE hAID系统框架，整合基础胰岛素输注与胰岛素推注模块，实时调整胰岛素输注边界以适应血糖动态变化，同时考虑自动和用户发起的输入。使用FDA认可的UVa/Padova代谢模拟器进行九种场景的仿真评估。

Result: 在基准场景中，UniBE系统平均血糖达标时间（TIR）为92.0±13.2%，低血糖时间（TBR）为0.1±0.2%，高血糖时间（TAR）为7.9±13.2%。在各种扰动场景中，TIR保持在75.1-92.8%之间，低血糖发生率低，显示出对临床相关干扰的良好鲁棒性。

Conclusion: UniBE hAID系统通过连续线性化MPC方法有效解决了传统线性模型的局限性，在仿真测试中表现出优异的血糖控制性能和临床干扰下的鲁棒性，为1型糖尿病患者的自动化胰岛素治疗提供了有前景的解决方案。

Abstract: Background and objective: Hybrid automated insulin delivery (hAID) systems represent the most advanced therapy for type 1 diabetes (T1D). Current systems rely on linear or linearized models of glucose homeostasis, which may compromise prediction accuracy and, in turn, timely decision-making by the controller. Physiological variability further complicates insulin requirements, underscoring the need for controllers that adapt dynamically and reduce user burden. Methods: We introduce the University of Bern (UniBE) hAID system, a framework based on successive linearization model predictive control (MPC). The controller integrates basal insulin infusion with the insulin bolus delivery module for meal-related and corrective bolus dosing, adapting bounds in real time to glucose dynamics while accounting for both automated and user-initiated inputs. In-silico evaluation was conducted using the commercial version of the FDA-accepted UVa/Padova metabolic simulator across nine scenarios involving persistent and time-varying errors in meal timing, carbohydrate estimation, and basal insulin profiles. Results: In the baseline scenario, UniBE achieved a mean time in range of 92.0+-13.2%, with time below range at 0.1+-0.2% and time above range at 7.9+-13.2%. Across perturbation scenarios, time in range remained between 75.1 and 92.8%, with low hypoglycemia incidence, demonstrating resilience to clinically relevant disturbances.

</details>


### [107] [A Hybrid Dynamic Model for Predicting Human Cognition and Reliance during Automated Driving](https://arxiv.org/abs/2512.05845)
*Sibibalan Jeevanandam,Neera Jain*

Main category: eess.SY

TL;DR: 提出一个12参数的混合动态模型，同时捕捉信任、感知风险和脑力负荷三个认知状态的连续动态变化，以及自动化依赖的离散转换。


<details>
  <summary>Details</summary>
Motivation: 需要建立可解释的认知状态动态模型，以理解人类在自动化系统中的依赖行为，为以人为本的车辆自动化设计提供依据。

Method: 使用一阶仿射差分方程建模认知状态的连续动态，依赖状态作为离散变量，其转换取决于认知状态是否满足阈值条件。基于16名参与者的驾驶模拟数据，估计个体化参数。

Result: 模型能很好地拟合多个参与者的观察轨迹，依赖行为主要受信任、感知风险或两者共同影响。模型参数差异揭示了认知状态演化时间尺度的个体差异及其受任务复杂度的影响。

Conclusion: 该模型具有可解释性，适合在线参数自适应，为理解人类在自动化系统中的认知动态和设计以人为本的车辆自动化系统提供了重要工具。

Abstract: We propose a simple (12 parameter) hybrid dynamic model that simultaneously captures the continuous-valued dynamics of three human cognitive states-trust, perceived risk, and mental workload-as well as discrete transitions in reliance on the automation. The discrete-time dynamic evolution of each cognitive state is modeled using a first-order affine difference equation. Reliance is defined as a single discrete-valued state, whose evolution at each time step depends on the cognitive states satisfying certain threshold conditions. Using data collected from 16 participants, we estimate participant-specific model parameters based on their reliance on the automation and intermittently self-reported cognitive states during a continuous drive in a vehicle simulator. The model can be estimated using a single user's trajectory data (e.g. 8 minutes of driving), making it suitable for online parameter adaptation methods. Our results show that the model fits the observed trajectories well for several participants, with their reliance behavior primarily influenced by trust, perceived risk, or both. Importantly, the model is interpretable, such that the variations in model parameters across participants provide insights into differences in the time scales over which cognitive states evolve, and how these states are influenced by task complexity. Implications on the design of human-centric vehicle automation design are discussed.

</details>


### [108] [InstructMPC: A Human-LLM-in-the-Loop Framework for Context-Aware Power Grid Control](https://arxiv.org/abs/2512.05876)
*Ruixiang Wu,Jiahao Ai,Tinko Sebastian Bartels*

Main category: eess.SY

TL;DR: 提出InstructMPC框架，将大语言模型与模型预测控制结合，通过上下文扰动预测器实现电网的上下文感知决策，具有在线调参机制和理论性能保证。


<details>
  <summary>Details</summary>
Motivation: 传统基于历史负荷预测的静态优化方法无法捕捉电网实时运行中的复杂情境（如维护指令、紧急拓扑变化、事件驱动的负荷激增），需要能理解上下文信息的决策框架。

Method: InstructMPC框架：1) 使用LLM生成上下文感知预测；2) 通过上下文扰动预测器将上下文信息转化为预测扰动轨迹；3) 将预测轨迹整合到MPC优化中；4) 采用在线调参机制，基于实际控制成本持续更新预测器参数。

Result: 在线调参机制具有理论保证，对于线性动态系统，通过定制损失函数优化可实现O(√(T log T))的遗憾界，确保任务感知学习和适应非平稳电网条件。

Conclusion: InstructMPC通过整合LLM的上下文理解能力和MPC的优化控制，为高可再生能源渗透的电网提供了闭环、自适应、任务感知的决策框架，优于传统开环预测方法。

Abstract: The transition toward power grids with high renewable penetration demands context-aware decision making frameworks. Traditional operational paradigms, which rely on static optimization of history-based load forecasting, often fail to capture the complex nature of real-time operational conditions, such as operator-issued maintenance mandates, emergency topology changes, or event-driven load surges. To address this challenge, we introduce InstructMPC, a closed-loop framework that integrates Large Language Models~(LLMs) to generate context-aware predictions, enabling the controller to optimize power system operation. Our method employs a Contextual Disturbances Predictor~(CDP) module to translate contextual information into predictive disturbance trajectories, which are then incorporated into the Model Predictive Control~(MPC) optimization. Unlike conventional open-loop forecasting frameworks, InstructMPC features an online tuning mechanism where the predictor's parameters are continuously updated based on the realized control cost with a theoretical guarantee, achieving a regret bound of $O(\sqrt{T \log T})$ for linear dynamics when optimized via a tailored loss function, ensuring task-aware learning and adaption to non-stationary grid conditions.

</details>


### [109] [Log-linear Dynamic Inversion for Thrusting Spacecraft on SE2(3)](https://arxiv.org/abs/2512.05888)
*Micah K. Condie,Abigaile E. Woodbury,Li-Yu Lin,Kartik A. Pant,Mike Walker,James Goppert*

Main category: eess.SY

TL;DR: 论文展示了推力航天器动力学可在SE2(3)李群中嵌入为群仿射形式，误差在李代数坐标中呈精确线性演化，使线性分析工具可直接应用于航天器运动控制。


<details>
  <summary>Details</summary>
Motivation: 传统局部线性化方法（如TH/YA）难以实现卫星对接、自主交会、鲁棒控制器设计和凸安全认证等复杂任务，需要更精确的数学框架来处理航天器非线性动力学。

Method: 通过前馈控制律将推力航天器动力学嵌入SE2(3)李群，使其具有群仿射结构，从而误差在李代数坐标中呈精确线性演化（对数线性动力学）。

Result: 数值模拟证实线性李代数动力学预测的误差与完整非线性系统计算的误差完全匹配，验证了精确对数线性行为，使线性分析工具可直接应用于航天器运动。

Conclusion: 该群仿射结构为卫星对接、自主交会、鲁棒控制器设计和凸安全认证提供了严格的数学基础，克服了传统局部线性化方法的局限性。

Abstract: We show that the dynamics of a thrusting spacecraft can be embedded in the Lie group SE2(3) in a form that is group-affine with application of a feed-forward control law. This structure implies that the configuration-tracking error evolves exactly linearly in the associated Lie algebra coordinates (log-linear dynamics), rather than arising from a local linearization of the nonlinear system. As a result, a broad class of linear analysis and synthesis tools becomes directly applicable to powered spacecraft motion on SE2(3). A simple numerical example confirms that the error predicted by the linear Lie-algebra dynamics matches the error computed from the full nonlinear system, illustrating the exact log-linear behavior. This foundational property opens a path toward rigorous tools for satellite docking, autonomous rendezvous and proximity operations, robust controller design, and convex safety certification-capabilities that are difficult to achieve with classical local linearizations such as Tschauner-Hempel/Yamanaka-Ankersen (TH/YA).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [110] [Advanced Unsupervised Learning: A Comprehensive Overview of Multi-View Clustering Techniques](https://arxiv.org/abs/2512.05169)
*Abdelmalik Moujahid,Fadi Dornaika*

Main category: cs.LG

TL;DR: 这篇论文是一篇关于多视图聚类(MVC)的综述性文章，系统性地分类了多视图聚类方法，分析了各种方法的优缺点，并讨论了该领域的未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 机器学习技术面临计算约束、单视图学习算法局限性以及处理来自不同领域、来源或视图的大数据集复杂性等挑战。多视图聚类作为无监督多视图学习的一种，能够弥补单视图方法的不足，提供更丰富的数据表示和有效的解决方案。

Method: 对140多篇基础和最新文献进行系统综述，将多视图聚类方法分类为协同训练、协同正则化、子空间、深度学习、基于核、基于锚点和基于图等策略，并比较了早期融合、晚期融合和联合学习等集成策略。

Result: 提供了多视图聚类方法的系统性分类框架，深入分析了各种方法的优缺点和实际挑战（如可扩展性和不完整数据），并探讨了在医疗保健、多媒体和社交网络分析等领域的实际应用案例。

Conclusion: 该研究填补了多视图聚类研究中的现有空白，为该领域的进一步发展提供了可操作的见解，并展望了新兴趋势、跨学科应用和未来研究方向。

Abstract: Machine learning techniques face numerous challenges to achieve optimal performance. These include computational constraints, the limitations of single-view learning algorithms and the complexity of processing large datasets from different domains, sources or views. In this context, multi-view clustering (MVC), a class of unsupervised multi-view learning, emerges as a powerful approach to overcome these challenges. MVC compensates for the shortcomings of single-view methods and provides a richer data representation and effective solutions for a variety of unsupervised learning tasks. In contrast to traditional single-view approaches, the semantically rich nature of multi-view data increases its practical utility despite its inherent complexity. This survey makes a threefold contribution: (1) a systematic categorization of multi-view clustering methods into well-defined groups, including co-training, co-regularization, subspace, deep learning, kernel-based, anchor-based, and graph-based strategies; (2) an in-depth analysis of their respective strengths, weaknesses, and practical challenges, such as scalability and incomplete data; and (3) a forward-looking discussion of emerging trends, interdisciplinary applications, and future directions in MVC research. This study represents an extensive workload, encompassing the review of over 140 foundational and recent publications, the development of comparative insights on integration strategies such as early fusion, late fusion, and joint learning, and the structured investigation of practical use cases in the areas of healthcare, multimedia, and social network analysis. By integrating these efforts, this work aims to fill existing gaps in MVC research and provide actionable insights for the advancement of the field.

</details>


### [111] [Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models](https://arxiv.org/abs/2512.05216)
*Rajna Fani,Rafi Al Attrach,David Restrepo,Yugang Jia,Leo Anthony Celi,Peter Schüffler*

Main category: cs.LG

TL;DR: 提出CV-Masking方法，根据生物标志物的内在波动性自适应调整掩码概率，相比随机掩码在EHR表示学习中取得更好效果


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法在电子健康记录中通常使用均匀随机掩码，假设所有特征同等可预测。但实际上实验室测试指标具有显著异质性波动性：有些生物标志物稳定，有些波动大且更难建模。临床上，波动性大的生物标志物通常指示急性病理生理变化，需要更复杂的建模来捕捉其时间模式。

Method: 提出波动性感知预训练策略CV-Masking，根据每个特征的内在变异性自适应调整掩码概率。结合与临床工作流程对齐的仅值掩码目标，相比随机和基于方差的策略有系统性改进。

Result: 在大规模实验室测试面板上的实验表明，CV-Masking增强了重建能力，提高了下游预测性能，加速了收敛，产生了更鲁棒和临床有意义的EHR表示。

Conclusion: CV-Masking方法通过考虑生物标志物的内在波动性，为电子健康记录的掩码自编码器预训练提供了更有效的策略，能够产生更好的临床表示。

Abstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly assuming all features are equally predictable. In reality, laboratory tests exhibit substantial heterogeneity in volatility: some biomarkers (e.g., sodium) remain stable, while others (e.g., lactate) fluctuate considerably and are more difficult to model. Clinically, volatile biomarkers often signal acute pathophysiology and require more sophisticated modeling to capture their complex temporal patterns. We propose a volatility-aware pretraining strategy, Coefficient of Variation Masking (CV-Masking), that adaptively adjusts masking probabilities according to the intrinsic variability of each feature. Combined with a value-only masking objective aligned with clinical workflows, CV-Masking yields systematic improvements over random and variance-based strategies. Experiments on a large panel of laboratory tests show that CV-Masking enhances reconstruction, improves downstream predictive performance, and accelerates convergence, producing more robust and clinically meaningful EHR representations.

</details>


### [112] [Rethinking Tokenization for Clinical Time Series: When Less is More](https://arxiv.org/abs/2512.05217)
*Rafi Al Attrach,Rajna Fani,David Restrepo,Yugang Jia,Peter Schüffler*

Main category: cs.LG

TL;DR: 系统评估临床时间序列建模中的分词策略，发现时间编码无显著收益，值特征重要性因任务而异，冻结预训练编码器优于可训练版本且参数更少。


<details>
  <summary>Details</summary>
Motivation: 当前对电子健康记录分词策略的有效性缺乏公平比较，需要系统评估不同分词方法在临床时间序列建模中的表现。

Method: 在MIMIC-IV数据集上使用基于Transformer的架构，通过控制消融实验评估四种临床预测任务中的分词策略，包括时间编码、值特征、代码序列等不同组合。

Result: 1) 显式时间编码对下游任务无一致统计显著收益；2) 值特征重要性任务依赖，影响死亡率预测但不影响再入院预测；3) 冻结预训练代码编码器大幅优于可训练版本且参数更少；4) 更大临床编码器带来一致改进。

Conclusion: 更简单、参数高效的方法在许多情况下能达到强性能，但最优分词策略仍依赖具体任务。研究为公平分词比较提供框架，并揭示了临床时间序列建模中的反直觉发现。

Abstract: Tokenization strategies shape how models process electronic health records, yet fair comparisons of their effectiveness remain limited. We present a systematic evaluation of tokenization approaches for clinical time series modeling using transformer-based architectures, revealing task-dependent and sometimes counterintuitive findings about temporal and value feature importance. Through controlled ablations across four clinical prediction tasks on MIMIC-IV, we demonstrate that explicit time encodings provide no consistent statistically significant benefit for the evaluated downstream tasks. Value features show task-dependent importance, affecting mortality prediction but not readmission, suggesting code sequences alone can carry sufficient predictive signal. We further show that frozen pretrained code encoders dramatically outperform their trainable counterparts while requiring dramatically fewer parameters. Larger clinical encoders provide consistent improvements across tasks, benefiting from frozen embeddings that eliminate computational overhead. Our controlled evaluation enables fairer tokenization comparisons and demonstrates that simpler, parameter-efficient approaches can, in many cases, achieve strong performance, though the optimal tokenization strategy remains task-dependent.

</details>


### [113] [Mitigating the Antigenic Data Bottleneck: Semi-supervised Learning with Protein Language Models for Influenza A Surveillance](https://arxiv.org/abs/2512.05222)
*Yanhua Xu*

Main category: cs.LG

TL;DR: 结合预训练蛋白质语言模型与半监督学习，在标记数据稀缺时仍能准确预测流感病毒抗原性，解决传统HI检测的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 流感病毒抗原性进化快，需要频繁更新疫苗，但传统血凝抑制试验劳动密集且难以扩展，导致基因组数据远多于可用表型标记，限制了监督模型的有效性。

Method: 评估两种半监督学习策略（自训练和标签传播），对比四种蛋白质语言模型嵌入（ESM-2、ProtVec、ProtT5、ProtBert），应用于血凝素序列，使用嵌套交叉验证框架模拟不同标记数据可用性（25%、50%、75%、100%）。

Result: 半监督学习在标记数据稀缺时持续提升性能，自训练与ProtVec组合获得最大相对增益，ESM-2在仅25%标记数据下F1分数仍高于0.82，H1N1和H9N2预测准确度高，H3N2虽具挑战性但半监督学习缓解了性能下降。

Conclusion: 蛋白质语言模型与半监督学习结合可解决抗原性标记瓶颈，更有效利用未标记监测序列，支持快速变异优先级排序和及时疫苗株选择。

Abstract: Influenza A viruses (IAVs) evolve antigenically at a pace that requires frequent vaccine updates, yet the haemagglutination inhibition (HI) assays used to quantify antigenicity are labor-intensive and unscalable. As a result, genomic data vastly outpace available phenotypic labels, limiting the effectiveness of traditional supervised models. We hypothesize that combining pre-trained Protein Language Models (PLMs) with Semi-Supervised Learning (SSL) can retain high predictive accuracy even when labeled data are scarce. We evaluated two SSL strategies, Self-training and Label Spreading, against fully supervised baselines using four PLM-derived embeddings (ESM-2, ProtVec, ProtT5, ProtBert) applied to haemagglutinin (HA) sequences. A nested cross-validation framework simulated low-label regimes (25%, 50%, 75%, and 100% label availability) across four IAV subtypes (H1N1, H3N2, H5N1, H9N2). SSL consistently improved performance under label scarcity. Self-training with ProtVec produced the largest relative gains, showing that SSL can compensate for lower-resolution representations. ESM-2 remained highly robust, achieving F1 scores above 0.82 with only 25% labeled data, indicating that its embeddings capture key antigenic determinants. While H1N1 and H9N2 were predicted with high accuracy, the hypervariable H3N2 subtype remained challenging, although SSL mitigated the performance decline. These findings demonstrate that integrating PLMs with SSL can address the antigenicity labeling bottleneck and enable more effective use of unlabeled surveillance sequences, supporting rapid variant prioritization and timely vaccine strain selection.

</details>


### [114] [Developing synthetic microdata through machine learning for firm-level business surveys](https://arxiv.org/abs/2512.05948)
*Jorge Cisneros Paz,Timothy Wojan,Matthew Williams,Jennifer Ozawa,Robert Chew,Kimberly Janda,Timothy Navarro,Michael Floyd,Christine Task,Damon Streat*

Main category: cs.LG

TL;DR: 该论文提出使用机器学习模型生成合成公共使用微观数据样本(PUMS)，以解决美国人口普查局商业数据中的隐私泄露风险，并通过经济计量复制验证合成数据的真实性。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力和大数据可用性的增加，传统匿名化数据面临重新识别的风险，可能违反调查受访者的保密承诺。商业数据尤其具有挑战性，因为企业缺乏匿名性且某些行业在特定地理区域容易被识别。

Method: 使用机器学习模型构建基于年度商业调查(ABS)的合成PUMS，开发质量评估指标，并通过2007年企业主调查的合成PUMS进行实证验证，采用经济计量方法复制已发表的高影响力分析。

Result: 虽然ABS PUMS仍在完善中且结果保密，但2007年企业主调查的合成PUMS展示了与真实数据的高度相似性，通过经济计量复制验证了合成数据的真实性。

Conclusion: 合成数据方法能够保护受访者隐私同时保留关键统计特征，为商业调查数据的安全公开使用提供了可行方案，并讨论了ABS数据的潜在应用场景。

Abstract: Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.

</details>


### [115] [Variance Matters: Improving Domain Adaptation via Stratified Sampling](https://arxiv.org/abs/2512.05226)
*Andrea Napoli,Paul White*

Main category: cs.LG

TL;DR: 提出VaRDASS方法，通过分层采样减少UDA中域差异估计的方差，提高目标域性能


<details>
  <summary>Details</summary>
Motivation: 无监督域适应中域差异估计在随机设置下存在高方差问题，限制了方法的理论优势

Method: 提出VaRDASS方法，针对相关性对齐和MMD两种差异度量推导分层采样目标，设计k-means风格优化算法

Result: 在三个域偏移数据集上实验显示，提高了差异估计准确性和目标域性能

Conclusion: VaRDASS是首个专门针对UDA的随机方差减少技术，在MMD情况下理论最优，能有效改善域适应性能

Abstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high variance in stochastic settings, which can stifle the theoretical benefits of the method. This paper proposes Variance-Reduced Domain Adaptation via Stratified Sampling (VaRDASS), the first specialised stochastic variance reduction technique for UDA. We consider two specific discrepancy measures -- correlation alignment and the maximum mean discrepancy (MMD) -- and derive ad hoc stratification objectives for these terms. We then present expected and worst-case error bounds, and prove that our proposed objective for the MMD is theoretically optimal (i.e., minimises the variance) under certain assumptions. Finally, a practical k-means style optimisation algorithm is introduced and analysed. Experiments on three domain shift datasets demonstrate improved discrepancy estimation accuracy and target domain performance.

</details>


### [116] [MAR-FL: A Communication Efficient Peer-to-Peer Federated Learning System](https://arxiv.org/abs/2512.05234)
*Felix Mulitze,Herbert Woisetschläger,Hans Arno Jacobsen*

Main category: cs.LG

TL;DR: MAR-FL是一种新型的P2P联邦学习系统，通过迭代分组聚合大幅降低通信开销，实现O(N log N)的通信复杂度，相比现有基线O(N²)显著提升可扩展性


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统与分布式机器学习的融合需要高效且鲁棒的联邦学习方法，特别是在无线连接和对等网络动态变化的场景下。现有的P2P FL方法存在通信复杂度过高的问题，限制了实际可扩展性

Method: MAR-FL采用迭代分组聚合机制，通过创新的对等网络联邦学习架构，在保持对网络动态变化鲁棒性的同时，大幅减少通信开销

Result: MAR-FL实现了O(N log N)的通信复杂度，相比现有基线O(N²)显著降低，特别是在聚合轮次中对等节点数量增加时仍能保持高效性。系统对不可靠的FL客户端具有鲁棒性，并能整合隐私计算

Conclusion: MAR-FL为无线环境下的分布式机器学习提供了一种高效、可扩展且鲁棒的P2P联邦学习解决方案，解决了现有方法通信复杂度过高的问题，具有实际应用价值

Abstract: The convergence of next-generation wireless systems and distributed Machine Learning (ML) demands Federated Learning (FL) methods that remain efficient and robust with wireless connected peers and under network churn. Peer-to-peer (P2P) FL removes the bottleneck of a central coordinator, but existing approaches suffer from excessive communication complexity, limiting their scalability in practice. We introduce MAR-FL, a novel P2P FL system that leverages iterative group-based aggregation to substantially reduce communication overhead while retaining resilience to churn. MAR-FL achieves communication costs that scale as O(N log N), contrasting with the O(N^2) complexity of previously existing baselines, and thereby maintains effectiveness especially as the number of peers in an aggregation round grows. The system is robust towards unreliable FL clients and can integrate private computing.

</details>


### [117] [Edged Weisfeiler-Lehman Algorithm](https://arxiv.org/abs/2512.05238)
*Xiao Yue,Bo Liu,Feng Zhang,Guangzhi Qu*

Main category: cs.LG

TL;DR: 提出E-WL算法扩展1-WL以纳入边特征，并基于此构建EGIN模型，在12个边特征图数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统GNN的传播-聚合方法与1-WL算法类似，但1-WL不利用边特征，而许多GNN也存在不利用图数据边特征的缺点，限制了在边特征重要领域的性能提升

Method: 提出E-WL算法扩展原始1-WL算法以纳入边特征，并在此基础上构建EGIN模型，进一步利用边特征进行图学习

Result: 在12个边特征基准图数据集上进行评估，与最先进的基线模型比较，EGIN模型在图形分类任务上总体表现出优越性能

Conclusion: 通过E-WL算法和EGIN模型成功解决了传统方法不利用边特征的问题，在边特征图数据集上取得了更好的图学习性能

Abstract: As a classical approach on graph learning, the propagation-aggregation methodology is widely exploited by many of Graph Neural Networks (GNNs), wherein the representation of a node is updated by aggregating representations from itself and neighbor nodes recursively. Similar to the propagation-aggregation methodology, the Weisfeiler-Lehman (1-WL) algorithm tests isomorphism through color refinement according to color representations of a node and its neighbor nodes. However, 1-WL does not leverage any edge features (labels), presenting a potential improvement on exploiting edge features in some fields. To address this limitation, we proposed a novel Edged-WL algorithm (E-WL) which extends the original 1-WL algorithm to incorporate edge features. Building upon the E-WL algorithm, we also introduce an Edged Graph Isomorphism Network (EGIN) model for further exploiting edge features, which addresses one key drawback in many GNNs that do not utilize any edge features of graph data. We evaluated the performance of proposed models using 12 edge-featured benchmark graph datasets and compared them with some state-of-the-art baseline models. Experimental results indicate that our proposed EGIN models, in general, demonstrate superior performance in graph learning on graph classification tasks.

</details>


### [118] [Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)](https://arxiv.org/abs/2512.05306)
*Y. Sungtaek Ju*

Main category: cs.LG

TL;DR: SVGP KANs：将稀疏变分高斯过程与Kolmogorov-Arnold网络结合，实现可解释且具有不确定性量化的科学机器学习架构。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov-Arnold网络缺乏系统的不确定性量化能力，这在科学应用中至关重要。需要一种既能保持可解释性又能进行贝叶斯推断的架构。

Method: 将稀疏变分高斯过程推断与Kolmogorov-Arnold拓扑结构集成，通过解析矩匹配在深层加性结构中传播不确定性，计算复杂度与样本量呈准线性关系。

Result: 在三个案例研究中展示了框架区分偶然不确定性和认知不确定性的能力：流体流动重建中的异方差测量噪声校准、平流-扩散动力学多步预测中的置信度退化量化、卷积自编码器中的分布外检测。

Conclusion: SVGP KANs是科学机器学习中具有不确定性感知能力的有前景架构，结合了可解释性和贝叶斯推断优势。

Abstract: Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Gaussian process inference with the Kolmogorov-Arnold topology, enabling scalable Bayesian inference with computational complexity quasi-linear in sample size. Through analytic moment matching, we propagate uncertainty through deep additive structures while maintaining interpretability. We use three example studies to demonstrate the framework's ability to distinguish aleatoric from epistemic uncertainty: calibration of heteroscedastic measurement noise in fluid flow reconstruction, quantification of prediction confidence degradation in multi-step forecasting of advection-diffusion dynamics, and out-of-distribution detection in convolutional autoencoders. These results suggest Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KANs) is a promising architecture for uncertainty-aware learning in scientific machine learning.

</details>


### [119] [Bridging quantum and classical computing for partial differential equations through multifidelity machine learning](https://arxiv.org/abs/2512.05241)
*Bruno Jacob,Amanda A. Howard,Panos Stinis*

Main category: cs.LG

TL;DR: 提出多保真度学习框架，用量子求解器生成低保真度解，再用少量经典数据学习校正映射，提升量子PDE求解精度


<details>
  <summary>Details</summary>
Motivation: 量子PDE求解器受限于近端硬件的量子比特数和电路深度，只能获得低保真度解，无法满足实际科学计算需求

Method: 多保真度神经网络架构：先用量子求解器生成大量低保真度解作为代理模型，再用稀疏经典高保真数据学习线性与非线性结合的校正映射

Result: 在粘性Burgers方程和不可压缩Navier-Stokes流等非线性PDE上成功校正粗网格量子预测，实现超出经典训练窗口的时间外推

Conclusion: 该框架弥合了硬件受限量子模拟与应用需求之间的差距，为近端量子设备在科学计算中提取实用价值提供了可行路径

Abstract: Quantum algorithms for partial differential equations (PDEs) face severe practical constraints on near-term hardware: limited qubit counts restrict spatial resolution to coarse grids, while circuit depth limitations prevent accurate long-time integration. These hardware bottlenecks confine quantum PDE solvers to low-fidelity regimes despite their theoretical potential for computational speedup. We introduce a multifidelity learning framework that corrects coarse quantum solutions to high-fidelity accuracy using sparse classical training data, facilitating the path toward practical quantum utility for scientific computing. The approach trains a low-fidelity surrogate on abundant quantum solver outputs, then learns correction mappings through a multifidelity neural architecture that balances linear and nonlinear transformations. Demonstrated on benchmark nonlinear PDEs including viscous Burgers equation and incompressible Navier-Stokes flows via quantum lattice Boltzmann methods, the framework successfully corrects coarse quantum predictions and achieves temporal extrapolation well beyond the classical training window. This strategy illustrates how one can reduce expensive high-fidelity simulation requirements while producing predictions that are competitive with classical accuracy. By bridging the gap between hardware-limited quantum simulations and application requirements, this work establishes a pathway for extracting computational value from current quantum devices in real-world scientific applications, advancing both algorithm development and practical deployment of near-term quantum computing for computational physics.

</details>


### [120] [Robustness Test for AI Forecasting of Hurricane Florence Using FourCastNetv2 and Random Perturbations of the Initial Condition](https://arxiv.org/abs/2512.05323)
*Adam Lizerbram,Shane Stevenson,Iman Khadir,Matthew Tu,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 测试AI天气预报模型FourCastNetv2对输入噪声的鲁棒性，通过注入高斯噪声和完全随机初始条件来评估其对飓风预测的敏感性。


<details>
  <summary>Details</summary>
Motivation: 评估AI天气预报模型对输入噪声和不确定性的鲁棒性对于极端天气事件（如飓风）的预测可靠性至关重要。

Method: 进行两个实验：1) 在飓风Florence的初始条件中注入不同水平的高斯噪声，观察预测轨迹和强度变化；2) 使用完全随机初始条件启动模型，观察模型对无意义输入的响应。

Result: FCNv2在低到中等噪声下能准确保持飓风特征；高噪声下仍能维持基本轨迹和结构，但位置精度下降；模型在所有噪声水平下都低估风暴强度和持续性；完全随机初始条件下，模型在几个时间步后能生成平滑连贯的预测。

Conclusion: FCNv2表现出对输入噪声的良好鲁棒性，倾向于生成稳定平滑的输出，该方法简单且可移植到其他数据驱动的AI天气预报模型。

Abstract: Understanding the robustness of a weather forecasting model with respect to input noise or different uncertainties is important in assessing its output reliability, particularly for extreme weather events like hurricanes. In this paper, we test sensitivity and robustness of an artificial intelligence (AI) weather forecasting model: NVIDIAs FourCastNetv2 (FCNv2). We conduct two experiments designed to assess model output under different levels of injected noise in the models initial condition. First, we perturb the initial condition of Hurricane Florence from the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset (September 13-16, 2018) with varying amounts of Gaussian noise and examine the impact on predicted trajectories and forecasted storm intensity. Second, we start FCNv2 with fully random initial conditions and observe how the model responds to nonsensical inputs. Our results indicate that FCNv2 accurately preserves hurricane features under low to moderate noise injection. Even under high levels of noise, the model maintains the general storm trajectory and structure, although positional accuracy begins to degrade. FCNv2 consistently underestimates storm intensity and persistence across all levels of injected noise. With full random initial conditions, the model generates smooth and cohesive forecasts after a few timesteps, implying the models tendency towards stable, smoothed outputs. Our approach is simple and portable to other data-driven AI weather forecasting models.

</details>


### [121] [When unlearning is free: leveraging low influence points to reduce computational costs](https://arxiv.org/abs/2512.05254)
*Anat Kleiman,Robert Fisher,Ben Deaner,Udi Wieder*

Main category: cs.LG

TL;DR: 本文提出了一种高效的机器学习遗忘框架，通过识别对模型输出影响可忽略的训练数据子集，在遗忘前缩减数据集规模，从而显著降低计算成本（可达约50%）。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习中数据隐私问题的日益突出，从训练模型中遗忘或移除特定数据点的能力变得越来越重要。现有遗忘方法通常平等对待遗忘集中的所有数据点，但作者质疑那些对模型学习影响可忽略的数据点是否真的需要被移除。

Method: 通过对语言和视觉任务中影响函数的比较分析，识别出对模型输出影响可忽略的训练数据子集。基于这一洞察，提出了一个高效的遗忘框架，在遗忘前缩减数据集规模。

Result: 该方法在实际应用中实现了显著的计算节省（可达约50%），通过减少需要处理的数据量来优化遗忘过程。

Conclusion: 挑战了传统遗忘方法平等对待所有数据点的做法，证明通过识别和排除影响可忽略的数据点，可以在保持遗忘效果的同时显著提高计算效率。

Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically treat all points in the forget set equally. In this work, we challenge this approach by asking whether points that have a negligible impact on the model's learning need to be removed. Through a comparative analysis of influence functions across language and vision tasks, we identify subsets of training data with negligible impact on model outputs. Leveraging this insight, we propose an efficient unlearning framework that reduces the size of datasets before unlearning leading to significant computational savings (up to approximately 50 percent) on real world empirical examples.

</details>


### [122] [Text Rationalization for Robust Causal Effect Estimation](https://arxiv.org/abs/2512.05373)
*Lijinghua Zhang,Hengrui Cai*

Main category: cs.LG

TL;DR: CATR框架通过选择稀疏的必要token子集来解决文本因果推断中的维度灾难和重叠性假设违反问题，提高因果效应估计的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 文本数据在因果推断中的应用面临独特挑战：高维文本特征会导致重叠性假设违反，产生极端倾向得分、权重不稳定和方差膨胀等问题。

Method: 提出Confounding-Aware Token Rationalization (CATR)框架，使用残差独立性诊断选择稀疏的必要token子集，保留足够的混杂信息以保证无混杂性，同时丢弃无关文本。

Result: 在合成数据和MIMIC-III数据库的真实世界研究中，CATR相比现有基线方法产生了更准确、稳定且可解释的因果效应估计。

Conclusion: CATR通过选择关键token子集有效缓解了文本因果推断中的观测级重叠性违反问题，提高了因果效应估计的质量和可解释性。

Abstract: Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.

</details>


### [123] [DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models](https://arxiv.org/abs/2512.05287)
*Ziqi Zhang*

Main category: cs.LG

TL;DR: DMAGT是一种基于多层Transformer图神经网络的新型机器学习模型，用于预测药物与miRNA之间的关联，在多个数据集上表现出色（AUC达95.24%），为miRNA药物开发提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验在探索药物与靶向miRNA潜在关联方面存在效率和成本限制，需要更高效的计算方法来加速miRNA药物开发。

Method: 提出DMAGT模型：将药物-miRNA关联转化为图结构，使用Word2Vec嵌入药物分子结构和miRNA碱基结构特征，利用图Transformer模型学习嵌入特征和关系结构来预测关联。

Result: 在ncDR、RNAInter和SM2miR三个数据集上测试，AUC最高达95.24±0.05；比较实验中表现优于其他方法；对5-氟尿嘧啶和奥沙利铂的预测中，前20个最可能关联中有14个得到验证。

Conclusion: DMAGT在预测药物-miRNA关联方面具有优异的性能和稳定性，为miRNA药物开发提供了新的捷径。

Abstract: MiRNAs, due to their role in gene regulation, have paved a new pathway for pharmacology, focusing on drug development that targets miRNAs. However, traditional wet lab experiments are limited by efficiency and cost constraints, making it difficult to extensively explore potential associations between developed drugs and target miRNAs. Therefore, we have designed a novel machine learning model based on a multi-layer transformer-based graph neural network, DMAGT, specifically for predicting associations between drugs and miRNAs. This model transforms drug-miRNA associations into graphs, employs Word2Vec for embedding features of drug molecular structures and miRNA base structures, and leverages a graph transformer model to learn from embedded features and relational structures, ultimately predicting associations between drugs and miRNAs. To evaluate DMAGT, we tested its performance on three datasets composed of drug-miRNA associations: ncDR, RNAInter, and SM2miR, achieving up to AUC of $95.24\pm0.05$. DMAGT demonstrated superior performance in comparative experiments tackling similar challenges. To validate its practical efficacy, we specifically focused on two drugs, namely 5-Fluorouracil and Oxaliplatin. Of the 20 potential drug-miRNA associations identified as the most likely, 14 were successfully validated. The above experiments demonstrate that DMAGT has an excellent performance and stability in predicting drug-miRNA associations, providing a new shortcut for miRNA drug development.

</details>


### [124] [Wasserstein distance based semi-supervised manifold learning and application to GNSS multi-path detection](https://arxiv.org/abs/2512.05567)
*Antoine Blais,Nicolas Couëllan*

Main category: cs.LG

TL;DR: 提出基于最优传输的半监督学习方法，利用Wasserstein距离作为图像相似性度量，通过标签传播机制处理标记数据稀缺问题，在GNSS多径干扰检测应用中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，标记图像数据往往稀缺，而获取大量标记数据成本高昂。需要开发能够有效利用少量标记数据和大量未标记数据的半监督学习方法，特别是在GNSS多径干扰检测等实际应用中。

Method: 基于隐式图传导的半监督学习方法，使用Wasserstein距离作为图像样本间的相似性度量，将最优传输理论融入标签传播机制。通过深度卷积网络学习特征表示，在训练过程中利用标记和未标记数据共同优化模型。

Result: 实验在不同信号条件下进行，结果显示：通过适当选择控制半监督程度和度量敏感度的超参数，分类准确率相比完全监督训练方法有显著提升，验证了该方法在GNSS多径干扰检测中的有效性。

Conclusion: 提出的基于最优传输的半监督学习方法能够有效利用稀缺标记数据，在GNSS多径干扰检测等实际应用中优于完全监督方法，为标记数据有限的场景提供了有效的解决方案。

Abstract: The main objective of this study is to propose an optimal transport based semi-supervised approach to learn from scarce labelled image data using deep convolutional networks. The principle lies in implicit graph-based transductive semi-supervised learning where the similarity metric between image samples is the Wasserstein distance. This metric is used in the label propagation mechanism during learning. We apply and demonstrate the effectiveness of the method on a GNSS real life application. More specifically, we address the problem of multi-path interference detection. Experiments are conducted under various signal conditions. The results show that for specific choices of hyperparameters controlling the amount of semi-supervision and the level of sensitivity to the metric, the classification accuracy can be significantly improved over the fully supervised training method.

</details>


### [125] [Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2512.05291)
*Na Li,Hangguan Shan,Wei Ni,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 提出RSA2C算法，通过RKHS-SHAP状态归因增强Actor-Critic方法，实现可解释性、效率和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有Actor-Critic方法缺乏可解释性，可解释RL方法很少利用状态归因辅助训练，且忽视不同状态维度对奖励的异质性影响

Method: 提出RSA2C算法：1）Actor在向量值RKHS中实现，使用马氏加权算子值核；2）值Critic和优势Critic在标量RKHS中；3）使用稀疏化字典；4）通过RKHS-SHAP计算状态归因，转换为马氏门控权重调节Actor梯度和优势Critic目标

Result: 理论上推导出状态扰动下的全局非渐近收敛界，实验在三个标准连续控制环境中验证了算法的效率、稳定性和可解释性

Conclusion: RSA2C算法通过状态归因增强Actor-Critic方法，在保持效率和稳定性的同时提供了可解释性，解决了现有方法忽视状态维度异质性影响的问题

Abstract: Actor-critic (AC) methods are a cornerstone of reinforcement learning (RL) but offer limited interpretability. Current explainable RL methods seldom use state attributions to assist training. Rather, they treat all state features equally, thereby neglecting the heterogeneous impacts of individual state dimensions on the reward. We propose RKHS--SHAP-based Advanced Actor--Critic (RSA2C), an attribution-aware, kernelized, two-timescale AC algorithm, including Actor, Value Critic, and Advantage Critic. The Actor is instantiated in a vector-valued reproducing kernel Hilbert space (RKHS) with a Mahalanobis-weighted operator-valued kernel, while the Value Critic and Advantage Critic reside in scalar RKHSs. These RKHS-enhanced components use sparsified dictionaries: the Value Critic maintains its own dictionary, while the Actor and Advantage Critic share one. State attributions, computed from the Value Critic via RKHS--SHAP (kernel mean embedding for on-manifold expectations and conditional mean embedding for off-manifold expectations), are converted into Mahalanobis-gated weights that modulate Actor gradients and Advantage Critic targets. Theoretically, we derive a global, non-asymptotic convergence bound under state perturbations, showing stability through the perturbation-error term and efficiency through the convergence-error term. Empirical results on three standard continuous-control environments show that our algorithm achieves efficiency, stability, and interpretability.

</details>


### [126] [Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability](https://arxiv.org/abs/2512.05638)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 论文提出了"模块化喷射"方法，通过分析模块对输入扰动的局部线性响应来识别模型内部分解的唯一性，区别于仅基于预测风险的传统评估。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习仅通过预测风险评估模型，无法确定模型内部分解是否由数据和评估设计唯一确定。需要新的方法来区分不同的模块分解是否在观测上等价。

Method: 提出模块化喷射方法：给定任务流形、模块分解和模块级表示访问，估计经验喷射（描述模块对输入结构化扰动的局部线性响应图）。开发MoJet算法进行经验喷射估计和海市蜃楼诊断。

Result: 在双模块线性回归管道中证明了喷射可识别性定理：在温和的秩假设和模块级喷射访问下，内部分解是唯一确定的。而仅基于风险的评估则允许大量实现相同输入-输出映射的海市蜃楼分解。

Conclusion: 模块化喷射提供了一种超越预测风险评估的新框架，能够识别模型内部分解的唯一性，区分可识别和海市蜃楼机制，为理解模型内部结构提供了新工具。

Abstract: Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.

</details>


### [127] [CFO: Learning Continuous-Time PDE Dynamics via Flow-Matched Neural Operators](https://arxiv.org/abs/2512.05297)
*Xianglong Hou,Xinquan Huang,Paris Perdikaris*

Main category: cs.LG

TL;DR: CFO是一种连续流算子框架，通过流匹配直接学习PDE的右侧项，无需通过ODE求解器反向传播，实现时间分辨率不变性，在长时程稳定性和数据效率上优于自回归方法。


<details>
  <summary>Details</summary>
Motivation: 传统神经算子代理方法采用自回归预测方案，存在误差累积问题且需要均匀时间离散化。需要一种能够学习连续时间PDE动态的方法，同时避免标准连续方法（如神经ODE）的计算负担。

Method: 通过流匹配直接学习PDE右侧项，无需通过ODE求解器反向传播。对轨迹数据进行时间样条拟合，使用节点处时间导数的有限差分估计来构建概率路径，其速度场近似真实PDE动态。通过流匹配训练神经算子来预测这些解析速度场。

Result: 在四个基准测试（Lorenz、1D Burgers、2D扩散反应、2D浅水方程）中，CFO表现出优越的长时程稳定性和显著的数据效率。仅使用25%不规则子采样时间点训练的CFO优于使用完整数据训练的自回归基线，相对误差减少高达87%。

Conclusion: CFO框架通过流匹配直接学习PDE动态，实现了时间分辨率不变性，在训练时接受任意非均匀时间网格采样，在推理时通过ODE积分实现任意时间分辨率查询，同时支持反向时间推理，在效率和准确性方面均优于传统方法。

Abstract: Neural operator surrogates for time-dependent partial differential equations (PDEs) conventionally employ autoregressive prediction schemes, which accumulate error over long rollouts and require uniform temporal discretization. We introduce the Continuous Flow Operator (CFO), a framework that learns continuous-time PDE dynamics without the computational burden of standard continuous approaches, e.g., neural ODE. The key insight is repurposing flow matching to directly learn the right-hand side of PDEs without backpropagating through ODE solvers. CFO fits temporal splines to trajectory data, using finite-difference estimates of time derivatives at knots to construct probability paths whose velocities closely approximate the true PDE dynamics. A neural operator is then trained via flow matching to predict these analytic velocity fields. This approach is inherently time-resolution invariant: training accepts trajectories sampled on arbitrary, non-uniform time grids while inference queries solutions at any temporal resolution through ODE integration. Across four benchmarks (Lorenz, 1D Burgers, 2D diffusion-reaction, 2D shallow water), CFO demonstrates superior long-horizon stability and remarkable data efficiency. CFO trained on only 25% of irregularly subsampled time points outperforms autoregressive baselines trained on complete data, with relative error reductions up to 87%. Despite requiring numerical integration at inference, CFO achieves competitive efficiency, outperforming autoregressive baselines using only 50% of their function evaluations, while uniquely enabling reverse-time inference and arbitrary temporal querying.

</details>


### [128] [NeuroMemFPP: A recurrent neural approach for memory-aware parameter estimation in fractional Poisson process](https://arxiv.org/abs/2512.05893)
*Neha Gupta,Aditya Maheshwari*

Main category: cs.LG

TL;DR: 提出基于LSTM的RNN框架，用于估计分数泊松过程参数，相比传统矩估计法降低55.3%的均方误差，在真实高频数据上有效跟踪日间模式和参数变化。


<details>
  <summary>Details</summary>
Motivation: 分数泊松过程能够建模具有记忆性和长程依赖的事件到达，但传统参数估计方法（如矩估计法）可能不够准确。需要开发更有效的参数估计方法来处理具有复杂时间依赖性的真实数据。

Method: 使用基于长短期记忆网络的循环神经网络框架，从到达时间间隔序列中估计分数泊松过程的两个关键参数μ>0和β∈(0,1)。LSTM能够有效建模时间依赖关系。

Result: 在合成数据上，相比传统矩估计法，该方法将均方误差降低了约55.3%。在两个真实高频数据集（蒙哥马利县紧急呼叫记录和AAPL股票交易数据）上，LSTM能够有效跟踪日间模式和参数变化。

Conclusion: 提出的LSTM框架能够有效估计分数泊松过程参数，在合成和真实数据上都表现出优越性能，特别适用于具有复杂时间依赖性的高频数据。

Abstract: In this paper, we propose a recurrent neural network (RNN)-based framework for estimating the parameters of the fractional Poisson process (FPP), which models event arrivals with memory and long-range dependence. The Long Short-Term Memory (LSTM) network estimates the key parameters $μ>0$ and $β\in(0,1)$ from sequences of inter-arrival times, effectively modeling their temporal dependencies. Our experiments on synthetic data show that the proposed approach reduces the mean squared error (MSE) by about 55.3\% compared to the traditional method of moments (MOM) and performs reliably across different training conditions. We tested the method on two real-world high-frequency datasets: emergency call records from Montgomery County, PA, and AAPL stock trading data. The results show that the LSTM can effectively track daily patterns and parameter changes, indicating its effectiveness on real-world data with complex time dependencies.

</details>


### [129] [On the Bayes Inconsistency of Disagreement Discrepancy Surrogates](https://arxiv.org/abs/2512.05931)
*Neil G. Marchant,Andrew C. Cullen,Feng Liu,Sarah M. Erfani*

Main category: cs.LG

TL;DR: 论文提出了一种新的分歧损失函数，解决了现有代理损失在分布偏移下不一致的问题，提供了更准确的分歧差异估计。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在现实世界部署中常因分布偏移而失效。虽然分歧差异方法被用于处理分布偏移问题，但现有代理损失函数存在贝叶斯不一致性缺陷，无法有效最大化真实的分歧差异。

Method: 提出新的理论分析框架，为代理损失的最优性差距提供上下界。基于此理论，设计了一种新的分歧损失函数，与交叉熵结合使用，形成可证明一致的代理损失。

Result: 在多种基准测试上的实验表明，新方法比现有方法能提供更准确、更稳健的分歧差异估计，特别是在具有挑战性的对抗条件下表现更优。

Conclusion: 通过理论分析和实验验证，论文提出的新分歧损失函数解决了现有代理损失的贝叶斯不一致性问题，为分布偏移下的模型鲁棒性评估提供了更可靠的工具。

Abstract: Deep neural networks often fail when deployed in real-world contexts due to distribution shift, a critical barrier to building safe and reliable systems. An emerging approach to address this problem relies on \emph{disagreement discrepancy} -- a measure of how the disagreement between two models changes under a shifting distribution. The process of maximizing this measure has seen applications in bounding error under shifts, testing for harmful shifts, and training more robust models. However, this optimization involves the non-differentiable zero-one loss, necessitating the use of practical surrogate losses. We prove that existing surrogates for disagreement discrepancy are not Bayes consistent, revealing a fundamental flaw: maximizing these surrogates can fail to maximize the true disagreement discrepancy. To address this, we introduce new theoretical results providing both upper and lower bounds on the optimality gap for such surrogates. Guided by this theory, we propose a novel disagreement loss that, when paired with cross-entropy, yields a provably consistent surrogate for disagreement discrepancy. Empirical evaluations across diverse benchmarks demonstrate that our method provides more accurate and robust estimates of disagreement discrepancy than existing approaches, particularly under challenging adversarial conditions.

</details>


### [130] [The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?](https://arxiv.org/abs/2512.05311)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee*

Main category: cs.LG

TL;DR: 研究评估SOTA模型区分人类与LLM生成科学想法的能力，发现经过多次改写后检测性能下降25.4%，加入研究问题上下文可提升2.97%性能，简化改写风格对检测挑战最大


<details>
  <summary>Details</summary>
Motivation: 随着LLM作为研究代理的依赖增加，区分LLM与人类生成的想法对于理解LLM研究能力的认知差异变得至关重要。虽然LLM生成文本检测已有广泛研究，但区分人类与LLM生成的科学想法仍是未探索领域。

Method: 系统评估SOTA机器学习模型区分人类与LLM生成想法的能力，特别关注经过连续改写阶段后的表现。研究包含将研究问题作为上下文信息的影响分析。

Result: SOTA模型在来源归因方面面临挑战，经过五次连续改写后检测性能平均下降25.4%。加入研究问题作为上下文信息可将检测性能提升最多2.97%。检测算法在想法被改写成简化的非专家风格时表现最差，这是导致可区分LLM特征消失的主要原因。

Conclusion: 区分人类与LLM生成的科学想法具有挑战性，特别是经过改写后。上下文信息可略微改善检测，但简化改写风格会显著降低检测效果，表明需要更鲁棒的检测方法。

Abstract: With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs' research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.

</details>


### [131] [Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay](https://arxiv.org/abs/2512.05320)
*Mehmet Efe Lorasdagi,Dogan Can Cicek,Furkan Burak Mutlu,Suleyman Serdar Kozat*

Main category: cs.LG

TL;DR: 提出DPER方法，通过为Actor和Critic网络分别采样不同的经验回放批次，提升深度确定性策略梯度算法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的Actor-Critic架构通常使用相同的经验回放批次训练两个网络，但由于Actor和Critic的学习目标和更新动态不同，这种统一采样可能不是最优的。

Method: 提出解耦优先经验回放（DPER），允许Actor和Critic独立采样不同的经验批次，该方法可与任何连续控制领域的离策略深度强化学习算法集成，并与TD3算法结合进行评估。

Result: 在多个MuJoCo任务中，DPER优于传统的经验回放策略（如普通经验回放和优先经验回放）。

Conclusion: 解耦Actor和Critic的经验回放可以改善训练动态和最终策略质量，DPER为广泛的Actor-Critic离策略强化学习算法提供了通用的性能提升机制。

Abstract: Background: Deep Deterministic Policy Gradient-based reinforcement learning algorithms utilize Actor-Critic architectures, where both networks are typically trained using identical batches of replayed transitions. However, the learning objectives and update dynamics of the Actor and Critic differ, raising concerns about whether uniform transition usage is optimal.
  Objectives: We aim to improve the performance of deep deterministic policy gradient algorithms by decoupling the transition batches used to train the Actor and the Critic. Our goal is to design an experience replay mechanism that provides appropriate learning signals to each component by using separate, tailored batches.
  Methods: We introduce Decoupled Prioritized Experience Replay (DPER), a novel approach that allows independent sampling of transition batches for the Actor and the Critic. DPER can be integrated into any off-policy deep reinforcement learning algorithm that operates in continuous control domains. We combine DPER with the state-of-the-art Twin Delayed DDPG algorithm and evaluate its performance across standard continuous control benchmarks.
  Results: DPER outperforms conventional experience replay strategies such as vanilla experience replay and prioritized experience replay in multiple MuJoCo tasks from the OpenAI Gym suite.
  Conclusions: Our findings show that decoupling experience replay for Actor and Critic networks can enhance training dynamics and final policy quality. DPER offers a generalizable mechanism that enhances performance for a wide class of actor-critic off-policy reinforcement learning algorithms.

</details>


### [132] [Non-Convex Federated Optimization under Cost-Aware Client Selection](https://arxiv.org/abs/2512.05327)
*Xiaowen Jiang,Anton Rodomanov,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 论文提出了一种新的联邦优化模型，量化通信和本地计算复杂度，并基于SAGA开发了RG-SAGA算法，在非凸优化中实现了最佳通信和本地计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有联邦优化算法采用不同的客户端选择策略（随机采样、全客户端通信或混合方案），这些策略在实际中产生不同的通信成本，但现有比较指标未能区分这些差异。

Method: 提出新的联邦优化模型量化通信和本地计算复杂度；基于SAGA方差缩减梯度估计器开发RG-SAGA算法，采用递归梯度技术改进误差界；使用不精确复合梯度方法配合精心构造的梯度估计器和辅助子问题求解过程。

Result: 新算法在非凸优化中实现了现有联邦优化方法中最佳的通信和本地计算复杂度；推导了SAGA的新方差界，证明其能利用函数相似性；通过递归梯度技术改进了SAGA和SVRG等条件无偏梯度估计器的误差界。

Conclusion: 提出的新模型能更准确地比较不同客户端选择策略的联邦优化算法，RG-SAGA算法在通信和计算效率方面达到最优性能，为联邦学习优化提供了新的理论框架和高效算法。

Abstract: Different federated optimization algorithms typically employ distinct client-selection strategies: some methods communicate only with a randomly sampled subset of clients at each round, while others need to periodically communicate with all clients or use a hybrid scheme that combines both strategies. However, existing metrics for comparing optimization methods typically do not distinguish between these strategies, which often incur different communication costs in practice. To address this disparity, we introduce a simple and natural model of federated optimization that quantifies communication and local computation complexities. This new model allows for several commonly used client-selection strategies and explicitly associates each with a distinct cost. Within this setting, we propose a new algorithm that achieves the best-known communication and local complexities among existing federated optimization methods for non-convex optimization. This algorithm is based on the inexact composite gradient method with a carefully constructed gradient estimator and a special procedure for solving the auxiliary subproblem at each iteration. The gradient estimator is based on SAGA, a popular variance-reduced gradient estimator. We first derive a new variance bound for it, showing that SAGA can exploit functional similarity. We then introduce the Recursive-Gradient technique as a general way to potentially improve the error bound of a given conditionally unbiased gradient estimator, including both SAGA and SVRG. By applying this technique to SAGA, we obtain a new estimator, RG-SAGA, which has an improved error bound compared to the original one.

</details>


### [133] [PathFinder: MCTS and LLM Feedback-based Path Selection for Multi-Hop Question Answering](https://arxiv.org/abs/2512.05336)
*Durga Prasad Maram,Kalpa Gunaratna,Vijay Srinivasan,Haris Jeelani,Srinivas Chappidi*

Main category: cs.LG

TL;DR: PATHFINDER使用蒙特卡洛树搜索生成训练路径轨迹，通过子答案召回和LLM-as-a-judge过滤错误轨迹，并重新表述子查询处理检索失败，提升多跳问答性能


<details>
  <summary>Details</summary>
Motivation: 现有基于训练的多跳问答系统仍受LLM幻觉和错误推理路径影响，导致性能受限，需要改进训练数据质量和处理检索失败的方法

Method: 1) 使用蒙特卡洛树搜索生成训练路径轨迹；2) 通过子答案召回和LLM-as-a-judge验证过滤错误和冗长轨迹；3) 重新表述子查询处理检索失败情况

Result: PATHFINDER在公共基准数据集上提升了多跳问答的性能

Conclusion: 通过改进训练数据生成、质量过滤和检索失败处理，PATHFINDER能有效提升多跳问答系统的性能

Abstract: Multi-hop question answering is a challenging task in which language models must reason over multiple steps to reach the correct answer. With the help of Large Language Models and their reasoning capabilities, existing systems are able to think and decompose an input question over multiple steps to analyze, retrieve, and reason. However, training-based approaches for this problem still suffer from LLM hallucinations and incorrect reasoning paths that hinder performance. Hence, we propose PATHFINDER, an approach that: (i) uses Monte Carlo Tree Search to generate training path traces, (ii) improves training data quality by filtering erroneous and lengthy traces using sub-answer recall and LLM-as-a-judge verification, and (iii) reformulates sub-queries to handle failed retrieval cases. By following these steps, we demonstrate that PATHFINDER improves the performance of multi-hop QA over public benchmark datasets.

</details>


### [134] [Interaction Tensor Shap](https://arxiv.org/abs/2512.05338)
*Hiroki Hasegawa,Yukihiko Okada*

Main category: cs.LG

TL;DR: 提出IT SHAP方法，将高阶Shapley交互表示为张量网络收缩，在张量列车结构下实现多项式时间计算，解决传统方法指数级复杂度问题


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型变得更深、维度更高，理解特征如何影响预测变得困难。现有Shapley值方法无法高效计算高阶交互：STII需要指数级枚举，MST只限于一阶效应。需要同时保持STII的公理精确性并避免指数计算复杂度

Method: 提出Interaction Tensor SHAP (IT SHAP)，将Shapley Taylor交互指数重新表述为值张量和权重张量的收缩。假设权重张量具有有限状态张量列车表示和多项式TT秩。在TT结构化的模型和分布张量下，将STII的指数复杂度降低到NC2并行时间

Result: IT SHAP能够将STII的指数复杂度Θ(4^n)降低到多项式时间，实现可扩展的高阶交互分析。在张量列车结构下，计算可以在多项式时间和多对数深度内完成

Conclusion: IT SHAP提供了一个统一、公理化且计算可处理的高维模型主效应和高阶交互分析框架，为可扩展的交互感知可解释AI奠定基础，使大型黑盒模型的组合结构分析变得可行

Abstract: Machine learning models have grown increasingly deep and high dimensional, making it difficult to understand how individual and combined features influence their predictions. While Shapley value based methods provide principled feature attributions, existing formulations cannot tractably evaluate higher order interactions: the Shapley Taylor Interaction Index (STII) requires exponential scale enumeration of subsets, and current tensor based approaches such as the Marginal SHAP Tensor (MST) are restricted to first order effects. The central problem is that no existing framework simultaneously preserves the axiomatic exactness of STII and avoids the exponential computational blow up inherent to high order discrete derivatives. Here we show that high order Shapley interactions can be represented exactly as tensor network contractions, enabling polynomial time and polylog depth computation under Tensor Train (TT) structure. We introduce Interaction Tensor SHAP (IT SHAP), which reformulates STII as the contraction of a Value Tensor and a Weight Tensor, and assume a finite state TT representation of the Weight Tensor with polynomial TT ranks. Under TT structured model and distribution tensors, we show that IT SHAP reduces the exponential complex Theta(4^n) of STII to NC2 parallel time. These results demonstrate that IT SHAP provides a unified, axiomatic, and computationally tractable formulation of main effects and higher order interactions in high dimensional models. This framework establishes a foundation for scalable interaction aware explainable AI, with implications for large black box models whose combinatorial structure has previously rendered interaction analysis infeasible.

</details>


### [135] [Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models](https://arxiv.org/abs/2512.05339)
*Mahesh Kumar Nandwana,Youngwan Lim,Joseph Liu,Alex Yang,Varun Notibala,Nishchaie Khanna*

Main category: cs.LG

TL;DR: Roblox Guard 1.0是基于Llama-3.1-8B-Instruct构建的指令微调LLM，用于增强LLM系统的安全性，通过输入输出审核和管道化LLM提升审核能力，并发布了RobloxGuard-Eval评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在训练后进行了安全对齐，但仍可能生成不适当的输出，存在用户风险，因此需要跨模型输入和输出的强大安全保障机制。

Method: 基于Llama-3.1-8B-Instruct骨干网络，通过指令微调使其能泛化到未见过的安全分类体系，使用合成和开源安全数据集的混合训练，增强链式思维推理和输入反转以提升上下文理解和决策能力。

Result: 模型在领域外安全基准测试中表现出色，能够有效进行全面的输入输出审核，并发布了RobloxGuard-Eval评估基准，包含可扩展的安全分类体系来评估LLM防护栏和审核框架的有效性。

Conclusion: Roblox Guard 1.0通过指令微调和管道化LLM方法，为LLM系统提供了有效的安全保障，其可扩展的安全分类体系为系统化评估LLM安全防护提供了新基准。

Abstract: Large Language Models (LLMs) are typically aligned for safety during the post-training phase; however, they may still generate inappropriate outputs that could potentially pose risks to users. This challenge underscores the need for robust safeguards that operate across both model inputs and outputs. In this work, we introduce Roblox Guard 1.0, a state-of-the-art instruction fine-tuned LLM designed to enhance the safety of LLM systems through comprehensive input-output moderation, using a pipeline of LLMs to enhance moderation capability. Built on the Llama-3.1-8B-Instruct backbone, our model is instruction fine-tuned to generalize across previously unseen safety taxonomies and demonstrates strong performance on out-of-domain safety benchmarks. The instruction fine-tuning process uses a mix of synthetic and open-source safety datasets, augmented with chain-of-thought (CoT) rationales and input inversion to enhance contextual understanding and decision making. To support systematic evaluation, we also release RobloxGuard-Eval, a new benchmark featuring an extensible safety taxonomy to assess the effectiveness of LLM guardrails and moderation frameworks.

</details>


### [136] [When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation](https://arxiv.org/abs/2512.05341)
*Yiwen Liang,Qiufeng Li,Shikai Wang,Weidong Cao*

Main category: cs.LG

TL;DR: 提出一种针对硬件代码生成的LLM遗忘框架，通过语法保持遗忘策略和细粒度选择性损失，有效移除问题知识而不损害代码生成能力。


<details>
  <summary>Details</summary>
Motivation: LLM在加速数字硬件设计方面潜力巨大，但现有模型存在三大风险：1）记忆专有知识产权（IP）；2）基准测试污染；3）不安全编码模式。需要确保LLM在硬件代码生成中的可靠性。

Method: 提出新颖的遗忘框架，包含两个核心组件：1）语法保持遗忘策略，在遗忘过程中保护硬件代码的结构完整性；2）细粒度floor-aware选择性损失，实现精确高效的问题知识移除。

Result: 实验表明该框架支持比现有方法大3倍的遗忘集，通常只需单个训练周期，同时保持寄存器传输级（RTL）代码的语法正确性和功能完整性。

Conclusion: 该工作为可靠的LLM辅助硬件设计开辟了新途径，通过有效的遗忘机制解决了LLM在硬件代码生成中的可靠性问题。

Abstract: Large Language Models (LLMs) have shown strong potential in accelerating digital hardware design through automated code generation. Yet, ensuring their reliability remains a critical challenge, as existing LLMs trained on massive heterogeneous datasets often exhibit problematic memorization of proprietary intellectual property (IP), contaminated benchmarks, and unsafe coding patterns. To mitigate these risks, we propose a novel unlearning framework tailored for LLM-based hardware code generation. Our method combines (i) a syntax-preserving unlearning strategy that safeguards the structural integrity of hardware code during forgetting, and (ii) a fine-grained floor-aware selective loss that enables precise and efficient removal of problematic knowledge. This integration achieves effective unlearning without degrading LLM code generation capabilities. Extensive experiments show that our framework supports forget sets up to 3x larger, typically requiring only a single training epoch, while preserving both syntactic correctness and functional integrity of register-transfer level (RTL) codes. Our work paves an avenue towards reliable LLM-assisted hardware design.

</details>


### [137] [Enhancing Dimensionality Prediction in Hybrid Metal Halides via Feature Engineering and Class-Imbalance Mitigation](https://arxiv.org/abs/2512.05367)
*Mariia Karabin,Isaac Armstrong,Leo Beck,Paulina Apanel,Markus Eisenbach,David B. Mitzi,Hanna Terletska,Hendrik Heinz*

Main category: cs.LG

TL;DR: 提出机器学习框架预测杂化金属卤化物结构维度，通过特征工程和类别不平衡处理技术提升预测准确性


<details>
  <summary>Details</summary>
Motivation: 杂化金属卤化物（包括有机-无机钙钛矿）的结构维度（0D、1D、2D、3D）预测对材料设计至关重要，但现有数据集类别高度不平衡，导致预测模型性能受限

Method: 采用化学信息特征工程开发相互作用描述符，结合SMOTE技术将数据集从494扩充到1336，使用多阶段工作流整合特征选择、模型堆叠和性能优化

Result: 显著提高了少数类别的F1分数，在所有维度类别上都实现了稳健的交叉验证性能

Conclusion: 该框架通过有效处理类别不平衡问题，显著提升了杂化金属卤化物结构维度的预测准确性，为材料设计提供了可靠工具

Abstract: We present a machine learning framework for predicting the structural dimensionality of hybrid metal halides (HMHs), including organic-inorganic perovskites, using a combination of chemically-informed feature engineering and advanced class-imbalance handling techniques. The dataset, consisting of 494 HMH structures, is highly imbalanced across dimensionality classes (0D, 1D, 2D, 3D), posing significant challenges to predictive modeling. This dataset was later augmented to 1336 via the Synthetic Minority Oversampling Technique (SMOTE) to mitigate the effects of the class imbalance. We developed interaction-based descriptors and integrated them into a multi-stage workflow that combines feature selection, model stacking, and performance optimization to improve dimensionality prediction accuracy. Our approach significantly improves F1-scores for underrepresented classes, achieving robust cross-validation performance across all dimensionalities.

</details>


### [138] [China Regional 3km Downscaling Based on Residual Corrective Diffusion Model](https://arxiv.org/abs/2512.05377)
*Honglu Sun,Hao Jing,Zhixiang Dai,Sa Xiao,Wei Xue,Jian Sun,Qifeng Lu*

Main category: cs.LG

TL;DR: 该研究扩展了CorrDiff扩散模型，用于中国区域天气预测的统计降尺度，将区域扩大20倍并增加高空变量，在3km分辨率预测中优于传统区域模型。


<details>
  <summary>Details</summary>
Motivation: 数值天气预报需要高效生成高分辨率预测，统计降尺度是常用方法。深度学习特别是扩散模型在超分辨率任务中表现出色，但现有CorrDiff模型仅考虑小区域和地表变量，需要扩展到更大区域并包含高空变量。

Method: 基于CorrDiff扩散模型框架，将应用区域扩大近20倍，增加六个气压层的高空变量作为降尺度目标，添加全局残差连接提高精度。使用CMA-GFS（25km）和SFF数据驱动模型作为输入，生成3km分辨率中国区域预测。

Result: 降尺度后的预测在目标变量的MAE指标上普遍优于CMA-MESO区域模型的直接预测。雷达组合反射率预测显示，CorrDiff作为生成模型能产生更真实的精细尺度细节，优于确定性回归模型。

Conclusion: 扩展后的CorrDiff扩散模型能有效用于大区域天气预测降尺度，不仅包含地表变量还涵盖高空变量，生成的高分辨率预测质量优于传统区域模型，展示了生成模型在天气预测降尺度中的优势。

Abstract: A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep learning has emerged as a powerful tool for this task, giving rise to various high-performance super-resolution models, which can be directly applied for downscaling, such as diffusion models and Generative Adversarial Networks. This work relies on a diffusion-based downscaling framework named CorrDiff. In contrast to the original work of CorrDiff, the region considered in this work is nearly 20 times larger, and we not only consider surface variables as in the original work, but also encounter high-level variables (six pressure levels) as target downscaling variables. In addition, a global residual connection is added to improve accuracy. In order to generate the 3km forecasts for the China region, we apply our trained models to the 25km global grid forecasts of CMA-GFS, an operational global model of the China Meteorological Administration (CMA), and SFF, a data-driven deep learning-based weather model developed from Spherical Fourier Neural Operators (SFNO). CMA-MESO, a high-resolution regional model, is chosen as the baseline model. The experimental results demonstrate that the forecasts downscaled by our method generally outperform the direct forecasts of CMA-MESO in terms of MAE for the target variables. Our forecasts of radar composite reflectivity show that CorrDiff, as a generative model, can generate fine-scale details that lead to more realistic predictions compared to the corresponding deterministic regression models.

</details>


### [139] [Generalization Beyond Benchmarks: Evaluating Learnable Protein-Ligand Scoring Functions on Unseen Targets](https://arxiv.org/abs/2512.05386)
*Jakub Kopko,David Graber,Saltuk Mustafa Eyrilmez,Stanislav Mazurenko,David Bednar,Jiri Sedlar,Josef Sivic*

Main category: cs.LG

TL;DR: 评估蛋白质-配体评分函数在新蛋白靶点上的泛化能力，发现常用基准测试不能反映真实挑战，探索大规模自监督预训练和简单测试数据利用方法的效果


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在分子设计中日益重要，需要确保可学习的蛋白质-配体评分函数在新蛋白靶点上的可靠性。虽然许多评分函数在标准基准测试中表现良好，但其在训练数据之外的泛化能力仍然是一个重大挑战。

Method: 在模拟评估具有有限已知结构和实验亲和力测量的靶点的数据集分割上，评估最先进评分函数的泛化能力。研究大规模自监督预训练是否能弥合泛化差距，并探索利用有限测试靶点数据改进评分函数性能的简单方法。

Result: 分析显示常用基准测试不能反映泛化到新靶点的真实挑战。提供了大规模自监督预训练潜力的初步证据，并探索了利用有限测试数据改进性能的方法。

Conclusion: 研究结果强调了需要更严格的评估协议，并为设计具有扩展到新蛋白靶点预测能力的评分函数提供了实用指导。

Abstract: As machine learning becomes increasingly central to molecular design, it is vital to ensure the reliability of learnable protein-ligand scoring functions on novel protein targets. While many scoring functions perform well on standard benchmarks, their ability to generalize beyond training data remains a significant challenge. In this work, we evaluate the generalization capability of state-of-the-art scoring functions on dataset splits that simulate evaluation on targets with a limited number of known structures and experimental affinity measurements. Our analysis reveals that the commonly used benchmarks do not reflect the true challenge of generalizing to novel targets. We also investigate whether large-scale self-supervised pretraining can bridge this generalization gap and we provide preliminary evidence of its potential. Furthermore, we probe the efficacy of simple methods that leverage limited test-target data to improve scoring function performance. Our findings underscore the need for more rigorous evaluation protocols and offer practical guidance for designing scoring functions with predictive power extending to novel protein targets.

</details>


### [140] [Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction](https://arxiv.org/abs/2512.05402)
*Sithumi Wickramasinghe,Bikramjit Das,Dorien Herremans*

Main category: cs.LG

TL;DR: 提出MineROI-Net，一种基于Transformer的模型，用于预测比特币挖矿硬件购买的盈利性，帮助矿工在波动的市场中做出更好的投资时机决策。


<details>
  <summary>Details</summary>
Motivation: 比特币挖矿硬件采购面临市场波动、技术快速过时和协议驱动收入周期等挑战，但目前缺乏关于何时购买ASIC硬件的指导，也没有计算框架解决这一决策问题。

Method: 将硬件采购问题建模为时间序列分类任务，预测购买ASIC机器在一年内是否盈利。提出MineROI-Net，一种开源的基于Transformer的架构，能够捕捉挖矿盈利性的多尺度时间模式。

Result: 在2015-2024年间发布的20种ASIC矿机数据上评估，MineROI-Net在准确率(83.7%)和宏平均F1分数(83.1%)上优于LSTM和TSLANet基线。模型在经济相关性方面表现强劲，对无盈利时期的检测精度达93.6%，对盈利时期的检测精度达98.5%。

Conclusion: MineROI-Net提供了一个实用的数据驱动工具，用于确定挖矿硬件采购时机，可能降低资本密集型挖矿操作的财务风险。

Abstract: Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net.

</details>


### [141] [LDLT $\mathcal{L}$-Lipschitz Network: Generalized Deep End-To-End Lipschitz Network Construction](https://arxiv.org/abs/2512.05915)
*Marius F. R. Juston,Ramavarapu S. Sreenivas,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.LG

TL;DR: 本文提出了一种基于线性矩阵不等式框架的Lipschitz深度残差网络设计方法，通过LDL分解扩展了Lipschitz约束到任意非线性架构，在121个UCI数据集上比SLL层获得3%-13%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 深度残差网络在计算机视觉任务中表现出色，但需要控制Lipschitz常数以增强对抗鲁棒性和网络可验证性。现有方法在构建Lipschitz约束网络方面存在局限性。

Method: 将ResNet架构重新表述为循环三对角LMI，推导网络参数的闭式约束以确保Lipschitz连续性。采用新的LDL分解方法验证LMI可行性，将Lipschitz网络构造扩展到任意非线性架构。使用Cholesky分解进行高效参数化。

Result: 提出的LDL公式是SDP-based网络的紧松弛，保持了完全表达能力，在121个UCI数据集上比SLL层获得3%-13%的准确率提升。实现了可证明的参数化方法，适用于对抗鲁棒性、认证训练和控制系统。

Conclusion: 该工作为构建Lipschitz约束的残差网络和其他分层架构提供了严格的理论框架，通过LMI和LDL分解方法实现了高效且表达能力强的网络设计，在多个应用领域具有实用价值。

Abstract: Deep residual networks (ResNets) have demonstrated outstanding success in computer vision tasks, attributed to their ability to maintain gradient flow through deep architectures. Simultaneously, controlling the Lipschitz constant in neural networks has emerged as an essential area of research to enhance adversarial robustness and network certifiability. This paper presents a rigorous approach to the general design of $\mathcal{L}$-Lipschitz deep residual networks using a Linear Matrix Inequality (LMI) framework. Initially, the ResNet architecture was reformulated as a cyclic tridiagonal LMI, and closed-form constraints on network parameters were derived to ensure $\mathcal{L}$-Lipschitz continuity; however, using a new $LDL^\top$ decomposition approach for certifying LMI feasibility, we extend the construction of $\mathcal{L}$-Lipchitz networks to any other nonlinear architecture. Our contributions include a provable parameterization methodology for constructing Lipschitz-constrained residual networks and other hierarchical architectures. Cholesky decomposition is also used for efficient parameterization. These findings enable robust network designs applicable to adversarial robustness, certified training, and control systems. The $LDL^\top$ formulation is shown to be a tight relaxation of the SDP-based network, maintaining full expressiveness and achieving 3\%-13\% accuracy gains over SLL Layers on 121 UCI data sets.

</details>


### [142] [RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design](https://arxiv.org/abs/2512.05403)
*Gyusam Chang,Jeongyoon Yoon,Shin han yi,JaeHyeok Lee,Sujin Jang,Sangpil Kim*

Main category: cs.LG

TL;DR: RevoNAD：一种反射式进化编排器，通过多轮多专家共识、自适应反射探索和帕累托引导进化选择，有效桥接LLM推理与反馈对齐的架构搜索，实现高性能神经架构设计。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的神经架构设计系统存在挑战：令牌级设计循环是离散且不可微分的，阻碍了反馈对架构改进的平滑指导。这些方法容易陷入冗余结构的模式崩溃或向不可行设计漂移，当建设性推理没有良好基础时。

Method: 1. 多轮多专家共识：将孤立的设计规则转化为有意义的架构线索
2. 自适应反射探索：利用奖励方差调整探索程度，在反馈不确定时探索，在稳定性达到时优化
3. 帕累托引导进化选择：有效促进同时优化准确性、效率、延迟、置信度和结构多样性的架构

Result: 在CIFAR10、CIFAR100、ImageNet16-120、COCO-5K和Cityscape数据集上实现了最先进的性能。消融和迁移研究进一步验证了RevoNAD在实际可靠和可部署神经架构设计中的有效性。

Conclusion: RevoNAD通过反射式进化编排有效解决了LLM驱动架构设计中的离散性和模式崩溃问题，实现了反馈对齐的神经架构搜索，为实际可靠且可部署的神经架构设计提供了有效解决方案。

Abstract: Recent progress in leveraging large language models (LLMs) has enabled Neural Architecture Design (NAD) systems to generate new architecture not limited from manually predefined search space. Nevertheless, LLM-driven generation remains challenging: the token-level design loop is discrete and non-differentiable, preventing feedback from smoothly guiding architectural improvement. These methods, in turn, commonly suffer from mode collapse into redundant structures or drift toward infeasible designs when constructive reasoning is not well grounded. We introduce RevoNAD, a reflective evolutionary orchestrator that effectively bridges LLM-based reasoning with feedback-aligned architectural search. First, RevoNAD presents a Multi-round Multi-expert Consensus to transfer isolated design rules into meaningful architectural clues. Then, Adaptive Reflective Exploration adjusts the degree of exploration leveraging reward variance; it explores when feedback is uncertain and refines when stability is reached. Finally, Pareto-guided Evolutionary Selection effectively promotes architectures that jointly optimize accuracy, efficiency, latency, confidence, and structural diversity. Across CIFAR10, CIFAR100, ImageNet16-120, COCO-5K, and Cityscape, RevoNAD achieves state-of-the-art performance. Ablation and transfer studies further validate the effectiveness of RevoNAD in allowing practically reliable, and deployable neural architecture design.

</details>


### [143] [Sepsis Prediction Using Graph Convolutional Networks over Patient-Feature-Value Triplets](https://arxiv.org/abs/2512.05416)
*Bozhi Dan,Di Wu,Ji Xu,Xiang Liu,Yiziting Zhu,Xin Shu,Yujie Li,Bin Yi*

Main category: cs.LG

TL;DR: Triplet-GCN：一种基于图卷积网络的脓毒症早期预警模型，通过患者-特征-值三元组构建二分图，在稀疏、异构的电子健康记录数据中实现更准确的脓毒症风险分层。


<details>
  <summary>Details</summary>
Motivation: 脓毒症在重症监护中仍是导致患者疾病和死亡的主要原因，但电子健康记录数据的复杂性、稀疏性和异质性阻碍了其及时检测。现有方法难以有效处理这种结构化医疗数据。

Method: 提出Triplet-GCN模型：1）将每次就诊表示为患者-特征-值三元组；2）构建二分EHR图；3）使用图卷积网络学习患者嵌入，后接轻量级多层感知机；4）采用类型特定的预处理策略（数值变量中值插补和标准化、二元特征效应编码、罕见分类属性众数插补和低维嵌入）；5）用汇总统计初始化患者节点，同时在边上保留测量值以保持"谁测量了什么以及测量了多少"的信息。

Result: 在中国三家三级医院的回顾性多中心队列（N=648；70/30训练-测试分割）中，Triplet-GCN在区分度和平衡误差指标上持续优于强大的表格基线模型（KNN、SVM、XGBoost、随机森林），产生更有利的敏感性-特异性权衡，并提高了早期预警的整体效用。

Conclusion: 将EHR编码为三元组并通过患者-特征图传播信息，比特征独立模型产生更具信息量的患者表示。这为可部署的脓毒症风险分层提供了一个简单、端到端的蓝图。

Abstract: In the intensive care setting, sepsis continues to be a major contributor to patient illness and death; however, its timely detection is hindered by the complex, sparse, and heterogeneous nature of electronic health record (EHR) data. We propose Triplet-GCN, a single-branch graph convolutional model that represents each encounter as patient-feature-value triplets, constructs a bipartite EHR graph, and learns patient embeddings via a Graph Convolutional Network (GCN) followed by a lightweight multilayer perceptron (MLP). The pipeline applies type-specific preprocessing -- median imputation and standardization for numeric variables, effect coding for binary features, and mode imputation with low-dimensional embeddings for rare categorical attributes -- and initializes patient nodes with summary statistics, while retaining measurement values on edges to preserve "who measured what and by how much". In a retrospective, multi-center Chinese cohort (N = 648; 70/30 train-test split) drawn from three tertiary hospitals, Triplet-GCN consistently outperforms strong tabular baselines (KNN, SVM, XGBoost, Random Forest) across discrimination and balanced error metrics, yielding a more favorable sensitivity-specificity trade-off and improved overall utility for early warning. These findings indicate that encoding EHR as triplets and propagating information over a patient-feature graph produce more informative patient representations than feature-independent models, offering a simple, end-to-end blueprint for deployable sepsis risk stratification.

</details>


### [144] [TS-HINT: Enhancing Semiconductor Time Series Regression Using Attention Hints From Large Language Model Reasoning](https://arxiv.org/abs/2512.05419)
*Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu*

Main category: cs.LG

TL;DR: 提出TS-Hint框架，结合时间序列基础模型与思维链推理，通过注意力提示改进半导体制造中材料去除率的预测，在有限数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法从时间序列提取静态特征来近似半导体制造过程（如化学机械抛光）的材料去除率，但这会导致时间动态信息丢失，且需要大量数据进行有效训练。

Method: 提出TS-Hint框架，整合时间序列基础模型与思维链推理，在训练过程中基于注意力机制数据和显著性数据提供注意力提示。

Result: 实验结果表明，该模型在有限数据设置下通过少样本学习表现有效，并能直接从多元时间序列特征中学习。

Conclusion: TS-Hint框架通过结合时间序列基础模型和思维链推理，解决了现有方法丢失时间动态信息、需要大量数据的问题，在半导体制造过程预测中展现出优越性能。

Abstract: Existing data-driven methods rely on the extraction of static features from time series to approximate the material removal rate (MRR) of semiconductor manufacturing processes such as chemical mechanical polishing (CMP). However, this leads to a loss of temporal dynamics. Moreover, these methods require a large amount of data for effective training. In this paper, we propose TS-Hint, a Time Series Foundation Model (TSFM) framework, integrated with chain-of-thought reasoning which provides attention hints during training based on attention mechanism data and saliency data. Experimental results demonstrate the effectiveness of our model in limited data settings via few-shot learning and can learn directly from multivariate time series features.

</details>


### [145] [IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?](https://arxiv.org/abs/2512.05442)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: IdealTSF框架利用非理想负样本增强时间序列预测，通过预训练、训练和优化三阶段，结合对抗扰动机制，显著提升基础注意力架构在噪声数据上的预测性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据中的缺失值和异常值阻碍深度学习预测性能的进一步提升。现有研究主要关注从序列数据提取特征或将次优数据作为正样本进行知识迁移，但未能充分利用非理想负样本的潜力来增强事件预测。

Method: 提出IdealTSF框架，包含三个渐进步骤：1) 预训练阶段从负样本数据中提取知识；2) 训练阶段将序列数据转化为理想正样本；3) 优化阶段应用带有对抗扰动的负优化机制。该框架整合理想正样本和负样本进行时间序列预测。

Result: 大量实验表明，负样本数据显著释放了基础注意力架构在时间序列预测中的潜力。IdealTSF特别适用于具有噪声样本或低质量数据的应用场景。

Conclusion: IdealTSF框架通过利用非理想负样本的优势，有效提升了时间序列预测性能，为处理噪声数据和低质量数据的实际应用提供了有效解决方案。

Abstract: Deep learning has shown strong performance in time series forecasting tasks. However, issues such as missing values and anomalies in sequential data hinder its further development in prediction tasks. Previous research has primarily focused on extracting feature information from sequence data or addressing these suboptimal data as positive samples for knowledge transfer. A more effective approach would be to leverage these non-ideal negative samples to enhance event prediction. In response, this study highlights the advantages of non-ideal negative samples and proposes the IdealTSF framework, which integrates both ideal positive and negative samples for time series forecasting. IdealTSF consists of three progressive steps: pretraining, training, and optimization. It first pretrains the model by extracting knowledge from negative sample data, then transforms the sequence data into ideal positive samples during training. Additionally, a negative optimization mechanism with adversarial disturbances is applied. Extensive experiments demonstrate that negative sample data unlocks significant potential within the basic attention architecture for time series forecasting. Therefore, IdealTSF is particularly well-suited for applications with noisy samples or low-quality data.

</details>


### [146] [How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data](https://arxiv.org/abs/2512.05469)
*Zubair Ahmed Mohammad*

Main category: cs.LG

TL;DR: 该研究通过四个表格分类任务，分析了集成模型如何平衡准确率和过拟合，发现集成方法通过平均或受控提升减少方差，能在保持高准确率的同时控制泛化差距。


<details>
  <summary>Details</summary>
Motivation: 集成模型通常比单一学习器获得更高准确率，但其保持较小泛化差距的能力尚未得到充分理解。研究旨在探索集成模型如何在准确率和过拟合之间取得平衡。

Method: 使用重复分层交叉验证和统计显著性检验，在四个表格分类任务（乳腺癌、心脏病、皮马糖尿病、信用卡欺诈）上比较线性模型、单一决策树和九种集成方法。

Result: 在近线性和干净数据上，线性模型已能很好泛化，集成方法增益有限；在具有非线性结构的数据集上，基于树的集成方法将测试准确率提高5-7个百分点，同时保持泛化差距低于3%；在噪声或高度不平衡数据集上，集成方法仍具竞争力但需要正则化避免过拟合。

Conclusion: 研究通过计算数据集复杂度指标（线性度评分、Fisher比率、噪声估计）解释了集成方法何时能有效控制方差，为实际表格应用中的模型选择提供了实用指导。

Abstract: Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.

</details>


### [147] [PERM EQ x GRAPH EQ: Equivariant Neural Networks for Quantum Molecular Learning](https://arxiv.org/abs/2512.05475)
*Saumya Biswas,Jiten Oswal*

Main category: cs.LG

TL;DR: 比较不同几何量子机器学习模型在分子几何结构学习中的性能，发现置换对称嵌入模型具有最佳泛化能力


<details>
  <summary>Details</summary>
Motivation: 研究不同对称性等变性对量子机器学习模型在分子几何结构学习中性能的影响，为几何数据集选择合适的模型提供标准

Method: 使用两个分子数据集（线性LiH分子和三角锥形NH3分子），比较无对称性等变性、旋转和置换等变性、图嵌入置换等变性的量子机器学习模型，以经典等变性模型为基线

Result: 图嵌入特征能有效提高几何数据集的可训练性，置换对称嵌入模型在几何学习中具有最佳泛化能力

Conclusion: 置换对称嵌入是几何学习中最具泛化能力的量子机器学习模型，图嵌入是提高几何数据集可训练性的有效途径

Abstract: In hierarchal order of molecular geometry, we compare the performances of Geometric Quantum Machine Learning models. Two molecular datasets are considered: the simplistic linear shaped LiH-molecule and the trigonal pyramidal molecule NH3. Both accuracy and generalizability metrics are considered. A classical equivariant model is used as a baseline for the performance comparison. The comparative performance of Quantum Machine Learning models with no symmetry equivariance, rotational and permutational equivariance, and graph embedded permutational equivariance is investigated. The performance differentials and the molecular geometry in question reveals the criteria for choice of models for generalizability. Graph embedding of features is shown to be an effective pathway to greater trainability for geometric datasets. Permutational symmetric embedding is found to be the most generalizable quantum Machine Learning model for geometric learning.

</details>


### [148] [Turbulence Regression](https://arxiv.org/abs/2512.05483)
*Yingang Fan,Binjie Ding,Baiyi Chen*

Main category: cs.LG

TL;DR: 提出基于离散化数据的NeuTucker分解模型，用于低空湍流预测，通过Tucker神经网络构建低秩分解模型，在风廓线雷达数据缺失观测估计中表现优于传统回归模型。


<details>
  <summary>Details</summary>
Motivation: 低空湍流受多种复杂因素影响，传统方法仅使用风廓线雷达数据时难以准确预测湍流状态，需要更有效的建模方法。

Method: 1) 将连续输入数据离散化以适应需要离散数据输入的模型；2) 构建四维Tucker交互张量来表示不同高度和三维风速之间的所有可能时空交互；3) 基于Tucker神经网络构建低秩Tucker分解模型。

Result: 在真实数据集的缺失观测估计中，离散化NeuTucF模型相比各种常见回归模型表现出更优越的性能。

Conclusion: 提出的离散化NeuTucker分解模型能够有效捕捉三维风场数据的潜在交互，为低空湍流预测提供了更准确的解决方案。

Abstract: Air turbulence refers to the disordered and irregular motion state generated by drastic changes in velocity, pressure, or direction during airflow. Various complex factors lead to intricate low-altitude turbulence outcomes. Under current observational conditions, especially when using only wind profile radar data, traditional methods struggle to accurately predict turbulence states. Therefore, this paper introduces a NeuTucker decomposition model utilizing discretized data. Designed for continuous yet sparse three-dimensional wind field data, it constructs a low-rank Tucker decomposition model based on a Tucker neural network to capture the latent interactions within the three-dimensional wind field data. Therefore, two core ideas are proposed here: 1) Discretizing continuous input data to adapt to models like NeuTucF that require discrete data inputs. 2) Constructing a four-dimensional Tucker interaction tensor to represent all possible spatio-temporal interactions among different elevations and three-dimensional wind speeds. In estimating missing observations in real datasets, this discretized NeuTucF model demonstrates superior performance compared to various common regression models.

</details>


### [149] [Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning](https://arxiv.org/abs/2512.05591)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Tiehua Mei,Zijia Lin,Yuntao Li,Wenping Hu,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 提出熵比裁剪(ERC)机制，通过约束当前与先前策略的熵比来稳定强化学习训练，解决分布偏移问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型后训练使用强化学习，但离策略训练范式引入分布偏移，导致训练不稳定（策略熵波动、梯度不稳定）。PPO-Clip通过重要性裁剪缓解但忽略了动作的全局分布偏移。

Method: 提出熵比作为量化策略探索相对变化的全局指标，并基于此设计熵比裁剪(ERC)机制，对熵比施加双向约束，稳定全局分布层面的策略更新，补偿PPO-clip无法调节未采样动作概率偏移的问题。

Result: 将ERC集成到DAPO和GPPO强化学习算法中，在多个基准测试上实验表明ERC能持续提升性能。

Conclusion: ERC机制通过约束熵比有效稳定强化学习训练，解决了分布偏移导致的训练不稳定问题，在多种算法中均能提升性能。

Abstract: Large language model post-training relies on reinforcement learning to improve model capability and alignment quality. However, the off-policy training paradigm introduces distribution shift, which often pushes the policy beyond the trust region, leading to training instabilities manifested as fluctuations in policy entropy and unstable gradients. Although PPO-Clip mitigates this issue through importance clipping, it still overlooks the global distributional shift of actions. To address these challenges, we propose using the entropy ratio between the current and previous policies as a new global metric that effectively quantifies the relative change in policy exploration throughout updates. Building on this metric, we introduce an \textbf{Entropy Ratio Clipping} (ERC) mechanism that imposes bidirectional constraints on the entropy ratio. This stabilizes policy updates at the global distribution level and compensates for the inability of PPO-clip to regulate probability shifts of un-sampled actions. We integrate ERC into both DAPO and GPPO reinforcement learning algorithms. Experiments across multiple benchmarks show that ERC consistently improves performance.

</details>


### [150] [GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop](https://arxiv.org/abs/2512.05502)
*Omid Bazgir,Vineeth Manthapuri,Ilia Rattsev,Mohammad Jafarnejad*

Main category: cs.LG

TL;DR: GRASP是一个多智能体、图推理框架，通过人机对话界面将QSP模型编码为类型化生物知识图谱，并编译为可执行的MATLAB/SimBiology代码，同时保持单位、质量平衡和生理约束。


<details>
  <summary>Details</summary>
Motivation: QSP建模对药物开发至关重要，但需要大量时间投入，限制了领域专家的吞吐量。需要一种方法让领域专家能够用自然语言指定机制，同时不牺牲生物医学保真度。

Method: 采用两阶段工作流：理解（旧代码的图重构）和行动（约束检查、语言驱动的修改），由状态机协调迭代验证。使用广度优先参数对齐围绕新实体发现依赖量并提出生物学合理的默认值，运行自动执行/诊断直到收敛。

Result: 在LLM作为评判的对比评估中，GRASP在生物合理性、数学正确性、结构保真度和代码质量方面优于SME引导的CoT和ToT基线（约9-10/10 vs. 5-7/10）。BFS对齐在依赖发现、单位和范围方面达到F1=0.95。

Conclusion: 图结构、智能体化的工作流可以使QSP模型开发既易于访问又严谨，使领域专家能够用自然语言指定机制，同时保持生物医学保真度。

Abstract: Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that encodes QSP models as typed biological knowledge graphs and compiles them to executable MATLAB/SimBiology code while preserving units, mass balance, and physiological constraints. A two-phase workflow -- \textsc{Understanding} (graph reconstruction of legacy code) and \textsc{Action} (constraint-checked, language-driven modification) -- is orchestrated by a state machine with iterative validation. GRASP performs breadth-first parameter-alignment around new entities to surface dependent quantities and propose biologically plausible defaults, and it runs automatic execution/diagnostics until convergence. In head-to-head evaluations using LLM-as-judge, GRASP outperforms SME-guided CoT and ToT baselines across biological plausibility, mathematical correctness, structural fidelity, and code quality (\(\approx\)9--10/10 vs.\ 5--7/10). BFS alignment achieves F1 = 0.95 for dependency discovery, units, and range. These results demonstrate that graph-structured, agentic workflows can make QSP model development both accessible and rigorous, enabling domain experts to specify mechanisms in natural language without sacrificing biomedical fidelity.

</details>


### [151] [Credal and Interval Deep Evidential Classifications](https://arxiv.org/abs/2512.05526)
*Michele Caprio,Shireen K. Manchingal,Fabio Cuzzolin*

Main category: cs.LG

TL;DR: 提出CDEC和IDEC两种新方法，通过信度集和证据区间来处理分类任务中的不确定性量化问题，能识别并避免在不确定性过高时进行分类，同时在可接受范围内提供有概率保证的标签集合。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化是AI领域的关键挑战，直接影响决策、风险评估和模型可靠性。现有方法存在局限性，需要新的方法来系统评估认知不确定性和偶然不确定性，并在不确定性过高时能够放弃分类。

Method: 提出CDEC（信度深度证据分类）和IDEC（区间深度证据分类）两种方法：CDEC使用信度集（概率的闭凸集），IDEC使用证据预测分布的区间。两种方法都使用标准反向传播和基于证据理论的损失函数进行训练。

Result: 在MNIST、CIFAR-10、CIFAR-100及其自然分布外偏移数据集上的实验表明：CDEC和IDEC实现了有竞争力的预测准确率，在认知不确定性和总不确定性下的分布外检测达到最先进水平，提供紧密且校准良好的预测区域，在分布偏移时能可靠扩展。消融实验显示CDEC仅需小规模集成就能获得稳定的不确定性估计。

Conclusion: CDEC和IDEC是处理分类任务中不确定性量化的有效新方法，能够系统评估认知和偶然不确定性，在不确定性过高时放弃分类，在可接受范围内提供有概率保证的预测，克服了先前方法的局限性并扩展了证据深度学习文献。

Abstract: Uncertainty Quantification (UQ) presents a pivotal challenge in the field of Artificial Intelligence (AI), profoundly impacting decision-making, risk assessment and model reliability. In this paper, we introduce Credal and Interval Deep Evidential Classifications (CDEC and IDEC, respectively) as novel approaches to address UQ in classification tasks. CDEC and IDEC leverage a credal set (closed and convex set of probabilities) and an interval of evidential predictive distributions, respectively, allowing us to avoid overfitting to the training data and to systematically assess both epistemic (reducible) and aleatoric (irreducible) uncertainties. When those surpass acceptable thresholds, CDEC and IDEC have the capability to abstain from classification and flag an excess of epistemic or aleatoric uncertainty, as relevant. Conversely, within acceptable uncertainty bounds, CDEC and IDEC provide a collection of labels with robust probabilistic guarantees. CDEC and IDEC are trained using standard backpropagation and a loss function that draws from the theory of evidence. They overcome the shortcomings of previous efforts, and extend the current evidential deep learning literature. Through extensive experiments on MNIST, CIFAR-10 and CIFAR-100, together with their natural OoD shifts (F-MNIST/K-MNIST, SVHN/Intel, TinyImageNet), we show that CDEC and IDEC achieve competitive predictive accuracy, state-of-the-art OoD detection under epistemic and total uncertainty, and tight, well-calibrated prediction regions that expand reliably under distribution shift. An ablation over ensemble size further demonstrates that CDEC attains stable uncertainty estimates with only a small ensemble.

</details>


### [152] [IDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection](https://arxiv.org/abs/2512.05531)
*Yang Xu,Yixiao Ma,Kaifeng Zhang,Zuliang Yang,Kai Ming Ting*

Main category: cs.LG

TL;DR: IDK-S是一种用于数据流异常检测的增量分布核方法，通过动态核均值嵌入实现高精度实时检测，相比现有方法在保持准确性的同时显著提升速度。


<details>
  <summary>Details</summary>
Motivation: 数据流异常检测面临两大挑战：需要在分布不断演变的情况下保持高检测精度，同时确保实时处理效率。现有方法难以同时满足这两点要求。

Method: 提出IDK-S（增量分布核流式异常检测），基于隔离分布核框架，采用轻量级增量更新机制。该方法继承离线检测器Isolation Distributional Kernel的优势，使用数据依赖核，同时通过增量更新避免完全模型重训练。

Result: 在13个基准测试中，IDK-S实现了优越的检测精度，同时运行速度显著快于现有最先进方法，在许多情况下快一个数量级。统计上等价于完全重训练模型，但计算开销大幅降低。

Conclusion: IDK-S成功解决了数据流异常检测中精度与效率的平衡问题，通过增量分布核框架实现了高精度实时检测，为流式异常检测提供了有效解决方案。

Abstract: Anomaly detection on data streams presents significant challenges, requiring methods to maintain high detection accuracy among evolving distributions while ensuring real-time efficiency. Here we introduce $\mathcal{IDK}$-$\mathcal{S}$, a novel $\mathbf{I}$ncremental $\mathbf{D}$istributional $\mathbf{K}$ernel for $\mathbf{S}$treaming anomaly detection that effectively addresses these challenges by creating a new dynamic representation in the kernel mean embedding framework. The superiority of $\mathcal{IDK}$-$\mathcal{S}$ is attributed to two key innovations. First, it inherits the strengths of the Isolation Distributional Kernel, an offline detector that has demonstrated significant performance advantages over foundational methods like Isolation Forest and Local Outlier Factor due to the use of a data-dependent kernel. Second, it adopts a lightweight incremental update mechanism that significantly reduces computational overhead compared to the naive baseline strategy of performing a full model retraining. This is achieved without compromising detection accuracy, a claim supported by its statistical equivalence to the full retrained model. Our extensive experiments on thirteen benchmarks demonstrate that $\mathcal{IDK}$-$\mathcal{S}$ achieves superior detection accuracy while operating substantially faster, in many cases by an order of magnitude, than existing state-of-the-art methods.

</details>


### [153] [On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability](https://arxiv.org/abs/2512.05534)
*Yiming Tang,Harshvardhan Saini,Yizhen Liao,Dianbo Liu*

Main category: cs.LG

TL;DR: 本文提出了首个统一的稀疏字典学习理论框架，将多种方法统一为优化问题，分析了优化景观，解释了特征吸收、死亡神经元等经验现象，并通过实验验证理论结果。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型能力增强，理解其内部表示和处理机制对科学进步和可信部署至关重要。现有稀疏字典学习方法经验成功但缺乏理论理解，特别是对稀疏自编码器以外的方法缺乏形式化基础。

Method: 建立统一的稀疏字典学习理论框架，将稀疏自编码器、转码器、交叉编码器等方法统一为优化问题，分析优化景观，解释经验现象，并设计控制实验验证理论。

Result: 提供了首个统一的理论框架，解释了特征吸收、死亡神经元和神经元重采样等经验现象，并通过实验验证了理论分析的正确性。

Conclusion: 本文填补了稀疏字典学习理论理解的空白，为多种方法提供了统一的形式化基础，有助于更好地理解和改进神经网络的可解释性方法。

Abstract: As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode many concepts in superposition. Various sparse dictionary learning (SDL) methods, including sparse autoencoders, transcoders, and crosscoders, address this by training auxiliary models with sparsity constraints to disentangle these superposed concepts into interpretable features. These methods have demonstrated remarkable empirical success but have limited theoretical understanding. Existing theoretical work is limited to sparse autoencoders with tied-weight constraints, leaving the broader family of SDL methods without formal grounding. In this work, we develop the first unified theoretical framework considering SDL as one unified optimization problem. We demonstrate how diverse methods instantiate the theoretical framwork and provide rigorous analysis on the optimization landscape. We provide the first theoretical explanations for some empirically observed phenomena, including feature absorption, dead neurons, and the neuron resampling technique. We further design controlled experiments to validate our theoretical results.

</details>


### [154] [SCoNE: Spherical Consistent Neighborhoods Ensemble for Effective and Efficient Multi-View Anomaly Detection](https://arxiv.org/abs/2512.05540)
*Yang Xu,Hang Zhang,Yixiao Ma,Ye Zhu,Kai Ming Ting*

Main category: cs.LG

TL;DR: 提出SCoNE方法解决多视图异常检测中局部邻域表示不一致和计算复杂度高的问题，通过直接使用多视图实例表示一致邻域，实现线性时间复杂度和更好的检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有多视图异常检测方法存在两个关键问题：1) 在不同视图中密度变化区域难以有效捕获一致邻域，导致检测精度下降；2) 学习过程计算复杂度为O(N²)，不适用于大规模数据集。

Method: 提出SCoNE方法，具有两个独特特性：1) 直接使用多视图实例表示一致邻域，无需现有方法中的中间表示；2) 邻域具有数据依赖特性，在稀疏区域形成大邻域，在密集区域形成小邻域。

Result: SCoNE在检测精度上优于现有方法，在大规模数据集上运行速度比现有方法快几个数量级，时间复杂度降低到O(N)。

Conclusion: SCoNE通过直接表示数据依赖的一致邻域，有效解决了多视图异常检测中的邻域表示不一致和高计算成本问题，实现了更好的检测性能和可扩展性。

Abstract: The core problem in multi-view anomaly detection is to represent local neighborhoods of normal instances consistently across all views. Recent approaches consider a representation of local neighborhood in each view independently, and then capture the consistent neighbors across all views via a learning process. They suffer from two key issues. First, there is no guarantee that they can capture consistent neighbors well, especially when the same neighbors are in regions of varied densities in different views, resulting in inferior detection accuracy. Second, the learning process has a high computational cost of $\mathcal{O}(N^2)$, rendering them inapplicable for large datasets. To address these issues, we propose a novel method termed \textbf{S}pherical \textbf{C}onsistent \textbf{N}eighborhoods \textbf{E}nsemble (SCoNE). It has two unique features: (a) the consistent neighborhoods are represented with multi-view instances directly, requiring no intermediate representations as used in existing approaches; and (b) the neighborhoods have data-dependent properties, which lead to large neighborhoods in sparse regions and small neighborhoods in dense regions. The data-dependent properties enable local neighborhoods in different views to be represented well as consistent neighborhoods, without learning. This leads to $\mathcal{O}(N)$ time complexity. Empirical evaluations show that SCoNE has superior detection accuracy and runs orders-of-magnitude faster in large datasets than existing approaches.

</details>


### [155] [RoBoN: Routed Online Best-of-n for Test-Time Scaling with Multiple LLMs](https://arxiv.org/abs/2512.05542)
*Jonathan Geuter,Gregor Kornhardt*

Main category: cs.LG

TL;DR: RoBoN是一种多LLM推理方法，通过在线路由机制在多个模型间选择最佳响应，相比传统单模型best-of-n方法获得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 传统best-of-n方法仅使用单一模型生成响应，但不同LLM在不同任务上具有互补优势。研究者希望利用多模型多样性来提升推理性能

Method: 提出RoBoN（Routed Online Best-of-n）方法：给定M个模型，基于奖励模型和响应一致性信号，在线逐个路由生成过程，无需额外训练，保持计算对等

Result: 在多个推理基准测试（MATH500、OlympiadBench、MinervaMath、GSM8K、MMLU）上，RoBoN在较大n值时始终优于传统单模型best-of-n，绝对准确率提升最高达3.4%

Conclusion: 多模型多样性可以在推理阶段被有效利用，RoBoN提供了一种简单、无需训练的测试时扩展方法，能够超越任何单一组成模型的性能

Abstract: Best-of-$n$ is a widely used test-time scaling approach for LLM inference. Yet despite evidence that LLMs exhibit complementary strengths across tasks, traditionally best-of-$n$ relies on a single model to generate responses. We propose RoBoN (Routed Online Best-of-$n$), a sequential multi-LLM alternative to the prevailing single-model best-of-$n$. Given a suite of models $\{m_i\}_{i=1}^M$, RoBoN sequentially routes generations one-by-one across models, based on scores computed using a reward model and an agreement signal on the predicted responses. This online routing requires no additional training, keeps compute parity, and works with any plug-in reward model. Across reasoning benchmarks (MATH500, OlympiadBench, MinervaMath, GSM8K, MMLU), RoBoN consistently outperforms standard best-of-$n$ applied to each individual model for larger $n$, with gains of up to 3.4\% in absolute accuracy, and also improves over a uniform multi-model portfolio baseline. Our results indicate that diversity across models can be exploited at inference to improve best-of-$n$ performance over any constituent model alone, providing a simple, training-free path to test-time scaling with multiple LLMs.

</details>


### [156] [Improving Local Fidelity Through Sampling and Modeling Nonlinearity](https://arxiv.org/abs/2512.05556)
*Sanjeev Shrestha,Rahul Dubey,Hui Liu*

Main category: cs.LG

TL;DR: 提出一种基于MARS的非线性局部解释方法，相比LIME能更好地捕捉黑盒模型的非线性决策边界，通过N-ball采样技术提高解释的忠实度。


<details>
  <summary>Details</summary>
Motivation: 随着黑盒机器学习模型在关键领域的应用增加，提供模型预测解释变得至关重要。现有的LIME方法假设局部决策边界是线性的，无法捕捉非线性关系，导致解释不准确。

Method: 使用多元自适应回归样条(MARS)来建模非线性局部边界，有效捕捉参考模型的底层行为；采用N-ball采样技术直接从期望分布中采样，而不是像LIME那样重新加权样本。

Result: 在三个UCI数据集上对不同分类器和不同核宽度进行评估，结果显示该方法相比基线方法能产生更忠实的解释，平均减少37%的均方根误差，显著提高了局部忠实度。

Conclusion: 提出的方法通过MARS建模非线性局部边界和N-ball采样技术，能够生成高保真度的解释，有效解决了LIME方法在捕捉非线性关系方面的局限性。

Abstract: With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.

</details>


### [157] [Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales](https://arxiv.org/abs/2512.05620)
*Shikai Qiu,Zixi Chen,Hoang Phan,Qi Lei,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 研究如何通过超参数迁移来扩展预条件优化器（如Shampoo、SOAP、Muon）的规模，发现按μP缩放学习率并结合分块和谱归一化可改善迁移效果，计算最优缩放中权重衰减按1/宽度缩放接近最优。应用这些规则后，Muon和Shampoo在190M到1.4B参数的Llama模型上分别获得1.4倍和1.3倍于AdamW的加速。


<details>
  <summary>Details</summary>
Motivation: 近期基于矩阵级预条件的深度学习优化器在小规模实验中显示出优于AdamW的加速效果，但验证和复现结果不一致。为了理解这些优化器在大规模场景下的有效性，需要研究如何通过超参数迁移来扩展预条件优化器的规模。

Method: 研究学习率和权重衰减如何随模型宽度和深度缩放，涵盖Shampoo、SOAP、Muon等多种优化器，考虑分块和嫁接等常用技术的影响。应用μP理论进行学习率缩放，并探索计算最优的权重衰减缩放规则。

Result: 按μP缩放学习率可改善迁移效果，但仍有显著的有限宽度偏差导致最优学习率漂移，可通过分块和显式谱归一化缓解。计算最优缩放中，权重衰减按1/宽度缩放接近最优。应用这些规则后，Muon和Shampoo在190M到1.4B参数的Llama模型上分别获得1.4倍和1.3倍于AdamW的加速，而错误缩放下加速效果会迅速消失。

Conclusion: 研究最优超参数迁移对于在现实调优预算下可靠比较大规模优化器至关重要。正确的缩放规则能确保预条件优化器在大规模场景下保持优势，而错误缩放会导致加速效果消失。

Abstract: Several recently introduced deep learning optimizers utilizing matrix-level preconditioning have shown promising speedups relative to the current dominant optimizer AdamW, particularly in relatively small-scale experiments. However, efforts to validate and replicate their successes have reported mixed results. To better understand the effectiveness of these optimizers at scale, in this work we investigate how to scale preconditioned optimizers via hyperparameter transfer, building on prior works such as $μ$P. We study how the optimal learning rate and weight decay should scale with model width and depth for a wide range of optimizers, including Shampoo, SOAP, and Muon, accounting for the impact of commonly used techniques such as blocking and grafting. We find that scaling the learning rate according to $μ$P improves transfer, but can still suffer from significant finite-width deviations that cause drifting optimal learning rates, which we show can be mitigated by blocking and explicit spectral normalization. For compute-optimal scaling, we find scaling independent weight decay as $1/\mathrm{width}$ is nearly optimal across optimizers. Applying these scaling rules, we show Muon and Shampoo consistently achieve $1.4\times$ and $1.3\times$ speedup over AdamW for training Llama-architecture language models of sizes ranging from $190$M to $1.4$B, whereas the speedup vanishes rapidly with scale under incorrect scaling. Based on these results and further ablations, we argue that studying optimal hyperparameter transfer is essential for reliably comparing optimizers at scale given a realistic tuning budget.

</details>


### [158] [Bounded Graph Clustering with Graph Neural Networks](https://arxiv.org/abs/2512.05623)
*Kibidi Neocosmos,Diego Baptista,Nicole Ludwig*

Main category: cs.LG

TL;DR: 提出一个灵活的GNN社区检测框架，允许用户指定社区数量范围或精确数量，解决传统GNN方法无法可靠控制社区数量的问题。


<details>
  <summary>Details</summary>
Motivation: 传统社区检测方法需要预先指定社区数量，而GNN方法即使指定了期望数量也经常无法返回精确结果。现有方法缺乏灵活控制社区数量的能力。

Method: 提出一个原则性框架，允许用户指定社区数量的合理范围，并在训练过程中强制执行这些边界约束。同时支持用户指定精确的社区数量。

Result: 该方法能够可靠地返回用户指定的社区数量或范围内的结果，解决了GNN在社区检测中无法精确控制输出社区数量的问题。

Conclusion: 提出的框架为GNN社区检测提供了灵活且可靠的数量控制机制，既支持范围约束也支持精确指定，增强了GNN在社区检测中的实用性。

Abstract: In community detection, many methods require the user to specify the number of clusters in advance since an exhaustive search over all possible values is computationally infeasible. While some classical algorithms can infer this number directly from the data, this is typically not the case for graph neural networks (GNNs): even when a desired number of clusters is specified, standard GNN-based methods often fail to return the exact number due to the way they are designed. In this work, we address this limitation by introducing a flexible and principled way to control the number of communities discovered by GNNs. Rather than assuming the true number of clusters is known, we propose a framework that allows the user to specify a plausible range and enforce these bounds during training. However, if the user wants an exact number of clusters, it may also be specified and reliably returned.

</details>


### [159] [Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs](https://arxiv.org/abs/2512.05648)
*Igor Shilov,Alex Cloud,Aryo Pradipta Gema,Jacob Goldman-Wetzler,Nina Panickssery,Henry Sleight,Erik Jones,Cem Anil*

Main category: cs.LG

TL;DR: SGTM（选择性梯度掩码）是一种改进的梯度路由技术，通过在预训练时选择性掩码梯度，将目标知识隔离到特定参数中，以应对标签噪声下的有害内容移除问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型具有双重使用风险，传统的数据过滤方法面临标签成本高和标签噪声问题，即使少量误标内容也可能导致危险能力产生，需要更鲁棒的预训练时缓解方法。

Method: 提出SGTM（选择性梯度掩码），通过零掩码选定梯度，使目标域示例仅更新其专用参数，将特定知识隔离到模型子集中，便于后续移除。

Result: 在双语数据集移除语言知识和维基百科移除生物学知识两个任务中，SGTM在存在标签错误时比数据过滤和先前梯度路由方法有更好的保留/遗忘权衡；对对抗性微调具有强鲁棒性，需要7倍微调步数才能恢复遗忘集性能。

Conclusion: SGTM为现有安全缓解措施提供了有前景的预训练时补充，特别是在标签噪声不可避免的场景中，能够更鲁棒地处理有害内容移除问题。

Abstract: Large Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) -- a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM's effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.

</details>


### [160] [Feasibility of AI-Assisted Programming for End-User Development](https://arxiv.org/abs/2512.05666)
*Irene Weber*

Main category: cs.LG

TL;DR: AI辅助的终端用户编码是可行的终端用户开发范式，非程序员通过与AI助手交互能够成功开发基础Web应用，可能补充甚至替代现有的低代码/无代码平台。


<details>
  <summary>Details</summary>
Motivation: 探索AI辅助终端用户编码是否可行，评估其作为终端用户开发新范式的潜力，特别是与现有低代码/无代码平台相比的优势。

Method: 通过案例研究，让非程序员与AI助手交互开发基础Web应用，分析任务完成情况、时间和用户反馈。

Result: 大多数参与者能在合理时间内成功完成任务，并支持AI辅助终端用户编码作为可行的终端用户开发方法。

Conclusion: AI辅助终端用户编码是可行的开发范式，具有灵活性、广泛适用性、快速开发等优势，可能补充甚至替代低代码/无代码平台。

Abstract: End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and "copilots", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.

</details>


### [161] [Meta-Learning Multi-armed Bandits for Beam Tracking in 5G and 6G Networks](https://arxiv.org/abs/2512.05680)
*Alexander Mattick,George Yammine,Georgios Kontes,Setareh Maghsudi,Christopher Mutschler*

Main category: cs.LG

TL;DR: 该论文提出了一种基于部分可观测马尔可夫决策过程（POMDP）的波束选择方法，将波束选择问题建模为在线搜索过程，显著优于现有监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 在5G/6G网络中，大规模天线阵列的模拟波束成形需要从预配置码本中选择最优波束。然而，大码本、反射和阻塞效应使得最优波束选择具有挑战性。现有方法主要使用监督学习基于历史波束选择进行预测，但难以处理新的轨迹和环境变化。

Method: 将波束选择问题建模为部分可观测马尔可夫决策过程（POMDP），将环境建模为码本本身。在每个时间步，基于不可观测最优波束的信念状态和先前探测的波束选择候选波束，将波束选择问题框架化为定位移动最优波束的在线搜索过程。

Result: 该方法能够处理新的或不可预见的轨迹和物理环境变化，性能比先前工作高出几个数量级。

Conclusion: 基于POMDP的在线搜索方法为波束选择问题提供了更鲁棒和自适应的解决方案，能够有效应对动态环境和未知轨迹的挑战。

Abstract: Beamforming-capable antenna arrays with many elements enable higher data rates in next generation 5G and 6G networks. In current practice, analog beamforming uses a codebook of pre-configured beams with each of them radiating towards a specific direction, and a beam management function continuously selects \textit{optimal} beams for moving user equipments (UEs). However, large codebooks and effects caused by reflections or blockages of beams make an optimal beam selection challenging. In contrast to previous work and standardization efforts that opt for supervised learning to train classifiers to predict the next best beam based on previously selected beams we formulate the problem as a partially observable Markov decision process (POMDP) and model the environment as the codebook itself. At each time step, we select a candidate beam conditioned on the belief state of the unobservable optimal beam and previously probed beams. This frames the beam selection problem as an online search procedure that locates the moving optimal beam. In contrast to previous work, our method handles new or unforeseen trajectories and changes in the physical environment, and outperforms previous work by orders of magnitude.

</details>


### [162] [BERTO: an Adaptive BERT-based Network Time Series Predictor with Operator Preferences in Natural Language](https://arxiv.org/abs/2512.05721)
*Nitin Priyadarshini Shankar,Vaibhav Singh,Sheetal Kalyani,Christian Maciocco*

Main category: cs.LG

TL;DR: BERTO是一个基于BERT的框架，用于蜂窝网络的流量预测和能耗优化，通过自然语言提示在节能和性能之间进行平衡。


<details>
  <summary>Details</summary>
Motivation: 蜂窝网络需要智能的流量预测和能耗优化方案，以平衡节能和网络性能这两个相互竞争的目标，传统方法难以灵活调整这种权衡。

Method: 基于Transformer架构的BERT框架，使用平衡损失函数和基于提示的自定义功能，通过自然语言提示指导模型管理预测不足和过度预测，根据运营商意图调整权衡。

Result: 在真实数据集上，BERTO相比现有模型将MSE降低了4.13%，能够在1.4kW的功率范围和9倍的服务质量变化范围内运行，通过简单的自然语言输入平衡节能和性能目标。

Conclusion: BERTO为智能RAN部署提供了一个有效的解决方案，能够通过自然语言提示灵活平衡节能和网络性能，具有实际应用价值。

Abstract: We introduce BERTO, a BERT-based framework for traffic prediction and energy optimization in cellular networks. Built on transformer architectures, BERTO delivers high prediction accuracy, while its Balancing Loss Function and prompt-based customization allow operators to adjust the trade-off between power savings and performance. Natural language prompts guide the model to manage underprediction and overprediction in accordance with the operator's intent. Experiments on real-world datasets show that BERTO improves upon existing models with a $4.13$\% reduction in MSE while introducing the feature of balancing competing objectives of power saving and performance through simple natural language inputs, operating over a flexible range of $1.4$ kW in power and up to $9\times$ variation in service quality, making it well suited for intelligent RAN deployments.

</details>


### [163] [Teaching Language Models Mechanistic Explainability Through Arrow-Pushing](https://arxiv.org/abs/2512.05722)
*Théo A. Neukomm,Zlatko Jončev,Philippe Schwaller*

Main category: cs.LG

TL;DR: 提出MechSMILES格式和语言模型框架，用于预测化学反应机理，提升计算机辅助合成规划的机理基础


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划系统缺乏机理基础，需要能够预测化学反应机理的方法来确保化学有效性

Method: 开发MechSMILES格式编码分子结构和电子流动，训练语言模型在四个复杂度递增的机理预测任务上

Result: 模型在基本步骤预测上达到95%以上top-3准确率，在完整反应机理检索任务上，mech-USPTO-31k数据集超过73%，FlowER数据集超过93%

Conclusion: 通过基于电子流动的机理预测，为计算机辅助合成规划提供更可解释和化学有效的途径，同时建立架构无关的机理预测基准框架

Abstract: Chemical reaction mechanisms provide crucial insight into synthesizability, yet current Computer-Assisted Synthesis Planning (CASP) systems lack mechanistic grounding. We introduce a computational framework for teaching language models to predict chemical reaction mechanisms through arrow pushing formalism, a century-old notation that tracks electron flow while respecting conservation laws. We developed MechSMILES, a compact textual format encoding molecular structure and electron flow, and trained language models on four mechanism prediction tasks of increasing complexity using mechanistic reaction datasets, such as mech-USPTO-31k and FlowER. Our models achieve more than 95\% top-3 accuracy on elementary step prediction and scores that surpass 73\% on mech-USPTO-31k, and 93\% on FlowER dataset for the retrieval of complete reaction mechanisms on our hardest task. This mechanistic understanding enables three key applications. First, our models serve as post-hoc validators for CASP systems, filtering chemically implausible transformations. Second, they enable holistic atom-to-atom mapping that tracks all atoms, including hydrogens. Third, they extract catalyst-aware reaction templates that distinguish recycled catalysts from spectator species. By grounding predictions in physically meaningful electron moves that ensure conservation of mass and charge, this work provides a pathway toward more explainable and chemically valid computational synthesis planning, while providing an architecture-agnostic framework for the benchmarking of mechanism prediction.

</details>


### [164] [Towards agent-based-model informed neural networks](https://arxiv.org/abs/2512.05764)
*Nino Antulov-Fantulin*

Main category: cs.LG

TL;DR: 提出ABM-NNs框架，通过受限图神经网络和层次分解学习可解释、保持结构约束的动力学，在生态、传染病、宏观经济三个案例中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 标准神经微分方程在建模复杂系统时存在局限，缺乏物理不变量（如能量）但需要强制执行其他约束（如质量守恒、网络局部性、有限理性）。需要设计保持智能体模型基本原理一致的神经网络。

Method: 引入Agent-Based-Model informed Neural Networks(ABM-NNs)，利用受限图神经网络和层次分解来学习可解释、保持结构约束的动力学。

Result: 在三个案例中验证：1)广义Lotka-Volterra系统中从短轨迹恢复真实参数；2)图基SIR传染病模型中在样本外预测和噪声鲁棒性上优于GCN、GraphSAGE、Graph Transformer等基线；3)真实宏观经济模型中从经验数据学习耦合GDP动力学并实现基于梯度的反事实政策分析。

Conclusion: ABM-NNs框架能够有效学习保持智能体模型约束的可解释动力学，在复杂系统建模中表现出色，为政策干预分析提供了新工具。

Abstract: In this article, we present a framework for designing neural networks that remain consistent with the underlying principles of agent-based models. We begin by highlighting the limitations of standard neural differential equations in modeling complex systems, where physical invariants (like energy) are often absent but other constraints (like mass conservation, network locality, bounded rationality) must be enforced. To address this, we introduce Agent-Based-Model informed Neural Networks(ABM-NNs), which leverage restricted graph neural networks and hierarchical decomposition to learn interpretable, structure-preserving dynamics. We validate the framework across three case studies of increasing complexity: (i) a generalized Generalized Lotka--Volterra system, where we recover ground-truth parameters from short trajectories in presence of interventions; (ii) a graph-based SIR contagion model, where our method outperforms state-of-the-art graph learning baselines (GCN, GraphSAGE, Graph Transformer) in out-of-sample forecasting and noise robustness; and (iii) a real-world macroeconomic model of the ten largest economies, where we learn coupled GDP dynamics from empirical data and demonstrate gradient-based counterfactual analysis for policy interventions.

</details>


### [165] [Learnability Window in Gated Recurrent Neural Networks](https://arxiv.org/abs/2512.05790)
*Lorenzo Livi*

Main category: cs.LG

TL;DR: 论文提出理论框架，解释门控机制如何决定循环神经网络的可学习窗口，强调有效学习率而非数值稳定性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 传统分析强调雅可比乘积的数值稳定性，但这不足以解释门控循环网络如何学习长期依赖关系。需要理解门控机制如何影响梯度信息的统计可恢复性。

Method: 通过一阶展开门控诱导的雅可比乘积，推导出有效学习率μ_{t,ℓ}，作为控制梯度传输的乘性滤波器。在重尾梯度噪声下，分析样本复杂度与有效学习率衰减的关系。

Result: 得到可学习窗口H_N的显式公式和缩放定律，发现更宽或更异构的门控谱产生更大的可学习窗口，而重尾噪声会压缩可学习窗口。

Conclusion: 有效学习率是决定门控循环网络何时以及多长能够学习长期时间依赖关系的基本量，连接了门控时间尺度结构、梯度噪声和样本复杂度。

Abstract: We develop a theoretical framework that explains how gating mechanisms determine the learnability window $\mathcal{H}_N$ of recurrent neural networks, defined as the largest temporal horizon over which gradient information remains statistically recoverable. While classical analyses emphasize numerical stability of Jacobian products, we show that stability alone is insufficient: learnability is governed instead by the \emph{effective learning rates} $μ_{t,\ell}$, per-lag and per-neuron quantities obtained from first-order expansions of gate-induced Jacobian products in Backpropagation Through Time. These effective learning rates act as multiplicative filters that control both the magnitude and anisotropy of gradient transport. Under heavy-tailed ($α$-stable) gradient noise, we prove that the minimal sample size required to detect a dependency at lag~$\ell$ satisfies $N(\ell)\propto f(\ell)^{-α}$, where $f(\ell)=\|μ_{t,\ell}\|_1$ is the effective learning rate envelope. This leads to an explicit formula for $\mathcal{H}_N$ and closed-form scaling laws for logarithmic, polynomial, and exponential decay of $f(\ell)$. The theory predicts that broader or more heterogeneous gate spectra produce slower decay of $f(\ell)$ and hence larger learnability windows, whereas heavier-tailed noise compresses $\mathcal{H}_N$ by slowing statistical concentration. By linking gate-induced time-scale structure, gradient noise, and sample complexity, the framework identifies the effective learning rates as the fundamental quantities that govern when -- and for how long -- gated recurrent networks can learn long-range temporal dependencies.

</details>


### [166] [Mechanistic Interpretability of Antibody Language Models Using SAEs](https://arxiv.org/abs/2512.05794)
*Rebonto Haque,Oliver M. Turnbull,Anisha Parsan,Nithin Parsan,John J. Yang,Charlotte M. Deane*

Main category: cs.LG

TL;DR: TopK SAEs能识别生物学相关特征但因果控制有限，Ordered SAEs能可靠实现生成控制但可解释性较差


<details>
  <summary>Details</summary>
Motivation: 研究稀疏自编码器在蛋白质语言模型中的机制可解释性，特别是如何有效控制和引导抗体语言模型p-IgGen的生成

Method: 使用TopK和Ordered两种稀疏自编码器技术分析自回归抗体语言模型p-IgGen，比较它们在特征识别和生成控制方面的表现

Result: TopK SAEs能揭示生物学意义的潜在特征，但高特征概念相关性不保证对生成的因果控制；Ordered SAEs能可靠识别可控制特征，但激活模式更复杂、可解释性较差

Conclusion: TopK SAEs适合将潜在特征映射到概念，而Ordered SAEs在需要精确生成控制时更优，这推进了领域特定蛋白质语言模型的机制可解释性

Abstract: Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.

</details>


### [167] [Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws](https://arxiv.org/abs/2512.05817)
*Zhengquan Luo,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 论文提出了一个统一的DD理论框架，通过配置-动态-误差分析解释了不同蒸馏方法的共同原理，推导出缩放定律和覆盖定律，揭示了匹配方法是可互换的替代目标。


<details>
  <summary>Details</summary>
Motivation: 数据集蒸馏(DD)虽然取得了快速的经验进展，但理论基础有限：现有方法基于不同的替代目标和优化假设，难以分析共同原理或提供一般性保证。同时不清楚在训练配置变化时，蒸馏数据如何保持有效性。

Method: 提出了配置-动态-误差分析统一理论框架，将主要DD方法重新表述在共同的泛化误差视角下，推导出缩放定律和覆盖定律，并通过实验验证。

Result: 推导出两个主要结果：(1)缩放定律提供了单配置上界，解释性能饱和效应；(2)覆盖定律显示所需蒸馏样本量与配置多样性呈线性比例，具有可证明匹配的上下界。实验证实了这些定律。

Conclusion: 统一分析揭示了各种匹配方法是可互换的替代目标，减少了相同的泛化误差，解释了它们都能实现数据集蒸馏的原因，为DD提供了理论基础，并支持理论驱动的紧凑、配置鲁棒的数据集蒸馏设计。

Abstract: Dataset distillation (DD) aims to construct compact synthetic datasets that allow models to achieve comparable performance to full-data training while substantially reducing storage and computation. Despite rapid empirical progress, its theoretical foundations remain limited: existing methods (gradient, distribution, trajectory matching) are built on heterogeneous surrogate objectives and optimization assumptions, which makes it difficult to analyze their common principles or provide general guarantees. Moreover, it is still unclear under what conditions distilled data can retain the effectiveness of full datasets when the training configuration, such as optimizer, architecture, or augmentation, changes. To answer these questions, we propose a unified theoretical framework, termed configuration--dynamics--error analysis, which reformulates major DD approaches under a common generalization-error perspective and provides two main results: (i) a scaling law that provides a single-configuration upper bound, characterizing how the error decreases as the distilled sample size increases and explaining the commonly observed performance saturation effect; and (ii) a coverage law showing that the required distilled sample size scales linearly with configuration diversity, with provably matching upper and lower bounds. In addition, our unified analysis reveals that various matching methods are interchangeable surrogates, reducing the same generalization error, clarifying why they can all achieve dataset distillation and providing guidance on how surrogate choices affect sample efficiency and robustness. Experiments across diverse methods and configurations empirically confirm the derived laws, advancing a theoretical foundation for DD and enabling theory-driven design of compact, configuration-robust dataset distillation.

</details>


### [168] [Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization](https://arxiv.org/abs/2512.05825)
*Shuhei Watanabe*

Main category: cs.LG

TL;DR: 本文填补了多目标贝叶斯优化中HV改进近似算法文献空白，提供了完整的数学和算法描述


<details>
  <summary>Details</summary>
Motivation: HV-based BO中获取函数的优化计算成本高，主要源于HV改进计算的昂贵性。虽然HV box分解能处理频繁的精确改进计算，但存在超多项式内存复杂度问题。现有近似算法缺乏严格的算法描述。

Method: 提供Couckuyt等人(2012)提出的近似算法的全面数学和算法细节，填补文献中的描述空白

Result: 为HV改进近似算法提供了完整的数学框架和算法实现细节，使该方法的实际应用成为可能

Conclusion: 本文填补了多目标贝叶斯优化领域的重要文献空白，为HV改进的高效近似计算提供了可实现的算法基础

Abstract: Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\lfloor \frac{M + 1}{2} \rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.

</details>


### [169] [NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation](https://arxiv.org/abs/2512.05844)
*Daniel Rose,Roxane Axel Jacob,Johannes Kirchmair,Thierry Langer*

Main category: cs.LG

TL;DR: NEAT：一种邻域引导、高效的自回归集合Transformer，用于3D分子生成，通过自回归流模型学习图边界上顺序无关的令牌分布，实现原子级置换不变性。


<details>
  <summary>Details</summary>
Motivation: 自回归模型是3D分子结构生成的有前景的替代方案，但存在令牌顺序假设的限制。文本有自然顺序，但分子图的下一令牌预测应对原子置换保持不变。先前工作使用规范顺序或焦点原子来回避这一问题，但作者认为这是不必要的。

Method: 提出NEAT（邻域引导、高效、自回归、集合Transformer），将分子图视为原子集合，通过自回归流模型学习图边界上可接受令牌的顺序无关分布。模型具有原子级置换不变性。

Result: NEAT在3D分子生成中达到最先进性能，具有高计算效率，建立了可扩展分子设计的实用基础。

Conclusion: NEAT通过处理分子图为原子集合并学习顺序无关分布，解决了自回归模型中令牌顺序假设的限制，为3D分子生成提供了高效且置换不变的解决方案。

Abstract: Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.

</details>


### [170] [Sparse Attention Post-Training for Mechanistic Interpretability](https://arxiv.org/abs/2512.05865)
*Florent Draye,Anson Lei,Ingmar Posner,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 提出一种简单的后训练方法，使Transformer注意力稀疏化而不牺牲性能，可将注意力连接减少到约0.3%，同时保持原始预训练损失


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法主要关注计算效率，而本文旨在利用稀疏性作为结构先验，揭示更有序、可解释的连接模式，探索Transformer中计算冗余的可能性

Method: 采用简单的后训练方法，在约束损失目标下应用灵活的稀疏正则化，使Transformer注意力稀疏化，保留原始预训练能力

Result: 在高达10亿参数的模型上，可将注意力连接减少到约0.3%的边，同时保持原始预训练损失；局部稀疏性级联为全局电路简化，任务特定电路涉及更少的组件（注意力头和MLP），连接边减少达100倍

Conclusion: Transformer注意力可以变得稀疏数个数量级，表明其大部分计算是冗余的，稀疏性可以作为构建更结构化、可解释模型的指导原则

Abstract: We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\approx 0.3 \%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.

</details>


### [171] [Predicting Price Movements in High-Frequency Financial Data with Spiking Neural Networks](https://arxiv.org/abs/2512.05868)
*Brian Ezinwoke,Oliver Rhodes*

Main category: cs.LG

TL;DR: 该研究将脉冲神经网络应用于高频交易中的价格尖峰预测，通过贝叶斯优化和惩罚性尖峰准确率目标函数提升性能，在模拟交易中取得了显著优于传统方法的回报率。


<details>
  <summary>Details</summary>
Motivation: 传统金融模型难以捕捉高频交易中的细粒度时间结构，而脉冲神经网络具有处理离散事件和保持毫秒级时间精度的天然优势，适合用于价格尖峰预测。

Method: 将高频股票数据转换为脉冲序列，评估三种架构：无监督STDP训练的SNN、具有显式抑制竞争的新型SNN、监督反向传播网络。使用贝叶斯优化和专门设计的惩罚性尖峰准确率目标函数进行超参数调优。

Result: 使用PSA优化的模型在模拟交易中表现优于SA优化的模型和基线。扩展的SNN模型在简单回测中实现了最高的累计回报率（76.8%），显著超过监督替代方案（42.54%回报率）。

Conclusion: 研究验证了脉冲神经网络在通过任务特定目标函数进行鲁棒调优后，在高频交易价格尖峰预测中的有效潜力。

Abstract: Modern high-frequency trading (HFT) environments are characterized by sudden price spikes that present both risk and opportunity, but conventional financial models often fail to capture the required fine temporal structure. Spiking Neural Networks (SNNs) offer a biologically inspired framework well-suited to these challenges due to their natural ability to process discrete events and preserve millisecond-scale timing. This work investigates the application of SNNs to high-frequency price-spike forecasting, enhancing performance via robust hyperparameter tuning with Bayesian Optimization (BO). This work converts high-frequency stock data into spike trains and evaluates three architectures: an established unsupervised STDP-trained SNN, a novel SNN with explicit inhibitory competition, and a supervised backpropagation network. BO was driven by a novel objective, Penalized Spike Accuracy (PSA), designed to ensure a network's predicted price spike rate aligns with the empirical rate of price events. Simulated trading demonstrated that models optimized with PSA consistently outperformed their Spike Accuracy (SA)-tuned counterparts and baselines. Specifically, the extended SNN model with PSA achieved the highest cumulative return (76.8%) in simple backtesting, significantly surpassing the supervised alternative (42.54% return). These results validate the potential of spiking networks, when robustly tuned with task-specific objectives, for effective price spike forecasting in HFT.

</details>


### [172] [Computational Design of Low-Volatility Lubricants for Space Using Interpretable Machine Learning](https://arxiv.org/abs/2512.05870)
*Daniel Miliate,Ashlie Martini*

Main category: cs.LG

TL;DR: 开发数据驱动的机器学习方法预测蒸汽压，用于筛选适合太空环境的液体润滑剂


<details>
  <summary>Details</summary>
Motivation: 太空环境中移动机械组件需要液体润滑剂，但现有适合真空条件的液体润滑剂种类有限且各有局限性，限制了机械设计

Method: 采用数据驱动的机器学习方法，结合高通量分子动力学模拟和实验数据库数据训练模型，注重模型可解释性以识别化学结构与蒸汽压的关系

Result: 训练出能够预测蒸汽压的机器学习模型，基于模型洞察提出了多个有潜力的候选分子用于未来太空润滑剂应用

Conclusion: 机器学习方法能够有效预测蒸汽压并发现新的太空适用液体润滑剂，为移动机械组件设计提供了更多选择

Abstract: The function and lifetime of moving mechanical assemblies (MMAs) in space depend on the properties of lubricants. MMAs that experience high speeds or high cycles require liquid based lubricants due to their ability to reflow to the point of contact. However, only a few liquid-based lubricants have vapor pressures low enough for the vacuum conditions of space, each of which has limitations that add constraints to MMA designs. This work introduces a data-driven machine learning (ML) approach to predicting vapor pressure, enabling virtual screening and discovery of new space-suitable liquid lubricants. The ML models are trained with data from both high-throughput molecular dynamics simulations and experimental databases. The models are designed to prioritize interpretability, enabling the relationships between chemical structure and vapor pressure to be identified. Based on these insights, several candidate molecules are proposed that may have promise for future space lubricant applications in MMAs.

</details>


### [173] [Neural Coherence : Find higher performance to out-of-distribution tasks from few samples](https://arxiv.org/abs/2512.05880)
*Simon Guiroy,Mats Richter,Sarath Chandar,Christopher Pal*

Main category: cs.LG

TL;DR: 提出Neural Coherence方法，仅需少量无标注目标域样本即可高效选择预训练模型检查点，在数据稀缺、无标注、分布外场景下显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前微调预训练视觉大模型时，如何从大量训练检查点中选择最佳起点仍是一个开放问题。当目标任务数据稀缺、无标注且分布外时，依赖分布内验证数据的传统方法变得不可靠或不适用。

Method: 提出Neural Coherence方法，通过分析模型在源域和目标域的激活统计特征来定义模型选择标准。该方法仅需少量无标注目标域样本，具有高数据效率。

Result: 在ImageNet1K预训练模型上，针对Food-101、PlantNet-300K和iNaturalist等目标域进行实验，同时在元学习设置中评估。相比基线方法，该方法在不同目标域上显著提升了泛化性能，并展示了在训练数据选择中的有效性。

Conclusion: Neural Coherence是一个强大的原则，能够在数据稀缺、无标注、分布外场景下高效选择预训练模型检查点，为模型选择问题提供了新颖有效的解决方案。

Abstract: To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.

</details>


### [174] [DAE-HardNet: A Physics Constrained Neural Network Enforcing Differential-Algebraic Hard Constraints](https://arxiv.org/abs/2512.05881)
*Rahul Golder,Bimol Nath Roy,M. M. Faruque Hasan*

Main category: cs.LG

TL;DR: DAE-HardNet是一种物理约束神经网络，通过可微分投影层同时学习函数及其导数，严格满足微分代数方程约束，相比传统PINNs实现物理损失数量级降低。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络(PINNs)通常以软约束方式最小化物理约束违反，难以严格满足包含微分算子的约束。数据驱动模型将原始函数视为黑箱，其导数只能在函数评估后获得，这使得严格嵌入微分代数方程(DAEs)约束具有挑战性。

Method: 提出DAE-HardNet，通过可微分投影层将模型预测投影到约束流形上，同时学习函数及其导数，强制满足代数和微分约束。该方法包含参数估计能力，并可在某些情况下绕过投影层进行快速推理。

Result: 相比多层感知机(MLPs)和PINNs，DAE-HardNet实现了物理损失的数量级降低，同时保持预测精度。具有学习导数的额外优势，改进了投影层前主干神经网络的约束学习。

Conclusion: DAE-HardNet提供了一种严格满足物理约束的神经网络框架，特别适用于微分代数方程约束的系统，在动态Lotka-Volterra捕食者-猎物系统和瞬态热传导等测试中表现优异。

Abstract: Traditional physics-informed neural networks (PINNs) do not always satisfy physics based constraints, especially when the constraints include differential operators. Rather, they minimize the constraint violations in a soft way. Strict satisfaction of differential-algebraic equations (DAEs) to embed domain knowledge and first-principles in data-driven models is generally challenging. This is because data-driven models consider the original functions to be black-box whose derivatives can only be obtained after evaluating the functions. We introduce DAE-HardNet, a physics-constrained (rather than simply physics-informed) neural network that learns both the functions and their derivatives simultaneously, while enforcing algebraic as well as differential constraints. This is done by projecting model predictions onto the constraint manifold using a differentiable projection layer. We apply DAE-HardNet to several systems and test problems governed by DAEs, including the dynamic Lotka-Volterra predator-prey system and transient heat conduction. We also show the ability of DAE-HardNet to estimate unknown parameters through a parameter estimation problem. Compared to multilayer perceptrons (MLPs) and PINNs, DAE-HardNet achieves orders of magnitude reduction in the physics loss while maintaining the prediction accuracy. It has the added benefits of learning the derivatives which improves the constrained learning of the backbone neural network prior to the projection layer. For specific problems, this suggests that the projection layer can be bypassed for faster inference. The current implementation and codes are available at https://github.com/SOULS-TAMU/DAE-HardNet.

</details>


### [175] [KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity](https://arxiv.org/abs/2512.05916)
*Damien Lesens,Beheshteh T. Rakhshan,Guillaume Rabusseau*

Main category: cs.LG

TL;DR: KQ-SVD：一种直接对注意力矩阵进行最优低秩分解的新方法，相比现有KV缓存压缩方法能更精确地保持注意力输出


<details>
  <summary>Details</summary>
Motivation: 随着序列长度和批处理大小的增长，KV缓存成为大语言模型推理的主要内存瓶颈。现有的压缩方法通常只对键进行低秩分解或联合嵌入查询和键，但都忽略了注意力本质上依赖于它们的内积这一事实。

Method: 提出KQ-SVD方法，通过闭式解直接对注意力矩阵进行最优低秩分解。该方法针对冗余的真正来源，在压缩下能更高保真度地保持注意力输出。

Result: 在LLaMA和Mistral模型上的广泛评估表明，KQ-SVD方法在投影质量方面始终优于现有方法。

Conclusion: KQ-SVD通过直接对注意力矩阵进行最优分解，解决了现有KV缓存压缩方法的局限性，为大语言模型的高效推理提供了更有效的解决方案。

Abstract: The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.

</details>


### [176] [Impugan: Learning Conditional Generative Models for Robust Data Imputation](https://arxiv.org/abs/2512.05950)
*Zalish Mahmud,Anantaa Kotal,Aritran Piplai*

Main category: cs.LG

TL;DR: Impugan是一种基于条件生成对抗网络（cGAN）的缺失值填补方法，能够处理异构数据集，相比传统方法显著降低了Earth Mover's Distance和互信息偏差。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常存在缺失值，传感器故障、记录不一致、多源数据差异等问题导致传统填补方法（如回归、期望最大化、多重填补）基于线性和独立性假设，难以处理复杂异构数据，容易产生偏差或过度平滑。

Method: 提出Impugan模型，使用条件生成对抗网络（cGAN）进行缺失值填补和异构数据集整合。模型在完整样本上训练，学习缺失变量对观测变量的依赖关系。推理时，生成器根据可用特征重构缺失条目，判别器通过区分真实数据和填补数据来强制实现真实性。

Result: 在基准数据集和多源整合任务实验中，Impugan相比领先基线方法实现了高达82%的Earth Mover's Distance降低和70%的互信息偏差降低。

Conclusion: 对抗训练的生成模型为填补和合并不完整、异构数据提供了一种可扩展且有原则的方法，能够捕捉传统方法无法表示的非线性和多模态关系。

Abstract: Incomplete data are common in real-world applications. Sensors fail, records are inconsistent, and datasets collected from different sources often differ in scale, sampling rate, and quality. These differences create missing values that make it difficult to combine data and build reliable models. Standard imputation methods such as regression models, expectation-maximization, and multiple imputation rely on strong assumptions about linearity and independence. These assumptions rarely hold for complex or heterogeneous data, which can lead to biased or over-smoothed estimates. We propose Impugan, a conditional Generative Adversarial Network (cGAN) for imputing missing values and integrating heterogeneous datasets. The model is trained on complete samples to learn how missing variables depend on observed ones. During inference, the generator reconstructs missing entries from available features, and the discriminator enforces realism by distinguishing true from imputed data. This adversarial process allows Impugan to capture nonlinear and multimodal relationships that conventional methods cannot represent. In experiments on benchmark datasets and a multi-source integration task, Impugan achieves up to 82\% lower Earth Mover's Distance (EMD) and 70\% lower mutual-information deviation (MI) compared to leading baselines. These results show that adversarially trained generative models provide a scalable and principled approach for imputing and merging incomplete, heterogeneous data. Our model is available at: github.com/zalishmahmud/impuganBigData2025

</details>


### [177] [MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution](https://arxiv.org/abs/2512.05958)
*Sara Patel,Mingxun Zhou,Giulia Fanti*

Main category: cs.LG

TL;DR: MaxShapley是一种用于生成式搜索引擎的高效公平归因算法，基于可分解的max-sum效用函数，将Shapley值计算复杂度从指数级降低到线性级，显著减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的生成式搜索引擎取代传统搜索，信息提供者的补偿方式发生根本变化。需要公平的机制来归因和补偿内容提供者，以维持生态系统可持续发展。

Method: 提出MaxShapley算法，这是Shapley值的一个特例，利用可分解的max-sum效用函数，在检索增强生成(RAG)管道中实现高效公平归因。算法将计算复杂度从指数级降低到线性级。

Result: 在三个多跳问答数据集(HotPotQA、MuSiQUE、MS MARCO)上评估，MaxShapley达到与精确Shapley计算相当的归因质量，同时显著减少资源消耗。相比先前最先进方法，在相同归因准确度下资源消耗减少高达8倍。

Conclusion: MaxShapley为生成式搜索引擎提供了一种高效公平的内容归因机制，能够在保持高质量归因的同时大幅降低计算成本，有助于构建可持续的生成式搜索生态系统。

Abstract: Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.

</details>


### [178] [Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity](https://arxiv.org/abs/2512.05962)
*Germán Kruszewski,Pierre Erbacher,Jos Rozen,Marc Dymetman*

Main category: cs.LG

TL;DR: 论文提出使用α散度替代传统RL来微调LLM，解决RL导致的多样性损失问题，在定理证明任务上实现了覆盖率和精度的帕累托最优。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法微调LLM会导致显著的多样性损失，这是因为RL隐式优化了"模式寻求"的反向KL散度，使模型集中在目标分布的高概率区域而忽略其他区域。

Method: 从显式目标分布出发（通过过滤错误答案同时保留正确答案的相对概率），使用α散度族来近似这个目标分布，通过插值在模式寻求和质量覆盖散度之间实现精度-多样性权衡的直接控制。

Result: 在Lean定理证明基准测试中，该方法在覆盖-精度帕累托前沿上实现了最先进的性能，在覆盖率轴上优于所有先前方法。

Conclusion: α散度方法能有效解决RL微调LLM时的多样性损失问题，通过显式控制精度-多样性权衡，在定理证明等推理任务上取得了更好的性能平衡。

Abstract: Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the "mode-seeking" or "zero-forcing" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.

</details>


<div id='q-fin.PR'></div>

# q-fin.PR [[Back]](#toc)

### [179] [Differential ML with a Difference](https://arxiv.org/abs/2512.05301)
*Paul Glasserman,Siddharth Hemant Karmarkar*

Main category: q-fin.PR

TL;DR: Differential ML 在间断收益期权（如数字期权、障碍期权）上存在路径wise敏感度偏差问题，作者提出使用似然比方法计算敏感度标签，并引入混合方法结合gamma估计，显著降低了测试误差。


<details>
  <summary>Details</summary>
Motivation: Differential ML 使用路径wise伴随微分计算价格敏感度来训练神经网络，但对于间断收益期权（数字期权、障碍期权），路径wise敏感度存在偏差，将其纳入损失函数会放大误差，需要寻找替代方法。

Method: 1) 使用似然比方法计算敏感度标签，扩展Differential ML到间断收益期权；2) 提出混合方法，同时结合gamma估计和delta估计，提供进一步的正则化。

Result: 替代的敏感度估计方法（特别是似然比方法）显著降低了价格及其敏感度的测试误差，混合方法通过结合gamma估计提供了额外的正则化效果。

Conclusion: 通过使用似然比方法计算敏感度标签，Differential ML可以扩展到间断收益期权，混合方法结合gamma估计进一步提高了性能，为复杂衍生品定价和风险管理提供了更准确的快速近似。

Abstract: Differential ML (Huge and Savine 2020) is a technique for training neural networks to provide fast approximations to complex simulation-based models for derivatives pricing and risk management. It uses price sensitivities calculated through pathwise adjoint differentiation to reduce pricing and hedging errors. However, for options with discontinuous payoffs, such as digital or barrier options, the pathwise sensitivities are biased, and incorporating them into the loss function can magnify errors. We consider alternative methods for estimating sensitivities and find that they can substantially reduce test errors in prices and in their sensitivities. Using differential labels calculated through the likelihood ratio method expands the scope of Differential ML to discontinuous payoffs. A hybrid method incorporates gamma estimates as well as delta estimates, providing further regularization.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [180] [Standard and stressed value at risk forecasting using dynamic Bayesian networks](https://arxiv.org/abs/2512.05661)
*Eden Gross,Ryan Kruger,Francois Toerien*

Main category: q-fin.RM

TL;DR: 该研究提出了一种用于预测风险价值（VaR）和压力风险价值（SVaR）的动态贝叶斯网络框架，并与传统模型进行了比较，发现自回归模型在VaR预测上表现最佳，DBNs虽未超越传统模型但展示了前瞻性方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统金融风险预测模型主要依赖历史数据，缺乏前瞻性视角。本研究旨在探索动态贝叶斯网络（DBN）这种能够整合历史与预测回报的前瞻性方法，以改进VaR和SVaR的预测准确性。

Method: 使用1991-2020年标普500指数日收益率数据，采用滚动窗口方法生成10天99%的VaR和SVaR预测。比较了传统模型（使用历史收益率）和三个DBN模型（同时使用历史和预测收益率），并通过标准回测和预测误差指标评估模型性能。

Result: 自回归模型在VaR预测上表现最准确，DBNs与历史模拟模型表现相当，尽管DBNs整合了前瞻性回报预测。对于SVaR，所有模型都产生高度保守的预测，突破次数极少，各模型间准确性差异有限。

Conclusion: 虽然DBNs未能超越传统模型，但它们证明了将前瞻性方法应用于金融风险预测的可行性，为未来研究将因果推断整合到金融风险预测中奠定了基础。

Abstract: This study introduces a dynamic Bayesian network (DBN) framework for forecasting value at risk (VaR) and stressed VaR (SVaR) and compares its performance to several commonly applied models. Using daily S&P 500 index returns from 1991 to 2020, we produce 10-day 99% VaR and SVaR forecasts using a rolling period and historical returns for the traditional models, while three DBNs use both historical and forecasted returns. We evaluate the models' forecasting accuracy using standard backtests and forecasting error measures. Results show that autoregressive models deliver the most accurate VaR forecasts, while the DBNs achieve comparable performance to the historical simulation model, despite incorporating forward-looking return forecasts. For SVaR, all models produce highly conservative forecasts, with minimal breaches and limited differentiation in accuracy. While DBNs do not outperform traditional models, they demonstrate feasibility as a forward-looking approach to provide a foundation for future research on integrating causal inference into financial risk forecasting.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [181] [Convolution-FFT for option pricing in the Heston model](https://arxiv.org/abs/2512.05326)
*Xiang Gao,Cody Hyndman*

Main category: q-fin.CP

TL;DR: 提出一种用于Heston模型下欧式期权定价的卷积-FFT方法，使用联合特征函数的连续可微表示，无需分支切割调整或经验调参，提供完全解析的误差界。


<details>
  <summary>Details</summary>
Motivation: 现有基于傅里叶变换的Heston模型期权定价方法通常需要分支切割调整或经验性阻尼参数调整，缺乏理论误差分析，计算稳定性不足。

Method: 采用卷积-FFT方法，利用联合特征函数的连续可微表示，推导出完全解析的截断误差和离散化误差界，通过数值实验验证理论收敛率。

Result: 方法在计算成本适中的情况下实现稳健的高精度期权定价，数值实验证实了理论收敛率，误差界能够准确量化模型参数和网格设置的影响。

Conclusion: 该方法为Heston模型下的FFT卷积方法提供了首个显式闭式误差估计，实现了无需经验调参的稳定、高效期权定价。

Abstract: We propose a convolution-FFT method for pricing European options under the Heston model that leverages a continuously differentiable representation of the joint characteristic function. Unlike existing Fourier-based methods that rely on branch-cut adjustments or empirically tuned damping parameters, our approach yields a stable integrand even under large frequency oscillations. Crucially, we derive fully analytical error bounds that quantify both truncation error and discretization error in terms of model parameters and grid settings. To the best of our knowledge, this is the first work to provide such explicit, closed-form error estimates for an FFT-based convolution method specialized to the Heston model. Numerical experiments confirm the theoretical rates and illustrate robust, high-accuracy option pricing at modest computational cost.

</details>


### [182] [A Unified AI System For Data Quality Control and DataOps Management in Regulated Environments](https://arxiv.org/abs/2512.05559)
*Devender Saini,Bhavika Jain,Nitish Ujjwal,Philip Sommer,Dan Romuald Mbanga,Dhagash Mehta*

Main category: q-fin.CP

TL;DR: 提出了一个统一的AI驱动数据质量控制和DataOps管理框架，将QC嵌入到整个数据流程中，而非孤立的前处理步骤


<details>
  <summary>Details</summary>
Motivation: 在金融等受监管领域，数据管道的完整性和治理至关重要，但现有系统将数据质量控制视为孤立的预处理步骤而非系统核心组件

Method: 开发了一个统一框架，将基于规则、统计和AI的QC方法嵌入到持续治理层中，涵盖数据摄取、模型管道和下游应用，整合开源工具和自定义模块

Result: 在生产级金融环境中部署成功，处理多资产类别和交易流，在异常检测召回率、减少人工修复工作量、提高审计可追溯性方面取得实证收益

Conclusion: 将QC作为系统关注点而非事后考虑，为受监管环境中可信、可扩展和合规的AI管道提供了基础

Abstract: In regulated domains such as finance, the integrity and governance of data pipelines are critical - yet existing systems treat data quality control (QC) as an isolated preprocessing step rather than a first-class system component. We present a unified AI-driven Data QC and DataOps Management framework that embeds rule-based, statistical, and AI-based QC methods into a continuous, governed layer spanning ingestion, model pipelines, and downstream applications. Our architecture integrates open-source tools with custom modules for profiling, audit logging, breach handling, configuration-driven policies, and dynamic remediation. We demonstrate deployment in a production-grade financial setup: handling streaming and tabular data across multiple asset classes and transaction streams, with configurable thresholds, cloud-native storage interfaces, and automated alerts. We show empirical gains in anomaly detection recall, reduction of manual remediation effort, and improved auditability and traceability in high-throughput data workflows. By treating QC as a system concern rather than an afterthought, our framework provides a foundation for trustworthy, scalable, and compliant AI pipelines in regulated environments.

</details>
