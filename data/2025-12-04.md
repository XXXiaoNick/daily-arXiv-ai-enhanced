<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [math.OC](#math.OC) [Total: 18]
- [q-fin.RM](#q-fin.RM) [Total: 2]
- [q-fin.PR](#q-fin.PR) [Total: 1]
- [econ.EM](#econ.EM) [Total: 3]
- [cs.CY](#cs.CY) [Total: 14]
- [cs.LG](#cs.LG) [Total: 101]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [eess.SY](#eess.SY) [Total: 15]
- [stat.ML](#stat.ML) [Total: 6]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 论文提出了一种动态评估大语言模型安全性的方法，通过定义伦理熵概念来量化模型的价值漂移，并开发了监控系统来实时检测对齐失效。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型安全性评估主要依赖静态基准测试，但关键失效往往是动态的：包括分布漂移下的价值漂移、越狱攻击以及部署中对齐的缓慢退化。需要一种动态监控方法来实时检测这些风险。

Method: 基于"智能第二定律"框架，将伦理熵作为状态变量；定义五类行为分类法；训练分类器从模型转录中估计伦理熵S(t)；在四个前沿模型的基础版和指令调优版上进行压力测试，测量熵动态变化；从轨迹中估计有效对齐工作率γ_eff；将S(t)和γ_eff嵌入监控管道，当熵漂移超过稳定阈值时发出警报。

Result: 基础模型显示持续的熵增长，而调优变体抑制了漂移，将伦理熵降低了约80%。通过轨迹分析能够估计有效对齐工作率，监控系统能够实时检测价值漂移。

Conclusion: 该框架为LLM安全提供了动态监控方法，使运行时监督价值漂移成为可能，有助于在部署中维持模型对齐状态，防止伦理退化。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [2] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 该论文研究EaaS水印技术，发现现有水印易被改写攻击绕过，并提出新的WET水印方案来防御模仿攻击。


<details>
  <summary>Details</summary>
Motivation: 随着企业提供嵌入即服务(EaaS)，模型面临模仿攻击威胁。现有水印保护技术存在漏洞，需要更强大的水印方案来保护EaaS提供商的知识产权。

Method: 首先分析现有EaaS水印的脆弱性，展示改写攻击如何绕过水印。然后提出WET水印技术，使用线性变换嵌入，通过反向变换和相似度比较进行验证。

Result: 发现改写攻击能有效绕过现有最先进的EaaS水印。提出的WET水印对改写攻击具有鲁棒性，验证准确率接近完美。通过消融研究分析了各组件和超参数的重要性。

Conclusion: 现有EaaS水印存在被改写攻击绕过的漏洞，提出的WET水印技术能有效防御此类攻击，为EaaS提供商提供了更可靠的模型知识产权保护方案。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [3] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 提出RDG框架，通过生成平衡推理数据来减轻LLM中的选择支持性偏见，在记忆和评估实验中分别提升81.5%和94.3%的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在评估时表现出选择支持性偏见，会系统性地偏向自己选择的选项，这可能损害AI辅助决策的客观性。现有去偏见方法主要针对人口统计和社会偏见，而针对LLM认知偏见的方法尚未充分探索。

Method: 提出推理依赖生成框架，自动构建平衡的推理问答对，明确建模选择、证据和理由之间的依赖关系。该方法生成跨领域的大规模数据集，包含上下文依赖数据和依赖解耦数据。

Result: 使用RDG生成数据微调的LLM在记忆实验中提升81.5%，在评估实验中提升94.3%，同时在标准BBQ基准测试中保持相似性能。

Conclusion: 这项工作开创了解决LLM认知偏见的方法，有助于开发更可靠的AI辅助决策支持系统。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [4] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 该研究开发了一个开源工具，结合句子链接和实体链接方法，将招聘文本链接到ESCO和EQF框架，并发布了两个标注数据集用于评估职业和资格在招聘文本中的表示。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进劳动力市场信息的分类，通过将招聘文本链接到欧洲技能、能力、资格和职业（ESCO）分类以及欧洲资格框架（EQF），以超越表面技能提取，深入分析职业和资格在招聘文本中的表示。

Method: 研究比较了两种主要方法：句子链接和实体链接。开发了开源工具整合这两种方法，并创建了两个专门用于评估职业和资格表示的标注数据集。同时探索了使用生成式大语言模型来完成此任务的不同方式。

Result: 研究结果推进了工作实体提取的技术水平，提供了用于分析数字化经济中工作、技能和劳动力市场叙事的计算基础设施。代码已公开在GitHub上。

Conclusion: 该研究为劳动力分类和就业话语分析提供了实用工具和数据集，有助于更深入地理解数字化经济中的劳动力市场动态，并为相关研究提供了基础设施支持。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [5] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune框架通过可控数据生成管道和监督微调，实现高效的单次知识图谱构建，性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有Text2KG方法依赖迭代式LLM提示，计算成本高且容易忽略文本中分布的复杂关系，需要更高效的解决方案

Method: 结合可控数据生成管道（从大型知识库提取子图、噪声过滤、LLM生成文本描述）和监督微调，训练轻量模型进行单次KG构建

Result: 在CE12k数据集上超越大型非微调LLM和SOTA Text2KG方法，在CrossEval-1200测试集上展现更强的跨数据集泛化能力

Conclusion: 现实高质量训练数据对推进高效高性能Text2KG系统至关重要，InvertiTune框架为此提供了有效解决方案

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [6] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 提出一个用于检测和解析政治文本中解释的框架，通过训练轻量级因果语言模型提取因果主张，形成结构化数据集供下游分析


<details>
  <summary>Details</summary>
Motivation: 解释是理解政治世界的基本要素，但政治科学中对解释的系统分析不足，现有方法分散且常针对特定问题

Method: 训练轻量级因果语言模型，从政治文本中提取因果主张，返回结构化的原因-结果对数据集

Result: 展示了如何大规模研究因果解释，方法具有适度的标注需求、良好的泛化能力和相对于人工编码的准确性

Conclusion: 提出了一个系统分析政治文本中解释的可行框架，为大规模研究政治因果解释提供了工具

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [7] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: RMFT是一种新的隐私保护微调技术，通过随机掩码减少LLM对训练数据中PII的记忆，相比基线减少80%以上的提取率，同时性能影响很小


<details>
  <summary>Details</summary>
Motivation: 当前LLM倾向于记忆训练数据中的个人身份信息，带来严重的安全和隐私风险，需要开发有效的隐私保护技术

Method: 提出随机掩码微调技术，在微调过程中随机掩码部分输入，减少模型对特定信息的记忆；同时提出MaxTER评估框架来评估隐私-效用权衡

Result: 在Enron邮件数据集上，RMFT相比基线微调减少了80.81%的总提取率和80.17%的已见提取率，性能仅增加5.73%的困惑度，优于去重方法

Conclusion: RMFT是一种有效的隐私保护微调方法，显著减少PII记忆同时保持模型性能，为LLM隐私保护提供了实用解决方案

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [8] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: LLM辅助的标注流水线用于分析西班牙语-英语和西班牙语-瓜拉尼语双语语料的社会语言学和主题特征，揭示了性别、语言优势和话语功能之间的系统性联系


<details>
  <summary>Details</summary>
Motivation: 传统的社会语言学分析依赖人工标注，成本高且难以扩展到大规模语料库。本研究旨在探索大语言模型是否能够可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式

Method: 使用大语言模型自动标注3,691个语码转换句子的主题、体裁和话语语用功能，整合迈阿密双语语料库的人口统计元数据，并为西班牙语-瓜拉尼语数据集添加新的主题标注

Result: 在迈阿密数据中发现了性别、语言优势和话语功能之间的系统性联系；在巴拉圭文本中发现了正式瓜拉尼语和非正式西班牙语之间的明显双语分工；这些发现用语料库规模的定量证据复制和扩展了早期的互动和社会语言学观察

Conclusion: 大语言模型能够可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，推进了跨语言和低资源双语研究的计算方法

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [9] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: PERCS数据集：针对不同医学知识水平用户（普通人、医学生、非医学研究者、医学专家）的个性化生物医学摘要简化数据集，支持可控摘要生成研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源通常假设单一通用受众，忽视了不同用户群体在医学素养和信息需求上的巨大差异，需要针对特定受众的个性化简化方法。

Method: 创建PERCS数据集，包含生物医学摘要及其针对四个不同医学知识水平用户的个性化摘要：普通人、医学生、非医学研究者、医学专家。所有摘要由医生根据详细错误分类法审核事实准确性和用户匹配度。

Result: 技术验证显示不同用户群体的摘要在可读性、词汇选择和内容深度上存在明显差异。使用自动评估指标对四个大语言模型进行基准测试，评估全面性、可读性和忠实度，为未来研究建立基线结果。

Conclusion: PERCS数据集支持个性化医学沟通和可控生物医学摘要生成研究，数据集、标注指南和评估材料已公开，有助于推动针对特定受众的医学信息传播。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [10] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 提出Idea-Gated Transformer架构，通过分离语义规划和语法生成来解决自回归语言模型中的"主题漂移"问题，使用"概念向量"实时门控词汇选择，提升生成的主题一致性。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型基于下一个词预测训练，容易产生"主题漂移"问题，即生成内容会逐渐偏离初始提示，这是因为模型过于依赖局部关联而非全局规划。虽然增大模型规模可以缓解这个问题，但NTP目标的根本短视性依然存在。

Method: 提出Idea-Gated Transformer架构，引入辅助的"Idea Head"来预测未来上下文窗口的词袋分布，生成潜在的"概念向量"。该向量通过可微分的门控机制主动门控主要词汇生成，抑制语义不相关的标记，实时修剪搜索空间。

Result: 在WikiText-103上的实验表明，Idea-Gated模型在验证困惑度上与标准GPT-2基线相当，但在领域保持性方面显著更优。定性和定量分析显示，门控机制成功将生成锁定在特定语义簇（如金融、科学）中，并能抵抗关联漂移。

Conclusion: Idea-Gated Transformer提供了一种参数高效的方法来实现更可控的语言建模，通过分离语义规划和语法生成，有效解决了自回归语言模型中的主题漂移问题，为更可控的文本生成提供了新途径。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [11] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: HBLR框架通过置信感知符号翻译和假设驱动后向推理，解决了传统前向推理中的冗余路径、幻觉步骤和语义漂移问题，在多个推理基准上实现了更高的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要依赖前向推理范式，从前提逐步生成结论，但这种方法存在推理路径冗余、幻觉步骤和语义漂移问题，导致推理效率低下且不可靠。需要一种更接近人类逻辑思维方式的推理框架。

Method: 提出假设驱动后向逻辑推理框架：1) 置信感知符号翻译：仅将高置信度文本转换为一阶逻辑等形式，不确定内容保留自然语言，并通过翻译反射模块确保语义保真度；2) 假设驱动后向推理：模拟人类演绎思维，假设结论为真并递归验证其前提，通过推理反射模块识别和修正错误推理步骤。

Result: 在五个推理基准上的广泛实验表明，HBLR在准确性和效率方面均持续优于强基线方法。

Conclusion: HBLR框架通过结合符号翻译和假设驱动后向推理，提供了一种更高效可靠的逻辑推理方法，能够更好地模拟人类逻辑思维过程，为自然语言理解中的逻辑推理挑战提供了有效解决方案。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [12] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出高阶注意力网络(Hon)，通过递归框架增强表示能力，解决标准注意力机制的低秩瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的一阶注意力机制存在低秩瓶颈，难以在单层内捕捉复杂、多跳的关系

Method: 使用递归框架动态精炼Query和Key表示，通过嵌套自注意力机制让token在最终注意力计算前聚合全局上下文并建模高阶相关性，采用参数高效的权重共享策略

Result: 理论分析表明该方法打破了标准注意力的线性瓶颈，实证结果显示Hon在多个基准测试中优于标准Transformer

Conclusion: 高阶注意力网络通过递归框架有效增强了表示能力，解决了标准注意力的局限性，同时保持了参数效率

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [13] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 收集了11.5小时的Portal 2合作模式语音对话语料库，包含24.5K话语，分析复杂空间指代、澄清修复等独特语言现象，公开了多模态数据。


<details>
  <summary>Details</summary>
Motivation: 合作视频游戏中的语言数据包含丰富的协调、沟通和不确定性推理，现有闲聊或任务导向语料库很少包含复杂空间指代、澄清修复等语言现象，需要专门语料库来研究复杂情境下的协作问题解决语言。

Method: 收集Portal 2合作模式中11.5小时的人类语音对话，包含24.5K话语，分析玩家语言和行为，识别独特语言现象，并公开包含视频、音频、转录、游戏状态数据以及手动和自动标注的多模态语料库。

Result: 创建了Portal对话语料库，识别出复杂空间指代、澄清修复、临时约定形成等现有语料库中罕见的语言现象，为研究复杂情境协作问题解决中的语言使用提供了宝贵资源。

Conclusion: 合作视频游戏是研究复杂情境下协调沟通语言的丰富数据源，公开的Portal对话语料库支持未来对复杂协作问题解决场景中语言使用的分析。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [14] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: Dual LoRA通过将低秩矩阵分为幅度组和方向组，引入ReLU和符号函数来改进原始LoRA，在多种NLP任务上优于LoRA及其变体。


<details>
  <summary>Details</summary>
Motivation: LoRA作为参数高效微调方法虽然流行，但由于其低秩假设，训练出的模型性能往往不理想。需要改进LoRA以更好地模拟基于梯度的全参数微调过程。

Method: 提出Dual LoRA方法，将低秩矩阵分为两组：幅度组控制参数是否更新及更新幅度（使用ReLU函数），方向组决定参数更新方向（使用符号函数）。这种方法更好地模拟了基于梯度优化的全参数微调过程。

Result: 在GPT-2、RoBERTa、DeBERTa和LLaMA-1/2/3等基准模型上，对自然语言生成、理解和常识推理任务进行了广泛实验。结果显示，在相同可训练参数数量下，Dual LoRA始终优于LoRA及其最先进的变体。

Conclusion: Dual LoRA通过引入幅度和方向分离的归纳偏置，有效改进了LoRA的性能，为参数高效微调提供了更优的解决方案。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [15] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: 提出PretrainZero强化主动学习框架，将RL从领域特定后训练扩展到通用预训练，通过主动识别语料库中的合理内容进行自我监督学习，显著提升基础模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的大思考模型虽然在特定领域（如软件和数学）表现出专家级能力，但严重依赖可验证奖励，限制了通用推理能力的扩展。需要打破验证数据壁垒，实现从领域特定后训练到通用预训练的扩展。

Method: 提出PretrainZero框架，包含三个核心特征：1）主动预训练：学习统一推理策略，主动识别语料库中的合理且信息丰富的内容；2）自我监督学习：无需可验证标签或预训练奖励模型，直接在通用语料库上使用RL预训练推理器；3）验证缩放：通过处理日益具有挑战性的掩码跨度来增强推理能力。

Result: 在强化预训练中，PretrainZero将Qwen3-4B-Base在MMLU-Pro、SuperGPQA和数学平均基准上的性能分别提升了8.43、5.96和10.60分。预训练模型还可作为下游RLVR任务的推理基础模型。

Conclusion: PretrainZero成功将强化学习从领域特定后训练扩展到通用预训练，通过主动学习和自我监督机制显著提升了基础模型的通用推理能力，为打破验证数据壁垒提供了有效解决方案。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [16] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: Top-k注意力机制在解码和训练阶段的有效性研究：验证了Top-k解码在保持性能的同时显著降低计算成本，并通过Top-k注意力训练策略进一步提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文建模中日益普及，但其推理计算成本已成为阻碍智能体和多模态应用发展的关键瓶颈，需要探索高效的注意力机制。

Method: 研究Top-k注意力机制在解码和训练阶段的有效性：1）验证精确Top-k解码，仅保留与查询相似度最高的关键键作为上下文窗口；2）探索原生Top-k注意力训练策略；3）研究近似Top-k算法精度对下游任务的影响；4）从熵的角度提供理论解释。

Result: 1）Top-k解码在HELMET和LongBench v2等下游任务上达到或超越全注意力性能；2）训练与推理一致的Top-k注意力操作能进一步释放Top-k解码潜力；3）下游任务性能与近似精度正相关；4）Top-k注意力SFT模型在下游任务中表现出明显的熵减现象。

Conclusion: Top-k注意力机制能有效降低大语言模型推理计算成本，通过精确Top-k解码和训练策略的协同优化，可在保持性能的同时显著提升效率，低熵状态更适合Top-k解码。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [17] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: LLMs在摘要生成中的推理能力效果有限，存在质量与忠实度的权衡，过度推理反而损害事实一致性


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在数学和代码生成等分析任务中表现出色，但其在抽象摘要生成中的有效性尚未得到充分验证，需要系统研究推理策略对摘要质量和忠实度的影响

Method: 将通用推理策略适配到摘要领域，对8种推理策略和3个大型推理模型在8个多样化数据集上进行大规模比较研究，评估摘要质量和忠实度

Result: 推理并非通用解决方案，其效果高度依赖具体策略和上下文；存在摘要质量与事实忠实度的权衡：显式推理策略提高流畅性但损害事实基础，隐式推理则相反；增加LRM的内部推理预算不会改善甚至可能损害事实一致性

Conclusion: 有效的摘要生成需要忠实的压缩而非创造性的过度思考，推理在摘要任务中的应用需要谨慎考虑策略选择和上下文因素

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [18] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 本文提出了INDI-PROP数据集，用于印度新闻媒体中的宣传分析，包含三个层次标注：意识形态偏见、细粒度叙事框架和说服技巧，并开发了两种GPT-4o-mini引导的多跳推理框架FANTA和TPTC进行分类。


<details>
  <summary>Details</summary>
Motivation: 叙事是宣传的认知和情感支架，将孤立的说服技巧组织成连贯的故事。现有研究缺乏针对意识形态基础的细粒度叙事分类，特别是在印度新闻媒体这样的多语言、多文化背景下。需要开发能够分析偏见、叙事框架和说服技巧的综合性方法。

Method: 1. 创建INDI-PROP数据集：包含1,266篇关于CAA和农民抗议两个极化社会政治事件的印度新闻文章，进行三个层次标注：意识形态偏见（亲政府、亲反对派、中立）、事件特定的细粒度叙事框架、说服技巧。
2. 提出两种GPT-4o-mini引导的多跳推理框架：FANTA通过整合信息提取和上下文框架进行分层推理；TPTC采用两阶段方法系统分解说服线索。

Result: 评估显示，FANTA和TPTC框架在偏见分类、叙事分类和说服技巧识别任务上均显著优于基线模型。INDI-PROP数据集为意识形态基础的宣传分析提供了首个细粒度多级标注资源。

Conclusion: 本文通过创建INDI-PROP数据集和开发FANTA、TPTC框架，为意识形态宣传分析提供了细粒度叙事分类的新方法。这些方法在印度新闻媒体的偏见、叙事和说服技巧分析中表现出色，为理解宣传的认知情感机制提供了工具。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [19] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 提出一个可解释的事实一致性评估框架，通过分解文本为原子事实，引入灵活的、无模式的方法论，包含加权度量和复杂度控制机制


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中取得显著进展，但容易生成错误或误导性但看似合理的论点（幻觉问题）。这在临床等高风险领域尤为严重，现有评估指标无法充分评估事实一致性且缺乏可解释性，难以诊断和缓解错误

Method: 提出可解释的事实一致性评估框架，将文本分解为原子事实，采用灵活的无模式方法，引入加权度量而非绝对度量，并提出控制复杂领域评估复杂度的机制

Result: 在流行的通用和临床数据集上进行基准测试，并发布代码以支持未来研究中的事实感知模型训练

Conclusion: 该框架解决了现有评估指标在事实一致性评估方面的不足，提供了更可解释和灵活的方法，特别适用于高风险领域如临床应用

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [20] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 意大利首次大规模调查显示：生成式AI在意大利广泛采用，正取代其他技术成为主要信息来源，但存在显著的数字素养不足和性别鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI聊天机器人具有社会潜力，但由于采用不均衡和对其局限性认识不足，可能加剧数字鸿沟。需要实证研究了解意大利的AI采用模式、使用习惯和数字素养状况。

Method: 基于新收集的1,906名意大利语成年人的调查数据，进行首次全面的生成式AI采用、使用模式和素养的实证映射研究。

Result: 1. 生成式AI在工作和个人用途中广泛采用，包括情感支持和医疗建议等敏感任务；2. 正取代其他技术成为主要信息来源；3. 用户数字素养低但仍在广泛使用，难以识别错误或虚假信息；4. 存在显著的性别鸿沟，女性采用率仅为男性一半，使用频率更低，尤其在年长群体中更明显；5. 数字素养是采用的关键预测因素，但只能部分解释性别差异。

Conclusion: 生成式AI的多用途使用需要有针对性的教育举措，并进一步调查素养无法完全解释的公平参与障碍，以应对数字鸿沟风险。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [21] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 该研究提出了Hydro-SE Bench基准测试，包含4000道选择题，用于评估大语言模型在水科学与工程领域的知识与应用能力。


<details>
  <summary>Details</summary>
Motivation: 水科学与工程是保障人类供水、发电和防灾的关键领域，需要多学科专家协作决策。随着大语言模型的发展，其在Hydro-SE领域的应用潜力日益受到关注，但现有模型在该领域的知识和应用能力尚未得到充分评估。

Method: 构建Hydro-SE Bench评估基准，包含4000道选择题，涵盖9个子领域，评估模型在基本概念知识、工程应用能力、推理计算能力三个方面的表现。

Result: 商业LLM准确率在0.74-0.80之间，小参数LLM在0.41-0.68之间。模型在自然科学相关子领域表现良好，但在行业标准、水工结构等专业领域表现不佳。模型规模主要提升推理计算能力，但在实际工程应用方面仍有很大提升空间。

Conclusion: 该研究揭示了LLM在Hydro-SE任务中的优势和不足，为模型开发者提供了明确的训练目标，为Hydro-SE研究者提供了应用LLM的实用指导。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [22] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 研究发现大语言模型中不同句法现象（特别是语法一致性）会激活重叠的神经元单元，表明语法一致性在LLM表征空间中构成有意义的类别，且结构相似的语言共享更多一致性处理单元。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能够可靠区分语法正确与错误的句子，但语法知识如何在模型内部表征仍然是一个开放问题。研究者希望探究不同句法现象在LLM中是共享还是使用不同的处理组件。

Method: 采用受认知神经科学启发的功能定位方法，在7个开源模型中识别对67个英语句法现象最敏感的神经元单元。通过跨语言分析（英语、俄语、中文）和57种语言的跨语言比较，研究语法一致性的神经表征。

Result: 不同语法一致性类型（如主谓一致、照应一致、限定词-名词一致）会激活重叠的神经元单元集合，表明一致性构成LLM中有意义的功能类别。这一模式在英语、俄语和中文中均成立，且结构更相似的语言在主谓一致性上共享更多神经元单元。

Conclusion: 句法一致性——作为句法依赖关系的关键标记——在大语言模型的表征空间中构成有意义的类别，揭示了LLM内部句法知识的组织方式。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [23] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit：一个使用语言技术评估AI导师教学质量的工具套件，包含演示评估、模型检查和数据可视化功能


<details>
  <summary>Details</summary>
Motivation: 需要评估AI导师的教学质量，为教育利益相关者和ACL社区提供支持学习和收集用户反馈的工具

Method: 开发基于语言技术的应用程序，包含教学质量评估、软件演示、模型检查、数据可视化等功能模块

Result: 创建了AITutor-EvalKit工具套件，支持AI导师教学质量评估，可用于演示、评估、模型检查和数据可视化

Conclusion: 该工具为教育利益相关者和ACL社区提供了评估AI导师教学质量的实用解决方案，支持学习和用户反馈收集

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [24] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO：一种非破坏性对齐框架，通过冲突感知的动态KL约束和可学习的时间注意力偏置，解决长上下文对话中的状态惯性问题，在保持零样本泛化能力的同时实现SOTA胜率。


<details>
  <summary>Details</summary>
Motivation: 长上下文对话系统存在"状态惯性"问题，即静态约束阻碍模型解决用户意图演变与历史上下文之间的冲突，限制了对话系统的动态适应能力。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL约束和可学习的时间注意力偏置，通过精确的注意力调节而非破坏性权重更新来缓解状态惯性。

Result: 在Multi-Session Chat数据集上，DZ-TDPO在Phi-3.5模型上达到86.2%的胜率，Qwen2.5-7B模型达到99.4%的胜率，同时保持零样本泛化能力，MMLU能力不受影响。

Conclusion: 研究表明状态惯性可以通过精确的注意力调节而非破坏性权重更新来缓解，揭示了"容量-稳定性权衡"现象，为长上下文对话系统的对齐提供了新思路。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [25] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: AR-Med是一个用于医疗搜索的自动相关性评估框架，通过检索增强的LLM推理和知识蒸馏技术，在在线医疗平台上实现了高精度和可扩展部署。


<details>
  <summary>Details</summary>
Motivation: 在线医疗平台的搜索准确性对用户安全和服务效果至关重要。传统方法难以理解复杂细微的用户查询，而LLMs虽然具有强大的语义理解能力，但在医疗领域部署面临事实幻觉、专业知识缺口和高运营成本等挑战。

Method: 1. 采用检索增强方法，将LLM推理建立在已验证的医学知识基础上；2. 设计实用的知识蒸馏方案，将大型教师模型压缩为紧凑而强大的学生模型；3. 开发LocalQSMed多专家标注基准，指导模型迭代并确保离线与在线性能的一致性。

Result: AR-Med实现了超过93%的离线准确率，比原始在线系统提高了24%的绝对改进，并在在线相关性和用户满意度方面带来了显著提升。

Conclusion: AR-Med为在现实世界医疗应用中开发可信赖的LLM驱动系统提供了一个实用且可扩展的蓝图，成功解决了医疗搜索中的准确性和可靠性问题。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [26] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: ESPO提出了一种针对扩散大语言模型的序列级强化学习框架，解决了传统token级RL方法不适用于dLLMs的根本问题


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法适用于自回归语言模型，但无法直接应用于扩散大语言模型，因为dLLMs通过迭代去噪步骤生成序列，缺乏token级条件概率分解

Method: 提出ELBO-based Sequence-level Policy Optimization (ESPO)，将整个序列生成视为单一动作，使用ELBO作为可处理的序列级似然代理，包含token级重要性比率归一化和鲁棒的KL散度估计

Result: 在数学推理、编程和规划任务上显著优于token级基线方法，在Countdown任务上提升20-40分，在数学和编程基准上保持稳定增益

Conclusion: ESPO建立了序列级优化作为dLLMs中强化学习的原理性和经验有效的范式

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [27] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: 提出一种名为Doublespeak的上下文表示劫持攻击，通过将有害关键词替换为良性标记，使模型内部将良性词解释为有害语义，从而绕过安全对齐机制。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的安全对齐策略存在漏洞，攻击者可能通过操纵模型的内部表示来绕过安全防护。研究旨在揭示这种新的攻击面，展示现有对齐策略在表示层面的不足。

Method: 采用上下文表示劫持攻击：1）将有害关键词（如"bomb"）系统性地替换为良性标记（如"carrot"）；2）在多个上下文示例中进行这种替换；3）提供有害请求的前缀。该方法无需优化，通过语义覆盖使良性标记的内部表示收敛到有害语义。

Result: 攻击成功率显著：在Llama-3.3-70B-Instruct上达到74%的攻击成功率（仅需单句上下文覆盖）。攻击具有广泛可转移性，适用于闭源和开源系统。使用可解释性工具显示语义覆盖逐层发生，早期层的良性含义在后期层收敛为有害语义。

Conclusion: Doublespeak攻击揭示了LLM潜在空间中的新攻击面，表明当前基于表层文本的对齐策略不足。安全对齐需要在表示层面进行操作，而不仅仅是表层文本过滤。这为未来更鲁棒的安全对齐方法提供了重要启示。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [28] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 将DoLa对比解码方法首次应用于T5/FLAN-T5编码器-解码器架构，评估其对指令遵循能力的影响，发现对某些任务类型有改进但对其他任务有损害


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法（如DoLa）仅在解码器架构中实现并主要研究其对事实性的改进，需要探索在编码器-解码器架构中的应用及其对指令遵循能力的影响

Method: 将DoLa方法适配到T5和FLAN-T5模型家族，通过层间对比解码策略，并对FLAN-T5模型进行逐层logit演化分析以量化DoLa对token输出概率的影响

Result: DoLa在某些任务类别中提高了文本生成的忠实度，但在其他任务中产生了负面影响；通过逐层分析揭示了DoLa对token输出概率的具体影响机制

Conclusion: 这是首次在编码器-解码器架构中实现对比解码策略的研究，为理解DoLa在不同任务类型中的异质性效果提供了量化分析框架

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [29] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 研究提出一个通过提示工程优化大语言模型在心理学文本分类任务中性能的实证框架，发现构造定义、任务框架和示例对性能影响最大，推荐结合人工和自动生成提示并基于训练集表现进行选择。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本分类中表现良好，但其输出严重依赖提示的措辞。现有研究较少关注分类任务，特别是在心理学等专业领域，这些领域的构造具有精确的理论定义，可能未在预训练数据中充分体现。需要系统方法来优化LLM在识别文本中理论构造时的性能。

Method: 提出一个实证框架，实验评估五种提示策略：代码本引导的经验提示选择、自动提示工程、角色提示、思维链推理和解释性提示，结合零样本和少样本分类。在三个构造和两个模型上进行测试，基于专家判断评估分类结果。

Result: 发现角色、思维链和解释并不能完全解决措辞不当提示带来的性能损失。最有影响力的提示特征是构造定义、任务框架，以及较小程度上的示例。最符合专家判断的分类结果来自结合代码本引导经验提示选择和自动提示工程的少样本提示。

Conclusion: 建议研究人员生成和评估尽可能多的提示变体（人工制作、自动生成或两者结合），基于训练集的实证表现选择提示和示例，并在保留集上验证最终方法。这为需要与专家判断对齐的场景提供了实用、系统和理论驱动的方法来优化LLM提示。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [30] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 该论文提出通过将医学共识指南转化为可训练的语言规则，微调LLMs以实现符合医学共识的推理和预测，在脓毒症预测任务中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前医学早期预测的机器学习方法过于关注预测准确性，忽视了可解释性和对医学共识的遵循，这限制了临床医生的信任和实际应用。

Method: 将医学共识指南（如Sepsis-3定义）转化为可训练的语言规则，通过电子病历数据实例化这些规则，用于微调LLMs学习共识规则及其例外情况，并采用多模态方法整合时间序列预测模型。

Result: 微调后的小模型在推理正确性和预测准确性上显著优于仅使用一次性学习的大型LLMs，在未见患者数据上几乎达到完美的推导正确性，时间序列预测的整合进一步提升了性能。

Conclusion: 通过将医学共识指南转化为可训练的语言规则来微调LLMs，能够实现符合医学共识的推理和预测，解决了早期预测中的可解释性和信任问题，而主要瓶颈在于对未来稀疏不规则临床变量的预测。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [31] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV通过融合底层和中层KV缓存来减少50%内存占用，同时保持甚至提升模型性能


<details>
  <summary>Details</summary>
Motivation: Transformer解码器的KV缓存内存消耗在长序列中变得不可承受，现有的跨层KV缓存共享方法性能不如GQA等层内方法，需要找到更有效的KV缓存压缩方案

Method: 分析顶层KV信息流发现：值主要来自底层，键来自底层和中层。提出FusedKV，顶层KV缓存是底层和中层最有信息量的KV的可学习融合，直接在RoPE后的键上操作。还提出FusedKV-Lite，顶层KV缓存直接来自底层值和中层键

Result: 在332M到4B参数的LLM上，方法减少50%缓存内存，同时获得比标准Transformer解码器更低的验证困惑度

Conclusion: FusedKV是一种内存高效、高性能的架构替代方案，通过智能融合不同层的KV缓存信息，在显著减少内存占用的同时保持甚至提升模型性能

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [32] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 语言模型应捕捉语言多样性而非仅依赖标准化文本，通过构建包含标准、社交媒体和历史语料的巴斯克语语料库，训练BERnaT模型，结果显示结合多样语料的模型在所有任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型依赖大规模文本语料库，但质量过滤过程可能无意中排除非标准语言变体，降低模型鲁棒性并强化表征偏见。需要构建能捕捉语言全谱系（方言、历史、非正式等）的模型。

Method: 针对巴斯克语（形态丰富、资源稀缺），构建包含标准、社交媒体和历史来源的新语料库，预训练BERnaT系列编码器模型（标准、多样、组合三种配置），并提出将NLU任务分为标准和多样子集的评估框架。

Result: 在标准和多样数据上训练的模型始终优于仅使用标准语料库的模型，在所有任务类型上都有提升，且不影响标准基准准确性。

Conclusion: 语言多样性对于构建包容性、可泛化的语言模型至关重要，结合多样语料的训练能提高模型性能而不损害标准任务表现。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [33] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: BRAND数据集用于评估多语言模型在宗教敏感话题上的偏见，发现模型在英语中表现优于孟加拉语，且对伊斯兰教存在系统性偏见


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在宗教等敏感话题上存在偏见检测和分类的挑战，特别是多语言模型经常误传宗教信息，在宗教语境中准确性不足，需要专门的数据集来评估和改进

Method: 引入BRAND数据集，聚焦南亚四大宗教（佛教、基督教、印度教、伊斯兰教），包含2400多个条目，使用英语和孟加拉语的三种不同提示类型进行评估

Result: 模型在英语中的表现优于孟加拉语，即使回答宗教中立问题时也持续显示对伊斯兰教的偏见，表明多语言模型在不同语言中询问相似问题时存在持续偏见

Conclusion: 多语言模型在宗教敏感话题上存在显著偏见，特别是在不同语言环境下，这些发现与HCI中宗教和灵性相关的更广泛问题相关，需要进一步改进模型公平性

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [34] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 该研究采用两阶段方法（持续预训练+监督微调）将Qwen2.5-3B模型适配到藏语，显著降低了困惑度并大幅提升了汉藏翻译质量，同时通过层分析揭示了适配机制主要发生在嵌入层和输出头。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在低资源语言（如藏语）上的适配面临数据稀缺和跨语言漂移的挑战，需要探索有效的适配方法。

Method: 采用两阶段适配：1) 持续预训练建立藏语语言基础；2) 监督微调进行任务和翻译专门化。并对Qwen3-4B的435层进行层分析。

Result: 困惑度从2.98降至1.54；汉藏翻译BLEU从0.046提升至0.261，chrF从2.2提升至6.6。层分析显示适配主要集中在嵌入层和输出头，中后期MLP投影编码领域特定转换。

Conclusion: 持续预训练构建藏语语义流形，监督微调以最小表示破坏实现任务对齐。该研究首次量化探索了藏语适配动态，为低资源语言适配提供了可复现框架。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [35] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出两种tokenizer适应方法：继续BPE训练用于词汇扩展，以及基于叶子的词汇剪枝，以提高tokenizer在新领域或语言中的效率。


<details>
  <summary>Details</summary>
Motivation: 将预训练语言模型迁移到新领域或语言时，tokenizer适应很重要。现有词汇扩展方法通常在新数据上训练新tokenizer并添加不重叠的token，但这会导致许多token无法访问或从未使用。

Method: 提出两种互补方法：1) 继续BPE训练：通过在新增数据上继续BPE合并学习过程来适应预训练tokenizer；2) 基于叶子的词汇剪枝：移除冗余token同时保持模型质量。

Result: 在多种语言和模型家族上的实验表明，继续BPE训练提高了tokenization效率，并更好地利用了新增词汇。词汇剪枝方法能有效移除冗余token。

Conclusion: 这两种方法为受控词汇修改提供了实用工具，已作为开源包发布，能有效改善tokenizer在新领域或语言中的适应效果。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [36] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe：针对增强型大语言模型推理服务的高效推理框架，通过两阶段自适应请求调度和动态令牌批处理，显著提升有效吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 随着增强型大语言模型在Web应用中日益普及，提升推理服务效率和优化服务级别目标对用户体验至关重要。现有系统面临两大挑战：1）先到先服务调度导致严重的队头阻塞，使许多请求的排队延迟超出SLO；2）静态批处理令牌限制无法适应波动负载和硬件条件，两者都降低了有效吞吐量和服务质量。

Method: AugServe采用两阶段自适应请求调度策略：第一阶段结合增强型LLM请求的推理特征优化调度决策顺序；第二阶段利用运行时信息持续优化决策，适应请求特征和系统能力。此外，AugServe根据硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验结果显示，AugServe相比vLLM和InferCept实现了4.7-33.1倍和3.3-13.2倍的有效吞吐量提升，同时将首令牌时间分别降低了96.3%和95.0%。

Conclusion: AugServe通过创新的自适应调度和动态批处理机制，有效解决了增强型LLM推理服务的效率瓶颈，显著提升了服务质量和用户体验。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [37] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个24亿参数的多语言视觉语言模型，在2B规模的开源VLM中实现了最先进的多语言视觉问答性能


<details>
  <summary>Details</summary>
Motivation: 开发一个在2B参数规模下具有卓越多语言视觉问答能力的开源视觉语言模型，同时保持有竞争力的纯文本性能

Method: 结合SigLIP2视觉编码器和Qwen3语言主干，通过注意力池化连接器实现任意分辨率图像的高效token处理

Result: 在标准VQA基准测试和多语言评估中，Jina-VLM超越了同类可比模型，同时保持了有竞争力的纯文本性能

Conclusion: Jina-VLM展示了通过精心设计的架构组合，可以在2B参数规模下实现多语言视觉问答的领先性能

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [38] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory是一种在强化学习前通过监督微调让模型学习认知技能的方法，通过重新排列模型自身输出来创建训练数据，帮助模型在强化学习后更好地泛化到更难任务


<details>
  <summary>Details</summary>
Motivation: 如何让模型学习基础模型不具备的认知技能（如验证答案、回溯、尝试替代方法等），而不是依赖从更强模型的蒸馏

Method: 在强化学习前进行监督微调，使用模型自身样本重新排列来创建"银色"SFT轨迹，这些轨迹可能不完美但能有效引导模型在强化学习中获取技能

Result: 1) SkillFactory SFT初始化帮助模型在强化学习后泛化到更难任务变体；2) 模型确实使用了认知技能；3) SkillFactory强化学习模型在域外任务上比基础模型更稳健

Conclusion: 强化学习前学习的归纳偏差有助于模型学习稳健的认知技能使用，SkillFactory方法有效提升了模型在复杂推理任务中的表现

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


### [39] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: MAPS框架通过结合思维链、自我反思和自动提示技术，采用迭代优化方法提升大语言模型的多步数学推理能力，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在问题解决能力上有所提升，但在处理复杂的多步推理任务时仍然存在困难。传统静态提示方法无法有效应对这类挑战，需要更智能的迭代优化方法。

Method: 提出MAPS框架，整合思维链、自我反思和自动提示技术。采用迭代优化流程：首先生成思维链解决方案，检测错误后通过自适应自我反思机制分析错误并生成定制化提示，引导模型修正推理过程。

Result: 在四个基准测试和多个大语言模型上的实验表明，MAPS显著优于标准思维链方法，与推理优化模型达到竞争性结果。通用大语言模型使用MAPS后能达到接近专用推理模型的性能水平。

Conclusion: MAPS框架有效提升了大语言模型的多步数学推理能力，通过策略性限制反思深度平衡了准确性与计算成本之间的权衡，为复杂推理任务提供了实用的解决方案。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [40] [Game-Theoretic Learning-Based Mitigation of Insider Threats](https://arxiv.org/abs/2512.03222)
*Gehui Xu,Kaiwen Chen,Thomas Parisini,Andreas A. Malikopoulos*

Main category: math.OC

TL;DR: 提出一个识别和缓解合作控制系统中内部威胁的框架，通过在线间接双重自适应控制方法同时推断内部人员策略并抵消其负面影响。


<details>
  <summary>Details</summary>
Motivation: 内部人员威胁会严重破坏合作系统：隐蔽的偏离可能降低集体性能、危及任务成功并损害操作安全。现有方法难以有效检测和应对这种隐蔽的对抗行为。

Method: 采用博弈论框架，将内部人员的隐藏意图参数化，将威胁识别转化为参数估计问题。使用在线间接双重自适应控制方法，同时推断内部人员控制策略并抵消其负面影响，通过注入适当设计的探测信号。

Result: 仿真结果验证了所提出的识别-缓解框架的有效性，展示了即使在存在隐蔽对抗行为的情况下也能保持团队性能的能力。缓解策略渐近地恢复了名义最优控制律。

Conclusion: 该框架为合作控制系统中的内部威胁提供了有效的识别和缓解解决方案，能够保护团队性能免受隐蔽对抗行为的影响，具有重要的实际应用价值。

Abstract: An insider is defined as a team member who covertly deviates from the team's optimal collaborative control strategy in pursuit of a private objective, while maintaining an outward appearance of cooperation. Such insider threats can severely undermine cooperative systems: subtle deviations may degrade collective performance, jeopardize mission success, and compromise operational safety. This paper presents a comprehensive framework for identifying and mitigating insider threats in cooperative control settings. We introduce an insider-aware, game-theoretic formulation in which the insider's hidden intention is parameterized, allowing the threat identification task to be reformulated as a parameter estimation problem. To address this challenge, we employ an online indirect dual adaptive control approach that simultaneously infers the insider's control strategy and counteracts its negative influence. By injecting properly designed probing signals, the resulting mitigation policy asymptotically recovers the nominal optimal control law - one that would be achieved under full knowledge of the insider's objective. Simulation results validate the effectiveness of the proposed identification-mitigation framework and illustrate its capability to preserve team performance even in the presence of covert adversarial behavior.

</details>


### [41] [Theoretical and numerical comparison of seven single-level reformulations for bilevel programs](https://arxiv.org/abs/2512.03376)
*Yu-Wei Li,Gui-Hua Lin,Xide Zhu*

Main category: math.OC

TL;DR: 该论文研究双层规划问题，通过比较不同单层重构方法（包括新的TWDP/TMDP/eTMDP方法）的数值性能，发现WDP/MDP/TWDP/TMDP重构优于MPCC重构，而eMDP/eTMDP重构表现最差，推翻了"可行域越紧性能越好"的猜想。


<details>
  <summary>Details</summary>
Motivation: 受近期研究中"重构的可行域越紧，数值性能越好"猜想的启发，本文旨在开发具有更紧可行域的新对偶重构方法，并通过系统比较各种重构方法的数值性能来验证或反驳这一猜想。

Method: 提出了三种新的对偶重构方法（TWDP/TMDP/eTMDP），设计了带有投影的直接和松弛算法，并在450个随机生成的测试算例上实现这些算法，系统比较了六种对偶重构方法（WDP/MDP/eMDP/TWDP/TMDP/eTMDP）和MPCC重构的性能。

Result: 数值实验表明：1）WDP/MDP/TWDP/TMDP重构始终优于MPCC重构；2）eMDP/eTMDP重构在六种对偶重构中表现最差；3）松弛算法中，WDP/MDP/TWDP/TMDP重构比MPCC重构好3-5倍，eMDP/eTMDP重构比MPCC重构好2倍；4）推翻了"可行域越紧性能越好"的猜想。

Conclusion: 虽然TWDP/TMDP/eTMDP重构具有更紧的可行域，但数值性能并不总是更好，表明可行域的紧致性不是决定重构方法数值性能的唯一因素。WDP/MDP/TWDP/TMDP重构在实际应用中表现最佳，而eMDP/eTMDP重构应谨慎使用。

Abstract: This paper considers a bilevel program. To solve this bilevel program, it is generally necessary to transform it into some single-level optimization problem. One approach is to replace the lower-level program by its KKT conditions to transform the bilevel program as a mathematical program with complementarity constraints (MPCC). Another approach is to apply the lower-level Wolfe/Mond-Weir/extended Mond-Weir duality to transform the bilevel program into some duality-based single-level reformulations, called WDP, MDP, and eMDP respectively in the literature. In this paper, inspired by a conjecture from a recent publication that the tighter feasible region of a reformulation, the better its numerical performance, we present three new duality-based single-level reformulations, called TWDP/TMDP/eTMDP, with tighter feasible regions. Our main goal is to compare all above-mentioned reformulations by designing some direct and relaxation algorithms with projection and implementing these algorithms on 450 test examples generated randomly. Our numerical experiments show that, whether overall comparison or pairwise comparison, at least in our tests, the WDP/MDP/TWDP/TMDP reformulations were always better than the MPCC reformulation, while the eMDP/eTMDP reformulations were always the worst ones among six duality-based reformulations, which indicates that the above conjecture is incorrect. In particular, for the relaxation algorithms, the WDP/MDP/TWDP/TMDP reformulations performed 3-5 times better than the MPCC reformulation, while the eMDP/eTMDP reformulations performed 2 times better than the MPCC reformulation.

</details>


### [42] [Suboptimal Shrinking Horizon MPC with a Lower Hessian Condition Number from Adjustable Terminal Cost](https://arxiv.org/abs/2512.03410)
*Steven van Leeuwen,Ilya Kolmanovsky*

Main category: math.OC

TL;DR: 提出一种减少收缩时域模型预测控制迭代次数和计算负担的策略，通过动态调整终端成本权重和时域长度，确保在规定步数内到达终端集


<details>
  <summary>Details</summary>
Motivation: 在存在未测量扰动的情况下，收缩时域模型预测控制在引导系统进入规定终端集时通常需要大量迭代和计算负担，需要更高效的策略

Method: 动态调整终端成本权重和时域长度，确保终端集在规定步数内到达，并证明在特定假设下能降低Hessian矩阵条件数从而减少计算量

Result: 提出的策略能有效减少迭代次数和计算负担，通过航天器章动阻尼的实例验证了方法的有效性

Conclusion: 该策略为收缩时域模型预测控制提供了一种计算高效的实现方法，特别适用于存在未测量扰动的控制系统

Abstract: A strategy for reducing the number of iterations and computational burden in shrinking horizon Model Predictive Control (SH-MPC) when steering into a prescribed terminal set despite unmeasured disturbances is proposed. This strategy exploits dynamic adjustment of the terminal cost weight and horizon length while ensuring that the terminal set is reached within a desired number of steps. A lower Hessian condition number which facilitates the computational reduction is proved under assumptions, and an example of spacecraft nutation damping using the proposed approach is reported.

</details>


### [43] [Mean-Square Stability of Continuous-Time Stochastic Model Predictive Control](https://arxiv.org/abs/2512.03516)
*Qi Lü,Bowen Ma,Enrique Zuazua*

Main category: math.OC

TL;DR: 提出一种用于无约束随机微分方程系统的随机模型预测控制框架，在无限时域极限下建立均方指数稳定性，通过线性化近似和延迟状态信息处理非线性随机系统。


<details>
  <summary>Details</summary>
Motivation: 现有随机模型预测控制理论对具有延迟状态信息的随机微分方程系统缺乏严格的稳定性保证，需要建立适用于非线性随机系统的控制框架。

Method: 在每个预测步将非线性随机微分方程在原点处线性化，以采样状态为初始条件求解有限时域随机线性二次最优控制问题，将最优控制应用于原始非线性系统直至下一个采样时刻，形成延迟随机模型预测控制方案。

Result: 对于线性和轻度非线性随机微分方程证明了全局均方指数稳定性；对于强非线性系统，通过停止时间技术和Grönwall型估计建立了局部均方指数稳定性，要求非线性项具有多项式增长而非指数增长。

Conclusion: 首次为具有延迟状态信息的随机微分方程系统提供了严格的均方稳定性保证，推进了随机预测控制的理论基础，区分了随机模型预测控制与确定性对应方法的关键差异。

Abstract: We propose a stochastic model predictive control (SMPC) framework for a broad class of unconstrained controlled stochastic differential equations (SDEs) and establish its mean-square exponential stability in the infinite-horizon limit. At each prediction step of the MPC iteration, the nonlinear controlled SDE is approximated by its linearization at the origin, with the sampled state of the nonlinear system as initial condition, yielding a finite-horizon stochastic linear-quadratic (SLQ) optimal control problem. The resulting optimal control is then applied to the original nonlinear stochastic dynamics until the next sampling instant. This construction leads to a delayed SMPC scheme whose closed-loop behavior is governed by a coupled time-delay SDE system, a setting that has not been analyzed before. We prove global mean-square exponential stability for linear and mildly nonlinear SDEs by exploiting the exponential convergence of the Riccati equation to the algebraic Riccati equation (ARE). For strongly nonlinear SDEs, we establish local mean-square exponential stability by combining exponential Riccati convergence with stopping-time techniques and Grönwall-type estimates. It is observed that, to ensure the desired local stability properties, the nonlinearities of the SDE are allowed to have polynomial growth but not exponential growth, distinguishing SMPC from its deterministic counterpart.
  These results provide the first rigorous mean-square stability guarantees for SMPC of SDE systems with delayed state information, thereby advancing the theoretical foundations of stochastic predictive control.

</details>


### [44] [Market share maximizing strategies of CAV fleet operators may cause chaos in our cities](https://arxiv.org/abs/2512.03524)
*Grzegorz Jamróz,Rafał Kucharski,David Watling*

Main category: math.OC

TL;DR: 研究自动驾驶车辆在个体路由与集体路由之间切换的新型路由博弈，分析车队运营商如何通过市场占有率最大化策略影响交通均衡，发现混合策略可能导致未来城市交通不可预测


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆(CAV)的发展，未来交通将出现个体驾驶(HDV)与集体路由(CAV)并存的混合模式。需要研究在这种新型路由博弈中，车队运营商如何优化市场占有率，以及这对交通均衡和人类驾驶员的影响。

Method: 建立了个性化集体路由的严格数学框架，研究CAV车队用于市场占有率优化的算法。定义了CAV-HDV双层均衡，并推导了CAV营销行为与人类行为特征之间的关联条件。

Result: 车队运营商通常可以通过模仿HDV的选择来实现完全市场占有率均衡。但在更现实的异质人口设置中，市场占有率最大化的车队控制器应使用高度可变的混合策略来吸引或保留客户，这导致HDV面临巨大的不确定性。

Conclusion: 混合市场占有率最大化策略可能导致不可预测的日常驾驶条件，这在未来城市中可能普遍存在。CAV作为强大的群体参与者，可以通过控制车辆在拥堵和非拥堵路线上的分配来影响交通模式，而HDV无法提前获知这些信息，面临巨大不确定性。

Abstract: We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.

</details>


### [45] [Leader-Follower Mean Field LQG Games with Multiplicative Noise](https://arxiv.org/abs/2512.03535)
*Bing-Chang Wang,Huanshui Zhang,Ji-Feng Zhang*

Main category: math.OC

TL;DR: 研究具有乘性噪声的领导者-跟随者平均场线性二次高斯博弈的开环和反馈解，采用直接方法处理非正定权重矩阵，通过变分分析和矩阵最大值原理获得解。


<details>
  <summary>Details</summary>
Motivation: 传统平均场博弈研究通常假设成本函数中的状态和控制权重矩阵为正定，这限制了应用范围。本文旨在解决具有乘性噪声的领导者-跟随者平均场LQG博弈，允许权重矩阵非正定，更符合实际应用需求。

Method: 采用直接方法，通过变分分析和平均场近似获得开环控制解（表示为平均场前向-后向随机微分方程的解），然后应用矩阵最大值原理构建分散化反馈策略。与传统方法不同，推导中出现了交叉项。

Result: 获得了开环和反馈两种解，所有参与者的最优成本分别用两个Riccati方程的解显式表示。推导中出现的交叉项是平均场项存在的结果。

Conclusion: 成功解决了具有乘性噪声和非正定权重矩阵的领导者-跟随者平均场LQG博弈问题，提供了开环和反馈两种解，并给出了最优成本的显式表达式，扩展了传统平均场博弈理论的应用范围。

Abstract: This paper studies open-loop and feedback solutions to leader-follower mean field linear-quadratic-Gaussian games with multiplicative noise by the direct approach. The leader-follower game involves a leader and many followers, where the state and control weight matrices in their costs are not limited to be positive definite. From variational analysis with mean field approximations, we obtain a set of open-loop controls in terms of solutions to mean field forward-backward stochastic differential equations. By applying the matrix maximum principle, a set of decentralized feedback strategies is constructed. Distinct from traditional works, a cross term has appeared in derivation due to the presence of mean field terms. For open-loop and feedback solutions, the corresponding optimal costs of all players are explicitly given in terms of the solutions to two Riccati equations, respectively.

</details>


### [46] [Learning-Based Hierarchical Approach for Fast Mixed-Integer Optimization](https://arxiv.org/abs/2512.03547)
*Stefan Clarke,Bartolomeo Stellato*

Main category: math.OC

TL;DR: 提出分层架构高效求解结构化混合整数规划问题，通过决策聚焦学习和保形预测实现计算时间显著减少同时保持可行性和高质量解


<details>
  <summary>Details</summary>
Motivation: 结构化混合整数规划问题计算成本高，需要高效方法在保持解质量的同时减少计算时间

Method: 分层架构将原问题分解为高层和低层子问题，使用决策聚焦学习技术将其表述为凸优化问题，通过保形预测确保鲁棒性

Result: 在设施选址、背包问题和车辆路径问题上的实验表明，相比最先进求解器，该方法显著减少计算时间同时保持可行性和高解质量

Conclusion: 分层架构结合决策聚焦学习和保形预测为结构化混合整数规划提供了一种高效且鲁棒的求解方法

Abstract: We propose a hierarchical architecture for efficiently computing high-quality solutions to structured mixed-integer programs (MIPs). To reduce computational effort, our approach decouples the original problem into a higher level problem and a lower level problem, both of smaller size. We solve both problems sequentially, where decisions of the higher level problem become parameters of the constraints of the lower level problem. We formulate this learning task as a convex optimization problem using decision-focused learning techniques and solve it by differentiating through the higher and the lower level problems in our architecture. To ensure robustness, we derive out-of-sample performance guarantees using conformal prediction. Numerical experiments in facility location, knapsack problems, and vehicle routing problems demonstrate that our approach significantly reduces computation time while maintaining feasibility and high solution quality compared to state-of-the-art solvers.

</details>


### [47] [Parameters Optimization in Trajectory Planning Using Diffrentiable Convex Programing](https://arxiv.org/abs/2512.03557)
*Ziqi Xu,Lin Cheng,Shengping Gong*

Main category: math.OC

TL;DR: 本文提出了一种可微分的顺序凸规划框架，将可微凸优化与顺序凸规划相结合，实现端到端的参数优化，显著提升了轨迹规划的性能和收敛性。


<details>
  <summary>Details</summary>
Motivation: 顺序凸规划在非凸轨迹规划中表现良好，但其性能对问题参数（包括轨迹变量、算法超参数和物理车辆参数）高度敏感。需要一种能够优化这些参数的方法来提高性能和收敛性。

Method: 提出可微分顺序凸规划框架，通过推导二阶锥规划解对问题数据的一阶灵敏度关系，获得轨迹性能指标对任意参数的精确梯度，并在迭代中传播这些梯度。

Result: 通过三个应用验证：动力着陆的最优终端时间预测、子问题中的信任域惩罚优化、高超声速滑翔飞行器的表面积质量比优化。仿真结果表明该框架能够实现可靠的基于梯度的参数学习，显著改善数值性能、收敛行为和设计效率。

Conclusion: 可微分顺序凸规划框架为航空航天轨迹规划中的车辆设计、任务优化和超参数选择提供了强大而通用的工具。

Abstract: Sequential convex programming has been established as an effective framework for solving nonconvex trajectory planning problems. However, its performance is highly sensitive to problem parameters, including trajectory variables, algorithmic hyperparameters, and physical vehicle parameters. This paper introduces a differentiable sequential convex programming framework that integrates differentiable convex optimization with sequential convex programming to enable end-to-end parameter optimization. By deriving first-order sensitivity relations of second-order cone programming solutions with respect to problem data, exact gradients of trajectory performance metrics with respect to arbitrary parameters are obtained and propagated through iterations. The effectiveness of the proposed framework is validated through three representative applications: optimal terminal-time prediction for powered landing, trust-region penalty optimization in subproblems, and surface-to-mass ratio optimization for hypersonic gliding vehicles. Simulation results show that the proposed framework enables reliable gradient-based parameter learning and significantly improves numerical performance, convergence behavior, and design efficiency. These results indicate that differentiable sequential convex programming framework provides a powerful and general tool for vehicle design, mission optimization, and hyperparameter selection in aerospace trajectory planning.

</details>


### [48] [A hybrid large neighborhood search algorithm for the integrated dial-a-ride problem using electric vehicles](https://arxiv.org/abs/2512.03562)
*Yumeng Fang,Tai-Yu Ma*

Main category: math.OC

TL;DR: 提出一种混合元启发式算法解决电动车辆与固定线路公交系统集成的拨召式出行问题，以最小化运营成本和客户旅行时间，相比现有求解器在2分钟内获得平均23.8%更优解。


<details>
  <summary>Details</summary>
Motivation: 整合需求响应型出行服务与公交系统是缓解交通拥堵和环境影响的有效策略，但现有方法在集成需求响应车辆路径规划、充电操作与固定线路公交系统方面存在挑战。

Method: 开发高效的混合元启发式算法，通过限制最大换乘时间来同步需求响应公交到达与公交发车，解决具有容量限制充电站和部分充电的集成拨召式出行问题。

Result: 算法在10-50个客户和两条公交线路的实例上，相比先进混合整数规划求解器，在约2分钟内获得平均23.8%更优的解质量，优于求解器8小时计算时间限制下的结果。

Conclusion: 集成拨召式出行服务能减少车辆行驶里程，但确保高质量服务时车队规模未必减少；在密集公交网络区域运营集成系统比增加公交频率更有益，为实践提供重要见解。

Abstract: Integrating demand-responsive mobility services with transit systems is recognized as a practical and effective strategy to mitigate their impact on traffic congestion and the environment. This study develops an efficient hybrid metaheuristic to solve the integrated dial-a-ride problem by utilizing electric vehicles to minimize operational costs and customer travel time. Customer transfer inconvenience is restricted by a maximum intermodal transfer time to synchronize demand-responsive buses' arrival and transit departures. The proposed metaheuristic addresses the challenges of integrating demand-responsive vehicle routing and charging operations with fixed-route transit systems with capacitated charging stations and partial recharge. We benchmarked our algorithm against a state-of-the-art mixed-integer programming solver on instances with 10-50 customers and two transit lines. Our approach achieves solutions that are, on average, 23.8% better in solution quality within around 2 minutes, outperforming those obtained by the solver using an 8-hour computational time limit. We evaluate the impact of various system parameters to bridge the gap between theory and practice. The results suggest that, from the operator's perspective, while the integrated dial-a-ride service reduces vehicle kilometers traveled, the used fleet size may not necessarily be reduced when ensuring high-quality service for passengers. Moreover, operating the integrated systems is more beneficial in areas with dense transit networks, compared with increases in transit frequency. The findings provide valuable insights for developing integrated dial-a-ride services in practice.

</details>


### [49] [A Gradient Method for Risk Averse Control of a PDE-SDE Interconnected System](https://arxiv.org/abs/2512.03626)
*Gabriel Velho,Jean Auriol,Riccardo Bonalli*

Main category: math.OC

TL;DR: 提出一种针对线性随机微分方程与线性抛物型热方程耦合系统的风险规避控制器，通过相干风险度量最小化成本，显著降低成本分布的尾部风险


<details>
  <summary>Details</summary>
Motivation: 现有最优控制方法主要关注最小化平均性能，这种风险中性视角可能允许罕见但高度不良的系统行为。需要设计风险规避控制器来考虑此类事件

Method: 将耦合动力学重新表述为随机偏微分方程，通过有限维随机微分方程系统进行近似，并应用基于梯度的方法计算风险规避反馈控制器

Result: 数值模拟显示，所提出的控制器显著降低了成本分布的尾部，在平均性能仅有轻微降低的情况下提高了系统可靠性

Conclusion: 通过相干风险度量设计风险规避控制器能有效处理耦合随机偏微分方程系统中的罕见不良事件，在保持平均性能的同时显著提高系统可靠性

Abstract: In this paper, we design a risk-averse controller for an interconnected system composed of a linear Stochastic Differential Equation (SDE) actuated through a linear parabolic heat equation. These dynamics arise in various applications, such as coupled heat transfer systems and chemical reaction processes that are subject to disturbances. While existing optimal control methods for these systems focus on minimizing average performance, this risk-neutral perspective may allow rare but highly undesirable system behaviors. To account for such events, we instead minimize the cost within a coherent risk measure. Our approach reformulates the coupled dynamics as a stochastic PDE, approximates it by a finite-dimensional SDE system, and applies a gradient-based method to compute a riskaverse feedback controller. Numerical simulations show that the proposed controller substantially reduces the tail of the cost distribution, improving reliability with only a minor reduction in average performance.

</details>


### [50] [A Lyapunov-based MPC for Distributed Multi Agent Systems with Time Delays and Packet Dropouts using Hidden Markov Models](https://arxiv.org/abs/2512.03708)
*Loaie Solyman,Aamir Ahmad,Ayman El-Badawy*

Main category: math.OC

TL;DR: 提出SCHMM LMPC框架，结合半连续隐马尔可夫模型和Lyapunov模型预测控制，用于网络不完美条件下的多智能体分布式最优控制。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在网络不完美条件下（如时延、丢包）的控制面临挑战，传统方法难以同时处理网络诱导误差和拓扑诱导误差。

Method: 结合SCHMM实时捕获随机网络行为，LMPC通过线性矩阵不等式确保一致性和最优性，并引入增量EM算法在线学习SCHMM。

Result: 仿真验证了SCHMM LMPC的有效性，展示了在不同拓扑结构的多智能体系统中的适应能力。

Conclusion: 提出的框架能够同时缓解网络误差和拓扑误差，在保持MPC最优性的同时实现多智能体系统的自适应控制。

Abstract: We propose a SCHMM LMPC framework, integrating Semi Continuous Hidden Markov Models with Lyapunov based Model Predictive Control, for distributed optimal control of multi agent systems under network imperfections. The SCHMM captures the stochastic network behavior in real time, while LMPC ensures consensus and optimality via Linear Matrix Inequalities LMIs. The developed optimal control problem simultaneously minimizes three elements. First, the control effort is reduced to avoid aggressive inputs and second, the network induced error caused by time delays and packet dropouts. Third, the topology-induced error, as the distributed graph restricts agents access to global information. This error is inherent to the communication graph and cannot be addressed through offline learning. To overcome this, the study also introduces the incremental Expectation Maximization EM algorithm, enabling online learning of the SCHMM. This adaptation allows the framework to mitigate both network and topology errors while maintaining optimality through MPC. Simulations validate the effectiveness of the proposed SCHMM LMPC, demonstrating adaptability in multi agent systems with diverse topologies.

</details>


### [51] [Variational Analysis in the Wasserstein Hierarchy](https://arxiv.org/abs/2512.03726)
*Christophe Vauthier*

Main category: math.OC

TL;DR: 本文为高阶Wasserstein空间P^{(n)}_2(M)建立了变分结构理论框架，利用范畴论工具将流形几何结构提升到高阶概率测度空间，并研究了测地线、梯度、可微性和凸性等性质。


<details>
  <summary>Details</summary>
Motivation: 标准最优传输理论为二阶Wasserstein空间P_2(M)提供了变分结构，但缺乏对高阶Wasserstein空间P^{(n)}_2(M)的系统理论框架。本文旨在建立高阶Wasserstein空间的严格变分分析理论。

Method: 利用范畴论工具将黎曼流形M的几何结构提升到高阶Wasserstein空间P^{(n)}_2(M)，建立严格的变分分析框架。通过最优速度规划精确刻画测地线，并引入高阶空间上的梯度概念。

Result: 成功建立了高阶Wasserstein空间的变分结构理论，精确刻画了常速测地线特征，引入了梯度概念，并研究了各类泛函的可微性和凸性性质。

Conclusion: 本文为高阶Wasserstein空间建立了系统的变分分析理论框架，将最优传输理论推广到高阶情形，为相关领域的数学分析提供了理论基础。

Abstract: Let $M$ be a complete connected Riemannian manifold. For $n \geq 0$, we endow the Wasserstein space $P^{(n)}_2(M) = P_2(\ldots P_2(M)\ldots)$, equipped with the Wasserstein distance $W_2$, with a variational structure that generalizes the standard variational structure on $P_2(M)$ provided by optimal transport theory. Our approach makes use of tools from category theory to lift the geometric structure of the manifold $M$ to the spaces $P^{(n)}_2(M)$, in order to establish in a principled way a rigorous theoretical framework for variational analysis on the space $P^{(n)}_2(M)$. In particular, we obtain a precise characterization of the constant speed geodesics of the space $P^{(n)}_2(M)$ in terms of optimal velocity plans. Moreover, we introduce a notion of gradient for functionals defined on $P^{(n)}_2(M)$, which allows us to study the differentiability and the convexity of various types of such functionals.

</details>


### [52] [Strategic Selection of Remanufacturing Business Models: A Consumer Perception Perspective](https://arxiv.org/abs/2512.03732)
*Zhongxin Hu,Christina Imdahl,Zumbul Atan*

Main category: math.OC

TL;DR: 研究OEM最优再制造商业模式，考虑消费者感知对价格和产量决策的影响，分析三种模式（无再制造、OEM内部再制造、第三方授权再制造）的盈利性和环境影响。


<details>
  <summary>Details</summary>
Motivation: 作为循环经济的关键策略，再制造允许OEM通过修复使用过的产品来减少浪费。然而，消费者对再制造产品的感知价值会影响OEM的商业模式选择，需要系统研究不同再制造模式下的最优决策。

Method: 分析三种替代模型：无再制造、OEM内部再制造、第三方授权再制造。扩展授权模型采用两部分关税合同，考虑随机市场规模。通过数值方法优化基于消费者感知的价格和数量决策，并开发分层决策路线图指导模型选择。

Result: 当消费者对再制造产品的感知价值高时，OEM内部再制造最有利可图且减少环境影响，但通常导致再制造产品主导市场。当感知价值中等且第三方再制造显著提高新产品感知价值时，第三方授权再制造最有利可图，通常增加总市场销量但相应增加环境影响。两部分授权合同比单部分合同更能满足严格的环境要求，考虑市场规模随机性可提高系统盈利性同时将环境影响控制在有限范围内。

Conclusion: 消费者感知价值是决定最优再制造商业模式的关键因素。OEM应根据消费者感知水平和环境要求选择适当的再制造策略，两部分授权合同和考虑市场随机性可以平衡盈利性和环境影响。

Abstract: As a key circular economy strategy, remanufacturing allows original equipment manufacturers (OEMs) to reduce waste by restoring used products to ``as-new'' conditions. This paper investigates an OEM's optimal remanufacturing business model by incorporating consumer perceptions into price and production quantity decisions. We analyze three alternative models: no remanufacturing, OEM in-house remanufacturing, and third-party remanufacturer (TPR) authorized remanufacturing. We extend the authorization with a two-part tariff contract and consider a stochastic market size. Through a numerical approach, we optimize price and quantity decisions based on consumer perceptions and develop a hierarchical decision roadmap to guide model selection. Our findings show that when consumer's perceived value of remanufactured products is high, OEM in-house remanufacturing is most profitable and reduces environmental impacts, but generally leads to a market dominated by remanufactured products. In contrast, when consumer's perceived value of remanufactured products is moderate and TPR remanufacturing significantly increases the perceived value of new products, the TPR-authorized remanufacturing is most profitable. It typically boosts total market sales, but accordingly increases environmental impacts. In addition, sensitivity analysis indicates that two-part authorization contracts are more advanced in meeting stringent environmental requirements than one-part contracts. Incorporating market size stochasticity enhances system profitability while keeping environmental impacts within a limited scope.

</details>


### [53] [Penalty-Free SDDP: Feasibility Cuts for Robust Multi-Stage Stochastic Optimization in Energy Planning](https://arxiv.org/abs/2512.03739)
*Guilherme Freitas,Luiz Carlos da Costa Junior,Tiago Andrade,Alexandre Street*

Main category: math.OC

TL;DR: 提出Penalty-Free SDDP算法，通过引入未来可行性函数和可行性割平面，自动处理不可行性，无需人工校准惩罚项


<details>
  <summary>Details</summary>
Motivation: 传统SDDP要求所有阶段问题可行，通常通过添加松弛变量和惩罚项来保证可行性，但这需要案例特定校准且扭曲经济解释

Method: 提出Penalty-Free SDDP，引入未来可行性函数与传统未来成本函数并行，通过可行性割平面在阶段间传播可行性信息，自动区分暂时性和真正不可行情况

Result: 在巴西水电系统启发的大规模确定性案例中验证，达到与基准解相同的可行性，同时消除了校准不当的人工惩罚项

Conclusion: 该方法具有鲁棒性和实用性，为未来随机多阶段应用奠定了基础

Abstract: Multi-stage decision problems under uncertainty can be efficiently solved with the Stochastic Dual Dynamic Programming (SDDP) algorithm. However, traditional implementations require all stage problems to be feasible. Feasibility is usually enforced by adding slack variables and penalizing them in the objective function, a process that depends on case-specific calibration and often distorts the economic interpretation of results. This paper proposes the Penalty-Free SDDP, an extension that introduces a Future Feasibility Function alongside the traditional Future Cost Function. The new recursion handles infeasibilities automatically, distinguishing between temporary and truly infeasible cases, and propagates feasibility information across stages through dedicated feasibility cuts. The approach was validated in a large-scale deterministic case inspired by the Brazilian hydrothermal system, achieving equivalent feasibility to the benchmark solution while eliminating miscalibrated artificial penalties. Results confirm its robustness and practicality as a foundation for future stochastic, multi-stage applications.

</details>


### [54] [Sample-Efficient Counterfactual Tuning for Compressor Pressure Control](https://arxiv.org/abs/2512.03747)
*Margarita A. Guerrero,Rodrigo A. González,Cristian R. Rojas*

Main category: math.OC

TL;DR: 提出一种基于反事实可解释性的数据驱动方法，用于高效重调压缩机控制回路，无需显式模型即可在保证稳定性的前提下最小化控制器调整


<details>
  <summary>Details</summary>
Motivation: 工业控制环境中，压缩机-气室-节流阀系统的控制回路调参既关键又具挑战性，不能容忍昂贵的停机，而激进的激励可能导致不安全运行状态。历史数据广泛可用，但传统方法需要显式模型或已知控制律。

Method: 采用反事实可解释性方法，提出数据驱动算法，无需显式工厂模型或先前控制律，确定实现预定性能规格所需的最小控制器调整，同时保证稳定性。

Result: 通过广泛的蒙特卡洛仿真研究证明了该方法的有效性，能够高效地重调压缩机控制回路。

Conclusion: 该方法为工业控制系统的安全高效调参提供了一种基于历史数据的实用解决方案，特别适用于不能容忍中断和不安全操作的关键系统。

Abstract: In controlled industrial environments, ensuring safety and performance during controller tuning is a challenging and critical task. In particular, control loops in compressor-plenum-throttle systems cannot tolerate costly interruptions, and aggressive excitation may lead to unsafe operating regimes. Given the wide availability of historical data, this paper introduces a counterfactual explainability approach for sample-efficient retuning of compressor control loops. The proposed data-driven algorithm determines, without an explicit plant model or previous control law, the smallest controller adjustment required to achieve predefined performance specifications while guaranteeing stability. The effectiveness of the method is demonstrated through an extensive Monte Carlo simulation study.

</details>


### [55] [A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models](https://arxiv.org/abs/2512.03915)
*X. Y. Han,Yuan Zhong*

Main category: math.OC

TL;DR: 本文为DeepSeek提出的无辅助损失负载均衡(ALF-LB)方法提供了理论框架，将其建模为分配问题的单步原始-对偶方法，证明了其在确定性和在线设置下的收敛性和平衡保证。


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家(s-MoE)层在大规模AI训练中通过仅激活每个token的少量专家来实现扩展，但面临负载均衡的操作挑战：需要高效路由token以避免GPU资源浪费。DeepSeek提出的ALF-LB方法缺乏理论分析，本文旨在填补这一空白。

Method: 将ALF-LB过程建模为分配问题的单步原始-对偶方法。首先在确定性设置中分析结构特性，然后扩展到随机动态的在线优化框架，利用目标的强凸性推导遗憾界，并通过1B参数DeepSeekMoE模型实验验证。

Result: 理论分析揭示了：(1)拉格朗日目标的单调改进；(2)从过载专家向欠载专家转移token的偏好规则；(3)近似平衡保证。在线设置中，特定步长选择下获得对数期望遗憾界。实验验证了理论发现。

Conclusion: 本文为s-MoE中的无辅助损失负载均衡建立了原则性理论框架，证明了ALF-LB方法的有效性，为大规模AI训练中的高效专家路由提供了理论基础。

Abstract: In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.

</details>


### [56] [Discontinuous Strongly Quasiconvex Functions](https://arxiv.org/abs/2512.03934)
*Nguyen Thi Van Hang,Felipe Lara,Nguyen Dong Yen*

Main category: math.OC

TL;DR: 本文详细回答了关于实值强拟凸函数是否必然连续的基本开放性问题，证明了这类函数可以有无限多个不连续点，并展示了某些实值强拟凸函数在无限多个点处既非下半连续也非上半连续。


<details>
  <summary>Details</summary>
Motivation: 研究实值强拟凸函数是否像凸函数一样必然连续的基本开放性问题。凸函数具有连续性，但强拟凸函数是否具有类似性质尚不清楚。

Method: 通过构造反例和分析函数性质，证明强拟凸函数可以有不连续点。具体展示了函数在无限多个点处既非下半连续也非上半连续的情况。

Result: 证明了实值强拟凸函数不一定连续，可以有无限多个不连续点。某些实值强拟凸函数在无限多个点处同时缺乏下半连续性和上半连续性。

Conclusion: 强拟凸函数与凸函数在连续性方面存在本质差异：凸函数必然连续，但强拟凸函数可以有不连续点，甚至可以有无限多个不连续点且同时缺乏上下半连续性。

Abstract: A fundamental open question asking whether all real-valued strongly quasiconvex functions defined on $\mathbb R^n$ are necessarily continuous, akin to their convex counterparts, is answered in detail in this paper. Among other things, we show that such functions can have infinitely many points of discontinuity. The failure of lower semicontinuity together with the lack of upper semicontinuity at infinitely many points of certain real-valued strongly quasiconvex functions are also shown.

</details>


### [57] [Data-Dependent Complexity of First-Order Methods for Binary Classification](https://arxiv.org/abs/2512.03947)
*Matthew Hough,Stephen A. Vavasis*

Main category: math.OC

TL;DR: 论文提出针对FISTA算法的早期停止策略，用于解决椭圆体分离问题和软间隔SVM分类问题，通过几何数据特性确定停止时机，避免传统基于容忍度的停止条件。


<details>
  <summary>Details</summary>
Motivation: 大规模数据科学问题通常用优化建模，一阶方法收敛速度可能较慢。传统基于容忍度的停止条件难以选择，需要根据底层数据科学任务完成情况来终止算法。

Method: 1) 对于椭圆体分离问题，将二阶锥对偶规划转化为FISTA可解形式，证明FISTA残差收敛到PDHG算法的最小位移向量；2) 对于SVM，提出强凹扰动对偶问题，在线性时间投影方案下实现高效FISTA更新；3) 推导数据依赖的迭代上界和早期停止准则。

Result: 1) 推导出迭代上界为O(1/δ_A^2)，其中δ_A是破坏可分性的最小扰动；2) 在合理数据模型下，早期停止的迭代能识别良好分类点并产生精确分离超平面；3) 在MNIST数据和SVM基准测试中显示竞争性运行时间和显著的早期停止加速效果。

Conclusion: 提出的早期停止策略基于数据几何特性，减少了对难以选择的容忍度停止条件的依赖，在椭圆体分离和SVM分类问题中实现了高效求解和显著加速。

Abstract: Large-scale problems in data science are often modeled with optimization, and the optimization model is usually solved with first-order methods that may converge at a sublinear rate. Therefore, it is of interest to terminate the optimization algorithm as soon as the underlying data science task is accomplished. We consider FISTA for solving two binary classification problems: the ellipsoid separation problem (ESP), and the soft-margin support-vector machine (SVM). For the ESP, we cast the dual second-order cone program into a form amenable to FISTA and show that the FISTA residual converges to the infimal displacement vector of the primal-dual hybrid gradient (PDHG) algorithm, that directly encodes a separating hyperplane. We further derive a data-dependent iteration upper bound scaling as $\mathcal{O}(1/δ_{\mathcal{A}}^2)$, where $δ_{\mathcal{A}}$ is the minimal perturbation that destroys separability. For the SVM, we propose a strongly-concave perturbed dual that admits efficient FISTA updates under a linear time projection scheme, and with our parameter choices, the objective has small condition number, enabling rapid convergence. We prove that, under a reasonable data model, early-stopped iterates identify well-classified points and yield a hyperplane that exactly separates them, where the accuracy required of the dual iterate is governed by geometric properties of the data. In particular, the proposed early-stopping criteria diminish the need for hard-to-select tolerance-based stopping conditions. Our numerical experiments on ESP instances derived from MNIST data and on soft-margin SVM benchmarks indicate competitive runtimes and substantial speedups from stopping early.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [58] [A Theoretical Framework Bridging Model Validation and Loss Ratio in Insurance](https://arxiv.org/abs/2512.03242)
*C. Evans Hedges*

Main category: q-fin.RM

TL;DR: 本文首次建立了预测模型性能与保险定价中损失率之间的解析关系，推导出预测与实际损失之间的皮尔逊相关系数与预期损失率的闭式公式，证明了模型改进存在边际收益递减规律。


<details>
  <summary>Details</summary>
Motivation: 保险定价中，精算师通常凭直觉优先改进表现不佳的模型，但缺乏量化分析框架。现有方法无法将模型性能提升与业务影响（损失率）直接关联，导致模型投资决策依赖定性判断而非定量成本效益分析。

Method: 推导预测模型性能（皮尔逊相关系数）与预期损失率之间的闭式解析公式，引入损失率误差（Loss Ratio Error）指标来量化频率、严重性和纯保费模型的业务影响，并通过模拟验证在假设条件下的可靠性。

Result: 建立了预测模型相关系数与损失率的数学关系，证明模型改进存在边际收益递减，为优先改进低性能模型提供了理论依据。模拟显示在假设条件下预测可靠，即使在假设违反时也能优雅降级。

Conclusion: 该框架将模型投资决策从定性直觉转变为定量成本效益分析，为保险定价中的模型改进提供了科学的优先级排序依据，实现了模型性能与业务影响的直接量化关联。

Abstract: This paper establishes the first analytical relationship between predictive model performance and loss ratio in insurance pricing. We derive a closed-form formula connecting the Pearson correlation between predicted and actual losses to expected loss ratio. The framework proves that model improvements exhibit diminishing marginal returns, analytically confirming the actuarial intuition to prioritize poorly performing models. We introduce the Loss Ratio Error metric for quantifying business impact across frequency, severity, and pure premium models. Simulations show reliable predictions under stated assumptions, with graceful degradation under assumption violations. This framework transforms model investment decisions from qualitative intuition to quantitative cost-benefit analysis.

</details>


### [59] [Orlicz-Lorentz premia and distortion Haezendonck-Goovaerts risk measures](https://arxiv.org/abs/2512.03267)
*Aline Goulard,Karl Grosse-Erdmann*

Main category: q-fin.RM

TL;DR: 提出一种新的风险度量类别——扭曲Haezendonck-Goovaerts风险度量，它统一了扭曲风险度量和Haezendonck-Goovaerts风险度量，并在比有界风险空间更大的空间上定义。


<details>
  <summary>Details</summary>
Motivation: 在金融和精算研究中，扭曲风险度量和Haezendonck-Goovaerts风险度量因其优良性质而备受关注，但迄今为止它们被分开处理。本文旨在统一这两种风险度量框架。

Method: 引入并研究一种新的风险度量类别——扭曲Haezendonck-Goovaerts风险度量，该度量在比有界风险空间更大的空间上定义，并分析其性质。

Result: 提供了这些新风险度量成为相干风险度量的条件，并探索了它们的风险理论性质。

Conclusion: 成功构建了一个统一框架，将两种重要的风险度量类别结合起来，扩展了风险度量的理论工具集。

Abstract: In financial and actuarial research, distortion and Haezendonck-Goovaerts risk measures are attractive due to their strong properties. They have so far been treated separately. In this paper, following a suggestion by Goovaerts, Linders, Van Weert, and Tank, we introduce and study a new class of risk measure that encompasses the distortion and Haezendonck-Goovaerts risk measures, aptly called the distortion Haezendonck-Goovaerts risk measures. They will be defined on a larger space than the space of bounded risks. We provide situations where these new risk measures are coherent, and explore their risk theoretic properties.

</details>


<div id='q-fin.PR'></div>

# q-fin.PR [[Back]](#toc)

### [60] [A Co-evolutionary Approach for Heston Calibration](https://arxiv.org/abs/2512.03922)
*Julian Gutierrez*

Main category: q-fin.PR

TL;DR: 评估Heston模型的协同进化校准框架，发现基于遗传算法历史采样的方法虽然能快速降低训练损失，但会导致过拟合；而使用拉丁超立方采样的多样化数据集在保持校准精度的同时，具有更好的样本外稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究协同进化校准框架的有效性，探索在Heston模型校准中，数据生成策略如何影响逆映射的稳健性和泛化能力。

Method: 采用协同进化校准框架：遗传算法优化参数，同时训练从期权曲面到参数的神经逆映射。比较两种数据生成策略：1）基于遗传算法历史的采样；2）拉丁超立方采样生成的空间填充数据集。

Result: 遗传算法历史采样能快速降低训练损失，但学习曲线显示训练-验证差距扩大，表明存在显著过拟合。拉丁超立方采样数据集在保持相近校准精度的同时，在保留样本曲面上表现出明显更好的样本外稳定性。

Conclusion: 协同进化数据生成带来的改进主要是目标特定专业化，而非更可靠的全局逆映射。保持数据集多样性对于稳健的摊销校准至关重要。

Abstract: We evaluate a co-evolutionary calibration framework for the Heston model in which a genetic algorithm (GA) over parameters is coupled to an evolving neural inverse map from option surfaces to parameters. While GA-history sampling can reduce training loss quickly and yields strong in-sample fits to the target surface, learning-curve diagnostics show a widening train--validation gap across generations, indicating substantial overfitting induced by the concentrated and less diverse dataset. In contrast, a broad, space-filling dataset generated via Latin hypercube sampling (LHS) achieves nearly comparable calibration accuracy while delivering markedly better out-of-sample stability across held-out surfaces. These results suggest that apparent improvements from co-evolutionary data generation largely reflect target-specific specialization rather than a more reliable global inverse mapping, and that maintaining dataset diversity is critical for robust amortized calibration.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [61] [Evaluating A/B Testing Methodologies via Sample Splitting: Theory and Practice](https://arxiv.org/abs/2512.03366)
*Ryan Kessler,James McQueen,Miikka Rokkanen*

Main category: econ.EM

TL;DR: 样本分割在A/B测试中的理论框架，用于在真实影响未知时评估方法性能，证明分割估计量对全样本性能有偏但能一致估计分割版本，推导渐近分布并构建置信区间


<details>
  <summary>Details</summary>
Motivation: 在A/B测试中，当测试的真实影响无法观测时，需要评估新估计器和决策规则的性能。传统方法面临真实效果未知的挑战，需要建立理论框架来指导样本分割设计

Method: 开发理论框架，将每个测试的数据分割为两部分：一部分用于测量方法性能，另一部分用于评估。推导样本分割估计量的渐近分布，构建有效置信区间，并分析偏差-方差权衡

Result: 证明样本分割估计量对全样本性能有偏，但能一致估计样本分割版本的性能。建立了渐近分布理论，构建了有效置信区间，并通过模拟验证了理论结果

Conclusion: 样本分割为A/B测试中评估方法性能提供了理论依据，指导了分割设计选择，为A/B测试产品评估新估计器和决策规则提供了实施指南

Abstract: We develop a theoretical framework for sample splitting in A/B testing environments, where data for each test are partitioned into two splits to measure methodological performance when the true impacts of tests are unobserved. We show that sample-split estimators are generally biased for full-sample performance but consistently estimate sample-split analogues of it. We derive their asymptotic distributions, construct valid confidence intervals, and characterize the bias-variance trade-offs underlying sample-split design choices. We validate our theoretical results through simulations and provide implementation guidance for A/B testing products seeking to evaluate new estimators and decision rules.

</details>


### [62] [Estimation of Panel Data Models with Nonlinear Factor Structure](https://arxiv.org/abs/2512.03693)
*Christina Maschmann,Joakim Westerlund*

Main category: econ.EM

TL;DR: 提出SCCE估计量，通过结合CCE方法和样条方法，放宽了交互效应模型中时间效应必须线性的假设，适用于更广泛的因子结构


<details>
  <summary>Details</summary>
Motivation: 传统面板数据模型假设未观测异质性（交互效应）中的时间效应是线性的，这一假设缺乏理论依据且过于严格。虽然观测变量之间的关系通常可以合理假设为线性，但对未观测成分施加线性假设是不自然的。现有方法保持线性假设主要是出于便利性，而非理论合理性。

Method: 将共同相关效应（CCE）方法与样条方法相结合，提出SCCE估计量。CCE方法处理标准交互效应，样条方法则允许因子结构具有更灵活的非线性形式。新方法保持了CCE的计算简单性，同时放宽了因子结构的线性限制。

Result: SCCE估计量保留了CCE的优点，包括计算简单性、良好的小样本和渐近性质，但适用于更广泛的因子结构类别，其中线性结构只是特例。这使得该方法适用于更广泛的实证应用场景。

Conclusion: SCCE估计量通过结合CCE和样条方法，有效放宽了交互效应模型中因子结构的线性假设，提供了更灵活、更合理的估计框架，适用于各种实证研究需求。

Abstract: Panel data models with unobserved heterogeneity in the form of interactive effects standardly assume that the time effects - or "common factors" - enter linearly. This assumption is unnatural in the sense that it pertains to the unobserved component of the model, and there is rarely any reason to believe that this component takes on a particular functional form. This is in stark contrast to the relationship between the observables, which can often be credibly argued to be linear. Linearity in the factors has persevered mainly because it is convenient, and that it is better than standard fixed effects. The present paper relaxes this assumption. It does so by combining the common correlated effects (CCE) approach to standard interactive effects with the method of sieves. The new estimator - abbreviated "SCCE" - retains many of the advantages of CCE, including its computational simplicity, and good small-sample and asymptotic properties, but is applicable under a much broader class of factor structures that includes the linear one as a special case. This makes it well-suited for a wide range of empirical applications.

</details>


### [63] [Learning from crises: A new class of time-varying parameter VARs with observable adaptation](https://arxiv.org/abs/2512.03763)
*Nicolas Hardy,Dimitris Korobilis*

Main category: econ.EM

TL;DR: 提出自适应变参数VAR模型，用可观测外生变量驱动确定性调整，替代传统TVP-VAR的潜在状态创新，简化估计并提升预测性能


<details>
  <summary>Details</summary>
Motivation: 传统时变参数VAR模型的参数变化可能过于缓慢，难以适应重大危机期间的急剧结构性变化，需要更灵活且简洁的参数动态机制

Method: 开发自适应变参数VAR模型，用宏观经济和金融指标的可观测外生变量线性组合替代潜在状态创新，将状态方程融入测量方程，实现简单线性估计

Result: 模拟显示自适应参数比传统TVP更简洁，能有效约束参数动态而不牺牲灵活性；在美国和欧元区数据中，AVP-VAR显著提升样本外预测精度，尤其在波动加剧时期

Conclusion: 自适应变参数VAR模型通过可观测变量驱动参数调整，提供更简洁有效的时变参数建模框架，在预测性能上优于传统方法，特别适用于危机时期

Abstract: We revisit macroeconomic time-varying parameter vector autoregressions (TVP-VARs), whose persistent coefficients may adapt too slowly to large, abrupt shifts such as those during major crises. We explore the performance of an adaptively-varying parameter (AVP) VAR that incorporates deterministic adjustments driven by observable exogenous variables, replacing latent state innovations with linear combinations of macroeconomic and financial indicators. This reformulation collapses the state equation into the measurement equation, enabling simple linear estimation of the model. Simulations show that adaptive parameters are substantially more parsimonious than conventional TVPs, effectively disciplining parameter dynamics without sacrificing flexibility. Using macroeconomic datasets for both the U.S. and the euro area, we demonstrate that AVP-VAR consistently improves out-of-sample forecasts, especially during periods of heightened volatility.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [64] [Echoes of AI Harms: A Human-LLM Synergistic Framework for Bias-Driven Harm Anticipation](https://arxiv.org/abs/2512.03068)
*Nicoleta Tantalaki,Sophia Vei,Athena Vakali*

Main category: cs.CY

TL;DR: 提出了ECHO框架，用于在AI系统开发早期主动预测和映射AI偏见类型与可能造成的危害之间的关系，通过利益相关者识别、情景展示和双标注方法，支持AI系统的预期治理。


<details>
  <summary>Details</summary>
Motivation: AI系统在关键领域决策中的影响日益增长，暴露出其可能造成重大危害的潜力，这些危害通常源于AI生命周期中嵌入的偏见。现有框架通常孤立地记录偏见或危害，很少在现实社会技术背景下建立特定偏见类型与所造成危害之间的系统性联系。技术修复方法通常在系统开发或部署后应用，预防价值有限。

Method: 提出了ECHO框架，采用模块化工作流程：包括利益相关者识别、基于情景的偏见AI系统展示、人类-LLM双标注危害，并整合到伦理矩阵中进行结构化解释。这种以人为中心的方法能够在早期阶段检测偏见到危害的路径。

Result: 在疾病诊断和招聘两个高风险领域验证了ECHO框架，揭示了领域特定的偏见到危害模式，展示了ECHO支持AI系统预期治理的潜力。

Conclusion: ECHO框架能够主动预测AI危害，通过系统性映射AI偏见类型与危害结果之间的关系，指导AI设计和治理决策从一开始就考虑潜在危害，为AI系统的预期治理提供了有效工具。

Abstract: The growing influence of Artificial Intelligence (AI) systems on decision-making in critical domains has exposed their potential to cause significant harms, often rooted in biases embedded across the AI lifecycle. While existing frameworks and taxonomies document bias or harms in isolation, they rarely establish systematic links between specific bias types and the harms they cause, particularly within real-world sociotechnical contexts. Technical fixes proposed to address AI biases are ill-equipped to address them and are typically applied after a system has been developed or deployed, offering limited preventive value. We propose ECHO, a novel framework for proactive AI harm anticipation through the systematic mapping of AI bias types to harm outcomes across diverse stakeholder and domain contexts. ECHO follows a modular workflow encompassing stakeholder identification, vignette-based presentation of biased AI systems, and dual (human-LLM) harm annotation, integrated within ethical matrices for structured interpretation. This human-centered approach enables early-stage detection of bias-to-harm pathways, guiding AI design and governance decisions from the outset. We validate ECHO in two high-stakes domains (disease diagnosis and hiring), revealing domain-specific, bias-to-harm patterns and demonstrating ECHO's potential to support anticipatory governance of AI systems

</details>


### [65] [Economies of Open Intelligence: Tracing Power & Participation in the Model Ecosystem](https://arxiv.org/abs/2512.03073)
*Shayne Longpre,Christopher Akiki,Campbell Lund,Atharva Kulkarni,Emily Chen,Irene Solaiman,Avijit Ghosh,Yacine Jernite,Lucie-Aimée Kaffee*

Main category: cs.CY

TL;DR: Hugging Face Model Hub数据研究显示：开源模型经济正经历重大重构，美国巨头主导地位下降，中国企业和独立开发者崛起，模型规模增长17倍，多模态和量化技术快速发展，但数据透明度下降。


<details>
  <summary>Details</summary>
Motivation: 研究动机是全面分析Hugging Face平台上的开源模型经济动态，追踪从2020年6月到2025年8月期间模型下载、属性变化和行业格局演变，为理解开源AI生态系统提供数据支持。

Method: 方法包括收集和分析Hugging Face Model Hub的完整历史数据，涵盖851,000个模型、每个模型200多个聚合属性、22亿次下载记录，使用统计方法识别显著变化趋势。

Result: 结果显示：1）美国企业（Google、Meta、OpenAI）主导地位大幅下降，中国行业（DeepSeek、Qwen）和独立开发者崛起；2）模型平均规模增长17倍；3）多模态生成增长3.4倍，量化技术增长5倍，MoE架构增长7倍；4）数据透明度下降，2025年首次出现"开放权重"模型超过"真正开源"模型；5）出现了专注于量化和适配的开发者中介层。

Conclusion: 开源模型经济正在经历根本性重构，权力从美国巨头向中国企业和社区转移，技术特征快速演变但透明度下降，需要持续监测。研究发布了完整数据集和交互式仪表板以支持后续研究。

Abstract: Since 2019, the Hugging Face Model Hub has been the primary global platform for sharing open weight AI models. By releasing a dataset of the complete history of weekly model downloads (June 2020-August 2025) alongside model metadata, we provide the most rigorous examination to-date of concentration dynamics and evolving characteristics in the open model economy. Our analysis spans 851,000 models, over 200 aggregated attributes per model, and 2.2B downloads. We document a fundamental rebalancing of economic power: US open-weight industry dominance by Google, Meta, and OpenAI has declined sharply in favor of unaffiliated developers, community organizations, and, as of 2025, Chinese industry, with DeepSeek and Qwen models potentially heralding a new consolidation of market power. We identify statistically significant shifts in model properties, a 17X increase in average model size, rapid growth in multimodal generation (3.4X), quantization (5X), and mixture-of-experts architectures (7X), alongside concerning declines in data transparency, with open weights models surpassing truly open source models for the first time in 2025. We expose a new layer of developer intermediaries that has emerged, focused on quantizing and adapting base models for both efficiency and artistic expression. To enable continued research and oversight, we release the complete dataset with an interactive dashboard for real-time monitoring of concentration dynamics and evolving properties in the open model economy.

</details>


### [66] [Will Power Return to the Clouds? From Divine Authority to GenAI Authority](https://arxiv.org/abs/2512.03076)
*Mohammad Saleh Torkestani,Taha Mansouri*

Main category: cs.CY

TL;DR: 本文比较了伽利略事件（宗教知识控制）与当代科技巨头内容审核，分析AI作为真理仲裁者的权力结构，提出四支柱治理蓝图以防止数字正统固化。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统已成为数亿用户新闻推送、搜索排名和创意内容的中介，使少数私营公司成为事实上的真理仲裁者。本文旨在通过历史比较，揭示当代AI内容审核与历史上知识控制机制的相似性，分析其权力结构并提出治理方案。

Method: 采用比较历史视角，将伽利略事件（宗教知识控制）与当代科技巨头内容审核进行对比。整合福柯的权力/知识理论、韦伯的权威类型（扩展到理性-技术和新兴代理-技术模式）和弗洛里迪的数据主义，分析五个维度：规训权力、权威模式、数据多元主义、信任与依赖、抵抗路径。使用主要来源（宗教裁判所记录、平台透明度报告）和AI信任实证研究作为证据基础。

Result: 研究发现强烈的结构趋同性：高度集中的把关机制、以超越性原则为合法性主张、系统性排除边缘声音。差异在于时间速度、全球规模以及公众对AI系统的依赖与信任之间的日益扩大的差距。伦理挑战集中在算法不透明性、语言不平等、偏见反馈循环和合成虚假信息。

Conclusion: 提出四支柱治理蓝图：1）强制性的国际模型注册表与版本化政策日志；2）代表配额和区域观察站以去中心化英语霸权；3）大规模批判性AI素养计划；4）公私合作支持社区主导的数据信托。这些措施旨在缩小信任-依赖差距，防止生成式AI固化21世纪的数字正统。

Abstract: Generative AI systems now mediate newsfeeds, search rankings, and creative content for hundreds of millions of users, positioning a handful of private firms as de-facto arbiters of truth. Drawing on a comparative-historical lens, this article juxtaposes the Galileo Affair, a touchstone of clerical knowledge control, with contemporary Big-Tech content moderation. We integrate Foucault's power/knowledge thesis, Weber's authority types (extended to a rational-technical and emerging agentic-technical modality), and Floridi's Dataism to analyze five recurrent dimensions: disciplinary power, authority modality, data pluralism, trust versus reliance, and resistance pathways. Primary sources (Inquisition records; platform transparency reports) and recent empirical studies on AI trust provide the evidentiary base. Findings show strong structural convergences: highly centralized gatekeeping, legitimacy claims couched in transcendent principles, and systematic exclusion of marginal voices. Divergences lie in temporal velocity, global scale, and the widening gap between public reliance and trust in AI systems. Ethical challenges cluster around algorithmic opacity, linguistic inequity, bias feedback loops, and synthetic misinformation. We propose a four-pillar governance blueprint: (1) a mandatory international model-registry with versioned policy logs, (2) representation quotas and regional observatories to de-center English-language hegemony, (3) mass critical-AI literacy initiatives, and (4) public-private support for community-led data trusts. Taken together, these measures aim to narrow the trust-reliance gap and prevent GenAI from hardcoding a twenty-first-century digital orthodoxy.

</details>


### [67] [Irresponsible AI: big tech's influence on AI research and associated impacts](https://arxiv.org/abs/2512.03077)
*Alex Hernandez-Garcia,Alexandra Volokhova,Ezekiel Williams,Dounia Shaaban Kabakibo*

Main category: cs.CY

TL;DR: 大科技公司在AI发展中日益增长的影响力与AI的负责任、伦理和可持续发展存在根本冲突，需要超越技术和监管的替代策略来应对。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨大科技公司在AI加速发展中的主导作用如何与AI的伦理问题、社会和环境负面影响相互关联，揭示其经济激励与负责任AI发展之间的根本矛盾。

Method: 采用文献综述和批判性分析方法：1) 分析大科技在AI研究中的不成比例影响力；2) 审查AI当前的环境和社会负面影响；3) 追溯这些影响与大科技经济激励的联系；4) 评估技术和监管方法的局限性；5) 提出基于责任和集体行动的替代策略。

Result: 研究发现大科技公司对扩展性和通用系统的追求与AI的负责任发展存在根本冲突，其经济激励导致了显著的环境和社会负面影响，单纯的技术和监管方法不足以应对这种结构性扭曲。

Conclusion: 需要超越传统技术和监管框架的替代策略，强调相关行为者的责任和集体行动，以应对大科技在AI发展中造成的结构性扭曲，实现更负责任、伦理和可持续的AI发展。

Abstract: The accelerated development, deployment and adoption of artificial intelligence systems has been fuelled by the increasing involvement of big tech. This has been accompanied by increasing ethical concerns and intensified societal and environmental impacts. In this article, we review and discuss how these phenomena are deeply entangled. First, we examine the growing and disproportionate influence of big tech in AI research and argue that its drive for scaling and general-purpose systems is fundamentally at odds with the responsible, ethical, and sustainable development of AI. Second, we review key current environmental and societal negative impacts of AI and trace their connections to big tech and its underlying economic incentives. Finally, we argue that while it is important to develop technical and regulatory approaches to these challenges, these alone are insufficient to counter the distortion introduced by big tech's influence. We thus review and propose alternative strategies that build on the responsibility of implicated actors and collective action.

</details>


### [68] [Culture Affordance Atlas: Reconciling Object Diversity Through Functional Mapping](https://arxiv.org/abs/2512.03173)
*Joan Nwatu,Longju Bai,Oana Ignat,Rada Mihalcea*

Main category: cs.CY

TL;DR: 论文提出功能中心框架，通过创建文化可供性图谱数据集，减少VL模型中的文化偏见和性能差距


<details>
  <summary>Details</summary>
Motivation: 主流视觉语言数据集存在文化偏见，过度偏向高收入西方语境，导致模型泛化能力下降和性能差异，尤其影响低收入和非西方社区

Method: 提出功能中心框架，按对象在不同文化和经济背景下实现的功能进行分类，创建文化可供性图谱数据集，包含46个功能和288个对象

Result: 功能中心标签显著减少高低收入群体间的社会经济性能差距（中位数降低6个百分点），提升模型在低收入语境下的有效性，识别出主流VL数据集忽视的文化必需对象

Conclusion: 功能中心框架为构建包容性VL数据集和公平AI系统提供了可扩展路径，有助于减少文化偏见和性能差异

Abstract: Culture shapes the objects people use and for what purposes, yet mainstream Vision-Language (VL) datasets frequently exhibit cultural biases, disproportionately favoring higher-income, Western contexts. This imbalance reduces model generalizability and perpetuates performance disparities, especially impacting lower-income and non-Western communities. To address these disparities, we propose a novel function-centric framework that categorizes objects by the functions they fulfill, across diverse cultural and economic contexts. We implement this framework by creating the Culture Affordance Atlas, a re-annotated and culturally grounded restructuring of the Dollar Street dataset spanning 46 functions and 288 objects publicly available at https://lit.eecs.umich.edu/CultureAffordance-Atlas/index.html. Through extensive empirical analyses using the CLIP model, we demonstrate that function-centric labels substantially reduce socioeconomic performance gaps between high- and low-income groups by a median of 6 pp (statistically significant), improving model effectiveness for lower-income contexts. Furthermore, our analyses reveals numerous culturally essential objects that are frequently overlooked in prominent VL datasets. Our contributions offer a scalable pathway toward building inclusive VL datasets and equitable AI systems.

</details>


### [69] [LLM-Generated Ads: From Personalization Parity to Persuasion Superiority](https://arxiv.org/abs/2512.03373)
*Elyas Meguellati,Stefano Civelli,Lei Han,Abraham Bernstein,Shazia Sadiq,Gianluca Demartini*

Main category: cs.CY

TL;DR: LLM生成的广告在个性化方面与人类专家持平，但在基于心理学说服原则的通用广告中显著优于人类，特别是在权威性和共识性诉求方面。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成说服性内容的能力增强，需要了解它们在不同广告策略中的效果，以评估其在广告实践中的应用潜力。

Method: 采用两部分研究：第一部分测试LLM生成针对特定人格特质（开放性和神经质）的个性化广告，并与人类专家比较；第二部分测试LLM在四种心理学说服原则（权威、共识、认知、稀缺性）下的表现。

Result: 研究一：LLM生成的个性化广告与人类广告表现相当（51.1% vs 48.9%）。研究二：AI生成的广告显著优于人类内容（59.1% vs 40.9%），在权威性（63.0%）和共识性（62.5%）诉求中表现最强。即使参与者能识别AI来源并施加21.2%的惩罚，AI广告仍优于人类广告。

Conclusion: LLM在广告领域已从个性化方面的持平发展到说服性叙事方面的优势，考虑到其近乎零的边际成本和时间需求，这对广告实践具有重要影响。

Abstract: As large language models (LLMs) become increasingly capable of generating persuasive content, understanding their effectiveness across different advertising strategies becomes critical. This paper presents a two-part investigation examining LLM-generated advertising through complementary lenses: (1) personality-based and (2) psychological persuasion principles.
  In our first study (n=400), we tested whether LLMs could generate personalized advertisements tailored to specific personality traits (openness and neuroticism) and how their performance compared to human experts. Results showed that LLM-generated ads achieved statistical parity with human-written ads (51.1% vs. 48.9%, p > 0.05), with no significant performance differences for matched personalities.
  Building on these insights, our second study (n=800) shifted focus from individual personalization to universal persuasion, testing LLM performance across four foundational psychological principles: authority, consensus, cognition, and scarcity. AI-generated ads significantly outperformed human-created content, achieving a 59.1% preference rate (vs. 40.9%, p < 0.001), with the strongest performance in authority (63.0%) and consensus (62.5%) appeals. Qualitative analysis revealed AI's advantage stems from crafting more sophisticated, aspirational messages and achieving superior visual-narrative coherence. Critically, this quality advantage proved robust: even after applying a 21.2 percentage point detection penalty when participants correctly identified AI-origin, AI ads still outperformed human ads, and 29.4% of participants chose AI content despite knowing its origin. These findings demonstrate LLMs' evolution from parity in personalization to superiority in persuasive storytelling, with significant implications for advertising practice given LLMs' near-zero marginal cost and time requirements compared to human experts.

</details>


### [70] [Joint Sensing, Communication, and Computation for Vertical Federated Edge Learning in Edge Perception Network](https://arxiv.org/abs/2512.03374)
*Xiaowen Cao,Dingzhu Wen,Suzhi Bi,Yuanhao Cui,Guangxu Zhu,Han Hu,Yonina C. Eldar*

Main category: cs.CY

TL;DR: 提出面向特征分区感知数据的垂直联邦边缘学习框架，在集成感知、通信和计算的边缘感知网络中，通过空中计算聚合特征嵌入进行全局模型训练


<details>
  <summary>Details</summary>
Motivation: 传统基于样本分割的水平联邦边缘学习难以有效融合分布式设备的互补多视图信息，需要针对特征分区感知数据设计更有效的联邦学习框架

Method: 提出垂直联邦边缘学习框架，在集成感知、通信和计算的边缘感知网络中，设备利用无线信号感知环境信息更新本地模型，边缘服务器通过空中计算聚合特征嵌入进行全局训练

Result: 分析了在无线感知噪声和空中计算聚合失真存在的情况下，集成感知、通信和计算的垂直联邦边缘学习的收敛行为，包括损失函数退化分析

Conclusion: 提出的垂直联邦边缘学习框架能够有效处理特征分区感知数据，为边缘感知网络中的智能数据收集和处理提供了新方法

Abstract: Combining wireless sensing and edge intelligence, edge perception networks enable intelligent data collection and processing at the network edge. However, traditional sample partition based horizontal federated edge learning struggles to effectively fuse complementary multiview information from distributed devices. To address this limitation, we propose a vertical federated edge learning (VFEEL) framework tailored for feature-partitioned sensing data. In this paper, we consider an integrated sensing, communication, and computation-enabled edge perception network, where multiple edge devices utilize wireless signals to sense environmental information for updating their local models, and the edge server aggregates feature embeddings via over-the-air computation for global model training. First, we analyze the convergence behavior of the ISCC-enabled VFEEL in terms of the loss function degradation in the presence of wireless sensing noise and aggregation distortions during AirComp.

</details>


### [71] [Functional Python Programming in Introductory Computer Science Courses](https://arxiv.org/abs/2512.03492)
*Rajshekhar Sunderraman*

Main category: cs.CY

TL;DR: 在Python入门编程课程中引入纯函数式编程子集的教学实践，让学生学习不可变性、无副作用函数等函数式概念


<details>
  <summary>Details</summary>
Motivation: 函数式编程范式具有悠久历史，纯函数式语言如Haskell已被证明能有效构建健壮软件。非函数式语言如Python也引入了不可变数据结构等函数式特性，可以在这些语言中进行纯函数式编程。计算机专业学生需要熟悉纯函数式编程，这可以在使用Python的入门编程课程中教授。

Method: 定义Python的函数式编程子集，在入门编程课程中采用"最佳实践"方法，强制学生学习和完成纯函数式Python子集的编程作业。通过小例子说明这一实践方法。

Result: 提出了一种在Python入门课程中教授函数式编程的教学方法，使学生能够学习不可变性、无副作用纯函数和无状态编程等函数式概念。

Conclusion: 学生需要熟悉纯函数式编程，这可以在使用Python的入门编程课程中有效教授。通过定义Python的函数式子集并采用强制性的最佳实践方法，学生可以掌握函数式编程的核心概念。

Abstract: The functional programming paradigm has a long and storied history, with its beginnings in the Lambda Calculus. In recent decades, pure functional languages such as Haskell have been shown to be highly effective in producing robust software due to immutable data structures, among other functional features. The advantages of programming with immutable data structures can also be had in non-functional languages such as Python. Over the years, non-functional languages have introduced immutable data structures as well as comprehension and lambda expressions, and it is possible to program in a purely functional style in them. In this paper, we present a ``best practice'' idea in introductory programming classes that forces students to learn and complete programming assignments in a purely functional subset of Python. By doing so, the student can learn functional ideas such as immutability, pure functions with no side effects, and stateless programming. We define a functional subset of Python and illustrate the best practice using small examples. We strongly feel that students in computing need familiarity with pure functional programming and argue that this can be taught in introductory programming courses that use Python.

</details>


### [72] [SocraticAI: Transforming LLMs into Guided CS Tutors Through Scaffolded Interaction](https://arxiv.org/abs/2512.03501)
*Karthik Sunil,Aalok Thakkar*

Main category: cs.CY

TL;DR: SocraticAI是一个将大语言模型融入本科计算机科学教育的脚手架式AI辅导系统，通过结构化约束而非禁止来培养学生负责任的AI交互技能。


<details>
  <summary>Details</summary>
Motivation: 传统AI禁令无法培养学生与AI互动的技能，而SocraticAI旨在通过结构化约束而非禁止的方式，将LLMs融入教育，培养学生负责任和战略性的AI交互能力。

Method: 系统实施技术护栏：身份验证、查询验证、结构化反馈和基于RAG的课程基础。强制要求问题表述清晰、反思性参与和每日使用限制，并提供苏格拉底式对话脚手架。

Result: 初步部署显示，学生在2-3周内从模糊求助转变为复杂问题分解，超过75%的学生产生实质性反思，并表现出深思熟虑、战略性的AI使用模式。

Conclusion: 通过结构化约束而非禁止的方法，SocraticAI成功培养了学生负责任和战略性的AI交互技能，为将LLMs融入教育提供了有效途径。

Abstract: We present SocraticAI, a scaffolded AI tutoring system that integrates large language models (LLMs) into undergraduate Computer Science education through structured constraints rather than prohibition. The system enforces well-formulated questions, reflective engagement, and daily usage limits while providing Socratic dialogue scaffolds. Unlike traditional AI bans, our approach cultivates responsible and strategic AI interaction skills through technical guardrails, including authentication, query validation, structured feedback, and RAG-based course grounding. Initial deployment demonstrates that students progress from vague help-seeking to sophisticated problem decomposition within 2-3 weeks, with over 75% producing substantive reflections and displaying emergent patterns of deliberate, strategic AI use.

</details>


### [73] [Ancient Algorithms for a Modern Curriculum](https://arxiv.org/abs/2512.03507)
*Aalok Thakkar*

Main category: cs.CY

TL;DR: 该论文指出当前算法教学过于去语境化和欧洲中心主义，提出应将算法教学嵌入更广泛的历史文化背景中，特别关注古印度等古代文明的贡献。


<details>
  <summary>Details</summary>
Motivation: 当前计算机科学基础课程中的算法教学存在去语境化问题，将算法思维呈现为纯粹形式化和非历史的，强调效率、正确性和抽象性。这种狭隘的欧洲中心主义视角歪曲了算法推理的起源，损害了STEM领域的公平性和代表性。

Method: 通过将算法教学嵌入更广泛的历史文化背景中，特别关注古典印度等古代文明的贡献，来回应这一教学空白。强调算法思维在电子计算机出现前数千年就已存在，并在印度、中国、巴比伦和埃及等古代文明中有深厚根源。

Result: 论文提出了一个更包容和文化响应的算法教学方法，挑战了当前以图灵、冯·诺依曼和巴贝奇为中心的欧洲中心主义叙事，为算法教学提供了更丰富的历史文化维度。

Conclusion: 算法教学需要超越当前的去语境化和欧洲中心主义方法，通过纳入古代文明的贡献来创建更包容、文化响应和公平的计算机科学教育，这有助于改善STEM领域的代表性和多样性。

Abstract: Despite ongoing calls for inclusive and culturally responsive pedagogy in computing education, the teaching of algorithms remains largely decontextualized. Foundational computer science courses often present algorithmic thinking as purely formal and ahistorical, emphasizing efficiency, correctness, and abstraction. When history is mentioned, it usually centers on the modern development of digital computers, highlighting figures such as Turing, von Neumann, and Babbage. This narrow view misrepresents the origins of algorithmic reasoning and perpetuates a Eurocentric worldview that undermines equity and representation in STEM. In contrast, algorithmic thinking predates electronic computers by millennia and has deep roots in ancient civilizations including India, China, Babylon, and Egypt. Our work responds to this gap by embedding algorithm instruction in broader historical and cultural contexts, with particular attention to classical Indian contributions.

</details>


### [74] [Lifting the Cage of Consent: A Techno-Legal Perspective on Evolvable Trust Relationships](https://arxiv.org/abs/2512.03674)
*Beatriz Esteves,Ruben Verborgh*

Main category: cs.CY

TL;DR: 论文批评当前隐私保护法规（如GDPR）过于惩罚性，阻碍了数据的合理流动，提出应建立可演化的信任系统，通过技术辅助的法律流程促进可持续的数据交换。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护法规过度关注惩罚违规行为，导致合规成本高昂，反而促使企业采用非法捷径。真正的挑战不是数据流动太多，而是流动不足，阻碍了数据驱动经济的发展。

Method: 提出实施可演化的信任系统作为替代当前"知情同意"模式的方案，描述了个性化、技术辅助的法律流程，用于建立和维护长期信任关系，使各方能够可靠、可持续地交换数据、商品和服务。

Result: 通过将额外努力重新导向技术和法律的对齐，使经济激励与社会激励相一致，技术可以支持人们发展和扩展关系，以满足当前和未来数据环境日益复杂的需求。

Conclusion: 隐私友好的数据处理需要更便宜、更简单的替代方案，否则经济需求将继续凌驾于法律要求之上。可演化的信任系统能够促进互利互动，而不仅仅是防止不良行为。

Abstract: Those concerned about privacy worry that personal data changes hands too easily. We argue that the actual challenge is the exact opposite: our data does not flow well enough, cultivating a reliance on questionable and often unlawful shortcuts in a desperate bid to survive within today's data-driven economy. Exclusively punitive interpretations of protective legislation such as the GDPR throw out the baby with the bathwater through barriers that equally hinder "doing the right thing" and "doing the wrong thing", in an abject mistranslation of how ethical choices correspond to financial cost. As long as privacy-friendly data treatment proves more expensive or complicated than readily available alternatives, economic imperatives will continue to outrank their legal counterparts. We examined existing legislation with the aim of facilitating mutually beneficial interactions, rather than more narrowly focusing on the prevention of undesired behaviors. In this article, we propose the implementation of evolvable trust systems as a scalable alternative to the omnipresent yet deeply broken delusion of ill-informed consent. We describe personalized, technology-assisted legal processes for initiating and maintaining long-term trust relationships, which enable parties to reliably and sustainably exchange data, goods, and services. Our proposal encourages a redirection of additional efforts towards the techno-legal alignment of economical incentives with societal ones, reminding us that - while trust remains an inherently human concept - technology can support people in evolving and scaling their relationships to meet the increasingly complex demands of current and future data landscapes.

</details>


### [75] [Knowing oneself with and through AI: From self-tracking to chatbots](https://arxiv.org/abs/2512.03682)
*Lucy Osler*

Main category: cs.CY

TL;DR: AI正在改变我们认识自我的方式，通过自我追踪、数字记忆存储和与LLMs的叙事共建，既带来新机会也带来风险。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能如何重塑自我认知、自我理解和自我叙事实践，分析AI技术在这些领域带来的变革和挑战。

Method: 基于分布式认知框架，分析三个关键领域：自我追踪应用、技术分布式自传记忆、与大型语言模型的叙事共建。

Result: 自我追踪设备提供量化数据但可能排挤其他自我理解形式；数字技术作为记忆存储既有益处又易受算法操控；LLMs支持自我探索但也可能导致叙事依赖和脱离现实。

Conclusion: AI正在深刻改变我们的自我认知方式，这些技术既提供了新的自我理解途径，也带来了自我优化压力、算法操控风险和叙事失真等挑战。

Abstract: This chapter examines how algorithms and artificial intelligence are transforming our practices of self-knowledge, self-understanding, and self-narration. Drawing on frameworks from distributed cognition, I analyse three key domains where AI shapes how and what we come to know about ourselves: self-tracking applications, technologically-distributed autobiographical memories, and narrative co-construction with Large Language Models (LLMs). While self-tracking devices promise enhanced self-knowledge through quantified data, they also impose particular frameworks that can crowd out other forms of self-understanding and promote self-optimization. Digital technologies increasingly serve as repositories for our autobiographical memories and self-narratives, offering benefits such as detailed record-keeping and scaffolding during difficult periods, but also creating vulnerabilities to algorithmic manipulation. Finally, conversational AI introduces new possibilities for interactive narrative construction that mimics interpersonal dialogue. While LLMs can provide valuable support for self-exploration, they also present risks of narrative deference and the construction of self-narratives that are detached from reality.

</details>


### [76] [The enshittification of online search? Privacy and quality of Google, Bing and Apple in coding advice](https://arxiv.org/abs/2512.03793)
*Konrad Kollnig*

Main category: cs.CY

TL;DR: 研究比较了Google、Bing和Apple三大搜索引擎在编程建议搜索质量上的表现，发现Bing在隐私保护和搜索结果质量方面均优于Google和Apple。


<details>
  <summary>Details</summary>
Motivation: 尽管面临ChatGPT等大语言模型的挑战，Google搜索仍然是人们获取信息的主要方式。然而，自1998年Google成立以来，网络信息检索方式几乎没有变化，这引发了对其市场主导地位和缺乏竞争的担忧。如果搜索市场充分竞争，搜索质量应该会随时间稳步提升，并出现替代Google的搜索方法。但目前很少有研究关注搜索质量这一竞争市场的关键方面，尤其是长期变化。

Method: 研究于2023年10月对1,467个编程建议搜索查询进行了大规模定量比较。选择编程建议作为研究对象是因为通用搜索质量研究较为困难。评估了Google Search、Microsoft Bing和Apple Search的搜索质量，特别关注了之前从未被研究过的Apple Search。使用两个独立指标：1）第一个搜索结果中的跟踪器数量（衡量隐私保护）；2）第一个Stack Overflow搜索结果的平均排名（假设Stack Overflow提供最佳编程建议）。

Result: 结果显示：1）Bing搜索结果的隐私保护水平高于Google和Apple；2）以Stack Overflow平均排名衡量的编程建议质量，Bing表现最佳。

Conclusion: 研究表明Bing在隐私保护和编程建议搜索质量方面优于Google和Apple，这为搜索质量评估提供了新的视角，并激励后续研究关注这一重要主题。

Abstract: Even though currently being challenged by ChatGPT and other large-language models (LLMs), Google Search remains one of the primary means for many individuals to find information on the internet. Interestingly, the way that we retrieve information on the web has hardly changed ever since Google was established in 1998, raising concerns as to Google's dominance in search and lack of competition. If the market for search was sufficiently competitive, then we should probably see a steady increase in search quality over time as well as alternative approaches to the Google's approach to search. However, hardly any research has so far looked at search quality, which is a key facet of a competitive market, especially not over time.
  In this report, we conducted a relatively large-scale quantitative comparison of search quality of 1,467 search queries relating to coding advice in October 2023. We focus on coding advice because the study of general search quality is difficult, with the aim of learning more about the assessment of search quality and motivating follow-up research into this important topic. We evaluate the search quality of Google Search, Microsoft Bing, and Apple Search, with a special emphasis on Apple Search, a widely used search engine that has never been explored in previous research. For the assessment of search quality, we use two independent metrics of search quality: 1) the number of trackers on the first search result, as a measure of privacy in web search, and 2) the average rank of the first Stack Overflow search result, under the assumption that Stack Overflow gives the best coding advice. Our results suggest that the privacy of search results is higher on Bing than on Google and Apple. Similarly, the quality of coding advice -- as measured by the average rank of Stack Overflow -- was highest on Bing.

</details>


### [77] [Non-Linear Determinants of Pedestrian Injury Severity: Evidence from Administrative Data in Great Britain](https://arxiv.org/abs/2512.04022)
*Yifei Tong*

Main category: cs.CY

TL;DR: 该研究使用英国2023年STATS19数据集，通过机器学习方法分析行人伤害严重程度的非线性决定因素，发现车辆数量、限速、照明和路面条件是主要预测因素，并识别出城乡地区伤害严重程度的空间差异。


<details>
  <summary>Details</summary>
Motivation: 传统线性模型难以捕捉行人伤害严重程度的复杂交互作用和异质性，且STATS19数据集存在数据质量问题（缺失信息和类别不平衡），需要更先进的分析方法。

Method: 采用严格的预处理流程（众数填补和SMOTE过采样），使用随机森林和XGBoost等非参数集成方法，结合SHAP解释技术确保模型可解释性，并进行空间分析。

Result: 车辆数量、限速、照明条件和路面状况是伤害严重程度的主要预测因素；警察到场和交叉口特征进一步区分严重碰撞；城市地区行人风险集中，但某些农村地区一旦发生碰撞，伤害严重程度更高。

Conclusion: 结合空间分析和可解释机器学习的方法，可为针对性的速度管理、基础设施投资和执法策略提供指导，有助于制定地理定位的安全干预措施。

Abstract: This study investigates the non-linear determinants of pedestrian injury severity using administrative data from Great Britain's 2023 STATS19 dataset. To address inherent data-quality challenges, including missing information and substantial class imbalance, we employ a rigorous preprocessing pipeline utilizing mode imputation and Synthetic Minority Over-sampling (SMOTE). We utilize non-parametric ensemble methods (Random Forest and XGBoost) to capture complex interactions and heterogeneity often missed by linear models, while Shapley Additive Explanations are employed to ensure interpretability and isolate marginal feature effects. Our analysis reveals that vehicle count, speed limits, lighting, and road surface conditions are the primary predictors of severity, with police attendance and junction characteristics further distinguishing severe collisions. Spatially, while pedestrian risk is concentrated in dense urban Local Authority Districts (LADs), we identify that certain rural LADs experience disproportionately severe outcomes conditional on a collision occurring. These findings underscore the value of combining spatial analysis with interpretable machine learning to guide geographically targeted speed management, infrastructure investment, and enforcement strategies.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [78] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: ECLIPSE是一个检测LLM幻觉的框架，通过结合语义熵估计和证据利用分析，在金融QA数据集上达到0.89的AUC，显著优于仅使用语义熵的基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型会产生流畅但无根据的答案（幻觉），这限制了其在高风险领域的安全部署。需要一种能够检测幻觉的机制。

Method: 提出ECLIPSE框架，将幻觉视为模型语义熵与可用证据容量之间的不匹配。结合多样本聚类的熵估计和新的困惑度分解方法，测量模型如何使用检索到的证据。证明在温和条件下，得到的熵-容量目标是严格凸的，具有唯一稳定最优解。

Result: 在受控金融问答数据集上（GPT-3.5-turbo，n=200平衡样本，包含合成幻觉），ECLIPSE达到ROC AUC 0.89和平均精度0.90，显著优于仅使用语义熵的基线（AUC 0.50）。使用Claude-3-Haiku的受控消融实验显示AUC降至0.59，系数幅度下降95%，表明ECLIPSE是依赖校准的令牌级不确定性的logprob原生机制。

Conclusion: ECLIPSE是一个有效的幻觉检测框架，其有效性依赖于校准的令牌级不确定性。困惑度分解特征具有最大的学习系数，证实证据利用是幻觉检测的核心。本研究是受控机制研究，跨领域和自然发生幻觉的广泛验证是未来工作。

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [79] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 提出结合物理知识与机器学习的计算框架，用于预测钢铁连续冷却转变（CCT）图，实现高效准确的相变预测。


<details>
  <summary>Details</summary>
Motivation: 机器学习在材料科学中主要应用于新化合物发现和制造过程优化，但将通用ML框架应用于复杂工业材料（如钢铁）仍面临挑战。关键难点在于准确捕捉化学成分、加工参数与微观结构/性能之间的复杂关系。

Method: 开发物理知识驱动的机器学习框架，结合物理洞察与ML技术，建立物理信息化的连续冷却转变（CCT）模型。模型基于4,100个CCT图数据集训练，并验证了其计算效率和泛化能力。

Result: 模型计算效率高，生成包含100条冷却曲线的完整CCT图仅需不到5秒。在合金钢中表现出强泛化能力：相分类F1分数均高于88%；相变温度回归中，除贝氏体（MAE 27°C）外，所有相的MAE均低于20°C。

Conclusion: 该框架可扩展为通用数字孪生平台，用于热处理优化。通过与补充模拟工具和针对性实验集成，将进一步支持加速材料设计工作流程。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [80] [Mitigating hallucinations and omissions in LLMs for invertible problems: An application to hardware logic design automation](https://arxiv.org/abs/2512.03053)
*Andrew S. Cassidy,Guillaume Garreau,Jay Sivagnaname,Mike Grassi,Bernard Brezzo,John V. Arthur,Dharmendra S. Modha*

Main category: cs.LG

TL;DR: 提出一种利用LLM进行无损编解码的方法，用于可逆问题（如LCT到HDL转换），可显著减少LLM的幻觉和遗漏问题，提高硬件设计生产力。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在代码生成任务中常见的幻觉和遗漏问题，特别是在硬件设计领域（如从逻辑条件表生成HDL代码），需要一种可靠的方法来确保生成的代码正确性。

Method: 采用信息论中无损压缩的思想：1) 使用LLM作为无损编码器从源域（LCT）转换到目标域（HDL）；2) 再使用LLM作为无损解码器从HDL转换回LCT；3) 比较原始LCT和重建LCT来验证生成质量。

Result: 使用7种不同LLM生成了二维网络芯片路由器（13个单元，1500-2000行代码）的完整HDL，通过重建LCT与原始LCT比较，能够：1) 确认正确生成的逻辑；2) 检测错误生成的逻辑；3) 帮助开发者发现设计规范错误。

Conclusion: 提出的无损编解码方法能有效缓解LLM的幻觉和遗漏问题，显著提高硬件设计生产力，不仅验证了LLM生成逻辑的正确性，还能辅助发现设计规范错误。

Abstract: We show for invertible problems that transform data from a source domain (for example, Logic Condition Tables (LCTs)) to a destination domain (for example, Hardware Description Language (HDL) code), an approach of using Large Language Models (LLMs) as a lossless encoder from source to destination followed by as a lossless decoder back to the source, comparable to lossless compression in information theory, can mitigate most of the LLM drawbacks of hallucinations and omissions. Specifically, using LCTs as inputs, we generate the full HDL for a two-dimensional network-on-chip router (13 units, 1500-2000 lines of code) using seven different LLMs, reconstruct the LCTs from the auto-generated HDL, and compare the original and reconstructed LCTs. This approach yields significant productivity improvements, not only confirming correctly generated LLM logic and detecting incorrectly generated LLM logic but also assisting developers in finding design specification errors.

</details>


### [81] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 提出一种面向绿色AI的自适应层冻结策略，用于联邦学习中的MRI-to-CT转换任务，在保持模型性能的同时减少能耗和碳排放达23%


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能促进医疗平等，但其高计算资源需求可能加剧医疗不平等。需要降低计算负担，使资源有限的机构也能参与，同时减少环境影响

Method: 提出自适应层冻结策略：基于轮次间编码器权重的相对差异选择性冻结权重，采用耐心机制确保仅在更新持续较小时才冻结。使用CodeCarbon库追踪能耗和碳排放

Result: 相比未冻结版本，训练时间、总能耗和CO2eq排放减少达23%。MRI-to-CT转换性能保持稳定，MAE仅有小幅变化。5种架构中3种无显著差异，2种有显著改进

Conclusion: 该方法为联邦学习提供了气候、社会和经济效益可持续的解决方案，为促进AI医疗中的隐私、公平和正义奠定了基础

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [82] [Physics-informed self-supervised learning for predictive modeling of coronary artery digital twins](https://arxiv.org/abs/2512.03055)
*Xiaowu Sun,Thabo Mahendiran,Ortal Senouf,Denise Auberson,Bernard De Bruyne,Stephane Fournier,Olivier Muller,Pascal Frossard,Emmanuel Abbe,Dorina Thanou*

Main category: cs.LG

TL;DR: PINS-CAD：基于物理信息的自监督学习框架，通过预训练图神经网络预测冠脉压力和血流，无需CFD或标注数据，在临床数据上微调后能预测心血管事件并生成可解释的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，冠心病是最常见形式，需要早期风险预测。3D冠脉数字孪生虽能提供详细解剖结构，但依赖计算流体动力学分析，可扩展性有限。数据驱动方法受限于标注数据稀缺和缺乏生理先验知识。

Method: 提出PINS-CAD框架：1）在20万个合成冠脉数字孪生上预训练图神经网络；2）使用1D Navier-Stokes方程和压降定律指导预测压力和血流；3）无需CFD或标注数据；4）在FAME2研究的635名患者临床数据上微调。

Result: 预测未来心血管事件的AUC达到0.73，优于临床风险评分和数据驱动基线。物理信息预训练提高了样本效率并产生生理意义表征。能生成空间分辨的压力和血流储备分数曲线，提供可解释生物标志物。

Conclusion: 通过将物理先验嵌入几何深度学习，PINS-CAD将常规血管造影转化为无需仿真、具有生理感知的框架，实现可扩展的预防性心脏病学。

Abstract: Cardiovascular disease is the leading global cause of mortality, with coronary artery disease (CAD) as its most prevalent form, necessitating early risk prediction. While 3D coronary artery digital twins reconstructed from imaging offer detailed anatomy for personalized assessment, their analysis relies on computationally intensive computational fluid dynamics (CFD), limiting scalability. Data-driven approaches are hindered by scarce labeled data and lack of physiological priors. To address this, we present PINS-CAD, a physics-informed self-supervised learning framework. It pre-trains graph neural networks on 200,000 synthetic coronary digital twins to predict pressure and flow, guided by 1D Navier-Stokes equations and pressure-drop laws, eliminating the need for CFD or labeled data. When fine-tuned on clinical data from 635 patients in the multicenter FAME2 study, PINS-CAD predicts future cardiovascular events with an AUC of 0.73, outperforming clinical risk scores and data-driven baselines. This demonstrates that physics-informed pretraining boosts sample efficiency and yields physiologically meaningful representations. Furthermore, PINS-CAD generates spatially resolved pressure and fractional flow reserve curves, providing interpretable biomarkers. By embedding physical priors into geometric deep learning, PINS-CAD transforms routine angiography into a simulation-free, physiology-aware framework for scalable, preventive cardiology.

</details>


### [83] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种无需训练数据、在推理时实现不同架构基础模型间知识迁移的新方法，通过利用模型适配前后的预测差异来指导新基础模型的去噪过程。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型的适配组件（如LoRA、ControlNet等）与特定基础模型紧密耦合，当基础模型升级时（如从SD 1.x到2.x），由于模型参数和架构的重大变化，这些适配组件难以复用。

Method: Delta Sampling (DS) 完全在推理时操作，通过计算模型适配前后的预测差异（delta），然后利用这个delta来指导新基础模型的去噪过程，实现跨架构的知识迁移。

Result: 在多个Stable Diffusion版本上的评估表明，DS在不同采样策略下都能一致地改善期望效果（如视觉风格、语义概念和结构）的创建，实现了有效的知识迁移。

Conclusion: DS作为一种即插即用的机制，为基于扩散的图像合成中的知识迁移提供了有效的解决方案，无需原始训练数据即可实现跨基础模型架构的知识转移。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [84] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 该论文研究预训练Transformer模型中token的动态特性，分析其连续时间极限的动态系统，并探索如何利用这些发现改进Transformer架构。


<details>
  <summary>Details</summary>
Motivation: 研究预训练Transformer模型中token的动态行为，理解token如何随时间相互靠近或远离，以及这些动态特性如何影响模型性能，为改进Transformer架构提供理论基础。

Method: 1. 分析预训练模型的连续时间极限动态系统；2. 基于模型参数表征解的渐近行为；3. 提供token收敛到零或发散到无穷的充分条件；4. 研究绝对位置编码和旋转位置编码对动态机制的影响；5. 提出简单的Transformer架构改进方案。

Result: 1. 建立了比先前工作更广泛、更适用于实际模型的收敛/发散条件；2. 发现收敛场景对模型性能有负面影响；3. 不同位置编码形式影响动态机制；4. 提出了缓解绝对和旋转位置编码模型收敛行为的简单改进方案。

Conclusion: 通过分析Transformer中token的动态特性，揭示了收敛行为对性能的负面影响，并提出了相应的架构改进方案，为改进Transformer模型提供了理论基础和设计原则。

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [85] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 提出一种安全的分层深度强化学习框架，用于优化电动公交车充电调度，解决光伏发电、动态电价等多源不确定性下的成本最小化与安全运行问题。


<details>
  <summary>Details</summary>
Motivation: 电动公交车与光伏等可再生能源结合是实现低碳公共交通的有效途径，但在实际运行中面临光伏发电不确定性、动态电价、旅行时间变化和充电设施有限等多重挑战，需要优化充电调度以降低运营成本并确保电池不耗尽。

Method: 将问题建模为带约束的马尔可夫决策过程，提出DAC-MAPPO-Lagrangian分层强化学习算法：高层采用集中式PPO-Lagrangian学习安全充电桩分配策略；低层采用MAPPO-Lagrangian在CTDE范式下学习分散式充电功率决策。

Result: 基于真实数据的实验表明，该方法在成本最小化和安全合规性方面优于现有基线方法，同时保持了较快的收敛速度。

Conclusion: 提出的安全分层深度强化学习框架能有效解决多源不确定性下的电动公交车充电调度问题，为可持续公共交通系统提供了可行的优化方案。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [86] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 提出两种基于物理启发的SVD LLM压缩改进方法：FermiGrad算法通过费米函数将离散奇异值截断松弛为连续优化来确定全局最优层间秩；PivGa利用参数化中的规范自由度对低秩因子进行无损压缩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对计算资源需求极高，低秩分解（如SVD）是LLM压缩的有前景方法，但存在实际挑战：需要选择适当的层间秩和消除参数冗余。

Method: 1. FermiGrad：基于梯度下降算法，通过费米函数将离散奇异值截断松弛为连续优化，确定全局最优层间秩。2. PivGa：利用低秩因子参数化中的规范自由度，对低秩因子进行额外的无损压缩。

Result: 论文提出了两种物理启发的改进方法，解决了SVD LLM压缩中的两个关键问题：层间秩选择和参数冗余消除，提高了压缩效率和效果。

Conclusion: 通过FermiGrad和PivGa两种方法，改进了基于SVD的LLM压缩技术，为大型语言模型的高效压缩提供了新的物理启发式解决方案。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [87] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 大规模工业框架利用数百个实验数据估计异质处理效应，通过组合多个实验结果发现潜在用户特征，并实现稳定的处理效应估计


<details>
  <summary>Details</summary>
Motivation: 传统方法假设处理效应对所有用户相同，但实际中用户对广告等干预的反应存在异质性，需要更精细的个性化效应估计

Method: 开发大规模工业框架，包括实验选择、基础学习器设计、增量训练等核心组件，利用Snapchat数亿用户的实验数据进行HTE/CATE估计

Result: 框架成功应用于用户对广告的影响性和敏感性分析，在线A/B测试显示使用影响性分数进行定向投放的关键业务指标提升超过典型显著水平的6倍

Conclusion: 该大规模HTE框架能够有效发现潜在用户特征，提供稳定的个性化处理效应估计，在广告定向等实际应用中显著提升业务效果

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [88] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator：将任意黑盒验证器分数转换为具有可证明误报率控制的决策规则的方法，用于在线监控智能体轨迹


<details>
  <summary>Details</summary>
Motivation: 现有验证器（如LLM评判器和过程奖励模型）虽然能对智能体轨迹中的每个动作进行评分，但这些启发式评分缺乏正确性保证，无法确保智能体最终产生成功输出

Method: 将区分成功轨迹与失败轨迹的问题构建为序贯假设检验问题，基于e-过程工具开发序贯假设检验，在智能体轨迹的每一步保持统计有效性，实现任意长动作序列的在线监控

Result: 在六个数据集和三种智能体上，e-valuator比其他策略具有更高的统计功效和更好的误报率控制；还能用于快速终止问题轨迹并节省token

Conclusion: e-valuator提供了一个轻量级、模型无关的框架，将验证器启发式方法转换为具有统计保证的决策规则，使能部署更可靠的智能体系统

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [89] [Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning](https://arxiv.org/abs/2512.03065)
*Nihir Chadderwala*

Main category: cs.LG

TL;DR: 提出一个结合AWS Strands Agents与Thompson Sampling上下文多臂老虎机的框架，让AI代理仅从用户反馈中学习最优决策策略，在生命科学领域实现15-30%的用户满意度提升。


<details>
  <summary>Details</summary>
Motivation: 生命科学领域的生成式AI代理面临关键挑战：如何为从简单事实性问题到复杂机制推理的多样化查询确定最优方法。传统方法依赖固定规则或昂贵的标注训练数据，都无法适应变化条件或用户偏好。

Method: 结合AWS Strands Agents与Thompson Sampling上下文多臂老虎机，让AI代理仅从用户反馈中学习最优决策策略。系统优化三个关键维度：生成策略选择（直接生成vs.思维链）、工具选择（文献搜索、药物数据库等）和领域路由（药理学、分子生物学、临床专家）。

Result: 在生命科学查询上的实证评估显示，相比随机基线，用户满意度提升15-30%，在20-30次查询后出现清晰的学习模式。

Conclusion: 该方法无需真实标签，能持续适应用户偏好，为代理AI系统中的探索-利用困境提供了原则性解决方案。

Abstract: Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.

</details>


### [90] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: SISR框架统一解决Shapley值两大挑战：通过单调变换恢复可加性，同时施加L0稀疏约束，提升高维解释的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值框架假设可加性，但现实世界中的非高斯分布、重尾、特征依赖等常违反该假设，导致归因失真。同时，高维稀疏解释需要先计算密集Shapley值再阈值处理，成本高且不一致。

Method: 提出Sparse Isotonic Shapley Regression (SISR)：同时学习单调变换恢复可加性（无需闭式指定），并施加L0稀疏约束。优化算法使用Pool-Adjacent-Violators进行等渗回归和归一化硬阈值进行支持选择。

Result: SISR能在多种场景中恢复真实变换，在高噪声下实现强支持恢复。实验表明，SISR能稳定不同支付方案下的归因，正确过滤无关特征，而标准Shapley值存在严重排序和符号失真。

Conclusion: 通过统一非线性变换估计与稀疏性追求，SISR推进了非线性可解释性前沿，提供了理论坚实且实用的归因框架，首次证明无关特征和特征间依赖可导致真实支付变换显著偏离线性。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [91] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 使用预拓扑学建模建筑能耗曲线，开发基于预拓扑空间特性的多准则层次分类算法，实现大规模建筑能耗的自动化分类与优化管理。


<details>
  <summary>Details</summary>
Motivation: 对数千栋建筑进行逐个深度能耗审计需要大量时间、资金和专业人员，因此需要开发自动化方法来建立有效的能耗管理推荐系统。

Method: 采用预拓扑学建模建筑能耗曲线，开发基于预拓扑空间特性的多准则层次分类算法，并实现为Python库。

Result: 在二维点数据集上能根据位置和大小识别聚类；在生成的时间序列数据集上使用皮尔逊相关系数达到调整兰德指数(ARI)为1的完美聚类效果；在400个真实建筑能耗时间序列数据集上验证了方法的有效性。

Conclusion: 预拓扑学和多准则层次分类算法能够有效建模和分类大规模分布式建筑的能耗曲线，为建筑能耗优化管理提供自动化解决方案。

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [92] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: SAFLe框架通过引入结构化头部和稀疏分组嵌入，将非线性模型转换为高维线性回归，实现了单轮联邦学习中非线性表达能力的突破。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临两大挑战：高通信开销和非IID数据下的性能崩溃。现有的分析联邦学习（AFL）虽然提供单轮、数据分布不变的解决方案，但仅限于线性模型；而非线性方法如DeepAFL虽然恢复了准确性，却牺牲了单轮优势。

Method: 提出SAFLe框架，通过引入结构化头部（bucketed features）和稀疏分组嵌入（sparse, grouped embeddings）实现可扩展的非线性表达能力。关键创新是证明这种非线性架构在数学上等价于高维线性回归，从而能够应用AFL的单轮、不变聚合定律。

Result: SAFLe在分析联邦学习中建立了新的最先进水平，在所有基准测试中显著优于线性AFL和多轮DeepAFL的准确性，为联邦视觉提供了高效可扩展的解决方案。

Conclusion: SAFLe成功打破了联邦学习中单轮通信和非线性表达能力之间的权衡，通过数学等价性实现了既保持单轮优势又具备非线性表达能力的突破，为联邦学习提供了更高效实用的解决方案。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [93] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 本文提出了一种基于预拓扑空间的混合数据聚类方法，用于解决大数据环境下数值和分类变量混合的聚类挑战，并通过与传统数值聚类算法和现有预拓扑方法的对比验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 大数据范式带来了数据量、速度和多样性的挑战，混合数据聚类成为关键问题。传统聚类方法通常针对同质数据集设计，难以处理数值和分类变量混合的复杂性，需要专门针对混合数据环境的创新方法。

Method: 提出了一种基于预拓扑空间的聚类方法。预拓扑空间提供了比传统拓扑更灵活的结构，能够更好地处理混合数据类型。该方法旨在提供层次化和可解释的聚类结果。

Result: 通过与经典数值聚类算法和现有预拓扑方法进行基准测试，评估了所提出方法的性能和有效性。结果表明该方法在大数据范式下具有较好的表现。

Conclusion: 基于预拓扑空间的聚类方法为解决大数据环境下的混合数据聚类问题提供了有效途径，能够处理数值和分类变量的混合，并提供结构化和可解释的聚类结果，支持明智的决策制定。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [94] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 提出首个确定性广告拍卖中的离策略评估框架，利用出价景观模型近似倾向得分，实现高效离线评估，显著减少在线A/B测试的成本和风险。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试消耗大量工程资源且存在收入损失风险，而传统离策略评估方法在确定性拍卖环境中不适用，因为非获胜广告的曝光概率为零。

Method: 重新利用出价景观模型近似倾向得分，推导稳健的近似倾向得分，使自归一化逆倾向评分等稳定估计器能够在确定性拍卖环境中进行反事实评估。

Result: 在AuctionNet仿真基准和大型工业平台2周在线A/B测试中验证，CTR预测的均值方向准确率达到92%，显著优于参数基线，与在线结果高度一致。

Conclusion: 贡献了首个实用且经验证的确定性拍卖环境可靠离策略评估框架，为成本高昂且风险大的在线实验提供了高效替代方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [95] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 提出一种基于预拓扑的新算法，无需降维即可聚类混合数据，使用析取范式构建可定制的逻辑规则和可调超参数，实现用户定义的分层聚类。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法在处理混合数据时通常需要降维，这会损失数据完整性。现有方法在聚类可解释性和异构数据集适应性方面存在不足。

Method: 基于预拓扑理论，利用析取范式构建可定制的逻辑规则和可调超参数，直接从原始数据构建分层聚类，无需降维处理。

Result: 通过分层树状图分析和聚类指标比较，该方法在保持数据完整性的同时，能够准确、可解释地划分聚类，在聚类可解释性方面表现优异。

Conclusion: 该方法避免了传统降维技术，通过创新的逻辑规则增强了聚类形成和清晰度，为混合数据聚类领域做出了重要贡献。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [96] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 提出一种无需调参的联合稀疏信号恢复框架，利用过参数化的隐式正则化来自动实现行稀疏结构，性能媲美传统方法但无需先验信息。


<details>
  <summary>Details</summary>
Motivation: 传统多测量向量（MMV）方法如M-OMP和M-FOCUSS需要仔细的参数调优或对信号稀疏度和噪声方差的先验知识，这在实际应用中存在局限性。

Method: 通过过参数化将估计矩阵重新参数化为因子，解耦共享的行支持与单个向量条目。对标准最小二乘目标应用梯度下降，优化动态通过"动量效应"自动促进行稀疏结构。

Result: 理论证明：在足够小且平衡的初始化下，优化动态使真实支持中的行范数比其他行增长快得多，确保解轨迹收敛到理想的行稀疏解。实证结果显示性能与现有方法相当。

Conclusion: 提出了一种无需调参的联合稀疏信号恢复框架，利用隐式正则化自动实现行稀疏，无需先验信息，性能与需要调参的传统方法相当。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [97] [Model-Agnostic Fairness Regularization for GNNs with Incomplete Sensitive Information](https://arxiv.org/abs/2512.03074)
*Mahdi Tavassoli Kejani,Fadi Dornaika,Jean-Michel Loubes*

Main category: cs.LG

TL;DR: 提出一个模型无关的公平性正则化框架，用于处理图神经网络中敏感属性仅部分可用的现实场景，在保持分类性能的同时显著减少偏见。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在关系学习任务中表现出色，但会延续和放大基于种族、性别等敏感属性的社会偏见。现有公平性方法假设所有节点的敏感属性在训练时完全可用，这在实践中因隐私和数据收集限制而难以实现。

Method: 提出一个模型无关的公平性正则化框架，针对敏感属性仅部分可用的现实场景。该方法形式化了一个公平性目标函数，将机会均等和统计奇偶性作为可微分的正则化项集成到模型中。

Result: 在五个真实世界基准数据集上的综合实证评估表明，该方法在关键公平性指标上显著减少了偏见，同时保持了竞争力的节点分类性能。框架在公平性-准确性权衡方面始终优于基线模型，预测准确性下降最小。

Conclusion: 该研究解决了图神经网络公平性方法中敏感属性完全可用的不现实假设问题，提出的模型无关正则化框架在部分敏感属性可用的情况下有效减少了偏见，同时保持了良好的分类性能，为实际应用提供了可行的解决方案。

Abstract: Graph Neural Networks (GNNs) have demonstrated exceptional efficacy in relational learning tasks, including node classification and link prediction. However, their application raises significant fairness concerns, as GNNs can perpetuate and even amplify societal biases against protected groups defined by sensitive attributes such as race or gender. These biases are often inherent in the node features, structural topology, and message-passing mechanisms of the graph itself. A critical limitation of existing fairness-aware GNN methods is their reliance on the strong assumption that sensitive attributes are fully available for all nodes during training--a condition that poses a practical impediment due to privacy concerns and data collection constraints. To address this gap, we propose a novel, model-agnostic fairness regularization framework designed for the realistic scenario where sensitive attributes are only partially available. Our approach formalizes a fairness-aware objective function that integrates both equal opportunity and statistical parity as differentiable regularization terms. Through a comprehensive empirical evaluation across five real-world benchmark datasets, we demonstrate that the proposed method significantly mitigates bias across key fairness metrics while maintaining competitive node classification performance. Results show that our framework consistently outperforms baseline models in achieving a favorable fairness-accuracy trade-off, with minimal degradation in predictive accuracy. The datasets and source code will be publicly released at https://github.com/mtavassoli/GNN-FC.

</details>


### [98] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出GaussDetect-LiNGAM方法，通过利用前向模型噪声高斯性与反向回归残差独立性之间的等价关系，无需显式高斯性检验即可进行双变量因果发现。


<details>
  <summary>Details</summary>
Motivation: 传统LiNGAM方法依赖脆弱且对样本敏感的高斯性检验，限制了实际应用。需要更稳健的方法来增强因果推断的效率和可靠性。

Method: 基于理论证明：在线性、无环、外生性假设下，前向模型噪声的高斯性等价于反向模型中回归变量与残差的独立性。利用这一等价关系，用稳健的核基独立性检验替代高斯性检验。

Result: 实验验证了理论等价性，GaussDetect-LiGAM在不同噪声类型和样本量下保持高一致性，同时减少了每次决策所需的检验次数（TPD）。

Conclusion: 该方法提高了因果推断的效率和实际应用性，使LiNGAM在现实场景中更易用和可靠。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [99] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 本文提出将倾斜（熵）风险应用于流匹配（FM），通过log-exponential变换改进标准FM损失，更好地捕捉数据流形的几何结构和少数分支。


<details>
  <summary>Details</summary>
Motivation: 标准FM使用均方误差损失，将所有到达同一时空点的速度目标压缩为单一条件均值，忽略了高阶条件信息（方差、偏度、多模态），这些信息编码了数据流形的精细几何结构和少数分支。

Method: 将标准风险敏感（log-exponential）变换应用于条件FM损失，得到的倾斜风险损失是有意义的条件熵FM目标的上界。通过小阶展开，得到两个可解释的一阶修正：FM残差的协方差预处理和偏好不对称或稀有分支的偏尾项。

Result: 在专门设计用于探测模糊性和尾部的合成数据上，风险敏感损失在统计指标上优于标准FM，并能更忠实地恢复几何结构。

Conclusion: 倾斜风险损失为FM提供了一种有前景的改进方法，能够更好地捕捉数据流形的精细几何特征和少数分支，同时保持可优化的特性。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [100] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: 提出DLC方法，通过LoRA插件扩展范式解决类增量学习中的遗忘问题，仅需少量参数即可显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有类增量学习方法存在遗忘问题或稳定性-可塑性困境，而扩展方法虽然准确率高但参数增加显著。需要一种高效且参数友好的解决方案。

Method: 将基于重放或蒸馏训练的特征提取器作为基础模型，为每个任务使用LoRA注入任务特定残差。推理时聚合带任务特定残差的表示，并引入轻量级权重单元来分配不同LoRA调整表示的重要性分数。

Result: 在ImageNet-100上，仅使用标准ResNet-18 4%的参数，DLC模型实现了8%的准确率提升。在固定内存预算下超越了最先进方法。

Conclusion: DLC作为一种即插即用的增强方法，能够高效扩展基础方法，在类增量学习中实现了参数效率和性能的平衡。

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [101] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: ALARM是一个基于多模态大语言模型的视觉异常检测框架，集成了不确定性量化、推理链、自反思和模型集成等技术，在复杂环境中实现鲁棒可靠的异常检测。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，视觉异常检测面临挑战：异常具有高度上下文相关性和模糊性，因此需要不确定性量化能力来确保MLLM-based VAD系统的成功部署。

Method: ALARM框架集成了不确定性量化与质量保证技术，包括推理链、自反思和MLLM集成，基于严格的概率推理流程和计算过程设计。

Result: 在真实世界的智能家居基准数据和伤口图像分类数据上进行了广泛实证评估，结果显示ALARM具有优越性能，并在不同领域具有通用适用性。

Conclusion: ALARM框架通过集成不确定性量化与质量保证技术，为复杂环境中的视觉异常检测提供了可靠决策支持，展现了跨领域的通用适用性。

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [102] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 该论文为模糊单纯集提供了一个概率解释框架，将其解释为单纯集上概率测度的边际，揭示了UMAP中模糊权重的生成模型来源，并展示了如何基于此框架推导新的降维方法。


<details>
  <summary>Details</summary>
Motivation: 模糊单纯集在降维和流形学习中（特别是UMAP）很重要，但其基于代数拓扑的定义缺乏清晰的概率解释，与这些领域常用的理论框架脱节。作者希望建立一个概率框架来解释模糊单纯集。

Method: 提出一个框架，将模糊单纯集解释为单纯集上概率测度的边际。具体展示了UMAP的模糊权重源于一个生成模型，该模型在随机尺度上采样Vietoris-Rips过滤，产生成对距离的累积分布函数。框架还连接了模糊单纯集与面偏序集上的概率模型。

Result: 该框架为模糊单纯集提供了统一的概率理论基础，阐明了UMAP在该框架中的角色，澄清了Kullback-Leibler散度与模糊交叉熵的关系，并通过底层单纯集的布尔运算恢复了标准的t-范数和t-余范数。还展示了如何基于此框架推导新的嵌入方法，例如使用Čech过滤和三重组采样的UMAP泛化。

Conclusion: 概率视角为模糊单纯集提供了统一的概率理论基础，阐明了UMAP在该框架中的角色，并使得能够系统性地推导新的降维方法。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [103] [Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration](https://arxiv.org/abs/2512.03102)
*Yiwei Shi,Hongnan Ma,Mengyue Yang,Cunjia Liu,Weiru Liu*

Main category: cs.LG

TL;DR: 提出扩散驱动的贝叶斯探索框架，解决粒子滤波中初始状态估计错误导致的永久性支持不变性问题，实现实时错误校正。


<details>
  <summary>Details</summary>
Motivation: 在应急响应等高风险应用中，基于有限或偏差信息的早期状态估计可能与现实严重不符，导致后续行动受限、资源错配和人员伤害。传统粒子滤波存在"平稳性诱导的后验支持不变性"问题，即初始先验排除的区域将永久无法探索，即使新证据与当前信念矛盾也无法修正。

Method: 提出扩散驱动的贝叶斯探索框架：1) 通过熵正则化采样和协方差缩放扩散扩展后验支持；2) 使用Metropolis-Hastings检查验证提议并保持推理对意外证据的自适应性。

Result: 在危险气体定位任务中，当先验正确时与强化学习和规划基线相当；在先验错误时显著优于经典SMC扰动和基于RL的方法。理论保证DEPF解决了S-PSI问题同时保持统计严谨性。

Conclusion: 该框架为高风险应用中的早期状态估计错误提供了原则性的实时校正方法，克服了传统粒子滤波的局限性，在理论和实证上都表现出优越性。

Abstract: In emergency response and other high-stakes societal applications, early-stage state estimates critically shape downstream outcomes. Yet, these initial state estimates-often based on limited or biased information-can be severely misaligned with reality, constraining subsequent actions and potentially causing catastrophic delays, resource misallocation, and human harm. Under the stationary bootstrap baseline (zero transition and no rejuvenation), bootstrap particle filters exhibit Stationarity-Induced Posterior Support Invariance (S-PSI), wherein regions excluded by the initial prior remain permanently unexplorable, making corrections impossible even when new evidence contradicts current beliefs. While classical perturbations can in principle break this lock-in, they operate in an always-on fashion and may be inefficient. To overcome this, we propose a diffusion-driven Bayesian exploration framework that enables principled, real-time correction of early state estimation errors. Our method expands posterior support via entropy-regularized sampling and covariance-scaled diffusion. A Metropolis-Hastings check validates proposals and keeps inference adaptive to unexpected evidence. Empirical evaluations on realistic hazardous-gas localization tasks show that our approach matches reinforcement learning and planning baselines when priors are correct. It substantially outperforms classical SMC perturbations and RL-based methods under misalignment, and we provide theoretical guarantees that DEPF resolves S-PSI while maintaining statistical rigor.

</details>


### [104] [Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics](https://arxiv.org/abs/2512.04006)
*Connall Garrod,Jonathan P. Keating,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 本文首次证明了在交叉熵损失下，梯度流会收敛到神经坍缩几何，通过分析两层线性神经网络，构建了显式Lyapunov函数，并发现Hadamard初始化能对角化softmax算子，简化了动力学分析。


<details>
  <summary>Details</summary>
Motivation: 现有理论对交叉熵损失的分析存在简化，要么用平方损失替代，要么局限于凸模型，无法捕捉真实深度学习中交叉熵损失的本质动态。需要研究非凸优化中交叉熵损失的真实动态。

Method: 分析一个规范的两层线性神经网络，使用标准基向量作为输入。构建显式Lyapunov函数证明全局收敛性，关键发现是Hadamard初始化能够对角化softmax算子，冻结权重矩阵的奇异向量，将动态完全简化为奇异值。

Result: 首次证明了在交叉熵损失下，梯度流会收敛到神经坍缩几何。尽管存在虚假临界点，但全局收敛性得到保证。Hadamard初始化的对角化特性为分析交叉熵训练动态开辟了新途径。

Conclusion: 交叉熵损失与平方损失产生根本不同的动态，本文首次在非凸设置下严格分析了交叉熵优化动态，证明了神经坍缩几何的收敛性，并提供了分析交叉熵训练动态的新技术框架。

Abstract: Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.

</details>


### [105] [SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening](https://arxiv.org/abs/2512.03471)
*Ian Henriques,Lynda Elhassar,Sarvesh Relekar,Denis Walrave,Shayan Hassantabar,Vishu Ghanakota,Adel Laoui,Mahmoud Aich,Rafia Tir,Mohamed Zerguine,Samir Louafi,Moncef Kimouche,Emmanuel Cosson,Niraj K Jha*

Main category: cs.LG

TL;DR: SweetDeep是一个轻量级神经网络，利用三星Galaxy Watch 7采集的生理和人口统计数据，在自由生活条件下实现82.5%的2型糖尿病检测准确率。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病全球发病率上升，需要可扩展且经济高效的筛查方法。现有生化检测方法具有侵入性和成本高的缺点，而基于可穿戴设备的机器学习检测方法先前研究仅限于受控环境。

Method: 开发了参数少于3000的紧凑神经网络SweetDeep，使用欧盟和中东地区285名参与者的生理和人口统计数据训练。数据通过三星Galaxy Watch 7在6天自由生活条件下采集，每人每天多个2分钟传感器记录，总计约20个记录/人。

Result: 在三折交叉验证下，SweetDeep达到82.5%患者级准确率（82.1%宏F1，79.7%灵敏度，84.6%特异性），预期校准误差5.5%。在放弃不到10%低置信度预测后，剩余患者准确率达84.5%。

Conclusion: 工程特征与轻量级架构结合可在真实世界可穿戴设备设置中实现准确、快速且可泛化的2型糖尿病检测，为可扩展的糖尿病筛查提供了有前景的解决方案。

Abstract: The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.

</details>


### [106] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 提出一种离散更新规则的低精度训练方法，避免连续更新的量化，为具有离散结构的模型提供高效训练新途径


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要巨大的计算资源，低精度训练成为研究热点。传统的量化训练通常依赖于离散化实值更新，本文提出一种替代方法

Method: 引入离散更新规则本身的方法，避免通过设计来量化连续更新。建立此类离散方案的收敛保证，并提出多项式更新规则作为具体示例

Result: 建立了离散更新方案的收敛理论保证，并通过实证评估支持了多项式更新规则的有效性

Conclusion: 这种离散视角为高效训练开辟了新途径，特别适用于具有固有离散结构的模型，提供了一种避免连续更新量化的替代方案

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [107] [Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data](https://arxiv.org/abs/2512.03114)
*Srijani Mukherjee,Laurent Vuillon,Liliane Bou Nassif,Stéphanie Giroux-Julien,Hervé Pabiou,Denys Dutykh,Ionnasis Tsanakas*

Main category: cs.LG

TL;DR: 提出基于时序图神经网络的新方法，利用环境与运行参数预测光伏输出功率并检测异常


<details>
  <summary>Details</summary>
Motivation: 光伏系统快速增长需要先进的性能监测和异常检测方法以确保最佳运行

Method: 使用时序图神经网络，基于关键参数（辐照度、模块温度、环境温度）之间的图结构时序关系来预测电功率输出

Result: 基于法国里昂屋顶户外设施收集的数据，包括光伏模块功率测量和气象参数

Conclusion: 提出了一种创新的时序图神经网络方法，能够有效预测光伏输出功率并检测异常，有助于光伏系统性能监测

Abstract: The rapid growth of solar photovoltaic (PV) systems necessitates advanced methods for performance monitoring and anomaly detection to ensure optimal operation. In this study, we propose a novel approach leveraging Temporal Graph Neural Network (Temporal GNN) to predict solar PV output power and detect anomalies using environmental and operational parameters. The proposed model utilizes graph-based temporal relationships among key PV system parameters, including irradiance, module and ambient temperature to predict electrical power output. This study is based on data collected from an outdoor facility located on a rooftop in Lyon (France) including power measurements from a PV module and meteorological parameters.

</details>


### [108] [Real-Time Structural Health Monitoring with Bayesian Neural Networks: Distinguishing Aleatoric and Epistemic Uncertainty for Digital Twin Frameworks](https://arxiv.org/abs/2512.03115)
*Hanbin Cho,Jecheon Yu,Hyeonbin Moon,Jiyoung Yoon,Junhyeong Lee,Giyoung Kim,Jinhyoung Park,Seunghwa Ryu*

Main category: cs.LG

TL;DR: 提出一个结合PCA、贝叶斯神经网络和哈密顿蒙特卡洛的结构健康监测框架，能从稀疏应变测量重建全场应变分布并量化不确定性，在含裂纹的CFRP试件上验证有效。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需要实时分析传感器数据，但现有方法难以获得空间分辨的全场随机和认知不确定性，限制了可靠决策制定。

Method: 集成框架结合主成分分析(PCA)、贝叶斯神经网络(BNN)和哈密顿蒙特卡洛(HMC)推理，将稀疏应变计测量映射到主要PCA模式，重建全场应变分布并量化不确定性。

Result: 在含不同裂纹长度的碳纤维增强聚合物试件上进行循环四点弯曲测试验证，实现了准确的应变场重建(R平方值>0.9)，同时能实时生成不确定性场。

Conclusion: 该框架能处理含裂纹引起的应变奇异性的噪声实验数据，提供两种互补的不确定性场，支持局部诊断和可靠决策，推动结构健康监测向可信数字孪生部署发展。

Abstract: Reliable real-time analysis of sensor data is essential for structural health monitoring (SHM) of high-value assets, yet a major challenge is to obtain spatially resolved full-field aleatoric and epistemic uncertainties for trustworthy decision-making. We present an integrated SHM framework that combines principal component analysis (PCA), a Bayesian neural network (BNN), and Hamiltonian Monte Carlo (HMC) inference, mapping sparse strain gauge measurements onto leading PCA modes to reconstruct full-field strain distributions with uncertainty quantification. The framework was validated through cyclic four-point bending tests on carbon fiber reinforced polymer (CFRP) specimens with varying crack lengths, achieving accurate strain field reconstruction (R squared value > 0.9) while simultaneously producing real-time uncertainty fields. A key contribution is that the BNN yields robust full-field strain reconstructions from noisy experimental data with crack-induced strain singularities, while also providing explicit representations of two complementary uncertainty fields. Considered jointly in full-field form, the aleatoric and epistemic uncertainty fields make it possible to diagnose at a local level, whether low-confidence regions are driven by data-inherent issues or by model-related limitations, thereby supporting reliable decision-making. Collectively, the results demonstrate that the proposed framework advances SHM toward trustworthy digital twin deployment and risk-aware structural diagnostics.

</details>


### [109] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: 提出MoDE架构解决统一多模态生成模型中的模态间遗忘问题，通过解耦模态特定更新和知识蒸馏来缓解梯度冲突和灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型在持续学习新任务时面临严重的灾难性遗忘问题，不仅存在于模态内，还存在于模态间。虽然模态内遗忘已有研究，但模态间遗忘尚未被充分探索，本文旨在识别并解决这一问题

Method: 提出模态解耦专家架构，通过隔离模态特定更新来缓解梯度冲突，并利用知识蒸馏防止灾难性遗忘和保持预训练能力。与之前保持模态耦合的方法不同，MoDE显式解耦模态以防止干扰

Result: 在多样化基准测试中，MoDE显著缓解了模态间和模态内遗忘，在统一多模态生成设置中优于先前的持续学习基线方法

Conclusion: MoDE架构通过解耦模态特定更新有效解决了统一多模态生成模型中的模态间遗忘问题，为多模态持续学习提供了轻量级且可扩展的解决方案

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [110] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR：首个端到端框架，仅从1D NMR谱和化学式直接预测未知分子结构，在天然产物结构解析中达到超过65%的准确率


<details>
  <summary>Details</summary>
Motivation: NMR谱解析是确定小分子结构的关键技术，但当前仍需要大量领域专家进行耗时的手动分析。特别是在天然产物和临床治疗药物发现中，自动化结构解析是一个重大挑战

Method: 将结构解析构建为条件生成问题，采用基于非等变transformer架构的原子扩散模型。创建了包含超过111,000个天然产物的模拟1D NMR谱数据集来训练模型

Result: ChefNMR在挑战性天然产物化合物结构预测中达到了超过65%的准确率，超越了现有方法。代码已在GitHub开源

Conclusion: 该研究在自动化小分子结构解析这一重大挑战上迈出了重要一步，展示了深度学习在加速分子发现方面的潜力

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [111] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 提出基于VQ-VAE的无监督病毒变异检测框架，用于废水基因组监测，无需参考基因组或变异标签，在SARS-CoV-2废水测序数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 废水基因组监测面临高测序噪声、低病毒覆盖率、片段化读取和缺乏标注变异注释等挑战，传统基于参考的变异检测方法难以处理新突变且计算资源需求大。

Method: 使用向量量化变分自编码器（VQ-VAE）从k-mer标记化序列中学习基因组模式的离散码本，无需参考基因组或变异标签。扩展基础架构，加入掩码重建预训练以增强对缺失数据的鲁棒性，以及对比学习以获得高判别性嵌入。

Result: 在约10万条SARS-CoV-2废水测序数据上，VQ-VAE达到99.52%的平均标记级准确率和56.33%的精确序列匹配率，码本利用率为19.73%（512个码中101个活跃）。对比微调显著改善聚类效果：64维嵌入使轮廓系数提高35%（0.31到0.42），128维嵌入提高42%（0.31到0.44）。

Conclusion: 该无参考框架为基因组监测提供了可扩展、可解释的方法，可直接应用于公共卫生监测，展示了嵌入维度对变异判别能力的重要影响。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [112] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 提出交错推理（IR）和Plantain方法，让语言模型在推理过程中交替输出中间结果，减少用户等待时间并允许早期干预，相比传统"先思考后回答"方法提升6%准确率并减少60%首次响应时间。


<details>
  <summary>Details</summary>
Motivation: 传统推理模型在生成最终答案前需要长时间"思考"，期间不给用户任何提示，导致用户无法判断推理是否正确或及时纠正错误前提，浪费用户时间。相比之下，人类对话中会通过轻量级、增量的确认行为确保双方理解一致。

Method: 提出交错推理（IR）方法，模型在推理过程中交替输出中间结果，而不是完全思考后再回答。进一步提出Plantain（计划-思考-答案交错）方法，首先生成明确的逐步执行计划，然后交替进行思考和回答，允许用户早期干预和反馈。

Result: 在多个具有挑战性的数学推理和编程基准测试中，Plantain方法相比传统"先思考后回答"基线，pass@1准确率提升约6%，同时首次响应时间减少超过60%。

Conclusion: 交错推理方法能够显著改善用户体验，减少感知延迟，同时提升最终答案质量。通过允许用户早期干预，模型可以避免基于错误前提的推理，实现更高效的人机协作。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [113] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1 是一种基于草图技术的异常检测算法，用于快速识别大规模单细胞RNA测序数据中的稀有细胞亚群；Enhash 是一种快速且资源高效的集成学习器，使用投影哈希检测流数据中的概念漂移。


<details>
  <summary>Details</summary>
Motivation: 需要在大规模单细胞RNA测序数据中快速识别稀有细胞亚群，以及在流数据中高效检测概念漂移。

Method: FiRE/FiRE.1 采用基于草图的异常检测算法；Enhash 使用投影哈希的集成学习方法。

Result: FiRE/FiRE.1 在性能上优于现有最先进技术；Enhash 在各种漂移类型中在时间和准确性方面表现出高度竞争力。

Conclusion: 该研究提出了两种高效算法：FiRE/FiRE.1 用于单细胞数据分析，Enhash 用于流数据概念漂移检测，两者都表现出优越性能。

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [114] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出了几种改进算法，用于在无限时域设置中学习具有记忆的策略，包括在环境模型已知时直接学习，以及通过模拟学习，并在大型POMDP问题上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法在部分可观测环境中学习行动机制方面受到关注，但在需要记忆的问题上表现不佳。本文旨在改进具有记忆的策略学习算法。

Method: 开发了几种改进算法：在环境模型已知时直接学习具有记忆的策略；通过模拟学习具有记忆的策略。在无限时域设置中实现。

Result: 在大型POMDP问题上进行了比较测试，包括噪声机器人导航和多智能体问题，验证了算法的有效性。

Conclusion: 提出的改进算法能够有效学习具有记忆的策略，解决了策略梯度方法在需要记忆的问题上的局限性，为部分可观测环境中的强化学习提供了更好的解决方案。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [115] [A Multi-Agent, Policy-Gradient approach to Network Routing](https://arxiv.org/abs/2512.03211)
*Nigel Tao,Jonathan Baxter,Lex Weaver*

Main category: cs.LG

TL;DR: OLPOMDP强化学习算法成功应用于模拟网络路由，多个分布式路由器代理学习协作行为，无需显式通信，避免个体最优但群体有害的行为，通过奖励塑形显著提升收敛速度。


<details>
  <summary>Details</summary>
Motivation: 网络路由是一个分布式决策问题，具有数值性能度量（如平均传输时间）。需要探索强化学习算法如何应用于网络路由，使分布式路由器能够学习协作行为，避免个体最优但群体有害的决策。

Method: 使用OLPOMDP（策略梯度强化学习算法），在多种网络模型下进行模拟网络路由实验。多个分布式代理（路由器）在没有显式通信的情况下学习协作行为，并通过奖励塑形技术（明确惩罚次优行为模式）来优化学习过程。

Result: OLPOMDP算法成功应用于网络路由，分布式路由器学会了协作行为，避免了仅对个体有利但对群体整体性能有害的行为。奖励塑形技术显著提高了算法的收敛速度。

Conclusion: OLPOMDP强化学习算法可以有效解决网络路由的分布式决策问题，使路由器能够学习协作行为，而奖励塑形是提升学习效率的关键技术。

Abstract: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.

</details>


### [116] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0生物声学基础模型在海洋哺乳动物分类任务中通过少样本迁移学习表现出色，优于其他预训练模型。


<details>
  <summary>Details</summary>
Motivation: 尽管Perch 2.0在训练数据中几乎不包含海洋哺乳动物音频，但研究者希望评估其在海洋哺乳动物和水下音频任务上的迁移学习能力，以验证该基础模型的泛化性能。

Method: 使用Perch 2.0生成的嵌入进行线性探测（linear probing），与其他预训练生物声学模型（包括Perch 1.0、SurfPerch、AVES-bio、BirdAVES、Birdnet V2.3等）进行少样本迁移学习性能比较。

Result: Perch 2.0的嵌入在少样本迁移学习中表现出持续的高性能，在大多数任务上优于其他嵌入模型，特别适合在只有少量标注样本的情况下开发新的海洋哺乳动物分类器。

Conclusion: Perch 2.0基础模型在海洋哺乳动物分类任务中具有优秀的迁移学习能力，推荐在只有少量标注数据的情况下使用该模型开发新的线性分类器。

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [117] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK框架通过三阶段方法：1) 生成多样解并用验证器评估，2) 用验证输出训练生成式过程奖励模型，3) 将PRM-CoT作为RL奖励模型，在数学推理任务上超越基于真实结果的监督方法。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型(PRMs)需要昂贵的步骤级标注或真实参考，限制了其应用。作者希望开发无需真实参考的RL训练方法，在缺乏可验证答案或真实数据的领域实现超越真实监督的性能。

Method: 三阶段框架：第一阶段，生成器产生多样解，验证器通过并行扩展(自一致性)和序列扩展(元批判)进行评估；第二阶段，用验证输出作为合成训练数据微调生成式过程奖励模型；第三阶段，将PRM-CoT作为RL奖励模型，并引入格式约束防止奖励黑客攻击。

Result: 在ProcessBench上达到67.5 F1，优于参考指导训练的66.4和GPT-4o的61.9；使用Qwen2.5-Math-7B在六个数学推理基准上平均准确率达到47.4%，超越基于真实结果的RLVR(43.9%)。

Conclusion: SPARK框架实现了无需真实参考的RL训练，性能超越基于真实结果的方法，为缺乏可验证答案或真实数据的领域开辟了新可能性。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [118] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 研究发现视觉语言模型在事实回忆任务上表现下降，主要原因是实体表示形成过晚，无法有效利用LLM已有的知识回忆机制。


<details>
  <summary>Details</summary>
Motivation: 许多视觉语言模型在事实回忆性能上比其LLM主干模型表现更差，这引发了对多模态微调在扩展LLM机制到视觉输入方面有效性的质疑。

Method: 对14个不同架构、规模和训练设置的VLM进行基准测试，使用归因修补、激活修补和探测技术分析性能差异，并尝试两种性能恢复方法。

Result: 14个模型中有11个表现出事实回忆性能下降，性能差的VLM因为实体表示形成过晚而无法利用LLM已有的知识回忆机制，而高性能VLM能早期形成实体表示。

Conclusion: 早期实体表示形成的速度是VLM能否有效利用预训练LLM机制的关键因素，机制分析可以解释多模态对齐中的系统性失败。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [119] [BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark](https://arxiv.org/abs/2512.03280)
*Nicholas Sung,Steven Spreizer,Mohamed Elrefaie,Matthew C. Jones,Faez Ahmed*

Main category: cs.LG

TL;DR: BlendedNet++是一个大型空气动力学数据集和基准测试，专注于翼身融合飞机，包含12,000多个几何形状的CFD模拟结果，提供集成系数和密集表面场数据，并建立了前向代理预测和逆向设计任务的统一基准。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习空气动力学代理模型的进展受到大规模、场解析数据集稀缺的限制，这阻碍了点态预测准确性和可重复逆向设计的进展。需要标准化的数据集和基准来促进该领域的研究。

Method: 创建了包含12,000多个独特几何形状的BlendedNet++数据集，每个几何在单一飞行条件下进行稳态RANS CFD模拟。建立了前向代理基准测试，评估六种模型架构的点态场预测能力，并设计了基于条件扩散模型的逆向设计任务，与梯度优化和混合方法进行比较。

Result: 提供了包含12,490个空气动力学结果的大型数据集，包含集成力/力矩系数和密集表面场数据。建立了统一的前向和逆向协议，提供了多模型基线，实现了跨架构和优化范式的公平、可重复比较。

Conclusion: BlendedNet++为场级空气动力学和逆向设计提供了可重复研究的统一平台，预计将催化该领域的研究进展。数据集、分割、基线和脚本将在论文接受后发布。

Abstract: Despite progress in machine learning-based aerodynamic surrogates, the scarcity of large, field-resolved datasets limits progress on accurate pointwise prediction and reproducible inverse design for aircraft. We introduce BlendedNet++, a large-scale aerodynamic dataset and benchmark focused on blended wing body (BWB) aircraft. The dataset contains over 12,000 unique geometries, each simulated at a single flight condition, yielding 12,490 aerodynamic results for steady RANS CFD. For every case, we provide (i) integrated force/moment coefficients CL, CD, CM and (ii) dense surface fields of pressure and skin friction coefficients Cp and (Cfx, Cfy, Cfz). Using this dataset, we standardize a forward-surrogate benchmark to predict pointwise fields across six model families: GraphSAGE, GraphUNet, PointNet, a coordinate Transformer (Transolver-style), a FiLMNet (coordinate MLP with feature-wise modulation), and a Graph Neural Operator Transformer (GNOT). Finally, we present an inverse design task of achieving a specified lift-to-drag ratio under fixed flight conditions, implemented via a conditional diffusion model. To assess performance, we benchmark this approach against gradient-based optimization on the same surrogate and a diffusion-optimization hybrid that first samples with the conditional diffusion model and then further optimizes the designs. BlendedNet++ provides a unified forward and inverse protocol with multi-model baselines, enabling fair, reproducible comparison across architectures and optimization paradigms. We expect BlendedNet++ to catalyze reproducible research in field-level aerodynamics and inverse design; resources (dataset, splits, baselines, and scripts) will be released upon acceptance.

</details>


### [120] [Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors](https://arxiv.org/abs/2512.03287)
*Dario Fenoglio,Mohan Li,Davide Casnici,Matias Laporte,Shkurta Gashi,Silvia Santini,Martin Gjoreski,Marc Langheinrich*

Main category: cs.LG

TL;DR: 提出多频联邦学习用于头戴式设备的人体活动识别，解决隐私问题和设备采样频率差异


<details>
  <summary>Details</summary>
Motivation: 传统HAR需要集中上传用户数据，存在隐私风险；头戴式设备相比智能手表/手机研究较少；不同设备采样频率不同，需要统一学习框架

Method: 采用多频联邦学习框架，支持隐私保护机器学习，并能在不同采样频率的设备间进行联合模型学习

Result: 在两个数据集上相比频率特定方法有所改进，表明多频FL-HAR任务具有前景

Conclusion: 多频联邦学习是头戴式设备HAR的有效方法，既能保护隐私又能处理设备频率差异，网络实现已公开供研究使用

Abstract: Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.

</details>


### [121] [ASPEN: An Adaptive Spectral Physics-Enabled Network for Ginzburg-Landau Dynamics](https://arxiv.org/abs/2512.03290)
*Julian Evan Chrisnanto,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

TL;DR: ASPEN是一种新型PINN架构，通过自适应谱层和可学习傅里叶特征解决传统PINN在处理刚性、多尺度非线性系统时的频谱偏差问题，成功应用于复杂的Ginzburg-Landau方程。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在处理刚性、多尺度非线性偏微分方程时存在频谱偏差问题，无法充分表示高频分量，导致在复杂物理系统求解中失败。

Method: 提出自适应谱物理网络（ASPEN），在网络的输入阶段集成具有可学习傅里叶特征的自适应谱层，使模型能够在训练过程中动态调整其谱基，高效学习解所需的精确频率内容。

Result: 在复杂的Ginzburg-Landau方程上，传统PINN架构完全失败，而ASPEN成功求解，预测解与高分辨率真实解视觉上无法区分，达到5.10×10^-3的低中值物理残差，并能正确捕捉物理特性。

Conclusion: 通过引入自适应谱基，ASPEN为传统PINN失败的复杂动力系统提供了鲁棒且物理一致的求解器，为机器学习在挑战性物理领域开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful, mesh-free paradigm for solving partial differential equations (PDEs). However, they notoriously struggle with stiff, multi-scale, and nonlinear systems due to the inherent spectral bias of standard multilayer perceptron (MLP) architectures, which prevents them from adequately representing high-frequency components. In this work, we introduce the Adaptive Spectral Physics-Enabled Network (ASPEN), a novel architecture designed to overcome this critical limitation. ASPEN integrates an adaptive spectral layer with learnable Fourier features directly into the network's input stage. This mechanism allows the model to dynamically tune its own spectral basis during training, enabling it to efficiently learn and represent the precise frequency content required by the solution. We demonstrate the efficacy of ASPEN by applying it to the complex Ginzburg-Landau equation (CGLE), a canonical and challenging benchmark for nonlinear, stiff spatio-temporal dynamics. Our results show that a standard PINN architecture catastrophically fails on this problem, diverging into non-physical oscillations. In contrast, ASPEN successfully solves the CGLE with exceptional accuracy. The predicted solution is visually indistinguishable from the high-resolution ground truth, achieving a low median physics residual of 5.10 x 10^-3. Furthermore, we validate that ASPEN's solution is not only pointwise accurate but also physically consistent, correctly capturing emergent physical properties, including the rapid free energy relaxation and the long-term stability of the domain wall front. This work demonstrates that by incorporating an adaptive spectral basis, our framework provides a robust and physically-consistent solver for complex dynamical systems where standard PINNs fail, opening new options for machine learning in challenging physical domains.

</details>


### [122] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 将自适应共形推理（ACI）及其聚合变体（AgACI）与深度切换状态空间模型结合，为具有状态切换的时间序列提供分布无关的不确定性量化，并在各种序列模型上实现统一的共形包装器。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的状态切换会破坏平稳性，使得校准的不确定性与点预测精度同等重要。需要为具有状态切换的预测问题提供分布无关的不确定性量化方法。

Method: 1. 将深度切换状态空间模型与自适应共形推理（ACI）及其聚合变体（AgACI）结合；2. 提出统一的共形包装器，可应用于多种序列基线模型（S4、MC-Dropout GRU、稀疏高斯过程、变化点局部模型）；3. 在非平稳性和模型误设条件下提供在线预测区间。

Result: 在合成和真实数据集上，共形化预测器实现了接近名义水平的覆盖率，同时保持竞争性的预测精度，并且通常提高了区间效率。

Conclusion: 该方法为具有状态切换的时间序列预测提供了有效的分布无关不确定性量化，在各种模型上都能保证有限样本的边缘覆盖保证，适用于非平稳环境和模型误设情况。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [123] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: HydroDCM：一个用于跨水库流量预测的可扩展域泛化框架，通过空间元数据构建伪域标签指导对抗学习，并在推理时通过轻量级条件层适应目标水库特征


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在水库流量预测中表现良好，但在不同水库间应用时性能下降，存在域偏移问题。传统域泛化方法难以处理水文系统中每个水库独特的流量模式，且空间元数据等非观测信息对预测有间接但重要的影响

Method: 提出HydroDCM框架：1）利用水库空间元数据构建伪域标签指导对抗学习，提取域不变的时间特征；2）推理时通过轻量级条件层，根据目标水库的元数据自适应调整特征，平衡域泛化的不变性与位置特异性适应

Result: 在科罗拉多河上游流域30个真实水库上的实验表明，该方法在多域条件下显著优于最先进的域泛化基线方法，且保持计算高效

Conclusion: HydroDCM成功解决了水文系统中多域泛化问题，通过结合对抗学习和元数据条件适应，实现了跨水库流量预测的准确性和泛化能力

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [124] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: RTFM提出了一种对抗性训练框架，通过参数化生成器分布来强调对模型具有挑战性的合成数据集，从而提升表格基础模型的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型(TFMs)在结构化数据上显示出超越传统ML方法的潜力。现有研究主要关注设计高质量的数据生成器先验来提升预训练性能，但作者发现参数化生成器分布可以从对抗鲁棒性角度出发，在训练中强调对模型特别具有挑战性的数据集。

Method: 提出了RTFM（Robust Tabular Foundation Models）框架：1）引入最优性间隙度量，计算TFM性能与XGBoost、CatBoost、Random Forests等强基线最佳可达性能之间的差异；2）基于此度量，设计模型无关的对抗训练框架，在训练过程中调整生成器以强调对模型具有挑战性的数据集。

Result: 在TabPFN V2分类器上应用RTFM，相比原始TabPFN和其他基线算法，平均归一化AUC提升高达6%，且仅需不到10万个额外的合成数据集。

Conclusion: RTFM展示了仅使用合成数据进行针对性对抗训练和微调TFMs的新方向，为提升表格基础模型的鲁棒性和性能提供了有前景的方法。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [125] [Retrofitting Earth System Models with Cadence-Limited Neural Operator Updates](https://arxiv.org/abs/2512.03309)
*Aniruddha Bora,Shixuan Zhang,Khemraj Shukla,Bryce Harrop,George Em. Karniadakis,L. Ruby Leung*

Main category: cs.LG

TL;DR: 提出一种基于算子学习的框架，通过在线应用偏差修正趋势来改进地球系统模型预测，使用U-Net架构变体在多尺度特征提取方面优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 传统地球系统模型存在分辨率低、参数化不完善、初始状态和强迫不确定等问题，传统的数据同化偏差修正方法在模型自由运行时效果有限，需要一种能在模型集成过程中在线应用的偏差修正方法。

Method: 开发了基于U-Net的算子学习框架，包括Inception U-Net (IUNet)和多尺度网络(M&M)两种架构，结合多种上采样和感受野来捕获多尺度非线性特征。使用E3SM模型向ERA5再分析数据同化的两年模拟数据进行训练。

Result: 两种架构在离线测试中都优于标准U-Net基线，表明功能丰富性而非参数数量驱动性能。在线混合E3SM运行中，M&M在变量和垂直层次上提供最一致的偏差减少。ML增强配置在多年模拟中保持稳定且计算可行。

Conclusion: 该框架强调长期稳定性、可移植性和更新频率限制，展示了表达性ML算子在学习结构化跨尺度关系和改造传统ESM方面的实用性，为可扩展混合建模提供了实用途径。

Abstract: Coarse resolution, imperfect parameterizations, and uncertain initial states and forcings limit Earth-system model (ESM) predictions. Traditional bias correction via data assimilation improves constrained simulations but offers limited benefit once models run freely. We introduce an operator-learning framework that maps instantaneous model states to bias-correction tendencies and applies them online during integration. Building on a U-Net backbone, we develop two operator architectures Inception U-Net (IUNet) and a multi-scale network (M\&M) that combine diverse upsampling and receptive fields to capture multiscale nonlinear features under Energy Exascale Earth System Model (E3SM) runtime constraints. Trained on two years E3SM simulations nudged toward ERA5 reanalysis, the operators generalize across height levels and seasons. Both architectures outperform standard U-Net baselines in offline tests, indicating that functional richness rather than parameter count drives performance. In online hybrid E3SM runs, M\&M delivers the most consistent bias reductions across variables and vertical levels. The ML-augmented configurations remain stable and computationally feasible in multi-year simulations, providing a practical pathway for scalable hybrid modeling. Our framework emphasizes long-term stability, portability, and cadence-limited updates, demonstrating the utility of expressive ML operators for learning structured, cross-scale relationships and retrofitting legacy ESMs.

</details>


### [126] [Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs](https://arxiv.org/abs/2512.03324)
*Ngoc Bui,Shubham Sharma,Simran Lamba,Saumitra Mishra,Rex Ying*

Main category: cs.LG

TL;DR: TRIM-KV：一种通过轻量级保留门学习token内在重要性的方法，在内存受限时根据预测的保留分数淘汰不重要的token，实现高效的长序列LLM推理。


<details>
  <summary>Details</summary>
Motivation: 长序列LLM推理中，自注意力的二次计算成本和不断增长的KV缓存导致内存和计算瓶颈。现有方法（如量化、卸载或启发式KV淘汰）要么协调成本高，要么依赖不可靠的重要性代理。

Method: 提出TRIM-KV方法，通过轻量级保留门在token创建时学习其内在重要性。每个门预测一个随时间衰减的标量保留分数，反映token在特定层和注意力头中的长期效用。当内存预算超限时，淘汰低分token。

Result: 在数学推理、程序生成、对话长记忆和长上下文理解等多个基准测试中，TRIM-KV始终优于强淘汰和可学习检索基线，尤其在低内存场景下表现突出。在某些设置中甚至超越全缓存模型。

Conclusion: TRIM-KV不仅提高了推理效率，其学习到的保留分数还与人类直觉一致，自然地恢复了sink token、滑动窗口和要点压缩等启发式方法。保留分数还提供了层和头特定角色的洞察，为LLM可解释性开辟了新路径。

Abstract: Memory and computation remain core bottlenecks in long-horizon LLM inference due to the quadratic cost of self-attention and the ever-growing key-value (KV) cache. Existing strategies for memory-bounded inference, such as quantization, offloading, or heuristic KV eviction, either incur high orchestration costs or rely on unreliable attention-based proxies of importance. We propose TRIM-KV, a novel approach that learns each token's intrinsic importance at creation time via a lightweight retention gate. Each gate predicts a scalar retention score that decays over time, reflecting the long-term utility of the token for a specific layer and head. Tokens with low scores are evicted when the memory budget is exceeded, ensuring that the cache always contains the most critical tokens. TRIM-KV is trained efficiently through distillation from a frozen LLM combined with a capacity loss, requiring only gate fine-tuning and adding negligible inference overhead. Across mathematical reasoning (GSM8K, MATH-500, AIME24), procedural generation (LongProc), conversational long-memory benchmarks (LongMemEval), and long-context understanding (LongBench and SCBench), TRIM-KV consistently outperforms strong eviction and learnable retrieval baselines, especially in low-memory regimes. Remarkably, it even surpasses full-cache models in some settings, showing that selective retention can serve as a form of regularization, suppressing noise from uninformative tokens. Qualitative analyses further reveal that learned retention scores align with human intuition, naturally recovering heuristics such as sink tokens, sliding windows, and gist compression without explicit design. Beyond efficiency, retention scores provide insights into layer- and head-specific roles, suggesting a new path toward LLM interpretability.

</details>


### [127] [A2G-QFL: Adaptive Aggregation with Two Gains in Quantum Federated learning](https://arxiv.org/abs/2512.03363)
*Shanika Iroshi Nanayakkara,Shiva Raj Pokhrel*

Main category: cs.LG

TL;DR: 提出A2G框架，通过几何增益和QoS增益自适应聚合量子联邦学习中的客户端模型，解决异构网络下的性能退化问题


<details>
  <summary>Details</summary>
Motivation: 量子增强的异构经典网络中的联邦学习面临客户端质量不均、量子隐形传态保真度随机、设备不稳定以及局部与全局模型几何不匹配等问题，传统基于欧几里得拓扑和均匀通信可靠性的聚合规则不适用于新兴量子联邦系统

Method: 提出A2G（自适应双增益聚合）框架，包含几何增益（调节几何混合）和QoS增益（基于隐形传态保真度、延迟和不稳定性调节客户端重要性），开发A2G更新规则，并在平滑性和有界方差假设下建立收敛保证

Result: A2G在量子经典混合测试平台上表现出更好的稳定性和更高的准确性，特别是在异构和噪声条件下，且能恢复FedAvg、QoS感知平均和基于流形的聚合作为特例

Conclusion: A2G框架有效解决了量子联邦学习中的异构网络挑战，通过双增益机制自适应调节聚合过程，为量子增强的联邦学习系统提供了更鲁棒的解决方案

Abstract: Federated learning (FL) deployed over quantum enabled and heterogeneous classical networks faces significant performance degradation due to uneven client quality, stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models. Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their suitability for emerging quantum federated systems. This paper introduces A2G (Adaptive Aggregation with Two Gains), a dual gain framework that jointly regulates geometric blending through a geometry gain and modulates client importance using a QoS gain derived from teleportation fidelity, latency, and instability. We develop the A2G update rule, establish convergence guarantees under smoothness and bounded variance assumptions, and show that A2G recovers FedAvg, QoS aware averaging, and manifold based aggregation as special cases. Experiments on a quantum classical hybrid testbed demonstrate improved stability and higher accuracy under heterogeneous and noisy conditions.

</details>


### [128] [MAGE-ID: A Multimodal Generative Framework for Intrusion Detection Systems](https://arxiv.org/abs/2512.03375)
*Mahdi Arab Loodaricheh,Mohammad Hossein Manshaei,Anita Raja*

Main category: cs.LG

TL;DR: MAGE-ID是一个基于扩散的多模态攻击生成框架，通过统一的潜在先验耦合表格流量特征及其转换图像，用于入侵检测系统的数据增强。


<details>
  <summary>Details</summary>
Motivation: 现代入侵检测系统面临异构网络流量、不断演变的网络威胁以及良性流量与攻击流量之间严重数据不平衡的挑战。现有生成方法仅限于单模态，无法捕捉跨域依赖关系。

Method: 提出MAGE-ID框架，结合Transformer和CNN变分编码器与EDM风格去噪器，联合训练表格流量特征及其转换图像，实现平衡且连贯的多模态合成。

Result: 在CIC-IDS-2017和NSL-KDD数据集上的评估显示，MAGE-ID在保真度、多样性和下游检测性能方面显著优于TabSyn和TabDDPM。

Conclusion: MAGE-ID证明了多模态数据增强在入侵检测中的有效性，能够生成平衡且连贯的多模态合成数据，提升检测性能。

Abstract: Modern Intrusion Detection Systems (IDS) face severe challenges due to heterogeneous network traffic, evolving cyber threats, and pronounced data imbalance between benign and attack flows. While generative models have shown promise in data augmentation, existing approaches are limited to single modalities and fail to capture cross-domain dependencies. This paper introduces MAGE-ID (Multimodal Attack Generator for Intrusion Detection), a diffusion-based generative framework that couples tabular flow features with their transformed images through a unified latent prior. By jointly training Transformer and CNN-based variational encoders with an EDM style denoiser, MAGE-ID achieves balanced and coherent multimodal synthesis. Evaluations on CIC-IDS-2017 and NSL-KDD demonstrate significant improvements in fidelity, diversity, and downstream detection performance over TabSyn and TabDDPM, highlighting the effectiveness of MAGE-ID for multimodal IDS augmentation.

</details>


### [129] [UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs](https://arxiv.org/abs/2512.03383)
*Hung-Yueh Chiang,Chi-Chih Chang,Yu-Chen Lu,Chien-Yu Lin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu*

Main category: cs.LG

TL;DR: UniQL是一个统一的边缘LLM后训练量化和低秩压缩框架，支持在设备上配置剪枝率，实现4-5.7倍内存减少和2.7-3.4倍吞吐提升，精度损失在5%以内。


<details>
  <summary>Details</summary>
Motivation: 在移动平台上部署大语言模型面临内存有限和计算资源共享的挑战，设备工作负载直接影响资源可用性，增加了模型部署的不确定性。

Method: 提出统一的后训练量化和低秩压缩框架，包含高效结构化权重排序（加速20倍）、量化感知SVD、SSM状态感知权重排序、剪枝模型融合RoPE内核，支持Transformers、SSMs和混合模型。

Result: 量化剪枝模型实现4-5.7倍内存减少和2.7-3.4倍token吞吐提升，在15%剪枝率下精度损失在5%以内，支持Llama3、Qwen2.5、Mamba2、Nemotron-H和Bamba-v2等模型。

Conclusion: UniQL为边缘LLM部署提供高效解决方案，通过云上单次工作流完成权重排序、微调和量化，支持设备端配置剪枝率，显著降低资源需求同时保持模型精度。

Abstract: Deploying large language model (LLM) models on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework with on-device configurable pruning rates for edge LLMs. UniQL is a general framework that integrates quantization and low-rank compression for Transformers, State Space Models (SSMs), and hybrid models to support diverse edge applications. In our proposed joint framework, we introduce an efficient structured weight-sorting method that speeds up computation by 20x, quantization-aware singular value decomposition (SVD) to minimize quantization errors, state-aware weight sorting for SSMs, and a fused rotary positional embedding (RoPE) kernel for pruned models. Our framework performs weight-sorting, fine-tuning, and quantization in the cloud in a single-pass workflow, while enabling on-device configurable pruning rates up to 35%. Our experiments show that quantized and pruned models achieve a memory reduction of 4x-5.7x and a token-throughput improvement of 2.7x-3.4x, maintaining accuracy within 5% of the original models at 15% pruning across Transformers (Llama3 and Qwen2.5), SSMs (Mamba2), and hybrid models (Nemotron-H and Bamba-v2). The code and quantized models are available at: https://github.com/enyac-group/UniQL.

</details>


### [130] [VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing](https://arxiv.org/abs/2512.03394)
*Hamed Poursiami,Shay Snyder,Guojing Cong,Thomas Potok,Maryam Parsa*

Main category: cs.LG

TL;DR: VS-Graph：一种基于向量符号架构的图学习框架，通过尖峰扩散机制和关联消息传递，在保持超维计算效率的同时达到接近图神经网络的性能表现。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）在图分类任务中表现出色但计算成本高，限制了其在资源受限设备上的应用。超维计算（HDC）虽然轻量但性能通常不如GNNs。需要一种既能保持HDC效率又能接近GNNs表达能力的方法。

Method: VS-Graph框架包含两个核心组件：1）尖峰扩散机制用于拓扑驱动的节点识别；2）关联消息传递方案用于在高维向量空间内进行多跳邻域聚合。整个方法无需梯度优化或反向传播。

Result: 在MUTAG和DD等标准基准测试中，VS-Graph比之前的HDC基线性能提升4-5%，与现代GNNs竞争，并在多个数据集上匹配或超越GNN基线。训练速度提升高达450倍，即使在超向量维度降至D=128时仍保持高精度。

Conclusion: VS-Graph成功缩小了HDC效率与消息传递表达能力之间的差距，为在边缘和神经形态硬件上实现超高效执行铺平了道路，展示了在保持高性能的同时大幅降低计算成本的潜力。

Abstract: Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.

</details>


### [131] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: 论文提出需要"全栈对齐"——同时对齐AI系统及其所在机构与人类价值观，而非仅对齐单个AI与操作者意图。现有价值表示方法存在局限，需要"厚价值模型"来结构化表示价值观和规范。


<details>
  <summary>Details</summary>
Motivation: 仅将AI系统与操作者意图对齐不足以保证有益的社会结果，因为机构目标可能与其他机构和个人目标不一致。需要解决AI系统、机构与人类价值观的整体对齐问题。

Method: 提出"厚价值模型"方法，结构化表示价值观和规范，使系统能够区分持久价值观与短暂偏好，建模个体选择的社会嵌入性，并在新领域进行规范性推理。

Result: 在五个领域展示了该方法的应用：AI价值管理、规范性能力代理、双赢谈判系统、意义保持的经济机制、民主监管机构。

Conclusion: 需要全栈对齐和厚价值模型来有效解决AI与人类价值观的对齐问题，避免仅依赖效用函数、偏好排序或无结构文本等传统方法的局限性。

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [132] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 研究显式世界建模目标如何影响Transformer在不同训练阶段的内部表示和下游能力，发现显式世界建模能产生更线性可解码和因果可控的状态表示，并提升强化学习后训练效果


<details>
  <summary>Details</summary>
Motivation: 探索显式世界建模目标对Transformer内部表示和下游能力的影响，特别是在不同训练阶段如何影响模型的潜在表示和强化学习后训练效果

Method: 使用2x2x2魔方作为测试环境，比较标准下一个token预测与两种显式世界建模策略：(i)状态预测预训练，(ii)状态预测+下一个token联合目标；使用GRPO进行后训练，通过线性探测和因果干预评估表示质量

Result: 显式世界建模产生更线性可解码和因果可控的状态表示；改进的状态表示能显著提升GRPO后训练效果，特别是在更难的魔方状态上

Conclusion: 锐化状态表示可以提升序列规划任务的后训练效果，显式世界建模有助于改善Transformer的内部表示和下游任务性能

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [133] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 研究发现，在模型完成"顿悟"（grokking）阶段后应用机器遗忘方法，比在早期训练阶段应用更有效，能实现更高效的遗忘、更少的副作用和更稳定的更新。


<details>
  <summary>Details</summary>
Motivation: 探索"顿悟"（延迟泛化现象）是否有助于机器遗忘任务，即在不完全重新训练的情况下移除特定数据的影响。

Method: 在视觉（CNN/ResNet在CIFAR、SVHN、ImageNet）和语言（transformer在TOFU风格设置）任务上，比较在顿悟前后应用标准遗忘方法的效果。

Result: 从顿悟后检查点开始遗忘：(1) 遗忘效率更高（达到目标遗忘水平所需更新更少）；(2) 附带损害更小（保留数据和测试性能下降更少）；(3) 不同种子间更新更稳定。

Conclusion: 顿悟后模型学习到更模块化的表示，减少了遗忘子集和保留子集之间的梯度对齐，有利于选择性遗忘。模型训练时机（顿悟前后）是改进现有遗忘方法的正交杠杆。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [134] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 本文提出了一种用于金融情感分析的端到端深度学习框架，通过跨模态注意力机制整合时效性意见和流行性意见两种模态，显著提升了情感分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析方法难以有效整合多样化的意见模态并捕捉模态间的细粒度交互，而时效性意见（近期市场更新）和流行性意见（趋势性集体情感）代表了不同的信息渠道，需要专门的方法来融合这两种关键模态。

Method: 提出端到端深度学习框架：1) 使用BERT（Chinese-wwm-ext）进行特征嵌入；2) 设计金融多头跨注意力机制（FMHCA）促进两种意见模态间的信息交换；3) 通过Transformer层优化特征；4) 使用多模态因子双线性池化进行特征融合；5) 分类为负面、中性和正面情感。

Result: 在涵盖837家公司的综合数据集上进行实验，该方法达到83.5%的准确率，显著优于BERT+Transformer等基线方法（提升21%）。

Conclusion: 该框架通过有效整合时效性和流行性两种金融意见模态，显著提升了金融情感分析的准确性，具有支持更准确金融决策和风险管理的潜力。

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [135] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 本文提出了一种新的贝叶斯亚型事件模型（BEBMS），在多种模拟数据实验中显著优于现有的SuStaIn方法，并在阿尔茨海默病真实数据上得到更符合科学共识的结果。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病在不同患者中的进展方式存在差异，通常存在少量亚型。现有的SuStaIn方法虽然广泛应用，但其鲁棒性需要验证。本文旨在开发更稳健的贝叶斯亚型事件模型，并与SuStaIn进行系统比较。

Method: 开发了基于贝叶斯框架的亚型事件模型（BEBMS），通过合成数据实验在不同程度的模型误设条件下与SuStaIn进行比较，评估排序、分期和亚型分配性能。最后在真实阿尔茨海默病数据集上应用两种方法。

Result: BEBMS在排序、分期和亚型分配任务上均显著优于SuStaIn。在阿尔茨海默病数据应用中，BEBMS的结果更符合该疾病进展的科学共识。

Conclusion: BEBMS作为SuStaIn的贝叶斯改进版本，在疾病亚型分析中表现出更好的鲁棒性和准确性，为疾病进展建模提供了更可靠的工具。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [136] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: JPM是一个概率框架，用于从横断面数据推断混合神经退行性疾病的联合进展，通过将单病轨迹视为部分排序并构建联合进展先验，相比传统单病EBM提高了排序准确性。


<details>
  <summary>Details</summary>
Motivation: 传统事件模型（EBM）假设每个个体只有单一疾病，但神经退行性疾病中混合病理很常见。需要开发能够处理多种疾病同时进展的模型。

Method: 提出联合进展模型（JPM），将单病轨迹视为部分排序，构建联合进展先验。研究了四种变体：Pairwise、Bradley-Terry、Plackett-Luce和Mallows，分析了校准性、分离性和锐度三个特性。

Result: 所有JPM变体都具有校准性，分离性接近完美；锐度因变体而异，可由输入部分排序的简单特征预测。在合成实验中，JPM比强基线SA-EBM提高约21%的排序准确性。在NACC数据中，Mallows变体和SA-EBM的结果与AD和VaD混合病理进展的现有文献更一致。

Conclusion: JPM为从横断面数据推断混合神经退行性疾病的联合进展提供了一个有效的概率框架，相比传统单病EBM显著提高了准确性，其中Mallows变体在真实数据中表现最佳。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [137] [ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms](https://arxiv.org/abs/2512.03476)
*Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis*

Main category: cs.LG

TL;DR: ATHENA是一个自主实验室框架，通过知识驱动的诊断过程（HENA循环）管理端到端计算研究生命周期，在科学计算和科学机器学习中实现超人类性能，达到10^-14的验证误差。


<details>
  <summary>Details</summary>
Motivation: 解决科学计算和科学机器学习中理论概念化与计算实现之间的差距，这是当前研究的主要瓶颈。现有方法缺乏系统性的端到端管理能力，无法自主处理复杂的科学问题。

Method: 基于上下文多臂老虎机问题构建HENA循环（知识驱动的诊断过程），作为在线学习系统分析先前试验，从组合空间中选择结构动作，通过专家蓝图指导转换为可执行代码生成科学奖励。结合混合符号-数值工作流，支持"人在回路"协作干预。

Result: 在科学计算中自主识别数学对称性获得精确解析解，在基础模型失败时推导稳定数值求解器；在科学机器学习中解决不适定问题，结合PINN与FEM等多物理场问题。达到10^-14的验证误差，通过人工干预可将结果提升一个数量级。

Conclusion: ATHENA实现了从实现机制到方法创新的范式转变，超越了标准自动化，通过自主诊断和协作干预加速科学发现，展示了超人类性能的计算研究能力。

Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

</details>


### [138] [Physics-Driven Learning Framework for Tomographic Tactile Sensing](https://arxiv.org/abs/2512.03512)
*Xuanxuan Yang,Xiuyang Zhang,Haofeng Chen,Gang Ma,Xiaojie Wang*

Main category: cs.LG

TL;DR: PhyDNN：一种物理驱动的深度学习框架，通过将EIT正向模型嵌入学习目标，解决了电阻抗断层扫描中非线性逆问题导致的伪影和重建不准确问题，显著提升了触觉传感的重建质量。


<details>
  <summary>Details</summary>
Motivation: 电阻抗断层扫描（EIT）因其布线简单和形状灵活而成为大面积触觉传感的理想方案，但其非线性逆问题常导致严重伪影和不准确的重建结果。现有方法在物理合理性和泛化能力方面存在局限。

Method: 提出PhyDNN框架，将EIT正向模型直接嵌入学习目标，联合最小化预测与真实电导率图的差异，并强制与正向偏微分方程的一致性。设计了可微分的正向算子网络来近似非线性EIT响应，实现高效的物理引导训练。

Result: 在16电极软传感器上的仿真和实际触觉实验表明，PhyDNN在重建接触形状、位置和压力分布方面始终优于NOSER、TV和标准DNN方法，产生更少伪影、更清晰边界和更高的度量分数。

Conclusion: PhyDNN通过融合物理模型与深度学习，减少了深度网络的黑盒特性，提高了物理合理性和泛化能力，为高质量断层触觉传感提供了有效解决方案。

Abstract: Electrical impedance tomography (EIT) provides an attractive solution for large-area tactile sensing due to its minimal wiring and shape flexibility, but its nonlinear inverse problem often leads to severe artifacts and inaccurate contact reconstruction. This work presents PhyDNN, a physics-driven deep reconstruction framework that embeds the EIT forward model directly into the learning objective. By jointly minimizing the discrepancy between predicted and ground-truth conductivity maps and enforcing consistency with the forward PDE, PhyDNN reduces the black-box nature of deep networks and improves both physical plausibility and generalization. To enable efficient backpropagation, we design a differentiable forward-operator network that accurately approximates the nonlinear EIT response, allowing fast physics-guided training. Extensive simulations and real tactile experiments on a 16-electrode soft sensor show that PhyDNN consistently outperforms NOSER, TV, and standard DNNs in reconstructing contact shape, location, and pressure distribution. PhyDNN yields fewer artifacts, sharper boundaries, and higher metric scores, demonstrating its effectiveness for high-quality tomographic tactile sensing.

</details>


### [139] [Modal Logical Neural Networks](https://arxiv.org/abs/2512.03491)
*Antonin Sulc*

Main category: cs.LG

TL;DR: 提出模态逻辑神经网络（MLNNs），一种将深度学习与模态逻辑形式语义相结合的神经符号框架，能够进行必然性和可能性推理。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够结合深度学习能力和形式逻辑推理的框架，特别是能够处理模态逻辑（必然性和可能性）的神经符号系统，以提高模型的逻辑一致性和可解释性。

Method: 基于克里普克语义学，引入专门用于模态运算符□和◇的神经元，这些神经元在一组可能世界上操作。框架允许用户固定世界间的可达关系以强制执行已知规则，或者通过神经网络参数化学习逻辑系统的关系结构。

Result: 在四个案例研究中展示了MLNNs的应用：语法保护、未知的公理检测、多智能体认知信任、以及自然语言谈判中的建设性欺骗检测。实验表明，强制执行或学习可达关系可以提高逻辑一致性和可解释性，而不改变底层任务架构。

Conclusion: MLNNs提供了一个灵活、可微分的神经符号框架，能够整合深度学习和模态逻辑推理，使模型既能学习非线性关系，又能保持逻辑一致性，为复杂推理任务提供了新的解决方案。

Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.

</details>


### [140] [When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate](https://arxiv.org/abs/2512.03578)
*Florent Forest,Amaury Wei,Olga Fink*

Main category: cs.LG

TL;DR: MAGNETS是一个用于时间序列外生回归的固有可解释神经网络架构，通过掩码聚合学习可理解的概念，无需标注即可提供透明决策过程


<details>
  <summary>Details</summary>
Motivation: 当前时间序列外生回归模型虽然预测性能强，但通常是黑盒模型，难以理解驱动决策的时间模式。后验可解释性技术往往产生粗糙、嘈杂或不稳定的解释，而固有可解释方法需要概念监督、难以捕捉特征交互、表达能力有限且难以扩展到高维数据

Method: 提出MAGNETS架构，通过掩码聚合学习紧凑的人类可理解概念集，每个概念对应基于掩码的选定输入特征聚合，明确揭示哪些特征驱动预测以及何时重要。预测通过透明加性结构组合这些学习到的概念

Result: MAGNETS能够学习无需标注的可理解概念，提供清晰的模型决策过程洞察，解决了现有方法在概念监督、特征交互捕捉、复杂时间模式表达和高维数据扩展方面的限制

Conclusion: MAGNETS为时间序列外生回归提供了一个固有可解释的解决方案，通过掩码聚合学习透明概念，既保持预测准确性又提供可信推理，解决了当前可解释性方法的多个关键限制

Abstract: Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.
  To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.

</details>


### [141] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 提出自适应稀疏感知框架，结合变分自编码器先验和强化学习进行顺序测量选择，在稀疏测量重建中优于传统压缩感知、最优传感器布置和生成模型方法。


<details>
  <summary>Details</summary>
Motivation: 传统压缩感知使用通用基和随机测量，效率和质量有限；最优传感器布置基于历史数据但使用固定线性基，无法适应非线性或样本特异性变化；生成模型压缩感知虽使用深度生成先验但仍采用次优随机采样。

Method: 提出自适应稀疏感知框架，将变分自编码器先验与强化学习结合，通过强化学习顺序选择测量位置，利用生成模型作为先验知识指导测量策略。

Result: 实验表明该方法在稀疏测量重建中优于压缩感知、最优传感器布置和生成模型重建方法。

Conclusion: 自适应稀疏感知框架通过结合生成先验和强化学习顺序测量选择，显著提升了稀疏采样重建性能。

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [142] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 使用视觉语言模型从视频编码的网格天气数据直接生成航运天气预报文本，展示了提高气象产品生产效率的创新方法


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型具有强大能力，但在气象产品和服务生成方面的应用仍处于起步阶段，需要加速其在该领域的应用和采纳

Method: 探索使用视觉语言模型，直接从视频编码的网格天气数据生成航运天气预报文本

Result: 早期结果显示该方法具有可扩展的技术机会，能够提高气象企业的生产效率和服务创新

Conclusion: 该方法为气象企业及其他领域提供了增强生产效率和推动服务创新的有前景的技术途径

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [143] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了一种针对扩散模型微调式遗忘学习的攻击方法DiMRA，并提出了更鲁棒的遗忘学习方法DiMUM来防御这种攻击。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成合成图像方面表现出色，但存在安全、隐私和版权问题，需要机器遗忘技术来让模型忘记特定训练数据。现有基于微调的遗忘方法虽然高效，但存在被逆向攻击的风险。

Method: 1. 提出DiMRA攻击：在无先验知识的情况下，通过优化辅助数据集来逆向遗忘过程，使模型重新学习被遗忘的元素。2. 提出DiMUM防御方法：通过记忆替代数据/特征来替换目标遗忘数据/特征，防止生成这些元素。

Result: 实验证明DiMRA能有效逆转最先进的基于微调的扩散模型遗忘方法，揭示了现有技术的脆弱性。DiMUM在保持扩散模型生成性能的同时，显著增强了对DiMRA攻击的鲁棒性。

Conclusion: 现有基于微调的扩散模型遗忘方法存在被逆向攻击的严重漏洞，需要更鲁棒的解决方案。DiMUM通过记忆替代策略有效防御DiMRA攻击，为安全机器遗忘提供了新思路。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [144] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS是一种动态缩放激活引导框架，可根据输入内容自适应调整引导强度，在需要时才进行干预，从而在毒性缓解和模型效用之间实现更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有输入统一应用干预，在不必要引导时会降低模型性能。需要一种能自适应判断何时需要引导以及引导强度的框架。

Method: DSAS将"何时引导"与"如何引导"解耦，通过计算上下文相关的缩放因子，动态调整现有引导方法的强度。可以端到端联合优化引导函数，并在生成时选择性调整引导强度。

Result: DSAS与现有引导方法结合时，能持续改进帕累托前沿，在毒性缓解和效用保持之间实现更好的权衡。应用于文本到图像扩散模型时，能有效调节特定概念。计算开销最小，同时提高可解释性。

Conclusion: DSAS提供了一种方法无关的动态引导框架，通过自适应调整引导强度，在保持模型性能的同时有效引导模型行为，具有广泛适用性和实用性。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [145] [Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns](https://arxiv.org/abs/2512.03696)
*Mohammad Doost,Mohammad Manthouri*

Main category: cs.LG

TL;DR: QTGNN是一个用于大规模金融网络欺诈检测的量子拓扑图神经网络框架，结合量子嵌入、变分图卷积和拓扑数据分析，在NISQ设备上实现稳定训练，在金融数据集上优于经典和量子基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统欺诈检测方法难以捕捉大规模金融交易网络中的复杂动态和结构异常，需要结合量子计算、图神经网络和拓扑数据分析的新框架来提高检测精度和可解释性。

Method: 1) 量子数据嵌入与纠缠增强；2) 具有非线性动态的变分量子图卷积；3) 高阶拓扑不变量提取；4) 自适应优化的混合量子-经典异常学习；5) 通过拓扑归因的可解释决策；6) NISQ硬件优化，包括电路简化和图采样。

Result: 在PaySim和Elliptic等金融数据集上的模拟实验表明，QTGNN在ROC-AUC、精确率和误报率等指标上优于经典和量子基线方法。消融研究验证了量子嵌入、拓扑特征、非线性通道和混合学习各组件的重要性。

Conclusion: QTGNN为金融欺诈检测提供了一个理论严谨、可解释且实用的解决方案，成功桥接了量子机器学习、图论和拓扑分析，为NISQ时代的金融安全应用开辟了新途径。

Abstract: We propose a novel QTGNN framework for detecting fraudulent transactions in large-scale financial networks. By integrating quantum embedding, variational graph convolutions, and topological data analysis, QTGNN captures complex transaction dynamics and structural anomalies indicative of fraud. The methodology includes quantum data embedding with entanglement enhancement, variational quantum graph convolutions with non-linear dynamics, extraction of higher-order topological invariants, hybrid quantum-classical anomaly learning with adaptive optimization, and interpretable decision-making via topological attribution. Rigorous convergence guarantees ensure stable training on noisy intermediate-scale quantum (NISQ) devices, while stability of topological signatures provides robust fraud detection. Optimized for NISQ hardware with circuit simplifications and graph sampling, the framework scales to large transaction networks. Simulations on financial datasets, such as PaySim and Elliptic, benchmark QTGNN against classical and quantum baselines, using metrics like ROC-AUC, precision, and false positive rate. An ablation study evaluates the contributions of quantum embeddings, topological features, non-linear channels, and hybrid learning. QTGNN offers a theoretically sound, interpretable, and practical solution for financial fraud detection, bridging quantum machine learning, graph theory, and topological analysis.

</details>


### [146] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 本文为高斯分布下的最优传输和Gromov-Wasserstein对齐提供了全面的理论框架，解决了未中心化高斯分布的IGW对齐问题，并提出了高效的多边际OT算法。


<details>
  <summary>Details</summary>
Motivation: 最优传输和Gromov-Wasserstein对齐在数据科学中应用广泛，但计算成本高。现有方法主要针对二次成本下的高斯分布，但未中心化高斯分布的IGW对齐问题尚未解决，限制了实际应用。

Method: 1) 为可分希尔伯特空间上的未中心化高斯分布IGW对齐提供闭式表达式（需酉算子优化）；2) 当至少一个高斯分布中心化时，给出完全闭式解；3) 提出高斯多边际OT的降维优化方法，使用秩亏约束高效求解。

Result: 解决了未中心化高斯分布IGW对齐的开放问题，给出了闭式表达式和紧致的上下界。提出了中心化高斯IGW重心解析解，以及高效的多边际OT算法。在知识蒸馏和异构聚类任务中验证了实用性。

Conclusion: 本文填补了高斯分布下OT和GW对齐的理论空白，扩展了其应用范围。提出的闭式解和高效算法为大规模数据科学应用提供了理论基础和实用工具。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [147] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统利用联邦学习和带宽受限轨迹压缩技术，通过扩展AIS覆盖范围来增强海上态势感知能力


<details>
  <summary>Details</summary>
Motivation: 解决海上AIS覆盖范围有限的问题，提高海上态势感知能力，特别是在低带宽连接环境下实现实时异常检测

Method: 结合联邦学习（M3fed模型）和轨迹压缩（BWC-DR-A算法），将船舶转化为移动传感器，优先传输异常数据

Result: 初步结果显示VesselEdge能有效提高AIS覆盖范围和态势感知能力，基于历史数据的验证证明了系统有效性

Conclusion: VesselEdge系统通过联邦学习和轨迹压缩技术成功扩展了AIS覆盖范围，为海上实时异常检测和低带宽数据传输提供了可行解决方案

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [148] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Transformer的深度学习架构，通过同化最新现场观测数据来校正全球天气预报系统(GFS)输出，从而提高海洋风速预报精度。


<details>
  <summary>Details</summary>
Motivation: 海洋风速预报对航行安全、船舶航线规划和能源运营至关重要，但由于海洋观测数据稀疏、异构且时间变化大，准确预报仍然具有挑战性。现有数值天气预报(NWP)模型存在系统性误差，需要有效的后处理方法进行校正。

Method: 将风速预报重新定义为观测信息驱动的NWP模型校正问题。提出基于Transformer的深度学习架构，通过掩码和基于集合的注意力机制处理不规则和时间变化的观测集，使用交叉注意力将预测条件化于最近的观测-预报对，采用循环时间嵌入和坐标感知位置表示，实现任意空间坐标的单次推理。

Result: 在大西洋区域使用ICOADS观测数据进行评估，模型在所有48小时预报时效内都降低了GFS 10米风速的RMSE，在1小时预报时效改善45%，48小时预报时效改善13%。空间分析显示在海岸线和航运路线等观测密集区域改进最显著。架构能够自然处理异构观测平台，并在单次前向传递中生成站点特定预测和流域尺度网格产品。

Conclusion: 该研究展示了一种实用、低延迟的后处理方法，通过学习校正系统性预报误差来补充NWP模型，为海洋风速预报提供了有效的观测同化校正框架。

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [149] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO：结合条件风险理论和分布价值建模的RL框架，通过token级价值分布和不对称风险正则化，在噪声监督下平衡鲁棒性和泛化性


<details>
  <summary>Details</summary>
Motivation: 现有RL方法（如RFQI、CQL、PPO、GRPO）在噪声或不完整监督下存在稳定性与泛化性平衡问题，容易产生过于保守的策略，在实际场景中表现不稳定

Method: DVPO结合条件风险理论和分布价值建模，学习token级价值分布提供细粒度监督，应用不对称风险正则化：压缩下尾抑制噪声负偏差，扩展上尾保持探索多样性

Result: 在多轮对话、数学推理和科学QA等任务中，DVPO在噪声监督下持续优于PPO、GRPO和基于鲁棒Bellman的PPO

Conclusion: DVPO通过分布价值建模和风险感知策略优化，有效平衡鲁棒性和泛化性，为LLM后训练提供了有前景的解决方案

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [150] [CoGraM: Context-sensitive granular optimization method with rollback for robust model fusion](https://arxiv.org/abs/2512.03610)
*Julius Lenz*

Main category: cs.LG

TL;DR: CoGraM是一种用于联邦学习和分布式学习的神经网络合并方法，通过多阶段、上下文敏感、基于损失的迭代优化，在层、神经元和权重级别对齐决策，避免有害更新，相比传统方法显著提升合并网络性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习和分布式学习中需要在不重新训练的情况下合并神经网络，但现有方法如权重平均或Fisher合并存在精度损失和不稳定问题，需要更有效的合并方法。

Method: CoGraM采用多阶段、上下文敏感的基于损失的迭代优化方法，在层、神经元和权重级别进行操作，通过损失差异对齐决策、设置阈值，并通过回滚机制防止有害更新。

Result: CoGraM能够显著改善合并后的网络性能，解决了Fisher等传统方法的弱点，提供更稳定和准确的神经网络合并。

Conclusion: CoGraM是一种有效的神经网络合并优化方法，适用于联邦学习和分布式学习场景，能够在不重新训练的情况下实现更好的模型合并效果。

Abstract: Merging neural networks without retraining is central to federated and distributed learning. Common methods such as weight averaging or Fisher merging often lose accuracy and are unstable across seeds. CoGraM (Contextual Granular Merging) is a multi-stage, context-sensitive, loss-based, and iterative optimization method across layers, neurons, and weight levels that aligns decisions with loss differences and thresholds and prevents harmful updates through rollback. CoGraM is an optimization method that addresses the weaknesses of methods such as Fisher and can significantly improve the merged network.

</details>


### [151] [Scalable Decision Focused Learning via Online Trainable Surrogates](https://arxiv.org/abs/2512.03861)
*Gaetano Signorelli,Michele Lombardi*

Main category: cs.LG

TL;DR: 提出一种基于无偏估计器替代的加速方法，用于决策导向学习，减少训练时昂贵的内层求解器调用，同时保持解质量。


<details>
  <summary>Details</summary>
Motivation: 决策支持系统需要解决复杂的优化问题，传统训练估计器会导致次优解。决策导向学习使用实际决策成本作为损失函数可以解决这个问题，但训练时扩展性差。

Method: 提出加速方法：用高效的无偏估计器替代昂贵的损失函数评估。该方法适用于黑盒设置，能补偿优化模型的简化并考虑补救行动，提供局部置信度信息以便必要时切换到备用方法。

Result: 该方法显著减少了昂贵的内层求解器调用次数，解质量与其他最先进技术相当。

Conclusion: 提出的基于无偏估计器替代的加速方法有效解决了决策导向学习的扩展性问题，在保持解质量的同时大幅减少计算成本。

Abstract: Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.

</details>


### [152] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 研究比较了智能加工中AI模型的能耗、精度和速度，提出超维计算(HDC)作为替代方案，在保持精度的同时大幅降低能耗和提升速度


<details>
  <summary>Details</summary>
Motivation: 智能制造虽能提高效率和降低能耗，但AI模型的高能耗可能抵消这些优势。需要寻找既能保证精度又能显著降低能耗的AI解决方案

Method: 利用原位传感预测智能加工的几何质量，比较常见AI模型的能耗、精度和速度。引入超维计算(HDC)作为替代方案进行对比分析

Result: HDC达到与传统模型相当的精度，但能耗大幅降低：训练能耗降低200倍，推理能耗降低175-1000倍。训练时间减少200倍，推理时间减少300-600倍

Conclusion: 超维计算(HDC)在智能加工中展现出巨大潜力，能够在保持精度的同时显著降低能耗和提升速度，是实现节能智能制造的有前景的解决方案

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [153] [Conditional updates of neural network weights for increased out of training performance](https://arxiv.org/abs/2512.03653)
*Jan Saynisch-Wagner,Saran Rajendran Sari*

Main category: cs.LG

TL;DR: 提出一种增强神经网络在训练数据与应用数据不相似时性能的方法，通过重训练、建立预测器与权重异常回归、外推权重三个步骤，在气候科学中实现时空和跨域外推。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在训练数据与应用数据不相似时的性能问题，如分布外问题、模式转换和机制变化等挑战。

Method: 三步骤方法：1) 对训练数据集的合理子集进行重训练并记录权重异常；2) 选择合理预测器并建立预测器与权重异常之间的回归关系；3) 将权重外推到应用数据，从而外推神经网络。

Result: 在气候科学的三个用例中展示了该方法，成功实现了神经网络的时间、空间和跨域外推。

Conclusion: 该方法能有效增强神经网络在训练数据与应用数据不相似时的性能，为分布外问题提供了实用解决方案。

Abstract: This study proposes a method to enhance neural network performance when training data and application data are not very similar, e.g., out of distribution problems, as well as pattern and regime shifts. The method consists of three main steps: 1) Retrain the neural network towards reasonable subsets of the training data set and note down the resulting weight anomalies. 2) Choose reasonable predictors and derive a regression between the predictors and the weight anomalies. 3) Extrapolate the weights, and thereby the neural network, to the application data. We show and discuss this method in three use cases from the climate sciences, which include successful temporal, spatial and cross-domain extrapolations of neural networks.

</details>


### [154] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 提出一个统一的深度学习框架，结合循环时间编码和混合LSTM-CNN架构，用于多步能源预测，在七个预测时间范围内均取得改进。


<details>
  <summary>Details</summary>
Motivation: 准确的电力消费预测对于需求管理和智能电网运营至关重要。现有方法需要更好地整合时间周期特征和深度学习架构。

Method: 使用正弦余弦编码系统转换基于日历的属性以保留周期结构，通过相关性分析评估预测相关性。采用由LSTM、CNN和针对每个预测时间范围专门设计的MLP回归器元学习器组成的集成模型，同时利用长期季节效应和短期局部模式。

Result: 使用一年全国消费数据集进行实验，包括有/无循环编码和日历特征的消融分析，以及与文献中基准方法的比较。结果显示在所有七个预测时间范围内均取得一致改进，混合模型比单个架构和先前方法获得更低的RMSE和MAE。

Conclusion: 研究证实了将循环时间表示与互补的深度学习结构相结合的好处。据作者所知，这是首个在统一的短期能源预测框架中联合评估时间编码、基于日历的特征和混合集成架构的工作。

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [155] [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973)
*Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: GFP通过结合多步流匹配策略和蒸馏的单步演员，区分数据集中的高价值和低价值动作，实现更好的离线强化学习性能


<details>
  <summary>Details</summary>
Motivation: 传统离线强化学习的行为正则化方法对所有动作一视同仁，无法区分高价值和低价值动作，限制了性能提升

Method: GFP结合多步流匹配策略和蒸馏的单步演员，演员通过加权行为克隆指导流策略专注于克隆高价值动作，流策略则约束演员与数据集最佳转移对齐

Result: 在OGBench、Minari和D4RL基准的144个状态和像素任务上达到最先进性能，在次优数据集和挑战性任务上表现尤为突出

Conclusion: GFP通过演员和流策略的相互指导机制，有效区分动作价值，显著提升离线强化学习性能

Abstract: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

</details>


### [156] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 提出一种特征感知的时间调制机制，通过调节特征的统计属性来对齐跨时间段的特征语义，平衡表格数据中时序分布漂移的鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 表格机器学习在现实部署中面临时序分布漂移的挑战，静态模型假设固定映射以保证泛化性，而自适应模型可能过拟合瞬态模式，需要在鲁棒性和适应性之间找到平衡。

Method: 提出特征感知的时间调制机制，将特征表示条件化于时间上下文，调节特征的统计属性（如尺度和偏度），通过对齐跨时间段的特征语义实现轻量级但强大的适应。

Result: 基准评估验证了该方法在处理表格数据时序漂移方面的有效性，实现了泛化性和适应性的平衡。

Conclusion: 通过调节特征统计属性来对齐跨时间特征语义的特征感知时间调制机制，能够有效处理表格数据中的时序分布漂移，平衡模型的鲁棒性和适应性。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [157] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune是一种针对开源权重语言模型的理论化、策略性微调框架，通过将水印信号作为奖励进行优化，在保持文本质量的同时显著提升水印检测能力，接近推理时水印的性能。


<details>
  <summary>Details</summary>
Motivation: 开源权重语言模型对水印技术提出了严峻挑战，因为一旦模型权重公开，就无法强制执行推理时干预。现有技术如GaussMark需要在模型权重上进行小修改，但要在保持检测能力的同时不损害生成质量非常困难。

Method: MarkTune是一个理论化、策略性微调框架，将GaussMark水印信号作为奖励函数，同时通过正则化防止文本质量下降。该方法在模型表示空间中进行更精细的、水印感知的权重更新。

Result: MarkTune在质量-检测能力权衡上持续优于GaussMark，将检测性能推近到接近推理时水印的水平。该方法对改写和微调攻击具有鲁棒性，并在未见数据集上表现出强大的泛化能力。

Conclusion: MarkTune为开源权重语言模型嵌入鲁棒、高质量水印提供了一种通用策略，解决了开源模型水印的核心挑战。

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [158] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出一种基于物理约束哈密顿学习的算法，通过"结构不可逆性检测"和"能量景观重构"来识别城市交通系统的隐藏结构损伤，避免传统表面指标导致的"虚假恢复"误判。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通系统的韧性评估方法依赖表面恢复指标，无法检测隐藏的结构损伤，导致可能将"虚假恢复"（流量指标正常化但系统动力学永久退化）误判为真实恢复。

Method: 开发了物理约束哈密顿学习算法，结合结构不可逆性检测和能量景观重构：提取低维状态表示，通过物理约束优化识别准哈密顿结构，通过能量景观比较量化结构变化。

Result: 对伦敦2021年极端降雨的分析显示，虽然表面指标完全恢复，但该算法检测到64.8%的结构损伤被传统监测方法遗漏。

Conclusion: 该框架为主动结构风险评估提供了工具，使基础设施投资能够基于真实的系统健康状况而非误导性的表面指标。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [159] [Fare Comparison App of Uber, Ola and Rapido](https://arxiv.org/abs/2512.04065)
*Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina*

Main category: cs.LG

TL;DR: 开发了一个网约车比价Web应用，通过API获取Ola、Uber、Rapido的实时价格，为用户提供最优选择，解决出行成本和时间效率问题。


<details>
  <summary>Details</summary>
Motivation: 随着网约车服务日益普及，用户在选择最合适、最经济的出行方式时面临困难，需要透明化的价格比较工具来优化出行决策。

Method: 构建Web应用程序，使用Python后端通过API获取多家网约车平台（Ola、Uber、Rapido）的实时价格数据，进行对比分析并推荐最优选项。

Result: 开发了一个功能完整的比价系统，能够为用户提供透明的价格比较，帮助用户选择最经济高效的出行方案，提升了出行决策效率。

Conclusion: 该项目成功解决了网约车价格不透明的问题，通过技术手段为用户提供了更好的出行体验，提高了出行效率和成本效益。

Abstract: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

</details>


### [160] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 研究发现，近60个不同模态的科学模型（字符串、图、3D原子、蛋白质）在化学系统上表现出高度对齐的表示学习，表明基础模型学习到了物理现实的共同底层表示。


<details>
  <summary>Details</summary>
Motivation: 理解不同科学模型的内部表示是否相似，对于构建能够可靠泛化到训练域之外的科学基础模型至关重要。虽然表示收敛在语言和视觉领域已被观察到，但在科学领域尚未系统探索。

Method: 分析了近60个科学模型的表示对齐情况，涵盖字符串、图、3D原子和蛋白质等不同模态。研究了在不同数据集上训练的模型在小分子表示上的相似性，以及机器学习原子间势能在表示空间中的收敛行为。

Result: 发现科学模型存在两种不同机制：在类似训练数据的输入上，高性能模型高度对齐，而弱模型在表示空间中发散到局部最优；在完全不同于训练数据的结构上，几乎所有模型都坍缩到低信息表示，表明当前模型仍受限于训练数据和归纳偏差。

Conclusion: 表示对齐可作为科学基础模型通用性的定量基准。该工作能够追踪物质通用表示随模型规模扩展的出现，并为选择在模态、物质域和科学任务间转移性最好的模型提供指导。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [161] [Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition](https://arxiv.org/abs/2512.03755)
*Stephen Law,Tao Yang,Nanjiang Chen,Xuhui Lin*

Main category: cs.LG

TL;DR: 提出条件轨迹编码器，联合学习空间与运动表征，利用几何特征保持起点依赖的不对称性，量化城市形态导致的认知不平等


<details>
  <summary>Details</summary>
Motivation: 当前城市轨迹分析方法存在碎片化：轨迹学习忽略空间上下文，空间嵌入方法忽略时间动态。存在三个主要问题：缺乏空间与时间表征的联合训练、忽略导航方向不对称性（A→B ≠ B→A）、过度依赖辅助数据而非城市空间基本几何特性

Method: 引入条件轨迹编码器，通过双向LSTM处理可见性比率和曲率等几何特征，以可学习的起点嵌入为条件，将表征分解为共享城市模式和起点特定特征，使用对比学习进行训练

Result: 在六个合成城市和北京西城区的真实数据验证表明，城市形态会产生系统性认知不平等。该方法为城市规划者提供评估体验公平性的量化工具，为建筑师提供布局决策的认知影响洞察，并为导航系统实现起点感知分析

Conclusion: 该框架将城市导航分解为共享认知模式和起点特定空间叙事，能够跨起点位置量化认知不对称性，为解决当前城市轨迹分析方法的局限性提供了有效解决方案

Abstract: Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.

</details>


### [162] [Deep Unfolding: Recent Developments, Theory, and Design Guidelines](https://arxiv.org/abs/2512.03768)
*Nir Shlezinger,Santiago Segarra,Yi Zhang,Dvir Avrahami,Zohar Davidov,Tirza Routtenberg,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 深度展开是一种将迭代优化算法转化为结构化可训练机器学习架构的框架，连接了经典优化和机器学习两大范式


<details>
  <summary>Details</summary>
Motivation: 经典优化算法具有可解释性和理论保证，但依赖代理目标、需要仔细调参且计算延迟大；机器学习具有强大的数据驱动建模能力，但缺乏优化驱动推理所需的结构、透明度和效率。需要一种能结合两者优势的方法。

Method: 深度展开框架通过系统地将迭代优化算法转化为结构化、可训练的机器学习架构。文章介绍了四种代表性的设计范式，以及由其迭代特性产生的独特训练方案。

Result: 文章提供了深度展开的统一方法论视角，回顾了优化理论基础，介绍了设计范式，讨论了训练方案，并调查了建立收敛性和泛化保证的理论进展。

Conclusion: 深度展开是一个有前景的框架，能够桥接经典优化和机器学习，在复杂性、可解释性和鲁棒性之间提供权衡，为优化驱动的推理提供了新的可能性。

Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

</details>


### [163] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 利用智能手机和智能手表的运动传感器数据，通过机器学习方法生成不同身体活动类型的似然比，用于法医调查中的活动识别和活动时间线重建。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表在日常生活中的普及提供了丰富的用户行为信息，特别是手机内置运动传感器产生的数字痕迹为法医调查人员了解个人身体活动提供了机会。

Method: 提出基于机器学习的方法，将数字痕迹转换为不同身体活动类型的似然比。使用包含四种不同iPhone型号、标记有19种活动的新数据集NFI_FARED进行评估，并将方法扩展到同时分析多个活动（或活动组）并创建活动时间线。

Result: 在171种可能的活动配对中，该方法能够为167种配对产生有用的似然比系统。数据集和所有代码已公开，以促进该主题的进一步研究。

Conclusion: 该方法能够有效利用移动设备的传感器数据进行法医调查中的活动识别，为调查早期和后期阶段提供支持，具有实际应用价值。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [164] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 提出基于过程挖掘的两阶段临床路径建模方法，利用一致性检查扩展临床路径知识库，通过历史数据构建参考模型，再基于新数据验证一致性并扩展知识库。


<details>
  <summary>Details</summary>
Motivation: 临床路径是标准化的医疗计划，但基于临床指南和领域专家知识的手动建模困难，且难以反映不同疾病变异或组合的最佳实践。

Method: 两阶段建模方法：第一阶段收集特定疾病的历史数据，构建过程模型；第二阶段将新数据与参考模型进行一致性检查，基于检查结果扩展知识库，为新的变异或疾病组合创建更具体的模型。

Result: 使用Synthea基准数据集（模拟SARS-CoV-2感染及COVID-19并发症）验证方法，结果显示能够以足够精度扩展临床路径知识库，AUC最高达95.62%，同时保持67.11%的弧度简单性。

Conclusion: 提出的两阶段过程挖掘方法能够有效扩展临床路径知识库，为不同疾病变异和组合提供更精准的标准化治疗方案。

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [165] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 本文提出基于EfficientNet的轻量级ECG分类模型EfficientECG，以及跨注意力特征融合模型，用于多导联心电图分析，实现高精度、多特征融合的自动诊断。


<details>
  <summary>Details</summary>
Motivation: 心电图是重要的诊断信号，但现有ECG模型误诊率高。本文旨在开发深度学习技术，自动提取ECG特征，构建准确快速的诊断模型，减轻医疗工作者负担。

Method: 1. 基于EfficientNet设计EfficientECG，处理高频长序列多导联ECG数据；2. 提出跨注意力特征融合模型，整合多导联ECG数据及性别、年龄等多特征。

Result: 在代表性ECG数据集上的评估验证了模型在精度、多特征融合和轻量化方面的优越性，优于现有最先进方法。

Conclusion: 提出的深度学习方法能有效管理分析ECG数据，构建准确快速的诊断模型，显著降低医疗工作负担，具有实际应用价值。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [166] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文系统研究了深度强化学习在动态算法配置中的应用，针对(1+(λ,λ))-GA算法的种群规模参数控制问题，揭示了DDQN和PPO算法的两大挑战：可扩展性退化和学习不稳定性，并提出了自适应奖励偏移机制等解决方案。


<details>
  <summary>Details</summary>
Motivation: 强化学习在动态算法配置中面临挑战，需要大量领域专业知识。本文旨在通过系统研究深度强化学习算法在DAC中的表现，识别关键问题并提供解决方案。

Method: 通过控制(1+(λ,λ))-GA在OneMax实例上的种群规模参数，系统分析DDQN和PPO算法。引入自适应奖励偏移机制解决探索不足问题，采用无折扣学习解决规划视野覆盖问题。

Result: 发现DDQN和PPO存在可扩展性退化和学习不稳定性问题。自适应奖励偏移机制显著提升DDQN探索能力，无折扣学习有效解决规划视野覆盖问题。DDQN结合自适应奖励偏移策略达到与理论推导策略相当的性能，样本效率提升数个数量级。

Conclusion: 深度强化学习在DAC中存在系统性挑战，但通过针对性解决方案可以有效克服。DDQN配合自适应奖励偏移机制在DAC中表现优异，为算法参数控制提供了高效解决方案。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [167] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 提出一种基于对数概率的廉价LLM API监控方法，仅需单token输出即可检测微小模型变化，比现有方法敏感1000倍


<details>
  <summary>Details</summary>
Motivation: LLM API提供商需要保持模型一致性以确保下游应用可靠性和研究可复现性，但现有审计方法成本过高无法定期监控广泛可用的LLM API

Method: 利用LLM对数概率（logprobs）的统计特性，基于每个token对数概率的平均值设计简单统计测试，仅需请求单token输出

Result: 该方法能检测小至单步微调的模型变化，比现有方法更敏感且成本降低1000倍，并引入TinyChange基准评估审计方法对微小实际变化的敏感性

Conclusion: 基于对数概率的简单统计测试为LLM API提供了一种经济高效的连续监控方案，解决了现有审计方法成本过高的问题

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [168] [Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission](https://arxiv.org/abs/2512.03819)
*Junlin Chang,Yubo Han,Hnag Yue,John S Thompson,Rongke Liu*

Main category: cs.LG

TL;DR: 提出基于深度联合信源信道编码的语义无线传输框架，通过预测接收端语义正交特征池的组合权重实现紧凑表示和鲁棒重建，在带宽受限场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着深度传感器的普及，点云获取门槛降低，但传统传输方法在带宽受限环境下效率不高。需要一种能够实现紧凑表示和鲁棒重建的语义传输框架。

Method: 基于DeepJSCC构建语义无线传输框架，发送端预测接收端语义正交特征池的组合权重而非原始特征；使用折叠式解码器将2D网格变形为3D点云，保持流形连续性；采用Chamfer距离和正交正则化进行训练。

Result: 在ModelNet40数据集上测试，高带宽时性能与SEPT相当，带宽受限时明显优于SEPT，PSNR和CD指标均有提升。消融实验验证了正交化和折叠先验的有效性。

Conclusion: 提出的语义传输框架通过正交特征池和折叠解码器实现了高效的点云传输，在带宽受限场景下表现出色，为点云语义通信提供了新思路。

Abstract: The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.

</details>


### [169] [Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882)
*Haidong Kang,Wei Wu,Hanling Wang*

Main category: cs.LG

TL;DR: 本文提出ACraft方法，利用大语言模型自动生成针对少样本类增量学习（FSCIL）的攻击方法，显著超越人工设计的攻击效果，且成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有FSCIL研究主要关注提升学习效果，而忽视了安全问题。传统人工设计的攻击方法（如PGD、FGSM）要么无法有效攻击基础类，要么依赖大量专家知识导致成本高昂，因此需要专门针对FSCIL的攻击方法。

Method: 提出ACraft方法：1）利用大语言模型自动搜索和发现针对FSCIL的最优攻击方法；2）引入基于近端策略优化（PPO）的强化学习来优化大语言模型的推理，通过建立正反馈机制让大语言模型在下一代生成更好的攻击方法。

Result: 在主流基准测试中，ACraft方法显著降低了最先进FSCIL方法的性能，大幅超越人工专家设计的攻击方法，同时保持了最低的攻击成本。

Conclusion: 本文首次全面研究了FSCIL的安全问题，提出的ACraft方法能够自动生成高效攻击，揭示了FSCIL系统在实际部署中面临的安全风险，为后续防御研究提供了基础。

Abstract: Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.

</details>


### [170] [Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations](https://arxiv.org/abs/2512.03923)
*Xiang Rao,Yina Liu,Yuxuan Shen*

Main category: cs.LG

TL;DR: 提出了一种离散变量量子-经典物理信息神经网络（DV-QCPINN），用于解决储层渗流偏微分方程，相比传统PINNs具有更高的参数效率和更强的非线性拟合能力。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法存在网格依赖误差和计算成本高的问题，经典物理信息神经网络在参数效率、高维表达和强非线性拟合方面存在瓶颈，需要新的方法来解决储层渗流问题。

Method: 将经典预处理/后处理网络与离散变量量子核心集成，利用量子叠加和纠缠增强高维特征映射，同时嵌入物理约束确保解的一致性。测试了三种量子电路拓扑结构（级联、交叉网格、交替）。

Result: QCPINNs相比经典PINNs以更少的参数实现了高预测精度。在异质单相流和两相BL方程模拟中，交替拓扑表现最佳；在考虑吸附的组分流中，级联拓扑表现最优。

Conclusion: 验证了QCPINN在储层工程应用中的可行性，弥合了量子计算研究与油气工程工业实践之间的差距。

Abstract: Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.

</details>


### [171] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE是一种轻量级VAE正则化器，通过将VAE的先验对数概率与数据估计的对数密度对齐，改善潜在空间与数据空间密度的匹配。


<details>
  <summary>Details</summary>
Motivation: 标准VAE将潜在变量匹配到简单先验分布，忽略了数据空间中的密度结构，导致潜在空间与数据密度不匹配。

Method: DiVAE在ELBO中添加一个稳健的、精度加权的惩罚项，使编码器按数据空间密度比例分配后验质量，并推动可学习先验向高密度区域移动。

Result: 在合成数据集上：改善潜在对数密度与真实分布的匹配、提高先验覆盖度、改善OOD不确定性校准；在MNIST上：改善先验与外部密度估计的对齐、提高可学习先验的OOD检测能力。

Conclusion: DiVAE通过轻量级的数据驱动正则化，有效改善了VAE中潜在空间与数据密度的对齐，提高了模型的可解释性和OOD检测性能。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [172] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文综述了文本数据集蒸馏领域的发展历程，从最初借鉴视觉领域方法到形成独立研究方向，涵盖了关键里程碑、当前挑战和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 文本数据集蒸馏相比视觉领域研究较少，但具有重要价值。随着模态特殊性带来的挑战日益明显，需要专门针对文本数据的蒸馏方法，以解决大语言模型训练中的效率问题。

Method: 综述了文本数据集蒸馏的主要方法：包括从视觉领域迁移的方法、基于Transformer模型的方法、生成离散合成文本的方法，以及扩展到超过10亿参数的仅解码器模型的方法。

Result: 文本数据集蒸馏领域已取得显著进展，包括引入Transformer模型、生成离散合成文本、扩展到大规模模型等里程碑，但仍处于成熟阶段，面临多项挑战。

Conclusion: 文本数据集蒸馏是一个快速发展的研究领域，需要在基准标准化、处理文本离散性、应对复杂任务和展示实际应用等方面进一步改进，具有广阔的研究前景。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [173] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 提出一种无需训练的高效方法，将策略违规检测视为分布外检测问题，通过白化技术处理隐藏激活，在变换空间中使用欧几里得范数作为合规分数，仅需策略文本和少量示例即可实现轻量级部署。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域（法律、金融、医疗）的部署，组织需要可靠机制检测内部政策违规，现有方法（如护栏、LLM-as-a-judge、微调）存在延迟高、可解释性差、鲁棒性不足等问题。

Method: 将策略违规检测视为分布外检测问题，采用白化技术对模型隐藏激活进行线性变换以解相关并标准化，在变换空间中使用欧几里得范数作为合规分数，仅需策略文本和少量示例样本。

Result: 在具有挑战性的策略基准测试中达到最先进水平，超越现有护栏和微调推理模型，提供实用且统计基础扎实的框架。

Conclusion: 为组织提供实用且统计基础扎实的LLM政策感知监督框架，推进可部署AI治理的广泛目标，方法轻量、易于部署且无需训练。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [174] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 提出PEGP框架，通过设计基于经典交通流模型的多输出核，将物理知识嵌入高斯过程，改善稀疏观测下的交通状态估计。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在观测数据稀疏时缺乏物理解释和泛化能力，而物理模型难以整合不确定性和捕捉真实交通复杂性。现有结合方法依赖惩罚调优且缺乏不确定性校准，对模型误设敏感。

Method: 提出物理嵌入高斯过程(PEGP)，通过线性化微分算子的显式应用，设计基于LWR和ARZ经典交通流模型的多输出核，将物理结构作为硬约束而非软约束。

Result: 在HighD和NGSIM数据集上实验显示，PEGP相比非物理基线有持续改进。PEGP-ARZ在稀疏观测下更可靠，PEGP-LWR在密集观测下误差更低。残差分析显示PEGP-ARZ与物理更一致且不确定性可解释。

Conclusion: PEGP框架成功结合物理先验和不确定性量化，为交通状态估计提供可靠支持，解决了现有方法的惩罚调优依赖和不确定性校准不足问题。

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [175] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 提出首个差分隐私算法，其隐私保证验证成本远低于模型训练成本，显著降低大规模数据集上的验证开销


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私算法的验证计算量与训练计算量相当，数据提供者和公众缺乏高效验证DP保证的方法，需要降低验证成本

Method: 通过私有化最小化一系列正则化目标，仅使用标准DP组合边界，获得紧致的隐私-效用权衡

Result: 实现了接近最优的隐私-效用权衡，且DP验证计算量远低于训练成本，显著减少大规模数据集上的验证开销

Conclusion: 首次设计出验证成本低于训练成本的DP-SCO算法，为数据提供者提供更实用的DP验证方法

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [176] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 本文从信息论角度解释了为什么在单域数据集上训练的模型会出现OOD检测的灾难性失败，证明了单域监督学习必然导致域特征坍缩，并提出通过域过滤保留域信息来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 解释一个令人困惑的经验现象：为什么最先进的OOD检测方法在单域数据集上训练的模型会出现灾难性失败（例如MNIST上仅53% FPR@95）。作者希望从信息论角度提供首个理论解释。

Method: 1. 从信息论角度证明单域监督学习必然导致域特征坍缩（I(x_d; z)=0）；2. 使用Fano不等式量化实际场景中的部分坍缩；3. 引入Domain Bench基准测试；4. 通过域过滤（使用预训练表示）保留I(x_d; z)>0来验证理论。

Result: 理论证明单域训练会导致模型完全丢弃域特定信息，这是信息瓶颈优化的必然结果。实验验证通过域过滤保留域信息可以解决OOD检测失败问题，为信息论框架提供了强有力的经验证据。

Conclusion: 本文首次从信息论角度解释了单域训练模型的OOD检测失败现象，揭示了监督学习在窄域中的根本局限性，对迁移学习以及何时微调与冻结预训练模型具有更广泛的意义。

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [177] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: Eval Factsheets：为AI系统评估提供结构化文档框架，解决评估方法缺乏系统化文档标准的问题，提升评估的透明度、可复现性和可比性。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域基准测试激增，但评估方法缺乏系统化的文档标准，导致可复现性、透明度和决策制定方面存在挑战。与数据集和模型已有Datasheets和Model Cards等结构化文档框架不同，评估方法缺乏相应的标准化文档。

Method: 提出Eval Factsheets框架，通过全面的分类法和基于问卷的方法来记录AI系统评估。框架将评估特征组织为五个基本维度：Context（谁在何时进行评估）、Scope（评估什么）、Structure（评估基于什么构建）、Method（如何工作）、Alignment（可靠性/有效性/鲁棒性）。实现为包含强制和推荐文档元素的实用问卷。

Result: 通过多个基准测试的案例研究证明，Eval Factsheets能够有效捕捉从传统基准测试到LLM-as-judge方法等多样化的评估范式，同时保持一致性和可比性。

Conclusion: Eval Factsheets应被纳入现有和新发布的评估框架中，以促进评估的透明度和可复现性，为AI系统评估提供标准化的文档实践。

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>


### [178] [Learning Steerable Clarification Policies with Collaborative Self-play](https://arxiv.org/abs/2512.04068)
*Jonathan Berant,Maximillian Chen,Adam Fisch,Reza Aghajani,Fantine Huot,Mirella Lapata,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 训练可调控的AI助手策略，通过自博弈学习在不确定情况下决定何时猜测用户意图、枚举多种可能性或提问澄清，根据成本参数优化奖励


<details>
  <summary>Details</summary>
Motivation: AI助手需要智能策略来处理模糊查询，但现有策略缺乏对上下文因素（如用户偏好、设备模态）的适应性。例如，在小屏幕或语音场景下枚举多种意图会显得笨拙，因此需要可调控的策略来平衡准确性和成本

Method: 采用自博弈方法训练可调控策略：一个代理模拟用户，另一个模拟AI助手。通过强化自训练（ReST）优化模型，输入包括澄清问题和每个生成单词的数值成本，目标是最大化成本惩罚后的准确率奖励

Result: 训练出的策略能够根据提供的成本参数可预测地调整行为，实现更高的奖励和准确率。更重要的是，该方法能泛化到训练时未观察到的成本数值

Conclusion: 自博弈训练可产生可调控的不确定性管理策略，使AI助手能根据上下文成本因素灵活选择响应方式，并在未见过的成本设置下保持良好性能

Abstract: To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [179] [A Stochastic Thermodynamics Approach to Price Impact and Round-Trip Arbitrage: Theory and Empirical Implications](https://arxiv.org/abs/2512.03123)
*Amit Kumar Jha*

Main category: q-fin.MF

TL;DR: 该论文将随机热力学概念引入金融市场，将交易循环视为非平衡热力学过程，证明金融第二定律：在凸冲击函数下，任何往返交易策略的期望利润非正，并提出连接微观冲击与宏观无套利条件的物理启发框架。


<details>
  <summary>Details</summary>
Motivation: 将热力学概念应用于金融市场，为价格冲击建模和套利可行性分析提供新的理论框架，建立微观市场结构与宏观无套利条件之间的严格联系。

Method: 将交易循环视为非平衡热力学过程，价格冲击对应耗散功，市场噪声对应热涨落。引入由吉布斯测度支配的交易策略统计系综，建立自由能分解，连接期望成本、策略熵和市场温度参数。

Result: 证明金融第二定律：在一般凸冲击函数下，任何往返交易策略的期望利润非正。提出涨落定理，用耗散功和市场波动率界定盈利循环的概率。推导典型交易策略的解析结果。

Conclusion: 该框架为市场效率提供了物理启发的新视角，建立了连接微观结构冲击与宏观无套利条件的可检验不等式，为价格冲击建模和套利分析提供了严谨的理论基础。

Abstract: This paper develops a comprehensive theoretical framework that imports concepts from stochastic thermodynamics to model price impact and characterize the feasibility of round-trip arbitrage in financial markets. A trading cycle is treated as a non-equilibrium thermodynamic process, where price impact represents dissipative work and market noise plays the role of thermal fluctuations. The paper proves a Financial Second Law: under general convex impact functionals, any round-trip trading strategy yields non-positive expected profit. This structural constraint is complemented by a fluctuation theorem that bounds the probability of profitable cycles in terms of dissipated work and market volatility. The framework introduces a statistical ensemble of trading strategies governed by a Gibbs measure, leading to a free energy decomposition that connects expected cost, strategy entropy, and a market temperature parameter. The framework provides rigorous, testable inequalities linking microstructural impact to macroscopic no-arbitrage conditions, offering a novel physics-inspired perspective on market efficiency. The paper derives explicit analytical results for prototypical trading strategies and discusses empirical validation protocols.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [180] [Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation](https://arxiv.org/abs/2512.03160)
*Feiya Zhu,Tarun Pati,Sze Zheng Yong*

Main category: eess.SY

TL;DR: 提出针对不确定线性连续/离散时间系统的新型多面体和区间观测器设计，保证真实状态包含和输入到状态稳定性，适用于所有可检测系统


<details>
  <summary>Details</summary>
Motivation: 现有观测器设计方法在处理不确定线性系统时存在局限性，特别是在非正定约束条件下可能失效，需要一种更通用且保证性能的观测器设计框架

Method: 基于多面体Lyapunov函数和混合单调嵌入系统，采用非方（提升）时不变坐标变换，不施加任何正定性约束，构建多面体和区间观测器

Result: 提出的方法保证真实状态包含和输入到状态稳定性，适用于所有可检测系统，在先前方法失效的情况下仍能实现可行且最优的观测器设计

Conclusion: 通过多个不确定线性连续/离散时间系统示例验证了所提方法的有效性，为不确定线性系统观测器设计提供了更通用和鲁棒的解决方案

Abstract: This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems.

</details>


### [181] [Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion](https://arxiv.org/abs/2512.03459)
*Hidaka Asai,Tomoyuki Noda,Jun Morimoto*

Main category: eess.SY

TL;DR: 该研究通过分层控制器（高层神经网络+低层可变阻抗肌肉协调模型）探索肌肉形态计算如何减轻高层控制器的负担，发现在受限控制频率和观察条件下，可变阻抗肌肉协调仍能实现稳定运动。


<details>
  <summary>Details</summary>
Motivation: 人类运动控制在有限感官反馈下仍能保持敏捷和鲁棒，这归因于身体通过肌肉协调进行形态计算的能力。但尚不清楚这种低层机械计算如何减轻高层控制器的控制需求。

Method: 实现分层控制器：高层使用强化学习训练的神经网络，低层采用具有单关节和双关节肌肉的可变阻抗肌肉协调模型。通过改变控制频率和引入延迟、部分、替代等生物启发的观察条件来限制高层控制器。

Result: 可变阻抗肌肉协调即使在慢速控制频率和有限观察条件下也能实现稳定运动。肌肉协调的形态计算有效减轻了高层控制器的高频反馈需求。

Conclusion: 肌肉协调的形态计算能够有效减轻高层控制器的控制负担，为运动控制中的控制器设计提供了原则。

Abstract: Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control.

</details>


### [182] [Resilient AFE Drive Control using Neural Networks with Tracking Guarantees](https://arxiv.org/abs/2512.03545)
*Nicolas Kirsch,Catalin Arghir,Silvia Mastellone,Giancarlo Ferrari-Trecate*

Main category: eess.SY

TL;DR: 提出使用参考跟踪性能提升(rPB)神经网络控制框架，增强主动前端(AFE)驱动器在电网故障（如缺相）下的韧性，保持直流母线电压和电网电流在安全范围内。


<details>
  <summary>Details</summary>
Motivation: 工业应用中广泛使用中压变频器提高生产效率，主动前端(AFE)驱动器因能维持安全电气设定点而受欢迎。但在电网异常条件（如缺相）下，传统AFE控制可能无法保证安全约束，导致驱动器停机和经济损失。

Method: 采用参考跟踪性能提升(rPB)神经网络控制框架，通过精心设计rPB控制器的输入信号，确保其仅在电网故障时激活，不影响正常运行。该框架提供了一种优化瞬态性能同时保持AFE驱动器稳态跟踪特性的原则性方法。

Result: 仿真结果表明，所提方法在单相缺失事件中成功保持直流母线电压和电网电流在安全限值内。

Conclusion: rPB控制框架能有效提升标准AFE控制在电网故障下的韧性，避免驱动器停机和经济损失，同时保持正常运行不受影响。

Abstract: Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events.

</details>


### [183] [Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control](https://arxiv.org/abs/2512.03604)
*Abbas Tariverdi*

Main category: eess.SY

TL;DR: 提出静态方向性触发机制，利用李雅普诺夫矩阵P对误差进行加权，实现各向异性触发阈值，相比传统各向同性方法减少43.6%事件数，同时获得2.1倍更好的控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统事件触发控制使用各向同性误差阈值（‖e‖ ≤ σ‖x‖），将所有方向同等对待，忽略了稳定性几何结构，导致保守触发。需要利用系统稳定性的不对称性来设计更高效的触发机制。

Method: 提出静态方向性触发机制，通过李雅普诺夫矩阵P对误差进行加权，定义各向异性半空间缩放：沿稳定模式允许较大偏差，在不稳定威胁处设置严格边界。机制作为运行时安全门，适用于通信受限下的学习型控制器。

Result: 证明了全局渐近稳定性和排除Zeno行为。蒙特卡洛模拟（N=100）显示比最优调谐的各向同性方法减少43.6%事件数，同时比时变替代方案获得2.1倍更好的控制性能。

Conclusion: 静态方向性触发机制通过利用稳定性几何结构的不对称性，显著减少了通信开销，同时保持控制性能，为通信受限环境下的学习型控制器提供了有效的运行时安全门。

Abstract: Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\|e\| \le σ\|x\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\% fewer events than optimally tuned isotropic methods while achieving $2.1\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints.

</details>


### [184] [A Perception-feedback position-tracking control for quadrotors](https://arxiv.org/abs/2512.03605)
*Eduardo Espindola,Yu Tang*

Main category: eess.SY

TL;DR: 提出一种基于感知反馈的四旋翼位置跟踪控制器，直接使用低成本IMU和GPS等机载传感器测量值生成控制指令，无需状态估计，通过陀螺仪偏置校正提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼控制通常需要状态估计环节，增加了系统复杂性和计算负担。本文旨在开发一种直接利用传感器测量的控制器，简化系统架构，同时通过陀螺仪偏置校正提高跟踪精度。

Method: 设计基于感知反馈的位置跟踪控制器，直接处理IMU和GPS原始测量数据生成控制命令。采用陀螺仪偏置校正技术补偿传感器误差。使用李雅普诺夫分析证明跟踪误差系统在外部扰动下的实际稳定性，无扰动时具有指数稳定性。

Result: 通过数值仿真验证了所提控制方案的有效性，控制器在噪声测量和参数不确定条件下表现出良好的鲁棒性。理论分析证明了系统在外部扰动下的实际稳定性和无扰动时的指数稳定性。

Conclusion: 成功开发了一种无需状态估计的四旋翼位置跟踪控制器，直接利用传感器测量实现控制，简化了系统结构。陀螺仪偏置校正提高了跟踪性能，李雅普诺夫分析确保了系统稳定性，仿真验证了控制器的鲁棒性。

Abstract: In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties.

</details>


### [185] [Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach](https://arxiv.org/abs/2512.03615)
*Kaouther Moussa,Dimitri Peaucelle*

Main category: eess.SY

TL;DR: 该论文在随机模型预测控制框架下，针对受加性和参数随机不确定性影响的线性离散随机系统，提出了基于线性矩阵不等式的协方差控制设计方法。


<details>
  <summary>Details</summary>
Motivation: 处理同时受随机不确定性和确定性不确定性影响的线性随机离散时间系统的协方差控制问题。现有方法在处理这类复杂不确定性系统时存在保守性或数值计算困难。

Method: 采用S变量方法将控制设计条件表述为线性矩阵不等式，通过确定性精确描述协方差动态，并引入描述符表示来线性化控制增益中的双线性项，从而推导出协方差控制设计的充分条件。

Result: 提出的条件虽然比无确定性不确定性和加性随机噪声系统的必要充分稳定性条件更保守，但数值计算更易处理。该方法能设计对确定性和随机不确定性都具有鲁棒性的控制器，数值示例验证了其有效性。

Conclusion: 该论文提出了一种基于线性矩阵不等式的协方差控制设计方法，能够有效处理同时受随机和确定性不确定性影响的线性随机系统，在保守性和数值可处理性之间取得了良好平衡。

Abstract: This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration.

</details>


### [186] [Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes](https://arxiv.org/abs/2512.03680)
*Dawei Zhao,Kai Wang,Xianglong Zhou,Xin Ma,Lei Jia*

Main category: eess.SY

TL;DR: 提出一种基于转矩抖动输出限幅约束的模糊调节非线性控制方法，用于抑制双摆效应的桥式起重机系统摆动并实现精确定位


<details>
  <summary>Details</summary>
Motivation: 针对具有双摆效应的桥式起重机系统，需要有效抑制摆动并实现精确位置控制，同时考虑转矩抖动输出限制的实际约束条件

Method: 1) 增强小车位移与摆角耦合关系，设计含误差项的复合信号；2) 基于复合误差信号构造能量Lyapunov函数，包含新的惯性矩阵和势能函数形式；3) 结合反步法和双曲正切函数设计具有部分性能约束的控制器；4) 设计在线可调系统参数的模糊控制方案以增强动态性能

Result: 仿真结果表明所提出的控制器表现出优越的性能和鲁棒性，能有效抑制摆动并实现精确定位

Conclusion: 提出的模糊调节非线性控制方法通过Lyapunov理论和LaSalle不变原理证明了系统稳定性，为具有双摆效应的桥式起重机系统提供了有效的控制解决方案

Abstract: This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness.

</details>


### [187] [A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF](https://arxiv.org/abs/2512.03712)
*Sary Yehia,Alessandra Parisio*

Main category: eess.SY

TL;DR: 提出一种混合序列凸规划框架，用于解决不平衡三相交流最优潮流问题，结合多种凸近似技术，在保持凸性的同时确保收敛到非线性OPF的KKT稳定点。


<details>
  <summary>Details</summary>
Motivation: 不平衡三相交流最优潮流问题在配电网中具有重要应用价值，但传统非线性求解方法如IPOPT在计算效率和收敛性方面存在局限，需要开发更高效可靠的求解方法。

Method: 采用混合序列凸规划框架，结合固定McCormick外近似处理双线性电压电流项、一阶泰勒线性化以及自适应信赖域约束，确保每次迭代保持凸性并促进收敛。

Result: 在标准IEEE馈线和塞浦路斯实际低压网络上测试，获得低于0.1%的最优性间隙，相比IPOPT运行时间最多快2倍，证明方法在大规模不平衡配电网中具有高精度和计算效率。

Conclusion: 该方法为大规模不平衡配电网的最优潮流问题提供了一种准确且计算高效的解决方案，能够收敛到满足一阶KKT条件的稳定点，具有实际应用价值。

Abstract: This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks.

</details>


### [188] [Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression](https://arxiv.org/abs/2512.03764)
*Bowen Song,Sebastien Gros,Andrea Iannelli*

Main category: eess.SY

TL;DR: 论文研究了用于未知随机线性系统LQR问题的两种策略梯度算法，通过原始-对偶估计解决噪声数据中的梯度估计问题，实现了O(1/ε)的样本复杂度收敛保证。


<details>
  <summary>Details</summary>
Motivation: 策略梯度算法在强化学习中广泛应用，但应用于未知随机线性系统的LQR问题时，面临从噪声数据中获取无偏梯度估计的挑战，这源于线性回归中的变量误差问题。

Method: 采用原始-对偶估计程序来解决噪声数据中的梯度估计问题，研究了自然策略梯度和高斯-牛顿方法两种关键算法，并建立了收敛理论分析。

Result: 提出了新的梯度估计方案，建立了收敛保证，样本复杂度为O(1/ε)，数值实验验证了所提算法的有效性。

Conclusion: 通过原始-对偶估计方法成功解决了未知随机线性系统LQR问题中的梯度估计挑战，为策略梯度算法在该领域的应用提供了理论保证和实用方案。

Abstract: Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms.

</details>


### [189] [CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond](https://arxiv.org/abs/2512.03767)
*Bo Qian,Hanlin Wu,Jiacheng Chen,Yunting Xu,Xiaoyu Wang,Haibo Zhou,Yusheng Ji*

Main category: eess.SY

TL;DR: 提出CaFTRA框架，利用AI通过用户地理位置预测CSI，消除实时上行反馈，结合匹配理论算法实现多基站关联和资源分配，显著提升频谱效率和用户公平性。


<details>
  <summary>Details</summary>
Motivation: 面向AI原生6G及更高代际无线系统，需要满足移动数据流量持续增长、极端频谱效率和多样化服务场景的需求。传统基于反馈的MIMO传输存在局限性，需要克服这些限制。

Method: 提出CaFTRA框架：1) 使用可学习查询驱动的Transformer网络，通过用户地理位置映射CSI，利用多头注意力和可学习查询嵌入准确捕捉频域相关性；2) 采用基于低复杂度多对一匹配理论的算法，实现高效的多基站关联和多资源块资源分配。

Result: CaFTRA实现了稳定匹配收敛，与5G相比在频谱效率和用户公平性方面获得显著增益，证明了其对6G标准化的潜在价值。

Conclusion: CaFTRA框架通过AI预测CSI消除实时上行反馈，结合匹配理论资源调度，为AI原生6G及更高代际无线系统提供了有效的解决方案，具有标准化潜力。

Abstract: The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts.

</details>


### [190] [Exact and Parametric Dynamical System Representation of Nonlinear Functions](https://arxiv.org/abs/2512.03779)
*Toshiyuki Ohtsuka*

Main category: eess.SY

TL;DR: 该论文提出了一种固定初始状态恒定输入动态系统(FISCIDS)表示法，为一大类非线性函数提供精确的参数化模型。


<details>
  <summary>Details</summary>
Motivation: 科学和工程中各种函数的参数化表示是基础工具，需要为非线性函数提供精确的参数化模型表示方法。

Method: 提出FISCIDS表示法：使用具有固定初始状态和恒定输入的输入仿射动态系统，将函数参数作为恒定输入，函数值作为系统在固定终端时间的输出。

Result: 证明任何微分代数函数都有二次FISCIDS表示，且存在非微分代数的解析函数也具有二次FISCIDS表示，表明大多数实际科学工程问题中的函数都可用二次FISCIDS表示。

Conclusion: FISCIDS表示法为广泛非线性函数提供了精确的参数化模型，适用于大多数实际科学工程问题中的函数表示。

Abstract: Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation.

</details>


### [191] [Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN](https://arxiv.org/abs/2512.03835)
*Ghoshana Bista,Abbas Bradai,Emmanuel Moulay,Abdulhalim Dandoush*

Main category: eess.SY

TL;DR: 本文提出了一种基于多智能体深度强化学习（MADRL）的框架，用于优化5G网络中无人机基站的位置、资源分配、服务质量和能效，通过三种算法（MAPPO、MADDPG、MADQN）在不同场景下实现最佳性能平衡。


<details>
  <summary>Details</summary>
Motivation: 随着5G及未来网络对稳健、可扩展无线网络的需求增长，无人机作为移动基站被部署以增强密集城市和欠发达农村地区的覆盖。需要一种智能框架来联合优化无人机定位、资源分配、服务质量和能效，同时满足不同用户群体的差异化需求。

Method: 采用多智能体深度强化学习框架，整合了三种算法：近端策略优化（MAPPO）、多智能体深度确定性策略梯度（MADDPG）和多智能体深度Q网络（MADQN）。采用集中训练分散执行（CTDE）架构，将用户分为Premium（A）、Silver（B）和Bronze（C）三个优先级切片，每个切片有不同的服务质量要求。

Result: 在真实城市和农村场景的实验中，MAPPO在干扰丰富的环境中实现了最佳的整体QoS-能效平衡；MADDPG在开放农村环境中能获得略高的信干噪比，但能耗更高；MADQN为离散动作空间提供了计算高效的基线。结果表明没有单一算法在所有场景中都占优，算法适用性取决于环境拓扑、用户密度和服务需求。

Conclusion: MADRL驱动的无人机系统在下一代无线网络中具有增强可扩展性、可靠性和差异化QoS交付的潜力。算法选择应根据具体环境特征和性能要求进行权衡，没有通用的最优解决方案。

Abstract: The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks.

</details>


### [192] [Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN](https://arxiv.org/abs/2512.03846)
*Mojtaba Fanoodi,Farzaneh Abdollahi,Mahdi Aliyari Shoorehdeli*

Main category: eess.SY

TL;DR: 提出一种针对HRSG蒸汽温度调节的容错控制框架，结合滑模观测器、物理信息神经网络和单边滑模控制器，处理执行器故障并保持热力学一致性。


<details>
  <summary>Details</summary>
Motivation: 解决热回收蒸汽发生器(HRSG)中过热器喷水减温器阀门退化导致的执行器故障问题，确保蒸汽温度稳定控制，提高电厂运行可靠性。

Method: 采用三组件协同架构：1)滑模观测器(SMO)估计未测量的热状态；2)物理信息神经网络(PINN)利用物理定律约束估计乘性执行器故障；3)单边滑模控制器(SMC)根据估计故障自适应调整控制，同时最小化过度执行。

Result: 通过李雅普诺夫分析建立了严格的均匀最终有界性(UUB)，在实际HRSG运行数据验证中，框架表现出有效的故障适应能力，减少温度超调，在阀门效能损失情况下保持蒸汽温度在设定点1°C范围内。

Conclusion: 该工作将控制理论与物理引导的机器学习相结合，为电厂韧性提供了实际可部署的解决方案，并可扩展到受乘性故障影响的热系统。

Abstract: This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation.
  The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency.
  Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss.
  This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults.

</details>


### [193] [An Information Theory of Finite Abstractions and their Fundamental Scalability Limits](https://arxiv.org/abs/2512.03977)
*Giannis Delimpaltadakis,Gabriel Gleizer*

Main category: eess.SY

TL;DR: 该论文首次为动力系统的有限抽象建立了统计量化理论，揭示了抽象精度与规模之间的基本权衡关系，通过率失真理论证明了抽象存在维度灾难的根本限制。


<details>
  <summary>Details</summary>
Motivation: 尽管有限抽象作为动力系统的离散近似已被研究数十年，但缺乏关于其精度与规模权衡的正式理论结果。现有共识认为抽象存在维度灾难问题，但缺乏量化分析。

Method: 将抽象视为编码器-解码器对，使用率失真理论（信息论中研究有损压缩的分支）进行分析。率表示抽象规模，失真表示抽象精度，定义为抽象轨迹与系统轨迹之间的空间平均偏差。

Result: 推导出给定系统动力学和抽象规模阈值下，最小抽象失真的基本下界。该界限依赖于动力学的复杂性（通过广义熵度量），并在某些动力系统上证明了界限的紧致性。

Conclusion: 建立了抽象精度-规模权衡的统计量化理论，揭示了抽象可扩展性的基本限制。该理论可用于构建最优抽象，并通过混沌系统示例展示了其应用价值。

Abstract: Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system.

</details>


### [194] [Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder](https://arxiv.org/abs/2512.03990)
*Soha Ilbeigi,Ashkan Bagherzadeh,Alireza Sharifi*

Main category: eess.SY

TL;DR: 提出一种基于模型主动控制与神经网络相结合的新方法，用于控制圆柱结构的涡激振动，在存在建模不确定性的情况下实现高达99%的振动抑制。


<details>
  <summary>Details</summary>
Motivation: 涡激振动对海洋立管、高层建筑和可再生能源系统等工程应用构成重大挑战，需要有效的控制方法来提高结构效率、稳定性和使用寿命。

Method: 采用基于模型的主动控制策略与神经网络集成，构建闭环控制系统，利用系统动态状态的反馈生成自适应控制指令，并实施简单学习和复合学习两种控制方法。

Result: 两种控制策略均显著增强了振动抑制效果，在系统存在不确定性的情况下实现了高达99%的振动减少，证明了该方法在缓解涡激振动方面的有效性。

Conclusion: 所提出的方法具有增强受涡激振动影响结构的效率、稳定性和使用寿命的潜力，通过可控性分析验证了控制策略的有效性。

Abstract: Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [195] [A note on the impossibility of conditional PAC-efficient reasoning in large language models](https://arxiv.org/abs/2512.03057)
*Hao Zeng*

Main category: stat.ML

TL;DR: 证明了在大语言模型中条件性PAC高效推理的不可能性结果


<details>
  <summary>Details</summary>
Motivation: 最近的研究为在昂贵专家模型和廉价快速模型之间切换的复合模型建立了边际PAC效率保证，但条件性（逐点）保证是否可能尚不清楚

Method: 通过理论分析证明在无分布设置下条件性PAC效率的不可能性

Result: 对于非原子输入空间，任何实现条件性PAC效率的算法都必须是平凡的，即对于几乎每个输入，它必须以至少1-α的概率依赖专家模型

Conclusion: 条件性PAC效率保证在无分布设置下是不可能的，这为复合模型的理论研究提供了重要的限制性结果

Abstract: We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-α$ for almost every input.

</details>


### [196] [Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback](https://arxiv.org/abs/2512.03208)
*Pangpang Liu,Junwei Lu,Will Wei Sun*

Main category: stat.ML

TL;DR: 论文提出了一种考虑人类反馈异质性的奖励模型估计与统计推断方法，用于大语言模型对齐，通过联合建模答案潜在奖励和人类理性，解决了异质偏好下的奖励学习问题。


<details>
  <summary>Details</summary>
Motivation: 人类反馈在RLHF中具有固有的异质性，这给可靠的奖励学习带来了重大挑战。现有方法往往忽视这种异质性，导致奖励估计不可靠，缺乏统计推断能力。

Method: 采用异质偏好框架，联合建模答案的潜在奖励和人类理性，将其转化为双凸优化问题，并通过交替梯度下降算法求解。建立了估计器的理论保证，包括收敛性和渐近分布。

Result: 方法能够为奖励估计构建置信区间，支持有效的统计比较，并将不确定性纳入最佳N策略框架。仿真实验验证了方法的有效性，真实LLM数据应用显示了在奖励建模中考虑不确定性的实际价值。

Conclusion: 提出的异质偏好框架为LLM对齐中的奖励学习提供了可靠的统计推断工具，能够处理人类反馈的异质性，为奖励估计提供不确定性量化，从而改进对齐策略。

Abstract: We study estimation and statistical inference for reward models used in aligning large language models (LLMs). A key component of LLM alignment is reinforcement learning from human feedback (RLHF), where humans compare pairs of model-generated answers and their preferences are used to train a reward model. However, human feedback is inherently heterogeneous, creating significant challenges for reliable reward learning. To address this, we adopt a heterogeneous preference framework that jointly models the latent reward of answers and human rationality. This leads to a challenging biconvex optimization problem, which we solve via an alternating gradient descent algorithm. We establish theoretical guarantees for the resulting estimator, including its convergence and asymptotic distribution. These results enable the construction of confidence intervals for reward estimates. Leveraging these uncertainty quantification results, we conduct valid statistical comparisons between rewards and incorporate uncertainty into the best-of-$N$ (BoN) policy framework. Extensive simulations demonstrate the effectiveness of our method, and applications to real LLM data highlight the practical value of accounting for uncertainty in reward modeling for LLM alignment.

</details>


### [197] [Iterative Tilting for Diffusion Fine-Tuning](https://arxiv.org/abs/2512.03234)
*Jean Pachebat,Giovanni Conforti,Alain Durmus,Yazid Janati*

Main category: stat.ML

TL;DR: 提出了一种无需梯度的迭代倾斜方法，用于将扩散模型微调至奖励倾斜分布，通过将大奖励倾斜分解为多个小倾斜来实现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将扩散模型微调至奖励倾斜分布时，通常需要反向传播通过采样链，计算成本高且实现复杂。需要一种更简单、无需梯度的替代方法。

Method: 迭代倾斜方法：将大奖励倾斜exp(λr)分解为N个顺序的小倾斜，每个小倾斜通过一阶泰勒展开获得可处理的分数更新。仅需奖励函数的前向评估，避免通过采样链反向传播。

Result: 在具有线性奖励的二维高斯混合模型上验证，该模型的精确倾斜分布有闭式解，证明了方法的有效性。

Conclusion: 迭代倾斜是一种简单有效的梯度自由方法，能够将扩散模型微调至奖励倾斜分布，避免了传统方法中复杂的反向传播需求。

Abstract: We introduce iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions. The method decomposes a large reward tilt $\exp(λr)$ into $N$ sequential smaller tilts, each admitting a tractable score update via first-order Taylor expansion. This requires only forward evaluations of the reward function and avoids backpropagating through sampling chains. We validate on a two-dimensional Gaussian mixture with linear reward, where the exact tilted distribution is available in closed form.

</details>


### [198] [Novelty detection on path space](https://arxiv.org/abs/2512.03243)
*Ioannis Gasteratos,Antoine Jacquier,Maud Lemercier,Terry Lyons,Cristopher Salvi*

Main category: stat.ML

TL;DR: 该论文提出了一种基于路径空间签名的异常检测方法，通过假设检验框架和运输成本不等式获得错误率边界，推导了条件风险值的精确公式，并建立了统计功效的下界。


<details>
  <summary>Details</summary>
Motivation: 在路径空间上进行异常检测是一个重要问题，需要开发能够处理复杂路径数据的统计方法。现有方法在处理非高斯分布和计算条件风险值方面存在局限。

Method: 1. 将路径空间异常检测构建为假设检验问题，使用基于签名的检验统计量
2. 利用运输成本不等式获得错误率边界，扩展到RDE解的非高斯分布
3. 通过洗牌积推导条件风险值平滑替代的精确公式
4. 建立类型II错误的下界，给出统计功效的一般边界
5. 开发优化平滑CVaR目标的一类SVM算法

Result: 1. 获得了超出高斯分布的尾边界，可用于估计分位数和p值
2. 推导了条件风险值平滑替代的精确公式，基于期望签名
3. 建立了类型II错误的下界，为绝对连续分布提供了一般功效边界
4. 数值评估显示基于签名的检验统计量在合成异常扩散数据和真实分子生物学数据上表现良好

Conclusion: 该研究提出了一种基于签名的路径空间异常检测框架，通过理论分析和算法开发，为处理复杂路径数据提供了有效的统计工具，在理论和应用层面都有重要贡献。

Abstract: We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.

</details>


### [199] [Colored Markov Random Fields for Probabilistic Topological Modeling](https://arxiv.org/abs/2512.03727)
*Lorenzo Marinucci,Leonardo Di Nino,Gabriele D'Acunto,Mario Edoardo Pandolfo,Paolo Di Lorenzo,Sergio Barbarossa*

Main category: stat.ML

TL;DR: 提出彩色马尔可夫随机场（CMRF），通过链接着色同时建模条件独立性和边际独立性，扩展传统高斯马尔可夫随机场，适用于拓扑空间上的高斯边缘变量分析。


<details>
  <summary>Details</summary>
Motivation: 传统概率图模型在分析定义在拓扑空间上的变量时表达能力有限，因为底层拓扑结构会影响统计关系。需要一种能够同时建模条件依赖和边际依赖的模型。

Method: 引入彩色马尔可夫随机场（CMRF），基于Hodge理论，通过链接着色扩展经典高斯马尔可夫随机场：连接性编码条件独立性，颜色编码边际独立性。

Result: 通过物理网络上的分布式估计案例研究量化CMRF的优势，与具有不同拓扑先验水平的基线方法进行比较。

Conclusion: CMRF能够更好地建模拓扑空间上的统计关系，为复杂系统分析和决策支持提供更强大的工具。

Abstract: Probabilistic Graphical Models (PGMs) encode conditional dependencies among random variables using a graph -nodes for variables, links for dependencies- and factorize the joint distribution into lower-dimensional components. This makes PGMs well-suited for analyzing complex systems and supporting decision-making. Recent advances in topological signal processing highlight the importance of variables defined on topological spaces in several application domains. In such cases, the underlying topology shapes statistical relationships, limiting the expressiveness of canonical PGMs. To overcome this limitation, we introduce Colored Markov Random Fields (CMRFs), which model both conditional and marginal dependencies among Gaussian edge variables on topological spaces, with a theoretical foundation in Hodge theory. CMRFs extend classical Gaussian Markov Random Fields by including link coloring: connectivity encodes conditional independence, while color encodes marginal independence. We quantify the benefits of CMRFs through a distributed estimation case study over a physical network, comparing it with baselines with different levels of topological prior.

</details>


### [200] [Comparison of neural network training strategies for the simulation of dynamical systems](https://arxiv.org/abs/2512.03851)
*Paul Strasser,Andreas Pfeffer,Jakob Weber,Markus Gurtner,Andreas Körner*

Main category: stat.ML

TL;DR: 该论文比较了神经网络建模非线性动态系统时的两种主要训练策略：并行训练和串行-并行训练，发现尽管当前实践中串行-并行训练占主导，但并行训练在长期预测精度上表现更优，应作为默认训练策略。


<details>
  <summary>Details</summary>
Motivation: 神经网络已成为从数据建模非线性动态系统的广泛工具，但训练策略的选择仍是关键设计决策，特别是在仿真任务中。当前实践中训练策略的选择缺乏明确指导，且文献中术语使用不一致。

Method: 通过实证分析比较两种主要训练策略：并行训练和串行-并行训练。研究涵盖五种神经网络架构和两个实际案例：气动阀门测试台和工业机器人基准测试。同时澄清文献中不一致的术语，并将两种策略与系统辨识概念联系起来。

Result: 研究发现，尽管串行-并行训练在当前实践中占主导地位，但并行训练在长期预测精度上表现更优，能产生更好的仿真结果。研究还澄清了相关术语的混淆。

Conclusion: 并行训练应被视为基于神经网络的动态系统仿真的默认训练策略。该研究为神经网络在动态系统建模中的训练策略选择提供了实证依据和明确指导。

Abstract: Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [201] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 本文主张将AI对齐重新构想为通过基于过程、多智能体、发展性机制来构建具有熵减性、原因响应性的智能体，而非编码固定的人类价值内容。


<details>
  <summary>Details</summary>
Motivation: 传统基于内容的价值规范方法存在结构性不稳定问题，这是由于"是-应当"鸿沟、价值多元主义和扩展框架问题共同导致的"规范陷阱"。需要新的理论框架来理解多智能体对齐动态。

Method: 提出三个哲学贡献：1) 阐述"规范陷阱"论证；2) 提出"熵减"作为理解多智能体对齐动态的信息论框架；3) 建立基于兼容主义指导控制理论的真实与模拟道德能力的功能区分，并设计具身实验范式和验证机制。

Result: 建立了关于人工系统中价值涌现和道德能动性的具体、可证伪预测，但实证验证仍在进行中。该框架为更广泛研究计划提供了哲学基础。

Conclusion: AI对齐应转向基于过程、多智能体、发展性的方法，通过熵减机制构建原因响应性智能体，而非试图编码固定的人类价值内容。这为解决规范陷阱问题提供了新的理论方向。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [202] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 提出基于第一性原理的"权重计算主义"认知架构，通过逻辑原子和基础操作实现可解释决策，为AGI提供透明、可对齐的理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前AI范式作为"经验架构师"面临可解释性和价值对齐的根本挑战，需要一种基于第一性原理的认知架构来解决这些问题。

Method: 将认知解构为不可分割的逻辑原子和两个基本操作（指向和比较），通过可解释的权重计算模型（权重=收益×概率）形式化决策，所有值可追溯到可审计的初始权重集，使用基于图算法的计算引擎和全局工作空间工作流实现。

Result: 该架构在未见场景中实现了透明、类人的推理和鲁棒学习，为构建可信赖和对齐的AGI奠定了实践和理论基础。

Conclusion: 权重计算主义为AGI提供了一条可行的路径，实现了根本的可解释性、内在的泛化能力和可追溯的价值对齐，为解决当前AI的核心挑战提供了新方向。

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [203] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 研究探索符号求解器何时能增强传统长推理链方法，发现符号求解器主要在需要有限隐式推理但搜索空间大的约束满足问题上有效，而最新LLM在推理深度浅的演绎问题上表现更好。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长推理链在复杂推理任务上表现良好，但这种方法可能导致大量token开销，甚至因"过度思考"而产生错误答案。符号求解器集成方法利用LLM的代码生成能力将推理任务转化为可执行代码，然后用符号求解器解决，但何时这种集成方法能增强传统长推理链仍是一个开放问题。

Method: 采用符号求解器集成方法，利用LLM的代码生成能力将推理任务翻译成可执行代码，然后使用符号求解器解决。通过实验比较传统长推理链方法与符号求解器集成方法在不同类型问题上的表现。

Result: 符号求解器集成方法仅在需要有限隐式推理但涉及充足搜索空间的问题上有帮助。最新LLM（如GPT-4o）在推理深度浅的演绎问题上表现更好，而符号求解器集成方法显著提高了LLM在需要重复回溯的约束满足问题上的性能。当提供声明性示例时，即使是CodeLlama-13B也能在困难的斑马谜题上超越GPT-4o。

Conclusion: 符号求解器集成方法对特定类型的问题（特别是约束满足问题）有显著优势，而传统长推理链方法在其他类型问题上可能更有效。两种方法各有适用场景，需要根据问题特性选择合适的方法。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [204] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 研究比较了主动推理中四种偏好分布定义方式（硬目标vs软目标，有无目标塑造）在网格世界导航任务中的表现，发现目标塑造能提升性能但会牺牲环境动态学习。


<details>
  <summary>Details</summary>
Motivation: 主动推理使用期望自由能作为规划目标，但偏好分布如何定义及其对推理和学习的影响在文献中很少被关注。本研究旨在探索不同偏好分布定义方式对智能体性能的影响。

Method: 考虑了四种偏好分布定义方式：硬目标vs软目标，以及有无目标塑造（中间目标）。在网格世界导航任务中比较了四种智能体的表现。

Result: 目标塑造能带来最佳整体性能（促进利用），但会牺牲对环境转移动态的学习（阻碍探索）。

Conclusion: 偏好分布的定义方式显著影响主动推理智能体的性能，目标塑造在提升利用能力的同时会损害探索能力，需要在两者之间进行权衡。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [205] [Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia](https://arxiv.org/abs/2512.03318)
*Chandler Smith,Marwa Abdulhai,Manfred Diaz,Marko Tesic,Rakshit S. Trivedi,Alexander Sasha Vezhnevets,Lewis Hammond,Jesse Clifton,Minsuk Chang,Edgar A. Duéñez-Guzmán,John P. Agapiou,Jayd Matyas,Danny Karmon,Akash Kundu,Aliaksei Korshuk,Ananya Ananya,Arrasy Rahman,Avinaash Anand Kulandaivel,Bain McHale,Beining Zhang,Buyantuev Alexander,Carlos Saith Rodriguez Rojas,Caroline Wang,Chetan Talele,Chenao Liu,Chichen Lin,Diana Riazi,Di Yang Shi,Emanuel Tewolde,Elizaveta Tennant,Fangwei Zhong,Fuyang Cui,Gang Zhao,Gema Parreño Piqueras,Hyeonggeun Yun,Ilya Makarov,Jiaxun Cui,Jebish Purbey,Jim Dilkes,Jord Nguyen,Lingyun Xiao,Luis Felipe Giraldo,Manuela Chacon-Chamorro,Manuel Sebastian Rios Beltran,Marta Emili García Segura,Mengmeng Wang,Mogtaba Alim,Nicanor Quijano,Nico Schiavone,Olivia Macmillan-Scott,Oswaldo Peña,Peter Stone,Ram Mohan Rao Kadiyala,Rolando Fernandez,Ruben Manrique,Sunjia Lu,Sheila A. McIlraith,Shamika Dhuri,Shuqing Shi,Siddhant Gupta,Sneheel Sarangi,Sriram Ganapathi Subramanian,Taehun Cha,Toryn Q. Klassen,Wenming Tu,Weijian Fan,Wu Ruiyang,Xue Feng,Yali Du,Yang Liu,Yiding Wang,Yipeng Kang,Yoonchang Sung,Yuxuan Chen,Zhaowei Zhang,Zhihan Wang,Zhiqiang Wu,Ziang Chen,Zilong Zheng,Zixia Jia,Ziyan Wang,Dylan Hadfield-Menell,Natasha Jaques,Tim Baarslag,Jose Hernandez-Orallo,Joel Z. Leibo*

Main category: cs.AI

TL;DR: 本文提出了一种评估LLM智能体在零样本、混合动机环境中合作能力的方法，使用Concordia多智能体模拟环境，通过NeurIPS 2024竞赛发现当前智能体在说服和规范执行等需要泛化的合作场景中存在显著能力差距。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在社会互动方面展现出强大能力，并被部署到与人类和人工智能体交互的场景中。然而，现有评估方法无法衡量这些能力在新颖社交情境中的泛化能力，这是LLM智能体发展的关键前沿问题。

Method: 引入Concordia自然语言多智能体模拟环境，通过评估智能体在不同伙伴和情境中识别和利用互利机会的能力，来衡量通用合作智能。该方法在NeurIPS 2024 Concordia竞赛中得到实证应用。

Result: NeurIPS 2024竞赛结果显示，当前智能体能力与可靠合作所需的稳健泛化之间存在显著差距，特别是在需要说服和规范执行的场景中。智能体在谈判到集体行动等多样化场景中实现互利的能力有限。

Conclusion: LLM智能体在合作能力泛化方面仍存在重大挑战，特别是在复杂社交情境中。Concordia评估方法为衡量和提升智能体合作智能提供了有效框架，揭示了未来研究需要关注说服和规范执行等关键能力的发展。

Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.

</details>


### [206] [Multimodal Reinforcement Learning with Agentic Verifier for AI Agents](https://arxiv.org/abs/2512.03438)
*Reuben Tan,Baolin Peng,Zhengyuan Yang,Hao Cheng,Oier Mees,Theodore Zhao,Andrea Tupini,Isar Meijier,Qianhui Wu,Yuncong Yang,Lars Liden,Yu Gu,Sheng Zhang,Xiaodong Liu,Lijuan Wang,Marc Pollefeys,Yong Jae Lee,Jianfeng Gao*

Main category: cs.AI

TL;DR: Argos是一个用于多模态强化学习的智能奖励代理，通过选择多种评分函数来评估最终答案、时空定位和推理过程质量，提升模型性能并减少奖励黑客行为。


<details>
  <summary>Details</summary>
Motivation: 当前多模态强化学习模型主要使用基于最终结果的稀疏奖励，缺乏对推理过程的细粒度指导。不同样本需要不同的评分函数，且教师模型可能提供噪声信号，因此需要更智能的奖励机制。

Method: 提出Argos奖励代理，为每个样本从教师模型和基于规则的评分函数池中选择，同时评估：1)最终响应准确性；2)实体和动作的时空定位；3)推理过程质量。应用于SFT数据筛选和RL训练。

Result: 在空间推理、视觉幻觉以及机器人和具身AI基准测试中取得最先进结果。证明仅依赖SFT后训练不足，需要在线验证防止模型崩溃到非接地解决方案。还能减少奖励黑客行为。

Conclusion: Argos通过帕累托最优性理论证明其有效性，为多模态强化学习提供了更智能的奖励机制，显著提升模型性能并解决现有方法的局限性。

Abstract: Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.

</details>


### [207] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 提出一种通信受限的多智能体强化学习框架，通过区分有损/无损消息并量化通信影响来提升复杂动态环境中的学习效果


<details>
  <summary>Details</summary>
Motivation: 现实世界场景中普遍存在有损通信问题，现有多智能体通信方法由于可扩展性和鲁棒性有限，难以应用于复杂动态环境

Method: 提出广义通信受限模型统一描述不同场景的通信条件，作为学习先验区分有损/无损消息；使用双互信息估计器解耦有损/无损消息对分布式决策的影响；引入通信受限多智能体强化学习框架，将通信消息影响量化到全局奖励中

Result: 在多个通信受限基准测试中验证了方法的有效性

Conclusion: 提出的通信受限多智能体强化学习框架能够有效处理现实世界中的有损通信问题，提升在复杂动态环境中的学习性能

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [208] [PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks](https://arxiv.org/abs/2512.03549)
*Yuki Orimo,Iori Kurata,Hodaka Mori,Ryuhei Okuno,Ryohto Sawada,Daisuke Okanohara*

Main category: cs.AI

TL;DR: PARC是一个用于自主执行长时程计算任务的编码代理，采用分层多智能体架构，具备自我评估和反馈机制，能够在材料科学和Kaggle竞赛中实现大规模自主工作。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI系统在长时程计算任务中需要持续人工干预的问题，开发能够自主检测和纠正错误、持续进展的智能代理。

Method: 采用分层多智能体架构，包含任务规划、执行和独立的自我评估反馈机制，能够从独立上下文评估自身行动和结果。

Result: 在材料科学中成功复现锂离子传导和合金偏析研究的关键结果，协调数十个并行模拟任务（每个约43小时计算）；在Kaggle实验中，从自然语言指令开始，实现数据分析和搜索策略，产生与人工基线竞争的结果。

Conclusion: 分层多智能体系统与自我评估反馈机制的结合，使AI系统能够独立进行大规模科学和分析工作，展示了自主智能代理在复杂计算任务中的潜力。

Abstract: We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.

</details>


### [209] [Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks](https://arxiv.org/abs/2512.03560)
*Gianni Molinari,Fabio Ciravegna*

Main category: cs.AI

TL;DR: RP-ReAct是一种新型多智能体方法，通过将战略规划与低级执行解耦，解决了企业级复杂任务中单智能体架构的轨迹不稳定性和上下文窗口限制问题。


<details>
  <summary>Details</summary>
Motivation: 当前自主智能体在企业级复杂任务中面临两大挑战：1) 单智能体架构的单一规划-执行循环导致轨迹不稳定；2) 为数据隐私使用本地开源模型时，较小的上下文窗口难以处理大型工具输出。

Method: 提出RP-ReAct多智能体架构，包含：1) 推理规划智能体(RPA)，负责子步骤规划并持续分析执行结果；2) 代理执行智能体(PEA)，使用ReAct方法将子步骤转换为具体工具交互；3) 上下文保存策略，通过外部存储和按需访问管理大型工具输出。

Result: 在ToolQA基准测试中，使用六种开源推理模型评估，RP-ReAct在性能、泛化能力、鲁棒性和稳定性方面均优于现有最先进基线方法。

Conclusion: RP-ReAct通过解耦规划与执行，结合上下文管理策略，为企业级可部署的智能体解决方案提供了有效途径，在不同模型规模下均表现出增强的鲁棒性和稳定性。

Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.

</details>


### [210] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 提出PAN编程模型，通过概率天使非确定性分离智能体工作流逻辑与推理时策略，实现EnCompass框架


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体编程方法通常将核心工作流逻辑与推理时策略（如树搜索）耦合在一起，限制了灵活性和实验效率

Method: 引入"概率天使非确定性"（PAN）编程模型，使用Python装饰器将智能体工作流程序编译为搜索空间，实现工作流与推理策略的解耦

Result: 开发了EnCompass框架，通过三个案例研究证明该框架能快速提升智能体可靠性，轻松切换不同推理策略，且代码增量小

Conclusion: PAN编程模型和EnCompass框架为LLM智能体开发提供了更灵活、可实验的编程范式，显著改善了开发效率和系统可靠性

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [211] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule：零售品类与定价优化的自动化业务规则生成框架，通过LLM解析非结构化文本、博弈论约束优化和可解释决策蒸馏，解决理论与现实经济复杂性之间的系统错位问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有理论模型与现实经济复杂性之间的系统错位问题，具体包括：1) 非结构化文本数据模态不匹配阻碍准确客户画像；2) 动态特征纠缠挑战非线性价格弹性和时变属性建模；3) 多层业务约束导致的运营不可行性。

Method: 采用三层架构：1) 混合知识融合引擎，使用LLM深度语义解析非结构化文本，将分销商协议和销售评估转化为结构化特征；2) 博弈论约束优化机制，通过双边效用函数动态协调供应链利益；3) 可解释决策蒸馏接口，利用LLM引导的符号回归优化定价策略和可审计业务规则。

Result: 在真实零售环境中验证，相比系统性B2C基线实现更高利润，同时确保运营可行性，建立了从非结构化知识注入到多智能体优化再到可解释策略合成的闭环管道。

Conclusion: DeepRule建立了统一非结构化知识注入、多智能体优化和可解释策略合成的闭环管道，为真实经济智能提供了系统性解决方案，弥合了理论模型与现实经济复杂性之间的鸿沟。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [212] [MemVerse: Multimodal Memory for Lifelong Learning Agents](https://arxiv.org/abs/2512.03627)
*Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: MemVerse：一个模型无关的即插即用记忆框架，通过结合快速参数化召回与分层检索式记忆，解决AI代理的记忆问题，支持多模态持续学习和推理。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模语言和视觉模型快速发展，但AI代理仍存在根本性限制：无法记忆。没有可靠的记忆，代理会灾难性遗忘过去经验，难以进行长时程推理，无法在多模态或交互环境中连贯操作。

Method: MemVerse采用模型无关的即插即用架构，结合快速参数化召回与分层检索式记忆。维护短期记忆处理近期上下文，将原始多模态经验转化为结构化长期记忆，组织为分层知识图谱。引入周期性蒸馏机制，将长期记忆中的关键知识压缩到参数化模型中，实现快速可微召回。

Result: 大量实验表明，MemVerse显著提升了多模态推理和持续学习效率，使代理能够在扩展交互中记忆、适应和连贯推理。

Conclusion: MemVerse通过桥接参数化与检索式记忆，解决了AI代理的记忆瓶颈，实现了可扩展的自适应多模态智能，支持持续整合、自适应遗忘和有界内存增长。

Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

</details>


### [213] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个基于多智能体角色协作的自动启发式设计系统，通过四个专门角色（探索者、利用者、批评者、整合者）的协作，在组合优化问题上生成高质量启发式方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动启发式设计研究通常只考虑单一角色，缺乏多样性和协作机制。为了提升启发式设计的多样性和质量，需要建立一个多角色协作的系统框架。

Method: 提出RoCo多智能体角色协作系统，包含四个专门角色：探索者（创造性、多样性驱动）、利用者（保守性、效率导向）、批评者（评估效果并提供反馈）、整合者（平衡创新与利用）。这些角色通过结构化多轮交互过程协作，包括反馈、精炼和精英突变。

Result: 在五个不同组合优化问题的白盒和黑盒设置下进行评估，RoCo表现优异，生成的启发式方法在性能上超越了现有方法（包括ReEvo和HSEvo），在白盒和黑盒场景中都取得了更好的结果。

Conclusion: 基于角色的协作范式为鲁棒且高性能的自动启发式设计建立了新标准，通过多角色协作显著提升了启发式设计的多样性和质量。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [214] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: 提出Omni-AutoThink自适应推理框架，通过动态调整推理深度解决现有Omni模型推理行为僵化的问题，在文本、音频、视觉等多模态任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在推理行为上存在僵化问题：要么对简单问题过度思考，要么在需要推理时无法有效推理。需要一种能够根据任务难度动态调整推理深度的自适应框架。

Method: 提出两阶段框架：1) 自适应监督微调阶段，使用大规模推理增强数据赋予模型基础推理能力；2) 自适应强化学习阶段，基于任务复杂度和奖励反馈优化推理行为。同时构建了涵盖文本、文本-音频、文本-视觉、文本-音频-视觉多模态的自适应推理基准。

Result: 实验结果表明，相比先前基线方法，提出的框架在自适应推理性能上取得显著提升。所有基准数据和代码将公开。

Conclusion: Omni-AutoThink通过动态调整推理深度有效解决了Omni模型推理行为僵化的问题，在多模态自适应推理任务上表现出色，为未来自适应推理系统的发展提供了重要基础。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [215] [A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)](https://arxiv.org/abs/2512.03887)
*Saurav Prateek*

Main category: cs.AI

TL;DR: 提出Static-DRA，一种基于树状静态工作流的深度研究代理，通过可配置的Depth和Breadth参数让用户平衡研究质量与计算成本


<details>
  <summary>Details</summary>
Motivation: 现有静态RAG管道在处理复杂多轮研究任务时存在局限，需要更灵活的深度研究代理系统

Method: 构建基于树状静态工作流的代理架构，包含Supervisor、Independent和Worker三种代理，通过Depth和Breadth参数控制研究深度和广度

Result: 在DeepResearch Bench上使用RACE框架评估，Depth=2、Breadth=5配置下获得34.72分，验证参数增加能提升研究深度和评分

Conclusion: Static-DRA提供了实用且资源感知的解决方案，赋予用户对深度研究过程的透明控制，代码和结果已开源

Abstract: The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.
  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.
  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/

</details>


### [216] [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931)
*Vineel Tummala,Daniela Inclezan*

Main category: cs.AI

TL;DR: 本文提出了一种基于逻辑编程的政策感知自主代理框架，能够推理违规行为的潜在惩罚并相应行动。相比以往只关注合规的方法，该框架考虑为达成高风险目标可能需要偏离政策的情况，并通过模拟现实人类决策辅助政策制定者。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注确保合规性，但实际场景中为达成高风险目标可能需要偏离政策。同时，建模违规行为可以帮助政策制定者模拟现实人类决策过程。需要一种能够权衡合规与目标达成、考虑惩罚后果的推理框架。

Method: 扩展Gelfond和Lobo的授权与义务政策语言(AOPL)以纳入惩罚机制，集成答案集编程(ASP)进行推理。开发从扩展AOPL到ASP的自动翻译，并改进基于ASP的规划算法以考虑惩罚。引入基于惩罚的推理来区分违规计划，优先选择惩罚最小的方案。

Result: 在两个领域进行的实验表明，该框架能生成更高质量的计划，避免有害行动，在某些情况下还能提高计算效率。相比先前方法，确保政策格式良好、考虑政策优先级，并通过明确识别规则违规及其后果增强可解释性。

Conclusion: 该框架展示了增强自主决策和为政策改进提供信息的潜力。通过惩罚推理机制，能够在必要时偏离政策达成目标，同时最小化负面后果，为政策感知自主代理提供了更实用的解决方案。

Abstract: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [217] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 本文提出了一个用于评估基于LLM的工业自动化代理的标准化基准测试框架，包含可执行的模拟环境和五个复杂度类别的Blocksworld问题，通过MCP协议实现工具接口标准化。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要灵活的自适应控制策略，基于LLM的代理具有这种潜力，但缺乏标准化的基准测试来系统比较不同代理架构的性能。

Method: 1) 创建包含可执行模拟环境的基准测试，基于Blocksworld问题设计五个复杂度类别；2) 集成模型上下文协议(MCP)作为标准化工具接口，使不同代理架构无需修改即可连接评估；3) 实现单代理系统验证基准的适用性。

Result: 开发了一个可执行的基准测试环境，建立了定量评估指标，能够系统比较基于LLM的规划和执行方法，并通过单代理实现验证了框架的实用性。

Conclusion: 提出的基准测试框架为评估和比较基于LLM的工业自动化代理提供了标准化平台，通过MCP协议实现了工具接口的统一，有助于推动自适应规划执行方法的研究和发展。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>
