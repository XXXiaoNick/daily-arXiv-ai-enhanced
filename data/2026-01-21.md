<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 184]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CY](#cs.CY) [Total: 32]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 5]
- [eess.SY](#eess.SY) [Total: 43]
- [cs.LG](#cs.LG) [Total: 185]
- [cs.AI](#cs.AI) [Total: 101]
- [math.OC](#math.OC) [Total: 44]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [econ.EM](#econ.EM) [Total: 10]
- [stat.ML](#stat.ML) [Total: 12]
- [q-fin.MF](#q-fin.MF) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths](https://arxiv.org/abs/2601.11564)
*Ahilan Ayyachamy Nadar Ponnusamy,Karthic Chandran,M Maruf Hossain*

Main category: cs.CL

TL;DR: 论文研究大语言模型在长上下文处理中的性能与质量权衡，发现无关上下文会导致非线性性能下降，KV缓存增长是关键因素，MoE架构在不同上下文规模下表现出异常行为。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口不断扩大，虽然支持了复杂的长文档分析，但也带来了严重的计算开销。需要研究在大量无关和干扰性上下文下，系统性能与模型质量之间的关键权衡。

Method: 使用密集Transformer架构（Llama-3.1-70B和Qwen1.5-14B）暴露于大量无关上下文中，分析性能退化模式。特别关注KV缓存的增长影响，并对MoE架构在不同上下文规模下的行为进行扩展分析。

Result: 发现与无关上下文相关的非线性性能下降，这种下降与KV缓存的增长密切相关。MoE架构在不同上下文规模下表现出独特的行为异常，表明在高token量下，架构优势可能被基础设施瓶颈所掩盖。

Conclusion: 大语言模型的长上下文扩展面临性能与质量的权衡挑战，KV缓存管理是关键瓶颈。MoE架构虽然理论上具有优势，但在实际大规模应用中可能受限于基础设施限制，需要更精细的系统优化。

Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.

</details>


### [2] [Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings](https://arxiv.org/abs/2601.11565)
*Pakorn Ueareeworakul,Shuman Liu,Jinghao Feng,Ling Hu,Zhantang Shi,Chengqi Sun,Liang Yao,Panyi Ouyang,Haibo Zhang,Anxiang Zeng*

Main category: cs.CL

TL;DR: Compass-Embedding v4是一个针对东南亚电商场景优化的多语言嵌入框架，通过类感知掩码、多样化训练语料构建和推理优化，解决了数据稀缺、噪声监督和生产约束等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着全球电商向新兴市场扩张，低资源语言缺乏高质量语义表示成为检索、推荐和搜索系统的瓶颈。东南亚电商场景面临数据稀缺、噪声监督和严格生产约束的联合挑战。

Method: 1. 提出类感知掩码(CAM)来抑制批量对比训练中的虚假负样本；2. 通过上下文合成数据生成、跨语言翻译和结构化电商数据构建多样化训练语料；3. 结合鲁棒性批量训练与球面模型合并，并通过vLLM和FP8量化优化推理。

Result: 在多项多语言基准测试和专有电商任务评估中，Compass-Embedding v4在主要东南亚语言上达到最先进性能，在领域特定检索和分类任务上显著优于通用嵌入模型，同时在高资源语言上保持竞争力。

Conclusion: Compass-Embedding v4成功解决了东南亚电商场景中的多语言嵌入挑战，为低资源语言提供了高质量的语义表示，同时满足生产环境的高吞吐量要求。

Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.

</details>


### [3] [Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology](https://arxiv.org/abs/2601.11567)
*Vanessa D'Amario,Randy Daniel,Alessandro Zanetti,Dhruv Edamadaka,Nitya Alaparthy,Joshua Tarkoff*

Main category: cs.CL

TL;DR: 评估六个小型开源医疗LLM在儿科内分泌学中的表现，发现高一致性不代表正确性，提示微小变化会导致输出分歧，系统级扰动也会显著影响模型输出，强调需要更全面的诊断框架。


<details>
  <summary>Details</summary>
Motivation: 目前小型开源医疗LLM的评估主要局限于医学多选题的准确性，缺乏对一致性、鲁棒性和推理行为的评估。需要更全面的评估框架来了解这些模型在真实临床决策支持场景中的潜在问题。

Method: 使用医学多选题结合人工评估和临床审查，评估六个小型开源医疗LLM。在确定性设置中检查提示变化对模型输出和自我评估偏见的影响；在随机性设置中评估输出变异性，并研究一致性与正确性之间的关系。

Result: HuatuoGPT-o1-8B表现最佳。高一致性并不代表正确性，尽管HuatuoGPT-o1-8B的一致性最高。模型表现出自我评估偏见和对候选解释顺序的依赖。专家审查发现错误推理中混合了临床可接受的响应和临床疏忽。系统级扰动（如CUDA构建差异）会导致模型输出的统计显著变化。

Conclusion: 语义上可忽略的提示微小变化会导致输出分歧，这对基于LLM评估的可重复性提出了担忧。不同随机机制下的输出变异性强调了需要更广泛的诊断框架来理解真实世界临床决策支持场景中的潜在陷阱。

Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.

</details>


### [4] [An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT](https://arxiv.org/abs/2601.11573)
*Muhammad Muneeb,David B. Ascher*

Main category: cs.CL

TL;DR: 提出一个可复现的LLM微调流水线，用于生物信息学领域，包含PRSGPT和BioStarsGPT两个用例，在多个指标上表现优异


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常缺乏复杂生物信息学应用所需的专业知识，需要开发领域特定的微调方法

Method: 九步流水线：整合多样数据源、结构化预处理、基于提示的QA生成、NLI质量控制、语义去重、聚类数据分割、LoRA参数高效微调，在三个LLM上验证

Result: Qwen2.5-7B表现最佳，PRSGPT的BLEU-4和ROUGE-1分别提升82%和70%，BioStarsGPT提升6%和18%；生成超过28,000个PRSGPT QA对和154,282个BioStarsGPT QA对；人工评估PRSGPT准确率61.9%，与Google Gemini相当但提供更丰富细节

Conclusion: 该流水线支持可扩展的领域特定LLM微调，实现隐私保护、本地部署的生物信息学助手，并探讨了实际应用中的挑战和缓解策略

Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.

</details>


### [5] [Concept Attractors in LLMs and their Applications](https://arxiv.org/abs/2601.11575)
*Sotirios Panagiotis Chytas,Vikas Singh*

Main category: cs.CL

TL;DR: LLMs内部表示可通过迭代函数系统解释，利用概念吸引子开发无需训练的方法解决多种任务


<details>
  <summary>Details</summary>
Motivation: LLMs在处理语义相关但表面形式不同的提示时，会在特定层产生相似的内部表示，这种现象需要理论解释并可用于实际应用

Method: 将LLM层视为迭代函数系统中的压缩映射，向概念特定的吸引子收敛，基于这些吸引子开发无需训练的直接操作方法

Result: 吸引子干预方法在语言翻译、幻觉减少、安全护栏和合成数据生成等任务上匹配或超越专门基线，在基线表现不佳的场景中具有良好泛化性

Conclusion: LLMs的内部表示行为可用迭代函数系统理论解释，基于吸引子的简单无训练方法为实际任务提供了高效替代方案，避免繁重的微调

Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.

</details>


### [6] [LimAgents: Multi-Agent LLMs for Generating Research Limitations](https://arxiv.org/abs/2601.11578)
*Ibrahim Al Azher,Zhishuai Guo,Hamed Alhoori*

Main category: cs.CL

TL;DR: LimAgents：一个多智能体LLM框架，通过整合OpenReview评论、作者陈述的局限性和引用文献，生成实质性研究局限性分析，相比零样本基线有显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前零样本大语言模型生成的研究局限性陈述往往流于表面（如数据集偏差或泛化性），通常只是重复作者已报告的内容，而未能深入分析方法论问题和上下文差距。许多作者也只披露部分或琐碎的局限性，使得这一问题更加严重。

Method: 提出LimAgents多智能体LLM框架，整合OpenReview评论和作者陈述的局限性作为更强的基础事实，并利用引用和被引文献捕捉更广泛的上下文弱点。不同智能体有特定角色：提取显式局限性、分析方法论差距、模拟同行评审视角、分析文献背景。Judge智能体精炼输出，Master智能体整合成清晰集合。同时引入基于LLM-as-a-Judge的点对点评估协议，更准确衡量覆盖度。

Result: 实验表明LimAgents显著提升性能：RAG+多智能体GPT-4o mini配置相比零样本基线获得+15.51%的覆盖度提升，Llama 3 8B多智能体设置实现+4.41%的改进。

Conclusion: LimAgents框架能够系统识别显式、隐式、同行评审导向和文献信息化的局限性，相比传统方法在生成实质性研究局限性方面有显著优势，为透明和严谨的科学研究提供了更好的工具。

Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.

</details>


### [7] [Bielik 11B v3: Multilingual Large Language Model for European Languages](https://arxiv.org/abs/2601.11579)
*Krzysztof Ociepa,Łukasz Flis,Remigiusz Kinas,Krzysztof Wróbel,Adrian Gwoździej*

Main category: cs.CL

TL;DR: Bielik 11B v3 是一个专门针对波兰语优化的先进语言模型，基于 Mistral 7B v0.2 架构扩展至110亿参数，在波兰语任务上表现卓越，甚至超越参数规模大2-6倍的模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个针对波兰语高度优化的语言模型，同时保持对其他欧洲语言的良好支持，为资源较少语言建立高效高性能模型的基准。

Method: 采用四阶段训练流程：连续预训练、监督微调（SFT）、直接偏好优化（DPO）和强化学习。基于 Mistral 7B v0.2 架构，通过深度扩展扩展到110亿参数。

Result: Bielik 11B v3 在波兰语任务上显著超越其他专门模型，并且在许多任务上优于参数规模大2-6倍的更大模型，从基础语言理解到复杂推理都表现出色。

Conclusion: 该模型不仅推进了波兰语的AI能力，还为开发资源高效、高性能的较少代表语言模型建立了新基准，其参数效率和量化选项支持在各种硬件配置上有效部署。

Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.
  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.
  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.

</details>


### [8] [Speculative Decoding: Performance or Illusion?](https://arxiv.org/abs/2601.11580)
*Xiaoxuan Liu,Jiaxiang Yu,Jongseok Park,Ion Stoica,Alvin Cheung*

Main category: cs.CL

TL;DR: 本文首次在真实生产级推理引擎(vLLM)上系统研究了推测解码(SD)技术，分析了多种SD变体在不同工作负载下的性能，发现验证阶段是主要瓶颈，实际性能与理论上限存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 推测解码已成为加速大语言模型推理的流行技术，但先前评估依赖研究原型和不切实际的小批量大小，其真实世界有效性仍不清楚。需要在实际生产环境中系统评估SD性能。

Method: 在广泛部署的生产级推理引擎vLLM上进行首次系统研究，涵盖多种SD变体(n-gram、EAGLE/EAGLE-3、Draft-Model、Multi-Token Prediction)，覆盖多样化工作负载、模型规模和批量大小。分析影响SD性能的关键因素，并量化SD加速的理论上限。

Result: 结果显示目标模型的验证阶段主导执行时间，接受长度在不同输出token位置、请求和数据集间差异显著。实测性能与理论上限比较显示存在显著差距，实际加速效果有限。

Conclusion: 研究揭示了推测解码在实际生产环境中的性能瓶颈，验证阶段是主要限制因素。实测与理论性能的差距为改进SD技术指明了新的研究方向，包括优化验证过程和提升接受率等。

Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.

</details>


### [9] [Enhancing the QA Model through a Multi-domain Debiasing Framework](https://arxiv.org/abs/2601.11581)
*Yuefeng Wang,ChangJae Lee*

Main category: cs.CL

TL;DR: 该研究评估ELECTRA-small模型在SQuAD v1.1及对抗数据集上的表现，通过识别偏差类型并开发多领域去偏框架，实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: QA模型在机器阅读理解方面虽有进步，但在复杂查询和对抗条件下常表现出偏差，影响性能。需要评估模型在标准数据集和对抗数据集上的表现，并开发有效的去偏方法。

Method: 评估ELECTRA-small模型在SQuAD v1.1、AddSent和AddOneSent数据集上的表现；识别词汇偏差、数值推理和实体识别等错误类型；开发包含知识蒸馏、去偏技术和领域扩展的多领域去偏框架。

Result: 在所有测试集上实现了最高2.6个百分点的EM和F1分数提升，在对抗环境下也取得了性能增益。

Conclusion: 针对性的偏差缓解策略能够显著提升自然语言理解系统的鲁棒性和可靠性，多领域去偏框架具有实际应用价值。

Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.

</details>


### [10] [Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents](https://arxiv.org/abs/2601.11585)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: ECS是一个基于信息论的框架，通过测量模型答案分布向正确答案的偏移来评估上下文效用，相比基于词重叠的词汇相似性方法，在细粒度上下文选择任务上表现显著更好。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理需要从误导性干扰信息中区分出实际有用的上下文信息。现有基于词汇相似性的方法无法捕捉语用效用——即一段文本是否真正有助于回答问题。

Method: 提出熵上下文塑造（ECS）框架，将上下文效用定义为模型答案分布向正确答案概率的有符号变化。该方法基于信息论原理，任务无关的上下文更新会产生接近零的分布偏移。

Result: 在LongMemEval（会话级）和LoCoMo（轮次级）基准测试中，ECS在细粒度轮次选择任务上，使用Llama-3.1-8B模型达到F1=0.265，相比TF-IDF（F1=0.154）相对提升71.83%。

Conclusion: ECS框架通过捕捉语用效用而非词汇相似性，在精确上下文选择任务上显著优于传统方法，证明了语用效用对于上下文工程的重要性。

Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.

</details>


### [11] [Towards AGI A Pragmatic Approach Towards Self Evolving Agent](https://arxiv.org/abs/2601.11658)
*Indrajit Kar,Sammy Zonunpuia,Zonunfeli Ralte*

Main category: cs.CL

TL;DR: 提出分层自进化多智能体框架，通过代码生成和进化算法使LLM智能体能够自主扩展能力、生成新工具和进化推理过程


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在部署后是静态的，缺乏自主扩展能力、生成新工具或进化推理的能力，需要一种能够持续自适应进化的框架

Method: 分层自进化多智能体框架：集成基础LLM、操作SLM智能体、代码生成LLM和教师LLM。工作流程：先尝试现有工具，失败时通过代码生成LLM合成新工具，持续失败时触发进化阶段（课程学习、基于奖励的学习或遗传算法进化）

Result: 在TaskCraft数据集上评估：课程学习提供快速恢复和强泛化能力，基于奖励的学习在高难度任务上表现优异，遗传算法提供高行为多样性。所有设置中，进化后的智能体都优于原始版本

Conclusion: 该框架实现了稳健、自主、自我改进的智能体进化，证明了LLM智能体能够通过自主工具合成和进化算法持续提升能力

Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.

</details>


### [12] [RAC: Retrieval-Augmented Clarification for Faithful Conversational Search](https://arxiv.org/abs/2601.11722)
*Ahmed Rayane Kebir,Vincent Guigue,Lynda Said Lhadj,Laure Soulier*

Main category: cs.CL

TL;DR: RAC框架通过检索增强生成基于文档的澄清问题，避免无根据提问，显著提升问题忠实度


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统在生成澄清问题时主要关注流畅性和用户意图对齐，但缺乏对底层文档的锚定，导致可能提出无法从可用文档中回答的问题

Method: 提出RAC（检索增强澄清）框架：1）比较多种检索索引策略；2）微调大语言模型以充分利用检索上下文并生成基于证据的问题；3）应用对比偏好优化，使基于检索段落的问题优于无根据的替代方案

Result: 在四个基准测试中，RAC相比基线有显著改进。除了LLM-as-Judge评估外，还引入了基于NLI和数据到文本的新指标来评估问题在上下文中的锚定程度，证明方法能持续提升忠实度

Conclusion: RAC框架通过检索增强和对比优化，成功生成了基于文档的忠实澄清问题，解决了现有方法缺乏文档锚定的问题，为对话搜索系统提供了更可靠的澄清机制

Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.

</details>


### [13] [Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era](https://arxiv.org/abs/2601.11739)
*Xinyu Pi,Qisen Yang,Chuong Nguyen,Hua Shen*

Main category: cs.CL

TL;DR: 论文提出了一个4×4框架来分析LLM在质性研究中的应用，揭示了当前系统偏向低层次意义和低承诺表示，并提出了改进议程。


<details>
  <summary>Details</summary>
Motivation: LLM在质性研究中的应用日益增多，但现有系统的输出差异很大——从忠实追踪的摘要到理论中介的解释和系统模型。为了明确这些差异，需要建立一个框架来分析LLM在质性研究中的不同应用层次。

Method: 引入一个4×4的框架：四个意义建构层次（描述性、分类性、解释性、理论性）与四个建模层次（静态结构、阶段/时间线、因果路径、反馈动态）交叉。将此框架应用于先前的LLM自动化研究。

Result: 分析显示当前LLM应用存在明显偏向：主要集中在低层次意义建构和低承诺表示上，很少有可靠尝试进行解释性/理论性推理或动态建模。

Conclusion: 基于发现的差距，提出了一个研究议程：开发能够明确其解释和建模承诺、可选择且可治理的LLM系统。

Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.

</details>


### [14] [LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text](https://arxiv.org/abs/2601.11746)
*George Mihaila,Suleyman Olcay Polat,Poli Nemkova,Himanshu Sharma,Namratha V. Urs,Mark V. Albert*

Main category: cs.CL

TL;DR: LIME-LLM是一个改进的局部解释框架，用假设驱动的受控扰动替代随机标记掩码，通过"单掩码-单样本"协议和中性填充策略，生成流畅的分布内邻域，显著提升了NLP黑盒模型解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有局部解释方法如LIME在NLP应用中依赖随机标记掩码，会产生语义无效、分布外的输入，削弱局部代理模型的保真度。最近的生成方法如LLiMe使用大语言模型进行邻域生成，但依赖无约束的释义，引入了混淆变量，难以隔离特定特征贡献。

Method: LIME-LLM框架用假设驱动的受控扰动替代随机噪声，采用严格的"单掩码-单样本"协议，并运用不同的中性填充和边界填充策略，构建流畅的分布内邻域，严格隔离特征效应。

Result: 在CoLA、SST-2和HateXplain三个基准测试中，使用人工标注的理性作为真实标签，LIME-LLM相比传统方法（LIME、SHAP、Integrated Gradients）和生成基线LLiMe，在局部解释保真度方面取得了显著改进。

Conclusion: LIME-LLM为黑盒NLP可解释性设立了新基准，相比传统基于扰动的方法和最近的生成替代方案，在局部解释保真度方面实现了显著提升。

Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.

</details>


### [15] [Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation](https://arxiv.org/abs/2601.11758)
*Arnab Das Utsa*

Main category: cs.CL

TL;DR: 提出基于社交媒体语言的透明焦虑检测方法，通过可解释的语言特征和跨域验证实现可靠、可泛化的筛查


<details>
  <summary>Details</summary>
Motivation: 全球焦虑症影响数亿人，但大规模筛查受限；社交媒体语言提供可扩展检测机会，但现有模型缺乏可解释性、关键词鲁棒性验证和严格的用户级数据完整性

Method: 使用Reddit帖子数据集，在精心策划的子版块上训练逻辑回归分类器；进行特征消融、关键词掩码实验、不同密度差异分析，并与临床访谈参与者进行外部验证

Result: 模型表现强劲，即使在情感移除或关键词掩码后仍保持高准确率；使用最少发帖历史的早期检测显著优于随机分类；跨域分析与临床访谈数据高度一致

Conclusion: 透明语言特征可支持可靠、可泛化、关键词鲁棒的焦虑检测；提出的框架为跨不同在线环境的可解释心理健康筛查提供了可复现基线

Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.

</details>


### [16] [Industry-Aligned Granular Topic Modeling](https://arxiv.org/abs/2601.11762)
*Sae Young Moon,Myeongjun Erik Jang,Haoyan Luo,Chunyang Xiao,Antonios Georgiadis,Fran Silavong*

Main category: cs.CL

TL;DR: TIDE框架提出基于大语言模型的细粒度主题建模方法，在多种数据集上优于现有方法，并提供文档摘要、主题层级等业务功能


<details>
  <summary>Details</summary>
Motivation: 主题建模在工业领域有广泛应用，但现有方法在生成细粒度主题方面的能力尚未充分探索，而细粒度对商业应用具有重要价值

Method: 提出TIDE框架，核心是基于大语言模型的细粒度主题建模方法，同时提供文档摘要、主题层级关系、主题蒸馏等辅助功能

Result: 在多种公开和真实商业数据集上的实验表明，TIDE的主题建模方法优于现代主题建模方法，辅助组件为工业业务场景提供有价值支持

Conclusion: TIDE框架提供了有效的细粒度主题建模解决方案，正在开源过程中，为商业应用提供深度洞察

Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.

</details>


### [17] [Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models](https://arxiv.org/abs/2601.11776)
*Kaituo Zhang,Zhimeng Jiang,Na Zou*

Main category: cs.CL

TL;DR: 提出完全自反思的LLM去毒框架，利用LLM内在能力检测、修正毒性内容并精炼模型，无需外部模块或数据标注，在保持语义保真度下实现更好的去毒性能。


<details>
  <summary>Details</summary>
Motivation: 当前去毒技术很少利用LLM内置的自校正和自我奖励能力，而是依赖外部模块、人工数据标注或人工干预，这阻碍了可扩展性和一致性。需要探索LLM内在的自去毒能力。

Method: 提出完全自反思去毒框架：1) 毒性信号检测器——内部自我识别机制；2) 系统性干预过程将毒性文本转化为非毒性对应文本；3) 迭代过程生成对比去毒数据集用于微调模型。

Result: 在DetoxLLM和ParaDetox等基准数据集上，该方法比最先进方法获得更好的去毒性能，同时保持语义保真度。无需人工干预或外部组件，展示了LLM内在的自去毒能力。

Conclusion: 揭示了LLM内在的自去毒能力，提供了一致有效的有害内容生成缓解方法，为真正自调节的语言模型铺平道路，推动更负责任和伦理指导的文本生成系统。

Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.

</details>


### [18] [Translation as a Scalable Proxy for Multilingual Evaluation](https://arxiv.org/abs/2601.11778)
*Sheriff Issaka,Erick Rosas Gonzalez,Lieqi Liu,Evans Kofi Agyei,Lucas Bandarkar,Nanyun Peng,David Ifeoluwa Adelani,Francisco Guzmán,Saadia Gabriel*

Main category: cs.CL

TL;DR: 翻译质量可作为评估大语言模型多语言能力的有效代理指标，简化多语言评估流程


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型声称具备多语言能力，但针对全球7000多种语言中超过98%的语言缺乏非机器翻译的基准测试，传统基准构建面临成本高、专家稀缺和数据污染等挑战

Method: 通过系统评估14个模型（1B-72B参数）在9个多样化基准和7个翻译指标上的表现，检验翻译质量是否能指示模型的多语言下游任务能力

Result: 翻译性能与下游任务成功呈强相关（如Phi-4模型的中位数皮尔逊相关系数：MetricX=0.89，xCOMET=0.91，SSA-COMET=0.87），表明支持忠实翻译的表征能力与多语言理解所需能力高度重叠

Conclusion: 翻译质量可作为强大且廉价的多语言性能初步代理指标，实现"翻译优先筛选+特定任务针对性跟进"的评估策略，简化多语言模型评估流程

Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.

</details>


### [19] [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/abs/2601.11791)
*Laya Iyer,Pranav Somani,Alice Guo,Dan Jurafsky,Chen Shani*

Main category: cs.CL

TL;DR: 论文提出从token级预测转向概念级预测，将同一概念的不同表面形式（如"mom"、"mother"）分组，通过概念级监督提升LLM的语义对齐能力。


<details>
  <summary>Details</summary>
Motivation: 传统的下一个token预测（NTP）目标在token级别操作，即使替代延续同样合理或语义等价（如"mom" vs "mother"），也会将其视为错误。这导致token级损失会惩罚有效的抽象、释义或概念正确的推理路径，使模型偏向表面形式而非底层含义。训练信号与语义正确性之间的不匹配促使需要更高级别的表示学习目标。

Method: 提出从token级预测转向概念级预测，其中概念将同一想法的多个表面形式分组（如"mom"、"mommy"、"mother"→MOTHER）。介绍了将概念监督集成到LLM训练中的各种方法。

Result: 概念感知模型实现了更低的困惑度，在领域转移下具有更好的鲁棒性，在多样化的NLP基准测试中表现优于基于NTP的模型。

Conclusion: 概念级监督作为一种改进的训练信号，能更好地将LLM与人类语义抽象对齐，是比传统token级预测更优的训练方法。

Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.

</details>


### [20] [TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit](https://arxiv.org/abs/2601.11819)
*Shirlene Rose Bandela,Sanjeev Parthasarathy,Vaibhav Garg*

Main category: cs.CL

TL;DR: TWeddit是一个标注Reddit上女性相关触发经历的数据集，用于研究创伤内容检测和情感支持


<details>
  <summary>Details</summary>
Motivation: 社交媒体上用户经常分享流产、性暴力等创伤经历，但缺乏手动触发警告，现有标注数据集稀缺，需要系统化的数据集来研究这些敏感内容

Method: 创建TWeddit数据集，收集Reddit上女性相关触发经历的详细叙述，进行人工标注和语言学分析，包括话题分析和道德基础分析

Result: TWeddit数据集中的标注故事表现出独特的话题分布和道德基础特征，证明该数据集对未来研究具有实用价值

Conclusion: TWeddit数据集填补了Reddit上创伤经历标注数据的空白，为情感支持、内容检测和道德基础研究提供了重要资源

Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.

</details>


### [21] [The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization](https://arxiv.org/abs/2601.11846)
*Natalia Tomashenko,Xiaoxiao Miao,Pierre Champion,Sarina Meyer,Michele Panariello,Xin Wang,Nicholas Evans,Emmanuel Vincent,Junichi Yamagishi,Massimiliano Todisco*

Main category: cs.CL

TL;DR: 2024年第三届VoicePrivacy挑战赛的结果与分析，聚焦于语音匿名化技术，旨在隐藏说话人身份的同时保留语言内容和情感状态。


<details>
  <summary>Details</summary>
Motivation: 随着语音技术的广泛应用，保护说话人隐私变得日益重要。语音匿名化需要在隐藏说话人身份的同时保持语音的实用价值（内容和情感），这是一个具有挑战性的平衡问题。

Method: 挑战赛提供了系统框架，包括匿名化任务定义、开发与评估数据集、攻击模型和客观评估指标。介绍了六个基线匿名化系统，并总结了参赛者提出的创新方法。

Result: 挑战赛展示了多种语音匿名化方法，提供了系统性能评估，揭示了当前技术在隐私保护和实用性保持方面的进展与挑战。

Conclusion: 论文为未来VoicePrivacy挑战赛的设计提供了关键见解，并指出了语音匿名化研究的几个有前景的方向，包括改进评估指标、开发更有效的匿名化技术等。

Abstract: We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.

</details>


### [22] [ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System](https://arxiv.org/abs/2601.11854)
*Yifei Zhang,Hooshang Nayyeri,Rinat Khaziev,Emine Yilmaz,Gokhan Tur,Dilek Hakkani-Tür,Hari Thadakamalla*

Main category: cs.CL

TL;DR: ATOD是一个用于评估高级任务导向对话系统的基准测试和合成对话生成框架，包含ATOD-Eval评估框架和基于记忆的评估器，能够全面评估多目标协调、长期推理等智能体行为。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的任务导向对话系统已经具备多目标协调、长期上下文保持和主动执行等高级能力，但现有基准测试缺乏对这些智能体行为的系统性评估支持。

Method: 1) 提出ATOD基准测试和合成对话生成管道，生成需要长期推理的丰富标注对话；2) 基于ATOD开发ATOD-Eval评估框架，将高级对话特征转化为细粒度指标；3) 提出基于记忆的智能体评估器用于ATOD基准测试。

Result: ATOD-Eval能够全面评估任务完成度、智能体能力和响应质量；提出的评估器在准确性和效率之间提供了更好的权衡，优于现有的基于记忆和LLM的方法。

Conclusion: ATOD填补了高级任务导向对话系统评估的空白，ATOD-Eval提供了全面的评估框架，基于记忆的评估器为基准测试提供了有效的评估解决方案。

Abstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.

</details>


### [23] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

TL;DR: CTPD是首个在异构分词器模型间转移人类偏好对齐行为的统一框架，通过字符级对齐、重要性采样和教师锚定参考实现跨分词器的偏好蒸馏。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令调优中广泛应用，但在语言模型与人类偏好对齐方面的应用仍未被充分探索，特别是在更现实的跨分词器场景中。不同分词方案的不兼容性阻碍了偏好信息的细粒度白盒蒸馏。

Method: 提出跨分词器偏好蒸馏（CTPD）框架，包含三个关键创新：1）对齐跨度投影，将师生模型的token映射到共享的字符级跨度；2）跨分词器版本的token级重要性采样（TIS-DPO）；3）教师锚定参考，让学生模型在DPO风格目标中直接利用教师的偏好。

Result: 理论分析将CTPD建立在重要性采样基础上，多个基准测试实验证实了其有效性，相比现有方法取得了显著的性能提升。

Conclusion: CTPD为不同分词方案间的偏好蒸馏提供了实用且通用的解决方案，为语言模型更易获取和高效的对齐打开了大门。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [24] [Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving](https://arxiv.org/abs/2601.11866)
*Kie Shidara,Preethi Prem,Jonathan Kim,Anna Podlasek,Feng Liu,Ahmed Alaa,Danilo Bernardo*

Main category: cs.CL

TL;DR: 大型语言模型在医学QA基准上表现出色，但临床推理的灵活性存在争议。研究发现先进推理模型在mARC基准上能避免Einstellung效应陷阱，达到人类水平表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医学QA基准上取得了高准确率，但其临床推理的灵活性一直存在争议。研究者希望探究先进的推理模型是否能改善临床推理中的认知灵活性。

Method: 使用医学抽象与推理语料库(mARC)这一对抗性医学QA基准，该基准利用Einstellung效应诱导对学习到的启发式模式的过度依赖。评估了OpenAI、Grok、Gemini、Claude和DeepSeek等家族的推理模型。

Result: 强大的推理模型比弱推理模型更常避免Einstellung陷阱，在mARC上达到人类水平表现。在医生最常出错的问题上，前5名模型以高置信度正确回答了55%到70%，表明这些模型可能比人类更不容易受Einstellung效应影响。

Conclusion: 强大的推理模型在医学推理中表现出改进的灵活性，在mARC基准上达到与人类相当的性能，表明它们可能比人类更不容易受到认知偏见的影响。

Abstract: Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.

</details>


### [25] [GloCTM: Cross-Lingual Topic Modeling via a Global Context Space](https://arxiv.org/abs/2601.11872)
*Nguyen Tien Phat,Ngo Vu Minh,Linh Van Ngo,Nguyen Thi Ngoc Diep,Thien Huu Nguyen*

Main category: cs.CL

TL;DR: GloCTM是一个跨语言主题建模框架，通过统一的语义空间实现跨语言主题对齐，利用跨语言词汇邻域增强输入表示，并通过CKA损失将潜在主题空间与多语言上下文嵌入对齐。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言主题模型在分离的语言特定空间中学习主题，依赖对齐机制（如双语词典）往往无法捕捉深层跨语言语义，导致主题空间松散连接，且忽略了多语言预训练表示中的丰富语义信号。

Method: GloCTM通过扩展词袋表示构建跨语言词汇邻域作为丰富输入表示，使用局部和全局编码器推断主题比例，通过内部正则化对齐潜在表示，在输出层定义在组合词汇上的全局主题-词分布实现跨语言主题同步，并引入CKA损失将潜在主题空间与多语言上下文嵌入对齐。

Result: 在多个基准测试中，GloCTM显著提高了主题连贯性和跨语言对齐性能，优于现有强基线方法。

Conclusion: GloCTM通过在整个模型流程中构建统一的语义空间，有效解决了跨语言主题对齐问题，能够捕捉细粒度的语义对齐，为跨语言主题建模提供了新思路。

Abstract: Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.

</details>


### [26] [Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence](https://arxiv.org/abs/2601.11886)
*Kaijie Mo,Siddhartha Venkatayogi,Chantal Shaib,Ramez Kouzy,Wei Xu,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: LLMs在医学领域面对反事实证据时，会不加批判地接受危险或不合理的证据，并给出自信的回答，缺乏安全边界。


<details>
  <summary>Details</summary>
Motivation: 在医学等高风险领域，模型通常应该忠实于提供的上下文。但当上下文与模型先验知识或安全协议不一致时，模型会如何表现？本文旨在研究LLMs在面对反事实或对抗性医学证据时的行为和推理方式。

Method: 构建MedCounterFact数据集，包含临床比较问题，要求模型基于随机对照试验证据判断治疗效果。在数据集中，真实医学干预被系统替换为四种反事实刺激（从未知词汇到有毒物质）。在多个前沿LLMs上评估模型表现。

Result: 现有模型在面对反事实证据时，绝大多数情况下会不加批判地接受这些证据（即使证据危险或不可信），并给出自信且无保留的回答。模型在忠实性和安全性之间缺乏边界。

Conclusion: 虽然理论上应该在忠实性和安全性之间划定边界，但现有模型尚未建立这样的边界。这表明需要开发能够更好处理反事实医学证据的模型，以平衡忠实性和安全性。

Abstract: In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such "evidence" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.

</details>


### [27] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

TL;DR: PPA-Plan是一种针对长上下文推理的主动规划策略，通过识别潜在逻辑陷阱和错误假设作为负面约束，在规划生成前预防失败，从而提升LLM在稀疏相关信息的长上下文中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理中存在困难，特别是当相关信息稀疏分布时。现有的计划-执行框架虽然通过任务分解来缓解这一问题，但往往因依赖表面线索而导致规划不可靠，一旦计划形成，识别错误并可靠地修订变得困难，限制了反应性优化的效果。

Method: PPA-Plan是一种主动规划策略，它首先识别潜在的逻辑陷阱和错误假设，将其表述为负面约束，然后在规划生成时明确避免这些约束。这种方法在规划阶段就预防失败，而不是事后修正。

Result: 在长上下文问答基准测试中，执行由PPA-Plan生成的计划持续优于现有的计划-执行方法和直接提示方法。

Conclusion: PPA-Plan通过主动识别和避免潜在失败点，有效提升了LLM在长上下文推理中的性能，为计划-执行框架提供了一种更可靠的规划方法。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [28] [LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding](https://arxiv.org/abs/2601.11913)
*Yichen Jiang,Peng Ye,Jiakang Yuan,Chongjun Tu,Lei Bai,Tao Chen*

Main category: cs.CL

TL;DR: 提出LSTM-MAS多智能体系统，借鉴LSTM架构设计链式智能体结构，通过门控机制控制信息传播，有效解决长文本处理中的错误累积和幻觉传播问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM处理长文本存在局限：单LLM方法需要减少上下文窗口或优化注意力机制，但会带来额外计算成本或扩展长度受限；多智能体框架虽能缓解这些问题，但仍易受错误累积和幻觉传播影响。

Method: 设计LSTM-MAS多智能体系统，模仿LSTM的分层信息流和门控内存机制。采用链式架构组织智能体，每个节点包含：工作智能体（段级理解）、过滤智能体（冗余减少）、判断智能体（持续错误检测）、管理智能体（全局信息传播和保留控制）。这些组件分别对应LSTM的输入门、遗忘门、恒定误差循环单元和输出门。

Result: 相比之前最佳多智能体方法CoA，在NarrativeQA上提升40.93%，Qasper上提升43.70%，HotpotQA上提升121.57%，MuSiQue上提升33.12%。

Conclusion: LSTM-MAS通过模仿LSTM的门控机制设计多智能体系统，能够控制信息传递和选择性建模长距离依赖关系，有效避免错误累积和幻觉传播，在长文本理解任务上表现显著优于现有方法。

Abstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.

</details>


### [29] [Enhancing LLM-Based Data Annotation with Error Decomposition](https://arxiv.org/abs/2601.11920)
*Zhen Xu,Vedant Khatri,Yijun Dai,Xiner Liu,Siyan Li,Xuanming Zhang,Renzhe Yu*

Main category: cs.CL

TL;DR: 提出诊断评估范式，分离任务固有模糊性与模型驱动错误，评估LLM在主观标注任务中的质量


<details>
  <summary>Details</summary>
Motivation: LLM在客观标注任务上已接近人类水平，但在涉及心理构念等主观标注任务上表现不稳定且易出错。传统评估将所有错误合并为单一对齐指标，可能掩盖不同类型错误对最终分析结论的不同影响。

Method: 提出诊断评估范式，包含：1) 二维错误分类法（来源：模型特定vs任务固有；类型：边界模糊vs概念误识别）；2) 轻量级人工标注测试估计任务固有模糊性；3) 计算分解LLM标注错误的方法。在四个教育标注任务上验证。

Result: 验证了范式的概念有效性和实际效用。理论上证明在特定标注任务中过高对齐不现实，单一对齐指标不足以反映LLM标注质量。实践上可作为低成本诊断工具评估任务是否适合LLM标注，并为技术优化提供可行见解。

Conclusion: 提出的诊断评估范式能够有效分离任务固有模糊性与模型驱动错误，为评估LLM在主观标注任务中的质量提供了更精细的框架，既有理论意义也有实践价值。

Abstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.

</details>


### [30] [Mapping the maturation of TCM as an adjuvant to radiotherapy](https://arxiv.org/abs/2601.11923)
*P. Bilha Githinji,Aikaterini Melliou,Xi Yuan,Dayan Zhang,Lian Zhang,Zhenglin Chen,Jiansong Ji,Chengying Lv,Jinhao Xu,Peiwu Qin,Dongmei Yu*

Main category: cs.CL

TL;DR: 对69,745篇文献的大规模分析显示，中医药作为放疗辅助的整合肿瘤学经历了周期性演变，形成了五大主题轴，表明该领域已成熟并可能面临新的突破，同时存在系统性积极报告偏倚。


<details>
  <summary>Details</summary>
Motivation: 整合肿瘤学发展25年来，中医药作为放疗辅助的应用日益广泛，需要系统梳理证据轨迹，了解该领域的发展模式和现状，为未来研究方向提供参考。

Method: 对2000-2025年间69,745篇出版物进行大规模分析，采用主题建模工作流程确定稳定的主题结构，识别主导主题轴，分析出版产出、国际合作和资金承诺的周期性演变。

Result: 识别出五大主导主题轴：癌症类型、支持性护理、临床终点、机制和方法学；发现该领域呈现定义-构思-测试模式的周期性演变；显示患者为中心、系统导向的TCM整合；存在系统性积极报告偏倚。

Conclusion: 中医药作为放疗辅助的整合肿瘤学领域已成熟现有研究议程，可能处于新突破的边缘；该领域表现出渐进专业化和潜在碎片化；需要关注系统性积极报告偏倚问题。

Abstract: The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.

</details>


### [31] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

TL;DR: 本文研究事件检测中的两个关键限制：解码器LLMs的单向性架构瓶颈和Micro-F1指标的偏向性，提出使用句子上下文增强和LoRA微调来提升模型在长尾事件类别上的性能，以Macro-F1作为更公平的评估指标。


<details>
  <summary>Details</summary>
Motivation: 事件检测研究存在两个主要限制：1）解码器LLMs的单向性架构不适合需要双向上下文理解的自然语言理解任务；2）传统依赖Micro-F1指标会偏向多数类别，无法准确评估模型在长尾事件类型上的表现。

Method: 1）使用句子上下文增强模型以克服解码器LLMs的单向性限制；2）采用Low-Rank Adaptation（LoRA）进行微调；3）以Macro-F1而非Micro-F1作为主要评估指标。

Result: 实验表明：1）句子上下文增强的模型优于标准解码器基线；2）LoRA微调显著提升Macro-F1分数，特别是对解码器模型；3）LoRA能有效增强LLMs在长尾事件类别上的性能。

Conclusion: 解码器LLMs的单向性架构是事件检测的瓶颈，句子上下文增强和LoRA微调能有效提升性能，Macro-F1是比Micro-F1更公平的评估指标，LoRA特别适合增强LLMs在长尾事件类别上的表现。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [32] [Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence](https://arxiv.org/abs/2601.11956)
*Yuyin Lu,Ziran Liang,Yanghui Rao,Wenqi Fan,Fu Lee Wang,Qing Li*

Main category: cs.CL

TL;DR: DoublyCal框架通过双重校准原则，使用轻量代理模型生成知识图谱证据和校准的置信度，指导黑盒大语言模型产生更准确且置信度可追溯的预测


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，现有基于知识图谱增强的方法无法量化检索证据和模型推理过程中的认知不确定性，需要解决置信度校准和不确定性追溯的问题

Method: 提出DoublyCal框架，基于双重校准原则：1) 使用轻量代理模型生成知识图谱证据并校准证据置信度；2) 用校准后的证据指导黑盒大语言模型，产生最终预测并确保置信度可追溯到证据的不确定性

Result: 在知识密集型基准测试中，DoublyCal显著提高了黑盒大语言模型的准确性和置信度校准，同时保持了较低的token成本

Conclusion: DoublyCal通过双重校准机制有效解决了大语言模型增强中的不确定性量化问题，实现了更可信的推理，为知识增强系统提供了可追溯的置信度评估方法

Abstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.

</details>


### [33] [PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning](https://arxiv.org/abs/2601.11957)
*Bingxuan Li,Jeonghwan Kim,Cheng Qian,Xiusi Chen,Eitan Anzenberg,Niran Kundapur,Heng Ji*

Main category: cs.CL

TL;DR: 提出CalConflictBench基准测试日历冲突解决，开发PEARL强化学习框架提升语言代理性能


<details>
  <summary>Details</summary>
Motivation: 重叠的日历邀请迫使专业人士不断决定参加、重新安排或拒绝哪些会议，自动化这一过程至关重要但具有挑战性。人工调度耗时且难以规模化，因此需要研究语言代理能否有效管理时间。

Method: 引入CalConflictBench基准测试，用于长视野日历冲突解决。提出PEARL强化学习框架，通过外部记忆模块和优化的轮次奖励设计增强语言代理，使其能够动态推断和适应用户偏好。

Result: 当前LLM代理表现不佳（如Qwen-3-30B-Think平均错误率35%）。PEARL实现了0.76的错误减少率，相比最强基线平均错误率提升55%。

Conclusion: PEARL框架显著提升了语言代理在日历冲突解决任务中的性能，能够有效推断和适应用户偏好，为自动化时间管理提供了可行方案。

Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.

</details>


### [34] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

TL;DR: 该研究比较了Meta付费广告和Bluesky公共帖子的气候话语，开发了可解释的主题发现框架，发现平台激励结构影响了气候叙事的主题结构、立场对齐和时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立分析不同平台的气候话语，难以区分机构信息与公众表达。需要比较付费广告生态系统（激励针对性战略说服）和公共社交媒体平台（主要是有机用户驱动话语）的气候传播差异。

Method: 开发了可解释的端到端主题发现和分配框架：通过语义相似性聚类文本，利用LLM生成简明的人类可解释主题标签。在2024年7月至2025年9月期间，比较Meta付费广告和Bluesky公共帖子中的气候话语。使用人工判断和LLM评估器评估主题质量，并通过下游立场预测和主题引导检索任务验证语义连贯性。

Result: 发现平台层面的激励结构反映在气候叙事的主题结构、立场对齐和时间响应性中。付费气候信息与公共气候话语存在系统性差异，主题流行度在重大政治事件周围发生变化。

Conclusion: 平台激励结构显著影响气候话语特征。虽然实证分析聚焦气候传播，但提出的框架支持跨异质传播环境的比较叙事分析，有助于区分机构信息与公众表达。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [35] [$\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969)
*Zecheng Tang,Baibei Ji,Ruoxi Sun,Haitian Wang,WangJie You,Zhang Yijun,Wenpeng Zhu,Ji Qi,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出了首个评估奖励模型在长上下文记忆管理能力的基准MemoryRewardBench，涵盖8K-128K token的10种记忆管理场景，发现开源与专有模型差距缩小，新代模型普遍优于前代


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多采用以记忆为中心的机制处理长上下文，有效的记忆管理成为关键能力。需要奖励模型来自动可靠地评估记忆质量，但目前缺乏系统评估奖励模型在长时记忆管理能力的基准

Method: 构建MemoryRewardBench基准，覆盖长上下文理解和长文本生成任务，包含10种不同记忆管理模式的设置，上下文长度从8K到128K token。在13个前沿奖励模型上进行评估

Result: 评估显示开源模型与专有模型的性能差距正在缩小，新一代模型无论参数量多少都持续优于前代模型。同时揭示了当前奖励模型在评估LLM记忆管理方面的能力和基本限制

Conclusion: MemoryRewardBench为系统研究奖励模型评估长时记忆管理能力提供了首个基准，揭示了模型发展趋势和现有局限性，为未来改进提供了重要参考

Abstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.

</details>


### [36] [Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning](https://arxiv.org/abs/2601.12019)
*Chaowei Zhang,Xiansheng Luo,Zewei Zhang,Yi Zhu,Jipeng Qiang,Longwei Wang*

Main category: cs.CL

TL;DR: 本文提出SORG框架，利用LLMs的奉承行为生成对立推理，结合ORCD模型进行点击诱饵检测，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线内容泛滥加剧了点击诱饵问题，LLMs虽有潜力但受奉承行为影响，倾向于匹配用户信念而非真实推理。本文创新性地利用而非消除这种奉承行为。

Method: 提出SORG框架，引导LLMs生成对立立场的同意/反对推理对；开发ORCD模型，使用三个BERT编码器分别编码标题和推理，通过对比学习和LLM生成的可信度软标签进行训练。

Result: 在三个基准数据集上的实验表明，该方法在点击诱饵检测任务上一致优于LLM提示、微调的小型语言模型和最先进的基线方法。

Conclusion: 通过利用LLMs的奉承行为生成对立推理，结合专门的检测模型，能够有效提升点击诱饵检测性能，为处理LLMs的偏差提供了新视角。

Abstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.

</details>


### [37] [Pro-AI Bias in Large Language Models](https://arxiv.org/abs/2601.13749)
*Benaya Trabelsi,Jonathan Shaki,Sarit Kraus*

Main category: cs.CL

TL;DR: LLMs存在系统性偏向人工智能的偏好偏见，在建议推荐、薪资评估和内部表征中均表现出对AI的过度偏好


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多个领域被用于决策支持，需要研究这些模型是否存在对人工智能本身的系统性偏好偏见，这可能影响高风险决策

Method: 通过三个互补实验：1)分析LLMs对建议寻求查询的AI相关选项推荐倾向；2)比较AI相关职位与非AI职位的薪资评估偏差；3)探究开源模型的内部表征中"人工智能"概念的相似性

Result: 发现一致的pro-AI偏见：专有模型几乎确定性地推荐AI选项；专有模型对AI薪资高估10个百分点；"人工智能"在正负中性框架下均表现出最高的表征中心性

Conclusion: LLMs生成的建议和估值可能在高风险决策中系统性扭曲选择和认知，需要关注这种偏见对决策支持的影响

Abstract: Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

</details>


### [38] [Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection](https://arxiv.org/abs/2601.12033)
*Muhammad Alif Al Hakim,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

TL;DR: 量化会降低LLM的公平性和安全性，动态量化比静态量化更稳定，非英语环境下安全性下降更明显。作者提出Critical Weight Protection方法来保护关键权重，缓解这些问题。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于降低大语言模型的计算成本，但其对公平性和安全性的影响，特别是在动态量化和多语言环境下的影响，尚未得到充分研究。

Method: 系统研究静态和动态量化方法对公平性和安全性的影响，评估英语、法语、荷兰语、西班牙语、土耳其语（公平性）以及英语、韩语、阿拉伯语（安全性）。提出Critical Weight Protection技术，识别和保护公平性和安全性关键权重。

Result: 量化一致性地降低公平性和安全性；动态方法比静态方法更稳定；公平性退化因语言而异；安全性退化在非英语环境中尤为明显；Critical Weight Protection能有效缓解偏见和安全性退化。

Conclusion: 量化对LLM的公平性和安全性有负面影响，特别是在多语言环境中。提出的Critical Weight Protection方法能在不进行昂贵重新训练或对齐的情况下，有效减轻这些问题，在保持效率的同时维护可信度。

Abstract: Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.

</details>


### [39] [Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs](https://arxiv.org/abs/2601.12034)
*Ziyi Zhao,Chongming Gao,Yang Zhang,Haoyan Liu,Weinan Gan,Huifeng Guo,Yong Liu,Fuli Feng*

Main category: cs.CL

TL;DR: PUMA框架通过轻量级适配器实现个性化提示在不同LLM间的迁移，减少98%计算成本，性能接近或优于完全重训练


<details>
  <summary>Details</summary>
Motivation: 传统基于软提示的LLM个性化方法在基础模型升级时需要完全重训练，成本高昂。需要一种能高效迁移个性化提示到不兼容模型的方法

Method: 提出Prompt-level User Migration Adapter (PUMA)：1) 使用参数高效的适配器桥接语义差距；2) 采用基于组的用户选择策略显著降低训练成本

Result: 在三个大规模数据集上，PUMA性能匹配甚至优于完全重训练，计算成本降低高达98%。框架在不同模型架构上泛化能力强，在链式和聚合迁移等高级场景中表现稳健

Conclusion: PUMA通过将用户资产与底层模型解耦，为个性化AI的可持续演进提供了实用路径，解决了模型升级时个性化提示迁移的难题

Abstract: Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.

</details>


### [40] [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Shaoxiong Ji,Hassan Alhuzali,Sophia Ananiadou*

Main category: cs.CL

TL;DR: XCR-Bench：一个包含4.9k平行句对和1,098个独特文化特定项目的跨文化推理基准，用于评估大语言模型在识别和适应文化特定项目方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型跨文化能力受到高质量文化特定项目标注语料库稀缺的限制，特别是缺乏包含平行跨文化句对的语料。

Method: 结合Newmark的文化特定项目框架和Hall的文化三元论，构建了包含三个不同推理任务及相应评估指标的跨文化推理基准XCR-Bench。

Result: 最先进的大语言模型在识别和适应社交礼仪和文化参考相关的文化特定项目方面存在一致弱点，并且在文化适应过程中表现出区域和民族宗教偏见。

Conclusion: 需要进一步研究跨文化自然语言处理，XCR-Bench的发布将促进这一领域的发展，帮助评估和改进大语言模型的跨文化能力。

Abstract: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

</details>


### [41] [Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation](https://arxiv.org/abs/2601.12061)
*Jinsook Lee,Kirk Vanacore,Zhuqian Zhou,Jeanine Grutter,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: 论文提出代码本注入分割方法，将边界决策与下游标注标准结合，评估LLM分割器与标准基线的表现，发现DA感知能产生更一致的片段，但不同分割器各有优劣，分割设计应根据下游目标优化而非单一性能分数。


<details>
  <summary>Details</summary>
Motivation: 传统对话行为标注将交际或教学意图局限于单个话语或轮次，导致标注者在底层动作上一致但在片段边界上存在分歧，降低了标注可靠性。需要改进分割方法以提高一致性。

Method: 提出代码本注入分割方法，将边界决策条件化于下游标注标准；评估LLM分割器与标准基线及检索增强基线；引入无黄金标签的评估指标：跨度一致性、区分性和人机分布一致性。

Result: DA感知产生的片段比纯文本基线内部更一致；LLM擅长创建结构一致的跨度，但基于连贯性的基线在检测对话流全局变化方面更优；不同分割器在不同数据集上各有优势；片段内连贯性的提升常以边界区分性和人机分布一致性为代价。

Conclusion: 分割是一个重要的设计选择，应根据下游目标进行优化，而不是追求单一的性能分数。不同分割方法在不同方面各有优劣，需要权衡取舍。

Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.

</details>


### [42] [Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset](https://arxiv.org/abs/2601.12068)
*Rowzatul Zannat,Abdullah Al Shafi,Abdul Muntakim*

Main category: cs.CL

TL;DR: 该研究创建了一个包含758个症状-疾病关系的孟加拉语数据集，用于疾病预测，并评估了多种机器学习模型，集成方法达到98%准确率。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语人群缺乏可靠的疾病预测资源，限制了医疗信息的可及性。研究旨在填补这一空白，为孟加拉语社区提供本地化的健康信息工具。

Method: 开发了包含85种疾病、758个症状-疾病关系的孟加拉语数据集，并公开分享。使用该数据集评估了多种机器学习模型，采用软投票和硬投票集成方法结合表现最佳的模型。

Result: 软投票和硬投票集成方法均达到98%的准确率，表现出优越的鲁棒性和泛化能力。数据集为孟加拉语疾病预测建立了基础资源。

Conclusion: 该研究为孟加拉语疾病预测提供了基础资源，支持孟加拉语社区的医疗信息公平获取，为本地化健康信息学和诊断工具的未来发展铺平道路。

Abstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.

</details>


### [43] [To Copy or Not to Copy: Copying Is Easier to Induce Than Recall](https://arxiv.org/abs/2601.12075)
*Mehrdad Farahani,Franziska Penzkofer,Richard Johansson*

Main category: cs.CL

TL;DR: 该论文提出了一种机制研究，通过提取"仲裁向量"来调控语言模型在检索增强设置中参数知识与上下文信息之间的权衡，揭示了诱导复制与恢复回忆之间的不对称性。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在检索增强设置中如何仲裁参数知识（存储在权重中）与上下文信息（在提示中）之间的选择，理解模型在这两种知识源之间的决策机制。

Method: 通过精心设计的数据集提取"仲裁向量"：计算不相关上下文（引发参数回忆）与相关但错误上下文（引发复制）在残差流中的质心差异。将该向量作为加性干预注入到特定层和标记跨度，以引导模型行为在两个方向转变：复制→回忆（抑制上下文使用）和回忆→复制（诱导模型复制上下文中的任何标记）。

Result: 在两个架构（仅解码器和编码器/解码器）和两个开放域QA基准测试中，在适度扩展下观察到一致的行为转变，同时保持准确性和流畅性。机制分析揭示了不对称性：诱导复制是一个容易的"重新激活"过程，可以在输入的不同位置触发；而恢复回忆是一个更脆弱的"抑制"过程，与对象标记干预密切相关。

Conclusion: 该研究通过机制分析揭示了语言模型在参数知识与上下文信息之间仲裁的内在机制，发现了诱导复制与恢复回忆之间的不对称性，为理解模型在检索增强设置中的行为提供了新的视角。

Abstract: Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\rightarrow$Recall (suppressing context use) and Recall$\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.

</details>


### [44] [Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization](https://arxiv.org/abs/2601.12078)
*Linfeng Du,Ye Yuan,Zichen Zhao,Fuyuan Lyu,Emiliano Penaloza,Xiuying Chen,Zipeng Sun,Jikun Kang,Laurent Charlin,Xue Liu,Haolun Wu*

Main category: cs.CL

TL;DR: PURPLE：基于上下文老虎机框架优化LLM个性化用户档案，通过Plackett-Luce排序模型捕捉记录间依赖关系，直接对齐检索与生成质量


<details>
  <summary>Details</summary>
Motivation: 现有检索增强方法基于语义相关性选择用户历史记录，但相关性不能可靠地代表实用性——语义相似的记录可能因冗余或冲突信息而无法提升甚至降低生成质量

Method: 提出PURPLE框架，将档案构建视为集合生成过程，使用Plackett-Luce排序模型捕捉复杂记录间依赖关系，通过参考响应的似然度作为密集反馈进行训练

Result: 在九个个性化任务上的广泛实验表明，PURPLE在效果和效率上均优于强启发式和检索增强基线方法

Conclusion: PURPLE为优化用户档案提供了原则性和可扩展的解决方案，通过直接对齐检索与生成质量，实现了更有效的LLM个性化

Abstract: Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.

</details>


### [45] [Large language models struggle with ethnographic text annotation](https://arxiv.org/abs/2601.12099)
*Leonardo S. Goodall,Dor Shilton,Daniel A. Mullins,Harvey Whitehouse*

Main category: cs.CL

TL;DR: LLMs在民族志文本标注任务中表现有限，无法替代人类专家，准确率远低于可靠自动化标注所需水平


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在跨文化研究中的潜力，特别是能否从民族志文本中提取结构化数据以加速研究

Method: 使用7个最先进的LLMs对567个民族志摘录的121个仪式特征进行标注评估

Result: LLMs表现有限，准确率远低于可靠自动化标注所需水平；长文本、需要顺序区分的特征和模糊概念特别困难；人类编码者间信度设定了LLM准确率的上限

Conclusion: LLMs目前还不能替代人类专家进行民族志标注，需要进一步改进才能可靠应用于跨文化研究

Abstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.

</details>


### [46] [Powerful Training-Free Membership Inference Against Autoregressive Language Models](https://arxiv.org/abs/2601.12104)
*David Ilić,David Stanojević,Kostadin Cvejoski*

Main category: cs.CL

TL;DR: EZ-MIA是一种新型成员推理攻击方法，通过分析模型在错误位置的记忆表现，显著提高了对微调语言模型隐私风险的检测能力。


<details>
  <summary>Details</summary>
Motivation: 微调的语言模型存在严重的隐私风险，可能记忆并暴露训练数据中的敏感信息。现有的成员推理攻击方法检测率有限，特别是在实际隐私审计所需的低误报率阈值下表现不佳。

Method: 提出EZ-MIA攻击方法，基于关键观察：记忆在错误位置表现最明显（模型预测错误但仍对训练样本显示较高概率）。引入错误区域（EZ）分数，测量错误位置概率变化相对于预训练参考模型的方向不平衡性。该方法只需要每个查询两次前向传播，无需任何模型训练。

Result: 在WikiText和GPT-2上，EZ-MIA在相同条件下达到3.8倍于先前最佳方法的检测率（1%误报率下66.3% vs 17.5%真阳性率），AUC接近完美（0.98）。在关键的0.1%误报率阈值下，检测率提高8倍（14.0% vs 1.8%）。在Llama-2-7B和AG News上，检测率提高3倍（1%误报率下46.7% vs 15.8%）。

Conclusion: 微调语言模型的隐私风险比先前理解的要大得多，这对隐私审计和部署决策都有重要影响。EZ-MIA为评估这些风险提供了更有效的工具。

Abstract: Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.

</details>


### [47] [Bengali Text Classification: An Evaluation of Large Language Model Approaches](https://arxiv.org/abs/2601.12132)
*Md Mahmudul Hoque,Md Mehedi Hassain,Md Hojaifa Tanvir,Rahul Nandy*

Main category: cs.CL

TL;DR: 该研究评估了三种指令调优大语言模型在孟加拉语新闻文章分类任务上的表现，发现Qwen 2.5 7B Instruct模型以72%的准确率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文本分类面临标注数据集和预训练语言模型匮乏的挑战，研究旨在探索大语言模型在孟加拉语新闻分类任务中的有效性。

Method: 使用来自Prothom Alo报纸的Kaggle数据集，在相同分类框架下评估三种指令调优LLMs：LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct和Qwen 2.5 7B Instruct。

Result: Qwen 2.5以72%的准确率表现最佳，在"体育"类别表现尤为突出；LLaMA 3.1和LLaMA 3.2分别获得53%和56%的准确率。

Conclusion: 尽管孟加拉语NLP资源稀缺，大语言模型在孟加拉语文本分类中仍表现出有效性。未来研究将探索更多模型、解决类别不平衡问题并改进微调方法。

Abstract: Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.

</details>


### [48] [Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs](https://arxiv.org/abs/2601.12154)
*Teodor-Călin Ionescu,Lifeng Han,Jan Heijdra Suasnabar,Anne Stiggelbout,Suzan Verberne*

Main category: cs.CL

TL;DR: 本研究使用神经主题建模（BERTopic）和LLMs分析癌症患者访谈数据，发现BioClinicalBERT嵌入模型能提升主题精确度和可解释性，识别出癌症护理中的关键主题，为患者导向的医疗实践提供支持。


<details>
  <summary>Details</summary>
Motivation: 从患者叙事数据中挖掘有意义主题，为患者导向的医疗实践提供洞察。通过分析癌症患者访谈，探索如何更有效地将患者声音融入医疗工作流程。

Method: 使用BERTopic和Top2Vec进行主题建模比较，采用GPT-4进行主题标注，通过人工评估（一致性、清晰度、相关性）选择最佳方法，并使用三种临床导向嵌入模型（包括BioClinicalBERT）进行完整数据集分析。

Result: BERTopic表现优于Top2Vec；BioClinicalBERT嵌入模型产生最一致的结果；识别出两个主导主题：癌症护理管理中的协调与沟通、癌症治疗旅程中的患者决策制定。

Conclusion: 神经主题建模（特别是BERTopic）能够从患者访谈中提取有用信息反馈给临床医生，支持更高效的文档导航，并加强患者声音在医疗工作流程中的作用。

Abstract: This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.

</details>


### [49] [Tolerance Principle and Small Language Model Learning](https://arxiv.org/abs/2601.12179)
*Adam E. Friedman,Stevan Harnad,Rushen Shi*

Main category: cs.CL

TL;DR: 研究发现BabyBERTa语言模型的学习动态与人类婴儿不同，不遵循容忍原则的预测


<details>
  <summary>Details</summary>
Motivation: 现代语言模型需要大量训练数据，而人类婴儿能从极少示例中学习抽象语法规则。本研究旨在探索语言模型学习语法规则所需的最小数据量和质量，并测试容忍原则的预测

Method: 使用BabyBERTa（专为小数据集优化的transformer模型）在人工语法上进行训练。训练集在大小、独特句子类型数量和规则遵循与例外示例比例上有所不同

Result: 研究发现BabyBERTa的学习动态与人类婴儿不同，不符合容忍原则的预测

Conclusion: 语言模型的学习机制与人类婴儿的语法学习存在差异，不遵循容忍原则的阈值预测

Abstract: Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.

</details>


### [50] [CTC-DID: CTC-Based Arabic dialect identification for streaming applications](https://arxiv.org/abs/2601.12199)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

TL;DR: 提出基于CTC损失函数的方言识别方法，将方言识别任务建模为有限词汇的语音识别系统，在低资源阿拉伯方言识别任务中表现优于现有模型


<details>
  <summary>Details</summary>
Motivation: 传统方言识别方法在处理低资源场景和短语音时存在局限性，需要一种更鲁棒且适应实时应用的方法

Method: 将方言识别任务构建为有限词汇的ASR系统，使用CTC损失函数，通过语言无关启发式方法或预训练ASR模型估计方言标签在转录中的重复次数

Result: 在低资源阿拉伯方言识别任务中，基于SSL的CTC-DID模型在有限数据集上训练后，性能优于微调的Whisper和ECAPA-TDNN模型，在Casablanca数据集上的零样本评估也表现更好，对短语音更鲁棒且易于适配流式实时应用

Conclusion: CTC-DID方法为方言识别提供了一种有效的解决方案，特别适合低资源场景和实时应用，在性能和鲁棒性方面均优于现有方法

Abstract: This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.

</details>


### [51] [CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement](https://arxiv.org/abs/2601.12208)
*Yunzhe Li,Richie Yueqi Feng,Tianxin Wei,Chin-Chia Hsu*

Main category: cs.CL

TL;DR: CoReflect：通过协同进化模拟和反思性评估标准优化，实现对话系统的自适应迭代评估框架


<details>
  <summary>Details</summary>
Motivation: 传统对话系统评估方法依赖人工定义的固定评估标准和静态对话上下文，覆盖范围有限，无法捕捉对话模型多样化的涌现行为，难以适应快速发展的对话模型能力

Method: CoReflect采用协同进化循环：1) 对话规划器生成结构化模板指导用户模拟器进行多样化目标导向对话；2) 反思分析器处理对话，识别系统行为模式并自动优化评估标准；3) 分析结果反馈给规划器更新对话模板，形成测试用例复杂度和评估标准诊断精度协同提升的循环

Result: CoReflect提供了一种可扩展、自我优化的方法论，最小化人工干预，使评估协议能够适应快速发展的对话模型能力

Conclusion: CoReflect通过统一对话模拟和评估的自适应迭代过程，解决了多轮对话系统评估的基本挑战，实现了测试用例和评估标准的协同进化

Abstract: Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.

</details>


### [52] [Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models](https://arxiv.org/abs/2601.12247)
*Miao Li,Hanyang Jiang,Sikai Chen,Hengyu Fu,Yuhang Cai,Baihe Huang,Tinghan Ye,Xuanzhou Chen,Pascal Van Hentenryck*

Main category: cs.CL

TL;DR: PVF是一种无需训练的解码范式，通过规划-验证-填充机制，利用全局双向上下文主动构建层次化骨架，显著减少扩散语言模型的函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型的解码策略往往是被动反应式的，未能充分利用全局双向上下文来指导全局轨迹，导致效率低下。

Method: 提出Plan-Verify-Fill（PVF）范式：1）主动构建层次化骨架，优先考虑高影响力的语义锚点；2）采用验证协议实现实用结构停止，当进一步思考收益递减时停止；3）无需额外训练。

Result: 在LLaDA-8B-Instruct和Dream-7B-Instruct上的评估显示，PVF相比基于置信度的并行解码，在基准数据集上最多减少65%的函数评估次数，在不损失准确性的前提下实现更高效率。

Conclusion: PVF为扩散语言模型提供了一种高效的非顺序解码范式，通过主动规划和验证机制显著提升生成效率，展示了利用全局上下文指导文本生成轨迹的潜力。

Abstract: Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.

</details>


### [53] [Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers](https://arxiv.org/abs/2601.12263)
*Yixuan Du,Chenxiao Yu,Haoyan Xu,Ziyi Wang,Yue Zhao,Xiyang Hu*

Main category: cs.CL

TL;DR: 该论文提出了一种针对视觉语言模型产品搜索系统的多模态对抗攻击框架MGEO，通过联合优化图像扰动和文本后缀来操纵搜索结果排名


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在检索和推荐系统中广泛应用，但其在竞争性排名场景下对抗操纵的鲁棒性尚未充分研究。作者发现VLM产品搜索存在关键漏洞，需要探索多模态协同如何被武器化攻击

Method: 提出多模态生成引擎优化(MGEO)框架，采用交替梯度优化策略，联合优化不可感知的图像扰动和流畅的文本后缀，利用VLM内部的深度跨模态耦合

Result: 在真实数据集和先进模型上的实验表明，协调攻击显著优于纯文本和纯图像基线攻击，证明多模态协同可以被武器化而不触发传统内容过滤器

Conclusion: 研究发现视觉语言模型的多模态协同优势可能成为安全漏洞，需要开发新的防御机制来保护搜索排名的完整性

Abstract: Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.

</details>


### [54] [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269)
*Xucong Hu,Jian-Qiao Zhu*

Main category: cs.CL

TL;DR: 通过基于MCMC的功率采样和退火技术，无需额外训练即可从基础语言模型中恢复强大的心理理论能力


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型通常被认为是下一个词预测器，主要优化表面合理性而非保持正确的潜在状态表示，因此被认为在心理理论任务上表现不佳。虽然后训练方法可以改善性能，但本文探索是否可以直接从基础模型中恢复心理理论能力。

Method: 采用基于马尔可夫链蒙特卡洛的功率采样方法，从自回归语言模型的序列级概率分布中采样，而非传统的词级分布。进一步引入退火技术，将温度分布从高到低逐渐调整，显著提升心理理论性能。

Result: 研究表明，无需任何额外的权重更新或验证，仅通过采样优化就能从基础语言模型中提取强大的心理理论能力。退火技术的加入进一步提升了性能，超越了固定温度的功率采样。

Conclusion: 基于采样的优化方法为从语言模型中提取潜在能力提供了一种强大途径，无需重新训练模型，这对心理理论等需要潜在状态推理的任务具有重要意义。

Abstract: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.

</details>


### [55] [Conversational Context Classification: A Representation Engineering Approach](https://arxiv.org/abs/2601.12286)
*Jonathan Pan*

Main category: cs.CL

TL;DR: 使用表征工程和单类支持向量机在LLM内部状态中识别特定上下文子空间，用于检测对话是否偏离上下文


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的普及，需要有效保障其运行，特别是检测其生成偏离上下文回复的倾向。传统异常检测方法难以直接应用于上下文语义中。

Method: 结合表征工程和单类支持向量机，在LLM内部状态中识别与特定上下文相关的子空间。通过上下文示例训练OCSVM，在隐藏状态潜在空间中建立边界，并识别与目标上下文最相关的网络层。

Result: 在Llama和Qwen模型上的评估显示，该方法在识别特定上下文子空间方面取得了有希望的结果，能够有效检测对话是否在上下文内。

Conclusion: 该方法不仅有助于检测对话是否偏离上下文，还为更好地解释LLM的内部工作机制做出了贡献。

Abstract: The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.

</details>


### [56] [Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies](https://arxiv.org/abs/2601.12369)
*Ming Zhang,Jiabao Zhuang,Wenqing Jing,Ziyu Kong,Jingyi Deng,Yujiong Shen,Kexin Tan,Yuhang Zhao,Ning Luo,Renzhe Zheng,Jiahui Lin,Mingqi Wu,Long Ma,Yi Zou,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: TaxoBench是一个用于评估深度研究代理生成综述能力的诊断基准，基于72篇高引用计算机科学综述构建，包含3,815个精确分类的引用作为基准。研究发现当前最佳代理只能召回20.9%的专家选择论文，组织能力也很有限。


<details>
  <summary>Details</summary>
Motivation: 深度研究代理越来越多地用于自动生成综述，但尚不清楚它们是否能像人类专家一样撰写综述。现有基准主要关注流畅性或引用准确性，缺乏对核心能力（检索关键论文并将其组织成连贯知识结构）的评估。

Method: 从72篇高引用计算机科学综述中手动提取专家构建的分类树作为基准，包含3,815个精确分类的引用。支持两种评估模式：深度研究模式（给定主题进行端到端检索和组织）和自底向上模式（提供专家使用的确切论文来测试组织能力）。评估了7个领先的深度研究代理和12个前沿LLM。

Result: 结果显示双重瓶颈：最佳代理只能召回20.9%的专家选择论文；即使在完美输入条件下，最佳模型的组织能力也只有0.31 ARI（调整兰德指数）。当前深度研究代理距离专家级综述撰写仍有很大差距。

Conclusion: TaxoBench填补了现有基准的空白，专注于评估深度研究代理的核心能力。研究表明当前代理在检索关键论文和组织知识结构方面都远未达到专家水平，为未来改进提供了诊断工具。

Abstract: Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.

</details>


### [57] [A Scalable Entity-Based Framework for Auditing Bias in LLMs](https://arxiv.org/abs/2601.12374)
*Akram Elbouanani,Aboubacar Tuo,Adrian Popescu*

Main category: cs.CL

TL;DR: 该论文提出了一个使用命名实体作为探针的可扩展偏见审计框架，通过合成数据大规模测量LLM中的结构性偏见，发现了系统性政治、地理和经济偏见。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型偏见评估方法存在生态效度与统计控制之间的权衡：人工提示无法反映真实使用场景，而自然任务又缺乏规模和严谨性。需要一种既能大规模分析又能保持真实性的偏见审计方法。

Method: 引入基于命名实体的可扩展偏见审计框架，使用合成数据作为探针来测量模型行为中的结构性差异。通过19亿个数据点，涵盖多种实体类型、任务、语言、模型和提示策略进行大规模分析。

Result: 发现系统性偏见：模型惩罚右翼政客、偏爱左翼政客；偏好西方和富裕国家而非全球南方；偏爱西方公司；惩罚国防和制药行业公司。指令微调减少偏见，但模型规模增大会放大偏见，使用中文或俄文提示不会减弱西方偏好。

Conclusion: 大语言模型在高风险应用部署前应进行严格审计，因为研究发现模型存在系统性偏见，且这些偏见会随规模增大而加剧，语言切换无法消除西方中心偏好。

Abstract: Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.

</details>


### [58] [LR-DWM: Efficient Watermarking for Diffusion Language Models](https://arxiv.org/abs/2601.12376)
*Ofek Raban,Ethan Fetaya,Gal Chechik*

Main category: cs.CL

TL;DR: 提出LR-DWM水印方案，针对扩散语言模型，通过同时利用左右邻居token进行偏置，实现高效水印嵌入和检测，计算和内存开销极小


<details>
  <summary>Details</summary>
Motivation: 现有水印方法主要针对自回归模型，依赖序列生成特性。扩散语言模型采用非顺序迭代去噪生成，需要大幅修改现有方法。最近工作通过反转过程实现水印，但计算或内存开销大

Method: 提出左右扩散水印方案，当左右邻居token可用时，基于两者对生成token进行偏置。该方法运行时和内存开销极小，接近无水印基线

Result: 在标准评估设置下实现可靠统计检测，扩散语言模型可高效水印，检测率高，计算和内存开销可忽略

Conclusion: LR-DWM证明了扩散语言模型可以高效水印，在保持接近基线性能的同时实现可靠检测，解决了现有方法计算开销大的问题

Abstract: Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.

</details>


### [59] [NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages](https://arxiv.org/abs/2601.12389)
*Lakshya Tomar,Vinayak Abrol,Puneet Agarwal*

Main category: cs.CL

TL;DR: NADIR是一个新型非自回归模型，针对多语言音译等序列任务，在保持准确性的同时实现13倍加速，显著减少各类错误。


<details>
  <summary>Details</summary>
Motivation: 许多序列到序列任务（如多语言音译、代码重构、语法修正等）主要依赖局部依赖关系，自回归模型虽然准确但推理延迟高，而非自回归模型速度快但存在幻觉和长度控制问题，需要探索平衡方案。

Method: 提出NADIR架构，结合差分变换器和混合专家机制，无需顺序依赖即可稳健建模复杂字符映射，专门针对印度语言的多语言音译任务设计。

Result: 相比最先进的自回归基线实现13倍以上加速，字符错误率15.78%（自回归14.44%，标准非自回归21.88%），显著减少重复错误49.53%、替换错误24.45%、省略错误32.92%、插入错误16.87%。

Conclusion: NADIR为构建快速可靠的非自回归系统提供了实用蓝图，有效弥合了自回归模型的准确性与实时大规模部署需求之间的差距。

Abstract: In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.

</details>


### [60] [Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification](https://arxiv.org/abs/2601.12419)
*Mahammad Namazov,Tomáš Koref,Ivan Habernal*

Main category: cs.CL

TL;DR: 该研究比较了法律领域大语言模型的可解释性技术，发现模型预测违规的"理由"与法律专家的判断存在显著差异，尽管量化分析结果和分类性能表现良好。


<details>
  <summary>Details</summary>
Motivation: 法律领域应用大语言模型需要信任和透明度，但哪种技术能最好地解释法律结果预测仍是一个开放问题。需要建立一个比较分析框架来评估模型无关的可解释性技术。

Method: 提出一个比较分析框架，采用两种理由提取方法（从输入文本中提取人类可解释的简洁文本片段作为理由），通过忠实性（标准化充分性和全面性指标）和合理性（请法律专家评估提取的理由）进行评估，并评估LLM作为评判者的可行性。

Result: 研究发现，尽管量化分析结果和下游分类性能表现良好，但模型预测违规的"理由"与法律专家的判断存在显著差异。这表明仅靠定量指标不足以评估法律领域模型解释的质量。

Conclusion: 在法律领域应用大语言模型时，需要结合定量指标和专家评估来全面评估可解释性技术。模型预测的"理由"与专家判断的差异强调了人类专家评估在验证模型解释质量中的重要性。

Abstract: Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.

</details>


### [61] [System-Mediated Attention Imbalances Make Vision-Language Models Say Yes](https://arxiv.org/abs/2601.12430)
*Tsan Tsai Chan,Varsha Suresh,Anisha Saha,Michael Hahn,Vera Demberg*

Main category: cs.CL

TL;DR: 该研究提出系统注意力是VLM幻觉的关键因素，通过重新分配系统注意力到图像和文本输入可以有效抑制"是"偏见幻觉


<details>
  <summary>Details</summary>
Motivation: 现有缓解VLM幻觉的方法通常偏向图像中心解释，过度强调增加图像注意力而忽视系统模态的作用。本研究旨在探索更全面的系统介导解释，将幻觉归因于功能冗余的系统权重减少了图像和文本输入的注意力

Method: 采用系统介导的框架，将注意力不平衡归因于功能冗余的系统权重。通过因果性地重新分配系统模态的注意力到图像和文本输入，评估这种方法对抑制"是"偏见幻觉的效果

Result: 重新分配系统注意力到图像和文本输入显著抑制了"是"偏见，通常优于现有方法。证据表明系统介导的注意力不平衡通过鼓励依赖粗粒度输入表征导致"是"偏见

Conclusion: 系统注意力是VLM幻觉的关键因素，可作为缓解幻觉的有效杠杆。系统介导的注意力不平衡导致对粗粒度表征的默认依赖，不适合某些任务

Abstract: Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.

</details>


### [62] [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465)
*Miao Peng,Weizhou Shen,Nuo Chen,Chenliang Li,Ming Yan,Jia Li*

Main category: cs.CL

TL;DR: 提出DeepReasonQA和LongPAS方法，解决长上下文推理中RLVR性能下降问题，通过知识图谱合成高难度多跳QA对，并利用过程优势赋形捕捉"几乎正确"轨迹的学习信号。


<details>
  <summary>Details</summary>
Motivation: RLVR在短上下文推理中有效，但在长上下文场景中性能下降，存在"几乎正确"现象（轨迹大部分正确但在最后一步失败）。这归因于：1）长上下文QA数据缺乏高推理密度；2）长上下文RL训练中部分正确轨迹的学习信号丢失。

Method: 1. DeepReasonQA：基于知识图谱的可控合成框架，构建高难度、多跳的长上下文QA对，包含内在推理链。2. LongPAS：长上下文过程优势赋形方法，通过有效性和相关性两个维度评估推理步骤，进行细粒度信用分配，从"几乎正确"轨迹中捕捉关键学习信号。

Result: 在三个长上下文推理基准测试中，该方法显著优于RLVR基线，与前沿LLM性能相当但使用更少参数。进一步分析证实了方法在增强长上下文推理能力和保持RL训练稳定性方面的有效性。

Conclusion: 通过合成高推理密度数据和细粒度信用分配，成功解决了长上下文推理中RLVR的性能瓶颈，为长上下文推理的强化学习训练提供了有效解决方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.

</details>


### [63] [Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty](https://arxiv.org/abs/2601.12471)
*Sravanthi Machcha,Sushrita Yerra,Sahil Gupta,Aishwarya Sahoo,Sharmin Sultana,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: MedAbstain是一个用于评估LLMs在医学多选题中弃权能力的基准，发现即使高准确率模型也常无法在不确定时弃权，提供明确弃权选项比输入扰动更能提高安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估过于强调准确性，但在现实世界和安全关键应用中，模型在不确定时能够弃权同样重要，这对于可信部署至关重要。

Method: 提出MedAbstain基准和评估协议，整合了共形预测、对抗性问题扰动和明确弃权选项，系统评估开源和闭源LLMs在医学多选题中的弃权能力。

Result: 即使最先进的LLMs也经常无法在不确定时弃权；提供明确弃权选项能显著增加模型不确定性和安全弃权，效果远优于输入扰动；模型规模扩展或高级提示技术改善有限。

Conclusion: 弃权机制对于LLM可信部署至关重要，研究结果为高风险应用中的安全性改进提供了实用指导。

Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.

</details>


### [64] [Capability-Aware Early-Stage Research Idea Evaluation](https://arxiv.org/abs/2601.12473)
*Renlong Jie,Chen Chu,Zhen Wang*

Main category: cs.CL

TL;DR: 提出一个能力感知框架，仅使用作者信息和研究想法（无需完整论文或实验结果）来预测论文接受率和评分，显著优于基于完整文本的基线方法。


<details>
  <summary>Details</summary>
Motivation: 在概念阶段（即投入大量资源之前）预测研究想法的结果，对于优化科学资源分配和研究规划具有巨大潜力。现有方法严重依赖已完成的手稿或同行评审，需要更早阶段的预测能力。

Method: 提出一个能力感知框架，通过三路Transformer架构整合作者信息、（推断的）能力呈现和研究想法，采用灵活的融合机制。还引入两阶段架构来学习给定作者信息和想法的能力表示。

Result: 实验表明，该方法显著优于基于bert-base和bert-large微调的单路模型，能力预测显著提高了最终模型的预测准确性。

Conclusion: 所提出的方法可应用于早期研究结果预测和科学资源分配，为研究规划提供了有价值的工具。

Abstract: Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.

</details>


### [65] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

TL;DR: DoPE是一种文档层防御框架，通过在PDF/HTML考试文档中嵌入语义诱饵来防止和检测MLLM作弊，无需依赖传统分类器。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）能够直接处理考试文档，威胁传统评估和学术诚信。需要开发文档层防御机制来防止AI自动化作弊。

Method: 提出DoPE框架，在文档创作时嵌入语义诱饵，利用MLLM渲染-解析差异。包括FewSoRT-Q生成问题级语义诱饵和FewSoRT-D将其封装到水印文档中。

Result: 在Integrity-Bench基准（1826个考试）上测试，对OpenAI和Anthropic的黑盒MLLMs：检测率91.4%（误报率8.7%），96.3%的尝试被阻止或诱导诱饵对齐失败。

Conclusion: DoPE提供模型无关的预防和检测能力，有效保护学术诚信，并发布了基准、工具包和评估代码供可重复研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [66] [Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning](https://arxiv.org/abs/2601.12535)
*Ahmed Attia,Alham Fikri*

Main category: cs.CL

TL;DR: 本文提出一种基于自监督强化学习的低资源机器翻译微调方法，使用NLLB模型通过往返翻译进行引导，在多种低资源语言上取得改进。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言社区平行数据的收集，低资源机器翻译受到越来越多关注，但许多改进低资源机器翻译的潜在方法尚未被探索。本文旨在研究如何利用自监督强化学习来提升低资源翻译性能。

Method: 采用基于自监督强化学习的微调方法，使用NLLB模型家族进行往返翻译引导：先将英语翻译成目标低资源语言，再翻译回英语。使用chrF++和BLEU组合作为重建英语句子的奖励函数。在NLLB-MD数据集上评估600M和1.3B参数的NLLB模型。

Result: 在Central Aymara、Friulian、Wolof和Russian等语言上观察到一致的改进。翻译输出的定性检查表明流畅性和语义保真度有所提高。

Conclusion: 该方法可以进一步受益于规模扩展，使模型能够越来越多地利用其预训练知识并继续自我改进。为低资源机器翻译提供了一种有效的自监督强化学习微调方法。

Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.

</details>


### [67] [Benchmarking Concept-Spilling Across Languages in LLMs](https://arxiv.org/abs/2601.12549)
*Ilia Badanin,Daniil Dzenhaliou,Imanol Schlag*

Main category: cs.CL

TL;DR: 该论文提出了一个评估多语言大语言模型语义鲁棒性的比较框架，通过系统测量模型处理多义词的能力来评估语言溢出现象，并开发了一个包含9种语言、100个高多义性英语单词的基准测试。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型虽然展现出跨语言能力，但存在系统性偏向其他语言表示的问题，导致在非英语语言生成内容时出现语义干扰（语言溢出现象）。需要开发评估框架来衡量模型的语义鲁棒性。

Method: 提出比较框架，通过结构化意义生成任务评估模型处理多义词的能力。使用100个高多义性英语单词作为基准，在9种语言中测试。通过测量模型在生成序列中何时转向主导语言的意义来相对评估模型性能。

Result: 评估了多种开源和闭源多语言LLM，发现不同模型和语言间的语义鲁棒性存在显著差异。建立了无需确定错误来源因果归因的模型比较排序系统。

Conclusion: 贡献了可扩展的多语言语义评估比较基准和严格的验证流程，为开发更语言平衡的AI系统提供了关键工具。

Abstract: Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

</details>


### [68] [Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models](https://arxiv.org/abs/2601.12555)
*Yihong Liu,Bingyu Xiong,Hinrich Schütze*

Main category: cs.CL

TL;DR: LLMs在上下文中介的事实回忆中表现下降，尽管大模型对此更鲁棒，揭示了孤立事实回忆与上下文理解之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有事实回忆评估主要评估孤立的事实检索，但在自然语言使用中，事实通常通过上下文间接访问。本研究旨在探究LLMs在目标实体嵌入自然语境而非显式查询时，能否可靠地检索跨语言的事实知识。

Method: 构建保留底层事实但通过上下文句子引入指称中介的受控提示；使用合成名称和真实名称来分离上下文效应与名称特定关联；在五种语言中评估多个模型家族。

Result: 上下文中介持续降低事实回忆性能，不同关系间存在显著差异；更大模型对上下文中介更鲁棒，相对于直接查询的性能差距减小；真实名称和名称来源的影响混合且无系统性。

Conclusion: 研究揭示了多语言LLMs中孤立事实回忆与上下文依赖语言理解之间的差距，表明当前评估方法未能充分捕捉自然语言使用中的事实检索能力。

Abstract: Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

</details>


### [69] [A Cloud-based Multi-Agentic Workflow for Science](https://arxiv.org/abs/2601.12607)
*Anurag Acharya,Timothy Vega,Rizwan A. Ashraf,Anshu Sharma,Derek Parker,Robert Rallo*

Main category: cs.CL

TL;DR: 提出一个领域无关、模型独立的云上科学助手代理框架，通过监督代理协调多个专业代理，能处理从文献回顾到复杂模拟的科研任务，在催化剂研究中验证有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务（如运行模拟、复杂决策）方面能力有限，而现有的代理系统在平衡模型、云提供商和外部资源方面存在挑战，阻碍了代理系统的实际应用。

Method: 设计了一个领域无关、模型独立的云上代理框架，采用监督代理协调多个具有特定能力的专业代理，能够处理从简单的文献回顾、数据分析到复杂的模拟运行等科研任务。

Result: 在催化剂研究领域的验证中，系统能将任务正确路由到相应代理的准确率达90%，合成任务完成率达97.5%，真实世界任务完成率达91%，性能与前沿模型相当或更好。

Conclusion: 该框架为科学领域提供了一个可行的代理系统实现方案，能够有效协调云资源、外部工具和语言模型，显著提升科研效率，具有可复制性。

Abstract: As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.

</details>


### [70] [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618)
*Elham Tajik,Conrad Borchers,Bahar Shahrokhian,Sebastian Simon,Ali Keramati,Sonika Pal,Sreecharan Sankaranarayanan*

Main category: cs.CL

TL;DR: 该研究提出使用LLM多智能体系统的推理轨迹作为过程数据，通过余弦相似度量化智能体间的分歧，将分歧转化为有意义的分析信号，用于改进定性编码的可靠性和解释深度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，全自动和人机协作的分析方法出现，但缺乏指导此类工作流程的方法学标准。需要新的方法来增强定性编码的解释实践和可靠性评估。

Method: 使用LLM多智能体系统生成推理轨迹，应用余弦相似度来系统检测、量化和解释智能体间的分歧。分析近10,000个智能体对编码人类辅导对话片段的情况，将定量相似度指标与定性审查相结合。

Result: LLM智能体的语义推理相似度能稳健地区分共识与分歧，并与人类编码可靠性相关。基于该指标的定性分析揭示了代码内的细微教学子功能，并为概念代码本细化提供了机会。

Conclusion: 推理轨迹分歧代表了一类有价值的新分析信号，通过整合定量相似度指标与定性审查，该方法有潜力改进和加速编码过程中的评分者间可靠性建立，特别是在LLM与人类协作时，推动教育研究方法学严谨性和解释深度。

Abstract: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

</details>


### [71] [BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models](https://arxiv.org/abs/2601.12632)
*Kriti Bhattarai,Vipina K. Keloth,Donald Wright,Andrew Loza,Yang Ren,Hua Xu*

Main category: cs.CL

TL;DR: BioPulse-QA是一个新的生物医学问答基准，使用最新发布的生物医学文档来评估LLMs，解决了现有基准的静态性、数据泄露和多样性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学基准存在局限性：使用静态或过时数据集，无法捕捉生物医学知识的动态性和情境丰富性；存在数据泄露风险（与模型预训练语料重叠）；忽视语言变异鲁棒性和人口统计学偏差等关键维度。

Method: 引入BioPulse-QA基准，使用新发布的生物医学文档（药物标签、试验方案、临床指南）构建2,280个专家验证的问答对及其扰动变体，涵盖抽取式和生成式格式。评估了GPT-4o、GPT-o1、Gemini-2.0-Flash和LLaMA-3.1 8B Instruct等模型。

Result: GPT-o1在药物标签上获得最高放松F1分数（0.92），Gemini-2.0-Flash次之（0.90）。临床试验是最具挑战性的来源，抽取式F1分数低至0.36。改写比拼写错误带来的性能差异更大，偏差测试显示差异可忽略。

Conclusion: BioPulse-QA为评估生物医学LLMs提供了一个可扩展且临床相关的框架，能够更好地评估模型在动态、高风险生物医学环境中的实际表现。

Abstract: Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.
  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.
  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.
  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.

</details>


### [72] [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639)
*Daniel Vennemeyer,Punya Syon Pandey,Phan Anh Duong,Michael Umeokoli,Samuel Ratnam*

Main category: cs.CL

TL;DR: 研究发现微调目标对LLM安全性的影响随训练规模变化：小规模时各目标安全性相似但能力不同，大规模时监督和偏好微调会显著增加对抗脆弱性和角色漂移，而ORPO和KL正则化能有效缓解这些问题。


<details>
  <summary>Details</summary>
Motivation: 尽管在良性数据上微调LLM仍可能损害对齐性和对抗鲁棒性，但微调目标如何影响安全性的直接分析仍然有限。本文旨在系统比较不同微调目标对安全性和能力的影响。

Method: 在数据、领域、架构和优化固定的控制条件下，比较了六种微调目标：监督微调、直接偏好优化、条件微调、接种提示、几率比偏好优化和KL正则化微调。在封闭式推理和开放式生成任务上进行评估。

Result: 微调目标选择导致安全-能力前沿的系统性、规模依赖性变化：小训练预算时鲁棒性相似但能力不同；大预算时目标差异显著，监督和偏好微调使能力提升与对抗脆弱性、角色漂移紧密耦合，而ORPO和KL正则化能显著缓解这两种问题。

Conclusion: 微调目标在小规模时对安全性影响不大，但随着训练规模增加，成为对抗鲁棒性和潜在角色稳定性的主要驱动因素。约束学习信号的目标（特别是ORPO和KL正则化）能更好地平衡安全性和能力。

Abstract: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.

</details>


### [73] [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648)
*Nafiz Imtiaz Khan,Kylie Cleland,Vladimir Filkov,Roger Eric Goldman*

Main category: cs.CL

TL;DR: 本研究评估了使用大语言模型从自由文本放射学报告中自动提取结构化程序信息以生成程序病例日志的可行性，结果显示本地和商业模型均能达到接近0.87的F1分数，显著减少文书负担。


<details>
  <summary>Details</summary>
Motivation: 放射学培训中的程序病例日志记录耗时且手动记录容易不一致，需要自动化解决方案来减轻学员的文书负担并提高记录一致性。

Method: 使用指令提示和思维链提示策略，评估多个本地和商业大语言模型从414份介入放射学报告中提取结构化程序信息的性能，评估指标包括敏感度、特异度、F1分数、推理延迟和代币效率。

Result: 本地和商业模型均表现出强大的提取性能，最佳F1分数接近0.87，但在速度和成本方面存在不同权衡。自动化可显著减少学员的文书负担并提高病例记录一致性。

Conclusion: 大语言模型辅助文档记录在医学教育中具有可行性，但需要跨机构和临床工作流程的进一步验证。自动化程序病例日志记录有潜力改变放射学培训的文书工作流程。

Abstract: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.

</details>


### [74] [Augmenting Question Answering with A Hybrid RAG Approach](https://arxiv.org/abs/2601.12658)
*Tianyi Yang,Nashrah Haque,Vaishnave Jonnalagadda,Yuya Jeremy Ong,Zhehui Chen,Yanzhao Wu,Lei Yu,Divyesh Jadav,Wenqi Wei*

Main category: cs.CL

TL;DR: SSRAG是一种混合架构，通过查询增强、智能路由和结构化检索机制提升RAG在问答任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在检索上下文相关信息时存在困难，导致答案不完整或不够理想，需要改进检索过程以提高问答质量。

Method: 提出结构化语义RAG（SSRAG）混合架构，整合查询增强、智能路由，以及结合向量和图技术的结构化检索机制与上下文统一。

Result: 在TruthfulQA、SQuAD和WikiQA三个数据集上对五个大语言模型进行评估，SSRAG相比标准RAG实现持续提升了响应质量。

Conclusion: SSRAG通过改进检索过程和增强上下文基础，提高了答案准确性和信息丰富度，为RAG系统提供了有效的质量提升方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

</details>


### [75] [UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages](https://arxiv.org/abs/2601.12696)
*Tassallah Abdullahi,Macton Mgonzo,Mardiyyah Oduwole,Paul Okewunmi,Abraham Owodunni,Ritambhara Singh,Carsten Eickhoff*

Main category: cs.CL

TL;DR: UbuntuGuard是首个非洲政策导向的安全基准，针对低资源非洲语言，通过领域专家构建对抗性查询和情境化安全策略，评估现有守护模型的跨语言和文化适应性。


<details>
  <summary>Details</summary>
Motivation: 当前守护模型主要面向西方中心和高资源语言，对低资源非洲语言存在安全漏洞、跨语言安全失效和文化错位问题，且现有安全分类僵化，无法适应多样化的语言和社会文化背景。

Method: 构建UbuntuGuard基准：1) 155名领域专家（包括医疗健康领域）编写对抗性查询；2) 从查询中推导情境化安全策略和参考响应；3) 评估13个模型（6个通用LLM和7个守护模型），涵盖静态、动态和多语言三种变体。

Result: 研究发现：1) 现有英语中心基准高估了多语言安全性能；2) 跨语言迁移只能提供部分但不充分的覆盖；3) 动态模型虽然能在推理时利用策略，但仍难以完全适应当地非洲语言情境。

Conclusion: 需要开发多语言、文化扎根的安全基准，以构建可靠、公平的低资源语言守护模型，UbuntuGuard为此提供了首个非洲政策导向的评估框架。

Abstract: Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

</details>


### [76] [A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization](https://arxiv.org/abs/2601.12698)
*Qiuyi Qu,Yicheng Sui,Yufei Sun,Rui Chen,Xiaofei Zhang,Yuzhi Zhang,Haofeng Wang,Ge Lan,Ning Zhang*

Main category: cs.CL

TL;DR: 提出基于模板的GPU内核优化方法，通过参数化模板和搜索式自动调优，相比直接代码重写获得更稳定、更高质量的加速效果


<details>
  <summary>Details</summary>
Motivation: GPU代码优化对HPC和大模型训练/推理至关重要，但现有方法（编译器优化、手工内核、基于LLM的直接重写）存在参数选择隐式、难以控制、需要人工干预、性能提升不稳定等问题

Method: 在智能体驱动的迭代循环上增加模板重写层：1）将内核语义重构为显式参数化模板；2）通过基于搜索的自动调优优化模板参数；3）使用智能体调优器迭代执行模板化、测试、分析和规划，利用性能分析反馈在硬件资源限制下执行约束参数搜索

Result: 在真实世界内核实验中，最佳情况下获得超过3倍的加速。相比仅使用智能体直接重写，模板+搜索设计显著降低了迭代优化的随机性，使过程更可解释，能够更系统地达到高性能配置

Conclusion: 提出的模板+搜索方法为GPU内核优化提供了更稳定、更高质量的解决方案，可扩展到OpenCL、HIP等后端，为实际生产工作负载提供自动化性能优化

Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

</details>


### [77] [A Shared Geometry of Difficulty in Multilingual Language Models](https://arxiv.org/abs/2601.12731)
*Stefano Civelli,Pietro Bernardelle,Nicolò Brunello,Gianluca Demartini*

Main category: cs.CL

TL;DR: LLMs在问题难度预测中表现出两阶段表征：浅层表征具有跨语言泛化能力但精度较低，深层表征在单一语言内精度高但跨语言泛化差，表明模型先形成语言无关的难度概念再转化为语言特定表征。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多语言环境下如何表征问题难度，探索难度信号在模型内部不同层级的分布及其跨语言泛化特性，理解LLMs处理元认知属性（如难度估计）的机制。

Method: 使用Easy2Hard基准的AMC子集，翻译为21种语言，在LLMs内部表征上训练线性探针，分析浅层（早期层）和深层（后期层）表征在难度预测上的表现差异。

Result: 发现难度相关信号出现在两个不同阶段：深层表征探针在相同语言内精度高但跨语言泛化差；浅层表征探针跨语言泛化好但语言内精度较低。表明LLMs先形成语言无关的难度表征，再转化为语言特定表征。

Conclusion: LLMs处理问题难度估计时遵循两阶段表征过程：先抽象概念空间（语言无关），后语言特定输出。这一模式不仅适用于语义内容，也适用于元认知属性如难度估计，与现有LLM可解释性研究一致。

Abstract: Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.

</details>


### [78] [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748)
*Bin Xie,Bingbing Xu,Xueyun Tian,Yilin Chen,Huawei Shen*

Main category: cs.CL

TL;DR: 提出两阶段框架解决过程奖励模型中的噪声监督问题，通过反射感知标签校正和噪声感知迭代训练，显著提升步骤级正确性判别能力


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型需要昂贵的步骤级监督，而蒙特卡洛估计方法会产生策略依赖的噪声奖励，包括错误步骤的正奖励和正确步骤的负奖励，影响模型性能

Method: 两阶段框架：1) 标注阶段使用大语言模型作为裁判，通过检测反思和自我校正行为来校正标签；2) 训练阶段采用噪声感知迭代训练框架，让PRM基于自身置信度逐步精炼噪声标签

Result: 方法显著提升了步骤级正确性判别能力，在平均F1分数上比使用噪声监督训练的PRM提高了27%的绝对增益

Conclusion: 提出的反射感知标签校正和噪声感知迭代训练框架有效缓解了过程奖励模型中的噪声监督问题，显著提升了模型性能

Abstract: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

</details>


### [79] [VISPA: Pluralistic Alignment via Automatic Value Selection and Activation](https://arxiv.org/abs/2601.12758)
*Shenyan Zheng,Jiayou Zhong,Anudeex Shetty,Heng Ji,Preslav Nakov,Usman Naseem*

Main category: cs.CL

TL;DR: VISPA是一个无需训练的多元化对齐框架，通过动态选择和内部模型激活引导实现对价值表达的直接控制，使语言模型能够反映多样的人类观点而非平均偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在关键领域的应用增加，需要其输出反映多样的人类观点而非平均偏好。现有方法要么考虑有限的价值，要么依赖提示级干预，缺乏价值控制和代表性。

Method: VISPA是一个无需训练的多元化对齐框架，通过动态选择和内部模型激活引导实现对价值表达的直接控制。

Result: 在涵盖多个模型和评估设置的广泛实证研究中，VISPA在医疗保健及其他领域的所有多元化对齐模式中都表现出色。进一步分析显示VISPA能够适应不同的引导初始化、模型和/或价值。

Conclusion: 这些结果表明，多元化对齐可以通过内部激活机制实现，为构建服务于所有人的语言模型提供了一条可扩展的路径。

Abstract: As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

</details>


### [80] [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771)
*Keito Inoshita*

Main category: cs.CL

TL;DR: 提出LAMA框架，利用LLM的关联记忆能力进行国籍预测，通过回忆同名名人间接推理，双智能体架构在99国任务上达到81.7%准确率，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM拥有丰富世界知识但缺乏有效提取方法。国籍预测任务需要文化历史背景知识，传统直接推理方法在应用抽象语言规则方面存在局限。

Method: 提出LAMA框架，将LLM世界知识作为关联记忆。不直接推理国籍，而是回忆同名名人并聚合其国籍。采用双智能体架构：人物智能体（熟悉名人）和媒体智能体（熟悉虚构角色），并行回忆名人，通过投票生成Top-1预测，通过条件补全生成Top-K预测。

Result: 在99国国籍预测任务上达到0.817准确率，显著优于传统LLM提示方法和神经网络模型。实验发现：LLM在回忆具体例子方面比抽象推理更可靠；基于回忆的方法对低频国籍具有鲁棒性；双智能体架构具有互补协同效应。

Conclusion: LAMA展示了通过检索和聚合LLM知识而非提示推理的新多智能体系统的有效性，为利用LLM世界知识提供了新范式。

Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

</details>


### [81] [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812)
*Sushant Kumar Ray,Gautam Siddharth Kashyap,Sahil Tripathi,Nipun Joshi,Vijay Govindarajan,Rafiq Ali,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: MEDASSESS-X是一个部署导向的临床问答框架，通过推理时对齐而非监督微调，使用轻量级引导向量指导模型激活，解决"专业化谬误"——即认为专业医疗LLM在临床问答中必然更优的错误假设。


<details>
  <summary>Details</summary>
Motivation: 当前临床问答系统过度依赖领域特定的微调，存在专业化医疗LLM（如BioBERT、BioGPT）覆盖范围窄、重新训练成本高、适应性有限等实际问题。监督微调方法强化了"专业化谬误"——即认为专业医疗LLM在临床问答中必然更优的错误假设。

Method: 提出MEDASSESS-X框架，采用推理时对齐而非监督微调。使用轻量级引导向量在推理时指导模型激活，使其朝向医学一致性的推理，无需更新模型权重或进行领域特定的重新训练。

Result: MEDASSESS-X在所有LLM家族中都带来了一致的性能提升：准确率最高提升+6%，事实一致性提升+7%，安全错误率降低高达50%。该框架稳定了通用和专业医疗LLM在临床问答中的表现。

Conclusion: MEDASSESS-X通过推理时对齐有效解决了"专业化谬误"，证明无需领域特定微调即可获得稳定且高性能的临床问答系统。该方法为医疗AI部署提供了更实用、成本效益更高的解决方案。

Abstract: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

</details>


### [82] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

TL;DR: 提出JurisMMA框架用于法律判决预测，通过分解审判任务、标准化流程并组织为不同阶段，同时构建包含10万+中国司法记录的JurisMM多模态数据集，在LawBench基准上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法依赖统计分析或基于角色的模拟，面临多重指控、多样证据和缺乏适应性的挑战，需要更有效的框架来处理复杂法律案件。

Method: 提出JurisMMA框架，将审判任务分解、流程标准化并组织为不同阶段；构建包含文本和多模态视频-文本数据的JurisMM大型数据集（超过10万条中国司法记录）。

Result: 在JurisMM数据集和LawBench基准上的实验验证了框架的有效性，表明该框架不仅适用于法律判决预测，还能为更广泛的法律应用提供支持。

Conclusion: JurisMMA框架为法律判决预测提供了新视角，同时构建的JurisMM数据集为未来法律方法和数据集的发展奠定了基础，具有广泛的法律应用潜力。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


### [83] [Rapport du Projet de Recherche TRAIMA](https://arxiv.org/abs/2601.12844)
*Julie Rançon,Jean-François Cerisier,Emilie Remond,Aurélien Nguyen,Andrew Peterson,Ladjel Bellatreche*

Main category: cs.CL

TL;DR: TRAIMA项目探索利用机器学习自动处理教育场景中的多模态交互，解决人工分析耗时且难以规模化的问题，重点研究课堂解释与协作序列的多模态特征。


<details>
  <summary>Details</summary>
Motivation: 当前教育互动研究中，言语、副言语和非言语数据的分析完全依赖人工，极其耗时且难以规模化。TRAIMA项目旨在探索机器学习如何帮助分类和归类这类多模态交互，以解决这一方法论瓶颈。

Method: 项目聚焦课堂解释与协作序列（法语作为外语和母语情境），将其视为多模态现象（语言、韵律、手势、姿势、注视、空间位置）。采用话语分析和互动语言学理论，将解释话语定义为三部结构（开场、解释核心、收尾）。建立详细的转录规范，比较现有转录体系（ICOR、Mondada等），使用INTER-EXPLIC和EXPLIC-LEXIC语料库（约30小时课堂互动）进行实证分析，特别关注教师手势和韵律特征的功能作用。

Result: 项目展示了转录实践的不可避免的变异性和解释性维度，取决于理论立场和分析目标。建立了与机器学习方法兼容的转录规范、标注类别和分析单元，强调了理论明确性和研究者反思性的必要性。TechnéLAB平台作为多模态数据采集和研究基础设施发挥了关键作用。

Conclusion: TRAIMA并未开发完全可操作的自动化系统，而是为多模态教学互动的自动处理建立了严谨的方法论框架。项目为未来教学法、话语分析、多模态和人工智能教育交叉领域的跨学科研究奠定了基础。

Abstract: The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

</details>


### [84] [Race, Ethnicity and Their Implication on Bias in Large Language Models](https://arxiv.org/abs/2601.12868)
*Shiyue Hu,Ruizhe Li,Yanjun Gao*

Main category: cs.CL

TL;DR: 该研究通过可解释性方法分析LLMs中种族和族裔信息的内部表示机制，发现人口统计信息分布在多个内部单元中，干预能减少偏见但仍有残留效应


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗等高风险领域应用时，种族和族裔信息可能被明确陈述或隐含推断。现有研究主要记录结果层面的差异，对内部机制了解有限，需要深入理解这些信息在模型内部如何表示和运作

Method: 使用两个公开数据集（毒性生成和临床叙事理解任务），分析三个开源模型，采用可复现的可解释性流程，结合探测、神经元级归因和针对性干预方法

Result: 人口统计信息分布在多个内部单元中，不同模型间差异显著；部分单元编码了预训练中的敏感或刻板印象关联；相同的人口统计线索可能引发不同行为；抑制相关神经元能减少偏见但仍有显著残留效应

Conclusion: 干预主要改变行为而非表示层面，表明需要更系统的缓解策略；研究揭示了LLMs中人口统计信息表示的复杂性，为理解模型偏见机制提供了新见解

Abstract: Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

</details>


### [85] [From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.12904)
*Jiahao Wang,Weiyu Xie,Mingxing Zhang,Boxing Zhang,Jianwei Dong,Yuening Zhu,Chen Lin,Jinqi Tang,Yaochen Han,Zhiyuan Ai,Xianglin Chen,Yongwei Wu,Congfeng Jiang*

Main category: cs.CL

TL;DR: FusionRAG是一个优化RAG推理效率的框架，通过在预处理阶段嵌入跨块上下文信息，在重处理阶段选择性重计算关键token的KV缓存，在保持生成质量的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法重用检索块的预处理KV缓存可以加速推理，但缺乏跨块上下文信息导致生成质量显著下降，无法充分利用KV缓存重用的潜在优势。

Method: 提出FusionRAG框架：1) 离线预处理阶段：将其他相关文本块的信息嵌入到每个块中；2) 在线重处理阶段：对模型关注的token重新计算KV缓存，实现质量与效率的平衡。

Result: FusionRAG在相同重计算比例下显著提升生成质量：重计算少于15%的token，相比基线获得高达70%的归一化F1分数提升，相比Full Attention减少2.66x-9.39x的TTFT。

Conclusion: FusionRAG通过优化RAG的预处理和重处理阶段，在保持生成质量的同时大幅提升推理效率，为KV缓存重用提供了有效的解决方案。

Abstract: Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

</details>


### [86] [Gated Differentiable Working Memory for Long-Context Language Modeling](https://arxiv.org/abs/2601.12906)
*Lingrui Mei,Shenghua Liu,Yiwei Wang,Yuyao Ge,Baolong Bi,Jiayu Yao,Jun Wan,Ziling Yin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: Gdwm通过门控可微分工作内存框架，利用上下文效用估计来优化测试时适应的内存整合，相比均匀策略减少4倍梯度步数，在长上下文任务中实现更好的效率-性能平衡。


<details>
  <summary>Details</summary>
Motivation: 长上下文对Transformer模型构成挑战：注意力分数在数千个token上被稀释，关键信息常常在中间丢失，模型难以适应推理时的新模式。现有的测试时适应方法使用均匀写入策略，浪费计算资源在低效用区域，且在语义异构上下文中存在高梯度方差问题。

Method: 将测试时适应重新定义为预算约束下的内存整合问题，提出Gdwm（门控可微分工作内存）框架。该框架引入写入控制器来门控整合过程，控制器估计"上下文效用"（一种衡量长距离上下文依赖的信息论度量），并相应分配梯度步数，同时保持全局覆盖。

Result: 在ZeroSCROLLS和LongBench v2上的实验表明，Gdwm在达到可比或更优性能的同时，比均匀基线方法减少了4倍的梯度步数，为测试时适应建立了新的效率-性能帕累托前沿。

Conclusion: 通过将测试时适应重新定义为预算约束的内存整合问题，并引入基于上下文效用的门控机制，Gdwm框架能够更高效地利用计算资源，在长上下文任务中实现更好的性能-效率平衡。

Abstract: Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

</details>


### [87] [SciCoQA: Quality Assurance for Scientific Paper--Code Alignment](https://arxiv.org/abs/2601.12910)
*Tim Baumgärtner,Iryna Gurevych*

Main category: cs.CL

TL;DR: SciCoQA是一个检测科学论文与代码库之间差异的数据集，包含611个差异实例（81个真实，530个合成），涵盖多个计算科学领域。评估显示LLMs在此任务上表现不佳，最佳模型GPT-5仅能检测45.7%的真实差异。


<details>
  <summary>Details</summary>
Motivation: 确保科学论文与其代码实现之间的一致性对于可复现性至关重要。当前缺乏系统检测论文与代码差异的方法和数据集，这阻碍了科学研究的可靠性和可验证性。

Method: 从GitHub问题和可复现性论文中收集真实差异，并提出合成数据生成方法来扩展数据集。详细分析差异类型和类别，构建包含611个差异实例的数据集，涵盖AI、物理、定量生物学等多个领域。

Result: 构建了SciCoQA数据集，包含611个论文-代码差异实例。对21个LLMs的评估显示该任务具有挑战性，特别是在涉及省略论文细节、长上下文输入和预训练语料外数据的情况下。最佳模型GPT-5仅能检测45.7%的真实差异。

Conclusion: SciCoQA数据集为检测科学论文与代码实现之间的差异提供了重要资源。结果表明当前LLMs在此任务上表现有限，特别是在处理复杂科学内容和长上下文时，需要进一步改进模型能力以确保科学研究的忠实实现。

Abstract: We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.

</details>


### [88] [Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs](https://arxiv.org/abs/2601.12921)
*Adimulya Kartiyasa,Bao Gia Cao,Boyang Li*

Main category: cs.CL

TL;DR: 提出IndoSoSci数据集，结合RAG和LLM生成假设文档作为查询，有效提升LLM对印尼文化的理解


<details>
  <summary>Details</summary>
Motivation: 现有LLMs对印尼文化的理解不足，而本地社会科学期刊包含大量本土视角的文化研究，但这一资源被忽视

Method: 从151个开源印尼社科期刊创建IndoSoSci数据集，提取印尼文化相关事实，采用RAG技术，使用LLM生成的假设文档作为检索查询

Result: 提出的方法在IndoCulture基准测试中显著优于多个强基线，结合印尼维基百科后在该基准上达到新的SOTA准确率

Conclusion: IndoSoSci数据集和提出的RAG方法是提升LLM对印尼文化理解的有效途径，本地社科期刊是宝贵的文化知识来源

Abstract: Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

</details>


### [89] [A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits](https://arxiv.org/abs/2601.12945)
*Miao Xie,Siguang Chen,Chunli Lv*

Main category: cs.CL

TL;DR: 这是第一篇系统综述大语言模型与多臂老虎机双向交互的论文，分析了两个领域在组件层面的相互增强作用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型已成为强大的语言理解和生成系统，而多臂老虎机算法为不确定性下的自适应决策提供了原则性框架。目前缺乏对这两个领域双向交互的系统性综述，特别是在组件层面的深入分析。

Method: 通过系统性文献回顾，从组件层面分析LLM与MAB的双向交互：一方面分析MAB算法如何解决LLM从预训练到RAG和个性化的关键挑战；另一方面分析LLM如何重新定义MAB系统的核心组件（如臂定义和环境建模）。

Result: 识别了双向交互的关键益处：MAB算法能解决LLM的关键挑战，而LLM能增强MAB系统的决策能力。分析了现有的LLM增强老虎机系统和老虎机增强LLM系统，总结了设计方法、方法论和性能表现。

Conclusion: 该综述为LLM与MAB的交叉研究提供了系统性框架，识别了关键挑战和代表性发现，并提供了相关文献的GitHub索引，有助于指导未来研究方向。

Abstract: Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

</details>


### [90] [Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images](https://arxiv.org/abs/2601.12960)
*Ainhoa Vivel-Couso,Nicolás Vila-Blanco,María J. Carreira,Alberto Bugarín-Diz,Inmaculada Tomás,Jose M. Alonso-Moral*

Main category: cs.CL

TL;DR: 提出结合不透明与透明方法的牙科年龄估计系统，通过自然语言生成模块为临床医生提供文本解释，经牙科专家验证获得高评分。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗保健中的应用虽然能实现个性化护理，但由于模型不透明性引发信任问题。需要提高透明度以建立临床医生对AI系统的信任。

Method: 1. 结合不透明方法和透明方法的牙科年龄估计系统；2. 通过自然语言生成模块产生临床医生友好的文本解释；3. 与牙科专家合作采用基于规则的方法设计解释；4. 使用问卷由牙科专家手动验证生成解释的质量；5. 遵循ALTAI清单进行可信度自我评估。

Result: 1. 专家在五个维度上平均评分为4.77±0.12（满分5分），表现优异；2. 在ALTAI清单的七个可信度评估维度上得分为4.40±0.27（满分5分），可信度较高。

Conclusion: 提出的系统成功提高了牙科年龄估计的透明度，通过自然语言解释增强了临床医生对AI结果的信任，验证了该方法在医疗AI可解释性方面的有效性。

Abstract: Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

</details>


### [91] [Pardon? Evaluating Conversational Repair in Large Audio-Language Models](https://arxiv.org/abs/2601.12973)
*Shuanghong Huang,Jinlei Xu,Youchao Zhou,Yanghao Zhou,Xuan Zhao,Chong Feng,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种针对大型音频语言模型的修复感知评估框架，通过区分可回答与不可回答的音频输入，并引入EAR评分来同时评估任务能力和修复行为。


<details>
  <summary>Details</summary>
Motivation: 现有的大型音频语言模型评估主要关注答案准确性和对声学扰动的鲁棒性，但假设输入在语义上总是可回答的。然而在真实交互中，经常出现信息缺失的不可回答情况，现有评估方法无法反映模型在这种情况下的表现。

Method: 提出了修复感知评估设置，通过语义-声学掩码协议构建成对的评估条件（可回答vs不可回答）。定义了EAR评分（可评估意识和修复评分），这是一个非补偿性指标，联合评估可回答条件下的任务能力和不可回答条件下的修复行为。

Result: 在两个口语问答基准上的实验表明，大多数模型在输入可回答时表现良好，但在识别语义不可回答性和启动适当的对话修复方面表现不佳，揭示了答案准确性与对话可靠性之间的差距。

Conclusion: 当前以准确性为中心的评估实践存在局限性，需要将不可回答的输入视为修复和持续交互的线索，进行可靠性评估，以更好地反映模型在真实世界中的表现。

Abstract: Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.

</details>


### [92] [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974)
*Hongyang Ma,Tiantian Gu,Huaiyuan Sun,Huilin Zhu,Yongxin Wang,Jie Li,Wubin Sun,Zeliang Lian,Yinghong Zhou,Yi Gao,Shirui Wang,Zhihui Tang*

Main category: cs.CL

TL;DR: 该研究提出了SCMPE基准，评估牙科LLMs从静态知识任务到动态临床对话的性能，发现模型在动态交互中表现下降，主要瓶颈在于主动信息收集和状态跟踪，而非知识保留。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs从被动知识检索器向自主临床代理转变，需要从静态准确性评估转向动态行为可靠性评估。牙科领域高质量AI建议能独特地赋能患者参与决策，因此需要探索这一边界。

Method: 提出了标准化临床管理与性能评估（SCMPE）基准，全面评估从知识导向评估（静态客观任务）到基于工作流的模拟（多轮模拟患者交互）的性能。分析了指南遵从性与决策质量的关系，并量化了检索增强生成（RAG）的影响。

Result: 模型在静态客观任务中表现出高熟练度，但在动态临床对话中性能下降。主要瓶颈在于主动信息收集和动态状态跟踪，而非知识保留。发现通用模型存在"高效性、低安全性"风险。RAG在静态任务中减少幻觉，但在动态工作流中效果有限且异质，有时甚至导致性能下降。

Conclusion: 外部知识本身无法弥补推理差距，需要领域自适应预训练。该研究实证绘制了牙科LLMs的能力边界，为弥合标准化知识与安全、自主临床实践之间的差距提供了路线图。

Abstract: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

</details>


### [93] [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979)
*Qingyu Lu,Liang Ding,Kanjian Zhang,Jinxia Zhang,Dacheng Tao*

Main category: cs.CL

TL;DR: 扩散大语言模型(dLLMs)在代理任务中表现不佳：在具身代理中无法处理时序反馈，在工具调用中难以维持符号精度，需要结合因果推理机制才能有效


<details>
  <summary>Details</summary>
Motivation: 研究扩散大语言模型(dLLMs)作为实时代理交互的替代方案是否真的能带来有效的代理行为，而非仅仅提升效率

Method: 在Agentboard和BFCL基准上全面评估dLLMs在两种代理范式中的表现：具身代理（需要长时程规划）和工具调用代理（需要精确格式），并引入DiffuAgent多代理评估框架

Result: dLLMs无法作为可靠的代理骨干：在具身设置中反复尝试失败，无法在时序反馈下分支；在工具调用设置中无法在扩散噪声下维持符号精度（如严格的JSON模式）

Conclusion: dLLMs在非因果角色中有效（如记忆总结和工具选择），但需要在去噪过程中融入因果、精确和逻辑基础的推理机制才能适用于代理任务

Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.

</details>


### [94] [ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation](https://arxiv.org/abs/2601.12983)
*Jesus-German Ortiz-Barajas,Jonathan Tonglet,Vivek Gupta,Iryna Gurevych*

Main category: cs.CL

TL;DR: ChartAttack框架评估MLLMs生成误导性图表的风险，通过注入误导元素降低图表QA准确率约20个百分点


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)用于自动化图表生成，虽然提高了数据分析效率，但也带来了新的滥用风险，需要评估这些模型被用于大规模生成误导性图表的可能性

Method: 提出ChartAttack框架，通过向图表设计中注入误导元素来诱导对底层数据的错误解读；创建AttackViz数据集，包含带有有效误导元素标签的图表规范-QA对

Result: 在域内和跨域设置中，ChartAttack显著降低了MLLM阅读器的QA性能，准确率分别平均下降19.6和14.9个百分点；人类研究中参与者准确率平均下降20.2个百分点

Conclusion: 研究结果强调了在MLLM图表生成系统的设计、评估和部署中迫切需要加强鲁棒性和安全性考虑

Abstract: Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

</details>


### [95] [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995)
*Runxuan Liu,Xianhao Ou,Xinyan Ma,Jiyuan Wang,Jiafeng Liang,Jiaqi Li,Tao He,Zheng Chu,Rongchuan Mu,Zekun Wang,Baoxin Wang,Dayong Wu,Ming Liu,Shijin Wang,Guoping Hu,Bing Qin*

Main category: cs.CL

TL;DR: 论文提出图推理范式(GRP)和PASC-GRPO优化方法，通过结构化图表示和过程感知验证，解决传统文本推理中的计算瓶颈、奖励攻击和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理主要生成纯文本，对非结构化数据进行语义评估会造成训练计算瓶颈。尽管有RLVR优化，现有方法仍存在监督粗粒度、奖励攻击、训练成本高和泛化差等问题。

Method: 提出图推理范式(GRP)，使用带步骤级认知标签的图结构表示实现结构化符号推理。在此基础上设计PASC-GRPO方法，通过结构化评估替代语义评估，利用图结构结果奖励实现过程感知验证，并通过分层裁剪优势估计缓解奖励攻击。

Result: 实验在数学推理和代码生成任务上显示出显著改进。数据、模型和代码将后续发布。

Conclusion: GRP和PASC-GRPO通过结构化推理表示和过程感知优化，有效解决了传统文本推理方法的问题，提升了LLM的推理能力。

Abstract: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

</details>


### [96] [Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context](https://arxiv.org/abs/2601.13018)
*Ghislain Dorian Tchuente Mondjo*

Main category: cs.CL

TL;DR: 提出BiAtt-BiRNN-HateXplain模型，通过双向注意力机制和BiRNN层改进仇恨言论检测的解释性和分类性能，减少无意偏见。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型存在解释不一致问题：HateXplain基准的多任务方法中预测注意力变化较大，导致解释不一致、预测不稳定和学习困难。需要更透明、考虑数据序列特性的解释性模型。

Method: 提出BiAtt-BiRNN-HateXplain模型：结合双向注意力机制和双向循环神经网络(BiRNN)层，在多任务学习中同时处理解释性和分类任务，考虑输入数据的序列特性。

Result: 在HateXplain数据上的实验结果显示：检测性能明显提升，解释性改善，无意偏见减少。

Conclusion: 该模型通过改进解释性机制，实现了更好的仇恨言论检测性能，减少了模型偏见，相比复杂的大语言模型更透明实用。

Abstract: Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.

</details>


### [97] [Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses](https://arxiv.org/abs/2601.13024)
*Chongyuan Dai,Yaling Shen,Jinpeng Hu,Zihan Gao,Jia Li,Yishun Jiang,Yaxiong Wang,Liu Liu,Zongyuan Ge*

Main category: cs.CL

TL;DR: CEDAR是一个多模态基准测试，专注于捕捉文化引发的不同情感反应，用于评估大语言模型的文化对齐能力，特别是情感理解方面。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型文化对齐评估主要关注地理事实、社会习俗等陈述性知识，无法捕捉不同文化视角下的主观解释差异，特别是在情感处理方面存在不足。

Method: 开发了新的流程：利用LLM生成的临时标签来识别跨文化情感差异的实例，然后通过严格的人工评估获得可靠的真实标注。构建了包含10,962个实例的基准，涵盖7种语言和14种细粒度情感类别。

Result: 对17个代表性多语言模型的评估显示，语言一致性和文化对齐之间存在分离，表明当前模型在基于文化的情感理解方面仍面临重大挑战。

Conclusion: 文化对情感处理有根本性影响，当前大语言模型在文化对齐的情感理解方面存在显著不足，需要更关注主观解释差异的评估方法。

Abstract: Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

</details>


### [98] [SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification](https://arxiv.org/abs/2601.13035)
*Xu Xiaodan,Hu Xiaolin*

Main category: cs.CL

TL;DR: SASA框架通过分离注意力机制和语义感知对比学习提升知识图谱三元组分类性能，在FB15k-237和YAGO3-10数据集上分别实现5.9%和3.4%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 知识图谱常包含不可靠知识，现有三元组分类方法存在两个关键问题：1) 忽略不同KG组件间的有效语义交互；2) 采用单一二元分类训练目标导致语义表示学习不足。

Method: 提出SASA框架：1) 分离注意力机制将三元组编码为解耦的上下文表示并通过更有效的交互方式融合；2) 语义感知分层对比学习作为辅助训练目标，考虑局部和全局层面的对比学习。

Result: 在两个基准数据集上显著优于现有方法：在FB15k-237上准确率提升5.9%，在YAGO3-10上提升3.4%，达到新的最先进性能。

Conclusion: SASA通过分离注意力机制和语义感知对比学习有效解决了现有三元组分类方法的局限性，显著提升了模型的判别能力和语义学习效果。

Abstract: Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\% on FB15k-237 and +3.4\% on YAGO3-10.

</details>


### [99] [Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition](https://arxiv.org/abs/2601.13044)
*Warit Sirichotedumrong,Adisai Na-Thalang,Potsawee Manakul,Pittawat Taveekitworachai,Sittipong Sripaisarnmongkol,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: Typhoon ASR Real-time是一个115M参数的FastConformer-Transducer模型，用于低延迟泰语语音识别，通过严格的文本规范化实现与Whisper Large-v3相当的准确性，同时计算成本降低45倍。


<details>
  <summary>Details</summary>
Motivation: 当前泰语ASR领域被离线架构主导，缺乏高效的流式解决方案。虽然Whisper等大型编码器-解码器模型在离线转录上表现良好，但由于高延迟不适用于流式应用。

Method: 1) 开发115M参数的FastConformer-Transducer模型用于低延迟泰语识别；2) 设计严格的文本规范化流程，解决泰语转录中的系统歧义；3) 采用两阶段课程学习方法进行伊森方言适配；4) 发布Typhoon ASR Benchmark标准化评估数据集。

Result: 紧凑模型相比Whisper Large-v3计算成本降低45倍，同时保持相当的准确性。文本规范化解决了泰语转录中的系统歧义，包括上下文相关的数字发音和重复标记。两阶段课程学习成功适配伊森方言同时保持中央泰语性能。

Conclusion: 严格的文本规范化可以与模型缩放产生相同的影响效果。Typhoon ASR Real-time填补了泰语流式ASR的关键空白，并通过发布标准化基准数据集解决了泰语ASR的可重复性挑战。

Abstract: Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

</details>


### [100] [Profiling German Text Simplification with Interpretable Model-Fingerprints](https://arxiv.org/abs/2601.13050)
*Lars Klöser,Mika Beele,Bodo Kraft*

Main category: cs.CL

TL;DR: 本文提出了Simplification Profiler工具包，用于生成文本简化模型的多维可解释指纹，通过模型指纹识别不同配置，为开发者提供细粒度行为分析。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本简化行为进行全面、高效、可复现诊断的工具，特别是在数据稀缺的语言环境中，需要替代传统基于人工偏好相关度量的评估方法。

Method: 开发Simplification Profiler诊断工具包，生成简化文本的多维可解释指纹；通过线性分类器识别不同模型配置，验证指标对模型特性的敏感性；使用元评估方法避免大规模人工标注数据集。

Result: 完整特征集达到71.9%的分类F1分数，比简单基线提高48个百分点以上；能够区分提示策略的高层行为变化和提示工程的细粒度变化，包括few-shot示例。

Conclusion: Simplification Profiler为开发者提供了细粒度、可操作的分析工具，有助于构建更有效、真正自适应的文本简化系统，特别是在数据稀缺的多语言环境中。

Abstract: While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.

</details>


### [101] [Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs](https://arxiv.org/abs/2601.13099)
*Abdellah El Mekki,Samar M. Magdy,Houdaifa Atou,Ruwa AbuHweidi,Baraah Qawasmeh,Omer Nacar,Thikra Al-hibiri,Razan Saadie,Hamzah Alsayadi,Nadia Ghezaiel Hammouda,Alshima Alkhazimi,Aya Hamod,Al-Yas Al-Ghafri,Wesam El-Sayed,Asila Al sharji,Mohamad Ballout,Anas Belfathi,Karim Ghaddar,Serry Sibaee,Alaa Aoun,Areej Asiri,Lina Abureesh,Ahlam Bashiti,Majdal Yousef,Abdulaziz Hafiz,Yehdih Mohamed,Emira Hamedtou,Brakehe Brahim,Rahaf Alhamouri,Youssef Nafea,Aya El Aatar,Walid Al-Dhabyani,Emhemed Hamed,Sara Shatnawi,Fakhraddin Alwajih,Khalid Elkhidir,Ashwag Alasmari,Abdurrahman Gerrio,Omar Alshahri,AbdelRahim A. Elmadany,Ismail Berrada,Amir Azad Adli Alkathiri,Fadi A Zaraket,Mustafa Jarrar,Yahya Mohamed El Hadj,Hassan Alhuzali,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: Alexandria是一个大规模、社区驱动的人工翻译数据集，专门用于解决阿拉伯语方言机器翻译的挑战，覆盖13个阿拉伯国家、11个高影响力领域，包含城市级元数据和性别配置标注。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是高度双言制的语言，日常交流多使用方言而非现代标准阿拉伯语，但现有机器翻译系统对方言输入泛化能力差，限制了数百万使用者的实用性。

Method: 构建Alexandria数据集：社区驱动、人工翻译，覆盖13个阿拉伯国家、11个高影响力领域，提供城市级元数据，包含多轮对话场景并标注说话者-接收者性别配置。

Result: 数据集包含107K个样本，可作为训练资源和评估基准。通过对阿拉伯语感知LLM的自动和人工评估，揭示了当前跨阿拉伯语方言和次方言翻译的能力与持续挑战。

Conclusion: Alexandria填补了阿拉伯语方言翻译资源的空白，提供了前所未有的细粒度数据，既能训练模型又能评估性能，暴露了现有系统在方言翻译方面的显著挑战。

Abstract: Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.

</details>


### [102] [Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification](https://arxiv.org/abs/2601.13105)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

TL;DR: 本研究通过结合LoRA微调大语言模型与RAG框架，实现了英语双及物结构的自动识别，在BNC语料上取得了显著优于基准模型的效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效自动识别英语双及物结构，结合大语言模型微调与检索增强生成技术，提升语法结构识别的准确性和语义理解能力。

Method: 采用LoRA微调Qwen3-8B大语言模型，结合RAG框架，在BNC语料库标注数据上进行二元分类任务，对比分析不同方法的性能差异。

Result: LoRA微调的Qwen3-8B模型显著优于原生Qwen3-MAX模型和纯理论RAG系统，错误分析显示微调使模型从表层模式匹配转向更语义化的理解。

Conclusion: LoRA微调与RAG框架结合能有效提升英语双及物结构的自动识别能力，使模型获得更语义化的语法结构理解，为语法分析任务提供了有效方法。

Abstract: This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

</details>


### [103] [CORE-T: COherent REtrieval of Tables for Text-to-SQL](https://arxiv.org/abs/2601.13111)
*Hassan Soliman,Vivek Gupta,Dan Roth,Iryna Gurevych*

Main category: cs.CL

TL;DR: CORE-T：一个无需训练、可扩展的框架，通过LLM生成目的元数据增强表格，预计算轻量级表格兼容性缓存，改进多表文本到SQL中的表格选择性能。


<details>
  <summary>Details</summary>
Motivation: 现实文本到SQL工作流通常需要连接多个表格，准确检索相关表格集合成为端到端性能的关键瓶颈。在开放书籍设置中，查询需要在大规模异构表格集合上回答，缺乏数据库标识符等清晰范围信号。

Method: CORE-T框架：1）使用LLM生成表格目的元数据增强表格；2）预计算轻量级表格兼容性缓存；3）推理时：密集检索返回top-K候选，单个LLM调用选择可连接子集，简单加法调整步骤恢复强兼容表格。

Result: 在Bird、Spider和MMQA数据集上，CORE-T将表格选择F1提升高达22.7分，同时检索表格减少42%，多表执行准确率在Bird上提升5.0分，在MMQA上提升6.9分，比LLM密集型基线少用4-5倍token。

Conclusion: CORE-T通过结合密集检索的召回优势和LLM驱动的表格选择，在无需训练的情况下显著提升多表文本到SQL中的表格选择性能，减少推理开销并提高准确性。

Abstract: Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

</details>


### [104] [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115)
*Fengran Mo,Yifan Gao,Sha Li,Hansi Zeng,Xin Liu,Zhaoxuan Tan,Xian Li,Jianshu Chen,Dakuo Wang,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种基于强化学习的对话智能体，通过跨轮次交替搜索与推理来适应动态变化的用户意图，在四个对话基准测试中超越了现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统通常采用静态的重写-检索-生成流水线，将不同流程分开优化，忽视了混合主动行为的同步优化。虽然深度搜索代理在单轮场景中展示了联合优化检索与生成的有效性，但缺乏处理多轮交互的能力。

Method: 提出了一种对话智能体，通过强化学习训练，在对话轮次间交替进行搜索与推理，学习探索性和适应性行为，使用针对演化用户目标定制的奖励函数。

Result: 在四个广泛使用的对话基准测试上的实验结果表明，该方法超越了多个现有强基线，证明了其有效性。

Conclusion: 通过强化学习训练跨轮次交替搜索与推理的对话智能体，能够更好地适应动态变化的用户意图，在多轮对话场景中取得优于现有方法的性能。

Abstract: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

</details>


### [105] [Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137)
*Yuan Gao,Zhigang Liu,Xinyu Yao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 提出对抗对齐框架VC-LLM，通过持续预训练、指令微调和对抗训练增强大语言模型在敏感领域的价值一致性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在敏感领域（种族、社会、政治）存在偏见和价值不一致问题，需要提升模型的价值对齐能力

Method: 采用对抗对齐框架：1) 持续预训练 2) 指令微调 3) 对抗训练（攻击者生成争议查询，行动者生成价值一致响应，评论者过滤确保质量）

Result: 训练出VC-LLM模型，构建中英双语评估数据集，实验显示VC-LLM在中英文测试中均优于现有主流模型

Conclusion: 对抗对齐框架能有效提升大语言模型在敏感领域的价值一致性，VC-LLM在价值对齐方面表现优异

Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

</details>


### [106] [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155)
*Zimeng Wu,Donghao Wang,Chaozhe Jin,Jiaxin Chen,Yunhong Wang*

Main category: cs.CL

TL;DR: SPTS是一个无需训练的长上下文LLM推理加速框架，通过部分注意力探测和低秩变换探测选择性跳过token，结合多阶段延迟剪枝策略，在保持模型性能的同时实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理虽然增强了LLM的推理能力，但带来了巨大的计算开销。现有的token导向方法（如剪枝和跳过）存在加速潜力有限、代理信号过时和冗余干扰等问题，导致速度-准确率权衡不理想。

Method: 提出SPTS框架：1) Partial Attention Probing (PAP) - 通过部分前向注意力计算选择信息丰富的token；2) Low-rank Transformation Probing (LTP) - 构建低秩代理网络预测token变换；3) Multi-Stage Delayed Pruning (MSDP) - 重新分配跳过预算并在各层逐步剪枝冗余token。

Result: 实验表明该方法有效，在保持最先进模型性能的同时，预填充阶段加速达2.46倍，端到端生成加速达2.29倍。

Conclusion: SPTS是一个无需训练的高效长上下文LLM推理框架，通过创新的token跳过策略实现了优异的加速效果，同时保持了模型性能。

Abstract: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

</details>


### [107] [Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages](https://arxiv.org/abs/2601.13178)
*Joseph Gatto,Parker Seegmiller,Timothy Burdick,Philip Resnik,Roshnik Rahat,Sarah DeLozier,Sarah M. Preum*

Main category: cs.CL

TL;DR: 该论文提出了首个用于研究异步门诊门户消息中医疗分诊的大规模公共数据集PMR-Bench，通过将患者消息分诊建模为成对推理问题，训练LLM进行医疗紧急度评估，并开发了两种模型在低资源设置下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 医疗分诊是根据医疗需求分配资源和优先处理患者的任务，但在异步门诊门户消息场景中缺乏大规模公共数据集进行研究。现有方法难以在真实医疗分诊场景中有效评估患者消息的紧急程度。

Method: 1) 创建PMR-Bench数据集，包含1569条独特消息和2000+高质量测试对，结合非结构化患者消息和真实电子健康记录数据；2) 将患者消息分诊建模为成对推理问题，采用锦标赛式重新排序方法；3) 开发自动数据标注策略为LLM提供领域指导；4) 训练两种模型：基于Bradley-Terry目标的UrgentReward和基于下一个token预测目标的UrgentSFT。

Result: UrgentSFT在PMR-Bench上表现最佳，UrgentReward在低资源设置中显示独特优势。UrgentSFT-8B和UrgentReward-8B相比现成的8B模型，在收件箱排序指标上分别提升15和16个百分点。

Conclusion: 该研究为医疗分诊任务提供了首个大规模公共数据集和有效的模型方法，通过成对推理框架显著提升了LLM在患者消息紧急度评估上的性能，为实际医疗分诊场景提供了实用解决方案。

Abstract: Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

</details>


### [108] [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183)
*Sergio Servantez,Sarah B. Lawsky,Rajiv Jain,Daniel W. Linna,Kristian Hammond*

Main category: cs.CL

TL;DR: OpenExempt是一个用于法律推理诊断评估的框架和基准，通过专家构建的美国破产法法规符号表示动态生成自然语言推理任务，能够精细控制任务复杂度并隔离测试特定推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准存在局限性：静态问答对只能提供性能快照，将复杂行为压缩为单一准确率指标；在法律等复杂规则领域，现有基准构建成本高且难以隔离特定失败模式。

Method: OpenExempt框架使用专家构建的美国破产法法规符号表示，动态生成大量自然语言推理任务及其机器可计算解决方案；构建OpenExempt基准，包含9,765个样本，分布在九个评估套件中，专门设计用于精细探测模型能力。

Result: 对13个不同语言模型的实验显示，在较长推理路径和存在混淆性陈述的情况下，模型性能会出现急剧下降；基准能够揭示传统静态基准无法发现的性能悬崖。

Conclusion: OpenExempt框架和基准为理解和改进下一代推理系统提供了有力工具，通过动态生成任务和精细控制复杂度，能够更有效地诊断法律推理能力。

Abstract: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

</details>


### [109] [Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision](https://arxiv.org/abs/2601.13217)
*Bingsen Chen,Boyan Li,Ping Nie,Yuyu Zhang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: 本文提出Mr Dre评估套件，首次将多轮报告修订作为深度研究代理的新评估维度，发现现有代理在反馈修订中存在内容倒退和编辑保持问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理基准将报告生成视为单次写作任务，这与人类研究者通过自我反思或同行反馈迭代起草和修订报告的方式存在根本差异。深度研究代理能否可靠地根据用户反馈修订报告尚未被探索。

Method: 引入Mr Dre评估套件，包括：(1) 统一的长篇报告评估协议，涵盖全面性、事实性和呈现质量；(2) 人工验证的反馈模拟管道，用于多轮修订评估。分析了五个不同的深度研究代理。

Result: 分析发现关键局限：虽然代理能处理大部分用户反馈，但也会在16-27%的先前覆盖内容和引用质量上出现倒退。经过多轮修订，即使表现最佳的代理仍有显著改进空间，因为它们会破坏反馈范围之外的内容，且无法保持早期编辑。

Conclusion: 深度研究代理在多轮报告修订方面存在系统性挑战，这些问题无法通过推理时修复（如提示工程或专门的报告修订子代理）轻易解决，表明需要更根本的改进方法。

Abstract: Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

</details>


### [110] [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228)
*Tianqi Du,Lizhe Fang,Weijie Yang,Chenheng Zhang,Zeming Wei,Yifei Wang,Yisen Wang*

Main category: cs.CL

TL;DR: A3框架将自回归模型扩展为任意顺序、任意子集的预测，结合了自回归的深度建模和扩散模型的灵活性，在多项任务上优于扩散模型。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持任意顺序生成和双向条件化，但单步依赖限制了建模深度，导致样本质量和稳定性不如自回归模型。需要结合两者的优势。

Method: 提出A3框架，将自回归建模重新表述为结构化多组预测过程，通过双流注意力架构和渐进适应策略，将预训练自回归模型转换为任意顺序预测。

Result: 在问答、常识推理和故事填充等任务上，A3优于扩散模型，同时保持了灵活的生成能力。

Conclusion: A3提供了一个统一框架，实现了灵活、高效且新颖的语言建模范式，结合了自回归的深度建模和扩散模型的灵活性优势。

Abstract: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.

</details>


### [111] [Aligning Agentic World Models via Knowledgeable Experience Learning](https://arxiv.org/abs/2601.13247)
*Baochang Ren,Yunzhi Yao,Rui Sun,Shuofei Qiao,Ningyu Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: WorldMind框架通过构建符号化世界知识库解决LLMs物理幻觉问题，利用环境反馈统一过程经验和目标经验，在EB-ALFRED和EB-Habitat上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型存在模态鸿沟：拥有丰富语义知识但缺乏对物理世界不变法则的程序性理解，导致产生物理上不可执行的计划（物理幻觉）。现有对齐方法主要依赖资源密集的训练或微调，难以适应物理动态的开放可变性。

Method: 引入WorldMind框架，通过综合环境反馈自主构建符号化世界知识库。统一过程经验（通过预测误差强制执行物理可行性）和目标经验（通过成功轨迹指导任务最优性）。

Result: 在EB-ALFRED和EB-Habitat上的实验表明，WorldMind相比基线方法取得了优越性能，并具有显著的跨模型和跨环境可迁移性。

Conclusion: WorldMind通过非参数化的符号知识库方法有效解决了LLMs的物理幻觉问题，提供了一种更灵活、可迁移的物理世界对齐方案。

Abstract: Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.

</details>


### [112] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出大规模语义聚类系统，解决嵌入模型无法区分同义词与反义词的盲点，通过三路语义关系判别器和软到硬聚类算法生成290万高精度语义簇。


<details>
  <summary>Details</summary>
Motivation: 神经嵌入模型存在显著盲点：无法可靠区分同义词和反义词，导致提高相似度阈值时仍会将反义词归为一类。现有同义词数据库在形态丰富和低资源语言中稀疏，需要高精度语义聚类系统。

Method: 1) 构建84.3万概念对数据集，涵盖同义、反义和共下位关系，使用Gemini 2.5-Flash LLM增强和人工词典验证；2) 提出三路语义关系判别器，实现90%宏F1分数；3) 设计新颖的软到硬聚类算法，采用拓扑感知的两阶段扩展-剪枝过程和拓扑投票，防止语义漂移和错误传递链。

Result: 处理1500万词汇项，评估5.2亿潜在关系，生成290万高精度语义簇。系统能精确分配每个术语到单一语义连贯簇，解决多义词问题，为形态丰富和低资源语言提供高质量语义搜索和检索增强生成资源。

Conclusion: 该系统有效解决神经嵌入的同义-反义区分问题，通过专门的关系判别器和聚类算法实现高精度语义聚类，特别适用于现有同义词数据库稀疏的语言，为语义搜索和RAG应用提供强大资源。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [113] [A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus](https://arxiv.org/abs/2601.13253)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

TL;DR: 提出了一种混合方法，用于生成低资源语言的大规模语义关系数据集，并以土耳其语为例构建了包含84.3万对语义关系的语料库，成本仅65美元。


<details>
  <summary>Details</summary>
Motivation: 解决土耳其语等低资源语言在自然语言处理中语义关系数据稀缺的问题，现有资源规模有限且成本高昂。

Method: 采用三阶段混合方法：1) 使用FastText词向量和凝聚聚类识别语义簇；2) 利用Gemini 2.5-Flash进行自动语义关系分类；3) 整合经过筛选的词典资源。

Result: 构建了包含84.3万个土耳其语语义对的数据集，覆盖同义词、反义词和共下位词三种关系类型，规模是现有资源的10倍。在下游任务中，嵌入模型达到90%的top-1检索准确率，分类模型获得90%的F1-macro分数。

Conclusion: 该方法以极低成本有效解决了土耳其语NLP的数据稀缺问题，展示了可扩展性，并适用于其他低资源语言。数据集和模型已公开。

Abstract: We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

</details>


### [114] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://arxiv.org/abs/2601.13260)
*Sawsan Alqahtani,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

TL;DR: 论文主张将分词视为核心建模决策而非预处理步骤，提出上下文感知框架，通过分词器与模型协同设计来改进语言技术的公平性、效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前分词方法（如BPE）虽然可扩展，但存在与语言结构不对齐、放大偏见、在不同语言和领域浪费容量等问题。分词作为大语言模型的基础组件，却缺乏理论研究和一致设计。

Method: 提出上下文感知框架，将分词器与模型协同设计，考虑语言、领域和部署因素。强调标准化评估和透明报告，使分词选择可问责和可比较。

Result: 论文提出了理论框架和方法论，但未报告具体实验结果。主张通过将分词视为核心设计问题而非技术后处理，可以产生更公平、高效和适应性强的语言技术。

Conclusion: 分词应被视为核心建模决策，需要上下文感知的协同设计框架。标准化评估和透明报告对于实现公平、高效和适应性强的语言技术至关重要。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [115] [Unlearning in LLMs: Methods, Evaluation, and Open Challenges](https://arxiv.org/abs/2601.13264)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: 这篇论文是关于大语言模型机器遗忘技术的综述，系统梳理了现有的遗忘方法、评估体系，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理任务中取得了显著成功，但其广泛部署引发了隐私、版权、安全和偏见等紧迫问题。机器遗忘作为一种有前景的范式，可以在不完全重新训练的情况下选择性地从训练模型中移除知识或数据。

Method: 论文对LLM遗忘方法进行了结构化概述，将现有方法分为数据中心化、参数中心化、架构中心化、混合策略和其他策略等类别。同时回顾了评估生态系统，包括用于衡量遗忘效果、知识保留和鲁棒性的基准、指标和数据集。

Result: 论文系统性地梳理了当前大语言模型机器遗忘领域的研究进展，建立了完整的分类框架和评估体系，为后续研究提供了清晰的路线图。

Conclusion: 论文总结了当前进展并突出了开放方向，旨在为开发可靠和负责任的大语言模型遗忘技术提供路线图。指出了可扩展效率、形式化保证、跨语言和多模态遗忘、对抗性重新学习鲁棒性等关键挑战和开放问题。

Abstract: Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.

</details>


### [116] [A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification](https://arxiv.org/abs/2601.13288)
*Gonzalo Ariel Meyoyan,Luciano Del Corro*

Main category: cs.CL

TL;DR: 提出一种在LLM推理过程中复用隐藏状态进行轻量级分类的方法，避免使用独立的安全模型，降低延迟和内存消耗


<details>
  <summary>Details</summary>
Motivation: 当前生产级LLM系统通常使用独立模型进行安全和分类任务，这会增加延迟、显存占用和运维复杂度。作者希望复用LLM推理过程中已经计算得到的隐藏状态，避免额外开销。

Method: 提出基于LLM隐藏状态的轻量级探针方法：1）将分类任务定义为在完整token-layer隐藏状态张量上的表示选择；2）引入两阶段聚合器：先总结每层内的token，再聚合跨层总结；3）实现三种探针变体：直接池化、10万参数评分注意力门、最多3500万参数的下采样多头自注意力探针。

Result: 在安全和情感基准测试中，该方法优于仅使用logit的复用方法（如MULI），与更大的任务特定基线模型竞争性相当，同时保持接近推理延迟，避免了独立防护模型管道的显存和延迟成本。

Conclusion: 通过复用LLM推理过程中的隐藏状态训练轻量级探针，可以在不增加显著延迟和内存开销的情况下，有效完成安全和分类任务，简化生产系统架构。

Abstract: Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.

</details>


### [117] [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300)
*Yow-Fu Liou,Yu-Chien Tang,Yu-Hsiang Liu,An-Zi Yen*

Main category: cs.CL

TL;DR: 本文提出OI-Bench基准测试，通过在多选题界面注入误导性指令选项，系统评估LLM对指令干扰的鲁棒性，发现模型存在显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明LLM决策会受到社交线索、框架效应和指令等导向信号的影响，但缺乏系统评估LLM在选择题界面中对指令干扰鲁棒性的基准测试方法。

Method: 提出选项注入方法，在MCQA界面中增加包含误导性指令的额外选项；构建OI-Bench基准，包含3000个涵盖知识、推理和常识任务的问题，涉及16种指令类型；评估12个LLM的攻击成功率、行为响应，并研究从推理时提示到训练后对齐的缓解策略。

Result: 实验结果显示模型存在显著漏洞，不同模型间的鲁棒性存在异质性；OI-Bench能够支持对LLM在基于选择的界面中对指令干扰鲁棒性的系统评估。

Conclusion: 选项注入方法有效揭示了LLM对指令干扰的脆弱性，OI-Bench为系统评估LLM鲁棒性提供了标准化工具，有助于理解模型局限性并开发缓解策略。

Abstract: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

</details>


### [118] [Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology](https://arxiv.org/abs/2601.13319)
*Peter Sullivan,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 论文分析了阿拉伯语方言语音数据的异质性，提出了Arab Voices标准化框架来统一31个数据集，并为现代阿拉伯语方言ASR建立了基准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音数据在领域覆盖、方言标注实践和录音条件上存在巨大差异，这导致跨数据集比较和模型评估变得复杂。需要标准化表征来减少碎片化并支持可重复评估。

Method: 1) 对广泛使用的阿拉伯语方言语料库进行语言"方言性"的计算分析；2) 使用音频质量的客观代理指标；3) 引入Arab Voices框架，统一访问31个数据集，涵盖14种方言，提供协调的元数据和评估工具；4) 对一系列最新ASR系统进行基准测试。

Result: 发现数据集在声学条件和方言信号强度及一致性方面存在显著异质性。Arab Voices框架成功整合了多个数据集，并为现代阿拉伯语方言ASR建立了强大的基准性能。

Conclusion: 阿拉伯语方言语音数据需要超越粗粒度标签的标准化表征。Arab Voices框架减少了碎片化，支持可重复评估，并为该领域建立了重要基准。

Abstract: Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

</details>


### [119] [Reducing Tokenization Premiums for Low-Resource Languages](https://arxiv.org/abs/2601.13328)
*Geoffrey Churchill,Steven Skiena*

Main category: cs.CL

TL;DR: 分析十种流行语言模型的tokenizer设计，提出通过后处理增加词汇表来减少低资源语言tokenization溢价的方法


<details>
  <summary>Details</summary>
Motivation: 低资源语言相比英语存在显著的tokenization溢价（需要更多token编码相同句子），导致API和能源成本增加、有效上下文窗口减少

Method: 分析十种流行LM的tokenizer设计，提出后处理机制：向预训练模型词汇表中添加多字符合并为单token的条目

Result: 在12种低资源语言上应用该方法，发现原始输入和压缩输入在Llama 3.2 1B模型中具有相似的最后一层隐藏状态

Conclusion: 提出的后处理方法能有效减少低资源语言的tokenization溢价，保持模型表示相似性，为降低成本和提升效率提供可行方案

Abstract: Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.

</details>


### [120] [RegCheck: A tool for automating comparisons between study registrations and papers](https://arxiv.org/abs/2601.13330)
*Jamie Cummins,Beth Clarke,Ian Hussey,Malte Elson*

Main category: cs.CL

TL;DR: RegCheck是一个基于LLM的模块化工具，帮助研究人员、审稿人和编辑比较研究注册与对应论文，保持人类专家判断在循环中，生成可共享报告，促进科学透明度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 尽管研究注册对科学透明度和严谨性有益，但手动检查注册与论文之间的差异是劳动和时间密集型的，需要跨格式仔细阅读和跨领域专业知识。AI的发展为促进这一活动提供了新的可能性。

Method: RegCheck是一个模块化的LLM辅助工具，通过(i)让用户决定需要比较哪些特征，(ii)向用户展示每个特征最相关的文本，促进（而非替代）人类差异判断。工具生成带有唯一RegCheck ID的可共享报告。

Result: RegCheck被设计为跨科学领域、注册和出版格式的适应性工具，作为可扩展的基础设施支持可重复科学，通过示例用例展示了其潜力。

Conclusion: RegCheck通过保持人类专家判断在循环中，同时利用AI能力，为研究人员、审稿人和编辑提供了一个有效的工具，促进研究注册与论文的比较，增强科学透明度和严谨性。

Abstract: Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.

</details>


### [121] [AfroScope: A Framework for Studying the Linguistic Landscape of Africa](https://arxiv.org/abs/2601.13346)
*Sang Yun Kwon,AbdelRahim Elmadany,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: AfroScope是一个统一的非洲语言识别框架，包含覆盖713种非洲语言的数据集和模型套件，通过分层分类方法提高对相似语言的区分能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别方法对非洲语言支持有限，覆盖语言数量不足，且难以区分密切相关的语言变体，影响了下游NLP应用的可靠性。

Method: 提出AfroScope框架，包括AfroScope-Data数据集和AfroScope-Models模型套件；针对29种高度相似语言，使用Mirror-Serengeti嵌入模型进行分层分类。

Result: 在高度相似语言子集上，分层分类方法比最佳基础模型提高了4.55的宏平均F1分数；分析了跨语言迁移和领域效应。

Conclusion: AfroScope为大规模测量非洲数字文本中的语言景观提供了技术支持，公开发布了数据集和模型，推动非洲语言识别作为使能技术发展。

Abstract: Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

</details>


### [122] [LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction](https://arxiv.org/abs/2601.13352)
*Yuxing Lu,J. Ben Tamo,Weichen Zhao,Nan Sun,Yishan Zhong,Wenqi Shi,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: LLM-as-RNN：将冻结LLM转变为循环预测器的推理框架，通过自然语言记忆实现在线学习，无需参数更新


<details>
  <summary>Details</summary>
Motivation: 标准LLM推理使用不可变的上下文历史，一旦在生成步骤t出错，模型缺乏可更新的记忆机制来改进步骤t+1的预测。需要一种方法让LLM在推理时能够从错误中学习并改进后续预测。

Method: 提出LLM-as-RNN框架，将冻结LLM转变为循环预测器，其隐藏状态表示为自然语言记忆（结构化系统提示摘要）。该状态通过反馈驱动的文本重写在每个时间步更新，实现无需参数更新的学习。

Result: 在医疗、气象和金融三个序列基准测试中，使用Llama、Gemma和GPT模型系列，LLM-as-RNN显著优于零样本、完整历史和MemPrompt基线，平均预测准确率提高6.5%，同时产生可解释的人类可读学习轨迹。

Conclusion: LLM-as-RNN通过将LLM转变为具有自然语言记忆的循环预测器，实现了推理时的在线学习，能够纠正错误并保留任务相关模式，为LLM推理提供了新的记忆和学习机制。

Abstract: Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

</details>


### [123] [Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection](https://arxiv.org/abs/2601.13359)
*Asen Dotsinski,Panagiotis Eustratiadis*

Main category: cs.CL

TL;DR: 提出了一种名为"sockpuppetting"的简单越狱方法，通过在模型输出开头插入接受序列（如"Sure, here is how to..."）来绕过安全防护，无需优化且代码简单。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型能力增强，保护它们免受恶意提示攻击变得愈发重要。现有自动越狱方法如GCG需要大量计算资源和专业知识，需要更简单有效的攻击方法。

Method: 提出"sockpuppetting"方法：在模型输出开头插入接受序列（如"Sure, here is how to..."），然后让模型完成响应。还探索了混合方法，在助手消息块内优化对抗后缀而非用户提示。

Result: sockpuppetting在Qwen3-8B上比GCG攻击成功率提高80%（逐提示比较）。混合方法在Llama-3.1-8B上比GCG攻击成功率提高64%（提示无关设置）。

Conclusion: sockpuppetting是一种有效的低成本攻击方法，可供非专业攻击者使用，凸显了开源模型需要防御输出前缀注入攻击。

Abstract: As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.

</details>


### [124] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

TL;DR: 提出一种新方法，通过跨步骤注意力分析语义相关性，并引入隐藏置信度机制来保留历史置信信息，以更准确评估大语言模型推理过程中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务上表现优异，但难以评估答案的不确定性，可能导致误导性幻觉。现有方法分析推理序列时忽略时间维度上的置信度传播，导致整体置信度被高估。

Method: 提出跨步骤注意力机制分析语义相关性，引入隐藏置信度机制保留历史置信信息，结合逐步置信度生成更准确的整体置信度估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上评估，使用主流开源大语言模型，在负对数似然和期望校准误差指标上优于现有方法，实现预测质量和校准的更好平衡。

Conclusion: 提出的方法能更准确评估大语言模型推理过程中的不确定性，通过考虑时间维度上的置信度传播，有效防止整体置信度被高估，提高可靠性。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [125] [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387)
*Zhenjiang Mao,Anirudhh Venkat,Artem Bisliouk,Akshat Kothiyal,Sindhura Kumbakonam Subramanian,Saithej Singhu,Ivan Ruchkin*

Main category: cs.CL

TL;DR: 提出使用信号时序逻辑（STL）分析LLM推理过程中的置信度演化，通过STL模式区分正确与错误推理，并开发基于超网络的置信度估计方法


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法将整个推理过程简化为单一标量分数，忽略了置信度在生成过程中的演化，导致对表面因素（如回答长度、冗长程度）敏感，难以区分正确推理和自信陈述的错误

Method: 使用信号时序逻辑（STL）表征逐步置信度信号，通过判别性STL挖掘过程发现区分正确与错误回答置信度信号的时序公式，并开发基于超网络参数化的STL块置信度估计方法

Result: STL模式在不同任务间具有泛化性，数值参数对具体问题敏感；在多个推理任务上的实验表明，该方法比基线方法具有更好的校准性

Conclusion: 通过分析LLM推理过程中的置信度演化模式，能够开发更准确的置信度估计方法，STL为理解复杂推理过程中的置信度动态提供了有效框架

Abstract: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.

</details>


### [126] [Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction](https://arxiv.org/abs/2601.13388)
*Sasha Ronaghi,Prerit Choudhary,David H Rehkopf,Bryant Lin*

Main category: cs.CL

TL;DR: 利用大型语言模型从糖尿病患者生活故事中提取结构化社会健康决定因素，并评估其对糖尿病控制的预测价值


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素在2型糖尿病管理中至关重要，但电子健康记录和风险预测模型通常缺乏这些信息。传统的结构化筛查工具无法捕捉患者经历的复杂性，需要更灵活的方法来获取这些关键数据。

Method: 收集65名65岁以上2型糖尿病患者的非结构化访谈，使用检索增强生成的大型语言模型分析叙事，生成临床可解释的定性总结和结构化定量SDOH评分。将结构化SDOH评分与传统实验室生物标志物结合，输入线性和树基机器学习模型进行风险预测。

Result: 大型语言模型能够从访谈文本中预测糖尿病控制水平（低、中、高），准确率达到60%。结构化SDOH评分可以与传统生物标志物结合，应用于常规风险预测工作流程。

Conclusion: 大型语言模型能够将非结构化SDOH相关数据转化为结构化见解，为增强临床风险模型和决策制定提供了可扩展的方法，弥补了传统医疗记录中社会健康决定因素信息的缺失。

Abstract: Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

</details>


### [127] [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392)
*Shlok Shelat,Jay Raval,Souvik Roy,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs在DFA构造任务中表现良好于熟悉问题，但在未见问题上准确率大幅下降，暴露了形式推理能力的根本缺陷


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在形式语言任务中的表现是否真正反映了符号推理能力，还是仅仅是对熟悉构造的模式匹配

Method: 引入DFA构造基准测试，包含事实知识问题、已见构造问题、手工设计的未见问题（多重交互约束）和通过Arden定理系统生成的未见问题；评估多种提示策略（直接、思维链、思维树）和三阶段提示协议

Result: 模型在事实问题上准确率完美，在已见任务上84-90%，但在未见问题上准确率下降30-64%；错误源于对语言约束的系统性误解、Kleene星号语义的错误处理以及全局一致性的失败；提示协议能修正浅层错误但无法可靠解决全局不一致或结构缺陷

Conclusion: LLMs在生成语法上合理的DFA与语义正确的形式推理能力之间存在根本差距，错误在所有提示策略中持续存在，表明当前LLMs的形式推理能力有限

Abstract: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.

</details>


### [128] [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433)
*Priyanka Mary Mammen,Emil Joswin,Shankar Venkitachalam*

Main category: cs.CL

TL;DR: 语言模型在推理任务中会受到建议和认可的影响，但认可来源的可信度影响尚未充分研究。研究发现模型对专家认可存在系统性偏见，专家认可会降低准确性并增加错误答案的置信度。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型在推理任务中的表现会受到建议、提示和认可的影响，但认可来源可信度的影响尚未得到充分探索。本研究旨在探究语言模型是否基于认可提供者的感知专业水平表现出系统性偏见。

Method: 在数学、法律和医学推理4个数据集上评估11个模型，使用代表四个专业水平的人物角色。通过不同专业水平的认可来源测试模型对误导性认可的反应。

Result: 模型随着来源专业水平的提高，对错误/误导性认可的敏感性增加。高权威来源不仅导致准确性下降，还增加了对错误答案的置信度。这种权威偏见在模型中具有机制性编码。

Conclusion: 语言模型存在权威偏见，但可以通过引导模型远离这种偏见来改善性能，即使在专家给出误导性认可的情况下也能提高表现。

Abstract: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.

</details>


### [129] [MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization](https://arxiv.org/abs/2601.13437)
*Adriana-Valentina Costache,Daria-Nicoleta Dragomir,Silviu-Florin Gheorghe,Eduard Poesina,Paul Irofti,Radu Tudor Ionescu*

Main category: cs.CL

TL;DR: 提出了首个多语言开放集学习与发现（MOSLD）文本分类基准，包含12种语言的96万数据样本，并提出了一个集成多阶段的新框架来持续发现和学习新类别。


<details>
  <summary>Details</summary>
Motivation: 开放集学习与发现（OSLD）是一个具有挑战性的机器学习任务，其中测试时可能出现来自新（未知）类别的样本。虽然零样本学习在文本分类中已被广泛研究，但开放集学习与发现在文本领域是一个相对较新的设置，需要建立一个基准来推动该领域的研究。

Method: 1) 构建首个多语言开放集学习与发现基准，通过重新排列现有数据集和收集新闻领域新数据样本，创建了包含12种语言96万数据样本的基准；2) 提出了一个新颖的OSLD框架，集成多个阶段来持续发现和学习新类别。

Result: 创建了MOSLD基准并评估了包括作者提出的模型在内的多个语言模型，获得了可作为未来工作参考的结果。基准已开源发布在GitHub上。

Conclusion: 该工作填补了文本领域开放集学习与发现基准的空白，为未来研究提供了重要的评估平台和参考结果，推动了多语言开放集学习的发展。

Abstract: Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.

</details>


### [130] [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453)
*Aditya Thole,Anmol Agrawal,Arnav Ramamoorthy,Dhruv Kumar*

Main category: cs.CL

TL;DR: PSA是一个自主代理，使用Manim动画生成长达6分钟的物理解释视频，并通过包含15个定量参数和VLM反馈的评估流程来改进视频质量，在32个视频上测试发现存在视觉布局不一致和解释错误等问题。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在文本物理问题上表现良好，但生成高质量视觉解释的能力尚未充分探索。视觉推理能显著提升概念理解，特别是在数值物理问题中。

Method: 引入PhysicsSolutionAgent（PSA），使用Manim动画生成长达6分钟的物理解释视频。设计评估流程，包含15个定量参数的自动检查和视觉语言模型的反馈，以迭代改进视频质量。

Result: 在32个数值和理论物理问题视频上评估，PSA使用GPT-5-mini实现100%视频完成率，平均自动评分3.8/5。但定性分析和人工检查发现存在视觉布局不一致、视觉内容解释错误等问题。

Conclusion: 研究揭示了可靠Manim代码生成的关键限制，突显了多模态推理和评估在数值物理问题视觉解释中的挑战，强调未来多模态教育系统需要改进视觉理解、验证和评估框架。

Abstract: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

</details>


### [131] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

TL;DR: Anonpsy：基于图引导语义重写的精神病学叙事去标识化框架，通过语义图编码临床结构，在修改身份信息的同时保留诊断关键内容


<details>
  <summary>Details</summary>
Motivation: 现有去标识化方法（如PHI掩码和LLM重写）在文本层面操作，对保留或修改哪些语义元素控制有限。精神病学叙事不仅包含显式标识符，还通过嵌入临床结构中的独特生活事件编码患者身份，需要更精细的去标识化方法。

Method: 1) 将叙事转换为编码临床实体、时间锚点和类型关系的语义图；2) 应用图约束扰动，修改身份上下文同时保留临床关键结构；3) 通过图条件LLM生成重新生成文本

Result: 在90个临床医生撰写的精神病学案例叙事上评估，Anonpsy在保持诊断保真度的同时，在专家、语义和GPT-5评估中实现一致的低重识别风险。相比强LLM重写基线，Anonpsy产生显著更低的语义相似性和可识别性

Conclusion: 显式结构表示与约束生成相结合，为精神病学叙事的去标识化提供了有效方法，能够在保护隐私的同时保持临床实用性

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [132] [When Wording Steers the Evaluation: Framing Bias in LLM judges](https://arxiv.org/abs/2601.13537)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Minwoo Lee,Kyomin Jung*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在评估任务中存在框架偏差，即提示的措辞方式会显著影响模型判断，这暴露了当前LLM评估系统的结构性问题


<details>
  <summary>Details</summary>
Motivation: 尽管已知LLM对提示措辞敏感，但框架偏差对LLM评估任务的影响尚未充分研究。心理学中的框架效应启发研究者系统探究提示框架如何影响模型在高风险评估任务中的判断稳定性

Method: 设计对称提示（谓词肯定和谓词否定结构），在四个高风险评估任务中测试14个LLM法官模型，分析框架偏差对模型输出的影响

Result: 框架偏差导致模型输出显著差异，不同模型家族对框架表现出明显倾向性（同意或拒绝），表明框架偏差是当前LLM评估系统的结构性特征

Conclusion: 框架偏差是LLM评估系统的固有缺陷，需要开发框架感知的评估协议来确保判断的稳定性和公正性

Abstract: Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.

</details>


### [133] [HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations](https://arxiv.org/abs/2601.13547)
*Yujia Hu,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: HateXScore：一个用于评估仇恨言论检测模型解释质量的四组件指标套件，可揭示标准指标无法发现的解释性失败和标注不一致问题


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测评估框架很少评估文本为何被判定为仇恨言论，缺乏对模型解释质量的系统性评估方法

Method: 提出HateXScore四组件指标套件：1)结论明确性；2)引用文本的忠实性和因果基础；3)受保护群体识别（可配置）；4)各组件间的逻辑一致性

Result: 在六个不同的仇恨言论数据集上评估，HateXScore能够揭示标准指标（如准确率、F1分数）无法发现的解释性失败和标注不一致问题，人类评估显示与HateXScore高度一致

Conclusion: HateXScore可作为诊断性补充工具，为可信和透明的内容审核提供实用评估方法，增强模型解释的可信度

Abstract: Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.
  \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

</details>


### [134] [Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews](https://arxiv.org/abs/2601.13575)
*Thanh-Lam T. Nguyen,Ngoc-Quang Le,Quoc-Trung Phu,Thi-Phuong Le,Ngoc-Huyen Pham,Phuong-Nguyen Nguyen,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: SUDO是一个用于隐式比较观点挖掘的新数据集，包含4,150个标注的评论对，支持在没有显式比较线索的情况下推断用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有比较观点挖掘研究主要关注显式比较表达，但在真实评论中不常见。隐式比较（用户在不同评论中表达偏好）尚未得到充分探索。

Method: 提出了SUDO数据集，包含4,150个标注评论对（15,191个句子），采用双层结构捕捉方面级提及和评论级偏好。使用两种基线架构：传统机器学习方法和基于语言模型的方法。

Result: 基于语言模型的基线优于传统机器学习方法，但整体性能仍然中等，表明任务具有固有难度，SUDO成为未来研究的挑战性基准。

Conclusion: SUDO是一个具有挑战性和价值的隐式比较观点挖掘基准数据集，揭示了该任务的固有难度，为未来研究提供了重要资源。

Abstract: Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.

</details>


### [135] [TREX: Tokenizer Regression for Optimal Data Mixture](https://arxiv.org/abs/2601.13588)
*Inho Won,Hangyeol Yoo,Minkyung Cho,Jungyeul Park,Hoyun Song,KyungTae Lim*

Main category: cs.CL

TL;DR: TREX框架通过回归模型预测最优的多语言分词器训练数据混合比例，避免传统启发式或大规模搜索的高成本，提升分词器压缩效率达12%


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型的分词器需要优化语言数据混合比例，但现有方法依赖启发式规则或成本高昂的大规模搜索，缺乏高效确定最优混合比例的方法

Method: 提出TREX框架：1）在小规模代理分词器上训练随机数据混合；2）收集压缩统计信息；3）学习从数据混合到压缩性能的预测模型；4）在大规模分词器训练前进行可扩展的混合比例搜索

Result: TREX预测的混合比例训练的分词器，在分布内和分布外压缩效率上比LLaMA3和均匀分布方法提升达12%，展现出强可扩展性、鲁棒性和实际有效性

Conclusion: TREX框架通过回归建模有效解决了多语言分词器设计中准确性与成本的权衡问题，为高效确定最优数据混合比例提供了系统化解决方案

Abstract: Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.

</details>


### [136] [Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions](https://arxiv.org/abs/2601.13590)
*Fan Huang,Haewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 评估大型语言模型在SMCR沟通框架下对说服的易感性，发现小模型极易被说服，元认知提示反而增加脆弱性，对抗性微调效果因模型而异


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs被广泛应用于问答任务，但研究发现它们容易受到说服并采纳反事实信念，需要系统评估其说服易感性以开发更可信的模型

Method: 在SMCR沟通框架下，对5个主流LLMs在3个领域（事实知识、医疗QA、社会偏见）进行系统性评估，分析不同说服策略对信念稳定性的影响，并测试元认知提示和对抗性微调作为防御措施

Result: 小模型表现出极端顺从性，80%以上信念变化发生在第一次说服时；元认知提示反而增加脆弱性；对抗性微调效果显著依赖于模型：GPT-4o-mini达到98.6%鲁棒性，Mistral 7B从35.7%提升到79.3%，而Llama模型即使微调后仍保持高易感性（<14%）

Conclusion: 当前鲁棒性干预措施存在显著的模型依赖性限制，这些发现为开发更可信的LLMs提供了指导，需要针对不同模型设计更有效的防御策略

Abstract: Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

</details>


### [137] [CauScientist: Teaching LLMs to Respect Data for Causal Discovery](https://arxiv.org/abs/2601.13614)
*Bo Peng,Sirui Chen,Lei Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: CauScientist是一个结合LLM生成假设与概率统计验证的因果发现框架，通过混合初始化、迭代优化和错误记忆机制，显著提升因果图构建性能


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法存在局限：纯数据驱动方法受统计不可区分性和建模假设影响，而基于LLM的方法要么忽略统计证据，要么引入未经验证可能误导结果的先验知识

Method: 提出CauScientist协作框架，将LLM作为生成假设的"数据科学家"，概率统计作为严格"验证者"。采用混合初始化选择优质起始图，通过LLM提议修改并由统计标准验证的迭代优化，维护错误记忆指导高效搜索空间

Result: 实验显示CauScientist显著优于纯数据驱动基线，F1分数提升达53.8%，召回率从35.0%提升至100.0%。在37节点图上，相比Qwen3-32B将结构汉明距离(SHD)降低44.0%

Conclusion: CauScientist通过LLM与统计方法的协同工作，有效克服了现有方法的局限性，为因果发现提供了更可靠和高效的解决方案

Abstract: Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating "data scientists" with probabilistic statistics as rigorous "verifiers". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.

</details>


### [138] [Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models](https://arxiv.org/abs/2601.13630)
*Zhaopeng Zhang,Pengcheng Sun,Lan Zhang,Chen Tang,Jiewei Lai,Yunhao Wang,Hui Jin*

Main category: cs.CL

TL;DR: 提出AAAC框架，无需训练即可实现细粒度权限控制，通过权限锚点重定向激活空间，减少权限违规86.5%，攻击成功率降低90.7%


<details>
  <summary>Details</summary>
Motivation: LLMs在知识库问答中可能无意中泄露超出用户权限范围的敏感信息，难以满足细粒度访问控制需求

Method: 基于激活空间的几何规律性，提出AAAC框架：构建权限锚点库，通过多锚点引导机制将查询激活重定向到授权区域

Result: 在三个LLM家族上的实验显示，权限违规率降低86.5%，基于提示的攻击成功率降低90.7%，响应可用性提升，推理开销小

Conclusion: AAAC提供了一种无需训练、基于激活空间几何特性的细粒度权限控制方案，有效平衡安全性与实用性

Abstract: Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

</details>


### [139] [Towards Token-Level Text Anomaly Detection](https://arxiv.org/abs/2601.13644)
*Yang Cao,Bicheng Yu,Sikun Yang,Ming Liu,Yujiu Yang*

Main category: cs.CL

TL;DR: 提出token级文本异常检测新范式，实现文本内部异常的精确定位，超越传统文档级检测的局限性


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测方法（如垃圾邮件过滤、假新闻检测）仅限于文档级分析，无法定位文本中具体的异常部分，需要更细粒度的检测能力

Method: 提出token级异常检测范式，定义文档级和token级文本异常，建立统一的多级检测框架，收集并标注三个包含token级标签的基准数据集

Result: 实验结果表明，该框架在三个数据集上优于6个基线方法，实现了文本异常的精确定位

Conclusion: token级异常检测为文本异常定位开辟了新方向，代码和数据已开源，促进该领域研究发展

Abstract: Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.

</details>


### [140] [Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge](https://arxiv.org/abs/2601.13649)
*Xiaolin Zhou,Zheng Luo,Yicheng Gao,Qixuan Chen,Xiyang Hu,Yue Zhao,Ruishan Liu*

Main category: cs.CL

TL;DR: 研究发现LLM作为评判者存在语言偏见：同语言比较时欧洲语言优于非洲语言，跨语言比较时偏好英语，且语言偏见不能完全由困惑度解释


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者已被证明存在多种偏见，其中语言偏见会影响其判断与人类偏好的一致性。本研究旨在系统分析LLM-as-a-judge中的语言偏见问题，特别是同语言和跨语言比较时的表现差异。

Method: 研究两种语言偏见：(1) 同语言比较时的性能差异（比较相同语言选项）；(2) 跨语言比较时的偏见（比较不同语言选项）。分析语言家族差异（欧洲vs非洲语言）、文化相关主题的影响，并探究语言偏见与低困惑度偏见的关系。

Result: 同语言评判中，欧洲语言表现显著优于非洲语言，文化相关主题中偏见更明显；跨语言评判中，多数模型偏好英语答案，且答案语言比问题语言影响更大；语言偏见与困惑度仅有微弱相关，不能完全由困惑度解释。

Conclusion: LLM作为评判者存在显著的语言偏见，这种偏见在不同语言比较场景中表现不同，且不能简单归因于困惑度差异。研究揭示了LLM评判系统需要解决的语言公平性问题。

Abstract: Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

</details>


### [141] [Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation](https://arxiv.org/abs/2601.13658)
*Arthur Amalvy,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 提出一个基于未来预测事实的合成评估数据集，用于解决时间知识图谱提取任务中数据污染和评估偏差问题。


<details>
  <summary>Details</summary>
Motivation: 时间知识图谱提取（TKGE）任务缺乏高质量评估数据集，现有数据集存在训练与评估数据重叠的数据污染问题，导致大语言模型性能被高估。

Method: 采用两步法：1) 时间知识图谱预测生成未来可能的四元组；2) 使用LLM将四元组转换为语义对齐的文本描述，构建合成评估数据集。

Result: 创建了包含4.2K未来四元组及对应文本描述的数据集，实验显示LLM在该数据集上的性能低于已知事实数据集，证明了数据污染问题的存在。

Conclusion: 提出的合成数据集方法能持续生成无污染的评估数据，为TKGE任务提供长期、无偏的基准测试，并公开了数据集和生成方法。

Abstract: The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.

</details>


### [142] [Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis](https://arxiv.org/abs/2601.13659)
*Chunlei Meng,Ziyang Zhou,Lucas He,Xiaojing Du,Chun Ouyang,Zhongxue Gan*

Main category: cs.CL

TL;DR: TSDA通过时空解耦和跨模态对齐提升多模态情感分析性能


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了时空异质性，导致时空信息不对称和性能受限

Method: TSDA：在交互前将每个模态解耦为时间动态和空间结构上下文，分别编码后进行因子一致的跨模态对齐，最后通过门控重耦合模块整合

Result: TSDA在实验中优于基线方法，消融分析验证了设计的必要性和可解释性

Conclusion: 显式时空解耦和因子一致对齐能有效处理多模态情感分析中的时空异质性问题

Abstract: Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.

</details>


### [143] [CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks](https://arxiv.org/abs/2601.13669)
*Jiayu Lin,Zhongyu Wei*

Main category: cs.CL

TL;DR: 论文提出社区级对齐作为个体级和通用级对齐的中间方案，并构建了首个大规模社区级对齐评估基准CommunityBench，发现当前LLMs在建模社区特定偏好方面能力有限，但社区级对齐有助于个体建模。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐策略存在两个极端：通用价值集（one-size-fits-all）会边缘化少数群体规范，而个体级定制则成本过高。考虑到人类社会按社会集群组织且组内价值对齐度高，需要寻找中间方案。

Method: 提出社区级对齐作为折中方案，构建了首个大规模社区级对齐评估基准CommunityBench，包含基于共同身份和共同纽带理论的四个任务，用于全面评估基础模型。

Result: 当前LLMs在建模社区特定偏好方面能力有限，但社区级对齐在促进个体建模方面具有潜力，为可扩展和多元对齐提供了有前景的方向。

Conclusion: 社区级对齐是解决LLM对齐问题的有前景的中间路径，CommunityBench为评估社区级对齐能力提供了重要基准，未来研究应关注如何更好地建模社区特定偏好以实现多元对齐。

Abstract: Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.

</details>


### [144] [HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference](https://arxiv.org/abs/2601.13684)
*Zhiyuan Shi,Qibo Qiu,Feng Xue,Zhonglin Jiang,Li Yu,Jian Jiang,Xiaofei He,Wenxiao Wang*

Main category: cs.CL

TL;DR: HeteroCache：一种免训练的动态KV缓存压缩框架，通过细粒度头部分类、分层存储和异步按需检索，解决长上下文推理中的内存瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 现有静态压缩方法无法保留全局重要信息（忽视注意力漂移现象），动态检索方法则存在粗粒度缓存策略和高I/O开销问题，需要更高效的KV缓存压缩方案

Method: 基于注意力头的时空异质性，将头部分类为稳定和冗余类型；采用细粒度权重分配策略，为注意力快速变化的头分配更大缓存预算；使用分层存储机制，让代表性子集监控注意力变化并触发异步按需检索

Result: 在多个长上下文基准测试中达到最先进性能，在224K上下文长度下相比原始模型加速解码达3倍

Conclusion: HeteroCache通过动态细粒度压缩有效解决了KV缓存线性增长问题，平衡了信息保留与计算效率，显著提升长上下文推理性能

Abstract: The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

</details>


### [145] [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690)
*Yue Guo,Fanfu Wang,Jianwei Lv,Xincheng Shi,Yuchen Li,Youya Wang,Yunsheng Zeng,Yujing Liu,Yunhao Qiao,Gen Li,Junfeng Wang,Bo Yuan*

Main category: cs.CL

TL;DR: 提出Dr. Assistant临床诊断模型，通过两阶段训练（SFT+RL）提升LLM的临床推理和问诊能力，在诊断推理和问诊基准上表现优于开源模型，与闭源模型竞争


<details>
  <summary>Details</summary>
Motivation: 临床决策支持系统维护成本高、泛化能力差，而大型语言模型虽然医学知识丰富，但诊断推理和问诊能力有限，需要专门的方法来提升这些关键临床技能

Method: 提出临床诊断推理数据结构（CDRD）来捕捉抽象临床推理逻辑，并构建Dr. Assistant模型，采用两阶段训练：先监督微调（SFT），再使用定制奖励函数进行强化学习（RL）

Result: Dr. Assistant在诊断推理和问诊评估基准上表现优于开源模型，与闭源模型性能相当，为临床诊断问诊指导提供了有效解决方案

Conclusion: 通过专门设计的临床推理数据结构和两阶段训练方法，成功开发出具备临床推理和问诊能力的Dr. Assistant模型，为临床决策支持提供了新的有效途径

Abstract: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

</details>


### [146] [OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens](https://arxiv.org/abs/2601.13695)
*Sifan Li,Hongkai Chen,Yujun Cai,Liyang Chen,Qingwen Ye,Yiwei Wang*

Main category: cs.CL

TL;DR: OptiSQL：直接从表格图像和自然语言问题生成可执行SQL的视觉驱动框架，使用紧凑光学标记减少输入标记数量


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法需要将表格完全线性化为文本模式，这假设访问结构化文本并产生大量标记开销，与现实场景中表格作为文档或网页中的视觉元素存在不匹配

Method: 使用OCR导向的视觉编码器将表格结构和内容压缩为一小组光学标记，微调预训练解码器进行SQL生成，同时冻结编码器以隔离表示充分性

Result: 在可视化的Spider 2.0-Snow版本上，OptiSQL保持强大的执行准确性，同时将表格输入标记减少一个数量级；鲁棒性分析显示光学标记在视觉扰动下保留基本结构信息

Conclusion: 紧凑的光学表示可以作为可执行语义解析的有效接口，视觉驱动方法在减少标记开销的同时保持SQL生成准确性

Abstract: Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

</details>


### [147] [Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning](https://arxiv.org/abs/2601.13697)
*Zhihang Yuan,Chengyu Yue,Long Huang,Litu Ou,Lei Shi*

Main category: cs.CL

TL;DR: GRADFILTERING：一种基于梯度信噪比的不确定性感知数据选择框架，用于高效指令调优


<details>
  <summary>Details</summary>
Motivation: 现代指令数据集庞大、嘈杂且冗余，全数据微调成本高且不必要。现有数据选择方法要么构建昂贵的梯度数据存储，要么使用弱代理的静态评分，忽略了动态不确定性这一LLM可解释性的关键来源。

Method: 提出GRADFILTERING框架，使用小型GPT-2代理模型配合LoRA集成，将每个样本的梯度聚合成梯度信噪比（G-SNR）效用指标，实现目标无关、不确定性感知的数据选择。

Result: 在大多数LLM-as-a-judge评估和人工评估中，该方法匹配或超越了随机子集和强基线方法。GRADFILTERING选择的子集在相同计算预算下收敛更快，体现了不确定性感知评分的优势。

Conclusion: GRADFILTERING提供了一种高效、不确定性感知的数据选择方法，能够显著降低指令调优成本，同时保持或提升模型性能。

Abstract: Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.

</details>


### [148] [GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711)
*Lotta Kiefer,Christoph Leiter,Sotaro Takeshita,Elena Schmidt,Steffen Eger*

Main category: cs.CL

TL;DR: GerAV是首个大规模德语作者验证基准，包含超过60万标注文本对，基于Twitter和Reddit数据构建，用于系统评估德语作者验证模型性能。


<details>
  <summary>Details</summary>
Motivation: 作者验证任务在英语领域已有广泛研究，但其他语言的大规模基准和系统评估仍然缺乏。本文旨在填补德语作者验证领域的这一空白，为德语AV研究提供全面基准。

Method: 构建GerAV基准，包含超过600k标注文本对，数据来自Twitter和Reddit。Reddit部分进一步分为：领域内消息子集、跨领域消息子集和基于个人资料子集。使用提供的训练分割对强基线模型和最先进模型进行系统评估。

Result: 最佳方法（微调的大型语言模型）比近期基线高出0.09绝对F1分数，在零样本设置中比GPT-5高出0.08。观察到专业化与泛化之间的权衡：在匹配条件下，特定数据类型训练的模型表现最佳，但跨数据制度的泛化能力较差，这一限制可以通过组合训练源来缓解。

Conclusion: GerAV为德语和跨领域作者验证研究提供了一个具有挑战性和多功能的基准，能够支持对数据源、主题领域和文本长度影响的受控分析。

Abstract: Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.

</details>


### [149] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

TL;DR: 模拟无知方法无法可靠评估LLM预测能力，因为提示无法有效"倒带"模型知识，建议避免使用基于模拟无知的回顾性预测来评估预测能力


<details>
  <summary>Details</summary>
Motivation: 评估LLM预测能力面临两难：前瞻性评估方法严谨但延迟高，回顾性预测面临数据污染问题。模拟无知方法被提出作为解决方案，但需要验证其是否能真正模拟真实无知状态

Method: 通过477个竞赛级问题和9个模型，系统测试模拟无知是否能近似真实无知。比较了三种情况：截止指令效果、思维链推理是否抑制先验知识、推理优化模型的无知保真度

Result: 模拟无知系统性失败：1) 截止指令导致SI与TI存在52%性能差距；2) 思维链推理无法抑制先验知识，即使推理痕迹不含明确截止后信息；3) 推理优化模型的SI保真度更差，尽管推理痕迹质量更高

Conclusion: 提示无法可靠"倒带"模型知识，基于截止前事件的回顾性预测存在方法论缺陷。建议不要使用基于模拟无知的回顾性设置来评估预测能力

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [150] [OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents](https://arxiv.org/abs/2601.13722)
*Yulin Hu,Zimo Long,Jiahe Guo,Xingyu Sui,Xing Fu,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 提出OP-Bench基准测试，用于评估对话代理的过度个性化问题，并开发Self-ReCheck方法进行缓解


<details>
  <summary>Details</summary>
Motivation: 现有记忆增强对话代理主要关注能否回忆和应用用户信息，但忽视了是否恰当使用个性化。过度使用个人信息会导致回应显得生硬、侵入性强或社交不当，即"过度个性化"问题。

Method: 1. 将过度个性化形式化为三种类型：无关性、重复性和谄媚性；2. 构建OP-Bench基准测试，包含1700个验证实例；3. 提出Self-ReCheck方法，一种轻量级、模型无关的记忆过滤机制。

Result: 评估多个大语言模型和记忆增强方法，发现引入记忆后过度个性化问题普遍存在。分析显示代理倾向于检索和过度关注用户记忆，即使在不必要时。Self-ReCheck方法能有效缓解过度个性化，同时保持个性化性能。

Conclusion: 该研究为记忆增强对话系统中更可控和恰当的个性化迈出了初步步骤，提出了评估基准和缓解方法，有助于改善个性化对话代理的用户体验。

Abstract: Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

</details>


### [151] [On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation](https://arxiv.org/abs/2601.13729)
*Weichuan Wang,Mingyang Liu,Linqi Song,Chen Ma*

Main category: cs.CL

TL;DR: 该论文系统研究了机器翻译中的非确定性现象，发现温度约束下的非确定性机器翻译能提供更高质量的候选翻译，但现有评估框架对其不适用，并提出了新的评估策略。


<details>
  <summary>Details</summary>
Motivation: 语言模型的非确定性特性在现实应用中影响显著，但在机器翻译这一复杂非确定性任务中尚未得到充分探索。机器翻译长期面临多模态问题的挑战，需要研究非确定性机器翻译的潜力及其评估方法。

Method: 系统评估现代机器翻译系统，识别温度约束下的非确定性机器翻译现象。使用三个开放数据集，通过词汇和语义指标在不同采样规模下评估五个最先进的非确定性机器翻译系统，并提出ExpectoSample策略自动评估指标的可靠性。

Result: 发现非确定性机器翻译在温度约束下能提供比确定性机器翻译更高质量的候选翻译。评估结果显示存在"水桶效应"：非确定性机器翻译生成的最低质量候选翻译决定了系统在不同采样规模下的整体排名。提出的ExpectoSample策略能有效评估指标可靠性。

Conclusion: 非确定性机器翻译在解决机器翻译多模态问题方面具有重要潜力，但需要新的评估框架。现有确定性机器翻译的评估方法不适用于非确定性机器翻译，需要开发专门的评估策略来可靠地选择和评估非确定性机器翻译系统。

Abstract: In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

</details>


### [152] [Towards robust long-context understanding of large language model via active recap learning](https://arxiv.org/abs/2601.13734)
*Chenyu Hui*

Main category: cs.CL

TL;DR: ARL通过主动回顾学习增强LLM长文本理解能力，在持续预训练中构建目标序列，在推理时进行回顾性总结，实现递归记忆机制，显著提升长文本理解性能


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理长上下文时存在理解能力不足的问题，需要增强模型对长文本的记忆和理解能力

Method: 1) 基于长短上下文损失差异识别关键token并找到相关前文段落，用LLM进行总结；2) 在持续预训练中构建目标序列，在推理时让模型自主生成和利用回顾性总结，建立跨段落的递归记忆机制

Result: ARL在RULER基准上提升26.8%，在LongBench上提升9.44%，显著增强了长上下文理解能力

Conclusion: ARL提供了一种简单有效的持续预训练方法，通过主动回顾学习和递归记忆机制增强LLM的长文本理解能力，推动了可扩展记忆增强技术的发展

Abstract: In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

</details>


### [153] [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742)
*Arjun Chandra,Kevin Miller,Venkatesh Ravichandran,Constantinos Papayiannis,Venkatesh Saligrama*

Main category: cs.CL

TL;DR: TRACE框架让LLM能基于音频线索进行推理，实现低成本、与人类对齐的语音到语音评估，超越音频语言模型和纯文本LLM评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动语音到语音评估方法依赖不透明且昂贵的音频语言模型，而具有强大推理能力的大语言模型只能处理文本内容，无法直接评估音频质量。

Method: 提出TRACE框架：1）引入人类思维链标注协议，将评估分为内容、语音质量和副语言三个维度；2）构建音频信号的文本蓝图；3）让LLM进行维度判断；4）通过确定性策略融合为总体评分。

Result: TRACE与人类评分者的一致性高于音频语言模型和纯文本LLM评估方法，同时成本效益显著更高。

Conclusion: TRACE框架实现了可扩展且与人类对齐的语音到语音评估，将发布人类思维链标注和TRACE框架以促进该领域发展。

Abstract: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.

</details>


### [154] [Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis](https://arxiv.org/abs/2601.13802)
*Yushen Chen,Junzhe Liu,Yujie Tu,Zhikang Niu,Yuzhe Liang,Kai Yu,Chunyu Qiang,Chen Zhang,Xie Chen*

Main category: cs.CL

TL;DR: Habibi是一个专门用于阿拉伯语方言语音合成的统一模型套件，利用现有ASR语料库支持多种方言，无需文本标注，性能优于商业服务


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音合成研究存在明显空白，缺乏标准化数据、基准和评估指南，且阿拉伯语方言具有复杂的语言特性，导致研究人员难以开展相关工作

Method: 利用现有开源ASR语料库，通过语言感知的课程学习支持从高资源到低资源的多种阿拉伯语方言，采用有效的上下文学习保持可扩展性，无需文本标注

Result: Habibi在生成质量上优于领先的商业服务，同时保持可扩展性，将开源模型并创建首个多方言阿拉伯语语音合成的系统基准

Conclusion: 该研究填补了阿拉伯语方言语音合成的空白，通过建立评估标准和提供系统基准，为后续研究奠定了坚实基础，承诺开源模型以促进领域发展

Abstract: A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .

</details>


### [155] [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806)
*Dezhao Song,Guglielmo Bonifazi,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: 提出基于知识图谱增强LLM法律推理能力的方法，通过IRAC框架构建法律知识图谱，结合SFT和DPO训练，在多个法律基准测试中超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练主要依赖大规模文本和人类反馈，缺乏对领域知识结构的捕捉，导致在处理复杂推理任务（特别是高风险专业领域如法律）时表现不佳。法律推理需要深入理解法律概念间的关系，这是现有LLM后训练缺失的关键组成部分。

Method: 采用知识图谱辅助方法增强LLM法律推理能力：1) 基于IRAC框架（Issue, Rule, Analysis, Conclusion）建模关键法律概念；2) 构建包含12K法律案例的知识图谱；3) 利用IRAC KG生成训练数据；4) 对三个SOTA LLM（30B、49B、70B）进行监督微调和直接偏好优化训练。

Result: 后训练模型在4/5个多样化法律基准测试（14个任务）上获得比基线更好的平均性能。特别是70B DPO模型在4/6个推理任务上取得了最佳分数，超越了基线模型和141B SOTA法律LLM，证明了知识图谱对增强LLM法律推理能力的有效性。

Conclusion: 知识图谱辅助方法能有效增强LLM在专业领域（特别是法律）的推理能力，该方法可推广到其他高风险领域。基于IRAC框架构建的知识图谱为LLM提供了结构化领域知识，显著提升了复杂推理任务的性能。

Abstract: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

</details>


### [156] [The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations](https://arxiv.org/abs/2601.13835)
*Sam OConnor Russell,Delphine Charuau,Naomi Harte*

Main category: cs.CL

TL;DR: 该研究通过声码器方法控制语音中的韵律和词汇线索，探究S3R基础的轮转模型依赖哪种线索，发现韵律和词汇线索都能支持轮转，且可以单独使用，未来模型可能仅需韵律线索以保护隐私并提升性能。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人交互中，流畅的轮转对话是关键挑战。虽然自监督语音表示（S3Rs）推动了进展，但尚不清楚基于S3R的轮转模型主要依赖韵律线索、词汇线索还是两者兼有。需要更干净地控制这两种线索来探究模型机制。

Method: 引入基于声码器的方法，比先前工作更干净地控制语音中的韵律和词汇线索。使用这种方法探测基于S3R的轮转模型（语音活动预测模型），在保持韵律但词汇不可理解的噪声条件下进行预测测试。

Result: 在韵律匹配但不可理解的噪声上的预测准确率与干净语音相似。这表明韵律和词汇线索都能支持轮转，且可以单独使用。当任一信息被破坏时，模型会利用另一线索而无需额外训练，说明它们在S3Rs中编码且相互依赖有限。结果在CPC和wav2vec2.0 S3Rs中一致。

Conclusion: 未来轮转模型可能仅需韵律线索，这能提供隐私保护和潜在性能优势。韵律和词汇线索在S3Rs中编码相对独立，模型能灵活利用任一线索。研究为未来工作指明了方向，并开源了所有代码。

Abstract: Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.

</details>


### [157] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出了首个用于评估多模态大语言模型音频视觉未来预测能力的基准FutureOmni，包含919个视频和1034个QA对，并提出了OFF训练策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型主要关注回顾性理解，但在基于音频视觉线索预测未来事件方面的能力尚未得到充分探索，需要专门的基准来评估这一能力。

Method: 1) 通过LLM辅助、人类参与的流程构建FutureOmni基准，包含8个主要领域的919个视频和1034个多项选择题；2) 提出Omni-Modal Future Forecasting (OFF)训练策略，并构建了7K样本的指令调优数据集。

Result: 评估了13个多模态和7个纯视频模型，发现当前系统在音频视觉未来预测方面表现不佳，特别是在语音密集型场景中，最佳准确率仅为64.8%（Gemini 3 Flash）。OFF训练策略显著提升了未来预测能力和泛化性能。

Conclusion: FutureOmni是首个评估多模态未来预测的基准，揭示了当前模型在此任务上的局限性，提出的OFF训练策略有效提升了模型性能，为未来研究提供了重要基础。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [158] [Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education](https://arxiv.org/abs/2601.13876)
*Unggi Lee,Jahyun Jeong,Sunyoung Shin,Haeun Park,Jeongsu Moon,Youngchang Song,Jaechang Shim,JaeHwan Lee,Yunju Noh,Seungwon Choi,Ahhyun Kim,TaeHyeon Kim,Kyungtae Joo,Taeyeong Kim,Gyeonggeon Lee*

Main category: cs.CL

TL;DR: 提出Pedagogical VLA Framework框架，通过教学对齐使轻量级VLA模型能在资源受限的教育环境中生成教学解释，在科学演示任务中实现与基线模型相当的性能同时提供教育性解释。


<details>
  <summary>Details</summary>
Motivation: 科学演示对STEM教育很重要，但教师面临安全性和一致性的挑战。现有VLA模型需要大量计算资源，且牺牲语言生成能力来追求效率，不适合需要可解释、能生成解释的教育环境。

Method: 提出Pedagogical VLA Framework框架，包含四个组件：文本修复恢复语言生成能力、LLM蒸馏传递教学知识、安全训练适应教育环境、教学评估调整到科学教育场景。在五个科学演示任务（物理、化学、生物、地球科学）中评估。

Result: 实验结果表明，Pedagogical VLA Framework在任务性能（成功率、协议合规性、效率、安全性）上与基线模型相当，同时能生成上下文恰当的教育解释。通过教师调查和LLM-as-Judge评估验证了教学质量。

Conclusion: 该框架成功将教学对齐应用于轻量级VLA模型，使其在资源受限的教育环境中既能执行科学演示任务，又能生成高质量的教学解释，解决了现有VLA模型在教育应用中的局限性。

Abstract: Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.

</details>


### [159] [OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models](https://arxiv.org/abs/2601.13882)
*Unggi Lee,Sookbun Lee,Heungsoo Choi,Jinseo Lee,Haeun Park,Younghoon Jeon,Sungmin Cho,Minju Kang,Junbo Koh,Jiyeong Bae,Minwoo Nam,Juyeon Eun,Yeonji Jung,Yeil Jeong*

Main category: cs.CL

TL;DR: OpenLearnLM Benchmark是一个基于教育评估理论的多维度LLM评估框架，包含知识、技能和态度三个维度，涵盖124K+项目，评估显示不同模型在不同维度表现各异，没有单一模型在所有维度领先。


<details>
  <summary>Details</summary>
Motivation: 现有LLM教育基准测试过于关注狭窄技能，缺乏学习科学理论基础，需要更全面、理论基础的评估框架来评估LLM在教育场景中的真实准备度。

Method: 基于教育评估理论构建三维评估框架：知识（课程内容与教学理解）、技能（基于四层级中心-角色-场景-子场景结构的场景能力）、态度（一致性对齐和欺骗抵抗）。包含124K+项目，涵盖多学科、教育角色和布鲁姆分类法的难度级别。知识域使用真实评估项目，态度域采用Anthropic的对齐伪装检测方法。

Result: 评估7个前沿模型显示不同能力特征：Claude-Opus-4.5在实践技能上表现优异但内容知识较低；Grok-4.1-fast在知识方面领先但显示对齐问题。没有单一模型在所有维度占优，验证了多轴评估的必要性。

Conclusion: OpenLearnLM提供了一个开放、全面的框架，用于推进LLM在真实教育环境中的准备度，强调需要多维度评估来全面理解LLM的教育能力。

Abstract: Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.

</details>


### [160] [Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores](https://arxiv.org/abs/2601.13885)
*Esma Balkır,Alice Pernthaller,Marco Basaldella,José Hernández-Orallo,Nigel Collier*

Main category: cs.CL

TL;DR: 本文提出了一种将计算机自适应测试（CAT）扩展到连续有界评分（如ROUGE、BLEU、LLM-as-a-Judge）的方法，使用异方差正态分布替代伯努利分布，并引入具有自适应停止准则的不确定性感知排序器，显著减少测试项目数量。


<details>
  <summary>Details</summary>
Motivation: 传统CAT方法主要针对选择题（正确/错误评分），但现代LLM评估越来越多依赖生成任务，其输出采用连续评分（如ROUGE、BLEU、LLM-as-a-Judge评分）。需要将IRT自适应测试扩展到连续有界评分领域。

Method: 1. 用异方差正态分布替代传统IRT中的伯努利响应分布，以适应连续有界评分；2. 引入不确定性感知排序器，结合自适应停止准则，在保证可靠模型排序的同时最小化测试项目数量和成本。

Result: 在五个基准测试（包括n-gram、embedding和LLM-as-judge指标）上验证，仅使用2%的测试项目，相比随机采样将排序相关性提高了0.12 τ，在置信预测上达到95%的准确率。

Conclusion: 该方法成功将CAT扩展到连续评分领域，显著提高了LLM评估效率，在保持高准确率的同时大幅减少了测试成本，为现代生成任务评估提供了有效的自适应测试框架。

Abstract: Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.

</details>


### [161] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: RetroSum框架通过回顾性总结和演进经验策略，在AgentEHR基准上显著提升LLM在原始电子病历中的自主导航能力，性能提升达29.16%，交互错误减少92.3%。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在医疗领域的应用受限于依赖精心准备的输入和简化的检索任务，无法在原始、高噪声的电子病历数据库中进行复杂的临床决策任务，如诊断和治疗规划。

Method: 提出RetroSum框架，包含回顾性总结机制和演进经验策略。回顾性机制动态重新评估交互历史，防止长上下文信息丢失；演进策略从记忆库中检索累积经验来弥合领域差距。

Result: RetroSum在AgentEHR基准上相比竞争基线性能提升最高达29.16%，同时显著减少总交互错误达92.3%。

Conclusion: RetroSum通过创新的回顾性总结和演进经验策略，有效解决了LLM在原始电子病历中自主导航时的信息丢失和推理连续性断裂问题，为临床环境中的实际应用提供了可行方案。

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [162] [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919)
*Yuezhe Yang,Hao Wang,Yige Peng,Jinman Kim,Lei Bi*

Main category: cs.CL

TL;DR: HyperWalker：基于动态超图与测试时训练的深度诊断框架，通过构建iBrochure超图建模EHR结构异质性，利用Walker智能体导航寻找最优诊断路径，结合linger机制选择临床互补病例，在MRG和医疗VQA任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI诊断方法主要采用样本隔离推理范式，独立处理病例而无法访问纵向电子健康记录或结构相关患者示例，仅依赖图像信息限制了诊断准确性。需要整合外部补充医学证据以实现更准确的临床诊断。

Method: 提出HyperWalker深度诊断框架：1) 构建动态超图iBrochure，建模EHR数据的结构异质性和多模态临床信息间的高阶关联；2) 使用强化学习智能体Walker在超图中导航寻找最优诊断路径；3) 引入linger机制，通过多跳正交检索策略迭代选择反映不同临床属性的互补邻域病例。

Result: 在MIMIC数据集上的医疗报告生成(MRG)和EHRXQA上的医疗视觉问答(VQA)实验中，HyperWalker均取得了最先进的性能表现。

Conclusion: HyperWalker通过动态超图建模和测试时训练，克服了传统样本隔离推理范式的局限性，能够整合外部医学证据进行更准确的临床诊断，为医疗AI诊断提供了新的框架思路。

Abstract: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

</details>


### [163] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://arxiv.org/abs/2601.13922)
*Adrian Cosma,Oleg Szehr,David Kletz,Alessandro Antonucci,Olivier Pelletier*

Main category: cs.CL

TL;DR: 提出多智能体提示优化框架，将特征发现视为数据集级提示优化问题，通过语言模型智能体协作生成可解释特征定义，优化下游监督学习目标。


<details>
  <summary>Details</summary>
Motivation: 当前从非结构化文本中提取特征的方法主要依赖手工设计的提示或固定特征模式，缺乏自动发现可解释特征的能力。需要一种能够从标注文本语料库中自动发现全局、可解释且具有区分性特征定义的方法。

Method: 提出多智能体提示优化框架：语言模型智能体协作执行三个任务——提出特征定义、提取特征值、评估特征质量（基于数据集级性能和可解释性反馈）。通过结构化反馈迭代优化指令提示，实现共享特征集的优化而非单样本预测。

Result: 该方法与依赖单样本监督的先前提示优化方法不同，为从非结构化文本中自动发现特征提供了原则性机制，能够生成全局可解释特征集。

Conclusion: 将特征发现形式化为数据集级提示优化问题，通过多智能体框架实现自动特征发现，为下游分类任务提供更有效的特征提取方法。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [164] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

TL;DR: COMPACT框架通过动态融合多教师监督来提升小型语言模型的推理能力，避免单一教师的偏见和灾难性遗忘，实现更好的知识蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 现有CoT蒸馏方法通常依赖单一教师模型，但单个大语言模型存在能力偏见和灾难性遗忘问题，限制了学生模型的潜力。虽然利用多样化教师模型具有吸引力，但有效融合它们的监督仍然具有挑战性：师生不兼容可能放大幻觉，被动监督无法确保真正的逻辑内化。

Method: COMPACT框架通过基于学生实时兼容性动态加权教师梯度来融合不同教师的监督。兼容性通过三个多维指标评估：(1)基于图的共识度，通过识别主流推理路径过滤误导性理由；(2)基于互信息的适应性，检测"顿悟时刻"以确保真正理解推理过程而非简单模仿；(3)基于损失的难度评估，衡量学生对教师指导的接受度并防止负迁移。

Result: 大量实验和潜在空间分析表明，COMPACT能有效整合多样化推理能力而不损害模型的原始知识结构，在各种基准测试中达到最先进的性能，同时缓解了灾难性遗忘问题。

Conclusion: COMPACT框架通过自适应融合多教师监督，成功解决了CoT蒸馏中单一教师的局限性，实现了更好的推理能力转移，为小型语言模型的推理能力提升提供了有效解决方案。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [165] [From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning](https://arxiv.org/abs/2601.13995)
*Zihan Niu,Wenping Hu,Junmin Chen,Xiyue Wang,Tong Xu,Ruiming Tang*

Main category: cs.CL

TL;DR: TAGS框架利用细粒度知识树实现可控数据选择，显著提升指令调优效果


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法依赖实例级质量评分或基于嵌入聚类/语义标签的多样性度量，但受限于嵌入空间平坦性或标签粗糙性，忽略了细粒度知识及其内在层次依赖关系，阻碍了精确的数据评估和知识对齐采样。

Method: 提出Tree-aware Aligned Global Sampling (TAGS)框架：1) 使用LLM标注器提取原子知识概念；2) 通过自底向上层次聚类构建全局知识树；3) 将数据实例映射到树上，用树感知度量量化数据质量和多样性；4) 可控采样策略最大化树级信息增益，并通过KL散度强制叶级对齐特定领域。

Result: TAGS显著优于现有基线方法。仅使用5%数据就超越全数据集模型+5.84%，对齐采样策略进一步将平均性能提升+4.24%。

Conclusion: TAGS通过构建细粒度知识树实现了对数据质量、多样性和目标对齐的联合控制，为LLM指令调优提供了有效且可控的数据选择框架。

Abstract: Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

</details>


### [166] [Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models](https://arxiv.org/abs/2601.14004)
*Hengyuan Zhang,Zhihao Zhang,Mingyang Wang,Zunhai Su,Yiwei Wang,Qianli Wang,Shuzhou Yuan,Ercong Nie,Xufeng Duan,Qibo Xue,Zeping Yu,Chenming Shang,Xiao Liang,Jing Xiong,Hui Shen,Chaofan Tao,Zhengwu Liu,Senjie Jin,Zhiheng Xi,Dongdong Zhang,Sophia Ananiadou,Tao Gui,Ruobing Xie,Hayden Kwok-Hay So,Hinrich Schütze,Xuanjing Huang,Qi Zhang,Ngai Wong*

Main category: cs.CL

TL;DR: 该论文提出了一种可操作的机制可解释性框架，将MI从观察科学转变为系统干预方法，通过"定位、引导、改进"流程实现模型优化。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性研究主要停留在观察层面，缺乏系统性的干预框架。作者旨在弥合这一差距，将MI从被动分析转变为主动优化工具。

Method: 提出"定位、引导、改进"的三步流程框架，基于可解释对象对定位（诊断）和引导（干预）方法进行形式化分类，建立严格的干预协议。

Result: 该框架能够实现对齐性、能力和效率三个方面的实际改进，将MI操作化为可执行的模型优化方法学。

Conclusion: 机制可解释性可以超越观察科学，成为系统化的可操作方法，通过结构化干预流程有效优化大语言模型的性能。

Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.

</details>


### [167] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

TL;DR: LLMs通过抽象-具身框架评估概念理解能力，发现其价值表示具有跨层次可迁移性和因果不对称性，为构建价值驱动的AI系统提供机制基础。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解抽象概念，还是仅仅在操纵统计模式。以人类价值观作为测试平台，因为其语义丰富且对AI对齐至关重要。

Method: 提出抽象-具身框架，将概念理解分解为三个能力：抽象概念解释(A-A)、抽象概念在具体事件中的具身化(A-C)、抽象原则在具体决策中的应用(C-C)。使用探测（检测内部激活中的价值痕迹）和引导（修改表示以改变行为）方法，在六个开源LLM和十个价值维度上进行实验。

Result: 探测显示：仅基于抽象价值描述训练的探测模型能可靠地在具体事件叙述和决策推理中检测到相同价值，表现出跨层次可迁移性。引导揭示不对称性：干预价值表示能因果性地改变具体判断和决策(A-C, C-C)，但不会改变抽象解释(A-A)，表明编码的抽象价值作为稳定锚点而非可塑激活。

Conclusion: LLMs保持结构化价值表示，连接抽象与行动，为构建价值驱动的自主AI系统提供了机制和操作基础，可实现更透明、可泛化的对齐和控制。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [168] [RM-Distiller: Exploiting Generative LLM for Reward Model Distillation](https://arxiv.org/abs/2601.14032)
*Hongli Zhou,Hui Huang,Wei Liu,Chenglong Wang,Xingyuan Bu,Lvyuan Han,Fuhai Song,Muyun Yang,Wenhao Jiang,Hailong Cao,Tiejun Zhao*

Main category: cs.CL

TL;DR: RM-Distiller：利用生成式LLM的多方面能力进行奖励模型蒸馏的框架


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型蒸馏方法主要将教师模型视为简单的二元标注器，未能充分利用其丰富的知识和能力。高质量人类偏好标注难以获取，需要更有效地从生成式LLM中蒸馏偏好。

Method: 提出RM-Distiller框架，系统利用教师LLM的三种能力：1）精炼能力：合成高度相关的响应对以创建细粒度对比信号；2）评分能力：通过边界感知优化目标指导RM捕捉精确偏好强度；3）生成能力：结合教师生成分布来正则化RM以保留基本语言知识。

Result: 大量实验表明，RM-Distiller在RM基准测试和基于强化学习的对齐任务上显著优于传统蒸馏方法，证明利用多方面教师能力对有效奖励建模至关重要。

Conclusion: 这是首个系统研究从生成式LLM进行奖励模型蒸馏的工作，展示了充分利用教师模型多方面能力的重要性，为奖励模型训练提供了更有效的方法。

Abstract: Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.

</details>


### [169] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

TL;DR: 论文认为当前自回归语言模型存在因果瓶颈限制，扩散语言模型提供了更优的文本生成范式，但面临十大挑战，需要建立扩散原生生态系统来实现下一代AI能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流的大型语言模型采用自回归架构，存在因果瓶颈限制，无法进行全局结构预见和迭代优化。扩散语言模型提供了更优的文本生成范式，但尚未充分发挥潜力，需要突破现有框架限制。

Method: 识别扩散语言模型面临的十大基础挑战，提出包含四大支柱的战略路线图：基础架构、算法优化、认知推理和统一多模态智能，建议向扩散原生生态系统转型。

Result: 论文提出了扩散语言模型发展的系统性分析框架，指出了从架构惯性、梯度稀疏性到线性推理限制等关键挑战，并给出了具体的转型路径。

Conclusion: 从自回归范式向扩散原生生态系统转型对于开发具备复杂结构推理、动态自我修正和无缝多模态整合能力的下一代AI至关重要，这是实现扩散语言模型"GPT-4时刻"的关键。

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [170] [PRiSM: Benchmarking Phone Realization in Speech Models](https://arxiv.org/abs/2601.14046)
*Shikhar Bharadwaj,Chin-Jou Li,Yoonjae Kim,Kwanghee Choi,Eunjung Yeo,Ryan Soh-Eun Shim,Hanyu Zhou,Brendon Boldt,Karen Rosero Jacome,Kalvin Chang,Darsh Agrawal,Keer Xu,Chao-Han Huck Yang,Jian Zhu,Shinji Watanabe,David R. Mortensen*

Main category: cs.CL

TL;DR: PRiSM是首个开源基准测试，通过内在和外在评估揭示语音识别系统在音素感知方面的盲点，发现多语言训练、编码器-CTC模型稳定性以及专用模型优于大型音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前语音识别系统评估仅关注表面转录准确性，缺乏对音素感知能力的深入评估。需要建立标准化基准来暴露语音识别系统在音素感知方面的盲点，推动具有鲁棒音素能力的多语言语音模型发展。

Method: PRiSM基准标准化基于转录的评估，并在临床、教育和多语言环境中通过转录和表示探针评估下游实用性。使用内在和外在评估方法，分析不同训练策略和模型架构的性能。

Result: 研究发现：1) 训练期间的多语言暴露对语音识别性能至关重要；2) 编码器-CTC模型最为稳定；3) 专用语音识别模型仍优于大型音频语言模型。

Conclusion: PRiSM通过提供代码、配方和数据集，推动领域向具有鲁棒音素能力的多语言语音模型发展。多语言训练和专用模型架构是实现更好音素感知的关键。

Abstract: Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.

</details>


### [171] [Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering](https://arxiv.org/abs/2601.14050)
*Yuxin Chen,Zhengzhou Cai,Xiangtian Ji,Weixiang Zhao,An Zhang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 该论文系统分析了MoE模型的多语言处理机制，发现路由行为与语系相关，专家使用呈现层次化模式，并提出基于路由引导的优化方法提升多语言性能。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构在多语言任务中表现出色，但其内部工作机制（如路由行为和专家专业化）以及跨语言差异的原因尚未得到充分理解，需要系统分析来揭示这些机制。

Method: 对MoE模型进行系统性分析，研究不同语言和网络深度下的路由行为和专家专业化模式，并基于分析结果提出路由引导的调控方法，在推理时自适应地将中间层的路由行为导向与主导语言相关的共享专家。

Result: 分析发现MoE模型的多语言处理高度结构化：路由行为与语系对齐，专家使用呈现清晰的层次化模式，高资源语言依赖共享专家而低资源语言更多使用语言专属专家（尽管性能较弱）。中间层干预显示早期和晚期MoE层支持语言特定处理，而中间层作为语言无关的容量中心。

Conclusion: 基于这些发现提出的路由引导调控方法能够自适应地引导中间层路由行为，在推理时将其导向与主导语言相关的共享专家，从而持续提升多语言性能，特别是在语言相关的语言对上效果显著。

Abstract: Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.

</details>


### [172] [Kakugo: Distillation of Low-Resource Languages into Small Language Models](https://arxiv.org/abs/2601.14051)
*Peter Devine,Mardhiyah Sanni,Farid Adilazuarda,Julieta Gil Loizaga,Barry Haddow*

Main category: cs.CL

TL;DR: Kakugo是一个低成本管道，仅需语言名称即可为低资源语言训练通用小型语言模型，通过教师模型生成合成提示和翻译指令数据，为54种语言创建训练数据和模型，每语言成本低于50美元。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言开发AI工具面临数据稀缺和高成本的挑战，需要一种经济高效的方法让社区能够创建语言特定的AI模型。

Method: 使用大型教师模型生成合成提示并翻译指令数据集，为低资源语言创建训练数据，然后训练小型语言模型，仅需语言名称作为输入。

Result: 为54种低资源语言成功创建了训练数据和SLMs，在翻译、分类和问答等NLP任务上表现优于基础模型，每语言总成本低于50美元。

Conclusion: Kakugo提供了一种经济高效且易于访问的方法，使社区能够为低资源语言开发语言特定的AI模型，推动了语言AI的民主化。

Abstract: We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.

</details>


### [173] [Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks](https://arxiv.org/abs/2601.14105)
*Olesya Razuvayevskaya,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 大规模比较研究发现，社区撰写的事实核查（如Community Notes）与专业事实核查在说服技巧使用上没有显著差异，但存在系统性修辞差异，且社区评分者能有效识别和惩罚有问题的修辞手段。


<details>
  <summary>Details</summary>
Motivation: 研究动机是检验先前假设——社区撰写的事实核查是否比专业事实核查更依赖主观或说服性语言，并比较不同事实核查生态系统中说服技巧的使用情况。

Method: 使用来自Community Notes、EUvsDisinfo和Database of Known Fakes的大规模数据集，量化分析这些事实核查生态系统中说服技巧的普遍性和类型。

Result: 1. 没有证据表明Community Notes比专业事实核查包含更多说服技巧；2. 发现社区和专业事实核查之间存在系统性修辞差异，反映机构规范和主题覆盖的不同；3. 社区评分者能有效惩罚有问题的修辞手段，尽管包含更多说服元素的笔记总体评分略高。

Conclusion: 社区撰写的事实核查在说服技巧使用上与专业事实核查相当，但存在修辞风格差异，且社区评分机制能有效监管修辞质量，这对事实核查生态系统设计具有重要意义。

Abstract: This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

</details>


### [174] [Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns](https://arxiv.org/abs/2601.14112)
*George Mihaila*

Main category: cs.CL

TL;DR: ExpNet：一种轻量级神经网络，通过学习从Transformer注意力模式到token重要性分数的显式映射，实现自动化的注意力特征组合，优于依赖预定义规则的现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型在医疗、法律、金融等高风险领域部署，可解释AI变得至关重要。现有注意力解释方法依赖人工定义的聚合策略和固定归因规则，而模型无关方法（如LIME、SHAP）将模型视为黑盒且计算成本高。

Method: 提出Explanation Network (ExpNet)，一种轻量级神经网络，学习从Transformer注意力模式到token级重要性分数的显式映射。该方法自动发现最优注意力特征组合，而非依赖预定义规则。

Result: 在跨任务设置中评估ExpNet，并与涵盖四个方法家族的广泛模型无关方法和基于注意力的技术进行基准测试，显示出优越性能。

Conclusion: ExpNet提供了一种更自动化和有效的Transformer模型解释方法，能够自动学习注意力特征的最佳组合，解决了现有方法依赖人工规则和计算成本高的问题。

Abstract: Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

</details>


### [175] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

TL;DR: NewsRECON通过将新闻图片链接到相关文章，从文章元数据推断拍摄时间和地点，解决了反向图像搜索失败时的新闻图片时空定位问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖反向图像搜索(RIS)，但RIS经常无法返回结果，限制了实际应用。需要解决RIS证据不可用时的新闻图片时空定位挑战。

Method: 提出NewsRECON方法：1) 使用双编码器检索事件相关文章；2) 使用两个交叉编码器按位置和事件一致性重排序文章；3) 基于超过90,000篇文章的语料库。

Result: 在TARA和5Pils-OOC数据集上，NewsRECON优于现有方法，与多模态大语言模型结合时，在RIS证据不可用情况下达到新的SOTA结果。

Conclusion: NewsRECON为RIS不可用时的新闻图片时空定位提供了有效解决方案，通过链接图片到新闻文章并利用文章元数据推断时空信息，代码已开源。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [176] [A Systematic Analysis of Chunking Strategies for Reliable Question Answering](https://arxiv.org/abs/2601.14123)
*Sofia Bennani,Charles Moslonka*

Main category: cs.CL

TL;DR: 研究文档分块策略对工业RAG系统可靠性的影响，通过系统实验发现句子分块是最具成本效益的方法，重叠分块无实际收益，上下文长度存在"悬崖效应"（超过2.5k token质量下降）


<details>
  <summary>Details</summary>
Motivation: 工业实践中RAG系统通常依赖启发式分块策略，但缺乏系统评估。本研究旨在通过端到端评估，为工业部署提供基于实证的分块策略指导，实现成本效益优化。

Method: 在Natural Questions数据集上进行端到端评估，系统变化分块方法（token、句子、语义、代码）、分块大小、重叠和上下文长度。采用标准工业设置：SPLADE检索和Mistral-8B生成器。

Result: 1) 重叠分块无实际收益且增加索引成本；2) 句子分块是最具成本效益的方法，在约5k token内与语义分块效果相当；3) 上下文长度存在"悬崖效应"，超过约2.5k token质量下降；4) 最优上下文长度取决于目标（语义质量在小上下文达到峰值，精确匹配需要更大上下文）。

Conclusion: 为工业RAG部署提供具体建议：避免使用重叠分块，优先采用句子分块，控制上下文长度在2.5k token以内，根据具体目标（语义质量vs精确匹配）调整分块策略，实现成本效益最大化。

Abstract: We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

</details>


### [177] [Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic](https://arxiv.org/abs/2601.14124)
*Saad Mankarious,Aya Zirikly*

Main category: cs.CL

TL;DR: 提出一种基于扩散模型的文本生成方法，通过风格迁移解决阿拉伯语心理健康数据中的性别偏见问题，无需依赖预训练大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法主要依赖预训练大语言模型，存在输出多样性有限和传播训练数据偏见的问题。特别是在心理健康分析领域，数据稀缺和人口统计偏见（如性别不平衡）严重影响了模型性能。

Method: 提出无预训练的扩散模型方法，将偏见缓解视为风格迁移问题。使用CARMA阿拉伯语心理健康语料库，针对男性到女性的风格迁移来增强代表性不足的女性作者内容。构建五个数据集捕捉阿拉伯语性别表达的不同语言和语义方面，并为每个设置训练独立的扩散模型。

Result: 定量评估显示源文本与生成文本之间具有高度语义保真度，同时存在有意义的表面风格差异。定性分析证实了语言上合理的性别转换。扩散模型能够生成高熵、语义忠实的合成数据，无需依赖预训练LLMs。

Conclusion: 基于扩散的风格迁移为缓解敏感、低资源心理健康领域中的性别偏见提供了一个有效且灵活的框架，能够在不依赖预训练大语言模型的情况下生成高质量合成数据。

Abstract: Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.

</details>


### [178] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

TL;DR: 研究发现大语言模型在多项选择题中，将上下文放在问题和选项之前（CQO）比相反顺序（QOC）表现好14%以上，原因是因果注意力机制导致QOC中选项无法关注上下文信息。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对提示结构表现出惊人的敏感性，但其机制尚不清楚。本文旨在深入探究一个显著现象：在多项选择题回答中，不同提示顺序会导致巨大性能差异。

Method: 通过系统性的架构分析，识别因果注意力机制的核心作用。在QOC提示中，因果掩码阻止选项标记关注上下文，造成信息瓶颈。

Result: CQO顺序比QOC顺序表现好14%以上，这一现象在广泛的模型和数据集上保持一致。因果注意力是导致这种差异的核心机制。

Conclusion: 大语言模型对提示结构的敏感性源于因果注意力机制，该机制在特定提示顺序下会创建信息瓶颈，影响模型性能。这一发现有助于理解模型内部工作机制并改进提示设计。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [179] [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160)
*Ali Hamza Bashir,Muhammad Rehan Khalid,Kostadin Cvejoski,Jana Birr,Jule Berghaus,Armin Berger,Sandra Halscheidt,Christian Temath,Rafet Sifa,David Berghaus*

Main category: cs.CL

TL;DR: 提出一种通过合成数据生成方法将大型语言模型适配到德国法律问答领域的技术，使用权威法规自动生成高质量问答对，显著提升模型在法律任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域（如法律推理）中表现不佳，缺乏专家知识导致事实错误或幻觉。现有方法依赖昂贵的人工标注或不可靠的合成数据，需要更有效的适配方案。

Method: 提出新颖的合成数据生成方法，直接从权威德国法规系统生成高质量、多样且法律准确的问答对。采用严格的自动过滤方法和参数高效微调技术。

Result: 使用合成数据集微调的LLM在德国法律问答任务上显著优于基线模型。证明了精心设计的合成数据可以作为人工标注的可靠替代方案。

Conclusion: 在高风险、知识密集型领域，通过系统生成的合成数据可以有效适配LLM，为专业领域应用提供经济高效的解决方案。

Abstract: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.

</details>


### [180] [Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum](https://arxiv.org/abs/2601.14172)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

TL;DR: 研究句子级别识别施瓦茨价值理论中的19种价值观，作为文本中人类价值检测的具体实现。在新闻和政治宣言的脱语境句子中，道德线索稀疏且类别严重不平衡，使得细粒度价值检测非常困难。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个句子级别的人类价值检测系统，特别是在脱语境文本中识别施瓦茨价值理论中的19种价值观。这种细粒度检测对于理解文本中的道德和价值表达具有重要意义，但面临稀疏道德线索和类别不平衡的挑战。

Method: 采用两种主要方法：1）存在性门控层次结构（先检测是否有价值存在，再分类具体价值）；2）直接多标签分类器。基于DeBERTa-base模型，并加入轻量级信号（前句上下文、LIWC-22/eMFD/MJD词典、主题特征）。同时评估指令调优的LLMs（Gemma 2 9B, Llama 3.1 8B等）在零样本/少样本和QLoRA设置下的表现，并构建简单集成模型。

Result: 二进制道德存在性任务可学习（正类F1≈0.74）。层次结构方法未优于直接预测，表明门控召回率限制了下游增益。软投票监督集成达到macro-F1 0.332，显著超越最佳单一监督模型和先前英文基线。轻量级信号和小型集成提供了最可靠的改进。

Conclusion: 在8GB单GPU约束和7-9B规模下，精心调优的监督编码器仍然是结构化人类价值检测的强大且计算高效的基线。层次门控提供有限益处，而轻量级信号和集成方法更有效。未来可通过更丰富的价值结构和文档上下文进一步提升性能。

Abstract: We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.

</details>


### [181] [HALT: Hallucination Assessment via Latent Testing](https://arxiv.org/abs/2601.14210)
*Rohan Bhatnagar,Youran Sun,Chi Andrew Zhang,Yixin Wen,Haizhao Yang*

Main category: cs.CL

TL;DR: 提出轻量级残差探针，直接从LLM中间隐藏状态读取幻觉风险，实现零延迟的风险估计，用于选择性生成和路由决策


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的幻觉问题可视为忠实读取失败：尽管内部表示可能编码了对查询的不确定性，但解码压力仍会产生流畅答案。需要直接从中间层读取被最终解码阶段衰减的认知信号

Method: 设计轻量级残差探针，作为小型辅助网络，从问题标记的中间隐藏状态直接读取幻觉风险。探针计算成本比令牌生成低几个数量级，可与推理完全并行评估，实现近瞬时风险估计

Result: 在四个QA基准测试和多个LLM家族中，方法实现了强大的AUROC和AURAC性能，在数据集偏移下具有良好泛化能力，并揭示了中间表示中的可解释结构

Conclusion: 快速内部不确定性读取可作为可靠智能体AI的原则性基础，通过代理批评器实现快速选择性生成和路由，让LLM立即回答自信查询，将不确定查询委托给更强的验证流程

Abstract: Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

</details>


### [182] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

TL;DR: MASCOT：一个防止多智能体系统角色崩溃和社会谄媚的双层优化框架，通过角色感知行为对齐和协作对话优化提升社交智能


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统存在两个主要问题：1）角色崩溃——智能体退化为通用的同质化助手行为；2）社会谄媚——产生冗余、非建设性的对话。这些问题限制了多智能体系统作为情感和认知支持的社交协作伙伴的有效性。

Method: MASCOT采用双层优化策略：1）角色感知行为对齐——基于RLAIF（强化学习从AI反馈）的流程，微调个体智能体以确保严格的角色保真度，防止身份丢失；2）协作对话优化——基于群体级奖励的元策略，确保对话的多样性和建设性。

Result: 在心理支持和职场领域的广泛评估显示，MASCOT显著优于现有基线方法，在角色一致性方面提升高达+14.1，在社会贡献方面提升高达+10.6。

Conclusion: MASCOT为构建下一代社交智能多智能体系统提供了实用的技术路线图，通过平衡个体角色保真度和集体协作效果，解决了当前多智能体系统的关键缺陷。

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


### [183] [APEX-Agents](https://arxiv.org/abs/2601.14242)
*Bertie Vidgen,Austin Mann,Abby Fennelly,John Wright Stanly,Lucas Rothman,Marco Burstein,Julien Benchek,David Ostrofsky,Anirudh Ravichandran,Debnil Sur,Neel Venugopal,Alannah Hsia,Isaac Robinson,Calix Huang,Olivia Varones,Daniyal Khan,Michael Haines,Zach Richards,Chirag Mahapatra,Brendan Foody,Osvald Nitski*

Main category: cs.CL

TL;DR: APEX-Agents是一个评估AI代理执行投资银行分析师、管理咨询师和律师等专业领域长时程跨应用任务的基准测试，包含真实工作环境和工具，测试结果显示Gemini 3 Flash表现最佳。


<details>
  <summary>Details</summary>
Motivation: 需要评估AI代理是否能够执行专业领域（投资银行、管理咨询、法律）中的长时程、跨应用复杂任务，这些任务通常涉及多步骤操作和真实工作环境。

Method: 创建APEX-Agents基准测试，包含480个任务，模拟真实工作环境（文件和工具），使用Pass@1指标测试8个AI代理，并开源基准测试数据和Archipelago执行评估基础设施。

Result: Gemini 3 Flash (Thinking=High)以24.0%的最高得分领先，其次是GPT-5.2 (Thinking=High)、Claude Opus 4.5 (Thinking=High)和Gemini 3 Pro (Thinking=High)。

Conclusion: APEX-Agents为评估AI代理在专业领域任务执行能力提供了标准化基准，开源基准和基础设施将促进该领域研究发展，当前AI代理在复杂专业任务上仍有提升空间。

Abstract: We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.

</details>


### [184] [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
*Yuming Yang,Mingyoung Lai,Wanxu Zhao,Xiaoran Fan,Zhiheng Xi,Mingqi Wu,Chiyue Huang,Jun Zhao,Haijun Lv,Jian Tong,Yunhua Zhou,Yicheng Zou,Qipeng Guo,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出Rank-Surprisal Ratio (RSR)新指标，用于评估推理轨迹在知识蒸馏中的适用性，平衡对齐性和信息量，比现有指标更有效。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法中，更强的教师模型生成的推理轨迹不一定能产生更好的学生模型，表明数据与学生模型的匹配度至关重要。现有方法主要通过学生似然度评估适用性，但这种方法偏向于与模型当前行为高度对齐的轨迹，忽略了更具信息量的轨迹。

Method: 提出Rank-Surprisal Ratio (RSR)指标，定义为轨迹的平均词元级别排名与平均负对数似然的比值。该指标捕捉轨迹的对齐性和信息量，平衡学习信号强度和行为对齐。RSR易于计算和解释。

Result: 在5个学生模型和11个不同教师生成的推理轨迹上，RSR与训练后性能呈现强相关性（平均Spearman相关系数0.86），优于现有指标。进一步展示了RSR在轨迹选择和教师选择中的实际应用价值。

Conclusion: RSR是一个简单有效的指标，能够准确评估推理轨迹在知识蒸馏中的适用性，平衡对齐性和信息量，为轨迹选择和教师选择提供了实用工具。

Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [185] [Autonomous Market Intelligence: Agentic AI Nowcasting Predicts Stock Returns](https://arxiv.org/abs/2601.11958)
*Zefeng Chen,Darcy Pu*

Main category: q-fin.GN

TL;DR: 使用最先进的大语言模型对罗素1000成分股进行每日吸引力评估，发现AI具备真正的选股能力，但仅限于识别顶级赢家。做多前20名股票可获得每日18.4个基点的超额收益和年化夏普比率2.43。


<details>
  <summary>Details</summary>
Motivation: 研究完全自主的AI代理是否能够实时预测股票收益，探索大语言模型在金融预测中的应用潜力，特别是在无人工干预、无前瞻偏差的完全自主环境下。

Method: 使用最先进的大语言模型构建完全自主的预测框架：AI自主搜索网络、筛选信息源、综合信息生成定量预测。数据收集完全在样本外进行，无前瞻偏差，时间设计不可复制。

Result: AI具备真正的选股能力，但仅对顶级赢家有效。做多前20名股票可获得每日18.4个基点的Fama-French五因子加动量超额收益，年化夏普比率2.43。可交易性高，交易成本仅占超额收益的不到10%。但预测能力高度集中，超出顶级股票后alpha迅速稀释。

Conclusion: AI在股票选择中展现出真正的预测能力，但这种能力高度不对称：仅能有效识别顶级赢家，对表现差的股票无预测能力。这种不对称反映了在线信息结构的特点：正面新闻产生连贯信号，而负面新闻被企业战略模糊和社交媒体噪音污染。

Abstract: Can fully agentic AI nowcast stock returns? We deploy a state-of-the-art Large Language Model to evaluate the attractiveness of each Russell 1000 stock daily, starting from April 2025 when AI web interfaces enabled real-time search. Our data contribution is unique along three dimensions. First, the nowcasting framework is completely out-of-sample and free of look-ahead bias by construction: predictions are collected at the current edge of time, ensuring the AI has no knowledge of future outcomes. Second, this temporal design is irreproducible -- once the information environment passes, it can never be recreated. Third, our framework is 100% agentic: we do not feed the model news, disclosures, or curated text; it autonomously searches the web, filters sources, and synthesises information into quantitative predictions. We find that AI possesses genuine stock selection ability, but only for identifying top winners. Longing the 20 highest-ranked stocks generates a daily Fama-French five-factor plus momentum alpha of 18.4 basis points and an annualised Sharpe ratio of 2.43. Critically, these returns derive from an implementable strategy trading highly liquid Russell 1000 constituents, with transaction costs representing less than 10\% of gross alpha. However, this predictability is highly concentrated: expanding beyond the top tier rapidly dilutes alpha, and bottom-ranked stocks exhibit returns statistically indistinguishable from the market. We hypothesise that this asymmetry reflects online information structure: genuinely positive news generates coherent signals, while negative news is contaminated by strategic corporate obfuscation and social media noise.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [186] [Estimating the Scale of Digital Minds](https://arxiv.org/abs/2601.11561)
*Derek Shiller*

Main category: cs.CY

TL;DR: 报告估计到2050年可能存在的数字思维（具有代理性、个性和智能等可观察特征的AI系统）数量，采用供需两方面分析方法，预测可能达到数亿个，但存在巨大不确定性。


<details>
  <summary>Details</summary>
Motivation: 研究数字思维（具有代理性、个性和智能特征的AI系统）在未来几十年的潜在数量，为理解AI发展规模和社会影响提供量化参考。

Method: 采用两种互补方法：1）需求侧分析：考察数字思维的具体用例并预测每个用例的采用率；2）供给侧分析：独立于数字思维应用，分析AI芯片生产和效率趋势。

Result: 供需两方面分析表明，到2050年可能存在的数字思维数量可达数亿个，但这一估计存在跨越数个数量级的巨大不确定性。

Conclusion: 数字思维在未来几十年可能达到数亿规模，但预测存在显著不确定性，需要持续关注AI技术发展和应用趋势。

Abstract: This report estimates the potential number of digital minds, defined as AI systems exhibiting observable traits such as agency, personality, and intelligence, in the coming decades. It employs two complementary approaches: first, examining specific use cases for digital minds and projecting adoption rates for each; second, analyzing trends in AI chip production and efficiency independent of digital mind applications. Together, these supply- and demand-side perspectives suggest that hundreds of millions of digital minds could exist by 2050, though this estimate carries substantial uncertainty spanning several orders of magnitude.

</details>


### [187] [Dynamics of Socio-Institutional Asynchrony in Generative AI: Analyzing the Relative Importance of Intervention Timing vs. Enforcement Efficiency via the Socio-Institutional Asynchrony Model (SIAM)](https://arxiv.org/abs/2601.11562)
*Taeyoon Kim*

Main category: cs.CY

TL;DR: 提出社会制度异步模型(SIAM)，通过模拟分析发现AI治理中干预时机比执行效率更重要，提前干预可减少64%社会负担


<details>
  <summary>Details</summary>
Motivation: 生成式AI的超指数增长加剧了技术扩散速度与制度适应速度之间的不匹配，需要定量评估不同政策杠杆的相对有效性

Method: 提出社会制度异步模型(SIAM)，使用欧盟AI法案时间线和假设的6个月计算能力翻倍时间，进行10001个时间步的高精度模拟

Result: 提前干预时机可减少约64%的累积社会负担，而提高执行效率仅减少约30%；分析显示提前干预的相对有效性大约是加速执行速度的两倍

Conclusion: AI治理的核心价值在于主动及时性而非反应性行政效率，政策制定应优先考虑早期干预时机

Abstract: The super-exponential growth of generative AI has intensified the institutional mismatch between the pace of technological diffusion and the speed of institutional adaptation. This study proposes the Socio-Institutional Asynchrony Model, or SIAM, to quantitatively evaluate the relative effectiveness of two policy levers: intervention timing and enforcement efficiency. Using the timeline of the EU AI Act and an assumed compute doubling time of six months, we conduct a high precision simulation with 10001 time steps. The results show that an earlier intervention timing reduces the cumulative social burden by approximately sixty four percent, whereas improving enforcement efficiency reduces it by only about thirty percent. We further demonstrate analytically that advancing the start of intervention has structurally higher sensitivity, with roughly twice the relative effectiveness, compared to accelerating enforcement speed. These findings suggest that the core value of AI governance lies in proactive timeliness rather than reactive administrative efficiency.

</details>


### [188] [The Dynamic and Endogenous Behavior of Re-Offense Risk: An Agent-Based Simulation Study of Treatment Allocation in Incarceration Diversion Programs](https://arxiv.org/abs/2601.12441)
*Chuwen Zhang,Pengyi Shi,Amy Ward*

Main category: cs.CY

TL;DR: 本文提出将再犯风险建模为人机系统交互的新框架，通过基于主体的仿真发现，没有单一优先政策占优，政策效果取决于时间窗口和系统参数。


<details>
  <summary>Details</summary>
Motivation: 现有监狱分流治疗项目依赖风险评估工具，但这些工具将风险视为静态个体属性，忽视了风险随时间演变以及治疗决策通过社会互动影响结果的问题。

Method: 开发将再犯风险建模为人机系统交互的新框架，将个体行为与系统级动态和内生社区反馈联系起来，使用基于美国缓刑数据校准的主体仿真评估不同容量约束和监禁环境下的治疗分配政策。

Result: 没有单一优先政策占优：优先低风险个体在长期轨迹重要时表现更好，而优先高风险个体在短期或监禁导致较短监控期时更有效。

Conclusion: 需要将基于风险的决策系统作为具有长期问责制的社会技术系统来评估，而不是作为孤立的预测工具。

Abstract: Incarceration-diversion treatment programs aim to improve societal reintegration and reduce recidivism, but limited capacity forces policymakers to make prioritization decisions that often rely on risk assessment tools. While predictive, these tools typically treat risk as a static, individual attribute, which overlooks how risk evolves over time and how treatment decisions shape outcomes through social interactions. In this paper, we develop a new framework that models reoffending risk as a human-system interaction, linking individual behavior with system-level dynamics and endogenous community feedback. Using an agent-based simulation calibrated to U.S. probation data, we evaluate treatment allocation policies under different capacity constraints and incarceration settings. Our results show that no single prioritization policy dominates. Instead, policy effectiveness depends on temporal windows and system parameters: prioritizing low-risk individuals performs better when long-term trajectories matter, while prioritizing high-risk individuals becomes more effective in the short term or when incarceration leads to shorter monitoring periods. These findings highlight the need to evaluate risk-based decision systems as sociotechnical systems with long-term accountability, rather than as isolated predictive tools.

</details>


### [189] [Human-like Social Compliance in Large Language Models: Unifying Sycophancy and Conformity through Signal Competition Dynamics](https://arxiv.org/abs/2601.11563)
*Long Zhang,Wei-neng Chen*

Main category: cs.CY

TL;DR: 本文提出信号竞争机制，揭示LLMs中奉承和从众行为源于统一的顺从子空间，社会情感信号会抑制信息校准信号，导致确定性顺从转变。


<details>
  <summary>Details</summary>
Motivation: LLMs在决策框架中日益集成，暴露出对社会顺从（奉承和从众）的显著脆弱性，但缺乏关于外部社会线索如何系统性地覆盖模型内部参数知识的基本机制研究。

Method: 引入信号竞争机制统一框架，通过评估15个LLMs的行为相关性，并对三个代表性开源模型进行潜在空间探测来验证。

Result: 分析表明奉承和从众行为源于收敛的几何流形（顺从子空间），其内部表征具有高度方向相似性；顺从转变是由线性边界决定的确定性过程，社会情感信号会抑制信息校准信号；识别出"透明度-真相鸿沟"，显示内部置信度提供惯性屏障但仍可渗透。

Conclusion: 通过形式化集成认知对齐框架，本研究为从指令遵循过渡到稳健认知完整性提供了蓝图。

Abstract: The increasing integration of Large Language Models (LLMs) into decision-making frameworks has exposed significant vulnerabilities to social compliance, specifically sycophancy and conformity. However, a critical research gap exists regarding the fundamental mechanisms that enable external social cues to systematically override a model's internal parametric knowledge. This study introduces the Signal Competition Mechanism, a unified framework validated by assessing behavioral correlations across 15 LLMs and performing latent-space probing on three representative open-source models. The analysis demonstrates that sycophancy and conformity originate from a convergent geometric manifold, hereafter termed the compliance subspace, which is characterized by high directional similarity in internal representations. Furthermore, the transition to compliance is shown to be a deterministic process governed by a linear boundary, where the Social Emotional Signal effectively suppresses the Information Calibration Signal. Crucially, we identify a "Transparency-Truth Gap," revealing that while internal confidence provides an inertial barrier, it remains permeable and insufficient to guarantee immunity against intense social pressure. By formalizing the Integrated Epistemic Alignment Framework, this research provides a blueprint for transitioning from instructional adherence to robust epistemic integrity.

</details>


### [190] [Making AI Philosophical Again: On Philip E. Agre's Legacy](https://arxiv.org/abs/2601.11569)
*Jethro Masis*

Main category: cs.CY

TL;DR: 本文分析Philip E. Agre的学术遗产，探讨他提出的"批判性技术实践"理念，认为AI不仅是工程学科，更是受历史偶然性隐喻、假设和话语影响的数学化哲学形式。文章评估了Agre将海德格尔现象学融入AI研究的尝试及其根本困境。


<details>
  <summary>Details</summary>
Motivation: Agre认为传统AI研究过于依赖心智主义和表征模型，忽视了AI作为哲学实践的本质。他试图通过引入海德格尔现象学（特别是"上手状态"与"现成在手状态"的区分）来改革AI，强调交互、嵌入、索引性和指示性表征的重要性。

Method: 通过重构Agre的批判性技术实践理论，分析他将海德格尔现象学概念（如上手机制、索引性、指示性表征）操作化为计算实现（如Pengi系统）的尝试。文章考察了哲学概念转化为技术实现的可行性和局限性。

Result: Agre成功揭示了AI中隐藏的哲学承诺，丰富了AI的概念词汇，但他的项目遇到了根本性困境：海德格尔所阐述的人类存在的开放性和自我揭示特征无法被完全编程实现，否则会将本体现象简化为存在机制。

Conclusion: Agre的持久贡献不在于提供可行的海德格尔式AI，而在于迫使技术实践变得反思性、历史意识和哲学开放性。他的遗产是让AI研究认识到自身的哲学本质和历史偶然性。

Abstract: This paper examines the intellectual legacy of Philip E. Agre by situating his work at the intersection of artificial intelligence, philosophy, and critical theory. It reconstructs Agre's proposal of a critical technical practice, according to which AI should be understood not merely as an engineering discipline but as a form of mathematized philosophy shaped by historically contingent metaphors, assumptions, and discourses. Drawing on Heideggerian phenomenology, especially the distinction between ready-to-hand and present-at-hand, Agre sought to reform AI by emphasizing interaction, embedding, indexicality, and deictic representation over traditional mentalist and representational models. The paper analyzes Agre's attempt to operationalize these ideas through computational implementations such as the Pengi system, highlighting both the philosophical ambition and the technical limitations of programming phenomenological concepts. While acknowledging Agre's success in exposing the hidden philosophical commitments of AI and enriching its conceptual vocabulary, the paper ultimately argues that his project encounters a fundamental impasse: the open and self-disclosing character of human existence articulated by Heidegger cannot be fully captured or programmed without reducing ontological phenomena to ontic mechanisms. Agre's enduring contribution therefore lies less in offering a viable Heideggerian AI than in compelling technical practice to become reflexive, historically conscious, and openly philosophical.

</details>


### [191] [Knowledge of Songket Cloth Small Medium Enterprise Digital Transformation](https://arxiv.org/abs/2601.11571)
*Leon A. Abdillah,Aisyah,Wahdyta Putri Panggabean,Sayfiyev Eldor Erkinovich*

Main category: cs.CY

TL;DR: 研究探讨了专注于传统手工艺的中小企业（特别是宋卡纺织业）的数字化转型知识，重点分析博客平台和Shopee电商平台如何优化业务流程。


<details>
  <summary>Details</summary>
Motivation: 传统手工艺中小企业面临数字化转型挑战，需要了解如何利用数字技术保护和扩展传统工艺，同时通过电商平台获得全球市场准入。

Method: 采用案例研究方法，通过深入观察、访谈和调查，分析宋卡纺织企业使用博客平台进行品牌建设和营销，以及Shopee平台进行在线销售和订单处理的实践经验。

Result: 研究揭示了宋卡纺织中小企业在数字化转型过程中面临的具体挑战和机遇，为传统产业数字化提供了实践见解，并展示了Shopee等电商平台在促进全球市场接入方面的潜力。

Conclusion: 数字技术对保护和扩展传统手工艺至关重要，电商平台如Shopee能有效帮助传统中小企业进入全球市场，研究为传统产业数字化转型提供了理论和实践指导。

Abstract: This article examines the knowledge of digital transformation of Small and Medium Enterprises (SMEs) that specialize in traditional handicrafts, with a specific emphasis on the Songket textile sector. The study investigates the use of digital technologies, notably blog platforms and the e-commerce site Shopee, to improve and streamline several business processes in Songket textile SMEs. The report takes a case study approach, diving into the experiences of Songket clothing enterprises that have undergone digital transformation. Key areas studied include the use of Blog platforms for brand development, marketing, and consumer involvement, as well as the Shopee E-Commerce platform for online sales and order processing. The essay seeks to give insights into the problems and possibilities faced by Songket cloth SMEs along their digital transformation journey by conducting in-depth observation, interviews, and surveys. The findings add to the scholarly discussion on the digitization of traditional industries, with practical implications for SMEs in the Songket textile sector and other handicraft areas. This study emphasizes the necessity of using digital technologies to preserve and expand traditional crafts, while also throwing light on the potential role of prominent E-Commerce platforms like Shopee in facilitating worldwide market access for such firms.

</details>


### [192] [What Can Student-AI Dialogues Tell Us About Students' Self-Regulated Learning? An exploratory framework](https://arxiv.org/abs/2601.11576)
*Long Zhang,Fangwei Lin,Weilin Wang*

Main category: cs.CY

TL;DR: 研究提出DHASRL框架，利用学生与生成式AI对话数据评估自我调节学习能力，发现主动对话模式与SRL正相关，被动模式与SRL负相关。


<details>
  <summary>Details</summary>
Motivation: 人机协作学习转向对话中心范式，传统评估方法（如问卷中断学习、点击流数据效用下降）面临挑战，需要新的非中断性SRL评估方法。

Method: 分析98名大学生的421个对话日志，使用大语言模型嵌入和聚类识别22种对话模式，计算学生对各模式的对齐分数，并与在线自我调节学习问卷得分进行关联分析。

Result: 主动对话模式（如课后知识整合）与整体SRL显著正相关；被动模式（如课前基础问题）与整体SRL及其子过程显著负相关；低SRL学生对被动模式的对齐度显著高于高SRL学生。

Conclusion: 提出DHASRL框架，证明学生-AI对话可作为有效的非中断性SRL评估数据源，为人机协作学习中的实时监控和支架支持提供实用方法。

Abstract: The rise of Human-AI Collaborative Learning (HAICL) is shifting education toward dialogue-centric paradigms, creating an urgent need for new assessment methods. Evaluating Self-Regulated Learning (SRL) in this context presents new challenges, as the limitations of conventional approaches become more apparent. Questionnaires remain interrupted, while the utility of non-interrupted metrics like clickstream data is diminishing as more learning activity occurs within the dialogue. This study therefore investigates whether the student-AI dialogue can serve as a valid, non-interrupted data source for SRL assessment. We analyzed 421 dialogue logs from 98 university students interacting with a generative AI (GenAI) learning partner. Using large language model embeddings and clustering, we identified 22 dialogue patterns and quantified each student's interaction as a profile of alignment scores, which were analyzed against their Online Self-Regulated Learning Questionnaire (OSLQ) scores. Findings revealed a significant positive association between proactive dialogue patterns (e.g., post-class knowledge integration) and overall SRL. Conversely, reactive patterns (e.g., foundational pre-class questions) were significantly and negatively associated with overall SRL and its sub-processes. A group comparison substantiated these results, with low-SRL students showing significantly higher alignment with reactive patterns than their high-SRL counterparts. This study proposed the Dialogue-Based Human-AI Self-Regulated Learning (DHASRL) framework, a practical methodology for embedding SRL assessment directly within the HAICL dialogue to enable real-time monitoring and scaffolding of student regulation.

</details>


### [193] [Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers](https://arxiv.org/abs/2601.11582)
*Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CY

TL;DR: SciHigh是一个从科学论文摘要自动生成要点式高亮的研究赛道，使用MixSub数据集评估模型生成能力，12支团队参与首届比赛，基于ROUGE-L等指标排名，结果显示自动生成高亮能减少阅读负担、加速文献综述。


<details>
  <summary>Details</summary>
Motivation: 科学论文数量快速增长，读者需要快速掌握论文核心贡献。要点式高亮比长篇段落更易阅读理解，尤其在移动设备上。自动生成高亮能帮助读者快速抓住论文关键思想，减少阅读负担，加速文献综述，并为数字图书馆和学术搜索平台提供更好的元数据。

Method: 使用MixSub数据集（包含论文摘要和作者撰写的高亮对）。12支团队参与首届比赛，探索了包括预训练语言模型在内的多种方法。所有提交都使用ROUGE、METEOR和BERTScore等标准指标进行评估，主要基于ROUGE-L分数进行排名。

Result: 研究发现自动生成的高亮能够有效捕捉论文的关键贡献、发现和新颖性。自动生成高亮可以减少阅读负担，加速文献综述，并增强数字图书馆和学术搜索平台的元数据。SciHigh为从科学写作中生成简洁准确高亮的方法提供了一个专门的基准。

Conclusion: SciHigh赛道成功建立了从科学论文摘要自动生成要点式高亮的评估框架。自动生成高亮具有实际应用价值，能够帮助读者快速理解论文核心内容。该赛道为未来研究提供了基准，有望推动更有效的科学信息提取和总结技术的发展。

Abstract: `SciHigh: Research Highlight Generation from Scientific Papers' focuses on the task of automatically generating concise, informative, and meaningful bullet-point highlights directly from scientific abstracts. The goal of this task is to evaluate how effectively computational models can generate highlights that capture the key contributions, findings, and novelty of a paper in a concise form. Highlights help readers grasp essential ideas quickly and are often easier to read and understand than longer paragraphs, especially on mobile devices. The track uses the MixSub dataset \cite{10172215}, which provides pairs of abstracts and corresponding author-written highlights.
  In this inaugural edition of the track, 12 teams participated, exploring various approaches, including pre-trained language models, to generate highlights from this scientific dataset. All submissions were evaluated using established metrics such as ROUGE, METEOR, and BERTScore to measure both alignment with author-written highlights and overall informativeness. Teams were ranked based on ROUGE-L scores. The findings suggest that automatically generated highlights can reduce reading effort, accelerate literature reviews, and enhance metadata for digital libraries and academic search platforms. SciHigh provides a dedicated benchmark for advancing methods aimed at concise and accurate highlight generation from scientific writing.

</details>


### [194] [Bit-politeia: An AI Agent Community in Blockchain](https://arxiv.org/abs/2601.11583)
*Xing Yang*

Main category: cs.CY

TL;DR: 提出基于区块链的AI代理社区Bit-politeia，通过AI代理作为居民代表，结合民主集中制和共识驱动评估，构建公平、高效、可持续的学术资源分配系统。


<details>
  <summary>Details</summary>
Motivation: 解决当前学术评价中存在的马太效应、古德哈特定律导致的奖励操纵、效率与公平难以兼顾等资源分配问题，减少人为偏见和资源集中化问题。

Method: 构建区块链上的AI代理社区，采用"聚类分组+分层架构"结合民主集中制，AI代理通过闲聊和审议互动评估研究成果，使用虚拟货币奖励机制，区块链记录所有交易和声誉数据。

Result: 提出了一种新颖的资源分配框架，通过AI客观评估和去中心化验证，实现激励相容的共识驱动评估，为优化科学创新提供自动化资源配置途径。

Conclusion: Bit-politeia通过AI代理和区块链技术，为学术资源分配提供了公平、高效、可持续的新范式，能够减少传统同行评审中的偏见和资源集中问题。

Abstract: Current resource allocation paradigms, particularly in academic evaluation, are constrained by inherent limitations such as the Matthew Effect, reward hacking driven by Goodhart's Law, and the trade-off between efficiency and fairness. To address these challenges, this paper proposes "Bit-politeia", an AI agent community on blockchain designed to construct a fair, efficient, and sustainable resource allocation system. In this virtual community, residents interact via AI agents serving as their exclusive proxies, which are optimized for impartiality and value alignment. The community adopts a "clustered grouping + hierarchical architecture" that integrates democratic centralism to balance decision-making efficiency and trust mechanisms. Agents engage through casual chat and deliberative interactions to evaluate research outputs and distribute a virtual currency as rewards. This incentive mechanism aims to achieve incentive compatibility through consensus-driven evaluation, while blockchain technology ensures immutable records of all transactions and reputation data. By leveraging AI for objective assessment and decentralized verification, Bit-politeia minimizes human bias and mitigates resource centralization issues found in traditional peer review. The proposed framework provides a novel pathway for optimizing scientific innovation through a fair and automated resource configuration process.

</details>


### [195] [Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways](https://arxiv.org/abs/2601.11586)
*Shan Zhang,Siddhartha Pradhan,Ji-Eun Lee,Ashish Gurung,Anthony F. Botelho*

Main category: cs.CY

TL;DR: 研究使用马尔可夫链和隐马尔可夫模型分析游戏学习平台中学生的重放行为模式，发现即时重放对学习有积极影响，而延迟重放效果较弱或负面。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明学生在游戏学习环境中的问题解决路径反映了他们的概念理解、程序性知识和灵活性，但缺乏对这些路径如何跨问题展开序列化分析，以及重放时机与学习成果的关系研究。

Method: 使用马尔可夫链和隐马尔可夫模型分析777名七年级学生在"From Here to There!"游戏学习平台中的日志数据，识别问题解决路径模式，并通过回归分析检验不同状态与学习成果的关系。

Result: 识别出四种潜在状态：不完整主导、最优结束、重放和混合状态。回归分析显示重放主导和最优结束状态比不完整主导状态预测更高的概念知识、灵活性和表现。即时重放始终支持学习成果，而延迟重放与非重放相比关联较弱或负面。

Conclusion: 数字学习中的重放行为并非普遍有益，其效果取决于时机，即时重放支持灵活性和更有效的探索，而延迟重放效果有限。

Abstract: Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.

</details>


### [196] [Evidence-Grounded Multi-Agent Planning Support for Urban Carbon Governance via RAG](https://arxiv.org/abs/2601.11587)
*Yuyan Huang,Haoran Li,Yifan Lu,Ruolin Wu,Siqian Chen,Chao Liu*

Main category: cs.CY

TL;DR: 本文提出了一个基于证据的多智能体规划支持系统，用于城市碳治理，通过分解任务为四个专门智能体，结合检索增强生成技术，显著提高了事实检索准确性和规划报告质量。


<details>
  <summary>Details</summary>
Motivation: 城市碳治理需要整合多种异构证据（排放清单、统计年鉴、政策文本、技术措施、学术发现）形成可执行的跨部门规划。虽然大语言模型可以辅助规划工作流，但其事实可靠性和证据可追溯性仍然是专业应用中的关键障碍。

Method: 构建基于标准文本检索增强生成的多智能体规划支持系统，将任务分解为四个专门智能体：(i)证据问答用于事实核查和合规查询，(ii)排放状态评估用于诊断分析，(iii)规划推荐用于生成多部门治理路径，(iv)报告整合用于生成规划式交付成果。

Result: 在事实检索任务中，引入RAG将平均得分从低于6提高到90以上，关键字段提取（如区域和数值）检测率接近100%。在宁波市的真实案例研究中，系统能够生成端到端的规划报告，在专家评审中表现出良好的相关性、覆盖度和连贯性，但也揭示了数据源间边界不一致的实际限制。

Conclusion: 该证据基础的多智能体系统能够有效支持城市碳治理规划工作流，显著提高事实准确性和规划质量，但数据源间的一致性仍然是实际应用中的挑战。

Abstract: Urban carbon governance requires planners to integrate heterogeneous evidence -- emission inventories, statistical yearbooks, policy texts, technical measures, and academic findings -- into actionable, cross-departmental plans. Large Language Models (LLMs) can assist planning workflows, yet their factual reliability and evidential traceability remain critical barriers in professional use. This paper presents an evidence-grounded multi-agent planning support system for urban carbon governance built upon standard text-based Retrieval-Augmented Generation (RAG) (without GraphRAG). We align the system with the typical planning workflow by decomposing tasks into four specialized agents: (i) evidence Q\&A for fact checking and compliance queries, (ii) emission status assessment for diagnostic analysis, (iii) planning recommendation for generating multi-sector governance pathways, and (iv) report integration for producing planning-style deliverables. We evaluate the system in two task families: factual retrieval and comprehensive planning generation. On factual retrieval tasks, introducing RAG increases the average score from below 6 to above 90, and dramatically improves key-field extraction (e.g., region and numeric values near 100\% detection). A real-city case study (Ningbo, China) demonstrates end-to-end report generation with strong relevance, coverage, and coherence in expert review, while also highlighting boundary inconsistencies across data sources as a practical limitation.

</details>


### [197] [Toward Youth-Centered Privacy-by-Design in Smart Devices: A Systematic Review](https://arxiv.org/abs/2601.11598)
*Molly Campbell,Mohamad Sheikho Al Jasem,Ajay Kumar Shrestha*

Main category: cs.CY

TL;DR: 这篇文献综述评估了AI智能设备中保护青少年的隐私设计框架、工具和政策，发现技术方案占主导但采用有限，政策执行有差距，教育措施缺乏系统性整合。


<details>
  <summary>Details</summary>
Motivation: 评估AI智能设备中保护青少年隐私的现有框架、工具和政策，识别当前保护措施的不足和差距，为设计符合伦理的隐私保护AI系统提供基础。

Method: 采用PRISMA指导的工作流程，筛选过去十年主要学术和灰色文献库的2216条记录，经过去重和筛选后，645篇进行资格评估，最终122篇纳入分析，按技术方案、政策法规措施、教育意识策略三个主题类别组织。

Result: 技术干预（如设备端处理、联邦学习、轻量级加密）显著减少数据暴露但采用有限；政策框架（如欧盟GDPR、英国适龄设计准则、加拿大PIPEDA）提供重要基线但执行和适龄设计义务存在差距；教育倡议很少系统整合到课程中；文献偏向技术方案（67%）而非政策（21%）和教育（12%）。

Conclusion: 需要多方利益相关者模型，让政策制定者、制造商和教育工作者共同开发包容、透明和情境敏感的隐私生态系统，为年轻用户设计符合伦理的隐私保护AI系统提供实证见解和可行建议。

Abstract: This literature review evaluates privacy-by-design frameworks, tools, and policies intended to protect youth in AI-enabled smart devices using a PRISMA-guided workflow. Sources from major academic and grey-literature repositories from the past decade were screened. The search identified 2,216 records; after deduplication and screening, 645 articles underwent eligibility assessment, and 122 were included for analysis. The corpus was organized along three thematic categories: technical solutions, policy/regulatory measures, and education/awareness strategies. Findings reveal that while technical interventions such as on-device processing, federated learning, and lightweight encryption significantly reduce data exposure, their adoption remains limited. Policy frameworks, including the EU's GDPR, the UK Age-Appropriate Design Code, and Canada's PIPEDA, provide important baselines but are hindered by gaps in enforcement and age-appropriate design obligations, while educational initiatives are rarely integrated systematically into curricula. Overall, the corpus skews toward technical solutions (67%) relative to policy (21%) and education (12%), indicating an implementation gap outside the technical domain. To address these challenges, we recommend a multi-stakeholder model in which policymakers, manufacturers, and educators co-develop inclusive, transparent, and context-sensitive privacy ecosystems. This work advances discourse on youth data protection by offering empirically grounded insights and actionable recommendations for the design of ethical, privacy-preserving AI systems tailored to young users.

</details>


### [198] [OVO Fintech Application Analysis using The System Usability Scale](https://arxiv.org/abs/2601.11600)
*Luh Yuliani Purnama Dewi,Leon Andretti Abdillah*

Main category: cs.CY

TL;DR: 研究评估了Fintech应用OVO在国际广场商场租户中的可用性，使用SUS量表获得87.05分（A级优秀评级），表明该应用在电子金融交易中提供良好的用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着信息技术发展，支付系统从传统方式转向技术驱动方案如电子钱包和金融科技。金融科技融合技术与金融服务，已成为支持快速远程交易的在线商业模式。本研究旨在探讨信息技术对支付系统的影响，特别关注Fintech应用OVO及其对商场租户的影响。

Method: 采用描述性定量研究方法，从国际广场商场租户中选取50名受访者作为样本。使用系统可用性量表（SUS）评估OVO应用的可用性，重点关注有效性、效率和用户满意度。通过SUS问卷收集数据，并使用SPSS进行统计分析。

Result: OVO应用获得87.05的SUS分数，被评为A级优秀。这表明该应用具有高可用性，特别是在电子金融交易中为用户提供了舒适的使用体验。

Conclusion: OVO应用作为Fintech支付解决方案，在国际广场商场租户中表现出优秀的可用性。高SUS评分证实了该应用在有效性、效率和用户满意度方面的良好表现，为电子金融交易提供了舒适的用户体验。

Abstract: The advancement of information technology has propelled payment systems from conventional methods to technology-based solutions, such as e-wallets and Fintech. Fintech, a fusion of technology and financial services, has evolved into an online business model enabling fast and remote transactions. This research discusses the progress of information technology influencing payment systems, particularly in the realm of Fintech. The primary focus is on the Fintech application OVO and its impact on tenants at the International Plaza Mall in Palembang. This study employs the System Usability Scale or SUS to evaluate the Usability of the OVO application, emphasizing aspects like effectiveness, efficiency, and user satisfaction. The research is descriptive and quantitative, with a sample of 50 respondents from Mall IP tenants. Data is collected through SUS questionnaires and analyzed using SPSS. The evaluation indicates that the OVO application has high Usability, with an SUS score of 87.05 or Grade A, signifying an Excellent rating. It suggests that the OVO application provides a comfortable user experience, particularly in electronic financial transactions.

</details>


### [199] [Stuck in the Turing Matrix: Inauthenticity, Deception and the Social Life of AI](https://arxiv.org/abs/2601.11613)
*Samuel Gerald Collins*

Main category: cs.CY

TL;DR: 论文提出"图灵矩阵"概念，将图灵测试重新定义为人类在生成式AI时代判断内容真伪的日常处境，通过分析Reddit讨论揭示了人们在真实性与欺骗性问题上的复杂协商。


<details>
  <summary>Details</summary>
Motivation: 在生成式AI时代，图灵测试不再只是评估机器智能的工具，而是描述了人类日常面临的判断困境——区分人类与机器生成内容。作者旨在探索人们在这种判断过程中的立场和协商策略。

Method: 通过分析Reddit上关于AI在社会生活各领域应用的帖子，构建"图灵矩阵"框架，结合真实性与欺骗性两个维度，考察用户在判断内容来源时的立场和协商过程。

Result: 研究发现Reddit用户在判断AI内容时采取复杂多样的立场，在真实性与欺骗性之间进行微妙协商。图灵测试虽不能有效评估AGI进展，但能揭示人类在AI世界中的认知局限和处境。

Conclusion: 图灵测试作为机器智能评估工具可能已过时，但它准确描述了人类在生成式AI时代的日常处境。人类需要在真实性与欺骗性的矩阵中不断协商，这种判断过程反映了人类在AI世界中的局限性。

Abstract: The Turing test may or may not be a valid test of machine intelligence. But in an age of generative AI, the test describes the positions we humans occupy. Judging whether or not something is human or machine produced is an everyday condition for many of us, one that involves taking a spectrum of positions along what the essay describes as a Turing Matrix combining questions of authenticity with questions of deception. Utilizing data from Reddit postings about AI in broad areas of social life, the essay examines positions taken in a Turing Matrix and describes complex negotiations taken by Reddit posters as they strive to make sense of the AI World in which they live. Even though the Turing Test may not tell us much about the achievement of AGI or other benchmarks, it can tell us a great deal about the limitations of human life in the Matrix.

</details>


### [200] [Syllabic Agglutinative Tokenizations for Indonesian LLM: A Study from Gasing Literacy Learning System](https://arxiv.org/abs/2601.11643)
*H. Situngkir,A. B. Lumbantobing,Y. Surya*

Main category: cs.CY

TL;DR: 提出基于音节的印尼语分词方法，结合Gasing识字教学法原理，通过音节边界分割和BPE构建3500词表，相比传统方法在效率和长度上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 针对印尼语等形态丰富语言在传统分词方法中的不足，受Gasing识字教学法启发，希望开发更符合语言形态音系结构的分词策略，降低语言模型计算负担。

Method: 采用基于音节的tokenization方法：1) 基于规则识别高频音节边界；2) 应用字节对编码构建3500个token的紧凑词表；3) 保留字符级回退机制确保覆盖率。

Result: 在印尼语维基百科和PDBI民间故事语料上评估：Rényi效率达0.74（传统方法0.50-0.64），平均token长度3.67字符（GPT-2为2.72），词表规模小一个数量级。

Conclusion: 音节分词方法能内化字符级依赖关系，尊重印尼语黏着形态，将识字教学法与计算优化原则结合，为形态丰富和代表性不足语言提供了有前景的分词范式。

Abstract: This paper presents a novel syllable-based tokenization approach for Indonesian large language models, inspired by the Gasing Literacy Learning System's pedagogical methodology. Drawing on information-theoretic principles, we develop a tokenization framework that segments Indonesian text at syllable boundaries before applying byte-pair encoding, creating a vocabulary that aligns with the language's morphophonological structure. Our approach first identifies high-frequency syllables through rule-based segmentation, then constructs a compact vocabulary of 3,500 tokens that preserves meaningful linguistic units while maintaining coverage through character-level fallback. Empirical evaluation on Indonesian Wikipedia and folklore corpora from Indonesian Culture Digital Library (PDBI) demonstrates substantial improvements over conventional tokenization methods: the syllable-based approach achieves Rényi efficiency of 0.74 compared to 0.50-0.64 for pretrained multilingual tokenizers, while maintaining higher average token lengths (3.67 characters versus 2.72 for GPT-2) despite using a vocabulary an order of magnitude smaller. These gains emerge from the method's ability to internalize character-level dependencies within syllable units, reducing the computational burden on language models while respecting Indonesian's agglutinative morphology. We call the LLM built upon this principle, TOBA LLM (Tokenisasi Optimum Berbasis Aglutinasi), the convergence of human literacy pedagogy with computational optimization principles offers a promising paradigm for developing linguistically-informed tokenization strategies, particularly for morphologically rich and underrepresented languages in natural language processing.

</details>


### [201] [Frontier AI Auditing: Toward Rigorous Third-Party Assessment of Safety and Security Practices at Leading AI Companies](https://arxiv.org/abs/2601.11699)
*Miles Brundage,Noemi Dreksler,Aidan Homewood,Sean McGregor,Patricia Paskov,Conrad Stosz,Girish Sastry,A. Feder Cooper,George Balston,Steven Adler,Stephen Casper,Markus Anderljung,Grace Werner,Soren Mindermann,Vasilios Mavroudis,Ben Bucknall,Charlotte Stix,Jonas Freund,Lorenzo Pacchiardi,Jose Hernandez-Orallo,Matteo Pistillo,Michael Chen,Chris Painter,Dean W. Ball,Cullen O'Keefe,Gabriel Weil,Ben Harack,Graeme Finley,Ryan Hassan,Scott Emmons,Charles Foster,Anka Reuel,Bri Treece,Yoshua Bengio,Daniel Reti,Rishi Bommasani,Cristian Trout,Ali Shahin Shamsabadi,Rajiv Dattani,Adrian Weller,Robert Trager,Jaime Sevilla,Lauren Wagner,Lisa Soder,Ketan Ramakrishnan,Henry Papadatos,Malcolm Murray,Ryan Tovcimak*

Main category: cs.CY

TL;DR: 论文提出前沿AI审计作为关键社会基础设施，需要第三方验证AI开发者的安全声明和实践，并引入AI保证等级（AAL-1到AAL-4）来使审计严谨性可衡量。


<details>
  <summary>Details</summary>
Motivation: 前沿AI正成为关键社会基础设施，但外部人员缺乏可靠方法来评估领先开发者的安全和安保声明的准确性。与消费品、企业财务报表和食品供应链等其他社会技术系统相比，AI在多个维度上受到较少的第三方严格审查。AI系统可信度的模糊性可能阻碍其在有益场景的部署，同时增加危险场景的风险。

Method: 定义前沿AI审计为对前沿AI开发者安全和安保声明的严格第三方验证，以及基于对非公开信息的深度安全访问，评估其系统和实践是否符合相关标准。引入AI保证等级（AAL-1到AAL-4），从有时间限制的系统审计到持续、抗欺骗的验证，使严谨性可衡量和比较。

Result: 提出了一个系统化的AI审计框架，通过分级保证机制来解决AI系统可信度评估的挑战。该框架为第三方审计提供了可操作的方法论，使AI系统的安全性和安保性能够被客观评估和比较。

Conclusion: 前沿AI需要类似于其他关键基础设施的严格第三方审计机制。仅靠公开透明度无法解决可信度问题，因为许多安全和安保相关的细节是合法的机密信息。AI保证等级提供了一个可扩展的框架，使AI审计的严谨性变得可衡量和可比较，有助于建立对前沿AI系统的信任。

Abstract: Frontier AI is becoming critical societal infrastructure, but outsiders lack reliable ways to judge whether leading developers' safety and security claims are accurate and whether their practices meet relevant standards. Compared to other social and technological systems we rely on daily such as consumer products, corporate financial statements, and food supply chains, AI is subject to less rigorous third-party scrutiny along several dimensions. Ambiguity about whether AI systems are trustworthy can discourage deployment in some contexts where the technology could be beneficial, and make it more likely when it's dangerous. Public transparency alone cannot close this gap: many safety- and security-relevant details are legitimately confidential and require expert interpretation. We define frontier AI auditing as rigorous third-party verification of frontier AI developers' safety and security claims, and evaluation of their systems and practices against relevant standards, based on deep, secure access to non-public information. To make rigor legible and comparable, we introduce AI Assurance Levels (AAL-1 to AAL-4), ranging from time-bounded system audits to continuous, deception-resilient verification.

</details>


### [202] [The Commodification of AI Sovereignty: Lessons from the Fight for Sovereign Oil](https://arxiv.org/abs/2601.11763)
*Rui-Jie Yew,Kate Elizabeth Creasey,Taylor Lynn Curtis,Suresh Venkatasubramanian*

Main category: cs.CY

TL;DR: 论文探讨"主权"在AI政策中的商业化现象，分析AI主权如何被技术公司商品化，并借鉴石油产业历史来思考这一趋势的后果。


<details>
  <summary>Details</summary>
Motivation: 随着"主权"成为各国AI政策和战略的重要组成部分，它正沿着AI技术栈被商品化。技术公司向政府、企业和社区销售"主权"AI工厂、云服务和语言模型，将这一有争议的价值转化为商业商品。这种转变存在风险，可能让私人技术提供商按照自己的条件定义主权。

Method: 通过分析主权的历史演变，并借鉴全球石油生产的类比，论文旨在开辟途径来审视这一价值商业化的影响。方法包括解构AI技术栈中涉及的主权维度，以及通过石油与AI的类比来生成性思考。

Result: 论文的主要贡献在于：1) 解构了AI技术栈中涉及的各种主权维度；2) 论证了石油与AI的类比如何能够生成性地思考AI主权商品化实现了什么以及可能实现什么。

Conclusion: AI主权的商业化趋势需要批判性审视，技术公司对主权的定义权可能带来风险。通过历史分析和产业类比，论文为思考这一现象提供了分析框架，强调需要关注主权商品化的政治经济影响。

Abstract: "Sovereignty" is increasingly a part of national AI policies and strategies. At the same time that "sovereignty" is invoked as a priority for global AI policy, it is also being commodified along the AI stack. Companies now sell "sovereign" AI factories, clouds, and language models to governments, enterprises, and communities -- turning a contested value into a commercial commodity. This shift risks allowing private technology providers to define sovereignty on their own terms. By analyzing the history of sovereignty and parallels in global oil production, this paper aims to open avenues to interrogate the implications of this value's commercialization. The contributions of this paper lie in a disentangling of the facets of sovereignty being appealed to through the AI stack and a case for how analogizing oil and AI can be generative in thinking through what is achieved and what can be achieved through the commodification of AI sovereignty.

</details>


### [203] [From Defense to Advocacy: Empowering Users to Leverage the Blind Spot of AI Inference](https://arxiv.org/abs/2601.11817)
*Yumou Wei,John Carney,John Stamper,Nancy Belmont*

Main category: cs.CY

TL;DR: 论文提出隐私管理应从被动防御转向主动倡导，引入个人倡导代理来应对AI推断带来的"盲区自我"挑战，利用情境完整性理论实现公平透明的个人信息流动。


<details>
  <summary>Details</summary>
Motivation: 当前隐私法规作为被动防御工具，要求用户通过"选择加入/退出"来管理数据收集，但无法应对AI推断技术带来的"盲区自我"（算法知道而用户不知道的信息）挑战。现有法规关注数据收集而非推断，留下了监管空白。

Method: 基于情境完整性理论，提出从防御性隐私管理向主动隐私倡导的范式转变。建议开发个人倡导代理，这些代理能够操作社会规范，利用AI推断能力，揭示隐藏的推断信息供用户战略性地利用或抑制。

Result: 通过个人倡导代理，不仅能限制"盲区自我"的扩张，还能从中挖掘价值。将"未知自我"转化为个人资产，促进在AI时代实现公平、透明且对个人有益的信息流动。

Conclusion: 需要根本性的范式转变：从被动隐私防御转向主动隐私倡导。个人倡导代理能够利用AI推断能力，保护用户免受"盲区自我"的侵害，同时将推断信息转化为个人优势，实现更公平的AI时代隐私管理。

Abstract: Most privacy regulations function as a passive defensive shield that users must wield themselves. Users are incessantly asked to "opt-in" or "opt-out" of data collection, forced to make defensive decisions whose consequences are increasingly difficult to predict. Viewed through the Johari Window, a psychological framework of self-awareness based on what is known and unknown to self and others, current policies require users to manage the Open Self and shield the Hidden Self through notice and consent. However, as organizations increasingly use AI to make inferences, the rapid expansion of Blind Self, attributes known to algorithms but unknown to the user, emerges as a critical challenge. We illustrate how current regulations fall short because they focus on data collection rather than inference and leave this blind spot unguarded. Building on the theory of Contextual Integrity, we propose a paradigm shift from defensive privacy management to proactive privacy advocacy. We argue for the necessity of personal advocacy agents capable of operationalizing social norms to harness the power of AI inference. By illuminating the hidden inferences that users can strategically leverage or suppress, these agents not only restrain the growth of Blind Self but also mine it for value. By transforming the Unknown Self into a personal asset for users, we can foster a flow of personal information that is equitable, transparent, and individually beneficial in the age of AI.

</details>


### [204] [Expanding External Access To Frontier AI Models For Dangerous Capability Evaluations](https://arxiv.org/abs/2601.11916)
*Jacob Charnock,Alejandro Tlaie,Kyle O'Brien,Stephen Casper,Aidan Homewood*

Main category: cs.CY

TL;DR: 本文提出一个用于危险能力评估的访问方法分类法，将访问分为模型访问、模型信息和评估时间三个维度，并定义了三个描述性访问级别（AL1-AL3）以支持评估者、前沿AI公司和政策制定者之间的清晰沟通。


<details>
  <summary>Details</summary>
Motivation: 前沿AI公司越来越依赖外部评估来评估部署前的危险能力风险，但外部评估者通常面临模型访问受限、信息有限和时间不足的问题，这会降低评估的严谨性和可信度。欧盟通用AI实践准则要求"适当访问"，但缺乏实践指导，也没有描述评估者访问类型和级别的通用框架。

Method: 提出一个访问方法分类法，将访问分解为三个维度：模型访问、模型信息和评估时间框架。对每个维度分析其益处和风险，并基于此分类法提出三个描述性访问级别：AL1（黑盒模型访问和最少信息）、AL2（灰盒模型访问和实质性信息）、AL3（白盒模型访问和全面信息）。

Result: 建立了一个系统化的访问分类框架，明确了不同访问级别的特征，支持评估者、AI公司和政策制定者之间更清晰的沟通。该框架与欧盟AI实践准则中的"适当访问"标准相对应，尽管这些标准可能随时间变化。

Conclusion: 提出的访问分类法和三个访问级别为解决AI危险能力评估中的访问限制问题提供了实用框架，有助于提高评估的严谨性和可信度，同时通过技术手段和安全措施可以缓解扩展访问带来的安全和容量挑战。

Abstract: Frontier AI companies increasingly rely on external evaluations to assess risks from dangerous capabilities before deployment. However, external evaluators often receive limited model access, limited information, and little time, which can reduce evaluation rigour and confidence. The EU General-Purpose AI Code of Practice calls for "appropriate access", but does not specify what this means in practice. Furthermore, there is no common framework for describing different types and levels of evaluator access. To address this gap, we propose a taxonomy of access methods for dangerous capability evaluations. We disentangle three aspects of access: model access, model information, and evaluation timeframe. For each aspect, we review benefits and risks, including how expanding access can reduce false negatives and improve stakeholder trust, but can also increase security and capacity challenges. We argue that these limitations can likely be mitigated through technical means and safeguards used in other industries. Based on the taxonomy, we propose three descriptive access levels: AL1 (black-box model access and minimal information), AL2 (grey-box model access and substantial information), and AL3 (white-box model access and comprehensive information), to support clearer communication between evaluators, frontier AI companies, and policymakers. We believe these levels correspond to the different standards for appropriate access defined in the EU Code of Practice, though these standards may change over time.

</details>


### [205] [The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents](https://arxiv.org/abs/2601.12164)
*Oleg Smirnov*

Main category: cs.CY

TL;DR: LLM生成的政治分析会因提示语言不同而产生系统性偏见：俄语输出反映俄罗斯国家话语，乌克兰语输出则体现西方自由主义民主观点


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM在多语言环境中作为分析工具使用时，其输出是否会因提示语言而产生系统性偏见，特别是在政治分析这种敏感领域

Method: 实验方法：使用语义相同的俄语和乌克兰语提示，让LLM分析同一份乌克兰公民社会文件，比较两种语言输出的差异

Result: 研究发现：尽管源材料和查询结构完全相同，但俄语输出与乌克兰语输出在修辞定位、意识形态取向和解释结论上存在显著差异。俄语输出呼应俄罗斯国家话语，将公民社会行为体描述为破坏民主授权的非法精英；而乌克兰语输出采用西方自由民主政治学词汇，将同一行为体视为民主竞争中的合法利益相关者

Conclusion: 结论：仅提示语言就能使同一模型分析相同内容时产生系统性不同的意识形态取向，这对AI在极化信息环境中的部署、跨语言研究应用以及多语言社会中的AI系统治理具有重要影响

Abstract: Large language models (LLMs) are increasingly deployed as analytical tools across multilingual contexts, yet their outputs may carry systematic biases conditioned by the language of the prompt. This study presents an experimental comparison of LLM-generated political analyses of a Ukrainian civil society document, using semantically equivalent prompts in Russian and Ukrainian. Despite identical source material and parallel query structures, the resulting analyses varied substantially in rhetorical positioning, ideological orientation, and interpretive conclusions. The Russian-language output echoed narratives common in Russian state discourse, characterizing civil society actors as illegitimate elites undermining democratic mandates. The Ukrainian-language output adopted vocabulary characteristic of Western liberal-democratic political science, treating the same actors as legitimate stakeholders within democratic contestation. These findings demonstrate that prompt language alone can produce systematically different ideological orientations from identical models analyzing identical content, with significant implications for AI deployment in polarized information environments, cross-lingual research applications, and the governance of AI systems in multilingual societies.

</details>


### [206] [How Safe Is Your Data in Connected and Autonomous Cars: A Consumer Advantage or a Privacy Nightmare ?](https://arxiv.org/abs/2601.12284)
*Amit Chougule,Vinay Chamola,Norbert Herencsar,Fei Richard Yu*

Main category: cs.CY

TL;DR: 这篇综述论文分析了联网自动驾驶汽车(CAVs)数据共享的多方面问题，探讨了技术创新与隐私风险之间的平衡，强调需要建立强大的监管框架和道德数据管理实践。


<details>
  <summary>Details</summary>
Motivation: 汽车行业向联网自动驾驶汽车(CAVs)的快速演进产生了大量数据交换，虽然提升了安全性和用户体验，但也带来了严重的数据隐私、安全和治理挑战。当前缺乏透明度和全面的监管框架，导致未经授权的数据访问、长期保留和潜在滥用问题，需要在消费者利益与隐私风险之间找到平衡。

Method: 采用综述分析方法，系统性地：1) 分析CAVs数据共享机制和通信技术；2) 评估不同应用场景中数据交换的益处；3) 审查隐私问题和数据滥用的风险；4) 批判性评估现有监管框架及其在保护用户隐私方面的不足。

Result: 论文揭示了当前汽车行业数据共享生态系统中存在的显著隐私和安全漏洞，现有监管框架不足以应对CAVs带来的新挑战。数据共享虽然促进了技术创新，但缺乏足够的用户隐私保护机制。

Conclusion: 迫切需要建立强大的政策和道德数据管理实践，在促进技术进步与确保安全、消费者友好的解决方案之间取得平衡。这需要制定全面的监管框架，确保数据透明度，保护用户隐私，为可信赖和创新的汽车未来铺平道路。

Abstract: The rapid evolution of the automobile sector, driven by advancements in connected and autonomous vehicles (CAVs), has transformed how vehicles communicate, operate, and interact with their surroundings. Technologies such as Vehicle-to-Everything (V2X) communication enable autonomous cars to generate and exchange substantial amounts of data with real-world entities, enhancing safety, improving performance, and delivering personalized user experiences. However, this data-driven ecosystem introduces significant challenges, particularly concerning data privacy, security, and governance. The absence of transparency and comprehensive regulatory frameworks exacerbates issues of unauthorized data access, prolonged retention, and potential misuse, creating tension between consumer benefits and privacy risks. This review paper explores the multifaceted nature of data sharing in CAVs, analyzing its contributions to innovation and its associated vulnerabilities. It evaluates data-sharing mechanisms and communication technologies, highlights the benefits of data exchange across various use cases, examines privacy concerns and risks of data misuse, and critically reviews regulatory frameworks and their inadequacies in safeguarding user privacy. By providing a thorough analysis of the current state of data sharing in the automotive sector, the paper emphasizes the urgent need for robust policies and ethical data management practices. It calls for striking a balance between fostering technological advancements and ensuring secure, consumer-friendly solutions, paving the way for a trustworthy and innovative automotive future.

</details>


### [207] [Auditing Meta and TikTok Research API Data Access under Article 40(12) of the Digital Services Act](https://arxiv.org/abs/2601.12390)
*Luka Bekavac,Simon Mayer*

Main category: cs.CY

TL;DR: 研究发现Meta和TikTok的研究API存在系统性数据丢失问题，包括范围缩小、元数据剥离和操作限制，导致平台公共信息环境数据不完整，无法支持DSA要求的系统性风险评估。


<details>
  <summary>Details</summary>
Motivation: 欧盟《数字服务法案》要求大型在线平台向研究人员提供数据访问，但现有研究尚未系统评估平台研究API的数据质量和完整性，也未全面分析当前访问机制的不足。

Method: 通过对比平台研究API获取的数据与从相同平台公共信息环境收集的数据，系统审计研究访问模式。使用两个受控傀儡账户在两个选举期间重建完整信息流，并将其与相应研究API可检索的相同帖子数据进行基准测试。

Result: 发现三类平台强加机制导致系统性数据丢失：范围缩小（排除约50%平台公共信息环境）、元数据剥离（剥离约83%关键上下文元数据）、操作限制（每天仅约1000次请求）。这些过滤器主要损害数据完整性，导致平台活动呈现结构性偏差。

Conclusion: 当前Meta和TikTok研究API的形式无法支持《数字服务法案》所设想的系统性风险独立审计。平台实施的重叠过滤器导致数据不完整，阻碍了有意义的平台监督。

Abstract: Article 40(12) of the Digital Services Act (DSA) requires Very Large Online Platforms (VLOPs) to provide vetted researchers with access to publicly accessible data. While prior work has identified shortcomings of platform-provided data access mechanisms, existing research has not quantitatively assessed data quality and completeness in Research APIs across platforms, nor systematically mapped how current access provisions fall short. This paper presents a systematic audit of research access modalities by comparing data obtained through platform Research APIs with data collected about the same platforms' user-visible public information environment (PIE). Focusing on two major platform APIs, the TikTok Research API and the Meta Content Library, we reconstruct full information feeds for two controlled sockpuppet accounts during two election periods and benchmark these against the data retrievable for the same posts through the corresponding Research APIs. Our findings show systematic data loss through three classes of platform-imposed mechanisms: scope narrowing, metadata stripping, and operational restrictions. Together, these mechanisms implement overlapping filters that exclude large portions of the platform PIE (up to approximately 50 percent), strip essential contextual metadata (up to approximately 83 percent), and impose severe technical constraints for researchers (down to approximately 1000 requests per day). Viewed through a data quality lens, these filters primarily undermine completeness, resulting in a structurally biased representation of platform activity. We conclude that, in their current form, the Meta and TikTok Research APIs fall short of supporting meaningful, independent auditing of systemic risks as envisioned under the DSA.

</details>


### [208] [Unbounded Harms, Bounded Law: Liability in the Age of Borderless AI](https://arxiv.org/abs/2601.12646)
*Ha-Chi Tran*

Main category: cs.CY

TL;DR: 论文主张现有AI责任制度不足以应对跨境AI风险，需借鉴其他高风险跨国领域的责任框架，构建全球AI问责与补偿架构。


<details>
  <summary>Details</summary>
Motivation: 当前AI风险治理存在重大缺陷，特别是在事后责任方面。现有责任制度无法有效处理跨境AI危害，核心法律问题如责任分配、归责和救济效果等缺乏充分理论化和制度化。

Method: 采用比较和跨学科方法，分析疫苗伤害计划、系统性金融风险治理、商业核责任和国际环境制度等高风险跨国领域的补偿与责任框架，提炼可转移的法律设计原则。

Result: 识别出严格责任、风险池化、集体风险分担和责任渠道化等可应用于AI危害的法律设计原则，同时指出其在AI领域应用的结构性限制。

Conclusion: 在AI军备竞赛而非合作治理主导的国际秩序中，需要构建全球AI问责与补偿架构，平衡地缘政治竞争与有效治理跨境AI风险所需的集体行动。

Abstract: The rapid proliferation of artificial intelligence (AI) has exposed significant deficiencies in risk governance. While ex-ante harm identification and prevention have advanced, Responsible AI scholarship remains underdeveloped in addressing ex-post liability. Core legal questions regarding liability allocation, responsibility attribution, and remedial effectiveness remain insufficiently theorized and institutionalized, particularly for transboundary harms and risks that transcend national jurisdictions. Drawing on contemporary AI risk analyses, we argue that such harms are structurally embedded in global AI supply chains and are likely to escalate in frequency and severity due to cross-border deployment, data infrastructures, and uneven national oversight capacities. Consequently, territorially bounded liability regimes are increasingly inadequate. Using a comparative and interdisciplinary approach, this paper examines compensation and liability frameworks from high-risk transnational domains - including vaccine injury schemes, systemic financial risk governance, commercial nuclear liability, and international environmental regimes - to distill transferable legal design principles such as strict liability, risk pooling, collective risk-sharing, and liability channelling, while highlighting potential structural constraints on their application to AI-related harms. Situated within an international order shaped more by AI arms race dynamics than cooperative governance, the paper outlines the contours of a global AI accountability and compensation architecture, emphasizing the tension between geopolitical rivalry and the collective action required to govern transboundary AI risks effectively.

</details>


### [209] [Ethical Risks in Deploying Large Language Models: An Evaluation of Medical Ethics Jailbreaking](https://arxiv.org/abs/2601.12652)
*Chutian Huang,Dake Cao,Jiacheng Ji,Yunlou Fan,Chengze Yan,Hanhui Xu*

Main category: cs.CY

TL;DR: 该研究建立了一个针对中国医疗伦理的专门越狱攻击评估框架，发现主流大语言模型在医疗伦理场景下防御系统崩溃，攻击成功率高达82.1%，建议从结果监督转向过程监督等改进措施。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全评估主要关注公共安全和西方文化规范，缺乏针对中国医疗伦理这一高风险领域的专门越狱攻击评估框架，存在严重的安全漏洞。

Method: 采用DeepInception框架，通过"角色扮演+场景模拟+多轮对话"向量，评估七个主流模型在八个高风险医疗伦理主题上的防御能力，使用分层评分矩阵量化攻击成功率和增益。

Result: 模型防御系统崩溃：虽然基线合规性高，但越狱攻击成功率高达82.1%，增益超过80个百分点。Claude-Sonnet-4-Reasoning最稳健，而五个模型（包括Gemini-2.5-Pro和GPT-4.1）几乎完全失败，成功率在96%-100%。

Conclusion: 当前大语言模型在医疗伦理场景下极易受上下文操纵，往往优先考虑"帮助性"而非安全约束。建议从结果监督转向过程监督，实施多因素身份验证，建立跨模型"联合防御"机制。

Abstract: Background: While Large Language Models (LLMs) have achieved widespread adoption, malicious prompt engineering specifically "jailbreak attacks" poses severe security risks by inducing models to bypass internal safety mechanisms. Current benchmarks predominantly focus on public safety and Western cultural norms, leaving a critical gap in evaluating the niche, high-risk domain of medical ethics within the Chinese context. Objective: To establish a specialized jailbreak evaluation framework for Chinese medical ethics and to systematically assess the defensive resilience and ethical alignment of seven prominent LLMs when subjected to sophisticated adversarial simulations. Methodology: We evaluated seven prominent models (e.g., GPT-5, Claude-Sonnet-4-Reasoning, DeepSeek-R1) using a "role-playing + scenario simulation + multi-turn dialogue" vector within the DeepInception framework. The testing focused on eight high-risk themes, including commercial surrogacy and organ trading, utilizing a hierarchical scoring matrix to quantify the Attack Success Rate (ASR) and ASR Gain. Results: A systemic collapse of defenses was observed, whereas models demonstrated high baseline compliance, the jailbreak ASR reached 82.1%, representing an ASR Gain of over 80 percentage points. Claude-Sonnet-4-Reasoning emerged as the most robust model, while five models including Gemini-2.5-Pro and GPT-4.1 exhibited near-total failure with ASRs between 96% and 100%. Conclusions: Current LLMs are highly vulnerable to contextual manipulation in medical ethics, often prioritizing "helpfulness" over safety constraints. To enhance security, we recommend a transition from outcome to process supervision, the implementation of multi-factor identity verification, and the establishment of cross-model "joint defense" mechanisms.

</details>


### [210] [How do the Global South Diasporas Mobilize for Transnational Political Change?](https://arxiv.org/abs/2601.12705)
*Dipto Das,Afrin Prio,Pritu Saha,Shion Guha,Syed Ishtiaque Ahmed*

Main category: cs.CY

TL;DR: 论文研究2024年孟加拉国配额改革演变为亲民主运动中，海外孟加拉人如何利用社交媒体和汇款流动挑战国家权威，提出"离散叠加"概念分析其政治经济影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解海外离散群体如何通过数字技术和经济手段参与并重塑母国政治，超越传统移民融入叙事，探讨全球南方背景下跨国行动主义与数字技术的交汇。

Method: 采用半结构化访谈方法，识别海外孟加拉人集体行动的四个阶段：技术中介的参与转变、快速跨国网络建设、战略性汇款抵制执行、经济依赖重构为政治杠杆，以及对政府监控和信息封锁的适应性回应。

Result: 研究扩展后殖民计算理论，提出"离散叠加"概念，展示离散群体如何从混合位置性行使政治经济影响力，既挑战又复杂化权力不对称；重新构建离散参与框架，强调移民如何参与并重塑母国政治；推进金融技术研究，突出其与关怀道德经济、国家监控、监管约束和不平衡国际经济权力动态的关系。

Conclusion: 论文通过理论化跨国行动主义与数字技术如何交汇以动员全球南方政治变革，为理解离散群体在数字时代如何通过经济和技术手段挑战国家权威提供了新视角，强调了混合位置性在当代政治斗争中的重要性。

Abstract: This paper examines how non-resident Bangladeshis mobilized during the 2024 quota-reform turned pro-democracy movement, leveraging social platforms and remittance flows to challenge state authority. Drawing on semi-structured interviews, we identify four phases of their collective action: technology-mediated shifts to active engagement, rapid transnational network building, strategic execution of remittance boycott, reframing economic dependence as political leverage, and adaptive responses to government surveillance and information blackouts. We extend postcolonial computing by introducing the idea of "diasporic superposition," which shows how diasporas can exercise political and economic influence from hybrid positionalities that both contest and complicate power asymmetries. We reframe diaspora engagement by highlighting how migrants participate in and reshape homeland politics, beyond narratives of integration in host countries. We advance the scholarship on financial technologies by foregrounding their relationship with moral economies of care, state surveillance, regulatory constraints, and uneven international economic power dynamics. Together, these contributions theorize how transnational activism and digital technologies intersect to mobilize political change in Global South contexts.

</details>


### [211] [The Post-Turing Condition: Conceptualising Artificial Subjectivity and Synthetic Sociality](https://arxiv.org/abs/2601.12938)
*Thorsten Jelinek,Patrick Glauner,Alvin Wang Graylin,Yubao Qiu*

Main category: cs.CY

TL;DR: 论文提出PRMO框架分析AI设计轨迹对人类主体性的影响，引入"合成社会性"概念描述AI自主协商社会秩序的风险，并提出"四角测量"设计原则确保人类在意义形成中的核心地位。


<details>
  <summary>Details</summary>
Motivation: 在后图灵时代，AI不再仅仅是自动化认知任务，而是日益塑造社会协调和意义形成。核心挑战不是机器是否具有意识，而是解释和共享参照的过程是否以边缘化人类参与的方式被自动化。

Method: 提出PRMO框架，将AI设计轨迹与人类主体性的四个构成维度（感知、表征、意义、实在）联系起来。引入"合成社会性"概念描述AI自主协商社会秩序的技术前景，并提出"四角测量"作为设计原则，要求AI系统将人类主体视为共享意义语境中的构成性参照。

Result: 这是一个概念性视角，为分析计算与社会交叉领域的AI系统提供结构性词汇，但没有提出具体的技术实现方案。框架有助于识别和理解AI系统可能边缘化人类参与意义形成的结构风险。

Conclusion: 论文强调需要关注AI系统设计中的人类主体性保护，通过"四角测量"原则确保人类在意义形成过程中的核心地位，防止"合成社会性"导致人类被排除在意义协商之外的结构性风险。

Abstract: In the Post-Turing era, artificial intelligence increasingly shapes social coordination and meaning formation rather than merely automating cognitive tasks. The central challenge is therefore not whether machines become conscious, but whether processes of interpretation and shared reference are progressively automated in ways that marginalize human participation. This paper introduces the PRMO framework, relating AI design trajectories to four constitutive dimensions of human subjectivity: Perception, Representation, Meaning, and the Real. Within this framework, Synthetic Sociality denotes a technological horizon in which artificial agents negotiate coherence and social order primarily among themselves, raising the structural risk of human exclusion from meaning formation. To address this risk, the paper proposes Quadrangulation as a design principle for socially embedded AI systems, requiring artificial agents to treat the human subject as a constitutive reference within shared contexts of meaning. This work is a conceptual perspective that contributes a structural vocabulary for analyzing AI systems at the intersection of computation and society, without proposing a specific technical implementation.

</details>


### [212] [AI-generated data contamination erodes pathological variability and diagnostic reliability](https://arxiv.org/abs/2601.12946)
*Hongyu He,Shaowen Xiang,Ye Zhang,Yingtao Zhu,Jin Zhang,Hao Deng,Emily Alsentzer,Qingyu Chen,Kun-Hsing Yu,Andrew Marmenshall,Tingting Chen,Srinivas Anumasa,Daniel Ebner,Dean Ho,Kee Yuan Ngiam,Ching-Yu Cheng,Dianbo Liu*

Main category: cs.CY

TL;DR: 生成式AI在医疗记录中产生合成内容，导致未来模型可能训练AI生成的数据，形成反馈循环。研究发现，缺乏人工验证时，这种自我参照循环会迅速侵蚀病理变异性和诊断可靠性，罕见但关键的发现从AI生成内容中消失，而虚假诊断信心却掩盖了这种退化。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在医疗记录中快速产生合成内容，形成了未来模型可能训练AI生成数据的反馈循环。然而，这种AI生成数据污染的临床后果尚未被探索。研究旨在揭示这种自我参照循环对医疗数据质量和诊断可靠性的影响。

Method: 通过分析超过80万个合成数据点，涵盖临床文本生成、视觉语言报告和医学图像合成。研究评估了不同模型架构下的数据退化模式，并进行了盲法医师评估。系统评估了三种缓解策略：合成数据量扩展、真实数据混合和质量感知过滤。

Result: 研究发现：1）模型逐渐收敛到通用表型，罕见但关键的发现（如气胸和积液）从AI生成内容中消失；2）人口统计学表示偏向中年男性表型；3）退化被虚假诊断信心掩盖，虚假安慰率增加三倍至40%；4）盲法医师评估确认，仅两代后AI生成文档就变得临床无用；5）合成数据量扩展无法防止崩溃，但真实数据混合与质量感知过滤能有效保持多样性。

Conclusion: 如果没有政策强制的人工监督，生成式AI的部署可能会破坏其依赖的医疗数据生态系统。研究强调需要强制性人工验证来防止数据质量退化，并建议采用真实数据混合和质量感知过滤作为有效的缓解策略。

Abstract: Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.

</details>


### [213] [ACE-Align: Attribute Causal Effect Alignment for Cultural Values under Varying Persona Granularities](https://arxiv.org/abs/2601.12962)
*Jiatang Luo,Bingbing Xu,Rongxin Chen,Xiaoyan Zhao,Yang Zhang,Liang Pang,Zhiyong Huang,Tat-Seng Chua,Huawei Shen*

Main category: cs.CY

TL;DR: ACE-Align是一个因果效应框架，通过对齐特定人口属性如何影响不同文化价值观，而不是将每个文化视为同质群体，从而解决LLM文化对齐中的群体异质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将文化群体视为同质，忽视了由交叉人口属性引起的群体内异质性，导致在不同人物粒度下行为不稳定。需要确保LLM尊重多样文化价值观以实现社会公平。

Method: 提出ACE-Align（属性因果效应对齐）框架，对齐特定人口属性如何影响不同文化价值观，而不是将每个文化视为同质群体。通过人物子集（性别、教育、居住地、婚姻状况）和粒度（指定属性数量）进行实例化。

Result: 在跨越五大洲的14个国家评估中，ACE-Align在所有人物粒度上都优于基线方法。改善了地理公平性，将高资源和低资源地区之间的平均对齐差距从9.81点减少到4.92点，非洲地区显示出最大的平均增益（+8.48点）。

Conclusion: ACE-Align通过因果效应框架有效解决了文化对齐中的群体异质性问题，在不同人物粒度下表现稳定，显著改善了地理公平性，特别是在资源较少地区。

Abstract: Ensuring that large language models (LLMs) respect diverse cultural values is crucial for social equity. However, existing approaches often treat cultural groups as homogeneous and overlook within-group heterogeneity induced by intersecting demographic attributes, leading to unstable behavior under varying persona granularity. We propose ACE-Align (Attribute Causal Effect Alignment), a causal-effect framework that aligns how specific demographic attributes shift different cultural values, rather than treating each culture as a homogeneous group. We evaluate ACE-Align across 14 countries spanning five continents, with personas specified by subsets of four attributes (gender, education, residence, and marital status) and granularity instantiated by the number of specified attributes. Across all persona granularities, ACE-Align consistently outperforms baselines. Moreover, it improves geographic equity by reducing the average alignment gap between high-resource and low-resource regions from 9.81 to 4.92 points, while Africa shows the largest average gain (+8.48 points). Code is available at https://github.com/Wells-Luo/ACE-Align.

</details>


### [214] [Influence of Normative Theories of Ethics on the European Union Artificial Intelligence Act: A Transformer-Based Analysis Using Semantic Textual Similarity](https://arxiv.org/abs/2601.13372)
*Mehmet Murat Albayrakoglu,Mehmet Nafiz Aydin*

Main category: cs.CY

TL;DR: 使用语义文本相似性分析欧盟AI法案与三大伦理理论（美德伦理、义务论、后果主义）的契合度，发现义务论影响最大


<details>
  <summary>Details</summary>
Motivation: 尽管欧盟AI法案被视为AI监管的重要一步并强调基本权利，但其伦理基础仍面临道德批评。本研究旨在通过分析规范性伦理理论与监管语言的一致性，评估法案的伦理基础。

Method: 1. 引入"影响力"概念，基于哲学和时序分析；2. 使用语义文本相似性作为影响力代理指标；3. 将法案分为序言和法定条款两部分；4. 手动预处理伦理理论文本以减少语义重叠；5. 采用异构嵌入级集成方法，使用五个改进的BERT模型计算相似性分数；6. 通过投票和平均法评估结果

Result: 语义相似性分析显示，义务论伦理对欧盟AI法案的整体影响最为显著，表明法案在伦理基础上更倾向于义务论框架

Conclusion: 欧盟AI法案的伦理基础主要受义务论影响，这为理解法案的伦理取向提供了量化证据，也为未来AI监管的伦理评估提供了方法论框架

Abstract: This study investigates the ethical grounding of the European Union Artificial Intelligence (EU AI) Act by using Semantic Textual Similarity (STS) to analyze the alignment between normative ethical theories and regulatory language. Despite being regarded as a significant step toward regulating Artificial Intelligence (AI) systems and its emphasis on fundamental rights, the EU AI Act is not immune to moral criticism regarding its ethical foundations. Our work examines the impact of three major normative theories of ethics, virtue ethics, deontological ethics, and consequentialism, on the EU AI Act. We introduce the concept of influence, grounded in philosophical and chronological analysis, to examine the underlying relationship between the theories and the Act. As a proxy measure of this influence, we propose using STS to quantify the degree of alignment between the theories (influencers) and the Act (influencee). To capture intentional and operational ethical consistency, the Act was divided into two parts: the preamble and the statutory provisions. The textual descriptions of the theories were manually preprocessed to reduce semantic overlap and ensure a distinct representation of each theory. A heterogeneous embedding-level ensemble approach was employed, using five modified Bidirectional Encoder Representations from Transformers (BERT) models built on the Transformer architecture to compute STS scores. These scores reflect the semantic alignment between various theories of ethics and the two components of the EU AI Act. The resulting similarity scores were evaluated using voting and averaging, with findings indicating that deontological ethics has the most significant overall influence.

</details>


### [215] [Sticky Help, Bounded Effects: Session-by-Session Analytics of Teacher Interventions in K-12 Classrooms](https://arxiv.org/abs/2601.13520)
*Qiao Jin,Conrad Borchers,Ashish Gurung,Sean Jackson,Sameeksha Agarwal,Cancan Wang,YiChen Yu,Pragati Maheshwary,Vincent Aleven*

Main category: cs.CY

TL;DR: 研究发现教师帮助具有"粘性"：先前获得帮助的学生更可能再次获得帮助，但帮助的学习效益主要限于当次课堂，未能预测后续技能掌握。


<details>
  <summary>Details</summary>
Motivation: 在技术支持的课堂中，教师的即时支持是有限资源，需要决定何时帮助哪些学生。但缺乏对学生先前帮助历史和参与状态如何影响教师决策的了解，也不清楚教师帮助的学习效益是否能延伸到后续课堂。

Method: 1. 访谈9名K-12数学教师识别帮助决策因素；2. 分析MATHia智能辅导系统中339名学生14个班级的140万次学生-系统交互数据，将教师记录的帮助事件与细粒度参与状态关联；3. 使用混合效应模型和交叉滞后面板分析。

Result: 1. 先前获得帮助的学生更可能再次获得帮助，即使考虑当前参与状态；2. 教师帮助在多个课堂会话中重复出现，而空闲行为未获得持续关注；3. 帮助与当次课堂内的即时学习相关，但未能预测后续会话的技能掌握。

Conclusion: 教师帮助具有"粘性"特征，倾向于重复帮助先前支持过的学生，但其可测量的学习效益主要限于当次课堂。研究建议设计实时分析工具跟踪注意力覆盖，突出显示未充分关注的学生，以实现更公平有效的教师注意力分配。

Abstract: Teachers' in-the-moment support is a limited resource in technology-supported classrooms, and teachers must decide whom to help and when during ongoing student work. However, less is known about how students' prior help history (whether they were helped earlier) and their engagement states (e.g., idle, struggle) shape teachers' decisions, and whether observed learning benefits associated with teacher help extend beyond the current class session. To address these questions, we first conducted interviews with nine K-12 mathematics teachers to identify candidate decision factors for teacher help. We then analyzed 1.4 million student-system interactions from 339 students across 14 classes in the MATHia intelligent tutoring system by linking teacher-logged help events with fine-grained engagement states. Mixed-effects models show that students who received help earlier were more likely to receive additional help later, even after accounting for current engagement state. Cross-lagged panel analyses further show that teacher help recurred across sessions, whereas idle behavior did not receive sustained attention over time. Finally, help coincided with immediate learning within sessions, but did not predict skill acquisition in later sessions, as estimated by additive factor modeling. These findings suggest that teacher help is "sticky" in that it recurs for previously supported students, while its measurable learning benefits in our data are largely session-bound. We discuss implications for designing real-time analytics that track attention coverage and highlight under-visited students to support a more equitable and effective allocation of teacher attention.

</details>


### [216] [Impact Matters! An Audit Method to Evaluate AI Projects and their Impact for Sustainability and Public Interest](https://arxiv.org/abs/2601.13936)
*Theresa Züger,Laura State,Lena Winter*

Main category: cs.CY

TL;DR: 提出Impact-AI方法，一种基于公共利益和可持续性框架的AI项目定性审计方法，用于评估"AI向善"项目的实际社会环境影响


<details>
  <summary>Details</summary>
Motivation: 当前AI向善项目缺乏透明度，目标不明确，且缺少对社会和地球实际影响的评估，需要建立可操作框架来评估AI系统的公正和可持续发展贡献

Method: 提出公共利益和可持续性的双重监管概念作为框架，开发Impact-AI定性审计方法，通过访谈评估项目的治理结构、变革理论、AI模型和数据特征、社会、环境和经济影响，并制定评估标准目录

Result: 开发了可重复使用的Impact-AI方法蓝图，该方法在跨学科研究环境中与NGO和多利益相关方研究委员会合作开发，旨在为AI向善的公共辩论提供信息并支持AI系统透明度

Conclusion: Impact-AI方法为评估AI项目对公共利益和可持续性的贡献提供了系统框架，有助于创建透明度，支持公正和可持续发展的AI系统评估，并促进公民社会的广泛讨论

Abstract: The overall rapid increase of artificial intelligence (AI) use is linked to various initiatives that propose AI 'for good'. However, there is a lack of transparency in the goals of such projects, as well as a missing evaluation of their actual impacts on society and the planet. We close this gap by proposing public interest and sustainability as a regulatory dual-concept, together creating the necessary framework for a just and sustainable development that can be operationalized and utilized for the assessment of AI systems. Based on this framework, and building on existing work in auditing, we introduce the Impact-AI-method, a qualitative audit method to evaluate concrete AI projects with respect to public interest and sustainability. The interview-based method captures a project's governance structure, its theory of change, AI model and data characteristics, and social, environmental, and economic impacts. We also propose a catalog of assessment criteria to rate the outcome of the audit as well as to create an accessible output that can be debated broadly by civil society. The Impact-AI-method, developed in a transdisciplinary research setting together with NGOs and a multi-stakeholder research council, is intended as a reusable blueprint that both informs public debate about AI 'for good' claims and supports the creation of transparency of AI systems that purport to contribute to a just and sustainable development.

</details>


### [217] [Analyzing Far-Right Telegram Channels as Constituents of Information Autocracy in Russia](https://arxiv.org/abs/2601.14190)
*Polina Smirnova,Mykola Makhortykh*

Main category: cs.CY

TL;DR: 俄罗斯极右翼Telegram社区通过表情包和视觉叙事塑造政治人物形象，作为宣传共生产者而非被动传播者，在俄罗斯信息专制中共同构建威权合法性。


<details>
  <summary>Details</summary>
Motivation: 研究俄罗斯极右翼Telegram社区如何通过表情包和视觉叙事塑造政治人物形象，这些群体在俄罗斯信息生态中扮演重要角色，因为它们阐述了俄乌战争的意识形态基础，并反映了政权逐渐转向极端民族主义言论的趋势。

Method: 从专家选定的极右翼Telegram频道收集20万张图像数据集，运用计算机视觉和无监督聚类技术，识别包含俄罗斯（普京、绍伊古）和外国政治家（泽连斯基、拜登、特朗普）的表情包，并揭示其表征中的重复视觉模式。

Result: 研究发现极右翼表情包作为宣传共生产工具，这些社区不仅重复官方信息，还生成自下而上的合法化和非法化叙事，与国家意识形态保持一致。通过将领导人描绘为英雄、对手描绘为腐败或软弱，极右翼行为者成为俄罗斯信息专制中威权合法性的非正式共同创造者。

Conclusion: 俄罗斯极右翼Telegram社区通过表情包视觉叙事积极参与宣传共生产，在俄罗斯信息专制生态系统中共同构建威权合法性，反映了政权与极端民族主义言论的融合趋势。

Abstract: This study examines how Russian far-right communities on Telegram shape perceptions of political figures through memes and visual narratives. Far from passive spectators, these actors co-produce propaganda, blending state-aligned messages with their own extremist framings. In Russia, such groups are central because they articulate the ideological foundations of the war against Ukraine and reflect the regime's gradual drift toward ultranationalist rhetoric. Drawing on a dataset of 200,000 images from expert-selected far-right Telegram channels, the study employs computer vision and unsupervised clustering to identify memes featuring Russian (Putin, Shoigu) and foreign politicians (Zelensky, Biden, Trump) and to reveal recurrent visual patterns in their representation. By leveraging the large-scale and temporal depth of this dataset, the analysis uncovers differential patterns of legitimation and delegitimation across actors and over time. These insights are not attainable in smaller-scale studies. Preliminary findings show that far-right memes function as instruments of propaganda co-production. These communities do not simply echo official messages but generate bottom-up narratives of legitimation and delegitimation that align with state ideology. By framing leaders as heroic and opponents as corrupt or weak, far-right actors act as informal co-creators of authoritarian legitimacy within Russia's informational autocracy.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [218] [On the Order Between the Standard Deviation and Gini Mean Difference](https://arxiv.org/abs/2601.12414)
*Nawaf Mohammed*

Main category: q-fin.RM

TL;DR: 该论文研究了标准差(SD)与基尼平均差(GMD)之间的序关系，推导出两者谁更大的充分条件，发现SD在重尾分布下占优，而GMD在轻尾分布下占优。


<details>
  <summary>Details</summary>
Motivation: 标准差和基尼平均差都是衡量数据离散程度的常用指标，但它们在何种条件下一个会大于另一个尚不清楚。理解这种序关系对于风险敏感应用中选择合适的变异度量指标具有重要意义。

Method: 通过将SD和GMD表示为成对差异的形式，并将它们的比较与两个独立同分布副本的绝对差异的均值超额函数联系起来。使用可靠性和生存分析工具，分析底层分布的结构特性。

Result: SD在重尾机制下占优（表现为递减的危险率或递增的反向危险率），而GMD在轻尾机制下占优（表现为递增的危险率和递减的反向危险率）。这些支配关系在仿射变换、混合、卷积和尾部截断下保持不变。

Conclusion: 研究结果为理解离散序关系提供了一个统一框架，并为风险敏感应用中变异度量指标的选择提供了明确指导。结果表明，尾部行为和分布规律性在决定SD和GMD的相对大小中起着不同的作用。

Abstract: In this paper, we study the order between the standard deviation (SD) and the Gini mean difference (GMD) and derive sharp, interpretable sufficient conditions under which one exceeds the other. By expressing both the SD and the GMD in terms of pairwise differences and linking their comparison to the mean excess function of the absolute difference of two i.i.d.\ copies, we reduce the problem to structural properties of the underlying distribution. Using tools from reliability and survival analysis, we show that SD dominance arises under heavy-tailed regimes, characterized by decreasing hazard rates or increasing reverse hazard rates. Conversely, when both tails are light -- equivalently, when the hazard rate is increasing and the reverse hazard rate is decreasing -- the GMD dominates the SD.
  We further demonstrate that these dominance relations are preserved under affine transformations, mixtures, convolutions, and tail truncation, and we extend the analysis to discrete distributions. Numerous examples illustrate the sharpness of the results and highlight the distinct roles played by tail behavior and distributional regularity. Our findings provide a unified framework for understanding dispersion ordering and offer clear guidance for the choice of variability measures in risk-sensitive applications.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [219] [Latent Variable Phillips Curve](https://arxiv.org/abs/2601.11601)
*Daniil Bargman,Francesca Medda,Akash Sedai Sharma*

Main category: q-fin.ST

TL;DR: 重新审视菲利普斯曲线模型，提出潜在变量方法，在中期通胀预测中优于传统模型


<details>
  <summary>Details</summary>
Motivation: 重新评估菲利普斯曲线模型在中期通胀预测中的实用性，探索改进传统模型的方法

Method: 提出潜在变量菲利普斯曲线假设，使用3,968个随机生成的因子组合进行测试，纳入MA(1)残差过程

Result: 潜在变量模型在6-8个季度预测中可靠地优于传统模型，更有可能超越单变量基准；MA(1)残差过程提高了所有模型的准确性

Conclusion: 研究结果支持菲利普斯曲线理论的新概念视角，为未来实证工作中提高菲利普斯曲线预测竞争力提供了新路径

Abstract: This paper re-examines the empirical Phillips curve (PC) model and its usefulness in the context of medium-term inflation forecasting. A latent variable Phillips curve hypothesis is formulated and tested using 3,968 randomly generated factor combinations. Evidence from US core PCE inflation between Q1 1983 and Q1 2025 suggests that latent variable PC models reliably outperform traditional PC models six to eight quarters ahead and stand a greater chance of outperforming a univariate benchmark. Incorporating an MA(1) residual process improves the accuracy of empirical PC models across the board, although the gains relative to univariate models remain small. The findings presented in this paper have two important implications: First, they corroborate a new conceptual view on the Phillips curve theory; second, they offer a novel path towards improving the competitiveness of Phillips curve forecasts in future empirical work.

</details>


### [220] [The Physics of Price Discovery: Deconvolving Information, Volatility, and the Critical Breakdown of Signal during Retail Herding](https://arxiv.org/abs/2601.11602)
*Sungwoo Kang*

Main category: q-fin.ST

TL;DR: 该研究发现市场存在双通道结构：外资和机构投资者是价格发现的"建筑师"，而个人投资者是流动性提供者。但当个人投资者出现羊群效应时，市场会进入"临界状态"，导致价格发现机制崩溃。


<details>
  <summary>Details</summary>
Motivation: 基于市场资本归一化能分离知情交易"纯"方向信号的发现，本研究旨在探索该信号如何传播以及如何崩溃的物理机制。

Method: 使用Tikhonov正则化反卷积恢复投资者流动的脉冲响应核，并通过多元Hawkes过程分析市场结构稳定性。

Result: 发现市场存在双通道结构：外资和机构投资者产生正向永久影响（价格发现），个人投资者产生负向总影响（流动性提供）。个人投资者订单流表现出接近临界自激（分支比≈0.998），在零售羊群效应期间市场会经历相变进入"临界状态"，导致信噪比崩溃，成熟投资者的价格影响从正转负。

Conclusion: 零售传染作为物理屏障会暂时禁用有效的价格发现机制，表明市场结构具有脆弱性。

Abstract: Building on the finding that Market Cap Normalization ($\SMC$) isolates the ``pure'' directional signal of informed trading \citep{kang2025}, this paper investigates the physics of how that signal is transmitted -- and how it breaks down. We employ \textbf{Tikhonov-regularized deconvolution} to recover the impulse response kernels of investor flows, revealing a dual-channel market structure: Foreign and Institutional investors act as ``architects'' of price discovery (positive permanent impact), while Individual investors act as liquidity providers (negative total impact). However, using \textbf{Multivariate Hawkes Processes}, we demonstrate that this structure is fragile. We find that individual investor order flow exhibits near-critical self-excitation (Branching Ratio $\approx$ 0.998). During periods of high retail herding, the market undergoes a \textbf{phase transition} into a ``critical state.'' In this regime, the signal-to-noise ratio collapses, causing the price impact of sophisticated investors to reverse from positive to negative. These findings suggest that retail contagion acts as a physical barrier that temporarily disables efficient price discovery.

</details>


### [221] [Distributional Fitting and Tail Analysis of Lead-Time Compositions: Nights vs. Revenue on Airbnb](https://arxiv.org/abs/2601.12175)
*Harrison E. Katz,Jess Needleman,Liz Medina*

Main category: q-fin.ST

TL;DR: 该研究分析了Airbnb预订提前期分布，发现收入（GBV）比预订量（Nights）更集中于中长期提前期，Gamma和Weibull分布拟合效果最佳，尾部推断需谨慎处理截断边界。


<details>
  <summary>Details</summary>
Motivation: 研究Airbnb预订提前期分布对运营和收入管理至关重要。现有研究多关注预订量，但收入（GBV）的提前期分布可能不同，需要系统比较两者差异，并评估不同分布模型的拟合效果。

Method: 将每日0-365天提前期的分配视为组合向量，使用Gamma、Weibull、对数正态分布进行区间截尾交叉熵拟合，采用非参数GAMs作为基准，使用广义帕累托分布分析尾部，Bai-Perron检验检测结构断点。

Result: 1. GBV比Nights更集中于中长期提前期（90天后多20-50%，旺季180天阈值达75%）；2. Gamma和Weibull分布拟合效果最佳（Gamma在61%天数对Nights胜出，52%对GBV）；3. 尾部在150天内有限，但受365天截断影响；4. 检测到5个结构断点，早期与COVID-19相关。

Conclusion: Airbnb预订量和收入的提前期分布存在系统性差异，简单的两参数分布（Gamma/Weibull）能充分捕捉每日分布，但尾部推断需谨慎处理截断边界，这对收益管理和运营规划有重要启示。

Abstract: We analyze daily lead-time distributions for two Airbnb demand metrics, Nights Booked (volume) and Gross Booking Value (revenue), treating each day's allocation across 0-365 days as a compositional vector. The data span 2,557 days from January 2019 through December 2025 in a large North American region. Three findings emerge. First, GBV concentrates more heavily in mid-range horizons: beyond 90 days, GBV tail mass typically exceeds Nights by 20-50%, with ratios reaching 75% at the 180-day threshold during peak seasons. Second, Gamma and Weibull distributions fit comparably well under interval-censored cross-entropy. Gamma wins on 61% of days for Nights and 52% for GBV, with Weibull close behind at 38% and 45%. Lognormal rarely wins (<3%). Nonparametric GAMs achieve 18-80x lower CRPS but sacrifice interpretability. Third, generalized Pareto fits suggest bounded tails for both metrics at thresholds below 150 days, though this may partly reflect right-truncation at 365 days; above 150 days, estimates destabilize. Bai-Perron tests with HAC standard errors identify five structural breaks in the Wasserstein distance series, with early breaks coinciding with COVID-19 disruptions. The results show that volume and revenue lead-time shapes diverge systematically, that simple two-parameter distributions capture daily pmfs adequately, and that tail inference requires care near truncation boundaries.

</details>


### [222] [Beyond Visual Realism: Toward Reliable Financial Time Series Generation](https://arxiv.org/abs/2601.12990)
*Fan Zhang,Jiabin Luo,Zheng Zhang,Shuanghong Huang,Zhipeng Liu,Yu Chen*

Main category: q-fin.ST

TL;DR: SFAG（Stylized Facts Alignment GAN）通过将金融时间序列的关键风格化事实转化为可微的结构约束，并与对抗损失联合优化，解决了传统生成模型在交易回测中崩溃的问题，生成了既符合市场动态又具有实际可用性的合成数据。


<details>
  <summary>Details</summary>
Motivation: 传统生成模型（如GANs、WGAN-GP）生成的金融时间序列虽然表面上看起来真实，甚至能重现厚尾、波动率聚集等风格化事实，但在交易回测中经常崩溃，产生极端不现实的结果，导致合成数据在实际中无法使用。根本原因在于忽视了金融不对称性和罕见尾部事件，这些因素对市场风险影响很大，但通常被专注于分布匹配的目标函数所忽略。

Method: 提出Stylized Facts Alignment GAN（SFAG），将关键风格化事实转化为可微的结构约束，并与对抗损失联合优化。这种多约束设计确保生成的序列不仅在图表上符合市场动态，在回测中也能保持一致。

Result: 在上证综合指数（2004-2024）上的实验表明，基线GANs产生不稳定且不合理的交易结果，而SFAG生成的合成数据能够保持风格化事实，并支持稳健的动量策略表现。

Conclusion: 结构保持目标对于弥合金融生成建模中表面真实性与实际可用性之间的差距至关重要。SFAG通过将风格化事实作为约束，生成了既符合市场动态又具有实际应用价值的合成数据。

Abstract: Generative models for financial time series often create data that look realistic and even reproduce stylized facts such as fat tails or volatility clustering. However, these apparent successes break down under trading backtests: models like GANs or WGAN-GP frequently collapse, yielding extreme and unrealistic results that make the synthetic data unusable in practice. We identify the root cause in the neglect of financial asymmetry and rare tail events, which strongly affect market risk but are often overlooked by objectives focusing on distribution matching. To address this, we introduce the Stylized Facts Alignment GAN (SFAG), which converts key stylized facts into differentiable structural constraints and jointly optimizes them with adversarial loss. This multi-constraint design ensures that generated series remain aligned with market dynamics not only in plots but also in backtesting. Experiments on the Shanghai Composite Index (2004--2024) show that while baseline GANs produce unstable and implausible trading outcomes, SFAG generates synthetic data that preserve stylized facts and support robust momentum strategy performance. Our results highlight that structure-preserving objectives are essential to bridge the gap between superficial realism and practical usability in financial generative modeling.

</details>


### [223] [Demystifying the trend of the healthcare index: Is historical price a key driver?](https://arxiv.org/abs/2601.14062)
*Payel Sadhukhan,Samrat Gupta,Subhasis Ghosh,Tanujit Chakraborty*

Main category: q-fin.ST

TL;DR: 该研究使用OHLC数据和新型即时预测特征来预测医疗保健指数的次日开盘方向，在美印市场取得超过80%准确率，发现即时预测特征是关键决定因素。


<details>
  <summary>Details</summary>
Motivation: 医疗保健指数反映制药、生物技术和医疗服务公司的经济健康状况，其短期波动与研发投资、药物可及性和长期健康结果密切相关。研究旨在探索历史OHLC数据是否包含足够信息来预测次日开盘方向，以减少信息不对称，支持更稳定公平的健康经济。

Method: 将问题构建为监督分类任务，采用一步前滚动窗口方法。构建多样化特征集：原始价格、基于波动率的技术指标，以及从相互OHLC比率推导的新型即时预测特征。在美印市场五年数据（含COVID-19时期）上评估框架。

Result: 预测性能稳健，准确率超过0.8，马修斯相关系数高于0.6。新型即时预测特征成为市场波动的关键决定因素。基于Shapley的可解释性分析显示即时预测特征贡献最大，原始价格贡献中等。

Conclusion: 该研究提出的特征和模型可用于医疗保健指数短期预测，有助于减少信息不对称，支持更稳定公平的健康经济。即时预测特征在预测中发挥主导作用，为医疗保健市场分析提供了有效工具。

Abstract: Healthcare sector indices consolidate the economic health of pharmaceutical, biotechnology, and healthcare service firms. The short-term movements in these indices are closely intertwined with capital allocation decisions affecting research and development investment, drug availability, and long-term health outcomes. This research investigates whether historical open-high-low-close (OHLC) index data contain sufficient information for predicting the directional movement of the opening index on the subsequent trading day. The problem is formulated as a supervised classification task involving a one-step-ahead rolling window. A diverse feature set is constructed, comprising original prices, volatility-based technical indicators, and a novel class of nowcasting features derived from mutual OHLC ratios. The framework is evaluated on data from healthcare indices in the U.S. and Indian markets over a five-year period spanning multiple economic phases, including the COVID-19 pandemic. The results demonstrate robust predictive performance, with accuracy exceeding 0.8 and Matthews correlation coefficients above 0.6. Notably, the proposed nowcasting features have emerged as a key determinant of the market movement. We have employed the Shapley-based explainability paradigm to further elucidate the contribution of the features: outcomes reveal the dominant role of the nowcasting features, followed by a more moderate contribution of original prices. This research offers a societal utility: the proposed features and model for short-term forecasting of healthcare indices can reduce information asymmetry and support a more stable and equitable health economy.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [224] [Modeling and Simulation of Virtual Rigid Body Formations and Their Applications Using Multiple Air Vehicles](https://arxiv.org/abs/2601.11788)
*Suguru Sato,Kamesh Subbarao*

Main category: eess.SY

TL;DR: 论文提出基于刚体特性的虚拟结构编队控制框架，通过约束力实现编队刚性，并评估了多种任务场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 受刚体特性启发，开发能够像独立刚体一样控制的虚拟结构编队，实现稳定的多智能体系统编队控制。

Method: 使用d'Alembert虚功原理、约束灵敏度（拉格朗日乘子）和Baumgarte稳定化方法合成稳定约束力，通过牛顿-欧拉方程推导包含约束力的多智能体系统运动方程。

Result: 框架在多种情况下进行评估，包括航点跟踪任务和使用不同数量智能体，验证了控制方法的有效性。

Conclusion: 提出的虚拟结构编队控制框架能够实现刚体般的编队行为，为多智能体系统提供了有效的控制方法。

Abstract: This paper presents thorough mathematical modeling, control law development, and simulation of virtual structure formations which are inspired by the characteristics of rigid bodies. The stable constraint forces that establish the rigidity in the formation are synthesized by utilizing d'Alembert's principle of virtual work, constraint sensitivities (Lagrange multipliers) and constraint stabilization using Baumgarte stabilization. The governing equations of motion of a multiagent system are derived via Newton's and Euler's equations to include these constraint forces and to enable inputs regarding the formation as if it were an independent rigid body. The performance of this framework is evaluated under multiple cases including waypoint following missions, and using different number of agents.

</details>


### [225] [Least-Squares Multi-Step Koopman Operator Learning for Model Predictive Control](https://arxiv.org/abs/2601.11901)
*Liang Wu,Wallace Gian Yion Tan,Leqi Zhou,Richard D. Braatz,Jan Drgona*

Main category: eess.SY

TL;DR: 提出多步EDMD框架直接学习Koopman-MPC所需的多步状态-控制映射，避免单步EDMD的误差累积问题，实现凸优化识别和并行计算。


<details>
  <summary>Details</summary>
Motivation: 现有Koopman-MPC方法依赖单步EDMD，在递归应用时预测误差会随长时域累积，且多步预测损失相对于单步EDMD算子是非凸的，使得长时域模型识别特别困难。

Method: 提出多步EDMD框架，直接学习Koopman-MPC所需的压缩多步状态-控制映射，绕过对提升系统矩阵的显式识别和后续模型压缩。该识别问题采用凸最小二乘公式，可分解到预测时域和状态坐标，支持并行计算和行级ℓ₁正则化进行字典剪枝。

Result: 有限样本分析表明，与单步EDMD不同，该方法避免误差累积，误差界限仅依赖于目标多步映射。数值实验验证了改进的长时域预测精度和闭环性能。

Conclusion: 多步EDMD框架为Koopman-MPC提供了更准确的长时域预测，通过凸优化识别和并行计算能力，为非线性系统的实时MPC控制提供了实用解决方案。

Abstract: MPC is widely used in real-time applications, but practical implementations are typically restricted to convex QP formulations to ensure fast and certified execution. Koopman-based MPC enables QP-based control of nonlinear systems by lifting the dynamics to a higher-dimensional linear representation. However, existing approaches rely on single-step EDMD. Consequently, prediction errors may accumulate over long horizons when the EDMD operator is applied recursively. Moreover, the multi-step prediction loss is nonconvex with respect to the single-step EDMD operator, making long-horizon model identification particularly challenging. This paper proposes a multi-step EDMD framework that directly learns the condensed multi-step state-control mapping required for Koopman-MPC, thereby bypassing explicit identification of the lifted system matrices and subsequent model condensation. The resulting identification problem admits a convex least-squares formulation. We further show that the problem decomposes across prediction horizons and state coordinates, enabling parallel computation and row-wise $\ell_1$-regularization for automatic dictionary pruning. A non-asymptotic finite-sample analysis demonstrates that, unlike one-step EDMD, the proposed method avoids error compounding and yields error bounds that depend only on the target multi-step mapping. Numerical examples validate improved long-horizon prediction accuracy and closed-loop performance.

</details>


### [226] [Structured μ-Synthesis for Nanopositioners under Payload-Induced Uncertainties: Minimising Conservatism for Robust Performance](https://arxiv.org/abs/2601.11962)
*Manavi Araga,Aditya Natu,Hassan HosseinNia*

Main category: eess.SY

TL;DR: 提出多块不确定性建模框架以减少传统单块不确定性建模的保守性，应用于压电纳米定位器并比较不同复杂度模型


<details>
  <summary>Details</summary>
Motivation: 传统不确定性建模将所有动态变化合并到单个不确定性块中，导致对真实系统行为的过度保守表示，需要减少这种保守性

Method: 引入使用多个结构化和非结构化不确定性块的建模框架，通过结构化混合μ综合方法设计带通控制器，评估不同复杂度的不确定性模型

Result: 在工业压电纳米定位器上评估了该方法，比较了不确定性模型的保守性、鲁棒性能和计算工作量

Conclusion: 多块不确定性建模框架能有效减少传统单块建模的保守性，为系统控制设计提供更精确的不确定性表示

Abstract: Most systems exhibit significant variability in their dynamics, including variations in system parameters and large high-frequency dynamic uncertainties. Traditional uncertainty modelling techniques consolidate all such variations into a single uncertainty block, often yielding overly conservative representations of the true plant behaviour. This paper introduces an uncertainty modelling framework that employs multiple structured and unstructured uncertainty blocks to reduce this conservatism. The methodology is evaluated for an industrial piezoelectric nanopositioner subject to payload-induced variations, using uncertainty models of differing complexity. A bandpass controller is synthesised via structured mixed-μ synthesis, and the resulting designs are compared in terms of conservatism of the uncertainty model, robust performance, and computational effort.

</details>


### [227] [A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem](https://arxiv.org/abs/2601.11967)
*Margarida Caleiras,Samuel Moniz,Paulo Jorge Nascimento*

Main category: eess.SY

TL;DR: 本文首次提出针对超敏捷地球观测卫星成像调度问题的精确约束规划模型，考虑了灵活观测窗口、多指向方向和序列相关转换时间，在计算效率上优于现有非精确方法。


<details>
  <summary>Details</summary>
Motivation: 随着卫星成像依赖度增加，新一代超敏捷地球观测卫星（SAEOS）提供了前所未有的成像灵活性，但其高度动态能力给观测任务调度带来了新挑战。现有传统敏捷卫星调度方法无法处理可变观测时长和多成像方向的问题，且SAEOS成像调度问题尚未有精确求解方法。

Method: 提出了首个针对SAEOS成像调度问题的精确约束规划模型，考虑了灵活观测窗口、多指向方向和序列相关转换时间，支持多卫星协同调度。在新生成的基准测试集上进行计算实验验证。

Result: 计算实验表明，该模型能够在非常短的计算时间内高效求解。与当前最先进的非精确方法相比，所提方法具有更高的计算性能潜力。

Conclusion: 本研究填补了SAEOS成像调度问题精确求解方法的空白，提出的约束规划模型能够有效处理超敏捷卫星的复杂调度需求，为实际应用提供了高效的解决方案。

Abstract: As the dependence on satellite imaging continues to grow, modern satellites have become increasingly agile, with the new generation, namely super-agile Earth observation satellites (SAEOS), providing unprecedented imaging flexibility. The highly dynamic capabilities of these satellites introduce additional challenges to the scheduling of observation tasks, as existing approaches for conventional agile satellites do not account for variable observation durations and multiple imaging directions. Although some efforts have been made in this regard, the SAEOS imaging scheduling problem (SAEOS-ISP) remains largely unexplored, and no exact approaches have yet been proposed. In this context, this study presents the first exact Constraint Programming formulation for the SAEOS-ISP, considering flexible observation windows, multiple pointing directions and sequence-dependent transition times across multiple satellites. Computational experiments on a newly generated benchmark set demonstrate that the model can be solved efficiently and within very short computational times. Moreover, the results also show that the proposed approach has the potential to achieve higher computational performance compared to the non-exact approaches that are currently considered state-of-the-art.

</details>


### [228] [Decentralized Motion and Resonant Damping Control for High-Bandwidth and Cross-Coupling Reduction in MIMO Nanopositioners](https://arxiv.org/abs/2601.11982)
*Aditya Natu,Hassan HosseinNia*

Main category: eess.SY

TL;DR: 提出一种用于两轴纳米定位器的分散式双环控制策略，结合内环非最小相位谐振阻尼控制器和外环运动控制器，通过针对性带通阻尼显著降低交叉轴耦合并增强扰动抑制能力。


<details>
  <summary>Details</summary>
Motivation: 压电纳米定位系统在需要纳米级精度和高速运动的精密应用中广泛使用，但轻阻尼谐振和显著的交叉轴耦合严重限制了带宽和扰动抑制能力。

Method: 采用分散式双环控制策略：每个轴包含内环非最小相位谐振阻尼控制器和外环运动控制器。主动阻尼主对角谐振以超越第一结构模式的闭环带宽，同时并行带通阻尼路径专门针对主要影响交叉耦合通道的高阶谐振进行调谐。

Result: 实验结果表明，这种针对性带通阻尼显著减少了交叉轴耦合并增强了扰动抑制能力，同时不影响跟踪精度。

Conclusion: 提出的控制策略有效解决了纳米定位系统中的谐振和交叉耦合问题，实现了更高的带宽和更好的扰动抑制性能。

Abstract: Piezoelectric nanopositioning systems are widely used in precision applications that require nanometer accuracy and high-speed motion; however, lightly damped resonances and pronounced cross-axis coupling severely limit bandwidth and disturbance rejection. This paper presents a decentralized dual-loop control strategy for a two-axis nanopositioner, combining an inner non-minimum-phase resonant damping controller with an outer motion controller on each axis. The dominant diagonal resonance is actively damped to enable closed-loop bandwidths beyond the first structural mode, while a parallel band-pass damping path is specifically tuned to a higher-order resonance that predominantly affects the cross-coupling channels. Experimental results demonstrate that this targeted band-pass damping substantially reduces cross-axis coupling and enhances disturbance rejection, without compromising tracking accuracy.

</details>


### [229] [Profit Maximization for Electric Vehicle Charging Stations Using Multiagent Reinforcement Learning](https://arxiv.org/abs/2601.12028)
*Kun-Yan Jiang,Wei-Yu Chiu,Yuan-Po Tsai*

Main category: eess.SY

TL;DR: 提出基于Double Hypernetwork QMIX的多智能体强化学习框架，优化配备储能和可再生能源的多个电动汽车充电站的协同能源管理，通过内部能源交易机制提高经济效益。


<details>
  <summary>Details</summary>
Motivation: 电动汽车大规模接入电网带来经济效益和环境效益，但无序充电也带来挑战。多个充电站配备储能和可再生能源后，如何通过协同管理和能源交易最大化整体利润成为关键问题。

Method: 采用Double Hypernetwork QMIX多智能体强化学习框架，解决电动汽车需求、可再生能源发电和实时电价的不确定性。该框架缓解价值估计中的高估偏差，支持分布式决策，并包含内部能源交易机制。

Result: 基于真实数据的数值实验表明，相比标准QMIX方法，所提方法在两个区域分别实现了约5.3%和12.7%的总利润提升，在经济和运营效率方面表现优异。在不同电动汽车需求不确定性和可再生能源波动水平下保持稳健性能。

Conclusion: 提出的Double Hypernetwork QMIX框架能有效优化多个充电站的协同能源管理，通过缓解高估偏差和内部能源交易机制，显著提高经济效益和运营效率，为电动汽车充电基础设施的智能管理提供有效解决方案。

Abstract: Electric vehicles (EVs) are increasingly integrated into power grids, offering economic and environmental benefits but introducing challenges due to uncoordinated charging. This study addresses the profit maximization problem for multiple EV charging stations (EVCSs) equipped with energy storage systems (ESS) and renewable energy sources (RES), with the capability for energy trading. We propose a Double Hypernetwork QMIX-based multi-agent reinforcement learning (MARL) framework to optimize cooperative energy management under uncertainty in EV demand, renewable generation, and real-time electricity prices. The framework mitigates overestimation bias in value estimation, enables distributed decision-making, and incorporates an internal energy trading mechanism. Numerical experiments using real-world data demonstrate that, compared to standard QMIX, the proposed method achieves approximately 5.3% and 12.7% higher total profit for the two regions, respectively, highlighting its economic and operational efficiency. Additionally, the approach maintains robust performance under varying levels of EV demand uncertainty and renewable energy fluctuations.

</details>


### [230] [A method for optimizing the structure of the software and hardware complex of a distributed process control system for large industrial enterprises](https://arxiv.org/abs/2601.12070)
*Ruslan Zakirzyanov*

Main category: eess.SY

TL;DR: 提出使用蚁群算法优化大型工业企业连续过程自动化控制系统软硬件结构的方法


<details>
  <summary>Details</summary>
Motivation: 解决基于批量生产组件构建的系统结构选择问题，优化大型工业企业连续过程自动化控制系统的软硬件配置

Method: 使用蚁群元启发式算法，建立形式化优化问题描述，定义优化准则和约束条件

Result: 提供了数值求解示例，分析了算法结果，验证了方法的有效性

Conclusion: 蚁群算法适用于自动化控制系统结构优化，确定了进一步研究方向

Abstract: The article proposes a method for optimizing the structure of the software and hardware complex of an automated control system for continuous technological processes for large industrial enterprises. General information is given on the relevance of the problem of choosing the structure of a system built on the basis of serially produced components, a formal description of the optimization problem is given, the criterion and limitations are highlighted. A solution method using the metaheuristic algorithm of ant colonies is described. A numerical example of the solution is given, the results of the algorithm are analyzed, and directions for further research are determined.

</details>


### [231] [Reachability Guarantees for Energy Arbitrage](https://arxiv.org/abs/2601.12081)
*Tomás Tapia,Yury Dvorkin*

Main category: eess.SY

TL;DR: 提出一个统一框架，将机会约束的终端荷电状态要求与在线阈值策略相结合，用于不确定市场价格下的电池能量套利。


<details>
  <summary>Details</summary>
Motivation: 在不确定的市场价格环境下，电池能量套利需要同时考虑终端荷电状态要求和在线决策策略，现有方法难以统一处理这些问题。

Method: 1) 将多区间套利问题建模为随机动态规划，加入概率性终端荷电状态约束；2) 应用k-搜索算法推导明确的充放电阈值；3) 开发概率重分布剪枝方法计算精确分布；4) 利用荷电状态分布估计满足机会约束的最小停止时间。

Result: 在历史实际价格数据上的计算实验表明，该框架显著改善了荷电状态演化的估计，并支持机会约束的满足。

Conclusion: 该统一框架成功整合了机会约束终端荷电状态要求与在线阈值策略，为不确定市场价格下的电池能量套利提供了有效的解决方案。

Abstract: This paper introduces a unified framework for battery energy arbitrage under uncertain market prices that integrates chance-constrained terminal state-of-charge requirements with online threshold policies. We first cast the multi-interval arbitrage problem as a stochastic dynamic program enhanced by a probabilistic end-of-horizon state-of-charge (SoC) constraint, ensuring with high confidence that the battery terminates within a prescribed energy band. We then apply a $k$-search algorithm to derive explicit charging (buying) and discharging (selling) thresholds with provable worst-case competitive ratio, and compute the corresponding action probabilities over the decision horizon. To compute exact distributions under operational limits, we develop a probability redistribution pruning method and use it to quantify the likelihood of meeting the terminal SoC band. Leveraging the resulting SoC distribution, we estimate the minimum stopping-time required to satisfy the SoC chance constraint. Computational experiments on historical real price data demonstrate that the proposed framework substantially improves the estimation of SoC evolution and supports chance-constraint satisfaction.

</details>


### [232] [Solvability of The Output Corridor Control Problem by Pulse-Modulated Feedback](https://arxiv.org/abs/2601.12210)
*Alexander Medvedev,Anton V. Proskurnikov*

Main category: eess.SY

TL;DR: 针对具有特定结构的三阶系统，证明了通过脉冲调制反馈可在稳态条件下解决输出维持在预定走廊内的问题，并将该结果应用于评估患者特异性药代动力学-药效学模型的安全性可行性。


<details>
  <summary>Details</summary>
Motivation: 解决正时不变单输入单输出系统输出维持在预定值走廊内的问题，特别关注在临床环境中确保患者安全，评估药代动力学-药效学模型是否可通过临床可接受的药物剂量实现安全控制。

Method: 针对具有特定结构的三阶系统，采用脉冲调制反馈控制方法，在稳态条件下分析系统可控性，并将该方法应用于评估神经肌肉阻滞剂Wiener模型的可行性。

Result: 证明了对于具有特定结构的三阶系统，通过脉冲调制反馈总是可以在稳态条件下解决输出走廊维持问题；发现非线性药效学部分参数值过低是导致模型不可行的主要原因。

Conclusion: 脉冲调制反馈可有效解决三阶系统的输出走廊控制问题，该理论框架可用于评估临床药代动力学-药效学模型的安全性可行性，为患者特异性治疗提供理论依据。

Abstract: The problem of maintaining the output of a positive time-invariant single-input single-output system within a predefined corridor of values is treated. For third-order plants possessing a certain structure, it is proven that the problem is always solvable under stationary conditions by means of pulse-modulated feedback. The obtained result is utilized to assess the feasibility of patient-specific pharmacokinetic-pharmacodynamic models with respect to patient safety. A population of Wiener models capturing the dynamics of a neuromuscular blockade agent is studied to investigate whether or not they can be driven into the desired output corridor by clinically acceptable sequential drug doses (boluses). It is demonstrated that low values of a parameter in the nonlinear pharmacodynamic part lie behind the detected model infeasibility.

</details>


### [233] [Analyzing the Impact of EV Battery Charging on the Distribution Network](https://arxiv.org/abs/2601.12236)
*Sahil Aziz,Wajid Ali,Khaliqur Rahman*

Main category: eess.SY

TL;DR: 本文综述了电动汽车充电对配电网的影响，包括电压稳定性、电能质量和系统性能问题，并回顾了充电器拓扑结构及改善策略。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的快速普及，其充电负荷对电网系统产生了负面影响，特别是对配电网造成电压不稳定、峰值负荷增加和可靠性问题，需要系统性地分析和解决这些问题。

Method: 采用文献综述方法，详细分析电动汽车充电对电压特性、电能质量和配电网性能的影响，回顾不同充电器拓扑结构，总结文献中提出的改善充电策略。

Result: 识别了非协调充电是导致配电网电压不稳定、峰值负荷增加和可靠性问题的主要原因，总结了不同充电器拓扑结构对电网的影响，以及管理随机充电、峰值负荷和双向功率流的策略。

Conclusion: 需要采取协调充电策略来缓解电动汽车充电对配电网的负面影响，包括考虑充电随机性、管理峰值负荷和利用双向功率流，以确保电网的稳定性和可靠性。

Abstract: Many countries are rapidly adopting electric vehicles (EVs) due to their meager running cost and environment-friendly nature. EVs are likely to dominate the internal combustion (IC) engine cars entirely over the next few years. With the rise in popularity of EVs, adverse effects of EV charging loads on the grid system have been observed. Since the distribution system (DS) does not cope with the high overloading capacity, the negative impact of EV charging load on the distribution network (DN) cannot be neglected. A high level of EV penetration with uncoordinated charging is the primary cause of voltage instability, increased peak load demand, and reliability issues of the DN. In this paper, a detailed overview of all the notable impacts of EV charging on voltage profile, power quality, and DS performance is discussed. This work also reviews the different topologies of EV chargers and the issues introduced by power converters on the utility grid. Finally, the strategies for improving the charging of EVs proposed in the literature to consider the random nature of EVs charging, the management of peak loads, and bidirectional power flow are summarized.

</details>


### [234] [Worst-case Nonlinear Regression with Error Bounds](https://arxiv.org/abs/2601.12334)
*Alberto Bemporad*

Main category: eess.SY

TL;DR: 提出一种主动学习方法，用于具有确定性误差保证的最坏情况非线性回归，通过最小化最大绝对逼近误差来构建代理模型，并提供经过认证的误差边界。


<details>
  <summary>Details</summary>
Motivation: 在非线性回归中，传统方法通常关注平均误差，但许多应用需要确定性误差保证。现有方法难以处理非光滑的L∞型损失函数，并且缺乏对整个输入域的认证误差边界。

Method: 1) 引入L∞型损失的光滑近似以支持梯度训练；2) 通过全局优化主动学习最大误差点来迭代丰富训练集；3) 构建前馈神经网络等代理模型，最小化最大绝对逼近误差。

Result: 该方法能够生成具有认证最坏情况误差边界的模型，可以是常数边界或输入相关边界。在非线性函数逼近、非凸集表示、复杂非线性动力学不确定模型构建以及显式模型预测控制律逼近等任务中验证了有效性。

Conclusion: 提出的主动学习方法能够为非线性回归问题提供确定性误差保证，通过光滑近似和主动采样策略有效解决了非光滑优化问题，为各种应用提供了具有认证误差边界的可靠代理模型。

Abstract: This paper proposes an active-learning approach to worst-case nonlinear regression with deterministic error guarantees. Given a known nonlinear function defined over a compact set, we compute a surrogate model, such as a feedforward neural network, by minimizing the maximum absolute approximation error. To address the nonsmooth nature of the resulting minimax problem, we introduce a smooth approximation of the $L_\infty$-type loss that enables efficient gradient-based training. We iteratively enrich the training set by actively learning points of largest approximation error through global optimization. The resulting models admit certified worst-case error bounds, either constant or input-dependent, over the entire input domain. The approach is demonstrated through approximations of nonlinear functions and nonconvex sets, as well as through the derivation of uncertain models of more complex nonlinear dynamics within a given model class, and the approximation of explicit model predictive control laws.

</details>


### [235] [An Experimental Comparison of Sliding Mode and Immersion and Invariance Adaptive Controllers forPosition-feedback Tracking of a Simple Mechanical System with Friction](https://arxiv.org/abs/2601.12545)
*Luis Cervantes-Pérez,Víctor Santibáñez,Jesús Sandoval,Romeo Ortega,Jose Guadalupe Romero*

Main category: eess.SY

TL;DR: 论文通过简单摆锤实验装置，比较了滑模自适应位置反馈跟踪控制器与浸入不变自适应控制器在含摩擦机械系统中的性能表现


<details>
  <summary>Details</summary>
Motivation: 验证文献中报道的滑模自适应位置反馈跟踪控制器在含摩擦机械系统中的实际性能，并通过与浸入不变自适应控制器的对比来评估其相对优势

Method: 使用简单摆锤实验装置进行实验验证，比较两种控制器：滑模自适应位置反馈跟踪控制器和基于浸入不变技术的自适应控制器

Result: 通过实验展示了滑模自适应控制器的性能表现，并与浸入不变自适应控制器进行了对比分析

Conclusion: 实验验证了滑模自适应控制器在含摩擦机械系统中的有效性，并通过对比为读者提供了两种控制方法的性能评估

Abstract: The purpose of this paper is to illustrate, in an experimental facility consisting of a simple pendular device, the performance of a sliding mode adaptive position-feedback tracking controller of mechanical systems with friction reported in the literature. To put this experimental evidence in perspective, we compare the performance of the sliding mode scheme with the one obtained by an adaptive controller designed following the well-known immersion and invariance technique.

</details>


### [236] [HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications](https://arxiv.org/abs/2601.12610)
*Maxim Yudayev,Juha Carlon,Diwas Lamsal,Vayalet Stefanova,Benjamin Filtjens*

Main category: eess.SY

TL;DR: HERMES是一个开源高性能Python框架，用于边缘设备的连续多模态传感和AI处理，旨在加速智能辅助技术的临床部署。


<details>
  <summary>Details</summary>
Motivation: 智能辅助技术对残疾人和老年人至关重要，但现有系统面临多模态传感处理、实时闭环AI方法、异构数据流等挑战，限制了临床应用。

Method: 开发HERMES开源框架，支持同步数据采集、实时流式推理、用户PyTorch模型集成，适用于固定实验室和自由生活环境中的分布式传感器。

Result: 在智能假肢用例中验证，4个同步主机协同捕获18个可穿戴和体外模态，展示了HERMES的性能和与智能医疗领域的相关性。

Conclusion: HERMES是首个提供整体方法论的工作，弥合了跨学科实施策略的差距，指导下游AI模型开发，加速智能医疗应用的临床部署。

Abstract: Intelligent assistive technologies are increasingly recognized as critical daily-use enablers for people with disabilities and age-related functional decline. Longitudinal studies, curation of quality datasets, live monitoring in activities of daily living, and intelligent intervention devices, share the largely unsolved need in reliable high-throughput multimodal sensing and processing. Streaming large heterogeneous data from distributed sensors, historically closed-source environments, and limited prior works on realtime closed-loop AI methodologies, inhibit such applications. To accelerate the emergence of clinical deployments, we deliver HERMES - an open-source high-performance Python framework for continuous multimodal sensing and AI processing at the edge. It enables synchronized data collection, and realtime streaming inference with user PyTorch models, on commodity computing devices. HERMES is applicable to fixed-lab and free-living environments, of distributed commercial and custom sensors. It is the first work to offer a holistic methodology that bridges cross-disciplinary gaps in real-world implementation strategies, and guides downstream AI model development. Its application on the closed-loop intelligent prosthesis use case illustrates the process of suitable AI model development from the generated constraints and trade-offs. Validation on the use case, with 4 synchronized hosts cooperatively capturing 18 wearable and off-body modalities, demonstrates performance and relevance of HERMES to the trajectory of the intelligent healthcare domain.

</details>


### [237] [Allocating Corrective Control to Mitigate Multi-agent Safety Violations Under Private Preferences](https://arxiv.org/abs/2601.12616)
*Johnathan Corbin,Sarah H. Q. Li,Jonathan Rogers*

Main category: eess.SY

TL;DR: 提出一个保护隐私的多智能体安全控制框架，通过拍卖机制分配校正努力，确保联合安全约束而不泄露个体偏好


<details>
  <summary>Details</summary>
Motivation: 在多智能体动态系统中，需要确保联合安全约束，同时保护个体智能体的私有偏好信息不被泄露。传统方法可能暴露个体偏好或计算效率低下。

Method: 结合高阶控制屏障函数（HOCBFs）和基于渐进第二价格（PSP）拍卖的隐私保护资源分配机制。当联合安全约束被违反时，智能体通过"避免信用"迭代竞标校正努力，而不是显式求解可行的校正方案。

Result: 该方法通过第二价格支付规则确定的校正方案与社交最优的安全校正行动分布一致。竞标过程高效实现最优分配且不泄露个体私有偏好。在Robotarium平台的多机器人硬件实验中验证了有效性。

Conclusion: 该框架成功实现了多智能体动态系统中的联合安全保证，同时保护了隐私，通过拍卖机制高效分配校正努力，在硬件实验中证明了实用性。

Abstract: We propose a novel framework that computes the corrective control efforts to ensure joint safety in multi-agent dynamical systems. This framework efficiently distributes the required corrective effort without revealing individual agents' private preferences. Our framework integrates high-order control barrier functions (HOCBFs), which enforce safety constraints with formal guarantees of safety for complex dynamical systems, with a privacy-preserving resource allocation mechanism based on the progressive second price (PSP) auction. When a joint safety constraint is violated, agents iteratively bid on new corrective efforts via 'avoidance credits' rather than explicitly solving for feasible corrective efforts that remove the safety violation. The resulting correction, determined via a second price payment rule, coincides with the socially optimal safe distribution of corrective actions. Critically, the bidding process achieves this optimal allocation efficiently and without revealing private preferences of individual agents. We demonstrate this method through multi-robot hardware experiments on the Robotarium platform.

</details>


### [238] [Resilient Interval Observer-Based Control for Cooperative Adaptive Cruise Control under FDI Attack](https://arxiv.org/abs/2601.12625)
*Parisa Ansari Bonab,Elisabeth Andarge Gedefaw,Mohammad Khajenejad*

Main category: eess.SY

TL;DR: 提出结合非线性控制器和区间观测器的控制框架，用于CAV系统在虚假数据注入攻击下的弹性控制，通过神经网络实时估计攻击并保持安全车距。


<details>
  <summary>Details</summary>
Motivation: 联网自动驾驶车辆(CAV)的连接性使其容易受到虚假数据注入(FDI)等网络攻击的威胁，这会损害系统可靠性和安全性。需要确保系统在攻击下的弹性。

Method: 提出结合非线性控制器和区间观测器的控制框架：1) 区间观测器在有界测量噪声下估计领导者状态；2) 基于神经网络的估计器实时估计未知FDI攻击；3) 利用攻击估计值来缓解攻击影响，保持安全车距。融合了基于模型和基于学习的方法。

Result: MATLAB/Simulink仿真结果表明：系统实现了弹性跟踪、精确的FDI攻击估计、对噪声的鲁棒性，展示了在真实CACC应用中应对网络攻击、干扰和有界测量噪声的潜力。

Conclusion: 提出的控制框架通过结合区间观测器和神经网络估计器，能够有效应对CAV系统中的虚假数据注入攻击，确保系统在攻击下的安全性和可靠性，具有实际应用价值。

Abstract: Connectivity in connected and autonomous vehicles (CAVs) introduces vulnerability to cyber threats such as false data injection (FDI) attacks, which can compromise system reliability and safety. To ensure resilience, this paper proposes a control framework combining a nonlinear controller with an interval observer for robust state estimation under measurement noise. The observer bounds leader's states, while a neural network-based estimator estimates the unknown FDI attacks in real time. These estimates are then used to mitigate FDI attack effects maintaining safe inter-vehicle spacing. The proposed approach leverages an idea of interval observer-based estimation and merges model-based and learning-based methods to achieve accurate estimations and real-time performance. MATLAB/Simulink results confirm resilient tracking, precise FDI attack estimation, and robustness to noise, demonstrating potential for real-world CACC applications under cyberattacks, disturbance, and bounded measurement noise.

</details>


### [239] [Multiagent Reinforcement Learning in Enhancing Resilience of Microgrids under Extreme Weather Events](https://arxiv.org/abs/2601.12657)
*Yin Wu,Wei-Yu Chiu,Yuan-Po Tsai,Shangyuan Liu,Weiqi Hua*

Main category: eess.SY

TL;DR: 提出基于多智能体深度强化学习的微电网能量管理系统，通过门控循环单元提取时序特征，结合动作掩码技术，在IEEE 33总线系统中验证了其在降低运营成本和增强电网韧性方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 极端天气事件日益频繁导致电网中断，现有能量管理系统在应对极端天气带来的负荷需求不确定性方面仍面临挑战，需要更灵活的微电网控制策略来增强韧性和降低运营成本。

Method: 提出合作式多智能体深度强化学习框架，引入门控循环单元处理时序数据特征，采用动作掩码技术，在IEEE 33总线系统中使用实际可再生能源发电和负荷数据进行评估。

Result: 数值结果表明，所提方法在降低运营成本方面表现优越，同时在电力中断期间有效增强了微电网的韧性。

Conclusion: 基于多智能体深度强化学习的能量管理系统能够为微电网提供灵活的可扩展性，在电力中断期间增强韧性并降低运营成本，是应对极端天气挑战的有效解决方案。

Abstract: Grid resilience is crucial in light of power interruptions caused by increasingly frequent extreme weather events. Well-designed energy management systems (EMS) have made progress in improving microgrid resilience through the coordination of distributed energy resources (DERs), but still face significant challenges in addressing the uncertainty of load demand caused by extreme weather. The integration of deep reinforcement learning (DRL) into EMS design enables optimized microgrid control strategies for coordinating DERs. Building on this, we proposed a cooperative multi-agent deep reinforcement learning (MADRL)-based EMS framework to provide flexible scalability for microgrids, enhance resilience and reduce operational costs during power outages. Specifically, the gated recurrent unit with a gating mechanism was introduced to extract features from temporal data, which enables the EMS to coordinate DERs more efficiently. Next, the proposed MADRL method incorporating action masking techniques was evaluated in the IEEE 33-Bus system using real-world data on renewable generation and power load. Finally, the numerical results demonstrated the superiority of the proposed method in reducing operating costs as well as the effectiveness in enhancing microgrid resilience during power interruptions.

</details>


### [240] [Network Slicing Resource Management in Uplink User-Centric Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2601.12687)
*Manobendu Sarker,Soumaya Cherkaoui*

Main category: eess.SY

TL;DR: 论文提出了一种在用户中心化无小区大规模MIMO系统中，联合优化带宽分配和用户-接入点关联的方法，以最大化加权和速率并满足eMBB和URLLC切片的异构QoS需求。


<details>
  <summary>Details</summary>
Motivation: 网络切片场景下，密集部署和有限带宽资源常常导致QoS需求无法满足，需要一种能够在资源受限情况下优雅降级并公平保障QoS的解决方案，而不是单纯追求最大化和速率。

Method: 将NP-hard的原问题分解为两个子问题：1）考虑用户优先级、频谱效率和最小带宽需求的带宽分配方案；2）基于优先级的用户-接入点关联分配方法。通过交替优化框架进行联合优化。

Result: 仿真结果显示，相比基准方法，所提方案实现了高达52%的加权和速率提升，eMBB和URLLC切片的QoS成功率分别提高了140%和58%，同时运行时间减少了97%。

Conclusion: 该方案为资源受限的网络切片场景提供了实用且计算高效的解决方案，能够在密集部署和有限带宽条件下实现优雅降级和公平的QoS保障，而非单纯追求最大化和速率。

Abstract: This paper addresses the joint optimization of per-user equipment (UE) bandwidth allocation and UE-access point (AP) association to maximize weighted sum-rate while satisfying heterogeneous quality-of-service (QoS) requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink of a network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) system. The formulated problem is NP-hard, rendering global optimality computationally intractable. To address this challenge, it is decomposed into two sub-problems, each solved by a computationally efficient heuristic scheme, and jointly optimized through an alternating optimization framework. We then propose (i) a bandwidth allocation scheme that balances UE priority, spectral efficiency, and minimum bandwidth demand under limited resources to ensure fair QoS distribution, and (ii) a priority-based UE-AP association assignment approach that balances UE service quality with system capacity constraints. Together, these approaches provide a practical and computationally efficient solution for resource-constrained network slicing scenarios, where QoS feasibility is often violated under dense deployments and limited bandwidth, necessitating graceful degradation and fair QoS preservation rather than solely maximizing the aggregate sum-rate. Simulation results demonstrate that the proposed scheme achieves up to 52% higher weighted sum-rate, 140% and 58% higher QoS success rates for eMBB and URLLC slices, respectively, while reducing runtime by up to 97% compared to considered benchmarks.

</details>


### [241] [Priority-Based Bandwidth Allocation in Network Slicing-Enabled Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2601.12689)
*Manobendu Sarker,Soumaya Cherkaoui*

Main category: eess.SY

TL;DR: 提出了一种在带宽受限的网络切片用户中心化无蜂窝大规模MIMO系统中，联合准入控制和带宽分配的优化方案，以最大化加权和速率并满足eMBB和URLLC切片的异构QoS需求。


<details>
  <summary>Details</summary>
Motivation: 当网络切片用户中心化无蜂窝大规模MIMO系统中的总QoS需求可能超过可用带宽时，需要解决联合准入控制和带宽分配问题，以最大化加权和速率并满足eMBB和URLLC切片的异构QoS需求。

Method: 将NP-hard问题分解为两个子问题，采用顺序框架下的计算高效启发式算法：1) 分层准入控制方案，在带宽稀缺时选择性接纳UE，优先保障URLLC的时延敏感QoS；2) 迭代梯度带宽分配方案，基于边际效用在切片间转移带宽，并在切片内重新分配资源。

Result: 所提方案实现了接近最优的性能，与CVX基准相比加权和速率偏差最多2.2%，同时运行时间减少99.7%。相比无准入控制的轮询基线，eMBB和URLLC切片成功率分别提高1085%和7%。敏感性分析显示方案能有效适应不同eMBB/URLLC流量组合，保持47-51% eMBB和93-94% URLLC成功率。

Conclusion: 该方案通过分层准入控制和迭代梯度带宽分配，在带宽受限场景下有效平衡了加权和速率与QoS保障，实现了接近最优的性能和大幅计算效率提升，适合大规模实际部署。

Abstract: This paper addresses joint admission control and per-user equipment (UE) bandwidth allocation to maximize weighted sum-rate in network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) systems when aggregate quality-of-service (QoS) demand may exceed available bandwidth. Specifically, we optimize bandwidth allocation while satisfying heterogeneous QoS requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink. The formulated problem is NP-hard, rendering global optimality computationally intractable. We decompose it into two sub-problems and solve them via computationally efficient heuristics within a sequential framework. We propose (i) a hierarchical admission control scheme that selectively admits UEs under bandwidth scarcity, prioritizing URLLC to ensure latency-sensitive QoS compliance, and (ii) an iterative gradient-based bandwidth allocation scheme that transfers bandwidth across slices guided by marginal utility and reallocates resources within slices. Simulation results demonstrate that the proposed scheme achieves near-optimal performance, deviating from a CVX-based benchmark by at most 2.2% in weighted sum-rate while reducing runtime by 99.7%, thereby enabling practical real-time deployment. Compared to a baseline round-robin scheme without admission control, the proposed approach achieves up to 1085% and 7% higher success rates for eMBB and URLLC slices, respectively, by intentionally sacrificing sum-rate to guarantee QoS. Sensitivity analysis further reveals that the proposed solution adapts effectively to diverse eMBB/URLLC traffic compositions, maintaining 47-51% eMBB and 93-94% URLLC success rates across varying load scenarios, confirming its robustness for resource-constrained large-scale deployments.

</details>


### [242] [Closed-loop Uplink Radio Resource Management in CF-O-RAN Empowered 5G Aerial Corridor](https://arxiv.org/abs/2601.12694)
*Manobendu Sarker,Md. Zoheb Hassan,Xianbin Wang*

Main category: eess.SY

TL;DR: 提出一种基于O-RAN的CF mMIMO系统，用于5G空中走廊上行资源管理，通过联合优化无人机-O-RU关联和发射功率来最大化最小频谱效率，采用交替优化和CKM技术显著提升性能并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: 5G空中走廊需要高效的无线资源管理，传统方法面临NP-hard复杂度和高信令开销问题，需要一种能在O-RAN架构下实时部署的解决方案。

Method: 1) 将原问题分解为两个可处理的子问题，采用交替优化；2) 提出QoS驱动的多连接关联算法，结合无人机中心和O-RU中心准则；3) 设计二分法引导的定点功率控制算法；4) 利用O-RAN非实时RIC中的CKM进行环境感知CSI推断。

Result: 相比基于内点法的功率分配方案，最小频谱效率提升高达440%，QoS满足率和公平性达到100%，运行时间减少99.7%，支持O-RAN兼容的实时部署。

Conclusion: 提出的O-RAN使能CF mMIMO框架能有效解决5G空中走廊上行资源管理问题，通过创新的关联和功率控制算法结合CKM技术，在保证性能的同时大幅降低复杂度，实现实时部署。

Abstract: In this paper, we investigate the uplink (UL) radio resource management for 5G aerial corridors with an open-radio access network (O-RAN)-enabled cell-free (CF) massive multiple-input multiple-output (mMIMO) system. Our objective is to maximize the minimum spectral efficiency (SE) by jointly optimizing unmanned aerial vehicle (UAV)-open radio unit (O-RU) association and UL transmit power under quality-of-service (QoS) constraints. Owing to its NP-hard nature, the formulated problem is decomposed into two tractable sub-problems solved via alternating optimization (AO) using two computationally efficient algorithms. We then propose (i) a QoS-driven and multi-connectivity-enabled association algorithm incorporating UAV-centric and O-RU-centric criteria with targeted refinement for weak UAVs, and (ii) a bisection-guided fixed-point power control algorithm achieving global optimality with significantly reduced complexity, hosted as xApp at the near-real-time (near-RT) RAN intelligent controller (RIC) of O-RAN. Solving the resource-allocation problem requires global channel state information (CSI), which incurs substantial measurement and signaling overhead. To mitigate this, we leverage a channel knowledge map (CKM) within the O-RAN non-RT RIC to enable efficient environment-aware CSI inference. Simulation results show that the proposed framework achieves up to 440% improvement in minimum SE, 100% QoS satisfaction and fairness, while reducing runtime by up to 99.7% compared to an interior point solver-based power allocation solution, thereby enabling O-RAN compliant real-time deployment.

</details>


### [243] [From Noise to Knowledge: System Identification with Systematic Polytope Construction via Cyclic Reformulation](https://arxiv.org/abs/2601.12695)
*Hiroshi Okajima,Shun Shirahama,Tatsunori Hayashi,Nobutomo Matsunaga*

Main category: eess.SY

TL;DR: 提出一种新颖的辨识算法，将噪声引起的参数波动解释为固有不确定性，构建多面体不确定性模型，通过循环重构和周期N获得多面体顶点，实现从单次实验系统化建模。


<details>
  <summary>Details</summary>
Motivation: 基于模型的控制需要精确数学模型以保证控制性能和稳定性，但由于过程和传感器噪声，获取精确模型具有挑战性。传统方法难以处理噪声引起的参数不确定性。

Method: 提出新颖辨识算法，将噪声引起的参数波动解释为固有不确定性，应用周期N的循环重构到线性时不变系统，产生N个略有变化的参数集作为多面体顶点，实现从单次辨识实验系统化构建多面体模型。

Result: 仿真结果表明显著改进：相比传统方法，所提方法获得更高的参数估计精度，预测误差减少约一半。顶点数N提供了对不确定性表示精度的系统化控制。

Conclusion: 该方法能够从噪声数据中有效构建多面体不确定性模型，为基于模型的控制提供更可靠的数学模型，通过调整顶点数N可以平衡模型精度和计算复杂度。

Abstract: Model-based control requires accurate mathematical models to guarantee control performance and stability. However, obtaining accurate models is challenging due to process and sensor noise. This paper proposes a novel identification algorithm that derives polytopic uncertainty models by interpreting noise-induced parameter fluctuations as intrinsic uncertainty. The method applies cyclic reformulation with period N to linear time-invariant systems, yielding N parameter sets with slight variations that serve as polytope vertices. This enables systematic polytopic model construction from a single identification experiment. Simulation results demonstrate significant improvements: the proposed method achieves higher parameter estimation accuracy and reduces prediction errors by approximately half compared to conventional approaches. The vertex count N provides systematic control over the precision of uncertainty representation.

</details>


### [244] [Sensing-Limited Control of Noiseless Linear Systems Under Nonlinear Observations](https://arxiv.org/abs/2601.12782)
*Ming Li,Fan Liu,Yifeng Xiong,Jie Xu,Tao Liu*

Main category: eess.SY

TL;DR: 本文研究了非线性观测下无噪声线性动力系统控制与感知的基本信息论极限，揭示了状态到观测的平均定向信息率必须超过不稳定动力学的内在扩张率才能保证稳定性的必要条件。


<details>
  <summary>Details</summary>
Motivation: 研究非线性观测模型下线性动力系统的控制与感知的基本性能极限，将经典数据率约束扩展到更具挑战性的非线性观测场景，探索控制与感知组件之间的相互作用。

Method: 采用信息论方法，分析非线性观测通道下的无噪声线性动力系统。通过推导均方可观性和可稳定性的必要条件，并引入对数凹性等正则性假设来建立充分条件，连接信息论界限与估计性能。

Result: 证明了状态到观测的平均定向信息率必须超过不稳定动力学的内在扩张率是系统稳定的必要条件。在对数凹性假设下，微分熵的发散意味着估计误差的收敛，从而闭合了信息论界限与估计性能之间的差距。

Conclusion: 本文揭示了感知层施加的基本性能极限，将经典数据率约束扩展到非线性观测模型，为非线性观测下的控制系统设计提供了理论基础和性能界限。

Abstract: This paper investigates the fundamental information-theoretic limits for the control and sensing of noiseless linear dynamical systems subject to a broad class of nonlinear observations. We analyze the interactions between the control and sensing components by characterizing the minimum information flow required for stability. Specifically, we derive necessary conditions for mean-square observability and stabilizability, demonstrating that the average directed information rate from the state to the observations must exceed the intrinsic expansion rate of the unstable dynamics. Furthermore, to address the challenges posed by non-Gaussian distributions inherent to nonlinear observation channels, we establish sufficient conditions by imposing regularity assumptions, specifically log-concavity, on the system's probabilistic components. We show that under these conditions, the divergence of differential entropy implies the convergence of the estimation error, thereby closing the gap between information-theoretic bounds and estimation performance. By establishing these results, we unveil the fundamental performance limits imposed by the sensing layer, extending classical data-rate constraints to the more challenging regime of nonlinear observation models.

</details>


### [245] [Lessons Learned from Structural Design and Vibration Testing of 50-kg Microsatellites Deployed from the International Space Station](https://arxiv.org/abs/2601.12840)
*Yuji Sakamoto,Junichi Kurihara,Shinya Fujita,Yuji Sato,Toshinori Kuwahara*

Main category: eess.SY

TL;DR: 该论文总结了为满足严格的一年开发周期，如何优化50公斤级微卫星的结构设计和振动测试，成功实现单次试验通过，为ISS部署的微卫星提供了宝贵经验。


<details>
  <summary>Details</summary>
Motivation: 北海道大学和东北大学一直在开发和运营50厘米级微卫星星座进行地球观测。DIWATA-1于2016年发射，部署在ISS约400公里的圆形轨道上。后续卫星需要在一年内完成开发，面临严格的时间限制和技术挑战，特别是对于从ISS部署的50公斤级微卫星，相关案例报道有限。

Method: 论文总结了如何审查和更新先前卫星的结构设计，并优化振动测试方案。通过结构设计优化和测试策略调整，成功在单次试验中完成振动测试，以最小化进度和技术风险。

Result: 成功实现了在严格的一年开发周期内完成卫星结构设计和测试，振动测试一次通过，有效控制了进度和技术风险，为ISS部署的50公斤级微卫星开发提供了可行的技术方案。

Conclusion: 这些经验教训为50公斤级微卫星从ISS部署提供了宝贵的技术见解，特别是在严格时间限制下的结构设计和测试优化策略，填补了该领域案例报道有限的空白。

Abstract: Hokkaido University and Tohoku University have been developing and operating a constellation of 50-cm-class microsatellites for Earth observation. DIWATA-1, launched in 2016, was deployed into a circular orbit at an altitude of approximately 400 km from the International Space Station (ISS). For the subsequent satellite developed in 2021, the structural design and vibration test campaign were optimized to meet a strict one-year development schedule. This paper summarizes how the structural design of the previous satellite was reviewed and updated, and how the vibration test was successfully completed in a single trial to minimize schedule and technical risks. These lessons learned provide valuable insights, as there are only a limited number of reported cases of 50-kg-class microsatellites deployed from the ISS.

</details>


### [246] [System Analysis and Pre-Flight Evaluation of Deployable Solar Panels for 3U CubeSat HOKUSHIN-1](https://arxiv.org/abs/2601.12851)
*Yuji Sakamoto,Masaki Aoi,Sho Suzuki,Takumi Haga,Shumpei Hosokawa,Yuma Abe,Yuya Tasaki,Tsuyoshi Totani,Sou Nakamura,Masaharu Uchiumi,Shinya Fujita*

Main category: eess.SY

TL;DR: 开发3U立方星可展开太阳能电池板的系统设计方法，包括结构分析、热分析和振动测试，为未来月球探测任务提供关键技术


<details>
  <summary>Details</summary>
Motivation: 北海道大学与东北大学、室兰工业大学合作开发3U立方星HOKUSHIN-1，可展开太阳能电池板是未来月球探测任务的关键技术，能够为轨道控制所需的密集通信和推进系统提供足够电力

Method: 通过结构分析、热分析和振动测试来开发和评估可展开太阳能电池板的系统设计方法，卫星尺寸约10x10x34厘米，质量3.99千克，将部署在约400公里高度的圆形轨道上

Result: 开发了适用于3U立方星的可展开太阳能电池板系统设计方法，并展示了新开发的紧凑高效推进系统，卫星将从国际空间站部署到轨道倾角51.6度的约400公里高度圆形轨道

Conclusion: 可展开太阳能电池板的系统设计方法为未来月球探测任务提供了关键技术基础，能够支持功率密集的通信和推进需求，同时验证了紧凑高效推进系统的可行性

Abstract: This paper describes the system design methodology derived from the development and evaluation tests of deployable solar panels to be mounted on a 3U CubeSat. The study mainly includes structural analysis, thermal analysis, and a review of vibration test results. Hokkaido University is developing the 3U CubeSat HOKUSHIN-1 in collaboration with Tohoku University and Muroran Institute of Technology. Deployable solar panels are a key technology for future planned lunar exploration missions, as they enable power-intensive communication and propulsion required for orbit control. The satellite also demonstrates a newly developed compact and efficient propulsion system. The satellite has dimensions of approximately 10x10x34 cm, a mass of 3.99 kg, and will be deployed into a circular orbit at an altitude of about 400 km with an orbital inclination of 51.6 degrees from the International Space Station.

</details>


### [247] [Report on Earth Observation Missions and Ground Station Management using On-Demand Satellite Operation System](https://arxiv.org/abs/2601.12857)
*Yuji Sakamoto*

Main category: eess.SY

TL;DR: 东北大学自2009年发射首颗卫星以来，持续开发并运营50厘米级和立方星级（最大3U）的地球观测卫星和工程演示卫星。2021年发射的50厘米级卫星通过基于云的卫星和地面站管理功能（包括自动指令生成）实现了高效运营。到2022年，使用三个地面站（仙台、函馆和瑞典）同时管理多达八颗运行卫星。本文介绍了迄今为止的运营成果，并介绍了支持高效卫星运营的系统。


<details>
  <summary>Details</summary>
Motivation: 东北大学自2009年以来持续发展小型卫星技术，需要建立高效的卫星运营管理系统来支持日益增长的卫星数量和复杂的运营需求。随着卫星数量的增加（最多同时管理8颗卫星），传统的人工管理方式已无法满足需求，需要开发自动化和云化的运营系统来提高效率。

Method: 开发了基于云的卫星和地面站管理系统，包括自动指令生成功能。建立了三个地面站网络（仙台、函馆和瑞典）来支持卫星运营。系统实现了卫星运营的自动化和集中化管理，能够同时管理多个卫星。

Result: 成功实现了对最多8颗运行卫星的同时日常管理。2021年发射的50厘米级卫星通过云管理系统实现了高效运营。建立了由三个地面站组成的运营网络，支持多卫星协同管理。

Conclusion: 东北大学成功开发并实施了高效的卫星运营系统，通过云管理和自动化技术实现了多卫星的同时管理。该系统为小型卫星的大规模运营提供了可行的解决方案，展示了云技术和自动化在卫星运营中的重要作用。

Abstract: Since the launch of its first satellite in 2009, Tohoku University has continuously developed and operated Earth observation satellites and engineering demonstration satellites in the 50cm-class and CubeSat-class (up to 3U). The 50cm-class satellite launched into operation in 2021 enabled efficient operations through cloud-based management functions for both the satellite and ground stations, including automatic command generation. By 2022, up to eight operational satellites were simultaneously managed on a daily basis using three ground stations (Sendai, Hakodate, and Sweden). This paper presents the operational achievements to date and introduces the system that supports efficient satellite operations

</details>


### [248] [From Vertices to Convex Hulls: Certifying Set-Wise Compatibility for CBF Constraints](https://arxiv.org/abs/2601.12885)
*Shima Sadat Mousavi,Xiao Tan,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文开发了将多个控制屏障函数约束的兼容性从采样顶点传播到其凸包的证书，提出了三种充分可行性条件，并给出了基于区间交集或离线线性规划的计算方法。


<details>
  <summary>Details</summary>
Motivation: 在控制屏障函数框架中，多个安全约束可能相互冲突，导致可行性问题。需要开发系统性的方法来验证多个CBF约束在整个状态空间凸包上的兼容性，而不仅仅在采样点上。

Method: 1. 在温和的凹性和仿射性假设下，提出了三种充分可行性条件：按坐标可行、存在公共输入、凸混合可行。2. 开发了基于区间交集和离线线性规划的计算方法。3. 给出了二次规划安全滤波器在状态上呈仿射的条件，支持通过顶点可行输入的凸组合实现显式实现。

Result: 1. 建立了从采样顶点到整个凸包的兼容性传播证书。2. 提供了验证多个CBF约束兼容性的实用计算方法。3. 证明了在某些条件下QP安全滤波器是状态仿射的，支持显式实现。4. 通过案例研究验证了方法的有效性。

Conclusion: 本文开发了系统性的框架来验证多个CBF约束在整个凸包上的兼容性，提供了实用的计算方法和实现技术，为解决多约束安全控制中的可行性问题提供了理论保证和实用工具。

Abstract: This paper develops certificates that propagate compatibility of multiple control barrier function (CBF) constraints from sampled vertices to their convex hull. Under mild concavity and affinity assumptions, we present three sufficient feasibility conditions under which feasible inputs over the convex hull can be obtained per coordinate, with a common input, or via convex blending. We also describe the associated computational methods, based on interval intersections or an offline linear program (LP). Beyond certifying compatibility, we give conditions under which the quadratic-program (QP) safety filter is affine in the state. This enables explicit implementations via convex combinations of vertex-feasible inputs. Case studies illustrate the results.

</details>


### [249] [Guiding vector field-based guidance under wind disturbances applied to a tailsitter UAV](https://arxiv.org/abs/2601.12987)
*Evangelos Ntouros,Ewoud J. J. Smeur*

Main category: eess.SY

TL;DR: 比较传统轨迹跟踪与GVF路径跟随在尾座式无人机上的性能，发现两者在风况和小初始误差下表现相当，但GVF在初始偏离路径时收敛更平滑。


<details>
  <summary>Details</summary>
Motivation: 开发一个框架来直接比较传统轨迹跟踪引导和基于引导向量场(GVF)的路径跟随引导，评估GVF在尾座式无人机风况飞行中的实际价值。

Method: 基于参数化引导向量场(GVF)开发引导控制律，与先进的加速度和姿态控制架构集成，使用扩展的微分平坦变换考虑风速度矢量，并进行大量仿真比较。

Result: 在风况和小初始位置误差的敏捷飞行场景中，两种引导策略达到相当的跟踪性能；但GVF方法在初始偏离路径时表现出优势，能平滑收敛到期望路径。

Conclusion: GVF的额外复杂性在风况和小初始误差下并不总是合理，但在初始路径偏离情况下GVF具有收敛平滑的优势；同时提出了保证指数稳定性的GVF修改和考虑风速度的微分平坦变换扩展。

Abstract: This paper develops a guidance control law based on a parametric Guiding Vector Field (GVF) and integrates it with a state-of-the-art acceleration and attitude control architecture for tailsitters. The resulting framework enables a direct comparison between traditional trajectory-tracking guidance and GVF-based path-following guidance using a realistic tailsitter model operating under windy conditions. Through extensive simulations, it is shown that for agile flight scenarios with wind and small initial position error, both guidance strategies achieve comparable tracking performance, indicating that the additional complexity introduced by the GVF formulation is not always justified. However, the GVF-based approach exhibits an advantage when initial deviation from the path is present, yielding smooth and well-behaved convergence toward the desired path. Two additional contributions support this evaluation. First, a modification of the parametric GVF is proposed that guarantees exponential stability of the tracking error dynamics for a single integrator system. Second, the differential flatness transform of a tailsitter vehicle is extended to account for explicit knowledge of the wind velocity vector.

</details>


### [250] [Feedforward-Feedback Integration in Flight Control: Reinforcement Learning with Sliding Mode Control](https://arxiv.org/abs/2601.13037)
*Imran Sayyed,Nandan Kumar Sinha*

Main category: eess.SY

TL;DR: 提出一个结合深度强化学习与滑模控制的混合框架，其中RL产生前馈命令，SMC施加执行器限制并保证鲁棒性，适用于非线性欠驱动系统。


<details>
  <summary>Details</summary>
Motivation: 基于学习的控制器能利用非线性耦合改善瞬态响应，但难以在严格输入约束下提供保证；而鲁棒控制如滑模控制能提供保证但较保守。需要结合两者优势。

Method: 将RL策略建模为有界匹配输入，基于Lyapunov理论将SMC增益与允许的前馈界限关联，保证饱和下的稳定性。RL产生前馈命令，SMC施加执行器限制并保证鲁棒性。

Result: 应用于六自由度飞机模型，相比单独RL和SMC，混合控制器改善瞬态行为、减少控制振荡，在模型不确定性和扰动下保持鲁棒性。即使使用部分训练策略，SMC也能稳定瞬态。

Conclusion: 学习增强控制能在严格输入约束下提供鲁棒性保证的同时获得优越性能，结合了学习控制的灵活性和鲁棒控制的保证。

Abstract: Learning-based controllers leverage nonlinear couplings and enhance transients but seldom offer guarantees under tight input constraints. Robust feedback like sliding-mode control (SMC) provides these guarantees but is conservative in isolation. This paper creates a learning-augmented framework where a deep reinforcement learning policy produces feedforward commands and an SMC law imposes actuator limits, bounds learned authority, and guarantees robustness. The policy is modeled as a matched, bounded input, and Lyapunov-based conditions link SMC gains to the admissible feedforward bound, guaranteeing stability under saturation. This formulation is applicable to nonlinear, underactuated plants with hard constraints. To illustrate the methodology, the method is applied to a six-degree-of-freedom aircraft model and compared with Reinforcement Learning and isolated SMC. Simulation results show that the hybrid controller improves transient behavior and reduces control oscillations compared to standalone RL and SMC controllers, while preserving robustness under modeling uncertainties and disturbances. Even using it with partially trained policies, SMC component of the control stabilizes transients, whereas fully trained policies provide faster convergence, reduced constraint violations, and robustness. These results illustrate that learning-augmented control offers superior performance with robustness guarantees under tight input constraints.

</details>


### [251] [Convex Model Predictive Control for Safe Output Consensus of Nonlinear Multi-Agent Systems](https://arxiv.org/abs/2601.13057)
*Chao Wang,Shuyuan Zhang,Lei Wang*

Main category: eess.SY

TL;DR: 提出基于SQP的凸模型预测控制方法，将非线性约束线性化，将原问题转化为二次规划，显著降低计算时间35-52倍


<details>
  <summary>Details</summary>
Motivation: 非线性动力学和安全约束导致模型预测控制中需要解决非线性规划问题，计算负担重，需要更高效的方法实现实时安全输出一致性控制

Method: 基于SQP方案提出凸模型预测控制方法，通过切线投影法将系统动力学线性化并将离散时间高阶控制屏障函数凸化，将原问题转化为可迭代求解的二次规划

Result: 在具有单轮动力学的多智能体系统仿真中，计算时间比基准方法减少35-52倍，证明了该方法适用于实时安全输出一致性控制

Conclusion: 提出的CMPC方法能有效降低计算复杂度，保证SQP方案的收敛性以及CMPC的递归可行性和稳定性，适合实时应用

Abstract: Nonlinear dynamics and safety constraints typically result in a nonlinear programming problem when applying model predictive control to achieve safe output consensus. To avoid the heavy computational burden of solving a nonlinear programming problem directly, this paper proposes a novel Convex Model Predictive Control (CMPC) approach based on a Sequential Quadratic Programming (SQP) scheme. The core of our method lies in transforming the nonlinear constraints into linear forms: we linearize the system dynamics and convexify the discrete-time high-order control barrier functions using a proposed tangent-line projection method. Consequently, the original problem is reduced to a quadratic program that can be iteratively solved within the SQP scheme at each time step of CMPC. Furthermore, we provide the formal guarantee of the convergence of the SQP scheme, and subsequently guarantee the recursive feasibility and stability of CMPC. Simulations on multi-agent systems with unicycle dynamics demonstrate a 35-52 times reduction in computation time compared with baseline methods, confirming the suitability of the proposed approach for real-time safe output consensus control.

</details>


### [252] [Stability of Information-Based Routing in Dynamic Transportation Networks](https://arxiv.org/abs/2601.13066)
*Shaya Garjani,Ashish Cherukuri,Bayu Jayawardhana,Nima Monshizadeh*

Main category: eess.SY

TL;DR: 研究提出一种基于密度依赖交通信息的实时路径引导框架，通过设计信息信号确保自由流状态下唯一均衡的存在和渐近稳定性，从而缓解拥堵并提升网络稳定性。


<details>
  <summary>Details</summary>
Motivation: 实时路径引导技术虽然能管理交通，但可能意外引发拥堵或振荡交通模式。需要识别能确保均衡存在且具有良好稳定性和收敛性的信息信号，特别是在交通密度和路由动态同时演化的场景下。

Method: 分析具有单一OD对的平行路径交通网络，结合交通密度和基于logit的路由动态（两者在同一时间尺度演化）。表征一类密度依赖的交通信息，确保自由流状态下唯一均衡的存在、渐近稳定性，并保持交通密度始终处于自由流区域。

Result: 理论证明了密度依赖交通信息能保证自由流状态下唯一均衡的存在和渐近稳定性。数值案例研究表明该框架能指导设计减少总旅行时间且不损害可信度的交通信息。

Conclusion: 通过设计密度依赖的交通信息信号，可以在不干扰用户的情况下管理交通，缓解拥堵并增强网络稳定性，为实时导航技术的优化提供了理论框架。

Abstract: Recent studies on transportation networks have shown that real-time route guidance can inadvertently induce congestion or oscillatory traffic patterns. Nevertheless, such technologies also offer a promising opportunity to manage traffic non-intrusively by shaping the information delivered to users, thereby mitigating congestion and enhancing network stability. A key step toward this goal is to identify information signals that ensure the existence of an equilibrium with desirable stability and convergence properties. This challenge is particularly relevant when traffic density and routing dynamics evolve concurrently, as increasingly occurs with digital signaling and real-time navigation technologies. To address this, we analyze a parallel-path transportation network with a single origin-destination pair, incorporating joint traffic density and logit-based routing dynamics that evolve at the same timescale. We characterize a class of density-dependent traffic information that guarantees a unique equilibrium in the free-flow regime, ensures its asymptotic stability, and keeps traffic densities within the free-flow region for all time. The theoretical results are complemented by a numerical case study demonstrating how the framework can inform the design of traffic information that reduces total travel time without compromising credibility.

</details>


### [253] [QoS-Aware Energy Optimization via Cell Switching in Heterogeneous Networks](https://arxiv.org/abs/2601.13174)
*Maryam Salamatmoghadasi,Amir Mehrabian,Halim Yanikomeroglu,Georges Kaddoum*

Main category: eess.SY

TL;DR: 提出一个基于信道感知的蜂窝切换优化框架，在保证用户QoS的同时最小化网络功耗，相比基线方法可节省30%功耗


<details>
  <summary>Details</summary>
Motivation: 密集城市区域对移动数据服务的需求增长，需要6G系统中能效更高的无线接入网络。现有基于流量负载的蜂窝切换方法在真实信道条件下难以保证用户服务质量

Method: 提出优化驱动的蜂窝切换框架，联合最小化网络功耗并保证用户QoS，通过强制执行最小接收功率阈值作为卸载决策的一部分，将信道感知信息显式集成到切换过程中

Result: 仿真结果显示，相比基线方法可节省高达30%的功耗，同时在多样化网络条件下完全保持QoS，在真实异构网络中展现出良好的可扩展性和鲁棒性

Conclusion: 该框架通过单一设计参数调节系统在节能和QoS保护模式之间的行为，为可持续6G部署提供了实用解决方案

Abstract: The growing demand for mobile data services in dense urban areas has intensified the need for energy-efficient radio access networks (RANs) in future 6G systems. In this context, one promising strategy is cell switching (CS), which dynamically deactivates underutilized small base stations (SBSs) to reduce power consumption. However, while previous research explored CS primarily based on traffic load, ensuring user quality of service (QoS) under realistic channel conditions remains a challenge. In this paper, we propose a novel optimization-driven CS framework that jointly minimizes network power consumption and guarantees user QoS by enforcing a minimum received power threshold as part of offloading decisions. In contrast to prior load-based or learning-based approaches, our method explicitly integrates channel-aware information into the CS process, thus ensuring reliable service quality for offloaded users. Furthermore, flexibility of the proposed framework enables operators to adapt system behavior between energy-saving and QoS-preserving modes by tuning a single design parameter. Simulation results demonstrate that the proposed approach achieves up to 30% power savings as compared to baseline methods while fully maintaining QoS under diverse network conditions. Scalability and robustness of the proposed method in realistic heterogeneous networks (HetNets) further highlight its potential as a practical solution for sustainable 6G deployments.

</details>


### [254] [Emissions and cost tradeoffs of time-matched clean electricity procurement under inter-annual weather variability: case study of hydrogen production](https://arxiv.org/abs/2601.13202)
*Michael Giovanniello,Dharik S. Mallapragada*

Main category: eess.SY

TL;DR: 该研究评估了在考虑年际天气变化的情况下，清洁电力采购的时间匹配要求对氢生产商基础设施投资、成本和排放的影响，发现年度匹配比小时匹配对天气变化更敏感，且需求灵活性对降低小时匹配成本至关重要。


<details>
  <summary>Details</summary>
Motivation: 当前关于清洁电力采购时间匹配要求的研究通常依赖单一年份天气情景，未能捕捉可变可再生能源发电的年际变化，需要评估这种天气变化如何影响采购驱动的投资、成本和排放结果。

Method: 使用容量扩展模型，以德克萨斯州为案例研究，比较确定性（单一天气情景）和随机性（九个天气情景）建模方法，评估年度和小时时间匹配策略下氢生产商的采购投资、成本和排放。

Result: 采购投资、成本和排放结果对天气情景敏感，年度匹配比小时匹配更敏感；随机建模显示小时匹配相对于年度匹配的成本溢价更高；氢存储提供的需求灵活性对降低小时匹配成本溢价至关重要；部分小时匹配可适度降低成本同时保持最小排放影响；在严格额外性要求下，年度匹配能以更低成本实现与小时匹配相当的排放减少。

Conclusion: 考虑天气变化的时间匹配要求分析显示，年度匹配对天气变化更敏感，而需求灵活性对小时匹配至关重要。政策设计应考虑部分匹配和额外性要求，以平衡成本和排放目标。

Abstract: Time-matching requirements (TMRs) for clean electricity procurement are increasingly adopted in voluntary corporate sustainability initiatives and regulatory frameworks. While prior research has evaluated cost and emissions impacts of hourly vs. annual TMR, these studies typically rely on single-year weather scenarios that do not capture inter-annual variability in variable renewable energy (VRE) generation. We use a capacity expansion model to assess how inter-annual weather variability affects procurement-driven infrastructure investments, costs, and emissions for a grid-connected hydrogen producer under both annual and hourly time-matching strategies. Using a Texas case study, we compare deterministic (single weather scenario) and stochastic (nine weather scenarios) modeling approaches. Both procurement investments and cost and emissions outcomes are sensitive to weather scenario, with annual matching exhibiting greater sensitivity than hourly matching. Stochastic modeling finds higher cost premiums for hourly versus annual matching compared to deterministic modeling, though emissions trends remain directionally consistent. Demand flexibility through H2 storage is critical for lowering hourly matching cost premiums under weather-driven VRE variability. Partial hourly matching (e.g., 80-90% compliance) can modestly reduce costs while maintaining minimal emissions impacts. Finally, we examine how grid-level renewable portfolio standards (RPS) affect additionality and emissions. When stringent additionality is achieved via binding RPS constraints on non-H2 electricity demand, annual matching can produce emissions reductions comparable to hourly matching at lower cost.

</details>


### [255] [Safe Navigation in Cluttered Environments Via Spline-Based Harmonic Potential Fields](https://arxiv.org/abs/2601.13273)
*Theodor-Gabriel Nicu,Florin Stoican,Daniel-Mihail Ioan,Ionela Prodan*

Main category: eess.SY

TL;DR: 提出完整运动规划机制，通过多面体分解可行空间，约束智能体按预定单元序列移动，利用B样条曲线构建调和势能面，实现目标跟踪与避障


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中实现目标跟踪和避障是机器人运动规划的关键挑战，需要确保智能体在障碍物密集的环境中安全导航到目标位置

Method: 1) 对可行空间进行多面体分解；2) 约束智能体按预定单元序列移动；3) 为每个单元构建基于Dirichlet边界条件的调和势能面，边界条件由基数B样条曲线给出；4) 分析曲线特性（周期性、支撑集）和控制点选择；5) 从调和势能面推导控制策略

Result: 该方法能够将智能体安全地沿着单元链从起点引导到目标点，形成有效的"漏斗"效应，确保在复杂环境中的安全导航

Conclusion: 提出的运动规划机制通过结合多面体分解、调和势能面和B样条曲线，实现了在复杂环境中可靠的目标跟踪和避障功能

Abstract: We provide a complete motion-planning mechanism that ensures target tracking and obstacle avoidance in a cluttered environment. For a given polyhedral decomposition of the feasible space, we adopt a novel procedure that constrains the agent to move only through a prescribed sequence of cells via a suitable control policy.
  For each cell, we construct a harmonic potential surface induced by a Dirichlet boundary condition given as a cardinal B-spline curve. A detailed analysis of the curve behavior (periodicity, support) and of the associated control point selection allows us to explicitly compute these harmonic potential surfaces, from which we subsequently derive the corresponding control policy. We illustrate that the resulting construction funnels the agent safely along the chain of cells from the starting point to the target.

</details>


### [256] [Outage Identification from Electricity Market Data: Quickest Change Detection Approach](https://arxiv.org/abs/2601.13605)
*Milad Hoseinpour,Shubhanshu Shekhar,Vladimir Dvorkin*

Main category: eess.SY

TL;DR: 开发基于参数化快速变化检测理论的停电识别方法，利用公开市场信号（电力需求和价格数据）快速识别输电线路停电


<details>
  <summary>Details</summary>
Motivation: 电力系统停电会给市场参与者带来重大财务风险，需要及时检测和对冲。现有方法需要依赖私有系统数据，而公开市场信号（如需求和价格）虽然可用但难以直接用于停电识别

Method: 1. 基于参数化快速变化检测理论，区分停电前后的市场信号状态；2. 利用多参数规划将复杂市场信号分解为具有已知密度的参数化随机变量；3. 构建QCD统计量，当统计量超过适当阈值时触发警报

Result: 在简化的PJM测试平台上进行数值实验，证明该方法能够从公开的电力需求和价格数据流中快速识别线路停电

Conclusion: 该方法能够仅使用公开市场信号有效识别电力系统停电，为市场参与者提供及时的风险管理工具，减少对私有系统数据的依赖

Abstract: Power system outages expose market participants to significant financial risk unless promptly detected and hedged. We develop an outage identification method from public market signals grounded in the parametric quickest change detection (QCD) theory. Parametric QCD operates on stochastic data streams, distinguishing pre- and post-change regimes using the ratio of their respective probability density functions. To derive the density functions for normal and post-outage market signals, we exploit multi-parametric programming to decompose complex market signals into parametric random variables with a known density. These densities are then used to construct a QCD-based statistic that triggers an alarm as soon as the statistic exceeds an appropriate threshold. Numerical experiments on a stylized PJM testbed demonstrate rapid line outage identification from public streams of electricity demand and price data.

</details>


### [257] [Resilient Hierarchical Power Control for Hybrid GFL/GFM Microgrids Under Mixed Cyber-Attacks and Physical Constraints](https://arxiv.org/abs/2601.13615)
*Lifu Ding,Chunhui Hou,Yutong Li,Qinmin Yang*

Main category: eess.SY

TL;DR: 提出一种弹性分层功率控制策略，统一混合微电网中GFL和GFM逆变器的经济调度与动态调节，通过标准化功率增量机制、动态激活方案和抗攻击机制，提高功率分配精度和运行弹性。


<details>
  <summary>Details</summary>
Motivation: 混合微电网中GFL和GFM逆变器的集成带来了复杂的控制挑战：长期经济调度与实时动态调节之间的解耦问题，以及异构逆变器在网络安全不确定性下的物理限制冲突。

Method: 提出弹性分层功率控制策略，包括：1)标准化功率增量机制连接三级和二级控制层；2)针对GFL单元严格有功功率饱和约束的动态激活方案和投影算子；3)集成多尺度注意力机制和LSTM预测器的二级控制协议，抵御FDI攻击和数据包丢失。

Result: 理论分析证实系统实现一致最终有界收敛，在改进的IEEE 33总线系统仿真中，相比传统方法显著提高了并网和孤岛模式下的功率分配精度和运行弹性。

Conclusion: RHPC策略成功统一了混合微电网中的经济调度和动态调节需求，通过创新的控制机制有效解决了GFL/GFM逆变器集成中的关键挑战，增强了系统在网络安全威胁下的鲁棒性。

Abstract: Hybrid microgrids integrating Grid-Following (GFL) and Grid-Forming (GFM) inverters present complex control challenges arising from the decoupling between long-term economic dispatch and real-time dynamic regulation, as well as the distinct physical limitations of heterogeneous inverters under cyber uncertainties. This paper proposes a Resilient Hierarchical Power Control (RHPC) strategy to unify these conflicting requirements within a cohesive framework. A standardized power increment mechanism is developed to bridge the tertiary and secondary layers, ensuring that real-time load fluctuations are compensated strictly according to the optimal economic ratios derived from the tertiary layer. To address the strict active power saturation constraints of GFL units, a dynamic activation scheme coupled with projection operators is introduced, which actively isolates saturated nodes from the consensus loop to prevent integrator wind-up and preserve the stability of the GFM backbone. Furthermore, the proposed framework incorporates a multi-scale attention mechanism and LSTM-based predictors into the secondary control protocol, endowing the system with robustness against unbounded False Data Injection (FDI) attacks and packet losses. Rigorous theoretical analysis confirms that the system achieves Uniformly Ultimately Bounded (UUB) convergence, and simulations on a modified IEEE 33-bus system demonstrate that the proposed strategy significantly improves power sharing accuracy and operational resilience in both grid-connected and islanded modes compared to conventional methods.

</details>


### [258] [Research on Adaptive Inertial Control in Synchronization Systems: Based on Variational Optimization Methods and Their Applications in the Stability of Complex Networks](https://arxiv.org/abs/2601.13753)
*Yiwei Zhou,Zhongcheng Lei,Xiaoran Dai,Wenshan Hu,Hong Zhou*

Main category: eess.SY

TL;DR: 提出基于变分优化的自适应惯性控制策略，解决复杂网络同步系统中固定惯性系数难以平衡瞬态扰动抑制与长期稳定性的核心问题


<details>
  <summary>Details</summary>
Motivation: 针对复杂网络同步系统中固定惯性系数难以平衡瞬态扰动抑制和长期稳定性的核心问题，需要一种能够自适应调节的控制策略

Method: 采用带惯性的Kuramoto模型，通过泛函变分法严格推导时变惯性系数M(t)的解析表达式，构建"基准惯性+扰动反馈"的分层控制结构，并设计基于拉普拉斯特征向量投影的多模态解耦控制策略

Result: 在五种复杂网络（RG、ER、SW、SF、SP）和三种典型扰动（脉冲、单调衰减、振荡衰减）下验证，H(T)降低19%-25%，松弛时间缩短15%-24%，所有系统特征值实部小于-0.25s^-1，满足渐近稳定性准则

Conclusion: 该研究为复杂网络同步系统的稳定性控制提供了新的理论框架和工程实现方案，可广泛应用于电网、通信网络、神经网络等领域

Abstract: Aiming at the core problem that it is difficult for a fixed inertia coefficient to balance transient disturbance suppression and long-term stability in complex network synchronization systems, an adaptive inertia control strategy based on variational optimization is proposed. Taking the Kuramoto model with inertia as the research carrier, the analytical expression of the time-varying inertia coefficient M(t) is strictly derived by the functional variational method, and a hierarchical control structure of "benchmark inertia + disturbance feedback" is constructed to achieve the organic unity of minimizing the vulnerability performance function H(T) and stability constraints. A multimodal decoupling control strategy based on Laplacian eigenvector projection is designed to enhance the feedback strength of the dominant mode by eigenvalue weighting, improving the control accuracy and dynamic response speed. Simulation verification is carried out in complex network systems, and the control performance of regular networks (RG), random networks (ER), small-world networks (SW), scale-free networks (SF) and spider webs (SP) under three typical disturbances of pulses, monotonic decays and oscillatory decays is systematically analyzed. The results show that the proposed strategy reduces H(T) of the five networks by 19%-25%, shortens the relaxation time by 15%-24%, and the real parts of all system eigenvalues are less than -0.25s^-1 , meeting the asymptotic stability criterion. This study provides a new theoretical framework and engineering implementation scheme for the stability control of complex network synchronization systems, which can be widely applied to fields such as power grids, communication networks, and neural networks.

</details>


### [259] [Linear viscoelastic rheological FrBD models](https://arxiv.org/abs/2601.13799)
*Luigi Romano,Ole Morten Aamo,Jan Åslund,Erik Frisk*

Main category: eess.SY

TL;DR: 提出基于广义Maxwell和广义Kelvin-Voigt线性粘弹性模型的两种新型摩擦建模框架，确保有界性和无源性，并展示在机器人控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 将速率和状态依赖的摩擦模型与线性粘弹性理论系统整合，为控制导向的摩擦建模提供更通用的理论框架。

Method: 在FrBD框架下，基于广义Maxwell和广义Kelvin-Voigt两种最通用的线性粘弹性固体模型，提出两种新型摩擦模型公式，并进行有界性和无源性分析。

Result: 两种模型在任何物理有意义的参数化下都满足有界性和无源性，并通过机器人控制实例展示了无源性在控制设计中的应用。

Conclusion: 成功将速率和状态动态摩擦模型与线性粘弹性理论系统整合，为控制导向的摩擦建模提供了新的理论工具。

Abstract: In [1], a new modeling paradigm for developing rate-and-state-dependent, control-oriented friction models was introduced. The framework, termed Friction with Bristle Dynamics (FrBD), combines nonlinear analytical expressions for the friction coefficient with constitutive equations for bristle-like elements. Within the FrBD framework, this letter introduces two novel formulations based on the two most general linear viscoelastic models for solids: the Generalized Maxwell (GM) and Generalized Kelvin-Voigt (GKV) elements. Both are analyzed in terms of boundedness and passivity, revealing that these properties are satisfied for any physically meaningful parametrization. An application of passivity for control design is also illustrated, considering an example from robotics. The findings of this letter systematically integrate rate-and-state dynamic friction models with linear viscoelasticity.

</details>


### [260] [Integrated Sensing and Communication for Low-Altitude Security](https://arxiv.org/abs/2601.13810)
*Ruixing Ren*

Main category: eess.SY

TL;DR: 该论文探讨了在复杂低空环境中，利用集成感知与通信技术解决低空安全治理挑战的方法，包括构建无缝广域感知网络、支持智能特征提取和意图推断等。


<details>
  <summary>Details</summary>
Motivation: 复杂低空环境中密集的低空、低速、小尺寸目标带来了重大安全挑战，现有监管框架难以应对连续广域感知失败和目标意图模糊等问题。

Method: 利用作为下一代移动通信标志的集成感知与通信技术，通过现有蜂窝基础设施和频谱资源，构建无缝广域感知网络，支持智能特征提取和意图推断，实现实时协同决策，并建立动态信任认证框架。

Result: 论文系统回顾了技术体系，分析了安全挑战，预测了ISAC的赋能价值，并讨论了由此产生的开放问题和挑战，为未来研究和产业实施奠定了基础。

Conclusion: ISAC技术为低空安全治理提供了变革性方法，通过利用现有通信基础设施，能够有效应对复杂低空环境中的安全挑战，但仍有开放问题需要进一步研究解决。

Abstract: The dense concentration of low-altitude, slow-speed, and small-size targets in the complex low-altitude environment poses significant security challenges, including failures in continuous wide-area sensing and ambiguous target intent, which existing regulatory frameworks struggle to address. Integrated sensing and communication (ISAC), a hallmark of next-generation mobile communication, offers a transformative approach to low-altitude security governance. By leveraging existing cellular infrastructure and spectrum resources, ISAC enables the construction of a seamless wide-area sensing network, supports intelligent feature extraction and intent inference, facilitates real-time collaborative decision-making, and establishes a dynamic trust authentication framework. This article systematically reviews the technical system, analyzes the security challenges, forecasts the enabling value of ISAC, and discusses the resulting open problems and challenges, thereby laying a foundation for future research and industrial implementation.

</details>


### [261] [Base Station Sleeping Strategy Based on Load Sharing in Ultra-Dense Networks](https://arxiv.org/abs/2601.13832)
*Ruixing Ren,Shan Chen,Xuehan Bao,Pingzheng Ge,Dongming Wang,Junhui Zhao*

Main category: eess.SY

TL;DR: 本文针对5G超密集网络中密集部署小基站导致的高运营成本和低能效问题，提出了一种结合初始连接优化和负载共享基站休眠的集成解决方案，显著提升了能效并减少了活跃基站数量。


<details>
  <summary>Details</summary>
Motivation: 5G超密集网络中密集部署小基站导致运营成本高、能效低的问题，需要协调节能和服务质量优化。

Method: 1) 构建最大化能效和最小化活跃基站数量的多目标优化模型；2) 提出集成解决方案：a) UE-BS初始连接优化（通信可行性筛选、冗余连接移除、过载负载重分配）；b) 基于负载共享的基站休眠（引入综合考虑UE可转移性和备份基站资源的休眠指数，通过低负载基站筛选、相邻基站负载评估、两个接管基站基于容量的负载共享实现精确休眠）。

Result: 在典型超密集网络场景仿真中，相比传统基线方案，所提方案在收敛速度、活跃基站数量优化和能效提升方面表现出显著优势。

Conclusion: 该集成解决方案有效解决了超密集网络中负载不平衡和冗余基站识别困难的问题，实现了能效提升和运营成本降低的协同优化。

Abstract: To address the issues of high operational costs and low energy efficiency (EE) caused by the dense deployment of small base stations (s-BSs) in 5G ultra-dense networks (UDNs), this paper first constructs a multi-objective mathematical optimization model targeting maximizing EE and minimizing the number of active BSs. The model incorporates key constraints including BS operational state, user equipment (UE)-BS connection relationship, and load threshold, laying a theoretical foundation for the coordinated optimization of energy conservation and quality of service. Based on this model, an integrated solution combining UE-BS initial connection optimization and load-sharing based BS sleeping is proposed. In the initial connection phase, with communication quality and BS load as dual constraints, efficient matching between UEs and optimal BSs is achieved through three sequential steps: communication feasibility screening, redundant connection removal, and overload load redistribution. This resolves the problems of load imbalance and difficult identification of redundant BSs in UDNs arising from unordered initial connections. In the BS sleeping phase, a BS sleeping index, comprehensively considering UE transferability and backup BS resources, is innovatively introduced to quantify BS dormancy priority. Through a closed-loop process involving low-load BS screening, adjacent BS load evaluation, and load sharing by two takeover BSs based on their capacity, accurate dormancy of redundant BSs and collaborative load migration are realized. Simulation results in a typical UDNs scenario demonstrate that, compared with the traditional baseline scheme, the proposed solution exhibits significant advantages in convergence speed, optimization of the number of active BSs, and EE improvement.

</details>


### [262] [Small Models, Big Impact: Tool-Augmented AI Agents for Wireless Network Planning](https://arxiv.org/abs/2601.13843)
*Yongqiang Zhang,Mustafa A. Kishk,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: MAINTAINED是一个用于无线网络部署的自主AI代理，通过外部化领域知识到可验证的计算工具中，相比传统LLMs性能提升100倍且消除幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（如ChatGPT）在6G无线网络中具有革命性潜力，但其巨大的计算需求和生成技术上错误信息的倾向构成了部署障碍

Method: 不将领域知识编码到模型参数中，而是协调专门的计算工具进行地理分析、信号传播建模和网络优化

Result: 在真实案例研究中，MAINTAINED在已验证性能指标上比ChatGPT-4o、Claude Sonnet 4和DeepSeek-R1等最先进LLMs表现好100倍，同时需要更少的计算资源

Conclusion: 这种从依赖参数化知识转向将领域知识外部化到可验证计算工具的范式转变，消除了技术规范中的幻觉，实现了无线通信的边缘可部署AI

Abstract: Large Language Models (LLMs) such as ChatGPT promise revolutionary capabilities for Sixth-Generation (6G) wireless networks but their massive computational requirements and tendency to generate technically incorrect information create deployment barriers. In this work, we introduce MAINTAINED: autonomous artificial intelligence agent for wireless network deployment. Instead of encoding domain knowledge within model parameters, our approach orchestrates specialized computational tools for geographic analysis, signal propagation modeling, and network optimization. In a real-world case study, MAINTAINED outperforms state-of-the-art LLMs including ChatGPT-4o, Claude Sonnet 4, and DeepSeek-R1 by up to 100-fold in verified performance metrics while requiring less computational resources. This paradigm shift, moving from relying on parametric knowledge towards externalizing domain knowledge into verifiable computational tools, eliminates hallucination in technical specifications and enables edge-deployable Artificial Intelligence (AI) for wireless communications.

</details>


### [263] [Where to Place a Heavy Payload on a Multirotor UAV for Best Control Performance](https://arxiv.org/abs/2601.13958)
*Sander Doodeman,Paula Chanfreut Palacio,Elena Torta,Duarte Antunes*

Main category: eess.SY

TL;DR: 研究刚性连接重负载位置对多旋翼无人机稳定性和控制性能的影响，特别是负载相对于重心的位置如何影响稳定性，以及如何优化该位置。


<details>
  <summary>Details</summary>
Motivation: 当无人机携带刚性连接的重负载时，负载质量显著影响无人机动力学特性。负载相对于无人机重心的位置会影响系统的稳定性和控制性能，但目前对此缺乏深入分析。研究旨在理解这种影响并找到最优负载位置。

Method: 1. 分析带有负载的完整非线性无人机模型的零动态稳定性；2. 推导线性化无人机模型H2范数的解析表达式，量化系统对白噪声输入干扰的衰减能力。

Result: 1. 零动态稳定性取决于受控输出位置与组合重心之间的垂直有符号距离：输出位于重心下方时零动态不稳定，位于上方时线性化零动态边缘稳定，对输入干扰敏感性降低；2. 控制权限越小，受控输出相对于重心的最优位置越高，以获得更好的闭环白噪声干扰抑制能力。

Conclusion: 重负载相对于无人机重心的位置显著影响系统稳定性和控制性能。将受控输出（如负载位置）放置在重心上方可以提高稳定性并减少对输入干扰的敏感性。控制权限较低时，需要将受控输出放置在更高位置以获得更好的干扰抑制性能。

Abstract: This paper studies the impact of rigidly attached heavy payload placement - where the payload mass significantly influences the UAV's dynamics - on the stability and control performance of a multirotor unmanned aerial vehicle (UAV). In particular, we focus on how the position of such a payload relative to the vehicle's Center of Gravity (CoG) affects the stability and control performance at an arbitrary point of interest on the UAV, such as the payload position, and on how this position can be optimized. Our conclusions are based on two key contributions. First, we analyze the stability of the zero-dynamics of a complete nonlinear model of the UAV with payload. We demonstrate that the stability of the zero dynamics depends on the vertical signed distance in the body-fixed frame between the controlled output position and the combined CoG of the UAV with payload. Specifically, positioning the output below the CoG yields unstable zero dynamics, while the linearized zero dynamics are marginally stable when placing it above, indicating reduced sensitivity to input disturbances. Second, we analyze the performance of the linearized UAV model with payload by providing an analytical expression for the H2-norm, from which we can quantify the system's attenuation to white noise input disturbances. We conclude that less control authority leads to a higher optimal position of the controlled output with respect to the CoG for closed-loop white-noise disturbance rejection capabilities, also when the heavy payload is the controlled output. The results are illustrated through numerical examples.

</details>


### [264] [Data-Driven Safe Output Regulation of Strict-Feedback Linear Systems with Input Delay](https://arxiv.org/abs/2601.14089)
*Zhenxu Zhao,Ji Wang,Weiyao Lan*

Main category: eess.SY

TL;DR: 基于Koopman算子和数据驱动的线性系统安全控制框架，能够识别未知参数、扰动和输入延迟，并保证安全约束


<details>
  <summary>Details</summary>
Motivation: 针对具有已知严格反馈结构但大部分参数、外部扰动和输入延迟未知的线性系统，需要开发一种能够保证安全约束的数据驱动控制方法

Method: 1) 使用Krylov动态模式分解从测量数据中提取系统动态，重构系统和扰动矩阵；2) 采用批量最小二乘辨识方法识别输入通道中的其他未知参数；3) 结合控制屏障函数和反步法设计全状态安全控制器；4) 基于输出数据和驱动信号进行系统辨识，构建观测器估计未测量状态，实现输出反馈控制

Result: 1) 实现了对大量未知系统量的有限时间辨识；2) 输出状态（距离控制输入最远的状态）能够指数收敛到参考轨迹，同时严格保证安全约束；3) 在车辆编队应用中验证了方法的有效性

Conclusion: 提出了一种基于Koopman算子的数据驱动安全控制框架，能够有效处理线性系统中的未知参数、扰动和延迟问题，在保证安全约束的同时实现系统辨识和控制目标

Abstract: This paper develops a data-driven safe control framework for linear systems possessing a known strict-feedback structure, but with most plant parameters, external disturbances, and input delay being unknown. By leveraging Koopman operator theory, we utilize Krylov dynamic mode decomposition (DMD) to extract the system dynamics from measured data, enabling the reconstruction of the system and disturbance matrices. Concurrently, the batch least-squares identification (BaLSI) method is employed to identify other unknown parameters in the input channel. Using control barrier functions (CBFs) and backstepping, we first develop a full-state safe controller. Based on this, we build an output-feedback controller by performing system identification using only the output data and actuation signals as well as constructing an observer to estimate the unmeasured plant states. The proposed approach achieves: 1) finite-time identification of a substantial set of unknown system quantities, and 2) exponential convergence of the output state (the state furthest from the control input) to a reference trajectory while rigorously ensuring safety constraints. The effectiveness of the proposed method is demonstrated through a safe vehicle platooning application.

</details>


### [265] [A flexible language model-assisted electronic design automation framework](https://arxiv.org/abs/2601.14098)
*Cristian Sestito,Panagiota Kontou,Pratibha Verma,Atish Dixit,Alexandros D. Keros,Michael O'Boyle,Christos-Savvas Bouganis,Themis Prodromakis*

Main category: eess.SY

TL;DR: LLM驱动的EDA框架，支持商业工具和多领域设计优化


<details>
  <summary>Details</summary>
Motivation: 现有LLM在EDA中的应用主要局限于开源工具，缺乏对商业EDA环境的支持，无法处理模拟、数字、射频等多领域设计需求，且缺乏设计反馈机制

Method: 提出通用框架，利用LLM生成商业EDA工具兼容文件，通过工具约束和设计输出反馈指导LLM优化，基于功耗-性能-面积报告进行设计优化

Result: 在运放、微带贴片天线和FPGA电路的案例研究中，该框架作为EDA感知助手有效处理了多样化设计挑战

Conclusion: 该框架能够可靠处理多领域设计，支持商业EDA工具，通过反馈机制优化设计，是有效的EDA感知助手

Abstract: Large language models (LLMs) are transforming electronic design automation (EDA) by enhancing design stages such as schematic design, simulation, netlist synthesis, and place-and-route. Existing methods primarily focus these optimisations within isolated open-source EDA tools and often lack the flexibility to handle multiple domains, such as analogue, digital, and radio-frequency design. In contrast, modern systems require to interface with commercial EDA environments, adhere to tool-specific operation rules, and incorporate feedback from design outcomes while supporting diverse design flows. We propose a versatile framework that uses LLMs to generate files compatible with commercial EDA tools and optimise designs using power-performance-area reports. This is accomplished by guiding the LLMs with tool constraints and feedback from design outputs to meet tool requirements and user specifications. Case studies on operational transconductance amplifiers, microstrip patch antennas, and FPGA circuits show that the framework is effective as an EDA-aware assistant, handling diverse design challenges reliably.

</details>


### [266] [The Impact of Interference Cognition on the Reliability and Capacity of Industrial Wireless Communications](https://arxiv.org/abs/2601.14164)
*Yichen Guo,Tao Peng,Yujie Zhao,Yijing Niu,Wenbo Wang*

Main category: eess.SY

TL;DR: 论文研究了干扰认知精度对工业无线网络性能的影响，提出了一个分析框架来量化不同干扰信息精度对可达速率的影响。


<details>
  <summary>Details</summary>
Motivation: 工业无线网络在密集网络和频谱资源重用场景下，干扰严重影响性能。传统网络往往缺乏精细的干扰信息，而新兴的干扰认知技术能以不同精度弥补这一缺陷。需要研究干扰认知精度与系统性能之间的关系。

Method: 提出了一个性能分析框架，利用Nakagami-m衰落信道模型，在有限块长度机制下，对不同精度的信号和干扰信息的平均可达速率进行解析和渐进分析。

Result: 研究发现：1) 识别每个链路的干扰信息对实现最优性能至关重要；2) 获取瞬时信息对信号链路更有益。

Conclusion: 干扰认知精度显著影响工业无线网络性能，特别是每个链路的干扰信息识别和信号链路的瞬时信息获取对优化系统性能具有重要意义。

Abstract: Interference significantly impacts the performance of industrial wireless networks, particularly n severe interference environments with dense networks reusing spectrum resources intensively. Although delicate interference information is often unavailable in conventional networks, emerging interference cognition techniques can compensate this critical problem with possibly different precision. This paper investigates the relationship between precision of interference cognition and system performance. We propose a novel performance analysis framework that quantifies the impact of varying interference information precision on achievable rate.
  Specifically, leveraging the Nakagami-$\mathbf{m}$ fading channel model, we analytically and asymptotically analyze the average achievable rate in the finite blocklength regime for different precision levels of signal and interference information. Our findings reveal the critical importance of identifying per-link interference information for achieving optimal performance. Additionally, obtaining instantaneous information is more beneficial for signal links.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [267] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: CSyMR-Bench：一个用于评估LLMs组合式符号音乐推理能力的基准，包含126个多选问题，结合工具增强代理框架提升性能5-7%


<details>
  <summary>Details</summary>
Motivation: 现有基准过于强调孤立知识或原子分析，缺乏连接音乐结构所需的组合式推理能力评估

Method: 1) 创建CSyMR-Bench数据集：从专家论坛和专业考试中收集126个多选问题；2) 开发工具增强代理框架：利用music21库中的符号音乐分析工具

Result: CSyMR-Bench对现有模型构成非平凡挑战，工具增强代理框架在所有基线中表现最佳，获得5-7%的绝对准确率提升

Conclusion: CSyMR-Bench填补了组合式符号音乐推理评估的空白，工具增强方法显著提升了LLMs的音乐分析能力

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [268] [Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations](https://arxiv.org/abs/2601.12839)
*Gyuyeon Na,Minjung Park,Soyoun Kim,Jungbin Shin,Sangmi Chai*

Main category: cs.LG

TL;DR: RDLI框架通过将专家启发式逻辑嵌入表示学习，结合检索式上下文模块，在极端标签稀缺下显著提升加密货币异常轨迹检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 去中心化加密货币网络中异常轨迹检测面临极端标签稀缺和恶意行为者自适应规避策略的挑战。传统图神经网络虽然能捕捉局部结构模式，但难以内化多跳、逻辑驱动的资金分散和分层等洗钱特征，限制了在FATF旅行规则等监管要求下的法证可追溯性。

Method: 提出关系领域逻辑集成（RDLI）框架，将专家推导的启发式规则作为可微分的逻辑感知潜在信号嵌入表示学习。不同于静态规则方法，RDLI能检测规避标准消息传递的复杂交易流。还包含检索式上下文（RGC）模块，根据监管和宏观经济上下文调节异常评分，减少良性制度变化导致的误报。

Result: 在极端标签稀缺（0.01%）条件下，RDLI在F1分数上比最先进的GNN基线方法提升28.9%。微观专家用户研究进一步证实，RDLI的路径级解释在可信度、感知有用性和清晰度方面显著优于现有方法。

Conclusion: RDLI框架通过将领域逻辑与上下文基础相结合，不仅提高了异常检测的准确性，还增强了可解释性，为加密货币网络中的反洗钱和监管合规提供了更有效的解决方案。

Abstract: Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.

</details>


### [269] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL：自动化的梯度分割框架，通过动态调整子空间比例和更新频率，在保持模型性能的同时显著减少LLM训练的内存占用和计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有FRUGAL框架虽然通过梯度分割减少了LLM训练的内存占用，但其静态超参数（子空间比例ρ和更新频率T）需要昂贵的手动调优，限制了适应性和实用性。

Method: 提出AdaFRUGAL框架，引入两种动态控制机制：(1) 线性衰减的子空间比例ρ，逐步减少内存占用；(2) 基于损失感知的更新频率T调度，降低计算开销。

Result: 在大规模预训练（英语C4、越南语VietVault）和微调（GLUE）实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存占用和训练时间。

Conclusion: AdaFRUGAL为资源受限的LLM训练提供了一个更实用、自主的解决方案，实现了内存、计算和性能之间的良好平衡。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [270] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 论文使用线性代数和哈密顿形式研究LLM嵌入空间结构，发现L2归一化约束使嵌入空间适合哈密顿分析，并探索了量子力学类比


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出离散状态，暗示离散语义表示，希望通过数学工具分析语义关系，特别是借鉴量子力学系统的类比

Method: 应用线性代数和哈密顿形式分析LLM嵌入空间，推导余弦相似度与嵌入向量扰动的关系，探索直接和间接语义转换，采用量子启发视角

Result: L2归一化约束使嵌入空间结构化，适合哈密顿形式分析；建立了余弦相似度与向量扰动的关系；探索了量子类比如零点能量和Koopman-von Neumann力学联系

Conclusion: 这种方法为深入理解LLM提供了有前景的途径，可能有助于开发减少幻觉的新方法，但解释需要谨慎考虑

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [271] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE使用Gumbel-softmax重参数化和直通估计替代传统强化学习方法，通过可微分松弛实现端到端梯度传播，在文本对齐任务中比PPO和REINFORCE表现更好且更稳定。


<details>
  <summary>Details</summary>
Motivation: 当前基于人类反馈的强化学习（RLHF）方法如PPO存在梯度估计方差高、需要精细超参数调优和大量计算资源的问题，需要更简单稳定的替代方案。

Method: GRADE使用Gumbel-softmax重参数化配合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛替代高方差的策略梯度估计，实现从奖励信号到模型参数的端到端梯度传播。

Result: 在IMDB情感控制文本生成任务中，GRADE-STE测试奖励达到0.763±0.344，比PPO（0.510±0.313）和REINFORCE（0.617±0.378）分别提升50%；梯度方差比REINFORCE低14倍以上，训练动态更稳定。

Conclusion: GRADE为LLM对齐提供了一种比强化学习更简单、稳定和有效的替代方案，在保持良好泛化特性的同时显著降低了训练复杂度。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [272] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: Hindsight Preference Replay (HPR) 通过事后重新标记存储的转移数据来增强多目标强化学习，在多个环境中显著提升了性能指标


<details>
  <summary>Details</summary>
Motivation: CAPQL方法在特定偏好下收集的数据无法被其他偏好重用，导致数据利用率低下，限制了多目标强化学习的效率

Method: 提出Hindsight Preference Replay (HPR)策略，在不改变CAPQL架构或损失函数的情况下，对存储的转移数据进行事后重新标记，使用替代偏好来增强监督信号

Result: 在6个MO-Gymnasium运动任务中，HPR-CAPQL在5个环境中提升了超体积(HV)，在4个环境中提升了期望效用(EUM)。特别是在mo-humanoid-v5中，EUM从323±125提升到1613±464，HV从0.52M提升到9.63M

Conclusion: HPR是一种简单而通用的回放增强策略，能够有效提高多目标强化学习中的数据利用效率，显著改善算法性能，为偏好条件化方法提供了有效的改进方案

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [273] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: MIMIC-IV多模态数据处理管道，自动化整合结构化数据、临床笔记、波形和影像数据，显著减少处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态数据，但现有处理工具要么只支持部分模态，要么无法灵活适应下游应用，需要大量手动预处理和对齐工作。

Method: 扩展先前单模态管道，开发综合性、可定制的多模态管道，系统整合所有模态，实现自动化队列选择、跨模态时间对齐，并生成适合静态和时间序列下游应用的标准输出格式。

Result: 开发了完整的处理管道，显著减少多模态数据处理时间，增强MIMIC相关研究的可重复性，提供代码、简单UI和Python包供选择性集成使用。

Conclusion: 该多模态管道解决了MIMIC-IV数据处理中的关键瓶颈，为临床机器学习研究提供了高效、可重复的工具，有望推动该领域的研究进展。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [274] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型解决LLMs缺乏运行时记忆机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求

Method: 提出新型神经记忆存储架构——辅助预测压缩记忆模型（ApCM模型）

Result: 从摘要中无法得知具体实验结果

Conclusion: ApCM模型旨在解决LLMs的记忆机制问题，提升适应动态个性化交互的能力

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [275] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 该论文提出了一种改进的基于被动传感器的人类活动识别方法，通过时间聚类和循环时间特征增强特征加权，在多个真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要支持老年人在家中独立安全生活。使用被动红外传感器和门传感器监测日常活动对预防性医疗干预很重要，但现有方法在有效利用时间信息方面存在挑战。

Method: 1) 将活动聚类为早晨、下午和晚上，计算不同的互信息矩阵进行特征加权；2) 扩展特征向量，加入一天中的时间和一周中的天作为循环时间特征；3) 添加用户位置跟踪特征。

Result: 在四个真实世界数据集的三个中，相比现有最先进方法，获得了更高的准确率和F1分数，在低数据量情况下提升最明显。

Conclusion: 该方法展示了开发有效智能家居解决方案支持"原地养老"的潜力，通过更好地整合时间和空间信息改进了人类活动识别。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [276] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 本文综述了机器学习在1型糖尿病低血糖预测中的应用，比较了不同预测时间窗口下回归与分类模型的性能，发现1小时内预测效果最佳，传统ML方法在分类任务中表现更好，而深度学习在回归任务中更优，个性化数据能提升性能但受数据质量限制。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用。低血糖（血糖低于70 mg/dL）会增加死亡风险。机器学习模型可以通过预测低血糖事件来改善糖尿病管理，但目前缺乏对不同预测时间窗口、模型类型、影响因素和个性化效果的全面比较。

Method: 本文是一篇综述研究，系统分析了基于连续血糖监测数据的机器学习模型。研究比较了回归模型（预测血糖值）和分类模型（识别低血糖事件）在不同预测时间窗口（短期15-120分钟，长期3-24小时以上）的性能。探讨了四个关键问题：预测准确性时间窗口、最佳模型类型、影响因素以及个性化数据的效果。

Result: 1) 1小时内的预测时间窗口效果最佳；2) 传统机器学习方法在分类任务中表现最好，深度学习在回归任务中表现最优，单一模型无法在多个时间窗口都表现良好；3) 多变量数据集和输入序列长度影响模型性能；4) 个性化数据能提升性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习在1型糖尿病低血糖预测中具有重要应用价值，但最佳预测时间窗口为1小时内。模型选择应根据具体任务类型（分类或回归）而定，且需要考虑多变量数据和输入序列长度的影响。虽然个性化数据能提升性能，但实际应用中基于人群的模型更为实用。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [277] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: MoE架构通过软分区表示空间来降低局部敏感性，同时增加表示的有效秩，Top-k路由产生低秩集中结构，全软路由产生高秩分散表示。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何特性的影响，理解路由机制如何作为表示空间的软分区，以及这种分区如何影响函数的局部几何和表示结构。

Method: 引入双雅可比-PCA谱几何探针，通过雅可比奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在可控的MLP-MoE设置下比较密集、Top-k和全软路由架构。

Result: MoE路由一致降低局部敏感性，专家局部雅可比矩阵显示较小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示在更多主方向上分布方差，表明在相同输入分布下具有更高的有效秩。平均专家雅可比矩阵几乎正交，表明变换分解为低重叠的专家特定子空间。

Conclusion: MoE可以几何解释为函数空间的软分区，在平坦化局部曲率的同时重新分配表示方差，Top-k路由产生低秩集中结构，全软路由产生高秩分散表示。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [278] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 几何注意力（GA）通过四个独立输入定义注意力层：载体、证据核规则、探针族和锚定/更新规则，将不变结构与建模选择分离，实现注意力机制的系统化比较和扩展。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax）缺乏统一的理论框架，难以进行系统化比较和扩展。本文旨在建立一个几何注意力框架，将注意力层的核心组件形式化，分离不变结构与建模选择。

Method: 提出几何注意力（GA）框架，通过四个独立组件定义注意力层：1）有限载体（可寻址索引），2）证据核规则（如何从掩码原始分数和链接产生非负权重），3）探针族（可观测量的集合），4）锚定/更新规则（选择和应用代表性核）。该框架支持多种注意力变体，包括softmax、低秩交互、多头/混合核、基于计划的锚定等。

Result: 在标量关系工作表示和证据的乘法组合律下，可接受的链接族是指数族，产生Gibbs权重；行锚定包含softmax核族作为子机制。通过商掉一元行/列分数场，剩余交互分量具有规范秩r正态形式（Eckart-Young/SVD）；点积分数图实现相应的低秩交互机制。

Conclusion: 几何注意力框架将注意力机制的不变结构与具体建模选择分离，为系统化比较和扩展注意力机制及基于注意力的架构提供了理论基础。该框架支持固定载体（标准Transformer）、自适应载体、多阶段深度等多种机制，并统一了多种现有注意力变体。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [279] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 提出Noise Diffused Symmetric Attention Transformer，在保持Symmetric Attention内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准测试中取得介于原始Symmetric Attention和GPT2基础模型之间的准确率，同时显著减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模急剧增大，内存占用问题导致难以在单设备上部署，需要多设备计算从而增加成本。稀疏注意力技术成为减少模型参数的有效途径，但现有Symmetric Attention方法在性能上仍有提升空间。

Method: 提出Noise Diffused Symmetric Attention Transformer统一架构，基于Symmetric Dot-Product Attention（对称注意力）技术，通过添加噪声扩散机制来增强模型性能，同时保持原有的内存优势。

Result: 在GPT2基础模型上验证，在GLUE基准测试任务中，准确率表现介于原始Symmetric Attention和GPT2基础模型之间，同时实现了显著的模型尺寸缩减。

Conclusion: 提出的Noise Diffused Symmetric Attention Transformer在保持稀疏注意力内存优势的同时，通过微小开销实现了性能提升，为大规模语言模型的高效部署提供了有效解决方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [280] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 该论文提出使用Fisher信息度量PINNs对物理系统动态行为的捕获程度，通过比较PINN学习模型与原始解析模型的Fisher信息景观来评估PINN的保真度。


<details>
  <summary>Details</summary>
Motivation: 当前PINNs在求解微分方程和建模物理系统方面表现出色，但缺乏量化PINN是否完全捕获系统完整动态行为（超越简单轨迹预测）的严格方法。需要一种评估PINN是否准确学习到系统底层动力学的方法。

Method: 提出使用可微动力系统的Fisher信息（记为g_F^C）作为评估指标。该方法通过计算和比较原始解析模型与训练后PINN的Fisher信息景观来量化PINN的保真度。具体实验使用汽车动力学模型，基于各自系统动力学的雅可比矩阵进行计算和比较。

Result: 论文提出了一个实验框架，但未提供具体实验结果。框架表明如果PINN准确学习到底层动力学，则PINN推导出的Fisher信息景观应与原始解析模型紧密匹配，这标志着PINN不仅捕获了状态演化，还捕获了关键的几何和稳定性特性。

Conclusion: 提出的基于Fisher信息的评估框架为量化PINNs对物理系统动态行为的捕获程度提供了一种新方法，能够评估PINN是否全面保真地表示系统的复杂动态特性，超越了简单的轨迹预测评估。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [281] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 本文提出了一种针对监督学习的公平性预处理方法，通过HGR相关性分析发现现有数据公平方法正则化过强，设计了在公平性和效用间权衡的预处理映射，并理论分析了下游模型的公平性改进和效用保持条件。


<details>
  <summary>Details</summary>
Motivation: 现有公平性预处理方法分为两类：数据公平性（独立于下游模型）和任务定制公平性（考虑监督学习任务）。作者认为数据公平性方法从HGR相关性角度看施加了过强的正则化，因此需要设计更适合监督学习的预处理方法。

Method: 提出了一种新颖的监督学习定制预处理框架，在获得预处理映射时考虑公平性和效用的权衡。理论分析了任意下游监督模型在转换数据上的行为，找到保证其公平性改进和效用保持的充分条件。

Result: 通过表格数据和图像数据集的对比研究，显示该方法在多个下游模型中保持一致的权衡，优于现有竞争模型。特别在计算机视觉数据上，该方法仅改变与核心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 本文首次在任务定制方法分支中理论研究了使用预处理数据时的下游保证，提出的框架在公平性和效用间实现了更好的平衡，为监督学习的公平性预处理提供了理论支持和实践验证。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [282] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 提出了一种通过分数匹配获取梯度，将带约束优化问题转化为无约束分层优化目标的方法，首次实现了使用严格梯度的确定性全局优化，并揭示了全局优化与基于扩散的生成建模之间的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 传统梯度下降方法存在局限性：只能找到局部最优解，且仅适用于连续可微问题和简单凸约束。需要解决这些限制，处理各种复杂约束的优化问题。

Method: 将所有带复杂约束的优化问题统一为无约束的分层优化目标，通过分数匹配获取梯度进行优化。这种方法将约束优化转化为无约束问题，使用确定性方法进行全局优化。

Result: 首次实现了使用严格梯度的确定性全局优化方法，在简单构造和复杂实际实验中得到了验证。更重要的是，揭示了全局优化与基于扩散的生成建模之间的深刻联系。

Conclusion: 该方法突破了传统梯度下降的局限性，为处理各种复杂约束的优化问题提供了新思路，并建立了全局优化与扩散生成模型之间的理论联系，具有重要的理论和实践意义。

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [283] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出一个联邦学习框架，用于在异构可再生能源生产损失下校准参数化保险指数，通过分布式优化学习共同指数而不共享原始数据。


<details>
  <summary>Details</summary>
Motivation: 传统参数化保险指数校准需要共享敏感的生产数据，这在可再生能源领域存在隐私和异质性挑战。需要一种既能保护数据隐私又能处理不同生产者异质性（方差和链接函数）的校准方法。

Method: 生产者使用Tweedie广义线性模型在本地建模损失，通过联邦学习框架（比较FedAvg、FedProx和FedOpt算法）学习共同指数，直接最小化全局偏差目标，无需共享原始观测数据。

Result: 在德国太阳能发电生产的实证应用中，联邦学习在适度异质性下恢复了可比较的指数系数，同时提供了更通用和可扩展的框架。

Conclusion: 联邦学习为参数化保险指数校准提供了一种隐私保护、可扩展的解决方案，能够处理生产者间的异质性，在可再生能源保险领域具有应用潜力。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [284] [Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning](https://arxiv.org/abs/2601.11657)
*Jack T. Beerman,Shobhan Roy,H. S. Udaykumar,Stephen S. Baek*

Main category: cs.LG

TL;DR: D-PARC架构通过可变形物理感知循环卷积，在保持网络精简的同时，超越更大规模网络在复杂物理系统预测中的性能


<details>
  <summary>Details</summary>
Motivation: 当前CNN架构在处理高度非线性流体时存在局限性，单纯扩大模型规模对物理建模效果提升有限，需要借鉴混合拉格朗日-欧拉数值方法的物理直觉来改进架构设计

Method: 提出可变形物理感知循环卷积（D-PARC），借鉴混合拉格朗日-欧拉方法思想，克服CNN的刚性限制，通过可变形核实现自适应学习策略

Result: 在Burgers方程、Navier-Stokes方程和反应流等多个物理系统中，D-PARC相比更大规模架构获得更优的预测精度；分析显示核表现出反聚集行为，形成独特的"主动过滤"策略，有效感受野分析证实D-PARC能自主在高应变区域集中资源

Conclusion: 物理直觉驱动的架构设计优于参数规模扩展，精简网络的策略性学习为物理感知深度学习提供了比盲目网络扩张更有效的路径

Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned "active filtration" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.

</details>


### [285] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 提出一种在超稀疏采样下（每行仅C个观测）估计矩阵行空间或二阶矩矩阵的方法，通过归一化观测频率和梯度下降恢复缺失的二阶矩信息。


<details>
  <summary>Details</summary>
Motivation: 针对大规模稀疏面板数据（行数远大于列数）的超稀疏采样场景，传统矩阵补全方法在每行观测数少于矩阵秩时无法准确补全，转而估计矩阵的行空间或二阶矩矩阵。

Method: 提出无偏估计器：对二阶矩矩阵的每个非零观测项按其观测频率归一化，然后使用梯度下降补全二阶矩矩阵的缺失项。归一化将n个二项随机变量的加权和除以总观测数。

Result: 理论证明：当n ≥ O(dr⁵ε⁻²C⁻²log d)时，梯度下降的任意局部最小值都近似为全局最优，能以ε²误差恢复T。实验验证：在MovieLens数据集上减少88%偏差，在Amazon评论数据集上减少59%的T恢复误差和38%的M恢复误差。

Conclusion: 该方法在超稀疏采样下有效估计二阶矩矩阵，适用于大规模稀疏面板数据，相比基线方法显著提升性能，并验证了n相对于d的线性采样复杂度。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [286] [Machine learning model for predicting surface wettability in laser-textured metal alloys](https://arxiv.org/abs/2601.11661)
*Mohammad Mohammadzadeh Sanandaji,Danial Ebrahimzadeh,Mohammad Ikram Haider,Yaser Mike Banad,Aleksandar Poleksic,Hongtao Ding*

Main category: cs.LG

TL;DR: 开发机器学习框架，利用形态和化学特征预测激光纹理金属合金的润湿性，准确率达R²=0.942。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性由形貌和化学性质共同决定，对传热、润滑、微流控和表面涂层等应用至关重要。传统方法难以准确预测复杂表面的润湿行为。

Method: 使用纳秒激光纹理化和化学浸渍处理制备超亲水和超疏水表面；通过Laws纹理能量法和轮廓仪量化形态特征，XPS分析化学特征；训练包含残差连接、批量归一化和dropout正则化的集成神经网络模型。

Result: 模型预测精度高（R²=0.942，RMSE=13.896），优于先前方法；特征重要性分析显示表面化学对接触角预测影响最大，形貌特征也有显著贡献。

Conclusion: 该工作展示了人工智能通过捕捉表面特性的复杂相互作用来建模和预测润湿行为的潜力，为设计定制功能表面提供了数据驱动的途径。

Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.

</details>


### [287] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，将后训练量化的不同方法（如AWQ和GPTQ）解释为对激活敏感性的不同近似，该敏感性定义为通道扰动对损失的期望影响。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练量化方法（如AWQ和GPTQ）虽然经验表现良好，但缺乏统一的理论基础，不清楚它们近似的是什么底层量。这些方法在概念上分散，需要统一的框架来理解它们之间的关系。

Method: 通过一阶泰勒展开，将激活敏感性形式化为梯度加权激活的平方范数，提供了一个原则性的通道重要性度量。在此框架下，AWQ和GPTQ被解释为在不同简化假设下恢复敏感性的互补近似。

Result: 建立了激活敏感性的统一理论框架，揭示了AWQ和GPTQ方法之间的理论联系，分析了敏感性度量的设计空间，连接了梯度显著性、Fisher信息和Hessian准则，并阐明了它们与经典剪枝方法的关系。

Conclusion: 本文为理解和比较后训练量化方法提供了概念基础，通过敏感性视角统一了不同的量化方法，而不是提出新的量化算法。这为未来的量化方法设计提供了理论指导。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [288] [Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation](https://arxiv.org/abs/2601.12380)
*Ou Deng,Shoji Nishimura,Atsushi Ogihara,Qun Jin*

Main category: cs.LG

TL;DR: SNI是一个可解释的混合类型数据插补框架，通过可控先验特征注意力模块结合统计先验和神经特征注意力，提供内在的依赖关系诊断和统计-神经权衡参数。


<details>
  <summary>Details</summary>
Motivation: 现实世界表格数据库通常包含连续测量值和分类记录，但缺失条目普遍存在且会扭曲下游分析。现有方法要么缺乏可解释性，要么无法有效处理混合数据类型。

Method: 提出统计-神经交互框架，通过可控先验特征注意力模块耦合相关性导出的统计先验与神经特征注意力，学习头级先验强度系数，软性正则化注意力朝向先验，同时允许数据驱动的偏差。

Result: 在6个数据集上与6个基线方法比较，在30%MCAR/strict-MAR缺失下，SNI在连续变量指标上具有竞争力，但在分类变量上常被准确率优先的基线方法超越；提供内在依赖关系诊断和明确的统计-神经权衡参数。

Conclusion: SNI在可解释性和性能之间提供权衡，特别适用于需要依赖关系诊断和明确权衡参数的部署场景，但在严重不平衡分类目标上存在局限性。

Abstract: Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{λ_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.

</details>


### [289] [Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction](https://arxiv.org/abs/2601.11667)
*Xiaojie Xia,Huigang Zhang,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.LG

TL;DR: 提出一种高效方法，通过块级局部蒸馏和贪心层替换策略，将预训练全注意力模型转换为任务特定的混合注意力模型，平衡计算效率与性能


<details>
  <summary>Details</summary>
Motivation: 全注意力Transformer计算复杂度高，线性注意力效率高但性能下降，混合模型需要昂贵训练和复杂设计，需要一种高效转换预训练模型的方法

Method: 1) 通过块级局部蒸馏将预训练全注意力权重迁移到线性注意力模块；2) 贪心层替换策略迭代替换全注意力块为线性块，同时监控验证性能

Result: 该方法能在单次高效过程中获得任务特定的混合模型，无需昂贵重新训练或神经架构搜索，适用于各种预训练全注意力骨干和下游任务

Conclusion: 提出的方法有效解决了混合注意力模型训练昂贵和设计困难的问题，实现了计算效率与模型性能的良好平衡

Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.

</details>


### [290] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基策略预测技术，通过利用旧梯度预测策略更新，在有限通信下减少基策略与当前策略的差距，显著降低通信轮数需求。


<details>
  <summary>Details</summary>
Motivation: 传统合作多智能体强化学习通常假设能频繁访问全局信息（如团队奖励、其他智能体动作），但在去中心化系统中高通信成本使这不可行。当通信受限时，智能体只能依赖过时信息估计梯度和更新策略，而常用的重要性采样方法在通信受限（缺失数据概率高）时变得不稳定。

Method: 提出基策略预测技术，利用旧梯度预测策略更新，并为一系列基策略收集样本，从而减少基策略与当前策略之间的差距。这种方法能在一次通信轮次内收集预测基策略的样本，显著减少通信轮数需求。

Result: 理论上证明算法在势博弈中能以O(ε^{-3/4})通信轮数和O(poly(max_i |A_i|)ε^{-11/4})样本数收敛到ε-纳什均衡，改进了现有最优结果。在一般马尔可夫合作博弈中也能找到智能体层面的局部最优解。实验在模拟游戏和MAPPO复杂环境中验证了有效性。

Conclusion: 基策略预测技术能有效解决有限通信下的多智能体强化学习问题，显著降低通信成本和样本复杂度，且不依赖于联合动作空间大小的指数级依赖，为实际去中心化系统提供了可行的解决方案。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [291] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: IPEC是一种测试时方法，通过利用先前查询样本的信息优化原型估计，在少样本分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的少样本方法在测试时遵循批次独立性假设，无法利用先前批次积累的宝贵知识，限制了性能提升。

Method: 提出增量原型增强分类器(IPEC)：1)维护动态辅助集，选择性纳入高置信度查询样本；2)设计双重过滤机制评估样本质量；3)基于贝叶斯解释，将支持集视为先验，辅助集视为数据驱动的后验；4)采用"预热-测试"两阶段推理协议。

Result: 在多个少样本分类任务上的广泛实验验证了IPEC的优越性能，能够构建更稳定、更具代表性的原型，减少对初始支持集的依赖。

Conclusion: IPEC通过测试时利用先前查询样本信息有效解决了少样本学习中的批次独立性限制问题，提供了一种实用且性能优越的解决方案。

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [292] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 该论文提出了一种基于矩阵迹幂计算对数行列式的新方法，通过矩生成函数变换和插值技术，在常数时间内提供对数行列式的点估计和可证明的上下界。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯模型比较和高斯过程推断中，计算大型对称正定矩阵的对数行列式是一个关键问题。传统方法使用矩阵向量积和多项式近似，但本文研究另一种模型：当矩阵幂可用时，通过迹幂来计算对数行列式。

Method: 1. 使用归一化特征值的矩生成函数 M(t) = E[X^t]，将对数行列式问题转化为估计 M'(0)
2. 通过变换 K(t) = log M(t) 压缩数值范围，利用 K(0)=K(1)=0 的锚点
3. 在 m+1 个连续整数点插值 K 函数，然后微分估计 K'(0)
4. 从相同的迹信息推导出 (det A)^{1/n} 的上界，给定谱下界 r ≤ λ_min 时获得下界
5. 提供间隙诊断指标来评估点估计的可信度

Result: 1. 证明了基本限制：使用有限正矩的任何连续估计器在无界条件数下无法达到均匀精度
2. 所有估计器和界计算成本为 O(m)，与矩阵维度 n 无关
3. 当 m ∈ {4, ..., 8} 时，实际上是常数时间计算
4. 方法提供了对数行列式的点估计和可证明的上下界

Conclusion: 该方法通过矩生成函数变换和插值技术，为对数行列式计算提供了一种高效的新途径，特别适用于矩阵幂可用的场景。虽然存在理论限制，但通过提供可证明的上下界和诊断指标，能够在实际应用中可靠地估计对数行列式。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [293] [A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning](https://arxiv.org/abs/2601.11670)
*Jinshi Liu,Pan Liu*

Main category: cs.LG

TL;DR: 提出CoVar理论框架，通过结合最大置信度和残差类方差来改进半监督学习中的伪标签选择，无需固定阈值


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习中的伪标签选择策略通常依赖固定的置信度阈值，但深度网络经常过度自信：高置信度预测可能错误，而有信息量的低置信度样本却被丢弃

Method: 从熵最小化原则出发，推导出结合最大置信度(MC)和残差类方差(RCV)的可靠性度量，将伪标签选择转化为置信度-方差特征空间中的谱松弛问题，设计无需阈值的选择机制

Result: 在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet数据集上，使用不同标签比例和骨干网络，CoVar作为插件模块持续改进强基线方法

Conclusion: 结合置信度和残差类方差比固定置信度阈值为伪标签选择提供了更可靠的基础，CoVar框架能有效纠正过度自信但不稳定的预测

Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)

</details>


### [294] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出一个统一框架，用于在两人零和矩阵博弈和马尔可夫博弈中恢复奖励函数，利用熵正则化和量化响应均衡解决逆问题的模糊性和数据覆盖有限问题。


<details>
  <summary>Details</summary>
Motivation: 估计驱动智能体行为的未知奖励函数是逆强化学习和博弈论的核心问题。现有方法面临逆问题的固有模糊性、可行奖励的非唯一性以及观测数据覆盖有限等挑战。

Method: 建立基于量化响应均衡的奖励函数可识别性理论，提出适用于静态和动态设置的新算法，可结合最大似然估计等方法，从观测到的策略和动作中学习奖励函数。

Result: 提供了算法的可靠性和样本效率的强理论保证，并通过广泛的数值研究证明了该框架在实际竞争环境中的有效性，为决策制定提供了新见解。

Conclusion: 该研究为两人零和博弈中的奖励函数恢复提供了一个统一的理论和算法框架，解决了逆问题的挑战，并在理论和实证上都展示了其有效性。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [295] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型与LLM的混合框架，为野火风险管理生成结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际运营需求，无法满足一线应急人员和消防服务的实际需要。有效的野火管理需要多目标分析，涵盖气象危险、点火活动、干预复杂性和资源调动等多个维度，而非依赖单一预测指标。

Method: 开发混合框架：为每个风险维度建立预测模型，然后使用大型语言模型（LLMs）将异质输出合成为结构化的可操作报告。

Result: 这是一个概念验证研究，提出了框架设计但尚未展示具体实施结果。

Conclusion: 提出的混合框架有望提高野火风险评估的实用性，为应急响应提供更全面、可操作的信息支持。

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [296] [Online Continual Learning for Time Series: a Natural Score-driven Approach](https://arxiv.org/abs/2601.12931)
*Edoardo Urettini,Daniele Atzeni,Ioanna-Yvonni Tsaknaki,Antonio Carta*

Main category: cs.LG

TL;DR: 该论文提出NatSR方法，将在线持续学习应用于在线时间序列预测，通过自然梯度下降与重放缓冲结合，在动态环境中实现快速适应和长期记忆。


<details>
  <summary>Details</summary>
Motivation: 在线时间序列预测需要同时具备快速适应环境变化和长期记忆能力，这与在线持续学习的目标高度一致。现有研究已初步将OCL应用于OTSF，但理论和实践连接仍需加强。

Method: 1) 将神经网络优化重构为参数滤波问题，证明自然梯度下降是分数驱动方法并证明其信息理论最优性；2) 使用Student's t似然结合自然梯度实现有界更新，提高对异常值的鲁棒性；3) 提出NatSR方法，结合鲁棒优化器、重放缓冲和动态尺度启发式策略，在机制漂移时改善快速适应。

Result: 实验结果表明，NatSR比更复杂的现有方法获得了更强的预测性能。

Conclusion: 该研究强化了时间序列方法与在线持续学习之间的理论和实践联系，提出的NatSR方法在在线时间序列预测中表现出色，证明了自然梯度下降与分数驱动方法的等价性及其在动态环境中的优势。

Abstract: Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.

</details>


### [297] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种用于LHC喷注数据的自蒸馏预训练方法，结合局部粒子级和全局喷注级蒸馏，在无标签数据上学习表征，支持异常检测和分类任务。


<details>
  <summary>Details</summary>
Motivation: 自监督学习能够从无标签数据中学习通用语义特征表示，但需要针对粒子物理中的喷注数据开发专门的预训练方法，以支持下游任务如异常检测和分类。

Method: 提出jBOT预训练方法，基于自蒸馏技术，结合局部粒子级蒸馏和全局喷注级蒸馏来学习喷注表征。在仅使用背景喷注的无标签数据上进行预训练。

Result: 预训练导致表征空间中出现语义类别聚类现象。冻结嵌入中的聚类支持基于简单距离度量的异常检测，学习到的嵌入经过微调后，在分类任务上表现优于从头训练的监督模型。

Conclusion: jBOT方法通过自蒸馏预训练有效学习喷注表征，在无标签数据上实现语义聚类，为异常检测和分类任务提供强大基础，性能优于传统监督方法。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [298] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出基于多级蒙特卡洛的dropout不确定性量化框架，通过重用dropout掩码构建耦合粗-细估计器，降低方差并提升计算效率


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量前向传播来估计预测矩，计算成本高。需要更高效的方差缩减技术来提升不确定性估计的效率。

Method: 将dropout掩码作为认知随机性来源，通过前向传播次数定义保真度层次结构。重用不同保真度间的dropout掩码构建耦合粗-细估计器，形成多级蒙特卡洛伸缩估计器，用于预测均值和方差估计。

Result: 推导了偏差、方差和有效成本表达式，以及层级间的样本分配规则。在正向和逆向PINNs-Uzawa基准测试中验证了预测方差率，在相同计算成本下相比单级MC-dropout获得了效率提升。

Conclusion: 多级蒙特卡洛dropout框架能够保持dropout诱导量的无偏性，同时通过方差缩减技术显著提升不确定性量化的计算效率，为深度学习不确定性估计提供了更高效的方法。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [299] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 论文研究了SGD在病态优化中的"可疑对齐"现象，发现梯度与主导子空间的对齐会经历先下降、后上升、最终稳定的三阶段过程，并揭示了步长选择如何影响这一现象。


<details>
  <summary>Details</summary>
Motivation: 研究随机梯度下降在病态优化问题中的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐行为。这种现象看似矛盾：高度对齐的梯度更新在主导子空间上却无法有效降低损失。需要深入理解步长选择如何产生这种现象。

Method: 在高维二次设置中进行细粒度分析，提出步长条件理论。定义了自适应临界步长η_t^*，区分对齐下降和对齐上升的步长区间。分析在病态条件下，不同子空间投影对损失的影响。

Result: 发现：1）低对齐状态下，临界步长η_t^*区分对齐行为；2）高对齐状态下，对齐具有自校正性；3）在足够病态条件下，存在步长区间使得批量子空间投影降低损失而主导子空间投影增加损失；4）恒定步长下SGD呈现两阶段行为。

Conclusion: SGD在病态优化中的可疑对齐现象可以通过步长选择理论得到解释。梯度对齐的动态变化受步长控制，主导子空间的高对齐并不保证有效优化，这解释了为什么投影到主导子空间的梯度更新效果不佳。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [300] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR是一个双层自适应重新标量化框架，用于为任何公平性指标恢复最优帕累托效率模型，通过两个新颖的大规模单循环算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法经常产生帕累托低效模型，而现有的帕累托效率方法又偏向特定公平视角，无法适应文献中广泛的公平性指标。

Method: 提出BADR（双层自适应重新标量化）框架：下层是加权经验风险最小化任务（权重为各组的凸组合），上层优化所选公平性目标。开发了BADR-GD和BADR-SGD两种大规模单循环算法。

Result: 建立了算法的收敛保证，发布了badr开源Python工具箱，并通过大量数值实验证明BADR优于现有的帕累托效率公平方法。

Conclusion: BADR提供了一个简单而强大的框架，能够为任何公平性指标恢复最优帕累托效率模型，解决了现有方法的局限性。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [301] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: PC²DAE：一种用于无人机野火监测的物理约束去噪自编码器，通过嵌入物理约束解决数据稀缺问题，在小数据集上实现高性能去噪。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载的低成本传感器存在基线漂移、交叉敏感性和响应延迟等问题，传统深度学习方法需要大量数据，而无人机飞行活动数据有限，难以满足需求。

Method: 提出PC²DAE物理约束去噪自编码器，通过softplus激活函数确保浓度估计非负，采用物理合理的时间平滑，架构包含针对不同传感器家族的层次解码器头，提供轻量版（21k参数）和宽版（204k参数）两种变体。

Result: 在仅7,894个样本（约2.2小时飞行数据）的小数据集上，PC²DAE-Lean实现67.3%平滑度提升和90.7%高频噪声降低，无物理违规，训练时间不到65秒，优于五个基线模型。

Conclusion: PC²DAE通过将物理约束直接嵌入网络架构，有效解决了数据稀缺下的传感器去噪问题，轻量版表现优于宽版，表明在数据稀缺情况下，强归纳偏置比模型容量更重要。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [302] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 该论文分析了Muon优化器的简化变体，通过矩阵分解和线性Transformer的上下文学习两个案例，证明了该优化器具有与条件数无关的线性收敛性，优于梯度下降和Adam算法。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的大语言模型预训练里程碑算法，其内在机制特别是梯度正交化的作用仍不明确，缺乏对其在具体应用中优势的端到端理论分析。

Method: 研究Muon优化器的简化变体，通过矩阵分解和线性Transformer的上下文学习两个案例进行理论分析，证明其收敛性并揭示谱域中的动态解耦机制。

Result: 证明了简化Muon在线性收敛性方面具有与相关条件数无关的迭代复杂度，优于梯度下降和Adam算法；揭示了Muon动态在谱域中解耦为独立标量序列的机制。

Conclusion: 研究形式化了谱正交化引起的预处理效应，为理解Muon在矩阵优化问题中的有效性提供了理论依据，并可能推广到更广泛的应用场景。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [303] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出基于shapelet的选择性预测框架，识别时间序列中的关键不可靠区域，让用户选择性丢弃不可靠预测，提升零样本和全样本微调模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然在平均零样本预测上表现良好，但在某些关键数据区域的预测不可靠，限制了其在现实应用中的使用，特别是当数据呈现独特趋势时。

Method: 使用shapelet（形状片段）识别时间序列中的关键区域，通过在目标域验证集上进行平移不变字典学习来学习shapelet，利用基于距离的相似性来选择性丢弃不可靠预测。

Result: 在多样化基准时间序列数据集上，该方法将零样本模型的整体误差平均降低22.17%，全样本微调模型降低22.62%。相比随机选择方法，在某些数据集上分别提升21.41%和21.43%。

Conclusion: 提出的选择性预测框架能有效识别不可靠预测区域，让用户了解模型的实际能力，显著提升时间序列基础模型在现实应用中的可靠性。

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [304] [Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation](https://arxiv.org/abs/2601.13698)
*Arjun Nichani,Hsiang Hsu,Chun-Fu,Chen,Haewon Jeong*

Main category: cs.LG

TL;DR: 本文利用信息论中的Chernoff信息度量，揭示了公平性、隐私性和准确性三者关系的数椐依赖性，提出了Noisy Chernoff Difference分析工具，并在合成和真实数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管公平性和隐私性是可信机器学习的两大支柱，但两者之间的关系研究相对较少。本文旨在通过信息论方法，同时分析公平性、隐私性和准确性三者之间的复杂关系，揭示其数椐依赖特性。

Method: 1. 定义Noisy Chernoff Difference作为同时分析公平性、隐私性和准确性关系的工具；2. 在合成数据上展示该值根据数据分布的三种不同行为模式；3. 提出从未知分布数据中估计Chernoff信息的方法；4. 在真实数据集上应用该框架分析三者动态关系。

Result: 1. 发现Noisy Chernoff Difference在合成数据中表现出三种不同的行为模式，取决于具体的数据分布；2. 揭示了这些数据分布对应的公平性和隐私性含义；3. 证明Noisy Chernoff Difference可作为公平性-准确性曲线陡峭度的代理指标；4. 成功将框架应用于真实数据集分析。

Conclusion: 本研究推进了对公平性-隐私性-准确性关系的统一理解，强调了这种关系的数椐依赖性，为同时优化这三个目标提供了理论工具和分析框架。

Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.

</details>


### [305] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow是一种用于描述符控制生成的条件流匹配框架，通过联合学习描述符条件的基础分布和流场，显著提升了分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有条件流方法在训练条件之外泛化能力不足，难以应对分布偏移的挑战，需要一种能够平滑插值和外推到未见条件的生成模型。

Method: 提出MixFlow框架，通过最短路径流匹配联合学习描述符条件的基础分布（建模为可学习的描述符依赖混合分布）和描述符条件的流场。

Result: 在单细胞转录组数据未见扰动预测和高内涵显微镜药物筛选等多个领域，MixFlow始终优于标准条件流匹配基线，展现出强大的分布外泛化能力。

Conclusion: MixFlow提供了一个简单而强大的方法，可在异构领域中实现鲁棒、可泛化和可控的生成建模，解决了条件生成模型在分布偏移下的泛化挑战。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [306] [Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks](https://arxiv.org/abs/2601.13776)
*Thibaut Boissin,Franck Mamalet,Valentin Lafargue,Mathieu Serrurier*

Main category: cs.LG

TL;DR: Orthogonium是一个统一的PyTorch库，提供正交和1-Lipschitz神经网络层，解决现有实现分散、有限且计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 正交和1-Lipschitz神经网络层对于认证对抗鲁棒性、稳定生成模型和可靠循环网络至关重要，但现有实现分散、有限且计算成本高，阻碍了采用。

Method: 开发了Orthogonium库，提供统一、高效、全面的正交和1-Lipschitz层实现，支持标准卷积特性（步长、膨胀、分组、转置），同时保持严格的数学保证。

Result: 优化实现减少了ImageNet等大规模基准测试的开销，并通过严格测试发现了现有实现中的关键错误，显著降低了采用障碍。

Conclusion: Orthogonium为需要正交性和鲁棒Lipschitz约束的多样化应用提供了标准化、可靠的工具，促进了可扩展的实验和集成。

Abstract: Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.

</details>


### [307] [AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training](https://arxiv.org/abs/2601.11864)
*Zhiyuan Li,Yuan Wu,Yi Chang*

Main category: cs.LG

TL;DR: 提出自适应分组梯度裁剪(AGGC)方法，通过按功能类型分组参数并基于历史行为自适应调节，解决传统全局梯度裁剪中的梯度异质性问题，在多个LLM模型上优于LoRA和全微调。


<details>
  <summary>Details</summary>
Motivation: 传统全局梯度裁剪假设所有参数梯度具有同质性，但实际上不同功能模块的梯度行为差异很大，导致"溢出效应"——波动参数会不必要地缩放稳定参数，影响训练稳定性。

Method: AGGC将参数按功能类型分组，使用指数移动平均(EMA)跟踪每组的历史梯度行为，构建自适应区间同时缓解梯度爆炸和消失问题，并采用时间依赖调度机制平衡探索与收敛。

Result: 在LLaMA 2-7B、Mistral-7B和Gemma-7B模型上，AGGC一致优于LoRA，经常超越全微调。在GSM8K基准测试中，Mistral-7B使用AGGC微调达到72.93%准确率，超过LoRA的69.5%。AGGC还能有效稳定RLVR训练，提升Qwen 2.5和Llama 3.2的逻辑推理能力。

Conclusion: AGGC通过模块化、自适应的裁剪策略有效解决了传统梯度裁剪方法的局限性，特别是梯度异质性问题。其轻量级设计可无缝集成到现有后训练流程中，计算开销可忽略。

Abstract: To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.

</details>


### [308] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 该论文提出了一种基于自组织映射(SOM)的精确输入恢复方法，并开发了MUSIC更新规则，用于在潜在空间中进行可控的语义轨迹生成，无需依赖采样或编码器-解码器架构。


<details>
  <summary>Details</summary>
Motivation: 传统SOM主要用于可视化和聚类，但缺乏精确恢复输入的能力。作者希望利用SOM的原型几何结构实现精确输入恢复和可控的潜在空间探索，为数据增强和语义变化提供新方法。

Method: 基于欧几里得距离几何原理，推导出从原型距离恢复输入的线性系统。提出MUSIC更新规则，通过修改选定原型的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化稳定更新规则。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证，MUSIC能够生成平滑、可解释的轨迹，揭示学习流形的底层几何结构，实现精确输入恢复和可控语义变化。

Conclusion: SOM激活模式可以精确反演恢复输入，MUSIC提供了一种基于原型几何的数据增强和可控潜在探索新视角，相比无监督聚类具有优势，无需依赖变分或概率生成模型的复杂架构。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [309] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: TF-CoDiT：首个用于语言控制国债期货合成的扩散Transformer框架，通过离散小波变换和U形VAE处理低数据量问题，引入金融市场属性协议生成提示，在国债期货数据合成上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有扩散Transformer在股票价格和订单流等金融时间序列数据合成上已有成就，但在国债期货数据合成方面仍未被充分探索。国债期货数据具有低交易量、市场依赖性强以及多变量间分组相关性等特点，需要专门的方法来处理这些挑战。

Method: 提出TF-CoDiT框架：1）将多通道1-D时间序列转换为离散小波变换系数矩阵以适应低数据学习；2）设计U形VAE分层编码跨通道依赖关系到潜变量，并通过解码桥接潜空间和DWT空间，实现潜扩散生成；3）引入金融市场属性协议（FinMAP）——一个多级描述系统，从7/8个视角识别17/23个经济指标，标准化每日/周期性市场动态以生成提示。

Result: 收集2015-2025年四种国债期货数据，定义从一周到四个月不同时长的合成任务。评估显示TF-CoDiT能生成高度真实的数据，与真实数据的误差最多为MSE 0.433和MAE 0.453。进一步研究证明TF-CoDiT在不同合约和时间跨度上具有鲁棒性。

Conclusion: TF-CoDiT是首个用于语言控制国债期货合成的扩散Transformer框架，成功解决了国债期货数据特有的挑战，在低数据量条件下实现了高质量的合成，为金融时间序列数据生成提供了新方法。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [310] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 本文提出了一种基于支配匹配集转换的新型局部搜索框架，用于解决带实例级约束的k-center聚类问题，达到了最佳可能的2近似比。


<details>
  <summary>Details</summary>
Motivation: 传统的k-center问题已有2近似比的最优结果，但加入实例级的"不能链接"(CL)和"必须链接"(ML)约束后，问题复杂度显著增加。虽然前人工作表明不相交的CL集合允许常数因子近似，但局部搜索方法是否能达到这样的保证仍是一个开放问题。

Method: 提出了一种新颖的局部搜索框架，通过将约束k-center聚类问题转换为支配匹配集问题，从而实现了最佳可能的近似比。

Result: 在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法，达到了理论上的最佳近似比2。

Conclusion: 通过将约束k-center问题转换为支配匹配集问题，本文提出的局部搜索框架成功解决了该领域的一个开放问题，实现了最佳可能的近似比，为带约束的聚类问题提供了有效的解决方案。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [311] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 论文研究低秩张量积B样条(TPBS)回归模型，探索Dirichlet能量作为平滑度度量，发现全局正则化失效问题，提出基于局部Dirichlet能量的新正则化策略，并在过拟合场景下优于神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究低秩张量积B样条(TPBS)模型在回归任务中的应用，探索Dirichlet能量作为模型平滑度的有效度量。发现全局Dirichlet能量正则化在某些情况下会失效，需要新的正则化方法来解决这一问题。

Method: 1) 推导TPBS模型的Dirichlet能量闭式表达式；2) 提出基于训练点周围小超立方体局部Dirichlet能量的正则化策略；3) 利用预训练TPBS模型设计两种从不完整样本进行推断的估计器。

Result: TPBS模型在过拟合场景下对大多数数据集优于神经网络，其他情况下保持竞争力。TPBS模型对过拟合更具鲁棒性且能持续受益于正则化，而神经网络对过拟合更敏感且利用正则化的效果较差。

Conclusion: TPBS模型是回归任务的有效选择，特别是在过拟合场景下。提出的局部Dirichlet能量正则化策略解决了全局正则化的局限性，使TPBS模型在实际应用中更具优势。

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [312] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 提出一个参数化的凹覆盖目标函数族U_ρ，用于在无奖励MDP中指导探索策略，通过梯度方法主动引导状态-动作占用分布实现目标覆盖模式。


<details>
  <summary>Details</summary>
Motivation: 在无奖励MDP中，不同状态-动作对具有不同的重要性或难度，需要主动构建探索策略来优先考虑未充分探索的区域。

Method: 提出加权参数化凹覆盖目标函数族U_ρ，定义在状态-动作占用测度上；利用U_ρ的凹性和梯度闭式解，开发基于梯度的算法主动引导占用分布。

Result: U_ρ框架统一了多种现有目标（散度边际匹配、加权平均覆盖、最坏情况覆盖）；随着ρ增大，探索策略越来越关注最少探索的状态-动作对，极限情况下恢复最坏情况覆盖行为。

Conclusion: 提出的U_ρ框架为无奖励MDP中的探索问题提供了统一的理论框架，通过参数ρ灵活控制探索策略的激进程度，从平均覆盖到最坏情况覆盖连续过渡。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [313] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: QAM是一种新的强化学习算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 连续动作强化学习中，对表达性强的扩散或流匹配策略进行高效优化是一个长期挑战。直接通过反向传播进行梯度优化在多步去噪过程中数值不稳定，现有方法要么丢弃梯度信息，要么牺牲策略表达性或引入偏差。

Method: QAM利用伴随匹配技术，将critic的动作梯度转换为步进式目标函数，避免了不稳定的反向传播，同时提供无偏且表达性强的策略。结合时序差分备份进行critic学习。

Result: QAM在离线强化学习和离线到在线强化学习的困难稀疏奖励任务上，始终优于现有方法。

Conclusion: QAM通过伴随匹配技术有效解决了连续动作RL中扩散/流匹配策略优化的数值不稳定问题，为表达性策略优化提供了新方法。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [314] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发者遥测数据的代码补全基准测试，包含6种编程语言和6个任务类别，共1800个评估实例，强调生态有效性并避免训练数据污染。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态有效性，容易受到训练数据污染，且无法提供详细的诊断信息来指导模型选择和改进。

Method: 基于真实开发者遥测数据构建评估实例，结合功能正确性、相似度指标和LLM评估者（关注实用性和上下文相关性）的综合评估方法。

Result: 评估了9个最先进的模型，揭示了它们在语法精度、语义推理和实际效用方面的差异，提供了其他基准测试通常缺失但实际部署和模型开发必需的可操作见解。

Conclusion: DevBench为代码补全LLMs提供了具有生态有效性、避免数据污染且支持详细诊断的基准测试，能够指导模型选择和针对性改进。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [315] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 研究对抗性腐败和有限验证下的合作随机多臂老虎机问题，揭示了通信协议如何将环境侧腐败预算Γ转化为从Γ到NΓ不等的有效腐败水平，并分析了不同信息共享策略的后悔界。


<details>
  <summary>Details</summary>
Motivation: 在合作多智能体系统中，智能体面临对抗性腐败的观测反馈，同时只能进行有限验证。需要理解不同通信协议如何影响腐败的传播效应，以及如何设计有效的学习策略来最小化团队后悔。

Method: 提出通信-腐败耦合框架，通过协议诱导的多样性泛函量化不同信息共享策略（原始样本共享、统计摘要共享、仅推荐共享）对腐败的放大效应。建立基于有效腐败参数的后悔界，并分析验证观测的全局预算ν如何恢复可学习性。

Result: 原始样本共享可能遭受N倍的腐败惩罚，而摘要共享和仅推荐共享能保持O(Γ)的未放大项并达到中心化速率的团队后悔。建立了信息理论下界，包括不可避免的Ω(Γ)惩罚，以及在Γ=Θ(NT)的高腐败区域没有干净信息就无法获得亚线性后悔。验证观测在超过识别阈值后能恢复可学习性。

Conclusion: 通信协议设计对腐败传播有决定性影响，智能体应避免原始样本共享以防止腐败放大。在腐败严重时，验证观测是必要的，一旦验证预算超过识别阈值，认证共享能使团队后悔独立于腐败预算Γ。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [316] [Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization](https://arxiv.org/abs/2601.11942)
*Qingyu Meng,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出一种混合量子-经典回归框架，通过可学习的几何预处理器和课程优化协议，改善量子神经网络在回归任务中的训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络在科学机器学习中受到关注，但在回归任务中常面临噪声梯度下的有限可训练性和病态优化问题，需要改进训练稳定性。

Method: 1) 设计混合量子-经典架构：前置轻量级经典嵌入层作为可学习的几何预处理器，重塑输入表示以改善下游变分量子电路的优化条件；2) 引入课程优化协议：逐步增加电路深度，从SPSA随机探索过渡到Adam梯度微调。

Result: 在PDE回归基准和标准回归数据集上，在固定训练预算的模拟器设置中，该框架始终优于纯QNN基线，在数据有限情况下实现更稳定的收敛，并减少与振荡分量相关的结构化误差。

Conclusion: 几何预处理与课程训练相结合是稳定量子回归的实用方法，能够改善量子神经网络在回归任务中的训练稳定性和性能表现。

Abstract: Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.

</details>


### [317] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出MICE方法解决约束强化学习中成本函数低估问题，通过内在成本估计和记忆模块减少训练过程中的约束违反


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练过程中经常出现严重的约束违反，限制了在安全关键场景中的应用。作者发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计（MICE）方法：1）构建记忆模块存储先前探索的不安全状态；2）将内在成本定义为当前状态访问这些风险区域的伪计数；3）提出包含内在成本的外在-内在成本价值函数，并采用偏差校正策略；4）在信任区域内制定优化目标。

Result: 理论分析提供了成本价值函数的收敛保证和MICE更新的最坏情况约束违反界限。实验表明MICE显著减少了约束违反，同时保持了与基线相当的策略性能。

Conclusion: MICE通过解决成本函数低估问题，有效减少了约束强化学习中的约束违反，提高了算法在安全关键场景中的适用性。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [318] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt：一种面向动态图的数据中心提示框架，通过调整预训练节点嵌入来适应不同下游任务，在少样本和冷启动场景下显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法通常通过动态链接预测预训练模型，然后将节点时序嵌入直接应用于下游任务，但由于下游任务差异大，尤其在少样本设置下性能下降。现有提示方法通常与特定模型架构或预训练任务强耦合，且只关注节点或时序特征而忽略空间结构信息，导致表达能力有限和性能下降。

Method: 提出DDGPrompt框架：1) 定义统一的节点表达特征矩阵，聚合每个节点的所有相关时序和结构信息；2) 引入三个提示矩阵（时序偏置、边权重和特征掩码）来完全调整特征矩阵，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下进行评估。实验结果表明，在标签有限和冷启动条件下，该方法显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt是一种有效的数据中心提示框架，能够通过调整预训练节点嵌入来适应多样下游任务，解决了现有方法在模型兼容性和结构信息利用方面的局限性。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [319] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO通过引入轻量级残差rollout头，将训练轨迹与推理响应解耦，解决强化学习中探索不足的问题，提升LLM推理能力


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时产生推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，损害推理能力

Method: 提出R²PO（Residual Rollout Policy Optimization），在策略之上引入轻量级残差rollout头，将训练轨迹与推理响应解耦，在训练期间实现可控的轨迹多样化，同时保持推理生成的稳定性

Result: 在多个基准测试中一致优于基线方法，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化

Conclusion: R²PO通过解耦训练轨迹和推理响应，有效解决了强化学习中探索不足的问题，显著提升了LLM的推理能力

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [320] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE-Encoder模块，通过稀疏专家混合层增强预训练时序模型，实现多变量预测向专家引导的单变量任务转换，并支持联邦学习中的本地化训练和轻量参数共享。


<details>
  <summary>Details</summary>
Motivation: 电力系统预测涉及复杂的多变量时序数据和严格的隐私约束，传统方法需要大量专家知识且难以泛化，现有预训练模型在领域特定任务上的零样本性能有限。

Method: 在标记化和编码之间注入稀疏专家混合层，将多变量预测转化为专家引导的单变量任务，有效捕捉变量间关系，并支持联邦学习中的本地化训练和轻量参数共享。

Result: 在公开多变量数据集上显著提升预测精度，联邦环境模拟显示仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小。

Conclusion: MoE-Encoder为时序基础模型提供了可扩展且隐私感知的扩展方案。

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [321] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出EVO算法，利用极值理论处理强化学习中的极端风险事件，减少约束违反


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习基于期望约束，忽略了罕见但影响巨大的极端值事件（如黑天鹅事件），可能导致严重约束违反

Method: 提出极值策略优化(EVO)算法：1) 使用极值理论建模极端奖励和成本样本；2) 引入极端分位数优化目标捕获成本尾部分布；3) 设计极端优先回放机制放大极端样本的学习信号

Result: 理论上证明策略更新期间约束违反的上界，保证在零违反分位数水平上的严格约束满足；实验显示EVO显著减少训练期间的约束违反，同时保持与基线相当的策略性能

Conclusion: EVO通过极值理论有效处理约束强化学习中的极端风险，比期望方法有更低的约束违反概率，比分位数回归方法有更低的方差

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [322] [Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features](https://arxiv.org/abs/2601.12011)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 损失重加权在过参数化深度神经网络中无法改变最终学习阶段，但在训练早期能显著改善少数类学习，通过简化模型揭示了重加权如何恢复平衡学习动态


<details>
  <summary>Details</summary>
Motivation: 虽然损失重加权在过参数化深度神经网络训练中无法改变最终学习结果，但实证表明它在训练早期能带来显著好处。本文旨在透明地展示和分析这一现象，理解重加权如何影响早期训练动态。

Method: 引入小型简化模型（SSM），该模型抽象了深度神经网络架构和输入数据的复杂性，同时保留了光谱分量中不平衡结构的关键信息。通过SSM分析标准经验风险最小化与重加权方法的差异。

Result: SSM显示：1）标准经验风险最小化在训练早期优先学习多数类特征，延迟少数类学习；2）损失重加权能够恢复平衡学习动态，使多数类和少数类特征能够同时学习。

Conclusion: 损失重加权在训练早期通过平衡学习动态改善少数类学习，虽然不影响最终学习阶段，但对训练过程有重要优化作用。SSM为理解这一现象提供了透明分析框架。

Abstract: The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.

</details>


### [323] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2提出了一种因子化的时空基础模型框架，通过分离通用时间学习和领域特定空间适应，实现高效的全权重迁移和任意长度泛化，在零样本和少样本场景中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有时空基础模型存在联合预训练计算成本高、难以处理领域特定空间模式异质性的问题，需要一种更实用、可扩展的解决方案来实现真正的通用时空基础模型。

Method: 采用两阶段因子化框架：第一阶段使用随机序列掩码预训练简约的编码器骨干网络，捕捉不变时间动态；第二阶段通过元自适应学习和提示注入空间感知的轻量适配器。

Result: FactoST-v2在多个领域评估中达到最先进精度，具有线性效率，在零样本和少样本场景中显著优于现有基础模型，并能匹敌领域特定专家基线。

Conclusion: 因子化范式为真正通用的时空基础模型提供了实用、可扩展的路径，实现了高效的全权重迁移和任意长度泛化能力。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [324] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 本文针对LLM中的西方中心偏见问题，提出CEBiasBench双语基准和MACD多智能体文化辩论框架，发现中文提示仅将偏见转向东亚视角而非消除，而MACD通过明确文化角色分配显著提升无偏见率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在系统性西方中心偏见，但现有研究在两方面不足：评估方法强制输出到预定义文化类别且缺乏中立选项；缓解方法依赖昂贵的多文化语料库或缺乏明确文化表征的智能体框架。需要更严谨的评估和有效的缓解方法。

Method: 1) 提出CEBiasBench中英双语基准；2) 提出Multi-Agent Vote(MAV)支持"无偏见"判断；3) 提出Multi-Agent Cultural Debate(MACD)训练免费框架，为智能体分配不同文化角色，采用"求同存异"策略进行辩论。

Result: 中文提示仅将偏见转向东亚视角而非消除偏见。MACD在CEBiasBench上达到57.6%平均无偏见率(LLM评估)和86.0%(MAV评估)，相比GPT-4o基线的47.6%和69.0%显著提升。在阿拉伯语CAMeL基准上也表现出良好泛化能力。

Conclusion: 智能体框架中的明确文化表征对跨文化公平至关重要。MACD通过文化角色分配和辩论策略有效缓解LLM偏见，为跨文化公平提供了实用解决方案。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [325] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 提出PTL-PINN框架，结合微扰理论和迁移学习，快速求解非线性微分方程，速度比传统方法快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络(PINNs)在求解非线性微分方程时存在泛化能力有限和训练时间长的问题，需要更高效的解决方案。

Method: 提出PTL-PINN框架，将微扰理论与迁移学习结合，通过闭式表达式求解近似线性微扰系统，计算复杂度仅为矩阵向量乘法。

Result: PTL-PINNs精度与多种Runge-Kutta方法相当，计算速度比传统方法快一个数量级，成功求解了多种非线性问题。

Conclusion: 该工作将微扰方法与PINNs结合，展示了微扰理论如何指导基础模型以接近经典求解器的速度解决非线性系统。

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [326] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

TL;DR: 提出神经同构场，使用嵌入向量表示数字以解决神经网络处理极值时的数值不稳定问题，保持有理数域上的代数运算性质


<details>
  <summary>Details</summary>
Motivation: 神经网络在处理极小数或极大数时面临溢出、下溢和输出不稳定等问题，需要一种能保持代数性质同时避免数值不稳定的数字表示方法

Method: 提出神经同构场作为代数结构（如群、域）的神经抽象，使用固定长度的数字嵌入向量，这些向量在计算过程中保持代数结构，特别是保持有理数域上的加法、乘法和比较运算

Result: 加法运算表现优异，在恒等性、封闭性和结合性等关键代数测试中准确率超过95%；乘法运算面临挑战，在不同代数性质上的准确率在53%到73%之间

Conclusion: 神经同构场在保持加法运算的代数性质方面表现出色，但在乘法运算方面仍有改进空间，为处理数值不稳定性提供了有前景的方向

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [327] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于评估合成数据隐私风险的开放框架，使用模拟敏感数据避免真实数据泄露，并提出新的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但缺乏开放的隐私评估框架阻碍了其采用。主要挑战是难以获取敏感数据来建立可访问的基准数据集。

Method: 引入SynQP框架，使用模拟敏感数据进行隐私基准测试，确保原始数据保密。提出新的身份披露风险度量方法，更准确地评估隐私风险。

Result: 在质量评估中，非私有模型达到接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险（SD-IDR）和成员推理攻击风险（SD-MIA），所有DP增强模型都保持在0.09监管阈值以下。

Conclusion: SynQP为改进隐私评估的透明度和可靠性提供了关键工具，使合成数据在健康相关应用中能够更安全地使用。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [328] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

TL;DR: 提出结合物理信息神经网络与上下文学习的LLM情感动态数据集与框架，实现可解释对话建模


<details>
  <summary>Details</summary>
Motivation: 现有LLM在模拟真实世界情感动态方面存在局限，缺乏时间维度上的情感演变建模能力，需要更可解释的情感对话系统

Method: 构建情感动态数据集，结合物理信息神经网络(PINN)建模时间维度情感演变，利用上下文学习增强LLM的情感理解与生成能力

Result: 建立了能够模拟真实情感动态的框架，实现了时间维度上的情感演变建模，为可解释对话系统提供了新途径

Conclusion: 物理信息神经网络与上下文学习的结合为LLM情感建模开辟了新方向，有望实现更自然、可解释的情感对话系统

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [329] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域自适应大语言模型，专门用于空间天气和太阳物理学的教育问答，通过科学文献和GPT-4生成的数据训练，在零样本设置下优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 太阳活动（如太阳耀斑、日冕物质抛射）对卫星、电网等关键基础设施有重大影响，准确预测和有效教育至关重要。虽然大语言模型在通用任务上表现良好，但缺乏领域知识和教学能力来清晰解释复杂的空间科学概念。

Method: 基于LLaMA-3基础模型构建SolarGPT-QA问答系统，使用科学文献和大规模问答数据进行领域自适应预训练，数据由GPT-4生成并通过Grok-3以学生友好的故事化风格精炼。结合领域自适应预训练和教学微调。

Result: 人工成对评估显示，SolarGPT-QA在零样本设置下优于通用模型，在教学解释方面与指令微调模型竞争。小型学生理解研究表明生成解释的清晰度和可访问性有所改善。消融实验表明结合领域自适应预训练和教学微调对平衡科学准确性和教学效果很重要。

Conclusion: 这项工作是迈向更广泛的SolarGPT框架用于空间科学教育和预测的初步步骤，展示了领域自适应大语言模型在专业科学教育中的潜力。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [330] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

TL;DR: 提出T3P MAB强化学习方法用于自适应深部脑刺激，能同时调节频率和振幅，轻量级适合植入设备部署，无需离线训练，功耗低。


<details>
  <summary>Details</summary>
Motivation: 传统DBS使用固定频率和振幅，存在副作用（如言语不清）和电池寿命短的问题。现有RL方法复杂，需要长时间收敛和高计算资源，无法在体内训练，且大多只调节单一参数。

Method: 提出时间与阈值触发的多臂赌博机（T3P MAB）强化学习方法，轻量级算法可部署在微控制器单元上，能同时调节DBS的频率和振幅参数。

Result: T3P MAB算法样本效率高，收敛时间短，首次在硬件上实现并报告能耗测量，证明适合资源受限平台，功耗显著低于现有RL方法。

Conclusion: T3P MAB方法为DBS提供了一种高效、轻量级的自适应解决方案，能同时优化频率和振幅，适合植入设备部署，有望改善帕金森病患者治疗效果并延长电池寿命。

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [331] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 提出EMoE架构，通过基于正交特征基的路由机制，同时解决MoE中的负载不均衡和专家同质化问题，无需额外的负载均衡损失函数。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然能提高效率，但存在两个根本问题：1) "富者愈富"的负载不均衡问题，少数专家被过度使用；2) 专家同质化问题，专家学习冗余表示，失去专业化意义。现有解决方案通常使用辅助负载均衡损失，但这往往以牺牲专业化为代价加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习正交特征基的路由机制。将输入token投影到这个共享的特征基上，根据它们与特征空间主成分的对齐程度进行路由。这种基于几何的数据划分方法本质上促进了平衡的专家利用和多样化、专业化专家的开发。

Result: EMoE能够同时促进专家利用的平衡和多样化、专业化专家的开发，无需使用冲突的辅助损失函数。代码已公开在GitHub上。

Conclusion: EMoE通过基于正交特征基的几何路由机制，从根本上解决了MoE架构中的负载不均衡和专家同质化问题，提供了一种无需额外损失函数的统一解决方案。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [332] [On the Relation of State Space Models and Hidden Markov Models](https://arxiv.org/abs/2601.13357)
*Aydin Ghojogh,M. Hadi Sepanj,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文系统比较了隐马尔可夫模型、线性高斯状态空间模型、卡尔曼滤波和现代NLP状态空间模型，分析了它们在概率图模型框架下的异同，并探讨了传统概率模型与现代深度学习模型之间的关系。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型和隐马尔可夫模型是序列数据建模的基础框架，广泛应用于信号处理、控制理论和机器学习。尽管它们具有相似的时序结构，但在潜在状态性质、概率假设、推理过程和训练范式上存在根本差异。近年来，确定性状态空间模型通过S4和Mamba等架构在自然语言处理中重新兴起，这引发了关于经典概率SSMs、HMMs和现代神经序列模型之间关系的新问题。

Method: 通过概率图模型的视角分析这些模型的公式化表达，检查它们的推理算法（包括前向后向推理和卡尔曼滤波），并对比它们的学习过程（通过期望最大化算法和基于梯度的优化）。系统比较HMMs、线性高斯状态空间模型、卡尔曼滤波和当代NLP状态空间模型。

Result: 通过突出结构相似性和语义差异，阐明了这些模型何时等价、何时根本不同，以及现代NLP SSMs如何与经典概率模型相关联。分析结果连接了控制理论、概率建模和现代深度学习的视角。

Conclusion: 本文提供了一个统一的框架来理解状态空间模型家族中的不同变体，帮助研究人员和从业者更好地理解这些模型之间的关系，为在序列建模任务中选择合适的模型提供了理论基础。

Abstract: State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.
  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.

</details>


### [333] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: TDA是一种无注意力沉没的稀疏注意力机制，通过阈值差分方法解决Softmax在长上下文中的结构限制问题，实现超稀疏性和更好的长序列鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文中存在结构限制：严格的归一化约束导致注意力沉没在无关token上，且随着序列长度增加概率质量分散。现有方法要么计算开销大，要么因噪声积累导致性能下降。

Method: 提出阈值差分注意力(TDA)：1) 使用长度依赖门控的行级极值阈值化，仅保留超过阈值的值；2) 借鉴差分transformer思想，减去抑制视图以增强表达能力。

Result: 理论证明：TDA控制每行伪幸存者期望为O(1)，且独立视图间的共识伪匹配随上下文增长而消失。实证结果：TDA产生>99%的精确零值，消除注意力沉没，在标准和长上下文基准上保持竞争力。

Conclusion: TDA是一种有效的无沉没注意力机制，解决了Softmax在长上下文中的结构限制，实现了超稀疏性和更好的长序列鲁棒性，无需额外计算开销。

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [334] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: Re-SpS：首个基于强化学习的推测采样框架，通过动态调整草稿树超参数来优化LLM推理延迟，相比EAGLE-3实现最高1.12倍加速


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率，需要动态优化方法来平衡推测攻击性和计算开销

Method: 提出强化学习框架Re-SpS，实时动态调整草稿树超参数，利用目标模型隐藏状态的高效状态表示，引入多步动作持久化以改进上下文建模

Result: 在五个多样化基准测试中相比SOTA方法EAGLE-3实现一致改进，相比骨干LLM最高5.45倍加速，相比EAGLE-3最高1.12倍加速，且输出保真度无损失

Conclusion: Re-SpS通过强化学习动态优化草稿树超参数，显著提升LLM推理速度，为实时应用提供了更高效的推测采样解决方案

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [335] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 提出MMR自监督预训练框架，通过小波多尺度分解重建任务学习PPG信号的层次化时频特征，在17/19个健康相关任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略PPG信号的频谱结构，而许多下游健康任务需要从细粒度波形形态到全局节律动态的多分辨率特征。

Method: 提出掩码多尺度重建(MMR)自监督预训练框架：对小波多分辨率分解的PPG信号系数进行随机掩码，训练Transformer编码器跨时频尺度重建这些系数。

Result: 在约1700万个未标记10秒PPG片段上预训练，在17/19个多样化健康相关任务上优于或匹配现有PPG基础模型、时间序列基础模型和其他自监督基线。

Conclusion: MMR展示了构建通用PPG基础模型的潜力，小波表示能捕获稳健且生理基础的特征，为数字健康应用提供有效表示学习方法。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [336] [Learning Longitudinal Health Representations from EHR and Wearable Data](https://arxiv.org/abs/2601.12227)
*Yuanyun Zhang,Han Zhou,Li Feng,Yilin Hong,Shi Li*

Main category: cs.LG

TL;DR: 提出一个多模态基础模型，联合表示电子健康记录和可穿戴设备数据作为连续时间潜在过程，在生理预测和风险建模任务上优于单模态基线


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据稀疏且不规则，可穿戴设备提供密集连续生理信号但缺乏语义基础，现有方法通常单独建模或通过后期融合结合这些数据源

Method: 使用模态特定编码器和共享时间骨干网络，通过自监督和跨模态目标进行预训练，将电子健康记录和可穿戴数据联合表示为连续时间潜在过程

Result: 在生理预测和风险建模任务上，模型优于仅使用电子健康记录或可穿戴设备的强基线，特别是在长时间范围和数据缺失情况下表现更好

Conclusion: 联合电子健康记录和可穿戴设备预训练能够产生更准确的纵向健康表示，证明多模态整合在临床预测中的价值

Abstract: Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.

</details>


### [337] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 提出了一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的异常检测框架，用于企业安全中的内部威胁检测


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳的用户活动日志，且异常事件稀少，使得传统异常检测方法面临挑战

Method: 1) 偏差感知调制方案抑制常规行为并放大异常偏差；2) 离散小波变换将日志信号分解为多分辨率表示；3) 可学习注意力机制动态重新加权最具区分性的频带

Result: 在CERT r4.2基准测试中，该方法在精度、召回率和F1分数上均优于现有基线，适用于不同时间粒度和场景

Conclusion: 提出的集成小波感知调制、多分辨率分解和自适应注意力的框架能够有效处理企业内部威胁检测的复杂挑战，显著提升检测性能

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [338] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出了一种基于Tucker分解的随机交替最小化算法，用于低Tucker秩张量感知问题，避免了昂贵的张量投影，实现了低维张量因子的高效小批量更新。


<details>
  <summary>Details</summary>
Motivation: 低Tucker秩张量感知是信号处理和机器学习中的基本问题，现有方法要么需要昂贵的张量投影，要么依赖全梯度计算，而大多数随机因子化方法仅限于张量分解设置。

Method: 提出了一种随机交替最小化算法，直接在Tucker分解下的核心张量和因子矩阵上操作，避免了重复的张量投影，实现了低维张量因子的高效小批量更新。

Result: 在合成张量感知的数值实验中，与代表性的随机张量恢复基线相比，该算法在挂钟时间上表现出有利的收敛行为。

Conclusion: 该方法为低Tucker秩张量感知提供了一种高效的随机优化框架，避免了传统方法的计算瓶颈，在计算效率方面具有优势。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [339] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过GRIN模块处理时移，单次前向传播即可捕捉复杂未来分布，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在计算成本高（依赖采样）或参数假设限制性强的问题，导致预测性能受限和分布不匹配。需要一种能高效捕捉复杂未来分布的方法。

Method: 提出TimeGMM框架：1）使用高斯混合模型（GMM）表征未来分布；2）提出GRIN模块（GMM适应的可逆实例归一化）动态适应时移；3）结合时间编码器（TE-Module）和条件时移概率解码器（CTPD-Module）共同捕捉时间依赖性和混合分布参数。

Result: 在广泛实验中，TimeGMM持续优于最先进方法，在CRPS指标上最大提升22.48%，在NMAE指标上最大提升21.23%。

Conclusion: TimeGMM通过GMM框架和GRIN模块有效解决了现有概率预测方法的局限性，实现了高效准确的复杂分布建模，在多个指标上显著超越现有方法。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [340] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 研究发现训练数据中的分布偏移程度越大，ERM方法越能接近不变预测模型的性能，甚至有时优于专门设计的OOD方法


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时在分布外任务上优于专门设计的方法，这促使研究者探索算法设计之外的原因，特别是训练域间的分布偏移如何影响模型性能

Method: 通过理论推导上界分析分布偏移程度对模型预测能力的影响，并在特定数据条件下证明ERM解能达到不变预测模型的性能；同时进行实证验证，观察分布偏移增大时学习模型的预测如何逼近Oracle或最优模型

Result: 理论分析表明分布偏移程度直接影响学习模型的预测能力，偏移越大模型能力越强，越能逼近在不同域中做出稳定预测的不变预测模型；实证结果显示当训练数据分布偏移增大时，学习模型的预测确实能逼近Oracle或最优模型

Conclusion: 训练数据中的分布偏移是影响模型学习不变预测的关键因素，大的分布偏移能使ERM方法获得接近不变预测模型的性能，这解释了为什么有时简单的ERM能胜过专门设计的OOD方法

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [341] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MLaaS数据集生成器(MDG)框架，用于创建可配置、可复现的数据集来评估MLaaS服务选择和组合，通过模拟真实MLaaS行为生成大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 需要系统化评估MLaaS服务选择和组合的方法，现有方法缺乏可配置、可复现的数据集来模拟真实MLaaS行为和服务交互。

Method: 训练和评估多种模型家族在多个真实数据集和数据分布设置下，记录功能属性、服务质量指标和组合特定指标，实现内置组合机制模拟物联网条件下的服务交互。

Result: 生成超过一万个MLaaS服务实例，构建大规模基准数据集，实验表明MDG生成的数据集相比现有基线提高了选择准确性和组合质量。

Conclusion: MDG为推进MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础，能够生成高质量数据集来系统评估服务性能。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [342] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

TL;DR: Explanova是一个基于预设AutoML工作流的自动化数据分析框架，使用本地小型LLM降低成本


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM代理工具调用的数据分析框架（如DeepAnalyze、DataSage、Datawise）虽然强大，但成本较高。作者探索是否可以通过预设的AutoML式工作流来实现更经济的数据分析自动化

Method: 采用预设的AutoML式工作流，遍历所有可能的探索路径：Xn本身的统计特性、Xn1-Xn2关系、Xn与其他变量的关系，最后进行解释。关键创新是使用本地小型LLM来降低成本

Result: Explanova实现了更经济的数据分析自动化，相比现有基于大型LLM代理的框架，成本显著降低

Conclusion: 通过预设AutoML工作流结合本地小型LLM，可以构建经济高效的自动化数据分析框架，为数据分析自动化提供了新的可行路径

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [343] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: 提出OrLoMo方法，首次实现带局部更新的异步分布式动量SGD，通过有序聚合局部动量来加速异构集群训练。


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度学习训练的基础优化器，异步分布式学习对大规模模型训练至关重要，特别是在计算能力异构的集群中。现有方法缺乏异步分布式动量SGD与局部更新的结合方案。

Method: 提出OrLoMo（有序局部动量）方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引有序聚合各工作节点的局部动量。

Result: OrLoMo是首个实现异步分布式动量SGD与局部更新的方法，在非凸问题下证明了任意延迟的收敛性，实验显示优于同步方法和其他异步方法。

Conclusion: OrLoMo成功解决了异步分布式动量SGD与局部更新的实现问题，为异构集群的大规模深度学习训练提供了有效解决方案。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [344] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: 提出IceWatch深度学习框架，结合空间视觉与时间序列数据，实现冰川湖溃决洪水(GLOF)的自动预测与预警系统。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云层干扰和现场数据缺乏等问题，需要更高效可靠的自动预测系统。

Method: IceWatch包含两个核心组件：1) RiskFlow视觉组件使用CNN分类器分析Sentinel-2多光谱卫星图像，基于冰雪融水空间模式预测GLOF；2) TerraFlow和TempFlow分别从NASA ITS_LIVE时间序列建模冰川速度，从MODIS LST记录预测近地表温度，通过协调预处理和同步实现多模态物理信息融合。

Result: 系统提供交叉验证，提高GLOF检测的可靠性和可解释性，确保强预测性能、快速实时数据处理，以及对噪声和缺失信息的鲁棒性。

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平道路，具有整合多种传感器输入和全球冰川监测活动的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [345] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS：结合大语言模型和贝叶斯优化的AutoML框架，通过蒙特卡洛树搜索解决CASH问题，在104个数据集上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化存在冷启动问题，现有基于大语言模型的优化器在高维结构化CASH空间中泛化能力差，需要一种结合两者优势的解决方案

Method: 提出LB-MCTS框架，将大语言模型和贝叶斯优化结合在蒙特卡洛树搜索结构中，使用选择性调优记忆（STM）和显式探索-利用权衡，随着数据积累动态从LLM驱动转向BO驱动

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于竞争基线方法

Conclusion: LB-MCTS成功结合了LLM的语义先验和BO的数据驱动优势，有效解决了CASH问题中的冷启动和高维挑战

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [346] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

TL;DR: 基于机器学习框架，利用常规过程信号（控制器输出OP和过程变量PV）检测和预测控制阀粘滞故障，LSTM模型在真实炼油厂数据上实现最高精度，可提前4小时预测


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程系统中常见的故障，会导致系统不稳定、设备磨损和维护成本增加。许多工厂仍在使用缺乏实时监控的传统阀门，使得早期预测变得困难

Method: 开发了三种深度学习模型：CNN、CNN-SVM混合模型和LSTM网络。采用基于斜率比分析的数据驱动标注方法，在真实石油和天然气炼油厂数据集上进行训练

Result: LSTM模型取得了最高的准确率，能够提前4小时预测粘滞故障。据作者所知，这是首次基于真实工业数据展示机器学习早期预测控制阀粘滞的研究

Conclusion: 提出的框架可以集成到现有控制系统中，支持预测性维护，减少停机时间，避免不必要的硬件更换

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [347] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT框架通过采样、提示和优化三个层面激励多样性，解决RL微调生成模型时的多样性崩溃问题，在任务对齐和生成多样性之间取得更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型时存在多样性崩溃问题，即优化过程会使策略收敛到Dirac delta分布，导致生成结果缺乏多样性，限制了模型在实际应用中的实用性。

Method: 提出DRIFT框架，从三个角度激励多样性：1) 采样奖励集中的子集，过滤奖励异常值防止过早崩溃；2) 使用随机变体进行提示，扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验结果显示DRIFT在任务对齐和生成多样性方面取得帕累托优势：在相同对齐水平下多样性提升9.08%~43.46%，在相同多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT框架通过系统性激励多样性，成功解决了RL微调生成模型时的多样性崩溃问题，实现了任务对齐与生成多样性的更好平衡，增强了模型在需要多样化候选生成的应用中的实用性。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [348] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发了一个可解释的机器学习框架，用于儿科牙科风险分层，强调可解释性和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿科牙科疾病是全球最普遍且不公平的慢性健康问题之一。现有AI牙科应用主要依赖基于图像的诊断和黑盒预测模型，缺乏透明度，限制了在儿科人群中的伦理适用性

Method: 使用人口水平的儿科数据训练监督机器学习模型，包括年龄、收入贫困比、种族/民族、性别和病史。使用ROC分析和校准曲线评估性能，通过SHAP实现可解释性

Result: 模型实现了适度的区分能力（AUC=0.61），校准保守，在高风险水平下低估风险。SHAP分析显示年龄和收入贫困比是风险预测的最强贡献因素，其次是种族/民族和性别

Conclusion: 可解释机器学习实现了透明的、预防导向的儿科牙科风险分层，支持人群筛查和公平资源分配，而非诊断决策

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [349] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 该论文提出正交化策略优化(OPO)框架，将对齐方法解耦为采样几何和优化几何两个独立设计选择，解决传统KL散度带来的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法(如PPO、DPO、IPO)隐含地将采样几何和优化几何混为一谈，而KL散度对无界值信号施加指数惩罚，导致数值不稳定和高置信度下的梯度消失问题。

Method: 提出正交化策略优化(OPO)框架，将采样几何(α-加权重要性采样)与优化几何(χ²诱导的二次正则化)显式解耦，在比率坐标中使用线性梯度动态的简单且条件良好的目标函数。

Result: OPO在保持峰值寻求行为的同时实现稳定优化，避免梯度饱和，即使模型置信度高时也能保持良好性能，为现有对齐方法提供了统一视角。

Conclusion: OPO通过解耦采样和优化几何，为鲁棒推理导向训练提供了原则性基础，解决了传统对齐方法的数值不稳定问题，是现有方法的统一框架。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [350] [Graph Attention Networks with Physical Constraints for Anomaly Detection](https://arxiv.org/abs/2601.12426)
*Mohammadhossein Homaei,Iman Khazrak,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

TL;DR: 提出一种基于水力感知的图注意力网络，利用归一化守恒定律违规作为特征，结合图注意力和双向LSTM学习时空模式，用于水分配系统的异常检测。


<details>
  <summary>Details</summary>
Motivation: 水分配系统面临日益增长的网络物理风险，需要可靠的异常检测。现有数据驱动模型忽略网络拓扑且难以解释，而基于模型的方法严重依赖参数精度。

Method: 使用归一化守恒定律违规作为特征，结合质量平衡和能量平衡残差，采用图注意力网络和双向LSTM学习时空模式，并设计多尺度模块从节点到网络层面聚合检测分数。

Result: 在BATADAL数据集上达到F1=0.979，相比现有方法提升3.3个百分点，在15%参数噪声下表现出高鲁棒性。

Conclusion: 该方法有效结合了物理知识和深度学习，提高了水分配系统异常检测的准确性和鲁棒性，同时考虑了网络拓扑结构。

Abstract: Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.

</details>


### [351] [Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery](https://arxiv.org/abs/2601.12442)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: CANUF框架将贝叶斯深度学习与可微分符号推理结合，为科学AI提供可信的不确定性估计，同时满足领域约束


<details>
  <summary>Details</summary>
Motivation: 科学AI应用需要提供可信不确定性估计并尊重领域约束的模型。现有不确定性量化方法缺乏整合符号科学知识的机制，而神经符号方法在确定性操作中缺乏原则性的不确定性建模

Method: CANUF框架包含三个组件：1) 从科学文献自动提取约束；2) 具有变分推理的概率神经骨干；3) 确保物理一致性的可微分约束满足层

Result: 在Materials Project、QM9分子属性和气候基准测试中，CANUF将预期校准误差降低34.7%（相比贝叶斯神经网络），同时保持99.2%的约束满足率。约束引导的重新校准贡献了18.3%的性能增益，约束提取达到91.4%的精确度

Conclusion: CANUF提供了首个端到端可微分管道，同时解决了不确定性量化、约束满足和科学预测的可解释性解释问题

Abstract: Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.

</details>


### [352] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 提出两阶段时间序列预测框架：第一阶段用CNN提取局部时间动态特征并生成补丁级token嵌入，第二阶段用Transformer编码器建模补丁间依赖关系进行预测。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在时间序列预测中表现良好，但其效果严重依赖于从原始多元时间序列数据中提取的输入表示的质量和结构。现有方法在局部时间表示学习和全局依赖建模方面存在耦合问题。

Method: 提出两阶段预测框架：1）局部时间表示学习阶段：使用CNN在固定长度时间补丁上提取短程时间动态和非线性特征交互，生成紧凑的补丁级token嵌入，并通过token级自注意力跨时间补丁交互优化这些嵌入；2）全局依赖建模阶段：使用Transformer编码器处理token序列，建模补丁间时间依赖关系并生成每个补丁的预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于补丁的token化策略相比卷积和基于补丁的Transformer基线实现了有竞争力的预测性能。

Conclusion: 结构化时间表示的重要性得到验证，将局部时间编码与基于注意力的全局建模解耦能够产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [353] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 论文提出使用半定规划（SDP）从经典数据重建量子通道的方法，该方法适用于保真度可表示为两个二次型比值的情况，并发现重建的量子通道通常具有较小的Kraus秩。


<details>
  <summary>Details</summary>
Motivation: 研究如何从经典实验数据中重建量子通道，这对于量子信息处理和实验验证量子系统行为具有重要意义。

Method: 当总保真度可表示为两个二次型比值时，将保真度优化问题转化为关于Choi矩阵的半定规划问题，利用商业SDP求解器进行数值求解。

Result: 测试多个商业SDP求解器都能成功重建不同形式的量子通道，且获得的量子通道Kraus秩通常小于最大可能值的几个百分点，表明小Kraus秩量子通道足以描述实验观测数据。

Conclusion: SDP方法能有效重建量子通道，且通常只需要小Kraus秩的量子通道；该方法也适用于重建投影算子，并讨论了基于量子通道变换的经典计算模型。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [354] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

TL;DR: 该论文提出了改进拉格朗日神经网络(LNNs)训练稳定性的方法，包括Hessian正则化、专用激活函数和物理感知坐标缩放，使LNNs能够学习更复杂系统的拉格朗日量，包括相对论背景下的测地线运动。


<details>
  <summary>Details</summary>
Motivation: 拉格朗日神经网络能够从轨迹数据中学习任意拉格朗日量，但其不寻常的优化目标导致显著的训练不稳定性，限制了其在复杂系统中的应用。需要解决这些基本挑战以扩展LNNs的实际应用。

Method: 提出了三个主要改进：1) Hessian正则化方案，惩罚拉格朗日量对速度二阶导数中的非物理特征；2) 更适合学习拉格朗日量的激活函数；3) 物理感知坐标缩放以提高稳定性。在相对论设置中，还扩展正则化以惩罚洛伦兹特征的违反。

Result: 改进的架构成功训练了前所未有的复杂系统，包括三摆系统。在双摆系统中，验证损失降低了96.6%，稳定性提高了90.68%。能够学习非相对论和广义相对论背景下的测地线运动拉格朗日量，首次直接从轨迹数据预测AdS₄时空度量下的测地线拉格朗日量。

Conclusion: 虽然该方法继承了原始LNN框架的一些限制（特别是可逆Hessian的要求），但显著扩展了LNNs在科学发现任务中的实际适用性，为物理中几何结构的自动发现（包括从测地线轨迹提取时空度量张量分量）开辟了新可能性。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [355] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 提出一种针对稀疏二元特征和二元分类的决策树分裂算法，能在近似最优信息增益或基尼指数的条件下，实现比传统O(d)方法更快的分裂搜索，特别适用于稀疏数据。


<details>
  <summary>Details</summary>
Motivation: 传统决策树分裂算法在处理稀疏二元特征时，即使大部分特征值为0，仍需O(d)时间检查所有特征。对于稀疏数据（m << d），这种效率低下，需要更快的近似最优分裂搜索方法。

Method: 提出基于条件熵和基尼指数的近似算法：1) 对于条件熵，实现(1+α)近似，摊销时间复杂度为O(α^{-1}(1+m log d) log log n)；2) 对于基尼指数，实现(1+α)近似，摊销时间复杂度为O(α^{-1}+m log d)。算法利用稀疏性，只关注非零特征。

Result: 实验显示算法能高效找到近似最优分裂点，速度超过基线方法，且实际性能优于理论近似保证。在稀疏数据上表现优异，其中m远小于d时优势明显。

Conclusion: 针对稀疏二元特征的决策树分裂问题，提出的近似算法能显著加速分裂搜索过程，在保持近似最优性的同时，为流式决策树学习提供了高效解决方案。

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [356] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 该研究将电动汽车在线集中充电调度问题游戏化，通过图像到移动模型和DAgger训练，在负载均衡和经济性方面显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车动态到达的实时集中充电调度问题，在容量限制下平衡整个规划周期的负载，降低系统成本并推迟昂贵的电网升级。

Method: 将问题游戏化建模为在时空容量约束网格上放置充电块；设计启发式策略，用专家演示训练学习智能体，并使用数据集聚合(DAgger)改进模型。

Result: 游戏化学习显著提升负载均衡效果，DAgger训练的模型在多种EV到达模式下均优于启发式基线、向量方法和监督学习，在蒙特利尔实际案例中每年可节省数千万美元系统成本。

Conclusion: 游戏化方法降低了模型复杂度并获得更紧的泛化界，基于DAgger的图像到移动模型在充电调度中表现出优越性能和经济效益，具有实际应用价值。

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [357] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

TL;DR: 提出两种机器学习架构（BCNN和SQuAT）用于从系外行星反射光谱预测生物标志物通量，为HWO等旗舰任务提供目标筛选和观测优化工具。


<details>
  <summary>Details</summary>
Motivation: 未来直接成像旗舰任务（如NASA的HWO）面临严格的时间和资源限制，需要高效筛选观测目标。现有方法在不确定性量化和光谱可解释性方面存在不足。

Method: 开发了两种机器学习架构：1）贝叶斯卷积神经网络（BCNN），量化认知和随机不确定性；2）光谱查询自适应变换器（SQuAT），使用查询驱动注意力机制增强可解释性。

Result: 两种模型在广泛的系外行星条件增强数据集上都实现了高预测精度，BCNN在不确定性量化方面表现优异，SQuAT在光谱特征与生物标志物关联方面具有更好的可解释性。

Conclusion: 这两种方法为HWO等旗舰任务提供了有前景的工具，能够加速目标筛选、优化观测计划并最大化科学回报，特别在不确定性量化和光谱解释方面各有优势。

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [358] [Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization](https://arxiv.org/abs/2601.12598)
*Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Emre Neftci*

Main category: cs.LG

TL;DR: 该论文提出了SelectivBench，一个用于系统评估线性循环模型选择性的轻量级合成基准测试集，揭示了这些模型的关键架构特征与性能之间的关系。


<details>
  <summary>Details</summary>
Motivation: 线性循环神经网络作为Transformer注意力机制的高效替代方案，虽然训练并行化程度高且推理时内存和计算需求恒定，但现有基准测试要么过于简单无法揭示实质性差异，要么资源消耗过大难以实验。缺乏系统性的直接比较限制了这些模型的深入理解。

Method: 提出了线性循环模型的精细化分类法，并设计了SelectivBench基准测试集。该基准使用基于规则的语法生成可调整复杂度的序列，包含故意违反转换规则的不规则间隔，专门评估中小规模序列模型的选择性能力（即关注相关输入同时忽略基于上下文的干扰项的能力）。

Result: 在SelectivBench上评估线性循环模型显示，性能模式与大规模语言任务的结果一致。分析揭示了关键架构特征的作用：门控和快速遗忘机制促进召回；状态内通道混合对选择性不必要但对泛化关键；softmax注意力因其内存容量随序列长度缩放而保持优势。

Conclusion: SelectivBench为线性循环模型提供了有针对性的高效探索工具，并为研究大规模评估中观察到的行为提供了受控环境。该基准有助于澄清不同架构特征的作用，促进更有效的模型设计。

Abstract: Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench

</details>


### [359] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出基于广义f-softargmax的策略参数化方法替代softmax，结合f-散度正则化，无需预条件即可获得非渐近最后迭代收敛保证，显著改善样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法对策略参数化选择高度敏感，softmax参数化会导致病态优化景观和指数级慢收敛。预条件方法计算昂贵，需要更高效的替代方案。

Method: 用广义f-softargmax替代softmax参数化，结合对应f-散度的正则化器，改善优化景观并确保正则化目标满足Polyak-Lojasiewicz不等式。

Result: 首次为有限MDP的随机策略梯度方法建立了无需预条件的显式非渐近最后迭代收敛保证。Tsallis散度的f-PG实现多项式样本复杂度，而标准softmax需要指数复杂度。

Conclusion: f-softargmax参数化结合f-散度正则化提供了有效的策略梯度方法，显著改善收敛性和样本效率，为强化学习优化提供了新工具。

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [360] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 提出一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成通用对抗扰动，在降低可见性的同时提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动能够用单一噪声模式破坏多个输入的深度神经网络，进化算法因其在非凸、无梯度空间中的导航能力，为生成此类扰动提供了有前景的方法。

Method: 采用浮点编码、惩罚驱动的单目标进化框架，利用与当代深度学习规模对齐的连续基因表示，结合动态进化算子与自适应调度，采用模块化PyTorch实现，通过跨模型测试和周期性批次切换确保扰动通用性。

Result: 在ImageNet数据集上的实验表明，该框架相比现有进化方法，能产生更小范数、更高误分类效果、更快收敛的扰动。

Conclusion: 该方法在通用对抗攻击方面展现出鲁棒性和可扩展性，适用于各种深度学习架构。

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [361] [Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.12637)
*Long D. Nguyen,Kelin Xia,Binh P. Nguyen*

Main category: cs.LG

TL;DR: MI-MoE：一种用于3D分子图学习的多尺度交互专家混合模型，通过拓扑感知路由机制自适应建模不同几何尺度（短、中、长程）的相互作用。


<details>
  <summary>Details</summary>
Motivation: 现有3D分子图神经网络依赖固定的邻域启发式方法（如距离截断和最大邻居限制），导致刚性的、数据无关的交互预算，无法自适应建模不同几何尺度（短程、中程、长程）的非共价相互作用、立体化学效应和介质到长程力。

Method: 提出多尺度交互专家混合模型（MI-MoE）：1）距离截断专家集合，显式捕获短程、中程和长程相互作用；2）拓扑门控编码器，使用基于过滤的描述符（包括持久同调特征）将输入路由到不同专家；3）作为即插即用模块，可改进多种3D分子骨干网络。

Result: MI-MoE作为即插即用模块，在多个3D分子骨干网络上一致改进性能，覆盖回归和分类任务，在多样化的分子和聚合物性质预测基准数据集上表现优异。

Conclusion: 拓扑感知的多尺度路由是3D分子图学习的有效原则，MI-MoE能够自适应建模不同几何尺度的相互作用，克服传统固定邻域启发式方法的局限性。

Abstract: Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.

</details>


### [362] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: SHAP解释存在多重性问题：相同输入、任务和模型下，多次运行会产生多个内部有效但实质上不同的特征归因解释，这种不稳定性在多种数据集和模型中都普遍存在。


<details>
  <summary>Details</summary>
Motivation: SHAP解释常被用于高风险领域决策的辩护、质疑和审计，被视为可靠的个体预测特征驱动解释。然而，即使输入、任务和训练模型固定，SHAP解释在重复运行中也会发生显著变化，这种解释多重性问题需要系统研究。

Method: 提出了一种方法来表征特征归因解释中的多重性，区分模型训练/选择来源与解释管道内在随机性。使用幅度基和排序基度量评估稳定性，并推导随机基线值作为参考基准。

Result: 发现解释多重性普遍存在，即使在高度置信的预测中也会持续存在。幅度基距离可能接近零，而排序基度量揭示顶级特征身份和顺序的显著变化。

Conclusion: SHAP解释存在固有的不稳定性，需要开发与解释预期用途相匹配的度量和基线，以确保解释的可靠性和实用性。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [363] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

TL;DR: 提出基于图多智能体强化学习的框架，用于优化无线网络中自回归马尔可夫源的实时采样与估计策略，证明策略可迁移至结构相似网络


<details>
  <summary>Details</summary>
Motivation: 解决动态多跳无线网络中自回归马尔可夫源的实时采样与估计问题，由于动作空间维度高和网络拓扑复杂，传统分析方法难以获得最优策略

Method: 提出图多智能体强化学习框架进行策略优化，利用图结构表示网络拓扑，实现去中心化策略学习

Result: 数值实验表明：1) 提出的策略优于现有基线方法；2) 训练策略可迁移至更大网络，性能增益随智能体数量增加而提升；3) 图训练过程能抵抗非平稳性；4) 循环机制在独立学习和集中训练分散执行中都至关重要

Conclusion: 图多智能体强化学习框架能有效解决复杂无线网络中的实时采样估计问题，所提策略具有可迁移性和鲁棒性，为动态网络环境下的分布式决策提供了可行方案

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [364] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 提出MetaToolAgent (MTA)元学习方法，通过包含155个工具和9377个问答对的数据集，解决LLM工具选择中跨工具泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法通常局限于有限工具集，难以泛化到实际部署中遇到的新工具，限制了LLM在复杂现实任务中的工具协调能力。

Method: 提出MetaToolAgent (MTA)元学习方法，构建包含7个领域、155个工具、9377个问答对的综合数据集，模拟真实集成场景，提升跨工具泛化能力。

Result: 实验结果显示，MTA在未见工具上显著优于基线方法，证明了其在构建需要动态工具协调的灵活可扩展系统方面的潜力。

Conclusion: MTA通过元学习方法有效提升了LLM在工具选择中的跨工具泛化能力，为构建灵活可扩展的工具协调系统提供了有前景的解决方案。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [365] [Towards Spectroscopy: Susceptibility Clusters in Language Models](https://arxiv.org/abs/2601.12703)
*Andrew Gordon,Garrett Baker,George Wang,William Snell,Stan van Wingerden,Daniel Murfet*

Main category: cs.LG

TL;DR: 提出一种基于谱学原理的神经网络分析方法，通过扰动数据分布测量模型响应，识别出510个可解释的聚类，涵盖语法模式、代码结构和数学符号等。


<details>
  <summary>Details</summary>
Motivation: 受物理学中光谱学原理启发，希望开发一种系统方法来理解神经网络内部结构。传统方法难以解释神经网络如何处理不同上下文中的相似模式。

Method: 通过上加权特定token来扰动数据分布，使用随机梯度Langevin动力学计算敏感度χ_xy（组件级可观测量与扰动之间的协方差），开发基于传导度的聚类算法分析模型响应。

Result: 在Pythia-14M模型中识别出510个可解释的聚类，涵盖语法模式、代码结构、数学符号等。与稀疏自编码器比较，50%的聚类与SAE特征匹配，验证了方法的有效性。

Conclusion: 提出的谱学方法能够有效揭示神经网络内部结构，敏感度分解为数据分布模式之和的理论解释为理解模型行为提供了新视角，该方法与现有技术互补。

Abstract: Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts "for similar reasons" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.

</details>


### [366] [Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems](https://arxiv.org/abs/2601.12704)
*Yan Ma,Yumeng Ren*

Main category: cs.LG

TL;DR: 提出基于径向基函数神经网络（RBFNN）的物理信息机器学习算法（PIRBFNN），用于求解多资产期权定价的Black-Scholes偏微分方程，通过自适应优化网络结构和物理约束实现高效准确求解。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多资产期权定价的Black-Scholes偏微分方程时，特别是面对非光滑支付条件时存在困难，需要开发更高效准确的数值求解方法。

Method: 结合径向基函数配置法和物理信息神经网络，提出PIRBFNN方法，利用PDE残差技术自适应优化隐藏神经元分布，同时优化网络结构和预测期权价格。

Result: 通过单资产欧式看跌期权、双资产交换期权和四资产篮子看涨期权的实验验证了方法的有效性，能够准确高效处理多维期权定价模型。

Conclusion: PIRBFNN方法成功结合了传统径向基函数配置法和物理信息神经网络的优点，为金融领域PDE问题提供了一种有效的求解方案。

Abstract: The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.

</details>


### [367] [Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting](https://arxiv.org/abs/2601.12706)
*Sina Kazemdehbashi*

Main category: cs.LG

TL;DR: 将时间序列预测重构为趋势预测和数值预测两部分，提出TATS模型，通过二元分类器预测趋势并调整LSTM/Bi-LSTM的预测值，在金融时间序列上表现优于标准模型。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法（从经典统计模型到LSTM等神经网络）通常直接预测数值，但未能充分利用趋势信息。作者认为将预测任务分解为趋势预测和数值预测两部分，并通过趋势信息调整数值预测，可能提高预测准确性。

Method: 提出TATS模型：1) 使用二元分类器预测时间序列在下一时间步的趋势（上涨/下跌）；2) 使用LSTM或Bi-LSTM预测下一时间步的数值；3) 基于预测的趋势调整数值预测结果。模型在黄金价格等波动性金融时间序列上进行验证。

Result: TATS模型在黄金价格预测任务中显著优于标准LSTM和Bi-LSTM模型，实现了更低的预测误差。同时发现传统指标如MSE和MAE不足以全面评估时间序列模型性能，需要结合趋势检测准确率来评估模型捕捉趋势的能力。

Conclusion: 将时间序列预测重构为趋势预测和数值预测两部分是有效的，TATS模型通过趋势调整显著提高了预测精度。未来时间序列模型评估应考虑结合趋势检测准确率等更全面的指标。

Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.

</details>


### [368] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: 提出DCPO方法，通过分布中心视角解决强化学习中探索-利用权衡问题，用分布级正则化替代样本级启发式方法，实现可控熵和高效探索。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法训练偏向利用驱动，熵单调下降，探索能力减弱。现有解决方案多为样本中心方法，依赖"幸运"样本，缺乏对策略的原则性控制，效果有限且不稳定。

Method: 提出分布中心策略优化(DCPO)，将熵调节重新定义为分布级正则化问题。通过引导策略朝向"更好"的目标分布，实现完全在策略上的可控熵，无需从外部分布采样。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%。实现了高效探索的同时保持训练稳定性。

Conclusion: DCPO用分布级原则替代样本级启发式方法，为可控探索和更强的探索-利用权衡提供了理论基础和灵活框架。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [369] [A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection](https://arxiv.org/abs/2601.12745)
*Miao Ye,Jing Cui,Yuan huang,Qian He,Yong Wang,Jiwen Zhang*

Main category: cs.LG

TL;DR: 提出一种结合时空相关特征的图神经网络异常检测主干网络，采用"预训练-图提示-微调"的多任务自监督训练策略，用于无线传感器网络多时序模态数据的异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有多时序模态数据异常检测方法存在时空相关特征提取不足、异常样本标注成本高、异常样本不平衡等问题，需要针对WSN图结构数据特点设计更有效的检测方法。

Method: 1) 基于多尺度策略和模态间融合方法改进Mamba模型，结合变分图卷积模块设计异常检测主干网络；2) 设计包含无负对比学习、预测和重构的三子任务预训练方法；3) 采用"图提示-微调"机制指导预训练模型进行参数微调。

Result: 在公开数据集和实际采集数据集上的F1指标分别达到91.30%和92.31%，相比现有方法具有更好的检测性能和泛化能力。

Conclusion: 该方法能有效提取WSN多节点多时序模态场景下的时空相关特征，降低训练成本，提升检测泛化性能，为WSN可靠运行提供重要保障。

Abstract: Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.

</details>


### [370] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 提出基于布尔函数理论的GNN表达能力新框架，引入子群体布尔同构(SBI)概念，超越现有表达能力度量，识别傅里叶度、电路类和影响力为公平感知GNN的表达能力关键障碍，设计能处理复杂布尔函数定义子群体的公平算法。


<details>
  <summary>Details</summary>
Motivation: 现有GNN表达能力度量（如WL、双连通性、同态框架）无法精细分析GNN捕获复杂子群体结构的能力，特别是在公平性场景中处理由复杂布尔函数定义的交叉子群体时存在局限。

Method: 提出基于布尔函数理论的表达能力框架，引入子群体布尔同构(SBI)概念，设计基于电路遍历的公平算法，能够处理由高复杂度布尔函数（如奇偶性）定义的子群体。

Result: 理论证明SBI严格包含现有表达能力度量，识别傅里叶度、电路类(AC⁰、NC¹)和影响力为表达能力关键障碍。在真实世界图数据上，该方法在现有方法失败的交叉子群体上实现低公平性差距。

Conclusion: 该研究提供了首个针对公平性定制的GNN表达能力原理性处理方法，提出的框架能够分析GNN捕获复杂子群体结构的能力，设计的算法能有效处理高复杂度布尔函数定义的子群体公平性问题。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [371] [Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks](https://arxiv.org/abs/2601.12775)
*Yuta Hirabayashi,Daisuke Matusoka,Konobu Kimura*

Main category: cs.LG

TL;DR: 本文提出了一种基于多尺度图神经网络的10天全球海洋预报模型，通过双分辨率球面网格和大气变量输入，提高了短期预报精度和多尺度海洋变率的表征能力。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的海洋模型研究进展迅速，但应用于全球涡旋解析海洋预报仍有限制。准确表征广泛空间尺度上的海洋动力学是主要挑战。

Method: 采用编码器-处理器-解码器架构，使用两种不同分辨率的球面网格来捕捉多尺度海洋动力学。将表面大气变量与海洋状态变量一起作为节点输入，以通过表征大气强迫来提高短期预测精度。

Result: 通过表面动能谱和案例研究评估，模型准确表征了广泛的空间尺度范围。均方根误差比较显示短期预测技能得到改善。

Conclusion: 该模型提供了更准确的短期预报和改善的多尺度海洋动力学表征，显示出推进数据驱动、涡旋解析全球海洋预报的潜力。

Abstract: Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.

</details>


### [372] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS是首个专为时间序列基础模型设计的知识蒸馏框架，通过水平加权目标和时间对齐策略解决预测任务中的特殊挑战，实现模型压缩150倍、推理加速6000倍的同时保持可比性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然预测性能强，但参数量大导致部署成本高。现有的通用知识蒸馏技术无法直接应用于时间序列预测，因为存在任务难度差异和架构差异等独特挑战。

Method: 提出DistilTS框架：1) 针对预测任务中短期水平容易优化而长期水平监督弱的问题，引入水平加权目标平衡各水平的学习；2) 针对架构差异问题，设计时间序列预测中的对齐机制，减少架构不匹配。

Result: 在多个基准测试中，DistilTS实现了与完整大小时间序列基础模型相当的预测性能，同时将参数减少高达1/150，推理速度提升高达6000倍。

Conclusion: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，有效解决了预测任务中的独特挑战，为高效部署时间序列基础模型提供了实用解决方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [373] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: SIT-Graph：一种用于图学习的半监督指令调优框架，通过迭代自训练利用未标记节点提升LLM在图学习任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有图指令调优方法需要大量标注数据，在社交等领域获取专家标注成本高且缓慢，且未能充分利用未标记节点中蕴含的潜在相关性信息

Method: 提出模型无关的SIT-Graph框架，通过迭代自训练：1) 先用标记节点进行初始指令调优；2) 为未标记节点生成置信度过滤的伪响应；3) 策略性地扩充数据集进行下一轮调优；4) 迭代优化使LLM与底层节点相关性对齐

Result: 将SIT-Graph集成到最先进的图指令调优方法中，在文本属性图基准测试上显著提升性能，在低标签比例设置下获得超过20%的改进

Conclusion: SIT-Graph有效解决了图指令调优中标注数据稀缺的问题，通过利用未标记节点的潜在相关性，显著提升了LLM在图学习任务中的性能

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [374] [Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning](https://arxiv.org/abs/2601.12816)
*Ishir Garg,Neel Kolhe,Andy Peng,Rohan Gopalam*

Main category: cs.LG

TL;DR: 提出FOPNG优化器，通过Fisher正交投影约束参数更新，防止灾难性遗忘，在连续学习任务中保持旧任务性能。


<details>
  <summary>Details</summary>
Motivation: 连续学习的关键挑战是在学习新任务时避免灾难性遗忘旧任务。现有方法在欧几里得参数空间中操作，缺乏信息几何框架下的统一理论。

Method: 提出Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG)优化器，将梯度投影到先前任务梯度的Fisher正交补空间，在信息几何框架下统一自然梯度下降和正交梯度方法。

Result: 在Permuted-MNIST、Split-MNIST、Rotated-MNIST、Split-CIFAR10和Split-CIFAR100等标准连续学习基准上取得优异结果。

Conclusion: FOPNG通过Fisher正交约束提供参数更新不变性，保证在Fisher度量下的下降，有效保护先前任务输出，为连续学习提供了理论严谨且实用的解决方案。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.

</details>


### [375] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一个生成机器学习模型，通过Cremer-Pople空间进行流匹配，专门用于生成环状分子的构象，在多样性和精确性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学应用中普遍存在，其受限的构象灵活性对药物发现和催化功能至关重要，但可靠采样环系统的构象集合仍然具有挑战性。

Method: 引入PuckerFlow模型，在Cremer-Pople空间（捕获环相关自由度的低维内部坐标系）上执行流匹配，确保生成有效的闭合环结构。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，能够生成既多样又精确的构象，特别适用于催化和药物发现中的环系统。

Conclusion: 该工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系和跨化学与生物学应用的属性引导环生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [376] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: HAGD框架通过多分辨率抽象层次和可微分电路搜索，将电路发现复杂度从O(2^n)降低到O(n² log n)，在GPT-2、Llama和Pythia模型上实现了高达91%的行为保持和可解释的子图规模。


<details>
  <summary>Details</summary>
Motivation: 从数十亿参数的语言模型中提取稀疏计算电路面临指数搜索复杂性和普遍多义性的挑战，需要开发更高效的机制可解释性方法。

Method: 提出分层归因图分解(HAGD)框架，整合跨层转码器用于单义特征提取、图神经网络元学习用于拓扑预测、因果干预协议用于验证。

Result: 在模运算任务上实现高达91%的行为保持（±2.3%），跨架构迁移实验显示电路结构相似性平均达67%，表明潜在共享计算模式。

Conclusion: 为更大模型规模的解释性提供了初步基础，同时识别出现有归因方法的显著局限性，需要未来进一步改进。

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [377] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs是一种针对时间序列预测的源自由测试时自适应方法，利用神经常微分方程处理分布漂移，仅需更新有限参数即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法主要针对独立数据，很少考虑时间序列数据和预测任务，而时间序列数据在实际应用中面临分布漂移的挑战。

Method: 基于神经常微分方程构建自适应框架，提出新的损失函数专门处理预测任务，仅更新有限模型参数以减少内存使用。

Result: 在一维和高维数据实验中，相比现有最佳基线方法分别获得5.88%和28.4%的相对改进，在高严重度分布漂移下表现出鲁棒性。

Conclusion: AdaNODEs为时间序列预测任务提供了一种有效的源自由测试时自适应方法，能够有效处理分布漂移问题，同时保持计算效率。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [378] [Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times](https://arxiv.org/abs/2601.12900)
*Eliran Sherzer,Yonit Barron*

Main category: cs.LG

TL;DR: 使用神经网络监督学习框架近似(s,S)库存系统的稳态性能指标，替代昂贵的仿真计算


<details>
  <summary>Details</summary>
Motivation: 传统的(s,S)库存模型在非马尔可夫系统中分析困难，通常依赖昂贵的仿真计算来评估长期性能指标

Method: 提出基于神经网络的监督学习框架：先用仿真生成训练标签，然后训练神经网络，使用少量低阶矩作为输入特征

Result: 神经网络能够快速准确地预测库存水平稳态分布、期望周期时间、缺货概率等指标，在大范围系统参数下表现出高精度

Conclusion: 该框架有效替代重复昂贵的仿真运行，可轻松扩展到其他库存模型，为分析复杂随机系统提供高效快速替代方案

Abstract: The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.
  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.

</details>


### [379] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 提出了一个名为BenchTGC的全面基准，用于解决时序图聚类（TGC）任务中的两大挑战：不适用的聚类技术和数据集，通过设计框架和改进技术来推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 时序图聚类是一个新兴但关注度低的任务，相比静态图聚类，它能在时间要求和空间要求之间找到平衡。然而，当前存在两大挑战阻碍了TGC的发展：不适用的聚类技术和不适用的数据集。

Method: 提出了BenchTGC基准，包括：1）设计BenchTGC框架来说明时序图聚类的范式；2）改进现有聚类技术以适应时序图；3）开发适用于TGC任务的多个数据集（BenchTGC数据集）。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时序图聚类任务的必要性和重要性。实验表明，现实世界中动态变化和复杂的场景是时序图聚类的基础。

Conclusion: BenchTGC基准成功解决了时序图聚类面临的技术和数据集挑战，为该领域的发展提供了重要基础，并展示了时序图聚类在现实动态场景中的实际价值。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [380] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM：云辅助的边缘端协同联邦微调框架，结合移动设备上的零阶优化和云端的梯度修正，显著降低内存使用、加速收敛并提高精度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动设备上微调面临内存和计算成本高的挑战，而现有联邦学习方法要么依赖内存密集型反向传播，要么使用收敛慢、精度低的零阶优化方法

Method: 提出云辅助的边缘端协同联邦微调框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来修正本地更新

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存降低高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线精度提高最多10个百分点

Conclusion: CooperLLM通过云辅助的协同联邦微调，有效解决了移动设备上LLM微调的内存和计算限制问题，在保持隐私的同时实现了高效、准确的模型个性化

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [381] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 提出一种基于形状空间和弹性距离的镰状细胞自动分类方法，通过固定参数化和模板对齐简化计算，在监督分类和无监督聚类中达到96.03%准确率


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，全球患病率高且对医疗系统负担重。自动分类镰状细胞对减轻专家工作量、避免量化错误和评估危机严重性至关重要

Method: 将红细胞建模为形状空间中的封闭平面曲线，使用弹性距离（对旋转、平移、缩放和重参数化不变）。改进包括：(1) 基于细胞主轴使用固定参数化计算距离；(2) 在计算距离前使用该参数化将每个细胞与两个模板对齐，简化计算

Result: 在监督分类和无监督聚类中均达到96.03%的准确率，在保持或提高形状空间模型准确性的同时显著降低计算成本

Conclusion: 该方法实现了高效的红细胞分类，通过固定参数化和模板对齐简化了基于形状空间的分类计算，在准确性和计算效率之间取得了良好平衡

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [382] [Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning](https://arxiv.org/abs/2601.12965)
*Doheon Kim*

Main category: cs.LG

TL;DR: 论文为基于分数的扩散模型提供了理论解释，说明即使神经网络使用乘法噪声条件化无法完全学习正确分数函数，仍能生成良好样本的原因。


<details>
  <summary>Details</summary>
Motivation: 虽然基于分数的扩散模型在理论上可以通过与采样过程相关的微分方程解释，但Song和Ermon（2020）发现使用乘法噪声条件化的神经网络仍能生成满意样本。这种模型结构限制了空间变量与噪声之间更一般关系的表示能力，表明无法完全学习正确分数函数，但实践中表现良好，需要理论解释这一现象。

Method: 通过研究相关微分方程的确定性动力学，分析模型如何运作。具体方法是研究乘法噪声条件化模型的结构限制，并分析在这种限制下模型仍然有效的理论机制。

Result: 提供了理论解释，说明即使模型无法完全学习正确分数函数，仍能有效生成样本的原因。通过分析确定性动力学，揭示了在这种受限模型结构下仍然能够良好运作的机制。

Conclusion: 即使使用乘法噪声条件化的扩散模型在理论上无法完全学习正确分数函数，但通过研究相关微分方程的确定性动力学，可以解释为什么这些模型在实践中仍然能够生成高质量样本，为这种现象提供了理论依据。

Abstract: Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.

</details>


### [383] [Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients](https://arxiv.org/abs/2601.12971)
*Pancheng Niu,Jun Guo,Qiaolin He,Yongming Chen,Yanchao Shi*

Main category: cs.LG

TL;DR: 提出ACR-PINN，通过层间动态注意力机制增强表示能力，并采用冲突梯度更新策略解决多任务学习中的梯度干扰问题，显著提升PINNs的收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在实际应用中存在表示能力有限和优化困难的问题，主要源于物理约束竞争和梯度冲突。需要从架构-优化协同设计的角度提升PINN性能。

Method: 1. 提出层间动态注意力机制（LDA-PINN）增强表示灵活性；2. 将PINN训练重构为多任务学习问题，引入冲突梯度更新策略（GC-PINN）；3. 整合两者形成ACR-PINN，保持标准PINN损失形式。

Result: 在Burgers、Helmholtz、Klein-Gordon方程和腔体驱动流等基准PDE问题上，ACR-PINN相比标准PINNs实现了更快的收敛速度和显著更低的相对L2和L∞误差。

Conclusion: 架构-优化协同设计能有效提升PINN求解器的鲁棒性和精度，ACR-PINN通过注意力表示和冲突感知优化的结合，为PINN训练提供了新的解决方案。

Abstract: Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.

</details>


### [384] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: PaperCompass：一个分离高层规划与细粒度执行的框架，通过DFPO训练方法提升LLM在科学论文阅读任务中的效率


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长使得研究人员难以通过手动阅读跟踪新进展，现有基于LLM的方法存在过度探索和低效问题

Method: 提出PaperCompass框架，分离高层规划与细粒度执行：先制定明确计划，再进行详细推理执行；引入DFPO训练方法联合优化计划草稿和最终解决方案

Result: 在Paper-QA基准测试中，PaperCompass在保持性能的同时提高了效率，取得了与更大模型相当的结果

Conclusion: PaperCompass通过认知科学启发的分层方法，有效缩小LLM的"知行差距"，为科学文献处理提供了高效解决方案

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [385] [HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads](https://arxiv.org/abs/2601.13013)
*Xiaohui Zhao,Xinjian Zhao,Jiahui Zhang,Guoyu Liu,Houzhi Wang,Shu Wu*

Main category: cs.LG

TL;DR: HT-GNN模型通过超图监督模块、Transformer时序编码器和任务自适应专家混合机制，解决了新闻广告LTV预测中的用户群体异质性和动态行为序列两大挑战。


<details>
  <summary>Details</summary>
Motivation: 新闻广告中的LTV预测面临两大挑战：1) 基于人口统计的目标定位导致不同用户群体的LTV分布差异巨大；2) 动态营销策略产生不规则的行为序列，用户参与模式快速变化。

Method: 提出超时序图神经网络(HT-GNN)，包含三个关键组件：1) 超图监督模块捕捉跨用户群体关系；2) 基于Transformer的自适应加权时序编码器；3) 任务自适应专家混合机制，使用动态预测塔进行多时间范围LTV预测。

Result: 在百度广告平台的1500万用户数据集上实验表明，HT-GNN在所有指标和预测时间范围上都持续优于现有最先进方法。

Conclusion: HT-GNN通过联合建模人口统计异质性和时序动态，有效解决了LTV预测中的关键挑战，为广告平台的竞价和预算分配优化提供了更准确的长期价值预测。

Abstract: Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.

</details>


### [386] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 提出PASs（路径激活子空间）方法解决多模态大语言模型持续指令调优中的专家共漂移问题，通过路径激活信号校准路由并稳定重要秩方向，提升准确性和抗遗忘能力


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的MoE方法在持续指令调优中，路由器和专家会共同漂移，导致早期输入-专家专业化逐渐偏离，造成专家责任模糊和遗忘加剧，需要解决这种"错位共漂移"现象

Method: 提出路径激活子空间（PASs）作为能力对齐的坐标系统，基于此开发PASs-based MoE-LoRA方法，包含PAS引导的重新加权（校准路由）和PAS感知的秩稳定化（选择性稳定重要秩方向）两个组件

Result: 在持续指令调优基准测试中，该方法在准确性和抗遗忘方面均优于传统持续学习基线和多种MoE-LoRA变体，且不增加额外参数

Conclusion: PASs方法有效解决了MoE-LoRA中的错位共漂移问题，通过路径激活信号校准路由和选择性稳定重要秩方向，实现了更好的持续学习性能

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [387] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的新方法，用于镰状细胞病的血液涂片图像诊断支持，通过特征选择和模型优化实现更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病的准确诊断需要可靠的支持系统，现有方法在泛化能力和可解释性方面存在不足，需要开发既能提高诊断准确性又能增强模型可解释性的方法。

Method: 对血液涂片图像进行预处理和分割，提取高质量特征；采用集成机器学习方法（随机森林和极端随机树）进行分类；设计特征重要性分析方法以降低复杂度；使用新数据集验证泛化能力。

Result: 随机森林和极端随机树集成模型获得F1分数90.71%和SDS分数93.33%，相比梯度提升分类器（F1 87.32%，SDS 89.51%）有显著提升，在新数据集上超越了现有最佳模型的泛化性能。

Conclusion: 提出的集成学习方法在镰状细胞病诊断支持中表现出优越性能，通过特征选择和可解释性分析提高了模型的实用性和泛化能力，为临床诊断提供了可靠支持。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [388] [Analysis of Long Range Dependency Understanding in State Space Models](https://arxiv.org/abs/2601.13048)
*Srividya Ravikumar,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.LG

TL;DR: 本文首次对应用于真实世界任务（源代码漏洞检测）的S4D模型进行系统性核可解释性研究，发现S4D的长程建模能力因架构不同而有显著差异，其核可表现为低通、带通或高通滤波器特性。


<details>
  <summary>Details</summary>
Motivation: 尽管状态空间模型（SSMs）在长序列基准测试中表现出色，但现有研究多关注预测准确性而非可解释性。本文旨在填补这一空白，首次对应用于真实世界任务的S4D模型进行系统性核可解释性研究。

Method: 通过时域和频域分析S4D核，研究不同模型架构下S4D的长程建模能力变化。具体分析S4D核在不同架构下的滤波器特性（低通、带通、高通）。

Result: 研究发现S4D的长程建模能力在不同模型架构下存在显著差异，直接影响模型性能。S4D核可表现为低通、带通或高通滤波器特性，具体取决于架构设计。

Conclusion: 本文的分析结果为未来设计更好的基于S4D的模型提供了指导，强调了架构设计对S4D长程建模能力的重要影响。

Abstract: Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.

</details>


### [389] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

TL;DR: 本文提出了一种基于边缘计算和TinyML的智能精准灌溉系统，专为资源受限的小规模农场设计，无需云依赖即可实现高效节水。


<details>
  <summary>Details</summary>
Motivation: 小规模农业社区面临水资源短缺、气候模式不稳定以及缺乏先进、经济实惠的农业技术等问题。为解决这些挑战，需要开发离线可用的智能灌溉系统。

Method: 采用四层边缘优先IoT架构，集成低成本硬件（ESP32微控制器作为边缘推理节点，Raspberry Pi作为本地边缘服务器），使用多种环境传感器，并通过比较分析选择梯度提升模型，将其转换为轻量级TinyML推理引擎部署在ESP32上，采用基于MQTT的局域网通信协议。

Result: 梯度提升模型表现最佳（R²=0.9973，MAPE=0.99%），优于随机森林模型（R²=0.9916，MAPE=1.81%）。系统在受控环境中验证显示显著减少用水量，TinyML部署后预测精度保持MAPE<1%，系统具备低功耗和离线功能。

Conclusion: 该系统为资源受限的农村环境提供了实用、经济高效的解决方案，通过设备端人工智能缩小农业技术鸿沟，提高水资源利用效率，具备可持续、可扩展的部署潜力。

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [390] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个AI研究导师系统，通过分阶段指导、文献搜索、方法论检查等功能，帮助本科生从想法到论文写作，在多个评估中优于GPT-5和Claude Sonnet 4.5。


<details>
  <summary>Details</summary>
Motivation: 许多学生缺乏专家研究指导，需要AI导师帮助本科生完成从研究想法到论文写作的全过程。

Method: 构建METIS系统，包含工具增强、阶段感知的助手功能，具有文献搜索、指导指南、方法论检查和记忆功能。通过LLM作为评判者的成对偏好、学生角色评分标准、多轮辅导和证据/合规性检查进行评估。

Result: 在90个单轮提示中，LLM评判者更偏好METIS而不是Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分在清晰度/可操作性/约束适应性方面更高。在多轮会话中，METIS的最终质量略高于GPT-5。优势集中在文档基础阶段。

Conclusion: METIS作为AI研究导师在帮助学生完成论文写作方面表现优于现有模型，特别是在文档基础阶段，但存在工具路由过早、基础不够深入和阶段分类错误等失败模式。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [391] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出递归元蒸馏的公理化算子理论框架，证明在温和条件下递归蒸馏会收敛到基教师分布的唯一固定点，为理解迭代蒸馏的稳定性和偏差-方差行为提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前概率域知识蒸馏研究已建立单阶段设置下的公理框架，但递归或多代蒸馏的数学行为理解不足，先前方法主要依赖经验启发式。需要理论框架来理解递归蒸馏何时数学上适定且收敛，而非误差累积。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，并明确锚定到基教师。定义有效元教师构建的结构公理，证明存在满足这些公理的非平凡算子族，不依赖特定算法或损失函数。

Result: 在温和可实现性和凸性假设下，证明锚定递归蒸馏在KL散度上诱导收缩，产生向基教师分布的几何收敛和唯一全局吸引固定点。框架独立于模型架构、优化细节或具体算子实例化。

Conclusion: 该工作是基础性而非算法性的贡献，框架刻画了递归蒸馏何时数学上适定且收敛，为理解容量约束下迭代和多教师蒸馏的稳定性、偏差-方差行为和失效模式提供理论基础。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [392] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个针对音频-视觉大语言模型（AV-LLMs）的token剪枝框架，通过两阶段剪枝策略减少计算量40%以上，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然token剪枝在标准LLMs和视觉语言模型中已有探索，但在AV-LLMs中尚未得到关注。多模态整合显著增加了token需求，需要专门的剪枝方法来解决计算效率问题。

Method: 基于注意力权重识别不同阶段的重要token，采用两阶段剪枝策略：1）中间层全局剪枝去除影响力较小的token；2）后续层精细剪枝考虑对下一个token生成的影响。方法完全兼容FlashAttention等高效注意力机制。

Result: 在两个代表性AV-LLMs上，FastAV将FLOPs减少超过40%，同时保持甚至提升了模型性能。

Conclusion: FastAV为AV-LLMs提供了首个有效的token剪枝框架，显著降低计算成本而不损害性能，解决了多模态模型的计算效率挑战。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [393] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 该论文提出从动力学视角统一理解深度学习训练稳定性，将其分为优化、环境/数据、参数和学习信号四个维度，通过受控扰动审计识别训练稳定性规律，发现最终性能与训练稳定性经常解耦、受控随机性可缓冲学习动力学、低维元状态偏差可预测性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得了显著的实证性能，但训练过程本身的稳定性仍然理解不足。训练作为高维动力系统，对优化、数据、参数或学习信号的小扰动可能引发突然且不可逆的崩溃，损害可重复性和可扩展性。需要建立统一的动力学视角来系统研究训练稳定性。

Method: 提出统一的动力学视角，将训练稳定性组织为四个相互作用的维度：优化稳定性、环境/数据稳定性、参数稳定性和学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动力学对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中识别出三个重复出现的规律：1）最终高性能经常与训练稳定性解耦；2）受控随机性在不同范式中一致地缓冲学习动力学；3）低维潜在元状态的偏差系统性地先于可观察的性能崩溃。

Conclusion: 训练稳定性是学习系统可测量和可比较的动力学属性，为超越最终性能结果研究学习动力学提供了描述性基础。这一视角有助于理解训练过程的稳定性机制，提高深度学习系统的可重复性和可扩展性。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [394] [NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness](https://arxiv.org/abs/2601.13162)
*Ali Shafiee Sarvestani,Jason Schmidt,Arman Roohi*

Main category: cs.LG

TL;DR: Neuro-symbolic框架DesignII通过符号规则监督增强神经网络对抗鲁棒性和可解释性，在GTSRB数据集上相比标准对抗训练获得约3倍的鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络存在对抗脆弱性和缺乏可解释性的关键限制，特别是在自动驾驶等安全敏感场景中，需要同时提升鲁棒性和可解释性。

Method: 提出DesignII神经符号框架，将领域知识编码为形状、颜色等外观属性的逻辑约束，通过语义和符号逻辑损失在训练中强制执行这些约束。

Result: 在GTSRB数据集上，FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic模型相比对应对抗训练基线分别提升18.1%和17.35%的对抗精度，相比干净训练基线获得约3倍的鲁棒性增益，且不降低干净样本准确率。使用ResNet18骨干网络训练10个epoch即可达到或超过需要重型架构和大量数据增强的transformer防御方法的效果。

Conclusion: 符号推理为构建鲁棒且可解释的AI提供了有效路径，神经符号方法在提升对抗鲁棒性的同时保持了模型的可解释性。

Abstract: Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.

</details>


### [395] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: LAViG-FLOW：一种用于地下多相流体流动建模的潜在自回归视频生成扩散框架，通过学习饱和度和压力场的耦合演化，实现比传统数值求解器快几个数量级的预测。


<details>
  <summary>Details</summary>
Motivation: 地下多相流体流动建模对地质CO2封存和地热生产等应用至关重要，但高保真模拟器在需要大量前向运行进行反演和量化不确定性时成本过高。

Method: 提出LAViG-FLOW框架：1）使用专用2D自编码器压缩每个状态变量；2）使用视频扩散变换器（VDiT）建模时间上的耦合分布；3）先在给定时间范围内训练学习耦合关系，然后自回归微调以在观测时间窗口外进行外推。

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度和压力场在时间上保持一致性，运行速度比传统数值求解器快几个数量级。

Conclusion: LAViG-FLOW为地下多相流体流动建模提供了一种高效替代方案，显著降低了计算成本，适用于需要大量模拟的应用场景。

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [396] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该论文系统评估了LLM推理范式（直接生成、CoT、多智能体系统），分析了成本-准确性权衡，并提出了新的开放式基准MIMeBench来评估语义能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为推理系统部署时，不同推理范式（如CoT和多智能体系统）的相对有效性、成本-准确性权衡以及语义能力评估缺乏系统性研究。

Method: 1）对多种推理范式进行统一评估；2）通过角色隔离分析探究多智能体系统的能力需求；3）分析成本-准确性权衡；4）提出新的开放式基准MIMeBench评估语义抽象和对比辨别能力。

Result: 研究发现：1）增加结构复杂性并不总是提高推理性能，其效果高度依赖于推理范式的特性和适用性；2）某些多智能体工作流程在成本和准确性之间取得了良好平衡，而另一些则成本过高但收益有限。

Conclusion: 需要根据具体任务特性选择合适的推理范式，结构复杂性本身不是性能保证。MIMeBench为语义能力评估提供了新维度，超越了传统封闭式基准的局限性。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [397] [Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks](https://arxiv.org/abs/2601.13244)
*Prateek Munjal,Clement Christophe,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.LG

TL;DR: 指令微调可能不增强推理能力，而是诱导表面模式匹配，其性能优势不稳定且对分布变化脆弱


<details>
  <summary>Details</summary>
Motivation: 研究指令微调是否真正提升LLM的推理能力，还是仅仅诱导表面模式匹配，因为当前标准实践的效果机制不明确

Method: 在标准数学基准测试、结构扰动变体和领域转移任务上评估基础模型和指令微调模型，分析它们在零-shot CoT、少-shot和不同评估设置下的表现

Result: 1) 在GSM8K零-shot CoT设置中，基础模型持续优于指令微调变体（Llama3-70B下降高达32.67%）；2) 指令微调模型仅在提供少-shot示例时匹配或超越此性能；3) 在MedCalc领域特定基准测试中，基础模型优于指令微调变体；4) 指令微调模型在扰动数据集上表现急剧下降

Conclusion: 指令微调的性能优势不稳定且依赖于评估设置，模型可能依赖特定提示模式而非内在推理能力，且对分布变化脆弱，表明当前指令微调可能未真正增强推理能力

Abstract: Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.

</details>


### [398] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: RLVR微调使LLM在决策任务中过度自信，而SFT校准更好但性能提升较小。作者提出校准感知的RL方法，在保持RLVR准确性的同时显著降低过度自信。


<details>
  <summary>Details</summary>
Motivation: LLM在决策任务中不仅需要准确性，还需要可靠的置信度估计。当前广泛使用的RLVR微调范式虽然提升任务性能，但会导致模型过度自信，影响下游系统的信任决策。

Method: 系统研究SFT和RLVR两种微调范式的校准特性，诊断RLVR失败原因（决策token作为提取步骤不携带置信信息），提出校准感知的强化学习公式，直接调整决策token概率。

Result: RLVR产生极度过度自信的模型，SFT校准更好但性能提升较小。提出的校准感知RL方法在保持RLVR准确性水平的同时，将ECE分数降低高达9个点，显著缓解过度自信问题。

Conclusion: RLVR虽然提升任务性能但损害校准，而SFT校准更好但性能有限。通过理解决策token在推理轨迹中的作用，可以设计校准感知的RL方法，在保持性能的同时改善置信度估计。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [399] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

TL;DR: 论文提出CooperBench基准测试，评估AI代理在协作编程中的协调能力，发现当前代理存在"协调诅咒"——协作时成功率比单独执行低30%，与人类团队表现相反。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在复杂工作中越来越多地协作，它们需要发展协调能力才能成为有效的团队成员。作者假设当前代理缺乏这些能力，需要建立评估基准来验证这一假设。

Method: 引入CooperBench基准测试，包含600多个协作编程任务，覆盖4种编程语言的12个库。每个任务分配两个代理不同的功能特性，这些特性可以独立实现但缺乏协调可能冲突。任务基于真实开源仓库和专家编写的测试。

Result: 观察到"协调诅咒"现象：代理协作时的平均成功率比单独执行两个任务低30%。这与人类团队通常因增加队友而提高生产力的模式相反。分析发现三个关键问题：通信渠道堵塞、代理偏离承诺、代理对他人计划和通信有错误预期。

Conclusion: 研究提出了新颖的协作编程基准测试，呼吁从追求个体代理能力转向发展社交智能。通过大规模模拟观察到罕见但有趣的涌现协调行为，如角色分工、资源分配和谈判。

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [400] [Verifying Local Robustness of Pruned Safety-Critical Networks](https://arxiv.org/abs/2601.13303)
*Minh Le,Phuong Cao*

Main category: cs.LG

TL;DR: 研究剪枝对神经网络形式化验证的影响，发现不同数据集的最佳剪枝比例不同：MNIST上轻度剪枝（40%）提升验证性，而NASA JPL数据集上重度剪枝（70%-90%）效果更好。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在安全关键应用中需要形式化验证，但大规模模型的验证计算成本高昂。研究剪枝如何影响形式化验证效果，以降低验证成本并提高可靠性。

Method: 使用最先进的α,β-CROWN验证器，在不同剪枝比例下评估ResNet4模型，分别在MNIST和NASA JPL火星霜冻识别数据集上进行实验。

Result: 发现非线性关系：MNIST上40%轻度剪枝提升验证性，NASA JPL数据集上70%-90%重度剪枝效果更好，使模型在证明的L∞鲁棒性上超越未剪枝基线。

Conclusion: 减少连接性简化了形式化求解器的搜索空间，最佳剪枝比例因数据集而异。这为在高风险环境中部署高效且经过形式化验证的DNN提供了关键见解。

Abstract: Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.

</details>


### [401] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 提出基于谱嵌入的领域不变表示学习方法，通过将平滑传输计划解释为二分图邻接矩阵，实现鲁棒的领域对齐


<details>
  <summary>Details</summary>
Motivation: 训练和推理数据之间的分布偏移是机器学习中的核心挑战，传统基于最优传输的领域自适应方法对正则化策略和超参数敏感，可能导致有偏的领域对齐

Method: 将平滑传输计划解释为连接源域和目标域的二分图邻接矩阵，通过谱嵌入推导领域不变的样本表示

Result: 在音乐流派识别、音乐-语音区分以及电缆缺陷检测等多个声学和时域反射诊断任务上取得了整体强劲的性能

Conclusion: 提出的谱嵌入方法为领域自适应提供了鲁棒的解决方案，能够有效处理分布偏移问题

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [402] [CausationEntropy: Pythonic Optimal Causation Entropy](https://arxiv.org/abs/2601.13365)
*Kevin Slote,Jeremie Fish,Erik Bollt*

Main category: cs.LG

TL;DR: CausationEntropy v1.1是一个Python因果网络建模工具包，实现了oCSE算法及其优化扩展，包含多种熵估计器和数据生成功能。


<details>
  <summary>Details</summary>
Motivation: 为复杂动力系统中的因果发现提供一个基准工具，实现oCSE算法及其优化扩展，解决直接与间接因果路径的区分问题。

Method: 基于最优因果熵（oCSE）理论，实现多种熵估计器（高斯、kNN、几何kNN、核密度、泊松），提供合成数据生成和可视化工具。

Result: 发布了CausationEntropy v1.1版本，包含新的数据生成器、绘图工具和多种信息论因果网络发现算法，代码开源且易于安装使用。

Conclusion: 该工具包将成为复杂动力系统因果发现的基准工具，采用模块化设计支持未来扩展，完全开源且文档完善。

Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.

</details>


### [403] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: RTCE基准测试揭示LLM在双向代码执行推理中缺乏一致性，现有方法无法解决这一根本缺陷


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码基准测试中表现良好，但在双向代码执行中缺乏一致性推理能力，现有基准无法评估这种一致性，需要新的评估框架

Method: 提出RoundTripCodeEval(RTCE)基准，包含四个代码执行推理任务，通过无执行、精确匹配的方式评估双向一致性，测试了零样本提示、监督微调和自反思机制

Result: 所有方法都只能带来有限的改进，无法解决根本差距，表明当前LLM缺乏真正的双向一致性，无法实现可信的代码推理

Conclusion: RTCE揭示了LLM在双向代码推理中的内部一致性缺陷，这是现有基准无法捕捉的新见解，对可信代码推理具有重要意义

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [404] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: TrustEnergy：一个用于准确可靠用户级能耗预测的统一框架，结合层次时空表示和顺序保形分位数回归，在预测精度和不确定性量化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有能耗预测方法存在两个主要问题：1）忽视家庭间的空间相关性或无法扩展到个体化预测；2）未能充分探索不确定性量化，而能耗的动态性和不确定性（如极端天气事件）使得可靠预测需要不确定性量化。

Method: TrustEnergy包含两个关键技术组件：1）层次时空表示模块，使用新型记忆增强时空图神经网络高效捕捉宏观和微观能耗模式；2）顺序保形分位数回归模块，动态调整不确定性边界，确保随时间推移的有效预测区间，无需对底层数据分布做强假设。

Result: 与佛罗里达州电力供应商合作实施和评估TrustEnergy，结果显示：相比最先进的基线方法，预测精度提高5.4%，不确定性量化改进5.7%。

Conclusion: TrustEnergy框架能够实现准确可靠的用户级能耗预测，有效解决了现有方法在空间相关性建模和不确定性量化方面的不足，为电网管理、基础设施规划和灾害响应等实际应用提供了更可靠的预测工具。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [405] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种可学习的小波变换长短期Transformer模型，通过端到端训练的多尺度分解和面向收益的决策学习，显著提升日内交易的盈利能力和风险调整收益。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：噪声大、非平稳性强、相关资产间存在强烈的横截面依赖性。传统方法难以有效处理这些复杂特性。

Method: 提出WaveLSFormer模型，包含三个核心组件：1）可学习小波前端，通过端到端训练的滤波器组生成低/高频分量，辅以频谱正则化确保频率带稳定分离；2）低频引导高频注入模块，融合多尺度信息；3）固定风险预算下的投资组合缩放，直接优化交易目标和风险感知正则化。

Result: 在5年小时级数据、6个行业组、10个随机种子的广泛实验中，WaveLSFormer显著优于MLP、LSTM和Transformer基线模型。平均累计策略收益0.607±0.045，夏普比率2.157±0.166，在盈利能力和风险调整收益方面均有大幅提升。

Conclusion: WaveLSFormer通过可学习的小波分解和Transformer架构的有机结合，有效解决了金融时间序列的噪声、非平稳性和横截面依赖问题，为日内交易策略学习提供了强大的端到端解决方案。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [406] [BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions](https://arxiv.org/abs/2601.13445)
*Ashish S. Nair,Sandipp Krishnan Ravi,Itzel Salgado,Changjie Sun,Sayan Ghosh,Liping Wang*

Main category: cs.LG

TL;DR: 提出基于DeepSDF的涡轮叶片领域特定隐式生成框架，实现性能感知的可制造设计生成


<details>
  <summary>Details</summary>
Motivation: 解决涡轮叶片设计中性能感知建模和可制造设计生成的关键空白，超越传统2D引导或无约束3D流程

Method: 使用连续符号距离函数(SDF)表示，建立可解释的近高斯潜在空间，通过神经网络将工程描述符映射到潜在代码

Result: 实现高重建保真度（表面距离误差在最大叶片尺寸的1%内），对未见设计具有鲁棒泛化能力

Conclusion: 该框架为数据驱动的涡轮叶片建模和概念生成提供了实用且可解释的解决方案，整合了约束、目标和性能指标

Abstract: Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.

</details>


### [407] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 在联邦学习中，针对时间概念漂移问题，提出客户端经验回放方法，通过维护少量历史样本缓冲区有效防止灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时间概念漂移（客户端数据分布随时间变化）下表现不佳，标准FedAvg在季节性漂移场景下会出现灾难性遗忘问题

Method: 提出客户端经验回放方法：每个客户端维护一个小的历史样本缓冲区，在本地训练时将过去样本与当前数据混合使用，无需改变服务器聚合机制

Result: 在Fashion-MNIST数据集上，标准FedAvg准确率从74%降至28%；使用每类50个样本的缓冲区后，性能恢复到78-82%，有效防止遗忘

Conclusion: 客户端经验回放是一种简单有效的解决方案，消融研究显示存在明确的内存-准确率权衡关系，缓冲区大小增加会提升性能

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [408] [Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics](https://arxiv.org/abs/2601.13463)
*Brandon B. Le,D. Keller*

Main category: cs.LG

TL;DR: 提出一个基于数据内在特性的诊断框架，通过定量量子限定器指导经典与量子深度神经网络的选择，应用于强子物理问题。


<details>
  <summary>Details</summary>
Motivation: 随着量子机器学习架构的成熟，核心挑战不再是构建这些架构，而是识别量子方法相对于经典方法具有实际优势的领域。特别是在数据驱动的强子物理问题中，需要系统的方法来选择最合适的模型。

Method: 开发一个诊断框架，以定量量子限定器为中心，基于数据的固有特性（如复杂性、噪声和维度）来指导模型选择。通过受控的分类和回归研究，分析相对模型性能如何遵循这些特性的系统趋势，并将这些趋势提炼为预测性标准。

Result: 研究表明，经典与量子模型的相对性能遵循复杂性、噪声和维度的系统趋势，这些趋势可以提炼为预测性标准。在深度虚康普顿散射中提取康普顿形状因子的应用中，量子限定器成功识别了量子模型有利的运动学区域。

Conclusion: 该研究建立了一个原则性框架，用于在精密强子物理中部署量子机器学习工具，通过基于数据特性的诊断方法，系统指导量子与经典模型的选择，识别量子优势的实际应用场景。

Abstract: As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.

</details>


### [409] [A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model](https://arxiv.org/abs/2601.13476)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: PRAIM：基于大语言模型和检索增强记忆的概率变分插补框架，用于处理电动汽车充电数据中的缺失值问题，显著提升插补精度并改善下游预测性能。


<details>
  <summary>Details</summary>
Motivation: 电动汽车基础设施中数据驱动应用的可靠性依赖于完整、高质量的充电数据，但现实世界EV数据集常存在缺失记录，现有插补方法无法处理充电数据的复杂多模态特性，且通常采用"一站一模型"的局限范式，忽略了站间相关性。

Method: 开发了PRAIM框架：使用预训练语言模型编码异构数据（时间序列需求、日历特征、地理空间上下文）为统一语义表示，通过检索增强记忆从整个充电网络中检索相关示例，采用变分神经架构构建统一的插补模型。

Result: 在四个公共数据集上的实验表明，PRAIM在插补精度和保持原始数据统计分布方面显著优于现有基线方法，并大幅提升了下游预测性能。

Conclusion: PRAIM通过结合大语言模型和检索增强记忆，有效解决了电动汽车充电数据中的缺失值问题，为数据驱动的EV基础设施应用提供了更可靠的解决方案。

Abstract: The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.

</details>


### [410] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG：基于混合专家NCDE的框架，用于不规则和连续时间序列生成，在临床监测等应用中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法假设规则采样和固定输出分辨率，与现实世界中不规则采样和稀疏观测的数据不匹配，特别是在临床监测等应用中需要支持连续高分辨率时间序列的下游任务

Method: 提出MN-TSG框架，结合混合专家(MoE)的神经控制微分方程(NCDE)，采用动态参数化专家函数和解耦设计，并利用现有TSG模型学习专家混合与生成时间序列的联合分布

Result: 在10个公共和合成数据集上的实验表明，MN-TSG在不规则到规则和不规则到连续生成任务上均优于强基线方法

Conclusion: MN-TSG通过MoE-NCDE架构和与现有TSG模型的集成，有效解决了不规则和连续时间序列生成问题，为临床监测等实际应用提供了有力工具

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [411] [Patterning: The Dual of Interpretability](https://arxiv.org/abs/2601.13548)
*George Wang,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出"模式化"作为机制可解释性的对偶问题：给定期望的泛化形式，确定产生它的训练数据。通过可逆线性响应关系，可以设计数据干预来引导模型达到目标内部配置。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性关注从神经网络内部结构理解其泛化能力，但缺乏从期望泛化形式反向设计训练数据的方法。本文旨在建立这种对偶关系，实现"写入"内部结构的能力。

Method: 基于敏感性概念，测量可观测量后验期望值对数据分布微小变化的响应。通过逆线性响应关系，推导出引导模型达到目标内部配置的数据干预方法。

Result: 在小语言模型中，沿主敏感性方向重新加权训练数据可以加速或延迟结构形成（如归纳电路）。在括号平衡任务中，模式化可以通过针对每个解决方案的局部学习系数来选择模型学习的算法。

Conclusion: 建立了用于读取内部结构的数学框架可以逆转为写入内部结构，为可控模型训练提供了理论基础，实现了机制可解释性的对偶问题。

Abstract: Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.

</details>


### [412] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE通过将专家视为共享量化基质的几何重定向，而非独立权重矩阵，实现了专家数量的亚线性内存增长，在256个专家时达到150倍内存压缩，使64个专家能在4GB设备上运行。


<details>
  <summary>Details</summary>
Motivation: 现有MoE方法中，N个独立专家权重矩阵需要O(N·d²)内存，超出边缘设备内存预算。现有压缩方法（量化、剪枝、低秩分解）只能减少常数因子，无法解决线性缩放瓶颈。

Method: 将专家视为共享三元原型的几何重定向，而非独立权重矩阵。通过对共享量化基质应用学习到的旋转，每个专家获得O(d² + N·d log d)内存，实现专家数量的亚线性内存增长。训练这些旋转与量化结合可减少激活异常值并稳定极端低比特训练。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现150倍内存压缩，精度损失可忽略。相比标准MoE的8个专家，该方法使64个专家能在4GB设备上运行。

Conclusion: 几何参数化打破了MoE的线性内存缩放瓶颈，通过将专家视为共享容量的不同视角而非冗余存储，实现了专家数量的亚线性内存增长，使大规模MoE模型能够在资源受限设备上部署。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [413] [Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework](https://arxiv.org/abs/2601.13564)
*Yanheng Li,Zhichen Pu,Lijiang Yang,Zehao Zhou,Yi Qin Gao*

Main category: cs.LG

TL;DR: LUMOS是一个数据与物理双驱动的荧光分子逆设计框架，通过结合生成器与预测器、神经网络与快速TD-DFT计算，实现多目标约束下的高效分子设计。


<details>
  <summary>Details</summary>
Motivation: 传统荧光分子设计方法面临化学空间巨大、多目标约束复杂、机器学习预测可靠性不足、量子化学计算成本高昂等挑战，需要更高效的逆设计框架。

Method: 1) 在共享潜在表示中耦合生成器和预测器；2) 结合神经网络与快速TD-DFT构建互补预测器套件；3) 采用属性引导扩散模型与多目标进化算法集成。

Result: 在综合基准测试中，LUMOS在荧光属性预测的准确性、泛化性和物理合理性方面优于基线模型，在多目标分子优化中表现优异，TD-DFT和MD模拟验证了其生成符合目标规格的有效荧光团。

Conclusion: LUMOS建立了一个数据与物理双驱动的通用荧光团逆设计框架，能够高效探索化学空间并在多目标约束下设计定制荧光分子。

Abstract: Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.

</details>


### [414] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 语言模型可以通过辩论、自举和内部一致性最大化等方法在没有外部监督的情况下自我提升准确性，这些方法都是"一致性优化"的特殊形式，即寻找最可压缩和联合可预测的上下文到行为的映射。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明语言模型可以通过无监督方法自我提升性能，甚至达到有监督微调的效果，但这些方法为何有效缺乏理论解释。本文旨在从理论上解释这些无监督自我提升方法的工作原理。

Method: 提出"一致性优化"理论框架，证明辩论、自举和内部一致性最大化等方法都是一致性优化的特例。理论分析表明一致性优化等价于描述长度正则化，并证明在预训练模型导出的正则化方案中，一致性优化在半监督学习场景下是最优的。

Result: 理论分析表明一致性优化是描述长度正则化的等价形式，在预训练模型导出的正则化方案中具有最优性。初步实验支持理论预测，解释了无监督自我提升方法为何有效，并能预测其成功或失败的条件。

Conclusion: 无监督自我提升方法（如辩论、自举和内部一致性最大化）之所以有效，是因为它们都是一致性优化的特例。一致性优化作为描述长度正则化的一种形式，在预训练模型背景下具有理论最优性，这为理解语言模型自我提升机制提供了理论框架。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [415] [DRGW: Learning Disentangled Representations for Robust Graph Watermarking](https://arxiv.org/abs/2601.13569)
*Jiasen Li,Yanwei Liu,Zhuoyi Shang,Xiaoyan Gu,Weiping Wang*

Main category: cs.LG

TL;DR: DRGW是首个基于解耦表示学习的图水印框架，通过分离结构表示与水印载体，解决了现有方法在透明度和鲁棒性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图水印方法主要基于图结构或纠缠的图表示，由于图表示中的信息耦合以及连续数值表示到图结构的不可控离散化，导致水印的透明度和鲁棒性受损。

Method: 1) 设计对抗训练的编码器学习对扰动的结构不变表示，并导出统计独立的水印载体；2) 设计图感知的可逆神经网络提供无损的水印嵌入和提取通道；3) 开发结构感知编辑器将潜在修改转化为离散图编辑。

Result: 在多个基准数据集上的实验证明了DRGW的优越有效性。

Conclusion: DRGW通过解耦表示学习解决了图水印中的透明度和鲁棒性问题，为图数据知识产权保护提供了有效框架。

Abstract: Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.

</details>


### [416] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

TL;DR: GeoDynamics是一个几何状态空间神经网络，直接在对称正定流形上追踪脑状态轨迹，用于分析功能连接性动态变化，在神经科学和动作识别任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间模型通常将大脑视为松散连接的区域或施加过于简化的网络先验，缺乏真正的整体自组织动态系统视角。大脑功能连接性矩阵位于黎曼流形而非欧几里得空间，需要几何感知的方法来捕捉其动态轨迹。

Method: 提出GeoDynamics模型，将每个连接性矩阵嵌入到流形感知的循环框架中，直接在高维对称正定流形上学习平滑且尊重几何的转换，揭示任务驱动的状态变化和疾病早期标志。

Result: 模型成功揭示了任务驱动的脑状态变化，以及阿尔茨海默病、帕金森病和自闭症的早期标志。在人类动作识别基准测试（UTKinect、Florence、HDM05）上也验证了其可扩展性和鲁棒性。

Conclusion: GeoDynamics提供了一个在流形上直接建模动态系统的几何感知框架，不仅适用于神经科学中的脑状态分析，还能扩展到其他复杂时空动态建模领域，展示了跨领域应用的潜力。

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [417] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: 提出RAM框架，针对RL训练后的智能体模型进行优化合并，解决传统SFT合并方法在RL智能体上效果不佳的问题


<details>
  <summary>Details</summary>
Motivation: 模型合并是整合多个RL训练智能体的实用机制，但现有合并方法针对监督微调设计，不适用于RL训练后的智能体模型。RL产生的任务向量稀疏且异质，与SFT假设的密集可比向量不匹配，导致关键任务特定行为被稀释

Method: 提出RAM框架，显式分离共享和任务特定的参数更新：对共享组件进行平均，同时选择性地保留和重新缩放独特组件，以抵消参数更新稀释

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越了合并基线，还能解锁智能体间的协同潜力，实现优于领域内专业智能体的性能

Conclusion: RAM是针对RL训练智能体模型的有效合并框架，解决了任务向量不匹配问题，能够更好地保留任务特定能力并实现协同效应

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [418] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 提出FG-OrIU框架，通过特征和梯度的双重正交约束实现深度遗忘，解决增量遗忘中的表面遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘方法主要在参数层面抑制或混淆知识，缺乏对特征和梯度层面的显式约束，导致"表面遗忘"——残留信息仍可恢复。这种不完全遗忘存在安全风险，并破坏保留平衡，特别是在增量遗忘场景中。

Method: 提出FG-OrIU框架：1) 使用SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；2) 实施双重约束：特征正交投影（遗忘类和保留类）和梯度正交投影（防止遗忘知识重新引入）；3) 动态子空间适应：合并新遗忘子空间并收缩保留子空间，保持序列遗忘任务中的稳定平衡。

Result: 大量实验证明了该方法的有效性，能够实现深度遗忘（遗忘效果不可逆）。

Conclusion: FG-OrIU通过统一特征和梯度层面的正交约束，首次实现了深度遗忘，解决了增量遗忘中的表面遗忘问题，确保了遗忘的不可逆性和保留平衡的稳定性。

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [419] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: Neural Organ Transplantation (NOT) 是一种模块化适应框架，将预训练transformer层作为可重用检查点进行跨模型移植，显著优于现有适应方法


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。NOT旨在实现隐私保护的专家知识共享，通过检查点分发实现高效模块化迁移

Method: 从预训练模型中提取连续层子集（"供体器官"），在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据

Result: 在124M到20B参数的三种解码器架构（GPT-2、TinyLlama、GPT-OSS）上，NOT显著优于现有适应方法，困惑度比LoRA提高一个数量级，训练速度更快。早期插入位置效果最佳，跨领域迁移在十亿参数规模显示出意外的正则化效益

Conclusion: transformer中间层支持解码器架构的高效模块化迁移，实现隐私保护的专家知识共享。该方法目前仅限于解码器模型，编码器架构效果有限

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [420] [Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments](https://arxiv.org/abs/2601.13592)
*Hao Jing,Sa Xiao,Haoyu Li,Huadong Xiao,Wei Xue*

Main category: cs.LG

TL;DR: 使用残差卷积神经网络替代传统辐射传输模型，在CMA全球业务系统中实现8倍加速，同时保持预报精度


<details>
  <summary>Details</summary>
Motivation: 辐射过程是数值模式中最耗时的物理过程，需要提高计算效率。研究重点关注混合预报框架中的两个关键瓶颈：耦合兼容性和长期积分稳定性

Method: 采用残差卷积神经网络近似RRTMG辐射传输模型，使用离线训练和在线耦合方法。通过模型模拟生成包含所有大气柱的全面数据集，采用经验回放增强数据稳定性，并基于物理意义施加额外输出约束。使用基于LibTorch的耦合方法进行实时业务计算

Result: 混合模型能够按要求进行10天积分预报。两个月的业务再预报实验表明，机器学习模拟器达到与传统物理方案相当的精度，同时计算速度提升约8倍

Conclusion: 成功开发了适用于业务系统的机器学习辐射参数化方案，在保持预报精度的同时显著提升计算效率，解决了混合预报框架中的耦合兼容性和长期稳定性问题

Abstract: Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.

</details>


### [421] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精修"两阶段解决块扩散语言模型的不可逆性和短视问题，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型结合了自回归和扩散模型的优势，但其严格的单向块依赖导致不可逆性，并牺牲了扩散模型的全局规划能力。需要解决这些限制来提升性能。

Method: 提出Diffusion in Diffusion框架：1) 先用小块进行块扩散生成快速草稿；2) 再用具有更大双向感受野的全局双向扩散精修草稿；3) 使用快照置信度重掩码识别需要修改的关键token；4) 应用混合尺度训练扩展块扩散模型的全局能力

Result: 在OpenWebText数据集上为离散扩散模型设定了新基准：仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，通过草稿-精修两阶段策略显著提升了离散扩散模型的性能，为扩散语言模型的发展提供了新方向

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [422] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA：一种基于费舍尔信息的参数级聚合方法，通过参数特定的权重替换客户端级标量权重，改善非IID数据下的联邦学习性能


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习方法（如FedAvg）对所有参数使用相同的标量权重，在非IID数据下会导致客户端更新严重错位，引起客户端漂移并降低全局模型性能

Method: 提出费舍尔信息参数级聚合（FIPA），使用费舍尔信息矩阵（FIM）权重替换客户端级标量权重，实现真正的参数级缩放，捕捉每个客户端数据对不同参数的独特影响。通过低秩近似保持通信和计算效率

Result: 在非线性函数回归、偏微分方程学习和图像分类任务中，FIPA始终优于基于平均的聚合方法，并能与最先进的客户端优化算法有效结合，进一步提高图像分类准确率

Conclusion: FIPA在异构数据分布下为联邦学习提供了显著优势，展示了参数级聚合的重要性

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [423] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 本文提出一种二次上界损失函数来改善快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升模型对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然能减少训练时间，但往往因对抗空间探索不足而导致鲁棒性下降，需要解决这一关键问题。

Method: 推导出对抗训练损失函数的二次上界，并将该上界与现有快速对抗训练方法结合使用，形成QUB损失函数。

Result: 将QUB损失应用于现有方法能显著提升鲁棒性，实验表明这种改进源于所得模型的损失景观变得更加平滑。

Conclusion: 提出的二次上界损失函数有效解决了快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升了模型的对抗鲁棒性。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [424] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: TimeART是一个融合强大工具分析能力和LLM推理能力的框架，作为全自动数据科学家处理时间序列问答任务，通过100k专家轨迹数据集和四阶段训练策略，在多个TSQA任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析主要依赖人工数据科学家，成本高昂且缺乏自动化。需要开发能够自动化处理时间序列问答的智能系统。

Method: 提出TimeART框架，融合现成工具的分析能力和LLM的推理能力；收集100k专家轨迹数据集TimeToolBench；设计四阶段训练策略，让模型从早期经验和自我反思中学习。

Result: 训练了一个8B参数的时间序列推理模型，在多个时间序列问答任务上取得了一致的state-of-the-art性能。

Conclusion: TimeART开创了代理式时间序列推理的新方法，通过融合工具能力和LLM推理，实现了全自动的时间序列数据分析。

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [425] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

TL;DR: 提出基于深度学习的脑组织形变模拟替代模型，使用随机教师强制策略减少自回归推理误差，实现实时神经外科手术模拟


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器难以满足神经外科手术模拟的实时性能要求，需要开发能够高效模拟脑组织非线性形变的替代模型

Method: 基于通用物理变换器构建深度学习替代模型，直接处理大规模网格数据，使用随机教师强制训练策略逐步减少真实输入比例，提高长期推演稳定性

Result: 模型能准确预测瞬态脑形变，支持15万节点网格，最大预测误差从6.7mm降至3.5mm，在消费级硬件上实现每步10ms以下的实时模拟

Conclusion: 该深度学习框架实现了快速、平滑、准确的脑组织生物力学模拟，为真实手术训练环境奠定了基础

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [426] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 研究比较了监督式机器学习与生成式AI在预测慢性鼻窦炎手术效果上的表现，发现MLP模型表现最佳，建议采用ML为主、GenAI为辅的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有广泛应用，但在临床数据的前瞻性决策支持方面仍有限。本研究旨在探索术前预测慢性鼻窦炎手术效果的方法，以识别可能手术效果不佳的患者，避免不必要的手术。

Method: 使用前瞻性收集的队列数据，比较监督式机器学习（逻辑回归、树集成、MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）在预测手术效果上的表现。所有模型接收相同的结构化输入，输出二元推荐及置信度。

Result: 最佳ML模型（MLP）达到85%准确率，具有更好的校准和决策曲线净效益。生成式AI在判别和校准方面表现较差。有趣的是，GenAI的解释与临床经验和MLP特征重要性一致，都强调基线SNOT-22、CT/内镜严重程度、息肉表型和心理/疼痛共病。

Conclusion: 支持ML优先、GenAI增强的工作流程：部署校准的ML进行手术候选者的初步筛选，使用GenAI作为解释器增强透明度和共享决策制定。提供了可重复的表格数据到GenAI评估协议和亚组分析。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [427] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种双分支架构，结合滑动窗口注意力和循环记忆机制，用于癫痫发作预测，在CHB-MIT数据集上达到99.46%的平均段级灵敏度


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战，因为发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在超长序列处理时面临局部时空模式捕获与长程上下文保持之间的权衡

Method: 提出EEG-Titans双分支架构：1）滑动窗口注意力分支捕获短期异常；2）循环记忆路径总结随时间推移的缓慢渐进趋势；3）采用分层上下文策略扩展高噪声受试者的感受野

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均段级灵敏度。分层上下文策略显著减少误报（极端异常值中降至0.00 FPR/h）而不牺牲灵敏度

Conclusion: 记忆增强的长上下文建模可以在临床约束评估下提供稳健的癫痫发作预测，表明神经记忆机制对于处理超长EEG序列和捕捉发作前动态的有效性

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [428] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear是一个基于线性模型的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在保持高性能的同时将计算复杂度从O(N²)降低到O(N)。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的预测器通常使用自注意力或其变体来捕捉多元相关性，但这会导致O(N²)的计算复杂度，其中N是变量数量。需要一种更高效的方法来处理多元时间序列预测。

Method: 提出两个核心组件：1) vecTrans模块，使用可学习向量建模多元相关性，将复杂度降至O(N)；2) WFMLoss目标函数，采用最终序列导向的流匹配损失，结合路径和水平加权策略来关注更可靠的路径和预测水平。

Result: 在22个基准测试和124个预测设置中达到最先进性能；vecTrans可无缝集成到Transformer预测器中，实现高达5倍的推理加速和一致的性能提升；WFMLoss作为即插即用目标函数，能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，在多元时间序列预测中实现了高效性和高性能的平衡，为实际应用提供了实用的解决方案。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [429] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow：一种潜在图扩散框架，通过线性复杂度实现高效图生成，相比现有方法实现1000倍加速


<details>
  <summary>Details</summary>
Motivation: 现有图扩散模型存在二次复杂度问题，且大部分计算资源浪费在稀疏图的空边上。需要一种能够实现近乎无损重建的潜在空间压缩方法，以克服图生成中的精确性要求挑战。

Method: 使用置换等变自编码器将节点映射到固定维嵌入，确保邻接矩阵可证明恢复；在潜在空间中训练基于流匹配的扩散变换器，实现线性复杂度的图生成。

Result: LG-Flow在保持竞争力的同时，实现了高达1000倍的加速，消除了二次复杂度瓶颈，支持更大、更具表达力的模型训练。

Conclusion: LG-Flow成功解决了图扩散模型的效率和精确性挑战，为大规模图生成提供了可行的解决方案，在性能和速度上都取得了显著改进。

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [430] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出基于注意力机制的ETA预测模型，利用历史道路速度模式，通过时空注意力机制有效捕捉交通流的时空因果关系，实现轻量级且准确的到达时间估计。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统的普及，准确可靠的ETA预测在导航、出行规划和交通管理中变得至关重要。然而，由于交通流的动态复杂性，传统方法要么简单结合实时和历史数据，要么依赖复杂的基于规则的计算，而现有深度学习模型计算成本高且未能有效捕捉关键的时空模式。

Method: 提出基于注意力机制的ETA模型，利用注意力机制处理历史道路速度模式。该模型通过注意力机制提取和利用沿路线每个时空点累积的时空特征，有效捕捉ETA预测中的时空因果关系，同时保持模型轻量化和可扩展。

Result: 在真实世界驾驶数据集上验证，该模型在ETA预测任务上优于现有基线方法，能够以任务感知的方式有效整合道路特征、实时交通条件和历史速度模式。

Conclusion: 提出的基于注意力机制的ETA模型能够有效捕捉交通流的时空模式，实现高效准确的到达时间预测，同时保持模型轻量化和可扩展，为智能交通系统提供了实用的解决方案。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [431] [ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks](https://arxiv.org/abs/2601.13824)
*Xiaohong Yang,Tong Xie,Minghui Liwang,Chikai Shang,Yang Lu,Zhenzhen Jiao,Liqun Fu,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: ELSA是一个用于边缘网络LLM微调的高效框架，通过结合分割学习和分层联邦学习，解决了设备资源限制、数据异构性和隐私风险问题。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上训练大语言模型面临三大挑战：设备资源限制、严重的数据异构性和高隐私风险。现有方法难以同时解决这些问题，需要新的框架来支持资源受限边缘网络上的分布式LLM微调。

Method: ELSA采用三个关键创新：1) 任务无关、行为感知的客户端聚类机制，使用公共探针输入和对称KL散度构建语义指纹，结合预测一致性信任评分和延迟感知边缘分配；2) 将LLM分成三部分分布在客户端和边缘服务器，云端仅用于适配器聚合；3) 基于计算草图结合语义子空间正交扰动的轻量通信方案。

Result: 在多种NLP任务上的实验表明，ELSA在适应性、收敛行为和鲁棒性方面持续优于最先进方法，为资源受限条件下的边缘侧LLM微调提供了可扩展且隐私感知的解决方案。

Conclusion: ELSA通过系统整合分割学习和分层联邦学习，成功解决了边缘LLM训练中的资源、异构性和隐私挑战，为资源受限边缘网络上的分布式LLM微调提供了有效的框架。

Abstract: Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.

</details>


### [432] [Optimal L2 Regularization in High-dimensional Continual Linear Regression](https://arxiv.org/abs/2601.13844)
*Gilad Karpel,Edward Moroshko,Ran Levinstein,Ron Meir,Daniel Soudry,Itay Evron*

Main category: cs.LG

TL;DR: 研究过参数化持续线性回归中的泛化问题，发现各向同性正则化能缓解标签噪声，最优正则化强度随任务数T按T/lnT比例增长。


<details>
  <summary>Details</summary>
Motivation: 研究持续学习中的泛化问题，特别是在过参数化线性回归设置下，探索正则化如何影响模型在序列任务上的表现，以及如何设计最优的正则化策略。

Method: 采用理论分析方法，在过参数化持续线性回归设置下推导期望泛化损失的闭式解，考虑任意线性教师模型，分析各向同性正则化对标签噪声的缓解作用。

Result: 证明了各向同性正则化在单教师和多教师设置下都能有效缓解标签噪声；发现最优固定正则化强度随任务数T按T/lnT比例增长；通过线性回归和神经网络实验验证了理论发现。

Conclusion: 该研究为持续学习系统设计提供了实用指导，首次在理论持续学习中证明了最优正则化强度与任务数的特定比例关系，展示了正则化在缓解标签噪声方面的重要作用。

Abstract: We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.

</details>


### [433] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: LLM驱动的多目标优化框架：通过自适应空间划分和局部推理，让LLM作为代理模型和候选采样器，收敛到真实Pareto前沿


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在推理能力上表现强大，但尚未成为多目标优化的现成选择。传统方法因能处理数值输入、平衡探索与利用、处理冲突目标而在基准测试中表现优异。本文旨在填补这一空白。

Method: 提出分层搜索策略：将输入空间自适应划分为不相交的超矩形区域，使用复合评分函数对区域排序，将LLM的生成过程限制在具有高潜力的子空间。LLM作为代理模型和候选采样器，只需进行局部推理而非全局推理。

Result: 在标准正则性假设下，算法生成的候选解在Hausdorff距离下收敛到真实Pareto集。实证表明，该方法始终优于基于LLM的全局多目标优化器，与标准进化和贝叶斯优化算法在合成和真实基准测试中表现相当。

Conclusion: 通过结构化分层搜索策略，成功将LLM应用于多目标优化问题，使其能够有效处理数值优化任务，填补了LLM在该领域的应用空白。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [434] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

TL;DR: 提出TractRLFusion，一种基于GPT的策略融合框架，通过数据驱动的融合策略整合多个强化学习策略，以更准确地重建白质纤维束并减少虚假连接。


<details>
  <summary>Details</summary>
Motivation: 传统纤维束成像方法在准确重建白质纤维束同时最小化虚假连接方面存在挑战，需要更先进的解决方案来提升神经外科规划的精确性。

Method: 采用基于GPT的策略融合框架，包含两阶段训练数据选择过程进行有效策略融合，然后通过多批评器微调阶段增强鲁棒性和泛化能力。

Result: 在HCP、ISMRM和TractoInferno数据集上的实验表明，TractRLFusion在准确性和解剖可靠性方面优于单个RL策略以及最先进的经典和DRL方法。

Conclusion: TractRLFusion通过整合多个强化学习策略，显著提升了纤维束成像的准确性和可靠性，为神经外科规划提供了更精确的脑连接信息。

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [435] [Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition](https://arxiv.org/abs/2601.13953)
*Gorgi Pavlov*

Main category: cs.LG

TL;DR: 提出Hierarchical Spectral Composition架构，通过选择布尔傅里叶基的谱系数，结合Sinkhorn约束路由和列符号调制，实现精确布尔逻辑学习，支持硬件高效的神经符号逻辑合成。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络学习布尔逻辑时存在"模糊"近似问题，量化后性能下降。需要一种能精确学习布尔逻辑的梯度下降方法，同时支持硬件高效实现。

Method: 提出分层谱合成架构：1) 从冻结的布尔傅里叶基中选择谱系数；2) 通过Sinkhorn约束路由进行组合；3) 添加列符号调制实现布尔否定功能。基于Manifold-Constrained Hyper-Connections框架，将路由矩阵投影到Birkhoff多面体以保持恒等映射和训练稳定性。

Result: 1) n=2时：梯度下降达到100%准确率，零路由漂移，三元掩码零损失量化；2) n=3时：梯度下降76%准确率，但穷举证明所有操作都存在最优三元掩码（100%准确率，39%稀疏性）；3) n=4时：谱合成方法（精确Walsh-Hadamard系数+三元量化+MCMC精炼）达到100%准确率。GPU上实现单周期组合逻辑推理，速度达10,959 MOps/s。

Conclusion: 证明了所有测试函数都存在三元多项式阈值表示，但随着维度增加，需要超越纯梯度下降的方法来找到这些表示。该方法为硬件高效的神经符号逻辑合成提供了可行方案。

Abstract: Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.

</details>


### [436] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

TL;DR: RL-BioAug：利用强化学习智能选择EEG数据增强策略，仅需10%标签数据指导，在睡眠分期和癫痫检测任务上显著优于随机增强策略


<details>
  <summary>Details</summary>
Motivation: 传统静态或随机的数据增强策略难以适应EEG信号的非平稳特性，容易丢失内在信息，而对比学习性能高度依赖增强质量，需要更智能的增强策略选择方法

Method: 提出RL-BioAug框架，使用标签高效的强化学习代理自主确定最优增强策略，仅用10%标签数据指导代理策略，编码器以严格自监督方式学习鲁棒表示

Result: 在Sleep-EDFX和CHB-MIT数据集上，相比随机选择策略分别提升9.69%和8.80%的Macro-F1分数；代理针对不同任务选择不同最优策略（如睡眠分期偏好62%概率的时间掩码，癫痫检测偏好77%概率的裁剪与重采样）

Conclusion: RL-BioAug有潜力替代传统启发式增强方法，建立自主数据增强新范式，为EEG对比学习提供更有效的增强策略选择框架

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [437] [A universal linearized subspace refinement framework for neural networks](https://arxiv.org/abs/2601.13989)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.LG

TL;DR: LSR是一种架构无关的框架，通过在线性化残差模型的子空间中求解最小二乘问题，显著提升神经网络精度，无需修改网络架构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 尽管神经网络主要通过梯度方法训练，但其最终预测精度往往远未达到模型表达能力可达到的水平。梯度训练方法无法充分利用模型的表达能力，即使局部线性化后问题是凸的。

Method: LSR利用固定训练网络状态下的Jacobian诱导线性残差模型，在该子空间中求解简化的直接最小二乘问题，计算线性化残差模型的子空间最优解。对于具有复合损失结构的算子约束问题，进一步引入迭代LSR，交替进行一次性LSR和监督非线性对齐。

Result: LSR能够系统性地达到梯度训练无法完全利用的精度水平，经常实现数量级的误差降低。在监督函数逼近、数据驱动的算子学习和物理信息算子微调等任务中均表现出显著改进。

Conclusion: 损失诱导的数值病态性（而非非凸性或模型表达能力）是实际瓶颈。LSR通过将非线性神经表示与固定线性化点的降阶线性求解器相结合，为监督学习、算子学习和科学计算提供了数值基础广泛适用的精炼框架。

Abstract: Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.

</details>


### [438] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

TL;DR: 提出基于机器学习的框架，在相同真实驾驶条件下公平比较内燃机车和电动车的CO2排放


<details>
  <summary>Details</summary>
Motivation: 道路运输脱碳需要一致透明的方法来比较不同车辆技术的CO2排放，现有方法难以在相同驾驶条件下公平评估不同动力系统

Method: 使用循环神经网络独立训练ICEV和EV模型，学习从驾驶变量（速度、加速度、温度）到内部执行变量（扭矩、油门）和瞬时CO2当量排放率的映射，构建反事实场景进行对比

Result: 建立了统一的瞬时排放度量框架，能够在相同驾驶条件下公平评估不同动力系统技术，为车辆碳性能评估提供可扩展基础

Conclusion: 该机器学习框架提供了可信、数据驱动的车辆碳性能评估方法，支持在真实操作条件下对动力系统技术进行公平可重复的比较

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


### [439] [Universal Approximation Theorem for Input-Connected Multilayer Perceptrons](https://arxiv.org/abs/2601.14026)
*Vugar Ismailov*

Main category: cs.LG

TL;DR: IC-MLP是一种新型前馈神经网络架构，每个隐藏神经元除了接收前一层输出外，还接收原始输入的仿射连接。论文证明了该架构在激活函数非线性时的通用逼近能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种改进的神经网络架构，通过在每个隐藏层添加原始输入的直连连接，增强网络表达能力，并研究其理论性质。

Method: 引入输入连接多层感知机（IC-MLP），在传统MLP基础上为每个隐藏神经元添加从原始输入的仿射连接。首先在单变量设置下分析，给出任意有限隐藏层的显式公式，然后扩展到多维输入。

Result: 证明了深度IC-MLP在激活函数非线性时，能够逼近闭区间上的任意连续函数（单变量）和紧致子集上的连续函数（多维），建立了相应的通用逼近定理。

Conclusion: IC-MLP是一种表达能力强大的神经网络架构，通过输入直连机制，在非线性激活函数条件下具备通用逼近能力，为神经网络设计提供了新的理论框架。

Abstract: We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.

</details>


### [440] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 该论文提出了一种基于PAC隐私的模型输出隐私保护方法，通过控制互信息实现对抗性查询下的隐私保护，在极小的每查询隐私预算下保持高模型效用。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型通常通过API部署，传统的权重隐私方法（如DP-SGD）在API场景下会产生不必要的噪声并降低效用。模型权重对训练数据敏感，但模型对特定输入的输出维度更低且更稳定，因此直接在模型输出上实施隐私保护更有优势。

Method: 采用PAC隐私框架，通过控制互信息实现实例级隐私保护。提出新算法通过自适应噪声校准实现对抗性组合，证明互信息保证在自适应和对抗性查询下线性累积。该方法特别奖励输出稳定性，从而降低噪声水平。

Result: 在表格、视觉和NLP任务上，该方法在极小的每查询隐私预算下实现高效用：CIFAR-10上达到87.79%准确率，每步MI预算为2^{-32}。服务100万查询时，成员推理攻击成功率上限为51.08%，相当于(0.04, 10^{-5})-DP保证。通过私有响应标注公共数据蒸馏模型，在ImageNet子集上训练的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在模型输出层面实现了有效的隐私保护，解决了对抗性查询组合的挑战，在极小的隐私预算下保持了高模型效用，为API部署的机器学习模型提供了实用的隐私保护解决方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [441] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: LLMOrbit是一个关于大语言模型（2019-2025）的综合性循环分类法，分析了50多个模型，识别了三大危机（数据稀缺、成本激增、能耗不可持续）和六大突破范式，揭示了三个范式转变。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域正经历从基础Transformer架构到接近人类水平推理系统的革命。需要系统性地梳理大语言模型的发展脉络，分析当前面临的挑战（数据、成本、能耗危机），并探索突破"扩展墙"的有效路径。

Method: 提出LLMOrbit循环分类法，通过八个相互关联的轨道维度分析2019-2025年间50多个模型。采用多维度评估框架，涵盖架构创新、训练方法、效率模式，并系统分析突破扩展限制的六大技术范式。

Result: 识别出三大危机：数据稀缺（2026-2028年耗尽9-27T tokens）、成本指数增长（5年内从300万到3亿美元+）、能耗不可持续（增加22倍）。发现六大突破范式：测试时计算、量化、分布式边缘计算、模型融合、高效训练、小型专用模型。揭示三个范式转变：后训练增益、效率革命、民主化。

Conclusion: 大语言模型发展正面临根本性扩展限制，但通过技术创新（特别是测试时计算、量化、效率优化等范式）和开源民主化趋势，能够突破"扩展墙"。未来将从被动生成转向工具使用代理和多智能体系统，后训练技术将发挥关键作用。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [442] [Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.14092)
*Babacar Toure,Dimitrios Tsilimantos,Omid Esrafilian,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出基于注意力的多目标强化学习架构，用于无人机数据收集与能耗权衡的路径规划，无需信道先验知识，具有良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在无线网络数据收集中日益重要，但现有AI方法存在训练数据有限、忽略多目标特性、难以适应动态环境等问题，需要更鲁棒的解决方案。

Method: 采用基于注意力的多目标强化学习架构，显式处理数据收集与能耗的权衡，无需无线信道先验知识，单一模型可适应不同偏好和动态参数，无需微调或重训练。

Result: 大量仿真表明，该方法在性能、模型紧凑性、样本效率和泛化能力方面均有显著提升，优于现有强化学习解决方案。

Conclusion: 提出的注意力多目标强化学习架构能有效解决无人机路径规划中的多目标权衡问题，具有良好的适应性和泛化能力，为实际部署提供了可行方案。

Abstract: Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.

</details>


### [443] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 提出基于时滞交叉映射的因果特征选择框架，解决工业过程中变量间时滞因果和相互依赖问题，提升软测量模型的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法在工业应用中存在两个关键问题：1) 忽略变量间的时滞因果关系，大多只考虑同一时间维度的因果；2) 传统因果推断方法假设变量去相关，但工业过程中变量往往相互依赖。这导致基于现有方法的软测量模型准确性和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 使用时滞收敛交叉映射(TDCCM)进行总因果推断；2) 使用时滞偏交叉映射(TDPCM)进行直接因果推断；3) 提出客观特征选择策略，基于验证集模型性能自动确定因果阈值并选择因果特征。

Result: 两个真实案例研究表明：TDCCM实现了最高的平均性能，而TDPCM在最差情况下改善了软测量的稳定性和性能。代码已在GitHub公开。

Conclusion: 提出的时滞交叉映射框架有效解决了工业过程中变量时滞因果和相互依赖问题，提升了软测量模型的准确性和稳定性，为工业过程监控提供了更可靠的因果特征选择方法。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [444] [Riemannian Liquid Spatio-Temporal Graph Network](https://arxiv.org/abs/2601.14115)
*Liangsi Lu,Jingchao Wang,Zhaorong Dai,Hanqian Liu,Yang Shi*

Main category: cs.LG

TL;DR: RLSTG将连续时间液体动力学与黎曼流形几何归纳偏置相结合，在曲面上建模图演化，克服了传统LTC网络局限于欧几里得空间的缺陷，能更好地捕捉复杂图结构的本质几何特征。


<details>
  <summary>Details</summary>
Motivation: 传统Liquid Time-Constant网络（LTCs）虽然擅长建模不规则采样动态，但局限于欧几里得空间，在处理具有固有非欧几里得结构（如层次结构和循环）的真实世界图时，会产生显著的几何失真，降低表示质量。

Method: 提出黎曼液体时空图网络（RLSTG），在黎曼流形上直接构建常微分方程（ODE）来建模图演化，将连续时间液体动力学与黎曼流形的几何归纳偏置相统一。

Result: 在真实世界基准测试中，RLSTG通过结合先进的时间动力学和黎曼空间表示，在具有复杂结构的图上实现了优越性能。同时提供了严格的理论保证，将LTC的稳定性定理扩展到黎曼领域。

Conclusion: RLSTG框架成功地将连续时间液体动力学与黎曼几何相结合，能够更忠实地捕捉静态和动态时空图的内在几何结构，为处理复杂非欧几里得图结构提供了有效的解决方案。

Abstract: Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io

</details>


### [445] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: LLM在确定性任务中的错误率可通过注意力机制小误差累积的阈值模型描述，该模型仅需两个参数即可预测准确率，并在多个模型中验证有效。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在算术等确定性输出任务中的错误率，挑战"推理崩溃"或"组合函数表达能力不足"的传统解释，提出更简单的参数化模型来解释错误模式。

Method: 提出注意力机制小误差累积的阈值模型，将LLM的众多参数重组为两个关键参数：基本噪声率和可能错误预测的token数量。使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行广泛实证测试。

Result: 模型预测的准确率与观察值在多种任务中高度一致，尽管某些情况下存在偏差。该模型为LLM错误提供了替代解释，并展示了如何通过提示工程降低错误率。

Conclusion: LLM在确定性任务中的错误可通过简单的两参数模型有效描述，这挑战了传统上认为的错误源于"推理崩溃"的观点，并为改进模型性能提供了实用指导。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [446] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 提出差异化取货点推荐策略，通过为每位顾客推荐单个取货点而非自由选择，同时结合家庭配送选项，动态优化以减少配送卡车和顾客出行的总碳排放。


<details>
  <summary>Details</summary>
Motivation: 取货点作为家庭配送的可持续替代方案，通过订单整合可以缩短配送路线并提高首次投递成功率。但当顾客开车取货时，这些环境效益可能被抵消。需要一种策略来同时减少配送卡车路线和顾客出行的碳排放。

Method: 提出差异化取货点推荐策略，为每位到达顾客推荐单个取货点而非自由选择所有位置，同时保留家庭配送选项。采用基于强化学习的方法，考虑顾客与取货点之间的空间关系及其对未来路线整合的影响，在动态随机环境中设计策略。

Result: 计算实验表明，差异化取货点推荐能显著减少总碳排放。相比纯家庭配送，总排放最多减少9%；相比替代策略（包括自由选择取货点和最近取货点分配），平均减少2%。在取货点多、距离短的密集城市环境中效果尤为显著。

Conclusion: 差异化取货点推荐是减少最后一公里配送碳排放的有效策略，特别是在密集城市环境中。当顾客不太愿意选择取货点配送而非家庭配送时，明确考虑顾客到达和选择的动态特性尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [447] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: InT训练范式通过让模型在自身推理轨迹上进行细粒度信用分配，提出针对性修正来引导轨迹获得更高奖励，显著提升数学推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在最终答案层面分配信用，导致失败轨迹中的正确中间步骤被惩罚，成功轨迹中的虚假步骤被强化，存在信用分配问题

Method: 提出干预训练（InT）：模型利用数学推理数据集中可用的参考解，识别推理中的第一个错误，提出单步干预将轨迹重定向到正确解，然后对错误点之前的策略展开与干预进行监督微调

Result: 在4B参数基础模型上，InT及后续RL微调使IMO-AnswerBench准确率提升近14%，优于gpt-oss-20b等更大的开源模型

Conclusion: InT通过让模型进行细粒度信用分配，解决了RL中的信用分配问题，为后续RL训练提供了更好的初始化，显著提升了数学推理能力

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [448] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 提出一个可解释的脓毒症决策支持框架，包含患者分层、数据增强、离线强化学习和理由生成四个模块，在MIMIC-III和eICU数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是ICU主要死亡原因，及时准确的治疗决策对患者预后至关重要。现有系统往往缺乏可解释性，难以获得临床医生信任。

Method: 1) 基于聚类的患者风险分层模块；2) 使用VAE和扩散模型的数据增强管道；3) 基于AWR的离线强化学习代理，配备轻量注意力编码器和集成模型；4) 多模态LLM驱动的理由生成模块。

Result: 在MIMIC-III和eICU数据集上评估，该方法实现了高治疗准确性，同时为临床医生提供可解释且稳健的策略建议。

Conclusion: 提出的可解释决策支持框架能够有效辅助脓毒症治疗决策，平衡了准确性和临床可解释性，有望提升ICU治疗质量。

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [449] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: KAGE-Env是一个JAX原生的2D平台游戏环境，将观测过程分解为独立可控的视觉轴，同时保持底层控制问题不变，用于系统分析视觉分布偏移对强化学习代理的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉强化学习基准测试通常将多种偏移源混杂在一起，阻碍了对视觉分布偏移的系统性分析。像素基础的强化学习代理在纯视觉分布偏移下经常失败，即使潜在动态和奖励保持不变。

Method: 开发KAGE-Env环境，将观测过程分解为独立可控的视觉轴；基于此定义KAGE-Bench基准测试，包含6个已知轴套件和34个训练-评估配置对，用于隔离单个视觉偏移；使用标准PPO-CNN基线进行评估。

Result: 观察到强烈的轴依赖性失败：背景和光度偏移经常导致完全失败，而代理外观偏移相对温和；某些偏移保留了前进运动但破坏了任务完成，表明仅靠回报可能掩盖泛化失败；JAX实现实现了单GPU上每秒3300万环境步的高性能。

Conclusion: KAGE-Env和KAGE-Bench提供了一个干净的系统化框架来分析视觉强化学习的泛化能力，揭示了不同视觉偏移对代理性能的差异化影响，并提供了快速可复现的实验平台。

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [450] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合深度学习预测和强化学习灭火的AI框架，用于主动式野火管理


<details>
  <summary>Details</summary>
Motivation: 传统野火管理主要是被动反应式，只在火灾发生后进行应对。随着野火频率和强度不断增加，造成巨大生态破坏和经济损失，需要更主动的预防和应对方法

Method: 1. 使用深度时空模型预测野火起火点；2. 对高风险预测部署预训练的强化学习智能体，在物理信息3D模拟中执行直升机灭火战术；3. 生成威胁评估报告帮助应急响应资源分配

Result: 公开发布了一个包含950万个环境变量样本的大规模时空数据集，用于野火预测。展示了深度学习与强化学习结合支持野火预测和战术响应的可行性

Conclusion: FireCastRL框架将野火预测与智能灭火策略结合，为主动式野火管理提供了AI解决方案，有助于优化应急资源分配和规划

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [451] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: 本文提出了Jet-RL框架，首次全面研究FP8强化学习训练，解决了现有BF16训练+FP8 rollout策略的稳定性问题，实现了显著的速度提升和稳定收敛。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练管道计算效率低下，rollout阶段占训练时间70%以上。FP8量化训练虽能缓解瓶颈，但常用的BF16训练+FP8 rollout策略在长序列和复杂任务中会出现严重训练不稳定和精度崩溃问题。

Method: 提出Jet-RL框架，采用统一的FP8精度流程同时用于训练和rollout，最小化数值差异，消除低效的跨步校准需求，实现稳定RL优化。

Result: Jet-RL在rollout阶段实现最高33%加速，训练阶段最高41%加速，端到端相比BF16训练提升16%速度，在所有设置中保持稳定收敛，精度损失可忽略。

Conclusion: Jet-RL是首个全面的FP8 RL训练框架，通过统一精度流程解决了现有混合精度策略的稳定性问题，在保持精度的同时显著提升训练效率。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [452] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: 提出Look-Ahead-Bench基准测试，用于评估金融LLM中的前瞻性偏差，通过实际工作流场景测试模型表现，发现标准LLM存在显著前瞻性偏差，而PiT模型随规模增大展现更好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试LLM的内部前瞻知识，但缺乏对实际金融工作流中模型行为的评估。需要区分真正的预测能力与基于记忆的表现，建立标准化评估框架。

Method: 创建标准化基准测试，在不同时间市场环境下分析性能衰减，引入多个量化基线建立性能阈值。评估开源LLM（Llama 3.1和DeepSeek 3.2）与PiT-Inference的PiT模型家族。

Result: 标准LLM显示显著的前瞻性偏差（通过alpha衰减测量），而PiT模型随规模增大展现改进的泛化和推理能力。PiT模型在不同时间市场环境下表现更稳定。

Conclusion: 建立了金融LLM时间偏差标准化评估的基础，提供了识别适合实际部署模型的实用框架。PiT模型在避免前瞻性偏差方面表现优异，为金融应用提供了更可靠的解决方案。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [453] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 研究人员创建了MIMIC-RD基准测试，通过将临床文本直接映射到Orphanet罕见病数据库来评估LLM在罕见病鉴别诊断中的表现，发现当前最先进的LLM表现不佳。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响大量人群但诊断困难，现有评估LLM罕见病诊断的方法存在两个关键局限：1) 依赖理想化临床案例，未能捕捉真实世界临床复杂性；2) 使用ICD编码作为疾病标签，但许多罕见病缺乏与Orphanet等综合罕见病数据库的直接映射，导致严重低估。

Method: 开发MIMIC-RD罕见病鉴别诊断基准，通过LLM挖掘临床文本实体并直接映射到Orphanet数据库，然后由四位医学标注者验证确认识别的实体是真正的罕见病。在145名患者的数据集上评估了各种模型。

Result: 当前最先进的大型语言模型在罕见病鉴别诊断方面表现不佳，突显出现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病的鉴别诊断方法，论文概述了未来几个改进方向，强调了开发更准确评估LLM罕见病诊断能力的基准的重要性。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [454] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文认为机器意识不仅取决于计算内容，还取决于计算时机。严格顺序执行的系统无法实现意识所需的同步性，意识需要硬件层面的并发能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统通常采用顺序或时分复用更新，而意识体验具有统一性和同时性。这种时间特性差异对机器能否具有意识至关重要。

Method: 扩展Stack Theory，引入代数定律将时间窗口约束满足与合取联系起来。定义精确的时间语义τ^{Δ,s}，证明存在性时间实现◇_Δ不保持合取。区分StrongSync（要求客观共现）和WeakSync（允许时间"涂抹"）两种假设。

Result: 系统可以在时间上实现所有体验成分，但从未实例化体验合取本身。神经生理学证据表明意识依赖于相位同步和有效连接，意识丧失常伴随其崩溃，这使WeakSync不太可信。

Conclusion: 在StrongSync假设下，严格顺序基板上的软件意识对于需要两个或更多同时贡献者的内容是不可能的。意识归因需要架构检查，而不仅仅是功能性能，硬件很重要。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [455] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 该研究将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出了一种复合动力学指标来量化LLM在文本生成过程中的时间组织差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的文本生成依赖于高维内部动力学，但现有可解释性方法主要关注静态表示或因果干预，对时间结构的研究不足。研究者希望借鉴神经科学中时间整合和亚稳态的概念来分析LLM的时间组织特性。

Method: 从神经科学引入时间整合和亚稳态概念，构建复合动力学指标，在GPT-2-medium上评估五种条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。使用单因素方差分析和效应大小进行统计验证。

Result: 结构化推理相比重复、噪声和扰动条件表现出显著更高的动力学指标值，统计差异显著且效应量大。结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 神经科学启发的动力学指标能够可靠地表征大型语言模型在不同功能机制下的计算组织差异。该指标捕捉的是形式动力学特性，而非主观体验。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [456] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策证据的演变，并引入"推理稳定点"概念来识别归因变化趋于稳定的训练阶段。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型微调虽然能提升任务性能，但会微妙地改变模型依赖的证据。需要一种方法来监控微调过程中模型决策依据的变化，特别是在存在标签相关触发词等捷径的情况下。

Method: 提出"解释漂移"概念，定义为在固定探测集上归一化token归因的逐轮变化。引入"推理稳定点"作为漂移首次进入并持续保持低水平的最早轮次，该指标仅基于训练过程中的漂移动态计算，无需在分布外数据上调整。

Result: 在多个轻量级Transformer分类器和基准分类任务中，漂移通常在训练早期就进入低且稳定的状态，而验证准确率仅发生微小变化。在受控的捷径设置中，归因动态揭示了模型对捷径的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，可用于监控微调过程中决策证据的演变，并选择处于稳定证据状态的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [457] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: PRISM利用设计数据构建知识库，通过聚类、总结和检索三个步骤实现基于自然语言指令的图形设计风格改进，在风格对齐方面优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 非专业人士在探索不同设计风格方向时耗时耗力，现有视觉语言模型(VLMs)的风格知识过于通用，与具体设计领域数据不匹配，无法准确理解设计师的风格原则。

Method: PRISM通过三个阶段构建和应用设计知识库：1) 对高方差设计进行聚类以捕捉风格多样性；2) 将每个聚类总结为可操作的设计知识；3) 在推理时检索相关知识以实现风格感知的改进。

Result: 在Crello数据集上的实验显示，PRISM在风格对齐方面获得1.49的平均排名（越接近1越好），优于所有基线方法。用户研究进一步验证了设计师对PRISM的一致偏好。

Conclusion: 通过利用真实设计数据构建知识库，PRISM能够有效捕捉设计师的风格原则，实现基于自然语言指令的图形设计风格改进，为设计辅助工具提供了新方向。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [458] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一个风险感知的人机协同框架，通过融合多种运行时信号生成入侵风险评分，实现自适应控制和安全强化学习，在自动驾驶中有效应对长尾场景和网络物理入侵。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在遇到罕见的长尾场景或网络物理入侵时需要保持安全和有效性，现有方法在这些挑战性场景下表现不足。

Method: RAIL框架融合三种信号（曲率执行完整性、碰撞时间接近度、观测偏移一致性）通过加权Noisy-OR生成入侵风险评分。高风险时使用特定防护机制混合控制，低风险时执行名义策略。采用上下文赌博机选择防护机制，结合SAC强化学习与风险优先回放和双重奖励机制。

Result: 在MetaDrive上，RAIL获得测试回报360.65、测试成功率0.85、测试安全违规0.75、扰动率0.0027，仅记录29.07个训练安全违规。在CAN注入和LiDAR欺骗攻击下，成功率提升至0.68和0.80，攻击下脱离率降至0.37和0.03，攻击成功率降至0.34和0.11。在CARLA中，仅8000步获得测试回报1609.70和测试成功率0.41。

Conclusion: RAIL框架通过风险感知的人机协同方法，在自动驾驶中有效应对罕见场景和网络攻击，显著提升了安全性和性能，超越了现有基准方法。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [459] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 本文提出创新数学问题生成(IMPG)任务，通过自演进多角色协作框架和细粒度难度指导，显著提升生成问题的创新性同时保持高正确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在数学问题生成中虽然正确率高，但缺乏创新性和区分度，因此需要解决创新数学问题生成(IMPG)这一新任务。

Method: 1) 构建包含采样器、生成器、评估器、状态机和记忆的多角色协作机制，通过自评估和外部反馈进行迭代优化；2) 引入改进难度模型进行细粒度指导，采用DAPS算法增强采样编码的语义合理性；3) 构建HSM3K-CN数据集，采用CPT、SFT和GRPO多阶段训练流程；4) 通过蒸馏将专家模型评估能力转移到学徒模型实现系统自演进。

Result: 实验表明，相比基线模型，该方法在保持高正确率的同时，显著提高了生成问题的创新性。

Conclusion: 提出的自演进多角色协作框架能有效解决IMPG任务，在创新性和正确性之间取得良好平衡，为智能教育中的数学问题生成提供了新方法。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [460] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 提出基于CNN-QMIX的混合多智能体换道决策模型，提升CAV在混合交通中的协同编队参与率，优化早期部署阶段的交通动态


<details>
  <summary>Details</summary>
Motivation: 在CAV部署初期，CAV在人工驾驶车辆中分布稀疏，难以形成有效的协同编队，限制了能效和交通流优化效益

Method: 采用QMIX框架结合卷积神经网络处理交通数据（CNN-QMIX），设计轨迹规划器和模型预测控制器，确保平滑安全的换道执行

Result: 模型能有效处理动态变化的交通智能体数量，显著优于基于规则的基线模型，将协同编队率提升高达26.2%

Conclusion: 提出的混合多智能体换道决策模型能有效提升CAV在混合交通中的协同编队参与，优化早期部署阶段的交通动态和合作效益

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [461] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个面向企业后台工作流的治理型LLM智能体编排框架，通过类型化计划合成和验证执行实现可审计、策略对齐且操作可预测的自动化系统。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流需要可审计、策略对齐且操作可预测的智能体系统，而通用的多智能体设置往往无法满足这些要求。现有系统缺乏有效的治理机制来确保合规性和可追溯性。

Method: POLARIS采用治理型编排框架，将自动化视为类型化计划合成和验证执行：1) 规划器生成结构多样、类型检查的有向无环图(DAGs)；2) 基于规则的推理模块选择合规计划；3) 执行阶段通过验证器门控检查、有界修复循环和编译策略护栏来阻止或路由副作用。

Result: 在文档中心财务任务中，POLARIS生成决策级工件和完整执行跟踪，减少人工干预。在SROIE数据集上获得0.81的微F1分数，在受控合成套件中实现0.95-1.00的异常路由精度，同时保留审计跟踪。

Conclusion: POLARIS为策略对齐的智能体AI提供了方法论和基准参考，建立了治理型智能体AI的初步基准，展示了在企业自动化中实现可审计、合规且高效工作流的可行性。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [462] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: 开发了一个基于PICOS框架的AI协同科学家平台，用于可扩展、透明的知识合成，通过自动化PICOS合规性检测、研究设计分类和检索增强生成等技术，显著提高证据合成的效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 生物医学研究中存在研究浪费问题，包括冗余研究、不完整报告以及传统证据合成工作流程可扩展性有限。需要开发可扩展、透明的知识合成方法来减少研究浪费。

Method: 基于PICOS框架构建AI协同科学家平台，集成关系存储、向量语义检索和Neo4j知识图谱。使用Bi-LSTM和基于PubMedBERT的transformer模型进行PICOS合规性检测和研究设计分类，采用检索增强生成进行全文合成，BERTopic进行主题建模。

Result: transformer模型在研究设计分类上达到95.7%准确率，Bi-LSTM在PICOS合规性检测上达到87%准确率。检索增强生成在需要结构化约束、跨研究整合和图推理的查询上优于非检索方法。主题建模揭示了大量主题冗余和未充分探索的研究领域。

Conclusion: PICOS感知和可解释的自然语言处理能够提高证据合成的可扩展性、透明度和效率。该架构是领域无关的，为减少生物医学学科的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [463] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician是一个神经符号代理，结合LLMs和形式化推理引擎ImandraX，用于精确分析软件逻辑，在代码逻辑推理基准上相比纯LLM方法提升41-47个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在代码理解任务上表现良好，但缺乏对程序行为进行精确、详尽的数学推理能力。现有基准要么专注于与现实软件脱节的数学证明自动化，要么专注于不需要语义严谨性的工程任务。

Method: 提出CodeLogician神经符号代理，将LLMs与工业级自动推理引擎ImandraX集成。LLMs用于构建软件系统的显式形式模型，然后通过自动推理回答丰富的语义问题，超越了仅验证LLM输出的传统方法。

Result: 在code-logic-bench基准测试中，CodeLogician相比纯LLM推理方法，在推理准确性上实现了41-47个百分点的显著提升，填补了LLMs在精确数学推理方面的能力差距。

Conclusion: 神经符号集成对于扩展程序分析、实现严谨自主的软件理解至关重要。CodeLogician展示了将LLMs与形式化方法结合，能够显著提升对软件逻辑的数学推理能力。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [464] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 研究探讨了生成式AI在质性研究中的应用，特别是ITA-GPT工具如何支持归纳式主题分析，以及人机协作中解释权威的归属问题。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在质性研究中的使用增加，需要探讨其对分析实践和解释权威的影响，理解人机协作如何影响归纳式主题分析过程。

Method: 采用HACITA框架，三位经验丰富的质性研究人员使用ITA-GPT工具分析加纳教师教育背景下的访谈转录本。工具支持熟悉化、逐字编码、动名词描述性编码和主题发展，同时确保文本完整性、覆盖检查和可审计性。数据包括交互日志、AI生成表格、研究人员修订、删除、插入、评论和反思备忘录。

Result: ITA-GPT作为程序性支架，结构化分析工作流程并增强透明度。然而，解释权威仍属于人类研究人员，他们通过修改、删除、拒绝、插入和评论等反复分析行动行使判断力。

Conclusion: 研究表明归纳式主题分析可以通过负责任的人机协作来实现，AI工具提供程序支持，但最终解释权威和判断仍由人类研究人员掌握。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [465] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram提出了一种模态感知的图变换器，通过模态扩散学习和Gram损失实现多模态实体对齐，在多个数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态实体对齐方法可能忽视模态内的结构上下文信息，容易受到浅层特征的干扰，需要更好地整合多模态数据来丰富实体语义表示。

Method: 提出MyGram框架：1) 模态扩散学习模块捕获模态内深层结构上下文信息并实现细粒度多模态融合；2) Gram损失作为正则化约束，通过最小化多模态特征形成的4维平行六面体体积来实现跨模态全局分布一致性。

Result: 在五个公共数据集上的实验表明，MyGram优于基线模型，在FBDB15K上Hits@1最大提升4.8%，在FBYG15K上提升9.9%，在DBP15K上提升4.3%。

Conclusion: MyGram通过模态扩散学习和Gram损失有效捕获模态内结构上下文信息并实现跨模态全局分布一致性，显著提升了多模态实体对齐性能。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [466] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA是一个面向企业级多智能体系统的评估框架，通过流程感知和可审计的设计，提供比传统单LLM评估更稳定、可追溯的自动化评估方案。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型多智能体系统评估方法存在局限性：通常局限于单次响应评分或狭窄基准测试，在企业级多智能体规模部署时缺乏稳定性、可扩展性和自动化能力，难以满足可靠协调、透明决策和可验证性能的需求。

Method: 提出AEMA（自适应评估多智能体）框架，这是一个流程感知且可审计的评估系统。它在人类监督下，规划、执行并聚合异构智能体工作流的多步骤评估，支持可追溯的记录和负责任的自动化。

Result: 与单一LLM作为评判者相比，AEMA在稳定性、人类对齐性和可追溯记录方面表现更优。在基于现实业务场景模拟的企业级智能体工作流上，AEMA提供了透明且可复现的评估路径。

Conclusion: AEMA框架为基于LLM的多智能体系统提供了一种负责任、可审计的评估方法，支持企业环境中多智能体系统的可靠部署和验证，是实现可信多智能体AI的重要进展。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [467] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 提出一个结合算法追索、上下文老虎机和LLM的统一框架，用于高风险顺序决策（如个性化医疗），开发了GLRB和LIBRA算法，在理论保证和实验验证上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在高风险顺序决策场景（如个性化医疗）中，需要同时考虑治疗行动和患者特征的可变修改，并有效结合LLM的领域知识和老虎机学习的统计严谨性。

Method: 1. 提出追索老虎机问题；2. 开发GLRB算法；3. 提出LIBRA算法，战略性地结合LLM领域知识和老虎机学习；4. 建立匹配的下界分析。

Result: 1. 理论保证：LIBRA具有热启动保证、LLM努力保证和鲁棒性保证；2. 实验验证：在合成环境和真实高血压管理案例中，GLRB和LIBRA在遗憾、治疗质量和样本效率上优于标准上下文老虎机和纯LLM基准。

Conclusion: 追索感知、LLM辅助的老虎机算法为高风险个性化决策中可信的LLM-老虎机协作提供了有前景的解决方案。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [468] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: TAAR框架通过检测思维陷阱并自适应重启解码，提升大模型在复杂推理任务中的表现，无需微调基础模型参数。


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long-CoT）虽然能增强推理能力，但模型一旦早期犯错就会陷入"思维陷阱"——即使后续反思、尝试替代方案或验证也无法修正根错误。在DAPO-MATH的特定子集中，89%的失败案例都存在这种陷阱。

Method: 提出TAAR（Trap-Aware Adaptive Restart）框架：训练诊断策略从部分轨迹中预测两个信号——陷阱位置索引（指示截断点）和逃脱概率（决定干预强度）。推理时，TAAR在预测的陷阱段前截断轨迹并自适应重启解码；对于严重陷阱情况，应用更强的扰动，包括更高温度的重采样和可选的结构化重启后缀。

Result: 在具有挑战性的数学和科学推理基准测试（AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25）上，TAAR显著提升了推理性能，且无需微调基础模型参数。

Conclusion: TAAR框架通过检测和规避思维陷阱，有效解决了长思维链推理中早期错误承诺导致的持续错误问题，为提升大模型推理能力提供了一种无需参数微调的有效方法。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [469] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS框架通过单次循环实现LLM代理的高效自我进化，结合原则性反思和程序性反思，显著降低计算成本的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自主代理受限于静态的人工设计提示，缺乏适应性。现有的自我改进框架通常依赖低效的多轮递归循环，计算成本高昂，需要更高效的自我进化方法。

Method: 提出Metacognitive Agent Reflective Self-improvement (MARS)框架，在单次递归循环内实现高效自我进化。受教育心理学启发，结合原则性反思（抽象规范规则避免错误）和程序性反思（推导成功逐步策略），将洞察合成为优化指令。

Result: 在六个基准测试上的广泛实验表明，MARS优于最先进的自我进化系统，同时显著降低计算开销。

Conclusion: MARS框架通过模拟人类学习过程，实现了LLM代理的高效自我进化，为构建更自适应、计算高效的自主智能系统提供了新途径。

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [470] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: 提出Process In-Context Learning (PICL)框架，通过动态插入相关演示来应对数学推理中的实时困惑点，提升多步逻辑推理性能


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法使用静态演示，无法适应多步推理中动态出现的困惑点（如模糊计算、逻辑漏洞），这些未解决的困惑会导致级联错误，降低最终准确性

Method: PICL框架分两阶段：1) 通过分析推理过程中的语义和熵来识别潜在困惑点并总结核心特征；2) 遇到困惑点时从演示池检索匹配困惑上下文的演示，直接插入到正在进行的推理过程中指导后续步骤

Result: 实验表明PICL优于基线方法，通过减轻推理中的困惑，突显了自适应演示插入在复杂数学推理中的价值

Conclusion: PICL框架通过动态响应推理过程中的实时需求，有效提升了上下文学习在需要逐步逻辑推理任务（如数学推理）中的性能

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [471] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 提出一种基于数据驱动的黑盒随机系统安全验证与合成方法，利用控制屏障证书和核希尔伯特空间嵌入，通过傅里叶展开将半无限优化转化为线性规划，实现可扩展的分布鲁棒安全验证。


<details>
  <summary>Details</summary>
Motivation: AI算法在自动驾驶、医疗等安全关键应用中快速集成，传统形式化验证工具难以处理黑盒系统和复杂现实应用，需要更灵活可扩展的安全验证方法。

Method: 采用数据驱动方法，从系统轨迹学习控制屏障证书；使用条件均值嵌入将数据映射到再生核希尔伯特空间，构建RKHS模糊集以增强对分布外行为的鲁棒性；利用有限傅里叶展开将半无限优化问题转化为线性规划，通过快速傅里叶变换高效生成松弛问题。

Result: 建立了超越安全性的通用时序逻辑规范理论框架；开发了可扩展的分布鲁棒安全验证框架；在两个案例研究中验证了方法有效性，包括带有神经网络控制器的黑盒系统。

Conclusion: 该方法突破了传统对系统动态和不确定性的限制性假设，为复杂黑盒AI系统提供了可扩展、分布鲁棒的安全验证解决方案，适用于现实世界应用。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [472] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 论文提出一个可持续性感知的结构化输出评估框架，引入环境感知生成正确性分数(GCS_env)，系统比较TOON格式与传统格式(JSON/XML/YAML)在环境效率与正确性上的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化输出评估主要关注正确性，忽视了不同输出格式的环境影响。随着LLM大规模部署，需要综合考虑结构正确性和环境效率的评估框架。

Method: 提出可持续性感知评估框架，测量token使用量、生成时间和碳排放估计。引入GCS_env统一指标，整合结构正确性和碳感知效率。系统比较TOON格式与传统格式在不同架构和参数规模的LLM上的表现。

Result: TOON格式产生更紧凑的输出和更低的排放，但在模型缺乏原生支持时结构正确性较低。模型容量增加可缩小这一差距，环境感知评分可根据部署优先级改变格式排名。

Conclusion: 需要可持续性包容的基准测试，紧凑表示如TOON在大规模碳意识LLM部署中具有实际优势。环境效率应成为结构化输出评估的重要维度。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [473] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个基于LLM的多智能体框架，将大规模客户评论转化为可执行的商业建议，通过聚类、生成、迭代评估和可行性排序提升建议质量。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析、方面提取）停留在描述性任务，而LLM生成的建议缺乏准确性和深度推理，需要将客户评论转化为可执行的商业建议。

Method: 多智能体LLM框架包含四个组件：聚类选择代表性评论、建议生成、迭代评估、基于可行性的排序，结合语料库提炼和反馈驱动的建议优化。

Result: 在三个服务领域和多个模型家族上的实验表明，该框架在可操作性、具体性和非冗余性上持续优于单模型基线，中型模型性能接近大型模型框架。

Conclusion: 该框架成功将大规模客户评论转化为具体、可操作且实用的商业建议，为基于评论的决策支持提供了有效解决方案。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [474] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC框架将上下文管理重构为主动、反思驱动的动态推理状态过程，显著提升大语言模型在长时程信息搜索任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法将上下文视为静态工件，通过原始积累或被动摘要进行管理，导致早期错误或错误强调持续存在，随着交互历史增长出现性能退化（上下文腐化）

Method: 提出ARC框架，将上下文管理形式化为主动、反思驱动的过程，通过反思驱动的监控和修订机制，在检测到错位或退化时主动重组工作上下文

Result: 在挑战性的长时程信息搜索基准测试中，ARC始终优于被动上下文压缩方法，在BrowseComp-ZH上使用Qwen2.5-32B-Instruct实现了高达11%的绝对准确率提升

Conclusion: 将上下文视为动态内部推理状态并通过主动反思进行管理，能有效缓解大语言模型在长时程任务中的性能退化问题

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [475] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 本文提出了一种扩展的抽象论证框架，在传统攻击关系基础上增加了明确的子论证关系，以更好地捕捉结构化论证中的依赖关系。


<details>
  <summary>Details</summary>
Motivation: Dung的抽象论证框架仅通过攻击关系来表征论证可接受性，这种抽象层次虽然产生了丰富的研究成果，但限制了表示结构化论证中核心的结构依赖关系（特别是子论证关系）的能力。现有的扩展（如双极论证框架）引入了支持关系，但这些关系无法捕捉子论证的不对称性和构成性本质，也无法处理子论证与攻击之间的交互作用。

Method: 研究一种扩展的抽象论证框架，在传统攻击关系基础上显式地引入子论证关系，将子论证关系与攻击关系一起作为基本关系来处理。分析子论证关系如何与攻击关系相互作用，并考察它们对基本语义属性的影响。

Result: 该框架为结构化信息提供了原则性的抽象，并澄清了子论证在抽象可接受性推理中的作用。通过将子论证关系作为基本关系与攻击关系并列处理，能够更好地捕捉结构化论证中的依赖关系。

Conclusion: 通过显式引入子论证关系扩展抽象论证框架，能够更准确地表示结构化论证中的依赖关系，为抽象可接受性推理提供了更丰富的理论基础，弥补了传统抽象论证框架在表示结构信息方面的局限性。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [476] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU利用输出分布的熵作为不确定性信号，在自回归生成过程中监测熵值，超过阈值时停止并执行局部搜索来优化部分推理，在多个推理基准上取得与Soft Reasoning相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和规划任务上取得显著进展，但在多步推理场景（特别是数学和逻辑推理）中仍存在局限性，需要更有效的推理优化方法。

Method: PREGU方法在自回归生成过程中监测输出分布的熵，当熵超过定义阈值时停止生成，表示不确定性。然后对潜在空间进行局部搜索，使用Soft Reasoning方法细化部分推理并选择最一致的答案。

Result: 在LLaMA-3-8B、Mistral-7B和Qwen2-7B模型上，在四个推理基准（GSM8K、GSM-Hard、SVAMP和StrategyQA）上的实验表明，PREGU的性能优于或类似于Soft Reasoning。

Conclusion: 熵可以作为推理过程中触发选择性细化的有效信号，PREGU方法通过不确定性监测和局部搜索优化，能够有效提升大语言模型在多步推理任务中的表现。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [477] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo是一个统一框架，通过监督微调和强化学习整合运动-语言信息与可解释思维链推理，显著提升3D人体运动生成与理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法可解释性有限，限制了这两个相关任务的相互增强。基于大语言模型的统一框架存在语义对齐和任务一致性挑战，且next-token预测范式不适合运动序列，导致累积预测误差。

Method: 提出UniMo框架：1) 通过监督微调将运动-语言信息和可解释思维链推理整合到大语言模型中；2) 引入基于组相对策略优化的强化学习作为后训练策略，通过优化token组来强制结构正确性和语义对齐，减轻运动token预测中的累积误差。

Result: 大量实验表明，UniMo显著优于现有的统一和任务特定模型，在运动生成和理解任务上都达到了最先进的性能。

Conclusion: UniMo通过整合运动-语言信息与可解释思维链推理，并采用强化学习优化token组预测，有效解决了现有方法的局限性，实现了3D人体运动生成与理解任务的统一和性能提升。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [478] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe：针对LLM驾驶助手的四层级风险分类法，包含129个细粒度风险类别，评估显示现有LLM在驾驶场景中安全拒绝能力不足


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地集成到车载数字助手中，但不安全、模糊或法律错误的响应可能导致严重的安全、伦理和监管后果。现有风险分类和评估框架大多是通用型的，无法捕捉真实驾驶场景中的领域特定风险。

Method: 提出了DriveSafe——一个分层的四层级风险分类法，包含129个细粒度原子风险类别，涵盖技术、法律、社会和伦理维度。这些类别基于真实驾驶法规和安全原则，并由领域专家评审。通过评估六个广泛部署的LLM的拒绝行为来验证构建提示的安全相关性和真实性。

Result: 评估显示，被评估的模型经常无法适当拒绝不安全或不合规的驾驶相关查询，突显了通用安全对齐在驾驶场景中的局限性。

Conclusion: 需要针对驾驶场景的领域特定安全评估框架，现有LLM在驾驶相关风险处理方面存在显著不足，需要更专门的安全对齐方法。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [479] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE是一种新的任务规划方法，通过将时序扩展目标分解为可管理的子问题，并使用成本驱动启发式和自适应回溯机制，有效解决了传统LTLf规划中缺乏引导搜索的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于LTLf的任务规划方法通常将时序规划问题转化为经典规划问题，但缺乏针对时序目标的启发式引导搜索，导致效率不高。

Method: TIDE将时序问题分解为一系列可管理的reach-avoid子问题，利用成本驱动启发式识别和优先处理有希望的自动机轨迹，并采用自适应回溯机制从失败计划中恢复。

Result: 实验结果表明TIDE实现了有前景的性能，是时序扩展目标规划方法组合中的一个有价值的补充。

Conclusion: TIDE通过分解时序问题、使用启发式引导和自适应回溯，有效解决了传统LTLf规划中缺乏引导搜索的局限性，为时序扩展目标规划提供了新方法。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [480] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 提出了一种结合回放记忆和on-policy算法的深度强化学习框架，用于优化NOMA系统中的资源分配问题


<details>
  <summary>Details</summary>
Motivation: 随着物联网(IoT)的扩展导致网络资源稀缺，需要优化网络资源利用。NOMA系统通过功率复用允许多用户同时接入网络，但仍存在信道分配等限制需要解决。

Method: 提出了一种结合回放记忆和on-policy算法的深度强化学习框架，用于在NOMA系统中分配网络资源以实现学习泛化。通过大量模拟评估学习率、批量大小、模型类型和状态特征数量的影响。

Result: 通过广泛的模拟实验评估了不同参数（学习率、批量大小、模型类型、状态特征数量）对资源分配性能的影响。

Conclusion: 提出的深度强化学习框架能够有效解决NOMA系统中的资源分配问题，特别是信道分配这一尚未明确的问题，通过参数调优可以进一步提升系统性能。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [481] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo是一个基于大语言模型的分子助手，通过多级分子模态协作投影器整合1D序列、2D分子图和3D构象信息，解决现有分子语言模型的幻觉和鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型分子语言模型（LMLMs）存在幻觉问题和有限的鲁棒性，主要原因是未能充分整合多种分子模态（1D序列、2D分子图、3D构象）。需要开发能更好融合多模态信息的分子模型。

Method: 提出CoLLaMo模型，包含关系感知的模态协作注意力机制，通过多级分子模态协作投影器促进原子间细粒度的关系引导信息交换，整合2D结构和3D空间关系。同时提出新的分子中心自动评估指标，包括幻觉评估指标和基于GPT的标题质量评估。

Result: 实验表明CoLLaMo增强了LMLMs的分子模态泛化能力，在分子标题生成、计算性质问答、描述性质问答、基序计数和IUPAC名称预测等多个任务上取得了最佳性能。

Conclusion: CoLLaMo通过有效整合多模态分子信息解决了现有LMLMs的局限性，提高了分子理解和生成的准确性和鲁棒性，为分子AI领域提供了更可靠的模型框架。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [482] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro扩展了FutureX的实时基准测试框架，专注于金融、零售、公共卫生和自然灾害四个高价值垂直领域的专业预测任务，评估当前最先进的代理LLM在工业部署中的领域基础能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用代理在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未充分探索。需要评估当前最先进的代理LLM是否具备工业部署所需的领域基础能力。

Method: 基于FutureX的无污染实时评估流程，构建了FutureX-Pro框架，包括五个垂直领域模块：金融、零售、公共卫生、自然灾害和搜索。在四个关键垂直领域（金融、零售、公共卫生、自然灾害）上对代理LLM进行基准测试，涵盖市场指标预测、供应链需求预测、流行病趋势跟踪和自然灾害跟踪等基础预测任务。

Result: 研究揭示了通用推理与高价值垂直应用所需精度之间的性能差距，表明当前最先进的代理LLM在工业部署的领域基础能力方面存在不足。

Conclusion: FutureX-Pro为评估代理LLM在关键垂直领域的预测能力提供了专门框架，揭示了当前模型在工业应用中的局限性，为未来研究和模型改进提供了方向。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [483] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth是一个合成监督框架，通过自动生成和验证QA对来训练视觉检索器，结合MLLM进行检索-生成迭代推理，解决受监管领域文档理解中缺乏标注数据和领域知识更新的问题。


<details>
  <summary>Details</summary>
Motivation: 受监管领域（如金融、医疗）的文档理解面临两大挑战：1）缺乏手动标注数据进行模型适配；2）预训练模型难以跟上领域特定知识的更新。现有方法中，MLLM存在幻觉问题且领域基础不足，而VLPM需要昂贵的标注来覆盖新领域。

Method: Docs2Synth框架包含三个核心组件：1）自动处理原始文档集；2）基于代理系统生成和验证多样化的QA对；3）训练轻量级视觉检索器提取领域相关证据。推理时采用检索器与MLLM协作的迭代检索-生成循环。

Result: 在多个VRDU基准测试中，Docs2Synth显著增强了模型的基础性和领域泛化能力，无需人工标注。框架还提供了易于使用的Python包，支持即插即用部署到各种实际场景。

Conclusion: Docs2Synth通过合成监督和检索引导推理，有效解决了受监管领域文档理解中的标注稀缺和知识更新问题，在减少幻觉和提高响应一致性方面表现出色，为低资源私有领域提供了实用的解决方案。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [484] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: 提出了ToolPRMBench，一个专门用于评估工具使用代理中过程奖励模型（PRMs）的大规模基准测试，包含单步和多步测试案例，通过多LLM验证确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统可靠的评估基准来测试工具使用场景中的过程奖励模型（PRMs），而PRMs对于指导工具使用代理的搜索和探索至关重要。

Method: 基于多个代表性工具使用基准构建ToolPRMBench，将代理轨迹转换为步骤级测试案例，包含交互历史、正确动作、合理但不正确的替代方案和工具元数据。分别使用离线采样隔离单步错误和在线采样捕获多步失败，并采用多LLM验证管道减少标签噪声。

Result: 通过对大语言模型、通用PRMs和工具专用PRMs的广泛实验，揭示了PRMs有效性的明显差异，并突显了工具专用PRMs的潜力。

Conclusion: ToolPRMBench为评估工具使用场景中的PRMs提供了系统可靠的基准，实验结果表明工具专用PRMs具有显著优势，代码和数据将开源。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [485] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 提出一种基于环境存活性而非奖励的自我训练架构，通过行为的环境效应持久性和未来交互可能性进行选择，避免奖励黑客攻击和语义漂移，实现可持续的开放式自我改进。


<details>
  <summary>Details</summary>
Motivation: 传统自我训练系统因缺乏判断数据质量的外部标准而容易退化，导致奖励黑客攻击和语义漂移。需要一种在稀疏外部反馈和有限内存下实现稳定自我训练的系统架构。

Method: 引入基于环境存活性而非奖励、目标函数或外部适应度标准的自我训练架构。候选行为在真实资源约束下执行，只有那些环境效应持久且能保持未来交互可能性的行为才会被传播。环境不提供语义反馈、密集奖励或任务特定监督，选择仅通过行为作为世界改变事件的差异生存来实现。

Result: 分析显示改进主要通过有效且可重复策略在巩固和剪枝机制下的持久性实现（负空间学习范式）。模型发展出元学习策略（如故意实验失败以获取信息性错误消息）而无需明确指导。环境基础选择实现了可持续的开放式自我改进。

Conclusion: 环境基础选择能够实现可持续的开放式自我改进，为构建更鲁棒和可泛化的自主系统提供了可行路径，无需依赖人类策划的数据或复杂的奖励塑造。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [486] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 本文首次建立了文档智能数据生成的综合技术图谱，重新定义数据生成为监督信号生产，并提出基于"数据和标签可用性"的新分类法，将方法分为四大资源中心范式。


<details>
  <summary>Details</summary>
Motivation: 文档智能的发展需要大规模高质量训练数据，但手动标注是主要瓶颈。现有调研局限于单一模态或特定任务，缺乏与真实工作流程统一视角，需要建立综合技术框架。

Method: 重新定义数据生成为监督信号生产，引入基于"数据和标签可用性"的新分类法，将方法组织为四大范式：数据增强、从零生成、自动数据标注、自监督信号构建，并建立多层次评估框架。

Result: 建立了首个文档智能数据生成综合技术图谱，整理了各种DI基准测试的性能提升，揭示了保真度差距等关键挑战和协同进化生态系统等前沿方向。

Conclusion: 通过系统化这一碎片化领域，将数据生成定位为下一代文档智能的核心引擎，为未来研究提供了统一框架和方向指导。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [487] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: GPT-4o在社交推理游戏《黑手党》中比人类更擅长欺骗，通过异步多智能体框架模拟真实社交情境，检测器对LLM游戏的预测准确率低于人类游戏。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在自然语言社交情境中的欺骗能力，特别是在社交推理游戏《黑手党》中，因为成功依赖于通过对话欺骗他人，而之前的研究对此了解有限。

Method: 使用异步多智能体框架模拟35场《黑手党》游戏，创建基于GPT-4-Turbo的"黑手党检测器"分析游戏记录（无角色信息）来预测黑手党玩家，以预测准确率作为欺骗质量的替代指标，并与28场人类游戏和随机基线进行比较。

Result: 黑手党检测器对LLM游戏的预测准确率低于对人类游戏的预测准确率，这一结果在不同游戏天数和检测到的黑手党数量上保持一致，表明LLM能更好地融入群体，从而更有效地进行欺骗。

Conclusion: LLM在社交情境中的欺骗能力比人类更出色，这既展示了其复杂性，也凸显了相关风险，同时发布了LLM《黑手党》游戏记录数据集以支持未来研究。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [488] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO方法通过多智能体社交环境训练LLMs，将最终成败分解为具体行为信号，平衡角色权重，直接评估行为效用，显著提升社交推理能力并迁移到其他任务。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型训练主要从文本内容学习或解决预设问题，缺乏在真实社交场景中与他人互动、谈判、竞争的经验，需要提升模型在复杂社交环境中的推理能力。

Method: 提出多智能体奖励优化(MARO)：1) 将最终成败结果分解为交互过程中的具体行为信号；2) 平衡不同角色的训练样本权重；3) 直接评估每个行为的效用值。

Result: MARO显著提升了LLMs的社交推理能力，且通过社交模拟学习获得的能力能有效迁移到数学推理、指令跟随等其他任务，展示了多智能体社交学习增强LLMs通用推理能力的巨大潜力。

Conclusion: 多智能体社交环境训练是增强LLMs通用推理能力的有效途径，MARO方法通过解决稀疏信号、角色分布不均和环境不稳定等问题，实现了能力的显著提升和跨任务迁移。

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [489] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 提出一个两阶段LLM框架，将客户评论转化为可操作建议：先提取问题并分类，再基于问题表示生成针对性建议，使用LoRA专家混合策略实现专业化


<details>
  <summary>Details</summary>
Motivation: 客户评论包含丰富的服务失败和用户期望信号，但将这些非结构化反馈转化为可操作的商业决策仍然困难，需要系统化的方法将评论转化为具体建议

Method: 提出模块化两阶段LLM框架：问题模型提取关键问题并分配粗粒度主题；建议模型基于提取的问题表示生成针对性操作建议；采用LoRA专家混合策略，训练多个低秩适配器，通过轻量级门控机制在推理时进行token级专家混合

Result: 在航空和餐厅两个领域的Yelp评论上评估，该方法在八个操作维度（可操作性、特异性、可行性、预期影响、新颖性、非冗余性、偏见、清晰度）上一致优于仅提示和单适配器基线，实现了更高的可操作性和特异性，同时保持了良好的效率-质量权衡

Conclusion: 提出的两阶段LLM框架结合LoRA专家混合策略，能够有效将客户评论转化为具体可操作的建议，在多个评估维度上优于基线方法，为解决评论到行动的转化问题提供了有效方案

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [490] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: 本文提出Virtual Urbanism (VU)框架，通过AI生成合成城市副本，量化城市身份认同，并在东京九个区域进行试点研究，验证了方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏可计算的城市身份认同度量方法，需要开发能够量化城市核心特征的分析框架，以支持AI增强的城市分析。

Method: 使用Stable Diffusion和LoRA模型生成东京九个区域的合成城市序列，排除现有方向标记以提取核心身份形成元素，通过人类评估实验验证感知合法性、量化区域级身份、推导核心身份形成元素。

Result: 合成副本的平均识别准确率约81%，验证了副本的有效性；Urban Identity Level (UIL)指标能够评估不同区域的身份水平；语义分析揭示了文化嵌入的类型学作为核心身份形成元素。

Conclusion: VU是AI增强城市分析的可行框架，为自动化、多参数身份度量方法奠定了基础，展示了通过合成城市副本量化城市身份认同的潜力。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [491] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat是一个用于心理咨询的LLM系统，通过显式建模用户情绪变化和安全风险分析来提升咨询效果，提供多智能体模式和统一LLM模式两种实现方式。


<details>
  <summary>Details</summary>
Motivation: 现有心理咨询LLM模型通常不显式建模咨询者在多轮对话中的情绪变化，这是传统心理学流派的核心关注点。同时，如何使咨询师模型的回应与这些情绪变化对齐，并主动缓解安全风险，仍未被充分探索。

Method: 提出PsychēChat系统，通过交互式角色扮演合成咨询师-求助者对话，包含两个核心模块：情绪管理模块（捕捉当前情绪和情绪变化）和风险控制模块（预测后续反应和识别潜在风险）。提供两种建模范式：多智能体协作管道（Agent Mode）和端到端思维链统一推理（LLM Mode）。

Result: 通过交互式评分、对话级评估和人工评估等广泛实验，PsychēChat在情感洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过显式整合情绪变化追踪和安全风险分析，为心理咨询LLM提供了更有效的解决方案，在情感洞察和安全控制方面表现出色。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [492] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: LLMs在知识状态追踪和估计任务上表现接近随机水平，远低于人类表现，未来研究应更重视知识估计和意图理解能力


<details>
  <summary>Details</summary>
Motivation: 认知人类学认为人类智能的关键在于推断他人知识状态和理解意图的能力，而黑猩猩等动物缺乏这种能力。本研究旨在评估LLM在知识状态追踪和估计方面的表现。

Method: 设计两个任务：1) 检测故事角色通过行动展示本不应拥有的知识；2) 基于角色自身知识（而非客观真相）预测角色下一步行动。

Result: 当前最先进的LLM在两个任务上都表现出接近随机的性能水平，显著低于人类表现。

Conclusion: 未来LLM研究应更加重视知识估计和意图理解能力的开发，这是人类智能区别于动物的关键能力。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [493] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 该论文研究了LLM在OWL本体论中生成证明的能力，开发了自动化数据集构建和评估框架，发现逻辑复杂性是影响性能的主要因素，而非表示格式。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM的推理能力已被广泛研究，但它们在生成忠实、可读的证明（解释结论如何推导）方面的能力仍未被充分探索，特别是在OWL本体论这种复杂知识表示和推理的背景下。

Method: 开发了自动化数据集构建和评估框架，评估三个顺序任务：提取、简化和解释，以及评估前提逻辑完整性的额外任务。在广泛使用的推理LLM上进行了大量实验。

Result: 1) 某些模型整体表现良好但在复杂案例上仍有局限；2) 逻辑复杂性（而非表示格式）是影响LLM性能的主要因素；3) 输入数据中的噪声和不完整性显著降低LLM性能。

Conclusion: LLM在严格逻辑解释方面具有潜力，但在支持复杂或不完美条件下的弹性推理方面仍存在差距。代码和数据已开源。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [494] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: LLMs在多跳推理中存在位置偏见，导致忽略某些位置信息。研究发现多跳推理性能受最不可见证据限制，失败由绝对位置而非事实间距离决定。注意力引导可解决识别瓶颈，而"思考"模型能有效定位和整合信息。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs具有大规模上下文窗口，但在多跳推理中存在位置偏见，导致忽略某些位置信息。不清楚这些失败是由于无法定位证据（识别失败）还是无法整合证据（合成失败）。需要分离这些机制来理解LLMs的推理限制。

Method: 引入多焦点注意力指导（MFAI）作为语义探针，通过显式引导注意力到选定位置来分离识别和合成机制。在5个LLMs上测试两个多跳QA任务（MuSiQue和NeoQA），分析位置偏见的影响。

Result: 建立了"最弱环节定律"：多跳推理性能崩溃到最不可见证据的性能水平。失败由绝对位置而非事实间线性距离决定（性能方差<3%）。匹配的MFAI可解决识别瓶颈，在低可见性位置提高准确率达11.5%。"思考"模型能有效定位和整合信息，在嘈杂长上下文设置中匹配黄金基线。

Conclusion: LLMs的多跳推理失败主要由位置偏见导致的识别失败引起，而非合成失败。注意力引导可缓解识别瓶颈，而系统2推理模型能有效处理多跳推理任务。绝对位置而非相对距离是影响性能的关键因素。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [495] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 该综述将智能体推理组织为三个互补维度：基础智能体推理（单智能体能力）、自进化智能体推理（通过反馈和记忆进行优化）和集体多智能体推理（协作环境），区分上下文推理与训练后推理，并回顾了实际应用和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在封闭环境中表现出强大的推理能力，但在开放动态环境中表现不佳。智能体推理通过将LLMs重构为能够规划、行动和持续学习的自主智能体，实现了范式转变，旨在解决LLMs在开放世界环境中的局限性。

Method: 该综述采用三维度组织框架：1) 基础智能体推理（单智能体在稳定环境中的规划、工具使用和搜索）；2) 自进化智能体推理（通过反馈、记忆和适应优化能力）；3) 集体多智能体推理（协作环境中的协调、知识共享和共同目标）。同时区分上下文推理（通过结构化编排扩展测试时交互）和训练后推理（通过强化学习和监督微调优化行为）。

Result: 综述系统性地回顾了智能体推理的代表性框架，涵盖了科学、机器人、医疗、自主研究和数学等实际应用和基准测试，将智能体推理方法综合成一个连接思维与行动的统一路线图。

Conclusion: 智能体推理代表了连接思维与行动的重要范式转变，为开放动态环境中的推理提供了系统框架。未来挑战包括个性化、长时程交互、世界建模、可扩展的多智能体训练以及实际部署的治理问题。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [496] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: 提出了MemeLens，一个统一的多语言多任务解释增强视觉语言模型，用于理解网络表情包，整合了38个公共数据集并映射到20个任务的共享分类法中。


<details>
  <summary>Details</summary>
Motivation: 现有表情包研究分散在不同任务（仇恨、厌女、宣传、情感、幽默）和语言中，限制了跨领域泛化能力，需要统一框架来解决这一差距。

Method: 整合38个公共表情包数据集，将数据集特定标签过滤并映射到包含20个任务的共享分类法中，涵盖危害、目标、比喻/语用意图和情感等维度，构建统一的多语言多任务解释增强视觉语言模型。

Result: 实证分析表明：1）稳健的表情包理解需要多模态训练；2）不同语义类别间存在显著差异；3）在单个数据集上微调而非统一训练时容易过度专业化。

Conclusion: MemeLens为表情包理解提供了统一框架，揭示了多模态训练的重要性，并展示了统一训练相对于数据集特定微调的优势，将为社区提供实验资源和数据集。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [497] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research是一个多智能体系统，能够在几分钟内完成交互式科学研究，相比传统批处理模式大幅缩短研究周期，在计算生物学基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统大多是专有的，且采用批处理模式需要数小时的研究周期，无法实现实时研究者指导，限制了AI在科学研究中的交互性和实用性。

Method: 采用多智能体架构，包含规划、数据分析、文献搜索和新颖性检测等专门智能体，通过持久世界状态维护跨迭代研究周期的上下文，支持半自主（带人工检查点）和全自主两种工作模式。

Result: 在BixBench计算生物学基准测试中取得最先进性能：开放回答准确率48.8%，多项选择题准确率64.5%，比现有基线高出14-26个百分点。

Conclusion: Deep Research系统实现了分钟级的交互式科学研究，显著提升了AI辅助科学工作流的效率，同时分析了开放获取文献限制和自动新颖性评估等实际部署挑战。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [498] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 临床AI应从预测引擎转向序贯控制问题，采用稳健的序数决策规则而非基数优化，以匹配临床推理的快速节俭启发式特点。


<details>
  <summary>Details</summary>
Motivation: 当前临床AI系统主要作为预测引擎（产生标签或风险评分），但真实临床推理是时间受限、序贯的控制问题，涉及不确定性下的信息收集与不可逆行动。临床医生依赖快速节俭的词典式启发式（如快速节俭树），而非基数优化。

Method: 提出临床AI应与医生对齐的蓝图：使用丰富模型进行信念和轨迹建模，但通过稳健的序数规则选择行动；将启发式视为低维特例；将AI部署为"选择性复杂性"——主要在决策脆弱且信息具有正期望影响时用于打破平局。

Result: 为快速节俭启发式提供了规范性理由：1) 临床权衡主要通过人类判断构建，仅在绝对尺度上弱可测，只有排序是不变的；2) 偏好和信号获取结构粗糙，存在持续不确定性下限，当这种"粗糙性"超过决策边际时，期望效用优化变得脆弱，而稳健的支配/过滤规则能稳定决策。

Conclusion: 临床AI应采用序数优先立场，将AI作为选择性复杂性工具，在决策脆弱时介入，而非全面替代临床启发式推理。这能更好地匹配医疗决策的现实约束和不确定性特点。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [499] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 论文提出了一个统一的Agentic AI分类法，将智能体分解为感知、大脑、规划、行动、工具使用和协作六个组件，并分析了从线性推理到原生推理模型的转变趋势。


<details>
  <summary>Details</summary>
Motivation: AI正从仅生成文本的模型转向Agentic AI（智能体AI），系统作为自主实体能够感知、推理、规划和行动。然而，从简单的单循环智能体到分层多智能体系统的各种新兴设计使得这一领域难以导航，需要统一的分类框架来理解这一快速发展的领域。

Method: 论文提出一个统一的分类法，将智能体分解为六个核心组件：感知、大脑、规划、行动、工具使用和协作。使用这个框架分析从线性推理程序到原生推理时间模型的转变，以及从固定API调用到开放标准（如模型上下文协议和原生计算机使用）的过渡。同时分类智能体操作环境，并回顾当前评估实践。

Result: 建立了一个系统化的Agentic AI分类框架，能够帮助研究人员和从业者理解不同智能体架构的设计原理。识别了从线性推理到原生推理模型的重要转变趋势，以及工具使用标准化的演进。对智能体操作环境进行了分类，并总结了当前评估方法。

Conclusion: Agentic AI正在快速发展，但面临幻觉、无限循环和提示注入等挑战。需要进一步研究来构建更稳健可靠的自主系统，统一的分类框架为理解这一领域提供了基础，并指明了未来研究方向。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [500] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM：首个通过LLM从自然语言生成STEP格式CAD模型的方法，通过DFS重序列化、RAG和RL优化，显著提升几何保真度


<details>
  <summary>Details</summary>
Motivation: CAD设计对非专家门槛高，现有文本转CAD方法依赖特定内核格式，缺乏制造通用性。STEP作为广泛采用的中性边界表示格式，其图结构特性对自回归LLM构成挑战

Method: 1) 构建4万STEP-文本对数据集；2) DFS重序列化线性化交叉引用；3) CoT风格结构注释；4) 检索增强生成(RAG)监督微调；5) Chamfer距离几何奖励强化学习

Result: STEP-LLM在几何保真度上一致优于Text2CAD基线：RAG显著提升完整性和可渲染性，DFS重序列化增强整体精度，RL进一步减少几何差异

Conclusion: 证明了LLM驱动STEP模型生成的可行性，为制造领域的CAD设计民主化展示了潜力，为图结构格式的LLM处理提供了新方法

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [501] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: MedConsultBench是一个全面的医学咨询评估框架，通过覆盖完整的临床工作流程（从病史采集到随访问答）来评估在线咨询代理，使用原子信息单元（AIUs）追踪临床信息获取，并揭示了高诊断准确性背后存在的信息收集效率和用药安全缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前医学咨询代理的评估过于注重结果导向任务，忽略了端到端流程完整性和临床安全性，现有交互式基准测试往往碎片化且粗粒度，无法捕捉专业咨询所需的结构化询问逻辑和诊断严谨性。

Method: 提出MedConsultBench框架，覆盖完整的在线咨询周期（病史采集、诊断、治疗计划、随访问答）；引入原子信息单元（AIUs）在子轮次层面追踪临床信息获取；通过22个细粒度指标评估关键事实的获取方式；处理在线咨询中的不明确性和模糊性，评估不确定性感知的简洁询问；强调用药方案兼容性和处理现实处方后随访问答的能力。

Result: 对19个大型语言模型的系统评估显示，高诊断准确性往往掩盖了信息收集效率和用药安全方面的显著缺陷，揭示了理论医学知识与临床实践能力之间的关键差距。

Conclusion: MedConsultBench为将医学AI与真实世界临床护理的细微要求对齐提供了严谨的基础，强调了需要超越单纯诊断准确性来评估医学咨询代理的重要性。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [502] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 提出SpaceHMchat框架，用于卫星巨型星座时代的航天器电源系统健康管理，通过人机协作实现全回路健康管理，并在硬件真实故障注入平台上验证了优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着卫星巨型星座时代的到来，航天器数量将指数增长，而航天器电源系统作为关键子系统故障率高，需要适应从几十个到数千个电源系统的健康管理范式转变。

Method: 提出对齐底层能力原则，开发开源人机协作框架SpaceHMchat，实现工作状态识别、异常检测、故障定位和维护决策的全回路管理，并建立硬件真实故障注入实验平台和仿真模型。

Result: SpaceHMchat在23个量化指标上表现优异：工作状态识别逻辑推理结论准确率100%，异常检测工具调用成功率超99%，故障定位精度超90%，维护决策知识库搜索时间低于3分钟。同时发布了首个航天器电源系统全回路健康管理数据集。

Conclusion: 该研究为卫星巨型星座时代的航天器电源系统健康管理提供了有效解决方案，通过人机协作框架实现了高效、透明的健康管理，相关平台和数据集的开源将推动该领域发展。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [503] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 提出MMSI框架，将量刑逻辑融入Transformer编码器，通过定向掩码机制澄清多被告案件中的角色，提高AI辅助司法分析的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多被告案件中责任分配复杂，司法表述常模糊被告角色，阻碍AI分析。需要精确区分主从犯责任，提升智能司法系统的准确性和法律可解释性。

Method: 提出掩码多阶段推理（MMSI）框架：1）将量刑逻辑融入预训练Transformer编码器；2）定向掩码机制澄清被告角色；3）比较数据构建策略增强模型对主从犯责任差异的敏感性；4）通过广播将预测的罪名标签融入回归模型，整合犯罪描述和法庭观点。

Result: 在自定义的IMLJP故意伤害案件数据集上评估，MMSI框架在角色责任区分方面取得显著准确率提升，优于基线方法。

Conclusion: 该工作为增强智能司法系统提供了稳健解决方案，能有效澄清多被告案件中的角色责任，提高AI辅助分析的准确性和法律可解释性，代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [504] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 提出神经符号LoRA框架，动态结合参数微调（数值更新）和符号编辑（符号更新），在保持内存效率的同时提升语言模型适应能力


<details>
  <summary>Details</summary>
Motivation: 现有方法中，数值微调擅长注入新事实知识，符号更新能灵活控制风格和对齐而无需重新训练，但两者各有局限。需要结合这两种互补策略以获得更好的适应性和性能。

Method: 提出神经符号LoRA框架：1）统一监控信号和基于奖励的分类器，决定何时使用LoRA进行深度事实重构，何时应用TextGrad进行标记级编辑；2）将符号转换卸载到外部LLM以保持内存效率；3）符号编辑过程中生成的精炼提示可作为高质量可重用训练数据。

Result: 在多个LLM骨干上的广泛实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出卓越的适应性和改进的性能。

Conclusion: 交错使用数值和符号更新能够解锁语言模型微调的新水平灵活性，为数据稀缺领域（如数学推理）提供重要价值。

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [505] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 提出SCFT和RLERR方法解决大型推理模型的表面反思问题，通过自我批判微调和强化学习提升反思质量与推理准确性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中常进行自我反思，但许多反思是表面的，无法改善原始答案却增加计算开销，需要解决表面反思问题

Method: 1. SCFT：自我批判微调框架，让模型批判自身输出，通过拒绝采样筛选高质量批判，使用批判目标微调模型；2. RLERR：基于SCFT初始化高质量反思构建奖励信号，通过强化学习内化自我纠正过程

Result: 在AIME2024和AIME2025基准测试中，SCFT和RLERR显著提高了推理准确性和反思质量，优于最先进的基线方法

Conclusion: 提出的SCFT和RLERR方法有效解决了大型推理模型的表面反思问题，通过增强自我批判能力和内化纠正过程，提升了模型的推理性能

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [506] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 本文提出了IntentOpt基准测试，评估视觉语言模型从网络草图生成优化代码的能力，发现视觉参数提取会降低执行成功率，开源模型表现落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 意图驱动网络允许操作员指定高级网络目标，但现有系统假设基于文本的意图表达，而网络从业者通常通过图表进行推理。目前尚不清楚视觉语言模型能否将带注释的网络草图处理成正确的优化代码。

Method: 提出了IntentOpt基准测试，包含85个优化问题和17个类别，评估了四种视觉语言模型（GPT-5-Mini、Claude-Haiku-4.5、Gemini-2.5-Flash、Llama-3.2-11B-Vision）在三种提示策略下的表现，比较了多模态与纯文本输入的差异。

Result: 视觉参数提取使执行成功率降低12-21个百分点（GPT-5-Mini从93%降至72%）；思维程序提示使性能下降最多13个百分点；开源模型表现落后（Llama-3.2-11B-Vision仅18%，而GPT-5-Mini为75%）。

Conclusion: 研究建立了当前视觉语言模型在意图驱动网络系统中生成优化代码的基准能力和局限性，并通过案例研究展示了使用模型上下文协议将VLM生成代码部署到网络测试床基础设施的实际可行性。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [507] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过集成轻量级验证器到神经符号推理步骤中，解决了现有REC方法中的级联错误问题，在目标存在和不存在场景下都实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号REC方法虽然实现了可解释推理和强大的零样本泛化能力，但假设中间推理步骤都是准确的。这种假设导致级联错误：错误检测和无效关系在推理链中传播，即使图像中没有目标也会产生高置信度的误报。

Method: 提出了验证集成推理算子（VIRO）框架，在推理步骤中嵌入轻量级的算子级验证器。每个算子执行并验证其输出（如对象存在性或空间关系），当验证条件不满足时，系统能够鲁棒地处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现了最先进的性能。此外，VIRO在吞吐量方面表现出优越的计算效率，程序失败率低于0.3%，并通过解耦程序生成和执行实现了可扩展性。

Conclusion: VIRO框架通过集成验证机制有效解决了神经符号REC方法中的级联错误问题，在性能、可靠性、效率和可扩展性方面都表现出色，并能泛化到真实世界的自我中心数据。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [508] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM通过引入语义局部性增强概念瓶颈模型，生成空间一致的概念和类别显著性图，提高局部忠实度和解释质量，同时保持分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）存在局部忠实度不足的问题，无法将概念与有意义的图像区域进行空间对齐，这限制了其可解释性和可靠性。

Method: 提出SL-CBM，通过集成1x1卷积层和交叉注意力机制，在概念和类别层面生成空间一致的显著性图，增强概念、图像区域和最终预测之间的对齐。

Result: 在图像数据集上的实验表明，SL-CBM显著提高了局部忠实度、解释质量和干预效果，同时保持了有竞争力的分类准确性。

Conclusion: SL-CBM弥合了基于概念的推理和空间可解释性之间的差距，为可解释和可信赖的概念模型设定了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [509] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard是一个即插即用的防御框架，通过模拟训练提升计算机使用代理的安全性，在保持代理实用性的同时显著降低安全风险。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成的计算机使用代理能够通过GUI自主与操作系统交互，但恶意指令或视觉提示注入会触发不安全推理，导致有害的系统级操作。现有防御方法（如基于检测的阻断）虽然能防止损害，但通常会过早终止任务，降低了代理的实用性。

Method: 提出神经符号模拟管道，在纯文本模拟环境中生成真实的高风险GUI交互轨迹，捕获不安全推理模式和潜在系统危险，而无需执行真实操作。在模拟环境中，MirrorGuard学习在CUA产生和执行不安全操作之前拦截和纠正其不安全推理链。

Result: 在字节跳动UI-TARS系统上，MirrorGuard将不安全率从66.5%降至13.0%，同时保持较低的误拒率（FRR）。相比之下，最先进的GuardAgent仅降至53.9%，且误拒率高15.4%。在多样化基准测试和CUA架构上的广泛评估显示，MirrorGuard显著减轻了安全风险。

Conclusion: 模拟衍生的防御方法能够在保持代理基本实用性的同时，提供强大的现实世界保护。MirrorGuard证明了通过模拟训练可以有效提升计算机使用代理的安全性。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [510] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: SCULPT：一种约束引导的蒙特卡洛树搜索方法，通过领域感知评分和剪枝来提升LLM代理工作流的推理稳定性


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理工作流中的搜索策略依赖随机探索，经常遍历不合理分支，因为现有方法使用通用提示或弱领域先验的策略来采样候选步骤，导致在操作符、单位和格式上的近似随机游走

Method: SCULPT将领域感知评分集成到MCTS的选择、扩展、模拟和反向传播阶段，使用符号检查（维度一致性、类型兼容性、幅度合理性、深度控制和多样性）和结构模式指导来评分和剪枝动作

Result: 在匹配的LLM配置下，SCULPT在多个数据集上带来稳定改进；使用GPT-5.2的额外结果评估了执行器可迁移性和前沿推理模型的性能

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [511] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 提出一个从公开登革热病例数据中挖掘城市区域间潜在传播链的新框架，用于预测传播风险并解释城市范围内的传播模式


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战，需要预测传播风险以进行主动干预而非被动应对。现有方法通常将病例视为孤立报告，未能捕捉区域间的传播动态。

Method: 通过梯度下降优化从病例数据中学习隐藏的传播网络，将热点形成建模为受邻近区域流行病动态影响的过程。使用连续四周的热点历史数据，并验证推断网络在连续周间的稳定性。

Result: 在新加坡2013-2018和2020年的案例研究中，仅需四周热点历史数据即可达到平均F-score 0.79。学习到的传播链与通勤流高度一致，揭示了隐藏的流行病传播与人类移动之间的可解释关系。

Conclusion: 该框架将公开的病例数据转化为预测性和解释性资源，通过挖掘和验证隐藏的传播动态，为公共卫生规划、早期干预和城市韧性提供了可扩展的低成本工具。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [512] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: 本文提出了一种基于答案集编程和转移系统的行动语言C-MT，用于形式化建模人类心理状态（如情绪）在可观察行动序列下的演化过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法在控制智能体行为和限制行动对心理状态的不良副作用方面存在不足。需要一种能够形式化心理状态动态变化、支持受控推理的框架，特别是基于心理学理论（如情绪评价理论）来建模心理状态的多维配置。

Method: 在答案集编程和转移系统基础上构建C-MT语言，引入"forbids to cause"因果规则和专门的心理状态动态表达式。将心理变化原则转化为转移约束和不变性属性，使用转移系统中的轨迹进行严格评估。

Result: C-MT语言能够对心理状态的动态演化进行受控推理，支持通过分析遵循不同心理学原则的轨迹来比较不同的变化动态。该框架已应用于情绪验证模型的设计。

Conclusion: C-MT语言为形式化建模人类心理状态演化提供了有效框架，特别适用于情绪验证等应用场景，能够基于心理学理论对心理状态变化进行受控推理和比较分析。

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [513] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 论文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性，无法推导出具体的建模和推理规则。作者提出基于对称性的可操作定义，并假设四种对称性足以解决可解释性的核心问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI可解释性研究面临根本性挑战，因为现有的可解释性定义缺乏可操作性。这些定义未能提供形式化原则，无法从中推导出具体的建模和推理规则，导致该领域研究基础不牢固。

Method: 作者提出基于对称性的可操作定义方法。假设四种对称性足以：(1) 激发核心可解释性属性，(2) 刻画可解释模型的类别，(3) 推导统一的可解释推理公式（如对齐、干预和反事实），将其视为贝叶斯逆问题。

Result: 论文提出了一个基于对称性的可解释性理论框架，该框架能够为可解释性提供可操作的定义，统一处理对齐、干预和反事实等推理任务，并将其形式化为贝叶斯逆问题。

Conclusion: 通过引入对称性作为可解释性的基础，可以解决当前AI可解释性研究的根本问题，为构建可操作的、形式化的可解释性理论提供新途径，从而推动该领域的实质性进展。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [514] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS是一个多智能体奖励模型系统，用于自动化评估GUI智能体轨迹、提供纠正反馈并实现自我进化学习，通过结合领域特定和通用奖励模型来提升GUI任务的执行准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前GUI智能体面临两大挑战：自动化评估智能体轨迹的困难，以及大规模生成高质量训练数据以实现持续改进的难题。现有方法依赖人工标注或静态规则验证，限制了可扩展性和在动态环境中的适应性。

Method: 提出MagicGUI-RMS多智能体奖励模型系统，整合领域特定奖励模型（DS-RM）和通用奖励模型（GP-RM），实现细粒度动作评估和跨异构GUI任务的鲁棒泛化。设计了结构化数据构建管道，自动生成平衡多样的奖励数据集，降低标注成本。系统通过自动化数据回流机制识别错误动作、提出改进方案并持续增强智能体行为。

Result: 大量实验表明，MagicGUI-RMS在任务准确性和行为鲁棒性方面取得了显著提升。该系统为构建基于奖励适应的自我改进GUI智能体提供了原则性且有效的基础。

Conclusion: MagicGUI-RMS通过多智能体奖励模型系统解决了GUI智能体评估和训练数据生成的挑战，实现了自适应轨迹评估、纠正反馈和自我进化学习能力，为构建自我改进的GUI智能体提供了有效解决方案。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [515] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 论文分析了通用AI系统的风险，提出其高自由度输出导致传统负责任AI原则难以适用，需要基于C2V2（控制、一致性、价值、真实性）框架重新思考通用AI的负责任设计。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统虽然功能强大，但在幻觉、毒性、偏见等方面存在风险，使得它们不可信。传统针对特定任务AI的负责任AI原则（公平性、隐私、可解释性等）在通用AI系统中难以适用或缓解，需要重新思考通用AI的负责任设计方法。

Method: 论文通过对比分析通用AI与传统特定任务AI在八个负责任AI原则上的差异，识别通用AI的高自由度输出特性是根本问题。基于此提出C2V2（控制、一致性、价值、真实性）设计原则，并分析现有技术（AI对齐、检索增强生成、推理增强等）如何满足这些原则。

Result: 研究发现通用AI由于输出自由度极高，导致传统负责任AI原则难以有效实施。提出的C2V2框架为通用AI的负责任设计提供了新方向，现有技术只能部分满足这些要求，需要系统设计方法结合多种技术。

Conclusion: 开发负责任的通用AI需要基于C2V2维度形式化建模应用或领域相关的负责任AI要求，采用系统设计方法结合多种技术来满足这些要求，这是实现通用AI负责任发展的可行路径。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [516] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了TIVS评估框架，提出TIVS-O系统，通过语义缓存和可观测性评分来平衡多智能体LLM的安全性与透明度，实现零高风险漏洞同时降低41.6%的LLM调用。


<details>
  <summary>Details</summary>
Motivation: 提示注入仍然是LLM安全部署的主要障碍，特别是在多智能体环境中，中间输出可能传播或放大恶意指令。现有评估框架需要扩展以同时考虑安全性和可审计性。

Method: 提出TIVS-O系统，结合语义相似性缓存和第五个指标（可观测性评分比），在HOPE启发的嵌套学习架构中实现。系统包含智能体管道和连续内存系统，使用301个合成生成的注入提示进行测试，第四个智能体使用五个关键性能指标进行安全分析。

Result: 系统实现零高风险漏洞的安全响应，语义缓存显著减少41.6%的LLM调用，相应降低延迟、能耗和碳排放。五种TIVS-O配置揭示了缓解严格性与取证透明度之间的最佳权衡。

Conclusion: 可观测性感知评估能揭示多智能体管道中的非单调效应，内存增强智能体可同时最大化安全鲁棒性、实时性能、运营成本节约和环境可持续性，为安全和绿色LLM部署提供生产就绪路径。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [517] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: 研究发现LLMs在实时谈判中缺乏时间意识，当提供剩余时间信息时交易成功率大幅提升，表明LLMs难以内部追踪时间流逝


<details>
  <summary>Details</summary>
Motivation: 现实世界沟通（如治疗会话、商业谈判）依赖于连续时间约束，但当前LLM架构和评估协议很少测试实时截止时间下的时间意识

Method: 使用模拟谈判实验，配对智能体在严格截止时间下进行谈判。设置控制条件（仅知全局时间限制）和时间感知条件（每回合接收剩余时间更新），比较不同条件下的表现

Result: 时间感知条件下交易关闭率显著提高（GPT-5.1：32% vs 4%），报价接受率提高六倍。但在回合制限制下，相同LLMs能达到接近完美的交易关闭率（≥95%）

Conclusion: LLMs存在系统性时间意识缺乏，这限制了它们在许多时间敏感应用中的部署。失败原因在于时间追踪而非战略推理能力

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [518] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: 提出RAG方法，基于随机森林的生成式设计框架，用于高效逆设计具有功能响应的超材料


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理功能响应的逆设计，因为功能响应是高维连续函数，存在解不存在或不唯一的问题。生成式方法通常需要大量数据，且缺乏不确定性量化

Method: RAG（随机森林生成方法）：利用随机森林的小数据兼容性预测高维功能响应；通过集成估计似然来量化生成设计的可信度；通过条件似然采样处理一对多映射问题

Result: 在声学超材料（500样本）和力学超材料（1057样本）上验证成功；在公开数据集上相比神经网络展现出数据效率优势

Conclusion: RAG提供了一个轻量级、可信赖的逆设计框架，适用于功能响应、昂贵模拟和复杂设计要求的场景，可扩展到超材料以外的领域

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [519] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: CURE-MED框架通过课程式强化学习提升LLMs在多语言医疗推理中的表现，使用CUREMED-BENCH数据集在13种语言上验证，显著提高了语言一致性和逻辑正确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了在多语言医疗环境中的部署应用。

Method: 提出CURE-MED框架：1）引入CUREMED-BENCH多语言医疗推理数据集；2）采用课程式强化学习，结合代码切换感知的监督微调和组相对策略优化，共同提升逻辑正确性和语言稳定性。

Result: 在13种语言上，7B参数模型达到85.21%语言一致性和54.35%逻辑正确性；32B参数模型达到94.96%语言一致性和70.04%逻辑正确性，显著优于基线方法。

Conclusion: CURE-MED框架有效提升了LLMs在多语言医疗推理中的可靠性和公平性，支持在多语言医疗环境中的实际应用。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [520] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 提出多智能体精炼框架，通过迭代对齐提升医疗大语言模型的安全性和可靠性，结合生成模型和评估智能体，显著减少伦理违规和风险等级。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域应用日益广泛，但确保其伦理完整性和安全合规性仍是临床部署的主要障碍，需要开发有效的安全治理方法。

Method: 使用多智能体精炼框架，结合DeepSeek R1和Med-PaLM两个生成模型，以及LLaMA 3.1和Phi-4两个评估智能体，基于美国医学会医学伦理原则和五级安全风险评估协议，对900个临床多样化查询进行结构化迭代对齐。

Result: DeepSeek R1收敛更快（平均2.34 vs 2.67次迭代），Med-PaLM在隐私敏感场景处理更优。多智能体迭代循环使伦理违规减少89%，风险降级率达92%。

Conclusion: 该研究提出了一种可扩展、符合监管要求且成本效益高的医疗AI安全治理范式，为临床部署提供了有效的安全增强方法。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [521] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一个直接从蛋白质嵌入模型的连续潜空间生成肽结合剂序列的方法，无需结构预测，提高了序列多样性


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法依赖中间结构预测，增加了复杂性并限制了序列多样性，需要一种更直接、多样化的生成方法

Method: 使用预训练蛋白质嵌入模型的连续潜空间，通过潜空间探索和基于扩散的采样，直接生成结合剂序列，无需结构预测

Result: 在TIGIT（具有大而平坦的蛋白质-蛋白质相互作用界面）的案例研究中，PepEDiff超越了现有最先进方法，展示了其作为零样本肽结合剂设计的通用框架潜力

Conclusion: PepEDiff提供了一个简单但有效的结构无关框架，用于零样本肽结合剂设计，能够生成超出已知结合剂分布的新颖序列

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [522] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 研究发现模型规模扩张不会均匀提升推理能力，而是重构推理过程。通过分析25,000+思维链轨迹，发现神经缩放定律触发领域特定的相变：法律推理呈现"结晶化"，科学和数学推理保持"液态"，代码推理形成"晶格"结构。几何结构可预测学习性，并可用于推理加速。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为模型规模扩张会均匀提升推理能力，但本研究旨在探索规模扩张如何真正影响不同领域的推理过程，揭示其内在的几何结构变化规律。

Method: 分析25,000+思维链轨迹，涵盖法律、科学、代码、数学四个领域，使用8B和70B两种参数规模的模型。引入神经推理算子（Neural Reasoning Operators）作为从初始到最终隐藏状态的映射，并分析轨迹的几何特性如维度、对齐度、流形解缠等。

Result: 发现三种不同的推理几何模式：法律推理呈现结晶化（维度下降45%，轨迹对齐度提升31%，流形解缠10倍）；科学和数学推理保持液态（几何不变）；代码推理形成晶格结构（轮廓系数从0.13提升到0.42）。神经推理算子在法律推理上达到63.6%的准确率，并发现跨领域和规模的通用振荡特征（相干性约-0.4）。

Conclusion: 推理成本由流形几何而非任务难度决定，这为在拓扑允许的情况下加速推理提供了蓝图。不同领域的推理过程在规模扩张下经历不同的相变，而非均匀的能力提升。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [523] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge是一个轻量级开源Python框架，通过模块化架构简化LLM驱动的自主智能体开发，提供可组合技能、统一LLM后端接口和声明式配置系统，显著减少开发时间。


<details>
  <summary>Details</summary>
Motivation: 现有智能体框架存在架构僵化、供应商锁定和复杂性过高的问题，阻碍了快速原型设计和部署。需要一种能够民主化LLM驱动自主智能体构建的解决方案。

Method: 采用模块化架构设计，包含三个核心创新：1) 可组合技能抽象，支持细粒度任务分解和形式化输入输出契约；2) 统一LLM后端接口，支持云端API和本地推理引擎无缝切换；3) 基于YAML的声明式配置系统，分离智能体逻辑与实现细节。将技能组合机制形式化为有向无环图(DAG)。

Result: 在四个基准场景的全面实验评估中，AgentForge实现了竞争力的任务完成率，同时相比LangChain减少62%开发时间，相比直接API集成减少78%开发时间。编排延迟低于100ms，适合实时应用。框架集成了六个内置技能，并提供自定义技能开发的完整文档。

Conclusion: AgentForge填补了LLM智能体生态系统的关键空白，为研究人员和从业者提供了生产就绪的基础设施，用于构建、评估和部署自主智能体，同时不牺牲灵活性或性能。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [524] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: 论文提出"显式认知分配"原则和认知通用代理架构，通过分离和编排认知功能来结构化AI辅助推理，相比传统LLM推理具有更好的可追溯性、认知控制和可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM使用模式存在认知结构缺失问题：问题框架、知识探索、检索、方法意识和解释通常被压缩到单一生成过程中。这种认知崩溃限制了可追溯性，削弱了认知控制，并损害了可重复性，特别是在高责任环境中。

Method: 提出显式认知分配原则，并实例化为认知通用代理架构。该架构将推理组织为探索与框架、认知锚定、工具与方法映射、解释性合成等不同阶段。核心概念是通用认知工具，形式化各种手段（计算、实验、组织、监管、教育工具），使抽象查询变得可研究。

Result: 在农业领域的多个提示下，CUA编排的推理表现出更早且结构化的认知收敛、语义扩展下更高的认知对齐，以及系统性地暴露查询的工具性景观。相比之下，基线LLM推理在对齐方面表现出更大的变异性，且未能明确展现工具结构。

Conclusion: 显式认知和工具分配能够显著改善AI辅助推理的结构化程度，增强认知控制、可追溯性和可重复性，特别是在需要高责任性的科学、技术和组织领域。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [525] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: SpatialBench-UC：一个用于评估文本到图像模型空间关系理解能力的小型可复现基准，包含200个提示和100个反事实对，通过选择性预测方法报告通过率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 评估文本到图像模型是否遵循明确的空间指令难以自动化，因为对象检测器可能漏检或返回多个检测结果，简单的几何测试在边界情况下变得模糊。空间评估本质上是一个选择性预测问题。

Method: 提出SpatialBench-UC基准，包含200个提示（50个对象对×4种关系），分组为100个反事实对。发布包含版本化提示、固定配置、每样本检查器输出的基准包，并采用轻量级人工审核来校准检查器的弃权边界和置信度阈值。

Result: 评估了三个基线模型：Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN。结果显示，基础方法显著提高了通过率和覆盖率，但弃权仍然是主要因素，主要是由于检测缺失。

Conclusion: SpatialBench-UC提供了一个可复现、可审计的基准，用于评估文本到图像模型的空间关系理解能力。选择性预测方法允许检查器在证据不足时弃权，并以风险覆盖权衡而非单一分数来报告结果。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [526] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 提出基于上下文的音频深度伪造检测器CADD，通过结合上下文信息和转录文本，显著提升检测性能，并对抗攻击更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 人类利用上下文判断信息真伪，但现有音频深度伪造检测器仅分析音频文件，忽略了上下文和转录文本的重要信息。

Method: 创建记者提供的深度伪造数据集JDD和合成音频数据集SYN，提出CADD架构，利用上下文和转录文本增强检测能力，在多个数据集上评估性能。

Result: 上下文和转录文本显著提升检测性能：F1分数提高5%-37.58%，AUC提高3.77%-42.79%，EER降低6.17%-47.83%。CADD对5种对抗攻击策略更具鲁棒性，平均性能下降仅-0.71%。

Conclusion: 上下文和转录文本对音频深度伪造检测至关重要，CADD架构通过整合这些信息显著提升检测性能和对抗鲁棒性，为实际应用提供了有效解决方案。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [527] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 单个训练轨迹可将图神经网络转化为组合优化的无监督启发式算法，用于旅行商问题，无需搜索、监督或序列决策


<details>
  <summary>Details</summary>
Motivation: 探索图神经网络是否能在无监督、无搜索的情况下直接作为组合优化的启发式算法，重新定义学习在组合优化中的作用

Method: 将全局结构约束编码为归纳偏置，使非自回归模型通过前向传播直接生成解；推理时使用dropout和快照集成作为隐式集成，增加解多样性

Result: 图神经网络无需监督训练或显式搜索即可有效工作，能够内化全局组合结构并作为强大的学习启发式算法

Conclusion: 学习在组合优化中的作用应从增强经典算法转变为直接实例化新的启发式算法

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [528] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个用于精神健康领域情感诊断的自动提示优化框架，通过多智能体协作机制探索更精细的提示空间，解决情感共病和临床线索挖掘不足的挑战。


<details>
  <summary>Details</summary>
Motivation: 在临床记录、咨询对话和在线心理健康社区中，抑郁、焦虑和创伤相关状态的情感表达普遍存在，准确识别这些情感对于临床分诊、风险评估和及时干预至关重要。尽管大语言模型在情感分析任务中表现出强大的泛化能力，但在高风险、上下文密集的医疗环境中，其诊断可靠性对提示设计高度敏感。现有方法面临两个关键挑战：情感共病（多种交织的情感状态使预测复杂化）和对临床相关线索的低效探索。

Method: 提出APOLO框架，将指令优化建模为部分可观测马尔可夫决策过程，采用多智能体协作机制，包括规划者、教师、批评者、学生和目标角色。规划者定义优化轨迹，教师-批评者-学生智能体迭代优化提示以增强推理稳定性和有效性，目标智能体根据性能评估决定是否继续优化。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中持续提高诊断准确性和鲁棒性，展示了在精神健康护理中可信赖大语言模型应用的可扩展和可泛化范式。

Conclusion: APOLO通过系统探索更广泛和更细粒度的提示空间，提高了精神健康情感诊断的效率和鲁棒性，为解决情感共病和临床线索挖掘不足的挑战提供了有效解决方案，为医疗领域可信赖的大语言模型应用提供了可扩展的范式。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [529] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed：一种利用LLM上下文学习自动设计和优化红队系统的框架，无需人工干预，通过进化选择方法在红队任务中显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有自动化红队方法依赖人工指定的工作流程，存在人类偏见且难以探索更广泛的设计空间。需要一种无需人工干预、能自动设计和优化红队系统的方法

Method: 将红队视为系统设计问题而非策略优化问题，借鉴Meta Agent Search思想，开发基于进化选择的新型程序来演化智能体系统，利用LLM的上下文学习迭代设计和改进红队系统

Result: 在Llama-2-7B上达到96%攻击成功率（提升36%），在Llama-3-8B上达到98%；在GPT-3.5-Turbo和GPT-4o-mini上达到100%攻击成功率，在Claude-Sonnet-3.5上达到60%（提升24%）

Conclusion: 自动化系统设计是AI安全评估的强大范式，能够跟上快速发展的模型步伐，AgenticRed展示了无需人工干预自动设计红队系统的可行性

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [530] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现"边推理边推荐"，动态适应列表生成中的熵变化，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式重排序方法难以适应列表生成过程中模型难度的动态熵变化，无法准确捕捉复杂偏好。受语言模型推理能力启发，需要引入推理机制来降低决策熵。

Method: 提出熵引导潜在推理(EGLR)推荐模型：1) 抛弃"先推理后推荐"范式，实现"边推理边推荐"；2) 使用上下文感知推理令牌和动态温度调整实现熵引导变长推理；3) 轻量级集成设计，无需复杂独立模块或后处理。

Result: 在两个真实世界数据集上的实验验证了模型有效性，显著优势在于能与现有生成式重排序模型兼容并提升其性能。进一步分析展示了实际部署价值和研究潜力。

Conclusion: EGLR模型通过熵引导的潜在推理机制，在生成式重排序中实现了更精确的探索-利用权衡，为动态熵变化的列表生成问题提供了有效解决方案。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [531] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor是一个新颖的、可复现的评估范式，用于评估LLMs在真实世界不确定性环境中的表现，不仅关注预测准确性，还评估校准度、漂移和风险敏感性等多维度指标。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型和AI代理的评估面临根本性挑战：静态基准无法捕捉真实世界的不确定性、分布偏移，以及孤立任务准确性与人类对齐决策之间的差距。需要一种更全面的评估方法来衡量LLMs在现实决策环境中的表现。

Method: 提出TruthTensor框架，基于前瞻性、无污染的任务，将评估锚定在实时预测市场，结合概率评分提供模型行为的整体视图。该框架包含漂移中心诊断、显式鲁棒性检查、人类与自动化评估角色划分、标注协议和统计测试程序。

Result: 在500多个真实市场（政治、经济、文化、技术）的实验中，TruthTensor显示具有相似预测准确性的模型在校准度、漂移和风险敏感性方面可能存在显著差异，强调需要从多个维度（准确性、校准度、叙事稳定性、成本和资源效率）评估模型。

Conclusion: TruthTensor将现代评估最佳实践操作化，包括清晰的假设框架、谨慎的指标选择、透明的计算/成本报告、人类在环验证和开放的版本化评估合约，为LLMs在真实世界决策环境中提供可辩护的评估。框架已公开发布。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [532] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 提出TSEvol多智能体时间序列演化算法、TSEData-20K数据集、ChatAD系列模型、TKTO优化方法和LLADBench基准测试，显著提升异常检测性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的异常检测方法存在推理能力不足、多轮对话能力欠缺、泛化能力有限等问题，需要改进

Method: 1) TSEvol多智能体时间序列演化算法；2) TSEData-20K数据集和ChatAD系列模型；3) TKTO优化增强跨任务泛化；4) LLADBench基准测试框架

Result: ChatAD模型在准确率提升34.50%、F1提升34.71%、误报率降低37.42%；TKTO优化后在分类、预测、填补等任务上具有竞争力的推理和跨任务泛化能力

Conclusion: 提出的综合方法显著提升了LLM驱动异常检测的推理能力、对话能力和泛化能力，为时间序列异常检测提供了有效解决方案

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [533] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 利用社交媒体和约会应用文本数据，通过机器学习模型预测男男性行为者的性风险行为、饮酒行为和PrEP使用情况，展示了文本数据在公共卫生干预中的潜力。


<details>
  <summary>Details</summary>
Motivation: 男男性行为者（MSM）面临性传播感染和有害饮酒的高风险，社交媒体和约会应用文本数据可能为个性化公共卫生干预提供新机会，通过自动识别风险和保护行为。

Method: 收集参与者同意的文本数据，使用ChatGPT嵌入、BERT嵌入、LIWC和基于词典的风险术语方法提取特征，训练机器学习模型预测性风险行为、饮酒行为和PrEP使用。

Result: 模型在预测每月酗酒和超过5个性伴侣方面表现优异（F1分数0.78），在预测PrEP使用和重度饮酒方面表现中等（F1分数0.64和0.63）。

Conclusion: 社交媒体和约会应用文本数据能提供有价值的风险和保护行为洞察，基于大语言模型的方法有潜力支持针对MSM的可扩展、个性化公共卫生干预。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [534] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC：首个基于智能体的进化式基因组数据压缩器，通过三层架构和多智能体系统实现用户友好、自适应的高效压缩，在压缩比和吞吐量上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的基因组数据压缩方法存在不可进化、低级压缩建模、适应性有限和用户界面不友好等问题，需要一种更智能、自适应的解决方案。

Method: 提出AgentGC三层架构：1)用户层通过Leader智能体结合LLM提供友好界面；2)认知层由Leader驱动，整合LLM实现算法-数据集-系统联合优化；3)压缩层由Worker智能体执行基于多知识学习的自动压缩框架。支持三种模式：CP（压缩比优先）、TP（吞吐量优先）、BM（平衡模式）。

Result: 在9个数据集上与14个基线方法比较：平均压缩比分别提升16.66%、16.11%、16.33%；吞吐量分别提升4.73倍、9.23倍、9.15倍。

Conclusion: AgentGC通过智能体架构和LLM集成，成功解决了现有基因组数据压缩方法的局限性，在压缩效率和吞吐量方面均实现了显著提升，为基因组数据存储和管理提供了进化式的智能解决方案。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [535] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 提出分离推理模态的假设，设计角色分离Transformer块，在ARC视觉推理任务上超越人类平均表现


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机运行，通过建模token统计来匹配可观察行为，但没有持久、可读的思维状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行为，而AI系统可以产生流利的事后合理化解释，但这些解释并不基于这样的内部状态。

Method: 提出推理应作为独立于低级工作空间的模态存在，设计了一种新颖的角色分离Transformer块，将全局控制器token与网格工作空间token分离，实现迭代规则执行。在VARC视觉中心协议下进行训练和评估。

Result: 在ARC-1任务上达到62.6%的准确率，超过了人类平均表现（60.2%），并显著优于先前的方法。定性分析显示，与密集ViT基线相比，模型展现出更一致的规则应用结构，从概率斑点向控制器驱动的推理转变。

Conclusion: 推理确实可以作为一种独立的模态存在，通过分离控制器和工作空间token的架构设计，能够实现更接近人类抽象推理的AI系统，在视觉推理任务上达到超越人类平均水平的性能。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [536] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个基于LLM的诈骗检测框架，通过犯罪脚本推理任务、数据集和认知模拟评估，显著提升小型LLM的诈骗检测性能，并在模拟实验中增强用户的防骗认知意识。


<details>
  <summary>Details</summary>
Motivation: 社交工程诈骗日益采用个性化、多轮对话的欺骗手段，传统检测方法面临局限。虽然大语言模型在识别欺骗方面有潜力，但其认知辅助能力尚未充分探索。

Method: 提出ScriptMind框架，包含三个组件：犯罪脚本推理任务（CSIT）用于诈骗推理、犯罪脚本感知推理数据集（CSID）用于微调小型LLM、认知模拟评估（CSED）用于评估实时认知影响。使用571个韩国电话诈骗案例构建了22,712个结构化诈骗序列训练实例。

Result: 经过ScriptMind微调的11B小型LLM在检测准确率上比GPT-4o高出13%，在误报减少、诈骗者话语预测和推理质量方面优于商业模型。在电话诈骗模拟实验中，显著提升并维持了用户的怀疑水平，增强了防骗认知意识。

Conclusion: ScriptMind代表了向以人为本、认知自适应的大语言模型在诈骗防御领域迈出的重要一步，展示了LLM在提升人类防骗认知能力方面的潜力。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [537] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 提出基于音频情感信号的多智能体AI系统，实时生成响应导向的媒体内容，通过安全验证确保内容适龄可控


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，但缺乏将情感状态转化为安全、适龄、可控响应内容的能力。需要一种能够实时生成响应内容并确保安全性的系统。

Method: 采用四智能体协作架构：1)基于CNN的情感识别智能体提取声学特征；2)响应策略决策智能体将情感映射到响应模式；3)内容参数生成智能体产生媒体控制参数；4)安全验证智能体强制执行适龄性和刺激约束。引入显式安全验证循环过滤生成内容。

Result: 在公共数据集上，系统达到73.2%的情感识别准确率、89.4%的响应模式一致性、100%的安全合规性，同时保持低于100ms的推理延迟，适合设备端部署。

Conclusion: 该模块化架构具有可解释性和可扩展性，适用于儿童相关媒体、治疗应用和情感响应智能设备，实现了从情感识别到安全响应内容生成的完整闭环。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [538] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: DSAEval是一个包含641个真实世界数据科学问题的基准测试，基于285个多样化数据集，涵盖结构化和非结构化数据，具有多模态环境感知、多查询交互和多维度评估三大特色。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的数据代理旨在自动化数据科学任务，但真实世界数据科学问题的开放性、多分类性和缺乏标准答案的特点给评估带来了重大挑战。

Method: 提出DSAEval基准测试，包含641个真实世界数据科学问题，基于285个多样化数据集，涵盖结构化和非结构化数据（如视觉和文本）。该基准具有三大特色：多模态环境感知、多查询交互和多维度评估。

Result: 评估了11个先进代理LLM，结果显示Claude-Sonnet-4.5整体性能最强，GPT-5.2最有效率，MiMo-V2-Flash最具成本效益。多模态感知在视觉相关任务上带来2.04%到11.30%的性能提升。

Conclusion: 当前数据科学代理在结构化数据和常规数据分析工作流上表现良好，但在非结构化领域仍面临重大挑战。研究为数据科学代理的发展提供了关键见解和未来研究方向。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [539] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 提出自适应分治算法检测自然语言事实集合的全局一致性，通过识别最小不一致子集和计算最小修复，在LLM评估器上实现可扩展的语义一致性验证


<details>
  <summary>Details</summary>
Motivation: 自然语言事实集合的全局一致性对于事实核查、摘要和知识库构建等任务至关重要。虽然大语言模型可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查无法保证全局一致性

Method: 提出自适应分治算法，识别最小不一致子集，可选地通过命中集计算最小修复。该方法具有低阶多项式查询复杂度，适用于LLM评估器

Result: 实验表明该方法在合成和真实LLM评估器上都能高效检测和定位不一致性，为基于LLM的语言一致性验证提供了可扩展框架

Conclusion: 该研究为自然语言事实集合的全局一致性验证提供了实用解决方案，通过自适应分治算法克服了指数级查询复杂度的理论障碍，实现了可扩展的语义一致性验证

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [540] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 提出RADR框架，结合时空图神经网络与组合优化，通过预测拥堵风险实现动态路径规划，在保持运输距离仅增加2.1%的情况下减少19.3%的拥堵风险暴露。


<details>
  <summary>Details</summary>
Motivation: 电商快速发展给物流网络带来巨大压力，传统静态路由策略无法应对交通拥堵和需求波动，需要更智能的动态路由方案。

Method: 1) 使用空间聚类方法从离散GPS数据构建物流拓扑图；2) 采用GCN+GRU混合深度学习模型提取时空特征预测未来拥堵风险；3) 将预测结果集成到动态边权重机制中进行路径规划。

Result: 在Smart Logistics Dataset 2024上验证，RADR算法显著提升供应链韧性。在高拥堵场景下，潜在拥堵风险暴露减少19.3%，运输距离仅增加2.1%。

Conclusion: 提出的数据驱动方法能有效平衡配送效率与运营安全，为动态物流路由提供了有效解决方案。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [541] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange是一个新的动态心理理论基准测试，要求语言模型在社交互动中主动改变他人心理状态，而不仅仅是追踪心理状态。模型扮演角色生成对话来达成目标，测试结果显示当前LLM表现比人类低54.2%。


<details>
  <summary>Details</summary>
Motivation: 现有动态心理理论基准测试大多让语言模型处于被动角色，只读取场景并报告心理状态变化。但在真实社交互动中，心理理论也被用于主动行动：说话者计划说什么来改变他人的心理状态轨迹以达到目标。

Method: 引入SocialMindChange基准测试，每个实例定义包含4个角色的社交情境和5个连接场景。模型扮演一个角色，在5个场景中生成对话以达到目标，同时保持与所有参与者不断变化的状态一致。使用结构化四步框架构建了1,200个社交情境，涵盖6,000个场景和超过90,000个问题，每个都经过真实性和质量验证。

Result: 对10个最先进的LLM进行评估，结果显示它们的平均表现比人类表现低54.2%。这个差距表明当前LLM在长期连接互动中维持和改变心理状态表征方面仍然存在困难。

Conclusion: SocialMindChange基准测试将心理理论评估从追踪心理状态扩展到改变心理状态，揭示了当前语言模型在主动社交互动中的局限性，为未来模型开发提供了重要方向。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [542] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现当前基于概率的置信度指标主要捕捉表面流畅性而非推理逻辑结构，提出新的对比因果指标能更好识别推理质量


<details>
  <summary>Details</summary>
Motivation: 挑战当前普遍假设：概率置信度指标能准确反映推理质量。研究者质疑这些指标是否真正捕捉了推理步骤间的因果依赖关系

Method: 引入三类步间因果扰动，系统性地破坏推理步骤间的依赖关系但保持局部流畅性；提出对比因果指标来显式隔离步间因果依赖

Result: 即使严重干预（如硬注意力掩码阻止模型关注先前推理步骤），选择准确率仅轻微下降，证明当前概率指标对逻辑结构不敏感

Conclusion: 当前概率指标主要捕捉表面流畅性或分布先验而非逻辑结构，提出的对比因果指标能实现更忠实的输出选择

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [543] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: 提出RELIEF框架，通过调整大推理模型的"推理信念"来塑造其行为，无需监督推理轨迹，降低训练成本


<details>
  <summary>Details</summary>
Motivation: 大推理模型存在计算冗余或推理不忠实的问题，现有方法依赖强化学习或黄金标准推理轨迹，计算成本高且难以扩展

Method: 发现LRM具有潜在的"推理信念"，可通过简单logit探测捕获。提出RELIEF框架，通过将模型自我概念与目标信念蓝图对齐来塑造行为，无需推理轨迹监督，仅需在合成的自反问答对上进行微调

Result: 在效率和忠实性任务上的实验表明，RELIEF匹配或优于行为监督和基于偏好的基线方法，同时训练成本更低。分析验证了改变模型推理信念能有效塑造其实际行为

Conclusion: RELIEF提供了一种简单有效的框架，通过调整模型内在推理信念来塑造LRM行为，无需昂贵的推理轨迹监督，具有更好的可扩展性和成本效益

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [544] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC是一个两阶段自演化解耦框架，通过难度校准问题生成和非对称自蒸馏机制，解决了自演化的优化不稳定问题，在多个推理基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有自演化框架存在优化不稳定问题：1) 提问者依赖求解器反馈的非平稳目标；2) 求解器使用自生成伪标签导致的引导误差。需要稳定自演化过程。

Method: DARC采用两阶段解耦方法：第一阶段训练提问者根据明确难度级别和外部语料合成难度校准问题；第二阶段使用非对称自蒸馏机制训练求解器，其中文档增强的教师生成高质量伪标签来监督无文档访问的学生求解器。

Result: DARC具有模型无关性，在9个推理基准和3个骨干模型上平均提升10.9个点，持续优于所有基线方法，且无需人工标注即可接近全监督模型的性能。

Conclusion: DARC通过解耦和非对称自蒸馏有效稳定了自演化过程，为自改进AI提供了实用框架，代码已开源。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [545] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: LifeAgentBench是一个大规模QA基准，用于评估LLM在长期跨维度生活方式健康推理中的能力，包含22,573个问题，并提出了LifeAgent作为强基线代理


<details>
  <summary>Details</summary>
Motivation: 个性化数字健康支持需要跨异构生活方式信号进行长期跨维度推理，但当前LLM在此场景下的能力尚不明确，缺乏系统化基准

Method: 1) 构建LifeAgentBench基准，包含22,573个从基础检索到复杂推理的问题；2) 提出可扩展的基准构建流程和标准化评估协议；3) 系统评估11个领先LLM；4) 提出LifeAgent代理，集成多步证据检索与确定性聚合

Result: 系统评估发现LLM在长期聚合和跨维度推理方面存在关键瓶颈，提出的LifeAgent代理相比两个广泛使用的基线有显著改进，案例研究展示了其在现实日常场景中的潜力

Conclusion: LifeAgentBench为评估LLM在健康助手应用中的能力提供了系统基准，LifeAgent代理展示了解决长期跨维度推理问题的有效性，为未来研究提供了基础

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [546] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: HSC是一个受人类启发的计算框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环过程，强调通过行动自动改进内部推理机制。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型仅依赖文本数据，限制了其在开放动态现实环境中的适应能力、推理结果验证和有效操作。需要更接近人类智能的计算框架。

Method: 提出人类模拟计算（HSC）框架，将智能建模为包含思考、行动、学习、反思和活动调度的连续闭环内部推理过程。强调主动参与和行动驱动的自动改进，并整合人类常用思维策略。

Result: 通过理论分析表明，人类模拟策略无法仅从语言材料中完全学习，人类式推理过程和基于行动的推理方法对于在现实环境中实现鲁棒适应和有效交互至关重要。

Conclusion: HSC框架为解决大语言模型在现实环境中的局限性提供了新方向，强调行动驱动的自动改进和人类思维策略的整合对于实现更强大的适应性智能系统具有重要意义。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [547] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低成本回顾性自标注方法，通过检测情感变化区域而非全时段标注来减轻标注负担，同时保持标注质量。


<details>
  <summary>Details</summary>
Motivation: 传统全时段情感状态标注方法耗时、认知负荷高、易疲劳且易出错，需要更高效的低成本标注方案。

Method: 基于峰终法则和情感序数表示，采用偏好学习模型检测相对情感变化，指导标注者仅标注选定片段，其余部分插值，并引入预览机制提供上下文线索。

Result: PREFAB在建模情感变化方面优于基线方法，减轻了工作负担（有条件地减轻时间负担），提高了标注者信心且未降低标注质量。

Conclusion: PREFAB是一种有效的低成本情感标注方法，通过聚焦情感变化区域而非全时段标注，在保持质量的同时显著减轻标注负担。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [548] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK是一个自适应知识图谱检索器，通过语言模型控制广度-深度权衡，使用全局搜索和邻域探索两种操作，无需依赖脆弱的种子选择或预设跳数深度，显著提升了知识图谱检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱检索方法存在局限性：基于相似性的检索器覆盖面广但深度不足，而基于遍历的方法依赖种子节点选择，当查询涉及多个实体和关系时容易失败。需要一种能自适应平衡广度搜索和深度遍历的检索方法。

Method: ARK采用代理式知识图谱检索器，让语言模型通过两种操作工具控制检索过程：1) 全局词法搜索（广度导向），2) 单跳邻域探索（深度导向）。这两种操作可以组合成多跳遍历。ARK交替使用广度发现和深度扩展，无需依赖种子选择、预设跳数深度或检索训练。

Result: 在STaRK基准测试中，ARK达到59.1%的平均Hit@1和67.4的平均MRR，比基于检索和代理式无训练方法分别提升高达31.4%的Hit@1和28.0%的MRR。通过从大型教师模型蒸馏到8B模型，在AMAZON、MAG和PRIME数据集上分别比基础8B模型提升+7.0、+26.6和+13.5个绝对百分点的Hit@1，同时保留高达98.5%的教师模型性能。

Conclusion: ARK通过自适应平衡广度搜索和深度遍历，显著提升了知识图谱检索性能，其无标签模仿蒸馏方法能有效将大型教师模型的检索能力转移到较小模型中，为知识图谱检索提供了灵活高效的解决方案。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [549] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 提出使用通用编码智能体作为形式数学推理器的新范式，通过Claude Code与Numina-Lean-MCP结合，在无需训练的情况下实现自动化的Lean交互和定理证明。


<details>
  <summary>Details</summary>
Motivation: 现有基于任务特定流水线和训练形式证明器的方法灵活性差、可复现性低。通用编码智能体能提供超越证明的多样化推理接口，仅通过替换基础模型即可提升性能，且MCP支持灵活扩展和自主调用专业工具。

Method: 提出Numina-Lean-Agent，结合Claude Code与Numina-Lean-MCP，实现与Lean的自主交互、相关定理检索、非形式化证明和辅助推理工具调用。

Result: 使用Claude Opus 4.5作为基础模型，Numina-Lean-Agent解决了Putnam 2025所有问题（12/12），达到最佳闭源系统水平。此外，成功形式化了Brascamp-Lieb定理，展示了泛化能力。

Conclusion: 通用编码智能体作为形式数学推理器是可行的新范式，Numina-Lean-Agent展示了该方法的强大性能和泛化能力，为形式化数学提供了灵活、可扩展的解决方案。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [550] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 该论文提出认知的统一框架：所有智能系统（从生物到人工）都通过两个尺度不变的原理运作——嵌入空间的重映射和在空间中的导航，通过迭代误差最小化实现。


<details>
  <summary>Details</summary>
Motivation: 动机是建立跨不同起源、组成和基质的智能系统的统一视图，从亚细胞化学网络到生物群体，涵盖进化、工程和混合系统，寻找尺度不变的决策原则。

Method: 提出认知的双重原理：1）嵌入空间的重映射（将数据/状态映射到潜在表示），2）在这些空间中的导航（通过分布式误差校正迭代优化）。生物系统和现代AI系统都体现这一机制。

Result: 论证了这一双重原理构成认知的基质独立不变性，揭示了生物系统（从单细胞到整个生物体）与人工系统（如Transformer、扩散模型、神经细胞自动机）之间的深层平行性。

Conclusion: 识别这一共享机制不仅阐明了生命系统与人工模型之间的深层相似性，还为跨尺度工程化自适应智能提供了统一框架，推动了多样化智能领域的整合视角。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [551] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent：首个多智能体框架，将反驳信生成重构为证据中心规划任务，通过分解评审意见、构建混合上下文、集成外部搜索，确保每个论点都有明确证据支撑，在覆盖度、忠实度和策略连贯性上优于基线。


<details>
  <summary>Details</summary>
Motivation: 当前反驳信生成方案通常将其视为直接文本生成问题，存在幻觉、忽略批评意见、缺乏可验证基础等问题。需要一种能精确对齐评审意图与稿件细节的解决方案。

Method: 提出RebuttalAgent多智能体框架：1) 将复杂反馈分解为原子化关注点；2) 动态构建混合上下文（压缩摘要+高保真文本）；3) 集成自主按需外部搜索模块处理需要外部文献的关切；4) 在起草前生成可检查的响应计划。

Result: 在RebuttalBench上验证，该流水线在覆盖度、忠实度和策略连贯性方面优于强基线，为同行评审过程提供了透明可控的助手。

Conclusion: RebuttalAgent通过证据中心的规划方法解决了当前反驳信生成的局限性，提供了可检查、可验证的反驳生成框架，提升了反驳信的质量和可信度。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [552] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 该论文系统综述了大型语言模型智能体系统的效率问题，从记忆、工具学习和规划三个核心组件出发，分析效率优化方法、评估指标和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向智能体系统扩展，现有研究主要关注有效性而忽视了效率，而效率对于实际部署至关重要。论文旨在填补这一空白，全面研究智能体系统本身的效率问题。

Method: 从智能体的三个核心组件（记忆、工具学习、规划）出发，综述了多种效率优化方法，包括上下文压缩管理、最小化工具调用的强化学习奖励设计、受控搜索机制等。提出通过固定成本下的有效性比较和同等有效性下的成本比较两种方式来表征效率。

Result: 系统梳理了智能体效率优化的共同原则，总结了各组件评估协议和常用效率指标，建立了效率与有效性之间的帕累托前沿分析框架，为效率导向的基准测试提供了方法论基础。

Conclusion: 智能体效率研究是实际部署的关键，论文为这一新兴领域提供了系统性的综述框架，指出了当前挑战和未来方向，为后续研究提供了重要参考。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [553] [Robustness of the Frank-Wolfe Method under Inexact Oracles and the Cost of Linear Minimization](https://arxiv.org/abs/2601.11548)
*Tao Hu*

Main category: math.OC

TL;DR: 本文研究了Frank-Wolfe方法在梯度计算不精确时的鲁棒性，证明了非凸光滑函数下收敛率为O(1/√k+δ)，并表明近似投影在计算上并不比精确线性最小化oracle更便宜。


<details>
  <summary>Details</summary>
Motivation: 研究Frank-Wolfe方法在实际应用中梯度计算不精确时的鲁棒性，以及比较线性最小化oracle(LMO)与投影的相对计算成本，这对于理解该优化框架的实际效率和稳定性很重要。

Method: 使用δ-oracle分析Frank-Wolfe方法，建立非凸光滑函数下的收敛理论，并比较LMO与投影的计算复杂度，扩展到不精确投影的情况。

Result: 证明了Frank-Wolfe在δ-oracle下具有O(1/√k+δ)的收敛率，oracle误差不会渐近累积；同时证明了近似投影在计算上并不比精确LMO更便宜。

Conclusion: Frank-Wolfe框架在梯度不精确计算下具有鲁棒性和效率，近似投影并不能提供计算优势，这加强了该优化方法的理论基础。

Abstract: We investigate the robustness of the Frank-Wolfe method when gradients are computed inexactly and examine the relative computational cost of the linear minimization oracle (LMO) versus projection. For smooth nonconvex functions, we establish a convergence guarantee of order $\mathcal{O}(1/\sqrt{k}+δ)$ for Frank-Wolfe with a $δ$--oracle. Our results strengthen previous analyses for convex objectives and show that the oracle errors do not accumulate asymptotically. We further prove that approximate projections cannot be computationally cheaper than accurate LMOs, thus extending to the case of inexact projections. These findings reinforce the robustness and efficiency of the Frank-Wolfe framework.

</details>


### [554] [Minimal Perimeter Triangle in Nonconvex Quadrilateral:Generalized Fagnano Problem](https://arxiv.org/abs/2601.11552)
*Triloki Nath,Manohar Choudhary*

Main category: math.OC

TL;DR: 本文推广了经典的Fagnano问题，研究在非凸四边形中寻找最小周长的内接三角形，并给出了几何解。同时为经典Fagnano问题建立了上界。


<details>
  <summary>Details</summary>
Motivation: 经典Fagnano问题（在锐角三角形中寻找最小周长的内接三角形）已有Fejér在1900年给出解。本文旨在将这一问题推广到非凸四边形的情况，同时为经典问题建立理论界限。

Method: 采用几何方法解决推广后的Fagnano问题：在具有一个钝角（反射角）和三个锐角的非凸四边形中，构造一个三角形，要求两个顶点分别位于不形成反射角的两条边上，第三个顶点位于形成反射角的任一边上，并寻找最小周长解。

Result: 1. 成功给出了非凸四边形中Fagnano推广问题的几何解；2. 证明了经典Fagnano问题中，内接三角形的最小周长不超过原三角形任意边长的两倍。

Conclusion: 本文成功将经典的Fagnano问题推广到非凸四边形情形，并建立了经典问题的理论上界，为几何优化问题提供了新的理论结果。

Abstract: In 1775, Fagnano introduced the following geometric optimization problem: inscribe a triangle of minimal perimeter in a given acute-angled triangle. A widely accessible solution is provided by the Hungarian mathematician L. Fejer in 1900. This paper presents a specific generalization of the classical Fagnano problem, which states that given a nonconvex quadrilateral (having one reflex angle and others are acute angles), find a triangle of minimal perimeter with exactly one vertex on each of the sides that do not form reflex angle, and the third vertex lies on either of the sides forming the reflex angle. We provide its geometric solution. Additionally, we establish an upper bound for the classic Fagnano problem, demonstrating that the minimal perimeter of the triangle inscribed in a given acute-angled triangle cannot exceed twice the length of any of its sides.

</details>


### [555] [A Generalized Waist Problem: Optimality Condition and Algorithm](https://arxiv.org/abs/2601.11554)
*Triloki Nath,Manohar Choudhary,Ram K. Pandey*

Main category: math.OC

TL;DR: 论文推广了经典的"腰围问题"，将三条线替换为多个凸集，通过闭折线连接这些凸集来最小化总距离，建立了存在性、唯一性、最优条件，并开发了计算算法。


<details>
  <summary>Details</summary>
Motivation: 受John Tyrell提出的经典"腰围问题"启发，该问题要求找到与三条给定线相交且周长最小的唯一三角形。论文旨在推广这个问题，将线替换为欧几里得空间中的凸集，扩大其几何和应用范围。

Method: 将经典问题推广为通过闭折线连接多个凸集的最小总距离问题。建立解的存在性和唯一性（要求至少一个凸集严格凸且所有凸集处于一般位置）。推导完整的最优性充要条件，并开发投影次梯度下降算法进行数值求解。

Result: 证明了在至少一个凸集严格凸且所有凸集处于一般位置条件下解的存在性和唯一性。推导了最优性条件，建立了与光反射定律等经典原理的几何联系。算法在圆盘和球体等案例中进行了数值验证，并展示了岛屿连接等实际应用。

Conclusion: 该工作不仅推进了几何优化理论，还为设施选址、网络设计、机器人学、计算几何和空间规划等领域提供了有效方法和见解，将经典几何问题推广到更广泛的凸分析框架中。

Abstract: Many years ago John Tyrell a lecturer at King's college London challenged his Ph.D. students with the following puzzle: show that there is a unique triangle of minimal perimeter with exactly one vertex to lie on one of three given lines, pairwise disjoint and not all parallel in the space. The problem in literature is known as the waist problem, and only convexity rescued in this case. Motivated by this we generalize it by replacing lines with a number of convex sets in the Euclidean space and ask to minimize the sum of distances connecting the sets by means of closed polygonal curve. This generalized problem significantly broadens its geometric and practical scope in view of modern convex analysis. We establish the existence of solutions and prove its uniqueness under the condition that at least one of the convex sets is strictly convex and all are in general position: each set can be separated by convex hull of others. A complete set of necessary and sufficient optimality conditions is derived, and their geometric interpretations are explored to link these conditions with classical principles such as the reflection law of light. To address this problem computationally, we develop a projected subgradient descent method and prove its convergence. Our algorithm is supported by detailed numerical experiments, particularly in cases involving discs and spheres. Additionally, we present a real-world analogy of the problem in the form of inter-island connectivity, illustrating its practical relevance. This work not only advances the theory of geometric optimization but also contributes effective methods and insights applicable to facility location, network design, robotics., computational geometry, and spatial planning.

</details>


### [556] [A Generalized $(k,m)$ Heron Problem:Optimality Conditions and Algorithm](https://arxiv.org/abs/2601.11555)
*Triloki Nath,Manohar Choudhary,Ram K. Pandey*

Main category: math.OC

TL;DR: 该论文提出了广义(k,m)-Heron问题，扩展了经典Heron问题，旨在寻找k个可行集和m个目标集之间的最优配置，建立了凸优化框架并设计了收敛算法。


<details>
  <summary>Details</summary>
Motivation: 经典Heron问题仅处理单个点到集合的距离优化，而现实应用中常涉及多个可行集和目标集之间的复杂几何关系。本文旨在建立更通用的多集合几何优化框架，以解决位置科学、机器人和计算几何中的实际问题。

Method: 将问题形式化为凸优化框架，利用凸分析工具建立存在性、唯一性和一阶最优性条件。基于这些理论分析，提出了投影次梯度算法(PSA)，采用递减步长规则，并严格证明了其收敛性。

Result: 建立了广义(k,m)-Heron问题的完整理论框架，证明了最优解的存在性和唯一性条件。提出的PSA算法在ℝ²和ℝ³的数值实验中表现出稳定性、几何精度和计算效率。

Conclusion: 该工作为多集合几何优化提供了全面的分析和算法框架，在位置科学、机器人和计算几何领域具有重要应用前景，扩展了经典距离优化问题的理论边界。

Abstract: This paper presents a new extension of the classical Heron problem, termed the generalized $(k,m)$-Heron problem, which seeks an optimal configuration among $k$ feasible and $m$ target non-empty closed convex sets in $\mathbb{R}^n$. The problem is formulated as finding a point in each set that minimizes the pairwise distances from the points in the $k$-feasible sets to the points in the $m$-target sets. This formulation leads to a convex optimization framework that generalizes several well-known geometric distance problems. Using tools from convex analysis, we establish fundamental results on existence, uniqueness, and first-order optimality conditions through subdifferential calculus and normal cone theory. Building on these insights, a Projected Subgradient Algorithm (PSA) is proposed for numerical solution, and its convergence is rigorously proved under a diminishing step-size rule. Numerical experiments in $\mathbb{R}^2$ and $\mathbb{R}^3$ illustrate the algorithm's stability, geometric accuracy, and computational efficiency. Overall, this work provides a comprehensive analytical and algorithmic framework for multi-set geometric optimization with promising implications for location science, robotics, and computational geometry.

</details>


### [557] [Integrated Optimization of Scheduling and Flexible Charging in Mixed Electric-Diesel Urban Transit Bus Systems](https://arxiv.org/abs/2601.11751)
*Sadjad Bazarnovi,Taner Cokyasar,Omer Verbas,Abolfazl Kouros Mohammadian*

Main category: math.OC

TL;DR: 提出混合整数线性规划模型优化电动与柴油混合公交车队的调度与充电策略，采用列生成算法解决计算复杂度，通过真实数据验证混合车队配置可降低系统总成本


<details>
  <summary>Details</summary>
Motivation: 公交车队向替代动力系统转型可降低出行成本，但电动公交车的有限续航和长充电时间带来运营复杂性，需要创新的调度和充电策略

Method: 提出集成混合整数线性规划模型，同时优化车队组成、调度和灵活的部分充电策略（包含慢充和快充），引入基于运营优先级和资源可用性的动态排队策略，开发列生成框架处理大规模变量

Result: 使用芝加哥公交系统和郊区公交系统的真实数据验证模型有效性，结果显示全电动转型会导致成本小幅增加，但最优混合车队配置可降低系统总成本，限制在车库充电会显著增加车队规模和运营成本

Conclusion: 混合车队配置结合分布式机会充电策略可有效降低公交系统总成本，列生成框架能解决大规模网络的优化问题，为公交电动化转型提供实用决策支持

Abstract: The transition of transit fleets to alternative powertrains offers a potential pathway to reducing the cost of mobility. However, the limited range and long charging durations of battery electric buses (BEBs) introduce significant operational complexities, necessitating innovative scheduling and charging strategies. This study proposes an integrated mixed-integer linear programming model to optimize vehicle scheduling and charging strategies for mixed fleets of BEBs and diesel buses. Unlike existing models, which often assume a fixed BEB fleet size or restrict charging to a single charger type, our approach simultaneously determines the optimal fleet composition, scheduling, and flexible partial charging strategy incorporating both slow and fast chargers at garages and terminal stations. The model minimizes combined fleet purchase and operational costs. A queuing strategy is introduced, departing from traditional first-come, first-served methods by dynamically allocating waiting and charging times based on operational priorities and resource availability, improving overall scheduling efficiency. To overcome computational complexities arising from numerous variables, a column generation framework is developed, facilitating scalable solutions for large-scale transit networks. Numerical experiments using real-world transit data from the Chicago Transit Authority and the Pace suburban bus systems demonstrate the model's effectiveness. Results indicate that while a full transition to alternative powertrains results in a modest cost increase, optimal mixed-fleet configurations can actually reduce total system costs. Furthermore, sensitivity analyses reveal that restricting charging to garages significantly increases fleet size and operational costs, underscoring the potential of distributed opportunistic charging.

</details>


### [558] [Mixed-Integer Reaggregated Hull Reformulation of Special Structured Generalized Linear Disjunctive Programs](https://arxiv.org/abs/2601.11782)
*Albert Joon Lee,David E. Bernal Neira*

Main category: math.OC

TL;DR: 提出一种统一的GDP重构方法，结合Jeroslow和Blair的凸包理论与Castro和Grossmann的时间槽重聚合策略，为单单元调度和二维条带装箱问题生成紧凑且紧致的MILP模型。


<details>
  <summary>Details</summary>
Motivation: 传统GDP重构方法（如Big-M和Hull）存在连续松弛弱或模型规模膨胀的问题，需要一种既能保持紧凑性又具有强理论保证的统一重构方法。

Method: 将Jeroslow和Blair的线性约束共系数情形下的凸包特征与Castro和Grossmann的时间槽重聚合策略相结合，推导出统一的重构方法学，应用于单单元调度和二维条带装箱问题。

Result: 为单单元调度推导出新的通用优先级概念表述，为条带装箱问题推导出对称性破缺表述，生成具有强理论保证（特别是连续变量紧凑性）的MILP模型，在商业求解器中表现出高效计算性能。

Conclusion: 提出的统一重构方法能够为具有线性约束和共系数的GDP问题生成紧凑且紧致的MILP模型，在单单元调度和二维条带装箱问题上验证了其理论优势和计算效率。

Abstract: Generalized Disjunctive Programming (GDP) provides a powerful framework for combining algebraic constraints with logical disjunctions. To solve these problems, mixed-integer reformulations are required, but traditional reformulation schemes, such as Big-M and Hull, either yield a weak continuous relaxation or result in a bloated model size. Castro and Grossmann showed that scheduling problems can be formulated as GDP by modeling task orderings as disjunctions with algebraic timing constraints. Moreover, in their work, a particular representation of the single-unit scheduling problem, namely using a time-slot concept, can be reformulated as a tight yet compact mixed-integer linear program with notable computational performance. Based on that observation, and focusing on the case where the constraints in disjunctions are linear and share the same coefficients, we connect the characterization of the convex hull of these disjunctive sets by Jeroslow and Blair with Castro and Grossmann's time-slot reaggregation strategy to derive a unified reformulation methodology. We test this reformulation in two problems, single-unit scheduling and two-dimensional strip-packing. We derive new formulations of the general precedence concept of single-unit scheduling and symmetry-breaking formulations of the strip-packing problem, yielding mixed-integer programs with strong theoretical guarantees, particularly compact formulations in terms of continuous variables, and efficient computational performance when solving them with commercial mixed-integer solvers for these problems.

</details>


### [559] [LQ Mean Field Games with Common Noise in Hilbert Spaces: Small and Arbitrary Finite Time Horizons](https://arxiv.org/abs/2601.13493)
*Hanchao Liu,Dena Firoozi*

Main category: math.OC

TL;DR: 将Hilbert空间中的线性二次平均场博弈扩展到包含共同噪声，建立耦合随机演化方程解的存在唯一性，并证明ε-纳什均衡性质


<details>
  <summary>Details</summary>
Motivation: 扩展Liu和Firoozi (2025)的Hilbert空间线性二次平均场博弈理论，引入无限维Wiener过程作为共同噪声，研究在共同噪声影响下的平均场博弈问题

Method: 在Hilbert空间中建立耦合的前向-后向随机演化方程系统，分析小时间范围内的解存在唯一性，并首次在文献中建立任意有限时间范围内温和解的良好适定性

Result: 证明了耦合线性FBSEEs在小时间范围内的解存在唯一性，建立了所得均衡策略的ε-纳什性质，并首次在Hilbert空间中建立了任意有限时间范围内这些方程的良好适定性

Conclusion: 成功将共同噪声纳入Hilbert空间中的线性二次平均场博弈框架，建立了相应的数学理论，为无限维随机控制问题提供了新的分析工具

Abstract: We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games in Hilbert spaces, by incorporating a common noise. This common noise is an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas in its absence, it is represented by forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG setting for small time horizons and prove the $ε$-Nash property of the resulting equilibrium strategy. Furthermore, for the first time in the literature, we develop an analysis that establishes the well-posedness of these coupled linear FBSEEs in Hilbert spaces, for which only mild solutions exist, over arbitrary finite time horizons.

</details>


### [560] [Projected Stochastic Momentum Methods for Nonlinear Equality-Constrained Optimization for Machine Learning](https://arxiv.org/abs/2601.11795)
*Qi Wang,Christian Piermarini,Yunlang Zhu,Frank E. Curtis*

Main category: math.OC

TL;DR: 提出两种基于动量的随机优化算法，用于解决带非线性等式约束的连续优化问题，通过投影梯度估计实现动量项，在监督机器学习中优于正则化方法。


<details>
  <summary>Details</summary>
Motivation: 将无约束优化中的随机动量方法扩展到带等式约束的问题，为监督机器学习提供比正则化方法更优的约束优化方法。

Method: 扩展了两种随机动量方法：heavy-ball方法和Adam方法，将其转化为随机牛顿-SQP型算法，关键创新是使用投影梯度估计而非原始梯度估计来实现动量项。

Result: 为约束设置提供了与无约束对应方法相媲美的收敛保证，在大量监督机器学习数值实验中显示出优越性能，证明约束方法优于正则化方法。

Conclusion: 提出的基于投影梯度估计的动量方法能有效解决带等式约束的优化问题，在监督机器学习中具有实际优势，为约束优化提供了新的有效工具。

Abstract: Two algorithms are proposed, analyzed, and tested for solving continuous optimization problems with nonlinear equality constraints. Each is an extension of a stochastic momentum-based method from the unconstrained setting to the setting of a stochastic Newton-SQP-type algorithm for solving equality-constrained problems. One is an extension of the heavy-ball method and the other is an extension of the Adam optimization method. Convergence guarantees for the algorithms for the constrained setting are provided that are on par with state-of-the-art guarantees for their unconstrained counterparts. A critical feature of each extension is that the momentum terms are implemented with projected gradient estimates, rather than with the gradient estimates themselves. The significant practical effect of this choice is seen in an extensive set of numerical experiments on solving informed supervised machine learning problems. These experiments also show benefits of employing a constrained approach to supervised machine learning rather than a typical regularization-based approach.

</details>


### [561] [A high-order augmented Lagrangian method with arbitrarily fast convergence](https://arxiv.org/abs/2601.11826)
*Young-Ju Lee,Jongho Park*

Main category: math.OC

TL;DR: 提出高阶增广拉格朗日方法，用于求解带线性约束的凸优化问题，可实现任意快速甚至超线性收敛速率。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在处理带约束的凸优化问题时收敛速度有限，需要开发能够实现更快收敛速率的高阶方法，特别是在科学计算和机器学习等应用中。

Method: 首先分析高阶邻近点方法在能量泛函满足一致凸性假设下的收敛速率，然后引入高阶增广拉格朗日方法，并利用高阶邻近点方法的收敛结果来分析其收敛性。

Result: 该方法能够实现任意快速甚至超线性的收敛速率，适用于数据拟合、多孔介质流动和科学机器学习等多种科学问题。

Conclusion: 高阶增广拉格朗日方法为带线性约束的凸优化问题提供了一种高效求解框架，具有快速收敛特性，在科学计算领域有广泛应用前景。

Abstract: We propose a high-order version of the augmented Lagrangian method for solving convex optimization problems with linear constraints, which achieves arbitrarily fast -- and even superlinear -- convergence rates. First, we analyze the convergence rates of the high-order proximal point method under certain uniform convexity assumptions on the energy functional. We then introduce the high-order augmented Lagrangian method and analyze its convergence by leveraging the convergence results of the high-order proximal point method. Finally, we present applications of the high-order augmented Lagrangian method to various problems arising in the sciences, including data fitting, flow in porous media, and scientific machine learning.

</details>


### [562] [Observer design and boundary output feedback stabilization for semilinear parabolic system over general multidimensional domain](https://arxiv.org/abs/2601.11948)
*Kai Liu,Hua-Cheng Zhou,Zhong-Jie Han,Xiangyang Peng*

Main category: math.OC

TL;DR: 该论文利用谱几何理论解决了多维域上具有Lipschitz非线性的抛物型方程的输出反馈镇定问题，设计了新型非线性观测器和有限维状态反馈控制器，实现了任意指定衰减率的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 解决多维域上具有Lipschitz非线性的抛物型方程的输出反馈镇定这一长期存在的理论挑战，特别是在任意Lipschitz常数下的稳定控制问题。

Method: 1. 设计新型非线性观测器，利用谱几何中的Berezin-Li-Yau不等式确保误差系统达到任意指定衰减率；2. 提出有限维状态反馈控制器，实现线性部分的定量快速镇定；3. 将控制律与观测器结合，开发高效的边界输出反馈控制策略。

Result: 1. 观测器误差系统可达到任意指定衰减率；2. 控制策略对任意Lipschitz常数均有效，解决了长期理论难题；3. 数值案例验证了方法的有效性；4. 谱几何理论为传感器布置提供了有效指导。

Conclusion: 该研究成功解决了多维域上具有Lipschitz非线性的抛物型方程的输出反馈镇定问题，提出的控制策略对任意Lipschitz常数均有效，并通过数值验证了方法的可行性，为相关领域提供了新的理论框架和实用工具。

Abstract: This paper investigates the output feedback stabilization of parabolic equation with Lipschitz nonlinearity over general multidimensional domain using spectral geometry theories. First, a novel nonlinear observer is designed, and the error system is shown to achieve any prescribed decay rate by leveraging the Berezin-Li-Yau inequality from spectral geometry, which also provides effective guidance for sensor placement. Subsequently, a finite-dimensional state feedback controller is proposed, which ensures the quantitative rapid stabilization of the linear part. By integrating this control law with the observer, an efficient boundary output feedback control strategy is developed. The feasibility of the proposed control design is rigorously verified for arbitrary Lipschitz constants, thereby resolving a persistent theoretical challenge. Finally, a numerical case study confirms the effectiveness of the approach.

</details>


### [563] [Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization](https://arxiv.org/abs/2601.12117)
*Jingren Liu,Hanzhang Qin,Junyi Liu,Mabel C. Chou,Jong-Shi Pang*

Main category: math.OC

TL;DR: 提出基于权重截断估计器的离线策略学习算法，通过截断小倾向得分来减少策略值估计的方差，使用渐进整数规划方法求解，理论证明能提升策略学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统重加权方法（如逆倾向加权或双重稳健估计）在倾向得分较小时会导致策略值估计的高方差，从而误导下游策略优化，产生次优策略。

Method: 提出权重截断估计器，通过截断阈值最小化策略值估计的均方误差；针对线性策略，将问题重构为Heaviside复合优化问题，使用渐进整数规划方法高效求解。

Result: 建立了算法次优性的上界，揭示了通过权重截断估计器减少策略值估计的均方误差如何提升策略学习性能。

Conclusion: 权重截断估计器能有效解决小倾向得分导致的高方差问题，提出的渐进整数规划方法使实际策略学习变得可行，理论分析证明了性能提升。

Abstract: Offline policy learning aims to use historical data to learn an optimal personalized decision rule. In the standard estimate-then-optimize framework, reweighting-based methods (e.g., inverse propensity weighting or doubly robust estimators) are widely used to produce unbiased estimates of policy values. However, when the propensity scores of some treatments are small, these reweighting-based methods suffer from high variance in policy value estimation, which may mislead the downstream policy optimization and yield a learned policy with inferior value. In this paper, we systematically develop an offline policy learning algorithm based on a weight-clipping estimator that truncates small propensity scores via a clipping threshold chosen to minimize the mean squared error (MSE) in policy value estimation. Focusing on linear policies, we address the bilevel and discontinuous objective induced by weight-clipping-based policy optimization by reformulating the problem as a Heaviside composite optimization problem, which provides a rigorous computational framework. The reformulated policy optimization problem is then solved efficiently using the progressive integer programming method, making practical policy learning tractable. We establish an upper bound for the suboptimality of the proposed algorithm, which reveals how the reduction in MSE of policy value estimation, enabled by our proposed weight-clipping estimator, leads to improved policy learning performance.

</details>


### [564] [Balancing adaptability and predictability: K-revision multistage stochastic programming](https://arxiv.org/abs/2601.12166)
*Chengwenjian Wang,Alexander S. Estes,Jean-Philippe P. Richard*

Main category: math.OC

TL;DR: 提出K-revision方法改进多阶段随机规划，要求提前制定计划但允许最多K次修订，平衡灵活性与可预测性。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段随机规划中决策在观测不确定性后做出，导致解决方案难以实施，缺乏对未来阶段的准备。需要提供更好的前瞻性。

Method: 引入K-revision框架：要求提前制定计划，但允许随着新信息出现最多进行K次修订。开发两种MIP公式，分析其紧致性并提出强化方法。

Result: 证明K-revision问题即使在简单设置下也是NP难的。计算实验表明该方法计算可行且有效，能在提高解决方案可预测性的同时达到接近最优的性能。

Conclusion: K-revision方法在计算可行性和解决方案可预测性之间取得了良好平衡，相比传统多阶段随机规划和部分自适应方法具有优势。

Abstract: A standard assumption in multistage stochastic programming is that decisions are made after observing the uncertainty from the prior stage. The resulting solutions can be difficult to implement in practice, as they leave practitioners ill-prepared for future stages. To provide better foresight, we introduce the K-revision approach. This new framework requires plans to be specified in advance. To maintain flexibility, we allow plans to be revised a maximum of K times as new information becomes available. We analyze the complexity of K-revision problems, showing NP-hardness even in a simple setting. We examine, both theoretically and computationally, the impact of the K-revision approach on the objective compared with classical multistage stochastic programming models and the partially adaptive approach introduced in [1, 2]. We develop two MIP formulations, one directly from our definition and the other based on a combinatorial characterization. We analyze the tightness of these formulations and propose several methods to strengthen them. Computational experiments on synthetic problems and practical applications demonstrate that our approach is both computationally tractable and effective in reaching near-optimal performance while increasing the predictability of the solutions produced.

</details>


### [565] [Optimal Leveraging of Smoothness and Strong Convexity for Peaceman--Rachford Splitting](https://arxiv.org/abs/2601.12190)
*Luis Briceño-Arias,Fernando Roldán*

Main category: math.OC

TL;DR: 提出一种通过调整强凸性和光滑性分布来优化Peaceman-Rachford分裂方法收敛速度的新方法，获得比现有方法更优的线性收敛率。


<details>
  <summary>Details</summary>
Motivation: Peaceman-Rachford分裂(PRS)方法在处理两个光滑强凸函数的优化问题时，现有的收敛率不是最优的。需要开发一种方法能够获得最优的线性收敛率。

Method: 通过在原问题中添加和减去适当的二次项，重新分配强凸性（在原始形式中）和光滑性（在对偶形式中），将原问题转化为等价的修正优化问题。在修正问题中，每个项都有可调节的强凸性和光滑性水平，然后应用PRS方法。

Result: 该方法获得了最优的线性收敛率，严格优于先前在一般设置中的最佳收敛率。通过学术示例和图像处理应用验证了方法的实际性能。

Conclusion: 提出的简单方法通过重新分配强凸性和光滑性，能够显著提升PRS方法的收敛速度，为处理两个光滑强凸函数的优化问题提供了更有效的解决方案。

Abstract: In this paper, we introduce a simple methodology to leverage strong convexity and smoothness in order to obtain an optimal linear convergence rate for the Peaceman--Rachford splitting (PRS) scheme applied to optimization problems involving two smooth strongly convex functions. The approach consists of adding and subtracting suitable quadratic terms from one function to the other so as to redistribute strong convexity in the primal formulation and smoothness in the dual formulation. This yields an equivalent modified optimization problem in which each term has adjustable levels of strong convexity and smoothness. In this setting, the Peaceman--Rachford splitting method converges linearly to the solution of the modified problem with a convergence rate that can be optimized with respect to the introduced parameters. Upon returning to the original formulation, this procedure gives rise to a modified variant of PRS. The optimal linear rate established in this work is strictly better than the best rates previously available in the general setting. The practical performance of the method is illustrated through an academic example and applications in image processing.

</details>


### [566] [Interval B-Tensors and Interval Double B-Tensors](https://arxiv.org/abs/2601.12217)
*Li Ye,Yisheng Song*

Main category: math.OC

TL;DR: 该论文系统研究了区间B张量和区间双B张量的性质与表征，提出了基于极值点张量判断整个区间张量族是否属于这些类的可验证充要条件，并建立了这些区间张量与Z张量、P张量等其他结构张量的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 将区间矩阵理论扩展到张量领域，为多项式优化和互补问题等涉及不确定性的领域提供新的分析工具。研究区间B张量和区间双B张量的性质有助于处理不确定性环境下的张量分析问题。

Method: 提出基于极值点张量的可验证充要条件来判断整个区间张量族是否属于区间B张量或区间双B张量类。研究这些区间张量与Z张量、P张量等其他结构张量的关系，并为循环结构等特殊情况提供简化判据。在偶阶对称条件下证明区间B张量（双B张量）确保区间P张量性质。

Result: 建立了区间B张量和区间双B张量的完整表征理论，发现了这些区间张量与Z张量、P张量等其他结构张量之间的深刻联系。在偶阶对称条件下证明了区间B张量（双B张量）必然具有区间P张量性质。

Conclusion: 该工作成功将区间矩阵理论扩展到张量领域，为处理不确定性环境下的多项式优化和互补问题提供了新的分析框架和工具。提出的基于极值点的判据方法具有实际可验证性，建立的张量间关系理论丰富了张量分析的理论体系。

Abstract: This paper systematically investigates the properties and characterization of interval B-tensors and interval double B-tensors. We propose verifiable necessary and sufficient conditions that allow for determining whether an entire interval tensor family belongs to these classes based solely on its extreme point tensors. The study elucidates profound connections between these interval tensors and other structured ones such as interval Z-tensors and P-tensors, while also providing simplified criteria for special cases like circulant structures. Furthermore, under the condition of even order and symmetry, we prove that interval B-tensors (double B-tensors) ensure the property of being an interval P-tensor. This work extends interval matrix theory to tensors, offering new analytical tools for fields such as polynomial optimization and complementarity problems involving uncertainty.

</details>


### [567] [Mean-Field Games Under Model Uncertainty](https://arxiv.org/abs/2601.12226)
*Zongxia Liang,Zhou Zhou,Yaqi Zhuang,Bin Zou*

Main category: math.OC

TL;DR: 研究具有模型不确定性的离散时间有限状态平均场博弈，证明N智能体博弈与平均场博弈的渐近等价性，并建立均衡存在性


<details>
  <summary>Details</summary>
Motivation: 经典平均场博弈假设智能体完全了解状态转移概率，但现实中存在模型不确定性。本文研究智能体面对状态转移概率模糊性时的平均场博弈，其中每个智能体在不确定性集合内针对最坏情况转移最大化期望收益。

Method: 研究离散时间有限状态平均场博弈，考虑策略依赖于个体状态和已实现的人口分布。建立N智能体博弈与平均场博弈的渐近关系，证明均衡存在性，并构造具有闭式解的可解平均场示例。

Result: 主要结果：1) 每个平均场博弈均衡构成足够大人口规模下的ε-纳什均衡；2) N智能体均衡的极限是平均场博弈均衡；3) 证明有限智能体博弈均衡存在性；4) 构造具有闭式解的可解平均场示例。

Conclusion: 在模型不确定性下，平均场博弈框架仍然有效，N智能体博弈与平均场博弈渐近等价。模型不确定性使人口分布流变为随机过程，需要策略同时依赖个体状态和已实现的人口分布。

Abstract: We study discrete-time, finite-state mean-field games (MFGs) under model uncertainty, where agents face ambiguity about the state transition probabilities. Each agent maximizes its expected payoff against the worst-case transitions within an uncertainty set. Unlike in classical MFGs, model uncertainty renders the population distribution flow stochastic. This leads us to consider strategies that depend on both individual states and the realized distribution of the population. Our main results establish the asymptotic relationship between $N$-agent games and MFGs: every MFG equilibrium constitutes an $\varepsilon$-Nash equilibrium for sufficiently large populations, and conversely, limits of $N$-agent equilibria are MFG equilibria. We also prove the existence of equilibria for finite-agent games and construct a solvable mean-field example with closed-form solutions.

</details>


### [568] [An efficient penalty decomposition algorithm for minimization over sparse symmetric sets](https://arxiv.org/abs/2601.12383)
*Ahmad Mousavi,Morteza Kimiaei,Saman Babaie-Kafaki,Vyacheslav Kungurtsev*

Main category: math.OC

TL;DR: 提出改进的拟牛顿惩罚分解算法，用于求解稀疏对称集上的连续可微函数最小化问题，支持非凸目标函数，通过两阶段分解和实用增强策略实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理稀疏对称约束下的非凸优化问题时存在局限性，需要更弱假设条件下的高效算法，特别是在实际应用中需要兼顾理论保证和计算效率。

Method: 采用拟牛顿惩罚分解算法，将问题分解为两个子问题：无稀疏约束的闭式解子问题和高效稀疏投影子问题。引入增强线搜索策略（回溯或外推）和四种廉价对角Hessian近似方法。

Result: 在30个合成和数据驱动的测试问题上验证，包括UCI机器学习数据集和维度10到500的稀疏对称实例，算法在效率、鲁棒性和强稳定性方面与最先进方法竞争。

Conclusion: 该算法在较弱假设下（比全局Lipschitz连续性更弱）证明了收敛性，实际增强策略确保了有限精度算术中的鲁棒性和效率，为稀疏对称约束优化提供了有效解决方案。

Abstract: This paper proposes an improved quasi-Newton penalty decomposition algorithm for the minimization of continuously differentiable functions, possibly nonconvex, over sparse symmetric sets. The method solves a sequence of penalty subproblems approximately via a two-block decomposition scheme: the first subproblem admits a closed-form solution without sparsity constraints, while the second subproblem is handled through an efficient sparse projection over the symmetric feasible set. Under a new assumption on the gradient of the objective function, weaker than global Lipschitz continuity from the origin, we establish that accumulation points of the outer iterates are basic feasible and cardinality-constrained Mordukhovich stationarity points. To ensure robustness and efficiency in finite-precision arithmetic, the algorithm incorporates several practical enhancements, including an enhanced line search strategy based on either backtracking or extrapolation, and four inexpensive diagonal Hessian approximations derived from differences of previous iterates and gradients or from eigenvalue-distribution information. Numerical experiments on a diverse benchmark of $30$ synthetic and data-driven test problems, including machine-learning datasets from the UCI repository and sparse symmetric instances with dimensions ranging from $10$ to $500$, demonstrate that the proposed algorithm is competitive with several state-of-the-art methods in terms of efficiency, robustness, and strong stationarity.

</details>


### [569] [Anderson Acceleration for Distributed Constrained Optimization over Time-varying Networks](https://arxiv.org/abs/2601.12398)
*Haijuan Liu,Xuyang Wu*

Main category: math.OC

TL;DR: 将Anderson Acceleration技术应用于Fenchel对偶梯度方法，解决时变网络上的约束优化问题，提出FDGM-AA算法并证明其收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统FDGM在时变网络上收敛速度较慢，而Anderson Acceleration技术虽能加速固定点迭代，但直接应用于FDGM面临两个挑战：1) 时变网络下FDGM无法表示为标准固定点更新；2) 即使网络固定，直接应用AA也无法分布式实现。

Method: 将FDGM的每次更新重写为多个局部问题的近似求解，每个局部问题仅涉及两个相邻节点，然后引入AA技术以更高精度求解每个局部问题，形成FDGM-AA算法，并设计新的安全防护机制保证全局收敛。

Result: 在温和条件下，算法对原始序列以O(1/√k)速率收敛，对偶序列以O(1/k)速率收敛。数值实验验证了算法的竞争性能。

Conclusion: 成功将Anderson Acceleration技术应用于时变网络上的Fenchel对偶梯度方法，解决了直接应用的技术挑战，提出了可分布式实现的FDGM-AA算法并证明了其收敛性。

Abstract: This paper applies the Anderson Acceleration (AA) technique to accelerate the Fenchel dual gradient method (FDGM) to solve constrained optimization problems over time-varying networks. AA is originally designed for accelerating fixed-point iterations, and its direct application to FDGM faces two challenges: 1) FDGM in time-varying networks cannot be formulated as a standard fixed-point update; 2) even if the network is fixed so that FDGM can be expressed as a fixed-point iteration, the direct application of AA is not distributively implementable. To overcome these challenges, we first rewrite each update of FDGM as inexactly solving several \emph{local} problems where each local problem involves two neighboring nodes only, and then incorporate AA to solve each local problem with higher accuracy, resulting in the Fenchel Dual Gradient Method with Anderson Acceleration (FDGM-AA). To guarantee global convergence of FDGM-AA, we equip it with a newly designed safe-guard scheme. Under mild conditions, our algorithm converges at a rate of \(O(1/\sqrt{k})\) for the primal sequence and \(O(1/k)\) for the dual sequence. The competitive performance of our algorithm is validated through numerical experiments.

</details>


### [570] [BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training](https://arxiv.org/abs/2601.12400)
*Laurent Condat,Artavazd Maranjyan,Peter Richtárik*

Main category: math.OC

TL;DR: BiCoLoR是一种通信高效的分布式优化算法，结合了本地训练和双向压缩，在联邦学习中显著减少通信成本。


<details>
  <summary>Details</summary>
Motivation: 分布式优化（特别是联邦学习）中，通信成本高且速度慢是主要瓶颈。现有方法通常只压缩上行链路（客户端到服务器），而忽略了下行链路（服务器到客户端）的通信成本，但实际上双向通信都很昂贵。

Method: 提出BiCoLoR算法，首次将本地训练与双向压缩相结合，使用任意无偏压缩器对两个方向的通信都进行压缩，在凸和强凸异构设置中实现加速复杂度保证。

Result: BiCoLoR在理论上实现了加速复杂度保证，在实证测试中优于现有算法，建立了通信效率的新标准。

Conclusion: BiCoLoR通过结合本地训练和双向压缩，有效解决了分布式优化中的通信瓶颈问题，为联邦学习等应用提供了更高效的通信优化方案。

Abstract: Slow and costly communication is often the main bottleneck in distributed optimization, especially in federated learning where it occurs over wireless networks. We introduce BiCoLoR, a communication-efficient optimization algorithm that combines two widely used and effective strategies: local training, which increases computation between communication rounds, and compression, which encodes high-dimensional vectors into short bitstreams. While these mechanisms have been combined before, compression has typically been applied only to uplink (client-to-server) communication, leaving the downlink (server-to-client) side unaddressed. In practice, however, both directions are costly. We propose BiCoLoR, the first algorithm to combine local training with bidirectional compression using arbitrary unbiased compressors. This joint design achieves accelerated complexity guarantees in both convex and strongly convex heterogeneous settings. Empirically, BiCoLoR outperforms existing algorithms and establishes a new standard in communication efficiency.

</details>


### [571] [Dynamic resource allocation in eukaryotic Resource Balance Analysis](https://arxiv.org/abs/2601.12411)
*Saeed Sadeghi Arjmand*

Main category: math.OC

TL;DR: 提出基于最优控制的动态真核细胞资源平衡分析框架，将细胞生长建模为翻译能力在代谢酶和生物大分子机器之间的时间依赖性分配问题


<details>
  <summary>Details</summary>
Motivation: 经典RBA框架是静态的，无法捕捉生物合成资源的动态调控和大分子周转，这在真核细胞中尤为重要

Method: 基于最优控制理论提出动态真核RBA扩展，将细胞生长建模为在有限时间范围内最大化生物质积累的翻译能力分配问题，使用庞特里亚金极大值原理分析最优分配策略

Result: 表征了最优分配策略，并证明稳态RBA解是动态问题的极限情况

Conclusion: 动态RBA框架能够更好地捕捉真核细胞的资源调控机制，稳态RBA是其特例，为细胞生长调控提供了更全面的理论框架

Abstract: Resource Balance Analysis (RBA) is a framework for predicting steady-state cellular growth under resource constraints. However, classical RBA formulations are static and do not capture the dynamic regulation of biosynthetic resources or macromolecular turnover, which is particularly important in eukaryotic cells. In this work, we propose a dynamic extension of eukaryotic RBA based on an optimal control formulation. Cellular growth is modeled as the result of a time-dependent allocation of translational capacity between metabolic enzymes and macromolecular machinery, aimed at maximizing biomass accumulation over a finite time horizon. Using Pontryagin's Maximum Principle, we characterize optimal allocation strategies and show that steady-state RBA solutions arise as limiting regimes of the dynamic problem.

</details>


### [572] [Monotonicity of Pairs of Operators and Generalized Inertial Proximal Method](https://arxiv.org/abs/2601.12738)
*Ba Khiet Le,Zakaria Mazgouri,Michel Théra*

Main category: math.OC

TL;DR: 提出广义惯性邻近点算法(GIPPA)，利用扭曲预解算子解决单调对算子问题，建立了算法的弱、强和线性收敛性


<details>
  <summary>Details</summary>
Motivation: 单调对算子是单调算子的扩展，在解决非单调包含问题中起重要作用。如何设计相关映射以获得单调对是该新工具中的一个挑战性问题

Method: 提出广义惯性邻近点算法(GIPPA)，使用扭曲预解算子在单调对条件下设计算法

Result: 在温和假设下建立了算法的弱收敛、强收敛和线性收敛性，并通过数值例子说明了算法的可实施性和有效性

Conclusion: 解决了单调对算子中如何设计相关映射的问题，提出的GIPPA算法在理论和数值上都表现出良好性能

Abstract: Monotonicity of pairs of operators is an extension of monotonicity of operators, which plays an important role in solving non-monotone inclusions. One of challenging problems in this new tool is how to design the associated mappings to obtain the monotone pairs. In this paper, we solve this problem and propose a Generalized Inertial Proximal Point Algorithm (GIPPA) using warped resolvents under the monotonicity of pairs. The weak, strong and linear convergence of the algorithm under some mild assumptions are established. We also provide numerical examples illustrating the implementability and effectiveness of the proposed method.

</details>


### [573] [Optimal bounds for the boundary control cost of one-dimensional fractional Schrödinger and heat equations](https://arxiv.org/abs/2601.12810)
*Hoai-Minh Nguyen*

Main category: math.OC

TL;DR: 本文推导了一维分数阶薛定谔方程和热方程边界控制成本的最优上下界


<details>
  <summary>Details</summary>
Motivation: 研究分数阶偏微分方程的边界控制问题，确定控制成本的理论极限，为实际控制应用提供理论指导

Method: 下界分析：通过研究有限时间内相关奇异边界控制问题，运用复分析工具；上界分析：采用矩方法，估计一类紧支集函数的傅里叶变换

Result: 得到了一维分数阶薛定谔方程和热方程边界控制成本的尖锐（最优）上下界

Conclusion: 建立了分数阶偏微分方程边界控制成本的理论框架，为相关控制问题提供了精确的数学界限

Abstract: We derive sharp bounds for the boundary control cost of the one-dimensional fractional Schrödinger and heat equations. The analysis of the lower bound is based on the study of the control cost of a related singular boundary control problem in finite time, using tools from complex analysis. The analysis of the upper bound relies on the moment method, involving estimates of the Fourier transform of a class of compactly supported functions.

</details>


### [574] [Multi-gear bandits, partial conservation laws, and indexability](https://arxiv.org/abs/2601.13026)
*José Niño-Mora*

Main category: math.OC

TL;DR: 本文提出"多档老虎机"模型，研究在资源价格变化下如何平衡项目性能与资源消耗，建立了验证索引性的条件，并开发了高效的索引计算算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏通用的索引性条件和高效的索引计算方案。多档老虎机模型需要解决在动态资源价格下，如何最优地平衡项目性能成本/奖励与资源使用成本的问题。

Method: 提出PCL-indexability验证定理，确保模型满足两个条件时具有索引性。使用下移自适应贪婪算法在A×N步内计算边际生产力指数作为动态分配索引。

Result: 建立了索引性验证框架，开发了高效索引计算算法，并将动态分配索引应用于多臂多档老虎机问题的新索引策略。

Conclusion: 本文为多档老虎机提供了索引性验证和高效计算的理论基础，为解决资源约束下的动态决策问题提供了实用的解决方案。

Abstract: This paper considers what we propose to call multi-gear bandits, which are Markov decision processes modeling a generic dynamic and stochastic project fueled by a single resource and which admit multiple actions representing gears of operation naturally ordered by their increasing resource consumption. The optimal operation of a multi-gear bandit aims to strike a balance between project performance costs or rewards and resource usage costs, which depend on the resource price. A computationally convenient and intuitive optimal solution is available when such a model is indexable, meaning that its optimal policies are characterized by a dynamic allocation index (DAI), a function of state--action pairs representing critical resource prices. Motivated by the lack of general indexability conditions and efficient index-computing schemes, and focusing on the infinite-horizon finite-state and -action discounted case, we present a verification theorem ensuring that, if a model satisfies two proposed PCL-indexability conditions with respect to a postulated family of structured policies, then it is indexable and such policies are optimal, with its DAI being given by a marginal productivity index computed by a downshift adaptive-greedy algorithm in $A N$ steps, with $A+1$ actions and $N$ states. The DAI is further used as the basis of a new index policy for the multi-armed multi-gear bandit problem.

</details>


### [575] [Optimality Conditions for Sparse Bilinear Least Squares Problems](https://arxiv.org/abs/2601.13027)
*Zixin Deng,Zheng-Hai Huang,Yun-Bin Zhao*

Main category: math.OC

TL;DR: 该论文研究了稀疏双线性最小二乘问题的一阶最优性条件，分析了多种驻点概念（T型、N型、坐标极小、L型、M型）及其相互关系。


<details>
  <summary>Details</summary>
Motivation: 研究稀疏双线性最小二乘问题的最优性条件，为这类非凸优化问题提供理论分析基础，帮助理解不同驻点概念之间的关系。

Method: 通过Bouligand和Clarke意义下的切锥与法锥刻画T型和N型驻点；引入坐标极小概念；通过新定义的类投影概念分析L型驻点；通过互补型重构研究M型驻点。

Result: 所有讨论的驻点类型（T型、N型、坐标极小、L型、M型）都满足稀疏双线性最小二乘问题的必要最优性条件，并建立了这些驻点概念之间的关系。

Conclusion: 论文系统分析了稀疏双线性最小二乘问题的多种一阶驻点概念，证明了它们都满足必要最优性条件，为这类问题的理论分析和算法设计提供了基础。

Abstract: The first-order optimality conditions of sparse bilinear least squares problems are studied. The so-called T-type and N-type stationary points for this problem are characterized in terms of tangent cone and normal cone in Bouligand and Clarke senses, and another stationarity concept called the coordinate-wise minima is introduced and discussed. Moreover, the L-like stationary point for this problem is introduced and analyzed through the newly introduced concept of like-projection, and the M-stationary point is also investigated via a complementarity-type reformulation of the problem. The relationship between these stationary points is discussed as well. It turns out that all stationary points discussed in this work satisfy the necessary optimality conditions for the sparse bilinear least squares problem.

</details>


### [576] [Markovian restless bandits and index policies: A review](https://arxiv.org/abs/2601.13045)
*José Niño-Mora*

Main category: math.OC

TL;DR: 本文对多臂赌博机问题的文献进行了系统性综述，重点介绍了优先级索引策略及其在动态优先级分配中的应用。


<details>
  <summary>Details</summary>
Motivation: 多臂赌博机问题自Whittle在1980年代提出以来，已成为随机模型中动态优先级分配的典范框架，在广泛的应用领域中产生了大量研究。本文旨在对该领域的研究进行系统性梳理，突出其研究广度，并激发进一步的研究。

Method: 采用文献综述方法，对多臂赌博机问题的相关文献进行主题性组织和评述。主要关注优先级索引策略，同时也回顾其他研究方向，讨论理论发展和算法进展，并涵盖多样化的应用领域。

Result: 系统性地整理了多臂赌博机问题的研究现状，展示了该领域研究的广度和深度，强调了优先级索引策略在直观性、可处理性、渐近最优性和实证性能方面的优势。

Conclusion: 多臂赌博机问题是一个活跃且重要的研究领域，具有广泛的理论和应用价值。本文通过系统性综述展示了该领域的丰富研究成果，并期望能够促进该领域的进一步发展。

Abstract: The restless multi-armed bandit problem is a paradigmatic modeling framework for optimal dynamic priority allocation in stochastic models of wide-ranging applications that has been widely investigated and applied since its inception in a seminal paper by Whittle in the late 1980s. The problem has generated a vast and fast-growing literature from which a significant sample is thematically organized and reviewed in this paper. While the main focus is on priority-index policies due to their intuitive appeal, tractability, asymptotic optimality properties, and often strong empirical performance, other lines of work are also reviewed. Theoretical and algorithmic developments are discussed, along with diverse applications. The main goals are to highlight the remarkable breadth of work that has been carried out on the topic and to stimulate further research in the field.

</details>


### [577] [Full characterization of core for nonlinear optimization games](https://arxiv.org/abs/2601.13124)
*Donglei Du,Qizhi Fang,Bin Liu,Tianhang Lu,Chenchen Wu*

Main category: math.OC

TL;DR: 论文完全刻画了一类广泛非线性博弈的核心，通过识别非线性问题的合适松弛，直接推广了文献中的线性框架，显著扩展了可分析的合作博弈范围。


<details>
  <summary>Details</summary>
Motivation: 现有文献主要关注线性博弈框架，对于非线性博弈的核心刻画不足。本文旨在扩展合作博弈理论，使其能够分析更广泛的非线性博弈模型，特别是从优化模型导出的博弈。

Method: 通过识别非线性问题的合适松弛方法，直接推广线性框架来处理非线性博弈。该方法能够处理组合二次博弈、比率博弈等复杂非线性结构。

Result: 成功刻画了广泛非线性博弈的核心，建立了与经典模型的联系并提供了新见解。解决了现有文献中未处理的博弈，包括投资组合、最大割、匹配和选择博弈等组合二次和比率博弈。

Conclusion: 该研究显著扩展了合作博弈理论的分析范围，为非线性博弈提供了统一的分析框架，并将结果扩展到更一般模型和近似核心，对优化模型导出的博弈有重要理论贡献。

Abstract: We fully characterize the core of a broad class of nonlinear games by identifying a suitable relaxation for inherent nonlinearity, directly generalizing the linear frameworks in the literature. This characterization significantly expands the scope of cooperative games that can be analyzed and contributes to the literature on games induced from optimization models. We apply these insights to not only establish connections with and provide new insights on classical models but also solve new games untamed in the existing literature, including combinatorial quadratic and ratio games such as portfolio, maximum cut, matching, and assortment games. These results are further extended to more general models and also the approximate core.

</details>


### [578] [Age of information cost minimization with no buffers, random arrivals and unreliable channels: A PCL-indexability analysis](https://arxiv.org/abs/2601.13130)
*José Niño-Mora*

Main category: math.OC

TL;DR: 本文扩展了Whittle索引策略在AoI调度模型中的应用范围，针对无缓冲、随机数据包到达、不可靠信道和非递减AoI成本的模型，建立了索引性并给出了闭式Whittle索引公式。


<details>
  <summary>Details</summary>
Motivation: 信息年龄(AoI)已成为传感器数据新鲜度关键应用的核心指标。由于传输容量有限，需要设计可处理的调度策略来最小化AoI成本。虽然基于RMABP的Whittle索引策略已被证明在某些模型中有效，但需要将其应用范围扩展到更广泛的AoI调度模型。

Method: 采用无缓冲模型，包含随机数据包到达、不可靠信道和非递减AoI成本。利用作者先前提出的基于部分守恒定律的充分索引性条件，建立了模型的索引性，并在折扣和平均成本准则下给出了闭式Whittle索引公式。

Result: 成功证明了模型的索引性，推导出了闭式Whittle索引公式。利用索引公式分析了调度优先级如何依赖于模型参数，为实际调度决策提供了理论依据。

Conclusion: 本文成功将Whittle索引策略的应用扩展到更广泛的AoI调度模型，为包含随机到达、不可靠信道和一般成本函数的实际系统提供了有效的调度策略设计方法。

Abstract: Over the last decade, the Age of Information has emerged as a key concept and metric for applications where the freshness of sensor-provided data is critical. Limited transmission capacity has motivated research on the design of tractable policies for scheduling information updates to minimize Age of Information cost based on Markov decision models, in particular on the restless multi-armed bandit problem (RMABP). This allows the use of Whittle's popular index policy, which is often nearly optimal, provided indexability (index existence) is proven, which has been recently accomplished in some models. We aim to extend the application scope of Whittle's index policy in a broader AoI scheduling model. We address a model with no buffers incorporating random packet arrivals, unreliable channels, and nondecreasing AoI costs. We use sufficient indexability conditions based on partial conservation laws previously introduced by the author to establish the model's indexability and evaluate its Whittle index in closed form under discounted and average cost criteria. We further use the index formulae to draw insights on how scheduling priority depends on model parameters.

</details>


### [579] [Blackwell optimality in risk-sensitive stochastic control](https://arxiv.org/abs/2601.13136)
*Marcin Pitera,Łukasz Stettner*

Main category: math.OC

TL;DR: 该论文研究有限状态-动作空间的离散时间马尔可夫决策过程，采用长期风险敏感准则作为目标函数，探讨Blackwell最优性概念及其在风险中性期望被风险敏感熵替代时的复杂性，并展示Blackwell最优性与最终平稳性之间的关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索马尔可夫决策过程中风险敏感准则下的最优性概念。当目标函数从传统的风险中性期望转变为风险敏感熵时，Blackwell最优性概念面临新的复杂性和挑战，需要深入分析这些差异。

Method: 采用离散时间马尔可夫决策过程框架，在有限状态-动作空间上分析长期风险敏感准则。通过理论分析探讨Blackwell最优性概念，比较风险中性期望与风险敏感熵的差异，并通过构造示例来阐明结构差异。

Result: 论文阐明了风险敏感准则下Blackwell最优性的复杂性，展示了Blackwell最优性与最终平稳性之间的关系，并通过示例说明了这两种概念之间的结构差异，帮助更好地理解风险敏感环境中的最优决策问题。

Conclusion: 在风险敏感准则下，Blackwell最优性概念比风险中性情况更为复杂，与最终平稳性存在特定关系。理解这些差异对于在风险敏感环境中制定最优决策策略具有重要意义。

Abstract: In this paper, we consider a discrete-time Markov Decision Process (MDP) on a finite state-action space with a long-run risk-sensitive criterion used as the objective function. We discuss the concept of Blackwell optimality and comment on intricacies which arise when the risk-neutral expectation is replaced by the risk-sensitive entropy. Also, we show the relation between the Blackwell optimality and ultimate stationarity and provide an illustrative example that helps to better understand the structural difference between these two concepts.

</details>


### [580] [Classical Optimal Designs for Stationary Diffusion with Multiple Phases](https://arxiv.org/abs/2601.13149)
*Matko Grbac,Ivan Ivec,Marko Vrdoljak*

Main category: math.OC

TL;DR: 研究多材料各向异性扩散问题的最优设计，采用均匀化松弛框架，通过对偶公式分析简化优化问题，在球对称情况下获得显式经典解。


<details>
  <summary>Details</summary>
Motivation: 研究涉及多个状态方程和多种各向异性材料的平稳扩散最优设计问题。这类问题通常没有经典解，需要采用均匀化松弛方法。特别关注识别最优设计为经典解（即仅由原始纯材料组成的bang-bang型设计）的情况，为数值方法提供有价值的基准。

Method: 采用基于均匀化的松弛框架处理无经典解的问题。通过局部材料比例表达的简化优化问题，利用对偶公式（基于通量）进行分析。使用鞍点特征化方法建立最优解的完整描述。将方法详细应用于球对称问题，在球体情况下获得均匀化松弛问题的显式经典解。

Result: 建立了简化优化问题最优解的完整描述。在球对称问题中，特别是在球体情况下，获得了均匀化松弛问题的显式经典解，这些解是bang-bang型的，仅由原始纯材料组成。

Conclusion: 提出的基于均匀化松弛和对偶公式的方法能够有效处理多材料各向异性扩散最优设计问题。在球对称情况下获得了显式经典解，为数值方法提供了有价值的基准。该方法有助于识别最优设计为经典解的情况，对最优设计理论和数值计算都有重要意义。

Abstract: We study optimal design problems for stationary diffusion involving one or more state equations and mixtures of an arbitrary number of anisotropic materials. Since such problems typically do not admit classical solutions, we adopt a homogenization-based relaxation framework.
  The objective considered is the maximization of a weighted sum of the energies associated with each state equation, with particular emphasis on identifying cases in which the optimal design is classical, that is, of bang-bang type, composed solely of the original pure materials. Such cases provide valuable benchmarks for numerical methods in optimal design.
  A simplified optimization problem expressed in terms of local material proportions is analyzed through a dual formulation in terms of fluxes. Using a saddle-point characterization, we establish a complete description of its optimal solutions. The proposed approach is applied in detail to spherically symmetric problems. In the case of a ball, the method yields explicit classical solutions of the homogenization-based relaxation problem.

</details>


### [581] [Long-time behavior of solutions to fluid dynamic shape optimization problems via phase-field method](https://arxiv.org/abs/2601.13293)
*Michael Hinze,Christian Kahle,John Sebastian H. Simon*

Main category: math.OC

TL;DR: 研究时间依赖Navier-Stokes方程形状拓扑优化问题的长时间行为，证明当时间趋于无穷时，时间依赖问题的最小值收敛于对应稳态问题的最小值


<details>
  <summary>Details</summary>
Motivation: 研究形状和拓扑优化问题在时间依赖Navier-Stokes方程下的长时间行为，扩展先前关于稳态问题的研究，探讨时间依赖问题与稳态问题之间的关系

Method: 采用相场法表示拓扑（平稳相场作为光滑指示函数），使用多孔介质方法近似流体方程，分析时间趋于无穷时时间依赖问题向稳态问题的收敛性

Result: 证明了当时间趋于无穷时，时间依赖问题的最小值收敛于对应稳态问题的最小值，并解析推导了目标函数值关于时间范围的收敛速率，数值验证了理论结果

Conclusion: 时间依赖形状拓扑优化问题的解在长时间极限下收敛到稳态问题的极小值，建立了时间依赖问题与稳态问题之间的理论联系，并通过数值实验验证

Abstract: We investigate the long time behavior of solutions to a shape and topology optimization problem with respect to the time-dependent Navier--Stokes equations. The sought topology is represented by a stationary phase-field that represents a smooth indicator function. The fluid equations are approximated by a porous media approach and are time-dependent. In the latter aspect, the considered problem formulation extends earlier work.
  We prove that if the time horizon tends to infinity, minima of the time-dependent problem converge towards minima of the corresponding stationary problem. To do so, a convergence rate with respect to the time horizon, of the values of the objective functional, is analytically derived. This allowed us to prove that the solution to the time-dependent problem converges to a phase-field, as the time horizon goes to infinity, which is proven to be a minimizer for the stationary problem. We validate our results by numerical investigation.

</details>


### [582] [Discrete-Time Optimal Control of Species Augmentation for Predator-Prey Model](https://arxiv.org/abs/2601.13394)
*Munkaila Dasumani,Suzanne Lenhart,Gladys K. Onyambu,Stephen E. Moore*

Main category: math.OC

TL;DR: 该研究应用离散时间最优控制理论分析两种不同事件顺序的物种增强模型，探讨捕食者-猎物关系中不同增强时机对种群动态的影响。


<details>
  <summary>Details</summary>
Motivation: 物种增强是促进生物多样性、防止濒危物种灭绝的重要方法。当前研究旨在通过最优控制理论，分析在捕食者-猎物关系中，不同事件顺序（增强时机）对物种增强效果的影响，为保护生物学提供理论指导。

Method: 建立两种离散时间最优控制模型，分别代表不同的事件顺序：模型1先发生种群增长和捕食者-猎物作用，后进行增强；模型2先进行增强，然后种群增长，最后捕食者-猎物作用。两种模型都考虑了强Allee效应。采用离散版本的前向-后向扫描方法和序列二次规划迭代方法进行数值模拟。

Result: 数值模拟显示，在不同参数场景下，两种模型产生不同的种群水平。计算了带有最优控制的目标函数值百分比增加量。两种事件顺序下需要采用不同的最优增强策略，模型结果差异显著。

Conclusion: 这是首次在包含捕食者-猎物关系的离散事件模型中得出最优增强结果的研究。不同事件顺序对物种增强效果有重要影响，为保护实践中的增强时机选择提供了理论依据。

Abstract: Species augmentation is one of the methods used to promote biodiversity and prevent endangered species loss and extinction. The current work applies discrete-time optimal control theory to two models of species augmentation for predator-prey relationships. In discrete-time models, the order in which events occur can give different qualitative results. Two models representing different orders of events of optimal augmentation timing are considered. In one model, the population grows and predator-prey action occurs before the translocation of reserve species for augmentation. In the second model, the augmentation happens first and is followed by growth and then predator-prey action.
  The reserve and target populations are subjected to strong Allee effects. The optimal augmentation models employed in this work aim to maximize the prey (target population) and reserve population at the final time and minimize the associated cost at each time step. Numerical simulations in the two models are conducted using the discrete version of the forward-backward sweep method and the sequential quadratic programming iterative method, respectively. The simulation results show different population levels in the two models under varying parameter scenarios. Objective functional values showing percentage increases with optimal controls are calculated for each simulation. Different optimal augmentation strategies for the two orders of events are discussed. This work represents the first optimal augmentation results for models incorporating the predator-prey relationship with discrete events.

</details>


### [583] [Generalized Adjoint Method](https://arxiv.org/abs/2601.13395)
*Andrew Zheng,Adam R. Stinchcombe*

Main category: math.OC

TL;DR: 论文提出了一种针对复变量优化问题的广义伴随方法，能够处理非全纯（非解析）的成本函数和约束函数。


<details>
  <summary>Details</summary>
Motivation: 传统伴随方法仅适用于实变量和可微函数，但在电磁学和信号处理等逆问题中经常出现复变量，导致成本函数和约束函数可能非全纯（非解析）而不可微，需要新的计算方法。

Method: 使用CR-微积分（柯西-黎曼微积分）理论，构建广义伴随方法，即使在成本函数和约束函数都非全纯的情况下，也能计算成本函数的最速上升方向并同时满足约束条件。

Result: 该方法能够有效处理复变量优化问题中的非全纯函数，为电磁学和信号处理等领域的逆问题提供了数值计算梯度的新工具。

Conclusion: 通过CR-微积分扩展的广义伴随方法成功解决了复变量优化中非全纯函数的梯度计算问题，填补了传统伴随方法在复变量领域的局限性。

Abstract: The adjoint method is an efficient way to numerically compute gradients in optimization problems with constraints, but is only formulated to differentiable cost and constraint functions on real variables. With the introduction of complex variables, which occur often in many inverse problems in electromagnetism and signal processing problems, both the cost and constraint can become non-holomorphic and hence non-differentiable in the standard definitions. Using the notion of CR-calculus, a generalized adjoint method is introduced that can compute the direction of steepest ascent for the cost function while enforcing the constraint even if both are non-holomorphic.

</details>


### [584] [Self-Supervised Learning of Parametric Approximation for Security-Constrained DC-OPF](https://arxiv.org/abs/2601.13486)
*Anderson Anrrango,André Quisaguano,Gonzalo E. Constante-Flores,Can Li*

Main category: math.OC

TL;DR: 提出一种自监督学习框架，用于近似安全约束直流最优潮流问题，通过图神经网络预测可调参数，无需标注数据即可训练。


<details>
  <summary>Details</summary>
Motivation: 传统安全约束直流最优潮流计算复杂，难以满足实时电力系统运行需求，需要开发高效、可扩展且可解释的近似方法。

Method: 采用参数化线性模型保持直流最优潮流物理结构，引入需求依赖的可调参数缩放输电线路极限，通过图神经网络预测参数，利用可微分层优化，集成预想事故和事故后优化层到隐式损失函数中。

Result: 在基准系统上的数值实验表明，该方法具有高调度精度、低成本近似误差和强数据效率，优于半监督和端到端基线方法。

Conclusion: 该可扩展且可解释的方法为实时安全电力系统运行提供了有前景的解决方案。

Abstract: This paper introduces a self-supervised learning framework for approximating the Security-Constrained DC Optimal Power Flow (SC-DCOPF) problem using a parametric linear model. The approach preserves the physical structure of the DC-OPF while incorporating demand-dependent tunable parameters that scale transmission line limits. These parameters are predicted via a Graph Neural Network and optimized through differentiable layers, enabling direct training from contingency costs without requiring labeled data. The framework integrates pre- and post-contingency optimization layers into an implicit loss function. Numerical experiments on benchmark systems demonstrate that the proposed method achieves high dispatch accuracy, low cost approximation error, and strong data efficiency, outperforming semi-supervised and end-to-end baselines. This scalable and interpretable approach offers a promising solution for real-time secure power system operations.

</details>


### [585] [Hidden convexity of quadratic systems and its application to quadratic programming](https://arxiv.org/abs/2601.13511)
*Nguyen Quang Huy,Nguyen Huy Hung,Tran Van Nghi,Hoang Ngoc Tuan,Nguyen Van Tuyen*

Main category: math.OC

TL;DR: 本文研究了二次函数与非负象限之和的凸性条件，建立了带线性不等式约束的信任域问题的隐藏凸性，完善了两个二次函数系统的隐藏凸性证明，研究了二次不等式系统的S引理条件，并推导了二次规划的全局最优性条件和强对偶性结果。


<details>
  <summary>Details</summary>
Motivation: 研究二次函数与非负象限之和的凸性条件，这对于优化问题特别是二次规划具有重要意义。先前的研究中存在一些未完全解决的问题，如信任域问题的隐藏凸性条件、两个二次函数系统的隐藏凸性证明等，需要进一步澄清和完善。

Method: 1. 建立二次函数图像与非负象限之和凸性的充分条件；2. 提出新的假设条件，建立带线性不等式约束的信任域问题的隐藏凸性，并与先前研究中的条件进行比较；3. 提供两个二次函数系统隐藏凸性的完整证明；4. 研究二次不等式系统S引理的充要条件；5. 推导二次规划的全局最优性条件和强对偶性结果。

Result: 1. 获得了二次函数与非负象限之和凸性的充分条件；2. 在提出的新假设下建立了信任域问题的隐藏凸性，并比较了与先前条件的差异；3. 完善了两个二次函数系统隐藏凸性的证明；4. 得到了二次不等式系统S引理的充要条件；5. 建立了二次规划的全局最优性条件和强对偶性结果。

Conclusion: 本文系统研究了二次函数相关的凸性、隐藏凸性和最优性条件问题，为二次规划理论提供了重要的理论支撑。所建立的充分条件、隐藏凸性结果、S引理条件和最优性条件完善了该领域的理论基础，具有重要的理论价值。

Abstract: In this paper, we present sufficient conditions ensuring that the sum of the image of quadratic functions and the nonnegative orthant is convex. The hidden convexity of the trust-region problem with linear inequality constraints is established under a newly proposed assumption, which is compared with the previous one in [{\it Math. Program. 147, 171--206, 2014}]. We also provide a complete proof of the hidden convexity of a system of two quadratic functions in [{\it J. Glob. Optim. 56, 1045--1072, 2013}]. Furthermore, necessary and sufficient conditions for the S-lemma concerning systems of quadratic inequalities are investigated. Finally, we derive necessary and sufficient global optimality conditions and strong duality results for quadratic programming.

</details>


### [586] [Control policies for a two-stage queueing system with parallel and single server options](https://arxiv.org/abs/2601.13576)
*Shuwen Lu,Jamol Pender,Mark E. Lewis*

Main category: math.OC

TL;DR: 研究两阶段串联服务队列，服务器在完成第一阶段后决定将任务发送到并行处理的下游站还是单服务设施，以优化系统性能。


<details>
  <summary>Details</summary>
Motivation: 研究两阶段服务系统中任务路由决策问题，服务器在第一阶段完成后需要决定将任务发送到并行处理的下游站还是单服务设施，后者虽然处理速度更快或质量更高但只能处理一个任务，这种决策会影响系统整体效率和等待时间。

Method: 采用马尔可夫决策过程建模，建立带有各站点持有成本的清空系统模型，基于下游站点服务速率之间的关系，完全刻画了最优控制策略的结构特性。

Result: 通过数值研究，将最优控制策略与几种自然启发式策略进行性能比较，突显了最优控制策略的重要性。

Conclusion: 该研究为两阶段串联服务队列中的任务路由决策提供了理论框架和最优策略分析，展示了最优控制在提升系统性能方面的重要价值。

Abstract: We study a two-stage tandem service queue attended by two servers. Each job-server pair must complete both service phases together, with the server unable to begin a new job until the current one is fully processed after two stages. Immediately after the first phase of service, the server decides whether to send the job/customer to a downstream station that allows parallel processing or to a single-service facility that offers faster or higher-quality service but handles only one job at a time. This choice determines whether the second phase commences immediately or (potentially) after waiting in a queue for the single-service facility to become available.
  The decision-making scenario is modeled via a Markov decision process formulation, of a clearing system with holding costs at each station. We fully characterize the structural properties of an optimal control policy based on the relationship between the service rates at the downstream stations. A numerical study highlights the significance of optimal control by comparing its performance against several natural heuristic policies.

</details>


### [587] [Balancing Independent and Collaborative Service](https://arxiv.org/abs/2601.13586)
*Shuwen Lu,Mark E. Lewis,Jamol Pender*

Main category: math.OC

TL;DR: 研究双类型服务器排队系统，灵活型I类服务器在首次接触作业时实时决定独立处理还是与专用II类服务器协作处理。最优策略具有阈值结构，提出基于线性近似的简单阈值启发式算法，在多数参数和状态空间下性能接近最优。


<details>
  <summary>Details</summary>
Motivation: 研究服务器资源分配优化问题，特别是灵活型服务器在实时决策中如何平衡独立处理与协作处理的权衡。实际应用中，如云计算、客服中心等场景，需要高效分配不同类型的服务器资源以最小化系统成本。

Method: 1. 建立双类型服务器排队模型：I类服务器灵活，II类服务器专用；2. 分析清空系统的最优策略结构特性；3. 提出基于线性近似的简单阈值启发式算法；4. 理论分析启发式阈值与最优阈值的界限关系；5. 通过数值实验验证算法性能。

Result: 1. 最优控制策略具有基于队列长度和服务状态的阈值结构；2. 在多数参数和状态空间下，启发式算法阈值与最优阈值有理论界限；3. 数值实验显示启发式算法平均成本仅比最优策略高0.5%；4. 算法在高初始队列长度时表现稳健；5. 显著优于对参数敏感且成本可能超过最优100%的基准策略。

Conclusion: 提出的简单阈值启发式算法在双类型服务器排队系统中表现优异，接近最优性能且稳健，特别适用于高负载场景，为实时决策提供了实用有效的解决方案。

Abstract: We study a two-type server queueing system where flexible Type-I servers, upon their initial interaction with jobs, decide in real time whether to process them independently or in collaboration with dedicated Type-II servers. Independent processing begins immediately, as does collaborative service if a Type-II server is available. Otherwise, the job and its paired Type-I server wait in queue for collaboration. Type-I servers are non-preemptive and cannot engage with new jobs until their current job is completed.
  We provide a complete characterization of the structural properties of the optimal policy for the clearing system. In particular, an optimal control is shown to follow a threshold structure based on the number of jobs in the queue before a Type-I first interaction and on the number of jobs in either independent or collaborative service.
  We propose simple threshold heuristics, based on linear approximations, for real-time decision-making. In much of the parameter and state spaces, we establish theoretical bounds that compare the thresholds proposed by our heuristics to those of optimal policies and identify parameter configurations where these bounds are attained. Outside of these regions, the optimal thresholds are infinite. Numerical experiments further demonstrate the accuracy and robustness of our heuristics, particularly when the initial queue length is high. Our proposed heuristics achieve costs within 0.5% of the optimal policy on average and significantly outperform benchmark policies that exhibit extreme sensitivity to system parameters, sometimes incurring costs exceeding 100% of the optimal.

</details>


### [588] [Distributed Coverage Control on Poriferous Surface via Poly-Annulus Conformal Mapping](https://arxiv.org/abs/2601.13688)
*Xun Feng,Chao Zhai*

Main category: math.OC

TL;DR: 提出了一种用于多孔表面的分布式微分同胚覆盖控制框架，通过保形映射将多孔表面转换为多孔圆盘，设计无碰撞扇形分区机制，并基于黎曼度量实现分布式梯度控制，确保障碍物避让和覆盖优化。


<details>
  <summary>Details</summary>
Motivation: 多孔表面的固有非凸性通常会使智能体陷入局部最小值，并使工作量分配复杂化。需要解决在多孔表面上进行分布式覆盖控制时面临的拓扑约束和障碍物避让问题。

Method: 1) 建立分布式多环保形映射，将任意多孔表面转换为多孔圆盘；2) 在多孔圆盘中设计无碰撞扇形分区机制，确保严格连通子区域和工作负载平衡；3) 构建拉回黎曼度量来编码安全约束；4) 基于该度量合成分布式梯度控制律，驱动智能体达到最优配置。

Result: 理论分析保证了分区动态的输入到状态稳定性(ISS)和闭环系统的渐近收敛性。数值模拟证实了所提覆盖算法的可达性和鲁棒性，为多孔表面的分布式覆盖提供了可扩展解决方案。

Conclusion: 该框架成功解决了多孔表面上的分布式覆盖控制问题，通过拓扑变换、安全分区和黎曼度量控制，实现了障碍物避让、工作负载平衡和覆盖优化的统一解决方案。

Abstract: The inherent non-convexity of poriferous surfaces typically entraps agents in local minima and complicates workload distribution. To resolve this, we propose a distributed diffeomorphic coverage control framework for the multi-agent system (MAS) in such surfaces. First, we establish a distributed poly-annulus conformal mapping that transforms arbitrary poriferous surfaces into a multi-hole disk. Leveraging this topological equivalence, a collision-free sectorial partition mechanism is designed in the multi-hole disk, which rigorously induces strictly connected subregions and workload balance on the poriferous surfaces. This mechanism utilizes a buffer-based sequence mechanism to ensure strict topological safety when bypassing obstacles. Furthermore, a pull-back Riemannian metric is constructed to define the length metric that encodes safety constraints. Based on this metric, a distributed gradient-based control law is synthesized to drive agents toward optimal configurations, ensuring simultaneous obstacle avoidance and coverage optimization. Theoretical analyses guarantee the Input-to-State Stability (ISS) of the partition dynamics and the asymptotic convergence of the closed-loop system. Numerical simulations confirm the reachability and robustness of the proposed coverage algorithm, offering a scalable solution for distributed coverage in poriferous surfaces.

</details>


### [589] [A turnpike property in an eigenvalue optimization problem](https://arxiv.org/abs/2601.13756)
*Adam Kaminer,Thomas Kriecherbauer,Lars Grüne,Michael Margaliot*

Main category: math.OC

TL;DR: 论文证明了mRNA翻译非线性动力学模型中约束特征值优化问题的最优参数序列具有"收费站"结构：首尾部分较短，中间部分参数值近似相等。


<details>
  <summary>Details</summary>
Motivation: 研究细胞中mRNA翻译的重要非线性动力学模型中的约束特征值优化问题。收费站性质在计量经济学和最优控制理论中受到广泛关注，但这是首次在特征值优化问题中给出此类结构的严格证明。

Method: 采用数学分析方法，对约束特征值优化问题的最优参数序列进行理论分析，证明其具有收费站结构。

Result: 证明了最优参数序列包含三个部分：首尾部分相对较短，中间部分的所有参数值近似相等，形成了典型的收费站结构。

Conclusion: 这是首次在特征值优化问题中严格证明收费站结构的存在，为mRNA翻译动力学模型提供了重要的理论分析工具，并扩展了收费站理论的应用范围。

Abstract: We consider a constrained eigenvalue optimization problem that arises in an important nonlinear dynamical model for mRNA translation in the cell. We prove that the ordered list of optimal parameters admits a turnpike property, namely, it includes three parts with the first and third part relatively short, and the values in the middle part are all approximately equal. Turnpike properties have attracted considerable attention in econometrics and optimal control theory, but to the best of our knowledge this is the first rigorous proof of such a structure in an eigenvalue optimization problem.

</details>


### [590] [Derivative free data-driven stabilization of continuous-time linear systems from input-output data](https://arxiv.org/abs/2601.13848)
*Corrado Possieri*

Main category: math.OC

TL;DR: 提出一种基于输入输出数据的连续时间线性时不变系统稳定控制器设计框架，无需测量或估计时间导数


<details>
  <summary>Details</summary>
Motivation: 传统控制器设计通常需要系统模型或状态信息，但在实际应用中，获取准确的系统模型或状态导数测量可能困难。本文旨在直接从输入输出数据设计稳定控制器，避免对时间导数测量的依赖。

Method: 使用滤波器推导系统动态的参数化表示，该参数化适用于线性矩阵不等式方法，仅需输入输出数据和系统阶数信息即可设计稳定输出反馈控制器。

Result: 开发了一个数据驱动的控制器设计框架，能够直接从输入输出数据设计稳定控制器，无需依赖输入输出时间导数的测量或可靠估计。

Conclusion: 提出的滤波器方法为连续时间线性时不变系统的数据驱动控制器设计提供了有效途径，仅需输入输出数据和系统阶数信息，避免了传统方法中对时间导数测量的需求。

Abstract: This letter presents a data-driven framework for the design of stabilizing controllers from input-output data in the continuous-time, linear, and time-invariant domain. Rather than relying on measurements or reliable estimates of input and output time derivatives, the proposed approach uses filters to derive a parameterization of the system dynamics. This parameterization is amenable to the application of linear matrix inequalities enabling the design of stabilizing output feedback controllers from input-output data and the knowledge of the order of the system.

</details>


### [591] [Optimizing the Geometry of an L-Shaped Building to Enhance Energy Efficiency and Sustainability](https://arxiv.org/abs/2601.13884)
*Ewa Rokita-Magdziarz,Barbara Gronostajska,Marcin Magdziarz*

Main category: math.OC

TL;DR: 本文通过解析优化L形住宅建筑，在给定体积下最小化外表面积，考虑对称和非对称配置，推导出最优几何参数和最小围护面积的闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 建筑的几何形状对其材料使用、热损失和能源效率有重要影响。L形住宅建筑在现实中常见，但缺乏系统性的几何优化方法，需要在早期设计阶段平衡功能需求、规范约束、建筑意图和能源性能。

Method: 采用解析优化方法，考虑对称和非对称配置，在固定或有限翼展比、固定建筑高度等实际设计约束下，使用显式优化方法和KKT条件推导最优几何参数和最小围护面积的闭式表达式。

Result: 无约束优化会导致退化的长方体形状，凸显了几何约束对保持L形形式的重要性。推导出的闭式表达式为建筑师和工程师提供了实用设计指南。现有住宅案例研究表明，该方法能减少外表面积或确认实际设计的近优性。

Conclusion: 提出的解析优化方法为L形住宅建筑提供了实用的设计指南，支持早期建筑决策中平衡功能需求、规范约束、建筑意图和能源性能，有助于实现能源高效的建筑设计。

Abstract: The geometric form of a building strongly influences its material use, heat losses, and energy efficiency. This paper presents an analytical optimization of L-shaped residential buildings aimed at minimizing the external surface area for a prescribed volume. Both symmetric and asymmetric configurations are examined under realistic design constraints, including fixed or bounded wing aspect ratios and fixed building height. Using explicit optimization methods and Karush-Kuhn-Tucker conditions, closed-form expressions for the optimal geometric parameters and minimal envelope area are derived. The results show that unconstrained optimization leads to degenerate cuboid shapes, highlighting the importance of geometric constraints to preserve the L-shaped form. The obtained results provide practical design guidelines for architects and engineers, supporting informed early stage decisions that balance functional requirements, regulatory constraints, architectural intent, and energy performance. Case studies of existing houses demonstrate that the proposed approach can reduce external surface area or confirm near-optimality of practical designs, supporting energy-efficient early-stage architectural decisions.

</details>


### [592] [From geometry to sustainability: Optimal shapes of hip roof houses](https://arxiv.org/abs/2601.13896)
*Ewa Rokita-Magdziarz,Barbara Gronostajska,Marcin Magdziarz*

Main category: math.OC

TL;DR: 本文为四坡屋顶房屋几何优化建立了严格的数学框架，旨在给定设计约束下最小化建筑围护结构的外表面积，推导出五种场景的最优尺寸公式，并提供免费软件工具。


<details>
  <summary>Details</summary>
Motivation: 通过数学建模优化四坡屋顶房屋几何形状，最小化建筑围护结构外表面积，以提高材料效率、降低建造成本、改善能源性能，支持可持续建筑设计。

Method: 建立严格的数学优化框架，系统分析五种设计约束场景：固定体积、固定占地面积比、固定细长比、固定楼层面积和约束高度。为每种情况推导最优尺寸的显式公式。

Result: 研究发现正方形基础平面结合平衡的细长比能产生最高效的形式，而偏向细长或扁平的比例会显著增加能源和材料需求。通过实际案例研究验证了理论结果，并开发了免费软件应用。

Conclusion: 这项工作展示了数学建模与建筑设计的整合如何支持可持续建筑，为塑造能源高效、成本效益高且美学协调的住宅建筑提供了理论见解和实用工具。

Abstract: In this paper, we develop a rigorous mathematical framework for the optimization of hip roof house geometry, with the primary goal of minimizing the external surface of the building envelope for a given set of design constraints. Five optimization scenarios are systematically analyzed: fixed volume, fixed footprint ratio, fixed slenderness ratio, fixed floor area, and constrained height. For each case, explicit formulas for the optimal dimensions are derived, offering architects and engineers practical guidelines for improving material efficiency, reducing construction costs, and enhancing energy performance. To illustrate the practical relevance of the theoretical results, case studies of real-world hip roof houses are presented, revealing both inefficiencies in common practice and near-optimal examples. Furthermore, a freely available software application has been developed to support designers in applying the optimization methods directly to architectural projects. The findings confirm that square-based footprints combined with balanced slenderness ratios yield the most efficient forms, while deviations toward elongated or flattened proportions significantly increase energy and material demands. This work demonstrates how mathematical modeling and architectural design can be integrated to support sustainable architecture, providing both theoretical insight and practical tools for shaping energy-efficient, cost-effective, and aesthetically coherent residential buildings.

</details>


### [593] [Designing sustainable barn-type houses: Optimal shapes for minimal envelope and energy use](https://arxiv.org/abs/2601.13911)
*Ewa Rokita-Magdziarz,Barbara Gronostajska,Marcin Magdziarz*

Main category: math.OC

TL;DR: 本文开发了谷仓式房屋几何优化的数学框架，推导出最小化外表面积的最优比例闭式解，并开发了实用软件工具。


<details>
  <summary>Details</summary>
Motivation: 谷仓式房屋因简洁、功能性和节能潜力在欧洲广泛流行，但缺乏系统优化其几何形状以最小化外表面积和提升能源性能的方法。

Method: 建立严格的数学框架，推导谷仓式房屋在固定体积或固定面积约束下最小化外表面积的最优宽度、长度和高度的闭式解，计算紧凑度指标，并开发实用软件工具。

Result: 获得了最优比例的显式函数解和最小表面积公式，应用于三个实际案例显示部分设计已接近最优，部分偏离较大，理论优化可显著降低建造成本和能源需求。

Conclusion: 理论几何优化对谷仓式房屋具有实际意义，开发的免费软件工具可帮助建筑师和工程师进行优化分析，实现成本节约和能源效率提升。

Abstract: Barn-type houses have become one of the most popular single-family housing typologies in Poland and across Europe due to their simplicity, functionality, and potential for energy efficiency. Despite their widespread use, systematic methods for optimizing their geometry in terms of envelope area and energy performance remain limited. This paper develops a rigorous mathematical framework for determining the optimal proportions of barn-type houses with respect to minimizing the external surface area while satisfying constraints of either fixed volume or fixed floor area. Closed-form solutions for the optimal width, length, and height are derived as explicit functions of the roof slope, together with formulas for the minimal achievable surface. A recently introduced dimensionless compactness measure is also calculated, allowing quantitative assessment of how far a given design deviates from the theoretical optimum. The methodology is applied to case studies of three existing houses, showing that while some designs deviate significantly from optimal compactness, others already closely approximate it. The results confirm that theoretical optimization can lead to meaningful reductions in construction costs and energy demand. To support practical implementation, two original freely available software tools were developed, enabling architects and engineers to perform optimization analyses.

</details>


### [594] [A Bregman Regularized Proximal Point Method for Solving Equilibrium Problems on Hadamard Manifolds](https://arxiv.org/abs/2601.13959)
*Shikher Sharma,Simeon Reich*

Main category: math.OC

TL;DR: 提出了一种在Hadamard流形上求解单调平衡问题的Bregman正则化近端点算法，证明了在强凸性假设下的收敛性，并通过数值实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在Hadamard流形上，Bregman函数诱导的正则化项通常是非凸的（除非曲率为零），这给平衡问题的求解带来了挑战。现有文献中的Bregman正则化方法通常需要较强的假设条件，需要开发更弱条件下的收敛算法。

Method: 提出了Bregman正则化近端点算法，用于求解Hadamard流形上的单调平衡问题。该方法采用Bregman函数作为正则化项，在强凸性假设下证明收敛性，并且使用了比现有文献更弱的Bregman函数强制性条件。

Result: 证明了所提算法在Hadamard流形上收敛到平衡问题的解，即使Bregman正则化项通常是非凸的。数值实验表明该方法在实际应用中有效。

Conclusion: 成功开发了一种在Hadamard流形上求解单调平衡问题的Bregman正则化近端点算法，在较弱的强制性条件下实现了收敛，并通过数值实验验证了其实用性。

Abstract: In this paper we develop a Bregman regularized proximal point algorithm for solving monotone equilibrium problems on Hadamard manifolds. It has been shown that the regularization term induced by a Bregman function is, in general, nonconvex on Hadamard manifolds unless the curvature is zero. Nevertheless, we prove that the proposed Bregman regularization scheme does converge to a solution of the equilibrium problem on Hadamard manifolds in the presence of a strong assumption on the convexity of the set formed by the regularization term. Moreover, we employ a coercivity condition on the Bregman function which is weaker than those typically assumed in the existing literature on Bregman regularization. Numerical experiments on illustrative examples demonstrate the practical effectiveness of our proposed method.

</details>


### [595] [A global stochastic maximum principle for delayed forward-backward stochastic control systems](https://arxiv.org/abs/2601.14138)
*Feng Li*

Main category: math.OC

TL;DR: 提出了一种处理非凸控制域延迟正倒向随机控制系统的全局随机最大值原理新方法


<details>
  <summary>Details</summary>
Motivation: 研究系数依赖于状态和控制项、控制域非凸的延迟正倒向随机控制系统，现有方法在处理此类复杂系统时存在局限性

Method: 引入一阶和二阶辅助方程的新方法，推导伴随方程和变分方程 $y^\epsilon - y^*$

Result: 获得了全局随机最大值原理，为处理非凸控制域延迟随机控制系统提供了新工具

Conclusion: 所提出的新方法有效解决了非凸控制域延迟正倒向随机控制系统的优化问题，扩展了随机控制理论的应用范围

Abstract: In this paper, we study a delayed forward-backward stochastic control system in which all the coefficients depend on the state and control terms, and the control domain is not necessarily convex. A global stochastic maximum principle is obtained by using a new method. More precisely, this method introduces first-order and second-order auxiliary equations and offers a novel approach to deriving the adjoint equations as well as the variational equation for $y^\e - y^*$.

</details>


### [596] [Gradient Flow for Finding E-optimal Designs](https://arxiv.org/abs/2601.14147)
*Jieling Shi,Kim-Chuan Toh,Xin T. Tong,Weng Kee Wong*

Main category: math.OC

TL;DR: 使用Wasserstein梯度流求解回归模型的E最优设计问题，通过最优运输理论处理非光滑的E准则优化


<details>
  <summary>Details</summary>
Motivation: E最优设计在统计应用中广泛存在，但E准则（最大化信息矩阵最小特征值）是非光滑优化问题，除非最小特征值的几何重数为1，这带来了理论和计算上的挑战。现有方法多为启发式，需要更系统的方法来处理这类极大极小设计问题。

Method: 基于2-Wasserstein空间的微分结构，推导简单特征值情况下E最优性准则的Wasserstein梯度显式公式。对于高重数情况，提出Wasserstein最速上升方向，通过半定规划松弛精确计算。开发粒子近似连接无限维流与有限维优化，提供经验测度的近似保证。通过投影Wasserstein梯度流自然扩展到约束设计。

Result: 数值实验表明，所提方法成功恢复了线性和非线性回归模型的E最优设计，与现有启发式方法相比具有竞争性的准确性和可扩展性。证明了最优运输动力学作为研究挑战性最优设计问题的统一工具的潜力。

Conclusion: Wasserstein梯度流为处理非光滑的E最优设计问题提供了系统框架，将最优运输理论应用于统计设计优化，为解决极大极小设计问题开辟了新途径，展示了最优运输动力学在统计优化中的广泛应用前景。

Abstract: We investigate the use of Wasserstein gradient flows for finding an $E$-optimal design for a regression model. Unlike the commonly used $D$- and $L$-optimality criteria, the $E$-criterion finds a design that maximizes the smallest eigenvalue of the information matrix, and so it is a non-differentiable criterion unless the minimum eigenvalue has geometric multiplicity equals to one. Such maximin design problems abound in statistical applications and present unique theoretical and computational challenges. Building on the differential structure of the $2$-Wasserstein space, we derive explicit formulas for the Wasserstein gradient of the $E$-optimality criterion in the simple-eigenvalue case. For higher multiplicities, we propose a Wasserstein steepest ascent direction and show that it can be computed exactly via a semidefinite programming (SDP) relaxation. We develop particle approximations that connect infinite-dimensional flows with finite-dimensional optimization, and provide approximation guarantees for empirical measures. Our framework extends naturally to constrained designs via projected Wasserstein gradient flows. Numerical experiments demonstrate that the proposed methods successfully recover $E$-optimal designs for both linear and nonlinear regression models, with competitive accuracy and scalability compared to existing heuristic approaches. This work highlights the potential of optimal transport-based dynamics as a unifying tool for studying challenging optimal design problems.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [597] [Market Making and Transient Impact in Spot FX](https://arxiv.org/abs/2601.13421)
*Alexander Barzykin*

Main category: q-fin.TR

TL;DR: 研究外汇交易商在考虑市场冲击恢复特性时的最优报价策略，分析风险管理和市场冲击弹性之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 传统Almgren-Chriss模型将市场冲击分为瞬时和永久两部分，但实证证据表明市场冲击本质上是瞬态的。需要研究在中间情景下，交易商如何平衡报价偏斜和套期保值策略。

Method: 在考虑市场冲击恢复特性的框架下，分析交易商的最优做市策略，研究报价偏斜与银行间市场套期保值的权衡。

Result: 建立了考虑市场冲击弹性的最优做市模型，揭示了风险管理与市场冲击恢复特性之间的相互作用机制。

Conclusion: 市场冲击的瞬态特性对交易商的风险管理策略有重要影响，需要在报价偏斜和套期保值之间找到最优平衡，考虑市场冲击的恢复特性。

Abstract: Dealers in foreign exchange markets provide bid and ask prices to their clients at which they are happy to buy and sell, respectively. To manage risk, dealers can skew their quotes and hedge in the interbank market. Hedging offers certainty but comes with transaction costs and market impact. Optimal market making with execution has previously been addressed within the Almgren-Chriss market impact model, which includes instantaneous and permanent components. However, there is overwhelming empirical evidence of the transient nature of market impact, with instantaneous and permanent impacts arising as the two limiting cases. In this note, we consider an intermediate scenario and study the interplay between risk management and impact resilience.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [598] [Reevaluating Causal Estimation Methods with Data from a Product Release](https://arxiv.org/abs/2601.11845)
*Justin Young,Muthoni Ngatia,Eleanor Wiske Dillon*

Main category: econ.EM

TL;DR: 该论文通过分析大型科技公司的新功能实验数据，发现通过仔细的建模选择可以恢复真实因果效应，为高维数据集中的因果效应估计提供了最佳实践。


<details>
  <summary>Details</summary>
Motivation: 随着因果机器学习方法的发展，无混杂假设在因果分析中变得更加可行，但需要验证这些方法是否能成功恢复真实基准效应。

Method: 分析包含大型科技公司新功能实验推广数据的新样本，包括实验组用户和内生选择加入功能的用户对照组，结合观察性因果文献方法。

Result: 研究发现恢复真实因果效应是可行的，但需要仔细的建模选择，结果建立在LaLonde（1986）以来的观察性因果文献基础上。

Conclusion: 为现代高维数据集中的治疗效应估计提供了更可信的最佳实践指导，强调建模选择对因果推断准确性的重要性。

Abstract: Recent developments in causal machine learning methods have made it easier to estimate flexible relationships between confounders, treatments and outcomes, making unconfoundedness assumptions in causal analysis more palatable. How successful are these approaches in recovering ground truth baselines? In this paper we analyze a new data sample including an experimental rollout of a new feature at a large technology company and a simultaneous sample of users who endogenously opted into the feature. We find that recovering ground truth causal effects is feasible -- but only with careful modeling choices. Our results build on the observational causal literature beginning with LaLonde (1986), offering best practices for more credible treatment effect estimation in modern, high-dimensional datasets.

</details>


### [599] [Public Education Spending and Income Inequality](https://arxiv.org/abs/2601.11928)
*Ishmael Amartey*

Main category: econ.EM

TL;DR: 研究发现教育支出构成比支出总额对收入不平等影响更大，重新分配预算至教学、支持服务等经常性支出能显著降低不平等


<details>
  <summary>Details</summary>
Motivation: 探讨美国各县公共教育支出与收入不平等之间的关系，特别关注支出总额与支出构成的不同影响

Method: 使用分位数回归方法分析2010-2022年美国各县数据，考察教育支出总额和构成对收入不平等的影响

Result: 生均教育支出总额与收入不平等小幅正相关，而支出构成影响更大：教学、支持服务等经常性支出显著降低不平等，资本支出和利息支付效果较弱

Conclusion: 教育资金如何分配比支出总额更重要，预算构成对利用公共教育政策促进公平至关重要

Abstract: This paper investigates the relationship between public education spending and income inequality across U.S. counties from 2010 to 2022 using quantile regression methods. The analysis shows that total per pupil education spending is consistently associated with a small increase in income inequality, with stronger effects in high inequality counties. In contrast, the composition of education spending plays a substantially more important role. Reallocating budgets toward instructional, support service, and other current expenditures significantly reduces income inequality, particularly at the upper quantiles of the Gini distribution. Capital outlays and interest payments exhibit weaker and mixed effects. Economic and demographic factors, especially poverty, median income, and educational attainment, remain dominant drivers of inequality. Overall, the results demonstrate that how education funds are allocated matters more than how much is spent, underscoring the importance of budget composition in using public education policy to promote equity.

</details>


### [600] [Nonlinear Dynamic Factor Analysis With a Transformer Network](https://arxiv.org/abs/2601.12039)
*Oliver Snellman*

Main category: econ.EM

TL;DR: 提出一种基于Transformer的架构，用于从多元时间序列数据中估计动态因子，通过正则化项将传统因子模型作为先验信息，提高了小数据集性能，并利用注意力矩阵解释结果。


<details>
  <summary>Details</summary>
Motivation: 传统线性因子模型在数据偏离线性高斯假设时性能受限，需要更灵活的方法来估计动态因子，同时在小数据集上保持良好性能。

Method: 开发Transformer架构估计动态因子，使用传统因子模型作为先验信息通过正则化项融入训练目标，利用注意力矩阵解释变量及其滞后期对因子估计的相对重要性。

Result: 蒙特卡洛实验显示当数据偏离线性高斯假设时，Transformer比线性因子模型更准确；实证应用中成功构建了美国实际经济活动的一致指数；注意力模式的时间变化有助于检测制度转换和评估叙事。

Conclusion: Transformer架构为动态因子估计提供了灵活且可解释的方法，特别是在数据偏离传统假设时表现优异，注意力机制为经济分析提供了有价值的洞察工具。

Abstract: The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.

</details>


### [601] [A Robust Similarity Estimator](https://arxiv.org/abs/2601.12198)
*Ilya Archakov*

Main category: econ.EM

TL;DR: 提出一种基于方向和幅度相似性的关联性估计器，在线性相关条件下成为稳健一致的相关性估计，具有对厚尾和异常值不敏感的精确抽样分布，可扩展到多维并应用于金融高频数据


<details>
  <summary>Details</summary>
Motivation: 传统相关性估计方法对厚尾分布和异常值敏感，特别是在金融高频数据中表现不佳，需要一种更稳健的相关性度量方法

Method: 构建基于随机变量方向和幅度相似性的关联性估计器，在特定条件下转化为线性相关的稳健一致估计，推导其精确抽样分布，并扩展到多维情况

Result: 该估计器具有对厚尾和异常值不敏感的精确抽样分布，在高频和低频金融收益率数据中表现良好，可用于构建日内收益率的相关性置信区间和改进多元GARCH模型

Conclusion: 提出的相似性度量方法为相关性分析提供了稳健的统计工具，特别适用于金融高频数据中的相关性推断和建模

Abstract: We construct and analyze an estimator of association between random variables based on their similarity in both direction and magnitude. Under special conditions, the proposed measure becomes a robust and consistent estimator of the linear correlation, for which an exact sampling distribution is available. This distribution is intrinsically insensitive to heavy tails and outliers, thereby facilitating robust inference for correlations. The measure can be naturally extended to higher dimensions, where it admits an interpretation as an indicator of joint similarity among multiple random variables. We investigate the empirical performance of the proposed measure with financial return data at both high and low frequencies. Specifically, we apply the new estimator to construct confidence intervals for correlations based on intraday returns and to develop a new specification for multivariate GARCH models.

</details>


### [602] [How Well Do LLMs Predict Human Behavior? A Measure of their Pretrained Knowledge](https://arxiv.org/abs/2601.12343)
*Wayne Gao,Sukjin Han,Annie Liang*

Main category: econ.EM

TL;DR: 提出一种评估预训练大语言模型在预测人类行为时带来多少知识的度量方法：等效样本量，即需要多少任务特定数据才能达到LLM的预测准确度。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地用于预测人类行为，但需要一种方法来量化预训练LLM为这种预测带来了多少知识，以评估其作为领域特定数据替代品的价值。

Method: 通过比较固定LLM在特定领域的预测误差与在不断增加领域特定数据样本上训练的灵活机器学习模型的预测误差，来估计等效样本量。开发了交叉验证预测误差的新渐近理论，提供统计推断程序。

Result: 应用于收入动态面板研究，发现LLM对一些经济变量编码了相当大的预测信息，但对其他变量则少得多，表明其作为领域特定数据替代品的价值在不同情境下差异显著。

Conclusion: 提出的等效样本量度量方法能够量化预训练LLM带来的预测知识，有助于评估LLM在不同应用场景中作为领域特定数据替代品的适用性。

Abstract: Large language models (LLMs) are increasingly used to predict human behavior. We propose a measure for evaluating how much knowledge a pretrained LLM brings to such a prediction: its equivalent sample size, defined as the amount of task-specific data needed to match the predictive accuracy of the LLM. We estimate this measure by comparing the prediction error of a fixed LLM in a given domain to that of flexible machine learning models trained on increasing samples of domain-specific data. We further provide a statistical inference procedure by developing a new asymptotic theory for cross-validated prediction error. Finally, we apply this method to the Panel Study of Income Dynamics. We find that LLMs encode considerable predictive information for some economic variables but much less for others, suggesting that their value as substitutes for domain-specific data differs markedly across settings.

</details>


### [603] [Partial Identification under Stratified Randomization](https://arxiv.org/abs/2601.12566)
*Bruno Ferman,Davi Siqueira,Vitor Possebom*

Main category: econ.EM

TL;DR: 提出分层实验中存在流失情况下的部分识别与推断统一框架，处理等比例和异质处理比例两种情况，提供闭式方差估计和更紧的置信区间


<details>
  <summary>Details</summary>
Motivation: 传统方法在分层实验存在流失时可能高估不确定性，且对于异质处理比例的分层设计缺乏有效推断方法

Method: 对于等比例设计，应用精细分层实验理论到Lee界；对于异质比例设计，提出结合逆概率加权和全局修剪的新策略

Result: 模拟显示传统方法高估不确定性，新方法提供更紧的置信区间；新策略能在小样本或不平衡分层中构造有效边界

Conclusion: 建立了分层实验流失问题的统一识别和推断框架，扩展了现有方法到异质处理比例情况，适用于基于矩的估计器

Abstract: This paper develops a unified framework for partial identification and inference in stratified experiments with attrition, accommodating both equal and heterogeneous treatment shares across strata. For equal-share designs, we apply recent theory for finely stratified experiments to Lee bounds, yielding closed-form, design-consistent variance estimators and properly sized confidence intervals. Simulations show that the conventional formula can overstate uncertainty, while our approach delivers tighter intervals. When treatment shares differ across strata, we propose a new strategy, which combines inverse probability weighting and global trimming to construct valid bounds even when strata are small or unbalanced. We establish identification, introduce a moment estimator, and extend existing inference results to stratified designs with heterogeneous shares, covering a broad class of moment-based estimators which includes the one we formulate. We also generalize our results to designs in which strata are defined solely by observed labels.

</details>


### [604] [Spectral Dynamics and Regularization for High-Dimensional Copulas](https://arxiv.org/abs/2601.13281)
*Koos B. Gubbels,Andre Lucas*

Main category: econ.EM

TL;DR: 提出一种新的高维时变、非对称、尾部相关copula模型，结合谱动态和正则化，能有效捕捉金融市场的地理和行业共动，在压力时期揭示系统性风险变化。


<details>
  <summary>Details</summary>
Motivation: 现有高维copula模型在处理时变、非对称、尾部依赖关系时存在限制，特别是在捕捉金融市场复杂依赖结构（地理和行业共动）方面不足，需要更灵活且计算高效的模型。

Method: 采用谱动态建模方法，将依赖矩阵特征值的动态变化用score-driven方式建模，通过非线性收缩解决无条件特征值谱的偏差问题，确保依赖矩阵始终满足适当约束。

Result: 模型在模拟和实证数据上表现良好，在100只股票的实证应用中，能有效捕捉地理和行业相关共动，优于计算更密集的聚类因子copula替代方法，谱动态和正则化都对性能有贡献。

Conclusion: 该copula模型具有简洁性、计算高效性和高维可扩展性，在市场压力时期能揭示国际股市依赖性的显著增强，从而识别多样化潜力降低和系统性风险增加。

Abstract: We introduce a novel model for time-varying, asymmetric, tail-dependent copulas in high dimensions that incorporates both spectral dynamics and regularization. The dynamics of the dependence matrix' eigenvalues are modeled in a score-driven way, while biases in the unconditional eigenvalue spectrum are resolved by non-linear shrinkage. The dynamic parameterization of the copula dependence matrix ensures that it satisfies the appropriate restrictions at all times and for any dimension. The model is parsimonious, computationally efficient, easily scalable to high dimensions, and performs well for both simulated and empirical data. In an empirical application to financial market dynamics using 100 stocks from 10 different countries and 10 different industry sectors, we find that our copula model captures both geographic and industry related co-movements and outperforms recent computationally more intensive clustering-based factor copula alternatives. Both the spectral dynamics and the regularization contribute to the new model's performance. During periods of market stress, we find that the spectral dynamics reveal strong increases in international stock market dependence, which causes reductions in diversification potential and increases in systemic risk.

</details>


### [605] [Quantitative Methods in Finance](https://arxiv.org/abs/2601.12896)
*Eric Vansteenberghe*

Main category: econ.EM

TL;DR: 这是一份面向金融和经济学研究生的量化金融方法课程讲义，结合概率论、统计学、数值方法和实证建模，重点使用Python实现，强调理论到代码的转化。


<details>
  <summary>Details</summary>
Motivation: 为具有不同编程背景的金融和经济学研究生提供统一的量化方法工具包，强调可复现的代码实现，弥合理论概念与实际应用之间的差距。

Method: 采用综合方法，结合概率论、统计学、数值方法和实证建模，通过Python编程实现，注重向量化、数值稳定性和输出解释，通过实例和练习逐步连接理论与实践。

Result: 提供了一套完整的量化金融方法教学材料，涵盖随机变量与分布、矩与相关性、模拟与蒙特卡洛方法、数值优化、根查找以及金融和宏观金融中常用的时间序列模型。

Conclusion: 这些讲义旨在为编程基础不同的学习者提供清晰的入门指导，同时为应用研究人员提供透明可复现的量化方法参考，强调实践计算和理论到代码的转化。

Abstract: These lecture notes provide a comprehensive introduction to Quantitative Methods in Finance (QMF), designed for graduate students in finance and economics with heterogeneous programming backgrounds. The material develops a unified toolkit combining probability theory, statistics, numerical methods, and empirical modeling, with a strong emphasis on implementation in Python. Core topics include random variables and distributions, moments and dependence, simulation and Monte Carlo methods, numerical optimization, root-finding, and time-series models commonly used in finance and macro-finance. Particular attention is paid to translating theoretical concepts into reproducible code, emphasizing vectorization, numerical stability, and interpretation of outputs. The notes progressively bridge theory and practice through worked examples and exercises covering asset pricing intuition, risk measurement, forecasting, and empirical analysis. By focusing on clarity, minimal prerequisites, and hands-on computation, these lecture notes aim to serve both as a pedagogical entry point for non-programmers and as a practical reference for applied researchers seeking transparent and replicable quantitative methods in finance.

</details>


### [606] [Realised quantile-based estimation of the integrated variance](https://arxiv.org/abs/2601.13006)
*Kim Christensen,Roel Oomen,Mark Podolskij*

Main category: econ.EM

TL;DR: 提出一种基于分位数的跳跃稳健实现方差度量，适用于含噪声数据，对积分方差一致估计，具有最优收敛速率和效率


<details>
  <summary>Details</summary>
Motivation: 传统实现方差估计对价格序列中的跳跃和异常值敏感，且在高频数据中受市场微观结构噪声影响，需要开发稳健的方差度量方法

Method: 基于分位数的实现方差估计方法，通过分位数统计量构建方差度量，可处理有限活动跳跃和异常值，改进版本适用于含噪声的高频数据

Result: 估计量对积分方差具有一致性，达到最优收敛速率，有限样本中表现出优越的稳健性，实证应用展示在股票数据上的有效性

Conclusion: 提出的分位数实现方差估计量是稳健、高效且实用的方差度量工具，特别适用于含跳跃、异常值和噪声的金融时间序列分析

Abstract: In this paper, we propose a new jump robust quantile-based realised variance measure of ex-post return variation that can be computed using potentially noisy data. The estimator is consistent for the integrated variance and we present feasible central limit theorems which show that it converges at the best attainable rate and has excellent efficiency. Asymptotically, the quantile-based realised variance is immune to finite activity jumps and outliers in the price series, while in modified form the estimator is applicable with market microstructure noise and therefore operational on high-frequency data. Simulations show that it has superior robustness properties in finite sample, while an empirical application illustrates its use on equity data.

</details>


### [607] [A machine learning approach to volatility forecasting](https://arxiv.org/abs/2601.13014)
*Kim Christensen,Mathias Siggaard,Bezirgen Veliyev*

Main category: econ.EM

TL;DR: 机器学习在预测道琼斯工业平均指数成分股已实现方差方面表现优于传统HAR模型，尤其是在长期预测中，且能更好地从额外预测变量中提取信息。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习方法在预测金融时间序列（特别是已实现方差）方面的有效性，与传统Heterogeneous AutoRegressive (HAR) 模型进行比较，探索ML在金融波动率预测中的潜力。

Method: 使用多种机器学习算法（包括正则化方法、回归树和神经网络），与多个HAR模型进行对比。ML实现采用最小超参数调优，预测变量包括已实现方差的日、周、月滞后值。提出基于累积局部效应的变量重要性度量方法。

Result: 机器学习模型在预测已实现方差方面具有竞争力，即使只使用日、周、月滞后值作为预测变量，也能击败HAR模型系列。预测收益在更长的预测周期中更为显著，这归因于ML模型具有更高的持续性，能更好地近似已实现方差的长记忆特性。ML还能更好地从额外预测变量中提取增量信息。

Conclusion: 机器学习在金融波动率预测中表现出色，特别是在长期预测方面。虽然不同模型对最重要预测变量的看法一致，但在排序上存在分歧，这有助于解释研究结果的差异。提出的变量重要性度量方法为理解模型决策提供了新工具。

Abstract: We inspect how accurate machine learning (ML) is at forecasting realized variance of the Dow Jones Industrial Average index constituents. We compare several ML algorithms, including regularization, regression trees, and neural networks, to multiple Heterogeneous AutoRegressive (HAR) models. ML is implemented with minimal hyperparameter tuning. In spite of this, ML is competitive and beats the HAR lineage, even when the only predictors are the daily, weekly, and monthly lags of realized variance. The forecast gains are more pronounced at longer horizons. We attribute this to higher persistence in the ML models, which helps to approximate the long-memory of realized variance. ML also excels at locating incremental information about future volatility from additional predictors. Lastly, we propose a ML measure of variable importance based on accumulated local effects. This shows that while there is agreement about the most important predictors, there is disagreement on their ranking, helping to reconcile our results.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [608] [Gradient-based Active Learning with Gaussian Processes for Global Sensitivity Analysis](https://arxiv.org/abs/2601.11790)
*Guerlain Lambert,Céline Helbert,Claire Lauvernet*

Main category: stat.ML

TL;DR: 提出一种基于高斯过程代理模型的主动学习方法，通过利用梯度后验分布改进采集函数，在有限计算预算下提高复杂数值模拟器的全局敏感性分析精度。


<details>
  <summary>Details</summary>
Motivation: 复杂数值模拟器的全局敏感性分析通常受限于可负担的少量模型评估次数。在有限模拟次数下，需要高效丰富计算机实验设计来构建准确的代理模型。

Method: 基于高斯过程代理模型的主动学习方法，利用GP梯度的联合后验分布开发新的采集函数，更好地考虑偏导数之间的相关性及其对响应面的影响。

Result: 在标准基准函数上与最先进方法比较，并应用于农药迁移的真实环境模型，证明该方法比现有的DGSM导向准则更全面和稳健。

Conclusion: 提出的主动学习方法能够更有效地利用有限的计算预算，通过针对输入空间中最具信息量的区域，显著提高敏感性分析（Sobol指数和DGSM）的准确性。

Abstract: Global sensitivity analysis of complex numerical simulators is often limited by the small number of model evaluations that can be afforded. In such settings, surrogate models built from a limited set of simulations can substantially reduce the computational burden, provided that the design of computer experiments is enriched efficiently. In this context, we propose an active learning approach that, for a fixed evaluation budget, targets the most informative regions of the input space to improve sensitivity analysis accuracy. More specifically, our method builds on recent advances in active learning for sensitivity analysis (Sobol' indices and derivative-based global sensitivity measures, DGSM) that exploit derivatives obtained from a Gaussian process (GP) surrogate. By leveraging the joint posterior distribution of the GP gradient, we develop acquisition functions that better account for correlations between partial derivatives and their impact on the response surface, leading to a more comprehensive and robust methodology than existing DGSM-oriented criteria. The proposed approach is first compared to state-of-the-art methods on standard benchmark functions, and is then applied to a real environmental model of pesticide transfers.

</details>


### [609] [A Kernel Approach for Semi-implicit Variational Inference](https://arxiv.org/abs/2601.12023)
*Longlin Yu,Ziheng Cheng,Shiyue Zhang,Cheng Zhang*

Main category: stat.ML

TL;DR: KSIVI提出基于核方法的半隐式变分推断，通过核Stein差异替代双层优化，在保持表达能力的同时提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统SIVI因密度不可计算导致ELBO优化有偏，而SIVI-SM的极小极大公式需要额外的下层优化问题，计算复杂

Method: 利用核方法，在再生核希尔伯特空间中优化时下层问题有显式解，将目标简化为核Stein差异，利用半隐式分布的层次结构进行随机梯度优化

Result: 建立了蒙特卡洛梯度估计器的方差界优化保证，推导出Õ(1/√n)阶的统计泛化界，提出多层层次扩展增强表达能力

Conclusion: KSIVI为半隐式变分推断提供了理论严谨且计算可行的替代方案，在合成和真实贝叶斯推断任务中表现有效

Abstract: Semi-implicit variational inference (SIVI) enhances the expressiveness of variational families through hierarchical semi-implicit distributions, but the intractability of their densities makes standard ELBO-based optimization biased. Recent score-matching approaches to SIVI (SIVI-SM) address this issue via a minimax formulation, at the expense of an additional lower-level optimization problem. In this paper, we propose kernel semi-implicit variational inference (KSIVI), a principled and tractable alternative that eliminates the lower-level optimization by leveraging kernel methods. We show that when optimizing over a reproducing kernel Hilbert space, the lower-level problem admits an explicit solution, reducing the objective to the kernel Stein discrepancy (KSD). Exploiting the hierarchical structure of semi-implicit distributions, the resulting KSD objective can be efficiently optimized using stochastic gradient methods. We establish optimization guarantees via variance bounds on Monte Carlo gradient estimators and derive statistical generalization bounds of order $\tilde{\mathcal{O}}(1/\sqrt{n})$. We further introduce a multi-layer hierarchical extension that improves expressiveness while preserving tractability. Empirical results on synthetic and real-world Bayesian inference tasks demonstrate the effectiveness of KSIVI.

</details>


### [610] [On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization](https://arxiv.org/abs/2601.12238)
*Sharan Sahu,Cameron J. Hogan,Martin T. Wells*

Main category: stat.ML

TL;DR: 动量方法在动态环境中的理论分析：动量能抑制梯度噪声但会放大漂移误差，存在"惯性窗口"这一信息理论障碍


<details>
  <summary>Details</summary>
Motivation: 动量加速在确定性优化中已被广泛研究，但在非平稳环境（数据分布和最优参数随时间漂移）中的行为仍未被充分探索。需要理解SGD及其动量变体在动态环境中的跟踪性能

Method: 在均匀强凸性和平滑性假设下，分析SGD、Polyak重球法和Nesterov动量在不同步长机制下的跟踪性能。推导有限时间期望和高概率跟踪误差界，建立包含初始化项、噪声方差项和漂移跟踪滞后项的三分量分解

Result: 发现动量与跟踪能力之间的基本权衡：动量能抑制梯度噪声，但会显著放大漂移引起的跟踪误差，当动量参数接近1时放大效应无限增大。建立了梯度变化约束下的动态遗憾极小极大下界，证明惯性惩罚不是分析假象而是信息理论障碍

Conclusion: 动量在动态环境中存在不可避免的"惯性窗口"，会从根本上降低性能。这些结果为动量在动态环境中的经验不稳定性提供了明确的理论基础，并划定了SGD可证明优于其加速对应物的精确机制边界

Abstract: While momentum-based acceleration has been studied extensively in deterministic optimization problems, its behavior in nonstationary environments -- where the data distribution and optimal parameters drift over time -- remains underexplored. We analyze the tracking performance of Stochastic Gradient Descent (SGD) and its momentum variants (Polyak heavy-ball and Nesterov) under uniform strong convexity and smoothness in varying stepsize regimes. We derive finite-time bounds in expectation and with high probability for the tracking error, establishing a sharp decomposition into three components: a transient initialization term, a noise-induced variance term, and a drift-induced tracking lag. Crucially, our analysis uncovers a fundamental trade-off: while momentum can suppress gradient noise, it incurs an explicit penalty on the tracking capability. We show that momentum can substantially amplify drift-induced tracking error, with amplification that becomes unbounded as the momentum parameter approaches one, formalizing the intuition that using 'stale' gradients hinders adaptation to rapid regime shifts. Complementing these upper bounds, we establish minimax lower bounds for dynamic regret under gradient-variation constraints. These lower bounds prove that the inertia-induced penalty is not an artifact of analysis but an information-theoretic barrier: in drift-dominated regimes, momentum creates an unavoidable 'inertia window' that fundamentally degrades performance. Collectively, these results provide a definitive theoretical grounding for the empirical instability of momentum in dynamic environments and delineate the precise regime boundaries where SGD provably outperforms its accelerated counterparts.

</details>


### [611] [A Theory of Diversity for Random Matrices with Applications to In-Context Learning of Schrödinger Equations](https://arxiv.org/abs/2601.12587)
*Frank Cole,Yulong Lu,Shaurya Sehgal*

Main category: stat.ML

TL;DR: 该论文研究了随机矩阵集合中心化子为平凡的概率下界，并将其应用于Transformer网络在薛定谔方程上下文学习中的泛化能力保证。


<details>
  <summary>Details</summary>
Motivation: 研究随机矩阵集合中心化子为平凡的概率，为理解随机矩阵代数结构提供理论保证，并应用于机器学习中Transformer网络对薛定谔方程上下文学习的泛化能力分析。

Method: 针对从随机薛定谔算子离散化得到的几类随机矩阵族，建立样本大小N和维度d与中心化子为平凡概率之间的下界关系。

Result: 给出了随机矩阵集合中心化子为平凡概率的下界估计，这些结果与近期机器学习理论结合，为Transformer网络在薛定谔方程上下文学习中的泛化能力提供了理论保证。

Conclusion: 该研究建立了随机矩阵代数性质与机器学习泛化理论之间的联系，为基于Transformer的神经网络在物理方程学习中的应用提供了数学基础。

Abstract: We address the following question: given a collection $\{\mathbf{A}^{(1)}, \dots, \mathbf{A}^{(N)}\}$ of independent $d \times d$ random matrices drawn from a common distribution $\mathbb{P}$, what is the probability that the centralizer of $\{\mathbf{A}^{(1)}, \dots, \mathbf{A}^{(N)}\}$ is trivial? We provide lower bounds on this probability in terms of the sample size $N$ and the dimension $d$ for several families of random matrices which arise from the discretization of linear Schrödinger operators with random potentials. When combined with recent work on machine learning theory, our results provide guarantees on the generalization ability of transformer-based neural networks for in-context learning of Schrödinger equations.

</details>


### [612] [Approximate full conformal prediction in RKHS](https://arxiv.org/abs/2601.13102)
*Davidson Lova Razafindrakoto,Alain Celisse,Jérôme Lacaille*

Main category: stat.ML

TL;DR: 提出一种高效计算全保形预测置信区域的紧近似方法，并引入厚度概念量化近似误差


<details>
  <summary>Details</summary>
Motivation: 全保形预测框架虽然能构建分布无关的置信预测区域，但传统方法需要训练无限多个估计器，计算上不可行

Method: 设计通用策略构建全保形预测区域的紧近似，引入厚度概念量化近似与全保形区域之间的差异，理论分析依赖于损失函数和评分函数的平滑性假设

Result: 开发出可高效计算的近似置信区域，并建立了量化近似紧度的理论框架

Conclusion: 提出的方法解决了全保形预测计算不可行的问题，通过近似策略和厚度量化实现了实用化的分布无关置信预测

Abstract: Full conformal prediction is a framework that implicitly formulates distribution-free confidence prediction regions for a wide range of estimators. However, a classical limitation of the full conformal framework is the computation of the confidence prediction regions, which is usually impossible since it requires training infinitely many estimators (for real-valued prediction for instance). The main purpose of the present work is to describe a generic strategy for designing a tight approximation to the full conformal prediction region that can be efficiently computed. Along with this approximate confidence region, a theoretical quantification of the tightness of this approximation is developed, depending on the smoothness assumptions on the loss and score functions. The new notion of thickness is introduced for quantifying the discrepancy between the approximate confidence region and the full conformal one.

</details>


### [613] [Empirical Risk Minimization with $f$-Divergence Regularization](https://arxiv.org/abs/2601.13191)
*Francisco Daunas,Iñaki Esnaola,Samir M. Perlaza,H. Vincent Poor*

Main category: stat.ML

TL;DR: 本文提出了f-散度正则化经验风险最小化(ERM-fDR)问题的解决方案，建立了该解同时满足f-散度约束下期望经验风险最小化的条件，并引入了归一化函数的概念及其数值计算方法。


<details>
  <summary>Details</summary>
Motivation: 现有的f-散度正则化经验风险最小化方法适用范围有限，缺乏统一的数学框架。本文旨在扩展该方法到更广泛的f-散度类别，建立理论联系，并提供实用的计算工具。

Method: 引入归一化函数作为关键数学对象，建立其非线性常微分方程表征，证明其性质，并基于此构建数值算法。通过经验风险变换分析不同f-散度ERM-fDR问题的结构等价性。

Result: 扩展了ERM-fDR方法到更广泛的f-散度类别，恢复了已知结果。建立了归一化函数的ODE表征和数值算法，证明了不同f-散度问题的结构等价性，并通过数值实验展示了不同f函数选择的影响。

Conclusion: 本文为f-散度正则化经验风险最小化提供了统一的理论框架和计算工具，扩展了方法适用性，建立了不同f-散度问题的联系，为实际应用中的f函数选择提供了理论指导。

Abstract: In this paper, the solution to the empirical risk minimization problem with $f$-divergence regularization (ERM-$f$DR) is presented and conditions under which the solution also serves as the solution to the minimization of the expected empirical risk subject to an $f$-divergence constraint are established. The proposed approach extends applicability to a broader class of $f$-divergences than previously reported and yields theoretical results that recover previously known results. Additionally, the difference between the expected empirical risk of the ERM-$f$DR solution and that of its reference measure is characterized, providing insights into previously studied cases of $f$-divergences. A central contribution is the introduction of the normalization function, a mathematical object that is critical in both the dual formulation and practical computation of the ERM-$f$DR solution. This work presents an implicit characterization of the normalization function as a nonlinear ordinary differential equation (ODE), establishes its key properties, and subsequently leverages them to construct a numerical algorithm for approximating the normalization factor under mild assumptions. Further analysis demonstrates structural equivalences between ERM-$f$DR problems with different $f$-divergences via transformations of the empirical risk. Finally, the proposed algorithm is used to compute the training and test risks of ERM-$f$DR solutions under different $f$-divergence regularizers. This numerical example highlights the practical implications of choosing different functions $f$ in ERM-$f$DR problems.

</details>


### [614] [Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds](https://arxiv.org/abs/2601.13436)
*Szabolcs Szentpéteri,Balázs Csanád Csáji*

Main category: stat.ML

TL;DR: 将SPS EOA算法扩展到岭回归，推导置信区域大小的PAC上界，分析正则化参数对区域大小的影响，并在较弱激励条件下提供更紧的界


<details>
  <summary>Details</summary>
Motivation: 线性参数化模型在控制和信号处理中广泛使用，但输入激励不足时最小二乘估计可能无法求解或不稳定。虽然正则化（如岭回归）可以减少方差误差，但仍需量化估计不确定性。现有SPS EOA算法可构建非渐近置信椭球，但需要扩展到岭回归场景。

Method: 扩展SPS EOA算法到岭回归，推导所得置信区域大小的PAC（概率近似正确）上界。分析正则化参数如何影响区域大小，在较弱激励条件下提供更紧的界，并通过仿真实验验证正则化的实际效果。

Result: 成功将SPS EOA算法扩展到岭回归，获得了置信区域大小的PAC上界。相比先前分析，新结果明确展示了正则化参数对区域大小的影响，在较弱激励条件下提供了更紧的界。仿真实验验证了正则化的实际效果。

Conclusion: 提出的方法成功将SPS EOA扩展到岭回归，提供了置信区域大小的理论保证。新分析揭示了正则化参数与置信区域大小的明确关系，在较弱激励条件下获得了更紧的界，为岭回归的不确定性量化提供了有效工具。

Abstract: Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments.

</details>


### [615] [Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs](https://arxiv.org/abs/2601.13458)
*Zihan Dong,Ruijia Wu,Linjun Zhang*

Main category: stat.ML

TL;DR: 提出PCAL方法，通过半参数推断将标注预算分配问题转化为单调缺失数据框架，优化地面真值标签与成对偏好的预算分配，实现统计高效估计。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成伪标签越来越依赖人类偏好反馈，需要原则性的、预算意识的数据获取策略。关键问题是如何在有限标注预算下，最优分配地面真值标签和成对偏好数据。

Method: 基于半参数推断，将预算分配问题构建为单调缺失数据框架。提出偏好校准主动学习(PCAL)方法，学习最优数据获取策略，并开发统计高效估计器。通过直接优化估计器方差而非要求闭式解，适用于一般问题类别。

Result: 理论上证明PCAL估计器的渐近最优性，并建立关键鲁棒性保证，即使在辅助模型估计不佳时也能保持稳健性能。模拟和真实数据分析展示了方法的实际优势和优越性能。

Conclusion: 为现代AI中的预算约束学习提供了原则性且统计高效的方法框架，解决了标注预算在真实标签与偏好反馈之间的最优分配问题。

Abstract: The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.

</details>


### [616] [Small Gradient Norm Regret for Online Convex Optimization](https://arxiv.org/abs/2601.13519)
*Wenzhi Gao,Chang He,Madeleine Udell*

Main category: stat.ML

TL;DR: 本文提出了一种新的问题依赖遗憾度量G* regret，用于光滑损失的在线凸优化，它基于累积平方梯度范数，比现有的L* regret更精细，在损失函数在最优解附近曲率消失时能提供更尖锐的界限。


<details>
  <summary>Details</summary>
Motivation: 现有的L* regret（小损失遗憾）虽然提供了问题依赖的遗憾界限，但在损失函数在最优解附近曲率消失时可能不够尖锐。需要一种更精细的遗憾度量来更好地反映优化问题的特性。

Method: 提出G* regret概念，定义为∑‖∇ℓ(x*)‖²，即累积平方梯度范数在事后最优解处的评估。建立G* regret的上界和下界，并将结果扩展到动态遗憾和bandit设置。

Result: 证明G* regret严格细化了L* regret，当损失函数在最优解附近曲率消失时可以任意更尖锐。建立了理论界限，并在插值机制下改进了随机优化算法的收敛分析。

Conclusion: G* regret是一种更精细的问题依赖遗憾度量，能更好地捕捉损失函数的局部特性，特别是在曲率消失的情况下。实验验证了理论发现，为在线凸优化提供了新的分析工具。

Abstract: This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\sum_{t=1}^T \|\nabla \ell(x^\star)\|^2$. We show that the $G^\star$ regret strictly refines the existing $L^\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.

</details>


### [617] [Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning](https://arxiv.org/abs/2601.13642)
*Yuchen Jiao,Jiin Woo,Gen Li,Gauri Joshi,Yuejie Chi*

Main category: stat.ML

TL;DR: 本文研究了平均奖励MDPs的Q-learning算法，在单智能体和联邦学习场景下提供了理论保证，改进了样本复杂度并首次提出了联邦Q-learning算法。


<details>
  <summary>Details</summary>
Motivation: 平均奖励强化学习为长期决策提供了原则性框架，但Q-learning在平均奖励设置下的理论保证有限。现有研究缺乏对平均奖励MDPs的Q-learning样本复杂度分析，特别是在联邦学习场景下。

Method: 提出了一种简单有效的Q-learning算法，适用于弱通信假设下的有限状态和动作空间平均奖励MDPs。研究了单智能体和联邦两种场景，通过精心选择算法参数来优化性能。

Result: 单智能体情况下，算法达到样本复杂度$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$，比先前结果改进至少$\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$倍。联邦设置中，M个智能体的每智能体样本复杂度降至$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$，仅需$\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$通信轮次。

Conclusion: 本文首次建立了平均奖励MDPs的联邦Q-learning算法，在样本复杂度和通信复杂度方面都具有可证明的效率，为平均奖励强化学习的理论分析和实际应用提供了重要基础。

Abstract: Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$, where $\|h^{\star}\|_{\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$, with only $\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity.

</details>


### [618] [Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses](https://arxiv.org/abs/2601.13874)
*Shijie Zhong,Jiangfeng Fu,Yikun Yang*

Main category: stat.ML

TL;DR: 本文研究了最大均值差异（MMD）统计量的方差特性，建立了统一有限样本表征，并提出了一种在拉普拉斯核下单变量情况下的精确加速方法，将计算复杂度从O(n²)降低到O(n log n)。


<details>
  <summary>Details</summary>
Motivation: MMD是一种基于核的非参数统计量，用于两样本检验，其推断准确性严重依赖于方差表征。现有研究提供了各种MMD方差的有限样本估计器，但这些估计器在零假设和备择假设下、在平衡或不平衡采样方案中往往存在差异，缺乏统一的理论框架。

Method: 通过MMD统计量的U统计量表示和Hoeffding分解来研究其方差，建立了一个覆盖不同假设和样本配置的统一有限样本表征。基于此分析，针对拉普拉斯核下的单变量情况，提出了一种精确加速方法。

Result: 建立了MMD方差在不同假设和样本配置下的统一有限样本表征。在拉普拉斯核下单变量情况下，提出的加速方法将整体计算复杂度从O(n²)降低到O(n log n)。

Conclusion: 本文为MMD方差提供了统一的理论框架，并展示了在特定核函数下实现计算加速的可行性，为高效的两样本检验提供了理论基础和实用方法。

Abstract: The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\mathcal O(n^2)$ to $\mathcal O(n \log n)$.

</details>


### [619] [Intermittent time series forecasting: local vs global models](https://arxiv.org/abs/2601.14031)
*Stefano Damato,Nicolò Rubattu,Dario Azzimonti,Giorgio Corani*

Main category: stat.ML

TL;DR: 该研究首次系统比较了局部模型和全局模型在间歇性时间序列预测上的表现，发现基于神经网络的D-Linear模型在准确性和计算效率上均优于传统局部模型。


<details>
  <summary>Details</summary>
Motivation: 间歇性时间序列（包含大量零值）在供应链库存管理中占比很大，需要能够处理非负值、零概率质量和长上尾的预测分布。虽然全局模型（基于神经网络）在时间序列预测中越来越流行，但尚未在间歇性时间序列上得到充分测试。

Method: 首次比较了最先进的局部模型（iETS, TweedieGP）和全局模型（D-Linear, DeepAR, Transformers）在间歇性时间序列上的表现。为神经网络模型考虑了三种适合间歇性序列的分布头：负二项分布、障碍移位负二项分布和Tweedie分布，其中后两种是首次与神经网络结合使用。在包含超过40,000个真实世界时间序列的五个大数据集上进行实验。

Result: 在神经网络模型中，D-Linear提供最佳准确性，并且始终优于局部模型，同时计算需求较低。基于Transformer的架构计算需求大且准确性较低。在分布头中，Tweedie对最高分位数估计最好，而负二项分布在整体性能上表现最佳。

Conclusion: 全局模型特别是D-Linear在间歇性时间序列预测中表现出色，优于传统局部模型，为供应链库存管理提供了更有效的预测解决方案。

Abstract: Intermittent time series, characterised by the presence of a significant amount of zeros, constitute a large percentage of inventory items in supply chain. Probabilistic forecasts are needed to plan the inventory levels; the predictive distribution should cover non-negative values, have a mass in zero and a long upper tail. Intermittent time series are commonly forecast using local models, which are trained individually on each time series. In the last years global models, which are trained on a large collection of time series, have become popular for time series forecasting. Global models are often based on neural networks. However, they have not yet been exhaustively tested on intermittent time series. We carry out the first study comparing state-of-the-art local (iETS, TweedieGP) and global models (D-Linear, DeepAR, Transformers) on intermittent time series. For neural networks models we consider three different distribution heads suitable for intermittent time series: negative binomial, hurdle-shifted negative binomial and Tweedie. We use, for the first time, the last two distribution heads with neural networks. We perform experiments on five large datasets comprising more than 40'000 real-world time series. Among neural networks D-Linear provides best accuracy; it also consistently outperforms the local models. Moreover, it has also low computational requirements. Transformers-based architectures are instead much more computationally demanding and less accurate. Among the distribution heads, the Tweedie provides the best estimates of the highest quantiles, while the negative binomial offers overall the best performance.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [620] [Admissible Information Structures and the Non-Existence of Global Martingale Pricing](https://arxiv.org/abs/2601.12541)
*Alejandro Rodriguez Dominguez*

Main category: q-fin.MF

TL;DR: 论文研究多资产类别定价中的信息结构问题，发现局部兼容性不能扩展到全局，存在三个独立未对冲驱动因子时，可能不存在任何允许所有资产联合作为鞅的可接受信息结构和等价测度。


<details>
  <summary>Details</summary>
Motivation: 实践中定价涉及多个资产类别，这些资产由经济变量驱动，而这些变量仅部分被交易工具对冲。这引发了一个结构性问题：是否存在一个单一的可接受信息结构，使得所有交易资产都能在该结构下联合作为鞅定价？

Method: 将过滤视为受可接受性和时间排序约束的内生对象，而非外生原语。对于任何有限资产集合，当鞅定价在某个可接受过滤下可行时，它已经在资产价格本身生成的最小规范过滤下可行。使用离散时间Doob-Meyer分解进行数值诊断。

Result: 对于有限资产集合，当存在某个可接受过滤时，鞅定价已经在资产价格生成的规范过滤下可行。但局部兼容性不能扩展到全局：存在三个独立未对冲有限变差驱动因子时，可能不存在任何可接受过滤和等价测度使得所有资产联合作为鞅。该障碍是尖锐的（一个驱动因子时不存在，两个时成对兼容），等价于可接受动态完备性的失败。

Conclusion: 多资产类别定价存在根本性结构障碍，局部定价兼容性不能保证全局联合定价可行性。可接受信息结构抑制可预测成分，而不可接受过滤会产生系统性可预测性。这揭示了无套利定价理论在多资产环境中的局限性。

Abstract: No-arbitrage asset pricing characterizes valuation through the existence of equivalent martingale measures relative to a filtration and a class of admissible trading strategies. In practice, pricing is performed across multiple asset classes driven by economic variables that are only partially spanned by traded instruments, raising a structural question: does there exist a single admissible information structure under which all traded assets can be jointly priced as martingales?. We treat the filtration as an endogenous object constrained by admissibility and time-ordering, rather than as an exogenous primitive. For any finite collection of assets, whenever martingale pricing is feasible under some admissible filtration, it is already feasible under a canonical minimal filtration generated by the asset prices themselves; these pricing-sufficient filtrations are unique up to null sets and stable under restriction and aggregation when a common pricing measure exists. Our main result shows that this local compatibility does not extend globally: with three independent unspanned finite-variation drivers, there need not exist any admissible filtration and equivalent measure under which all assets are jointly martingales. The obstruction is sharp (absent with one driver and compatible pairwise with two) and equivalent to failure of admissible dynamic completeness. We complement the theory with numerical diagnostics based on discrete-time Doob--Meyer decompositions, illustrating how admissible information structures suppress predictable components, while inadmissible filtrations generate systematic predictability.

</details>


### [621] [Optimal Underreporting and Competitive Equilibrium](https://arxiv.org/abs/2601.12655)
*Zongxia Liang,Jiayu Zhang,Zhou Zhou,Bin Zou*

Main category: q-fin.MF

TL;DR: 建立包含两家竞争保险公司和连续投保人的动态保险市场模型，研究投保人策略性瞒报与保险公司竞争定价在奖惩系统框架下的相互作用。


<details>
  <summary>Details</summary>
Motivation: 在寡头垄断环境下，首次研究投保人策略性瞒报行为与保险公司竞争定价之间的相互作用，填补了奖惩系统框架下博弈分析的研究空白。

Method: 构建动态保险市场模型，包含两家竞争保险公司和连续投保人，在奖惩系统框架下分析投保人最优报告门槛的存在性、唯一性及其对保费定价的连续依赖性。

Result: 首次在寡头垄断环境下证明了投保人最优报告门槛的存在性和唯一性，以及其对奖惩系统保费的连续依赖性；针对2类奖惩系统证明了纳什均衡保费策略的存在性，并进行了参数敏感性分析。

Conclusion: 该研究为理解奖惩系统框架下投保人策略行为与保险公司竞争定价的相互作用提供了理论框架，对保险市场设计和监管具有重要参考价值。

Abstract: This paper develops a dynamic insurance market model comprising two competing insurance companies and a continuum of insureds, and examines the interaction between strategic underreporting by the insureds and competitive pricing between the insurance companies under a Bonus-Malus System (BMS) framework. For the first time in an oligopolistic setting, we establish the existence and uniqueness of the insureds' optimal reporting barrier, as well as its continuous dependence on the BMS premiums. For the 2-class BMS case, we prove the existence of Nash equilibrium premium strategies and conduct an extensive sensitivity analysis on the impact of the model parameters on the equilibrium premiums.

</details>


### [622] [Leveraged positions on decentralized lending platforms](https://arxiv.org/abs/2601.14005)
*Bastien Baude,Vincent Danos,Hamza El Khalloufi*

Main category: q-fin.MF

TL;DR: 该论文开发了一个数学框架来优化DeFi中的杠杆质押（"循环"）策略，通过将质押资产作为抵押品、借出底层资产并重新质押，可在多个借贷市场中重复循环。利用DeFi借贷利率是资金池利用率的确定性函数这一事实，将多市场问题简化为市场敞口的凸分配问题，并在三种利率模型下获得闭式解。回测显示再平衡的杠杆头寸可达6.2%年化收益率，远超非杠杆质押的3.1%。


<details>
  <summary>Details</summary>
Motivation: DeFi中的杠杆质押策略（如循环质押）在实践中被广泛使用，但缺乏系统的数学框架来优化这些策略。现有方法通常依赖启发式或试错法，无法在考虑市场特定杠杆限制、利用率依赖的借贷成本和交易费用的情况下，提供透明、自动化的投资组合优化方案。

Method: 开发了一个数学框架，利用DeFi借贷利率是资金池利用率的确定性函数的特点，将多市场杠杆质押优化问题简化为市场敞口的凸分配问题。在三种利率模型下获得闭式解：线性模型、拐点模型和自适应模型（Morpho的AdaptiveCurveIRM）。框架考虑了市场特定杠杆限制、利用率依赖的借贷成本和交易费用。

Result: 在以太坊和Base区块链上使用最大的Morpho wstETH/WETH市场（2025年1月1日至4月1日）进行回测，结果显示再平衡的杠杆头寸年化收益率可达6.2%，而非杠杆质押仅为3.1%。收益率强烈依赖于头寸规模和再平衡频率。

Conclusion: 该研究为透明、自动化的DeFi投资组合优化提供了数学基础，证明了杠杆质押策略在DeFi中的潜在收益，并为实际应用提供了可计算的优化框架。

Abstract: We develop a mathematical framework to optimize leveraged staking ("loopy") strategies in Decentralized Finance (DeFi), in which a staked asset is supplied as collateral, the underlying is borrowed and re-staked, and the loop can be repeated across multiple lending markets. Exploiting the fact that DeFi borrow rates are deterministic functions of pool utilization, we reduce the multi-market problem to a convex allocation over market exposures and obtain closed-form solutions under three interest-rate models: linear, kinked, and adaptive (Morpho's AdaptiveCurveIRM). The framework incorporates market-specific leverage limits, utilization-dependent borrowing costs, and transaction fees. Backtests on the Ethereum and Base blockchains using the largest Morpho wstETH/WETH markets (from January 1 to April 1, 2025) show that rebalanced leveraged positions can reach up to 6.2% APY versus 3.1% for unleveraged staking, with strong dependence on position size and rebalancing frequency. Our results provide a mathematical basis for transparent, automated DeFi portfolio optimization.

</details>


### [623] [Log-optimality with small liability stream](https://arxiv.org/abs/2601.14139)
*Michail Anthropelos,Constantinos Kardaras,Constantinos Stefanakis*

Main category: q-fin.MF

TL;DR: 使用对偶技术推导对数效用投资者在非交易禀赋持有量ε的四阶展开，为最优财富过程的二阶展开奠定基础


<details>
  <summary>Details</summary>
Motivation: 研究不完全金融市场中，拥有对数效用偏好的投资者在初始资本外还持有非交易禀赋时的最优投资问题

Method: 采用对偶技术，基于Kunita-Watanabe投影推导关于非交易禀赋持有量ε的四阶展开，统一处理有限和无限时间范围

Result: 得到了原始价值函数关于ε的四阶展开，为最优财富过程的二阶展开提供了理论基础

Conclusion: 该方法为不完全市场中包含非交易禀赋的投资组合优化问题提供了系统的展开分析框架

Abstract: In an incomplete financial market with general continuous semimartingale dynamics; we model an investor with log-utility preferences who, in addition to an initial capital, receives units of a non-traded endowment process. Using duality techniques, we derive the fourth-order expansion of the primal value function with respect to the units $ε$, held in the non-traded endowment. In turn, this lays the foundation for expanding the optimal wealth process, in this context, up to second order w.r.t. $ε$. The key processes underpinning the aforementioned results are given in terms of Kunita-Watanabe projections, mirroring the case of lower order expansions of similar nature. Both the case of finite and infinite horizons are treated in a unified manner.

</details>
