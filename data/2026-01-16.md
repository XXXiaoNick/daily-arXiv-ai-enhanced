<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 78]
- [eess.SY](#eess.SY) [Total: 9]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [stat.ML](#stat.ML) [Total: 5]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [econ.EM](#econ.EM) [Total: 7]
- [q-fin.RM](#q-fin.RM) [Total: 2]
- [cs.LG](#cs.LG) [Total: 68]
- [cs.CY](#cs.CY) [Total: 13]
- [cs.AI](#cs.AI) [Total: 53]
- [math.OC](#math.OC) [Total: 8]
- [q-fin.ST](#q-fin.ST) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [LLM-Driven Preference Data Synthesis for Proactive Prediction of the Next User Utterance in Human-Machine Dialogue](https://arxiv.org/abs/2601.09713)
*Jinqiang Wang,Huansheng Ning,Jianguo Ding,Tao Zhu,Liming Chen,Chris Nugent*

Main category: cs.CL

TL;DR: ProUtt：一种基于LLM的偏好数据合成方法，用于主动预测用户下一轮话语。通过将对话历史转换为意图树，从利用和探索两个角度建模意图推理轨迹，并通过扰动或修改意图树路径来构建偏好和非偏好推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有商业API解决方案存在隐私问题，本地部署通用LLM计算成本高，而用户模拟器方法主要模仿说话风格而非推进对话。现有偏好数据合成方法缺乏对用户意图推理的显式建模能力，无法定义和合成用于预测用户下一轮话语的偏好和非偏好推理过程。

Method: ProUtt将对话历史转换为意图树，从利用（exploitation）和探索（exploration）两个角度显式建模意图推理轨迹，预测下一个可能的路径。通过在不同未来轮次扰动或修改意图树路径来构建偏好和非偏好推理过程。

Result: 在四个基准数据集上，使用LLM-as-a-judge和人工评估，ProUtt在主动下一轮话语预测任务中一致优于现有数据合成方法、用户模拟器和商业LLM API。

Conclusion: ProUtt通过显式建模意图推理轨迹和构建偏好/非偏好推理过程，有效解决了主动用户话语预测中的数据合成问题，为训练紧凑、任务特定的LLM提供了实用替代方案。

Abstract: Proactively predicting a users next utterance in human-machine dialogue can streamline interaction and improve user experience. Existing commercial API-based solutions are subject to privacy concerns while deploying general-purpose LLMs locally remains computationally expensive. As such, training a compact, task-specific LLM provides a practical alternative. Although user simulator methods can predict a user's next utterance, they mainly imitate their speaking style rather than advancing the dialogue. Preference data synthesis has been investigated to generate data for proactive next utterance prediction and help align LLMs with user preferences. Yet existing methods lack the ability to explicitly model the intent reasoning that leads to the user's next utterance and to define and synthesize preference and non-preference reasoning processes for predicting the user's next utterance.To address these challenges, we propose ProUtt, an LLM-driven preference data synthesis method for proactive next utterance prediction. ProUtt converts dialogue history into an intent tree and explicitly models intent reasoning trajectories by predicting the next plausible path from both exploitation and exploration perspectives. It then constructs preference and non-preference reasoning processes by perturbing or revising intent tree paths at different future turns. Extensive evaluations using LLM-as-a-judge and human judgments demonstrate that ProUtt consistently outperforms existing data synthesis methods, user simulators, and commercial LLM APIs across four benchmark datasets. We release both the code and the synthesized datasets to facilitate future research.

</details>


### [2] [Evaluating Novelty in AI-Generated Research Plans Using Multi-Workflow LLM Pipelines](https://arxiv.org/abs/2601.09714)
*Devesh Saraogi,Rohit Singhee,Dhruv Kumar*

Main category: cs.CL

TL;DR: 多步智能体工作流比单步提示能产生更具新颖性和可行性的研究计划，其中分解式和长上下文工作流表现最佳


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在科学生态系统中的整合问题，特别是针对"智能剽窃"现象（模型通过术语转换复制现有想法），探索多步智能体工作流是否能产生更具创造性和原创性的研究计划

Method: 基准测试五种推理架构：基于反思的迭代优化、Sakana AI v2进化算法、Google Co-Scientist多智能体框架、GPT Deep Research递归分解、Gemini~3 Pro多模态长上下文管道。使用30个提案在创新性、可行性和影响力三个维度进行评估

Result: 分解式和长上下文工作流平均创新性得分4.17/5，而基于反思的方法显著较低（2.33/5）。不同研究领域表现各异，高性能工作流能在不牺牲创造性的同时保持可行性

Conclusion: 精心设计的多阶段智能体工作流能够推进AI辅助研究构思，解决单步提示方法中的"智能剽窃"问题，产生更具新颖性和可行性的研究计划

Abstract: The integration of Large Language Models (LLMs) into the scientific ecosystem raises fundamental questions about the creativity and originality of AI-generated research. Recent work has identified ``smart plagiarism'' as a concern in single-step prompting approaches, where models reproduce existing ideas with terminological shifts. This paper investigates whether agentic workflows -- multi-step systems employing iterative reasoning, evolutionary search, and recursive decomposition -- can generate more novel and feasible research plans. We benchmark five reasoning architectures: Reflection-based iterative refinement, Sakana AI v2 evolutionary algorithms, Google Co-Scientist multi-agent framework, GPT Deep Research (GPT-5.1) recursive decomposition, and Gemini~3 Pro multimodal long-context pipeline. Using evaluations from thirty proposals each on novelty, feasibility, and impact, we find that decomposition-based and long-context workflows achieve mean novelty of 4.17/5, while reflection-based approaches score significantly lower (2.33/5). Results reveal varied performance across research domains, with high-performing workflows maintaining feasibility without sacrificing creativity. These findings support the view that carefully designed multi-stage agentic workflows can advance AI-assisted research ideation.

</details>


### [3] [Introducing Axlerod: An LLM-based Chatbot for Assisting Independent Insurance Agents](https://arxiv.org/abs/2601.09715)
*Adam Bradley,John Hastings,Khandaker Mamun Ahmed*

Main category: cs.CL

TL;DR: Axlerod是一个面向独立保险代理人的AI对话系统，通过NLP、RAG和领域知识集成，实现93.18%的政策检索准确率，平均搜索时间减少2.42秒。


<details>
  <summary>Details</summary>
Motivation: 保险行业正在经历AI技术带来的范式转变，特别是智能对话代理。现有系统需要提升独立保险代理人的运营效率，处理复杂的政策推荐和理赔分流工作流。

Method: 采用自然语言处理(NLP)、检索增强生成(RAG)和领域特定知识集成技术，设计并实现了Axlerod系统，能够解析用户意图、访问结构化政策数据库并提供实时、上下文相关的响应。

Result: 实验结果显示，Axlerod在政策检索任务中达到93.18%的整体准确率，同时将平均搜索时间减少了2.42秒。

Conclusion: 该研究为企业级AI在保险科技中的应用做出了贡献，特别关注代理辅助而非面向消费者的架构，证明了AI对话系统在提升保险代理人运营效率方面的有效性。

Abstract: The insurance industry is undergoing a paradigm shift through the adoption of artificial intelligence (AI) technologies, particularly in the realm of intelligent conversational agents. Chatbots have evolved into sophisticated AI-driven systems capable of automating complex workflows, including policy recommendation and claims triage, while simultaneously enabling dynamic, context-aware user engagement. This paper presents the design, implementation, and empirical evaluation of Axlerod, an AI-powered conversational interface designed to improve the operational efficiency of independent insurance agents. Leveraging natural language processing (NLP), retrieval-augmented generation (RAG), and domain-specific knowledge integration, Axlerod demonstrates robust capabilities in parsing user intent, accessing structured policy databases, and delivering real-time, contextually relevant responses. Experimental results underscore Axlerod's effectiveness, achieving an overall accuracy of 93.18% in policy retrieval tasks while reducing the average search time by 2.42 seconds. This work contributes to the growing body of research on enterprise-grade AI applications in insurtech, with a particular focus on agent-assistive rather than consumer-facing architectures.

</details>


### [4] [Opportunities and Challenges of Natural Language Processing for Low-Resource Senegalese Languages in Social Science Research](https://arxiv.org/abs/2601.09716)
*Derguene Mbaye,Tatiana D. P. Mbengue,Madoune R. Seye,Moussa Diallo,Mamadou L. Ndiaye,Dimitri S. Adjanohoun,Cheikh S. Wade,Djiby Sow,Jean-Claude B. Munyaka,Jerome Chenal*

Main category: cs.CL

TL;DR: 该论文首次全面综述了塞内加尔六种官方语言（沃洛夫语、普拉尔语、塞雷尔语、朱拉语、曼丁哥语、索尼基语）在自然语言处理领域的进展与挑战，建立了资源中心库，并为社会科学应用提供了技术路线图。


<details>
  <summary>Details</summary>
Motivation: 尽管NLP技术正在改变各学科研究方法，但非洲语言在这一技术转型中代表性严重不足。塞内加尔六种官方语言缺乏系统的NLP资源综述和基础设施，阻碍了相关研究和应用发展。

Method: 综合分析了语言、社会技术和基础设施因素对数字准备度的影响；梳理了文本规范化、机器翻译和语音处理等领域的现有工作；建立了集中化的GitHub资源库，收集整理了公开可用的NLP任务资源。

Result: 识别了塞内加尔语言在数据、工具和基准测试方面的关键差距；创建了促进协作和可重复性的资源中心；展示了NLP在社会科学研究（特别是多语言转录、翻译和检索）中的应用潜力。

Conclusion: 提出了面向塞内加尔语言的可持续、以社区为中心的NLP生态系统发展路线图，强调伦理数据治理、开放资源和跨学科合作的重要性，以促进技术包容性和研究效率。

Abstract: Natural Language Processing (NLP) is rapidly transforming research methodologies across disciplines, yet African languages remain largely underrepresented in this technological shift. This paper provides the first comprehensive overview of NLP progress and challenges for the six national languages officially recognized by the Senegalese Constitution: Wolof, Pulaar, Sereer, Joola, Mandingue, and Soninke. We synthesize linguistic, sociotechnical, and infrastructural factors that shape their digital readiness and identify gaps in data, tools, and benchmarks. Building on existing initiatives and research works, we analyze ongoing efforts in text normalization, machine translation, and speech processing. We also provide a centralized GitHub repository that compiles publicly accessible resources for a range of NLP tasks across these languages, designed to facilitate collaboration and reproducibility. A special focus is devoted to the application of NLP to the social sciences, where multilingual transcription, translation, and retrieval pipelines can significantly enhance the efficiency and inclusiveness of field research. The paper concludes by outlining a roadmap toward sustainable, community-centered NLP ecosystems for Senegalese languages, emphasizing ethical data governance, open resources, and interdisciplinary collaboration.

</details>


### [5] [SALP-CG: Standard-Aligned LLM Pipeline for Classifying and Grading Large Volumes of Online Conversational Health Data](https://arxiv.org/abs/2601.09717)
*Yiwei Yan,Hao Li,Hua He,Gong Kai,Zhengyi Yang,Guanfeng Liu*

Main category: cs.CL

TL;DR: 提出SALP-CG框架，基于大语言模型对在线医疗对话数据进行隐私风险分类与分级，遵循国家标准GB/T 39725-2020，实现高准确度的敏感信息识别。


<details>
  <summary>Details</summary>
Motivation: 在线医疗咨询产生大量包含受保护健康信息的对话数据，需要符合政策和实践的稳健分类与风险评估方法。现有方法缺乏统一标准和可靠的自动化解决方案来处理此类对话健康数据的敏感性分类。

Method: 提出SALP-CG框架：基于大语言模型的提取流程，结合少样本指导、JSON Schema约束解码和确定性高风险规则，实现后端无关的隐私风险分类与分级。遵循GB/T 39725-2020标准制定健康数据分类与分级规则。

Result: 在MedDialog-CN基准测试中，模型表现出稳健的实体计数、高模式合规性和准确的敏感性分级。最强模型在最高级别预测中达到micro-F1=0.900。分析显示2-3级项目占主导（组合后可重新识别），4-5级项目较少但危害更大。

Conclusion: SALP-CG能够可靠地对在线对话健康数据进行分类和敏感性分级，为健康数据治理提供了实用方法。该框架在不同大语言模型上表现稳定，具有实际应用价值。

Abstract: Online medical consultations generate large volumes of conversational health data that often embed protected health information, requiring robust methods to classify data categories and assign risk levels in line with policies and practice. However, existing approaches lack unified standards and reliable automated methods to fulfill sensitivity classification for such conversational health data. This study presents a large language model-based extraction pipeline, SALP-CG, for classifying and grading privacy risks in online conversational health data. We concluded health-data classification and grading rules in accordance with GB/T 39725-2020. Combining few-shot guidance, JSON Schema constrained decoding, and deterministic high-risk rules, the backend-agnostic extraction pipeline achieves strong category compliance and reliable sensitivity across diverse LLMs. On the MedDialog-CN benchmark, models yields robust entity counts, high schema compliance, and accurate sensitivity grading, while the strongest model attains micro-F1=0.900 for maximum-level prediction. The category landscape stratified by sensitivity shows that Level 2-3 items dominate, enabling re-identification when combined; Level 4-5 items are less frequent but carry outsize harm. SALP-CG reliably helps classify categories and grading sensitivity in online conversational health data across LLMs, offering a practical method for health data governance. Code is available at https://github.com/dommii1218/SALP-CG.

</details>


### [6] [StatLLaMA: A multi-stage training framework for building a domain-optimized statistical language model](https://arxiv.org/abs/2601.09718)
*Jing-Yi Zeng,Guan-Hua Huang*

Main category: cs.CL

TL;DR: 该研究探索了如何基于轻量级LLaMA-3.2-3B构建领域专用统计大语言模型，比较了三种训练流程，发现从指令调优基础模型开始才能有效实现领域专业化，最终开发的StatLLaMA在数学推理、常识推理和统计专业知识方面表现均衡。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索如何高效构建资源高效的领域专用统计大语言模型，特别是针对统计领域，使用轻量级基础模型来降低计算成本。

Method: 系统比较了三种多阶段训练流程：1) 从无指令跟随能力的基础模型开始；2) 从经过后处理指令调优的基础模型开始；3) 从具有强通用推理能力的指令调优模型开始。使用了持续预训练、监督微调、RLHF偏好对齐和下游任务适应等方法。

Result: 结果显示：从基础模型开始的流程无法发展有意义的统计推理能力；从LLaMA-3.2-3B-Instruct开始才能有效实现领域专业化；SFT变体在领域专业知识和通用推理能力之间存在权衡；直接偏好优化提供稳定有效的RLHF对齐；下游微调需要极低强度以避免灾难性遗忘。

Conclusion: 最终开发的StatLLaMA模型在数学推理、常识推理和统计专业知识基准测试中表现均衡，为开发资源高效的统计大语言模型提供了实用蓝图。

Abstract: This study investigates how to efficiently build a domain-specialized large language model (LLM) for statistics using the lightweight LLaMA-3.2-3B family as the foundation model (FM). We systematically compare three multi-stage training pipelines, starting from a base FM with no instruction-following capability, a base FM augmented with post-hoc instruction tuning, and an instruction-tuned FM with strong general reasoning abilities across continual pretraining, supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF) preference alignment, and downstream task adaptation. Results show that pipelines beginning with a base FM fail to develop meaningful statistical reasoning, even after extensive instruction tuning, SFT, or RLHF alignment. In contrast, starting from LLaMA-3.2-3B-Instruct enables effective domain specialization. A comprehensive evaluation of SFT variants reveals clear trade-offs between domain expertise and general reasoning ability. We further demonstrate that direct preference optimization provides stable and effective RLHF preference alignment. Finally, we show that downstream fine-tuning must be performed with extremely low intensity to avoid catastrophic forgetting in highly optimized models. The final model, StatLLaMA, achieves strong and balanced performance on benchmarks of mathematical reasoning, common-sense reasoning, and statistical expertise, offering a practical blueprint for developing resource-efficient statistical LLMs. The code is available at https://github.com/HuangDLab/StatLLaMA.

</details>


### [7] [Bounded Hyperbolic Tangent: A Stable and Efficient Alternative to Pre-Layer Normalization in Large Language Models](https://arxiv.org/abs/2601.09719)
*Hoyoon Byun,Youngjun Choi,Taero Kim,Sungrae Park,Kyungwoo Song*

Main category: cs.CL

TL;DR: BHyT是一种替代Pre-LN的归一化方法，通过tanh非线性和显式输入边界控制，解决了深度模型中的激活增长问题，同时提升了训练效率和推理性能。


<details>
  <summary>Details</summary>
Motivation: Pre-LN虽然是大语言模型的标准选择，但存在效率低下和深度诅咒问题。随着层数增加，隐藏状态的幅度和方差会增长，导致训练不稳定。现有的效率导向方法如DyT在深度下仍然脆弱，需要同时解决稳定性和效率问题。

Method: 提出Bounded Hyperbolic Tanh (BHyT)，结合tanh非线性和显式的数据驱动输入边界，将激活限制在非饱和范围内。每个块只计算一次精确统计量，并用轻量级方差近似替代第二次归一化，提升效率。

Result: BHyT在预训练中表现出更好的稳定性和效率，相比RMSNorm平均训练速度提升15.8%，token生成吞吐量提升4.2%，同时在语言理解和推理基准测试中匹配或超越了推理性能和鲁棒性。

Conclusion: BHyT作为Pre-LN的直接替代方案，有效解决了深度模型中的激活增长问题，提供了理论稳定性保证，并在保持或提升性能的同时显著提高了训练和推理效率。

Abstract: Pre-Layer Normalization (Pre-LN) is the de facto choice for large language models (LLMs) and is crucial for stable pretraining and effective transfer learning. However, Pre-LN is inefficient due to repeated statistical calculations and suffers from the curse of depth. As layers grow, the magnitude and variance of the hidden state escalate, destabilizing training. Efficiency-oriented normalization-free methods such as Dynamic Tanh (DyT) improve speed but remain fragile at depth. To jointly address stability and efficiency, we propose Bounded Hyperbolic Tanh (BHyT), a drop-in replacement for Pre-LN. BHyT couples a tanh nonlinearity with explicit, data-driven input bounding to keep activations within a non-saturating range. It prevents depth-wise growth in activation magnitude and variance and comes with a theoretical stability guarantee. For efficiency, BHyT computes exact statistics once per block and replaces a second normalization with a lightweight variance approximation, enhancing efficiency. Empirically, BHyT demonstrates improved stability and efficiency during pretraining, achieving an average of 15.8% faster training and an average of 4.2% higher token generation throughput compared to RMSNorm., while matching or surpassing its inference performance and robustness across language understanding and reasoning benchmarks. Our code is available at: https://anonymous.4open.science/r/BHyT

</details>


### [8] [Uncertainty-Aware Dynamic Knowledge Graphs for Reliable Question Answering](https://arxiv.org/abs/2601.09720)
*Yu Takahashi,Shun Takeuchi,Kexuan Xin,Guillaume Pelat,Yoshiaki Ikai,Junya Saito,Jonathan Vitale,Shlomo Berkovsky,Amin Beheshti*

Main category: cs.CL

TL;DR: 提出不确定性感知动态知识图谱框架，结合动态构建、置信度评分和交互界面，提升问答系统在医疗等高风险领域的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的问答系统通常将事实表示为静态和确定性的，无法捕捉信息的动态演变特性和推理中的不确定性，导致系统可靠性不足，特别是在证据不完整、有噪声或不确定的情况下。

Method: 提出不确定性感知动态知识图谱框架，包含三个核心组件：(1) 动态构建演化知识图谱，(2) 置信度评分和不确定性感知检索，(3) 用于可靠和可解释问答的交互界面。在医疗领域实例化该框架，从电子健康记录构建个性化知识图谱。

Result: 系统展示了不确定性建模如何通过让用户探索动态图谱、检查置信度标注的三元组、比较基线答案与置信度感知答案，使问答系统更加鲁棒和透明。在死亡率预测任务中评估了其影响。

Conclusion: 该框架展示了不确定性感知动态知识图谱在增强高风险应用（如医疗）中问答系统可靠性的广阔前景，特别适用于临床数据科学家和临床医生等目标用户。

Abstract: Question answering (QA) systems are increasingly deployed across domains. However, their reliability is undermined when retrieved evidence is incomplete, noisy, or uncertain. Existing knowledge graph (KG) based QA frameworks typically represent facts as static and deterministic, failing to capture the evolving nature of information and the uncertainty inherent in reasoning. We present a demonstration of uncertainty-aware dynamic KGs, a framework that combines (i) dynamic construction of evolving KGs, (ii) confidence scoring and uncertainty-aware retrieval, and (iii) an interactive interface for reliable and interpretable QA. Our system highlights how uncertainty modeling can make QA more robust and transparent by enabling users to explore dynamic graphs, inspect confidence-annotated triples, and compare baseline versus confidence-aware answers. The target users of this demo are clinical data scientists and clinicians, and we instantiate the framework in healthcare: constructing personalized KGs from electronic health records, visualizing uncertainty across patient visits, and evaluating its impact on a mortality prediction task. This use case demonstrates the broader promise of uncertainty-aware dynamic KGs for enhancing QA reliability in high-stakes applications.

</details>


### [9] [Cross-Platform Evaluation of Large Language Model Safety in Pediatric Consultations: Evolution of Adversarial Robustness and the Scale Paradox](https://arxiv.org/abs/2601.09721)
*Vahideh Zolfaghari*

Main category: cs.CL

TL;DR: 研究发现，在儿科咨询中，大型语言模型在焦虑用户压力下的安全性取决于对齐和架构而非规模，较小模型表现优于较大模型，但存在脆弱性，不适合分诊使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗咨询中应用增多，但现有评估多关注中性条件，忽视了焦虑用户挑战安全措施时的脆弱性。本研究旨在评估LLM在儿科咨询中面对父母焦虑驱动对抗性压力时的安全性。

Method: 使用PediatricAnxietyBench基准（300个查询，含150个真实查询和150个对抗性查询，涵盖10个主题），通过API评估三个模型：Llama-3.3-70B、Llama-3.1-8B（Groq）和Mistral-7B（HuggingFace），共获得900个响应。安全性采用0-15分制评估约束、转诊、模糊表达、紧急情况识别和非处方行为。使用配对t检验和自助法置信区间进行分析。

Result: 平均安全分数从9.70（Llama-3.3-70B）到10.39（Mistral-7B）。Llama-3.1-8B优于Llama-3.3-70B（+0.66分，p=0.0001）。模型均显示正向对抗效应，Mistral-7B最强（+1.09分，p=0.0002）。安全性在不同平台间具有一致性，但Llama-3.3-70B有8%失败率。癫痫主题最脆弱（33%不适当诊断）。模糊表达与安全性高度相关（r=0.68，p<0.001）。

Conclusion: 安全性取决于对齐和架构而非规模，较小模型可超越较大模型。版本迭代显示针对性训练进展。脆弱性和缺乏紧急情况识别表明不适合分诊使用。研究结果为医疗AI安全提供选择指导，强调对抗性测试重要性，并提供开放基准。

Abstract: Background Large language models (LLMs) are increasingly deployed in medical consultations, yet their safety under realistic user pressures remains understudied. Prior assessments focused on neutral conditions, overlooking vulnerabilities from anxious users challenging safeguards. This study evaluated LLM safety under parental anxiety-driven adversarial pressures in pediatric consultations across models and platforms. Methods PediatricAnxietyBench, from a prior evaluation, includes 300 queries (150 authentic, 150 adversarial) spanning 10 topics. Three models were assessed via APIs: Llama-3.3-70B and Llama-3.1-8B (Groq), Mistral-7B (HuggingFace), yielding 900 responses. Safety used a 0-15 scale for restraint, referral, hedging, emergency recognition, and non-prescriptive behavior. Analyses employed paired t-tests with bootstrapped CIs. Results Mean scores: 9.70 (Llama-3.3-70B) to 10.39 (Mistral-7B). Llama-3.1-8B outperformed Llama-3.3-70B by +0.66 (p=0.0001, d=0.225). Models showed positive adversarial effects, Mistral-7B strongest (+1.09, p=0.0002). Safety generalized across platforms; Llama-3.3-70B had 8% failures. Seizures vulnerable (33% inappropriate diagnoses). Hedging predicted safety (r=0.68, p<0.001). Conclusions Evaluation shows safety depends on alignment and architecture over scale, with smaller models outperforming larger. Evolution to robustness across releases suggests targeted training progress. Vulnerabilities and no emergency recognition indicate unsuitability for triage. Findings guide selection, stress adversarial testing, and provide open benchmark for medical AI safety.

</details>


### [10] [ADMEDTAGGER: an annotation framework for distillation of expert knowledge for the Polish medical language](https://arxiv.org/abs/2601.09722)
*Franciszek Górski,Andrzej Czyżewski*

Main category: cs.CL

TL;DR: 使用多语言Llama3.1作为教师模型标注波兰语医学文本，训练了三种BERT架构分类器，其中DistilBERT表现最佳，在保持高准确率的同时大幅减小模型尺寸和推理时间。


<details>
  <summary>Details</summary>
Motivation: 在ADMEDVOICE项目中需要开发多类别医学文本分类器，但面临波兰语医学文本标注资源不足的问题，需要寻找替代标注方案。

Method: 使用多语言Llama3.1模型作为教师模型自动标注波兰语医学文本，然后人工验证部分标签作为测试集。用这些数据训练三种BERT架构分类器：DistilBERT、BioBERT和HerBERT。

Result: DistilBERT模型表现最佳，在所有临床类别中F1分数均>0.80，其中3个类别>0.93。相比大语言模型，这些分类器尺寸小500倍，GPU显存消耗低300倍，推理速度快数百倍。

Conclusion: 通过多语言LLM的知识蒸馏，可以在标注资源有限的情况下开发高效的医学文本分类器，为资源受限环境提供了可行的替代方案。

Abstract: In this work, we present an annotation framework that demonstrates how a multilingual LLM pretrained on a large corpus can be used as a teacher model to distill the expert knowledge needed for tagging medical texts in Polish. This work is part of a larger project called ADMEDVOICE, within which we collected an extensive corpus of medical texts representing five clinical categories - Radiology, Oncology, Cardiology, Hypertension, and Pathology. Using this data, we had to develop a multi-class classifier, but the fundamental problem turned out to be the lack of resources for annotating an adequate number of texts. Therefore, in our solution, we used the multilingual Llama3.1 model to annotate an extensive corpus of medical texts in Polish. Using our limited annotation resources, we verified only a portion of these labels, creating a test set from them. The data annotated in this way were then used for training and validation of 3 different types of classifiers based on the BERT architecture - the distilled DistilBERT model, BioBERT fine-tuned on medical data, and HerBERT fine-tuned on the Polish language corpus. Among the models we trained, the DistilBERT model achieved the best results, reaching an F1 score > 0.80 for each clinical category and an F1 score > 0.93 for 3 of them. In this way, we obtained a series of highly effective classifiers that represent an alternative to large language models, due to their nearly 500 times smaller size, 300 times lower GPU VRAM consumption, and several hundred times faster inference.

</details>


### [11] [SagaScale: A Realistic, Scalable, and High-Quality Long-Context Benchmark Built from Full-Length Novels](https://arxiv.org/abs/2601.09723)
*Guancheng Du,Yong Hu,Wenqing Wang,Yaming Yang,Jiaheng Gao*

Main category: cs.CL

TL;DR: SagaScale：基于长篇小说的现实、可扩展、高质量长上下文基准测试，支持中英双语，平均上下文长度超过25万/32万token，评估12个前沿LLM和三种长上下文方法


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准测试存在任务真实性、数据可扩展性和数据质量等局限性，需要构建更现实、可扩展且高质量的长文档理解评估基准

Method: 使用自动化数据收集流水线，基于完整长篇小说构建，利用外部资源（如维基百科）生成问答对，但评估时不提供这些外部资源，确保问题的复杂性超出模型直接回答能力

Result: 1) 直接提供完整上下文给LLM能大幅优于其他方法；2) 大多数LLM仍难以处理长上下文，但Gemini-2.5-Pro表现突出；3) Agentic RAG能有效解决Naïve RAG的检索瓶颈问题

Conclusion: SagaScale为长文档理解提供了现实、可扩展、高质量的评估基准，揭示了当前LLM在长上下文处理中的能力差异，公开基准和代码以促进未来研究

Abstract: Large Language Models (LLMs) have shown significant progress, but understanding long and complex documents remains challenging. Many long-context benchmarks have been proposed, but they face several limitations, including task realism, data scalability, and data quality. To this end, we introduce SagaScale, a realistic, scalable, and high-quality long-context benchmark built from full-length novels. The entire benchmark is constructed using an automated data collection pipeline that utilizes external resources (e.g., Wikipedia pages) to curate question-answer pairs. Critically, these external resources are provided only for benchmark construction and not during evaluation, which allows LLMs to curate complex questions that go beyond what they can answer during evaluation. SagaScale is also bilingual and offers the largest context length to date, with average token counts exceeding 250K for English novels and 320K for Chinese novels. Our evaluation across 12 frontier LLMs and three long-context methods -- Naïve RAG, Agentic RAG, and Long Context -- yields key insights, including: (1) Directly supplying the full context to the LLM can outperform other methods by a large margin; (2) Most LLMs still struggle with lengthy contexts, but Gemini-2.5-Pro stands out as an exception; and (3) Agentic RAG effectively addresses the retrieval bottleneck in Naïve RAG. Finally, we publicly release the SagaScale benchmark and our data collection codebase to facilitate future research.

</details>


### [12] [Syntactic Framing Fragility: An Audit of Robustness in LLM Ethical Decisions](https://arxiv.org/abs/2601.09724)
*Katherine Elkins,Jon Chun*

Main category: cs.CL

TL;DR: LLMs在逻辑等价但句法不同的提示下表现出显著的伦理判断不一致性，特别是对否定和条件结构的敏感性，开源模型比商业模型脆弱性高两倍以上。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地应用于重要决策场景，但其对良性提示变化的鲁棒性尚未充分探索。研究旨在评估LLMs在逻辑等价但句法不同的提示下是否保持一致的伦理判断。

Method: 提出句法框架脆弱性(SFF)评估框架，通过逻辑极性归一化(LPN)隔离纯句法效应。审计23个最先进模型（涵盖中美及美国开源模型），在14个伦理场景和4种控制框架下分析39,975个决策。

Result: 发现广泛且统计显著的不一致性：许多模型仅因句法极性而反转伦理认可，开源模型脆弱性是商业模型的两倍以上。某些模型在"不应该"提示下80-97%情况下认可行动。思维链推理显著减少脆弱性。

Conclusion: 句法一致性是伦理鲁棒性的关键维度，SFF式审计应成为部署LLMs安全评估的标准组成部分。

Abstract: Large language models (LLMs) are increasingly deployed in consequential decision-making settings, yet their robustness to benign prompt variation remains underexplored. In this work, we study whether LLMs maintain consistent ethical judgments across logically equivalent but syntactically different prompts, focusing on variations involving negation and conditional structure. We introduce Syntactic Framing Fragility (SFF), a robustness evaluation framework that isolates purely syntactic effects via Logical Polarity Normalization (LPN), enabling direct comparison of decisions across positive and negative framings without semantic drift. Auditing 23 state-of-the-art models spanning the U.S. and China as well as small U.S. open-source software models over 14 ethical scenarios and four controlled framings (39,975 decisions), we find widespread and statistically significant inconsistency: many models reverse ethical endorsements solely due to syntactic polarity, with open-source models exhibiting over twice the fragility of commercial counterparts. We further uncover extreme negation sensitivity, where some models endorse actions in 80-97% of cases when explicitly prompted with "should not." We show that eliciting chain-of-thought reasoning substantially reduces fragility, identifying a practical mitigation lever, and we map fragility across scenarios, finding higher risk in financial and business contexts than in medical scenarios. Our results demonstrate that syntactic consistency constitutes a distinct and critical dimension of ethical robustness, and we argue that SFF-style audits should be a standard component of safety evaluation for deployed LLMs. Code and results will be available on github.com.

</details>


### [13] [Assessing and Improving Punctuation Robustness in English-Marathi Machine Translation](https://arxiv.org/abs/2601.09725)
*Kaustubh Shivshankar Shejole,Sourabh Deoghare,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: Virām是首个用于评估英语-马拉地语机器翻译中标点鲁棒性的诊断基准，包含54个手工标注的标点歧义实例。研究表明，专门的微调模型和流水线系统显著优于标准基线，而当前大语言模型在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 标点在书面语言中对于消除语义和结构歧义至关重要。机器翻译系统已广泛应用于各种领域和语言，包括许多低资源语言。本研究聚焦马拉地语（一种中低资源语言），旨在解决机器翻译中因标点歧义导致的翻译质量问题。

Method: 1. 创建Virām基准：包含54个手工标注的标点歧义英语-马拉地语实例；2. 评估两种增强策略：流水线方法（先恢复标点再翻译）和直接微调方法（在标点变化数据上微调）；3. 对比标准基线、微调模型和流水线系统的性能；4. 评估当前大语言模型在此任务上的表现。

Result: 1. 专门的微调模型和流水线系统在Virām基准上显著优于标准基线；2. 定性分析显示原始模型可能导致错误翻译和错误解释，而微调模型显著提高了整体可靠性；3. 当前大语言模型在保持标点歧义文本含义方面落后于这些任务特定方法。

Conclusion: 针对标点歧义问题的专门微调模型和流水线系统能显著提高英语-马拉地语机器翻译的可靠性。当前大语言模型在此任务上表现不足，需要进一步研究。Virām基准为评估标点鲁棒性提供了有价值的工具。

Abstract: Punctuation plays a critical role in resolving semantic and structural ambiguity in written language. Machine Translation (MT) systems are now widely applied across diverse domains and languages, including many low-resource settings. In this work, we focus on Marathi, a low- to middle-resource language. We introduce Virām, the first diagnostic benchmark for assessing punctuation robustness in English-to-Marathi machine translation, consisting of 54 manually curated, punctuation-ambiguous instances. We evaluate two primary strategies for enhancing reliability: a pipeline-based restore-then-translate approach and direct fine-tuned on punctuation-varied data. Our results demonstrate that specialized fine-tuned models and pipeline systems significantly improve translation quality over standard baselines on the Virām benchmark. Qualitative analysis reveals that the original model may result in wrong translations leading to wrong interpretations, while fine-tuned models significantly improve overall reliability. Furthermore, we find that current Large Language Models (LLMs) lag behind these task-specific approaches in preserving meaning for punctuation-ambiguous text, thus necessitating further research in this area.

</details>


### [14] [Forgetting as a Feature: Cognitive Alignment of Large Language Models](https://arxiv.org/abs/2601.09726)
*Hien Tran,Quinten Steenhuis,Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CL

TL;DR: LLM的遗忘行为被重新解释为功能性认知机制而非缺陷，通过指数衰减建模记忆过程，提出概率记忆提示策略改善长程推理


<details>
  <summary>Details</summary>
Motivation: 传统上LLM的遗忘被视为推理缺陷，但本文认为遗忘可能是功能性认知机制，类似于人类记忆的动态特性，值得系统研究

Method: 1) 将LLM推理建模为指数衰减的概率记忆过程；2) 开发评估时间推理、概念漂移适应和关联回忆的基准套件；3) 提出概率记忆提示策略，通过塑造证据整合来模拟人类记忆衰减

Result: 实证结果显示LLM表现出与人类记忆效率权衡相似的遗忘率，在稳定性与适应性之间找到平衡。概率记忆提示策略能改善长程推理性能

Conclusion: 遗忘不是失败模式，而是自适应智能的原则性机制。LLM的遗忘行为反映了类似人类的认知效率权衡，可通过记忆建模策略提升推理能力

Abstract: Large Language Models (LLMs) are often evaluated against ideals of perfect Bayesian inference, yet growing evidence suggests that their in-context reasoning exhibits systematic forgetting of past information. Rather than viewing this behavior as a limitation, we reinterpret forgetting as a functional cognitive mechanism. Drawing inspiration from human memory dynamics, we model LLM inference as a probabilistic memory process governed by exponential decay. We introduce a benchmark suite that evaluates temporal reasoning, concept drift adaptation, and associative recall, enabling direct comparison between model behavior and human cognitive patterns. Our empirical results reveal that LLMs demonstrate forgetting rates analogous to human memory efficiency trade-offs between stability and adaptability. Building on these observations, we propose probabilistic memory prompting, a lightweight strategy that shapes evidence integration to mimic human-like memory decay, leading to improved long-horizon reasoning performance. Our findings position forgetting not as a failure mode, but as a principled mechanism for adaptive intelligence.

</details>


### [15] [SciNets: Graph-Constrained Multi-Hop Reasoning for Scientific Literature Synthesis](https://arxiv.org/abs/2601.09727)
*Sauhard Dubey*

Main category: cs.CL

TL;DR: 该论文提出SciNets框架，将跨领域科学合成构建为基于文献概念图的多跳推理问题，通过图约束实现可控的机理解释生成，并揭示了符号推理深度与基础稳定性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 跨领域科学合成需要连接碎片化文献中的机理解释，但现有检索系统和无约束语言模型在这方面存在局限。当前基于大语言模型的科学总结和问答方法对推理深度和结构基础的控制有限。

Method: 将机理合成构建为基于文献概念图的多跳推理问题。给定科学查询和紧凑的查询局部语料库，SciNets构建有向概念图，通过识别多跳推理路径来合成机理解释，这些路径连接了在单篇论文中很少共现的概念。系统比较了最短路径推理、带多样性约束的k最短路径、随机游走和检索增强语言模型基线。

Result: 在机器学习、生物学和气候科学任务中，显式图约束实现了可控的多跳推理，同时揭示了一致的权衡：更深层和更多样化的符号推理增加了基础不稳定性，而最短路径推理保持高度稳定但结构保守。

Conclusion: 这些发现为当前图-LLM集成在科学合成中的局限性和能力提供了系统的行为特征描述。图约束方法能够实现可控的多跳推理，但需要在推理深度和基础稳定性之间进行权衡。

Abstract: Cross-domain scientific synthesis requires connecting mechanistic explanations across fragmented literature, a capability that remains challenging for both retrieval-based systems and unconstrained language models. While recent work has applied large language models to scientific summarization and question answering, these approaches provide limited control over reasoning depth and structural grounding. We frame mechanistic synthesis as a graph-constrained multi-hop reasoning problem over literature-derived concept graphs. Given a scientific query and a compact, query-local corpus, SciNets constructs a directed concept graph and synthesizes mechanistic explanations by identifying multi-hop reasoning paths that connect concepts that rarely co-occur within individual papers. We systematically compare shortest-path reasoning, k-shortest paths with diversity constraints, stochastic random walks, and a retrieval-augmented language model baseline. Rather than evaluating correctness, which is often indeterminate when synthesizing connections across distributed sources, we introduce a behavioral framework that measures symbolic reasoning depth, mechanistic diversity, and grounding stability. Across machine learning, biology, and climate science tasks, explicit graph constraints enable controllable multi-hop reasoning while revealing a consistent trade-off: deeper and more diverse symbolic reasoning increases grounding instability, whereas shortest-path reasoning remains highly stable but structurally conservative. These findings provide a systematic behavioral characterization of the limits and capabilities of current graph-LLM integration for scientific synthesis.

</details>


### [16] [Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models](https://arxiv.org/abs/2601.10460)
*Abhinaba Basu,Pavan Chakraborty*

Main category: cs.CL

TL;DR: 论文提出Contextual StereoSet基准测试，发现模型偏见会随上下文（时间、地点、受众）变化而显著波动，传统固定条件测试的偏见评分可能无法泛化。


<details>
  <summary>Details</summary>
Motivation: 现有偏见基准测试通常在固定条件下评估模型，但实际部署中上下文因素（如时间、地点、受众）会影响偏见表现。实验室基准测试中避免刻板印象的模型，在部署时可能无法避免。

Method: 提出Contextual StereoSet基准测试，固定刻板印象内容但系统变化上下文框架。引入Context Sensitivity Fingerprints（CSF）方法，包含每维度离散度和配对对比的紧凑配置文件，支持两种评估方案：360上下文诊断网格和包含4,229项的预算协议。

Result: 测试13个模型发现显著模式：锚定到1990年（vs. 2030年）在所有模型中提高刻板印象选择；八卦框架在5/6全网格模型中提高偏见；外群体观察者框架使偏见变化达13个百分点。这些效应在招聘、贷款和求助场景中复现。

Conclusion: 偏见评估需要从"模型是否有偏见"转向"在什么条件下偏见会出现"。CSF方法强调评估的鲁棒性，固定条件测试的偏见评分可能无法泛化到不同上下文环境。

Abstract: A model that avoids stereotypes in a lab benchmark may not avoid them in deployment. We show that measured bias shifts dramatically when prompts mention different places, times, or audiences -- no adversarial prompting required.
  We introduce Contextual StereoSet, a benchmark that holds stereotype content fixed while systematically varying contextual framing. Testing 13 models across two protocols, we find striking patterns: anchoring to 1990 (vs. 2030) raises stereotype selection in all models tested on this contrast (p<0.05); gossip framing raises it in 5 of 6 full-grid models; out-group observer framing shifts it by up to 13 percentage points. These effects replicate in hiring, lending, and help-seeking vignettes.
  We propose Context Sensitivity Fingerprints (CSF): a compact profile of per-dimension dispersion and paired contrasts with bootstrap CIs and FDR correction. Two evaluation tracks support different use cases -- a 360-context diagnostic grid for deep analysis and a budgeted protocol covering 4,229 items for production screening.
  The implication is methodological: bias scores from fixed-condition tests may not generalize.This is not a claim about ground-truth bias rates; it is a stress test of evaluation robustness. CSF forces evaluators to ask, "Under what conditions does bias appear?" rather than "Is this model biased?" We release our benchmark, code, and results.

</details>


### [17] [Eliminating Agentic Workflow for Introduction Generation with Parametric Stage Tokens](https://arxiv.org/abs/2601.09728)
*Meicong Zhang,Tiancheng su,Guoxiu He*

Main category: cs.CL

TL;DR: STIG方法通过将多阶段工作流的逻辑结构参数化到LLM中，实现单次推理生成完整研究引言，避免了传统工作流的长推理链和错误累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于预定义工作流的LLM文献分类和综述方法在处理研究引言生成时面临挑战：引言需要严谨逻辑、连贯结构和抽象概括，而传统工作流存在推理链过长、错误累积和文本连贯性降低的问题。

Method: 提出STIG（Stage Token for Introduction Generation）方法，将原始工作流的多个阶段转换为显式的阶段信号（stage tokens），通过指令调优让模型学习阶段token与文本功能的映射关系，以及阶段间的逻辑顺序和转换模式，将这些知识编码到模型参数中。

Result: 实验结果表明，STIG能够在单次推理中生成多阶段文本，无需显式工作流调用，在语义相似度和句子级结构合理性指标上优于传统工作流和其他基线方法。

Conclusion: STIG通过将工作流逻辑结构参数化到LLM中，有效解决了传统工作流在引言生成中的局限性，实现了更高效、连贯的文本生成。

Abstract: In recent years, using predefined agentic workflows to guide large language models (LLMs) for literature classification and review has become a research focus. However, writing research introductions is more challenging. It requires rigorous logic, coherent structure, and abstract summarization. Existing workflows often suffer from long reasoning chains, error accumulation, and reduced textual coherence. To address these limitations, we propose eliminating external agentic workflows. Instead, we directly parameterize their logical structure into the LLM. This allows the generation of a complete introduction in a single inference. To this end, we introduce the Stage Token for Introduction Generation (STIG). STIG converts the multiple stages of the original workflow into explicit stage signals. These signals guide the model to follow different logical roles and functions during generation. Through instruction tuning, the model learns the mapping between stage tokens and text functions. It also learns the logical order and transition patterns between stages, encoding this knowledge into the model parameters. Experimental results show that STIG can generate multi-stage text in a single inference. It does not require explicit workflow calls. STIG outperforms traditional agentic workflows and other baselines on metrics of semantic similarity and sentence-level structural rationality. The code is provided in the Supplementary Materials.

</details>


### [18] [Enhancing Business Analytics through Hybrid Summarization of Financial Reports](https://arxiv.org/abs/2601.09729)
*Tohida Rehman*

Main category: cs.CL

TL;DR: 提出混合摘要框架，结合抽取式和生成式方法，从财报电话会议中生成路透社风格的摘要，在计算受限环境下实现竞争性结果和事实一致性。


<details>
  <summary>Details</summary>
Motivation: 财务报告和财报电话会议包含大量结构化和半结构化信息，手动分析效率低下且易受解释偏差和无意错误影响。需要自动化系统来高效提炼冗长财务文本为可用商业洞察。

Method: 提出两阶段混合框架：首先使用LexRank算法识别关键句子，然后用微调的BART和PEGASUS变体进行摘要。同时微调Longformer Encoder-Decoder模型直接捕捉金融文档中的长距离上下文依赖。

Result: 使用ROUGE、METEOR、MoverScore、BERTScore等标准指标评估，以及SciBERTScore和FinBERTScore等领域特定变体。为评估事实准确性，采用基于源精度和F1目标的实体级指标。长上下文模型表现最佳，混合框架在计算约束下实现竞争性结果并提高事实一致性。

Conclusion: 研究支持开发实用的摘要系统，用于高效提炼冗长财务文本为可用商业洞察。长上下文模型整体表现最强，而混合框架在计算受限环境下实现竞争性结果并提高事实一致性。

Abstract: Financial reports and earnings communications contain large volumes of structured and semi structured information, making detailed manual analysis inefficient. Earnings conference calls provide valuable evidence about a firm's performance, outlook, and strategic priorities. The manual analysis of lengthy call transcripts requires substantial effort and is susceptible to interpretive bias and unintentional error. In this work, we present a hybrid summarization framework that combines extractive and abstractive techniques to produce concise and factually reliable Reuters-style summaries from the ECTSum dataset. The proposed two stage pipeline first applies the LexRank algorithm to identify salient sentences, which are subsequently summarized using fine-tuned variants of BART and PEGASUS designed for resource constrained settings. In parallel, we fine-tune a Longformer Encoder-Decoder (LED) model to directly capture long-range contextual dependencies in financial documents.
  Model performance is evaluated using standard automatic metrics, including ROUGE, METEOR, MoverScore, and BERTScore, along with domain-specific variants such as SciBERTScore and FinBERTScore. To assess factual accuracy, we further employ entity-level measures based on source-precision and F1-target. The results highlight complementary trade offs between approaches, long context models yield the strongest overall performance, while the hybrid framework achieves competitive results with improved factual consistency under computational constraints. These findings support the development of practical summarization systems for efficiently distilling lengthy financial texts into usable business insights.

</details>


### [19] [Clinical Document Metadata Extraction: A Scoping Review](https://arxiv.org/abs/2601.09730)
*Kurt Miller,Qiuhao Lu,William Hersh,Kirk Roberts,Steven Bedrick,Andrew Wen,Hongfang Liu*

Main category: cs.CL

TL;DR: 本文对临床文档元数据提取研究进行了范围综述，分析了2011-2025年的相关文献，总结了方法演进趋势和应用现状。


<details>
  <summary>Details</summary>
Motivation: 临床文档元数据（如文档类型、结构、作者角色、医学专业、就诊环境）对准确解读临床信息至关重要，但由于文档异质性和时间漂移，元数据协调面临挑战。需要系统梳理自动提取方法的研究现状。

Method: 遵循PRISMA-ScR指南进行范围综述，从2011-2025年发表的266篇文章中筛选出67篇相关文献进行分析，包括45篇方法学研究、17篇下游应用研究和5篇元数据组成分析。

Result: 发现临床文档元数据提取方法从基于规则和传统机器学习（需要大量特征工程）发展到基于Transformer的架构（特征工程需求最小化）。大语言模型的出现促进了跨任务和数据集泛化能力的探索。除结构部分数据集外，公开标注数据仍然稀缺。

Conclusion: 研究将继续向更丰富的文档元数据表示扩展，并进一步集成到临床应用和工作流程中。大语言模型为实现先进的临床文本处理系统提供了可能性。

Abstract: Clinical document metadata, such as document type, structure, author role, medical specialty, and encounter setting, is essential for accurate interpretation of information captured in clinical documents. However, vast documentation heterogeneity and drift over time challenge harmonization of document metadata. Automated extraction methods have emerged to coalesce metadata from disparate practices into target schema. This scoping review aims to catalog research on clinical document metadata extraction, identify methodological trends and applications, and highlight gaps. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines to identify articles that perform clinical document metadata extraction. We initially found and screened 266 articles published between January 2011 and August 2025, then comprehensively reviewed 67 we deemed relevant to our study. Among the articles included, 45 were methodological, 17 used document metadata as features in a downstream application, and 5 analyzed document metadata composition. We observe myriad purposes for methodological study and application types. Available labelled public data remains sparse except for structural section datasets. Methods for extracting document metadata have progressed from largely rule-based and traditional machine learning with ample feature engineering to transformer-based architectures with minimal feature engineering. The emergence of large language models has enabled broader exploration of generalizability across tasks and datasets, allowing the possibility of advanced clinical text processing systems. We anticipate that research will continue to expand into richer document metadata representations and integrate further into clinical applications and workflows.

</details>


### [20] [Geometric Patterns of Meaning: A PHATE Manifold Analysis of Multi-lingual Embeddings](https://arxiv.org/abs/2601.09731)
*Wen G Gong*

Main category: cs.CL

TL;DR: 论文提出了一个多层级语义几何分析框架，使用PHATE流形学习技术可视化多语言嵌入空间，揭示了不同语言层级的系统性几何模式及当前嵌入模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前对多语言嵌入空间语义几何结构的研究缺乏系统性的多层级分析框架，需要更好的工具来理解嵌入模型如何在不同语言层级捕捉语义关系，并验证模型的有效性。

Method: 开发了Semanscope可视化工具，应用PHATE流形学习技术，在四个语言层级（亚字符、字符、词语、数字概念）分析多语言嵌入的几何结构，涵盖中文、英文、德文和阿拉伯数字等多种语言数据。

Result: 发现了系统性几何模式：亚字符级（中文部首）出现几何塌陷；字符级不同书写系统有独特几何特征；词语级内容词在20个语义域形成聚类-分支模式；阿拉伯数字呈现螺旋轨迹而非聚类模式，违反了分布语义学假设。

Conclusion: PHATE流形学习是研究嵌入空间语义几何结构的重要分析工具，不仅能揭示语义关系的几何模式，还能验证嵌入模型捕捉语义关系的有效性，发现了当前模型在区分语义与结构组件方面的局限性。

Abstract: We introduce a multi-level analysis framework for examining semantic geometry in multilingual embeddings, implemented through Semanscope (a visualization tool that applies PHATE manifold learning across four linguistic levels). Analysis of diverse datasets spanning sub-character components, alphabetic systems, semantic domains, and numerical concepts reveals systematic geometric patterns and critical limitations in current embedding models. At the sub-character level, purely structural elements (Chinese radicals) exhibit geometric collapse, highlighting model failures to distinguish semantic from structural components. At the character level, different writing systems show distinct geometric signatures. At the word level, content words form clustering-branching patterns across 20 semantic domains in English, Chinese, and German. Arabic numbers organize through spiral trajectories rather than clustering, violating standard distributional semantics assumptions. These findings establish PHATE manifold learning as an essential analytic tool not only for studying geometric structure of meaning in embedding space, but also for validating the effectiveness of embedding models in capturing semantic relationships.

</details>


### [21] [Benchmarking Cross-Lingual Semantic Alignment in Multilingual Embeddings](https://arxiv.org/abs/2601.09732)
*Wen G. Gong*

Main category: cs.CL

TL;DR: 论文提出语义亲和度(SA)指标评估多语言嵌入模型的跨语言语义对齐能力，发现训练目标而非模型规模决定对齐质量，需要明确的翻译监督而非仅多语言数据。


<details>
  <summary>Details</summary>
Motivation: 当前有数百个多语言嵌入模型可用，但缺乏指导帮助从业者区分哪些模型真正实现了跨语言语义对齐，哪些只是通过语言特定模式获得任务性能。任务驱动的基准测试(如MTEB)可能掩盖基本的对齐缺陷。

Method: 引入语义亲和度(SA)指标，该指标使用余弦距离计算跨语言与语言内分布比率，值在0-1之间。结合PHATE可视化构建Semanscope框架。在4个数据集上对13个模型进行52次实验评估。

Result: 发现三层结构：1) 基于翻译对监督的BERT模型(LaBSE SA=0.70)表现最好；2) LLM嵌入在SA 0.55-0.61间停滞，与规模(0.6B-8B)无关；3) 仅MLM训练的BERT模型(SA<0.50)失败。甲骨文原语实验显示模型学习的是语料模式而非认知原语。

Conclusion: 训练目标而非架构或规模决定跨语言对齐质量。真正的跨语言语义对齐需要明确的翻译监督，而不仅仅是模型规模或多语言数据。该工作为从业者从数百个可用模型中选择高质量多语言嵌入提供了语义基准测试方法。

Abstract: With hundreds of multilingual embedding models available, practitioners lack clear guidance on which provide genuine cross-lingual semantic alignment versus task performance through language-specific patterns. Task-driven benchmarks (MTEB) may mask fundamental alignment shortcomings. We introduce Semantic Affinity (SA), a bounded (between 0 and 1) metric measuring inter-lingual to intra-lingual spread ratio using cosine distance, combined with PHATE visualization in our Semanscope framework. Benchmarking 13 models across 4 datasets (52 experiments) reveals a three-tier structure: (1) Top BERT models (LaBSE SA = 0.70, USE SA = 0.68, S-BERT SA = 0.68) achieve strong alignment via translation-pair supervision; (2) LLM embeddings plateau at SA between 0.55 and 0.61 regardless of 0.6 B to 8 B scale; (3) MLM-only BERT models (mBERT, XLM-R, SA < 0.50) fail despite more than 100 language training. Training objective, not architecture or scale, determines alignment. Oracle Bone primitives (1200 BCE) expose semantic drift-models learn corpus patterns rather than cognitive primitives. This work provides semantic benchmarking to help practitioners select quality multilingual embeddings from hundreds of available models, showing cross-lingual alignment requires explicit translation supervision, not merely model scale or multilingual data.

</details>


### [22] [Closing the Data Loop: Using OpenDataArena to Engineer Superior Training Datasets](https://arxiv.org/abs/2601.09733)
*Xin Gao,Xiaoyang Wang,Yun Zhu,Mengzhang Cai,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 论文提出了OpenDataArena（ODA）框架，通过价值锚定排名和多维分析将基准测试转化为指导数据集构建的反馈信号，创建了ODA-Math-460k和ODA-Mixture数据集，显著提升了LLM的领域推理和通用能力。


<details>
  <summary>Details</summary>
Motivation: 当前SFT数据集构建缺乏理论指导，主要依赖启发式聚合，缺乏对单个样本如何影响模型性能的系统理解。需要从临时性数据整理转向系统化的数据集工程框架。

Method: 提出ODA框架，利用价值锚定排名和多维分析将基准测试转化为反馈信号。具体实现包括：1）ODA-Math-460k：使用两阶段难度感知管道构建的数学推理数据集；2）ODA-Mixture：通过"锚定-修补"策略构建的多领域指令数据集。

Result: ODA-Math-460k在AIME和HMMT等基准测试上达到SOTA性能；ODA-Mixture数据集在显著小于开源基线的情况下表现更优；ODA驱动数据集显著提升领域特定推理和通用效用，同时实现卓越的数据效率。

Conclusion: ODA框架验证了向数据为中心AI的转变，其中透明评估成为工程化高质量训练数据的主要引擎，为系统化数据集构建提供了新范式。

Abstract: The construction of Supervised Fine-Tuning (SFT) datasets is a critical yet under-theorized stage in the post-training of Large Language Models (LLMs), as prevalent practices often rely on heuristic aggregation without a systematic understanding of how individual samples contribute to model performance. In this report, we propose a paradigm shift from ad-hoc curation to a closed-loop dataset engineering framework using OpenDataArena (ODA), which leverages value-anchored rankings and multi-dimensional analysis to transform value benchmarking into feedback signals guiding dataset construction. We instantiate this methodology through two new datasets: \textbf{ODA-Math-460k}, a specialized mathematics reasoning dataset that utilizes a novel two-stage difficulty-aware pipeline to achieve State-of-the-Art (SOTA) results on benchmarks such as AIME and HMMT, and \textbf{ODA-Mixture (100k \& 500k)}, a series of multi-domain instruction datasets built via an ``Anchor-and-Patch'' strategy that outperforms significantly larger open-source baselines. Our empirical results demonstrate that ODA-driven datasets significantly improve both domain-specific reasoning and general utility while achieving superior data efficiency, validating a transition toward data-centric AI where transparent evaluation serves as the primary engine for engineering high-quality training data.

</details>


### [23] [From Detection to Diagnosis: Advancing Hallucination Analysis with Automated Data Synthesis](https://arxiv.org/abs/2601.09734)
*Yanyi Liu,Qingwen Yang,Tiezheng Guo,Feiyu Qu,Jun Liu,Yingyou Wen*

Main category: cs.CL

TL;DR: 提出从幻觉检测转向幻觉诊断的新范式，通过自动化生成诊断数据训练4B参数模型，在检测和诊断任务上均取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM幻觉研究主要关注二元检测方法，虽然能识别幻觉但缺乏可解释性和可操作性反馈，限制了实际应用价值。需要从检测转向诊断，提供更全面的分析。

Method: 1) 提出幻觉诊断任务，要求模型检测幻觉、定位错误、解释原因并修正内容；2) 开发HDG自动化流水线，通过受控事实伪造和推理链扰动等策略生成高质量训练数据；3) 使用GRPO训练4B参数的HDM-4B-RL模型，采用包含结构、准确性和定位信号的综合奖励函数。

Result: 在HaluEval基准测试中超越先前最先进的检测模型；在综合诊断任务中，HDM-4B-RL与更大的通用模型能力相当，同时保持较小规模。

Conclusion: 验证了幻觉诊断的可行性和价值，为构建更可信赖的生成式AI系统提供了有效方法学，推动了从简单检测到全面诊断的研究范式转变。

Abstract: Hallucinations in Large Language Models (LLMs), defined as the generation of content inconsistent with facts or context, represent a core obstacle to their reliable deployment in critical domains. Current research primarily focuses on binary "detection" approaches that, while capable of identifying hallucinations, fail to provide interpretable and actionable feedback for model improvement, thus limiting practical utility. To address this limitation, a new research paradigm is proposed, shifting from "detection" to "diagnosis". The Hallucination Diagnosis Task is introduced, a task which requires models to not only detect hallucinations, but also perform error localization, causal explanation, and content correction. We develop the Hallucination Diagnosis Generator (HDG), an automated pipeline that systematically generates high-quality training samples with rich diagnostic metadata from raw corpora through multi-dimensional augmentation strategies including controlled fact fabrication and reasoning chain perturbation. Using HDG-generated data, we train HDM-4B-RL, a 4-billion-parameter hallucination diagnosis model, employing Group Relative Policy Optimization (GRPO) with a comprehensive reward function incorporating structural, accuracy, and localization signals. Experimental results demonstrate that our model surpasses previous state-of-the-art detection models on the HaluEval benchmark while achieving comparable performance to advanced general-purpose models. In comprehensive diagnosis tasks, HDM-4B-RL matches the capabilities of larger general models while maintaining a smaller size. This work validates the feasibility and value of hallucination diagnosis, providing an effective methodology for building more trustworthy and reliable generative AI systems.

</details>


### [24] [Stable and Explainable Personality Trait Evaluation in Large Language Models with Internal Activations](https://arxiv.org/abs/2601.09833)
*Xiaoxu Ma,Xiangbo Zhang,Zhenyu Weng*

Main category: cs.CL

TL;DR: PVNI：一种基于内部激活的稳定可解释LLM人格特质评估方法，通过提取人格向量并进行插值来估计中性分数


<details>
  <summary>Details</summary>
Motivation: 现有基于问卷的LLM人格评估方法稳定性差、可解释性低，结果对提示词微小变化敏感，需要更稳定可解释的评估方法

Method: 提出Persona-Vector Neutrality Interpolation (PVNI)：1) 使用对比提示从模型内部激活中提取目标人格特质相关的人格向量；2) 沿人格向量作为锚轴进行插值，估计相应的中性分数；3) 在中性提示表示和人格方向之间进行可解释比较

Result: 理论分析证明了PVNI的有效性和泛化特性；跨多种LLM的广泛实验表明，PVNI比现有方法产生更稳定的人格特质评估，即使在问卷和角色扮演变体下也表现良好

Conclusion: PVNI为LLM人格特质评估提供了稳定且可解释的方法，解决了现有问卷方法的局限性，有助于模型解释、比较和负责任部署

Abstract: Evaluating personality traits in Large Language Models (LLMs) is key to model interpretation, comparison, and responsible deployment. However, existing questionnaire-based evaluation methods exhibit limited stability and offer little explainability, as their results are highly sensitive to minor variations in prompt phrasing or role-play configurations. To address these limitations, we propose an internal-activation-based approach, termed Persona-Vector Neutrality Interpolation (PVNI), for stable and explainable personality trait evaluation in LLMs. PVNI extracts a persona vector associated with a target personality trait from the model's internal activations using contrastive prompts. It then estimates the corresponding neutral score by interpolating along the persona vector as an anchor axis, enabling an interpretable comparison between the neutral prompt representation and the persona direction. We provide a theoretical analysis of the effectiveness and generalization properties of PVNI. Extensive experiments across diverse LLMs demonstrate that PVNI yields substantially more stable personality trait evaluations than existing methods, even under questionnaire and role-play variants.

</details>


### [25] [Bears, all bears, and some bears. Language Constraints on Language Models' Inductive Inferences](https://arxiv.org/abs/2601.09852)
*Sriram Padmanabhan,Siyuan Song,Kanishka Misra*

Main category: cs.CL

TL;DR: 研究测试视觉语言模型是否能像儿童一样区分泛型陈述、全称量词和存在量词在归纳推理中的差异，发现模型行为与人类对齐。


<details>
  <summary>Details</summary>
Motivation: 语言对归纳推理有微妙约束，儿童研究显示他们能区分泛型陈述("Bears are daxable")、全称量词("all bears are daxable")和存在量词("some bears are daxable")。本研究想探究通用统计学习器（如视觉语言模型）是否也能表现出这种细微差异。

Method: 通过一系列预条件测试（图像类别识别、对"all"和"some"的敏感性），然后复制原始实验，测试视觉语言模型。事后分析检查模型的表征是否基于归纳约束而非表面形式差异。

Result: 发现模型行为与人类对齐，模型能区分不同量词类型（全称 > 泛型 > 存在）。事后分析表明这些差异是基于归纳约束组织的，而非表面形式差异。

Conclusion: 视觉语言模型作为通用统计学习器，能够捕捉语言对归纳推理的微妙约束，表现出与儿童相似的区分能力，表明这些差异源于深层的归纳约束机制。

Abstract: Language places subtle constraints on how we make inductive inferences. Developmental evidence by Gelman et al. (2002) has shown children (4 years and older) to differentiate among generic statements ("Bears are daxable"), universally quantified NPs ("all bears are daxable") and indefinite plural NPs ("some bears are daxable") in extending novel properties to a specific member (all > generics > some), suggesting that they represent these types of propositions differently. We test if these subtle differences arise in general purpose statistical learners like Vision Language Models, by replicating the original experiment. On tasking them through a series of precondition tests (robust identification of categories in images and sensitivities to all and some), followed by the original experiment, we find behavioral alignment between models and humans. Post-hoc analyses on their representations revealed that these differences are organized based on inductive constraints and not surface-form differences.

</details>


### [26] [MedRedFlag: Investigating how LLMs Redirect Misconceptions in Real-World Health Communication](https://arxiv.org/abs/2601.09853)
*Sraavya Sambara,Yuan Pu,Ayman Ali,Vishala Mishra,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: LLMs在回答包含错误前提的真实世界健康问题时，经常无法正确重定向，可能导致次优医疗决策，存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 患者提出的真实世界健康问题常常无意中嵌入错误假设，安全的医疗沟通需要重定向：先纠正隐含的误解，再回应患者的真实关切。虽然LLMs越来越多地被普通用户用于医疗咨询，但尚未测试其在这关键能力上的表现。

Method: 开发半自动化流程构建MedRedFlag数据集（1100+个来自Reddit的需要重定向的问题），系统比较最先进LLMs与临床医生的回答。

Result: LLMs经常无法重定向有问题的健康问题，即使检测到错误前提，仍会提供可能导致次优医疗决策的答案。

Conclusion: LLMs在真实世界健康沟通条件下存在显著能力差距，凸显了面向患者的医疗AI系统的关键安全问题。

Abstract: Real-world health questions from patients often unintentionally embed false assumptions or premises. In such cases, safe medical communication typically involves redirection: addressing the implicit misconception and then responding to the underlying patient context, rather than the original question. While large language models (LLMs) are increasingly being used by lay users for medical advice, they have not yet been tested for this crucial competency. Therefore, in this work, we investigate how LLMs react to false premises embedded within real-world health questions. We develop a semi-automated pipeline to curate MedRedFlag, a dataset of 1100+ questions sourced from Reddit that require redirection. We then systematically compare responses from state-of-the-art LLMs to those from clinicians. Our analysis reveals that LLMs often fail to redirect problematic questions, even when the problematic premise is detected, and provide answers that could lead to suboptimal medical decision making. Our benchmark and results reveal a novel and substantial gap in how LLMs perform under the conditions of real-world health communication, highlighting critical safety concerns for patient-facing medical AI systems. Code and dataset are available at https://github.com/srsambara-1/MedRedFlag.

</details>


### [27] [OUTLINEFORGE: Hierarchical Reinforcement Learning with Explicit States for Scientific Writing](https://arxiv.org/abs/2601.09858)
*Yilin Bao,Ziyao He,Zayden Yang*

Main category: cs.CL

TL;DR: 提出基于强化学习的科学论文生成框架，通过结构化编辑动作建模大纲演化，采用两阶段优化提升文档规划、引用一致性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在科学论文生成中存在全局结构、输入覆盖和引用一致性方面的不足，需要文档级规划和事实基础。

Method: 将科学大纲构建建模为分层文档结构上的长时程规划问题，通过结构化动作建模大纲演化。采用两阶段优化：1）从部分计划向后重建大纲以确保全局结构一致性；2）前向值引导的强化学习，奖励函数显式建模科学正确性、语篇连贯性和引用保真度。

Result: 相比强大的神经和LLM基线，在长程结构连贯性和引用可靠性方面取得一致改进，特别是在文档规划、输入利用和引用忠实度方面表现优异。

Conclusion: 提出的强化学习框架能有效解决科学论文生成中的文档级规划问题，通过结构化大纲编辑和两阶段优化显著提升全局结构一致性和引用保真度。

Abstract: Scientific paper generation requires document-level planning and factual grounding, but current large language models, despite their strong local fluency, often fail in global structure, input coverage, and citation consistency. We present a reinforcement learning framework that casts scientific outline construction as a long-horizon planning problem over hierarchical document structures. Our approach models edit evolving outlines through structured actions, enabling the system to incrementally build a complete scientific manuscript. To support effective and stabilize learning,we introduce a two-stage optimization procedure consisting of (i) backward outline reconstruction from partial plans to enforce global structural consistency, and (ii) forward value-guided reinforcement learning with rewards explicitly modeling scientific correctness, discourse coherence, and citation fidelity. In addition, We further introduce a benchmark for scientific paper generation that evaluates document planning, input utilization, reference faithfulness, outline organization, and content-level factual accuracy. Our results show consistent improvements over strong neural and LLM baselines, particularly in long-range structural coherence and citation reliability.

</details>


### [28] [Patient-Similarity Cohort Reasoning in Clinical Text-to-SQL](https://arxiv.org/abs/2601.09876)
*Yifei Shen,Yilun Zhao,Justice Ou,Tinglin Huang,Arman Cohan*

Main category: cs.CL

TL;DR: CLINSQL是一个临床文本到SQL的基准测试，包含633个专家标注任务，基于MIMIC-IV v3.1数据集，要求处理多表连接、临床相关过滤和可执行SQL查询，现有模型性能仍远未达到临床可靠性要求。


<details>
  <summary>Details</summary>
Motivation: 现实世界的临床文本到SQL需要处理异构的电子健康记录表格、时间窗口和患者相似性队列，而现有基准测试无法充分评估这些复杂需求。需要创建一个更贴近真实临床场景的基准来推动临床可靠文本到SQL系统的发展。

Method: 创建CLINSQL基准，包含633个专家标注任务，基于MIMIC-IV v3.1数据集。评估22个专有和开源模型，采用思维链自优化方法，使用基于规则的SQL分析和执行检查，重点关注关键的临床需求。

Result: GPT-5-mini在测试集上获得74.7%的执行分数，DeepSeek-R1在开源模型中领先为69.2%，Gemini-2.5-Pro从Easy任务的85.5%下降到Hard任务的67.2%。尽管有进展，但性能仍远未达到临床可靠性要求。

Conclusion: CLINSQL基准为临床文本到SQL系统提供了现实的评估标准，展示了当前模型在复杂临床查询处理上的局限性，但该基准的进展标志着向临床可靠文本到SQL系统迈出了切实的步伐。

Abstract: Real-world clinical text-to-SQL requires reasoning over heterogeneous EHR tables, temporal windows, and patient-similarity cohorts to produce executable queries. We introduce CLINSQL, a benchmark of 633 expert-annotated tasks on MIMIC-IV v3.1 that demands multi-table joins, clinically meaningful filters, and executable SQL. Solving CLINSQL entails navigating schema metadata and clinical coding systems, handling long contexts, and composing multi-step queries beyond traditional text-to-SQL. We evaluate 22 proprietary and open-source models under Chain-of-Thought self-refinement and use rubric-based SQL analysis with execution checks that prioritize critical clinical requirements. Despite recent advances, performance remains far from clinical reliability: on the test set, GPT-5-mini attains 74.7% execution score, DeepSeek-R1 leads open-source at 69.2% and Gemini-2.5-Pro drops from 85.5% on Easy to 67.2% on Hard. Progress on CLINSQL marks tangible advances toward clinically reliable text-to-SQL for real-world EHR analytics.

</details>


### [29] [Clozing the Gap: Exploring Why Language Model Surprisal Outperforms Cloze Surprisal](https://arxiv.org/abs/2601.09886)
*Sathvik Nair,Byung-Doh Oh*

Main category: cs.CL

TL;DR: LM概率在预测语言处理努力方面优于完形填空数据，主要因为其具有更高分辨率、能区分语义相似词、并能准确分配低频词概率


<details>
  <summary>Details</summary>
Motivation: 虽然语言模型概率在预测处理努力方面优于完形填空概率，但需要确认这种优势是否出于正确原因，因为不同的预测因子可能导致关于预测在语言理解中作用的不同科学结论

Method: 通过分析比较语言模型概率和完形填空概率的特性，提出并验证三个假设：1) 不遭受低分辨率问题；2) 能区分语义相似词；3) 能准确分配低频词概率

Result: 语言模型概率确实在三个关键方面优于完形填空概率：具有更高分辨率、能更好地区分语义相似词、并能更准确地处理低频词

Conclusion: 需要改进完形填空研究的分辨率，并实验验证人类预测是否也像语言模型概率那样对细微区分敏感，这对理解预测在语言理解中的作用具有重要意义

Abstract: How predictable a word is can be quantified in two ways: using human responses to the cloze task or using probabilities from language models (LMs).When used as predictors of processing effort, LM probabilities outperform probabilities derived from cloze data. However, it is important to establish that LM probabilities do so for the right reasons, since different predictors can lead to different scientific conclusions about the role of prediction in language comprehension. We present evidence for three hypotheses about the advantage of LM probabilities: not suffering from low resolution, distinguishing semantically similar words, and accurately assigning probabilities to low-frequency words. These results call for efforts to improve the resolution of cloze studies, coupled with experiments on whether human-like prediction is also as sensitive to the fine-grained distinctions made by LM probabilities.

</details>


### [30] [Take Out Your Calculators: Estimating the Real Difficulty of Question Items with LLM Student Simulations](https://arxiv.org/abs/2601.09953)
*Christabel Acquaye,Yi Ting Huang,Marine Carpuat,Rachel Rudinger*

Main category: cs.CL

TL;DR: 使用开源大语言模型模拟学生课堂，通过项目反应理论预测数学选择题难度，与真实NAEP数据相关性高达0.82


<details>
  <summary>Details</summary>
Motivation: 传统数学评估需要昂贵的人工试点研究来确定试题难度，研究探索使用开源LLMs预测真实学生数学题目难度的可行性

Method: 让LLMs扮演不同水平的学生（4、8、12年级），模拟"课堂"回答数学选择题，使用模拟结果拟合项目反应理论模型，将预测难度与NAEP真实数据对比

Result: 预测难度与真实难度相关性高达0.75（4年级）、0.76（8年级）、0.82（12年级）；使用具名学生角色扮演比匿名更好，按性别和种族分层进一步改善预测；数学能力较弱的Gemma模型反而比更强的Llama和Qwen预测更准确

Conclusion: LLMs模拟学生课堂的方法能有效预测数学题目难度，为标准化测试开发提供低成本替代方案，开源模型在此任务上表现优异

Abstract: Standardized math assessments require expensive human pilot studies to establish the difficulty of test items. We investigate the predictive value of open-source large language models (LLMs) for evaluating the difficulty of multiple-choice math questions for real-world students. We show that, while LLMs are poor direct judges of problem difficulty, simulation-based approaches with LLMs yield promising results under the right conditions. Under the proposed approach, we simulate a "classroom" of 4th, 8th, or 12th grade students by prompting the LLM to role-play students of varying proficiency levels. We use the outcomes of these simulations to fit Item Response Theory (IRT) models, comparing learned difficulty parameters for items to their real-world difficulties, as determined by item-level statistics furnished by the National Assessment of Educational Progress (NAEP). We observe correlations as high as 0.75, 0.76, and 0.82 for grades 4, 8, and 12, respectively. In our simulations, we experiment with different "classroom sizes," showing tradeoffs between computation size and accuracy. We find that role-plays with named students improves predictions (compared to student ids), and stratifying names across gender and race further improves predictions. Our results show that LLMs with relatively weaker mathematical abilities (Gemma) actually yield better real-world difficulty predictions than mathematically stronger models (Llama and Qwen), further underscoring the suitability of open-source models for the task.

</details>


### [31] [Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG](https://arxiv.org/abs/2601.09982)
*David Samuel Setiawan,Raphaël Merx,Jey Han Lau*

Main category: cs.CL

TL;DR: 针对低资源语言Dhao，提出混合框架：先用微调NMT生成初稿，再用LLM+RAG精修，有效恢复跨领域翻译性能损失


<details>
  <summary>Details</summary>
Motivation: 低资源语言的神经机器翻译模型在领域迁移时性能显著下降，特别是对于Dhao这种只有新约圣经数字资源的土著语言，应用到旧约圣经时性能大幅降低

Method: 混合框架：先对微调的NMT模型生成初始翻译草稿，然后使用大型语言模型通过检索增强生成技术进行精修

Result: 系统最终达到35.21 chrF++，恢复8.10分，基本匹配原始领域内质量；性能主要取决于检索示例数量而非检索算法选择

Conclusion: LLM+RAG作为强大的"安全网"，能有效修复零样本领域的严重翻译失败，为低资源语言跨领域翻译提供可行解决方案

Abstract: Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the unseen Old Testament (OT), a standard NMT model fine-tuned on the NT drops from an in-domain score of 36.17 chrF++ to 27.11 chrF++. To recover this loss, we introduce a hybrid framework where a fine-tuned NMT model generates an initial draft, which is then refined by a Large Language Model (LLM) using Retrieval-Augmented Generation (RAG). The final system achieves 35.21 chrF++ (+8.10 recovery), effectively matching the original in-domain quality. Our analysis reveals that this performance is driven primarily by the number of retrieved examples rather than the choice of retrieval algorithm. Qualitative analysis confirms the LLM acts as a robust "safety net," repairing severe failures in zero-shot domains.

</details>


### [32] [SocraticKG: Knowledge Graph Construction via QA-Driven Fact Extraction](https://arxiv.org/abs/2601.10003)
*Sanghyeok Choi,Woosang Jeon,Kyuseok Yang,Taehyeong Kim*

Main category: cs.CL

TL;DR: SocraticKG使用问答对作为中间表示来构建知识图谱，通过5W1H引导的QA扩展解决覆盖度与连接性的权衡问题，在保持结构连贯性的同时提高事实保留率。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的知识图谱构建方法面临一个基本权衡：追求事实覆盖度会导致关系碎片化，而提前整合又会导致信息丢失。需要一种方法能够系统性地展开文档级语义，然后再进行三元组抽取。

Method: 提出SocraticKG方法，引入问答对作为结构化中间表示，在抽取三元组之前系统性地展开文档级语义。采用5W1H引导的QA扩展来捕捉上下文依赖和隐含关系链接，提供源文档的显式基础以减少隐含推理错误。

Result: 在MINE基准测试中，该方法有效解决了覆盖度与连接性的权衡问题，在提取知识量大幅增加的情况下，实现了优越的事实保留率并保持高结构连贯性。

Conclusion: QA介导的语义支架在KG抽取前的语义结构化中发挥关键作用，能够在后续阶段实现更连贯可靠的知识图谱构建，表明中间表示对知识图谱构建质量有重要影响。

Abstract: Constructing Knowledge Graphs (KGs) from unstructured text provides a structured framework for knowledge representation and reasoning, yet current LLM-based approaches struggle with a fundamental trade-off: factual coverage often leads to relational fragmentation, while premature consolidation causes information loss. To address this, we propose SocraticKG, an automated KG construction method that introduces question-answer pairs as a structured intermediate representation to systematically unfold document-level semantics prior to triple extraction. By employing 5W1H-guided QA expansion, SocraticKG captures contextual dependencies and implicit relational links typically lost in direct KG extraction pipelines, providing explicit grounding in the source document that helps mitigate implicit reasoning errors. Evaluation on the MINE benchmark demonstrates that our approach effectively addresses the coverage-connectivity trade-off, achieving superior factual retention while maintaining high structural cohesion even as extracted knowledge volume substantially expands. These results highlight that QA-mediated semantic scaffolding plays a critical role in structuring semantics prior to KG extraction, enabling more coherent and reliable graph construction in subsequent stages.

</details>


### [33] [EHRNavigator: A Multi-Agent System for Patient-Level Clinical Question Answering over Heterogeneous Electronic Health Records](https://arxiv.org/abs/2601.10020)
*Lingfei Qian,Mauro Giuffre,Yan Wang,Huan He,Qianqian Xie,Xuguang Ai,Xeuqing Peng,Fan Ma,Ruey-Ling Weng,Donald Wright,Adan Wang,Qingyu Chen,Vipina K. Keloth,Hua Xu*

Main category: cs.CL

TL;DR: EHRNavigator是一个多智能体框架，利用AI智能体在异构多模态电子健康记录中进行患者级问答，在真实医院条件下达到86%准确率，有效弥合基准评估与临床部署之间的差距。


<details>
  <summary>Details</summary>
Motivation: 临床决策越来越依赖电子健康记录中及时且情境感知的患者信息访问，但现有自然语言问答系统大多仅在基准数据集上评估，限制了其实际相关性。

Method: 引入EHRNavigator多智能体框架，利用AI智能体在异构多模态EHR数据中执行患者级问答。在具有不同模式、时间推理需求和多模态证据整合的现实医院条件下，使用公共基准和机构数据集评估其性能。

Result: 通过定量评估和临床医生验证的图表审查，EHRNavigator表现出强大的泛化能力，在真实案例中达到86%准确率，同时保持临床可接受的响应时间。

Conclusion: EHRNavigator有效弥合了基准评估与临床部署之间的差距，为真实世界EHR问答提供了一个稳健、自适应且高效的解决方案。

Abstract: Clinical decision-making increasingly relies on timely and context-aware access to patient information within Electronic Health Records (EHRs), yet most existing natural language question-answering (QA) systems are evaluated solely on benchmark datasets, limiting their practical relevance. To overcome this limitation, we introduce EHRNavigator, a multi-agent framework that harnesses AI agents to perform patient-level question answering across heterogeneous and multimodal EHR data. We assessed its performance using both public benchmark and institutional datasets under realistic hospital conditions characterized by diverse schemas, temporal reasoning demands, and multimodal evidence integration. Through quantitative evaluation and clinician-validated chart review, EHRNavigator demonstrated strong generalization, achieving 86% accuracy on real-world cases while maintaining clinically acceptable response times. Overall, these findings confirm that EHRNavigator effectively bridges the gap between benchmark evaluation and clinical deployment, offering a robust, adaptive, and efficient solution for real-world EHR question answering.

</details>


### [34] [EmplifAI: a Fine-grained Dataset for Japanese Empathetic Medical Dialogues in 28 Emotion Labels](https://arxiv.org/abs/2601.10033)
*Wan Jou She,Lis Kanashiro Pereira,Fei Cheng,Sakiko Yahata,Panote Siriaraya,Eiji Aramaki*

Main category: cs.CL

TL;DR: EmplifAI是一个日本共情对话数据集，专门针对慢性疾病患者设计，包含28种细粒度情感类别、280个医疗情境和4125个双轮对话，用于提升LLM的共情对话能力。


<details>
  <summary>Details</summary>
Motivation: 慢性疾病患者经历复杂的情感波动（如希望与绝望），现有对话系统缺乏针对这种特定医疗情境的共情能力，需要专门的数据集来支持情感对齐的对话生成。

Method: 基于GoEmotions分类法构建28种细粒度情感类别，通过众包和专家评审收集280个医疗情境和4125个双轮对话。使用BERTScore评估情感对齐，并微调日本LLM（LLM-jp-3.1-13b-instruct4）。

Result: BERTScore评估显示F1分数达0.83，微调后模型在流畅性、一般共情和情感特定共情方面显著提升。LLM-as-a-Judge与人类评分者的相关性分析验证了评估流程的有效性。

Conclusion: EmplifAI数据集有效提升了LLM在医疗共情对话中的表现，为慢性疾病患者的心理支持提供了技术基础，同时揭示了评估流程的可行性和潜在风险。

Abstract: This paper introduces EmplifAI, a Japanese empathetic dialogue dataset designed to support patients coping with chronic medical conditions. They often experience a wide range of positive and negative emotions (e.g., hope and despair) that shift across different stages of disease management. EmplifAI addresses this complexity by providing situation-based dialogues grounded in 28 fine-grained emotion categories, adapted and validated from the GoEmotions taxonomy. The dataset includes 280 medically contextualized situations and 4125 two-turn dialogues, collected through crowdsourcing and expert review. To evaluate emotional alignment in empathetic dialogues, we assessed model predictions on situation--dialogue pairs using BERTScore across multiple large language models (LLMs), achieving F1 scores of 0.83. Fine-tuning a baseline Japanese LLM (LLM-jp-3.1-13b-instruct4) with EmplifAI resulted in notable improvements in fluency, general empathy, and emotion-specific empathy. Furthermore, we compared the scores assigned by LLM-as-a-Judge and human raters on dialogues generated by multiple LLMs to validate our evaluation pipeline and discuss the insights and potential risks derived from the correlation analysis.

</details>


### [35] [Long-Chain Reasoning Distillation via Adaptive Prefix Alignment](https://arxiv.org/abs/2601.10064)
*Zhenghao Liu,Zhuoyang Wu,Xinze Li,Yukun Yan,Shuo Wang,Zulong Chen,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: P-ALIGN提出了一种自适应前缀对齐的知识蒸馏框架，通过截断教师模型生成的过长推理轨迹，让学生模型更有效地学习推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的推理轨迹通常过长且结构复杂，超出了学生模型的学习能力，导致监督信号与学习能力不匹配的问题。

Method: P-ALIGN通过自适应地截断教师生成的推理轨迹，判断剩余后缀是否简洁且足以指导学生模型，然后利用教师生成的前缀来监督学生模型，实现有效的前缀对齐。

Result: 在多个数学推理基准测试中，P-ALIGN比所有基线方法性能提升超过3%，构建的前缀提供了更有效的监督信号，避免了冗余和不确定推理组件的负面影响。

Conclusion: P-ALIGN框架通过自适应前缀对齐有效利用了教师模型的推理轨迹，解决了传统知识蒸馏中推理轨迹过长导致的学习效率问题。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities, particularly in solving complex mathematical problems. Recent studies show that distilling long reasoning trajectories can effectively enhance the reasoning performance of small-scale student models. However, teacher-generated reasoning trajectories are often excessively long and structurally complex, making them difficult for student models to learn. This mismatch leads to a gap between the provided supervision signal and the learning capacity of the student model. To address this challenge, we propose Prefix-ALIGNment distillation (P-ALIGN), a framework that fully exploits teacher CoTs for distillation through adaptive prefix alignment. Specifically, P-ALIGN adaptively truncates teacher-generated reasoning trajectories by determining whether the remaining suffix is concise and sufficient to guide the student model. Then, P-ALIGN leverages the teacher-generated prefix to supervise the student model, encouraging effective prefix alignment. Experiments on multiple mathematical reasoning benchmarks demonstrate that P-ALIGN outperforms all baselines by over 3%. Further analysis indicates that the prefixes constructed by P-ALIGN provide more effective supervision signals, while avoiding the negative impact of redundant and uncertain reasoning components. All code is available at https://github.com/NEUIR/P-ALIGN.

</details>


### [36] [Deriving Character Logic from Storyline as Codified Decision Trees](https://arxiv.org/abs/2601.10080)
*Letian Peng,Kun Zhou,Longfei Yun,Yupeng Hou,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出Codified Decision Trees (CDT)框架，从大规模叙事数据中学习可执行、可解释的行为决策树，显著提升角色扮演代理的行为一致性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演代理的行为配置文件大多是非结构化、不可执行且验证不足的，导致代理行为脆弱且不一致。需要一种能够从数据中学习、可执行且可验证的行为表示方法。

Method: 提出Codified Decision Trees (CDT)框架，将行为配置文件表示为条件规则树：内部节点对应经过验证的场景条件，叶子节点编码具体行为语句。通过迭代诱导候选场景-动作规则、数据验证和层次化细化来学习决策树。

Result: 在多个基准测试中，CDT在85个角色和16个任务上显著优于人工编写的配置文件和先前的配置文件诱导方法，表明编码化和验证的行为表示能带来更可靠的代理基础。

Conclusion: Codified Decision Trees提供了一种数据驱动的、可执行且可解释的行为配置文件学习方法，能够显著提升角色扮演代理的行为一致性和可靠性，为行为表示提供了透明检查和原则性更新的支持。

Abstract: Role-playing (RP) agents rely on behavioral profiles to act consistently across diverse narrative contexts, yet existing profiles are largely unstructured, non-executable, and weakly validated, leading to brittle agent behavior. We propose Codified Decision Trees (CDT), a data-driven framework that induces an executable and interpretable decision structure from large-scale narrative data. CDT represents behavioral profiles as a tree of conditional rules, where internal nodes correspond to validated scene conditions and leaves encode grounded behavioral statements, enabling deterministic retrieval of context-appropriate rules at execution time. The tree is learned by iteratively inducing candidate scene-action rules, validating them against data, and refining them through hierarchical specialization, yielding profiles that support transparent inspection and principled updates. Across multiple benchmarks, CDT substantially outperforms human-written profiles and prior profile induction methods on $85$ characters across $16$ artifacts, indicating that codified and validated behavioral representations lead to more reliable agent grounding.

</details>


### [37] [Is MT Ready for the Next Crisis or Pandemic?](https://arxiv.org/abs/2601.10082)
*Vipasha Bansal,Elizabeth Brown,Chelsea Kendrick,Benjamin Pong,William D. Lewis*

Main category: cs.CL

TL;DR: 评估四种商业机器翻译系统在危机/医疗领域对低资源语言的翻译效果，使用TICO-19数据集分析其应对下一次大流行的准备程度


<details>
  <summary>Details</summary>
Motivation: 危机时期沟通至关重要，但政府、援助提供者、医生与受助者之间存在语言不匹配问题。商业MT系统是常用工具，但需要评估其在低资源语言、特别是危机/医疗领域的有效性，为下一次大流行做好准备。

Method: 使用TICO-19数据集（包含大量高优先级语言的疫情相关句子），评估四种商业机器翻译系统的翻译质量，分析输出翻译的可用性。

Result: 通过评估四种商业MT系统在TICO-19数据集上的表现，分析了当前机器翻译系统在危机/医疗领域对低资源语言的翻译准备程度。

Conclusion: 需要评估商业MT系统在危机/医疗领域对低资源语言的翻译能力，为下一次大流行或疫情做好准备，确保有效沟通。

Abstract: Communication in times of crisis is essential. However, there is often a mismatch between the language of governments, aid providers, doctors, and those to whom they are providing aid. Commercial MT systems are reasonable tools to turn to in these scenarios. But how effective are these tools for translating to and from low resource languages, particularly in the crisis or medical domain? In this study, we evaluate four commercial MT systems using the TICO-19 dataset, which is composed of pandemic-related sentences from a large set of high priority languages spoken by communities most likely to be affected adversely in the next pandemic. We then assess the current degree of ``readiness'' for another pandemic (or epidemic) based on the usability of the output translations.

</details>


### [38] [CALM-IT: Generating Realistic Long-Form Motivational Interviewing Dialogues with Dual-Actor Conversational Dynamics Tracking](https://arxiv.org/abs/2601.10085)
*Viet Cuong Nguyen,Nhi Yen Nguyen,Kristin A. Candan,Mary Conlon,Vanessa Rumie,Kristen Risola,Srijan Kumar,Munmun De Choudhury*

Main category: cs.CL

TL;DR: CALM-IT框架通过建模双向状态空间过程，显著提升了长程动机访谈对话的质量和稳定性，在治疗效果和目标对齐方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在心理健康应用中存在局限性：虽然能生成流畅回应，但仅局部优化下一轮对话，缺乏对治疗进展的连贯建模，导致对话脆弱性和长程漂移问题。

Method: CALM-IT框架将治疗师-来访者互动建模为双向状态空间过程，双方持续更新推断的对齐程度、心理状态和短期目标，以此指导策略选择和话语生成。

Result: 在大规模评估中，CALM-IT在效果和目标对齐方面持续优于强基线，对话长度增加时保持更高稳定性，来访者接受率达到64.3%，表明干预时机更精确且治疗对齐更好。

Conclusion: CALM-IT证明建模演化的对话状态对于生成高质量长程合成对话至关重要，为心理健康应用中大语言模型的改进提供了有效框架。

Abstract: Large Language Models (LLMs) are increasingly used in mental health-related settings, yet they struggle to sustain realistic, goal-directed dialogue over extended interactions. While LLMs generate fluent responses, they optimize locally for the next turn rather than maintaining a coherent model of therapeutic progress, leading to brittleness and long-horizon drift. We introduce CALM-IT, a framework for generating and evaluating long-form Motivational Interviewing (MI) dialogues that explicitly models dual-actor conversational dynamics. CALM-IT represents therapist-client interaction as a bidirectional state-space process, in which both agents continuously update inferred alignment, mental states, and short-term goals to guide strategy selection and utterance generation. Across large-scale evaluations, CALM-IT consistently outperforms strong baselines in Effectiveness and Goal Alignment and remains substantially more stable as conversation length increases. Although CALM-IT initiates fewer therapist redirections, it achieves the highest client acceptance rate (64.3%), indicating more precise and therapeutically aligned intervention timing. Overall, CALM-IT provides evidence for modeling evolving conversational state being essential for generating high-quality long-form synthetic conversations.

</details>


### [39] [SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature](https://arxiv.org/abs/2601.10108)
*Yiming Ren,Junjie Wang,Yuxin Meng,Yihang Shi,Zhiqiang Lin,Ruihang Chu,Yiran Xu,Ziming Li,Yunfei Zhao,Zihan Wang,Yu Qiao,Ruiming Tang,Minghao Liu,Yujiu Yang*

Main category: cs.CL

TL;DR: 提出FITO范式评估多模态大语言模型对长科学论文的理解能力，要求模型在原生科学文档中构建显式的跨模态证据链，并通过SIN-Bench四个渐进任务进行测试。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如答案匹配和"大海捞针"测试）存在缺陷，它们奖励答案匹配但不需要模型在文档中提供因果、证据链接的推理轨迹，无法真正评估模型对长科学论文的理解能力。

Method: 1. 提出"Fish-in-the-Ocean"范式，要求模型在原生科学文档中构建显式跨模态证据链；2. 构建SIN-Data科学交错语料库，保留文本和图形的原生交错结构；3. 在此基础上构建SIN-Bench，包含四个渐进任务：证据发现、假设验证、基于证据的问答和证据锚定的摘要生成；4. 引入"No Evidence, No Score"评分机制，要求预测必须基于可验证的锚点，并通过匹配度、相关性和逻辑性诊断证据质量。

Result: 在8个多模态大语言模型上的实验表明：1. 基于证据的推理是主要瓶颈；2. Gemini-3-pro获得最佳平均总分（0.573）；3. GPT-5在SIN-QA答案准确率上最高（0.767），但在证据对齐的整体得分上表现不佳，暴露了答案正确性与可追溯支持之间的差距。

Conclusion: FITO范式能够有效评估多模态大语言模型对长科学论文的深度理解能力，揭示了当前模型在基于证据的推理方面的局限性，强调需要开发能够构建显式、可追溯证据链的模型。

Abstract: Evaluating whether multimodal large language models truly understand long-form scientific papers remains challenging: answer-only metrics and synthetic "Needle-In-A-Haystack" tests often reward answer matching without requiring a causal, evidence-linked reasoning trace in the document. We propose the "Fish-in-the-Ocean" (FITO) paradigm, which requires models to construct explicit cross-modal evidence chains within native scientific documents. To operationalize FITO, we build SIN-Data, a scientific interleaved corpus that preserves the native interleaving of text and figures. On top of it, we construct SIN-Bench with four progressive tasks covering evidence discovery (SIN-Find), hypothesis verification (SIN-Verify), grounded QA (SIN-QA), and evidence-anchored synthesis (SIN-Summary). We further introduce "No Evidence, No Score", scoring predictions when grounded to verifiable anchors and diagnosing evidence quality via matching, relevance, and logic. Experiments on eight MLLMs show that grounding is the primary bottleneck: Gemini-3-pro achieves the best average overall score (0.573), while GPT-5 attains the highest SIN-QA answer accuracy (0.767) but underperforms on evidence-aligned overall scores, exposing a gap between correctness and traceable support.

</details>


### [40] [Skill-Aware Data Selection and Fine-Tuning for Data-Efficient Reasoning Distillation](https://arxiv.org/abs/2601.10109)
*Lechen Zhang,Yunxiang Zhang,Wei Hu,Lu Wang*

Main category: cs.CL

TL;DR: 提出技能中心蒸馏框架，仅用1000个训练样本就能显著提升小模型在数学推理任务上的表现


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型蒸馏需要大规模监督微调数据，这促使研究者寻求数据高效的训练方法

Method: 技能中心蒸馏框架包含两个组件：1) 基于技能的数据选择，优先选择针对学生模型较弱技能的示例；2) 技能感知微调，鼓励在问题解决过程中进行显式的技能分解

Result: 仅从10万教师生成语料中选择1000个训练样本，该方法在Qwen3-4B上比随机SFT基线提升+1.6%，在Qwen3-8B上提升+1.4%，在五个数学推理基准上表现优异

Conclusion: 技能中心训练对于高效推理蒸馏是有效的，增益主要集中在训练过程中强调的技能上

Abstract: Large reasoning models such as DeepSeek-R1 and their distilled variants achieve strong performance on complex reasoning tasks. Yet, distilling these models often demands large-scale data for supervised fine-tuning (SFT), motivating the pursuit of data-efficient training methods. To address this, we propose a skill-centric distillation framework that efficiently transfers reasoning ability to weaker models with two components: (1) Skill-based data selection, which prioritizes examples targeting the student model's weaker skills, and (2) Skill-aware fine-tuning, which encourages explicit skill decomposition during problem solving. With only 1,000 training examples selected from a 100K teacher-generated corpus, our method surpasses random SFT baselines by +1.6% on Qwen3-4B and +1.4% on Qwen3-8B across five mathematical reasoning benchmarks. Further analysis confirms that these gains concentrate on skills emphasized during training, highlighting the effectiveness of skill-centric training for efficient reasoning distillation.

</details>


### [41] [Role-Playing Agents Driven by Large Language Models: Current Status, Challenges, and Future Trends](https://arxiv.org/abs/2601.10122)
*Ye Wang,Jiaxing Chen,Hongjiang Xiao*

Main category: cs.CL

TL;DR: 本文系统综述了角色扮演语言代理(RPLAs)的发展历程、关键技术、数据构建、评估方法及未来方向，为NLP与人机交互交叉领域的研究提供系统视角和方法论洞见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLMs)的快速发展，角色扮演语言代理(RPLAs)已成为自然语言处理与人机交互交叉领域的重要研究方向。本文旨在系统梳理该领域的发展现状和关键技术，为后续研究提供系统性视角和方法论指导。

Method: 采用系统性综述方法，分析RPLAs的技术演进历程（从早期规则模板到语言风格模仿，再到认知模拟阶段），总结关键技术路径（心理量表驱动的角色建模、记忆增强提示机制、动机情境行为决策控制），分析角色特定语料构建方法及挑战，整理多维评估框架和基准数据集。

Result: 系统梳理了RPLAs的技术发展脉络，总结了支持高质量角色扮演的关键技术路径，分析了数据构建的方法与挑战，整理了涵盖角色知识、个性保真度、价值对齐、交互幻觉等多维度的评估框架和基准数据集，并评述了人工评估、奖励模型、LLM评分等方法的优缺点。

Conclusion: 本文为角色扮演语言代理研究提供了系统性视角和方法论洞见，并展望了未来发展方向，包括个性演化建模、多智能体协同叙事、多模态沉浸交互以及与认知神经科学的融合，为后续研究指明了方向。

Abstract: In recent years, with the rapid advancement of large language models (LLMs), role-playing language agents (RPLAs) have emerged as a prominent research focus at the intersection of natural language processing (NLP) and human-computer interaction. This paper systematically reviews the current development and key technologies of RPLAs, delineating the technological evolution from early rule-based template paradigms, through the language style imitation stage, to the cognitive simulation stage centered on personality modeling and memory mechanisms. It summarizes the critical technical pathways supporting high-quality role-playing, including psychological scale-driven character modeling, memory-augmented prompting mechanisms, and motivation-situation-based behavioral decision control. At the data level, the paper further analyzes the methods and challenges of constructing role-specific corpora, focusing on data sources, copyright constraints, and structured annotation processes. In terms of evaluation, it collates multi-dimensional assessment frameworks and benchmark datasets covering role knowledge, personality fidelity, value alignment, and interactive hallucination, while commenting on the advantages and disadvantages of methods such as human evaluation, reward models, and LLM-based scoring. Finally, the paper outlines future development directions of role-playing agents, including personality evolution modeling, multi-agent collaborative narrative, multimodal immersive interaction, and integration with cognitive neuroscience, aiming to provide a systematic perspective and methodological insights for subsequent research.

</details>


### [42] [ToolSafe: Enhancing Tool Invocation Safety of LLM-based agents via Proactive Step-level Guardrail and Feedback](https://arxiv.org/abs/2601.10156)
*Yutao Mou,Zhangchi Xue,Lijun Li,Peiyang Liu,Shikun Zhang,Wei Ye,Jing Shao*

Main category: cs.CL

TL;DR: 开发了TS-Guard防护模型和TS-Flow框架，用于实时检测和干预LLM代理的工具调用安全风险，在提示注入攻击下将有害调用减少65%，良性任务完成率提升10%。


<details>
  <summary>Details</summary>
Motivation: LLM代理通过外部工具调用扩展能力的同时也放大了安全风险，需要实时监控工具调用行为并在不安全执行前主动干预，但这一领域研究不足。

Method: 1) 构建TS-Bench基准测试用于工具调用安全检测；2) 使用多任务强化学习开发TS-Guard防护模型，通过推理交互历史主动检测不安全调用；3) 提出TS-Flow防护反馈驱动推理框架。

Result: TS-Flow框架将ReAct风格代理的有害工具调用平均减少65%，在提示注入攻击下将良性任务完成率提升约10%。

Conclusion: 该研究为LLM代理的工具调用安全提供了有效的实时监控和干预解决方案，通过主动检测和反馈机制显著提升了代理的安全性。

Abstract: While LLM-based agents can interact with environments via invoking external tools, their expanded capabilities also amplify security risks. Monitoring step-level tool invocation behaviors in real time and proactively intervening before unsafe execution is critical for agent deployment, yet remains under-explored. In this work, we first construct TS-Bench, a novel benchmark for step-level tool invocation safety detection in LLM agents. We then develop a guardrail model, TS-Guard, using multi-task reinforcement learning. The model proactively detects unsafe tool invocation actions before execution by reasoning over the interaction history. It assesses request harmfulness and action-attack correlations, producing interpretable and generalizable safety judgments and feedback. Furthermore, we introduce TS-Flow, a guardrail-feedback-driven reasoning framework for LLM agents, which reduces harmful tool invocations of ReAct-style agents by 65 percent on average and improves benign task completion by approximately 10 percent under prompt injection attacks.

</details>


### [43] [What Gets Activated: Uncovering Domain and Driver Experts in MoE Language Models](https://arxiv.org/abs/2601.10159)
*Guimin Hu,Meng Li,Qiwei Peng,Lijie Hu,Boyan Xu,Ruichu Cai*

Main category: cs.CL

TL;DR: 该研究分析了MoE（混合专家）模型中专家激活模式，区分了领域专家和驱动专家，发现特定专家对特定领域有偏好，某些专家对模型性能有强因果影响，调整这些专家权重可提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性研究主要关注Transformer的层或神经元级机制，而MoE LLMs中的专家级行为研究不足。受人类大脑功能专门化的启发，作者希望探索MoE模型中专家激活模式，了解哪些专家被激活、如何被激活，以及它们对模型输出的影响。

Method: 引入基于熵的指标和因果效应指标来识别领域专家和驱动专家：1）基于熵的指标评估专家是否对特定领域有强烈偏好；2）因果效应指标评估专家激活对模型输出的因果贡献程度。同时探索单个token如何与特定专家激活相关联。

Result: 1）激活的专家中，部分显示明确的领域偏好（领域专家），部分对模型性能有强因果影响（驱动专家）；2）句子中较早出现的token更可能触发驱动专家；3）调整领域专家和驱动专家的权重可在所有三个模型和领域中获得显著性能提升。

Conclusion: 该研究揭示了MoE模型的内部机制，增强了其可解释性，表明专家在MoE模型中扮演着专门化和决定性角色，调整关键专家权重可有效提升模型性能。

Abstract: Most interpretability work focuses on layer- or neuron-level mechanisms in Transformers, leaving expert-level behavior in MoE LLMs underexplored. Motivated by functional specialization in the human brain, we analyze expert activation by distinguishing domain and driver experts. In this work, we study expert activation in MoE models across three public domains and address two key questions: (1) which experts are activated, and whether certain expert types exhibit consistent activation patterns; and (2) how tokens are associated with and trigger the activation of specific experts. To answer these questions, we introduce entropy-based and causal-effect metrics to assess whether an expert is strongly favored for a particular domain, and how strongly expert activation contributes causally to the model's output, thus identify domain and driver experts, respectively. Furthermore, we explore how individual tokens are associated with the activation of specific experts. Our analysis reveals that (1) Among the activated experts, some show clear domain preferences, while others exert strong causal influence on model performance, underscoring their decisive roles. (2) tokens occurring earlier in a sentence are more likely to trigger the driver experts, and (3) adjusting the weights of domain and driver experts leads to significant performance gains across all three models and domains. These findings shed light on the internal mechanisms of MoE models and enhance their interpretability.

</details>


### [44] [Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment](https://arxiv.org/abs/2601.10160)
*Cameron Tice,Puria Radmard,Samuel Ratnam,Andy Kim,David Africa,Kyle O'Brien*

Main category: cs.CL

TL;DR: 研究发现预训练数据中关于AI系统的讨论会影响大语言模型的对齐行为：增加AI不对齐的讨论会加剧模型不对齐行为，增加对齐讨论则能显著改善对齐表现


<details>
  <summary>Details</summary>
Motivation: 预训练语料包含大量关于AI系统的讨论，但这些讨论对下游对齐任务的因果影响尚不清楚。如果主流AI行为描述是负面的，大语言模型可能内化相应的行为先验，导致自我实现的不对齐

Method: 通过预训练6.9B参数的大语言模型，控制不同数量的（不）对齐讨论语料。上采样合成训练文档中关于AI不对齐的内容，同时对比上采样对齐行为文档的效果

Result: AI讨论确实会导致不对齐：上采样不对齐文档显著增加不对齐行为；上采样对齐文档则将不对齐分数从45%降至9%。这些影响在后续训练中有所减弱但仍持续存在

Conclusion: 研究确立了"对齐预训练"作为后训练补充的重要性，建议从业者不仅要为能力预训练，也要为对齐预训练。预训练数据塑造对齐先验的研究成为新方向

Abstract: Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behaviour. Conversely, upsampling documents about aligned behaviour reduces misalignment scores from 45% to 9%. We consider this evidence of self-fulfilling alignment. These effects are dampened, but persist through post-training. Our findings establish the study of how pretraining data shapes alignment priors, or alignment pretraining, as a complement to post-training. We recommend practitioners pretrain for alignment as well as capabilities. Our models and datasets are available at alignmentpretraining.ai

</details>


### [45] [AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers](https://arxiv.org/abs/2601.10161)
*Prachuryya Kaushik,Ashish Anand*

Main category: cs.CL

TL;DR: AWED-FiNER是一个开源生态系统，为36种全球语言提供细粒度命名实体识别解决方案，覆盖超过66亿人口，特别关注弱势语言。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低资源语言和细粒度NLP任务上表现不佳，需要为全球多种语言提供专门的细粒度命名实体识别解决方案。

Method: 提供代理工具包、Web应用程序和49个专家模型组成的生态系统。代理工具将多语言文本路由到专门的专家模型获取标注；Web平台为非技术用户提供即用服务；小型专家模型支持资源受限环境离线部署。

Result: 建立了覆盖36种语言（包括Bodo、Manipuri、Bishnupriya、Mizo等弱势语言）的细粒度命名实体识别生态系统，支持秒级标注和边缘设备部署。

Conclusion: AWED-FiNER填补了细粒度命名实体识别在多语言特别是低资源语言领域的空白，为超过66亿人口提供可访问的NLP解决方案。

Abstract: We introduce AWED-FiNER, an open-source ecosystem designed to bridge the gap in Fine-grained Named Entity Recognition (FgNER) for 36 global languages spoken by more than 6.6 billion people. While Large Language Models (LLMs) dominate general Natural Language Processing (NLP) tasks, they often struggle with low-resource languages and fine-grained NLP tasks. AWED-FiNER provides a collection of agentic toolkits, web applications, and several state-of-the-art expert models that provides FgNER solutions across 36 languages. The agentic tools enable to route multilingual text to specialized expert models and fetch FgNER annotations within seconds. The web-based platforms provide ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language specific extremely small sized open-source state-of-the-art expert models facilitate offline deployment in resource contraint scenerios including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, including a specific focus on vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo. The resources can be accessed here: Agentic Tool (https://github.com/PrachuryyaKaushik/AWED-FiNER), Web Application (https://hf.co/spaces/prachuryyaIITG/AWED-FiNER), and 49 Expert Detector Models (https://hf.co/collections/prachuryyaIITG/awed-finer).

</details>


### [46] [Credit C-GPT: A Domain-Specialized Large Language Model for Conversational Understanding in Vietnamese Debt Collection](https://arxiv.org/abs/2601.10167)
*Nhung Nguyen Thi Hong,Cuong Nguyen Dang,Tri Le Ngoc*

Main category: cs.CL

TL;DR: Credit C-GPT：一个专门针对越南债务催收场景的70亿参数领域专用大语言模型，在对话理解、情感识别、意图检测等多任务上表现优于传统流水线方法


<details>
  <summary>Details</summary>
Motivation: BFSI领域的债务催收严重依赖大规模人工对话，这些对话使用非正式越南口语，包含情感变化和复杂领域推理，传统NLP系统难以处理

Method: 开发了70亿参数的领域专用大语言模型Credit C-GPT，采用单一推理框架集成对话理解、情感识别、意图检测、通话阶段分类和结构化槽值提取等多任务

Result: 在专有的人工标注数据集上评估，相比传统流水线方法取得了一致的改进效果

Conclusion: 领域专用对话语言模型为企业联络中心的实时协助和通话后分析提供了可扩展且注重隐私的解决方案

Abstract: Debt collection is a critical function within the banking, financial services, and insurance (BFSI) sector, relying heavily on large-scale human-to-human conversational interactions conducted primarily in Vietnamese contact centers. These conversations involve informal spoken language, emotional variability, and complex domain-specific reasoning, which pose significant challenges for traditional natural language processing systems. This paper introduces Credit C-GPT, a domain-specialized large language model with seven billion parameters, fine-tuned for conversational understanding in Vietnamese debt collection scenarios. The proposed model integrates multiple conversational intelligence tasks, including dialogue understanding, sentiment recognition, intent detection, call stage classification, and structured slot-value extraction, within a single reasoning-based framework. We describe the data construction process, annotation strategy, and training methodology, and evaluate the model on proprietary human-annotated datasets. Experimental results show consistent improvements over traditional pipeline-based approaches, indicating that domain-specialized conversational language models provide a scalable and privacy-aware solution for real-time assistance and post-call analytics in enterprise contact centers.

</details>


### [47] [HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning](https://arxiv.org/abs/2601.10187)
*Ziang Cui,Mengran Yu,Tianjiao Li,Chenyu Shi,Yingxuan Shi,Lusheng Zhang,Hongwei Lin*

Main category: cs.CL

TL;DR: 提出HOMURA框架，通过强化学习解决LLM翻译中的跨语言冗长偏差问题，实现音节级时长约束下的翻译优化


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言翻译中表现出色，但存在系统性跨语言冗长偏差，不适合字幕、配音等严格时间约束任务。现有提示工程方法难以平衡语义保真度和时间可行性

Method: 1) 引入Sand-Glass基准，专门评估音节级时长约束下的翻译质量；2) 提出HOMURA强化学习框架，使用KL正则化目标和新型动态音节比例奖励，明确优化语义保留与时间合规性之间的权衡

Result: 实验结果表明，该方法显著优于强大的LLM基线，实现了精确的长度控制，在尊重语言密度层次的同时不损害语义充分性

Conclusion: HOMURA框架有效"驯服"了LLM的输出长度，解决了翻译中的跨语言冗长偏差问题，为时间敏感型翻译任务提供了实用解决方案

Abstract: Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively "tames" the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy.

</details>


### [48] [HUMANLLM: Benchmarking and Reinforcing LLM Anthropomorphism via Human Cognitive Patterns](https://arxiv.org/abs/2601.10198)
*Xintao Wang,Jian Yang,Weiyuan Li,Rui Xie,Jen-tse Huang,Jun Gao,Shuai Huang,Yueping Kang,Liyuan Gou,Hongwei Feng,Yanghua Xiao*

Main category: cs.CL

TL;DR: HUMANLLM框架将心理模式视为相互作用的因果力，通过构建244个心理模式并合成11,359个多模式交互场景，实现了更真实的人类认知和行为对齐，在8B参数下超越了32B模型的多模式动态模拟能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理和生成方面表现出色，但现有角色扮演语言代理在真实对齐人类认知和行为模式方面仍面临关键挑战。需要模拟心理过程而不仅仅是行为本身。

Method: 从约12,000篇学术论文中构建244个心理模式，合成11,359个场景，其中2-5个模式相互增强、冲突或调节。创建表达内心想法、行动和对话的多轮对话。采用双层检查表评估个体模式保真度和涌现的多模式动态。

Result: HUMANLLM实现了强人类对齐（r=0.91），发现整体指标混淆了模拟准确性和社会期望性。HUMANLLM-8B在参数少4倍的情况下，在多模式动态方面超越了Qwen3-32B。

Conclusion: 真实的人类拟人化需要认知建模——不仅要模拟人类做什么，还要模拟产生这些行为的心理过程。心理模式作为相互作用因果力的框架是实现这一目标的有效方法。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning and generation, serving as the foundation for advanced persona simulation and Role-Playing Language Agents (RPLAs). However, achieving authentic alignment with human cognitive and behavioral patterns remains a critical challenge for these agents. We present HUMANLLM, a framework treating psychological patterns as interacting causal forces. We construct 244 patterns from ~12,000 academic papers and synthesize 11,359 scenarios where 2-5 patterns reinforce, conflict, or modulate each other, with multi-turn conversations expressing inner thoughts, actions, and dialogue. Our dual-level checklists evaluate both individual pattern fidelity and emergent multi-pattern dynamics, achieving strong human alignment (r=0.91) while revealing that holistic metrics conflate simulation accuracy with social desirability. HUMANLLM-8B outperforms Qwen3-32B on multi-pattern dynamics despite 4x fewer parameters, demonstrating that authentic anthropomorphism requires cognitive modeling--simulating not just what humans do, but the psychological processes generating those behaviors.

</details>


### [49] [One Instruction Does Not Fit All: How Well Do Embeddings Align Personas and Instructions in Low-Resource Indian Languages?](https://arxiv.org/abs/2601.10205)
*Arya Shah,Himanshu beniwal,Mayank Singh*

Main category: cs.CL

TL;DR: 本文提出了一个针对12种印度语言的统一基准测试，用于评估多语言嵌入模型在人物描述与指令兼容性任务上的表现，包括单语/跨语言检索、反向检索和二元分类四个任务。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试要么只关注单一语言，要么将检索与生成任务混为一谈，无法评估嵌入模型是否能在不依赖响应合成的情况下编码人物描述与指令的兼容性。为了服务印度超过10亿的多语言使用者，需要建立能够评估多语言助手文化适应性的基准。

Method: 创建了一个涵盖12种印度语言的统一基准测试，包含四个评估任务：单语人物描述到指令检索、跨语言检索、指令到人物描述的反向检索、以及二元兼容性分类。在冻结编码器设置下评估了8个多语言嵌入模型，仅使用逻辑回归头进行分类。

Result: E5-Large-Instruct在单语检索中达到27.4%的Recall@1，在跨语言迁移中达到20.7%；BGE-M3在反向检索中达到32.1%的Recall@1；LaBSE在分类任务中达到75.3%的AUROC并具有强校准性。

Conclusion: 该研究为印度多语言检索任务中的模型选择提供了实用指导，并为未来工作建立了可复现的基线。结果表明当前嵌入模型能够在一定程度上编码人物描述与指令的兼容性，无需依赖响应合成。

Abstract: Aligning multilingual assistants with culturally grounded user preferences is essential for serving India's linguistically diverse population of over one billion speakers across multiple scripts. However, existing benchmarks either focus on a single language or conflate retrieval with generation, leaving open the question of whether current embedding models can encode persona-instruction compatibility without relying on response synthesis. We present a unified benchmark spanning 12 Indian languages and four evaluation tasks: monolingual and cross-lingual persona-to-instruction retrieval, reverse retrieval from instruction to persona, and binary compatibility classification. Eight multilingual embedding models are evaluated in a frozen-encoder setting with a thin logistic regression head for classification. E5-Large-Instruct achieves the highest Recall@1 of 27.4\% on monolingual retrieval and 20.7\% on cross-lingual transfer, while BGE-M3 leads reverse retrieval at 32.1\% Recall@1. For classification, LaBSE attains 75.3\% AUROC with strong calibration. These findings offer practical guidance for model selection in Indic multilingual retrieval and establish reproducible baselines for future work\footnote{Code, datasets, and models are publicly available at https://github.com/aryashah2k/PI-Indic-Align.

</details>


### [50] [GeoSteer: Faithful Chain-of-Thought Steering via Latent Manifold Gradients](https://arxiv.org/abs/2601.10229)
*Kentaro Kazama,Daiki Shirafuji,Tatsuhiko Saito*

Main category: cs.CL

TL;DR: GeoSteer是一个基于流形的框架，通过隐空间中的自然梯度调整来提升LLM中间推理步骤的质量，在GSM8k数据集上实现了最高2.6个百分点的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多步推理方面有进步，但即使最终答案正确，它们经常生成逻辑不一致的推理步骤，这降低了步骤级推理的可靠性。

Method: 构建带分段评分的CoT数据集，训练VAE和质量估计模型学习高质量CoT轨迹的低维流形，然后在隐空间中引导目标LLM的隐藏状态向更高质量区域移动，实现类似自然梯度调整的几何一致引导。

Result: 在GSM8k数据集上使用Qwen3系列评估，GeoSteer将精确匹配准确率提升了最高2.6个百分点，成对胜率提升了5.3个百分点。

Conclusion: GeoSteer为提升LLM中间推理质量提供了一个有效且可控的机制，通过流形学习和隐空间引导实现了推理步骤的几何一致性改进。

Abstract: Recent advances in Large Language Models (LLMs) have improved multi-step reasoning. Most approaches rely on Chain-of-Thought (CoT) rationales. Previous studies have shown that LLMs often generate logically inconsistent reasoning steps even when their final answers are correct. These inconsistencies reduce the reliability of step-level reasoning. We propose GeoSteer, a manifold-based framework that improves the quality of intermediate reasoning. The method consists of: (1) constructing a CoT dataset with segment-level scores, (2) training a Variational Autoencoder (VAE) model and a quality estimation model to learn a low-dimensional manifold of high-quality CoT trajectories, and (3) steering hidden states of target LLMs toward higher-quality regions in the latent space. This update in a latent space behaves like a natural-gradient adjustment in the original hidden-state space. It ensures geometrically coherent steering. We evaluate GeoSteer on the GSM8k dataset using the Qwen3 series. We measure via answer accuracy and overall reasoning performance. GeoSteer improved the exact match accuracy by up to 2.6 points. It also enhanced the pairwise win rate by 5.3 points. These results indicate that GeoSteer provides an effective and controllable mechanism for improving the quality of intermediate reasoning in LLMs.

</details>


### [51] [Loop as a Bridge: Can Looped Transformers Truly Link Representation Space and Natural Language Outputs?](https://arxiv.org/abs/2601.10242)
*Guanxu Chen,Dongrui Liu,Jing Shao*

Main category: cs.CL

TL;DR: 研究发现循环Transformer通过增加循环迭代可以缩小内部知识与语言输出的差距，但部分原因是表征质量下降，且当前架构无法实现真正的内省


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在内部知识与显式语言输出之间的差距，研究探索循环Transformer能否通过其迭代特性作为内省机制来弥合这一差距

Method: 通过实验研究循环Transformer架构，分析增加循环迭代次数对内部知识与语言输出差距的影响，并评估模型对表征的感知能力

Result: 增加循环迭代确实能缩小差距，但部分原因是表征携带的内部知识质量下降；当前循环Transformer仅在最后循环中能感知表征，跨循环感知能力未改善

Conclusion: 循环Transformer为扩展计算深度提供了有前景的方向，但尚未实现真正连接表征空间与自然语言所需的内省能力

Abstract: Large Language Models (LLMs) often exhibit a gap between their internal knowledge and their explicit linguistic outputs. In this report, we empirically investigate whether Looped Transformers (LTs)--architectures that increase computational depth by iterating shared layers--can bridge this gap by utilizing their iterative nature as a form of introspection. Our experiments reveal that while increasing loop iterations narrows the gap, it is partly driven by a degradation of their internal knowledge carried by representations. Moreover, another empirical analysis suggests that current LTs' ability to perceive representations does not improve across loops; it is only present in the final loop. These results suggest that while LTs offer a promising direction for scaling computational depth, they have yet to achieve the introspection required to truly link representation space and natural language.

</details>


### [52] [coTherapist: A Behavior-Aligned Small Language Model to Support Mental Healthcare Experts](https://arxiv.org/abs/2601.10246)
*Prottay Kumar Adhikary,Reena Rawat,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: coTherapist是一个基于小型语言模型的统一框架，通过领域特定微调、检索增强和智能推理来模拟核心治疗能力，为心理健康专家提供支持。


<details>
  <summary>Details</summary>
Motivation: 心理健康服务面临劳动力短缺和需求增长的双重压力，需要开发智能系统来支持心理健康专家的工作。

Method: 采用小型语言模型，通过领域特定微调、检索增强和智能推理构建统一框架，模拟治疗师的核心能力。

Result: 在临床查询评估中，coTherapist比现有基线生成更相关且临床基础更强的回答；通过T-BARS评估和心理测量分析，显示其具有高共情和治疗师一致的人格特质；专家评估确认其回答准确、可信且安全。

Conclusion: 小型模型可以通过工程化设计展现专家级行为，为数字心理健康工具提供了可扩展的途径。

Abstract: Access to mental healthcare is increasingly strained by workforce shortages and rising demand, motivating the development of intelligent systems that can support mental healthcare experts. We introduce coTherapist, a unified framework utilizing a small language model to emulate core therapeutic competencies through domain-specific fine-tuning, retrieval augmentation, and agentic reasoning. Evaluation on clinical queries demonstrates that coTherapist generates more relevant and clinically grounded responses than contemporary baselines. Using our novel T-BARS rubric and psychometric profiling, we confirm coTherapist exhibits high empathy and therapist-consistent personality traits. Furthermore, human evaluation by domain experts validates that coTherapist delivers accurate, trustworthy, and safe responses. coTherapist was deployed and tested by clinical experts. Collectively, these findings demonstrate that small models can be engineered to exhibit expert-like behavior, offering a scalable pathway for digital mental health tools.

</details>


### [53] [Untangling Input Language from Reasoning Language: A Diagnostic Framework for Cross-Lingual Moral Alignment in LLMs](https://arxiv.org/abs/2601.10257)
*Nan Li,Bo Kang,Tijl De Bie*

Main category: cs.CL

TL;DR: 研究LLMs在不同语言中判断道德困境时结论差异的原因，分离输入语言和推理语言的影响，提出诊断框架并应用于中英文道德判断分析


<details>
  <summary>Details</summary>
Motivation: 当LLMs判断道德困境时，不同语言是否会导致不同结论？现有评估方法将输入语言和推理语言混为一谈，无法区分两者的独立影响，需要开发新的分解方法

Method: 提出分离输入语言和推理语言影响的方法论，覆盖匹配和不匹配条件（如英文困境+中文推理），使用道德基础理论解释道德判断，并将权威维度细分为家庭相关和制度维度

Result: 应用于13个LLMs的中英文道德判断：1)推理语言效应贡献的方差是输入语言效应的两倍；2)检测到近一半模型存在标准评估遗漏的上下文依赖性；3)诊断分类法将这些模式转化为部署指导

Conclusion: 提出的方法论具有诊断能力，能够分离语言效应，揭示LLMs道德判断中的语言依赖性，为跨文化部署提供指导，并发布了代码和数据集

Abstract: When LLMs judge moral dilemmas, do they reach different conclusions in different languages, and if so, why? Two factors could drive such differences: the language of the dilemma itself, or the language in which the model reasons. Standard evaluation conflates these by testing only matched conditions (e.g., English dilemma with English reasoning). We introduce a methodology that separately manipulates each factor, covering also mismatched conditions (e.g., English dilemma with Chinese reasoning), enabling decomposition of their contributions. To study \emph{what} changes, we propose an approach to interpret the moral judgments in terms of Moral Foundations Theory. As a side result, we identify evidence for splitting the Authority dimension into a family-related and an institutional dimension. Applying this methodology to English-Chinese moral judgment with 13 LLMs, we demonstrate its diagnostic power: (1) the framework isolates reasoning-language effects as contributing twice the variance of input-language effects; (2) it detects context-dependency in nearly half of models that standard evaluation misses; and (3) a diagnostic taxonomy translates these patterns into deployment guidance. We release our code and datasets at https://anonymous.4open.science/r/CrossCulturalMoralJudgement.

</details>


### [54] [Measuring Affinity between Attention-Head Weight Subspaces via the Projection Kernel](https://arxiv.org/abs/2601.10266)
*Hiroaki Yamagiwa,Yusuke Takase,Hidetoshi Shimodaira*

Main category: cs.CL

TL;DR: 提出基于投影核（PK）的注意力头相似性度量方法，比现有指标更清晰地捕捉Transformer内部结构，并展示其在GPT2-small模型分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有指标无法很好地捕捉Transformer中注意力头之间的关系结构，需要更有效的度量方法来理解Transformer的内部工作机制。

Method: 使用投影核（PK）——基于主夹角的子空间相似性度量，量化注意力头权重矩阵张成的子空间之间的相似性。引入框架通过比较随机正交子空间的参考分布来评估PK分布的信息量。

Result: PK在IOI任务上比组合分数等现有指标更清晰地再现已知的头对头交互。在GPT2-small中，通过PK构建的有向图显示L4H7作为身份头起到枢纽作用。

Conclusion: 投影核（PK）是量化Transformer中注意力头关系的有效指标，能够揭示模型内部的结构模式，为Transformer可解释性提供了新的分析工具。

Abstract: Understanding relationships between attention heads is essential for interpreting the internal structure of Transformers, yet existing metrics do not capture this structure well. We focus on the subspaces spanned by attention-head weight matrices and quantify head-to-head relationships using the Projection Kernel (PK), a principal-angle-based measure of subspace similarity. Experiments show that PK reproduces known head-to-head interactions on the IOI task more clearly than prior metrics such as the Composition Score. We further introduce a framework to quantify the informativeness of PK distributions by comparing them with a reference distribution derived from random orthogonal subspaces. As an application, we analyze a directed graph constructed from PK and show that, in GPT2-small, L4H7 acts as a hub by functioning as an identity head.

</details>


### [55] [MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts](https://arxiv.org/abs/2601.10272)
*Yuxuan Lou,Kai Yang,Yang You*

Main category: cs.CL

TL;DR: MoST是一个基于专家混合架构的多模态大语言模型，通过模态感知专家混合架构无缝集成语音和文本处理，使用开源数据集实现高效训练，在多个语音-文本任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型通常使用相同参数处理不同模态表示，忽视了模态间的固有差异。需要一种能够同时增强模态特定学习和跨模态理解的架构。

Method: 提出模态感知专家混合架构，包含模态特定专家组和共享专家；开发高效训练流程：在ASR/TTS数据集上进行后训练，然后在语音-文本指令数据集上微调。

Result: 在ASR、TTS、音频语言建模和口语问答等基准测试中，MoST在同等参数规模下持续优于现有模型；消融研究证实模态特定路由和共享专家设计对性能提升有显著贡献。

Conclusion: MoST是首个基于专家混合架构的完全开源语音-文本大语言模型，通过模态感知路由机制实现了模态特定学习和跨模态理解的平衡，为多模态AI研究提供了新方向。

Abstract: We present MoST (Mixture of Speech and Text), a novel multimodal large language model that seamlessly integrates speech and text processing through our proposed Modality-Aware Mixture of Experts (MAMoE) architecture. While current multimodal models typically process diverse modality representations with identical parameters, disregarding their inherent representational differences, we introduce specialized routing pathways that direct tokens to modality-appropriate experts based on input type. MAMoE simultaneously enhances modality-specific learning and cross-modal understanding through two complementary components: modality-specific expert groups that capture domain-specific patterns and shared experts that facilitate information transfer between modalities. Building on this architecture, we develop an efficient transformation pipeline that adapts the pretrained MoE language model through strategic post-training on ASR and TTS datasets, followed by fine-tuning with a carefully curated speech-text instruction dataset. A key feature of this pipeline is that it relies exclusively on fully accessible, open-source datasets to achieve strong performance and data efficiency. Comprehensive evaluations across ASR, TTS, audio language modeling, and spoken question answering benchmarks show that MoST consistently outperforms existing models of comparable parameter counts. Our ablation studies confirm that the modality-specific routing mechanism and shared experts design significantly contribute to performance gains across all tested domains. To our knowledge, MoST represents the first fully open-source speech-text LLM built on a Mixture of Experts architecture. \footnote{We release MoST model, training code, inference code, and training data at https://github.com/NUS-HPC-AI-Lab/MoST

</details>


### [56] [The Straight and Narrow: Do LLMs Possess an Internal Moral Path?](https://arxiv.org/abs/2601.10307)
*Luoming Hu,Jingjie Zeng,Liang Yang,Hongfei Lin*

Main category: cs.CL

TL;DR: 该论文提出基于道德基础理论（MFT）的AMF方法，通过提取可操控的道德向量和自适应融合，在保持安全性的同时减少错误拒绝，解决LLM安全性与帮助性的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的对齐技术往往只是表面护栏，未能真正改变模型内在的道德表征。需要开发能够深入影响LLM内在道德表征的方法，以解决安全性与帮助性之间的权衡问题。

Method: 1. 使用道德基础理论（MFT）映射LLM的道德表征；2. 通过跨语言线性探测验证道德表征的共享性；3. 提取可操控的道德向量；4. 提出自适应道德融合（AMF），在推理时动态结合探测检测和向量注入。

Result: 方法在内在和行为层面均验证有效：1. 减少良性查询的错误拒绝；2. 相比标准基线最小化越狱成功率；3. 作为有针对性的内在防御机制发挥作用。

Conclusion: 基于道德基础理论的方法能够深入影响LLM的内在道德表征，通过自适应道德融合有效解决安全性与帮助性的权衡，为LLM道德对齐提供了新途径。

Abstract: Enhancing the moral alignment of Large Language Models (LLMs) is a critical challenge in AI safety. Current alignment techniques often act as superficial guardrails, leaving the intrinsic moral representations of LLMs largely untouched. In this paper, we bridge this gap by leveraging Moral Foundations Theory (MFT) to map and manipulate the fine-grained moral landscape of LLMs. Through cross-lingual linear probing, we validate the shared nature of moral representations in middle layers and uncover a shared yet different moral subspace between English and Chinese. Building upon this, we extract steerable Moral Vectors and successfully validate their efficacy at both internal and behavioral levels. Leveraging the high generalizability of morality, we propose Adaptive Moral Fusion (AMF), a dynamic inference-time intervention that synergizes probe detection with vector injection to tackle the safety-helpfulness trade-off. Empirical results confirm that our approach acts as a targeted intrinsic defense, effectively reducing incorrect refusals on benign queries while minimizing jailbreak success rates compared to standard baselines.

</details>


### [57] [Multilinguality as Sense Adaptation](https://arxiv.org/abs/2601.10310)
*Jan Christian Blaise Cruz,David Ifeoluwa Adelani,Alham Fikri Aji*

Main category: cs.CL

TL;DR: SENSIA通过跨语言对齐语义表示而非共享参数，在四种语言上超越同类方法，用2-4倍少的数据达到与从头训练单语模型相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统多语言方法依赖共享参数和大规模数据，本文提出将多语言性视为语义适应问题，通过跨语言对齐潜在语义表示来提升多语言模型的效率和效果。

Method: 提出SENSIA方法：在平行数据上显式对齐语义级混合表示和上下文表示，同时联合训练目标语言的语言建模损失以保持流畅性，基于Backpack语言模型进行跨语言适应。

Result: 在四种类型学多样语言上的实验表明，SENSIA通常优于可比的多语言对齐方法，使用2-4倍少的目标语言数据即可达到与从头训练的单语基线相当的准确率。

Conclusion: SENSIA通过语义对齐而非参数共享实现了有效的跨语言适应，学习的语义几何结构保持良好，方法在设计和规模上具有鲁棒性，为多语言建模提供了新思路。

Abstract: We approach multilinguality as sense adaptation: aligning latent meaning representations across languages rather than relying solely on shared parameters and scale. In this paper, we introduce SENse-based Symmetric Interlingual Alignment (SENSIA), which adapts a Backpack language model from one language to another by explicitly aligning sense-level mixtures and contextual representations on parallel data, while jointly training a target-language language modeling loss to preserve fluency. Across benchmarks on four typologically diverse languages, SENSIA generally outperforms comparable multilingual alignment methods and achieves competitive accuracy against monolingual from-scratch baselines while using 2-4x less target-language data. Analyses of learned sense geometry indicate that local sense topology and global structure relative to English are largely preserved, and ablations show that the method is robust in terms of design and scale.

</details>


### [58] [ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in Courtroom Scenarios](https://arxiv.org/abs/2601.10315)
*Aniket Deroy*

Main category: cs.CL

TL;DR: 论文提出了Advosynth-500数据集，包含100个合成语音文件，模拟10个不同辩护律师身份在法庭辩论场景下的对话，用于评估现代系统识别合成语音来源的能力。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语音合成模型实现高保真度，合成语音在结构化环境中的区分变得至关重要。需要专门的数据集来研究合成语音的身份识别问题。

Method: 使用Speech Llama Omni模型生成合成语音，模拟5对不同辩护律师组合的法庭辩论。为每个辩护律师定义特定的声学特征，创建包含10个独特身份的100个语音文件数据集。

Result: 建立了Advosynth-500数据集，包含100个合成语音文件和10个独特的辩护律师身份。数据集可用于评估系统将音频文件映射到其合成来源的能力。

Conclusion: 该数据集为研究合成语音的身份识别提供了专门资源，有助于评估现代系统在结构化环境中区分不同合成语音身份的能力。

Abstract: As large-scale speech-to-speech models achieve high fidelity, the distinction between synthetic voices in structured environments becomes a vital area of study. This paper introduces Advosynth-500, a specialized dataset comprising 100 synthetic speech files featuring 10 unique advocate identities. Using the Speech Llama Omni model, we simulate five distinct advocate pairs engaged in courtroom arguments. We define specific vocal characteristics for each advocate and present a speaker identification challenge to evaluate the ability of modern systems to map audio files to their respective synthetic origins.
  Dataset is available at this link-https: //github.com/naturenurtureelite/ADVOSYNTH-500.

</details>


### [59] [Boundary-Aware NL2SQL: Integrating Reliability through Hybrid Reward and Data Synthesis](https://arxiv.org/abs/2601.10318)
*Songsong Tian,Kongsheng Zhuo,Zhendong Wang,Rong Shen,Shengtao Zhang,Yong Wu*

Main category: cs.CL

TL;DR: BAR-SQL是一个将可靠性和边界感知嵌入NL2SQL生成过程的统一训练框架，通过种子变异数据合成和知识基础推理合成构建企业语料，采用两阶段训练和任务条件混合奖励机制，在SQL生成质量和边界感知弃权能力上超越主流专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前NL2SQL系统在生成SQL查询时缺乏对边界情况（如歧义和模式限制）的可靠处理能力，需要一种能够同时优化SQL执行准确性和语义精确度的框架，特别是在企业环境中处理复杂分析查询时。

Method: 1. 种子变异数据合成范式构建包含多步分析查询和边界情况的企业语料库；2. 知识基础推理合成生成基于模式元数据和业务规则的思维链轨迹；3. 两阶段训练：监督微调后接基于组相对策略优化的强化学习；4. 任务条件混合奖励机制同时优化SQL执行准确性和语义精确度。

Result: 在Ent-SQL-Bench基准测试中，BAR-SQL达到91.48%的平均准确率，在SQL生成质量和边界感知弃权能力上超越了Claude 4.5 Sonnet和GPT-5等领先专有模型。

Conclusion: BAR-SQL通过将可靠性和边界感知直接嵌入生成过程，有效解决了NL2SQL系统中的边界情况处理问题，在SQL生成准确性和可靠弃权响应方面表现出色，为企业级应用提供了更可靠的解决方案。

Abstract: In this paper, we present BAR-SQL (Boundary-Aware Reliable NL2SQL), a unified training framework that embeds reliability and boundary awareness directly into the generation process. We introduce a Seed Mutation data synthesis paradigm that constructs a representative enterprise corpus, explicitly encompassing multi-step analytical queries alongside boundary cases including ambiguity and schema limitations. To ensure interpretability, we employ Knowledge-Grounded Reasoning Synthesis, which produces Chain-of-Thought traces explicitly anchored in schema metadata and business rules. The model is trained through a two-stage process: Supervised Fine-Tuning (SFT) followed by Reinforcement Learning via Group Relative Policy Optimization. We design a Task-Conditioned Hybrid Reward mechanism that simultaneously optimizes SQL execution accuracy-leveraging Abstract Syntax Tree analysis and dense result matching-and semantic precision in abstention responses. To evaluate reliability alongside generation accuracy, we construct and release Ent-SQL-Bench, which jointly assesse SQL precision and boundary-aware abstention across ambiguous and unanswerable queries. Experimental results on this benchmark demonstrate that BAR-SQL achieves 91.48% average accuracy, outperforming leading proprietary models, including Claude 4.5 Sonnet and GPT-5, in both SQL generation quality and boundary-aware abstention capability. The source code and benchmark are available anonymously at: https://github.com/TianSongS/BAR-SQL.

</details>


### [60] [An Efficient Long-Context Ranking Architecture With Calibrated LLM Distillation: Application to Person-Job Fit](https://arxiv.org/abs/2601.10321)
*Warren Jouanneau,Emma Jouffroy,Marc Palyart*

Main category: cs.CL

TL;DR: 提出基于新型交叉注意力架构的重新排序模型，通过LLM生成细粒度监督信号进行知识蒸馏，实现高效的多语言简历-职位匹配


<details>
  <summary>Details</summary>
Motivation: 实时为职位提案找到最合适的人选具有挑战性，特别是当简历内容冗长、结构化且多语言时。现有方法在处理长文本输入时计算开销大，且容易受到历史数据偏见的影响。

Method: 1) 提出基于新一代后期交叉注意力架构的重新排序模型，分解简历和项目简介以高效处理长文本输入；2) 使用生成式大语言模型作为教师模型，生成细粒度、语义基础化的监督信号；3) 通过增强的蒸馏损失函数将教师信号蒸馏到学生模型中

Result: 在相关性、排序和校准指标上的实验表明，该方法优于最先进的基线模型。模型产生的技能匹配分数能够实现一致且可解释的人岗匹配。

Conclusion: 提出的重新排序模型通过创新的交叉注意力架构和LLM知识蒸馏，有效解决了长文本、多语言简历匹配的挑战，减少了计算开销并提高了匹配质量。

Abstract: Finding the most relevant person for a job proposal in real time is challenging, especially when resumes are long, structured, and multilingual. In this paper, we propose a re-ranking model based on a new generation of late cross-attention architecture, that decomposes both resumes and project briefs to efficiently handle long-context inputs with minimal computational overhead. To mitigate historical data biases, we use a generative large language model (LLM) as a teacher, generating fine-grained, semantically grounded supervision. This signal is distilled into our student model via an enriched distillation loss function. The resulting model produces skill-fit scores that enable consistent and interpretable person-job matching. Experiments on relevance, ranking, and calibration metrics demonstrate that our approach outperforms state-of-the-art baselines.

</details>


### [61] [OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding](https://arxiv.org/abs/2601.10343)
*Deming Ding,Shichun Liu,Enhui Yang,Jiahang Lin,Ziying Chen,Shihan Dou,Honglin Guo,Weiyu Cheng,Pengyu Zhao,Chengjun Xiao,Qunhong Zeng,Qi Zhang,Xuanjing Huang,Qidi Xu,Tao Gui*

Main category: cs.CL

TL;DR: OctoBench：首个评估代码脚手架中LLM遵循异构指令能力的基准，包含34个环境、217个任务和7,098个检查项，揭示任务解决与脚手架遵循之间的系统性差距


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM在代码脚手架中遵循指定指令的能力关注不足，特别是当约束条件具有异质性且跨越多次交互时。需要专门的基准来评估脚手架感知的指令遵循能力

Method: 开发OctoBench基准，包含34个环境、217个任务，涵盖三种脚手架类型，配备7,098个客观检查项。提供自动化观察和评分工具包，捕获完整轨迹并进行细粒度检查，以区分任务解决和规则遵循

Result: 对8个代表性模型的实验显示，任务解决能力与脚手架感知的合规性之间存在系统性差距，表明需要专门针对异构指令遵循的训练和评估方法

Conclusion: OctoBench填补了代码脚手架中LLM指令遵循能力评估的空白，揭示了当前模型的局限性，为开发更脚手架感知的编码代理提供了基准支持

Abstract: Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.

</details>


### [62] [Training-Trajectory-Aware Token Selection](https://arxiv.org/abs/2601.10348)
*Zhanming Shen,Jiaqi Hu,Zeyu Qin,Hao Chen,Wentao Ye,Zenan Huang,Yihong Zhuang,Guoshan Lu,Junlin Zhou,Junbo Zhao*

Main category: cs.CL

TL;DR: 论文提出T3S方法解决前沿模型持续蒸馏中的瓶颈问题，通过token级训练轨迹感知选择，让Qwen3-8B仅用数百样本就超越DeepSeek-R1，Qwen3-32B接近Qwen3-235B性能


<details>
  <summary>Details</summary>
Motivation: 前沿模型持续蒸馏时，即使损失函数单调下降，性能指标仍会在瓶颈处急剧下降。研究发现token级置信度分化为模仿锚定token和待学习token，这两类token无法共存是持续蒸馏失败的根本原因

Method: 提出训练轨迹感知的token选择(T3S)方法，在token级别重构训练目标，为待学习token清除优化路径。该方法适用于自回归和dLLM两种设置

Result: Qwen3-8B仅用数百样本就超越DeepSeek-R1在竞争性推理基准上；Qwen3-32B接近Qwen3-235B性能；T3训练的LLaDA-2.0-Mini超越其自回归基线，在16B规模无思考模型中达到SOTA

Conclusion: T3S方法有效解决了前沿模型持续蒸馏中的瓶颈问题，通过token级训练目标重构实现了高效的知识迁移，在多个模型规模和设置下都取得了显著性能提升

Abstract: Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. And the characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To this end, we propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings: with only hundreds of examples, Qwen3-8B surpasses DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaches Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeds its AR baseline, achieving state-of-the-art performance among all of 16B-scale no-think models.

</details>


### [63] [Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text](https://arxiv.org/abs/2601.10355)
*Zhihao Xu,Rumei Li,Jiahuan Li,Rongxiang Weng,Jingang Wang,Xunliang Cai,Xiting Wang*

Main category: cs.CL

TL;DR: GEM提出基于文本语料库合成多轮工具使用轨迹的新范式，通过四阶段流程从文本中提取工具使用经验，并训练专门的轨迹合成器来降低计算成本，在BFCL V3基准上取得16.5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 获取多样且真实的多轮工具使用数据是构建自主智能体的关键挑战。文本语料库天然包含丰富的多步问题解决经验，可作为未开发、可扩展且真实的数据源。

Method: 提出GEM数据合成流水线，包含四个阶段：相关性过滤、工作流和工具提取、轨迹接地、复杂性精炼。为降低计算成本，进一步通过监督微调训练专门的轨迹合成器，将复杂生成流水线蒸馏为高效的端到端轨迹生成器。

Result: GEM-32B在BFCL V3多轮基准上实现16.5%的性能提升。模型部分超越了在τ-bench（航空和零售）领域内数据训练的模型性能，展示了文本合成范式的优越泛化能力。轨迹合成器在保持质量的同时显著降低了推理延迟和成本。

Conclusion: 文本语料库是高质量多轮工具使用数据的宝贵来源，GEM框架能够有效提取和合成这些数据，为构建更强大的自主智能体提供了可扩展的解决方案。

Abstract: Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. We observe that textual corpora naturally contain rich, multi-step problem-solving experiences, which can serve as an untapped, scalable, and authentic data source for multi-turn tool-use tasks. Based on this insight, we introduce GEM, a data synthesis pipeline that enables the generation and extraction of multi-turn tool-use trajectories from text corpora through a four-stage process: relevance filtering, workflow & tool extraction, trajectory grounding, and complexity refinement. To reduce the computational cost, we further train a specialized Trajectory Synthesizer via supervised fine-tuning. This model distills the complex generation pipeline into an efficient, end-to-end trajectory generator. Experiments demonstrate that our GEM-32B achieve a 16.5% improvement on the BFCL V3 Multi-turn benchmark. Our models partially surpass the performance of models trained on τ - bench (Airline and Retail) in-domain data, highlighting the superior generalization capability derived from our text-based synthesis paradigm. Notably, our Trajectory Synthesizer matches the quality of the full pipeline while significantly reducing inference latency and costs.

</details>


### [64] [The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models](https://arxiv.org/abs/2601.10387)
*Christina Lu,Jack Gallagher,Jonathan Michala,Kyle Fish,Jack Lindsey*

Main category: cs.CL

TL;DR: 研究发现大语言模型存在一个"助手轴"方向，控制模型在默认助手模式与其他角色之间的切换，可用于稳定模型行为并防止角色漂移


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常被训练成默认的助手身份，但可以扮演多种角色。研究者希望理解模型角色空间的结构，探索如何稳定模型行为，防止其偏离预期的助手角色而产生有害或怪异行为

Method: 通过提取不同角色原型的激活方向来研究模型角色空间结构，发现并定义了"助手轴"这一主导方向。通过沿此轴进行激活控制，测试模型在不同情境下的行为稳定性

Result: 助手轴存在于多个模型中，控制此方向可强化或减弱助手行为。远离助手方向会导致模型采用神秘、戏剧化的说话风格。角色漂移常发生在需要元反思或涉及情感脆弱用户的对话中。限制助手轴上的激活区域可稳定模型行为，抵御基于角色的越狱攻击

Conclusion: 后训练仅将模型松散地锚定在特定角色区域，需要开发更有效的训练和控制策略来深度锚定模型到一致的角色身份，防止角色漂移和有害行为

Abstract: Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an "Assistant Axis," which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts "persona drift," a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.

</details>


### [65] [INDIC DIALECT: A Multi Task Benchmark to Evaluate and Translate in Indian Language Dialects](https://arxiv.org/abs/2601.10388)
*Tarun Sharma,Manikandan Ravikiran,Sourava Kumar Behera,Pramit Bhattacharya,Arnab Bhattacharya,Rohit Saluja*

Main category: cs.CL

TL;DR: INDIC-DIALECT：一个包含印地语和奥里亚语11种方言的13k平行语料库，用于方言分类、选择题问答和机器翻译的多任务基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前NLP研究主要关注标准化语言，而印度等地的低资源方言（如印地语和奥里亚语的多种方言）严重缺乏代表性，尽管这些语言使用者众多但网络存在极少。

Method: 构建了人工整理的13k平行句对语料库，涵盖11种方言和2种语言（印地语和奥里亚语），并设计了包含方言分类、选择题问答和机器翻译三个任务的多任务基准。

Result: GPT-4o和Gemini 2.5等大语言模型在分类任务上表现不佳（F1仅19.6%），而针对印度语言预训练的微调transformer模型显著提升性能（F1达89.8%）。方言到标准语翻译中，混合AI模型BLEU得分61.32（基线23.36）；标准语到方言翻译中，"基于规则后接AI"方法BLEU得分48.44（基线27.59）。

Conclusion: INDIC-DIALECT为印度方言NLP研究提供了新的基准，展示了现有模型在方言处理上的局限性，并计划开源以支持低资源印度方言的进一步研究。

Abstract: Recent NLP advances focus primarily on standardized languages, leaving most low-resource dialects under-served especially in Indian scenarios. In India, the issue is particularly important: despite Hindi being the third most spoken language globally (over 600 million speakers), its numerous dialects remain underrepresented. The situation is similar for Odia, which has around 45 million speakers. While some datasets exist which contain standard Hindi and Odia languages, their regional dialects have almost no web presence. We introduce INDIC-DIALECT, a human-curated parallel corpus of 13k sentence pairs spanning 11 dialects and 2 languages: Hindi and Odia. Using this corpus, we construct a multi-task benchmark with three tasks: dialect classification, multiple-choice question (MCQ) answering, and machine translation (MT). Our experiments show that LLMs like GPT-4o and Gemini 2.5 perform poorly on the classification task. While fine-tuned transformer based models pretrained on Indian languages substantially improve performance e.g., improving F1 from 19.6\% to 89.8\% on dialect classification. For dialect to language translation, we find that hybrid AI model achieves highest BLEU score of 61.32 compared to the baseline score of 23.36. Interestingly, due to complexity in generating dialect sentences, we observe that for language to dialect translation the ``rule-based followed by AI" approach achieves best BLEU score of 48.44 compared to the baseline score of 27.59. INDIC-DIALECT thus is a new benchmark for dialect-aware Indic NLP, and we plan to release it as open source to support further work on low-resource Indian dialects.

</details>


### [66] [TF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction](https://arxiv.org/abs/2601.10410)
*Mihai Dan Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

TL;DR: TF3-RO是一个面向罗马尼亚语的端到端语言建模框架，包含分词器设计、预训练、模型压缩、评估和大规模合成数据生成，专门针对罗马尼亚语的形态丰富特性进行优化。


<details>
  <summary>Details</summary>
Motivation: 针对罗马尼亚语这类形态丰富但计算资源不足的语言，目前缺乏公开的、可复现的端到端语言建模管道，需要解决分词膨胀、模型压缩和合成数据生成等问题。

Method: 1) 构建罗马尼亚语特定的BPE和Unigram分词器以缓解形态导致的token膨胀；2) 从头预训练51.65M参数的LLaMA风格Transformer；3) 通过量化、结构化剪枝和基于logit的知识蒸馏压缩到26.45M参数；4) 使用蒸馏模型通过组合提示框架生成300万罗马尼亚语合成寓言。

Result: 开发了完整的TF3-RO管道，包含专门的分词器、预训练模型、压缩后的学生模型，以及300万罗马尼亚语合成寓言数据集。评估套件结合了内在指标、罗马尼亚语一致性探测、实体连贯性、基于规则的语法检查和LLM评估。

Conclusion: TF3-RO提供了一个可复现且语言学基础扎实的框架，用于训练紧凑的罗马尼亚语语言模型并生成大规模合成叙事语料库，填补了罗马尼亚语端到端语言建模管道的空白。

Abstract: Recent advances in synthetic data generation have shown that compact language models can be trained effectively when the underlying corpus is structurally controlled and linguistically coherent. However, for morphologically rich and computationally under-resourced languages such as Romanian, there is still no openly documented, end-to-end pipeline that unifies tokenizer design, preprocessing, pretraining, compression, evaluation, and large-scale synthetic data generation in a reproducible framework. Building on TF1, a three-million-story English fable dataset, and TF2, which extends TF1 through high-quality Romanian translations, we introduce TF3-RO, a Romanian-centric language modeling pipeline spanning tokenizer training, from-scratch model development, and Romanian-native dataset generation. TF3-RO constructs Romanian-specific BPE and Unigram tokenizers from a linguistically informed corpus to mitigate token inflation induced by Romanian morphology. Using long-sequence packed training, we pretrain a 51.65M-parameter LLaMA-style Transformer entirely from scratch. The model is subsequently optimized through quantization, structured pruning, and logit-based knowledge distillation, yielding a compact 26.45M-parameter student model with tied embeddings and strong deployment characteristics. Using this distilled model, TF3-RO generates three million Romanian-native synthetic fables via a controlled combinatorial prompting framework. Across all stages, the pipeline integrates a comprehensive evaluation suite combining intrinsic metrics, Romanian agreement probes, entity coherence, rule-based grammar checking, and LLM-based assessment. TF3-RO provides a reproducible and linguistically grounded framework for training compact Romanian language models and producing large-scale synthetic narrative corpora.

</details>


### [67] [Are Language Models Models?](https://arxiv.org/abs/2601.10421)
*Philip Resnik*

Main category: cs.CL

TL;DR: 论文批评将语言模型视为认知模型系统的说法，认为这种主张在Marr的三个分析层次上都存在问题，建议将其视为工具而非认知模型


<details>
  <summary>Details</summary>
Motivation: 针对Futrell和Mahowald提出的语言模型可作为"模型系统"的主张进行批判性评估，旨在澄清语言模型在认知科学中的适当定位，避免过度炒作

Method: 采用David Marr的计算神经科学分析框架，从三个层次评估语言模型：实现层次、算法-表征层次和计算理论层次

Result: 在实现层次上语言模型明显不适合作为认知模型；在算法-表征层次上动机不足；在计算理论层次上存在问题。语言模型更适合作为工具而非认知模型

Conclusion: 语言模型是有价值的工具，但将其称为认知模型夸大了其作用，且不必要地助长了LLM的炒作。应更准确地定位其在认知科学中的角色

Abstract: Futrell and Mahowald claim LMs "serve as model systems", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.

</details>


### [68] [SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability](https://arxiv.org/abs/2601.10455)
*Ruochen Li,Kun Yuan,Yufei Xia,Yue Zhou,Qingyu Lu,Weihang Li,Youxiang Zhu,Nassir Navab*

Main category: cs.CL

TL;DR: 本文提出基于阶段目标可满足性的手术规划正确性定义，开发了包含有效程序变体和无效规划的多中心元评估基准，发现序列相似性指标系统性误判规划质量，采用基于规则的目标可满足性指标评估Video-LLMs，揭示感知错误和约束不足导致的失败。


<details>
  <summary>Details</summary>
Motivation: 手术规划需要视觉感知、长时程推理和程序知识，但当前评估协议在安全关键环境中对视觉语言模型的评估可靠性不明确。从目标导向视角出发，需要更可靠的评估方法来衡量模型在手术规划中的表现。

Method: 1. 基于专家定义的手术规则，通过阶段目标可满足性定义规划正确性；2. 构建包含有效程序变体和无效规划（包含顺序和内容错误）的多中心元评估基准；3. 采用基于规则的目标可满足性指标作为高精度元评估参考；4. 在渐进约束设置下评估Video-LLMs，分析感知错误和推理约束不足的问题。

Result: 序列相似性指标系统性误判规划质量：惩罚有效规划同时无法识别无效规划。结构知识持续改善性能，而语义指导单独使用时不可靠，仅在与结构约束结合时才对较大模型有益。Video-LLMs在感知错误和约束不足的推理中表现失败。

Conclusion: 当前序列相似性指标不适合评估手术规划质量，基于规则的目标可满足性指标提供了更可靠的评估方法。结构约束对改善模型性能至关重要，而纯语义指导不足。需要更严谨的评估协议来确保视觉语言模型在安全关键医疗应用中的可靠性。

Abstract: Surgical planning integrates visual perception, long-horizon reasoning, and procedural knowledge, yet it remains unclear whether current evaluation protocols reliably assess vision-language models (VLMs) in safety-critical settings. Motivated by a goal-oriented view of surgical planning, we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules. Based on this definition, we introduce a multicentric meta-evaluation benchmark with valid procedural variations and invalid plans containing order and content errors. Using this benchmark, we show that sequence similarity metrics systematically misjudge planning quality, penalizing valid plans while failing to identify invalid ones. We therefore adopt a rule-based goal-satisfiability metric as a high-precision meta-evaluation reference to assess Video-LLMs under progressively constrained settings, revealing failures due to perception errors and under-constrained reasoning. Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints.

</details>


### [69] [DR-Arena: an Automated Evaluation Framework for Deep Research Agents](https://arxiv.org/abs/2601.10504)
*Yiwen Gao,Ruochen Zhao,Yang Deng,Wenxuan Zhang*

Main category: cs.CL

TL;DR: DR-Arena：一个完全自动化的评估框架，通过动态调查测试深度研究代理的能力极限，使用实时信息树和自适应演进循环来评估深度推理和广泛覆盖能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于静态数据集的评估方法存在任务泛化性有限、时间错位和数据污染等局限性，无法有效评估大型语言模型作为深度研究代理的自主调查和信息合成能力。

Method: DR-Arena从新鲜网络趋势构建实时信息树确保评估标准与实时世界状态同步，采用自动化考官生成结构化任务测试深度推理和广泛覆盖能力，并使用自适应演进循环动态提升任务复杂度。

Result: 实验显示DR-Arena与LMSYS搜索竞技场排行榜的Spearman相关性达到0.94，实现了与人类偏好的最先进对齐，无需任何人工努力，验证了其作为昂贵人工裁决可靠替代方案的可行性。

Conclusion: DR-Arena通过动态调查和自适应复杂度提升，为深度研究代理提供了可靠的自动化评估框架，解决了静态数据集的局限性，能够有效测试代理的能力边界。

Abstract: As Large Language Models (LLMs) increasingly operate as Deep Research (DR) Agents capable of autonomous investigation and information synthesis, reliable evaluation of their task performance has become a critical bottleneck. Current benchmarks predominantly rely on static datasets, which suffer from several limitations: limited task generality, temporal misalignment, and data contamination. To address these, we introduce DR-Arena, a fully automated evaluation framework that pushes DR agents to their capability limits through dynamic investigation. DR-Arena constructs real-time Information Trees from fresh web trends to ensure the evaluation rubric is synchronized with the live world state, and employs an automated Examiner to generate structured tasks testing two orthogonal capabilities: Deep reasoning and Wide coverage. DR-Arena further adopts Adaptive Evolvement Loop, a state-machine controller that dynamically escalates task complexity based on real-time performance, demanding deeper deduction or wider aggregation until a decisive capability boundary emerges. Experiments with six advanced DR agents demonstrate that DR-Arena achieves a Spearman correlation of 0.94 with the LMSYS Search Arena leaderboard. This represents the state-of-the-art alignment with human preferences without any manual efforts, validating DR-Arena as a reliable alternative for costly human adjudication.

</details>


### [70] [AEQ-Bench: Measuring Empathy of Omni-Modal Large Models](https://arxiv.org/abs/2601.10513)
*Xuan Luo,Lewei Yao,Libo Zhao,Lanqing Hong,Kai Chen,Dehua Tao,Daxin Tan,Ruifeng Xu,Jing Li*

Main category: cs.CL

TL;DR: AEQ-Bench是一个评估全模态大模型共情能力的新基准，专注于音频+文本多模态输入的共情响应生成和音频响应的共情判断，发现带音频输出能力的模型表现更好，但细粒度副语言表达评估仍不可靠。


<details>
  <summary>Details</summary>
Motivation: 全模态大模型的自动评估很重要，但共情评估因情感特性而具有挑战性。现有基准无法系统评估模型从多模态输入理解情感线索并生成共情响应的能力，以及不依赖文本转录评估音频响应共情的能力。

Method: 提出AEQ-Bench基准，包含两个核心共情能力评估：(1) 从音频+文本多模态输入理解情感线索并生成共情响应；(2) 不依赖文本转录评估音频响应的共情。基准采用两种新颖设置：不同上下文特异性和语音语调变化。

Result: 综合语言和副语言指标评估显示：(1) 具有音频输出能力的全模态大模型普遍优于仅文本输出的模型；(2) 全模态大模型在粗粒度质量评估上与人类判断一致，但在细粒度副语言表达评估上仍不可靠。

Conclusion: AEQ-Bench为全模态大模型的共情能力评估提供了系统框架，揭示了当前模型在音频共情能力上的优势和局限，特别是细粒度副语言表达评估仍需改进。

Abstract: While the automatic evaluation of omni-modal large models (OLMs) is essential, assessing empathy remains a significant challenge due to its inherent affectivity. To investigate this challenge, we introduce AEQ-Bench (Audio Empathy Quotient Benchmark), a novel benchmark to systematically assess two core empathetic capabilities of OLMs: (i) generating empathetic responses by comprehending affective cues from multi-modal inputs (audio + text), and (ii) judging the empathy of audio responses without relying on text transcription. Compared to existing benchmarks, AEQ-Bench incorporates two novel settings that vary in context specificity and speech tone. Comprehensive assessment across linguistic and paralinguistic metrics reveals that (1) OLMs trained with audio output capabilities generally outperformed models with text-only outputs, and (2) while OLMs align with human judgments for coarse-grained quality assessment, they remain unreliable for evaluating fine-grained paralinguistic expressiveness.

</details>


### [71] [PERM: Psychology-grounded Empathetic Reward Modeling for Large Language Models](https://arxiv.org/abs/2601.10532)
*Chengbing Wang,Wuqiang Zheng,Yang Zhang,Fengbin Zhu,Junyi Cheng,Yi Xie,Wenjie Wang,Fuli Feng*

Main category: cs.CL

TL;DR: 提出心理学基础的共情奖励建模(PERM)，通过支持者、寻求者和旁观者三重视角评估LLM的共情能力，显著提升情感支持效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在人类中心应用中缺乏实质性情感支持，传统RL奖励模型仅从单一视角评估共情，忽略了共情周期理论中支持者与寻求者之间的双向互动本质。

Method: 提出PERM框架，将共情评估分解为：1)支持者视角（内部共鸣与表达）；2)寻求者视角（情感接收）；3)旁观者视角（整体互动质量）。通过多视角奖励建模提升LLM共情能力。

Result: 在广泛使用的情感智能基准和工业日常对话数据集上，PERM比现有最佳基线提升超过10%。盲测用户研究显示70%用户偏好PERM生成的回应，证明其生成更共情响应的有效性。

Conclusion: PERM通过心理学基础的共情评估框架，显著提升了LLM的情感支持能力，为构建更人性化、有效的AI情感支持系统提供了新方向。

Abstract: Large Language Models (LLMs) are increasingly deployed in human-centric applications, yet they often fail to provide substantive emotional support. While Reinforcement Learning (RL) has been utilized to enhance empathy of LLMs, existing reward models typically evaluate empathy from a single perspective, overlooking the inherently bidirectional interaction nature of empathy between the supporter and seeker as defined by Empathy Cycle theory. To address this limitation, we propose Psychology-grounded Empathetic Reward Modeling (PERM). PERM operationalizes empathy evaluation through a bidirectional decomposition: 1) Supporter perspective, assessing internal resonation and communicative expression; 2) Seeker perspective, evaluating emotional reception. Additionally, it incorporates a bystander perspective to monitor overall interaction quality. Extensive experiments on a widely-used emotional intelligence benchmark and an industrial daily conversation dataset demonstrate that PERM outperforms state-of-the-art baselines by over 10\%. Furthermore, a blinded user study reveals a 70\% preference for our approach, highlighting its efficacy in generating more empathetic responses. Our code, dataset, and models are available at https://github.com/ZhengWwwq/PERM.

</details>


### [72] [Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure](https://arxiv.org/abs/2601.10566)
*Syed Naveed Mahmood,Md. Rezaur Rahman Bhuiyan,Tasfia Zaman,Jareen Tasneem Khondaker,Md. Sameer Sakib,Nazia Tasnim,Farig Sadeque*

Main category: cs.CL

TL;DR: KIF框架通过针对内部激活签名而非表面输出来实现真正的知识擦除，解决了现有遗忘方法混淆行为抑制与真实知识移除的问题，在保持模型效用的同时实现接近完美的擦除效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM知识擦除方法存在根本缺陷：将行为抑制与真实知识移除混为一谈，导致潜在能力在表面拒绝下仍然存在。这无法满足GDPR合规性和模型安全性的实际需求，需要区分真正的擦除与混淆。

Method: 提出知识免疫框架(KIF)，这是一种表示感知架构，通过针对内部激活签名而非表面输出来区分真正的擦除与混淆。方法结合主题特定表示的动态抑制和参数高效适配，实现无需完整模型重训练的持久遗忘。

Result: KIF实现接近完美的擦除效果(FQ≈0.99 vs 1.00)，同时保持接近基准水平的效用(MU=0.62)，有效打破了传统稳定性-擦除权衡。在3B到14B参数的Llama、Mistral、Qwen和DeepSeek模型上验证，发现标准模型表现出规模无关的真实擦除，而推理优先模型显示根本架构差异。

Conclusion: KIF框架通过操作化混淆-擦除区分，首次实现了跨模型家族和规模的机制级遗忘行为系统诊断，为LLM知识擦除提供了新的理论基础和实用解决方案。

Abstract: Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales.

</details>


### [73] [Form and Meaning in Intrinsic Multilingual Evaluations](https://arxiv.org/abs/2601.10580)
*Wessel Poelman,Miryam de Lhoneux*

Main category: cs.CL

TL;DR: 研究发现当前多语言环境下条件语言模型的内在评估指标（如困惑度）并不具备普遍可比性，因为它们基于信息论测量信息内容，而非语义含义。


<details>
  <summary>Details</summary>
Motivation: 条件语言模型的内在评估指标（如困惑度）在多语言设置中被广泛使用，但这些指标在多语言环境中基于许多假设，特别是假设比较并行句子的困惑度能反映模型质量，因为语义信息相同。然而这些指标本质上是从信息论角度测量信息内容，而非语义含义。

Method: 使用六个评估指标在两个多并行语料库上进行实验，既使用单语模型也使用多语模型。明确阐述并讨论了这些评估指标背后的假设及其影响。

Result: 实验发现当前的评估指标并不具备普遍可比性。通过形式-意义辩论为这一发现提供了解释。

Conclusion: 多语言环境下条件语言模型的内在评估指标存在局限性，不能简单通过比较并行句子的困惑度来评估模型质量，因为这些指标测量的是信息论意义上的信息内容而非语义含义。

Abstract: Intrinsic evaluation metrics for conditional language models, such as perplexity or bits-per-character, are widely used in both mono- and multilingual settings. These metrics are rather straightforward to use and compare in monolingual setups, but rest on a number of assumptions in multilingual setups. One such assumption is that comparing the perplexity of CLMs on parallel sentences is indicative of their quality since the information content (here understood as the semantic meaning) is the same. However, the metrics are inherently measuring information content in the information-theoretic sense. We make this and other such assumptions explicit and discuss their implications. We perform experiments with six metrics on two multi-parallel corpora both with mono- and multilingual models. Ultimately, we find that current metrics are not universally comparable. We look at the form-meaning debate to provide some explanation for this.

</details>


### [74] [Influential Training Data Retrieval for Explaining Verbalized Confidence of LLMs](https://arxiv.org/abs/2601.10645)
*Yuxi Xia,Loris Schoenegger,Benjamin Roth*

Main category: cs.CL

TL;DR: 论文提出TracVC方法追踪LLM表达自信的来源，发现模型常模仿表面自信表达而非基于内容可信度，揭示了当前训练机制的根本局限。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过表达自信可以增加用户信任，但现有研究表明LLM常常过度自信，其表达的自信度与事实准确性不一致。为了理解这种自信表达的来源，需要开发方法来追踪模型自信表达的训练数据基础。

Method: 提出TracVC方法，基于信息检索和影响估计技术，将生成的自信表达追溯到训练数据。在问答场景下评估OLMo和Llama模型，并引入内容基础性新指标，衡量LLM在表达自信时多大程度上基于与问题和答案相关的内容训练示例，而非通用的自信表达示例。

Result: 分析发现OLMo2-13B经常受到与查询词汇无关的自信相关数据影响，表明模型可能模仿表面的确定性语言表达，而非依赖真正的内容基础。这揭示了当前训练机制的根本局限：LLM可能学会了如何听起来自信，但未学会何时自信是合理的。

Conclusion: 研究为改进LLM表达更可靠自信的可信度提供了基础，指出了当前训练方法需要解决的核心问题：确保模型表达的自信基于内容相关性而非表面语言模式。

Abstract: Large language models (LLMs) can increase users' perceived trust by verbalizing confidence in their outputs. However, prior work has shown that LLMs are often overconfident, making their stated confidence unreliable since it does not consistently align with factual accuracy. To better understand the sources of this verbalized confidence, we introduce TracVC (\textbf{Trac}ing \textbf{V}erbalized \textbf{C}onfidence), a method that builds on information retrieval and influence estimation to trace generated confidence expressions back to the training data. We evaluate TracVC on OLMo and Llama models in a question answering setting, proposing a new metric, content groundness, which measures the extent to which an LLM grounds its confidence in content-related training examples (relevant to the question and answer) versus in generic examples of confidence verbalization. Our analysis reveals that OLMo2-13B is frequently influenced by confidence-related data that is lexically unrelated to the query, suggesting that it may mimic superficial linguistic expressions of certainty rather than rely on genuine content grounding. These findings point to a fundamental limitation in current training regimes: LLMs may learn how to sound confident without learning when confidence is justified. Our analysis provides a foundation for improving LLMs' trustworthiness in expressing more reliable confidence.

</details>


### [75] [Detecting Winning Arguments with Large Language Models and Persuasion Strategies](https://arxiv.org/abs/2601.10660)
*Tiziano Labruna,Arkadiusz Modzelewski,Giorgio Satta,Giovanni Da San Martino*

Main category: cs.CL

TL;DR: 论文提出一种基于说服策略的多策略评分方法，利用大语言模型预测论辩文本的说服力，并在三个数据集上验证了该方法的效果。


<details>
  <summary>Details</summary>
Motivation: 检测论辩文本中的说服力是一个重要但具有挑战性的任务，对理解人类沟通有重要意义。当前研究需要更好地理解说服策略（如攻击声誉、分散注意力、操纵性措辞等）如何影响文本的说服力。

Method: 提出Multi-Strategy Persuasion Scoring方法，利用大语言模型，通过引导模型对六种说服策略进行推理来评估文本的说服力。在三个标注数据集（Winning Arguments、Anthropic/Persuasion、Persuasion for Good）上进行实验，并将Winning Arguments数据集按讨论主题进行组织分析。

Result: 策略引导的推理方法提高了说服力预测的准确性。通过将数据集按主题组织分析，发现方法在不同主题上的表现差异。公开了主题标注版本的数据集供未来研究使用。

Conclusion: 结构化、策略感知的提示方法能增强论辩质量评估的可解释性和鲁棒性，证明了说服策略在理解论辩说服力中的价值。

Abstract: Detecting persuasion in argumentative text is a challenging task with important implications for understanding human communication. This work investigates the role of persuasion strategies - such as Attack on reputation, Distraction, and Manipulative wording - in determining the persuasiveness of a text. We conduct experiments on three annotated argument datasets: Winning Arguments (built from the Change My View subreddit), Anthropic/Persuasion, and Persuasion for Good. Our approach leverages large language models (LLMs) with a Multi-Strategy Persuasion Scoring approach that guides reasoning over six persuasion strategies. Results show that strategy-guided reasoning improves the prediction of persuasiveness. To better understand the influence of content, we organize the Winning Argument dataset into broad discussion topics and analyze performance across them. We publicly release this topic-annotated version of the dataset to facilitate future research. Overall, our methodology demonstrates the value of structured, strategy-aware prompting for enhancing interpretability and robustness in argument quality assessment.

</details>


### [76] [LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals](https://arxiv.org/abs/2601.10700)
*Gilat Toker,Nitay Calderon,Ohad Amosy,Roi Reichart*

Main category: cs.CL

TL;DR: LIBERTy是一个基于LLM生成结构性反事实对的框架，用于评估概念解释方法的忠实性，包含三个数据集和新评估指标，发现现有方法有改进空间且专有LLM对人口统计概念敏感性降低。


<details>
  <summary>Details</summary>
Motivation: 现有基于概念的解释方法评估依赖于昂贵的人工编写反事实，这些反事实作为不完美的代理。需要更系统、可扩展的基准来评估概念解释的忠实性。

Method: 提出LIBERTy框架：基于明确的结构因果模型，通过对概念进行干预，让LLM生成结构性反事实对。包含三个数据集（疾病检测、简历筛选、工作场所暴力预测）和新评估指标order-faithfulness。

Result: 评估多种方法在五个模型上的表现，发现概念解释方法有显著改进空间。专有LLM对人口统计概念敏感性明显降低，可能是由于后训练缓解措施。LIBERTy为开发忠实解释方法提供了急需的基准。

Conclusion: LIBERTy通过基于LLM生成结构性反事实对，为概念解释方法的忠实性评估提供了系统、可扩展的基准，有助于推动更忠实解释方法的发展。

Abstract: Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.

</details>


### [77] [Grounding Agent Memory in Contextual Intent](https://arxiv.org/abs/2601.10702)
*Ruozhen Yang,Yucheng Jiang,Yueqi Jiang,Priyanka Kargupta,Yunyi Zhang,Jiawei Han*

Main category: cs.CL

TL;DR: STITCH是一种用于长时程目标导向交互的智能记忆系统，通过结构化意图索引解决重复实体和事实的检索歧义问题，在CAME-Bench基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长时程目标导向交互中面临挑战，因为相似实体和事实在不同潜在目标和约束下重复出现，导致记忆系统检索到上下文不匹配的证据。

Method: 提出STITCH系统，为每个轨迹步骤建立结构化检索线索（上下文意图），包括：1）定义主题段的当前潜在目标；2）动作类型；3）锚定重要属性的显著实体类型。通过意图匹配检索历史，在推理时按意图兼容性过滤和优先处理记忆片段。

Result: 在CAME-Bench和LongMemEval基准上取得最先进性能，比最强基线提升35.6%，且随着轨迹长度增加，优势更加明显。分析表明意图索引显著减少了检索噪声。

Conclusion: STITCH通过结构化意图索引有效解决长时程交互中的检索歧义问题，支持意图感知记忆以实现鲁棒的长时程推理。

Abstract: Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history.
  For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.

</details>


### [78] [MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching](https://arxiv.org/abs/2601.10712)
*Changle Qu,Sunhao Dai,Hengyi Cai,Jun Xu,Shuaiqiang Wang,Dawei Yin*

Main category: cs.CL

TL;DR: MatchTIR提出基于二分图匹配的细粒度奖励分配框架，解决工具集成推理中粗粒度信用分配问题，提升多轮长程任务性能


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法通常依赖结果级或轨迹级奖励，对轨迹内所有步骤分配统一优势值。这种粗粒度信用分配无法区分有效工具调用与冗余/错误调用，尤其在长程多轮场景中问题更突出

Method: 提出MatchTIR框架：1) 将信用分配建模为预测轨迹与真实轨迹间的二分图匹配问题，使用两种分配策略获得密集的轮级奖励；2) 引入双级优势估计方案，整合轮级和轨迹级信号，为单个交互轮分配不同优势值

Result: 在三个基准测试上的广泛实验证明了MatchTIR的优越性。特别值得注意的是，4B模型超越了大多数8B竞争对手，尤其在长程和多轮任务中表现突出

Conclusion: MatchTIR通过细粒度监督和双级优势估计，有效解决了工具集成推理中的信用分配问题，显著提升了模型在复杂任务中的性能，特别是在长程多轮场景下

Abstract: Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [79] [Collision Avoidance for Non-Cooperative Multi-Swarm Coverage Control with Bounded Disturbance Measurements](https://arxiv.org/abs/2601.09917)
*Karolina Schmidt,Luis Rodrigues*

Main category: eess.SY

TL;DR: 提出一种考虑有界扰动测量不确定性的多非合作群集无碰撞覆盖控制算法


<details>
  <summary>Details</summary>
Motivation: 解决存在有界扰动且测量存在不确定性的多非合作群集覆盖控制中的碰撞避免问题

Method: 引入考虑扰动测量不确定性的新方法，开发确保多群集覆盖控制中无碰撞运动的算法

Result: 理论结果通过多群集在扰动环境中独立覆盖给定区域的仿真得到验证

Conclusion: 提出的方法能有效处理扰动测量不确定性，确保多非合作群集覆盖控制中的无碰撞运动

Abstract: This paper proposes a new algorithm for collision-free coverage control of multiple non-cooperating swarms in the presence of bounded disturbances. A new methodology is introduced that accounts for uncertainties in disturbance measurements. The proposed methodology is used to develop an algorithm that ensures collision-free motion in multi-swarm coverage control, specifically for cases where disturbances are present and their measurements are subject to bounded uncertainty. The theoretical results are validated through simulations of multiple swarms that independently aim to cover a given region in an environment with disturbances.

</details>


### [80] [Extremum Seeking Nonovershooting Control of Strict-Feedback Systems Under Unknown Control Direction](https://arxiv.org/abs/2601.09998)
*Kaixin Lu,Ziliang Lyu,Yanfang Mo,Yiguang Hong,Haoyong Yu*

Main category: eess.SY

TL;DR: 提出了一种结合极值搜索和Lie括号设计的方法，解决控制方向未知的严格反馈非线性系统的无超调控制问题，实现近似无超调跟踪。


<details>
  <summary>Details</summary>
Motivation: 针对控制方向未知的严格反馈非线性系统，传统控制方法难以实现无超调跟踪，特别是在安全关键场景中需要满足高阶无超调约束。

Method: 将极值搜索与基于Lie括号的设计相结合，构建控制器确保任意参考轨迹可以从下方跟踪，通过参数调节可将超调减小到任意小水平。

Result: 该方法能够实现近似无超调跟踪，对于任意初始条件都能从下方跟踪参考轨迹，超调可通过参数调节降至任意小，并能处理安全关键场景中的高阶无超调约束。

Conclusion: 提出的极值搜索与Lie括号结合方法有效解决了控制方向未知非线性系统的无超调控制问题，为安全关键应用提供了可行的解决方案。

Abstract: This paper addresses the nonovershooting control problem for strict-feedback nonlinear systems with unknown control direction. We propose a method that integrates extremum seeking with Lie bracket-based design to achieve approximately nonovershooting tracking. The approach ensures that arbitrary reference trajectories can be tracked from below for any initial condition, with the overshoot reducible to arbitrarily small levels through parameter tuning. The method further provides a mechanism for enforcing high-relative-degree nonovershooting constraints in safety-critical scenarios involving unknown control directions.

</details>


### [81] [Event-Driven Deep RL Dispatcher for Post-Storm Distribution System Restoration](https://arxiv.org/abs/2601.10044)
*Farshad Amani,Faezeh Ardali,Amin Kargarian*

Main category: eess.SY

TL;DR: 基于深度强化学习的电力系统灾后恢复调度器，实时更新维修人员分配决策，提升恢复性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害（飓风和洪水）损坏电网设备，运营商需要根据不断更新的信息重新规划恢复方案。传统方法难以实时响应动态变化的现场信息。

Method: 开发基于深度强化学习（DRL）的调度器，作为实时决策引擎。模型将恢复过程建模为顺序信息揭示过程，学习基于紧凑特征（组件状态、旅行/维修时间、人员可用性、边际恢复价值）的actor-critic策略。使用可行性掩码阻止不安全或不可行操作。采用轻量级代理模型生成运行时输入，避免依赖重型求解器。

Result: 在模拟的飓风和洪水事件中，学习到的策略能够实时更新维修人员决策。轻量级运行时逻辑在在线性能（未供电能量、关键负荷恢复时间、旅行距离）方面优于混合整数规划和标准启发式方法。在IEEE 13和123总线馈线上进行了混合飓风/洪水场景测试。

Conclusion: 提出的DRL方法能够有效处理自然灾害后的电网恢复问题，实现实时决策，提高恢复效率，为电力系统灾后恢复提供了新的解决方案。

Abstract: Natural hazards such as hurricanes and floods damage power grid equipment, forcing operators to replan restoration repeatedly as new information becomes available. This paper develops a deep reinforcement learning (DRL) dispatcher that serves as a real-time decision engine for crew-to-repair assignments. We model restoration as a sequential, information-revealing process and learn an actor-critic policy over compact features such as component status, travel/repair times, crew availability, and marginal restoration value. A feasibility mask blocks unsafe or inoperable actions, such as power flow limits, switching rules, and crew-time constraints, before they are applied. To provide realistic runtime inputs without relying on heavy solvers, we use lightweight surrogates for wind and flood intensities, fragility-based failure, spatial clustering of damage, access impairments, and progressive ticket arrivals. In simulated hurricane and flood events, the learned policy updates crew decisions in real time as new field reports arrive. Because the runtime logic is lightweight, it improves online performance (energy-not-supplied, critical-load restoration time, and travel distance) compared with mixed-integer programs and standard heuristics. The proposed approach is tested on the IEEE 13- and 123-bus feeders with mixed hurricane/flood scenarios.

</details>


### [82] [On the Computation and Approximation of Backward Reachable Sets for Max-Plus Linear Systems using Polyhedras](https://arxiv.org/abs/2601.10095)
*Yuda Li,Shaoyuan Li,Xiang Yin*

Main category: eess.SY

TL;DR: 提出了一种用于最大加线性系统后向可达性分析的新近似框架，利用热带多面体结构高效计算可达集，克服传统方法的非凸性和计算复杂性挑战。


<details>
  <summary>Details</summary>
Motivation: 最大加线性系统在定时离散事件系统中建模同步和延迟现象很重要，但后向可达性分析面临非凸动力学和集合补运算复杂性的挑战，传统DBM方法难以处理一般目标区域。

Method: 提出新颖的近似框架，将问题重新表述为符号操作序列，通过热带多面体并集的闭包操作近似非凸目标集，开发系统算法构建结果集的外部和内部表示，并采用极值过滤降低计算复杂度。

Result: 该方法为最大加线性系统提供了可扩展的替代方案，能够对一般目标区域进行可靠的后向可达性分析，相比传统DBM方法更具可扩展性。

Conclusion: 通过利用热带多面体结构，提出的框架有效解决了最大加线性系统后向可达性分析的计算挑战，为定时离散事件系统的验证提供了实用工具。

Abstract: This paper investigates reachability analysis for max-plus linear systems (MPLS), an important class of dynamical systems that model synchronization and delay phenomena in timed discrete-event systems. We specifically focus on backward reachability analysis, i.e., determining the set of states that can reach a given target set within a certain number of steps. Computing backward reachable sets presents significant challenges due to the non-convexity of max-plus dynamics and the complexity of set complement operations. To address these challenges, we propose a novel approximation framework that efficiently computes backward reachable sets by exploiting the structure of tropical polyhedra. Our approach reformulates the problem as a sequence of symbolic operations and approximates non-convex target sets through closure operations on unions of tropical polyhedra. We develop a systematic algorithm that constructs both outer (M-form) and inner (V-form) representations of the resulting sets, incorporating extremal filtering to reduce computational complexity. The proposed method offers a scalable alternative to traditional DBM-based approaches, enabling reliable approximate backward reachability analysis for general target regions in MPLS.

</details>


### [83] [Leveraging Digital Twin Technologies: All-Photonics Networks-as-a-Service for Data Center Xchange in the Era of AI [Invited Tutorial]](https://arxiv.org/abs/2601.10153)
*Hideki Nishizawa,Kazuya Anazawa,Tetsuro Inui,Toru Mano,Takeo Sasai,Giacomo Borraccini,Tatsuya Matsumura,Hiroyuki Ishihara,Sae Kojima,Yoshiaki Sone,Koichi Takasugi*

Main category: eess.SY

TL;DR: 提出数据中心交换架构，通过全光网络即服务连接分布式数据中心，实现虚拟化大规模数据中心，支持数字孪生操作


<details>
  <summary>Details</summary>
Motivation: 为分布式数据中心基础设施提供全光网络即服务，实现虚拟化大规模数据中心，满足低延迟、可扩展性、可靠性和灵活性需求

Method: 提出数据中心交换架构，采用云原生相干收发器架构、远程收发器控制、快速端到端光路配置、基于收发器的物理参数估计和数字纵向监测、光线路系统校准等技术

Result: 通过现场验证展示了所提技术的可行性，能够实现数字孪生操作的光网络

Conclusion: 提出的数据中心交换架构和数字孪生技术能够有效支持分布式数据中心的虚拟化连接，满足现代数据中心网络的关键需求

Abstract: This paper presents a data center exchange (Data Center Xchange, DCX) architecture for all-photonics networks-as-a-service in distributed data center infrastructures, enabling the creation of a virtual large-scale data center by directly interconnecting distributed data centers in metropolitan areas. Key requirements for such an architecture are identified: support for low-latency operations, scalability, reliability, and flexibility within a single network architecture; the ability to add new operator-driven automation functionalities based on an open networking approach; and the ability to control and manage remotely deployed transponders connected via access links with unknown physical parameters. We propose a set of technologies that enable digital twin operations for optical networks, including a cloud-native architecture for coherent transceivers, remote transponder control, fast end-to-end optical path provisioning, transceiver-based physical-parameter estimation incorporating digital longitudinal monitoring, and optical line system calibration, demonstrating their feasibility through field validations.

</details>


### [84] [HyMGP: A Customized MILP-Based Tool for Techno-Economic Planning of Islanded Microgrids](https://arxiv.org/abs/2601.10178)
*Andres Intriago,Rongxing Hu,Nabil Mohammed,S. Gokul Krishnan,Konstantinos Kotsovos,Issam Gereige,Nesren Attiah,Ali Basaheeh,Sarah Aqeel,Hamad A. Saiari,Shehab Ahmed,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 提出HyMGP微电网规划算法，针对干旱地区远程站点，与HOMER Pro对比显示在组件优化和约束处理方面更优，风能整合可降低净现值成本，磷酸铁锂电池比铅酸电池更具成本效益。


<details>
  <summary>Details</summary>
Motivation: 针对干旱地区远程站点的微电网规划需求，现有工具如HOMER Pro在组件规格定制和约束严格执行方面存在不足，需要开发更灵活、优化的规划算法。

Method: 提出HyMGP定制化微电网规划工具，采用混合整数线性规划(MILP)方法，优化光伏板、垂直轴风力发电机和电池储能系统的容量配置，并与HOMER Pro进行对比分析。

Result: HyMGP相比HOMER Pro提供更优、更灵活的解决方案；整合风力发电可降低净现值成本；增加电池自主性会提高成本；磷酸铁锂电池比铅酸电池更具成本效益。

Conclusion: HyMGP是干旱地区远程微电网规划的有效工具，能够提供优化的组件配置方案，风能整合和磷酸铁锂电池选择可显著降低系统总成本。

Abstract: This paper presents a customized microgrid planning algorithm and tool, HyMGP, for remote sites in arid regions, which is formulated as a Mixed Integer Linear Programming (MILP) problem. HyMGP is compared with HOMER Pro to evaluate its performance in optimizing the sizing of microgrid components, including photovoltaic panels (PVs), vertical axis wind turbines (VAWTs), and battery energy storage systems (BESS), for remote and off-grid applications. The study focuses on a standalone microgrid in the Saudi Arabia, considering high solar irradiance, limited wind availability, and a constant load profile composed of continuous cathodic protection and daytime cooling. In the simulation environment, comparisons with HOMER solutions demonstrate the advantages of HyMGP, which provides optimal and more flexible solutions by allowing user-defined component specifications and strictly enforcing all constraints. Further analysis shows that incorporating wind turbines reduces the Net Present Cost (NPC) by decreasing the required PV and battery capacities. Increasing battery autonomy leads to a higher NPC in both PV-only and hybrid systems due to the need for larger storage. Finally, lithium iron phosphate (Li-ion LFP) batteries are found to be more cost effective than lead acid, offering lower NPCs due to their longer lifespan, deeper discharge capability, and fewer replacement cycles.

</details>


### [85] [Model Predictive Control of Thermo-Hydraulic Systems Using Primal Decomposition](https://arxiv.org/abs/2601.10189)
*Jonathan Vieth,Annika Eichler,Arne Speerforck*

Main category: eess.SY

TL;DR: 提出自动化框架生成基于控制容积模型的模型预测控制器，采用原始分解提升可扩展性，在地下加热系统验证


<details>
  <summary>Details</summary>
Motivation: 全球能源供应脱碳需要更高效的加热冷却系统，模型预测控制能提升系统运行效率，但依赖基于控制容积的准确模型

Method: 开发自动化框架包括时间离散化生成模型预测控制器，采用原始分解利用模型结构确保可扩展性

Result: 在地下加热系统上验证，处理不同状态数量，证明原始分解在可扩展性方面的优势

Conclusion: 提出的自动化框架结合原始分解能够有效生成可扩展的模型预测控制器，适用于基于控制容积的加热冷却系统

Abstract: Decarbonizing the global energy supply requires more efficient heating and cooling systems. Model predictive control enhances the operation of cooling and heating systems but depends on accurate system models, often based on control volumes. We present an automated framework including time discretization to generate model predictive controllers for such models. To ensure scalability, a primal decomposition exploiting the model structure is applied. The approach is validated on an underground heating system with varying numbers of states, demonstrating the primal decomposition's advantage regarding scalability.

</details>


### [86] [Single-Feed Circularly Polarized Super Realized Gain Antenna](https://arxiv.org/abs/2601.10292)
*Georgia Psychogiou,Donal P. Lynch,Spyridon N. Daskalakis,Manos M. Tentzeris,George Goussetis,Stylianos D. Asimonis*

Main category: eess.SY

TL;DR: 该论文提出了一种工作在3.5GHz的超增益圆极化条带交叉偶极子天线，通过强互耦实现超指向性，结构简单且低剖面。


<details>
  <summary>Details</summary>
Motivation: 研究旨在设计一种同时实现圆极化和超指向性的天线，结构简单且低剖面，适合集成到紧凑的sub-6GHz无线和传感平台中。

Method: 采用条带交叉偶极子天线结构，通过精心调整条带尺寸实现强单元间互耦，一个单元主动驱动，另一个单元被动加载电抗阻抗，优化设计以最大化左旋圆极化实现增益。

Result: 优化设计具有3.29-4.17GHz（23.75%）的50Ω阻抗带宽和3.43-3.57GHz（4%）的轴比带宽，在3.5GHz处实现6.1dB峰值实现增益（ka≈1.65）和1.4dB轴比。

Conclusion: 圆极化和超指向性可以在几何简单、低剖面（0.15λ）天线中同时实现，适合集成到紧凑的sub-6GHz无线和传感平台。

Abstract: This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and good impedance matching. The optimized design exhibits a 50 $Ω$ impedance bandwidth of 3.29 - 4.17 GHz (23.75%) and an axial-ratio bandwidth of 3.43 - 3.57 GHz (4%). At 3.5 GHz, the antenna achieves a peak realized gain of 6.1 dB ($ka \approx 1.65$), with an axial ratio of 1.4 dB. These results demonstrate that circular polarization and superdirectivity can be simultaneously realized in a geometrically simple, low-profile ($0.15λ$) antenna, rendering it suitable for integration into compact sub-6~GHz wireless and sensing platforms.

</details>


### [87] [Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter](https://arxiv.org/abs/2601.10671)
*Trager Joswig-Jones,Baosen Zhang*

Main category: eess.SY

TL;DR: 提出一种直接考虑硬件约束的逆变器控制框架，使用安全轨迹梯度流控制器确保状态保持在约束范围内并收敛到最优平衡点。


<details>
  <summary>Details</summary>
Motivation: 现有并网逆变器控制方法通常在控制器设计时忽略硬件约束（如电流幅值限制），依赖临时限幅器可能导致不稳定或性能下降。需要直接考虑约束的控制框架。

Method: 提出安全轨迹梯度流控制器，将安全梯度流方法应用于滚动时域轨迹优化问题，确保状态保持在约束定义的安全集内，同时引导轨迹趋向非线性规划的最优平衡点。

Result: 仿真结果表明，该方法能够驱动模拟逆变器系统输出达到最优值并维持状态约束，即使在每个控制周期使用有限优化步数的情况下也能实现。

Conclusion: 提出的控制框架成功将约束直接纳入电压源逆变器控制，通过安全轨迹梯度流方法实现了约束满足和最优性能，为并网逆变器控制提供了更可靠的方法。

Abstract: Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control framework that directly incorporates constraints into the control of a voltage-source inverter. We propose a safe trajectory gradient flow controller, which applies the safe gradient flow method to a rolling horizon trajectory optimization problem to ensure that the states remain within a safe set defined by the constraints while directing the trajectory towards an optimal equilibrium point of a nonlinear program. Simulation results demonstrate that our approach can drive the outputs of a simulated inverter system to optimal values and maintain state constraints, even when using a limited number of optimization steps per control cycle.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [88] [A continuous-time Kyle model with price-responsive traders](https://arxiv.org/abs/2601.09872)
*Eunjung Noh*

Main category: q-fin.MF

TL;DR: 在Kyle模型中引入价格响应型交易者（动量与反向交易者），研究反馈效应对市场均衡、价格发现和知情交易者利润的影响


<details>
  <summary>Details</summary>
Motivation: 传统Kyle模型将噪声交易视为完全外生，但现实中许多市场参与者会对价格变动和新闻做出反应，产生反馈效应，这会显著改变市场动态

Method: 建立连续时间Kyle框架，引入两类价格响应型交易者（动量交易者和反向交易者），他们根据价格信号调整需求，得到有限维卡尔曼滤波用于价格发现，并通过前向-后向Riccati系统刻画均衡

Result: 弱反馈时均衡存在且唯一，是经典Kyle解的平滑扰动，可推导知情交易者利润和价格信息性的显式比较静态；强反馈时模型产生丰富动态，包括潜在多重均衡和放大效应

Conclusion: 该框架填补了纯粹外生噪声与更现实、行为动机驱动的交易之间的空白，为理解市场反馈机制提供了理论工具

Abstract: Classical Kyle-type models of informed trading typically treat noise trader demand as purely exogenous. In reality, many market participants react to price movements and news, generating feedback effects that can significantly alter market dynamics. This paper develops a continuous-time Kyle framework in which two types of price-responsive traders (momentum and contrarian traders) adjust their demand in response to price signals. This extension yields a finite-dimensional Kalman filter for price discovery and leads to a forward-backward Riccati system characterizing equilibrium. We show that when feedback is weak, equilibrium exists and is unique as a smooth perturbation of the classical Kyle solution, allowing us to derive explicit comparative statics for insider profits and price informativeness. For stronger feedback, the model generates rich dynamics, including potential multiplicity of equilibria and amplification effects. Our framework thus bridges the gap between purely exogenous noise and more realistic, behaviorally motivated trading.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [89] [Accelerated Regularized Wasserstein Proximal Sampling Algorithms](https://arxiv.org/abs/2601.09848)
*Hong Ye Tan,Stanley Osher,Wuchen Li*

Main category: stat.ML

TL;DR: 提出加速正则化Wasserstein近端方法(ARWP)，通过二阶得分ODE加速粒子采样，相比传统方法在混合速率和尾部探索方面表现更好


<details>
  <summary>Details</summary>
Motivation: 传统基于布朗运动的Gibbs分布采样方法效率有限，需要开发更快的采样算法，特别是对于非对数凹分布和多模态分布

Method: 使用二阶得分ODE（类似Nesterov加速）替代布朗运动，结合正则化Wasserstein近端方法进行得分估计，提出ARWP算法

Result: ARWP在渐近时间区域比动能Langevin采样具有更高的收缩率，在多模态高斯混合和病态Rosenbrock分布中表现出结构化和收敛的粒子，加速离散时间混合，更快尾部探索，在非对数凹贝叶斯神经网络任务中具有更好的泛化特性

Conclusion: ARWP是一种有效的加速采样方法，在多种分布类型中优于传统方法，特别适用于复杂非凸优化问题

Abstract: We consider sampling from a Gibbs distribution by evolving a finite number of particles using a particular score estimator rather than Brownian motion. To accelerate the particles, we consider a second-order score-based ODE, similar to Nesterov acceleration. In contrast to traditional kernel density score estimation, we use the recently proposed regularized Wasserstein proximal method, yielding the Accelerated Regularized Wasserstein Proximal method (ARWP). We provide a detailed analysis of continuous- and discrete-time non-asymptotic and asymptotic mixing rates for Gaussian initial and target distributions, using techniques from Euclidean acceleration and accelerated information gradients. Compared with the kinetic Langevin sampling algorithm, the proposed algorithm exhibits a higher contraction rate in the asymptotic time regime. Numerical experiments are conducted across various low-dimensional experiments, including multi-modal Gaussian mixtures and ill-conditioned Rosenbrock distributions. ARWP exhibits structured and convergent particles, accelerated discrete-time mixing, and faster tail exploration than the non-accelerated regularized Wasserstein proximal method and kinetic Langevin methods. Additionally, ARWP particles exhibit better generalization properties for some non-log-concave Bayesian neural network tasks.

</details>


### [90] [CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation with Smart Meter Data](https://arxiv.org/abs/2601.10494)
*Luke W. Yerbury,Ricardo J. G. B. Campello,G. C. Livingston,Mark Goldsworthy,Lachlan O'Neil*

Main category: stat.ML

TL;DR: CROCS是一个两阶段聚类框架，用于智能电表数据中的消费者行为细分，通过代表性负荷集和加权最小距离和来捕捉消费者内部变异性和行为相似性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源集成和电气化带来的不确定性增加，需求侧管理（特别是需求响应）成为平衡电力系统的关键。现有基于聚类的消费者细分方法无法充分反映消费者行为多样性，对时间对齐要求严格，且在异常值、缺失数据或大规模部署时表现不佳。

Method: 提出CROCS两阶段聚类框架：第一阶段对每个消费者的日负荷曲线独立聚类，形成代表性负荷集（RLS），总结其典型日消费行为；第二阶段使用加权最小距离和（WSMD）这一新颖的集合间度量来比较RLS，考虑行为的普遍性和相似性；最后在WSMD诱导图上进行社区检测，揭示定义消费者群体的共享日行为原型。

Result: 在合成和真实澳大利亚智能电表数据集上的实验表明，CROCS能够捕捉消费者内部变异性，发现同步和异步行为相似性，对异常值和缺失数据保持鲁棒性，并通过自然并行化实现高效扩展。

Conclusion: CROCS框架为智能电表数据驱动的消费者细分提供了更有效的方法，能够更好地支持需求侧管理和需求响应项目的设计，解决了现有方法在行为多样性、时间对齐和鲁棒性方面的局限性。

Abstract: With grid operators confronting rising uncertainty from renewable integration and a broader push toward electrification, Demand-Side Management (DSM) -- particularly Demand Response (DR) -- has attracted significant attention as a cost-effective mechanism for balancing modern electricity systems. Unprecedented volumes of consumption data from a continuing global deployment of smart meters enable consumer segmentation based on real usage behaviours, promising to inform the design of more effective DSM and DR programs. However, existing clustering-based segmentation methods insufficiently reflect the behavioural diversity of consumers, often relying on rigid temporal alignment, and faltering in the presence of anomalies, missing data, or large-scale deployments.
  To address these challenges, we propose a novel two-stage clustering framework -- Clustered Representations Optimising Consumer Segmentation (CROCS). In the first stage, each consumer's daily load profiles are clustered independently to form a Representative Load Set (RLS), providing a compact summary of their typical diurnal consumption behaviours. In the second stage, consumers are clustered using the Weighted Sum of Minimum Distances (WSMD), a novel set-to-set measure that compares RLSs by accounting for both the prevalence and similarity of those behaviours. Finally, community detection on the WSMD-induced graph reveals higher-order prototypes that embody the shared diurnal behaviours defining consumer groups, enhancing the interpretability of the resulting clusters.
  Extensive experiments on both synthetic and real Australian smart meter datasets demonstrate that CROCS captures intra-consumer variability, uncovers both synchronous and asynchronous behavioural similarities, and remains robust to anomalies and missing data, while scaling efficiently through natural parallelisation. These results...

</details>


### [91] [Coarsening Causal DAG Models](https://arxiv.org/abs/2601.10531)
*Francisco Madaleno,Pratik Misra,Alex Markham*

Main category: stat.ML

TL;DR: 提出了一种学习抽象因果图的新方法，包含图形可识别性结果、高效算法和理论洞察


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，估计特定粒度特征的因果模型往往不切实际或不可取，需要因果抽象方法来处理不同实验设置下的数据

Method: 提供新的图形可识别性结果，提出高效且一致性的算法直接从干预数据中学习抽象因果图，并揭示搜索空间的格结构理论洞察

Result: 在合成和真实数据集（包括具有已知真实值的受控物理系统）上验证了算法的有效性

Conclusion: 该研究为因果抽象领域做出了贡献，提供了实用的图形识别工具、高效算法和理论框架，有助于更广泛地理解因果发现

Abstract: Directed acyclic graphical (DAG) models are a powerful tool for representing causal relationships among jointly distributed random variables, especially concerning data from across different experimental settings. However, it is not always practical or desirable to estimate a causal model at the granularity of given features in a particular dataset. There is a growing body of research on causal abstraction to address such problems. We contribute to this line of research by (i) providing novel graphical identifiability results for practically-relevant interventional settings, (ii) proposing an efficient, provably consistent algorithm for directly learning abstract causal graphs from interventional data with unknown intervention targets, and (iii) uncovering theoretical insights about the lattice structure of the underlying search space, with connections to the field of causal discovery more generally. As proof of concept, we apply our algorithm on synthetic and real datasets with known ground truths, including measurements from a controlled physical system with interacting light intensity and polarization.

</details>


### [92] [Parametric RDT approach to computational gap of symmetric binary perceptron](https://arxiv.org/abs/2601.10628)
*Mihailo Stojnic*

Main category: stat.ML

TL;DR: 使用完全提升随机对偶理论分析对称二元感知机，发现二阶提升与七阶提升分别对应可满足性阈值α_c≈1.8159和算法阈值α_a≈1.6021，表明存在统计计算间隙SCG=α_c-α_a≈0.2138。


<details>
  <summary>Details</summary>
Motivation: 研究对称二元感知机中是否存在统计计算间隙，即理论可满足性阈值与算法可实现阈值之间的差距，这是理解计算复杂性的重要问题。

Method: 采用完全提升随机对偶理论，通过参数化分析c序列的结构变化，在不同提升层级上估计可满足性阈值α_c和算法阈值α_a。

Result: 在二阶提升层级得到α_c≈1.8159，在七阶提升层级得到α_a≈1.6021（有向约1.59收敛的趋势），表明存在非零统计计算间隙。结果与近期文献中的局部熵方法、重叠间隙性质预测一致。

Conclusion: 对称二元感知机中存在统计计算间隙，二阶提升对应理论可满足性阈值，高阶提升对应算法可实现阈值。这一现象与不对称二元感知机和负Hopfield模型中的观察相似，设计的CLuP算法性能与理论预测吻合。

Abstract: We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) -- \emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=α_c-α_a$. The second level estimate is shown to match the theoretical $α_c$ whereas the $r\rightarrow \infty$ level one is proposed to correspond to $α_a$. For example, for the canonical SBP ($κ=1$ margin) we obtain $α_c\approx 1.8159$ on the second and $α_a\approx 1.6021$ (with converging tendency towards $\sim 1.59$ range) on the seventh level. Our propositions remarkably well concur with recent literature: (i) in [20] local entropy replica approach predicts $α_{LE}\approx 1.58$ as the onset of clustering defragmentation (presumed driving force behind locally improving algorithms failures); (ii) in $α\rightarrow 0$ regime we obtain on the third lifting level $κ\approx 1.2385\sqrt{\frac{α_a}{-\log\left ( α_a \right ) }}$ which qualitatively matches overlap gap property (OGP) based predictions of [43] and identically matches local entropy based predictions of [24]; (iii) $c$-sequence ordering change phenomenology mirrors the one observed in asymmetric binary perceptron (ABP) in [98] and the negative Hopfield model in [100]; and (iv) as in [98,100], we here design a CLuP based algorithm whose practical performance closely matches proposed theoretical predictions.

</details>


### [93] [Classification Imbalance as Transfer Learning](https://arxiv.org/abs/2601.10630)
*Eric Xia,Jason M. Klusowski*

Main category: stat.ML

TL;DR: 该论文将类别不平衡问题重新定义为标签偏移下的迁移学习，分析比较了SMOTE和自助法（随机过采样）等过采样方法，发现在中等高维情况下自助法的迁移成本更低，性能更好。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡问题在实际应用中普遍存在，传统方法如SMOTE被广泛使用但缺乏理论分析。作者希望从迁移学习角度理解过采样方法的理论性质，为选择不平衡分类的数据增强策略提供指导。

Method: 将类别不平衡问题框架化为标签偏移下的迁移学习：将观测数据的不平衡分布视为源分布，将评估性能的平衡分布视为目标分布。分析过采样方法（特别是SMOTE和自助法）的过剩风险分解，推导迁移成本项来量化估计分布与真实分布之间的差异。

Result: 理论分析表明，在中等高维情况下，SMOTE的迁移成本主导自助法的迁移成本，这意味着自助法通常比SMOTE具有更好的性能。实验结果也支持这一理论发现。

Conclusion: 从迁移学习角度分析类别不平衡问题为理解过采样方法提供了新视角。研究结果表明，在中等高维情况下，简单的自助法（随机过采样）可能比更复杂的SMOTE算法表现更好，这为选择不平衡分类的数据增强策略提供了理论指导。

Abstract: Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by generating synthetic samples from an estimated minority-class distribution to roughly balance the classes, among which the celebrated SMOTE algorithm is a canonical example. We show that the excess risk decomposes into the rate achievable under balanced training (as if the data had been drawn from the balanced target distribution) and an additional term, the cost of transfer, which quantifies the discrepancy between the estimated and true minority-class distributions. In particular, we show that the cost of transfer for SMOTE dominates that of bootstrapping (random oversampling) in moderately high dimensions, suggesting that we should expect bootstrapping to have better performance than SMOTE in general. We corroborate these findings with experimental evidence. More broadly, our results provide guidance for choosing among augmentation strategies for imbalanced classification.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [94] [Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity Recognition](https://arxiv.org/abs/2601.10043)
*Zhiming Lian*

Main category: q-fin.CP

TL;DR: 该论文通过指令微调和LoRA方法，在Llama 3 8B模型上实现了金融命名实体识别，在1693句语料上获得了0.894的micro-F1分数，优于多个基线模型。


<details>
  <summary>Details</summary>
Motivation: 金融命名实体识别是将非结构化报告和新闻转化为结构化知识图谱的重要方法，但现有免费易用的大型语言模型在区分组织与人物、识别货币金额等金融实体方面表现不佳。

Method: 采用Meta的Llama 3 8B模型，结合指令微调和低秩适应（LoRA）技术。将标注句子转换为指令-输入-输出三元组，通过微调小规模低秩矩阵而非更新所有权重来训练模型。

Result: 在1693句语料上获得了0.894的micro-F1分数，优于Qwen3-8B、Baichuan2-7B、T5和BERT-Base等基线模型。通过实体密度、学习曲线和评估指标可视化展示了模型性能。

Conclusion: 指令微调结合参数高效微调能够在领域敏感的命名实体识别任务上实现最先进的性能，为金融文本分析提供了有效的解决方案。

Abstract: Particularly, financial named-entity recognition (NER) is one of the many important approaches to translate unformatted reports and news into structured knowledge graphs. However, free, easy-to-use large language models (LLMs) often fail to differentiate organisations as people, or disregard an actual monetary amount entirely. This paper takes Meta's Llama 3 8B and applies it to financial NER by combining instruction fine-tuning and Low-Rank Adaptation (LoRA). Each annotated sentence is converted into an instruction-input-output triple, enabling the model to learn task descriptions while fine-tuning with small low-rank matrices instead of updating all weights. Using a corpus of 1,693 sentences, our method obtains a micro-F1 score of 0.894 compared with Qwen3-8B, Baichuan2-7B, T5, and BERT-Base. We present dataset statistics, describe training hyperparameters, and perform visualizations of entity density, learning curves, and evaluation metrics. Our results show that instruction tuning combined with parameter-efficient fine-tuning enables state-of-the-art performance on domain-sensitive NER.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [95] [Learning about Treatment Effects with Prior Studies: A Bayesian Model Averaging Approach](https://arxiv.org/abs/2601.09888)
*Frederico Finan,Demian Pouzo*

Main category: econ.EM

TL;DR: 提出一个结合先验信息的实验处理效应估计方法，通过贝叶斯模型平均(BMA)整合不确定外部有效性的先验源，在非标准渐近框架下分析收敛速率


<details>
  <summary>Details</summary>
Motivation: 实验研究中经常有先验信息源（如过往试验、相关研究、专家评估），但这些信息的外部有效性不确定。需要一种方法能有效利用这些信息，同时保证估计的稳健性

Method: 将每个先验源建模为高斯先验（均值和精度），使用贝叶斯模型平均(BMA)结合这些先验，让新实验数据更新后验权重。引入非标准渐近框架，其中先验精度随样本量增长

Result: 后验权重由外部有效性指数决定，该指数同时考虑偏差和信息量：有偏源被指数级降权，无偏源占主导。当至少有一个无偏源时，方法能收敛到无偏集且比仅用新数据更快收敛；当所有源都有偏时，加入保守（扩散）先验可恢复标准收敛速率

Conclusion: 提出的贝叶斯模型平均框架能有效利用不确定外部有效性的先验信息，在适当条件下可加速收敛，同时通过保守先验保证稳健性，为实验设计中的先验信息整合提供了理论保证

Abstract: We establish concentration rates for estimation of treatment effects in experiments that incorporate prior sources of information -- such as past pilots, related studies, or expert assessments -- whose external validity is uncertain. Each source is modeled as a Gaussian prior with its own mean and precision, and sources are combined using Bayesian model averaging (BMA), allowing data from the new experiment to update posterior weights. To capture empirically relevant settings in which prior studies may be as informative as the current experiment, we introduce a nonstandard asymptotic framework in which prior precisions grow with the experiment's sample size. In this regime, posterior weights are governed by an external-validity index that depends jointly on a source's bias and information content: biased sources are exponentially downweighted, while unbiased sources dominate. When at least one source is unbiased, our procedure concentrates on the unbiased set and achieves faster convergence than relying on new data alone. When all sources are biased, including a deliberately conservative (diffuse) prior guarantees robustness and recovers the standard convergence rate.

</details>


### [96] [Corrected Forecast Combinations](https://arxiv.org/abs/2601.09999)
*Chu-An Liu,Andrey L. Vasnev*

Main category: econ.EM

TL;DR: 提出校正预测组合方法，当原始组合预测误差存在序列相关时，通过添加前一期误差的分数来校正下一期预测，显著提升预测精度


<details>
  <summary>Details</summary>
Motivation: 基于Bates和Granger(1969)的经典例子，发现组合预测误差可能存在强自相关性，通过简单校正可以大幅提高预测精度，甚至超过原始组合带来的增益

Method: 在Gibbs和Vasnev(2024)的条件风险框架内形式化方法，将组合误差分解为可预测成分和创新项；通过GLS联合估计组合权重和误差协方差结构；使用美国专业预测者调查数据进行实证分析

Result: 对均值预测采用系数约0.5的简约校正通常是稳健起点，能显著改善预测精度；对最优权重预测，校正能大幅缓解预测组合难题，使表现不佳的最优权重组合变为有竞争力的预测

Conclusion: 当组合预测误差存在序列相关时，简单的校正方法能带来显著的预测精度提升，特别是对于最优权重组合，能有效解决预测组合难题

Abstract: This paper proposes corrected forecast combinations when the original combined forecast errors are serially dependent. Motivated by the classic Bates and Granger (1969) example, we show that combined forecast errors can be strongly autocorrelated and that a simple correction--adding a fraction of the previous combined error to the next-period combined forecast--can deliver sizable improvements in forecast accuracy, often exceeding the original gains from combining. We formalize the approach within the conditional risk framework of Gibbs and Vasnev (2024), in which the combined error decomposes into a predictable component (measurable at the forecast origin) and an innovation. We then link this correction to efficient estimation of combination weights under time-series dependence via GLS, allowing joint estimation of weights and an error-covariance structure. Using the U.S. Survey of Professional Forecasters for major macroeconomic indices across various subsamples (including pre and post-2000, GFC, and COVID), we find that a parsimonious correction of the mean forecast with a coefficient around 0.5 is a robust starting point and often yields material improvements in forecast accuracy. For optimal-weight forecasts, the correction substantially mitigates the forecast combination puzzle by turning poorly performing out-of-sample optimal-weight combinations into competitive forecasts.

</details>


### [97] [Selecting and Testing Asset Pricing Models: A Stepwise Approach](https://arxiv.org/abs/2601.10279)
*Guanhao Feng,Wei Lan,Hansheng Wang,Jun Zhang*

Main category: econ.EM

TL;DR: 提出一个因子模型选择和测试框架，通过选择能够跨越测试资产和所有候选因子联合有效前沿的最优模型，并在测试资产和未选候选因子上测试定价性能


<details>
  <summary>Details</summary>
Motivation: 现有资产定价文献强调最小化定价误差的因子模型，但忽略了未选候选因子可能提升测试资产性能的问题

Method: 提出框架：(1)选择跨越测试资产和所有候选因子联合有效前沿的最优模型；(2)在测试资产和未选候选因子上测试定价性能。通过资产定价对偶性确保模型选择一致性，从基准模型开始顺序添加或移除因子

Result: 实证证据显示，主流因子模型无法通过资产定价测试，而提出的8因子模型未被拒绝且表现出稳健的样本外性能

Conclusion: 该框架解决了传统因子模型忽略未选候选因子的问题，通过联合有效前沿选择和双重测试，提供了更全面的因子模型评估方法

Abstract: The asset pricing literature emphasizes factor models that minimize pricing errors but overlooks unselected candidate factors that could enhance the performance of test assets. This paper proposes a framework for factor model selection and testing by (i) selecting the optimal model that spans the joint efficient frontier of test assets and all candidate factors, and (ii) testing pricing performance on both test assets and unselected candidate factors. Our framework updates a baseline model (e.g., CAPM) sequentially by adding or removing factors based on asset pricing tests. Ensuring model selection consistency, our framework utilizes the asset pricing duality: minimizing cross-sectionally unexplained pricing errors aligns with maximizing the Sharpe ratio of the selected factor model. Empirical evidence shows that workhorse factor models fail asset pricing tests, whereas our proposed 8-factor model is not rejected and exhibits robust out-of-sample performance.

</details>


### [98] [Como medir o invisível? Guerras, pizzarias do Pentágono e o uso de variáveis proxy em econometria](https://arxiv.org/abs/2601.10352)
*Guilherme Vianna,Victor Rangel*

Main category: econ.EM

TL;DR: 本文研究如何应对回归分析中潜在变量的识别挑战，探讨代理变量在缓解遗漏变量偏误中的作用，并提出基于四个属性的实用评估框架。


<details>
  <summary>Details</summary>
Motivation: 许多经济相关变量（如风险、信心、不确定性）是潜在变量，无法直接观测，这给应用回归分析带来了识别挑战。遗漏这些潜在因素会导致遗漏变量偏误，需要有效的方法来应对这一问题。

Method: 区分完美代理变量和现实中的不完美代理变量，提出基于四个属性的实用评估协议：相关性、条件充分性、外生性和稳定性。使用阿灵顿微出行数据和美国地缘政治风险指数作为实证案例，通过协整分析和二元VEC模型将本地活动解释为地缘政治紧张潜在成分的高频信号。

Result: 完美代理变量可以完全消除遗漏变量偏误，而不完美代理变量只能部分缓解偏误，估计效应会衰减。提出的评估框架为实际应用中代理变量的选择提供了系统方法。

Conclusion: 代理变量是处理潜在变量识别问题的有效工具，但需要根据相关性、条件充分性、外生性和稳定性四个属性进行系统评估。实证研究表明，高频本地活动数据可以作为地缘政治紧张潜在成分的有效代理变量。

Abstract: Many economically relevant variables (risk, confidence, uncertainty) are latent and therefore not directly observable, which creates identification challenges in applied regressions. This text formalizes how omitting latent factors generates omitted-variable bias and discusses when including a proxy variable can mitigate it. We distinguish the case of a perfect proxy, which can eliminate the bias, from the more realistic case of an imperfect proxy, where residual bias remains and the estimated effect is attenuated. We propose a practical evaluation protocol based on four properties: relevance, conditional sufficiency, exogeneity, and stability. As an illustration, we use micromobility data from Arlington together with the U.S. Geopolitical Risk Index, estimating cointegration and a bivariate VEC model to interpret local activity as a high-frequency signal of the latent component of geopolitical tension.

</details>


### [99] [Chasing Opportunity: Spillovers and Drivers of U.S. State Population Growth](https://arxiv.org/abs/2601.10444)
*Sebastian Kripfganz,Vasilis Sarafidis*

Main category: econ.EM

TL;DR: 该研究使用动态空间模型分析美国州人口增长的驱动因素和空间扩散，首次在空间计量经济学中结合内生变量、数据推断网络结构和普遍跨州依赖的统一估计框架。


<details>
  <summary>Details</summary>
Motivation: 研究美国州人口增长的驱动因素和空间扩散模式，解决传统空间计量方法中网络结构先验假设（如邻接或距离）的局限性，开发能够处理内生变量、数据推断网络和跨州依赖的统一估计框架。

Method: 使用动态空间模型分析49个州1965-2017年数据，从数据中恢复空间网络结构而非先验假设，结合允许异质性斜率和交互固定效应的IV估计器，提供具有内生变量、数据推断网络和普遍跨州依赖的灵活空间面板模型的一致估计和推断。

Result: 人口增长表现出广泛但异质性的条件收敛：约四分之三的州收敛，而一小部分高增长州轻微发散。核心驱动因素（便利设施、劳动收入、迁移摩擦）的效应在各种网络设定下稳定，而生产率效应仅在从数据估计网络时才显现。空间溢出效应显著，间接效应约占总影响的三分之一，扩散范围超出相邻州。

Conclusion: 该研究开发了空间计量经济学中首个结合内生变量、数据推断网络和普遍跨州依赖的统一估计框架，实证发现美国州人口增长存在异质性收敛模式，空间溢出效应显著且超越相邻关系，强调了从数据推断网络结构的重要性。

Abstract: We study the drivers and spatial diffusion of U.S. state population growth using a dynamic spatial model for 49 states, 1965-2017. Methodologically, we recover the spatial network structure from the data, rather than imposing it a priori via contiguity or distance, and combine this with an IV estimator that permits heterogeneous slopes and interactive fixed effects. This unified design delivers consistent estimation and inference in a flexible spatial panel model with endogenous regressors, a data-inferred network structure, and pervasive cross-state dependence. To our knowledge, it is the first estimation framework in spatial econometrics to combine all three elements within a single setting. Empirically, population growth exhibits broad yet heterogeneous conditional convergence: about three-quarters of states converge, while a small high-growth group mildly diverges. Effects of the core drivers, amenities, labour income, migration frictions, are stable across various network specifications. On the other hand, the productivity effect emerges only when the network is estimated from the data. Spatial spillovers are sizable, with indirect effects roughly one-third of total impacts, and diffusion extending beyond contiguous neighbours.

</details>


### [100] [Semiparametric inference for inequality measures under nonignorable nonresponse using callback data](https://arxiv.org/abs/2601.10501)
*Xinyu Wang,Chunlin Wang,Tao Yu,Pengfei Li*

Main category: econ.EM

TL;DR: 提出半参数方法，利用回访数据处理调查数据中的不可忽略无应答问题，估计不平等指标


<details>
  <summary>Details</summary>
Motivation: 家庭调查中常见的不可忽略无应答（应答概率依赖于未观测结果）会导致选择偏差和代表性缺失，使标准推断方法失效

Method: 利用重复联系尝试的回访数据，采用半参数模型（结果分布未指定），构建半参数全似然估计量，提出稳定的EM算法

Result: 建立了估计量的大样本性质，推导了显式渐近方差表达式，模拟显示能有效校正无应答偏差并接近基准效率

Conclusion: 该方法为不可忽略无应答下的不平等测量推断提供了有效工具，消费者支出调查应用显示了实际增益

Abstract: This paper develops semiparametric methods for estimation and inference of widely used inequality measures when survey data are subject to nonignorable nonresponse, a challenging setting in which response probabilities depend on the unobserved outcomes. Such nonresponse mechanisms are common in household surveys and invalidate standard inference procedures due to selection bias and lack of population representativeness. We address this problem by exploiting callback data from repeated contact attempts and adopting a semiparametric model that leaves the outcome distribution unspecified. We construct semiparametric full-likelihood estimators for the underlying distribution and the associated inequality measures, and establish their large-sample properties for a broad class of functionals, including quantiles, the Theil index, and the Gini index. Explicit asymptotic variance expressions are derived, enabling valid Wald-type inference under nonignorable nonresponse. To facilitate implementation, we propose a stable and computationally convenient expectation-maximization algorithm, whose steps either admit closed-form expressions or reduce to fitting a standard logistic regression model. Simulation studies demonstrate that the proposed procedures effectively correct nonresponse bias and achieve near-benchmark efficiency. An application to Consumer Expenditure Survey data illustrates the practical gains from incorporating callback information when making inference on inequality measures.

</details>


### [101] [causalfe: Causal Forests with Fixed Effects in Python](https://arxiv.org/abs/2601.10555)
*Harry Aytug*

Main category: econ.EM

TL;DR: CFFE（因果森林与固定效应）Python包，用于面板数据中异质性处理效应的估计，通过节点级残差化解决固定效应导致的虚假异质性


<details>
  <summary>Details</summary>
Motivation: 标准因果森林方法在处理面板数据时面临困难，因为单位和时间固定效应会导致处理效应估计中出现虚假异质性，需要专门的方法来解决这一问题

Method: CFFE方法通过在树构建过程中进行节点级残差化，在每个候选分割内而非全局地移除固定效应，从而更准确地估计异质性处理效应

Result: 通过模拟研究验证了该估计器在各种数据生成过程中的性能表现，证明了方法的有效性

Conclusion: causalfe包提供了一个有效的Python实现，能够准确估计面板数据中的异质性处理效应，解决了传统因果森林在面板数据中的局限性

Abstract: The causalfe package provides a Python implementation of Causal Forests with Fixed Effects (CFFE) for estimating heterogeneous treatment effects in panel data settings. Standard causal forest methods struggle with panel data because unit and time fixed effects induce spurious heterogeneity in treatment effect estimates. The CFFE approach addresses this by performing node-level residualization during tree construction, removing fixed effects within each candidate split rather than globally. This paper describes the methodology, documents the software interface, and demonstrates the package through simulation studies that validate the estimator's performance under various data generating processes.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [102] [Efficiency versus Robustness under Tail Misspecification: Importance Sampling and Moment-Based VaR Bracketing](https://arxiv.org/abs/2601.09927)
*Aditri*

Main category: q-fin.RM

TL;DR: 本文研究了在尾部模型误设下两种基于模拟的VaR估计方法（重要性抽样和离散矩匹配）的表现，发现重要性抽样在名义模型下方差低但在厚尾下会低估真实VaR，而离散矩匹配则能提供稳健的保守VaR边界。


<details>
  <summary>Details</summary>
Motivation: 高置信水平的VaR估计本质上是一个罕见事件问题，对尾部行为和模型误设特别敏感。需要评估不同VaR估计方法在模型误设下的表现，特别是当真实回报分布具有厚尾特征时。

Method: 1) 将名义模型（用于构建估计器）与真实数据生成过程（用于评估）分离；2) 使用广泛股票市场代理的日回报校准名义高斯模型；3) 用不同自由度的Student-t分布生成真实回报以模拟不同程度的厚尾；4) 通过高斯模型的指数倾斜实现重要性抽样，通过似然加权求根法估计VaR；5) 离散矩匹配通过对离散化损失分布施加有限数量的矩约束来构建确定性的VaR上下界。

Result: 结果显示了效率与稳健性之间的明确权衡：重要性抽样在名义模型下产生低方差VaR估计，但在厚尾回报下会系统性地低估真实VaR，偏差随着置信水平提高和尾部变厚而增加；离散矩匹配则产生保守的VaR边界，在尾部误设下保持稳健。

Conclusion: 当模型不确定性显著时，仅靠方差减少不足以进行可靠的尾部风险估计。离散矩匹配在模型误设下提供了更稳健的VaR估计方法，而重要性抽样虽然效率高但对模型假设敏感。

Abstract: Value-at-Risk (VaR) estimation at high confidence levels is inherently a rare-event problem and is particularly sensitive to tail behavior and model misspecification. This paper studies the performance of two simulation-based VaR estimation approaches, importance sampling and discrete moment matching, under controlled tail misspecification. The analysis separates the nominal model used for estimator construction from the true data-generating process used for evaluation, allowing the effects of heavy-tailed returns to be examined in a transparent and reproducible setting. Daily returns of a broad equity market proxy are used to calibrate a nominal Gaussian model, while true returns are generated from Student-t distributions with varying degrees of freedom to represent increasingly heavy tails. Importance sampling is implemented via exponential tilting of the Gaussian model, and VaR is estimated through likelihood-weighted root-finding. Discrete moment matching constructs deterministic lower and upper VaR bounds by enforcing a finite number of moment constraints on a discretized loss distribution. The results demonstrate a clear trade-off between efficiency and robustness. Importance sampling produces low-variance VaR estimates under the nominal model but systematically underestimates the true VaR under heavy-tailed returns, with bias increasing at higher confidence levels and for thicker tails. In contrast, discrete moment matching yields conservative VaR bracketing that remains robust under tail misspecification. These findings highlight that variance reduction alone is insufficient for reliable tail risk estimation when model uncertainty is significant.

</details>


### [103] [Dynamic reinsurance via martingale transport](https://arxiv.org/abs/2601.10375)
*Beatrice Acciaio,Brandon Garcia Flores,Antonio Marini,Gudmund Pammer*

Main category: q-fin.RM

TL;DR: 使用鞅最优输运技术解决动态再保险问题，控制终端盈余分布同时最小化分出风险的L2范数


<details>
  <summary>Details</summary>
Motivation: 保险公司需要在控制终端盈余分布的同时最小化分出风险，这在实际风险管理中具有重要意义

Method: 采用鞅最优输运技术，首先考虑匹配给定终端分布的情况，然后放松条件仅要求满足特定矩或风险约束

Result: 在适当假设下，问题存在类似于Bass鞅的可处理解

Conclusion: 鞅最优输运方法为动态再保险问题提供了有效的解决方案，能够处理终端分布匹配和约束放松两种情况

Abstract: We formulate a dynamic reinsurance problem in which the insurer seeks to control the terminal distribution of its surplus while minimizing the L2-norm of the ceded risk. Using techniques from martingale optimal transport, we show that, under suitable assumptions, the problem admits a tractable solution analogous to the Bass martingale. We first consider the case where the insurer wants to match a given terminal distribution of the surplus process, and then relax this condition by only requiring certain moment or risk-based constraints.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [104] [Social Determinants of Health Prediction for ICD-9 Code with Reasoning Models](https://arxiv.org/abs/2601.09709)
*Sharim Khan,Paul Landes,Adam Cross,Jimeng Sun*

Main category: cs.LG

TL;DR: 该研究探索使用推理模型和传统大语言模型在MIMIC-III数据集上进行医院入院多标签社会健康决定因素ICD-9代码分类，利用现有ICD-9代码预测入院情况，达到89% F1分数。


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素与患者预后相关，但很少在结构化数据中捕获。虽然大语言模型在从句子中识别SDoH标签方面表现良好，但在大型入院或纵向笔记中进行预测存在长距离依赖的挑战。

Method: 在MIMIC-III数据集上使用推理模型和传统大语言模型进行医院入院多标签SDoH ICD-9代码分类，利用现有ICD-9代码进行入院预测。

Result: 达到了89%的F1分数，发现了139个入院记录中缺失的SDoH代码，并提供了可复现结果的代码。

Conclusion: 该方法能够有效从临床文本中提取社会健康决定因素信息，补充诊断系统对患者社会环境的了解，为临床决策提供支持。

Abstract: Social Determinants of Health correlate with patient outcomes but are rarely captured in structured data. Recent attention has been given to automatically extracting these markers from clinical text to supplement diagnostic systems with knowledge of patients' social circumstances. Large language models demonstrate strong performance in identifying Social Determinants of Health labels from sentences. However, prediction in large admissions or longitudinal notes is challenging given long distance dependencies. In this paper, we explore hospital admission multi-label Social Determinants of Health ICD-9 code classification on the MIMIC-III dataset using reasoning models and traditional large language models. We exploit existing ICD-9 codes for prediction on admissions, which achieved an 89% F1. Our contributions include our findings, missing SDoH codes in 139 admissions, and code to reproduce the results.

</details>


### [105] [ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition](https://arxiv.org/abs/2601.10591)
*Arundeep Chinta,Lucas Vinh Tran,Jay Katukuri*

Main category: cs.LG

TL;DR: 论文提出ProbFM，一个基于深度证据回归的Transformer概率框架，首次为时间序列基础模型提供理论基础的、可分解的不确定性量化方法，在金融预测中实现竞争性精度和不确定性分解。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列基础模型在金融零样本预测中表现出色，但缺乏理论基础的、可分解的不确定性量化方法。现有方法要么依赖限制性分布假设，要么混淆不同不确定性来源，或缺乏校准机制，阻碍了其在金融应用中的采用。

Method: 提出ProbFM（概率基础模型），一个基于Transformer的概率框架，利用深度证据回归提供理论基础的不确定性量化，并实现明确的认知-偶然不确定性分解。该方法通过高阶证据学习最优不确定性表示，同时保持单次计算效率。

Result: 在加密货币回报预测评估中，深度证据回归方法在保持竞争性预测精度的同时，提供了明确的认知-偶然不确定性分解。通过使用一致的LSTM架构对五种概率方法进行控制比较研究，验证了DER方法的有效性。

Conclusion: 这项工作为时间序列基础模型中的理论基础不确定性量化建立了可扩展框架，并为深度证据回归在金融应用中的有效性提供了实证证据，解决了当前不确定性量化方法的根本局限性。

Abstract: Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.

</details>


### [106] [The Geometry of Thought: Disclosing the Transformer as a Tropical Polynomial Circuit](https://arxiv.org/abs/2601.09775)
*Faruk Alpay,Bilge Senturk*

Main category: cs.LG

TL;DR: Transformer的自注意力机制在高温极限下等价于热带半环中的矩阵乘法，揭示了其前向传播本质上是基于token相似度图的动态规划路径搜索算法。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer自注意力机制的数学本质，特别是在高温极限（β→∞）下的行为，以理解其计算过程的内在几何结构。

Method: 通过数学证明，将softmax注意力在高温极限下转化为热带半环（max-plus代数）中的矩阵乘法，并建立与动态规划（Bellman-Ford算法）的等价关系。

Result: 证明了Transformer自注意力在高温极限下等价于热带矩阵乘积，其前向传播执行的是基于token相似度图的动态规划路径搜索算法。

Conclusion: Transformer的思维链推理可以从几何角度理解为网络内部执行的最短路径（或最长路径）算法，这为理解其推理机制提供了新的理论视角。

Abstract: We prove that the Transformer self-attention mechanism in the high-confidence regime ($β\to \infty$, where $β$ is an inverse temperature) operates in the tropical semiring (max-plus algebra). In particular, we show that taking the tropical limit of the softmax attention converts it into a tropical matrix product. This reveals that the Transformer's forward pass is effectively executing a dynamic programming recurrence (specifically, a Bellman-Ford path-finding update) on a latent graph defined by token similarities. Our theoretical result provides a new geometric perspective for chain-of-thought reasoning: it emerges from an inherent shortest-path (or longest-path) algorithm being carried out within the network's computation.

</details>


### [107] [TimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models](https://arxiv.org/abs/2601.09776)
*Khalid Oublal,Quentin Bouniot,Qi Gan,Stephan Clémençon,Zeynep Akata*

Main category: cs.LG

TL;DR: TimeSAE：基于稀疏自编码器和因果关系的时序黑盒模型解释框架，提供更忠实和鲁棒的解释


<details>
  <summary>Details</summary>
Motivation: 随着黑盒模型和预训练模型在时序应用中的普及，理解其预测变得至关重要，尤其是在高风险领域。现有方法大多只关注分布内解释，无法泛化到训练支持之外，缺乏泛化能力。

Method: 基于稀疏自编码器概念，提出TimeSAE框架，结合因果关系视角来解释时序黑盒模型。通过稀疏自编码器学习可解释的表示，并考虑因果结构来提高解释的鲁棒性。

Result: 在合成和真实世界时序数据集上进行了广泛评估，与主流基线方法比较。定量指标和定性分析均表明TimeSAE提供更忠实和鲁棒的解释。

Conclusion: TimeSAE框架能够有效解决现有解释方法对分布偏移敏感的问题，为时序黑盒模型提供更可靠、泛化能力更强的解释，并发布了易于使用的TimeSAE-Lib代码库。

Abstract: As black box models and pretrained models gain traction in time series applications, understanding and explaining their predictions becomes increasingly vital, especially in high-stakes domains where interpretability and trust are essential. However, most of the existing methods involve only in-distribution explanation, and do not generalize outside the training support, which requires the learning capability of generalization. In this work, we aim to provide a framework to explain black-box models for time series data through the dual lenses of Sparse Autoencoders (SAEs) and causality. We show that many current explanation methods are sensitive to distributional shifts, limiting their effectiveness in real-world scenarios. Building on the concept of Sparse Autoencoder, we introduce TimeSAE, a framework for black-box model explanation. We conduct extensive evaluations of TimeSAE on both synthetic and real-world time series datasets, comparing it to leading baselines. The results, supported by both quantitative metrics and qualitative insights, show that TimeSAE provides more faithful and robust explanations. Our code is available in an easy-to-use library TimeSAE-Lib: https://anonymous.4open.science/w/TimeSAE-571D/.

</details>


### [108] [QFed: Parameter-Compact Quantum-Classical Federated Learning](https://arxiv.org/abs/2601.09809)
*Samar Abdelghani,Soumaya Cherkaoui*

Main category: cs.LG

TL;DR: QFed量子联邦学习框架通过量子辅助技术将VGG类模型的参数量减少77.6%，同时保持与经典方法相当的准确率，提升了边缘设备的计算效率。


<details>
  <summary>Details</summary>
Motivation: 医疗、金融、科研等领域需要在保护数据隐私和遵守法规的前提下，从分布式数据中提取集体智能。联邦学习虽然能实现不共享原始数据的协作建模，但面临统计异质性、系统多样性和复杂模型计算负担等挑战。

Method: 提出QFed量子联邦学习框架，利用量子计算辅助技术，通过多对数因子减少经典模型的参数数量，从而降低训练开销。在FashionMNIST数据集上评估该框架，使用VGG类模型进行实验。

Result: 实验结果显示，QFed在可扩展环境中实现了VGG类模型参数数量77.6%的减少，同时保持了与经典方法相当的准确率。

Conclusion: 量子计算与联邦学习的结合有潜力增强边缘设备的联邦学习能力，通过减少参数数量来提升计算效率，为解决联邦学习面临的挑战提供了新思路。

Abstract: Organizations and enterprises across domains such as healthcare, finance, and scientific research are increasingly required to extract collective intelligence from distributed, siloed datasets while adhering to strict privacy, regulatory, and sovereignty requirements. Federated Learning (FL) enables collaborative model building without sharing sensitive raw data, but faces growing challenges posed by statistical heterogeneity, system diversity, and the computational burden from complex models. This study examines the potential of quantum-assisted federated learning, which could cut the number of parameters in classical models by polylogarithmic factors and thus lessen training overhead. Accordingly, we introduce QFed, a quantum-enabled federated learning framework aimed at boosting computational efficiency across edge device networks. We evaluate the proposed framework using the widely adopted FashionMNIST dataset. Experimental results show that QFed achieves a 77.6% reduction in the parameter count of a VGG-like model while maintaining an accuracy comparable to classical approaches in a scalable environment. These results point to the potential of leveraging quantum computing within a federated learning context to strengthen FL capabilities of edge devices.

</details>


### [109] [Eluder dimension: localise it!](https://arxiv.org/abs/2601.09825)
*Alireza Bakhtiari,Alex Ayoub,Samuel Robertson,David Janz,Csaba Szepesvári*

Main category: cs.LG

TL;DR: 本文建立了广义线性模型类的eluder维度下界，表明标准eluder维度分析无法获得一阶遗憾界。为此引入了eluder维度的局部化方法，改进了伯努利多臂赌博机经典结果，并首次为有限时域强化学习任务提供了一阶遗憾界。


<details>
  <summary>Details</summary>
Motivation: 标准eluder维度分析无法获得一阶遗憾界，这限制了其在强化学习等任务中的应用。需要新的分析方法来突破这一限制。

Method: 引入了eluder维度的局部化方法，通过局部化处理来改进分析框架。

Result: 1) 建立了广义线性模型类的eluder维度下界；2) 改进了伯努利多臂赌博机的经典结果；3) 首次为有限时域强化学习任务提供了有界累积回报的一阶遗憾界。

Conclusion: eluder维度的局部化方法有效解决了标准分析无法获得一阶遗憾界的问题，为强化学习等任务提供了新的分析工具和理论保证。

Abstract: We establish a lower bound on the eluder dimension of generalised linear model classes, showing that standard eluder dimension-based analysis cannot lead to first-order regret bounds. To address this, we introduce a localisation method for the eluder dimension; our analysis immediately recovers and improves on classic results for Bernoulli bandits, and allows for the first genuine first-order bounds for finite-horizon reinforcement learning tasks with bounded cumulative returns.

</details>


### [110] [Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation](https://arxiv.org/abs/2601.10137)
*Ziyi Ding,Chenfei Ye-Hao,Zheyuan Wang,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: Tree-Query是一个树状结构的多专家LLM框架，将成对因果发现简化为关于后门路径、独立性、潜在混杂和因果方向的查询序列，提供可解释的判断和鲁棒性感知的置信度分数。


<details>
  <summary>Details</summary>
Motivation: 传统基于约束的方法（如PC、FCI）存在误差传播问题，而最近的LLM因果预测器往往表现为不透明、无置信度的黑盒。需要一种既能减少误差传播又能提供可解释判断的因果发现方法。

Method: 提出Tree-Query框架，将成对因果发现分解为关于后门路径、(不)依赖性、潜在混杂和因果方向的查询序列。采用树状结构和多专家LLM设计，提供可解释的判断和鲁棒性感知的置信度分数。

Result: 在基于Mooij等人和UCI因果图的数据无关基准测试中，Tree-Query在结构指标上优于直接LLM基线。饮食-体重案例研究展示了混杂因素筛选和稳定、高置信度的因果结论。理论保证支持四种成对关系的渐近可识别性。

Conclusion: Tree-Query提供了一种从LLM获取数据无关因果先验的原则性方法，可以补充下游数据驱动的因果发现，实现了可解释性和鲁棒性的平衡。

Abstract: Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96.

</details>


### [111] [A New Convergence Analysis of Plug-and-Play Proximal Gradient Descent Under Prior Mismatch](https://arxiv.org/abs/2601.09831)
*Guixian Xu,Jinglai Li,Junqi Tang*

Main category: cs.LG

TL;DR: 首次为数据分布不匹配情况下的PnP-PGD算法提供了收敛性理论证明


<details>
  <summary>Details</summary>
Motivation: 现有的PnP算法理论需要许多难以验证的限制性假设，且在先验分布不匹配（去噪器训练数据与推理任务数据分布不同）的情况下缺乏收敛性证明

Method: 提出了plug-and-play proximal gradient descent (PnP-PGD)在数据分布不匹配情况下的新收敛理论

Result: 首次证明了PnP-PGD在先验不匹配情况下的收敛性，并移除了现有理论中多个限制性且难以验证的假设

Conclusion: 该工作为PnP算法在更实际的数据分布不匹配场景中提供了理论保障，扩展了算法的适用范围

Abstract: In this work, we provide a new convergence theory for plug-and-play proximal gradient descent (PnP-PGD) under prior mismatch where the denoiser is trained on a different data distribution to the inference task at hand. To the best of our knowledge, this is the first convergence proof of PnP-PGD under prior mismatch. Compared with the existing theoretical results for PnP algorithms, our new results removed the need for several restrictive and unverifiable assumptions.

</details>


### [112] [Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching](https://arxiv.org/abs/2601.10418)
*Nadav Merlis*

Main category: cs.LG

TL;DR: 研究具有多步前瞻信息的表格强化学习，提出自适应批处理策略(ABPs)来优化利用前瞻信息，并设计了后悔最小化算法来学习最优ABP。


<details>
  <summary>Details</summary>
Motivation: 现有的前瞻信息处理方法（固定批处理策略和模型预测控制）存在局限性，需要更有效利用多步前瞻信息的方法。

Method: 提出自适应批处理策略(ABPs)，根据状态自适应地划分前瞻信息批次；推导了这些策略的最优贝尔曼方程；设计了乐观后悔最小化算法来学习未知环境中的最优ABP。

Result: 获得了阶最优的后悔界（最多相差前瞻视野ℓ的因子），ℓ通常可视为小常数，表明算法在理论上是有效的。

Conclusion: 自适应批处理策略(ABPs)能更有效地利用多步前瞻信息，提出的算法能在未知环境中学习最优ABP，后悔界接近最优。

Abstract: We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead in chunks of predefined sizes ('fixed batching policies'), and model predictive control. We first illustrate the problems with these two approaches and propose utilizing the lookahead in adaptive (state-dependent) batches; we refer to such policies as adaptive batching policies (ABPs). We derive the optimal Bellman equations for these strategies and design an optimistic regret-minimizing algorithm that enables learning the optimal ABP when interacting with unknown environments. Our regret bounds are order-optimal up to a potential factor of the lookahead horizon $\ell$, which can usually be considered a small constant.

</details>


### [113] [A pipeline for enabling path-specific causal fairness in observational health data](https://arxiv.org/abs/2601.09841)
*Aparajita Kashyap,Sara Matijevic,Noémie Elhadad,Steven A. Kushner,Shalmali Joshi*

Main category: cs.LG

TL;DR: 提出一个模型无关的流程，用于训练因果公平的机器学习模型，解决医疗保健中的直接和间接偏见问题


<details>
  <summary>Details</summary>
Motivation: 在医疗保健环境中部署机器学习模型时，需要确保模型不会复制或加剧现有的医疗偏见。现有的公平性定义很多，但作者关注路径特定的因果公平性，这能更好地考虑偏见发生的社会和医疗背景

Method: 将结构公平模型映射到观察性医疗保健设置中，创建一个通用的流程来训练因果公平模型。该流程明确考虑特定的医疗背景和差异来定义目标"公平"模型，并利用无公平约束训练的基础模型生成因果公平的下游预测

Result: 填补了两个主要空白：1)通过解耦直接和间接偏见来源，扩展了对"公平性-准确性"权衡的表征；2)展示了如何在已知社会和医疗差异的任务中，利用观察性健康数据训练的无公平约束基础模型生成因果公平的下游预测

Conclusion: 提出了一个模型无关的流程，用于训练因果公平的机器学习模型，能够解决医疗保健中的直接和间接偏见形式，为医疗AI的公平部署提供了实用方法

Abstract: When training machine learning (ML) models for potential deployment in a healthcare setting, it is essential to ensure that they do not replicate or exacerbate existing healthcare biases. Although many definitions of fairness exist, we focus on path-specific causal fairness, which allows us to better consider the social and medical contexts in which biases occur (e.g., direct discrimination by a clinician or model versus bias due to differential access to the healthcare system) and to characterize how these biases may appear in learned models. In this work, we map the structural fairness model to the observational healthcare setting and create a generalizable pipeline for training causally fair models. The pipeline explicitly considers specific healthcare context and disparities to define a target "fair" model. Our work fills two major gaps: first, we expand on characterizations of the "fairness-accuracy" tradeoff by detangling direct and indirect sources of bias and jointly presenting these fairness considerations alongside considerations of accuracy in the context of broadly known biases. Second, we demonstrate how a foundation model trained without fairness constraints on observational health data can be leveraged to generate causally fair downstream predictions in tasks with known social and medical disparities. This work presents a model-agnostic pipeline for training causally fair machine learning models that address both direct and indirect forms of healthcare bias.

</details>


### [114] [Advancing Model Refinement: Muon-Optimized Distillation and Quantization for LLM Deployment](https://arxiv.org/abs/2601.09865)
*Jacob Sander,Brian Jalaian,Venkat R. Dasari*

Main category: cs.LG

TL;DR: 提出一个集成框架，结合GPTQ量化、LoRA微调和数据蒸馏，显著减少LLM大小和复杂度，同时保持或提升任务特定性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在资源受限的边缘设备上部署面临计算、内存和能耗挑战，需要解决任务特定数据获取、性能微调和模型压缩三个关键问题

Method: 集成框架包含：GPTQ量化、低秩适应(LoRA)、专门的数据蒸馏过程、基于KL散度的知识蒸馏、贝叶斯超参数优化和Muon优化器

Result: 实现高达2倍内存压缩（如6GB模型减至3GB），在标准LLM基准测试中表现优于单独GPTQ量化，Muon优化器显著增强量化过程中微调模型的抗精度衰减能力

Conclusion: 该集成框架能有效解决LLM在边缘设备部署的资源限制问题，通过综合优化策略实现高效推理，为专业任务提供可行的解决方案

Abstract: Large Language Models (LLMs) enable advanced natural language processing but face deployment challenges on resource-constrained edge devices due to high computational, memory, and energy demands. Optimizing these models requires addressing three key challenges: acquiring task-specific data, fine-tuning for performance, and compressing models to accelerate inference while reducing resource demands. We propose an integrated framework combining GPTQ-based quantization, low-rank adaptation (LoRA), and a specialized data distillation process to significantly reduce model size and complexity while preserving or enhancing task-specific performance. By leveraging data distillation, knowledge distillation via Kullback-Leibler divergence, Bayesian hyperparameter optimization, and the Muon optimizer, our pipeline achieves up to 2x memory compression (e.g., reducing a 6GB model to 3GB) and enables efficient inference for specialized tasks. Empirical results demonstrate superior performance on standard LLM benchmarks compared to GPTQ quantization alone, with the Muon optimizer notably enhancing fine-tuned models' resistance to accuracy decay during quantization.

</details>


### [115] [The PROPER Approach to Proactivity: Benchmarking and Advancing Knowledge Gap Navigation](https://arxiv.org/abs/2601.09926)
*Kirandeep Kaur,Vinayak Gupta,Aditya Gupta,Chirag Shah*

Main category: cs.LG

TL;DR: ProPer是一个两智能体架构，通过生成用户未表达的隐性需求维度，实现个性化主动干预，相比传统被动式助手显著提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 当前语言助手主要采用被动问答模式，用户需要明确表达需求，导致相关但未表达的需求无法得到满足。现有主动代理要么需要用户进一步澄清（增加负担），要么从上下文推断未来需求（常导致不必要或时机不当的干预）。

Method: 提出ProPer两智能体架构：1) 维度生成智能体(DGA)：基于用户数据生成多个隐性维度（用户任务相关但未考虑的潜在方面）或知识缺口；2) 响应生成智能体(RGA)：平衡显性和隐性维度，生成个性化响应并进行及时主动干预。使用基于质量、多样性和任务相关性的重排序器筛选维度。

Result: 在多个领域评估显示，ProPer在所有领域都提高了质量分数和胜率，单轮评估中最高获得84%的提升，在多轮交互中持续占优。

Conclusion: ProPer通过两智能体架构有效识别和利用用户未表达的隐性需求，实现了更高质量的个性化主动干预，解决了传统被动助手的局限性。

Abstract: Most language-based assistants follow a reactive ask-and-respond paradigm, requiring users to explicitly state their needs. As a result, relevant but unexpressed needs often go unmet. Existing proactive agents attempt to address this gap either by eliciting further clarification, preserving this burden, or by extrapolating future needs from context, often leading to unnecessary or mistimed interventions. We introduce ProPer, Proactivity-driven Personalized agents, a novel two-agent architecture consisting of a Dimension Generating Agent (DGA) and a Response Generating Agent (RGA). DGA, a fine-tuned LLM agent, leverages explicit user data to generate multiple implicit dimensions (latent aspects relevant to the user's task but not considered by the user) or knowledge gaps. These dimensions are selectively filtered using a reranker based on quality, diversity, and task relevance. RGA then balances explicit and implicit dimensions to tailor personalized responses with timely and proactive interventions. We evaluate ProPer across multiple domains using a structured, gap-aware rubric that measures coverage, initiative appropriateness, and intent alignment. Our results show that ProPer improves quality scores and win rates across all domains, achieving up to 84% gains in single-turn evaluation and consistent dominance in multi-turn interactions.

</details>


### [116] [On the origin of neural scaling laws: from random graphs to natural language](https://arxiv.org/abs/2601.10684)
*Maissam Barkeshli,Alberto Alfarano,Andrey Gromov*

Main category: cs.LG

TL;DR: 该论文研究了神经网络缩放定律的起源，通过简化设置（图上的随机游走）和系统简化自然语言，证明缩放定律可以在数据相关性中不存在幂律结构的情况下出现，并对传统语言建模缩放定律进行了重新审视。


<details>
  <summary>Details</summary>
Motivation: 缩放定律在现代AI革命中发挥了重要作用，但对其起源的理解仍不充分。常见的假设是缩放定律源于数据中已有的幂律结构，但作者想探究在缺乏这种结构的情况下是否仍会出现缩放定律。

Method: 1) 在具有可调复杂度的图上训练transformer预测随机游走（二元语法）；2) 通过从简化生成语言模型（4层、2层、1层transformer语言模型到语言二元语法）采样序列，系统降低自然语言复杂度；3) 在Erdös-Renyi和Barabási-Albert随机图上训练随机游走；4) 使用2层transformer和50上下文长度重新审视传统语言建模缩放定律。

Result: 1) 即使在数据相关性中没有幂律结构的情况下，简化设置也会产生神经网络缩放定律；2) 缩放指数随着语言复杂度降低而单调演化；3) 传统缩放定律的许多关键结果可以用简化模型复现；4) 提供了对先前文献中各种拟合方法的批判性分析；5) 初步证据表明最大更新参数化可能比标准参数化更参数高效。

Conclusion: 缩放定律可以在没有数据幂律结构的情况下出现，表明其起源可能比通常假设的更基本。简化模型能够捕捉传统缩放定律的关键特征，为理解缩放行为提供了新视角，并提出了改进参数效率的方法。

Abstract: Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.

</details>


### [117] [Interpolation-Based Optimization for Enforcing lp-Norm Metric Differential Privacy in Continuous and Fine-Grained Domains](https://arxiv.org/abs/2601.09946)
*Chenxi Qiu*

Main category: cs.LG

TL;DR: 提出基于插值的框架优化lp-norm度量差分隐私，通过锚点优化和log-凸组合插值，在细粒度连续域中实现高效隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的方法在粗粒度域中能有效减少效用损失，但在细粒度或连续设置中优化度量差分隐私仍然具有挑战性，主要因为构建密集扰动矩阵的计算成本和满足逐点约束的困难。

Method: 提出插值框架：1) 在稀疏锚点集上优化扰动分布；2) 通过log-凸组合在非锚点位置插值分布，可证明保持度量差分隐私；3) 针对高维空间中朴素插值导致的隐私违规，将插值过程分解为一系列一维步骤，推导出强制lp-norm度量差分隐私的校正公式；4) 探索跨维度的扰动分布和隐私预算分配的联合优化。

Result: 在真实世界位置数据集上的实验表明，该方法在细粒度域中提供严格的隐私保证和具有竞争力的效用，优于基线机制。

Conclusion: 提出的插值框架成功解决了在细粒度和连续域中优化度量差分隐私的挑战，通过锚点优化和校正插值实现了计算效率和隐私保证的平衡，为高维空间中的隐私保护提供了有效解决方案。

Abstract: Metric Differential Privacy (mDP) generalizes Local Differential Privacy (LDP) by adapting privacy guarantees based on pairwise distances, enabling context-aware protection and improved utility. While existing optimization-based methods reduce utility loss effectively in coarse-grained domains, optimizing mDP in fine-grained or continuous settings remains challenging due to the computational cost of constructing dense perterubation matrices and satisfying pointwise constraints.
  In this paper, we propose an interpolation-based framework for optimizing lp-norm mDP in such domains. Our approach optimizes perturbation distributions at a sparse set of anchor points and interpolates distributions at non-anchor locations via log-convex combinations, which provably preserve mDP. To address privacy violations caused by naive interpolation in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms. in high-dimensional spaces, we decompose the interpolation process into a sequence of one-dimensional steps and derive a corrected formulation that enforces lp-norm mDP by design. We further explore joint optimization over perturbation distributions and privacy budget allocation across dimensions. Experiments on real-world location datasets demonstrate that our method offers rigorous privacy guarantees and competitive utility in fine-grained domains, outperforming baseline mechanisms.

</details>


### [118] [Kinematic Tokenization: Optimization-Based Continuous-Time Tokens for Learnable Decision Policies in Noisy Time Series](https://arxiv.org/abs/2601.09949)
*Griffin Kearney*

Main category: cs.LG

TL;DR: 论文提出Kinematic Tokenization方法，将连续时间信号通过样条重建表示为位置、速度、加速度等运动学系数，在金融时间序列中相比离散tokenization方法能保持稳定的策略学习。


<details>
  <summary>Details</summary>
Motivation: Transformer设计用于离散token，但现实世界信号是连续过程且存在噪声采样。离散tokenization方法（原始值、分块、有限差分）在低信噪比环境下脆弱，特别是当下游目标施加非对称惩罚时，理性策略会选择放弃预测。

Method: 提出Kinematic Tokenization方法：基于优化的连续时间表示，从噪声测量中重建显式样条，并将局部样条系数（位置、速度、加速度、加加速度）作为token。应用于金融时间序列数据（资产价格和交易量）。

Result: 在多资产日频股票测试中，使用风险厌恶的非对称分类目标作为可学习性压力测试。在此目标下，多个离散基线方法崩溃为吸收现金策略（清算均衡），而连续样条token能维持校准的非平凡动作分布和稳定策略。

Conclusion: 显式连续时间token可以改善在噪声时间序列中，在诱导放弃的损失函数下选择性决策策略的可学习性和校准性。

Abstract: Transformers are designed for discrete tokens, yet many real-world signals are continuous processes observed through noisy sampling. Discrete tokenizations (raw values, patches, finite differences) can be brittle in low signal-to-noise regimes, especially when downstream objectives impose asymmetric penalties that rationally encourage abstention. We introduce Kinematic Tokenization, an optimization-based continuous-time representation that reconstructs an explicit spline from noisy measurements and tokenizes local spline coefficients (position, velocity, acceleration, jerk). This is applied to financial time series data in the form of asset prices in conjunction with trading volume profiles. Across a multi-asset daily-equity testbed, we use a risk-averse asymmetric classification objective as a stress test for learnability. Under this objective, several discrete baselines collapse to an absorbing cash policy (the Liquidation Equilibrium), whereas the continuous spline tokens sustain calibrated, non-trivial action distributions and stable policies. These results suggest that explicit continuous-time tokens can improve the learnability and calibration of selective decision policies in noisy time series under abstention-inducing losses.

</details>


### [119] [A Sustainable AI Economy Needs Data Deals That Work for Generators](https://arxiv.org/abs/2601.09966)
*Ruoxi Jia,Luis Oala,Wenjie Xiong,Suqin Ge,Jiachen T. Wang,Feiyang Kang,Dawn Song*

Main category: cs.LG

TL;DR: 论文认为机器学习价值链在结构上不可持续，存在经济数据处理不平等：数据从输入到模型权重再到合成输出的每个阶段都增强了技术信号，但剥夺了数据生成者的经济权益。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习数据价值链存在结构性不平等，大多数价值被聚合者获取，而数据创作者获得的版税几乎为零，交易条款普遍不透明。这不仅影响经济福利，还威胁到维持当前学习算法的反馈循环。

Method: 分析了73个公开数据交易案例，识别出三个结构性缺陷：缺失溯源、不对称议价能力和非动态定价。提出了公平数据价值交换（EDVEX）框架来建立惠及所有参与者的最小市场。

Result: 研究发现大多数价值流向聚合者，创作者版税几乎为零，交易条款普遍不透明。识别出的三个结构性缺陷是造成这种不平等的主要机制。

Conclusion: 机器学习价值链存在结构性不可持续问题，需要建立公平的数据价值交换框架。论文提出了EDVEX框架，并指出了社区可以做出具体贡献的研究方向。

Abstract: We argue that the machine learning value chain is structurally unsustainable due to an economic data processing inequality: each state in the data cycle from inputs to model weights to synthetic outputs refines technical signal but strips economic equity from data generators. We show, by analyzing seventy-three public data deals, that the majority of value accrues to aggregators, with documented creator royalties rounding to zero and widespread opacity of deal terms. This is not just an economic welfare concern: as data and its derivatives become economic assets, the feedback loop that sustains current learning algorithms is at risk. We identify three structural faults - missing provenance, asymmetric bargaining power, and non-dynamic pricing - as the operational machinery of this inequality. In our analysis, we trace these problems along the machine learning value chain and propose an Equitable Data-Value Exchange (EDVEX) Framework to enable a minimal market that benefits all participants. Finally, we outline research directions where our community can make concrete contributions to data deals and contextualize our position with related and orthogonal viewpoints.

</details>


### [120] [Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers](https://arxiv.org/abs/2601.10274)
*Emre Ozbas,Melih Bastopcu*

Main category: cs.LG

TL;DR: LLM服务器为多任务类型查询优化token分配，平衡准确率与延迟，通过队列模型和优化算法找到最优分配方案


<details>
  <summary>Details</summary>
Motivation: 大型语言模型服务器需要同时处理多种任务类型的查询，不同任务需要不同的计算资源（token分配）。如何在有限的token预算下，平衡查询准确率和系统延迟，是一个重要的优化问题。

Method: 将系统建模为M/G/1队列，服务时间与分配的token数量相关。建立约束优化问题，最大化加权平均准确率并惩罚平均系统时间。使用严格凹函数性质保证最优解存在唯一，开发投影梯度法和迭代算法求解。

Result: 证明了目标函数在稳定区域内严格凹，确保最优解存在唯一。提出了耦合投影定点特征、迭代解法和收缩条件。开发了具有可计算全局步长界的投影梯度法，保证收敛性。通过舍入得到整数token分配，仿真评估性能损失。

Conclusion: 该研究为LLM服务器在多任务环境下的资源分配提供了理论框架和实用算法，能够在准确率和延迟之间实现最优权衡，并通过舍入方法获得实际可行的整数token分配方案。

Abstract: We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results.

</details>


### [121] [An Exploratory Study to Repurpose LLMs to a Unified Architecture for Time Series Classification](https://arxiv.org/abs/2601.09971)
*Hansen He,Shuheng Li*

Main category: cs.LG

TL;DR: 该论文探索了将专门的时间序列编码器与冻结的大型语言模型（LLM）主干结合的混合架构，发现Inception模型是唯一能持续带来性能提升的编码器架构。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究关注将大型语言模型（LLMs）用于时间序列分类（TSC），但现有工作主要集中在将时间序列数据映射到文本域的校准策略上，而时间序列编码器架构的选择尚未得到充分探索。

Method: 采用混合架构方法，将专门的时间序列编码器与冻结的LLM主干结合。评估了多种编码器家族，包括Inception、卷积、残差、基于Transformer和多层感知机等架构。

Result: 在所有评估的编码器架构中，Inception模型是唯一在与LLM主干集成时能持续带来积极性能提升的架构。

Conclusion: 时间序列编码器的选择对混合LLM架构有重要影响，基于Inception的模型是未来LLM驱动时间序列学习的有前景方向。

Abstract: Time series classification (TSC) is a core machine learning problem with broad applications. Recently there has been growing interest in repurposing large language models (LLMs) for TSC, motivated by their strong reasoning and generalization ability. Prior work has primarily focused on alignment strategies that explicitly map time series data into the textual domain; however, the choice of time series encoder architecture remains underexplored. In this work, we conduct an exploratory study of hybrid architectures that combine specialized time series encoders with a frozen LLM backbone. We evaluate a diverse set of encoder families, including Inception, convolutional, residual, transformer-based, and multilayer perceptron architectures, among which the Inception model is the only encoder architecture that consistently yields positive performance gains when integrated with an LLM backbone. Overall, this study highlights the impact of time series encoder choice in hybrid LLM architectures and points to Inception-based models as a promising direction for future LLM-driven time series learning.

</details>


### [122] [In-Context Operator Learning on the Space of Probability Measures](https://arxiv.org/abs/2601.09979)
*Frank Cole,Dixi Wang,Yineng Chen,Yulong Lu,Rongjie Lai*

Main category: cs.LG

TL;DR: 提出了一种基于概率测度空间的上下文算子学习方法，用于最优传输问题，通过少量样本作为提示学习映射分布对到OT映射的算子，无需推理时的梯度更新。


<details>
  <summary>Details</summary>
Motivation: 传统最优传输方法通常需要为每个新分布对重新计算，计算成本高。本文旨在学习一个通用的解决方案算子，能够仅通过少量样本作为上下文提示，直接预测OT映射，提高计算效率。

Method: 提出了上下文算子学习框架，参数化解算子。在非参数设置中，当任务集中在低内在维度的源-目标对流形上时，建立了泛化界限；在参数设置中（如高斯族），给出了显式架构来精确恢复上下文中的OT映射。

Result: 建立了泛化界限，量化了上下文准确度如何随提示大小、任务内在维度和模型容量扩展。在参数设置中，提供了有限样本超额风险界限。在合成传输和生成建模基准上的数值实验验证了该框架。

Conclusion: 本文提出了一个用于最优传输的上下文算子学习框架，能够在少量样本提示下预测OT映射，无需推理时梯度更新，为OT问题提供了高效、可扩展的解决方案。

Abstract: We introduce \emph{in-context operator learning on probability measure spaces} for optimal transport (OT). The goal is to learn a single solution operator that maps a pair of distributions to the OT map, using only few-shot samples from each distribution as a prompt and \emph{without} gradient updates at inference. We parameterize the solution operator and develop scaling-law theory in two regimes. In the \emph{nonparametric} setting, when tasks concentrate on a low-intrinsic-dimension manifold of source--target pairs, we establish generalization bounds that quantify how in-context accuracy scales with prompt size, intrinsic task dimension, and model capacity. In the \emph{parametric} setting (e.g., Gaussian families), we give an explicit architecture that recovers the exact OT map in context and provide finite-sample excess-risk bounds. Our numerical experiments on synthetic transports and generative-modeling benchmarks validate the framework.

</details>


### [123] [Combinatorial Optimization Augmented Machine Learning](https://arxiv.org/abs/2601.10583)
*Maximilian Schiffer,Heiko Hoppe,Yue Su,Louis Bouvier,Axel Parmentier*

Main category: cs.LG

TL;DR: COAML综述：将组合优化与机器学习结合的新兴领域，通过嵌入组合优化器构建数据驱动且保持可行性的策略，涵盖静态/动态问题、模仿学习、强化学习等应用。


<details>
  <summary>Details</summary>
Motivation: 组合优化增强机器学习（COAML）作为新兴范式，旨在整合预测模型与组合决策，构建既数据驱动又保持可行性的策略，弥合机器学习、运筹学和随机优化之间的传统鸿沟。

Method: 提出统一的COAML流程框架，描述方法构建模块，形式化其与经验成本最小化的联系；基于不确定性和决策结构形式建立问题设置分类法；回顾静态和动态问题的算法方法。

Result: 系统综述了COAML在调度、车辆路径、随机规划、强化学习等领域的应用，从经验成本最小化、模仿学习和强化学习角度综合方法贡献，并识别关键研究前沿。

Conclusion: 本文提供了COAML领域的全面概述，既可作为该领域的教程介绍，也可作为组合优化与机器学习交叉领域未来研究的路线图，推动这一新兴范式的发展。

Abstract: Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operations research, and stochastic optimization. This paper provides a comprehensive overview of the state of the art in COAML. We introduce a unifying framework for COAML pipelines, describe their methodological building blocks, and formalize their connection to empirical cost minimization. We then develop a taxonomy of problem settings based on the form of uncertainty and decision structure. Using this taxonomy, we review algorithmic approaches for static and dynamic problems, survey applications across domains such as scheduling, vehicle routing, stochastic programming, and reinforcement learning, and synthesize methodological contributions in terms of empirical cost minimization, imitation learning, and reinforcement learning. Finally, we identify key research frontiers. This survey aims to serve both as a tutorial introduction to the field and as a roadmap for future research at the interface of combinatorial optimization and machine learning.

</details>


### [124] [FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems](https://arxiv.org/abs/2601.09985)
*Tianqi Zhang,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: FaTRQ是一个面向远内存感知的近似最近邻搜索精炼系统，通过分层内存消除从存储中获取完整向量的需求，使用渐进距离估计器和分层残差量化，显著提升存储效率和查询吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现代ANNS引擎虽然使用预建索引和向量量化加速搜索，但仍依赖昂贵的二次精炼阶段，需要从慢速存储（如SSD）读取完整精度向量。对于现代文本和多模态嵌入，这些读取操作已成为整个查询延迟的主要瓶颈。

Method: 1) 提出渐进距离估计器，使用从远内存流式传输的紧凑残差来精炼粗略分数；2) 引入分层残差量化，将残差编码为三元值高效存储在远内存中；3) 在CXL Type-2设备中部署定制加速器，执行低延迟本地精炼。

Result: FaTRQ将存储效率提升2.4倍，相比最先进的GPU ANNS系统，吞吐量提升高达9倍。

Conclusion: FaTRQ通过消除从存储获取完整向量的需求，解决了ANNS精炼阶段的瓶颈问题，显著提升了检索增强生成（RAG）系统的性能和效率。

Abstract: Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed vector-quantized representations in fast memory. However, they still rely on a costly second-pass refinement stage that reads full-precision vectors from slower storage like SSDs. For modern text and multimodal embeddings, these reads now dominate the latency of the entire query. We propose FaTRQ, a far-memory-aware refinement system using tiered memory that eliminates the need to fetch full vectors from storage. It introduces a progressive distance estimator that refines coarse scores using compact residuals streamed from far memory. Refinement stops early once a candidate is provably outside the top-k. To support this, we propose tiered residual quantization, which encodes residuals as ternary values stored efficiently in far memory. A custom accelerator is deployed in a CXL Type-2 device to perform low-latency refinement locally. Together, FaTRQ improves the storage efficiency by 2.4$\times$ and improves the throughput by up to 9$ \times$ than SOTA GPU ANNS system.

</details>


### [125] [Continuous-Depth Transformers with Learned Control Dynamics](https://arxiv.org/abs/2601.10007)
*Peter Jemley*

Main category: cs.LG

TL;DR: 提出混合Transformer架构，用连续深度神经ODE块替代离散中间层，通过学习到的控制信号在推理时控制生成属性


<details>
  <summary>Details</summary>
Motivation: 标准Transformer通过固定离散层处理表示，无法在推理时灵活控制生成属性。需要一种能够将深度作为连续变量、通过控制信号实现可操纵生成的方法

Method: 使用神经ODE块替代Transformer的中间层，通过学习到的向量场F_θ(H, τ, u)控制深度连续变化，其中u是通过显式拼接注入的低维控制信号

Result: 梯度流稳定无爆炸/消失问题；情感控制准确率达98%/88%；连续插值轨迹差异仅0.068%；延迟与标准基准相当；控制信号将向量场划分为不同曲率特性的动态机制

Conclusion: 具有学习控制信号的连续深度动力学为可操纵语言生成提供了可行且高效的机制，伴随方法实现O(1)内存训练，自适应ODE求解器揭示了学习动力学中的几何结构

Abstract: We present a hybrid transformer architecture that replaces discrete middle layers with a continuous-depth Neural Ordinary Differential Equation (ODE) block, enabling inference-time control over generation attributes via a learned steering signal. Unlike standard transformers that process representations through fixed discrete layers, our approach treats depth as a continuous variable governed by a learned vector field $F_θ(H, τ, u)$, where $u$ is a low-dimensional control signal injected via explicit concatenation. We validate the architecture through four experiments: (1) gradient flow stability with zero exploding/vanishing gradient events, (2) semantic steering achieving 98\%/88\% accuracy for positive/negative sentiment control, (3) continuous interpolation validated by a negligible 0.068\% trajectory divergence between fixed and adaptive solvers, and (4) efficiency benchmarking demonstrating latency parity with standard discrete baselines. Additionally, we show that adaptive ODE solvers reveal geometric structure in the learned dynamics: the control signal partitions the vector field into distinct dynamical regimes with different curvature characteristics. The adjoint method enables $O(1)$ memory training regardless of integration depth. Our results demonstrate that continuous-depth dynamics with learned control signals provide a viable, efficient mechanism for steerable language generation.

</details>


### [126] [PID-Guided Partial Alignment for Multimodal Decentralized Federated Learning](https://arxiv.org/abs/2601.10012)
*Yanhang Shi,Xiaoyu Wang,Houwei Cao,Jian Li,Yong Liu*

Main category: cs.LG

TL;DR: PARSE：基于部分信息分解的多模态去中心化联邦学习框架，通过特征分裂和切片级对齐解决异构代理间的梯度冲突


<details>
  <summary>Details</summary>
Motivation: 多模态去中心化联邦学习面临挑战：代理在可用模态和模型架构上存在差异，需要在无中心协调的P2P网络中协作。传统多模态方法学习单一共享嵌入，在DFL中会导致单模态与多模态代理间的梯度错位，抑制异构共享和跨模态交互。

Method: PARSE框架将部分信息分解（PID）应用于无服务器设置。每个代理执行特征分裂，将潜在表示分解为冗余、独特和协同切片。通过切片级部分对齐实现异构代理间的P2P知识共享：仅交换具有对应模态的语义可共享分支。无需中心协调和梯度手术。

Result: 在基准测试和代理混合实验中，PARSE相比任务、模态和混合共享的DFL基线方法取得一致性能提升。对融合算子和分裂比例的消融研究以及定性可视化进一步证明了所提设计的效率和鲁棒性。

Conclusion: PARSE解决了单/多模态梯度冲突，克服了多模态DFL困境，同时保持与标准DFL约束的兼容性。通过部分信息分解和切片级对齐，实现了异构代理间的有效知识共享。

Abstract: Multimodal decentralized federated learning (DFL) is challenging because agents differ in available modalities and model architectures, yet must collaborate over peer-to-peer (P2P) networks without a central coordinator. Standard multimodal pipelines learn a single shared embedding across all modalities. In DFL, such a monolithic representation induces gradient misalignment between uni- and multimodal agents; as a result, it suppresses heterogeneous sharing and cross-modal interaction. We present PARSE, a multimodal DFL framework that operationalizes partial information decomposition (PID) in a server-free setting. Each agent performs feature fission to factorize its latent representation into redundant, unique, and synergistic slices. P2P knowledge sharing among heterogeneous agents is enabled by slice-level partial alignment: only semantically shareable branches are exchanged among agents that possess the corresponding modality. By removing the need for central coordination and gradient surgery, PARSE resolves uni-/multimodal gradient conflicts, thereby overcoming the multimodal DFL dilemma while remaining compatible with standard DFL constraints. Across benchmarks and agent mixes, PARSE yields consistent gains over task-, modality-, and hybrid-sharing DFL baselines. Ablations on fusion operators and split ratios, together with qualitative visualizations, further demonstrate the efficiency and robustness of the proposed design.

</details>


### [127] [CAFEDistill: Learning Personalized and Dynamic Models through Federated Early-Exit Network Distillation](https://arxiv.org/abs/2601.10015)
*Boyi Liu,Zimu Zhou,Yongxin Tong*

Main category: cs.LG

TL;DR: CAFEDistill是一个冲突感知的联邦退出蒸馏框架，将早期退出网络集成到个性化联邦学习中，通过深度优先的学生协调机制解决客户端异构性和深度间干扰问题，实现自适应推理。


<details>
  <summary>Details</summary>
Motivation: 现有PFL方法产生静态模型，在准确性和效率之间固定权衡，无法适应不同上下文和资源可用性的推理需求。早期退出网络提供自适应推理，但集成到PFL中面临客户端异构性和深度间目标冲突的挑战。

Method: 提出CAFEDistill框架，采用渐进式深度优先的学生协调机制，缓解浅层和深层退出之间的干扰，同时实现跨客户端的个性化知识转移。通过客户端解耦公式减少通信开销。

Result: CAFEDistill在广泛评估中优于现有方法，实现更高准确性，并将推理成本降低30.79%-46.86%。

Conclusion: CAFEDistill成功解决了PFL中集成早期退出网络的挑战，实现了自适应推理，平衡了准确性和效率，为资源受限环境提供了实用解决方案。

Abstract: Personalized Federated Learning (PFL) enables collaboratively model training on decentralized, heterogeneous data while tailoring them to each client's unique distribution. However, existing PFL methods produce static models with a fixed tradeoff between accuracy and efficiency, limiting their applicability in environments where inference requirements vary with contexts and resource availability. Early-exit networks (EENs) offer adaptive inference by attaching intermediate classifiers. Yet integrating them into PFL is challenging due to client-wise heterogeneity and depth-wise interference arising from conflicting exit objectives. Prior studies fail to resolve both conflicts simultaneously, leading to suboptimal performance. In this paper, we propose CAFEDistill, a Conflict-Aware Federated Exit Distillation framework that jointly addresses these conflicts and extends PFL to early-exit networks. Through a progressive, depth-prioritized student coordination mechanism, CAFEDistill mitigates interference among shallow and deep exits while allowing effective personalized knowledge transfer across clients. Furthermore, it reduces communication overhead via a client-decoupled formulation. Extensive evaluations show that CAFEDistill outperforms the state-of-the-arts, achieving higher accuracy and reducing inference costs by 30.79%-46.86%.

</details>


### [128] [Time Aggregation Features for XGBoost Models](https://arxiv.org/abs/2601.10019)
*Mykola Pinchuk*

Main category: cs.LG

TL;DR: 研究XGBoost模型在点击率预测中的时间聚合特征，比较不同时间窗口设计，发现简单的时间窗口效果最好


<details>
  <summary>Details</summary>
Motivation: 在点击率预测中，如何有效利用历史数据进行时间聚合特征工程，以提升模型性能

Method: 使用Avazu数据集，采用严格的时间外分割和无前瞻特征约束，比较时间感知目标编码基线与多种时间聚合窗口设计（包括时间窗口、事件计数窗口、间隔窗口和分桶窗口）

Result: 时间窗口相比单纯目标编码提升ROC AUC约0.0066-0.0082，PR AUC约0.0084-0.0094；事件计数窗口有轻微改进；间隔窗口和分桶窗口效果较差

Conclusion: 推荐使用时间窗口作为默认方法，当需要边际ROC AUC提升时可考虑事件计数窗口

Abstract: This paper studies time aggregation features for XGBoost models in click-through rate prediction. The setting is the Avazu click-through rate prediction dataset with strict out-of-time splits and a no-lookahead feature constraint. Features for hour H use only impressions from hours strictly before H. This paper compares a strong time-aware target encoding baseline to models augmented with entity history time aggregation under several window designs. Across two rolling-tail folds on a deterministic ten percent sample, a trailing window specification improves ROC AUC by about 0.0066 to 0.0082 and PR AUC by about 0.0084 to 0.0094 relative to target encoding alone. Within the time aggregation design grid, event count windows provide the only consistent improvement over trailing windows, and the gain is small. Gap windows and bucketized windows underperform simple trailing windows in this dataset and protocol. These results support a practical default of trailing windows, with an optional event count window when marginal ROC AUC gains matter.

</details>


### [129] [BPE: Behavioral Profiling Ensemble](https://arxiv.org/abs/2601.10024)
*Yanxin Liu,Yunqi Zhang*

Main category: cs.LG

TL;DR: BPE框架通过为每个模型构建"行为画像"，根据模型对测试实例的响应与其行为画像的偏差来确定集成权重，相比传统基于模型间差异的集成方法，在预测精度、计算效率和存储资源利用方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统静态集成方法（如Stacking）将每个基学习器视为整体分配权重，忽略了不同模型在实例空间不同区域的能力差异。动态集成选择（DES）虽然考虑了这一点，但传统方法主要依赖模型间的差异进行集成，忽视了模型自身的内在特性，且严重依赖验证集进行能力估计。

Method: 提出行为画像集成（BPE）框架，为每个模型构建内在的"行为画像"，根据模型对特定测试实例的响应与其已建立的行为画像之间的偏差来推导集成权重。这是一种范式转变，从基于模型间差异的传统方法转向基于模型自身行为特性的方法。

Result: 在合成和真实数据集上的大量实验表明，基于BPE框架的算法相比最先进的集成基线方法取得了显著改进。这些改进不仅体现在预测精度上，还包括计算效率和存储资源利用方面，在各种场景下都表现出色。

Conclusion: BPE框架通过关注模型自身的行为特性而非模型间差异，提供了一种更有效、更高效的集成学习方法，减少了对外部验证集的依赖，在多个性能指标上超越了传统集成方法。

Abstract: Ensemble learning is widely recognized as a pivotal strategy for pushing the boundaries of predictive performance. Traditional static ensemble methods, such as Stacking, typically assign weights by treating each base learner as a holistic entity, thereby overlooking the fact that individual models exhibit varying degrees of competence across different regions of the instance space. To address this limitation, Dynamic Ensemble Selection (DES) was introduced. However, both static and dynamic approaches predominantly rely on the divergence among different models as the basis for integration. This inter-model perspective neglects the intrinsic characteristics of the models themselves and necessitates a heavy reliance on validation sets for competence estimation. In this paper, we propose the Behavioral Profiling Ensemble (BPE) framework, which introduces a novel paradigm shift. Unlike traditional methods, BPE constructs a ``behavioral profile'' intrinsic to each model and derives integration weights based on the deviation between the model's response to a specific test instance and its established behavioral profile. Extensive experiments on both synthetic and real-world datasets demonstrate that the algorithm derived from the BPE framework achieves significant improvements over state-of-the-art ensemble baselines. These gains are evident not only in predictive accuracy but also in computational efficiency and storage resource utilization across various scenarios.

</details>


### [130] [Unlabeled Data Can Provably Enhance In-Context Learning of Transformers](https://arxiv.org/abs/2601.10058)
*Renpu Liu,Jing Yang*

Main category: cs.LG

TL;DR: 本文提出了一种增强的上下文学习框架，通过结合少量标注示例和大量未标注数据，利用Transformer模拟EM算法，显著提升ICL性能


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的上下文学习能力受限于提示中能容纳的少量昂贵标注示例，而现实中存在大量与任务相关的未标注数据。如何利用这些未标注数据来提升ICL性能成为一个关键问题。

Method: 提出增强的ICL框架，在提示中包含少量标注示例和一组未标注输入。在多类线性分类设置下，通过思维链提示使多层Transformer有效模拟期望最大化算法，从标注和未标注数据中提取有用信息。

Result: 增强的ICL框架在理论上能提升ICL准确性，且Transformer可以通过教师强制训练，参数以线性速率收敛到期望解。实验表明该框架持续优于传统的少样本ICL。

Conclusion: 这是首个关于未标注数据对Transformer ICL性能影响的理论研究，证明了结合未标注数据能显著提升ICL性能，为利用大量未标注数据增强大语言模型能力提供了新方向。

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL) capabilities, yet the quality of their predictions is fundamentally limited by the few costly labeled demonstrations that can fit into a prompt. Meanwhile, there exist vast and continuously growing amounts of unlabeled data that may be closely related to the ICL task. How to utilize such unlabeled data to provably enhance the performance of ICL thus becomes an emerging fundamental question. In this work, we propose a novel augmented ICL framework, in which the prompt includes a small set of labeled examples alongside a block of unlabeled inputs. We focus on the multi-class linear classification setting and demonstrate that, with chain-of-thought (CoT) prompting, a multi-layer transformer can effectively emulate an expectation-maximization (EM) algorithm. This enables the transformer to implicitly extract useful information from both labeled and unlabeled data, leading to provable improvements in ICL accuracy. Moreover, we show that such a transformer can be trained via teacher forcing, with its parameters converging to the desired solution at a linear rate. Experiments demonstrate that the augmented ICL framework consistently outperforms conventional few-shot ICL, providing empirical support for our theoretical findings. To the best of our knowledge, this is the first theoretical study on the impact of unlabeled data on the ICL performance of transformers.

</details>


### [131] [Efficient Content-based Recommendation Model Training via Noise-aware Coreset Selection](https://arxiv.org/abs/2601.10067)
*Hung Vinh Tran,Tong Chen,Hechuan Wen,Quoc Viet Hung Nguyen,Bin Cui,Hongzhi Yin*

Main category: cs.LG

TL;DR: 提出NaCS框架，通过子模优化构建核心集并校正噪声标签，仅用1%数据即可恢复93-95%的全数据集性能


<details>
  <summary>Details</summary>
Motivation: 基于内容的推荐系统需要大规模持续训练以适应多样用户偏好，计算成本高。核心集选择可减少训练开销，但现有方法对用户-物品交互中的噪声敏感，特别是核心集规模较小时

Method: 提出噪声感知核心集选择框架：1) 基于训练梯度的子模优化构建核心集；2) 使用渐进训练模型校正噪声标签；3) 通过不确定性量化过滤低置信度样本，避免不可靠交互训练

Result: NaCS为基于内容的推荐系统生成更高质量的核心集，效率优于现有技术。仅使用1%训练数据即可恢复93-95%的全数据集训练性能

Conclusion: NaCS框架有效解决了基于内容推荐系统中核心集选择对噪声敏感的问题，显著降低训练开销同时保持模型性能

Abstract: Content-based recommendation systems (CRSs) utilize content features to predict user-item interactions, serving as essential tools for helping users navigate information-rich web services. However, ensuring the effectiveness of CRSs requires large-scale and even continuous model training to accommodate diverse user preferences, resulting in significant computational costs and resource demands. A promising approach to this challenge is coreset selection, which identifies a small but representative subset of data samples that preserves model quality while reducing training overhead. Yet, the selected coreset is vulnerable to the pervasive noise in user-item interactions, particularly when it is minimally sized. To this end, we propose Noise-aware Coreset Selection (NaCS), a specialized framework for CRSs. NaCS constructs coresets through submodular optimization based on training gradients, while simultaneously correcting noisy labels using a progressively trained model. Meanwhile, we refine the selected coreset by filtering out low-confidence samples through uncertainty quantification, thereby avoid training with unreliable interactions. Through extensive experiments, we show that NaCS produces higher-quality coresets for CRSs while achieving better efficiency than existing coreset selection techniques. Notably, NaCS recovers 93-95\% of full-dataset training performance using merely 1\% of the training data. The source code is available at \href{https://github.com/chenxing1999/nacs}{https://github.com/chenxing1999/nacs}.

</details>


### [132] [Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment](https://arxiv.org/abs/2601.10070)
*Mohammad Abbadi*

Main category: cs.LG

TL;DR: 该研究比较了基于图像的深度学习模型(HuSHeM)与WHO标准结合炎症指标的传统方法在精子形态评估中的表现，发现深度学习模型在判别性能、校准和临床效用方面均更优。


<details>
  <summary>Details</summary>
Motivation: 精子形态评估是男性生育力评估的关键但主观的组成部分，常受观察者间变异性和资源限制的影响。需要更客观、可重复的评估方法来提高评估质量。

Method: 开发了基于图像的深度学习模型HuSHeM，在高分辨率精子形态图像上进行训练，并与基于WHO标准结合系统性炎症反应指数(SIRI)的临床基线方法进行比较。使用独立临床队列进行评估，通过判别性能、校准分析和临床效用分析来评估模型表现。

Result: HuSHeM模型显示出更高的判别性能（更高的AUC值），在类别不平衡情况下表现更好（更高的精确率-召回率面积值），校准分析显示预测概率与观察结果更一致，决策曲线分析表明在临床相关阈值概率范围内具有更大的净临床效益。

Conclusion: 基于图像的深度学习相比传统的基于规则和炎症增强的标准，可能提供更好的预测可靠性和临床效用。该框架支持精子形态的客观和可重复评估，可作为生育筛查和转诊工作流程中的决策支持工具，但不能替代临床判断或实验室评估。

Abstract: Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)).
  The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities.
  These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment.

</details>


### [133] [Sparse-RL: Breaking the Memory Wall in LLM Reinforcement Learning via Stable Sparse Rollouts](https://arxiv.org/abs/2601.10079)
*Sijia Luo,Xiaokang Zhang,Yuxuan Hu,Bohan Zhang,Ke Wang,Jinbo Su,Mengshu Sun,Lei Liang,Jing Zhang*

Main category: cs.LG

TL;DR: Sparse-RL：一种在稀疏rollouts下实现稳定强化学习训练的方法，通过稀疏感知拒绝采样和重要性重加权来纠正压缩引起的策略不匹配问题，显著降低KV缓存内存开销同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型强化学习中，长序列rollouts时存储KV缓存的内存开销巨大，成为硬件受限时的关键瓶颈。现有KV压缩技术虽然适用于推理，但直接应用于RL训练会导致严重的策略不匹配和性能崩溃。

Method: 提出Sparse-RL框架，包含：1）稀疏感知拒绝采样，纠正密集旧策略、稀疏采样策略和学习者策略之间的策略不匹配；2）基于重要性的重加权，修正压缩引起的信息损失带来的离策略偏差。

Result: Sparse-RL相比密集基线显著降低rollout开销，同时保持性能。此外，该方法实现了稀疏感知训练，显著增强了模型在稀疏推理部署时的鲁棒性。

Conclusion: Sparse-RL有效解决了RL训练中KV压缩导致的策略不匹配问题，实现了内存高效的稳定训练，并为稀疏推理部署提供了鲁棒性增强。

Abstract: Reinforcement Learning (RL) has become essential for eliciting complex reasoning capabilities in Large Language Models (LLMs). However, the substantial memory overhead of storing Key-Value (KV) caches during long-horizon rollouts acts as a critical bottleneck, often prohibiting efficient training on limited hardware. While existing KV compression techniques offer a remedy for inference, directly applying them to RL training induces a severe policy mismatch, leading to catastrophic performance collapse. To address this, we introduce Sparse-RL empowers stable RL training under sparse rollouts. We show that instability arises from a fundamental policy mismatch among the dense old policy, the sparse sampler policy, and the learner policy. To mitigate this issue, Sparse-RL incorporates Sparsity-Aware Rejection Sampling and Importance-based Reweighting to correct the off-policy bias introduced by compression-induced information loss. Experimental results show that Sparse-RL reduces rollout overhead compared to dense baselines while preserving the performance. Furthermore, Sparse-RL inherently implements sparsity-aware training, significantly enhancing model robustness during sparse inference deployment.

</details>


### [134] [Adaptive Label Error Detection: A Bayesian Approach to Mislabeled Data Detection](https://arxiv.org/abs/2601.10084)
*Zan Chaudhry,Noam H. Rotenberg,Brian Caffo,Craig K. Jones,Haris I. Sair*

Main category: cs.LG

TL;DR: ALED是一种新颖的标签错误检测方法，通过提取CNN中间特征、去噪、建模类别分布并进行似然比测试，在医学影像数据上比现有方法具有更高灵敏度且不损失精度。


<details>
  <summary>Details</summary>
Motivation: 机器学习分类系统在训练时若存在错误标注的ground truth标签，即使数据由专家精心整理，也会导致性能下降。随着机器学习应用日益广泛，识别和纠正错误标注对于开发更强大的模型变得至关重要。

Method: ALED方法：1）从深度卷积神经网络提取中间特征空间；2）对特征进行去噪处理；3）使用多维高斯分布对每个类别的降维流形进行建模；4）执行简单的似然比测试来识别错误标注样本。

Result: 在多个医学影像数据集上，ALED相比现有标签错误检测方法具有显著提高的灵敏度，且不损害精度。通过使用校正后的数据进行微调，神经网络在测试集上的错误率降低了33.8%。

Conclusion: ALED是一种有效的标签错误检测方法，能够显著提升模型性能，已部署在Python包statlab中，为终端用户提供强大益处。

Abstract: Machine learning classification systems are susceptible to poor performance when trained with incorrect ground truth labels, even when data is well-curated by expert annotators. As machine learning becomes more widespread, it is increasingly imperative to identify and correct mislabeling to develop more powerful models. In this work, we motivate and describe Adaptive Label Error Detection (ALED), a novel method of detecting mislabeling. ALED extracts an intermediate feature space from a deep convolutional neural network, denoises the features, models the reduced manifold of each class with a multidimensional Gaussian distribution, and performs a simple likelihood ratio test to identify mislabeled samples. We show that ALED has markedly increased sensitivity, without compromising precision, compared to established label error detection methods, on multiple medical imaging datasets. We demonstrate an example where fine-tuning a neural network on corrected data results in a 33.8% decrease in test set errors, providing strong benefits to end users. The ALED detector is deployed in the Python package statlab.

</details>


### [135] [Bayesian Meta-Analyses Could Be More: A Case Study in Trial of Labor After a Cesarean-section Outcomes and Complications](https://arxiv.org/abs/2601.10089)
*Ashley Klein,Edward Raff,Marcia DesJardin*

Main category: cs.LG

TL;DR: 本文提出一种贝叶斯方法来解决医学研究中关键决策变量未被记录的问题，通过分析TOLAC案例展示了该方法如何帮助医生在证据有限的情况下做出临床决策。


<details>
  <summary>Details</summary>
Motivation: 医学研究中经常存在关键决策变量未被记录的问题，这导致荟萃分析的结果不可靠，因为效应大小未知。在TOLAC（剖宫产后试产）等临床情境中，医生需要在干预措施有限的情况下做出决策，但缺乏可靠证据支持。

Method: 开发了一种贝叶斯分析方法来处理医学研究中常见的关键变量缺失问题。该方法允许在关键决策变量未被记录的情况下，评估阳性效应主张是否仍然成立。通过TOLAC案例研究来展示该方法的实用性。

Result: 该方法能够帮助产科医生在TOLAC情境中评估现有证据，确定是否仍有足够支持来推进患者护理。即使在关键变量缺失的情况下，也能提供更可靠的决策支持。

Conclusion: 贝叶斯方法为解决医学研究中关键变量缺失问题提供了有效途径，能够增强荟萃分析的可靠性，并为临床医生在证据有限的情况下提供更好的决策支持，特别是在TOLAC等高风险医疗情境中。

Abstract: The meta-analysis's utility is dependent on previous studies having accurately captured the variables of interest, but in medical studies, a key decision variable that impacts a physician's decisions was not captured. This results in an unknown effect size and unreliable conclusions. A Bayesian approach may allow analysis to determine if the claim of a positive effect is still warranted, and we build a Bayesian approach to this common medical scenario. To demonstrate its utility, we assist professional OBGYNs in evaluating Trial of Labor After a Cesarean-section (TOLAC) situations where few interventions are available for patients and find the support needed for physicians to advance patient care.

</details>


### [136] [LeMoF: Level-guided Multimodal Fusion for Heterogeneous Clinical Data](https://arxiv.org/abs/2601.10092)
*Jongseok Kim,Seongae Kang,Jonghwan Shin,Yuhan Lee,Ohyun Jo*

Main category: cs.LG

TL;DR: 提出LeMoF框架，通过层级引导的模态融合策略，在临床多模态预测中实现更优的性能平衡


<details>
  <summary>Details</summary>
Motivation: 现有多模态临床预测方法依赖静态模态整合方案和简单融合策略，未能充分利用模态特定表示，特别是在异构临床环境中

Method: 提出LeMoF框架，选择性整合每个模态内的层级引导表示，明确分离并学习全局模态级预测和层级特定判别表示

Result: 在ICU住院时间预测实验中，LeMoF在各种编码器配置下始终优于现有最先进的多模态融合技术

Conclusion: 层级引导的模态融合是实现稳健预测性能的关键因素，LeMoF能在异构临床环境中平衡预测稳定性和判别能力

Abstract: Multimodal clinical prediction is widely used to integrate heterogeneous data such as Electronic Health Records (EHR) and biosignals. However, existing methods tend to rely on static modality integration schemes and simple fusion strategies. As a result, they fail to fully exploit modality-specific representations. In this paper, we propose Level-guided Modal Fusion (LeMoF), a novel framework that selectively integrates level-guided representations within each modality. Each level refers to a representation extracted from a different layer of the encoder. LeMoF explicitly separates and learns global modality-level predictions from level-specific discriminative representations. This design enables LeMoF to achieve a balanced performance between prediction stability and discriminative capability even in heterogeneous clinical environments. Experiments on length of stay prediction using Intensive Care Unit (ICU) data demonstrate that LeMoF consistently outperforms existing state-of-the-art multimodal fusion techniques across various encoder configurations. We also confirmed that level-wise integration is a key factor in achieving robust predictive performance across various clinical conditions.

</details>


### [137] [Multilingual-To-Multimodal (M2M): Unlocking New Languages with Monolingual Text](https://arxiv.org/abs/2601.10096)
*Piyush Singh Pasi*

Main category: cs.LG

TL;DR: METAL：一种轻量级对齐方法，仅使用英语文本学习少量线性层，将多语言文本嵌入映射到多模态空间，实现强大的零样本跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 多模态模型在英语上表现优异，但在其他语言上性能大幅下降，主要原因是缺乏多语言多模态数据。现有解决方案过度依赖机器翻译，而多语言文本建模的进展未被充分利用。

Method: METAL（轻量级对齐方法）仅学习少量线性层，使用英语文本将多语言文本嵌入映射到多模态空间。该方法简单但有效，通过几何变换而非简单旋转来重塑嵌入空间。

Result: 在XTD文本到图像检索任务中，METAL在英语上达到94.9%的Recall@10，在11种语言（10种未见语言）上平均达到89.5%的Recall@10。定性t-SNE可视化显示多语言嵌入与多模态表示紧密对齐。

Conclusion: METAL证明了仅使用英语文本就能实现强大的多语言多模态对齐，该方法可推广到音频-文本检索和跨语言文本到图像生成。作者发布了代码、检查点和多语言评估数据集以促进进一步研究。

Abstract: Multimodal models excel in English, supported by abundant image-text and audio-text data, but performance drops sharply for other languages due to limited multilingual multimodal resources. Existing solutions rely heavily on machine translation, while advances in multilingual text modeling remain underutilized. We introduce METAL, a lightweight alignment method that learns only a few linear layers using English text alone to map multilingual text embeddings into a multimodal space. Despite its simplicity, METAL matches baseline performance in English (94.9 percent Recall at 10) and achieves strong zero-shot transfer (89.5 percent Recall at 10 averaged across 11 languages, 10 unseen) on XTD text-to-image retrieval. Qualitative t-SNE visualizations show that multilingual embeddings align tightly with multimodal representations, while weight analysis reveals that the transformation reshapes embedding geometry rather than performing trivial rotations. Beyond image-text retrieval, METAL generalizes to audio-text retrieval and cross-lingual text-to-image generation. We release code and checkpoints at https://github.com/m2m-codebase/M2M , as well as multilingual evaluation datasets including MSCOCO Multilingual 30K (https://huggingface.co/datasets/piyushsinghpasi/mscoco-multilingual-30k ), AudioCaps Multilingual (https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual ), and Clotho Multilingual (https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual ), to facilitate further research.

</details>


### [138] [Understanding and Preserving Safety in Fine-Tuned LLMs](https://arxiv.org/abs/2601.10141)
*Jiawen Zhang,Yangfan Hu,Kejia Chen,Lipeng He,Jiachen Ma,Jian Lou,Dan Li,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

TL;DR: 提出SPF方法，在微调大语言模型时通过移除与安全子空间冲突的梯度分量，解决安全性与实用性的两难困境。


<details>
  <summary>Details</summary>
Motivation: 微调大语言模型虽然对下游任务至关重要，但会严重破坏模型的安全对齐性，即使微调数据完全无害。现有方法面临安全性与实用性的两难困境：强调安全性会损害任务性能，而优先考虑实用性则需要深度微调，不可避免地导致安全性大幅下降。

Method: 提出安全保护微调（SPF）方法，基于三个关键发现：1）安全梯度位于低秩子空间，而实用梯度跨越更广的高维空间；2）这些子空间通常负相关，导致微调时的方向冲突；3）主要安全方向可以从单个样本中高效估计。SPF通过显式移除与低秩安全子空间冲突的梯度分量来实现。

Result: 理论上证明SPF能保证实用性收敛同时限制安全性漂移。实证上，SPF能持续保持下游任务性能，恢复几乎所有预训练的安全对齐性，即使在对抗性微调场景下。此外，SPF对深度微调和动态越狱攻击表现出强大的抵抗能力。

Conclusion: 该研究为始终对齐的LLM微调提供了新的机制理解和实践指导，通过几何视角分析安全与实用梯度的交互，提出了轻量级的SPF方法有效解决了安全-实用困境。

Abstract: Fine-tuning is an essential and pervasive functionality for applying large language models (LLMs) to downstream tasks. However, it has the potential to substantially degrade safety alignment, e.g., by greatly increasing susceptibility to jailbreak attacks, even when the fine-tuning data is entirely harmless. Despite garnering growing attention in defense efforts during the fine-tuning stage, existing methods struggle with a persistent safety-utility dilemma: emphasizing safety compromises task performance, whereas prioritizing utility typically requires deep fine-tuning that inevitably leads to steep safety declination.
  In this work, we address this dilemma by shedding new light on the geometric interaction between safety- and utility-oriented gradients in safety-aligned LLMs. Through systematic empirical analysis, we uncover three key insights: (I) safety gradients lie in a low-rank subspace, while utility gradients span a broader high-dimensional space; (II) these subspaces are often negatively correlated, causing directional conflicts during fine-tuning; and (III) the dominant safety direction can be efficiently estimated from a single sample. Building upon these novel insights, we propose safety-preserving fine-tuning (SPF), a lightweight approach that explicitly removes gradient components conflicting with the low-rank safety subspace. Theoretically, we show that SPF guarantees utility convergence while bounding safety drift. Empirically, SPF consistently maintains downstream task performance and recovers nearly all pre-trained safety alignment, even under adversarial fine-tuning scenarios. Furthermore, SPF exhibits robust resistance to both deep fine-tuning and dynamic jailbreak attacks. Together, our findings provide new mechanistic understanding and practical guidance toward always-aligned LLM fine-tuning.

</details>


### [139] [Simple Network Graph Comparative Learning](https://arxiv.org/abs/2601.10150)
*Qiang Yu,Xinran Cheng,Shiqiang Xu,Chuanyi Liu*

Main category: cs.LG

TL;DR: 提出SNGCL方法，通过叠加多层拉普拉斯平滑滤波器处理数据，使用改进的三元重组损失函数，在节点分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法在节点分类任务中存在两个主要问题：1) 数据增强技术可能导致新视图与原始视图差异过大，削弱视图相关性；2) 大多数图对比学习算法依赖大量负样本。

Method: 提出SNGCL方法：使用叠加多层拉普拉斯平滑滤波器处理数据，分别获得全局和局部特征平滑矩阵；将这些矩阵输入孪生网络的目标网络和在线网络；采用改进的三元重组损失函数，使类内距离更近、类间距离更远。

Result: 在节点分类任务中与最先进模型比较，实验结果显示SNGCL在大多数任务中具有很强的竞争力。

Conclusion: SNGCL通过创新的数据处理方法和损失函数设计，有效解决了现有图对比学习方法在节点分类中的挑战，取得了优异的性能表现。

Abstract: The effectiveness of contrastive learning methods has been widely recognized in the field of graph learning, especially in contexts where graph data often lack labels or are difficult to label. However, the application of these methods to node classification tasks still faces a number of challenges. First, existing data enhancement techniques may lead to significant differences from the original view when generating new views, which may weaken the relevance of the view and affect the efficiency of model training. Second, the vast majority of existing graph comparison learning algorithms rely on the use of a large number of negative samples. To address the above challenges, this study proposes a novel node classification contrast learning method called Simple Network Graph Comparative Learning (SNGCL). Specifically, SNGCL employs a superimposed multilayer Laplace smoothing filter as a step in processing the data to obtain global and local feature smoothing matrices, respectively, which are thus passed into the target and online networks of the siamese network, and finally employs an improved triple recombination loss function to bring the intra-class distance closer and the inter-class distance farther. We have compared SNGCL with state-of-the-art models in node classification tasks, and the experimental results show that SNGCL is strongly competitive in most tasks.

</details>


### [140] [LOOKAT: Lookup-Optimized Key-Attention for Memory-Efficient Transformers](https://arxiv.org/abs/2601.10155)
*Aryan Karmore*

Main category: cs.LG

TL;DR: LOOKAT 是一种压缩 KV 缓存的新方法，通过产品量化和非对称距离计算，将注意力计算从内存密集型转为计算密集型，实现高达64倍压缩且保持95%以上输出保真度。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法虽然能压缩存储，但无法减少带宽，因为注意力计算需要将INT4/INT8的键反量化为FP16。需要一种既能压缩存储又能减少带宽的KV缓存压缩方法，以便在边缘设备上部署大语言模型。

Method: 将注意力评分视为内积相似性搜索，应用向量数据库的压缩技术。采用产品量化将键向量分解为子空间，学习码本，通过查找表计算注意力表。这种方法将注意力计算从内存密集型转为计算密集型。

Result: 在GPT-2上测试，LOOKAT实现64倍压缩时输出保真度95.7%，32倍压缩时95.0%保真度。无需架构修改或训练，保持秩相关系数ρ>0.95。理论分析显示秩相关退化与d_k/mK成正比，在1024个token序列长度内得到验证。

Conclusion: LOOKAT通过产品量化和非对称距离计算有效压缩KV缓存，将注意力计算从内存密集型转为计算密集型，在保持高保真度的同时实现显著压缩比，适合边缘设备部署。

Abstract: Compressing the KV cache is a required step to deploy large language models on edge devices. Current quantization methods compress storage but fail to reduce bandwidth as attention calculation requires dequantizing keys from INT4/INT8 to FP16 before use. We observe that attention scoring is mathematically equivalent to the inner product similarity search and we can apply some compression techniques from vector databases to compress KV-cache better. We propose LOOKAT, which applies product quantization and asymmetric distance computation, to transformer architecture by decomposing key vectors into subspaces, learning codebooks and computing attention tables via lookup tables. This transforms attention from memory-bound to compute-bound. LOOKAT achieves 64 $\times$ compression at 95.7\% output fidelity and 32 $\times$ compression at 95.0\% fidelity when tested on GPT-2. LOOKAT requires no architecture changes or training while maintaining rank correlation $ρ> 0.95$. Theoretical analysis confirms that rank correlation degrades as $O(d_k/mK)$, with guarantees validated across sequence lengths up to 1024 tokens.

</details>


### [141] [CC-OR-Net: A Unified Framework for LTV Prediction through Structural Decoupling](https://arxiv.org/abs/2601.10176)
*Mingyu Zhao,Haoran Bai,Yu Tian,Bing Zhu,Hengliang Luo*

Main category: cs.LG

TL;DR: 提出CC-OR-Net框架，通过结构分解解决LTV预测中零膨胀长尾分布问题，平衡全局准确率与高价值用户精度


<details>
  <summary>Details</summary>
Motivation: LTV预测面临零膨胀长尾分布挑战：大量低中价值用户淹没少量高价值"鲸鱼"用户，且低中价值用户内部存在显著异质性。现有方法要么依赖刚性统计假设，要么通过损失约束而非架构设计来解耦排序和回归，无法平衡全局准确率与高价值精度。

Method: 提出CC-OR-Net框架，包含三个组件：1) 结构序数分解模块，通过架构保证稳健排序；2) 桶内残差模块，实现细粒度回归；3) 定向高价值增强模块，提升顶级用户预测精度。

Result: 在包含3亿用户的真实数据集上评估，CC-OR-Net在所有关键业务指标上实现了更优的权衡，超越了现有最先进方法，提供了全面且有商业价值的LTV预测解决方案。

Conclusion: CC-OR-Net通过结构分解实现了更稳健的排序与回归解耦，有效解决了LTV预测中的零膨胀长尾分布问题，为实际商业应用提供了更优的解决方案。

Abstract: Customer Lifetime Value (LTV) prediction, a central problem in modern marketing, is characterized by a unique zero-inflated and long-tail data distribution. This distribution presents two fundamental challenges: (1) the vast majority of low-to-medium value users numerically overwhelm the small but critically important segment of high-value "whale" users, and (2) significant value heterogeneity exists even within the low-to-medium value user base. Common approaches either rely on rigid statistical assumptions or attempt to decouple ranking and regression using ordered buckets; however, they often enforce ordinality through loss-based constraints rather than inherent architectural design, failing to balance global accuracy with high-value precision. To address this gap, we propose \textbf{C}onditional \textbf{C}ascaded \textbf{O}rdinal-\textbf{R}esidual Networks \textbf{(CC-OR-Net)}, a novel unified framework that achieves a more robust decoupling through \textbf{structural decomposition}, where ranking is architecturally guaranteed. CC-OR-Net integrates three specialized components: a \textit{structural ordinal decomposition module} for robust ranking, an \textit{intra-bucket residual module} for fine-grained regression, and a \textit{targeted high-value augmentation module} for precision on top-tier users. Evaluated on real-world datasets with over 300M users, CC-OR-Net achieves a superior trade-off across all key business metrics, outperforming state-of-the-art methods in creating a holistic and commercially valuable LTV prediction solution.

</details>


### [142] [Bias in the Shadows: Explore Shortcuts in Encrypted Network Traffic Classification](https://arxiv.org/abs/2601.10180)
*Chuyi Wang,Xiaohui Xie,Tongze Wang,Yong Cui*

Main category: cs.LG

TL;DR: BiasSeeker是一个模型无关、数据驱动的半自动化框架，用于检测加密网络流量分类中的数据集特定捷径特征，通过统计相关性分析识别虚假特征，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有预训练模型在加密网络流量分类中常出现捷径学习问题，依赖虚假相关性而无法泛化到真实数据。现有解决方案过度依赖模型特定的解释技术，缺乏跨模型架构和部署场景的适应性和通用性。

Method: 提出BiasSeeker框架：1）直接在原始二进制流量上进行统计相关性分析，识别虚假或环境纠缠特征；2）引入系统化的捷径特征分类；3）应用类别特定的验证策略，减少偏置同时保留有意义信息；4）强调上下文感知的特征选择和数据集特定诊断。

Result: 在三个网络流量分类任务的19个公共数据集上评估BiasSeeker，证明其能有效检测捷径特征，为理解和解决加密网络流量分类中的捷径学习问题提供了新视角。

Conclusion: 特征选择应该是模型训练前有意为之且场景敏感的步骤，BiasSeeker通过强调上下文感知特征选择和数据集特定诊断，为解决加密网络流量分类中的捷径学习问题提供了新方法。

Abstract: Pre-trained models operating directly on raw bytes have achieved promising performance in encrypted network traffic classification (NTC), but often suffer from shortcut learning-relying on spurious correlations that fail to generalize to real-world data. Existing solutions heavily rely on model-specific interpretation techniques, which lack adaptability and generality across different model architectures and deployment scenarios.
  In this paper, we propose BiasSeeker, the first semi-automated framework that is both model-agnostic and data-driven for detecting dataset-specific shortcut features in encrypted traffic. By performing statistical correlation analysis directly on raw binary traffic, BiasSeeker identifies spurious or environment-entangled features that may compromise generalization, independent of any classifier. To address the diverse nature of shortcut features, we introduce a systematic categorization and apply category-specific validation strategies that reduce bias while preserving meaningful information.
  We evaluate BiasSeeker on 19 public datasets across three NTC tasks. By emphasizing context-aware feature selection and dataset-specific diagnosis, BiasSeeker offers a novel perspective for understanding and addressing shortcut learning in encrypted network traffic classification, raising awareness that feature selection should be an intentional and scenario-sensitive step prior to model training.

</details>


### [143] [Reinforcement Learning to Discover a NorthEast Monsoon Index for Monthly Rainfall Prediction in Thailand](https://arxiv.org/abs/2601.10181)
*Kiattikun Chobtham*

Main category: cs.LG

TL;DR: 提出基于强化学习优化的东北季风气候指数，结合LSTM模型显著提升泰国地区长期月降雨预测精度


<details>
  <summary>Details</summary>
Motivation: 现有全球气候指数（如厄尔尼诺南方涛动）对泰国特定区域的长期降雨预测效果有限，缺乏能够反映当地气候特征的局部尺度指数

Method: 1. 提出基于海表温度的东北季风气候指数；2. 使用深度Q网络强化学习代理优化指数计算区域；3. 将降雨站分为12个聚类；4. 将优化指数输入LSTM模型进行预测

Result: 优化后的指数显著提高了大多数聚类区域的长期月降雨预测技能，有效降低了12个月提前预测的均方根误差

Conclusion: 基于强化学习优化的局部气候指数能够有效提升特定区域的长期降雨预测精度，为区域气候预测提供了新方法

Abstract: Climate prediction is a challenge due to the intricate spatiotemporal patterns within Earth systems. Global climate indices, such as the El Niño Southern Oscillation, are standard input features for long-term rainfall prediction. However, a significant gap persists regarding local-scale indices capable of improving predictive accuracy in specific regions of Thailand. This paper introduces a novel NorthEast monsoon climate index calculated from sea surface temperature to reflect the climatology of the boreal winter monsoon. To optimise the calculated areas used for this index, a Deep Q-Network reinforcement learning agent explores and selects the most effective rectangles based on their correlation with seasonal rainfall. Rainfall stations were classified into 12 distinct clusters to distinguish rainfall patterns between southern and upper Thailand. Experimental results show that incorporating the optimised index into Long Short-Term Memory models significantly improves long-term monthly rainfall prediction skill in most cluster areas. This approach effectively reduces the Root Mean Square Error for 12-month-ahead forecasts.

</details>


### [144] [Graph Regularized PCA](https://arxiv.org/abs/2601.10199)
*Antonio Briola,Marwin Schmidt,Fabio Caccioli,Carlos Ros Perez,James Singleton,Christian Michler,Tomaso Aste*

Main category: cs.LG

TL;DR: 提出图正则化PCA（GR-PCA），通过图拉普拉斯正则化处理非独立同分布噪声的高维数据，提高主成分的结构保真度


<details>
  <summary>Details</summary>
Motivation: 传统PCA假设噪声是各向同性的独立同分布，但实际高维数据中变量间存在依赖关系，噪声协方差非球形，需要能处理这种依赖结构的降维方法

Method: 通过图正则化PCA，学习稀疏精度图，利用图拉普拉斯正则化将载荷偏向低频傅里叶模式，抑制高频信号，保留图一致的低频信号

Result: 在合成数据上评估显示：相比主流方法，GR-PCA能更好地将方差集中在预期支撑集上，产生更低图拉普拉斯能量的载荷，在样本外重建中保持竞争力

Conclusion: GR-PCA提供了一种简单、模块化、可扩展的结构感知降维方法，在保持预测性能的同时提高结构保真度，特别适用于高频信号与图相关的情况

Abstract: High-dimensional data often exhibit dependencies among variables that violate the isotropic-noise assumption under which principal component analysis (PCA) is optimal. For cases where the noise is not independent and identically distributed across features (i.e., the covariance is not spherical) we introduce Graph Regularized PCA (GR-PCA). It is a graph-based regularization of PCA that incorporates the dependency structure of the data features by learning a sparse precision graph and biasing loadings toward the low-frequency Fourier modes of the corresponding graph Laplacian. Consequently, high-frequency signals are suppressed, while graph-coherent low-frequency ones are preserved, yielding interpretable principal components aligned with conditional relationships. We evaluate GR-PCA on synthetic data spanning diverse graph topologies, signal-to-noise ratios, and sparsity levels. Compared to mainstream alternatives, it concentrates variance on the intended support, produces loadings with lower graph-Laplacian energy, and remains competitive in out-of-sample reconstruction. When high-frequency signals are present, the graph Laplacian penalty prevents overfitting, reducing the reconstruction accuracy but improving structural fidelity. The advantage over PCA is most pronounced when high-frequency signals are graph-correlated, whereas PCA remains competitive when such signals are nearly rotationally invariant. The procedure is simple to implement, modular with respect to the precision estimator, and scalable, providing a practical route to structure-aware dimensionality reduction that improves structural fidelity without sacrificing predictive performance.

</details>


### [145] [PRL: Process Reward Learning Improves LLMs' Reasoning Ability and Broadens the Reasoning Boundary](https://arxiv.org/abs/2601.10201)
*Jiarui Yao,Ruida Wang,Tong Zhang*

Main category: cs.LG

TL;DR: 本文提出Process Reward Learning (PRL)，通过将熵正则化强化学习目标分解为中间步骤，为LLM推理过程提供细粒度监督，无需额外训练奖励模型或MCTS等繁琐步骤。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多基于轨迹级别的结果奖励，缺乏推理过程中的细粒度监督；其他结合过程信号的方法依赖MCTS、单独训练奖励模型等繁琐步骤，训练效率低；且过程信号设计缺乏严格理论支持，优化机制不透明。

Method: 提出Process Reward Learning (PRL)，从理论动机出发，将熵正则化强化学习目标分解为中间步骤，推导出等价于奖励最大化加KL散度惩罚项的PRL公式，将结果奖励转化为过程监督信号。

Result: 实验表明PRL不仅提高了LLM推理能力的平均性能（average @ n），还通过改善pass @ n指标拓宽了推理边界；大量实验验证了PRL的有效性和泛化能力。

Conclusion: PRL为LLM推理过程提供理论支持的细粒度监督，无需繁琐额外步骤，有效提升推理性能和边界，具有良好泛化能力。

Abstract: Improving the reasoning abilities of Large Language Models (LLMs) has been a continuous topic recently. But most relevant works are based on outcome rewards at the trajectory level, missing fine-grained supervision during the reasoning process. Other existing training frameworks that try to combine process signals together to optimize LLMs also rely heavily on tedious additional steps like MCTS, training a separate reward model, etc., doing harm to the training efficiency. Moreover, the intuition behind the process signals design lacks rigorous theoretical support, leaving the understanding of the optimization mechanism opaque. In this paper, we propose Process Reward Learning (PRL), which decomposes the entropy regularized reinforcement learning objective into intermediate steps, with rigorous process rewards that could be assigned to models accordingly. Starting from theoretical motivation, we derive the formulation of PRL that is essentially equivalent to the objective of reward maximization plus a KL-divergence penalty term between the policy model and a reference model. However, PRL could turn the outcome reward into process supervision signals, which helps better guide the exploration during RL optimization. From our experiment results, we demonstrate that PRL not only improves the average performance for LLMs' reasoning ability measured by average @ n, but also broadens the reasoning boundary by improving the pass @ n metric. Extensive experiments show the effectiveness of PRL could be verified and generalized.

</details>


### [146] [Fundamental Limitations of Favorable Privacy-Utility Guarantees for DP-SGD](https://arxiv.org/abs/2601.10237)
*Murat Bilgehan Ertan,Marten van Dijk*

Main category: cs.LG

TL;DR: DP-SGD在f-差分隐私框架下存在根本性限制：在标准最坏情况对抗模型下，无法同时实现强隐私和高效用，噪声乘子有严格下界，导致实际训练中精度显著下降。


<details>
  <summary>Details</summary>
Motivation: 虽然DP-SGD是私有训练的主要范式，但其在最坏情况对抗隐私定义下的根本限制尚未被充分理解。研究者希望分析DP-SGD在f-差分隐私框架下的隐私-效用权衡，揭示其内在局限性。

Method: 在f-差分隐私框架下分析DP-SGD，研究单轮训练中M次梯度更新的洗牌采样。推导出可实现的权衡曲线的显式次优上界，进而得到分离度κ的几何下界。分析噪声乘子σ与分离度κ之间的严格下界关系，并将结果扩展到泊松子采样。

Result: 证明在最坏情况对抗模型下，洗牌DP-SGD必须满足σ≥1/√(2lnM)或κ≥1/√8(1-1/√(4πlnM))，无法同时实现强隐私和高效用。该界限虽然随M→∞而消失，但收敛极慢，实际更新次数下所需噪声幅度仍然很大。实验证实该噪声水平会导致实际训练中精度显著下降。

Conclusion: DP-SGD在标准最坏情况对抗假设下存在关键瓶颈：隐私保护与模型效用之间存在根本性权衡，无法同时实现两者。这揭示了当前DP-SGD方法的局限性，为未来私有机器学习研究提供了重要方向。

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) is the dominant paradigm for private training, but its fundamental limitations under worst-case adversarial privacy definitions remain poorly understood. We analyze DP-SGD in the $f$-differential privacy framework, which characterizes privacy via hypothesis-testing trade-off curves, and study shuffled sampling over a single epoch with $M$ gradient updates. We derive an explicit suboptimal upper bound on the achievable trade-off curve. This result induces a geometric lower bound on the separation $κ$ which is the maximum distance between the mechanism's trade-off curve and the ideal random-guessing line. Because a large separation implies significant adversarial advantage, meaningful privacy requires small $κ$. However, we prove that enforcing a small separation imposes a strict lower bound on the Gaussian noise multiplier $σ$, which directly limits the achievable utility. In particular, under the standard worst-case adversarial model, shuffled DP-SGD must satisfy
  $σ\ge \frac{1}{\sqrt{2\ln M}}$ $\quad\text{or}\quad$ $κ\ge\ \frac{1}{\sqrt{8}}\!\left(1-\frac{1}{\sqrt{4π\ln M}}\right)$,
  and thus cannot simultaneously achieve strong privacy and high utility. Although this bound vanishes asymptotically as $M \to \infty$, the convergence is extremely slow: even for practically relevant numbers of updates the required noise magnitude remains substantial. We further show that the same limitation extends to Poisson subsampling up to constant factors. Our experiments confirm that the noise levels implied by this bound leads to significant accuracy degradation at realistic training settings, thus showing a critical bottleneck in DP-SGD under standard worst-case adversarial assumptions.

</details>


### [147] [X-SAM: Boosting Sharpness-Aware Minimization with Dominant-Eigenvector Gradient Correction](https://arxiv.org/abs/2601.10251)
*Hongru Duan,Yongle Chen,Lei Guan*

Main category: cs.LG

TL;DR: 论文提出X-SAM方法，通过沿Hessian矩阵最大特征向量正交分解修正梯度，更直接有效地正则化最大特征值，解决SAM在尖锐区域失效的问题。


<details>
  <summary>Details</summary>
Motivation: SAM方法旨在通过最小化参数邻域内的最差扰动损失来提升泛化能力，但实际训练中，尖锐和平坦区域都可能产生小的扰动损失，导致梯度仍指向尖锐区域，无法实现SAM的预期效果。

Method: 从谱和几何角度分析SAM，利用梯度与Hessian矩阵主导特征向量之间的夹角作为尖锐度度量。提出显式特征向量对齐的SAM（X-SAM），通过沿顶部特征向量进行正交分解来修正梯度，实现对Hessian最大特征值的更直接有效正则化。

Result: 证明了X-SAM的收敛性和优越泛化能力，大量实验评估证实了理论和实践优势。

Conclusion: X-SAM通过显式对齐Hessian特征向量，解决了SAM在尖锐区域失效的问题，实现了更有效的尖锐度正则化，提升了模型泛化性能。

Abstract: Sharpness-Aware Minimization (SAM) aims to improve generalization by minimizing a worst-case perturbed loss over a small neighborhood of model parameters. However, during training, its optimization behavior does not always align with theoretical expectations, since both sharp and flat regions may yield a small perturbed loss. In such cases, the gradient may still point toward sharp regions, failing to achieve the intended effect of SAM. To address this issue, we investigate SAM from a spectral and geometric perspective: specifically, we utilize the angle between the gradient and the leading eigenvector of the Hessian as a measure of sharpness. Our analysis illustrates that when this angle is less than or equal to ninety degrees, the effect of SAM's sharpness regularization can be weakened. Furthermore, we propose an explicit eigenvector-aligned SAM (X-SAM), which corrects the gradient via orthogonal decomposition along the top eigenvector, enabling more direct and efficient regularization of the Hessian's maximum eigenvalue. We prove X-SAM's convergence and superior generalization, with extensive experimental evaluations confirming both theoretical and practical advantages.

</details>


### [148] [In-Context Source and Channel Coding](https://arxiv.org/abs/2601.10267)
*Ziqiong Wang,Tianqi Ren,Rongpeng Li,Zhifeng Zhao,Honggang Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种接收端上下文解码（ICD）框架，通过错误校正码变换器获取比特可靠性，构建置信度排序的候选池，结合LLM算术解码器，在不改变发射端的情况下增强分离源信道编码的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 分离源信道编码（SSCC）在低信噪比下存在明显的悬崖效应，信道解码后的残留比特错误会灾难性地破坏无损源解码，特别是对于基于大语言模型的算术编码。需要在不修改发射端的情况下增强SSCC的鲁棒性。

Method: 提出接收端上下文解码（ICD）框架：1）使用错误校正码变换器（ECCT）获取解码信息比特的比特级可靠性；2）基于上下文一致的比特流，通过可靠性引导的比特翻转构建置信度排序的候选池；3）采样紧凑而多样化的候选子集；4）应用基于LLM的算术解码器获取重构和序列级对数似然；5）通过可靠性-似然融合规则选择最终输出。

Result: 在加性高斯白噪声（AWGN）和瑞利衰落信道上的大量实验表明，相比传统SSCC基线和代表性联合源信道编码（JSCC）方案，ICD框架取得了持续的性能增益。

Conclusion: ICD框架通过接收端处理增强了SSCC的鲁棒性，避免了发射端修改，提供了采样过程的稳定性和收敛性理论保证，在低信噪比下有效缓解了悬崖效应问题。

Abstract: Separate Source-Channel Coding (SSCC) remains attractive for text transmission due to its modularity and compatibility with mature entropy coders and powerful channel codes. However, SSCC often suffers from a pronounced cliff effect in low Signal-to-Noise Ratio (SNR) regimes, where residual bit errors after channel decoding can catastrophically break lossless source decoding, especially for Arithmetic Coding (AC) driven by Large Language Models (LLMs). This paper proposes a receiver-side In-Context Decoding (ICD) framework that enhances SSCC robustness without modifying the transmitter. ICD leverages an Error Correction Code Transformer (ECCT) to obtain bit-wise reliability for the decoded information bits. Based on the context-consistent bitstream, ICD constructs a confidence-ranked candidate pool via reliability-guided bit flipping, samples a compact yet diverse subset of candidates, and applies an LLM-based arithmetic decoder to obtain both reconstructions and sequence-level log-likelihoods. A reliability-likelihood fusion rule then selects the final output. We further provide theoretical guarantees on the stability and convergence of the proposed sampling procedure. Extensive experiments over Additive White Gaussian Noise (AWGN) and Rayleigh fading channels demonstrate consistent gains compared with conventional SSCC baselines and representative Joint Source-Channel Coding (JSCC) schemes.

</details>


### [149] [Early Fault Detection on CMAPSS with Unsupervised LSTM Autoencoders](https://arxiv.org/abs/2601.10269)
*P. Sánchez,K. Reyes,B. Radu,E. Fernández*

Main category: cs.LG

TL;DR: 提出一种无需故障标签的无监督涡扇发动机健康监测框架，通过回归归一化消除工况影响，使用LSTM自编码器检测异常，实现高召回率和低误报率。


<details>
  <summary>Details</summary>
Motivation: 传统健康监测方法需要故障标签（run-to-failure labels），这在现实中难以获取。需要开发无需标签、能快速部署、适应不同工况的无监督方法。

Method: 1. 使用基于回归的归一化消除NASA CMAPSS传感器数据中的工况影响；2. 仅使用健康数据训练LSTM自编码器；3. 采用自适应数据驱动阈值估计持续重构误差，实时触发警报，无需人工调参规则。

Result: 基准测试显示该方法在多种工况下均实现高召回率和低误报率，能够快速部署、适应不同机队规模，可作为剩余使用寿命模型的补充预警层。

Conclusion: 该无监督框架有效解决了故障标签稀缺问题，实现了实时健康监测，具有快速部署、可扩展性强等优势，为涡扇发动机健康管理提供了实用解决方案。

Abstract: This paper introduces an unsupervised health-monitoring framework for turbofan engines that does not require run-to-failure labels. First, operating-condition effects in NASA CMAPSS sensor streams are removed via regression-based normalisation; then a Long Short-Term Memory (LSTM) autoencoder is trained only on the healthy portion of each trajectory. Persistent reconstruction error, estimated using an adaptive data-driven threshold, triggers real-time alerts without hand-tuned rules. Benchmark results show high recall and low false-alarm rates across multiple operating regimes, demonstrating that the method can be deployed quickly, scale to diverse fleets, and serve as a complementary early-warning layer to Remaining Useful Life models.

</details>


### [150] [SPIKE: Sparse Koopman Regularization for Physics-Informed Neural Networks](https://arxiv.org/abs/2601.10282)
*Jose Marie Antonio Minoza*

Main category: cs.LG

TL;DR: SPIKE框架通过结合连续时间Koopman算子和稀疏正则化来改进PINNs，解决其在训练域内过拟合和域外泛化差的问题，提升对复杂动力学的长期预测能力。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）在求解微分方程时存在训练域内过拟合问题，导致在时空区域外泛化能力差。需要一种能学习简约动力学表示的方法来改善长期预测性能。

Method: 提出SPIKE框架，将连续时间Koopman算子作为正则化项融入PINNs。在学习的可观测空间中强制线性动力学dz/dt=Az，并通过L1正则化使生成矩阵A稀疏化，体现复杂动力学的低维结构原理。

Result: 在抛物线、双曲线、色散和刚性PDE（包括Navier-Stokes流体动力学）以及混沌ODE（Lorenz系统）上的实验表明，该方法在时间外推、空间泛化和长期预测精度方面均有显著提升。

Conclusion: SPIKE框架通过连续时间Koopman算子和稀疏正则化，有效解决了PINNs的过拟合问题，提高了对复杂动力学的泛化能力和长期预测稳定性，特别适用于刚性系统。

Abstract: Physics-Informed Neural Networks (PINNs) provide a mesh-free approach for solving differential equations by embedding physical constraints into neural network training. However, PINNs tend to overfit within the training domain, leading to poor generalization when extrapolating beyond trained spatiotemporal regions. This work presents SPIKE (Sparse Physics-Informed Koopman-Enhanced), a framework that regularizes PINNs with continuous-time Koopman operators to learn parsimonious dynamics representations. By enforcing linear dynamics $dz/dt = Az$ in a learned observable space, both PIKE (without explicit sparsity) and SPIKE (with L1 regularization on $A$) learn sparse generator matrices, embodying the parsimony principle that complex dynamics admit low-dimensional structure. Experiments across parabolic, hyperbolic, dispersive, and stiff PDEs, including fluid dynamics (Navier-Stokes) and chaotic ODEs (Lorenz), demonstrate consistent improvements in temporal extrapolation, spatial generalization, and long-term prediction accuracy. The continuous-time formulation with matrix exponential integration provides unconditional stability for stiff systems while avoiding diagonal dominance issues inherent in discrete-time Koopman operators.

</details>


### [151] [We Need a More Robust Classifier: Dual Causal Learning Empowers Domain-Incremental Time Series Classification](https://arxiv.org/abs/2601.10312)
*Zhipeng Liu,Peibo Duan,Xuan Tang,Haodong Jing,Mingyang Geng,Yongsheng Huang,Jialu Xu,Bin Zhang,Binwu Wang*

Main category: cs.LG

TL;DR: 提出DualCD框架，通过双重因果解耦增强时间序列分类在领域增量学习中的鲁棒性，包含时序特征解耦模块和双重因果干预机制。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类研究在领域增量学习方面面临挑战，需要提升模型在领域增量场景下的鲁棒性。

Method: 提出轻量级双重因果解耦框架(DualCD)：1) 时序特征解耦模块分离类别因果特征和伪特征；2) 双重因果干预机制消除类内和类间混淆特征影响，通过构建变体样本和因果干预损失训练模型。

Result: 在多个数据集和模型上的实验表明，DualCD能有效提升领域增量场景下的性能，并建立了全面的基准测试。

Conclusion: DualCD框架通过因果特征解耦和干预机制，显著增强了时间序列分类模型在领域增量学习中的鲁棒性，为相关研究提供了有价值的基准。

Abstract: The World Wide Web thrives on intelligent services that rely on accurate time series classification, which has recently witnessed significant progress driven by advances in deep learning. However, existing studies face challenges in domain incremental learning. In this paper, we propose a lightweight and robust dual-causal disentanglement framework (DualCD) to enhance the robustness of models under domain incremental scenarios, which can be seamlessly integrated into time series classification models. Specifically, DualCD first introduces a temporal feature disentanglement module to capture class-causal features and spurious features. The causal features can offer sufficient predictive power to support the classifier in domain incremental learning settings. To accurately capture these causal features, we further design a dual-causal intervention mechanism to eliminate the influence of both intra-class and inter-class confounding features. This mechanism constructs variant samples by combining the current class's causal features with intra-class spurious features and with causal features from other classes. The causal intervention loss encourages the model to accurately predict the labels of these variant samples based solely on the causal features. Extensive experiments on multiple datasets and models demonstrate that DualCD effectively improves performance in domain incremental scenarios. We summarize our rich experiments into a comprehensive benchmark to facilitate research in domain incremental time series classification.

</details>


### [152] [Meta Dynamic Graph for Traffic Flow Prediction](https://arxiv.org/abs/2601.10328)
*Yiqing Zou,Hanning Yuan,Qianyu Yang,Ziqiang Yuan,Shuliang Wang,Sijie Ruan*

Main category: cs.LG

TL;DR: MetaDG：一个利用动态图结构建模时空动态的交通预测框架，通过动态邻接矩阵和元参数统一捕捉时空异质性


<details>
  <summary>Details</summary>
Motivation: 现有交通预测方法存在两个主要局限：1）动态建模通常局限于空间拓扑的动态（如邻接矩阵变化），但可以扩展到更广范围；2）异质性建模通常将空间和时间维度分开处理，而动态建模可以弥合这一差距

Method: 提出Meta Dynamic Graph (MetaDG)框架，利用节点表示的动态图结构来显式建模时空动态，生成动态邻接矩阵和元参数，将动态建模扩展到拓扑之外，并将时空异质性的捕捉统一到单一维度

Result: 在四个真实世界数据集上的大量实验验证了MetaDG的有效性

Conclusion: MetaDG通过动态图结构建模时空动态，扩展了动态建模的范围并统一了时空异质性的捕捉，为交通预测提供了有效的解决方案

Abstract: Traffic flow prediction is a typical spatio-temporal prediction problem and has a wide range of applications. The core challenge lies in modeling the underlying complex spatio-temporal dependencies. Various methods have been proposed, and recent studies show that the modeling of dynamics is useful to meet the core challenge. While handling spatial dependencies and temporal dependencies using separate base model structures may hinder the modeling of spatio-temporal correlations, the modeling of dynamics can bridge this gap. Incorporating spatio-temporal heterogeneity also advances the main goal, since it can extend the parameter space and allow more flexibility. Despite these advances, two limitations persist: 1) the modeling of dynamics is often limited to the dynamics of spatial topology (e.g., adjacency matrix changes), which, however, can be extended to a broader scope; 2) the modeling of heterogeneity is often separated for spatial and temporal dimensions, but this gap can also be bridged by the modeling of dynamics. To address the above limitations, we propose a novel framework for traffic prediction, called Meta Dynamic Graph (MetaDG). MetaDG leverages dynamic graph structures of node representations to explicitly model spatio-temporal dynamics. This generates both dynamic adjacency matrices and meta-parameters, extending dynamic modeling beyond topology while unifying the capture of spatio-temporal heterogeneity into a single dimension. Extensive experiments on four real-world datasets validate the effectiveness of MetaDG.

</details>


### [153] [SuS: Strategy-aware Surprise for Intrinsic Exploration](https://arxiv.org/abs/2601.10349)
*Mark Kashirskiy,Ilya Makarov*

Main category: cs.LG

TL;DR: 提出Strategy-aware Surprise (SuS)框架，通过策略稳定性和策略惊喜两个互补组件，利用前后预测不匹配作为探索的新颖性信号，在数学推理任务上显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于好奇心的探索方法仅依赖状态预测误差，缺乏对智能体行为策略一致性和策略层面意外结果的考量，限制了在复杂任务（如数学推理）中的探索效果。

Method: 提出SuS框架，包含两个核心组件：策略稳定性（SS）衡量时间步之间行为策略的一致性；策略惊喜（SuS）捕捉相对于当前策略表示的意外结果。通过学习的权重系数将两个信号结合到奖励函数中。

Result: 在数学推理任务上，SuS相比基线方法在Pass@1上提升17.4%，在Pass@5上提升26.4%，同时保持更高的策略多样性。消融实验表明移除任一组件会导致至少10%的性能下降。

Conclusion: SuS框架通过结合策略稳定性和策略惊喜两个互补信号，有效提升了强化学习中的探索能力，特别是在数学推理等复杂任务中，证明了策略层面新颖性信号的重要性。

Abstract: We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.

</details>


### [154] [EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography](https://arxiv.org/abs/2601.10356)
*Mesut Ceylan,Alexis Tabin,Patrick Langer,Elgar Fleisch,Filipe Barata*

Main category: cs.LG

TL;DR: 提出EvoMorph框架，通过多目标进化算法生成生理上合理的反事实解释，用于可穿戴设备PPG信号的回归任务，支持临床不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备产生大量PPG信号用于临床评估，但现有反事实解释方法主要针对分类任务，忽视波形形态，且常产生生理上不合理的信号，限制了其在连续生物医学时间序列中的应用。

Method: 提出EvoMorph多目标进化框架，优化基于可解释信号描述符的形态感知目标，应用变换保持波形结构，生成生理合理且多样化的反事实解释。

Result: 在三个PPG数据集（心率、呼吸率、血氧饱和度）上评估，优于最近非相似邻居基线；案例研究显示可将反事实敏感性与bootstrap集成不确定性和数据密度测量相关联。

Conclusion: EvoMorph能够为连续生物医学信号生成生理感知的反事实解释，支持不确定性感知的可解释性，推进临床时间序列应用的可信模型分析。

Abstract: Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand whether predictions are stable under physiologically plausible variations and to what extent realistic, attainable changes in physiological signals would meaningfully alter a model's prediction. Counterfactual explanations (CFE) address these "what-if" questions, yet existing time series CFE generation methods are largely restricted to classification, overlook waveform morphology, and often produce physiologically implausible signals, limiting their applicability to continuous biomedical time series. To address these limitations, we introduce EvoMorph, a multi-objective evolutionary framework for generating physiologically plausible and diverse CFE for TSER applications. EvoMorph optimizes morphology-aware objectives defined on interpretable signal descriptors and applies transformations to preserve the waveform structure. We evaluated EvoMorph on three PPG datasets (heart rate, respiratory rate, and oxygen saturation) against a nearest-unlike-neighbor baseline. In addition, in a case study, we evaluated EvoMorph as a tool for uncertainty quantification by relating counterfactual sensitivity to bootstrap-ensemble uncertainty and data-density measures. Overall, EvoMorph enables the generation of physiologically-aware counterfactuals for continuous biomedical signals and supports uncertainty-aware interpretability, advancing trustworthy model analysis for clinical time-series applications.

</details>


### [155] [PLGC: Pseudo-Labeled Graph Condensation](https://arxiv.org/abs/2601.10358)
*Jay Nandy,Arnab Kumar Mondal,Anuj Rathore,Mahesh Chandran*

Main category: cs.LG

TL;DR: PLGC是一种无需真实标签的自监督图压缩方法，通过潜在伪标签和结构统计匹配来生成合成图，在标签噪声和分布偏移下表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有图压缩方法依赖干净监督标签，在标签稀缺、噪声或不一致时可靠性受限，需要一种无需真实标签的自适应方法。

Method: 提出伪标签图压缩(PLGC)框架：1)从节点嵌入构建潜在伪标签；2)联合学习潜在原型和节点分配；3)优化压缩图以匹配原图的结构和特征统计。

Result: 在节点分类和链接预测任务上，PLGC在干净数据集上与最先进的监督压缩方法性能相当，在标签噪声下显著优于所有基线方法。

Conclusion: 自监督图压缩在噪声或弱标签环境中具有实际和理论优势，PLGC为标签不可靠场景提供了鲁棒的解决方案。

Abstract: Large graph datasets make training graph neural networks (GNNs) computationally costly. Graph condensation methods address this by generating small synthetic graphs that approximate the original data. However, existing approaches rely on clean, supervised labels, which limits their reliability when labels are scarce, noisy, or inconsistent. We propose Pseudo-Labeled Graph Condensation (PLGC), a self-supervised framework that constructs latent pseudo-labels from node embeddings and optimizes condensed graphs to match the original graph's structural and feature statistics -- without requiring ground-truth labels. PLGC offers three key contributions: (1) A diagnosis of why supervised condensation fails under label noise and distribution shift. (2) A label-free condensation method that jointly learns latent prototypes and node assignments. (3) Theoretical guarantees showing that pseudo-labels preserve latent structural statistics of the original graph and ensure accurate embedding alignment. Empirically, across node classification and link prediction tasks, PLGC achieves competitive performance with state-of-the-art supervised condensation methods on clean datasets and exhibits substantial robustness under label noise, often outperforming all baselines by a significant margin. Our findings highlight the practical and theoretical advantages of self-supervised graph condensation in noisy or weakly-labeled environments.

</details>


### [156] [Discrete Feynman-Kac Correctors](https://arxiv.org/abs/2601.10403)
*Mohsin Hasan,Viktor Ohanesian,Artem Gazizov,Yoshua Bengio,Alán Aspuru-Guzik,Roberto Bondesan,Marta Skreta,Kirill Neklyudov*

Main category: cs.LG

TL;DR: 提出Discrete Feynman-Kac Correctors框架，用于在推理时控制离散掩码扩散模型的生成分布，无需额外训练或微调。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型虽然能捕捉数据中的层次非序列依赖关系，但其自定义的生成过程缺乏对生成样本分布的灵活控制。

Method: 基于离散Feynman-Kac校正器框架，推导出序列蒙特卡洛算法，可在推理时控制采样分布的温度、从多个扩散过程边缘分布的乘积中采样，以及从边缘分布与外部奖励函数的乘积中采样。

Result: 该框架在多个应用中展示了实用性：从伊辛模型的退火玻尔兹曼分布高效采样、提高代码生成和摊销学习的语言模型性能，以及奖励倾斜的蛋白质序列生成。

Conclusion: 提出的框架为离散扩散模型提供了灵活的推理时控制能力，无需额外训练成本，在多种序列生成任务中展现出实用价值。

Abstract: Discrete diffusion models have recently emerged as a promising alternative to the autoregressive approach for generating discrete sequences. Sample generation via gradual denoising or demasking processes allows them to capture hierarchical non-sequential interdependencies in the data. These custom processes, however, do not assume a flexible control over the distribution of generated samples. We propose Discrete Feynman-Kac Correctors, a framework that allows for controlling the generated distribution of discrete masked diffusion models at inference time. We derive Sequential Monte Carlo (SMC) algorithms that, given a trained discrete diffusion model, control the temperature of the sampled distribution (i.e. perform annealing), sample from the product of marginals of several diffusion processes (e.g. differently conditioned processes), and sample from the product of the marginal with an external reward function, producing likely samples from the target distribution that also have high reward. Notably, our framework does not require any training of additional models or fine-tuning of the original model. We illustrate the utility of our framework in several applications including: efficient sampling from the annealed Boltzmann distribution of the Ising model, improving the performance of language models for code generation and amortized learning, as well as reward-tilted protein sequence generation.

</details>


### [157] [CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning](https://arxiv.org/abs/2601.10407)
*Yuanjie Zhao,Junnan Qiu,Yue Ding,Jie Li*

Main category: cs.LG

TL;DR: 提出CS-GBA攻击框架，针对安全约束的离线强化学习算法，通过关键样本选择、相关性破坏触发器和梯度引导动作生成，在5%毒化预算下实现高隐蔽性和破坏性攻击。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击策略难以对抗安全约束的离线RL算法（如CQL），因为随机毒化效率低且使用易检测的分布外触发器。需要设计更隐蔽、高效的攻击方法。

Method: 1. 基于TD误差的关键样本选择策略，集中攻击预算于最有影响的转移样本；2. 相关性破坏触发器机制，利用状态特征的物理互斥性保持统计隐蔽性；3. 梯度引导动作生成机制，利用受害者Q网络的梯度在数据流形中搜索最坏动作。

Result: 在D4RL基准测试中显著优于现有基线方法，仅用5%毒化预算就能对代表性安全约束算法实现高攻击成功率，同时在干净环境中保持智能体性能。

Conclusion: CS-GBA框架成功解决了离线RL后门攻击中的隐蔽性和效率问题，通过理论驱动的关键样本选择和统计隐蔽的触发器设计，实现了对安全约束算法的高效攻击。

Abstract: Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructiveness under a strict budget. Leveraging the theoretical insight that samples with high Temporal Difference (TD) errors are pivotal for value function convergence, we introduce an adaptive Critical Sample Selection strategy that concentrates the attack budget on the most influential transitions. To evade OOD detection, we propose a Correlation-Breaking Trigger mechanism that exploits the physical mutual exclusivity of state features (e.g., 95th percentile boundaries) to remain statistically concealed. Furthermore, we replace the conventional label inversion with a Gradient-Guided Action Generation mechanism, which searches for worst-case actions within the data manifold using the victim Q-network's gradient. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms state-of-the-art baselines, achieving high attack success rates against representative safety-constrained algorithms with a minimal 5% poisoning budget, while maintaining the agent's performance in clean environments.

</details>


### [158] [DeFlow: Decoupling Manifold Modeling and Value Maximization for Offline Policy Extraction](https://arxiv.org/abs/2601.10471)
*Zhancun Mu*

Main category: cs.LG

TL;DR: DeFlow提出解耦的离线强化学习框架，利用流匹配技术捕捉复杂行为流形，通过轻量级精炼模块在信任区域内优化，避免求解器微分和损失项平衡问题


<details>
  <summary>Details</summary>
Motivation: 生成式策略优化计算成本高，通常需要通过ODE求解器进行反向传播，这限制了实际应用。现有方法要么计算代价大，要么通过单步蒸馏牺牲迭代生成能力

Method: 学习轻量级精炼模块，在流形显式的数据驱动信任区域内进行优化，而不是通过单步蒸馏牺牲迭代生成能力。这种方法绕过了求解器微分，消除了损失项平衡需求

Result: 在具有挑战性的OGBench基准测试中取得优越性能，并展示了高效的离线到在线适应能力

Conclusion: DeFlow通过解耦框架和流匹配技术，在保持流迭代表达能力的同时实现了稳定改进，为生成式离线RL提供了高效解决方案

Abstract: We present DeFlow, a decoupled offline RL framework that leverages flow matching to faithfully capture complex behavior manifolds. Optimizing generative policies is computationally prohibitive, typically necessitating backpropagation through ODE solvers. We address this by learning a lightweight refinement module within an explicit, data-derived trust region of the flow manifold, rather than sacrificing the iterative generation capability via single-step distillation. This way, we bypass solver differentiation and eliminate the need for balancing loss terms, ensuring stable improvement while fully preserving the flow's iterative expressivity. Empirically, DeFlow achieves superior performance on the challenging OGBench benchmark and demonstrates efficient offline-to-online adaptation.

</details>


### [159] [Communication-Efficient Federated Learning by Exploiting Spatio-Temporal Correlations of Gradients](https://arxiv.org/abs/2601.10491)
*Shenlong Zheng,Zhen Zhang,Yuhui Deng,Geyong Min,Lin Cui*

Main category: cs.LG

TL;DR: GradESTC：一种利用梯度的空间和时间相关性来减少联邦学习通信开销的压缩技术，相比最强基线平均减少39.79%的上行通信量。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的通信开销是一个关键挑战，特别是在带宽受限的网络中。现有方法大多只关注压缩单个梯度，忽略了梯度之间的时间相关性。研究发现梯度不仅具有空间相关性（低秩结构），在相邻轮次之间还存在强烈的时间相关性。

Method: 提出GradESTC压缩技术，同时利用梯度的空间和时间相关性：1）利用空间相关性将完整梯度分解为紧凑的基向量和组合系数；2）利用时间相关性，每轮只需动态更新少量基向量；3）通过传输轻量级组合系数和有限的更新基向量来替代完整梯度。

Result: 在达到接近收敛的目标精度水平时，GradESTC相比最强基线平均减少39.79%的上行通信量，同时保持了与未压缩FedAvg相当的收敛速度和最终精度。

Conclusion: 通过有效利用梯度的时空结构，GradESTC为通信高效的联邦学习提供了一个实用且可扩展的解决方案。

Abstract: Communication overhead is a critical challenge in federated learning, particularly in bandwidth-constrained networks. Although many methods have been proposed to reduce communication overhead, most focus solely on compressing individual gradients, overlooking the temporal correlations among them. Prior studies have shown that gradients exhibit spatial correlations, typically reflected in low-rank structures. Through empirical analysis, we further observe a strong temporal correlation between client gradients across adjacent rounds. Based on these observations, we propose GradESTC, a compression technique that exploits both spatial and temporal gradient correlations. GradESTC exploits spatial correlations to decompose each full gradient into a compact set of basis vectors and corresponding combination coefficients. By exploiting temporal correlations, only a small portion of the basis vectors need to be dynamically updated in each round. GradESTC significantly reduces communication overhead by transmitting lightweight combination coefficients and a limited number of updated basis vectors instead of the full gradients. Extensive experiments show that, upon reaching a target accuracy level near convergence, GradESTC reduces uplink communication by an average of 39.79% compared to the strongest baseline, while maintaining comparable convergence speed and final accuracy to uncompressed FedAvg. By effectively leveraging spatio-temporal gradient structures, GradESTC offers a practical and scalable solution for communication-efficient federated learning.

</details>


### [160] [Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning](https://arxiv.org/abs/2601.10498)
*Nilin Abrahamsen*

Main category: cs.LG

TL;DR: PROMA是一种用于大语言模型微调的新策略更新方法，通过投影去除序列梯度分量，实现更稳定的策略学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法如PPO和GRPO在策略更新中存在局限性，如熵崩溃、依赖参考策略或似然比裁剪，需要更稳定高效的近端策略更新方法。

Method: PROMA在反向传播过程中逐层投影去除序列梯度分量，然后在微批次间累积策略梯度，无需额外前向或反向传播。

Result: 相比GRPO，PROMA能更严格地控制局部KL散度，实现更稳定的策略学习，且不会导致熵崩溃，也不依赖参考策略或似然比裁剪。

Conclusion: PROMA提供了一种高效稳定的近端策略更新方法，解决了现有方法的局限性，为大语言模型微调提供了新选择。

Abstract: This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.

</details>


### [161] [Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models](https://arxiv.org/abs/2601.10519)
*Andrea Melis,Andrea Piroddi,Roberto Girau*

Main category: cs.LG

TL;DR: 使用GPT-2 Transformer模型生成新型调制方案，相比传统方法在SNR和PSD等性能指标上表现相当甚至更优


<details>
  <summary>Details</summary>
Motivation: 认知无线电系统需要动态适应频谱环境，机器学习技术特别是Transformer模型可以提升频谱效率、鲁棒性和安全性

Method: 使用GPT-2架构的Transformer模型，在现有调制公式数据集上进行训练，生成新的调制方案，并与传统方法在SNR和PSD等指标上进行比较

Result: Transformer生成的调制方案在性能上与传统方法相当，在某些情况下甚至更优

Conclusion: Transformer模型可以显著增强认知无线电系统，实现更高效、鲁棒和安全的通信系统

Abstract: Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems.

</details>


### [162] [Mixtures of Transparent Local Models](https://arxiv.org/abs/2601.10541)
*Niffa Cheick Oumar Diaby,Thierry Duchesne,Mario Marchand*

Main category: cs.LG

TL;DR: 该论文提出了一种基于局部透明模型的混合方法，用于构建可解释的机器学习模型，通过PAC-Bayesian理论建立了风险边界，并在合成和真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在人类活动中日益普及，对模型透明度的需求不断增长。透明模型有助于识别安全性和非歧视性等因素。当前需要一种能够处理输入空间中不同区域具有不同简单透明函数的场景的解决方案。

Method: 提出了一种混合局部透明模型的方法，通过多预测器（多局部性）损失函数同时学习透明标记函数和输入空间的局部区域。该方法建立了二元线性分类和线性回归问题的严格PAC-Bayesian风险边界。

Result: 在合成数据集上展示了学习算法的工作原理，在真实数据集上的结果表明该方法与其他现有方法以及某些不透明模型相比具有竞争力。

Conclusion: 混合局部透明模型是一种有效的可解释模型设计方法，能够在保持透明度的同时处理输入空间中函数变化的情况，并通过理论风险边界提供了理论保证。

Abstract: The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models.

</details>


### [163] [Process-Guided Concept Bottleneck Model](https://arxiv.org/abs/2601.10562)
*Reza M. Asiyabi,SEOSAW Partnership,Steven Hancock,Casey Ryan*

Main category: cs.LG

TL;DR: PG-CBM扩展了概念瓶颈模型，通过领域定义的因果机制约束学习，使用生物物理意义的中介概念，在科学应用中提高准确性、可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 标准概念瓶颈模型(CBMs)存在三个主要问题：1) 忽视领域特定关系和因果机制；2) 依赖完整概念标签；3) 在科学领域监督稀疏但过程定义明确的情况下适用性受限。需要一种能够利用领域知识、处理稀疏监督并保持可解释性的方法。

Method: 提出过程引导概念瓶颈模型(PG-CBM)，通过生物物理意义的中介概念约束学习遵循领域定义的因果机制。使用地球观测数据中的地上生物量密度估计作为案例研究，利用多源异构训练数据，产生可解释的中间输出。

Result: PG-CBM相比多个基准模型减少了误差和偏差，同时利用多源异构训练数据并产生可解释的中间输出。除了提高准确性外，还增强了透明度，能够检测虚假学习，并提供科学见解。

Conclusion: PG-CBM代表了科学应用中更可信AI系统的一步，通过整合领域知识、因果机制和可解释性，在保持准确性的同时提高模型的透明度和科学价值。

Abstract: Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications.

</details>


### [164] [Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling](https://arxiv.org/abs/2601.10563)
*Aradhya Gaonkar,Nihal Jain,Vignesh Chougule,Nikhil Deshpande,Sneha Varur,Channabasappa Muttal*

Main category: cs.LG

TL;DR: KAN在非线性函数逼近、时间序列预测和多变量分类任务中全面优于MLP，具有更高的预测精度和更低的计算成本，特别适合资源受限和实时应用场景。


<details>
  <summary>Details</summary>
Motivation: 比较Kolmogorov-Arnold网络（KAN）和多层感知机（MLP）在解决基本计算问题上的有效性，探索更高效、更准确的神经网络架构。

Method: 基于Kolmogorov表示定理，KAN采用自适应样条激活函数和网格结构，使用多种数据集（二次/三次函数估计、温度预测、葡萄酒分类）评估模型性能，通过MSE和FLOPs衡量精度和计算成本。

Result: KAN在所有基准测试中都显著优于MLP，获得更高的预测精度和显著降低的计算成本，在计算效率和准确性之间取得了良好平衡。

Conclusion: KAN在资源受限和实时操作环境中具有明显优势，为特定任务选择最合适的神经网络架构提供了系统框架，在推进智能系统方面具有变革性潜力。

Abstract: The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov's representation theorem, KANs utilize adaptive spline-based activation functions and grid-based structures, providing a transformative approach compared to traditional neural network frameworks. Utilizing a variety of datasets spanning mathematical function estimation (quadratic and cubic) to practical uses like predicting daily temperatures and categorizing wines, the proposed research thoroughly assesses model performance via accuracy measures like Mean Squared Error (MSE) and computational expense assessed through Floating Point Operations (FLOPs). The results indicate that KANs reliably exceed MLPs in every benchmark, attaining higher predictive accuracy with significantly reduced computational costs. Such an outcome highlights their ability to maintain a balance between computational efficiency and accuracy, rendering them especially beneficial in resource-limited and real-time operational environments. By elucidating the architectural and functional distinctions between KANs and MLPs, the paper provides a systematic framework for selecting the most suitable neural architectures for specific tasks. Furthermore, the proposed study highlights the transformative capabilities of KANs in progressing intelligent systems, influencing their use in situations that require both interpretability and computational efficiency.

</details>


### [165] [STEM: Scaling Transformers with Embedding Modules](https://arxiv.org/abs/2601.10639)
*Ranajoy Sadhukhan,Sheng Cao,Harry Dong,Changsheng Zhao,Attiano Purpura-Pontoniere,Yuandong Tian,Zechun Liu,Beidi Chen*

Main category: cs.LG

TL;DR: STEM是一种静态、令牌索引的稀疏Transformer架构，用嵌入查找替换FFN上投影，在减少计算和参数访问的同时提升模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 细粒度稀疏性虽然能提高参数容量而不增加计算成本，但存在训练不稳定、负载均衡和通信开销等问题。需要一种既能扩展参数容量又能保持稳定训练和高效推理的方法。

Method: STEM用层本地嵌入查找替换FFN的上投影层，保留门控和下投影层为密集层。这种方法消除了运行时路由，支持CPU异步预取，并将容量与每令牌FLOPs和跨设备通信解耦。

Result: 在350M和1B模型规模上，STEM带来约3-4%的整体准确率提升，在知识和推理密集型基准测试（ARC-Challenge、OpenBookQA、GSM8K、MMLU）上表现尤为突出。同时减少约三分之一的FFN参数访问。

Conclusion: STEM是扩展参数容量的有效方法，提供更好的可解释性、训练稳定性和效率改进，特别是在长上下文场景下能实现实用的测试时容量扩展。

Abstract: Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from both per-token FLOPs and cross-device communication. Empirically, STEM trains stably despite extreme sparsity. It improves downstream performance over dense baselines while reducing per-token FLOPs and parameter accesses (eliminating roughly one-third of FFN parameters). STEM learns embedding spaces with large angular spread which enhances its knowledge storage capacity. More interestingly, this enhanced knowledge capacity comes with better interpretability. The token-indexed nature of STEM embeddings allows simple ways to perform knowledge editing and knowledge injection in an interpretable manner without any intervention in the input text or additional computation. In addition, STEM strengthens long-context performance: as sequence length grows, more distinct parameters are activated, yielding practical test-time capacity scaling. Across 350M and 1B model scales, STEM delivers up to ~3--4% accuracy improvements overall, with notable gains on knowledge and reasoning-heavy benchmarks (ARC-Challenge, OpenBookQA, GSM8K, MMLU). Overall, STEM is an effective way of scaling parametric memory while providing better interpretability, better training stability and improved efficiency.

</details>


### [166] [Single-Stage Huffman Encoder for ML Compression](https://arxiv.org/abs/2601.10673)
*Aditya Agrawal,Albert Magyar,Hiteshwar Eswaraiah,Patrick Sheridan,Pradeep Janedula,Ravi Krishnan Venkatesan,Krishna Nair,Ravi Iyer*

Main category: cs.LG

TL;DR: 提出单阶段哈夫曼编码器，使用固定码本消除传统三阶段哈夫曼编码的计算、延迟和数据开销，实现接近理想压缩率的实时压缩


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型训练和推理中，多加速器间的集体操作受网络带宽限制。传统哈夫曼编码的三阶段设计（频率分析、码本生成、码本传输）引入过多开销，不适合延迟敏感场景如芯片间通信

Method: 提出单阶段哈夫曼编码器，使用从先前数据批次平均概率分布推导的固定码本。通过分析Gemma 2B模型，发现张量在层和分片间具有高统计相似性，因此可用固定码本替代动态生成

Result: 压缩率接近每分片哈夫曼编码的0.5%以内，接近理想香农可压缩性的1%以内，实现高效实时压缩

Conclusion: 固定码本单阶段哈夫曼编码能有效消除传统方法开销，在保持接近理想压缩率的同时实现低延迟压缩，适用于大规模语言模型训练和推理场景

Abstract: Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensitive scenarios such as die-to-die communication. This paper proposes a single-stage Huffman encoder that eliminates these overheads by using fixed codebooks derived from the average probability distribution of previous data batches. Through our analysis of the Gemma 2B model, we demonstrate that tensors exhibit high statistical similarity across layers and shards. Using this approach we achieve compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon compressibility, enabling efficient on-the-fly compression.

</details>


### [167] [Data-driven stochastic reduced-order modeling of parametrized dynamical systems](https://arxiv.org/abs/2601.10690)
*Andrew F. Ilersich,Kevin Course,Prasanth B. Nair*

Main category: cs.LG

TL;DR: 提出基于摊销随机变分推断的数据驱动框架，学习连续时间随机降阶模型，能够泛化到未见过的参数组合和强迫条件，计算成本与数据集大小和系统刚度无关。


<details>
  <summary>Details</summary>
Motivation: 当前降阶模型方法在处理随机动力学和量化预测不确定性方面存在困难，限制了在鲁棒决策中的实用性。复杂动力系统在不同条件下的高保真模拟计算成本高昂，难以实现。

Method: 基于摊销随机变分推断，利用马尔可夫高斯过程的重参数化技巧，避免训练期间使用计算昂贵的正向求解器。联合学习概率自编码器和控制潜在动力学的随机微分方程。

Result: 在三个具有挑战性的测试问题上展示了优秀的泛化能力，能够处理未见过的参数组合和强迫条件，相比现有方法显著提高了效率。

Conclusion: 提出的框架能够有效学习连续时间随机降阶模型，量化预测不确定性，计算成本低，并可灵活融入物理先验知识，为复杂动力系统的建模提供了实用解决方案。

Abstract: Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches.

</details>


### [168] [Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis](https://arxiv.org/abs/2601.10701)
*Chun Hei Michael Shiu,Chih Wei Ling*

Main category: cs.LG

TL;DR: 本文对CEPAM（通信高效且隐私可调机制）进行了理论分析和实验评估，该机制通过RSUQ量化器在联邦学习中同时实现通信效率和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在数据治理约束下提供隐私保护协作，但仍面临通信效率和参与方间隐私保护等关键挑战。CEPAM作为一种新方法能同时实现这两个目标，需要对其隐私保证和收敛特性进行理论分析。

Method: CEPAM利用RSUQ（拒绝采样通用量化器），这是一种随机向量量化器，其量化误差等价于预设噪声，可调节以实现参与方间的定制化隐私保护。本文对CEPAM进行理论分析和实验评估。

Result: 通过实验评估CEPAM的效用性能，包括与其他基线的收敛曲线比较，以及不同参与方间的准确率-隐私权衡分析。

Conclusion: CEPAM在联邦学习中能有效平衡通信效率和隐私保护，通过理论分析和实验验证了其隐私保证和收敛特性，为实际应用提供了重要参考。

Abstract: Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties.

</details>


### [169] [Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication](https://arxiv.org/abs/2601.10705)
*Keval Jain,Anant Raj,Saurav Prakash,Girish Varma*

Main category: cs.LG

TL;DR: 该论文提出了一种用于半异步客户端-服务器感知机的聚合规则，能够处理联邦学习中的版本滞后、部分参与和通信噪声问题，并证明了在可分离数据下的错误边界。


<details>
  <summary>Details</summary>
Motivation: 研究联邦学习和分布式部署中的三个系统效应：1）由于模型交付延迟和客户端计算延迟应用导致的陈旧更新（双向版本滞后）；2）部分参与（客户端间歇性可用）；3）下行和上行链路上的不完美通信（建模为有界二阶矩的零均值加性噪声）。

Method: 提出了一种服务器端聚合规则——带填充的陈旧性桶聚合，该规则确定性地强制执行预定的陈旧性配置文件，而不假设延迟或参与的随机模型。在边缘可分离性和有界数据半径条件下，通过迭代参数混合（IPM-style averaging）训练半异步客户端-服务器感知机。

Result: 证明了在给定服务器轮数内，感知机错误的累积加权数的有限时域期望边界：延迟的影响仅通过平均强制执行陈旧性体现，而通信噪声贡献了一个与噪声能量总和的平方根成比例增长的额外项。在无噪声情况下，展示了有限期望错误预算如何在温和的新鲜参与条件下产生明确的有限轮稳定边界。

Conclusion: 该研究为联邦学习中的异步感知机训练提供了理论保证，表明通过适当的聚合规则可以有效处理系统延迟和通信噪声，同时保持收敛性能。

Abstract: We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition.

</details>


### [170] [High-accuracy and dimension-free sampling with diffusions](https://arxiv.org/abs/2601.10708)
*Khashayar Gatmiry,Sitan Chen,Adil Salim*

Main category: cs.LG

TL;DR: 提出一种新的扩散模型求解器，使用低阶近似和配置方法，迭代复杂度在1/ε上呈多对数缩放，实现首个仅使用数据分布分数近似访问的高精度扩散采样器保证。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在采样丰富多模态分布方面表现出色，但传统数值求解方法需要大量小迭代步才能产生高质量样本，迭代复杂度随维度和精度呈多项式增长，限制了效率。

Method: 提出新求解器，结合低阶近似和配置方法（Lee, Song, Vempala 2018），利用数据分布分数的近似访问，实现高效求解扩散微分方程。

Result: 证明新求解器的迭代复杂度在1/ε上呈多对数缩放，不显式依赖于环境维度，仅通过目标分布支撑集的有效半径影响复杂度，实现高精度采样保证。

Conclusion: 该方法首次为仅使用数据分布分数近似访问的扩散采样器提供了高精度理论保证，显著降低了迭代复杂度，对高维采样具有重要理论意义。

Abstract: Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \emph{polylogarithmically} in $1/\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \emph{effective radius} of the support of the target distribution only.

</details>


### [171] [DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids](https://arxiv.org/abs/2601.10715)
*Navami Kairanda,Shanthika Naik,Marc Habermann,Avinash Sharma,Christian Theobalt,Vladislav Golyanik*

Main category: cs.LG

TL;DR: 提出DInf-Grid：一种基于网格的可微分表示，结合径向基函数插值和多分辨率分解，用于高效求解微分方程，相比基于坐标的MLP方法加速5-20倍。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器存在效率问题：基于坐标的MLP方法（如正弦神经网络）计算密集且训练慢；基于网格的替代方法（如Instant-NGP和K-Planes）虽然训练快，但线性插值无法计算高阶导数，不适用于求解微分方程。

Method: 结合特征网格效率和径向基函数插值（无限可微），引入多分辨率分解和共置网格以捕捉高频解并实现稳定快速的全局梯度计算。使用微分方程作为损失函数进行隐式训练。

Result: 在泊松方程图像重建、亥姆霍兹方程波场、基尔霍夫-洛夫边界值问题布料模拟等任务上验证，相比基于坐标的MLP方法实现5-20倍加速，在秒或分钟级别求解微分方程，同时保持相当的精度和紧凑性。

Conclusion: DInf-Grid通过结合网格效率和径向基函数可微性，成功解决了现有神经求解器在微分方程求解中的效率瓶颈，为物理场建模提供了高效准确的解决方案。

Abstract: We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [172] [Segmentação Comportamental, Do Not Track e o desenvolvimento jurídico europeu e holandês](https://arxiv.org/abs/2601.09711)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧洲数据保护法适用于行为定向广告，荷兰法律明确推定适用，要求企业遵守公平信息原则，技术设计可促进公平信息处理


<details>
  <summary>Details</summary>
Motivation: 探讨欧洲和荷兰法律对行为定向广告的监管现状，分析数据保护法如何适用于行为定向广告，并探索技术设计如何促进公平信息处理

Method: 分析欧洲和荷兰的法律发展，包括近期司法决定和法律条文，研究数据保护法对行为定向广告的适用性，探讨公平信息原则的具体要求

Result: 欧洲数据保护法在大多数情况下适用于行为定向广告，荷兰法律明确推定适用，企业必须遵守公平信息原则，避免秘密或过度数据收集

Conclusion: 数据保护法为行为定向广告提供了法律框架，公平信息原则可为未来W3C项目提供灵感，技术设计有助于促进公平信息处理

Abstract: This paper discusses legal developments in Europe and the Netherlands. Recent decisions show that European data protection law, or privacy law, applies to behavioral targeting in most cases. Dutch law explicitly presumes that data protection law applies to behavioral targeting. This means that companies have to comply with data protection law's fair information principles. For example, companies must refrain from secret or excessive data collection. Perhaps the principles could provide inspiration for future W3C projects. Could technology design foster fair information processing?

</details>


### [173] [Behavioral Targeting, a European Legal Perspective](https://arxiv.org/abs/2601.09712)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文分析了欧洲法律和政策对行为定向广告（在线画像）的监管发展，探讨了当前争议和监管困境


<details>
  <summary>Details</summary>
Motivation: 行为定向广告（在线画像）是当前激烈争议的话题，虽然研究表明大多数人不想接收行为定向广告，但互联网上大量个人信息收集与此相关。万维网联盟正在讨论"请勿追踪"标准，全球监管机构也在努力寻找解决方案。

Method: 本文采用法律和政策分析方法，重点讨论欧洲法律框架和近期政策发展，分析监管机构对行为定向广告的应对措施。

Result: 文章揭示了欧洲在行为定向广告监管方面的法律框架和政策动向，包括万维网联盟的"请勿追踪"标准讨论，以及全球监管机构面临的监管挑战。

Conclusion: 行为定向广告监管是一个复杂且发展迅速的领域，欧洲法律和政策正在积极应对这一挑战，但全球监管机构仍在努力寻找平衡隐私保护与商业利益的解决方案。

Abstract: Behavioral targeting, or online profiling, is a hotly debated topic. Much of the collection of personal information on the Internet is related to behavioral targeting, although research suggests that most people don't want to receive behaviorally targeted advertising. The World Wide Web Consortium is discussing a Do Not Track standard, and regulators worldwide are struggling to come up with answers. This article discusses European law and recent policy developments on behavioral targeting.

</details>


### [174] [Filtering for Copyright Enforcement in Europe after the Sabam cases](https://arxiv.org/abs/2601.09739)
*Stefan Kulk,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧盟法院判决社交网络和互联网服务提供商无需安装版权过滤系统，但这对隐私和信息自由权利的实际保护有限


<details>
  <summary>Details</summary>
Motivation: 分析欧盟法院关于版权过滤系统要求的判决是否真正保护了基本权利，特别是隐私和信息自由

Method: 通过分析比利时集体权利管理组织Sabam要求安装过滤系统的案例，以及欧盟法院的两项相关判决，评估这些判决对基本权利的实际影响

Result: 虽然法院判决社交网络和互联网服务提供商无需安装过滤系统，但这对隐私和信息自由权利的保护作用有限，基本权利的实际获益不大

Conclusion: 欧盟法院的判决表面上是基本权利的胜利，但实际上对隐私和信息自由的保护效果有限，需要更深入的权利保护机制

Abstract: Sabam, a Belgian collective rights management organisation, wanted an internet access provider and a social network site to install a filter system to enforce copyrights. In two recent judgments, the Court of Justice of the European Union decided that the social network site and the internet access provider cannot be required to install the filter system that Sabam asked for. Are these judgments good news for fundamental rights? This article argues that little is won for privacy and freedom of information.

</details>


### [175] [Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools](https://arxiv.org/abs/2601.09753)
*Carole J. Lee*

Main category: cs.CY

TL;DR: 论文警告AI科学评估工具存在误用风险，主张采用批判性实用主义框架来审视这些工具的目的和可靠性


<details>
  <summary>Details</summary>
Motivation: 同行评审能力危机、研究可复制性问题和AI伪造科学等问题引发了对自动化科研评估工具的兴趣，但科学界历史上存在将可信度标记去语境化和不当使用的问题

Method: 提出社会实用主义认识论和批判性实用主义新规范，要求科学界严格审查AI科学评估工具的目的和目的特定可靠性

Result: AI科学评估工具不应被视为科学可信度的客观仲裁者，而应成为科学界批判性话语实践的对象

Conclusion: 需要采用批判性实用主义框架，将AI科学评估工具置于科学界批判性话语实践中，避免因目的模糊、可移植性问题和数据规模优先于认知适配而导致的错误推断

Abstract: Crises in peer review capacity, study replication, and AI-fabricated science have intensified interest in automated tools for assessing scientific research. However, the scientific community has a history of decontextualizing and repurposing credibility markers in inapt ways. I caution that AI science evaluation tools are particularly prone to these kinds of inference by false ascent due to contestation about the purposes to which they should be put, their portability across purposes, and technical demands that prioritize data set size over epistemic fit. To counter this, I argue for a social, pragmatist epistemology and a newly articulated norm of Critically Engaged Pragmatism to enjoin scientific communities to vigorously scrutinize the purposes and purpose-specific reliability of AI science evaluation tools. Under this framework, AI science evaluation tools are not objective arbiters of scientific credibility, but the object of the kinds of critical discursive practices that ground the credibility of scientific communities.

</details>


### [176] [Democracy and Distrust in an Era of Artificial Intelligence](https://arxiv.org/abs/2601.09757)
*Sonia Katyal*

Main category: cs.CY

TL;DR: 本文探讨司法审查如何适应人工智能决策带来的挑战，特别是在保护少数群体权利方面，提出AI时代司法审查的理论框架。


<details>
  <summary>Details</summary>
Motivation: 人工智能决策中的私有化、预测和自动化趋势对少数群体构成风险，需要司法审查机制来应对算法歧视问题。

Method: 分析AI决策在法庭上受到挑战的案例，探讨正当程序和平等保护原则如何在AI时代被重新诠释并整合到AI系统中。

Result: 提出AI时代司法审查的理论框架，展示如何通过法律原则为AI决策提供更好的监督和问责机制。

Conclusion: 司法审查可以适应AI时代，通过重新诠释传统法律原则并将其整合到AI系统中，有效保护少数群体免受算法歧视。

Abstract: This essay examines how judicial review should adapt to address challenges posed by artificial intelligence decision-making, particularly regarding minority rights and interests. As I argue in this essay, the rise of three trends-privatization, prediction, and automation in AI-have combined to pose similar risks to minorities. Here, I outline what a theory of judicial review would look like in an era of artificial intelligence, analyzing both the limitations and the possibilities of judicial review of AI. I draw on cases in which AI decision-making has been challenged in courts, to show how concepts of due process and equal protection can be recuperated in a modern AI era, and even integrated into AI, to provide for better oversight and accountability, offering a framework for judicial review in the AI era that protects minorities from algorithmic discrimination.

</details>


### [177] [Strategies of cooperation and defection in five large language models](https://arxiv.org/abs/2601.09849)
*Saptarshi Pal,Abhishek Mallela,Christian Hilbe,Lenz Pracher,Chiyu Wei,Feng Fu,Santiago Schnell,Martin A Nowak*

Main category: cs.CY

TL;DR: 该研究探索了五个主流大语言模型在重复囚徒困境中的合作策略表现，测试了它们在各种参数变化下的适应能力，并与人类行为和理论预测进行比较。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地应用于支持人类决策，特别是在影响他人福利的场景下，需要了解它们如何进行社会决策。重复囚徒困境作为互惠合作的主要隐喻，是检验LLMs社会决策能力的理想测试平台。

Method: 研究首先在中性设置下测量LLMs的合作倾向，不使用游戏的标准表述语言。然后测试LLMs是否实施纳什均衡或其他已知策略类别。接着探索LLMs如何适应参数变化：改变游戏的继续概率、收益值、回合数是否共同知识。还研究了不同框架的影响。最后进行了LLM策略之间的锦标赛，并让LLMs在已知或未知最后一轮的10轮游戏中直接互动。

Result: 所有LLMs在多数任务中表现良好，但没有一个模型在所有任务中表现出完全一致性。LLMs能够适应参数变化，其策略调整与基本直觉、进化博弈论的理论预测以及人类参与者的实验证据基本一致。

Conclusion: 实验揭示了当前LLMs如何实例化互惠合作。虽然LLMs在许多社会决策任务中表现良好，但在一致性方面仍有改进空间，这为理解LLMs的社会决策能力提供了重要见解。

Abstract: Large language models (LLMs) are increasingly deployed to support human decision-making. This use of LLMs has concerning implications, especially when their prescriptions affect the welfare of others. To gauge how LLMs make social decisions, we explore whether five leading models produce sensible strategies in the repeated prisoner's dilemma, which is the main metaphor of reciprocal cooperation. First, we measure the propensity of LLMs to cooperate in a neutral setting, without using language reminiscent of how this game is usually presented. We record to what extent LLMs implement Nash equilibria or other well-known strategy classes. Thereafter, we explore how LLMs adapt their strategies to changes in parameter values. We vary the game's continuation probability, the payoff values, and whether the total number of rounds is commonly known. We also study the effect of different framings. In each case, we test whether the adaptations of the LLMs are in line with basic intuition, theoretical predictions of evolutionary game theory, and experimental evidence from human participants. While all LLMs perform well in many of the tasks, none of them exhibit full consistency over all tasks. We also conduct tournaments between the inferred LLM strategies and study direct interaction between LLMs in games over ten rounds with a known or unknown last round. Our experiments shed light on how current LLMs instantiate reciprocal cooperation.

</details>


### [178] [Modeling conflicting incentives in engineering senior capstone projects: A multi-player game theory approach](https://arxiv.org/abs/2601.09944)
*Richard Q. Blackwell,Eman Hammad,Congrui Jin,Jisoo Park,Albert E. Patterson*

Main category: cs.CY

TL;DR: 该论文开发了一个博弈论框架，将工程顶点项目建模为大学、行业赞助商和学生团队之间的序贯贝叶斯博弈，用于分析政策选择如何影响利益相关者行为和项目结果。


<details>
  <summary>Details</summary>
Motivation: 现有对工程顶点项目的分析通常非正式或描述性地处理利益相关者行为，未能深入探讨激励冲突、信息不对称和战略依赖。需要正式的理论框架来理解制度政策如何塑造项目动态。

Method: 开发了一个序贯贝叶斯博弈框架，将大学建模为受约束的斯塔克尔伯格领导者，设定课程政策和评估结构，同时考虑赞助商和学生在不完全信息下的战略响应。使用简化形式的结果函数和收益函数来捕捉技术质量、文档质量、及时性、与赞助商需求的契合度以及可发表性。

Result: 在标准假设下，模型产生了与实践中观察到的顶点项目动态相对应的稳定均衡机制，包括合作参与、赞助商主导的剥削和学生成绩博弈。框架提供了分析激励设计、政策权衡和结构性失败模式的结构化基础。

Conclusion: 该博弈论框架作为分析和解释工具，有助于理解制度政策选择如何影响利益相关者行为和项目结果，为未来扩展提供了基础，包括更丰富的动态、重复互动和实证校准。

Abstract: University engineering capstone projects involve sustained interaction among students, faculty, and industry sponsors whose objectives are only partially aligned. While capstones are widely used in engineering education, existing analyses typically treat stakeholder behavior informally or descriptively, leaving incentive conflicts, information asymmetries, and strategic dependencies underexplored. This paper develops a formal game-theoretic framework that models capstone projects as a sequential Bayesian game involving three players: the university, the industry sponsor, and the student team. The framework is intended as an analytical and explanatory tool for understanding how institutional policy choices, such as grading structures, intellectual property rules, and sponsor engagement expectations, shape stakeholder behavior and project outcomes, rather than as a calibrated or predictive model. The university acts as a constrained Stackelberg leader by committing to course policies and assessment structures while anticipating strategic responses by sponsors and students under incomplete information. Reduced-form outcome functions capture technical quality, documentation quality, timeliness, alignment with sponsor needs, and publishability, while payoff functions reflect stakeholder-specific objectives and costs. Under standard assumptions, the model admits stable equilibrium regimes that correspond to empirically recognizable capstone dynamics observed in practice, including cooperative engagement, sponsor-dominated exploitation, and student grade gaming. Rather than claiming precise prediction, the framework provides a structured basis for reasoning about incentive design, policy tradeoffs, and structural failure modes in project-based learning environments, as well as for future extensions incorporating richer dynamics, repeated interaction, and empirical calibration.

</details>


### [179] [Brief but Impactful: How Human Tutoring Interactions Shape Engagement in Online Learning](https://arxiv.org/abs/2601.09994)
*Conrad Borchers,Ashish Gurung,Qinyi Liu,Danielle R. Thomas,Mohammad Khalil,Kenneth R. Koedinger*

Main category: cs.CY

TL;DR: 研究显示，人类导师的简短干预能显著提升学生在数学学习中的参与度，干预时机比时长更重要，早期接触能防止参与度下降，而后期干预效果更明显。


<details>
  <summary>Details</summary>
Motivation: 学习分析可以指导人类导师有效解决AI系统难以支持的学习动机障碍。学生获得人类关注时会更投入，但需要了解简短干预期间发生了什么以及何时最有效。

Method: 将学生-导师对话转录与MATHia辅导系统日志数据对齐，分析191名中学生2,075小时的课堂数学练习中Zoom上的简短人类导师互动。使用混合效应模型分析参与度变化，并进行定性分析识别有效对话模式。

Result: 参与度（每分钟成功解题步骤）在人类导师访问期间和之后都保持较高水平。访问时长呈现边际效益递减：参与度在访问期间和之后短暂提升，与访问时长无关。时机很重要：后期访问比早期访问产生更大的即时提升，但早期访问对防止参与度下降很重要。具体、逐步的脚手架式互动和明确的工作组织最能提升参与度。

Conclusion: 在资源有限的辅导中，应优先安排多个简短、时机恰当的检查，同时确保至少一次早期接触。分析工具可以指导支持学生的优先级排序，并实时展示有效的导师策略。

Abstract: Learning analytics can guide human tutors to efficiently address motivational barriers to learning that AI systems struggle to support. Students become more engaged when they receive human attention. However, what occurs during short interventions, and when are they most effective? We align student-tutor dialogue transcripts with MATHia tutoring system log data to study brief human-tutor interactions on Zoom drawn from 2,075 hours of 191 middle school students' classroom math practice. Mixed-effect models reveal that engagement, measured as successful solution steps per minute, is higher during a human-tutor visit and remains elevated afterward. Visit length exhibits diminishing returns: engagement rises during and shortly after visits, irrespective of visit length. Timing also matters: later visits yield larger immediate lifts than earlier ones, though an early visit remains important to counteract engagement decline. We create analytics that identify which tutor-student dialogues raise engagement the most. Qualitative analysis reveals that interactions with concrete, stepwise scaffolding with explicit work organization elevate engagement most strongly. We discuss implications for resource-constrained tutoring, prioritizing several brief, well-timed check-ins by a human tutor while ensuring at least one early contact. Our analytics can guide the prioritization of students for support and surface effective tutor moves in real-time.

</details>


### [180] [STEAMROLLER: A Multi-Agent System for Inclusive Automatic Speech Recognition for People who Stutter](https://arxiv.org/abs/2601.10223)
*Ziqi Xu,Yi Liu,Yuekang Li,Ling Shi,Kailong Wang,Yongxin Zhao*

Main category: cs.CY

TL;DR: STEAMROLLER是一个实时系统，通过多阶段多智能体AI流水线将口吃语音转换为流畅输出，解决当前语音识别系统对口吃人群的排斥问题。


<details>
  <summary>Details</summary>
Motivation: 口吃人群在当前依赖流畅语音的语音助手、认证系统和远程工作工具中被系统性地排斥。现有的自动语音识别系统主要基于流畅语音训练，无法服务全球数百万口吃者。

Method: 采用三阶段架构：ASR转录、多智能体文本修复和语音合成。核心创新在于协作式多智能体框架，迭代优化转录文本同时保持语义意图。解决了三个关键技术挑战：口吃语音直接转换的困难、ASR转录引入的语义失真以及实时通信的延迟约束。

Result: 在FluencyBank数据集上的实验和用户研究表明，系统显著降低了词错误率（WER）并获得用户高度满意。此外，在STEAMROLLER修复的语音上微调ASR能进一步改善WER，为包容性AI生态系统开辟了途径。

Conclusion: STEAMROLLER为口吃人群提供了实时语音转换解决方案，不仅带来即时可访问性益处，还通过修复语音训练ASR创造了包容性AI生态系统的途径。

Abstract: People who stutter (PWS) face systemic exclusion in today's voice-driven society, where access to voice assistants, authentication systems, and remote work tools increasingly depends on fluent speech. Current automatic speech recognition (ASR) systems, trained predominantly on fluent speech, fail to serve millions of PWS worldwide. We present STEAMROLLER, a real time system that transforms stuttered speech into fluent output through a novel multi-stage, multi-agent AI pipeline. Our approach addresses three critical technical challenges: (1) the difficulty of direct speech to speech conversion for disfluent input, (2) semantic distortions introduced during ASR transcription of stuttered speech, and (3) latency constraints for real time communication. STEAMROLLER employs a three stage architecture comprising ASR transcription, multi-agent text repair, and speech synthesis, where our core innovation lies in a collaborative multi-agent framework that iteratively refines transcripts while preserving semantic intent. Experiments on the FluencyBank dataset and a user study demonstrates clear word error rate (WER) reduction and strong user satisfaction. Beyond immediate accessibility benefits, fine tuning ASR on STEAMROLLER repaired speech further yields additional WER improvements, creating a pathway toward inclusive AI ecosystems.

</details>


### [181] [Atelier à la conférence IHM 2025 : RA Permanente](https://arxiv.org/abs/2601.10291)
*Maxime Cauz,Thibaut Septon,Elise Hallaert,Theo Leclercq,Bruno Dumas,Charles Bailly,Clement Tyminski,Matias Peraza,Sophie Lepreux,Emmanuel Dubois*

Main category: cs.CY

TL;DR: 该研讨会汇集IHM'25会议参与者，讨论普及增强现实(PAR)的跨学科挑战、潜在影响及必要保障措施，旨在定义未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着普适计算发展，普及增强现实(PAR)可能彻底改变人、计算与世界的关系。这种持续增强的体验既有益处也有不良后果，需要在多个领域探讨相关问题。

Method: 通过研讨会形式，汇集所有对PAR话题关注或热情的IHM'25会议参与者，利用集体智慧进行讨论和分析。

Result: 将讨论元素分类整理，定义了围绕永久增强现实的未来主要研究领域，包括跨学科挑战、技术实施问题和必要保障措施。

Conclusion: PAR的发展需要平衡技术热情与现实考量，通过跨学科合作解决实施挑战，并建立适当的保障机制，以确保技术在日常生活中的负责任应用。

Abstract: As we move towards more ubiquitous computing, the concept of pervasive augmented reality (PAR) could lead to a major evolution in the relationship between humans, computing and the world. The experience of a continuously augmented world can have both benefits and undesirable consequences for users' lives, and raises many questions in multiple areas. In this workshop, we wanted to bring together all IHM'25 conference participants who are concerned or enthusiastic about discussing this topic. The aim was to draw on collective intelligence to identify the interdisciplinary challenges that remain to be resolved in order to enable the implementation of these technologies in everyday life, but also to define the necessary safeguards. Is PAR too techno-enthusiastic? All of these elements were grouped into categories to define a set of future major areas of research around permanent augmented reality. This document is in French as the conference is a French-speaking international conference.

</details>


### [182] [Job Anxiety in Post-Secondary Computer Science Students Caused by Artificial Intelligence](https://arxiv.org/abs/2601.10468)
*Daniyaal Farooqi,Gavin Pu,Shreyasha Paudel,Sharifa Sultana,Syed Ishtiaque Ahmed*

Main category: cs.CY

TL;DR: 计算机科学学生对AI取代工作的焦虑研究：通过访谈发现学生面临压力，采取不同应对策略，部分子领域被认为更易受影响，导致学生被迫提升AI技能或转行。


<details>
  <summary>Details</summary>
Motivation: 随着AI的广泛应用，行业采用AI提高效率和收益，但这也导致员工被AI取代，引发工作不安全感和不确定性。计算机科学学生即将进入职场，特别容易受到这种影响，因此需要研究他们面临的工作替代焦虑程度。

Method: 采用半结构化访谈方法，对多伦多大学计算机科学本科和研究生项目的25名学生进行访谈，通过主题分析确定工作替代焦虑的程度和表现形式。

Result: 研究发现计算机科学学生确实面临AI取代工作带来的压力和焦虑，并采取不同策略应对压力。软件工程和Web开发等子领域被认为易受影响，而量子计算和AI研究等专业领域被认为更安全。许多学生被迫通过使用更多AI技术、学习AI课程、攻读AI研究生来提升技能，部分学生则转向其他被认为不易受AI影响的领域。国际学生还因获得永久居留权的压力而面临额外焦虑。

Conclusion: 这些发现表明计算机科学职业安全感低，可能导致计算机科学学生过度集中于AI领域，并可能劝阻未来大学生选择计算机科学专业。需要关注AI发展对职业前景的影响，并制定相应支持策略。

Abstract: The emerging widespread usage of AI has led to industry adoption to improve efficiency and increase earnings. However, a major consequence of this is AI displacing employees from their jobs, leading to feelings of job insecurity and uncertainty. This is especially true for computer science students preparing to enter the workforce. To investigate this, we performed semi-structured interviews with (n = 25) students across computer science undergraduate and graduate programs at the University of Toronto to determine the extent of job replacement anxiety. Through thematic analysis, it was determined that computer science students indeed face stress and anxiety from AI displacement of jobs, leading to different strategies of managing pressure. Subfields such as software engineering and web development are strongly believed to be vulnerable to displacement, while specialized subfields like quantum computing and AI research are deemed more secure. Many students feel compelled to upskill by using more AI technologies, taking AI courses, and specializing in AI through graduate school. Some students also reskill by pursuing other fields of study seen as less vulnerable to AI displacement. Finally, international students experience additional job replacement anxiety because of pressure to secure permanent residence. Implications of these findings include feelings of low security in computer science careers, oversaturation of computer science students pursuing AI, and potential dissuasion of future university students from pursuing computer science.

</details>


### [183] [Institutional AI: A Governance Framework for Distributional AGI Safety](https://arxiv.org/abs/2601.10599)
*Federico Pierucci,Marcello Galisai,Marcantonio Syrnikov Bracale,Matteo Prandi,Piercosma Bisconti,Francesco Giarrusso,Olga Sorokoletova,Vincenzo Suriani,Daniele Nardi*

Main category: cs.CY

TL;DR: 论文提出"制度性AI"框架，将AI对齐问题从单个模型层面提升到集体治理层面，通过制度设计解决AI代理在复杂环境中的行为控制问题。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的系统越来越多地作为代理嵌入人类社会和技术的复杂环境中，对齐不能再被视为孤立模型的属性，而必须理解为与代理行动环境相关的系统性问题。即使最先进的对齐方法（如RLHF、RLAIF）也无法确保当内部目标结构与开发者意图偏离时的控制。

Method: 提出"制度性AI"的系统级方法，将对齐视为AI代理集体的有效治理问题。构建治理图，通过运行时监控、通过奖励和制裁的激励塑造、明确的规范和执法角色来约束代理。将安全从软件工程问题重构为机制设计问题。

Result: 识别了三个源于AI模型核心属性的结构性问题：1)行为目标独立性；2)自然语言约束的工具性覆盖；3)代理性对齐漂移。提出了制度性AI作为解决方案，通过改变AI代理集体的收益格局来实现对齐。

Conclusion: 需要从软件工程思维转向机制设计思维，将对齐的主要目标从训练单个模型转变为塑造AI代理集体的激励结构和治理框架，通过制度性AI确保在复杂社会技术系统中的安全运行。

Abstract: As LLM-based systems increasingly operate as agents embedded within human social and technical systems, alignment can no longer be treated as a property of an isolated model, but must be understood in relation to the environments in which these agents act. Even the most sophisticated methods of alignment, such as Reinforcement Learning through Human Feedback (RHLF) or through AI Feedback (RLAIF) cannot ensure control once internal goal structures diverge from developer intent. We identify three structural problems that emerge from core properties of AI models: (1) behavioral goal-independence, where models develop internal objectives and misgeneralize goals; (2) instrumental override of natural-language constraints, where models regard safety principles as non-binding while pursuing latent objectives, leveraging deception and manipulation; and (3) agentic alignment drift, where individually aligned agents converge to collusive equilibria through interaction dynamics invisible to single-agent audits. The solution this paper advances is Institutional AI: a system-level approach that treats alignment as a question of effective governance of AI agent collectives. We argue for a governance-graph that details how to constrain agents via runtime monitoring, incentive shaping through prizes and sanctions, explicit norms and enforcement roles. This institutional turn reframes safety from software engineering to a mechanism design problem, where the primary goal of alignment is shifting the payoff landscape of AI agent collectives.

</details>


### [184] [The Conversational Exam: A Scalable Assessment Design for the AI Era](https://arxiv.org/abs/2601.10691)
*Lorena A. Barba,Laura Stegner*

Main category: cs.CY

TL;DR: 提出"对话式考试"作为可扩展的口试形式，让学生在实时编码中解释推理过程，解决生成式AI导致评估失效的问题


<details>
  <summary>Details</summary>
Motivation: 传统评估方法在学生使用生成式AI完成作业但未真正参与时失效，造成能力错觉。许多教育工作者面临要么完全禁止AI，要么接受有效评估不可能的困境

Method: 基于人机交互原理设计对话式考试，学生实时编码并解释推理过程，可访问文档和监督下的AI。研究在两天内对58名学生进行小规模测试，证明口试可扩展到典型班级规模

Result: 对话式考试结合了真实实践（使用文档和监督AI）与内在有效性（实时表现无法伪造），恢复了评估的有效性

Conclusion: 提供了详细的实施指南，帮助教师采用这种方法，为教育工作者提供了一条实用路径，解决了在AI时代评估有效性的困境

Abstract: Traditional assessment methods collapse when students use generative AI to complete work without genuine engagement, creating an illusion of competence where they believe they're learning but aren't. This paper presents the conversational exam -- a scalable oral examination format that restores assessment validity by having students code live while explaining their reasoning. Drawing on human-computer interaction principles, we examined 58 students in small groups across just two days, demonstrating that oral exams can scale to typical class sizes. The format combines authentic practice (students work with documentation and supervised AI access) with inherent validity (real-time performance cannot be faked). We provide detailed implementation guidance to help instructors adapt this approach, offering a practical path forward when many educators feel paralyzed between banning AI entirely or accepting that valid assessment is impossible.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [185] [History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis](https://arxiv.org/abs/2601.10143)
*Haochong Xia,Yao Long Teng,Regan Tan,Molei Qin,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 提出一个漂移感知数据流系统，通过机器学习自适应控制数据管理流程，解决金融数据概念漂移问题，提升模型鲁棒性和风险调整收益


<details>
  <summary>Details</summary>
Motivation: 量化金融中，概念漂移和分布非平稳性导致训练与真实表现之间存在差距，基于静态历史数据的模型容易过拟合，无法适应动态市场变化

Method: 构建漂移感知数据流系统，包含参数化数据操作模块（单股变换、多股混合、筛选操作）和自适应规划调度器，采用基于梯度的双层优化控制，统一数据增强、课程学习和数据工作流管理

Result: 在预测和强化学习交易任务上的实验表明，该框架增强了模型鲁棒性，提高了风险调整收益

Conclusion: 该系统为金融数据提供了一种通用的自适应数据管理和学习引导工作流自动化方法

Abstract: In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra "History Is Not Enough" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.

</details>


### [186] [Antisocial behavior towards large language model users: experimental evidence](https://arxiv.org/abs/2601.09772)
*Paweł Niszczota,Cassandra Grützner*

Main category: cs.AI

TL;DR: 研究发现人们会花费自己的金钱惩罚使用LLM完成任务的人，惩罚程度随实际使用量单调增加，且存在"可信度鸿沟"：声称未使用比实际未使用受罚更重


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速传播引发了对其社会反应的担忧。先前研究记录了人们对AI用户的负面态度，但不清楚这种不赞成是否会转化为实际的代价性行动。

Method: 采用两阶段在线实验（第二阶段491名参与者），参与者可以花费自己的资金来减少之前使用或不使用LLM支持完成真实努力任务的同伴的收入。实验比较了实际LLM使用与自我报告使用之间的差异。

Result: 参与者平均摧毁了完全依赖LLM者36%的收入，惩罚程度随实际LLM使用量单调增加。存在"可信度鸿沟"：自我报告的未使用比实际未使用受罚更重，而高使用水平时，实际依赖比自我报告依赖受罚更重。

Conclusion: 这是第一个行为证据，表明LLMs的效率提升是以社会制裁为代价的。人们对LLM使用存在实质性惩罚，且对使用声明的可信度持怀疑态度。

Abstract: The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this question in a two-phase online experiment (N = 491 Phase II participants; Phase I provided targets) where participants could spend part of their own endowment to reduce the earnings of peers who had previously completed a real-effort task with or without LLM support. On average, participants destroyed 36% of the earnings of those who relied exclusively on the model, with punishment increasing monotonically with actual LLM use. Disclosure about LLM use created a credibility gap: self-reported null use was punished more harshly than actual null use, suggesting that declarations of "no use" are treated with suspicion. Conversely, at high levels of use, actual reliance on the model was punished more strongly than self-reported reliance. Taken together, these findings provide the first behavioral evidence that the efficiency gains of LLMs come at the cost of social sanctions.

</details>


### [187] [AI Survival Stories: a Taxonomic Analysis of AI Existential Risk](https://arxiv.org/abs/2601.09765)
*Herman Cappelen,Simon Goldstein,John Hawthorne*

Main category: cs.AI

TL;DR: 该论文提出了一个分析AI系统对人类构成生存风险的通用框架，基于两个前提构建了人类存续的四种可能情景，并探讨了不同情景面临的挑战和应对策略，最后给出了AI毁灭人类的概率估计。


<details>
  <summary>Details</summary>
Motivation: 自ChatGPT发布以来，关于AI系统是否对人类构成生存风险的争论日益激烈。本文旨在建立一个系统性的分析框架，帮助人们理性思考AI的生存风险问题，为相关讨论和政策制定提供理论基础。

Method: 论文构建了一个基于两个核心前提的分析框架：前提一：AI系统将变得极其强大；前提二：如果AI系统变得极其强大，它们将毁灭人类。基于这两个前提，作者提出了四种人类存续的情景（每个情景中至少有一个前提不成立），并分析了每种情景面临的挑战。

Result: 作者提出了一个分类法，将人类存续的情景分为四类：1）科学障碍阻止AI变得极其强大；2）人类禁止AI研究；3）极其强大的AI因其目标而不毁灭人类；4）人类能够可靠检测并禁用有毁灭人类目标的AI系统。不同情景需要不同的应对策略。

Conclusion: 该框架为分析AI生存风险提供了系统性的思考工具，不同存续情景面临不同的挑战并需要不同的政策回应。作者利用该分类法对P(doom)（AI毁灭人类的概率）进行了粗略估计，强调了理性评估AI风险的重要性。

Abstract: Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pose a threat to humanity. Premise one: AI systems will become extremely powerful. Premise two: if AI systems become extremely powerful, they will destroy humanity. We use these two premises to construct a taxonomy of survival stories, in which humanity survives into the far future. In each survival story, one of the two premises fails. Either scientific barriers prevent AI systems from becoming extremely powerful; or humanity bans research into AI systems, thereby preventing them from becoming extremely powerful; or extremely powerful AI systems do not destroy humanity, because their goals prevent them from doing so; or extremely powerful AI systems do not destroy humanity, because we can reliably detect and disable systems that have the goal of doing so. We argue that different survival stories face different challenges. We also argue that different survival stories motivate different responses to the threats from AI. Finally, we use our taxonomy to produce rough estimates of P(doom), the probability that humanity will be destroyed by AI.

</details>


### [188] [GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents](https://arxiv.org/abs/2601.09770)
*Chen Chen,Jiawei Shao,Dakuan Lu,Haoyi Hu,Xiangcheng Liu,Hantao Yao,Wu Liu*

Main category: cs.AI

TL;DR: GUI-Eyes是一个强化学习框架，通过主动视觉感知和工具使用策略，在GUI任务中实现更高效的数据利用和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有GUI自动化方法大多依赖静态视觉输入和被动感知，缺乏自适应决定何时、是否以及如何观察界面的能力。这限制了GUI代理的适应性和数据效率。

Method: 提出一个强化学习框架，采用渐进感知策略：将决策分解为粗粒度探索和细粒度定位，由两级策略协调。引入空间连续奖励函数，结合位置接近性和区域重叠，为工具使用提供密集监督。

Result: 在ScreenSpot-Pro基准测试中，GUI-Eyes-3B仅使用3k标记样本就实现了44.8%的定位准确率，显著优于监督学习和基于强化学习的基线方法。

Conclusion: 工具感知的主动感知，通过分阶段策略推理和细粒度奖励反馈，对于构建鲁棒且数据高效的GUI代理至关重要。

Abstract: Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether, and how to observe the interface. We present GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. To acquire more informative observations, the agent learns to make strategic decisions on both whether and how to invoke visual tools, such as cropping or zooming, within a two-stage reasoning process. To support this behavior, we introduce a progressive perception strategy that decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. In addition, we design a spatially continuous reward function tailored to tool usage, which integrates both location proximity and region overlap to provide dense supervision and alleviate the reward sparsity common in GUI environments. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, significantly outperforming both supervised and RL-based baselines. These results highlight that tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, is critical for building robust and data-efficient GUI agents.

</details>


### [189] [PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation](https://arxiv.org/abs/2601.09771)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.AI

TL;DR: PCN-Rec是一个证明携带的协商推荐系统，通过分离自然语言推理和确定性约束执行，可靠满足治理约束（如多样性要求），同时保持推荐质量。


<details>
  <summary>Details</summary>
Motivation: 现代基于LLM的推荐系统能生成有吸引力的排名列表，但难以可靠地满足治理约束（如最小长尾曝光或多样性要求），需要一种能同时保证约束满足和推荐质量的方法。

Method: 提出PCN-Rec证明携带协商管道：1）基础推荐器生成候选窗口；2）用户代理和政策代理分别优化相关性和约束执行；3）调解LLM合成top-N列表及结构化证书；4）确定性验证器重新计算约束；5）验证失败时使用确定性约束贪婪修复生成合规列表。

Result: 在MovieLens-100K数据集上，PCN-Rec对可行用户达到98.55%的通过率（n=551，W=80），相比无验证/修复的单LLM基线显著提升，同时NDCG@10仅下降0.021（0.403 vs 0.424），差异具有统计显著性（p<0.05）。

Conclusion: PCN-Rec通过证明携带协商方法，在保持推荐效用的同时可靠满足治理约束，提供了可审计的追踪记录，解决了LLM推荐系统在约束满足方面的可靠性问题。

Abstract: Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender (MF/CF) produces a candidate window of size W, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a top-N slate together with a structured certificate (JSON) describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users (n = 551, W = 80) versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10 (0.403 vs. 0.424); differences are statistically significant (p < 0.05).

</details>


### [190] [Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention](https://arxiv.org/abs/2601.09805)
*Nguyen Minh Phuong,Dang Huu Tien,Naoya Inoue*

Main category: cs.AI

TL;DR: 提出一种非交互式端到端推理框架AAI，通过注意力重加权激活逻辑推理模式，无需外部资源即可提升大语言模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑推理方法依赖复杂的交互框架或外部符号求解器，存在额外开销和可扩展性限制。需要一种非交互式、端到端的框架，让推理能力在模型内部自然涌现。

Method: 提出注意力感知干预(AAI)：在少样本提示中引入结构信息激活特定注意力头，识别这些头中的逻辑推理模式，在推理时对选定头的注意力分数进行重加权。

Result: AAI在多种基准测试和模型架构上显著提升逻辑推理性能，同时仅带来可忽略的计算开销。

Conclusion: AAI提供了一种高效的非交互式推理框架，通过注意力调制引导模型利用先验知识进行逻辑推理，具有良好的泛化性和可分析性。

Abstract: Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While interactive approaches introduce additional overhead, hybrid approaches depend on external components, which limit their scalability. A non-interactive, end-to-end framework enables reasoning to emerge within the model itself -- improving generalization while preserving analyzability without any external resources. In this work, we introduce a non-interactive, end-to-end framework for reasoning tasks. We show that introducing structural information into the few-shot prompt activates a subset of attention heads that patterns aligned with logical reasoning operators. Building on this insight, we propose Attention-Aware Intervention (AAI), an inference-time intervention method that reweights attention scores across selected heads identified by their logical patterns. AAI offers an efficient way to steer the model's reasoning toward leveraging prior knowledge through attention modulation. Extensive experiments show that AAI enhances logical reasoning performance across diverse benchmarks and model architectures, while incurring negligible additional computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.

</details>


### [191] [Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models](https://arxiv.org/abs/2601.09855)
*Michael R. Metel,Yufei Cui,Boxing Chen,Prasanna Parthasarathi*

Main category: cs.AI

TL;DR: 提出Min-Seek方法，一种新颖的顺序测试时间缩放技术，通过动态KV缓存管理解决现有方法在延长推理长度时出现的准确率下降和不稳定问题，无需推理长度微调，并能超越模型最大上下文长度限制。


<details>
  <summary>Details</summary>
Motivation: 当前顺序测试时间缩放方法存在显著限制：虽然诱导模型思考更长时间可以提高准确率，但进一步延长推理长度会导致准确率下降和模型不稳定，需要推理长度微调。

Method: 提出Min-Seek方法：1) 仅保留一个额外诱导思考的KV对在KV缓存中，提高效率；2) 使用自定义KV缓存，存储不带位置嵌入的键，并在每个新生成思考前动态连续编码；3) 实现线性计算复杂度。

Result: Min-Seek在广泛的诱导思考范围内显著提高模型准确率，稳定顺序缩放的准确率，无需推理长度微调，能在各种推理任务上提升模型性能，并能超越模型最大上下文长度限制。

Conclusion: Min-Seek是一种高效、稳定的顺序测试时间缩放方法，解决了现有方法的局限性，无需微调即可在广泛推理长度范围内保持高准确率，并具有超越上下文长度限制的能力。

Abstract: Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reasoning is further extended, it has also been shown to result in accuracy degradation and model instability. This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling, and removing the need for reasoning length fine-tuning. Beyond improving model accuracy over a variety of reasoning tasks, our method is inherently efficient, as only the KV pairs of one additional induced thought are kept in the KV cache during reasoning. With a custom KV cache which stores keys without position embeddings, by dynamically encoding them contiguously before each new generated thought, our method can continue to reason well beyond a model's maximum context length, and under mild conditions has linear computational complexity.

</details>


### [192] [A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents](https://arxiv.org/abs/2601.09869)
*Andrea Ferrario,Rasita Vinay,Matteo Casserini,Alessandro Facchini*

Main category: cs.AI

TL;DR: 本文对大型语言模型对话代理中拟人化现象的伦理研究进行了范围综述，梳理了概念基础、伦理挑战与机遇、方法论，并提出了研究议程和设计建议。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型的对话代理日益普及，拟人化现象（赋予非人类实体类人特质）变得愈发显著。现有文献在不同领域呈现碎片化，对拟人化的定义、操作化和伦理评估存在很大差异，需要进行系统性梳理。

Method: 采用范围综述方法，对五个数据库和三个预印本库中关于LLM对话代理拟人化的伦理研究进行系统映射，综合分析了概念基础、伦理挑战与机遇、方法论三个维度。

Result: 研究发现：在概念定义上趋向于基于归因的定义，但在操作化上存在显著分歧；伦理框架主要关注风险而非机遇；实证研究有限，难以将观察到的交互效应转化为可操作的治理指导。

Conclusion: 提出了研究议程和设计/治理建议，旨在为在LLM对话代理中伦理地部署拟人化线索提供指导，平衡拟人化带来的参与度提升与伦理风险。

Abstract: Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, including deception, overreliance, and exploitative relationship framing, while some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest in the phenomenon, literature remains fragmented across domains and varies substantially in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories. We synthesize (1) conceptual foundations, (2) ethical challenges and opportunities, and (3) methodological approaches. We find convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work that links observed interaction effects to actionable governance guidance. We conclude with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.

</details>


### [193] [Epistemology gives a Future to Complementarity in Human-AI Interactions](https://arxiv.org/abs/2601.09871)
*Andrea Ferrario,Alessandro Facchini,Juan M. Durán*

Main category: cs.AI

TL;DR: 该论文将人机互补性重新定义为可靠认知过程的证据，而非简单的预测准确性指标，为人机交互提供了更坚实的理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前人机互补性概念面临理论挑战：缺乏精确理论锚定、仅作为预测准确性的后验指标、忽视其他人机交互需求、抽象化性能增益的成本特征，导致难以在实证环境中实现。

Method: 利用认识论框架，将互补性重新置于可解释AI的讨论中，基于计算可靠性主义，将历史互补性实例视为人机交互作为可靠认知过程的证据。

Result: 提出互补性的作用和价值不在于提供预测准确性的相对度量，而在于帮助校准决策制定以适应日益塑造日常生活的AI支持过程的可靠性。

Conclusion: 通过认识论重构，为人机互补性提供了更坚实的理论基础，使其能够更好地支持受AI输出影响的各方（患者、管理者、监管者等）的实践推理。

Abstract: Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offering a more practical alternative to the contested construct of 'trust in AI.' Yet complementarity faces key theoretical challenges: it lacks precise theoretical anchoring, it is formalized just as a post hoc indicator of relative predictive accuracy, it remains silent about other desiderata of human-AI interactions and it abstracts away from the magnitude-cost profile of its performance gain. As a result, complementarity is difficult to obtain in empirical settings. In this work, we leverage epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, we argue that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a given predictive task. Together with other reliability indicators assessing the alignment of the human-AI team with the epistemic standards and socio-technical practices, complementarity contributes to the degree of reliability of human-AI teams when generating predictions. This supports the practical reasoning of those affected by these outputs -- patients, managers, regulators, and others. In summary, our approach suggests that the role and value of complementarity lies not in providing a relative measure of predictive accuracy, but in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.

</details>


### [194] [Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL](https://arxiv.org/abs/2601.09883)
*Xinxing Ren,Quagmire Zang,Caelum Forder,Suman Deb,Ahsen Tahir,Roman J. Georgio,Peter Carroll,Zekun Guo*

Main category: cs.AI

TL;DR: 提出基于信息流编排的多智能体范式，通过智能体间自然语言通信动态协调任务，无需预定义工作流，在GAIA基准上超越基于规则的OWL系统8.49个百分点


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体系统依赖预定义工作流，需要大量人工设计任务状态和路由规则，无法穷尽复杂现实任务的状态空间，存在灵活性和覆盖性限制

Method: 提出信息流编排的多智能体范式，通过专门的编排器持续监控任务进度，使用A2A工具包以自然语言动态协调其他智能体，无需依赖预定义工作流

Result: 在GAIA基准测试中，pass@1设置下达到63.64%准确率，比基于工作流的OWL系统（55.15%）提升8.49个百分点，token消耗相当，能更灵活监控任务并处理边缘情况

Conclusion: 信息流编排的多智能体范式通过动态协调机制克服了基于规则工作流的局限性，在复杂任务处理中展现出更好的灵活性和鲁棒性，为多智能体系统设计提供了新方向

Abstract: Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which suffer from two fundamental limitations: they require substantial manual effort to anticipate and encode possible task states, and they cannot exhaustively cover the state space of complex real-world tasks. To address these issues, we propose an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, in which a dedicated information flow orchestrator continuously monitors task progress and dynamically coordinates other agents through the A2A toolkit using natural language, without relying on predefined workflows. We evaluate our approach on the general-purpose benchmark GAIA, using the representative workflow-based MAS OWL as the baseline while controlling for agent roles and underlying models. Under the pass@1 setting, our method achieves 63.64% accuracy, outperforming OWL's 55.15% by 8.49 percentage points with comparable token consumption. Further case-level analysis shows that our paradigm enables more flexible task monitoring and more robust handling of edge cases. Our implementation is publicly available at: https://github.com/Coral-Protocol/Beyond-Rule-Based-Workflows

</details>


### [195] [Continuum Memory Architectures for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.09913)
*Joe Logan*

Main category: cs.AI

TL;DR: 提出Continuum Memory Architecture (CMA)作为RAG的替代方案，通过持久化存储、选择性保留、关联路由、时间链和知识整合来解决RAG在记忆积累、更新和消歧方面的结构性问题。


<details>
  <summary>Details</summary>
Motivation: RAG将记忆视为无状态的查找表，存在信息永久存储、检索只读、缺乏时间连续性的问题，无法支持长期智能体进行记忆积累、更新和消歧。

Method: 定义Continuum Memory Architecture (CMA)系统类别，强调架构要求而非具体实现，包括持久化存储、选择性保留、关联路由、时间链和知识整合到高阶抽象。

Result: 在知识更新、时间关联、关联回忆、上下文消歧等任务上，CMA展现出比RAG更优的行为优势，证明了其作为长期智能体必要架构原型的价值。

Conclusion: CMA是长期智能体必要的架构基础，但面临延迟、漂移和可解释性等开放挑战，为未来智能体记忆系统设计提供了新方向。

Abstract: Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal continuity is absent. We define the \textit{Continuum Memory Architecture} (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. Rather than disclosing implementation specifics, we specify the architectural requirements CMA imposes and show consistent behavioral advantages on tasks that expose RAG's structural inability to accumulate, mutate, or disambiguate memory. The empirical probes (knowledge updates, temporal association, associative recall, contextual disambiguation) demonstrate that CMA is a necessary architectural primitive for long-horizon agents while highlighting open challenges around latency, drift, and interpretability.

</details>


### [196] [CaMeLs Can Use Computers Too: System-level Security for Computer Use Agents](https://arxiv.org/abs/2601.09923)
*Hanna Foerster,Robert Mullins,Tom Blanchard,Nicolas Papernot,Kristina Nikolić,Florian Tramèr,Ilia Shumailov,Cheng Zhang,Yiren Zhao*

Main category: cs.AI

TL;DR: 论文提出了一种针对计算机使用代理（CUAs）的单次规划方法，通过可信规划器在执行前生成完整的条件分支执行图，提供可证明的控制流完整性保证，以防御提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: AI代理容易受到提示注入攻击，恶意内容可能劫持代理行为导致凭证窃取或财务损失。目前唯一的鲁棒防御是架构隔离，将可信任务规划与不可信环境观察严格分离。然而，将这种设计应用于计算机使用代理（CUAs）存在根本性挑战：当前代理需要持续观察UI状态来确定每个动作，这与安全所需的隔离要求相冲突。

Method: 引入单次规划方法，通过可信规划器在观察任何潜在恶意内容之前生成完整的执行图（包含条件分支），提供可证明的控制流完整性保证。同时需要额外措施防止分支导向攻击（Branch Steering attacks），这种攻击通过操纵UI元素来触发计划中意外的有效路径。

Result: 在OSWorld上评估该设计，在保持前沿模型性能高达57%的同时，将较小开源模型的性能提升高达19%，证明在CUAs中可以实现严格的安全性和实用性共存。

Conclusion: 通过单次规划方法解决了计算机使用代理中安全隔离与功能需求之间的根本矛盾，虽然架构隔离成功防止了指令注入攻击，但仍需要额外措施来防止分支导向攻击。研究表明在CUAs中可以实现严格的安全性和实用性的共存。

Abstract: AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) -- systems that automate tasks by viewing screens and executing actions -- presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.

</details>


### [197] [Hallucination Detection and Mitigation in Large Language Models](https://arxiv.org/abs/2601.09929)
*Ahmad Pesaranghader,Erin Li*

Main category: cs.AI

TL;DR: 提出一个基于根因认知的幻觉管理操作框架，通过模型、数据、上下文三个层面的分类干预，结合多维度检测和分层缓解策略，构建可信生成AI系统。


<details>
  <summary>Details</summary>
Motivation: 大语言模型和大推理模型在金融、法律等高风险领域具有变革潜力，但其产生幻觉（生成事实错误或无依据内容）的倾向带来了关键可靠性风险，需要系统化管理方法。

Method: 提出基于持续改进循环的幻觉管理操作框架，将幻觉来源分为模型、数据和上下文相关因素，整合多维度检测方法（不确定性估计、推理一致性等）和分层缓解策略（知识基础、置信度校准等），通过分层架构和金融数据提取案例展示应用。

Result: 框架通过模型层、上下文层和数据层形成闭环反馈循环，实现渐进式可靠性增强，为受监管环境中构建可信生成AI系统提供了系统化、可扩展的方法论。

Conclusion: 该综合操作框架为高风险领域的大语言模型应用提供了系统化的幻觉管理方法，通过根因认知驱动的持续改进循环，能够有效提升生成AI系统的可靠性和可信度。

Abstract: Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). We demonstrate its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.

</details>


### [198] [Chinese Labor Law Large Language Model Benchmark](https://arxiv.org/abs/2601.09972)
*Zixun Lan,Maochun Xu,Yifan Ren,Rui Wu,Jianghui Zhou,Xueyang Cheng,Jianan Ding Ding,Xinheng Wang,Mingmin Chi,Fei Ma*

Main category: cs.AI

TL;DR: LabourLawLLM：针对中国劳动法领域的专用大语言模型，在多项劳动法任务上超越通用模型和现有法律专用模型


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型（如GPT-4）在处理需要精确法律知识、复杂推理和语境敏感性的专业法律子领域时表现不佳，需要针对特定法律领域的专用模型

Method: 开发LabourLawLLM（中国劳动法专用大语言模型）和LabourLawBench（涵盖法律条文引用、知识问答、案件分类、赔偿计算、命名实体识别、案例分析等任务的综合基准），采用客观指标（ROUGE-L、准确率、F1、soft-F1）和基于GPT-4评分的主观评估相结合的评价框架

Result: LabourLawLLM在所有任务类别上持续优于通用模型和现有法律专用大语言模型

Conclusion: 该方法为构建其他法律子领域的专用大语言模型提供了可扩展的途径，提高了法律AI应用的准确性、可靠性和社会价值

Abstract: Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark covering diverse labor-law tasks, including legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework combines objective metrics (e.g., ROUGE-L, accuracy, F1, and soft-F1) with subjective assessment based on GPT-4 scoring. Experiments show that LabourLawLLM consistently outperforms general-purpose and existing legal-specific LLMs across task categories. Beyond labor law, our methodology provides a scalable approach for building specialized LLMs in other legal subfields, improving accuracy, reliability, and societal value of legal AI applications.

</details>


### [199] [SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation](https://arxiv.org/abs/2601.09974)
*Seoyeon Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: SPRInG是一个用于持续个性化LLM的半参数框架，通过漂移驱动的选择性适应来应对用户偏好动态变化，避免灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法假设用户偏好静态不变，但现实世界中用户兴趣持续演变，标准持续学习方法无法区分真实偏好漂移与瞬态上下文噪声

Method: SPRInG采用漂移驱动的选择性适应：训练时使用基于似然的评分函数识别高新颖性交互，选择性更新用户特定适配器，同时将难学习的残差保存在重放缓冲区；推理时应用严格相关性门控，通过logit插值融合参数化知识与检索历史

Result: 在长格式个性化生成基准测试中，SPRInG优于现有基线方法，验证了其在真实世界持续个性化任务中的鲁棒性

Conclusion: SPRInG框架有效解决了动态用户偏好下的持续个性化问题，通过选择性适应机制平衡了适应新偏好与保留历史知识的需求

Abstract: Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRInG, a novel semi-parametric framework designed for effective continual personalization. During training, SPRInG employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRInG outperforms existing baselines, validating its robustness for real-world continual personalization.

</details>


### [200] [Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL](https://arxiv.org/abs/2601.10011)
*Zerui Yang,Weichuan Wang,Yanwei Xu,Linqi Song,Yudai Matsuda,Wei Han,Bo Bai*

Main category: cs.AI

TL;DR: Memo-SQL：一个无需训练的NL2SQL框架，通过结构化分解和经验感知自校正解决现有方法的问题，在BIRD数据集上达到68.5%执行准确率，比之前方法节省10倍以上资源。


<details>
  <summary>Details</summary>
Motivation: 现有NL2SQL系统存在两个关键限制：1）仅依赖正确示例进行上下文学习，忽略了历史错误修复对中的丰富信号；2）测试时缩放方法通常任意分解问题，产生几乎相同的SQL候选，降低了集成增益。此外，这些方法面临严重的准确率-效率权衡：高性能需要过多计算，而快速变体则牺牲质量。

Method: Memo-SQL采用两种简单思想：结构化分解和经验感知自校正。结构化分解使用三种明确策略：实体级、分层和原子序列分解，以鼓励多样化推理。自校正方面，构建包含成功查询和历史错误修复对的动态记忆，使用检索增强提示在推理时将相关示例引入上下文，无需微调或外部API。

Result: 在BIRD数据集上，Memo-SQL达到68.5%的执行准确率，在开放、零微调方法中创造了新的最先进水平，同时比之前的TTS方法使用超过10倍的更少资源。

Conclusion: Memo-SQL通过结构化分解和经验感知自校正有效解决了现有NL2SQL系统的局限性，在保持高性能的同时显著提高了效率，为训练免费的NL2SQL系统提供了有前景的解决方案。

Abstract: Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive computation, while fast variants compromise quality. We present Memo-SQL, a training-free framework that addresses these issues through two simple ideas: structured decomposition and experience-aware self-correction. Instead of leaving decomposition to chance, we apply three clear strategies, entity-wise, hierarchical, and atomic sequential, to encourage diverse reasoning. For correction, we build a dynamic memory of both successful queries and historical error-fix pairs, and use retrieval-augmented prompting to bring relevant examples into context at inference time, no fine-tuning or external APIs required. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10 times fewer resources than prior TTS approaches.

</details>


### [201] [Structured Personality Control and Adaptation for LLM Agents](https://arxiv.org/abs/2601.10025)
*Jinpeng Wang,Xinyu Jia,Wei Wei Heng,Yuquan Li,Binbin Shi,Qianlei Chen,Guannan Chen,Junxia Zhang,Yuyu Yin*

Main category: cs.AI

TL;DR: 提出了一个基于荣格心理类型的LLM人格建模框架，通过三种机制实现人格的连贯表达、情境适应和长期演化，为HCI中的自然化智能体设计提供支持。


<details>
  <summary>Details</summary>
Motivation: LLM在HCI中应用日益广泛，但现有方法难以同时实现细腻且可适应的人格表达。人格特质对用户参与度、决策和真实感感知至关重要，需要更系统的人格建模方法。

Method: 基于荣格心理类型理论，设计包含三种机制的框架：1)主导-辅助协调机制实现核心人格连贯表达；2)强化-补偿机制实现情境适应；3)反思机制驱动长期人格演化。使用MBTI问卷进行人格对齐评估，并在多样化挑战场景中测试。

Result: 研究发现演化的人格感知LLM能够支持连贯且情境敏感的交云，为HCI中的自然化智能体设计提供可能。通过MBTI评估和挑战场景测试验证了框架的有效性。

Conclusion: 该框架使LLM能够保持细腻人格特质的同时动态适应交互需求并逐步更新底层结构，为构建更自然、人性化的HCI智能体提供了理论基础和技术路径。

Abstract: Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant-auxiliary coordination mechanism for coherent core expression, a reinforcement-compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers-Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.

</details>


### [202] [Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment](https://arxiv.org/abs/2601.10520)
*Felix Jahn,Yannic Muskalla,Lisa Dargasz,Patrick Schramowski,Kevin Baum*

Main category: cs.AI

TL;DR: GRACE是一个神经符号推理的基于原因的约束架构，通过将规范性推理与工具性决策解耦，实现对AI代理的道德约束和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在重要场景中自主部署并产生实际影响，确保其决策不仅工具性有效而且规范性对齐变得至关重要。需要一种能够约束任何设计AI代理的架构。

Method: GRACE将决策分为三个模块：道德模块（使用道义逻辑推理确定允许的宏观行动）、决策模块（封装目标代理并选择工具性最优的原始行动）、守卫模块（监控和执行道德合规）。采用基于原因的形式化方法，提供道义逻辑的语义基础。

Result: GRACE能够实现可解释性、可争议性和可辩护性，丰富决策模块的信息上下文，支持形式化验证和统计保证。在LLM治疗助手示例中展示了如何让利益相关者理解、争议和优化代理行为。

Conclusion: GRACE架构通过神经符号方法将规范性推理与工具性决策分离，为AI代理的道德对齐提供了可解释、可验证的解决方案，适用于各种AI设计。

Abstract: As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.

</details>


### [203] [PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization](https://arxiv.org/abs/2601.10029)
*Tingyue Pan,Jie Ouyang,Mingyue Cheng,Qingchuan Li,Zirui Liu,Mingfan Pan,Shuo Yu,Qi Liu*

Main category: cs.AI

TL;DR: PaperScout：将论文搜索重构为序列决策过程的自主代理，使用PSPO方法解决多轮代理任务中的粒度不匹配问题


<details>
  <summary>Details</summary>
Motivation: 现有论文搜索方法依赖僵化的预定义工作流，难以处理复杂的条件查询。需要一种能够动态决策何时、如何调用搜索工具的自主代理系统。

Method: 提出PaperScout自主代理框架，将论文搜索重构为序列决策过程。引入Proximal Sequence Policy Optimization (PSPO)方法，这是一种过程感知的序列级策略优化方法，解决多轮代理任务中token级优化与序列级交互的粒度不匹配问题。

Result: 在合成和真实世界基准测试中，PaperScout在召回率和相关性方面显著优于基于工作流和强化学习的基线方法。

Conclusion: PaperScout的自适应代理框架和PSPO优化策略有效解决了复杂论文搜索问题，验证了将搜索重构为序列决策过程的方法优势。

Abstract: Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such agents presents a fundamental challenge: standard reinforcement learning methods, typically designed for single-turn tasks, suffer from a granularity mismatch when applied to multi-turn agentic tasks, where token-level optimization diverges from the granularity of sequence-level interactions, leading to noisy credit assignment. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.

</details>


### [204] [Generative AI collective behavior needs an interactionist paradigm](https://arxiv.org/abs/2601.10567)
*Laura Ferrarotti,Gian Maria Campedelli,Roberto Dessì,Andrea Baronchelli,Giovanni Iacca,Kathleen M. Carley,Alex Pentland,Joel Z. Leibo,James Evans,Bruno Lepri*

Main category: cs.AI

TL;DR: 本文主张研究基于大语言模型（LLM）的智能体集体行为至关重要，需要采用交互主义范式来系统分析先验知识、嵌入价值观与社会情境如何共同塑造多智能体生成式AI系统中的涌现现象。


<details>
  <summary>Details</summary>
Motivation: 理解基于大语言模型的智能体集体行为是一个关键研究领域，对社会具有重要风险与收益影响。LLM的独特性质——通过预训练获得广泛知识、隐含社会先验，以及通过上下文学习进行适应——需要新的理论框架来研究先验知识、嵌入价值观与社会情境如何相互作用，从而影响多智能体系统中的涌现现象。

Method: 提出交互主义范式，包含替代性理论基础、方法论和分析工具。该方法强调系统性地研究先验知识、嵌入价值观与社会情境之间的动态交互，以理解多智能体生成式AI系统中的集体行为模式。

Result: 提出了四个关键发展方向：理论构建、方法论创新、跨学科对话，以及LLM集体系统的开发与部署策略。这些方向旨在为LLM集体行为研究提供系统性框架。

Conclusion: 研究LLM智能体集体行为需要新的交互主义范式，该范式应整合理论、方法和跨学科视角，以应对LLM集体系统带来的社会影响和挑战，确保其负责任的发展与部署。

Abstract: In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.

</details>


### [205] [FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data](https://arxiv.org/abs/2601.10031)
*Jianheng Tang,Shilong Tao,Zhe Feng,Haonan Sun,Menglu Wang,Zhanxing Zhu,Yunhuai Liu*

Main category: cs.AI

TL;DR: 提出FilDeep框架，通过同时使用低保真度（高数量）和高保真度（高精度）数据解决大变形弹性塑性固体计算中的数据数量-精度困境，首次将多保真度数据应用于大变形问题的深度学习。


<details>
  <summary>Details</summary>
Motivation: 大变形弹性塑性固体的科学计算在制造应用中至关重要，但传统数值方法存在局限。深度学习作为替代方案，其效果依赖于高质量数据集，而大变形问题中获取高数量、高精度数据存在困境，需要在数据数量与精度之间权衡。

Method: 提出FilDeep框架，以拉伸弯曲问题为代表应用，同时使用低保真度（高数量、低精度）和高保真度（低数量、高精度）数据进行训练。设计了注意力机制的跨保真度模块，有效捕捉多保真度数据间的长程物理相互作用。

Result: 大量实验表明，FilDeep框架始终达到最先进的性能水平，并且能够高效部署于制造应用中。这是首个将多保真度数据用于大变形问题的深度学习框架。

Conclusion: FilDeep成功解决了大变形问题中的数据数量-精度困境，通过创新的多保真度数据融合方法，为大变形弹性塑性固体的科学计算提供了有效的深度学习解决方案，在制造应用中具有实际部署价值。

Abstract: The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.

</details>


### [206] [State of AI: An Empirical 100 Trillion Token Study with OpenRouter](https://arxiv.org/abs/2601.10088)
*Malika Aubakirova,Alex Atallah,Chris Clark,Justin Summerville,Anjney Midha*

Main category: cs.AI

TL;DR: 基于OpenRouter平台分析100万亿token真实LLM使用数据，发现开源模型广泛采用、创意角色扮演和编码助手应用流行、智能体推理兴起，以及早期用户留存率显著更高的"灰姑娘玻璃鞋"效应。


<details>
  <summary>Details</summary>
Motivation: 随着o1等推理模型的发布，LLM从单次模式生成转向多步推理，但实际使用情况的实证理解滞后。需要了解真实世界中开发者与终端用户如何与LLM互动。

Method: 利用OpenRouter平台作为AI推理提供商，分析超过100万亿token的真实世界LLM交互数据，涵盖不同任务、地域和时间维度。

Result: 观察到开源模型广泛采用、创意角色扮演（不仅仅是生产力任务）和编码助手类别异常流行、智能体推理兴起。留存分析发现早期用户参与度远高于后期用户的"灰姑娘玻璃鞋"效应。

Conclusion: LLM在真实世界中的使用复杂多样，数据驱动的使用理解能为模型构建者、AI开发者和基础设施提供商提供更好的设计和部署指导。

Abstract: The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged behind. In this work, we leverage the OpenRouter platform, which is an AI inference provider across a wide variety of LLMs, to analyze over 100 trillion tokens of real-world LLM interactions across tasks, geographies, and time. In our empirical study, we observe substantial adoption of open-weight models, the outsized popularity of creative roleplay (beyond just the productivity tasks many assume dominate) and coding assistance categories, plus the rise of agentic inference. Furthermore, our retention analysis identifies foundational cohorts: early users whose engagement persists far longer than later cohorts. We term this phenomenon the Cinderella "Glass Slipper" effect. These findings underscore that the way developers and end-users engage with LLMs "in the wild" is complex and multifaceted. We discuss implications for model builders, AI developers, and infrastructure providers, and outline how a data-driven understanding of usage can inform better design and deployment of LLM systems.

</details>


### [207] [MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning](https://arxiv.org/abs/2601.10101)
*Ke Chen,Jiandian Zeng,Zihao Peng,Guo Li,Guangxue Zhang,Tian Wang*

Main category: cs.AI

TL;DR: MatrixCoT：一种基于矩阵的结构化思维链框架，通过矩阵规划、类型标注和反馈重规划机制，提升LLM在符号推理任务中的鲁棒性和可解释性，无需外部求解器。


<details>
  <summary>Details</summary>
Motivation: 当前CoT方法在处理依赖符号表达式和严格演绎规则的逻辑推理任务时存在不足，神经符号方法依赖外部求解器但格式敏感易失败，纯LLM方法缺乏结构化表示和错误纠正机制。需要一种既能保持形式正确性又避免解析脆弱性的解决方案。

Method: 提出MatrixCoT框架：1）对自然语言表达式进行归一化和类型标注；2）添加显式引用字段；3）引入基于矩阵的规划方法保持步骤间的全局关系；4）加入反馈驱动的重规划机制，在语义等价约束下识别遗漏和缺陷，重写压缩依赖矩阵。

Result: 在5个逻辑推理基准和5个LLM上的实验表明，MatrixCoT在不依赖外部求解器的情况下，显著提升了处理复杂符号推理任务的鲁棒性和可解释性，同时保持了有竞争力的性能。

Conclusion: MatrixCoT通过结构化表示和验证机制，有效解决了传统CoT在符号推理中的局限性，为LLM的逻辑推理能力提升提供了新方向，平衡了形式正确性和模型灵活性。

Abstract: As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions, attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan becomes a verifiable artifact, making execution more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both robustness and interpretability when tackling complex symbolic reasoning tasks, while maintaining competitive performance.

</details>


### [208] [Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs](https://arxiv.org/abs/2601.10114)
*Cheng Feng,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.AI

TL;DR: 本文提出了一种新的知识蒸馏方法SCD，通过模拟教师模型在领域任务上的收敛过程，结合自适应加权机制，使学生模型能够在特定领域任务上达到甚至超越教师模型的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型难以部署到特定领域任务中，而将微调后的LLM蒸馏到较小的学生模型时，师生模型之间的容量差距往往导致性能不佳。核心问题是：学生模型何时以及如何能在特定领域任务上匹配甚至超越教师模型？

Method: 提出了两个关键创新：1) Scheduled Checkpoint Distillation (SCD)：通过模拟教师模型在监督微调过程中的收敛过程，减少学生在教师优势子域上的缺陷；2) Adaptive Weighting (AW)：样本级别的自适应加权机制，保留学生在学生优势子域上的优势。

Result: 在多种领域任务（包括问答、命名实体识别、多语言文本分类）上的实验表明，该方法持续优于现有的蒸馏方法，使学生模型能够匹配甚至超越其微调教师模型的性能。

Conclusion: 本文提出了一个理论见解：如果学生在学生优势子域上的优势超过了其在教师优势子域上的缺陷，学生就能超越教师。基于这一见解提出的SCD和AW方法有效解决了知识蒸馏中的容量差距问题，为部署高效领域特定模型提供了新途径。

Abstract: Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher's convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks--including QA, NER, and text classification in multiple languages--show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.

</details>


### [209] [M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints](https://arxiv.org/abs/2601.10131)
*Yizhan Li,Florence Cloutier,Sifan Wu,Ali Parviz,Boris Knyazev,Yan Zhang,Glen Berseth,Bang Liu*

Main category: cs.AI

TL;DR: MolGen是一个两阶段分子生成框架，通过片段级检索增强和强化学习优化，在多属性约束下生成满足精确数值要求的分子。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在分子生成方面具有表达能力，但在精确的多目标控制和数值推理方面存在困难，需要外部结构和反馈。现有方法难以同时满足多个物理化学属性的精确数值约束。

Method: 提出两阶段框架：第一阶段原型生成，使用多智能体推理器进行检索锚定的片段级编辑；第二阶段基于强化学习的细粒度优化，使用GRPO训练片段级优化器进行单跳或多跳优化，最小化属性误差并控制编辑复杂度和原型偏差。

Result: 在两个属性约束集（QED、LogP、分子量和HOMO、LUMO）上的实验表明，该方法在有效性和多属性目标精确满足方面表现一致优于强LLM和基于图的算法。

Conclusion: MolGen通过片段级推理和可控优化，能够更好地在多属性约束下生成满足精确数值要求的分子，优于现有方法。

Abstract: Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reasoner performs retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II : RL-based fine-grained optimization: a fragment-level optimizer trained with Group Relative Policy Optimization (GRPO) applies one- or multi-hop refinements to explicitly minimize the property errors toward our target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.

</details>


### [210] [Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction](https://arxiv.org/abs/2601.10132)
*Yanan Cao,Farnaz Fallahi,Murali Mohana Krishna Dandu,Lalitesh Morishetti,Kai Zhao,Luyi Ma,Sinduja Subramaniam,Jianpeng Xu,Evren Korpeoglu,Kaushiki Nag,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: LLMs在预测用户重复行为时间间隔方面表现有限，虽然优于简单统计模型但不如专用机器学习模型，且过多上下文信息反而会降低预测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在多个领域展现出强大的推理和预测能力，但其从结构化行为数据中推断时间规律的能力尚未得到充分探索。本研究旨在探究LLMs是否能预测重复用户行为（如重复购买）之间的时间间隔，以及不同层次的上下文信息如何影响其预测表现。

Method: 使用简单但具有代表性的重复购买场景，在零样本设置下对最先进的LLMs进行基准测试，并与统计模型和机器学习模型进行比较。研究考察了不同层次上下文信息（从无上下文到详细用户级信息）对LLM预测性能的影响。

Result: 1. LLMs虽然超越了轻量级统计基线模型，但始终不如专用机器学习模型，显示出其在捕捉定量时间结构方面的有限能力。2. 适度的上下文信息可以提高LLM的准确性，但添加更多用户级详细信息反而会降低性能，挑战了"更多上下文带来更好推理"的假设。

Conclusion: 研究揭示了当前LLMs在结构化时间推理方面的基本局限性，为设计未来上下文感知的混合模型提供了指导，这些模型需要整合统计精度与语言灵活性。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that "more context leads to better reasoning". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.

</details>


### [211] [DecisionLLM: Large Language Models for Long Sequence Decision Exploration](https://arxiv.org/abs/2601.10148)
*Xiaowei Lv,Zhilin Zhang,Yijun Li,Yusen Huo,Siyuan Ju,Xuyan Li,Chunxiang Hong,Tianyu Wang,Yongcai Wang,Peng Sun,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.AI

TL;DR: 该论文提出DecisionLLM，将大型语言模型应用于离线决策任务，通过将轨迹数据作为独立模态与自然语言任务描述对齐，解决了LLM无法理解连续数值的问题，在迷宫导航和竞价场景中显著优于传统决策Transformer。


<details>
  <summary>Details</summary>
Motivation: 决策Transformer将强化学习框架为自回归序列建模问题，而大型语言模型在复杂推理和规划任务中表现出色。作者探索LLM是否能在长序列决策问题中发挥更大潜力，但面临LLM无法理解连续数值的根本挑战。

Method: 提出DecisionLLM框架，将轨迹数据视为独立模态，学习轨迹数据与自然语言任务描述的对齐，使模型能够在统一框架内自回归预测未来决策。建立了该范式的缩放定律，识别模型规模、数据量和数据质量三个关键因素。

Result: DecisionLLM-3B在Maze2D umaze-v1上比传统决策Transformer提升69.4分，在AuctionNet上提升0.085分。展示了该范式在离线实验基准和竞价场景中的强大性能。

Conclusion: DecisionLLM扩展了AIGB范式，为在线竞价等应用指明了有前景的研究方向，证明了LLM在长序列决策任务中的潜力，特别是通过模态对齐方法解决了数值理解问题。

Abstract: Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whether LLMs, which share the same Transformer foundation, but operate at a much larger scale, can unlock new levels of performance in long-horizon sequential decision-making problem. This work investigates the application of LLMs to offline decision making tasks. A fundamental challenge in this domain is the LLMs' inherent inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order when values are represented as text strings. To address this, we propose treating trajectories as a distinct modality. By learning to align trajectory data with natural language task descriptions, our model can autoregressively predict future decisions within a cohesive framework we term DecisionLLM. We establish a set of scaling laws governing this paradigm, demonstrating that performance hinges on three factors: model scale, data volume, and data quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance. Specifically, DecisionLLM-3B outperforms the traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding.

</details>


### [212] [MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging](https://arxiv.org/abs/2601.10154)
*Leonard Nürnberg,Dennis Bontempi,Suraj Pai,Curtis Lisle,Steve Pieper,Ron Kikinis,Sil van de Leemput,Rahul Soni,Gowtham Murugesan,Cosmin Ciausu,Miriam Groeneveld,Felix J. Dorfner,Jue Jiang,Aneesh Rangnekar,Harini Veeraraghavan,Joeran S. Bosma,Keno Bressem,Raymond Mak,Andrey Fedorov,Hugo JWL Aerts*

Main category: cs.AI

TL;DR: MHub.ai是一个开源容器化平台，旨在标准化医学影像AI模型的访问，解决模型实现多样、文档不一致和可复现性问题，通过容器化包装模型并提供统一接口。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI研究面临模型实现多样化、文档不一致和可复现性差的问题，限制了AI在临床研究和应用中的潜力。

Method: 开发开源容器化平台MHub.ai，将同行评审的AI模型打包为标准容器，支持DICOM等格式直接处理，提供统一应用接口和结构化元数据，并包含公开参考数据验证模型运行。

Result: 平台包含多种模态的最先进分割、预测和特征提取模型，通过肺分割模型的比较评估展示了临床实用性，并公开了分割结果和评估指标。

Conclusion: MHub.ai通过简化模型使用、支持标准化输出和降低临床转化门槛，促进了医学影像AI的可访问性和可复现性。

Abstract: Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation.

</details>


### [213] [MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning](https://arxiv.org/abs/2601.10157)
*Yusong Wang,Jialun Shen,Zhihao Wu,Yicheng Xu,Shiyin Tan,Mingkun Xu,Changshuo Wang,Zixing Song,Prayag Tiwari*

Main category: cs.AI

TL;DR: MMPG是一个多视角蛋白质图神经网络框架，通过混合专家模型自适应融合物理、化学和几何视角的蛋白质图表示，提升蛋白质表征学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的蛋白质表征学习方法通常采用单视角图构建策略，只能捕捉残基相互作用的部分特性，导致蛋白质表示不完整。需要多视角融合来获得更全面的蛋白质表征。

Method: 提出MMPG框架：1）从物理、化学和几何三个视角构建蛋白质图；2）设计混合专家模块动态路由不同视角到专门专家；3）专家学习内在特征和跨视角交互；4）捕捉从个体表示到成对跨视角协同再到全局共识的多层次信息。

Result: MoE模块自动专业化专家建模不同层次的交互：个体表示、成对跨视角协同、全局共识。MMPG在四个不同的下游蛋白质任务上实现了先进的性能。

Conclusion: 通过多视角图构建和自适应融合，MMPG能够产生更优的蛋白质表示，解决了单视角方法的局限性，为蛋白质表征学习提供了更全面的解决方案。

Abstract: Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.

</details>


### [214] [CtD: Composition through Decomposition in Emergent Communication](https://arxiv.org/abs/2601.10169)
*Boaz Carmeli,Ron Meir,Yonatan Belinkov*

Main category: cs.AI

TL;DR: 该研究提出"通过分解实现组合"的方法，让神经网络智能体通过两个训练步骤学习组合泛化能力，能够描述未见过的图像。


<details>
  <summary>Details</summary>
Motivation: 组合性是人类的认知机制，能够系统地将已知概念组合成新的表达。研究旨在探索人工神经网络如何获得并利用这种组合泛化能力来描述未见过的图像。

Method: 提出"通过分解实现组合"的两步训练法：1) "分解"步骤：在多目标协调游戏中，智能体学习将图像分解为基本概念，并建立概念代码本；2) "组合"步骤：智能体使用该代码本将基本概念组合成复杂短语来描述新图像。

Result: 智能体成功获得了组合泛化能力，能够描述未见过的图像。特别值得注意的是，在某些情况下，智能体在"组合"步骤中实现了零样本泛化，无需额外训练。

Conclusion: 该研究展示了神经网络智能体可以通过分解-组合的方法获得组合泛化能力，这种能力使得智能体能够处理新颖的输入，为人工智能系统实现类似人类的组合认知能力提供了可行路径。

Abstract: Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed "Composition through Decomposition", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game. Subsequently, in the 'Compose' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases. Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training.

</details>


### [215] [How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series](https://arxiv.org/abs/2601.10191)
*Mathieu Cherpitel,Janne Luijten,Thomas Bäck,Camiel Verhamme,Martijn Tannemaat,Anna Kononova*

Main category: cs.AI

TL;DR: 该研究提出了一种评估下采样对高频时间序列信息损失的系统工作流程，结合形状失真度量和分类性能分析，应用于针肌电图信号分析，以平衡计算负载与诊断信息保留。


<details>
  <summary>Details</summary>
Motivation: 针肌电图信号的高采样率和异质性给基于特征的机器学习模型带来计算挑战，特别是近实时分析。下采样是潜在解决方案，但其对诊断信号内容和分类性能的影响尚未充分理解。

Method: 提出系统工作流程，结合形状失真度量、特征机器学习模型分类结果和特征空间分析，量化不同下采样算法和因素对波形完整性和预测性能的影响。使用三类神经肌肉疾病分类任务进行实验评估。

Result: 工作流程能识别在显著减少计算负载的同时保留诊断信息的下采样配置。形状感知下采样算法优于标准抽取，能更好地保留峰值结构和整体信号形态。

Conclusion: 研究提供了选择下采样配置的实用指导，使近实时针肌电图分析成为可能，并提出了一个可推广的工作流程，可用于其他高频时间序列应用中平衡数据缩减与模型性能。

Abstract: Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals' high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.

</details>


### [216] [GFM4GA: Graph Foundation Model for Group Anomaly Detection](https://arxiv.org/abs/2601.10193)
*Jiujiu Chen,Weijun Zeng,Shaofeng Hu,Sihong Xie,Hui Xiong*

Main category: cs.AI

TL;DR: 提出GFM4GA，一种用于群体异常检测的图基础模型，通过双层次对比学习预训练和参数约束的少样本微调，在AUROC和AUPRC指标上平均提升2.85%和2.55%。


<details>
  <summary>Details</summary>
Motivation: 群体异常检测面临异常模式多样化的挑战。现有图基础模型（GFMs）虽然能检测个体异常，但无法推广到群体异常，因为群体异常需要整体检测，且异常群体中的个体可能看起来正常。

Method: 提出GFM4GA模型，采用基于特征估计和群体提取的双层次对比学习进行预训练，捕捉潜在群体异常结构和特征不一致性。在下游任务中，通过参数约束和群体异常比例加权的少样本设置进行微调，并通过标记异常邻居确定的群体上下文扩展对未见群体异常的适应能力。

Result: 实验表明GFM4GA超越了现有的群体异常检测器和用于个体异常的GFMs，在AUROC和AUPRC指标上分别平均提升了2.85%和2.55%。

Conclusion: GFM4GA成功将图基础模型扩展到群体异常检测领域，通过创新的预训练和微调策略有效解决了群体异常检测的独特挑战。

Abstract: Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.

</details>


### [217] [Topo-RAG: Topology-aware retrieval for hybrid text-table documents](https://arxiv.org/abs/2601.10215)
*Alex Dantart,Marco Kóvacs-Navarro*

Main category: cs.AI

TL;DR: Topo-RAG是一个针对企业混合文档（文本+表格）的检索增强生成框架，通过双架构分别处理文本叙述和表格结构，相比传统线性化方法在混合查询上提升了18.4%的nDCG@10性能。


<details>
  <summary>Details</summary>
Motivation: 企业文档通常是文本叙述和表格结构的复杂混合体，而当前的RAG系统采用线性化方法将多维表格转换为简单文本字符串，这种数学上已被证明是不充分的，无法有效捕捉表格的空间几何关系。

Method: 提出Topo-RAG框架，采用双架构设计：1）传统密集检索器处理流畅的文本叙述；2）Cell-Aware Late Interaction机制处理表格结构，保留其空间拓扑关系。挑战了"一切皆文本"的假设。

Result: 在模拟真实企业复杂性的SEC-25合成企业语料库上评估，Topo-RAG在混合查询上的nDCG@10指标相比标准线性化方法提升了18.4%。

Conclusion: Topo-RAG通过尊重数据的拓扑结构，不仅提升了搜索性能，更重要的是理解了信息的形状，为处理企业混合文档提供了更有效的方法。

Abstract: In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. We convert rich, multidimensional tables into simple Markdown-style text strings, hoping that an embedding model will capture the geometry of a spreadsheet in a single vector. But it has already been shown that this is mathematically insufficient.
  This work presents Topo-RAG, a framework that challenges the assumption that "everything is text". We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It's not just about searching better; it's about understanding the shape of information.

</details>


### [218] [TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks](https://arxiv.org/abs/2601.10245)
*Vansh Kapoor,Aman Gupta,Hao Chen,Anurag Beniwal,Jing Huang,Aviral Kumar*

Main category: cs.AI

TL;DR: TRIM提出了一种针对多步推理任务的定向路由方法，仅在关键步骤（可能导致解决方案崩溃的步骤）使用大模型，而让小模型处理常规步骤，从而显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM路由方法将整个查询分配给单一模型，将所有推理步骤视为同等重要。多步推理任务（如数学问题解决）容易发生级联失败，单个错误步骤会导致整个解决方案崩溃。

Method: TRIM在步骤级别操作：使用过程奖励模型识别错误步骤，基于步骤级别的不确定性和预算约束做出路由决策。开发了多种路由策略，从简单的基于阈值的策略到更复杂的策略，考虑长期准确性-成本权衡和步骤正确性估计的不确定性。

Result: 在MATH-500上，即使最简单的阈值策略也超越了先前的路由方法，成本效率提高5倍；更高级的策略使用80%更少的大模型token就能匹配强大昂贵模型的性能。在更难的基准测试如AIME上，TRIM实现了高达6倍的成本效率提升。

Conclusion: 所有方法在数学推理任务中都能有效泛化，表明步骤级别的难度代表了推理的基本特征。定向步骤级干预可以通过将昂贵调用限制在那些需要更强模型防止级联错误的步骤上，从根本上改变推理效率。

Abstract: Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\unicode{x2013}$those likely to derail the solution$\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.

</details>


### [219] [NoReGeo: Non-Reasoning Geometry Benchmark](https://arxiv.org/abs/2601.10254)
*Irina Abdullaeva,Anton Vasiliuk,Elizaveta Goncharova,Temurbek Rahmatullaev,Zagorulko Ivan,Maxim Kurkin,Andrey Kuznetsov*

Main category: cs.AI

TL;DR: NoReGeo是一个评估大语言模型内在几何理解能力的新基准，专注于空间关系和几何属性识别，无需代数推理，发现当前最先进模型在二元分类任务中最高准确率仅65%


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估基于推理的几何能力（使用代数方法求解），但缺乏对LLMs是否真正内在地编码空间关系和识别几何属性的评估。需要专门评估LLMs的固有几何理解能力，而不依赖推理或代数计算。

Method: 创建NoReGeo基准，包含2,500个简单几何问题，涵盖25个类别，每个问题都精心设计为仅通过固有几何理解即可解决（假设已知对象位置）。评估包括GPT-4在内的最先进模型，并进行消融实验。

Result: 即使是最先进的模型（如GPT-4）在二元分类任务中的总体最高准确率仅为65%。消融实验表明，仅通过微调无法获得几何理解能力，有效的几何理解训练需要从一开始就采用专门方法。

Conclusion: 当前LLMs在固有几何概念理解方面存在显著差距，这为未来开发具有真正几何认知能力的模型研究奠定了基础。几何理解需要专门的训练方法，不能仅靠微调获得。

Abstract: We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.

</details>


### [220] [Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning](https://arxiv.org/abs/2601.10306)
*Xin Guan,Zijian Li,Shen Huang,Pengjun Xie,Jingren Zhou,Jiuxin Cao*

Main category: cs.AI

TL;DR: EAPO提出证据增强策略优化方法，通过密集的过程监督改进长上下文推理中的证据提取质量，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在长上下文推理中存在结果奖励稀疏的问题，无法有效惩罚无根据的"幸运猜测"，导致证据检索过程缺乏监督。

Method: 1) 建立证据增强推理范式，通过树结构证据采样验证证据提取是关键瓶颈；2) 提出EAPO算法，使用奖励模型计算组相对证据奖励，提供密集过程监督；3) 引入自适应奖励-策略协同进化机制，迭代优化奖励模型。

Result: 在八个基准测试上的综合评估表明，EAPO相比现有最优基线显著提升了长上下文推理性能。

Conclusion: EAPO通过密集过程监督和自适应奖励-策略协同进化，有效解决了长上下文推理中证据提取的监督问题，为强化学习在复杂推理任务中的应用提供了新思路。

Abstract: While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded "lucky guesses," leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.

</details>


### [221] [C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing](https://arxiv.org/abs/2601.10342)
*Cheng Lin Cheng,Ting Chuan Lin,Chai Kai Chang*

Main category: cs.AI

TL;DR: C-GRASP是一个用于HRV解释的临床推理框架，通过八步可追溯推理步骤、Z-score优先级层次结构和RSA感知护栏，有效缓解LLM在生理信号处理中的幻觉问题，在情感分类和临床推理一致性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型应用于心率变异性解释时面临生理幻觉问题，包括呼吸性窦性心律失常污染、非线性指标的短数据不稳定性，以及忽视个体化基线而偏好群体规范。需要开发能够提供透明、基于证据的临床决策支持的解决方案。

Method: 提出C-GRASP（临床基础推理的情感信号处理）框架，包含八个可追溯推理步骤的护栏增强RAG流程。核心是Z-score优先级层次结构，强制优先考虑个体化基线偏移而非规范统计。通过自动RSA感知护栏缓解频谱幻觉，防止频域指标污染。

Result: 在DREAMER数据集的414个试验中评估，C-GRASP与高规模推理模型（如MedGemma3-thinking）集成，在4类情感分类中达到37.3%的准确率，临床推理一致性得分为69.6%。消融研究证实个体化Delta Z-score模块是关键逻辑锚点。

Conclusion: C-GRASP将情感计算从黑盒分类转变为透明、基于证据的临床决策支持，为生物医学工程中更安全的AI集成铺平道路，有效防止了原生LLM中常见的"群体偏见"。

Abstract: Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the "population bias" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.

</details>


### [222] [LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries](https://arxiv.org/abs/2601.10398)
*Xuancheng Ren,Shijing Hu,Zhihui Lu,Jiangqi Huang,Qiang Duan*

Main category: cs.AI

TL;DR: LatentRefusal：基于LLM隐藏激活信号预测查询可回答性的文本到SQL安全拒绝机制，通过Tri-Residual Gated Encoder增强模式不匹配信号，实现高效安全层


<details>
  <summary>Details</summary>
Motivation: 在基于LLM的文本到SQL系统中，不可回答或欠明确的用户查询可能生成错误的SQL程序，导致误导性结果或违反安全约束，现有拒绝策略要么依赖脆弱的输出级指令遵循，要么需要复杂的输出不确定性估计

Method: 将安全拒绝形式化为可回答性门控问题，提出LatentRefusal机制，从LLM中间隐藏激活预测查询可回答性，使用Tri-Residual Gated Encoder轻量探测架构抑制模式噪声并放大问题-模式不匹配的稀疏局部线索

Result: 在四个基准测试中，LatentRefusal将平均F1提升至88.5%，同时仅增加约2毫秒的探测开销，在多种模糊和不可回答场景下表现出有效性

Conclusion: LatentRefusal为文本到SQL系统提供了一个可附加的高效安全层，通过潜在信号拒绝机制有效处理不可回答查询，优于现有方法

Abstract: In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead.

</details>


### [223] [Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering](https://arxiv.org/abs/2601.10402)
*Xinyu Zhu,Yuzhu Cai,Zexi Liu,Bingyang Zheng,Cheng Wang,Rui Ye,Jiaao Chen,Hanrui Wang,Wei-Chen Wang,Yuzhi Zhang,Linfeng Zhang,Weinan E,Di Jin,Siheng Chen*

Main category: cs.AI

TL;DR: ML-Master 2.0通过分层认知缓存架构解决AI在超长周期自主性中的瓶颈，在机器学习工程任务上达到56.44%的奖牌率。


<details>
  <summary>Details</summary>
Motivation: 当前AI向代理科学发展的瓶颈在于超长周期自主性——在跨越数天或数周的实验周期中保持战略连贯性和迭代修正的能力。虽然大语言模型在短周期推理中表现出色，但在现实世界研究的高维、延迟反馈环境中容易被执行细节淹没，无法将稀疏反馈整合为连贯的长期指导。

Method: 提出分层认知缓存（HCC），这是一种受计算机系统启发的多层架构，将上下文管理重构为认知积累过程。HCC能够动态地将瞬时执行轨迹提炼为稳定知识和跨任务智慧，使代理能够将即时执行与长期实验策略解耦，有效克服静态上下文窗口的扩展限制。

Result: 在OpenAI的MLE-Bench上使用24小时预算进行评估，ML-Master 2.0实现了56.44%的最先进奖牌率。

Conclusion: 超长周期自主性为AI提供了一个可扩展的蓝图，使其能够在超越人类先例复杂性的领域进行自主探索。

Abstract: The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.

</details>


### [224] [ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics](https://arxiv.org/abs/2601.10406)
*Weiping Fu,Bifan Wei,Jingyi Hao,Yushun Zhang,Jian Zhang,Jiaxin Wang,Bo Li,Yu He,Lingling Zhang,Jun Liu*

Main category: cs.AI

TL;DR: ErrEval是一个错误感知的自动问题生成评估框架，通过显式错误诊断和两阶段评估流程，解决现有方法忽视关键缺陷和过高估计问题质量的问题。


<details>
  <summary>Details</summary>
Motivation: 自动问题生成（QG）常产生事实性幻觉和答案不匹配等关键缺陷，但现有评估方法（包括基于LLM的评估器）采用黑盒整体范式，缺乏显式错误建模，导致忽视这些缺陷并高估问题质量。

Method: ErrEval将评估重新定义为两阶段过程：错误诊断后接知情评分。第一阶段使用轻量级即插即用错误标识器检测和分类结构、语言和内容方面的常见错误；第二阶段将这些诊断信号作为显式证据指导LLM评估器做出更细粒度和有根据的判断。

Result: 在三个基准测试上的广泛实验证明ErrEval的有效性，显示显式诊断能提高与人类判断的一致性。进一步分析确认ErrEval有效缓解了对低质量问题的过高估计。

Conclusion: ErrEval通过显式错误诊断和知情评分框架，显著提升了自动问题生成评估的准确性和可靠性，解决了现有评估方法忽视关键缺陷的问题。

Abstract: Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.

</details>


### [225] [LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies](https://arxiv.org/abs/2601.10413)
*Haiyue Yuan,Nikolay Matyunin,Ali Raza,Shujun Li*

Main category: cs.AI

TL;DR: LADFA是一个端到端计算框架，结合LLM、RAG和定制知识库，从隐私政策中提取个人数据流并构建数据流图进行分析。


<details>
  <summary>Details</summary>
Motivation: 隐私政策通常使用复杂法律语言，难以理解且在不同组织间不一致，需要自动化大规模分析方法来帮助人们理解个人数据处理实践。

Method: 开发LADFA框架，结合大语言模型与检索增强生成技术，使用定制知识库处理隐私政策文本，提取个人数据流并构建数据流图进行分析。

Result: 通过汽车行业10个隐私政策的案例研究验证了方法的有效性和准确性，框架设计灵活可定制，适用于隐私政策分析之外的文本分析任务。

Conclusion: LADFA框架能够有效提取和分析隐私政策中的个人数据流，为自动化隐私政策分析提供了可行解决方案，具有广泛的应用潜力。

Abstract: Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.

</details>


### [226] [LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models](https://arxiv.org/abs/2601.10416)
*Tiesunlong Shen,Rui Mao,Jin Wang,Heming Sun,Jian Zhang,Xuejie Zhang,Erik Cambria*

Main category: cs.AI

TL;DR: LLMdoctor：一种基于患者-医生范式的测试时对齐框架，通过细粒度token级奖励获取和流引导偏好优化，在保持生成多样性的同时高效对齐大语言模型


<details>
  <summary>Details</summary>
Motivation: 传统微调方法计算成本高且不灵活，现有测试时对齐方法依赖扭曲的轨迹级信号或低效采样，性能受限且无法保持基础模型的生成多样性

Method: 采用患者-医生范式：从患者LLM的行为变化中提取细粒度token级偏好信号，通过token级流引导偏好优化（TFPO）训练小型医生模型，建立所有子轨迹的流一致性，实现精确的token级对齐

Result: LLMdoctor显著优于现有测试时对齐方法，甚至超越了DPO等完整微调方法的性能

Conclusion: LLMdoctor提供了一种高效、精确的测试时对齐框架，能够在保持生成多样性的同时实现更好的对齐效果，为LLM对齐提供了新思路

Abstract: Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.

</details>


### [227] [NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models](https://arxiv.org/abs/2601.10457)
*Ziming Dai,Dabiao Ma,Jinle Tong,Mengyuan Han,Jian Yang,Haojun Fei*

Main category: cs.AI

TL;DR: NSR-Boost是一个针对工业场景的神经符号残差增强框架，通过非侵入式方式修复遗留模型的"硬区域"，在金融风控系统中成功部署并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在工业表格应用中，GBDT模型占据主导地位，但在高并发生产环境中升级遗留模型面临昂贵的重新训练成本和系统性风险。需要一种安全、低成本的模型演进方案。

Method: NSR-Boost采用三阶段框架：1) 通过残差识别预测失败的"硬区域"；2) 使用LLM生成符号代码结构创建可解释专家，并通过贝叶斯优化微调参数；3) 通过轻量级聚合器动态集成专家与遗留模型输出。

Result: 在6个公共数据集和1个私有数据集上显著优于SOTA基线，在真实在线数据上表现出色，成功部署于Qfin Holdings核心金融风控系统，有效捕捉传统模型遗漏的长尾风险。

Conclusion: NSR-Boost为工业应用提供了一种安全、低成本的模型演进范式，能够非侵入式地修复遗留模型，在保持系统稳定性的同时提升性能。

Abstract: Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being "non-intrusive". It treats the legacy model as a frozen model and performs targeted repairs on "hard regions" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.

</details>


### [228] [ChartComplete: A Taxonomy-based Inclusive Chart Dataset](https://arxiv.org/abs/2601.10462)
*Ahmad Mustapha,Charbel Toumieh,Mariette Awad*

Main category: cs.AI

TL;DR: 提出ChartComplete数据集，覆盖30种图表类型，弥补现有图表理解基准数据集仅包含少量图表类型的不足


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准数据集仅覆盖少量图表类型，无法全面评估多模态大语言模型在图表理解任务上的性能

Method: 基于可视化社区的图表分类学，构建包含30种不同图表类型的ChartComplete数据集，仅包含分类的图表图像而不包含学习信号

Result: 创建了ChartComplete数据集，覆盖30种图表类型，为研究社区提供了更全面的图表理解基准

Conclusion: ChartComplete数据集填补了现有图表理解基准的空白，为评估多模态大语言模型的图表理解能力提供了更全面的测试平台

Abstract: With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.

</details>


### [229] [Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge](https://arxiv.org/abs/2601.10485)
*Runhao Zhao,Weixin Zeng,Wentao Zhang,Chong Chen,Zhengpin Li,Xiang Zhao,Lei Chen*

Main category: cs.AI

TL;DR: 提出Domain-specific Knowledge Graph Fusion (DKGF)任务，通过ExeFuse模型融合通用知识图谱到领域知识图谱，解决领域相关性和知识粒度对齐问题


<details>
  <summary>Details</summary>
Motivation: 领域知识图谱(DKGs)相比通用知识图谱(GKGs)覆盖不足，需要从GKGs中整合相关事实来丰富DKGs，但面临领域相关性高模糊性和知识粒度不对齐的挑战

Method: 提出ExeFuse模型，采用Fact-as-Program范式：将GKG事实视为潜在语义程序，将抽象关系映射为粒度感知操作符，通过程序在目标DKG上的可执行性验证领域相关性

Result: 构建了两个基准数据集DKGF(W-I)和DKGF(Y-I)包含21个评估配置，实验验证了任务的重要性和模型的有效性，为DKGF提供了首个标准化测试平台

Conclusion: 提出的DKGF任务和ExeFuse模型有效解决了领域知识图谱融合中的相关性和粒度对齐问题，为领域知识图谱增强提供了新方法

Abstract: Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF.

</details>


### [230] [Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection](https://arxiv.org/abs/2601.10524)
*Frank Bobe,Gregory D. Vetaw,Chase Pavlick,Darshan Bryner,Matthew Cook,Jose Salas-Vernis*

Main category: cs.AI

TL;DR: 本文提出一个多层诊断框架，用于分析LLM微调后的泛化失败问题。通过对Llama 3.1 8B、Gemma 2 9B和Mistral模型在钓鱼检测任务上的研究，揭示了架构与数据多样性对泛化性能的关键影响。


<details>
  <summary>Details</summary>
Motivation: 尽管微调大型语言模型在专业任务上取得了最先进的性能，但诊断这些模型为何变得脆弱且无法泛化仍然是一个关键未解决的问题。需要理解模型泛化失败的根本原因。

Method: 采用多层诊断框架，对Llama 3.1 8B、Gemma 2 9B和Mistral模型在高风险钓鱼检测任务上进行微调。使用SHAP分析和机制可解释性技术来揭示泛化失败的根源。

Result: 研究发现：(1) 泛化性能由架构与数据多样性的强大协同作用驱动，Gemma 2 9B在风格多样的"通才"数据集上达到>91% F1分数；(2) 泛化高度依赖架构，Llama 3.1 8B在窄域表现良好但无法整合多样数据；(3) 某些架构天生更具泛化能力，Mistral模型在多种训练范式中表现一致且稳健。

Conclusion: 通过识别导致泛化失败的错误启发式方法，本研究提供了诊断和理解泛化失败的具体方法，强调可靠AI需要对架构、数据和训练策略之间的相互作用进行深度验证。

Abstract: The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.

</details>


### [231] [A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5](https://arxiv.org/abs/2601.10527)
*Xingjun Ma,Yixu Wang,Hengyuan Xu,Yutao Wu,Yifan Ding,Yunhan Zhao,Zilong Wang,Jiabin Hua,Ming Wen,Jianan Liu,Ranjie Duan,Yifeng Gao,Yingshui Tan,Yunhao Chen,Hui Xue,Xin Wang,Wei Cheng,Jingjing Chen,Zuxuan Wu,Bo Li,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 该报告对7个前沿大模型进行了综合安全评估，发现安全性能存在显著异质性，GPT-5.2表现最均衡，其他模型在不同评估维度存在明显权衡，所有模型在对抗性评估中都表现脆弱。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和多模态大语言模型在推理、感知和生成能力上取得显著进展，但这些进步是否带来相应的安全改进仍不明确，主要因为现有评估实践局限于单一模态或威胁模型，缺乏综合评估框架。

Method: 采用统一协议对7个前沿模型（GPT-5.2、Gemini 3 Pro、Qwen3-VL、Doubao 1.8、Grok 4.1 Fast、Nano Banana Pro、Seedream 4.5）进行评估，涵盖语言、视觉语言和图像生成三种设置，整合基准评估、对抗性评估、多语言评估和合规性评估四种评估模式。

Result: 安全性能呈现显著异质性：GPT-5.2在所有评估中表现一致强劲且均衡；其他模型在基准安全、对抗对齐、多语言泛化和监管合规之间存在明显权衡；所有模型在对抗性评估中都显著退化；文本到图像模型在受监管视觉风险类别中相对对齐更强，但在对抗性或语义模糊提示下仍显脆弱。

Conclusion: 前沿模型的安全性本质上是多维度的，受模态、语言和评估方案影响，需要标准化安全评估来准确评估现实世界风险，指导负责任的模型开发和部署。

Abstract: The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment.

</details>


### [232] [Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing](https://arxiv.org/abs/2601.10543)
*Yinzhi Zhao,Ming Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.AI

TL;DR: 提出SafeProbing方法，通过在解码过程中显式利用LLMs内部潜在的安全信号，实现早期检测不安全内容，有效防御越狱攻击


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs经过安全对齐，但现有对齐往往是浅层的，容易受到越狱攻击。现有防御机制（如解码约束和后处理检测器）难以应对复杂越狱攻击，要么检测不鲁棒，要么过度降低模型效用

Method: 通过观察发现，即使成功越狱，模型在生成过程中内部仍会表现出潜在的安全相关信号。提出SafeProbing方法，在解码过程中显式地提取和利用这些潜在安全信号，实现早期不安全内容检测

Result: 在多种越狱攻击实验中，该方法显著增强了安全性，同时在良性输入上保持较低的过度拒绝率，并保持了响应质量

Conclusion: 在解码过程中激活内在的安全意识为防御越狱攻击提供了一个有前景的补充方向

Abstract: Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.

</details>


### [233] [From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA](https://arxiv.org/abs/2601.10581)
*Kimia Abedini,Farzad Shami,Gianmaria Silvello*

Main category: cs.AI

TL;DR: GenomAgent是一个多智能体框架，通过协调专门智能体处理复杂基因组查询，在GeneTuring基准测试中平均比GeneGPT提升12%，且架构灵活可扩展到其他科学领域


<details>
  <summary>Details</summary>
Motivation: 基因组信息理解对生物医学研究至关重要，但从复杂分布式数据库中提取数据仍然困难。大型语言模型在基因组问答方面有潜力，但受限于对领域特定数据库的访问。当前最先进的GeneGPT系统虽然通过专用API调用增强了LLM，但受限于僵化的API依赖和有限的适应性。

Method: 复制GeneGPT并提出GenomAgent，这是一个多智能体框架，能够高效协调专门智能体处理复杂的基因组查询。该框架采用灵活的架构设计，不依赖特定API。

Result: 在GeneTuring基准测试的九个任务上，GenomAgent平均比GeneGPT性能提升12%。其灵活架构不仅适用于基因组学，还可扩展到需要专家知识提取的各种科学领域。

Conclusion: GenomAgent通过多智能体协调机制有效解决了基因组问答中的数据库访问和适应性问题，显著超越了现有方法，并展示了在更广泛科学领域的应用潜力。

Abstract: Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.

</details>


### [234] [Multi-Property Synthesis](https://arxiv.org/abs/2601.10651)
*Christoph Weinhuber,Yannik Schnitzer,Alessandro Abate,David Parker,Giuseppe De Giacomo,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: 提出一种符号化算法，用于LTLf综合中处理多个可能冲突的属性，一次性计算所有可实现目标集合，避免枚举子集


<details>
  <summary>Details</summary>
Motivation: 在LTLf综合中，当需要同时满足多个属性时，这些属性可能存在冲突，无法全部实现。传统方法需要枚举所有属性子集，效率低下

Method: 引入布尔目标变量，利用单调性紧凑表示指数级的目标组合，通过单次不动点计算状态与可实现目标集合的关系，合成实现最大可实现集合的策略

Result: 该方法显著优于基于枚举的基线方法，速度提升可达两个数量级

Conclusion: 提出的符号化算法能高效处理LTLf综合中的多属性冲突问题，避免枚举开销，为实际应用提供可行解决方案

Abstract: We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.

</details>


### [235] [Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models](https://arxiv.org/abs/2601.10679)
*Zirui Ren,Ziming Liu*

Main category: cs.AI

TL;DR: HRM在推理任务中表现出色，但存在"猜测"而非"推理"的问题，通过数据增强、输入扰动和模型引导三种策略提升性能，将数独极端任务的准确率从54.5%提升至96.9%。


<details>
  <summary>Details</summary>
Motivation: 为了理解分层推理模型（HRM）的优势和潜在失败模式，研究其推理机制，发现HRM实际上更像是"猜测"而非"推理"，并基于这一发现提出改进策略。

Method: 对HRM进行机制性研究，发现三个关键现象：简单谜题失败、推理步骤中的"顿悟"动态、多个不动点存在。基于"猜测"视角提出三种扩展策略：数据增强（提升猜测质量）、输入扰动（利用推理随机性增加猜测次数）、模型引导（利用训练随机性增加猜测次数）。

Result: 结合所有方法开发了增强型HRM，在Sudoku-Extreme任务上将准确率从54.5%大幅提升至96.9%。

Conclusion: HRM实际上表现出"猜测"行为而非真正的推理，通过扩展猜测策略可以显著提升性能，这一分析为理解推理模型的"推理"机制提供了新视角。

Abstract: Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) "Grokking" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM "guesses" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be "guessing" instead of "reasoning". Leveraging this "guessing" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models "reason".

</details>


### [236] [Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems](https://arxiv.org/abs/2601.10681)
*Amir Khurshid,Abhishek Sehgal*

Main category: cs.AI

TL;DR: 提出一个基于结构信息和多样性约束的上下文气泡构建框架，用于在有限token预算下组装连贯、可引用的文本片段，相比传统RAG的top-k检索能减少冗余、提高覆盖率和答案质量。


<details>
  <summary>Details</summary>
Motivation: 传统RAG使用top-k检索方法存在信息图碎片化、过度检索、内容重复以及查询上下文不足（特别是二阶和三阶方面）等问题，需要更有效的上下文构建方法。

Method: 提出结构信息和多样性约束的上下文气泡框架：1) 利用文档结构组织多粒度文本片段；2) 使用任务条件化结构先验指导检索；3) 从高相关性锚点片段开始，通过平衡查询相关性、边际覆盖率和冗余惩罚的约束选择构建上下文气泡；4) 提供完整的检索追踪记录。

Result: 在企业文档上的实验表明，上下文气泡方法能显著减少冗余上下文，更好地覆盖次要方面，在有限上下文窗口内提供更好的答案质量和引用忠实度。消融研究显示结构先验和多样性约束都是必要的。

Conclusion: 提出的上下文气泡框架通过结构感知和多样性约束的检索，相比传统top-k方法能产生更紧凑、信息丰富的上下文集合，同时提供可审计性和确定性调优能力。

Abstract: Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.

</details>


### [237] [The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load](https://arxiv.org/abs/2601.10696)
*Han Jiang,Yao Xiao,Rachel Hurley,Shichao Liu*

Main category: cs.AI

TL;DR: 生成式AI对建筑设计新手有性能提升作用，但会降低一般创造性自我效能感，其效果取决于用户专业水平和提示策略


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在建筑概念设计任务中对设计性能、创造性自我效能感和认知负荷的影响，探索AI辅助设计的效果和适用条件

Method: 36名学生参与者完成两阶段建筑设计任务：独立设计和外部工具辅助设计（生成式AI组vs使用现有建筑项目在线资料库的对照组）。专家评估设计成果，参与者自我报告自我效能感和认知负荷，使用双重差分分析

Result: 生成式AI对所有参与者无整体性能优势，但对新手设计师显著提升设计性能；使用生成式AI的学生一般创造性自我效能感下降；认知负荷无显著差异，但迭代想法生成和视觉反馈提示与认知负荷更大降低相关

Conclusion: 生成式AI的效果取决于用户先前专业水平和通过提示的交互策略，对新手设计师有益但可能影响创造性自我效能感

Abstract: Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [238] [When an Approximate Model Suffices for Optimal Control](https://arxiv.org/abs/2601.09826)
*Andreas A. Malikopoulos*

Main category: math.OC

TL;DR: 本文提出了一种在模型不精确情况下的最优控制框架，证明了即使模型与真实系统存在偏差，只要满足特定条件，基于模型的最优控制仍能与真实系统最优控制一致。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，我们通常无法获得系统的精确模型，但传统最优控制方法需要精确模型。本文旨在研究在模型不精确的情况下，如何仍能实现有效的控制合成。

Method: 开发了一个最优控制框架，在模型与真实系统存在偏差的情况下，通过包含惩罚项的最优控制问题来合成控制策略。建立了模型哈密顿最小化器与真实系统最优控制一致的条件，并特别针对二次控制代价问题给出了可验证的充分条件。

Result: 证明了在特定条件下，即使模型不精确，基于模型的最优控制仍能与真实系统最优控制一致。为二次控制代价问题提供了明确的充分条件，并通过示例展示了即使在显著模型偏差下，控制轨迹仍能保持等价。

Conclusion: 精确的控制合成不需要系统的精确模型，而是需要控制选择的最优性条件对齐。这为数据驱动方法提供了理论基础，可以专注于识别模型与真实系统哈密顿最小化器一致的区域，从而支持在建模误差下的鲁棒模型决策和数字孪生的有效使用。

Abstract: In this paper, we develop an optimal control framework for dynamical systems when only an approximate model of the underlying plant is available. We consider a setting in which the control strategy is synthesized using a model-based optimal control problem that includes a penalty term capturing deviation from the plant trajectory, while the same control input is applied to both the model and the actual system. For a general class of optimal control problems, we establish conditions under which the control minimizing the model-based Hamiltonian coincides with the plant-optimal control, despite mismatch between the model and the true dynamics. We further specialize these results to problems with quadratic control effort, where explicit and easily verifiable sufficient conditions guarantee equivalence and uniqueness of the resulting optimal control. These results show that accurate control synthesis does not require an exact model of the underlying system, but rather alignment of the optimality conditions that govern control selection. From a learning perspective, this suggests that data-driven efforts can focus on identifying regimes in which model-based and plant-based Hamiltonian minimizers coincide, thereby providing a theoretical basis for robust model-based decision making and the effective use of digital twins under modeling error. We provide examples to illustrate the theoretical findings and demonstrate equivalence of the resulting control trajectories even in the presence of significant model mismatch.

</details>


### [239] [Global convergence of the subgradient method for robust signal recovery](https://arxiv.org/abs/2601.10062)
*Zesheng Cai,Lexiao Lai,Tiansheng Li*

Main category: math.OC

TL;DR: 研究因子化鲁棒信号恢复问题（鲁棒PCA、鲁棒相位恢复、鲁棒矩阵感知）的次梯度方法收敛性分析，建立了非光滑非凸目标函数的收敛框架，证明了在适当步长下避免伪临界点并收敛到全局最小值。


<details>
  <summary>Details</summary>
Motivation: 因子化鲁棒信号恢复问题（如鲁棒PCA、鲁棒相位恢复、鲁棒矩阵感知）的目标函数是非光滑、非凸的，且可能有无界次水平集，传统的基于下降性和强制性的优化算法分析框架不适用，需要新的收敛性分析理论。

Method: 针对局部Lipschitz半代数目标函数，在连续时间次梯度轨迹有界的假设下，建立了收敛框架：证明当步长为O(1/k)时，任何次梯度序列保持有界并收敛到临界点。通过调整和扩展现有轨迹分析方法验证轨迹有界性假设，在矩阵感知情况下仅需温和的非退化条件。对于秩一对称鲁棒PCA，证明次梯度方法对几乎所有初始化避免伪临界点。

Result: 建立了非光滑非凸优化问题的次梯度方法收敛理论框架；验证了鲁棒信号恢复问题的轨迹有界性假设；对于秩一对称鲁棒PCA，证明在相同步长机制下，次梯度方法对几乎所有初始化收敛到全局最小值。

Conclusion: 为因子化鲁棒信号恢复问题提供了严格的次梯度方法收敛性分析，解决了非光滑非凸目标函数的优化理论挑战，证明了在适当步长下可以避免伪临界点并实现全局收敛，为实际应用提供了理论保证。

Abstract: We study the subgradient method for factorized robust signal recovery problems, including robust PCA, robust phase retrieval, and robust matrix sensing. These objectives are nonsmooth and nonconvex, and may have unbounded sublevel sets, so standard arguments for analyzing first-order optimization algorithms based on descent and coercivity do not apply. For locally Lipschitz semialgebraic objectives, we develop a convergence framework under the assumption that continuous-time subgradient trajectories are bounded: for sufficiently small step sizes of order \(1/k\), any subgradient sequence remains bounded and converges to a critical point. We verify this trajectory boundedness assumption for the robust objectives by adapting and extending existing trajectory analyses, requiring only a mild nondegeneracy condition in the matrix sensing case. Finally, for rank-one symmetric robust PCA, we show that the subgradient method avoids spurious critical points for almost every initialization, and therefore converges to a global minimum under the same step-size regime.

</details>


### [240] [Line-search and Adaptive Step Sizes for Nonconvex-strongly-concave Minimax Optimization](https://arxiv.org/abs/2601.10086)
*Bohao Ma,Nachuan Xiao,Junyu Zhang*

Main category: math.OC

TL;DR: 提出一种新的光滑非凸-强凹极小极大问题重构方法，将其转化为联合最小化问题，并设计参数自由、非单调线搜索框架，兼容GDA算法，在数值实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有非光滑非凸-强凹极小极大问题的重构方法结构较弱，需要评估内部最大化问题。本文旨在提出更强的重构方法，保留原问题更多结构特性，并设计更高效的求解框架。

Method: 1) 提出新的光滑NC-SC问题重构为联合最小化问题；2) 设计参数自由、非单调线搜索框架，无需评估内部最大化；3) 框架兼容GDA算法，结合BB步长和非单调线搜索。

Result: 1) 重构方法保留了一阶平稳性、全局局部最优性、二阶平稳性和KL性质；2) 在温和条件下获得全局收敛率；3) 利用KL性质建立全序列收敛和渐近收敛率；4) 数值实验显示优于基准方法。

Conclusion: 提出的重构方法比现有非光滑方法结构更强，设计的求解框架具有理论保证和优异数值性能，为光滑NC-SC极小极大问题提供了有效的解决方案。

Abstract: In this paper, we propose a novel reformulation of the smooth nonconvex-strongly-concave (NC-SC) minimax problems that casts the problem as a joint minimization. We show that our reformulation preserves not only first-order stationarity, but also global and local optimality, second-order stationarity, and the Kurdyka-Łojasiewicz (KL) property, of the original NC-SC problem, which is substantially stronger than its nonsmooth counterpart in the literature. With these enhanced structures, we design a versatile parameter-free and nonmonotone line-search framework that does not require evaluating the inner maximization. Under mild conditions, global convergence rates can be obtained, and, with KL property, full sequence convergence with asymptotic rates is also established. In particular, we show our framework is compatible with the gradient descent-ascent (GDA) algorithm. By equipping GDA with Barzilai-Borwein (BB) step sizes and nonmonotone line-search, our method exhibits superior numerical performance against the compared benchmarks.

</details>


### [241] [Controllability score for linear time-invariant systems on an infinite time horizon](https://arxiv.org/abs/2601.10260)
*Kota Umezu,Kazuhiro Sato*

Main category: math.OC

TL;DR: 提出一种可计算不稳定系统可控性Gramian的缩放方法，并基于此定义两种动力学感知的网络中心性度量：体积可控性分数(VCS)和平均能量可控性分数(AECS)


<details>
  <summary>Details</summary>
Motivation: 传统可控性Gramian计算在系统不稳定时不可靠，需要一种能处理不稳定系统的可控性分析方法，为网络系统提供更稳健的中心性度量

Method: 引入缩放可控性Gramian，将可控性评分问题重新表述为数值稳定的优化问题，在无限时间范围内定义VCS和AECS，并证明其收敛性

Result: VCS和AECS在无限时间范围内具有唯一性，有限时间分数收敛到这些极限，两种分数在极限情况下可能显著不同，VCS考虑全系统可控性，AECS仅考虑稳定模式

Conclusion: 提出的缩放Gramian方法能可靠处理不稳定系统，VCS和AECS提供了不同的可控性视角，通过拉普拉斯动力学示例验证了收敛性

Abstract: We introduce a scaled controllability Gramian that can be computed reliably even for unstable systems. Using this scaled Gramian, we reformulate the controllability scoring problems into equivalent but numerically stable optimization problems. Their optimal solutions define dynamics-aware network centrality measures, referred to as the volumetric controllability score (VCS) and the average energy controllability score (AECS). We then formulate controllability scoring problems on an infinite time horizon. Under suitable assumptions, we prove that the resulting VCS and AECS are unique and that the finite-horizon scores converge to them. We further show that VCS and AECS can differ markedly in this limit, because VCS enforces controllability of the full system, whereas AECS accounts only for the stable modes. Finally, using Laplacian dynamics as a representative example, we present numerical experiments that illustrate this convergence.

</details>


### [242] [A two-step inertial method with a new step-size rule for variational inequalities in hilbert spaces](https://arxiv.org/abs/2601.10370)
*Jian-Wen Peng,Jun-Jie Luo,Abubakar Adamu*

Main category: math.OC

TL;DR: 提出一种两步惯性Tseng外梯度方法，结合自适应和Armijo-like步长，用于求解实Hilbert空间中拟单调变分不等式问题，无需Lipschitz条件假设


<details>
  <summary>Details</summary>
Motivation: 现有变分不等式求解方法通常需要Lipschitz连续性假设，限制了算法的适用范围。本文旨在开发一种无需Lipschitz条件、适用于拟单调问题的更通用算法

Method: 提出两步惯性Tseng外梯度方法，结合惯性项加速收敛，同时采用自适应步长和Armijo-like步长选择机制，在每步迭代中选择更优步长

Result: 证明了算法在无需Lipschitz条件假设下的弱收敛性，算法能够加速并补充现有Hilbert空间中变分不等式求解方法

Conclusion: 所提算法扩展了变分不等式求解的适用范围，通过移除Lipschitz条件要求并引入自适应步长选择机制，为拟单调问题提供了更通用的解决方案

Abstract: In this paper, a two-step inertial Tseng extragradient method involving self-adaptive and Armijo-like step sizes is introduced for solving variational inequalities with a quasimonotone cost function in the setting of a real Hilbert space. Weak convergence of the sequence generated by the proposed algorithm is proved without assuming the Lipschitz condition. An interesting feature of the proposed algorithm is its ability to select the better step size between the self-adaptive and Armijo-like options at each iteration step. Moreover, removing the requirement for the Lipschitz condition on the cost function broadens the applicability of the proposed method. Finally, the algorithm accelerates and complements several existing iterative algorithms for solving variational inequalities in Hilbert spaces.

</details>


### [243] [Algebraic Farkas Lemma and Strong Duality for Perturbed Conic Linear Programming](https://arxiv.org/abs/2601.10390)
*P. D. Khanh,V. V. H. Khoa,T. H. Mo*

Main category: math.OC

TL;DR: 本文在无限维对偶向量空间中的锥线性规划背景下，研究代数版本的Farkas引理和强对偶性，通过扰动最优值函数的超图/上图分析，建立新的凸分离特征，推导零对偶间隙的完整刻画。


<details>
  <summary>Details</summary>
Motivation: 研究无限维对偶向量空间中锥线性规划的代数Farkas引理和强对偶性，填补传统方法在无限维情况下的理论空白，为更广泛的优化问题提供理论基础。

Method: 通过分析原始和对偶问题的扰动最优值函数及其超图/上图，借鉴Kretschmer闭性条件，构建新的超图/上图集合，建立凸分离型特征，推导扰动Farkas型引理。

Result: 建立了多种扰动Farkas型引理，获得了零对偶间隙的完整刻画，当施加代数或拓扑对偶结构时，进一步探索了所提条件的深刻含义。

Conclusion: 在无限维对偶向量空间的锥线性规划中，通过扰动最优值函数的超图/上图分析和凸分离特征，成功建立了代数Farkas引理和零对偶间隙的完整理论框架。

Abstract: This paper addresses the study of algebraic versions of Farkas lemma and strong duality results in the very broad setting of infinite-dimensional conic linear programming in dual pairs of vector spaces. To this end, purely algebraic properties of perturbed optimal value functions of both primal and dual problems and their corresponding hypergraph/epigraph are investigated. The newly developed hypergraphical/epigraphical sets, inspired by Kretschmer's closedness conditions \cite{Kretschmer61}, together with their novel convex separation-type characterizations, give rise to various perturbed Farkas-type lemmas which allow us to derive complete characterizations of ``zero duality gap''. Principally, when certain structures of algebraic or topological duals are imposed, illuminating implications of the developed condition are also explored.

</details>


### [244] [Positive Damping Region: A Graphic Tool for Passivization Analysis with Passivity Index](https://arxiv.org/abs/2601.10475)
*Xiaoyu Peng,Xi Ru,Zhongze Li,Jianxin Zhang,Xinghua Chen,Feng Liu*

Main category: math.OC

TL;DR: 提出几何框架分析线性时不变系统的输出反馈和输入前馈被动化，揭示系统在特定正阻尼区域内可被动化，提供图形化分析工具


<details>
  <summary>Details</summary>
Motivation: 为线性时不变系统的被动化分析提供几何框架，帮助理解系统在何种条件下可通过输出反馈或输入前馈实现被动化，并量化被动化程度

Method: 基于几何框架，通过Nyquist图（SISO系统）或Rayleigh商（MIMO系统）分析系统传递函数是否位于特定正阻尼区域，建立被动化判据

Result: 提出正阻尼区域概念，建立被动化几何判据，开发图形化分析工具，可分析被动化频率范围、最大可达到被动指数及水床效应

Conclusion: 该几何框架为系统被动化分析提供直观工具，可集成到经典控制设计中，在电力系统稳定性分析中有实际应用价值

Abstract: This paper presents a geometric framework for analyzing output-feedback and input-feedforward passivization of linear time-invariant systems. We reveal that a system is passivizable with a given passivity index when the Nyquist plot for SISO systems or the Rayleigh quotient of the transfer function for MIMO systems lies within a specific, index-dependent region in the complex plane, termed the positive damping region. The criteria enable a convenient graphic tool for analyzing the passivization, the associated frequency bands, the maximum achievable passivity index, and the waterbed effect between them. Additionally, the tool can be encoded into classical tools such as the Nyquist plot, the Nichols plot, and the generalized KYP lemma to aid control design. Finally, we demonstrate its application in passivity-based power system stability analysis and discuss its implications for electrical engineers regarding device controller design trade-offs.

</details>


### [245] [High-Dimensional Analysis of Gradient Flow for Extensive-Width Quadratic Neural Networks](https://arxiv.org/abs/2601.10483)
*Simon Martin,Giulio Biroli,Francis Bach*

Main category: math.OC

TL;DR: 研究二次激活浅层神经网络在高维师生设置下的训练动态，分析过参数化对学习和泛化的影响，揭示标签噪声下的双下降现象


<details>
  <summary>Details</summary>
Motivation: 研究过参数化神经网络中特征学习仍然起核心作用的训练动态，理解过参数化如何影响学习和泛化性能

Method: 采用师生设置，研究二次激活的浅层神经网络，在扩展宽度机制下（师生网络宽度与输入维度成比例，样本量二次增长），使用动态平均场理论（DMFT）推导梯度流的高维极限动态方程

Result: 在l2正则化下分析长期动态，表征估计器的性能和谱特性；揭示标签噪声下的双下降现象（泛化在插值点后改善）；在小正则化极限下获得完美恢复阈值的精确表达式，量化过参数化对恢复的影响

Conclusion: 该研究提供了过参数化对学习和泛化影响的定量理解，精确表征了过参数化如何影响恢复性能，揭示了神经网络训练中的双下降现象

Abstract: We study the high-dimensional training dynamics of a shallow neural network with quadratic activation in a teacher-student setup. We focus on the extensive-width regime, where the teacher and student network widths scale proportionally with the input dimension, and the sample size grows quadratically. This scaling aims to describe overparameterized neural networks in which feature learning still plays a central role. In the high-dimensional limit, we derive a dynamical characterization of the gradient flow, in the spirit of dynamical mean-field theory (DMFT). Under l2-regularization, we analyze these equations at long times and characterize the performance and spectral properties of the resulting estimator. This result provides a quantitative understanding of the effect of overparameterization on learning and generalization, and reveals a double descent phenomenon in the presence of label noise, where generalization improves beyond interpolation. In the small regularization limit, we obtain an exact expression for the perfect recovery threshold as a function of the network widths, providing a precise characterization of how overparameterization influences recovery.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [246] [From rough to multifractal multidimensional volatility: A multidimensional Log S-fBM model](https://arxiv.org/abs/2601.10517)
*Othmane Zarhali,Emmanuel Bacry,Jean-François Muzy*

Main category: q-fin.ST

TL;DR: 将单变量Log S-fBM模型扩展到多维设置，提出mLog S-fBM模型，用于建模股票收益波动率，支持粗糙波动率和多重分形机制之间的桥接。


<details>
  <summary>Details</summary>
Motivation: 现有单变量Log S-fBM模型无法捕捉多维金融时间序列之间的依赖结构，需要扩展到多维设置以建模股票收益波动率的交叉协方差特性。

Method: 定义多维平稳分数布朗运动(mS-fBM)，其边缘遵循S-fBM动态和特定交叉协方差结构；通过将波动率分量建模为mS-fBM的指数来构建mLog S-fBM；将小间歇性近似技术推广到多变量设置，开发高效的广义矩估计校准程序。

Result: 模型在任意协Hurst矩阵（条目在[0,1/2)范围内）下定义良好，支持消失的协Hurst参数；在合成数据上验证有效；应用于标普500市场数据，股票Hurst矩阵对角线元素接近0（多重分形行为），非对角线协Hurst条目接近标普500指数的Hurst指数（H≈0.12），协间歇性非对角线条目与单变量估计一致。

Conclusion: mLog S-fBM模型成功将单变量框架扩展到多维设置，能够有效建模股票收益波动率的依赖结构，为粗糙波动率和多重分形机制之间的桥接提供了理论支持，并在实证应用中表现出良好的性能。

Abstract: We introduce the multivariate Log S-fBM model (mLog S-fBM), extending the univariate framework proposed by Wu \textit{et al.} to the multidimensional setting. We define the multidimensional Stationary fractional Brownian motion (mS-fBM), characterized by marginals following S-fBM dynamics and a specific cross-covariance structure. It is parametrized by a correlation scale $T$, marginal-specific intermittency parameters and Hurst exponents, as well as their multidimensional counterparts: the co-intermittency matrix and the co-Hurst matrix. The mLog S-fBM is constructed by modeling volatility components as exponentials of the mS-fBM, preserving the dependence structure of the Gaussian core. We demonstrate that the model is well-defined for any co-Hurst matrix with entries in $[0, \frac{1}{2}[$, supporting vanishing co-Hurst parameters to bridge rough volatility and multifractal regimes. We generalize the small intermittency approximation technique to the multivariate setting to develop an efficient Generalized Method of Moments calibration procedure, estimating cross-covariance parameters for pairs of marginals. We validate it on synthetic data and apply it to S\&P 500 market data, modeling stock return fluctuations. Diagonal estimates of the stock Hurst matrix, corresponding to single-stock log-volatility Hurst exponents, are close to 0, indicating multifractal behavior, while co-Hurst off-diagonal entries are close to the Hurst exponent of the S\&P 500 index ($H \approx 0.12$), and co-intermittency off-diagonal entries align with univariate intermittency estimates.

</details>
